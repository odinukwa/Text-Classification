The routes you proposed are incorrect according to the diagram you provided, the routes you need to configure on R2 and R3 are 

If "IP routing" is disabled then your frames are NOT getting forwarded by your CPU. I am familiar with the output that you are talking about though. The "show interfaces _ X/X stats" is a hidden command in IOS and as such it really isn't maintained the way most other show commands are. If you do a "show proc cpu sorted | in Input" then you will see the "IP Input" process. That is the best way that you can see how much of a tax the forwarding plane is putting on your CPU. 

The reason for this is that R2 and R3 do not have an interface connected to the 172.16.128.1/19 network, only R1 does. Since that network is not directly connected to R2 or R3, you cannot use it as a "next hop" for your static routes - it is not the next hop. R2 and R3 would have to forward traffic to R1 to reach the internet first, so it must be configured as the gateway for the default routes on R2 and R3. 

All of these terms arbitrary. A Vlan is a Vlan, some perform special functions though. I.E. Private VLAN configuration RSPAN VLAN configuration 

Reflexive ACLs were the first way to define directional traffic initiation and dynamically open up security for return traffic. Router logic on this below 

This is not so much related to MLD so much as it is to listening on the built-in IPv6 multicast groups. ff02::1 is the all-nodes multicast - I'm actually surprised you don't see that too (are you sure that you don't?) ff02::2 is the all-routers multicast, any device configured to forward IPv6 packets will listen on it. 

There is of course also the possibility of using large packets if the attacker knows that a well-crafted packet can cause additional processing time on the server in excess of the additional bandwidth cost. Simply dropping UDP packets below a certain size is far too blunt of an instrument to really be commendable, not least because this may well just result in your attacker changing strategy. For example, if the focus was to hammer your servers, the attacker could switch to an DNS amplification attack that aims to exhaust your available bandwidth. 

Enable IPv6 throughout the network, until IPv6 capabilities and connectivity are on par with IPv4. Wait for the day to come when IPv4 is no longer relevant. 

Given the prudence and importance of address conservation, the general approach to using a /31 should be "if it works, use it". Of course, you could take this a step further and start using private space for your point-to-point links, but this obviously can be problematic if you're going to run traceroutes from across the internet rather than within your own network, although even that can be mitigated somewhat by configuring your router to issue ICMP errors with a specific source IP address. In short, do whatever you can to waste as few addresses as possible (within the limits of best-practice and feasibility, don't start throwing NAT concentrators up everywhere) 

When you divide a network into smaller subnets, you no longer have the original network. Cut a piece of cake in half and you have two pieces of cake. The whole cake no longer exists. So it makes no sense to talk about the original network broadcast address. 

Routing protocols do not "achieve" L3 connectivity. They populate the routing (forwarding) table of the router with information learned from other routers. BGP is an "application" that runs over TCP/IP. In other words a BGP router uses TCP/IP to communicate with other BGP routers to exchange routing information. In order for BGP to work, you must already have L3 connectivity between the routers. 

I have to disagree with @ronroyston here. The OSI model is an idealized abstract model, and there are no protocols in use today that follow it. HTTP was created without regard to the OSI model, so there's no point to trying to make it fit. The TCP model is a little closer, because it lumps everything above transport into "application." As the Wikipedia article says, 

That depends on the model of access point and the amount of bandwidth each user requires. Cisco APs will allow up to 256 clients to associate, but normally you would saturate the channel long before then. 

Carrier refers to an electrical signal that is modulated, in the same way as radio transmissions. Sensing refers to detecting the presence of the carrier signal. 

This route-map should classify all traffic going back thru your RAS VPN (any source to a destination of your client ip subnet) and after the encapsulation/encryption it should route traffic out of your fast-wan interface. 

No, But what you CAN do is set up a box with SNORT. Or you can apply an access-list to your Span session port that is just "permit ip any any log" and that will log traffic source and destination addresses (along with TCP/UDP port info). Then if you can redirect these log messages to a syslog server you could export them in realtime to a CSV and have an application like SNORT alalyze the traffic flows. Or you can log them locally on the device and then extract/parse them manually to look for anomalous traffic flows. 

This configuration gives you interface rate-limiting down to the desired bandwith (it is a percentage so 3= 30mbps on a GigE interface) and also checks the traffic being sent thru your outbound L3 interface to make sure that the traffic complies. By outbound L3 interface I am referring generically to whatever L3 gateway is shared by both clients whether it is an SVI (interface Vlan X) or your outbound physical interface. 

Then how will your router know that it is not supposed to take traffic from another local sunbnet and encrypt it. Furthermore if you are running NAT on the same device, it adds further confusion. If your external IP on this VPN device is a public IP, then it also falls within the "any" statement of that ACL. "The reason they cited was because keeping the crypo ACL open like this and then limiting it with an ACL on the interface, you would cut down on the number of SA's built. How does this cut down on the number of SA's and is this the most efficient way to design VPN's?" This is technically incorrect, you will only have a singular SA (security association) between the devices for each tunnel, not for each individual TCP session or traffic flow. 

Larger images will consume more RAM - it does not impact the CPU once loaded although it will also incur a longer boot time since it of course has to be decompressed into memory and that takes time. On more modern platforms with speedy Intel Xeons, the decompression difference isn't very significant. On older MIPS or PowerPC processors, it is. 

This is basic subnetting/binary logic. There's 2 /25s in a /24, 2 /26s in a /25 (ergo 4 /26s in a /24) and so forth. The closest match to the requirements is to use which will leave you with one spare subnet. You cannot by definition have an odd number of subnets exist from any given subnet size. Either your teacher actually intended this and the 7 was a red herring, or somebody failed hard at math. 

Determining a loop really depends on the brand of switch that you have. For example, on an Extreme switch, I can run elrp-client on a VLAN and the switch will basically send out a broadcast frame on all ports for that VLAN and see if it returns by any of them, if so, it tells me which port(s) the frame was received back on, thereby revealing the loop candidates. On a Cisco, you can enable storm control, which is a bit more of a blunt instrument since it will basically block the port for a period of time until the status clears (or you clear the errdisable state) - generally speaking however, this sort of thing is only relevant when you're using Cisco switches in a mixed topology of devices that do not do spanning tree nor forward BPDUs. 

The router will provide an address to the AP. Connecting the AP to the PoE port is not currently supported by Cisco. In this small network, there is no need for multiple VLANs. The AP will find the controller because they are on the same VLAN. If youwere to have them on different VLANs, you could use either DHCP options (as @ronmaupin explains) or use DNS (my preference). 

Here is a high level answer: You will connect your two firewalls together (hopefully, you have vacant ports. If not, you will need to buy additional routers). The firewalls will forward traffic from one network to the other and vice versa. The link between the firewalls will have its own IP subnet (192.168.100.0/24, for example). Next, you will configure static routes on the firewalls so that each firewall knows how to reach to other. Finally, you will configure the firewall policy to allow traffic to flow from one network to the other. 

While it is possible to put servers on the external (i.e., public facing) subnet, it makes your servers more vulnerable to attack. A more secure way is to put your servers in a DMZ subnet on another router interface. You can then use NAT as required. 

If you think about that for a minute, you may change your mind. There's nothing to recurse because the next-hop simply isn't known. With no next hop, the local router has to assume the destination is directly connected. So, it ARPs for the destination address. Unless the next-hop router has Proxy-ARP enabled, it won't respond to the ARP. Proxy-ARP tells the next-hop router to respond to any ARP for which it has a route. In this case, it will respond to the ARP for the destination address. 

You may also have to append your "PERMIT-MNG" ACL to allow outbound IPSEC traffic (depending on what that ACL is configured to do) but you stripped it out of the running config so I can not fully comment on that. 

Or if your router does not have the "ahp" and "esp" options for an extended ACL, you can simply add in the specific ports that the ipsec client tunnels over, namely UDP ports 500, 10000, and 4500, and also TCP 4500 for good measure. 

You can simply append the ACL "REDIRECT-VIA-FAST-WAN" to route IPSEC traffic out your "fast wan" interface. 

For web management interfaces and the like, I have always found firefox to be the most compatible (least buggy) at interpreting HTML from various vendors and devices. However, I do not regularly use this browser personally, only professionally. 

Yes, The tunnels IP addresses need to be on their own subnet. The tunnel source and destination identify the points on the network where routers should encapsulate or de-encapsulate the traffic that is sent thru the tunnels. Having a route to your tunnel destination is a requirement for a tunnel interface to show "UP/UP" so really the 192.168.1.0/30 subnet doesn't even exist on the network until your source and destinations are configured. 

I use $URL$ on an almost daily basis to aid in forensics. I.e. If you have a mac address you can them obtain the manufacturer to guess at what the machine is. Then you can use only that mac address to find out other information 

At layer 2, all load balancing is, at best, done by an XOR or hash of the source and destination MAC, and if you're lucky, it may even read into layer 3 and hash that data too. At layer 3, however, where we're basically talking about multiple gateways (so, effectively, two physical links with a unique next-hop across each) you can max out the bandwidth across the links IF you're prepared to do per-packet balancing. Before I go on, per-packet balancing is generally a bad thing due to the fact that it can result in out-of-order packet delivery, this can be especially terrible with TCP connections, but that of course comes down to the implementation and most modern stacks can tolerate this relatively well. In order to do per-packet balancing, obviously one requirement is that the source and destination IP addresses are not at all on-link to the devices that have the multiple paths since they need to be routed in order for balancing to be possible. Redundancy can be achieved via a routing protocol such as BGP, OSPF, ISIS, RIP, or alternatively, BFD or simple link-state detection. Finally, there is of course a transport layer solution - protocols like SCTP support connecting to multiple endpoints, and TCP already has drafts in the making that will add options to do similar things. Or... you can just make your application open multiple sockets. 

Traceroute is used to determine the path between hosts, not between networks. From the PC on the left, you would traceroute to the PC on the right, 192.17.5.x. the result would show you the path used to get from one PC to the other (subject to all the usual disclaimers). Routers can (and often do) have multiple interfaces. In your diagram, for example, multiple interfaces allow the packet to take an alternate path if one becomes unavailable. That's what routing is all about. It's true, if you only have two routers, you only need one serial interface. But that's not the real world. I'm afraid I don't understand your question about colors. 

An interface can only be in one vrf. Otherwise, how would the router know which interface to use? If you don't specify a vrf, the interface is put into the global table. But your EIGRP process is configured to use vrf 4. 

Every switch that has guest devices on it should have VL 20 on it. Configure the security profile on the WAG102 to use VL 20 for the guest SSID (check "enable 802.1 VLAN"). For the management profile, uncheck the Enable 802.1q VLAN box. Make the AP ports on the switches VLAN 20 tagged and VL 1 untagged. Make the port for the BT router VL 20 untagged. If you have switch to switch connections, those ports should be set to VLAN 1 untagged and VL 20 tagged. Everything else (your internal devices, management interface, etc) should be on VL 1 untagged ports. 

Generally it comes down to interoperability - if you can guarantee that using a /31 is fine for both hosts on the link, and you are 100% sure that if one of the hosts fail, you will not be replacing it with something that can't handle a /31, you should absolutely just use a /31. In reality, the prime candidate for issues is going to be a routing protocol like OSPF, but as usual, this is implementation dependent - the vast majority of routers out there will behave properly when using a /31 - the adage "test your equipment" holds true. 

Using a /127 isn't terrible, but letting it go into your backbone as a /127 is. The reason for this is that, essentially, most modern router TCAMs can typically only handle up to 64 bits of address width at a time - this means that if you're in a situation where all routes are /64 or shorter, lookups can occur in a single cycle. Anything longer and it has to perform another lookup operation. Even on a TCAM that only has 32 or 48 bit width, going beyond /64 is obviously still significant. So, my personal recommendation is to allocate a /64 for every P2P link even if you only use a /127 on the wire - that way, when you bring up your routing protocol, you can then aggregate the /127 to a /64. My personal favourite, however is to allocate a reasonable chunk of your IPv6 space purely for facilitating P2P links (in my case, I reserved a /48) - this /48 is then blocked on all network edge interfaces at ingress as a destination. In this way, you're free to just go ahead and use a /64 on your P2P links and still have traceroutes, ICMP errors et. al work, but you are not vulnerable to NDP attacks from outside. Obviously not everyone is going to care about this and if the additional cost of using longer prefixes is acceptable to you (or you have super-duper 128 bit TCAMs) then you can of course ignore everything above. How scalable do you want your network to be?