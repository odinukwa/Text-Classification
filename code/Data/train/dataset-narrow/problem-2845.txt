In my test I keep adding and adding objects with the same image.. in this case a bullet... eventually the app crashed because it ran out of memory. Same thing happened to both situations with SpriteFrameCache and SpriteBatchNode they both dropped FPS to 30(when its supposed to be 60) and then just crashes...I understand the scenario is not real.And obviously its destiny its to crash if I just keep adding images without destroying objects that are no longer in use...but the question remains. I saw the same performance issue, however I read that SpriteBatchNode makes only one draw call making it best performance practice. Has anyone tried and can confirm the performance difference and exactly how can you prove this performance difference in code and in the app? 

When the loading screen loads objects like music cutscenes, the idea is to preload the objects, so... what should happen next? Do I transfer the objects to the next scene? or these special objects, media objects or even just images of the sprites, do they have to be part of a Singleton? According to my logic, singleton is a simple solution, that can I use whatever was preloaded in the loading screen to take to the game. The only drawback is that I have to keep management of these objects to unload them when out of the game scene.(its just an example, but its really close to what my game is doing). The thing is, i believe there is a more elegant solution to this problem. Anyone has any suggestions? or tell me if my method is wrong? 

It depends on your game. The containers are different in how fast the access to a specific element is, how quickly a element is removed and how quickly a element is added. 

Note that that way you would need a buffer for every ladder in your game. And even if you have only one ladder you will have to reset the mesh whenever it you want to display it with less steps. Based on that I think in this case the best wouldn't be to modify the mesh but rather to draw the parts the ladder is consisting of each on their own. Example: 

There is no reason. It's just a stupid thing which works but is completely unnecessary. The author probably just wanted to write down the chance as percent and not as permille . Better is: 

Classes and objects are just bundled functionality, nothing more. And that way you should work with them. Ideally you should build your classes around composition. The more advanced object should consist out of multiple smaller objects, and do all the communication needed between the smaller objects. The smaller objects should do nothing on their own and should know nothing about their parent. They just should do what is wanted from them. In the case of this question that would look like this: 

Im going through a tutorial to create a basic directx framework, and i've noticed that in there (and other tutorials, when i checked out) use inside the input element description. is there any reason to use this in a program over in terms of noticeable graphical difference? im thinking quadrupling the memory involved to store color would be a little heavy for larger programs. Also, i don't know if i have this right, but pure coloring isn't used much in more complex programs, and textures are used instead. so does this really matter? 

Well, i have been online for hours looking for solutions, but i have found none. Im looking for a way to create textures without the function . Since D3DX is deprecated i figured that DirectXTK was the way to go since it is supported officially. I found that i could use the function , but whenever i use it i get the following linker errors: LNK2038 mismatch detected for '_MSC_VER' value 1800 doesnt match value 1900 in LNK2019 unresolved external symbol "__declspec(dllimport) public: void __thiscall std::_Container_base12@std@QAEXXZ referenced in function "public: void __thiscall std::_String_alloc<0,struct std::_String_Base_types>>::_Free_proxy(void)"....... any idea why is this happening? (i have both the header included and the DirectXTK.lib library linked into the project)? and is there any simpler way to create textures, without the added whole library just for 1 function? 

The problem with adaptive difficulty is that games live from problems the player "overcomes". If you analyze the strength of the player then that is very linear and predictable. Either it is too easy all the time or too hard. I would suggest the opposite: Instead of changing the wave difficulty depending on the player strength let the player adapt to the difficulties ahead. Generate one difficulty progression at the start of the game and let the player know it in advance. If in 2 waves enemies will come that are resistant against arrow towers, tell the player. He will than be able to change his strategy accordingly. Add a user select-able difficulty level and you should have a game that is enjoyable for both "hardcore" gamers and "casuals". How you generate that wave progression is a different question and will require a lot of tweaking values until you get a satisfying result. I would suggest first putting down some "milestones" and then interpolating between them. E.g. 

For artists in general you should make it as easy as possible to add or change content in your engine, the more freedom he/she has and the easier he/she can experiment the better. 

I figured that what essentially needs to be done is similar to what the computer is doing when blending sprites. So what we need to do is: 

adding the .png file on the cache with SpriteFrameCache.. adding .plist with spritebatchnode adding the correspoding .png file, I didnt see any performance difference. 

My game has different, and detailed animations throughout the game. For example, the main character has an idle stance, so its not just painted still, giving him some life. Death animation, hurt animation, etc... even the background scenario has animations(which I don't think I went with the best approach here, but, it's working for now, this will be in another thread if not answered here) Anyways, the thing is, while the main character had these animations only that character was in the game at that time, so everything ran smoothly. After adding another character, the enemy, the burden of animations seems to overcharge the FPS and just slows the game down. The most obvious of this problems was that the spritesheet I was using was 1 per character, I figured how to use spritebatchnode efficiently and now 1 spritebatchnode covers the 2 characters animation set. The FPS tried to get back to normal, but its still laggy at times. This worries me because my game design has more enemies to the game, meaning that it will have this issue in a bigger scale. So I believe that its because of my animation approach, its poor, and inefficient making my game run slow. I have been trying to find the answer online with no luck, and I don't my approach is the best. I tried working some solutions by my own, but they end up in the same thing. THE ONLY, the only way I find how to reduce this problem is to make my sprites smaller, its not a big deal, but I wouldn't like this solution. 

For endless games like Geometry Wars your approach is a bit too static. I would calculate the wanted difficulty from multiple factors, then randomize it. With the following example harder enemies would get more probable while weaker enemies get less probable the more advanced you are into the game. Using random numbers increases the dynamics of your game, however can create "unfair" situations. Which is more important depends on your target audience. 

Find all systems that overlap with Point A. Determine a color and a alpha value at Point A for each system. In graphics context this is usually sampled from a bitmap, but in this case we just use a simple radial gradient function. Determine a "drawing order". In this case we sort by the size of the system so that smaller systems will be "drawn" on top of larger systems. Set the background color to a fixed value. Alpha blend all colors together, in the order previously determined. 

You might want to consider other, smaller, markets, such as the PC Indie market. The target audience may be a lot smaller, but you will be able to get ground much easier as your game isn't one of millions then but just one of hundreds. 

I am building a voxel engine with a similar mechanism to minecraft(yes, I know...). It works by loading and unloading individual chunks of 16*64*16 cubes each in a square grid around the player. This works fine for small render distances - like a 9x9 square grid of chunks. However, since updating a single vertex buffer entirely with a new mesh of millions of blocks each time a chunk is loaded/unloaded is inefficient, I have designed it so that each chunk has its own VB of fixed size, and rendering the entire world is basically looping through all the buffers, using . When I increase the render distance, say to a square grid of 11x11 (around minecraft's large render distance), creating the vertex buffers simply cannot proceed beyond a certain point, and returns E_OUTOFMEMORY. So my question is: How do i manage the memory usage of the vertices, to both maintain good FPS (not using a single buffer for the entire terrain) and to have decent memory usage? Additional Details: My vertex datatype is a struct composed of x,y,z coords, u,v texture coords and 3 normal coords. I know it can be improved in ways like a single byte for normals, since in voxels there are only 6 possible directions, however this will come later. The fixed size of each chunk's vertex buffer is 16*16*64*18 vertices (16*16*64 blocks with a maximum of half of the sides showing, or 36/2 vertices max per block). This could also use some work, as each of these buffers is around 10MB. How do games like minecraft handle this amount of data at once? (not to say i am using 64 blocks high chunks, where minecraft has 256) I have briefly considered using points as vertex shader inputs and expanding them to cubes in the geometry shader, to save 87.5% of the space, but this seems rather intense on the GPU. 

Generate waypoints from a god perspective and let the AI have a collection of waypoints it knows of (add them as the AI discovers them). Now whenever the AI has reached its temporary goal score all the reachable Waypoints by a few factors like distance and probability that it doesn't lead to already discovered area (if the path goes to the left and you already discovered a large area to the left it's likely that it will lead there, for example). Having that score you can now go to the waypoint with the highest score. This can be repeated till the AI has found the exit. 

This is just so you understand the logic behind drawing lines, if you understand Bresenham that might be the better option to implement. A truly perfect pixel line is rather simple, you just need to calculate the ratio like you did in the question, the ratio is the angle of the line. A 45Â° degree line will have a ratio of 1:1. Imagine moving a brush, if you have a 1:4 line that means for every 4 pixels you move on the y-axis you have to move one pixel on the x-axis. 

You can use a tile based collision approach independently whether the landscape itself is tile based or not. It's basically as fast as it can get and also as easy to implement as it can get. If you need a really high precision and memory usage is a issue you can use a quad tree instead of a simple array. (A data structure with almost O(1) performance but which is more flexible in how much detail is stored.) If you want more complex physics you probably want a collision polygon, so you can handle slopes, rotations etc. better.