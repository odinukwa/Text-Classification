I would argue neither is best for a beginner, but then "best" is a relative term that depends what exactly you are looking to gain. For example, if what you're wanting is to learn 3D graphics programming in order to gain skills that you could use to get a job as a 3D graphics programmer for a games company then those choices make sense. With this goal you might also look at DirectX. If however you have any other goal in mind then I would recommend looking at other options. For starters, while from your question one would assume you want to be involved in game development as a programmer, you didn't actually specify that. Both writing a graphics engine in OpenGL and building on top of Ogre are definitely for hard-core programmers. 

The second step is handled by turning the direction vector into a quaternion and then setting that as the player's rotation, something like: 

You're doing things in a good way. It's the way I do it, and clearly the way many people do it because this autoloader script (you can set a scene to automatically load first whenever you hit Play) exists: $URL$ Both of the first two options are also things your game may need for saving the game between sessions, but those are wrong tools for this problem. 

I would guess that your slowdown is because you are calculating a path for all characters simultaneously. Calculating a path for one character is fast but if there are two dozen characters in the scene then that can bog down. Instead you should spread out the load over a few frames. Stagger your AI updates so different characters update their path on different frames. It would be really noticeable if a character didn't react until a second later, but just one frame is not going to cause bad reactions. 

The main value we need here is the Distance - 4. Setting this to 4 will create a third person camera (Although with units other than a marine, you may need to edit this). 0 will create a first person camera. The same goes for the Target - Z Offset - 1. A taller unit will need a higher value to raise the camera up some. Global Variables A few global variables are needed, the names and types of which are indicated below (Name - Type - Value - (Description)): 

You really should tell us how this is being constructed as different technologies can have different advantages to your situation. Is it in Flash? PHP? HTML5? JavaSript? Java? The "web" tag doesn't give us much to go off. That being said: One of the most secure ways to transmit points score is to not let the client side decide what those points are. What you want is to create points based events: 

Please excuse the roughness but I hope this gives you a decent idea for structure. Formatting your XML a little better you can then create a parser to create the scenes and the requirements in them, here is an example of both the scenes above in one: 

There is nothing stopping you from using 2D sprites in a 3D world. Unity has support for 2D, 2.5D and 3D in all combinations of the set together. "I want 3D models in a 2D game." - Fix the camera to a pan only system and use 3D models. "I want 2D models in a 3D game." - Fix the camera to follow a 2D sprite but use the 3D character controller. Try it. If it doesn't work or you have issues along the way, come back and we can help! 

Shaders in 3D art applications almost never have anything to do with shaders within the game engine. The parts of the model that carry over are fundamentals like the mesh geometry. That said, fairly standard stuff like an alpha channel in the texture (to make parts of the model transparent) usually operate the same way in both places. Alpha transparency and diffuse color are about the only two things that you can make this assumption about. In other words, create diffuse texturing and alpha transparency in your 3D art application so that you can see what the model will look like in Unity, but realize you'll be setting it up again (this isn't hard, just telling Unity which image to use for transparency) within Unity. 

As I recall (haven't played it in a long time) the old school Shadowrun game on Genesis had a twist on your network trace mechanic for more dangerous targets. Less risky hacking targets would simply kick you out of the network, but more dangerous targets could actually trace your physical location and then send goons after you. That would certainly ratchet up the pressure to be fast! 

Since you're using Ogre then you should probably read those ogre3d.org links, but if you want to know the math behind the intersect algorithm, here it is: $URL$ When I do that I also use a bit from $URL$ 

You need to clamp the vertical rotation. I don't know off the top of my head the simplest way to adjust that code, but it'll just involve changing a couple lines around the transform.RotateAround() stuff, to use Mathf.Clamp() for the angle around the x-axis. I think you just need to put in right after incrementing y. This way the downward rotation will be limited to straight down and never allowed to go too far. 

I got this fully functioning in Unity on an empty game object, you need to make sure you make the list with the new statement and also ensure you have the imports correctly defined. 

Firstly, you need to use a switch case statement and decide which direction overrides the others, for example, if they press all four buttons, which button should be listened to for input? This gets put in order within the switch statements. Edit: For clarity about the above statement. You do need to use a switch case statement (or similar structural logic) to stop the following from happening. 

EDIT: Going back on my answers I realized this is not up to scratch and needs the tutorial content. Here it is: STEP 1: Choose the scale you want. Use a view for every room and have the port W and port H scaled appropriately. So, for example, if you were using a scale of 2... it would look like this, in GM's room editor. It is important that this is consistent for all rooms. If you have lots of rooms, it might be easier to do this via code*. I prefer to do it that way, because then the values aren't constant and I can support multiple different scales. STEP 2: Create 3 scripts, screen_init, screen_begin, and screen_end. Here is what goes in each of the scripts... Quote from: screen_init 

Just to extract an answer from the comments: Zophars Domain shows you a list of tools that you can use for NES ROMs including Graphics Extractor and Inserter which allows you to extract and insert tile graphics from the ROM. To use this you need the Extractor executable and the Inserter. Use the extractor to get the tiles first, edit them in your editor of choice (MS Paint ftw) and then use the inserter to pop them back into the ROM. Make sure you create a backup in-case it corrupts the ROM image. 

petr's answer assumes you already know how to deploy a Flash app on Android; maybe you already know that, but you don't mention it in your question so I want to point out that you can package a Flash .swf as an Android .apk using AIR. Once you are actually deploying your in-development game as an Android app then you get to the higher level concerns of adapting your game logic to the new input devices. 

The main difference in concept is also the main difference from a software engineering perspective: AR needs a view of the real world, VR does not. Thus AR has the challenge of overlaying graphics onto a live view, while VR has the challenge of completely replacing the environment around the viewer. 

I would tend to create a Scene object that all the various game states inherit from, and just create a variable called "currentScene" in the Main object. Then instead of a switch statement in the main loop, just call currentScene->Update(); each Scene would know what it specifically needs to do for input handling and rendering. To switch the game's state just switch which Scene is in currentScene. 

After using some modeling tool to build the geometry, a great free tool for lighting your level is gile[s] $URL$ 

There are a couple spots that could be relevant. First off, you can set the Min API Level in Player Settings (click the Player Settings button on the bottom of that screenshot). But besides that, you can manually provide your own manifest file; it looks like right now you are simply using the manifest that Unity automatically generates if you don't provide one manually. When an Android app is built, Unity puts the generated manifest file in the Temp folder at StagingArea/AndroidManifest.xml; copy that file to manually edit it. Provide one manually by putting it in Plugins/Android/ alongside the plug-in JAR. 

Why calculate the trajectory for the sounds/slow down effects? If you split the act of slowing down the camera and playing effects into sections upon approach to your squishy victim then you can essentially play them on condition of their proximity. This is a great example that comes to mind. The proximity slow down effects employed in Peggle The ball gets close to the peg and starts slowing down. This is actually based completely off proximity, no trajectory involved. If it gets close enough to the last peg it starts a drum roll and slows the game-play down, if it does not hit the peg and goes out of range you hear "Awww.. :(" and all returns to normal, but if it collides you will get the full fledged Overture and winning screen. This is a great technique if you approve of making your player go "Holy cow, I nearly got hit!". If you have a start-up sound/effect for a death cam that will play before impact then simply trigger this when the stone is close enough that even if the player moved at maximum speed in any direction - they have a great change of getting squished. Say your rock is falling and you want to begin the slow down effect to ~4m away from the player: You start by triggering slow-down, move your camera and start focusing on the player - if the rock is then interrupted by other debris then simply exit the slow down focus and your player continues as normal. 

First off, note that in game development this role is typically referred to as "artist". Referring to them as a "designer" could be misleading because a "game designer" is completely different from a "graphic designer". When you use the full title it's clear what you mean, but be careful about being unclear when shortening the term. Second, your question is somewhat circular. I mean, you ask: 

The rule of thumb for cloning games is that they can't copyright game mechanics but they can copyright or trademark the specific names and art. Thus making a game that plays the same but has a different title and different artwork is fine. 

aha I see in your posted code that you created LampPost as a literal object, and not as an object to instantiate. So you'll do something like: 

You can't really go to a game development company and have them make your idea. Unless of course you have a ton of money to pay them to make the game for you, in which case you aren't so much getting another company to make your game as funding a game company. Besides what people have said in other answers, refer to this page on Sloperama: $URL$ Near the end of that page is this great explanatory metaphor: 

Well, you do need a basic understanding of physics, but I mean like what they teach in physics class in highschool. Assuming you went to highschool, then no there isn't any additional knowledge of physics that you need as a prerequisite. That said, you're going to be learning a number of new concepts and/or applying concepts in ways that are new, because there frankly aren't many other places other than game development where that stuff would come up. I mean sure, high-end car engineering for example, but it's hardly the case that you need a degree in mechanical engineering before you can program a game. Don't worry that you're missing prerequisite knowledge, but do accept that you're going to encounter unfamiliar concepts, so you're going to have to lookup what they mean and then spend lots of time experimenting. 

Then look for and/or <- this will give you the values you need. It took 2 minutes to search in Google which gives me the impression you didn't, the API should be included with the download for the Unity Plugin - I'd highly recommend reading it. 

It will allow you to restrict physics but within Unity's scope and physics engine. You can jiggle around with the script to make it lock only one object to be moved etc but this should get you started. 

According to the way the documentation lays out the single alpha channel for both specular and transparency you are correct in your assumption. If you want full control over the textures my solution would be to separate your tire and rim-hubcap models so you can texture each individually. This would allow you to create a Transparent Bumped Specular on the rims for the cutout and shine control but also allow you to use a Bumped Specular on the tire wheel so you can get a more rubbery look without the transparency. 

Initial idea based off your Actor structure: You are basically just wanting a character to be null, if you have removed it from the list that updates and renders it why not just set to handle resource disposing in and track the resources themselves as part of your overall design. Otherwise these items will not be handled correctly and cause issues longer down the line. MonoBehaviours are handled behind the scenes and have a lot of code behind the simple function, so it's not as simple as a one line solution: 

The relevant keyword to lookup is TextAsset When you drag a text file into Unity, it gets treated as a type 'TextAsset'. Actually load the data either by linking it through a serialized variable or by using Resources.Load (just like any other asset: image, prefab, whatever) 

Short answer: probably Longer answer: A component-based entity system becomes more valuable quickly as the number of distinct entity types increases, so your saying "20-30 different entities" is an important consideration. However it doesn't really take many different entities for component-based to be a big advantage. 20 different entities would certainly benefit a lot from a component-based system, although you also don't think 20 is many entities so I'm curious what exactly you consider "different". For example, I wouldn't consider an old brass key and an electronic keycard to be different entities, but rather two instances of the same entity with different art assets assigned to the entity. Would you consider those to be different entities? 

I tend to avoid singletons too but there are a few objects that make the most sense as singletons and a central messaging system is one of them. Despite the rants I've heard, singletons are certainly much better than global variables/functions because you always have to deliberately address it (versus global values just magically appearing out of thin air). In the end every message sender and receiver must have some common point of intersection, and it is much better to keep your objects decoupled by having a common singleton shared by everything rather than have each of your message senders directly know about the message receivers. While I'm sure some other architecture could be devised for your event system, to me it seems like a waste of effort to over-think it, especially when using an event system is already a big win over not using one. EDIT: As for your specific example of an explosion event dispatched on a periodic trigger, I would probably have the events dispatched in some other object (like the turret gun or whatever causing those explosions) and not in the central event system. However those events would still be dispatched to the central event system. 

I would suggest not setting your vertical speed to -10 as this is essentially doubling the effect of gravity which can have some serious adverse effects later on. I would replace the collider with a spherical based one on your character: 

Now looking at your diagram is actually all we need to do to show why using the red square is the best convention and why having the dead zone arcs at north east south west positions of that square are necessary. I'll use my best PhotoShop skills to show you. If I have a game which my speed is linear in each direction based on the raw individual values from the stick for both x and y (let the range on the red square x and y be -100 to 100) then I have this situation: Bob is wearing a magic hat that allows him to float in any direction and at a constant x and y speed (because his hat has thrusters on the north and south sides as well as on the east and west sides) meaning he can move 100 units/s in both north and east directions at once. 

With so many resources to trace for rewinding a level it is often less processor intensive to simply destroy the entire level and reload all the assets again in their default or mission specific states. Having to reset specific objects involves searching a list of the objects in the scene and then accessing their properties to reset them. Instead of that bullet hole in the wall being repaired by cleaning up, you don't need to caluclate any clean up actions, just delete the whole level from memory and reload it from scratch. This means reloading a level is dones from one state object (a save game file or a mission script) and not needing dynamic caluclations. For consoles this is exacerbated by the loading times involved with discs. It also helps PC games as it can take into account computers that won't have the procesing power to make the loading times acceptable. So for large content levels - Loading a single state instead of calculating and "rewinding" one: