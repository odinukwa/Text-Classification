The solution was xinput for the time being. I have a little script I can run, so for future knowledge, what I was looking for included the following: 

Using xev to figure out which button was mapped to which button. lshal and xinput to gather information on the devices that were plugged in. xinput to actually set the thing to work the way I wanted. Specifically: xinput set-int-prop "Kensington Kensington USB/PS2 Orbit" "Evdev Wheel Emulation Button" 8 3 xinput set-int-prop "Kensington Kensington USB/PS2 Orbit" "Evdev Wheel Emulation" 8 1 

Where the 8 doesn't mean a whole lot. The '3' is the button I wanted to map. The '1' is basically the boolean true. 

Background: I am a programmer that occasionally has access to other computers when on vacation or something. These are generally the machines of friends or family, so randomly installing Ubuntu on it wouldn't be terribly polite. I would like to completely avoid the hard drive of the target machine. Not all of these machines can boot to USB either, so that simple solution is out. What I want to be able to do is boot to an Ubuntu live CD, plug in a USB drive and then grab various updates and other applications, installing them to the USB drive. Later, on another machine, put in the live CD, after boot, put in the USB drive and then magic, I have all of the updates/applications/data/etc that I've tossed onto the drive. I suspect that it should be possible to mount /home, /var, /usr, and maybe a couple of other locations from the USB drive or something along those lines. So is this possible and what do I need to do? 

I have a roughly 2 year old Macbook (10.5). I have iTunes 10. When iTunes is playing MP3s, I see CPU usage of the iTunes process in the system monitor ranging from 65%-75%. When I pause the music, I see CPU usage of about 65%-75%. I do not have any visualisations going, to my knowledge I have not turned on any CPU destroying features, my music library isn't tiny, but it's hardly huge (3GB). This is mildly annoying when I'm plugged into the wall as I only have slightly longer compile times, but if I am out and about, this is a major drain on the battery. Using VLC I see CPU loads of ~= 10% at the most when listening to music and generally lower. What the heck is iTunes doing? 

Check your firewall, it's likely blocking the ingress of your SSH and pings. Are you trying to connect to SSH via root? That's disabled by RH, you need to enable that. 

VMware Workstation and QEMU emulate & virtualize different hardware. Since XP is so old, it can rarely recover from a major subsystem change. First thing to try is removing the VMware Tools from the XP image while it's running in Workstation. This should remove any VMware specific drivers and may allow the system to boot. If that doesn't work, you will likely need to do a repair installation of XP. Boot from your XP CD-ROM, when you get to the setup screen, you want to press enter, not R. Follow the setup wizard, when you are prompted the second time to do a repair, press R, setup will detect the correct hardware and install the necessary drivers. Illustrated repair: $URL$ 

Older versions of the SonicWall clients have issues with Windows 10 (and Windows 8). There was a Windows and DNE fix offered for a while. Recent versions of the client starting with at least 4.9 will work with Windows 10. I believe the current version is 4.10 and also works fine with Windows 10. I have seen on occasion where a Windows update breaks the VPN, but all that's needed is a reinstall, no immediate reboot necessary, for the VPN to work again. 

In Search, search for and then select: System (Control Panel) Click the Advanced system settings link. Click Environment Variables. In the section System Variables, find the PATH environment variable and select it. Click Edit. If the PATH environment variable does not exist, click New. In the Edit System Variable (or New System Variable) window, specify the value of the PATH environment variable. Click OK. Close all remaining windows by clicking OK. Reopen Command prompt window, and run your java code. 

I'm managing 2 linux servers and looking to copy the data from one to the other. I'm looking to just copy these files on one server first then zip it and then scp it over. I need to copy a 100GB folder, but there are many subfolders in this folder. And in these folders that are some files that are 5MB+. How can I make a copy of this folder without including any of the files that are over 5MB+ in linux? 

I've been getting data from api websites by using file_get_contents or curl, but I never knew whats the difference from them. They seem to have the same results, but now there is Guzzle for php. What is the difference from all these 3? Why would one choose one over the other? 

I have no way to open ports on my router as its a shared office environment. I'm able to access my nas via CloudLink, but how do I get my Qsync to work with it? I can't find any docs in order to get this to work. 

I've been using dropbox's public folder to upload small files I want uploaded to my server via the wget command. Is there a better faster method than this without setting anything up? Is there an online service for this kind of thing? 

Is there a tool or how would one encrypt data into a jpg file and be able to upload to photo hosting service? Has anyone done this with RAW image files as those can be much bigger and can hold more data. Another thing is has anyone done this to much larger files and span it across multiple jpg files? 

Recently I've been getting notification popups on certain websites. I don't know if I accidentally clicked it or not, but its really annoying. I found that you can disable all of this completely in the "content settings" of chrome, but I want to leave it on with permission to ask. I couldn't find the stupid site in the list of "exceptions", but found a $URL$ wildcard indicating its being set by a plugin. But problem is WHAT PLUGIN? I want to remove this site from notifying me. Is there a way to do this? I also checked off "Do Not allow any site to show notifications" in chrome and it still showing up. 

In Windows diskpart should be able to delete these. It's a command line prompt you run as administrator. You need to launch and elevated command prompt and run diskpart. See: $URL$ In diskpart: 

After you click in the search bar, the search tab is now selected. At the end of the search section is a "+more" command, clicking that will bring up a list of categories to add to the search. 

repeat steps 3,4,5 for the remaining partitions until all 3 have been removed. Be very careful when selecting and deleting, make sure you've got the right disk and partition before you delete. If you select and delete the wrong partition you could lose your data some pics here: $URL$ 

Integration Components After the installation completes, you'll need to manually install the Integration Components (IC). (Same as the answer I provided on the other post you linked) You will need to get the IC from an older version of Hyper-V. I have them on my wordpress site here: $URL$ You can also download Hyper-V server from Microsoft and extract them, if you want them from a trusted source. The 2012R2 version of the IC should auto-install after you mount the ISO to the dvd drive and install all the necessary drivers. Unknown Devices You will see 2 unknown devices. Per Microsoft these are expected and can be ignored for OSes earlier than Windows Server 2012 R2. ($URL$ XP on Hyper-V is definitely achievable and generally trivial to install. One other note, audio will require you to use RDP to connect to XP and the host system must have working audio. 

Instead of messing with the Registry, have you tried via the Control Panel. Under "Associate a file type or protocol with a program" you can select the extension and then associate a program with it. Clicking the "Change program" button allows you to browse to the folder where the .exe is. Also, make sure you're selecting the correct .exe file. If you double-click the .exe you want to associate, does it launch the program you're expecting? 

I first installed WSL on win10 then did an uninstall via the command: lxrun /uninstall / full I then try to reinstall with lxrun /install But I'm getting the Error 0x80070091 -- I'm not sure how to solve this issue. 

But when i do a sudo su < user >, php is is loading the cgi version which is breaking some of my applications that require php-cli version. 

I'm thinking about using the google cloud storage as my main storage device instead of buying a bunch of my own nas devices. But what i'm wondering is my data secure and backed up via with google's massive infrastructure. So my question is, how does google cloud storage handle redundancy in case of a drive failure? do they even use raid or is it something much better? 

I'm currently in a symbolic link directory and I want to go up one level in the absolute path, but I cant as it will hit me back up to my home directory (~). I can do pwd -P to get the absolute path, but how do I pipe that result into the cd command? I always thought it was this: {} Sample: 

Page notes uses Crypto-JS library ($URL$ you can use that directly if you want to manually decrypt your notes. Something like CryptoJS.AES.decrypt(encrypted_notes, passphrase) should work. 

I'm in charge of migrating an existing server's websites to another server, but I require doing git clone and other related commands that require me to reach out into the internet and grab files. I can't even do a wget to pull in a file. The original server admins that set this up totally screwed it over with the blocked ports like :80. I cant do anything with wget or git clone as it just hangs and can't reach any of these sites. But it can grab from redhat repos only. And I even disabled the firewall. It's something to do on their end. Is there some sort of ssh tunneling where I can reroute the data from the server through my ssh connection in order to reach these websites? Waiting on the server admins to do anything takes days to weeks since its an outsource IT company. I just want to get it done today.