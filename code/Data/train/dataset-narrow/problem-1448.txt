First of all, your given sample features zero-padded 2-digit months and milliseconds which you currently don't reproduce. The mentioned 'smell' is probably caused by 

PS: Above code should translate pretty easily to coffeescript, but as I am not very well versed in that language, I chose to give code samples in vanilla JS. Edit: Instead of you probably want to use . 

Instance method vs. class method vs. function: You declared a constructor function whose instances all come with their own individual method. Since the method doesn't rely on other instance properties, it should probably be a class method instead. In JavaScript, a class method is simply a property of the constructor function: 

Notes Declaring some of your variables as can protect you against erroneous reassignment or rebinding, as any assignment to variables will throw a at runtime instead of silently continuing execution. Instead of I recommend using the unary plus operator which is "the fastest and preferred way of converting something into a number" according to MDN. Parsing I like your separation of input parsing and the actual program logic. However, you create a lot of temporary copies by first splitting and then mapping the array. If you like, you can use iterators or generator functions to parse input with only constant additional required space: 

I recommend removing the inline event handlers from your HTML document for a cleaner separation of markup and logic / JavaScript similarly to how you separate markup and style / CSS. You can then add all event handlers with a few lines of code as follows: 

Now, when the number of pages changes, you need to touch your code and modify the initialization. So you will probably want to introduce function arguments with default values: 

If you modify your function to increment frequencies for string and decrement frequencies for string , you can simply sum the absolute frequencies to get the number of required deletions. If you combine that with a more descriptive approach by replacing for-loops with and , you get a simpler implementation: 

naive: 10.82 incremental: 4.74 There are some asserts in the code which all hold and might help you read it. The given benchmark parameters and grid are all typical of my simulation. Background: Imagine a geographical area divided into disjoint regions (cells), where each cell has a base station which provides service for cellphones within its area. Two mobile callers within some distance of each other cannot use the same radio channel, lest their handsets will interfere. When a new caller requests service, we must therefore find the set of channels that are free in the cell of the caller and the neighboring cells within some given distance. We can represent such an area and the channels in use with a boolean 3D matrix where the first two dimensions represent the geographical position (i.e. the cell) and the depth represents the channel. Cell areas often are circular in the real world, and we can approximate them as hexagons instead. Finding the neighbors of a cell we must therefore use the hexagonal distance. Assigning new calls requires to find the channels that are free in the nearby area (eligible channels). However to select channels that will optimize grid usage as a whole, statistics, i.e. the feature representation, are useful. So when an action happens, i.e. a caller terminates a call or a new one requests service, there's a set of legal actions to take depending on the action type ( or ) and the grid. The afterstate is how the grid would look after performing an action, and the feature representation of that afterstate, when compared with the others, informs the decision making. 

Given a boolean 3D matrix and a set of actions specifying bit flips at certain positions, a set of resulting matrices can be obtained, one matrix for each action, as if executing each bit flip individually. A statistic (feature representation) defined on a matrix which for each row, column and depth counts the number of active bits at the same depth within some hexagonal distance in the first two dimensions of that row and column. What's the fastest way of getting such a statistic for each of the resulting matrices (afterstates), given the previously mentioned original matrix (grid) and actions (, and )? For example, given , , the first afterstate of can be obtained by . Actions are guaranteed to be bit flips. If the feature representation for is known, the feature representation for can be derived and need not be found from scratch. In the code below, the naive approach () and an incremental approach () are given. The naive approach should be easiest to understand. This is the hot hot hot path of my system and I want to make it faster, but I'm no speed demon. Any tips and comments on anything else, small or large, is also appreciated. Below the code is some background which is not required reading but may make things more concrete. 

Replacing above regular expression with e.g. a much more refined allows you to capture floating point numbers, negative numbers and whitespace. To support more operations, simply append them to the object literal, e.g. and add to the operator capture group within the regular expression. 

returns an array. So don't bind the result to a variable called . Or better, since you can't have multiple array entries with the same name, replace with : 

Especially the last two changes are subject to personal preferences - some prefer the declarative style, some stick to everywhere - it's your (team's) choice. 

Also, it is not clear how strong the given assumptions are and whether or not violations of those assumptions can occur and should be dealt with. 

Now, it is much easier to see that the inner loop is actually just checking the existence of an element within an array. You can use the faster built-in method instead: 

Of course, you might want to encapsulate above code in a function or even more versatile, a generator function and replace with . However, since you only have four different step-sizes of 1, 10, 100, and 1000 you can encode them manually and come up with an even simpler generator function as follows: 

See also Is JavaScript a pass-by-reference or pass-by-value language? Now, if we look again at your implementation, we note that you already perform a regex test. We could perform a regex matching instead and get rid of all those redundant calls. I wrapped this new implementation in a documented function and ended up with: 

We can get rid of the self-made zero-padding by using or - if compatibility is a concern - one of its many alternative implementations. We can't really get rid of the many hardcoded constants, but we can name them to make them meaningful and less magic in appearance: 

As already pointed out, you need a more sophisticated approach to testing runtime performance of runtime-optimized code produced by modern JavaScript engines. I compared the performance of your datastructure against the built-in as well as plain objects on the well-known performance testing playground jsperf.com based on the benchmark.js library and got the following results on Firefox 53 / Ubuntu: