In his 1999 workshop paper "A Metric Model of PCF", Martín Escardó showed that it is possible to give a simple interpretation of PCF in the category of complete ultrametric spaces and nonexpansive maps. He showed this model was adequate, and that it could model the addition of a timeout construct (i.e., an operator which would run its argument for some finite number of steps, and either yield an answer or signal an error if it failed to terminate within the time limit). He then suggested that it would be natural to investigate whether the metric model was fully abstract with respect to PCF+timeouts. 

What you want exists, and is an enormous area of research: it's the entire theory of programming languages. Loosely speaking, you can view computation in two ways. You can think of machines, or you can think of languages. A machine is basically some kind of finite control augmented with some (possibly unbounded) memory. This is why introductory TOC classes go from finite automata to pushdown automata to Turing machines --- each class takes a finite control and adds some more memory to it. (Nowadays, the finite control is often limited even more, as in circuit models.) The essential thing is that the finite control is given up front, and all at once. A language is a way of specifying a whole family of controls, in a compositional way. You have primitive forms for basic controls, and operators for building up larger controls from smaller ones. The primordial language, the lambda-calculus, in fact specifies nothing but control -- the only things you can define are function abstractions, applications, and variable references. You can go back and forth between these two views: the $snm$-theorem is essentially a proof that Turing machines can implement function abstraction and application, and Church encodings demonstrate that the lambda-calculus can encode data. But there's nontrivial content in both of these theorems, and so you should not make the mistake of thinking that the two ways of understanding computation are the same. Researchers in complexity and algorithms typically take machines as fundamental, because they are interested in costs and in feasibility results. To exaggerate a bit, the basic research question they have is: 

A subspace $S$ of a metric space $A$ is compact if it is complete and totally bounded. Here, complete means that every Cauchy sequence in $S$ has a limit also in $S$. For $S$ to be totally bounded, we must have for every radius $r$, that there is a finite set $U$ of open balls of radius $r$ whose union covers $S$. I would like to know if anyone has studied spaces where the size of $U$ is bounded by a function of $r$ -- for example, where $U(r)$ is $O(\frac{1}{r}^k)$ for some $k$. The reason I am curious is that I am investigating models of reactive programming (ie, stream functions), where boolean streams are given the Cantor metric (two streams have a distance of $2^{-n}$ when the first position at which they differ at time $n$), and programs between streams are interpreted by functions continuous with respect to this metric. While the continuity requirement functions nicely capture causality requirements very well, it unfortunately also permits stream functions to require their whole history to compute a value (that is, functions $f(x)$ may require their whole history $x_0, \ldots, x_n$ to compute $f(x)$ at time $n$). One idea I have for understanding this phenomenon is that the Cantor space is compact, and that at radius $2^{-n}$ you need $2^n$ balls to cover the space -- that is, there are $2^n$ length-$n$ binary sequences. So I have a vague idea that if somehow there were a way of equipping the Cantor space with an even coarser metric, I could model computations which are permitted to remember less of their input. (Eg, a polynomial bound would permit you to use space logarithmic in the elapsed time.) 

and figuring out (a) which context to use and (b) how to orient this equation gets tricky. IMO, the state of the art for rewriting-style approaches are Sam Lindley's Extensional Rewriting with Sums and Gabriel Scherer's Deciding Equivalence with Sums and the Empty Type, both of which consider the typed lambda calculus with both products and sums. 

Note that the type dependency permits us to define a datatype of terms containing only the well-typed terms of T. We can then give an interpretation function for the types: 

Linearly-typed languages can eliminate the reference count (essentially because counts are 0-1: either the value has a single reference to it or it is dead and can be freed). However, stack allocation still does not suffice. This is because it is possible to form function values which refer to free variables (i.e., we need to implement function closures), if you allocate things on the stack, then live values can be interleaved with dead values, and this will cause incorrect asymptotic space usage. You can get the right asymptotics by replacing a stack with a "spaghetti stack" (ie, implement the stack as a linked list in the heap, so that you can cut out dead frames as needed). If you want a real stack discipline, you can use type systems based on "ordered logic" (essentially linear types minus exchange). 

The category of coherence spaces is both Cartesian and monoidal closed. I would like to know when pullbacks or pushouts exist for this category, and when some monoidal analogue of pullbacks or pushout exists (and how to define it, in case this notion makes sense). 

Categorical approaches to query languages is a bit of a niche interest, but I think it's a very interesting niche! Two of the key figures in this area are Peter Buneman and Torsten Grust. Obviously, they didn't do all the work, but if you start with their papers and trace out the citation graph, you'll get pretty good coverage of the area. The central observation that they work from is that since a relation can be viewed as a set of tuples, the powerset functor can be interpreted as taking a tuple type to the type of relations over that tuple. Then, the fact that the powerset functor forms a monad means that you can use ideas inspired by Philip Wadler's monad comprehension syntax to give a categorically-inspired calculus for queries with a rich equational theory. Indeed, Buneman et al's query system Kleisli got its name from the fact that monads are sometimes called "Kleisli triples". Grust's PhD thesis, Comprehending Queries, works this out these ideas in detail, including the use of monad morphisms to model aggregation operators (like and ). Grust and his group also built a system, Ferry, which studied how to integrate databases into programming languages. One of the main issues in this work (and also in Kleisli, if memory serves), is that monadic query languages tend to be a bit more expressive than relational algebra -- they permit queries to handle sets of sets. Compiling this to SQL or relational algebra requires some care (for example, see Cheney et al's A practical theory of language-integrated query), but the basic issue has a very nice categorical formulation. Relational algebra only uses the monoidal structure of the powerset functor, i.e., the existence of a cartesian product natural transformation $(\bullet) : \mathcal{P}(X) \times \mathcal{P}(Y) \to \mathcal{P}(X \times Y)$; and monadic query languages also demand the join, $\mu : \mathcal{P}(\mathcal{P}(X)) \to \mathcal{P}(X)$. That's probably the primary stream of work on categorical approaches to query languages. A new idea (which unfortunately hasn't gotten as much traction as I think it deserves) is David Spivak's work on using simplicial sets to model databases -- see Simplicial Databases. The central innovation is that the simplicial structure permits explicitly modelling the whole database schema including the relationships between tables (eg, the system of foreign keys), and this enables giving semantics to schema update operations. Another deviation from standard query languages are restricted logic programming languages such as Datalog, which can be understood as relational algebra plus a fixed point operator. Fixed points permit expressing things like transitive closure queries, and so new databases like Datomic feature query languages based on Datalog. My PhD student, Michael Arntzenius, and I have studied the semantics of Datalog, and come up with a functional analogue we call Datafun, which has a pretty categorical interpretation in terms of the categories of posets and semilattices. 

From a ten thousand meter perspective, Jürgen Schmidhuber (and former students, like Marcus Hutter) have been investigating the idea of combining Levin search with Bayesian reasoning to work out algorithms for general problem-solving. The basic idea behind Levin search is that it's possible to use dovetailing and Goedel codes to give a single algorithm which is, up to constant factors, optimal. Loosely, you fix a Godel encoding of programs, and then run a Turing machine that runs the $n$-th program once every $2^{n}$ steps. This means that if the $n$-th program is optimal for some problem, then Levin search will "only" be a constant factor of $2^n$ times slower. They have done a fair amount of work on making the constant factors less stupendously, horrifically awful, and are optimistic that this kind of scheme can work in practice. I am (based on my experience in automated theorem proving) very skeptical, since good data structures are critical to theorem proving, and Goedel encodings are terrible data structures. But you don't know it can't work until you try to make it work! After all, we already live in a world where people solve problems by reduction to SAT. 

In computational terms, a sequent calculus term is a sequentialization of a lambda term. That is, viewed as a type system, sequent calculus can be seen as giving an evaluation order of a lambda-term. So, suppose $\Gamma \vdash e_1 : A \to B$, and $\Gamma \vdash e_2 : A$. In natural deduction, the term for implication elimination is $\Gamma \vdash e_1\;e_2 : B$ -- that is, application. However, note that this doesn't tell us whether to evaluate $e_1$ first or $e_2$ first. In sequent calculus, a corresponding proof term assignment must look like $$\mathsf{let}\; f = e_1 \;\mathsf{in}\;\mathsf{let}\;v = e_2\;\mathsf{in}\;\mathsf{let}\; x = f\;v \;\mathsf{in}\;x$$ or else it must look like $$\mathsf{let}\; v = e_2\;\mathsf{in}\;\mathsf{let}\;f = e_1 \;\mathsf{in}\;\mathsf{let}\; x = f\;v \;\mathsf{in}\;x$$ Here, the let-form is the proof term corresponding to the use of the cut-rule, and since all of the left rules act only on hypotheses/variables, this forces us to bind all intermediate results to variables. This requirement ensures that we are forced to explicitly say which of $e_1$ or $e_2$ we reduce and bind to a variable first. For purely functional languages, this explicitness doesn't matter, but as you add effects it becomes easier to work with sequent calculi. This is why things like calculi of control effects/classical logic are typically presented sequent calculus.