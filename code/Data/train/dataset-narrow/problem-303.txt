"The literatures says that because NA and NB randomly assign external ports anytime their respective clients initiate a new connection (even if the destination address is the same) the external port information that rendezvous server S swaps between its connecting clients is effectively useless." 

Now assume that instead of sending 1500 bytes packets, the packet size is half and the rate of sending out packets is double, so the amount of data that computer A and B are putting on the Ethernet cables is the same, only the packets are smaller and more frequent. Would this change impact the packet loss? How so and to what extent? 

"What i'm wondering is why is it not possible for clients A and B to try the external port information provided by S first and then, if that fails try repeatedly guessing/brute-forcing the external ports." 

Sources: $URL$ $URL$ Specific ingress/egress interfaces do not have to be the same as the initial session creation as long as they are in the same security zones as the interfaces used to set up the session. Source: $URL$ *see the note, just above purpose. Also - if interfaces/zones were an issue, you'd typically get specific output based on that. In my experience, I've seen drops in security flow traces that referenced the reason being that the egress interface (in the return direction) was not in the same security zone that the initial ingress traffic that established the session came in on. It's pretty verbose for the most part. Even with a chassis cluster, not much should be different as far as "session" matching goes, although there are some extra things that happen in some cases. If you're running an active/active cluster, where forwarding redundancy groups are primary/active on different nodes, you could end up with z-mode traffic. So if the ingress is on node 0 and the egress is on node 1, the active session will be maintained on node 1 (egress of the initial sync) and the backup session will be maintained on node 0. 

I want to understand packet loss a little bit better. I have computer A and computer B separated by public internet (ignore NAT/firewall - assume direct UDP connection between A and B). They have max upload rate ~500 kb/s, max download rate ~5000 kb/s. For the following sessions, assume that both applications are not sharing their bandwith with any other applications and that computers A and B are not sharing their bandwidth with any other computers - you can assume that each of their Ethernet cables goes directly from their modem to their computer. Packet loss is defined as "the failure of packets to arrive at their destination" 

What if instead of halving the packet size and doubling the rate of sending packets, you divided the packet size by 1/4 and multiplied the rate of sending packets by 4. How much more (roughly) would this effect the rate of packet loss? 

I think RFC 1583 is good reading material, and it seems to answer your question (section A.3, emphasis mine): 

You could indeed increase the window size beyond 1+2a, but it would indeed not increase the efficiency beyond 1 (or 100% if you like). I guess the correct formula would be Efficiency = min[1 , N/(1 + 2a)] If the window size exceeds 1 + 2a, and assuming the network delivers all acks, the sender would never be able to fill the window. After sending 1+2a packets, the ack for the first packet will be received. So the number of outstanding packets will stay at 1+2a, even if the window size would allow for more. 

The problem is that the remote routers are announcing themselves with PIM Hello messages from their own IP addresses and my router registers these addresses as PIM neighbours. The gateway in the routing table however contains the HSRP virtual address. When the router wants to join the multicast group, it looks for the route to the Rendezvous Point which has the HSRP virtual address as the next hop. Because this next-hop HSRP address is not one of the known PIM neighbours, the PIM-SM RFC specifies no Join should be sent. Changing the static route to use an actual IP address of one of the HSRP routers makes the multicast work, but of course this makes the HSRP useless. I have not tested VRRP because the other side did not want to change the network. VRRP would probably not have this problem since it does not use a virtual router IP, but uses the real IP address of the master router. 

Go back to session #1. What if instead of sending out the packets at a steady rate, you sent out all 333 packets at once, starting at the beginning of each second. So the clock ticks 30, send out 333 packets as quickly as possible from your computer, the clock tick 31, send out another 333 packets as quickly as possible, etc. How would that effect packet loss? 

Yes. Yes it is possible. The network has to be able to handle all the packets (without exceptions - packet loss means death), the machines have to be able to send out packets fast enough, the other end must not have "flooding protection" and the address has to not change every time you open a new connection. This method managed to connect my laptop behind my University's WiFi with my friends laptop behind his WiFi and it sent a packet from my home WiFi through my University's symmetric NAT. If you're using a phone, you should probably send packets as fast as possible because phones are slow but with laptops you can synchronize the barrage of UDP packets with Thread.sleep() 

That is a routing loop. The router with IP address 74.117.154.1 keeps sending your packets to another router (74.117.154.4), which keeps sending them back to 74.117.154.1. They keep doing this until the TTL of the packet reaches zero, and the packet is discarded. This cannot be caused by your bind9 setup, something is wrong with the configuration of the routers. You should contact the people running that network. If you are sure that is in the VPS provider's network, contact them. You can also do an IP whois lookup to see to whom the IP address is assigned. 

You could try if the frames can be blocked using a MAC ACL on interfaces and/or on vlans on the access switches. By applying the blocks selectively and checking if the error messages on the 4500 disappear or not, you can home in on the source of the traffic. Moving cables around to see if the port mentioned in the error message on the 4500 follows could also help, but might prove tricky in a production environment. 

TCP handshake timeout on the SRX is 20 seconds by default and you can't manually set it lower than 4 seconds, so that's definitely not the issue. Did you do the security flow trace in the other direction? It would be nice to see the session initiation (the SRX processing the initial TCP SYN) to see what the initial session actually looks like. That might shine some light on why the return traffic doesn't match the session. To answer your question though, in checking to see if a session is already established, the SRX will look at six match criteria: 

After more thoroughly combing through the RFC, I'm certain that the expected behavior I mentioned in my post is accurate. Intra-area routing within each area (area 1, area 0(a), and area 0(b)) will work as expected. Area 0 summaries will still flood to area 1 from each area 0 partition, giving area 1 all necessary routing information for both area 0 partitions. Area 1 summaries will still flood to both area 0 partitions from area 1, allowing both area 0 partitions to know about area 1 routes. Area 1 will not send area 0 summaries back into area 0, so split area 0 partitions will no longer know about each other and will not try to transit area 1 to get to each other (unless a virtual link through area 1 is created). This is my desired behavior for a failure scenario based on my circumstances. If all of the redundant links between my data centers go down, or I need to perform certain types of maintenance, I don't want data center to data center traffic (mostly backups / off-site replication) saturating my branch site WAN links. I could apply policing on the WAN links for transit traffic between data centers, but the little bit of bandwidth I could give that traffic would be useless anyway - and that would require my team to maintain more config. If anyone has any questions about this, feel free to comment and I will try to find the answers. 

As a side note, it is not about who answers first. If you give your computer an address in the same subnet, the traffic will go straight to the machine, no routers involved. Even if you would use routing, entering a route to 143.166.0.0/16 on some internal router(s) in your network, they will prefer this route over their (default?) route to the internet. This happens because the "longest prefix match" is preferred, ie. the most specific route is chosen. Your correct about the net result, the 143.166.0.0/16 part of the internet will be unreachable for you or your network should you install the route in your internal routers. /16 seems a bit large for this issue, the smaller the subnet you route to, the smaller the chance of getting bitten. 

without the remark about automatic VLAN id assignnment. I only have EX devices so I cannot verify this.