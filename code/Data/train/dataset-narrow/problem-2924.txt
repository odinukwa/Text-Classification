I am currently polishing a digital CCG where people can play against friend and random opponents in a classical Magic the Gathering-like duel CCG. I plan to award the players with 20 ingame currency units (lets call them gold) for each hour they are playing, 50 for each day they are playing and X for each victory. Now, the X is what I am trying to calculate here, since I would prefer keeping the currency to a certain value, but also with to entice the players to battle. I could go with a solid figure, say 25, for beating up an opponent. But that would result in experienced players only beating up newly started players, making the experience lame for both. I could also make a laddered tier, where you start at level 1, and raise in level as you defeat your opponents, where winning over a player awards you his level x 2 in gold. Which would you prefer if you were playing a game like this. There is no gold-based scoreboard, but the gold is used to purchase new cards along the way. 

I also need two levers to adjust difficulty. One being the number of colors the pearls can have (clear to the player) and another being a "cruelty" factor in how tight the spectrum of right solutions vs dead ends the level contains. I seem to be at a crossroad between two ways of approaching this, and would like feedback from you gents and gals. My two options seems to be : 

But here are the area that I'm concerned: If the same player has a second device, he would like to play from instead/also. It's a fair scenario that if the player requires an tablet next to his phone, and he wants to play with the same account. So my play so far, is to wipe the "temporary account" from the server, find the account with the matching FBID, and add this new device to an array of devices on the original account. I have session based control, so they can't be playing on the same time. The old device will simply be logged out if the same user appears on the new one. But I have a feeling this is not the best way of doing things. What if the "temporary" game is played by someone else, and that person will technicly get his account wiped and device "taken over" by the logged in user ? Im especially concerned about family-type scenarios, where devices are shared. Does anyone have any good suggestions on structure on this ? Maybe I'm completely in the woods with my method here, and doing it all wrong. My priorities are : 

From here, slice up the single image and get multiple sprites to your heart's content. Then you can use these sprites in your gameobject (might need some custom shaders). If you want to avoid using sprites, I believe you can access this feature by selecting Advanced import setting. 

Sadly, as things are of now, you can't run Unity3D content in flex. There is simply not enough Flex users for Unity to support it with their plugin. However, there are some hope coming in Unity 5, since it will be possible (at least promised) to build games that run straight with WebGL, discarding the need for a Unity Web player plugin (at least for most projects) Until then, I would say that the odds of Unity making a plugin for Flex in this "mid transition period" is very unlikely. 

Try doing a Reimport All. Do you have any duplicate modues ? (like two modules for In-app billing plugins). Getting rid of the surplus one entirely should solve it. When I ran into this recently, it seems to be caused by using a JAR which references classes.jar for android. It seems that I must reference the AndroidDevelopmentPlayer version when building my JAR if I want to build a development player the AndroidPlayer version if I'm not. I guess this kinda makes sense, but it also seems a little weird, since it's just a reference. 

I have a task in hand about making a puzzle generator, that can fill a game board with colored pearls, that then needs to be solved by the player. The core rules are 

One of the best seperators between real cars and toy cars, is in my experience the shaders. I've spent quite some time with BMW, where we needed to hit the exact glossyness, reflection and feeling of one of their chrome textures. Without it, the car looked like a small plastic toy, but once it got on, the whole imagry changed, and the car turned into a "believable" vehicle. Also, use of camera is important here as well. Notice in both car games and especially car ads, how they portray the car to make it look big and robust. In reality, cars aren't that impressive in size, but they always manage to make that feel to it. And last, but not least, make sure it FEELS like a car. The audio, the steering, the way it moves in place when you hit the brakes. The feel of an object is the final touch in making it feel believable. 

This should be almost working except one thing: Your character will move on line until he's not behind target position, so he doesn't have to stop exactly on line's ending point, but behind it. And then he will turn on other line segment. 

I don't know, how it's in named games, but in Mafia 2: Whole world is just a world. And missions are levels. Each mission can contain few "sublevels" (go from here to there and do some action) and special parts like buildings, items, characters, behavior, etc. World is streamed as it is needed. I think that level should represent one part of game (story), which can be "entered" (started) and completed. And because you can travel freely around the game world, it's not a level, but environment. Level should be one mission. 

I also think there is no way how to "discard" whole mesh, but you can transform every vertex of the mesh to the same output vertex, so whole mesh will "implode" into one point in space. If you place it behind camera, it will be clipped and not processed. 

In general fog is very simple. It just takes depth of each fragment / pixel and according to some function sets the output color (blends between original fragment color and fog color according to fragment depht). You can use linear blending or quadratic blending or whatever you want (if you implement it yourself). I'm not java programmer so I can't say you exact commands. But in OpenGL it's very simple and in original rendering pipeline (non-programmable) it can be just enabled by one command and disabled by other. In programmable pipeline you have to write it in your shaders, but it's only blending. 

As Tetrad suggested, I'm adding my comment as answer: You can find some useful info about BF3 here: The Secrets Behind Battlefield 3 and Frostbite 2 

You can use geometry shader and send just one point and normal for each rectangle. In geometry shader produce for example triangle strip. But if you need texture coordinates, it could be problem. // Deleted some Opengl info (now I have taken note that you are talking about XNA :) ) 

I think, you can use just simple division by velocity. For example: lost = 3 000 / myVelocity. When velocity is 300, you will lose 10, when it's 200, you will lose 15. It's up to you to choose correct constants. If you want, you can use more complex formula, like: constant / (constant2 * velocity^2 + constant3 * velocity). Again - just choose constants, which will suit you. 

Try to disable texturing before rendering (before while loop): glDisable(GL_TEXTURE_2D); - if it helps, there is problem with texturing. But I don't think it should help. You can also try to comment everything from glBegin(GL_QUADS); to glEnd(); - but you will not see if it helps. You would need some FPS counter. Also try to sleep while loop at the end for some time (let's say for 20 ms). But I don't think it will help anyway. And also try to change glOrtho(0, XSIZE, YSIZE, 0, 0, 1); to glOrtho(0, XSIZE, 0, YSIZE, 0, 1); Is your code rendering something? 

Maybe you can try one of these two variables. gl_fragcoord or gl_fragdepth I didn't read those manuals, but I think, it could be helpful. 

I believe that problem in your code is with "used". You are not trying to find shortest path or cheapest. You are searching for first path you can find. You implemented DFS algorithm (depth-first-search). Everytime you grab tile to the top left and update it's state and it's neighbors. Then you take tile to the top left from this tile and again. And it goes to the end of map. Then it goes to the top as much as it can. Then it will explore tiles in some other ways. It's definitely not growing in all direction at the same time. Anyway: Solution may be to implement BFS (breadth-first-search) - you will put your tiles to some queue instead of processing them immediately. You shouldn't update value in neighbors, but instead just put that neighbor to the end of the queue. When you push it from queue, you will update it's value. The best (and maybe - for you - simplest) way is to implement something like Dijkstra's algorithm - don't use "used" variable, instead try to update value everytime - if it's higher or equal than stored value, then stop. If it's lower, update value in tile and proceed to neighbors (again - compare value). But Dijkstra is probably also more suitable with BFS-based search, not DFS. 

Blue vector can be calculated easily: red - black (the sign between vectors is minus). But if you want just to interpolate between black and red vector, you don't have to calculate it. Linear interpolation is just linear combination. So you can just take: alpha * black + (1 - alpha) * red, where alpha has to be from interval <0,1>. If alpha will be 1, then you will get black vector, when alpha is 0, you will get red vector. And if I understood it right, you will interpolate between these vectors in time. So just choose right increment of alpha in time. Did I understand you right? Or did you meant something completelly diffent?