There is a paper in this year's ICFP, refinement types for Haskell. The paper deals with termination checking rather than full Hoare logic, but hopefully that's a start in this direction. The related work section in that paper contains some pointers, such as Xu, Peyton-Jones, and Claessen's static contract checking for Haskell, and Sonnex, Drossopoulou, and Eisenbach's Zeno and Vytiniotis, Peyton-Jones, Claessen, and Rosen's Halo. 

Lexical closures are an implementation technique in languages with first-class functions. I'm interested in a simple operational description of function closures. Does anyone know of such a description? 

Also, sometimes properties don't commute on the nose, and the structure under consideration is of higher-dimensional (i.e., 2-categorical). As to your question 3: you can define a category without mentioning objects at all (though it's conceptually clearer if we do mention the objects). 

My knowledge is a bit stale, as I haven't actively researched this field in the last couple of years. None of these is probably the state of the art, but a good place to start looking backwards (i.e., chase references) and forwards (i.e., see who cites it). If you're looking into information flow (making sure classified information doesn't leak to untrusted roles), a reasonable place to start is Martin Abadi et al's Dependency Core Calculus. I think it's reasonable enough that anyone who does formal methods in the area would refer to it (directly, or once removed). If you're looking into access control/authorisation (role A says role B controls the data, role B says you can access the data, etc.), Abadi recently published a tutorial book chapter on the subject, so might be a good place to start. If you're looking into authentication (whether the agent saying he is A is indeed A), I defer to someone else. I'll try to have a look later. 

This too contains a sequence of uniformly convergent continuous paths going from the start to the finish, by the same argument used to show the uniform convergence of the Hilbert curve. However it is a true "fractal maze" in the sense that it does not fill the whole space. Thus we have a fractal maze that is solvable by the analytic definition, but unsolvable by the graph theoretic definition..!? Anyways, I'm pretty sure my logic is correct, but it seems counterintuitive so if anyone can shed some light on this I would appreciate it. 

Since the Hilbert Curve iterations converge uniformly, that uniform limit is a continuous path that solves the maze in the analytic sense. It's as if you were able to do the following recursively defined infinite set of moves $P$: $P = APA^{-1}BPB^{-1}CPC^{-1}DPD^{-1}$ Now you might argue that this is not in the spirit of fractal mazes since the Hilbert curve fills the entire square and therefore you could just draw a straight line segment from the start to the finish. This objection is easily overridden though - simply use the hilbert curve diagram embedding directly, as shown here: 

This is not an "answer" to my question, but rather an extended comment that people here might find interesting. I claim that there is a natural "analysis-type" definition of a maze and a solution, and it differs from the computer-science/graph-theoretic definition we've used here. In particular, you can have a fractal maze that has a "solution" under the analysis definition, but would be declared unsolvable by Marizio De Biasi's algorithm and Peter Shor's pushdown automata technique. Definition: A maze $M$ is a compact subset of the plane $M \subset \mathbb{R}^2$ containing a start point and an endpoint $s,e \in M$, respectively. A solution is a continuous function $f:[0,T] \rightarrow M$ such that $f(0)=s$ and $f(T)=e$. Now consider the the Hilbert Curve: 

What are the justifications for using Moore machines as transducers in the first place? The slight simplicity over Mealy machines comes at a high cost, namely either a reduced expressive power (1st interpretation) or the lack of a canonical form (2nd interpretation), and in either case a potentially increased size compared to a Mealy machine. Am I injust when claiming that for these reasons, the concept of a Moore machine should be avoided altogether in a strictly formal setting? Is there an established name for the above-mentioned "generalized DFA"? Clearly, the term Moore machine is to confusing, as it is commonly associated with transducers. I've come across TDFA for the ternary case (true, false, unknown/dontcare/maybe/...), but I am looking for a generalization beyond that. Maybe simply GDFA (generalized DFA)? 

Ok, don't be scared by the title - it is not that I don't know the concept of a Moore machine, or basic FSM concepts in general. However, I think that the term "Moore machine", despite being frequently used in some areas, is generally poorly defined. I would be grateful if someone could point me to some (authoritative) source. Background The first and most prominent notion of a Moore machine I've come across is that a Moore machine is a certain kind of deterministic finite-state transducer. That is, given an input alphabet $\Sigma$ and an output alphabet $\Omega$, a Moore machine $M$ computes a function $\lambda_M \colon \Sigma^* \to \Omega^*$ such that for each input symbol that is consumed, a single output symbol is produced (this restriction is not always obeyed and, moreover, is not relevant to the question, but I will stick with it for simplicity). Thus, among other things, we have that for all $w \in \Sigma^*$, $|\lambda_M(w)| = |w|$, and in particular $\lambda_M(\varepsilon) = \varepsilon$. A Moore machine $M$ is generally defined as a tuple $M = \langle Q, \Sigma, q_o, \delta, \gamma\rangle$, where $\gamma \colon Q \to \Omega$ is the state output function. There exists two interpretations of this definition. In the original one presented by Moore, the state output function of the current state determines the output that is emitted when an input symbol is read. Note that in this case, for a given Moore machine $M$, the first symbol of $\lambda_M(w)$, $w \neq \varepsilon$, is necessarily fixed to $\gamma(q_0)$. Note that when relying on this interpretation, there are Mealy machines for which no equivalent Moore machines exist. On the positive side, this interpretation admits a (minimal) canonical form. In the second interpretation, the successor state determines the output that is emitted when an input symbol is read (i.e., when reading $\sigma\in\Sigma$ in state $q\in Q$, $\gamma(\delta(q, \sigma))$ is emitted). Then, every Mealy machine can be converted into an equivalent Moore machine (with potential blow-up by a factor of $|\Omega|$) and vice versa. However, then Moore machines do not admit a canonical form, due to the degree of freedom introduced by the fact that $\lambda_M$ does not constrain the output of the initial state, i.e., the value for $\gamma(q_0)$. For a more concrete example, consider the transducer with $\Sigma = \{a, b\}$ and $\Omega = \{x, y\}$ that outputs $x$ when reading $a$ and $y$ when reading $b$. The canonical Mealy machine has a single state with two loops with labels $a / x$ and $b / y$. A Moore machine (according to the second interpretation) needs two states, one with output $x$ and one with output $y$. $a$ loops on the $x$-state and $b$ loops on the $y$-state, and the state gets switched on all other inputs. Both states can be chosen as the initial state, and there is no natural choice. I've also come across a different notion of Moore machines, namely as a generalization of DFA (i.e., where a DFA is a Moore machine with output alphabet $\Omega = \mathbb{B} = \{0, 1\}$ indicating acceptance). In this case, the value $\lambda_M(w)$ of the output function $\lambda_M \colon \Sigma^* \to \Omega$ is a single symbol only, which is determined by $\gamma(\delta(q_0, w))$. While this admits a canonical form, evaluating $\lambda_M(w)$ in general yields significantly less information than in the above case, but also yields information that is not observable in the transducer interpretation (i.e., for $\lambda_M(\varepsilon)$). These aspects are relevant, e.g., in the field of state identification (finding the current state in a given Machine by experimentation). Questions This brings me to my main two questions: 

First, the property "having first-class functions" is a property of a programming language, not of particular functions in it. Either your language allows for functions to be passed around and created at will, or it doesn't. Functions that accept or return other functions as arguments are called higher-order functions. (The terminology comes from logic.) Functions that don't are called first-order functions. Perhaps this latter notion is what you wanted. 

Note that most of the categories you considered are 'abstract', i.e., they require structure or properties of an abstract category. As computer scientists we should also be familiar several concrete categories which turn out to be useful: Concrete categories 

Augmenting Noam's answer: Removing the implicit currying, $f : A \to B \to C$ is the same thing as $uncurry( f) : A \times B \to C$. Strong monads $T$ give a map (two, actually!): $dblstr : T A \times T B \to T (A\times B)$. We therefore have a map: $ T A \times T B \xrightarrow {dblstr} T(A\times B) \xrightarrow{uncurry(f)} TC $ If we instantiate this to the continuation monad, we obtain your construction. Generalizing to $n$-variables, the following should work (I didn't check all the details through). Once we choose a permutation $\pi$ over $n$, we have a $\pi$-strength morphism $str_{\pi} : T A_1 \times \cdots \times T A_n \to T(A_1 \times \cdots \times A_n)$. (The monad laws should guarantee that it doesn't matter how we associate this permutation.) Therefore, for every $n$-ary morphism $f : A_1 \times \cdots \times A_n \to C$, we can construct: $\gamma f : TA_1 \times \cdots \times TA_n \xrightarrow{str_{\pi}} T(A_1 \times \cdots \times A_n) \xrightarrow{Tf} TC$. But I still don't think this really gives you the answer you're looking for... 

A fractal maze is a maze which contains copies of itself. Eg, the following one by Mark J. P. Wolf from this article: 

Several state of the art approximate nearest neighbor methods in high dimensions are based on reducing the dimension of the space through randomized techniques. The main idea is that you can exploit concentration of measure to greatly reduce the dimension of the space while preserving distances up to tolerance $\epsilon$. In particular, following from the Johnson-Lindenstrauss lemma (upper bound) and a result of Noga Alon (lower bound), there exists a subspace of reduced dimension $$C_1 \frac{\log(N)}{\epsilon^2 \log(1/\epsilon)} \le \text{reduced dimension} \le C_2\frac{\log(N)}{\epsilon^2}$$ such that for any two points $u,v$ in your collection, their projections $\tilde{u}, \tilde{v}$ onto the reduced dimensional space satisfy $$(1-\epsilon)||u-v||^2 \le ||\tilde{u} - \tilde{v}||^2 \le (1+\epsilon)||u-v||^2.$$ Indeed, such subspaces are "typical" in a sense, and you can find such a subspace with high probability by simply projecting your points onto a completely random hyperplane (and in the unlikely event that such a hyperplane is not good enough, just pick another random one and project again). Now you have a nearest neighbor problem on a much much lower dimensional space. A key paper is, 

If a solution exists, breadth-first-search should find a solution. However, suppose there is no solution to the maze - then our search program would run forever going deeper and deeper. My question is: given a fractal maze, how can we determine if it has a solution or not? Or alternatively, for a fractal maze of a given size (number of inputs/outputs per copy), is there a bound on the length of the shortest solution? (if there was such a bound, we could exaustively search only that deep) 

Disclaimer: I can only vouch for my research fields, namely formal methods, semantics and programming language theory. The situation is possibly different in other parts of the discipline. It seems that TCS has become rather conference-oriented. Researchers aim at publishing in the next conference. Sometimes a journal version appears. Sometimes it doesn't. In other disciplines (biology, mathematics, and most others I guess) this is unheard of. The effort put into writing the conference papers is a lot lesser, but in turn, the conference papers count a lot less. The "real deal" is the journal publication. Arguing whether this situation is good or bad could result in a flame war, and doesn't have a precise answer. Instead, let's try a more factual question: How did we become so conference-oriented? How did conference papers gain so much weight? 

Augmenting Andrej's answer: There is still no widespread agreement on the appropriate interface monad transformers should support in the functional programming context. Haskell's MTL is the de-facto interface, but Jaskelioff's Monatron is an alternative. One of the earlier technical reports by Moggi, an abstract view of programming languages, discusses what should be the right notion of transformer to some extent (section 4.1). In particular, he discusses the notion of an operation for a monad, which he (20 years later) revisits with Jaskelioff in monad transformers as monoid transformers. (This notion of operation is different from Plotkin and Power's notion of an algebraic operation for a monad, which amounts to a Kleisli arrow.)