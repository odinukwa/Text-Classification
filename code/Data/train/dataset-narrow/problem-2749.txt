Then your paddles might also have some of these components, but they will probably have different initial parameters for each of them, and this is what will make them unique and different from the ball entity. A good component for them might be an that handles user input and updates the when the player presses the up or down keys. PS: If you have never tried Unity3D, I think it's a good place to start wrapping your head around these concepts! 

Bastion. It just won 3 Spike Video Game Awards a couple days ago (not to mention all the other ones it already had - check link). 

Other reasons might be for instance, using a spatial partitioning data structure to organize your objects in a way that improves the efficiency of performing view frustum culling. 

I'm not sure I understood what your problem is, but here's how I do it. First I create a static class on my project to provide an extension method for that lets it know how to draw textured line. Example (just the class, it's missing the using directives and the namespace so place it wherever you want): 

You can use effects like Normalize or Amplify in Audacity to make all of your audio files have the same peak volume without clipping them (in fact by default it normalizes the maximum amplitude to -3dB instead of 0dB, which is probably a good idea too). Subjective Then there's a more subjective point of view which is, some sound effects are by nature more aggressive to the ears and should probably be toned down a bit. This depends mostly in the very nature of the sound, so I'm not aware of any existing procedure to automate this correction. Therefore my suggestion would be to use your ears. In particular, author your audio files using headphones, and preferably on your iPhone and try to adjust the volume levels on your audio files manually so that they are as loud as possible without getting to the point that they "pierce" your ears. Possibly ask a few other people around you for opinion too, as different people might have different sensibilities. 

Implementation As for how to implement this, it depends on your platform. On XNA you can simply use the Origin parameter of to change the center of your rotation. Here's what I got with the following code (with a few tweaks to the origin to make it look better - basically the origin starts near the right corner and ends up near the left corner): 

Either way the solution to your problem will be fairly similar, so I'll assume all three are true for this explanation (I'll use C# as example). Read on for the full set of ideas... Implementation Part 1 - Storing and look up After you finish filling your grid with tiles, you should scan each tile and group tiles of each type together to make it easier to lookup. I'll use a Dictionary, like so: 

Note that you can create and chain all the processes you want before the game starts, because they only really start being executed when you call update for the first time on the queue. When implementing the class inheriting from make sure to set the property to true when the animation ends, so that it will get removed from the queue. I think that probably already answers your question, but if you're interested in the subject, keep reading. 

And finally find the intersection point between the ray and the plane using this method. You can use the out result parameter in order to calculate the intersection coordinates like in the example below: 

That should be enough to convert the above code into regular operations if you don't have a class available to you. 

Each Sprite object will hold its Position/Rotation/Scale/Origin in world space and when calling Draw those values are fed to a SpriteBatch instance and drawn. As for the Group class, it keeps a list of all the Sprites in the group and provides methods to manipulate the group as a whole. Those methods take an origin parameter which is the "center" of the group (e.g. around which point do you want it to rotate). The implementation goes something like: 

Basically if you move diagonally all at once, it can create an ambiguity where the algorithm needs to guess in which direction it should push out of the tile. It's possible to make it intelligent enough to always use the correct direction, but it's easier to just handle movement in each axis separately, as there's no ambiguity that way. 

EDIT I just tried implementing this exactly as I described (but in XNA) and it worked quite well. See this video of the demo. Source code here for those interested. 

And here's the transformation matrix I used in XNA. See if you can find any correlation to your code: 

All the unproject and matrix code you showed on your question is not needed. And now your sprites and camera are completely independent. If you want to move a sprite, just change the sprite's position. If you want to move the camera just change the camera's position. 

Edit - Changed to another solution that allows a source rectangle to be used. The color you choose when calling is automatically stored in all four vertices of the quad. There's no way to change this behavior because it's done internally inside the . But there's a hack that you can use that relies on looking at the vertices' texture coordinates (which bu the way are automatically generated by from your source rectangle and from the texture size) in order to identify which of the four vertices we're dealing with in the vertex shader, and then change its color before reaching the pixel shader. I can think of many variations, but the trick I used was to pre-calculate what the texture coordinates would end up being at the center of the quad, so that in the vertex shader you can simply compare to see if the X and Y components are lower or higher than the center in order to determine which corner we're dealing with. You also need to pass it the color for each of the vertices, obviously. So here's the complete effect file code I used: 

And that's all you need to reference any ComponentManager from within your Factory method. For instance: 

The first problem is that you're using which to put it simply, is not appropriate for this case because you're not even specifying the depth of your sprites. Just use the default mode instead which draws in the same order as your calls (just write with no parameters). Also, it's strange that you're drawing the background after the other sprites. If it's the background it should come first otherwise it will occlude everything else. Here's the corrected code, with some redundant parameters removed: 

Such as this (free license for bloggers and framework developers) or this (completely free but a bit less flexible)? 

Assign an origin to each sprite that would act as the sprite's "feet", i.e. a point in the sprite that is touching the ground. In its simplest form, you could simply pick the middle-bottom point of your sprites. Sort your sprites so that they're drawn starting from the ones with lower origin Y values and moving towards higher origin Y values. This way, objects further down the screen will automatically occlude objects that are supposed to be behind them. 

Step 2 - Calculating the LocalTransform matrix The matrix is just a regular world matrix built from the sprite's position, rotation and scale values. For the origin I assumed the center of the sprite: 

Note) Calculating the correct plane for your wall Of course part 2 only works if you're using the correct plane. Since the Plane is usually stored as a Normal and Distance from the origin, it might be hard to come up with the correct values to fit a specific object in the world. Luckily the Plane class also has a constructor that makes this task easy - you only need to pass it three points that lie on the plane. So to create a plane for your wall, all you'd have to do is: 

To put it simply, is used to to store the result of calling , or in other words, the number of miliseconds that have passed since the SDL library was initialized. This is supported by looking at the implementation file, and noticing that every assignment to is as follows: 

The utility of this matrix is that by multiplying a point in local space - and for instance if you get the pixels using a method like then 10,20 is defined in local space - by the corresponding world matrix will move it into world space: 

And once you have the theory down, jump into practice with "gem-styled" series such as GPU Gems which are available for free, and the ShaderX/GPU Pro series. 

The View Matrix describes the position and orientation of your camera, which is usually just a series of translations, rotations and scalings. It works by moving the entire world back in the inverse direction around the camera, so that the camera becomes the new origin. 

A vector can be used to store either a displacement (e.g. movement) or a position. In this case since you're passing the vector to it's a displacement - it specifies in which direction the TNT will be moving. But it's probably not working because your Vector is currently holding the position of the target block in the world, and what you want is the direction the player is facing. Try to see in the Player class if there's already a way to get a Vector representing the way it's facing. Otherwise you'd need to calculate one from the player's rotation values. 

It's relying on the && operator not bothering to run the second portion of the operation unless the first one is true. So if there's no path, nothing else happens. If there's a path, then is called, and its return value is what decides whether we should remove the point from the path list or not. 

2) Have CreateEntity also receive an id (e.g. a string, integer, it's up to you) besides the class/type of the entity, and automatically register the created entity on a Dictionary using that id as a key: 

I don't know about the ELO algorithm, but how about instead of penalizing people who don't play often, you reward people who play often? For instance if you made your score something like: 

Project your light position into the plane. Then move it out of the plane by the desired amount along the plane's normal. 

(Step 3) And now the hard part - rendering it. Well, not really hard, but requires two objects and one object. You should create these only once. 

I'm working on a "Game Maker"-type of application for Windows where the user imports his own assets to be used in the game. I need to be able to load this content at runtime on the engine side. However I don't want the user to have to install anything more than the XNA runtime, so calling the content pipeline at runtime is out. For images I'm doing fine using Texture2D.FromStream. I've also noticed that XNA 4.0 added a FromStream method to the SoundEffect class but it only accepts PCM wave files. I'd like to support more than wave files though, at least MP3. Any recommendations? Perhaps some C# library that would do the decoding to PCM wave format. 

In general, as long as I don't need to change any of these parameters I try to use the same block for all of my operations. The reason should become evident when I address your other question later, but to sum it up, it's to reduce the amount of calls (render stage changes and draw operations) made to the graphics device. Conversely, whenever I start a new block it's usually for a very specific reason. For instance, I might use separate blocks when: