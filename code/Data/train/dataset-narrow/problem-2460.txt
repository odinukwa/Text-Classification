Note that although this sounds like $\mathsf{ZPP}$, it is not since $\mathsf{ZPP}$ is the class of predicates, and not multifunctions. I really appreciate any pointer to the right sources. 

I'm currently a PhD student and not a prof, so my suggestion comes from my (limited) personal experience as a graduate student. When I was an undergraduate student, I always worked as a research assistant in summer with different profs in my department. I personal believe that the only way to figure out if TCS is truly for you or not is to work on concrete problems and see what you can enjoy the most. It did take me quite a while to find a prof and a topic that I liked. There's also a "social" aspect in research, and different profs have different working and supervision habits, and thus these summer research jobs will give you a better idea what quality you want the most from a supervisor in the future. There are many interesting fields in Computer Science, and TCS is just one of them. So it's always best to keep your options open and talk to different profs. It's very important to specialize when you're doing PhD, but as as an undergrad I think Mark Braverman's advice is extremely relevant: 

The folklore answer is that factoring is "structured" in a way that general NP-complete problems aren't, and this is why we have only been able to find quantum advantage for intermediate problems. Arguably a simpler version of your question is to look not at computational complexity, but at the query complexity of boolean functions. Here we can say some things provably, such as the fact that superpolynomial speedups are possible only for partial functions (proved in $URL$ and not for functions that are symmetric in their inputs and outputs (proved in $URL$ These results do not directly shed light on the BQP vs NP question, but are I think meaningful steps towards determining where there is quantum advantage. 

The sorting problem is actually complete for $\mathsf{TC}^0$ (under $\mathsf{AC}^0$-reduction). A standard source for this is Section 1.4.3 of Vollmer's book. Note that $\mathsf{TC}^0$ is the class of decision problems, but we usually think of sorting as a function problem, i.e., we want to output the numbers, say, in nondecreasing order. However, we can also define sorting as a decision problem as follows: 

[Mark tried to enroll in many courses (well above the limit), and explore different areas of Mathematics and Computer Science when he was an undergrad.] Try to attend lectures and seminars on different topics in your department. When you're in your upper years, you should also ask for permission to audit graduate courses related to your interest. Also depending if you're majoring in Maths or CS, you also have to plan courses you should take to prepare you a solid basic foundation. If you're a Maths undergrad, then you should take more CS courses in algorithms and complexity which give you a more "algorithmic" mind. If you're a CS or Engineering undergrad, then it's always a good idea to learn some basic Maths courses in: 

Sometimes measuring quantumness in algorithms gets conflated with trying to measure the amount of entanglement produced by an algorithm, but we now think that a noisy quantum computer could have computational advantages over classical computer even with so much noise that its qubits are never in an entangled state (e.g. the one clean qubit model). So the consensus is now more on the side of thinking of the quantumness in quantum algorithms as related to the dynamics rather than the states generated along the way. This can help explain why 'dequantizing' is not likely to be generally possible. 

I think courses on algorithm design and computational complexity are always challenging for students who not familiar with these subjects because they do require some degree of mathematical maturity and problem solving skill. In my first graduate course on "computational complexity", a friend of mine who had his degree in pure mathematics told me how surprised he was by the fact that although that course didn't require much maths background (at least that's what was told in the course outline), it actually required nearly all the skills he got through all of his pure maths undergrad degree! I found that I got to know about "the way" most (when I first start my graduate study) by reading and doing exercises from Sipser's book. Be sure that you do the exercises because problem solving skill and mathematical maturity is what you want to learn and not just a bunch of facts or definitions. However, Sipser's book is only good for complexity and NP-completeness stuffs, it won't suffice to substitute the CLRS book. The only problem with CLRS book is that its advantage of comprehensive coverage might become its weakness since the book might look quite scary or overwhelming for students. So my advice is that you should really go to the library and search for books on algorithms, scan through one by one and choose the ones that fit your thinking pattern most. And again don't forget to do exercises! For algorithms, I personally suggest the following books (besides the ones suggested by Sadeq and JeffE): 

For bipartite quantum states, where the context is two-party correlations, we have many many good measures of quantumness. Many have flaws, like being NP-hard, or not additive, but nevertheless we have a pretty sophisticated understanding of this situation. Here is a recent review. 

There are other contexts, such as when we have a quantum state and would like to choose between different incompatible measurements. In this setting, there are uncertainty principles that tell us things about how incompatible the measurements are. The more incompatible the measurements are, the more 'quantum' a situation we have. This is related to cryptography and zero-error capacities of noisy channels, among many other things. 

GNU grep is a command line tool for searching one or more input files for lines containing a match to a specified pattern. It is well-known that grep is very fast! Here's a quote from its author Mike Haertel (taken from here): 

Although the circuit $C'$ you mentioned computes a function $F:\{0,1\}^m \rightarrow L$, we can think of it as a sequence of circuits $C'_1,C'_2,\ldots,C'_n$, where $C'_i$ computes the $i^{\rm th}$ output bit of $F$. Since each $C'_i$ computes a boolean function $\{0,1\}^m\rightarrow \{0,1\}$, minimizing the circuits $C'_i$ seems hard according to the above result. 

It depends on the context. For quantum algorithms, the situation is tricky, since for all we know, P=BPP=BQP. So we can never say that a quantum algorithm does something that no classical algorithm can do; only something that a naive simulation would have trouble with. For example, if a quantum circuit is drawn as a graph, then there is a classical simulation that runs in time exponential in the treewidth of the graph). So treewidth can be thought of as an upper bound to 'quantumness', although not a precise measure. 

If I don't misunderstand what you mean by AND&OR gate, it is basically a comparator gate which takes two input bits $x$ and $y$ and produces two output bits $x\wedge y$ and $x\vee y$. The two output bits $x\wedge y$ and $x\vee y$ are basically min$(x,y)$ and max$(x,y)$. Comparator circuits are built by composing these comparator gates together but allowing no more fan-outs other than the two outputs produced by each gate. Thus, we can draw comparator circuits using the notations below (similarly to how we draw sorting networks). 

Like many complexity-class separations, our best guess is that the answer is that BPP^{HSP} != BQP, but we can only prove this rigorously relative to oracles. This separation was observed by Scott Aaronson in this blog post where he observed that the welded-tree speedup of Childs, Cleve, Deotto, Farhi, Gutmann and Spielman was not contained in SZK. On the other hand, BPP^{HSP} is contained in SZK, at least if the goal is to determine the size of the hidden subgroup. This includes even the abelian HSP, although I'm not sure how exactly to find the generators of an arbitrary hidden subgroup in SZK. The reason we can decide the size of the hidden subgroup is that if f:G->S has hidden subgroup H, and we choose g uniformly at random from G, then f(g) is uniformly random over a set of size |G|/|H|. In particular, f(g) has entropy log|G| - log|H|. And entropy estimation is in SZK.