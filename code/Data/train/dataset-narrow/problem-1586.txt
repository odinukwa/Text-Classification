If you are running virtual hosts on the the server you may want to pin the CPU(s) for the host. You may want to do the same for high CPU single threaded processes. Spread the load across CPUs if you do so. 

The simplest solution is to ensure that www-data can navigate all the directories to /home/user1/public_html directory and use 755 directory permissions from public_html and down. Files in the public_html directory need to be world (other) readable. These command should enable access: 

The public name server should respond that private address doesn't exit. If it is first and running you will get the public answer. List the private server first. The public server should only be used as a fallback. A solution on the nameserver side is to use a split configuation. This would serve up the private data on the private network, and provide only the public data on the public side. The public server should only offer referrals (google.com, etc.) on the private network. 

Munin does a good job gathering these statistics and others. It also has the capability to trigger alarms when thresholds are passed. Its warning capabilities are not as good as those of Nagios. Its gathering and display of historical data makes it a good choice to be able to review whether the current values differ significantly from past values. It is easy to setup and can be run without generating warnings. The main problem is volume of data captured, and its fixed frequency of gathering information. You may want to generate graphs on demand. Munin provides many of the statistics I would check using when a system was in trouble. It's overview page is useful for identifying possible problems. Nagios is very good at alerting, but has historically not been very good at gathering historical data in a manner suitable for comparison to current values. It appears this is changing and the new release is much better at gathering this data. It is a good choice for generating warnings when there are problems, and scheduling outages during which alerts are not generated. Nagios is very good at alerting when services go down. This is especially suitable for critical servers and services. 

It looks like you are using a self-signed certificate. Client software will often not trust these keys. If you can arrange to have your CA certificate added to the client's trust chain then you should have not problem. Otherwise, the users will need to accept the certificate the first time it is used. Usually the accept dialog will default to permanently accepting the exception. Thunderbird works this way, but appears to require you to accept once for the IMAP/POP server and once for the SMTP server even if the same certificate is used. Eudora and Exchange should work the same way. From what I have seen most email servers do not verify the certificates provided. If they do you will need to configure an ACL to prevent offering StartTLS to those servers. EDIT: OpenSSL trusted certificates are kept in a directory ( on Ubuntu). The certificate is usually named according to the signing authority. There is also a symbolic link based on a hash of the key, that is used for lookup. You can add your own trusted certificates. 

Try configuring a connect ACL to drop connections from invalid senders. This can be done at connect time with an ACL. 

The Wordpress admin users can not modify any files that cannot be modified by the web server that is running it. A secure site will lock down all PHP files so that they can not be modified by the web serve. It appears you have done this. You probably should have set the group to (directory may be wrong for your installation): 

If you are running process accounting, you may be able to find the call(s) to rm in the processs accounting log. Shell history may have been removed, or may be configured for session private history. Concurrent sessions can also cause problems with shell history. 

Try the following commands to determine if you have a lot of connections coming from one address or if you are under a distributed attack. 

It may be simpler to enable or use the existing IPv6 stack on the Ubuntu server. If your server is providing DNS services for the client, you may be able to use to provide the IPv6 address of the server to the client. This may be as simple as adding the IPv6 address of the server to the file. The package can be used to build an IPv6 firewall. The package can be uses to provide a list of services available on the server to the OS X client. For local access to the services, this may be the simplest solution. This works well if you have an IPv6 address on the server. (Most likely you do.) To determine if you already have IPv6 address run the command and look for lines starting . EDIT: If you want to enable the client to enable access to the web pages via the server, an IPv6 web proxy like (version 3.1) will work. (This last edit is done using squid3 over IPv6.) This can be made discoverable via Your server can also provide a relay service for outgoing email. For other services there may be proxies available, or you will need to use an IPv6 to IPv4 NAT. From what I have seen development of these providers has not been significant. Google and some other providers are available on IPv6 so you can get limited connectivity to the Internet using IPv6. As most ISPs don't yet support IPv6 you may need to use a tunnel to connect to the Internet. I started with 6to4 tunnel and moved to a 6in4 tunnel. While I implemented my tunnel on OpenWrt, the process is much the same for Ubuntu. It is easier to implement on a server connected directly to your ISP's modem. 

This will be in if you are using the split configuration, or if you are using the single configuration file option. The easiest way to do scanning is to create a local data acl like this. 

If you don't have a way to get a public address, IPv6 will be restricted to link local addresses. These are restricted to the local link, and should be slightly more secure than the private IPv4 ranges which can be routed within sites. The IPv6 equivalent is a site local address, but these are deprecated. Firewall IPv6 with , just like you would IPv4 with . The Shorewall firewall tool can be configured to lock down IPv6, or its Shorewall6 version can be used to build an IPv6 firewall. IPv6 requires several more types than IPv4 to work correctly. and enables the minimal types for both when used with the example configurations. You have the option to enable additional types. IPv6 does automatic configuration, so it is important to restrict incoming access if there is a risk that you may get a public address assigned. On the plus side, if the privacy extensions are enabled, your address will change every few hours, so your IPv6 address will only be vulnerable for a few hours before it replaced with a different address. People with access to your traffic would still be able to identify your address attempt to scan for open ports. The IPv6 address range on any network is huge, and it is not very practical to scan a network for hosts. 

You should define your where you added to your path. You don't need it in your path. This is a sample Compiler.java file. 

If this works try with a browser. You may want to try setting your preferred language to something other than English to see how the language variance works. EDIT2: You can handle the errors in your php index page like WordPress does. This is done with rewrite rules to pass any missing URLs to the index page. (You need to handle the 404 condition in the index page.) I haven't tested any cases not generated within WordPress. 

If your storage is network mounted, then activity on the network and storage appliance can change your results. There are several layers of caching involved in a configuration such as you are using. 

Try configuring your SMTP server to send all your email via your Groupwise server or your ISP's server. This will resolve any number of problems as you should not have the authentication hoops you would otherwise have. If you do so, you can skip the following. Make sure that both your domain and IP address can be resolved via DNS. I have been blocking a lot of spam based on lack of DNS servers for either the IP address or the corresponding domain lately. Check to see if you have SPF defined for your domain. If so, you may be blocking yourself. Check to see if your address is on any blacklists. Spamhaus is heavily used and trusted and easy to get off of in many cases. 

Read the canonical answer on avoiding having your email classified as Spam. Search for other answers on delivery issues. 

As you are trying to send the messages to yourself, configure Exim to authenticate with your gmail credentials when sending the messages. This should work for low volumes that are not being forwarded. Add your credentials to /etc/exim/passwd.client. You should secure this file so that Exim can read it but not general users. I would not recommend this for high volumes of email or for email forwarding to other users. 

You may want to use SPF records for the domain and MX. TXT records were originally used and some tools only look for them. Creating both SPF and TXT record should minimize lookups required. 

You don't use the GLUE record. The resolver library uses them to locate the IP address of the corresponding name servers. When you query the name servers for the name servers for they will provide both the name and an A record for . This address may not be correct, as it is the address configured as the GLUE record for . 

You can supply an rdate source from Unix (Linux) using either inetd or xinetd. The server is built in to both these servers. Where possible, use ntp as noted above. Your ISP's DNS servers are likely to provide NTP services. These are likely closer on the net than any other servers. As suggested above, you should consider setting up an NTP server on your network. OpenWRT has an ntp package, and can be uses as your NTP server. 

Handling the redirect of can be done with a simple record. PHPFog directions should include the correct target for the . You won't be able to receive mail addressed to the sub-domain. 

This would give a maximum of 4 messages every two minutes. Another approach would be to configure Postfix to rely via a server. Configure the relay server with the reception limits you need. You should be able to configure Postfix to relay only for the one host. Either of these solutions can result in your mail server's queue to grow out of control. 

Exim4 is character set agnostic. It just provides the transport and delivery mechanism for your email. It handles UTF-8 and a wide variety of other character sets. Character set selection must be specified. The content should specify utf-8 if it is using it. A content-type header can be used to indicate utf-8 content: 

Gathering traffic statistics for your switches may show you have periods where you are running at or near capacity. This can lead to retries when responses don't come back within the inital timeout (often 3 seconds). This increases congestion momentarily until congestion mitigation mechanisms kick in. Look for people using streaming media as that can soak up bandwith quickly. You may be able to mitigate the problem for the phones by traffic shaping. This will just move the problem to other users. 

The usual metrics which indicate problems include cpu utilization, memory utilization, load average, and disk utilization. For mail servers, the size of the mail queue is an important indicator. For web servers, the number of busy servers is an important measure. Excessive network throughput also leads to problems. If you have processes which need to check times NTP can be an important tool in keeping clocks in sync. Standard warning levels I have used include (warning, critical). You may want to adjust your values based on a number of factors. Higher values reduce the number of alerts, while lower values give you more time to react to developing problems. This might be a suitable starting point for a template. 

As the mail sub-domain is in your domain, you can specify the as either or . For a different domain you always need a fully qualified address . Consider setting an SPF record up for your mail server something like this: 

If you are on the same box as the server, you may not be able to connect if you try to connect to . Use to determine which address(es) the server is listening on. Assuming the server is on port 12345 this command should work: 

Many automated systems don't bother to follow the RFCs and just send email out the Internet. As a result the look more like spammers than legitimate e-mailers. As a result they have problems getting their mail delivered, or get their mail classified as Spam. Either send the mail to your own mail server for delivery, or setup your server with an RFC compliant mail server. It may be easier to relay mail via your own mail server. Review my rules for Detecting Email Server Forgery. It starts out listing the characteristics of a legitimate server. Try to configure your setup to meet all of them. At the end of the document is a list of Verification Services as well as a list of Documentation Resources. 

If you are using as your DHCP server, you can push the DNS domain, DNS search list, and router to the clients. This should resolve your issue. 

The application should use the domain from the request headers when reconstructing redirects, rather than the remote IP when creating a response If the redirects are send by your server, there are a couple of options, both of which can be used at the same time: 

You can configure the parent to point to both servers. Consider leaving the old servers active during switchover. (You should always have at least 2 domain servers.) For domains not available on a server there will be periodic delays during failover to the available server. Consider the following approach. 

Normally, all traffic will be routed over the VPN. You are being assigned a point to point adddress. It should have a route to another address on the remote network side. All traffic other that that required by the VPN connection itself should be routed over this address. The private addresses (such as your DC) that can be accessed will depend on the configuration of the network you are connected to via your VPN connection. This will depend on the routing and firewall configuration on that end. 

If you are doing address validation, you may be triggering any number of spam avoidance techniques. While in the past address validation was generally permitted, spammers have resulted validation being restricted. Fixing the items above may help but I wouldn't count on it. These days the only widely supported address validation is to send an email with a validation link for the user to confirm their address. You may want to review the canonical posts on email and postfix. 

Spam filtering software is reasonably good at finding Spam although some will get through. It can be tricky getting the false negative to a reasonable level without increasing the false positive too much. I find Spamassassin catches most of the Spam that reaches it. I've added a few custom rules, that fit my needs. Postmasters should configure the required abuse and postmaster addresses. Acknowledge the feedback you get to these addresses and act on it. This allows other to help you ensure your server is properly configured and not originating Spam. If you are a developer, use the existing email services rather than setting up your own server. It is my experience that servers setup for automated mail senders are likely to be incorrectly configured. Review the RFCs and send properly formatted email from a legitimate address in your domain. End users can do a number of things to help reduce Spam: