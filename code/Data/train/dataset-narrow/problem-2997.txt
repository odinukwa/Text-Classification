Having taught them binary, we can discuss storage limitations of different data types, floating-point imprecision (as Ellen mentioned), use cases for different bases such as octal and hexadecimal, and file signatures, among many other topics. We use to investigate a bitmap (and dive deeper into color representation) and to examine the metadata stored in pictures taken on a cell phone. Do I think binary-for-binary's sake is worth it? Probably not. It's a lot of work for not a huge pay-off for a beginner programmer, and it's easy enough to look up a binary-decimal converter. Is it worth it to understand binary in terms of the larger context of abstraction and to be comfortable occasionally looking at and deciphering representations of it (along with octal or hex)? Absolutely. It's how all digital data is represented, and the groundwork should be there in some form from the start. 

Computer science is a discipline of problem solving. I use this phrase from CS50 often (mainly because I teach an adaption of it): 

The example that instantly comes to mind is Blackjack. See the code excerpt below for an extended example in C (even though it's C, the syntax will pretty much hold true for Java as well): 

Let's start with the term "Loop Invariance". It is a property of a loop that is true before and after each iteration, thus in-variant, non-changing. So then, what is the purpose of the loop invariance in proving algorithm correctness? That is, it is a predicate about what the loop is supposed to do. Thus with proof by induction on this predicate shows the correctness of this algorithm. I know this is still very theory heavy so let's break this down even more. A simple insertion sort. The purpose of insertion sort is to sort an array. Therefore the loop invariance would be that after each i-th iteration, the array is sorted up to the i-th element. The magic here is that instead of looking at the nested for i, j, loops of the algorithm you are choosing the loop invariance that contributes to the goal of the algorithm. To answer (1). There is no sure guarenteed way to choose the correct loop invariance unless you are very experienced in algorithm correctness through countless examples. The best approach is to choose the segment of code that is actually doing what the algorithm is trying to do. Such as the example above, sorted up to the i-th element. (2). I believe this has to do with the proof itself, rather than understanding the loop invariance. Structurally, to prove that the algorithm is correct, you would have to use proof by induction (either simple, or complete) to pove the loop-invariance and the fact that the algorithm actually terminates. Usually proof of termination is a 1 liner, such as when i > array.length, loop will terminate. 

Since most of the answers here already provide a good pedagogical approach, I'm going to add one element you can use to completely shift the tone when these moments occur: use a meme. Find humor in the absurdities. I strongly believe that well-placed humor in the classroom is of instructional benefit. My reasoning as humor applies to this particular topic comes from the "Wat" talk given by Gary Bernhardt. In it he uses the "Wat" meme to point out some rather absurd characteristics of Ruby and JavaScript. The video is only a little over four minutes long and can be found here. Teaching with memes can be a memorable and funny experience for students, and it then becomes something they can continue to reference. Befuddled by why a language has a quirk that it does? Make a meme of it. Share it. Tweet it. Put it up on a classroom wall. The drastic difference in tone will help students create that cognitive separation between those big picture items and those more quirky items by which you don't want them to be distracted. Sometimes we don't need to take a serious, intellectualized approach; comedy can work in aiding the learning process. Here's an example based on what you list above: 

I can tell you are very intelligent as this is something only someone who truly understands algorithms and proof of correctness can say. It is actually very difficult for younger students to see this as they are tunnel-visioned by the actual loops in the code instead of the bigger picture. Instead, I think what you are trying to convey is to look for "what part of the code is doing what the algorithm is meant to do" 

That depends entirely on the context of your CS1 course. Are you teaching unit testing suite to your students? If you haven't learned something then how can you use it? If unittest is part of the curriculum, then definitely students should use it. At my University, students are formally introduced to the suite during 2nd year, and thus for all their Java projects they are required to have their own testing suite. As for their C projects, we do not require unittesting because is already enough hair pulling. So to answer your question, no we are not using unit testing in CS1 because it has not been formally taught yet. 

I've found a lot of success giving real world (often times very silly) examples of boolean algebra to give them a more intuitive understanding in addition to the pure algebraic laws. An example would be "If it rains tomorrow, I will bring an umbrella so I will stay dry". This is a simple A -> B: If it rains tomorrow then I will bring an umbrella, I will stay dry (T -> T = T) If it rains tomorrow then I will not bring an umbrella, I will not stay dry (T -> F = F) If it does not rain tomorrow then I will bring an umbrella, I will stay dry (F -> T = T) If it does not rain tomorrow then I will not bring an umbrella, I will stay dry (F -> F = T) Using DeMorgan's we know A -> B = !A V B. We can say A = it will rain tomorrow, B = bringing an umbrella and whether you stay dry or not is the equivalent of the resulting truth table value. You can incorporate students in coming up with these silly examples, and having them figure out how the narrative would look like to reflect the truth table values. In addition, pairs can come up with scenarios and test each other's knowledge. (This was during 2nd year University too! So it's never too old to get silly) Lastly as a remark, I did not see you mention some Laws of Boolean Algebra such as Associative, Commutative, Idempotent, Identity, and Distributive. I think it's worth while to introduce these laws during lesson 1 or 2 because solving boolean algebra down the road is built off of these fundamentals. 

I personally struggled a lot with what and how much homework to assign my AP students this past year. I wanted it to be effective and not just "homework-for-homework's-sake." I found students worked more effectively on coding when I was in the room and they could ask for help. If they hit a brick wall at home, they were stuck until a) they got to class the next day or b) they received an email from me (presuming they took the time to send one and I got it in time to reply in a timely manner). On the other hand, the content required in an AP class, especially CS50 AP, seems to necessitate some work be done at home. There's a lot to cover, and class minutes are at a premium, so if homework can reinforce the day's work and/or give a head start for the next day, it's worth it. Yet, as with the tweet's sentiment, I want to honor the lives of students outside of just my classroom. For my question, I'm thinking particularly of honors-level HS students (either AP CSP or AP CS A - I think this would apply roughly equally to both). What homework assignments do you and your students find beneficial? What type/amount of work done at home is most effective for increasing student learning? 

A set of instructions written in human readable language (at least to developers) that is executed to perform a task or goal. 

Ultimately it comes down to if the work can be done alone? The purpose of group work should not be so that everyone has less work to do, but rather if the original work could not be done within the given span by a single person. In the workforce, you're most likely to be working in a team and contribute to iterative releasts (Agile Methodologies). If your expectation is that because you're in a group, you don't have to work as hard compared to working alone, then you are set to fail. My suggestion would be to design a project such that bi-weekly or monthly iterations are presented, building up towards the final product. Incorporate Agile Methodologies into this as it is very useful in the workforce and teaches team management / tracking. Groups should be no bigger than 3-4, otherwise it is too big to be efficient. The number of hours required for the project should be big enough that everyone is kept busy. Of course some will do more than others, however one person should not be able to do the entire project. If this is too heavy for your course, then I'd suggest stick with single person projects as there is no merit to group work. 

I learned Racket using the material taught by the UW MOOC on Coursera Programming Languages, Part B, which is modeled after this UW course. Here are the relevant helpful documents, which do provide an introduction to the language along with quite advanced material which involves implementing a programming language within Racket: 

The best explanation I have seen is in the context of the Programming Languages MOOCs offered through Coursera modeled after this course at UW. The class works through, in order, a statically-typed functional language (ML), a dynamically-typed functional language (Racket), and a dynamically-typed object-oriented language (Ruby). Since this is an upper-division course and students presumably are somewhat familiar with it, Java is thrown in for comparisons when relevant as a statically-typed objected-oriented language. If you want to find a thorough comparison, build projects with each approach, spending time to learn the relevant nuances of FP and OOP along the way. There is no chart or tutorial that can substitute for this work; it simply takes time and practice. Based on my experience, the work of this course will not disappoint. There are short mini-lecture videos, excellent reading notes, and challenging homework assignments all available for free. At the end of the course, the professor does an excellent job breaking down OOP v. functional decomposition. By the time you reach the end, you will have a clear picture as to how these approaches differ, where their relative strengths and weaknesses like, and when/how to apply each paradigm to a particular problem. 

I've always admired the Swiss' education system of teaching kids where they rarely have examinations, but rather through constructive assignments and homeworks to teach students. At a conference I've attended, I heard a quick introduction on gamification of education and I am trying this out with some students. Here is what I proposed: Assesments (excluding exams and final project, due to curriculum and school board constraints) have unlimited re-tests, limited to once a week. 0.5 credit is awarded for 50%+ and 1.0 credit is awarded for 80%+ At the end of the term, their number of credit earned is divded by total number of credits for a "term work" grade worth x% of their final mark The goal here is for students to not worry about a 50, 60, 70, 80, 90 or 100, but rather track their progress through completion of content. I believe the unlimited retries gives incentive for students who are falling behind to realize early and catch up immediately, rather than later. This is to avoid the mentality of giving up because it is "too late" or "wait for next test". To some degree, I believe in the innate competitive nature of CS students transferred from love for gaming I believe this method (with modification to suit your needs) meets what you are looking for. Accurate enough to give a % mark because you track progression. Although I foresee multiple 100% with this method Does not disturb students because they are well aware of their progress, and know they can make improvements rather than blankly stare at an unfortunate poor test 1 Quick and low effort - I just use an excel macro and export to show my class after each week their progress 

From the perspective of MOOCs, a great place to start is MITx's 6.00.2x: Introduction to Computational Thinking and Data Science found on edX. It uses Python to introduce the study of data science and does not presume more than a beginner level of either Python or data science (although 6.00.1x, the first part of the course, is helpful for those who no experience whatsoever). The penultimate unit focuses on Machine Learning using the following outline: 

To elaborate on my comment, I suggest approaching both (but HTML first) by way of the DOM. W3 Schools has a tutorial on both HTML and XML using this model for conceptualizing the structure of HTML/XML documents. The XML tutorial stresses the importance of knowing this structure: 

I'm going to begin by quoting Ken Thompson's Turing Award Lecture "Reflections on Trusting Trust" (link). 

To implement an interface is to promise, to guarantee, that the class will come through on its end of the bargain and implement everything in the interface. The idea of a contract is already a successful analogy, so I wouldn't try to necessarily reinvent the wheel here lest you introduce more confusion with a different analogy. You could have students use the word promise if contractual language does not hit home for them. Putting it in the context of friendship and promises being made might make them understand an interface in a better way than legal agreements and contracts. Ultimately, simple, relevant examples that clearly illustrate why interfaces are of value and how they are central to human-computer interaction will probably be of more value than a different, clever analogy. You may find this since-closed discussion on SO of value.