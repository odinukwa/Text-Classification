This is not about natural and surrogate keys, but about concept of independent and dependent entities. Here is your original example 

I prefer the first case when possible -- you choose your favourite. And obviously, there is no need for direct FK from to in these three cases. 

| School (SchoolId) is located in county (CountyCode), district (DistrictId). School is identified by SchoolId. For each school, that school is located in exactly one county, district. For each county, district; more than one school may be located in that county, district. If a school is located in a county, district; then that county must be located in that district. 

If you prefer single-column then you can ADD them to and tables, but you must keep the existing ones as (unique) and reference them in foreign keys where applicable. 

Note that is propagated to the to serve as a FK. If you squint a bit, this is close to your example, but with only -- as opposed to two column PKs from your example. Now the question is, why not simplify to something like this? 

| Student (StudentId) attends school (SchoolId). Each student may attend more than one school, for each school is is possible that more than one student attends that school. If a student attends school, then that student must exist. If a student attends school, then that school must exist. 

I would say both are OK, but I prefer the second example. The confusion stems from something that you know as absolute. 

And here is how it looks in an ERD; note that comments (grey) are not necessary, used only to illustrate the method. You may also note that it is not easy to express all the constraints here -- if comments are removed the [c2.3] will not be obvious. 

| County (CountyCode) is located in district (DistrictId). County is identified by CountyCode. Each county is located in exactly one district; for each district that district may have more than one county. If a county is locaeted in a district, then that district must exist. 

As far as mandatory address is concerned, verify that on the application layer and wrap the loading statements into a transaction -- that way you'll get all or nothing. 

I have column of type bytea in PostgreSQL database. If I update a row, is it possible to chunk the data into the bytea column in several small steps? The size of one bytea entry will be mostly below 200MByte. The chunks will be about 1MByte. I use psycopg2 and Python to access the db. This is a follow-up question of Store HTTP response in PostgreSQL 

The application "foo" uses this plpythonu source code to read the custom variable . I guess this is way too complicated. How to shorten/simplify below lines? 

We use check_postgres.pl to monitor our database. We use this to check the count of the locks: $URL$ We often see more than 150 locks. The question was: What is going on? We patched the script to output this sql statement, if the lock count was exceeded: 

How to realize these improvements? Are there other things which could get improved? I am using PostgreSQL 9.3.13 

I read this article about PostgreSQL performance on SSD: $URL$ These two configurations seem to be important vs Since both parameters need to match the particular hardware I wonder if it is possible to automatically detect the matching values? Update I have these steps on my mind: 

I want to understand a database layout. It has 180 tables. I only know the high level use case: Owncloud (File Hosting Server. Can be compared to DropBox). How to understand the database layout? How to identify the most important tables? Is there a tool which helps me to understand the layout? At the moment am interested in two facts: 

I want to check if our code does use only indexed columns. I think it does, but I want to be sure. How can I configure/modify PostgreSQL to raise an exception if it needs to do an sequence scan? It is ok, if PostgreSQL wants to do an sequence scan, but an index exists. Then I run our software tests to see if an exception gets raised. 

$URL$ row2: I think every person has exactly one date of birth. I don't understand this row4: I think every person has exactly one birth place. I don't understand this. What am I missing? 

From what I understand of your problem your "duplicity" is fine. If your saying that all of the shops act totally independently then yes in your example shop E and shop D might have the same data but the data is not related so it might look like a duplicate, but I would not consider that a duplicate. Another example, I am answering this question now, but I expect someone else is going to hit the submit button to a different question at exactly the same time, so in their "answer" table (or whatever) there will be two rows with "duplicate" data on it (the time of answer would be the same), is this a problem..... no because the data is unrelated, its simply a record of what happened. The only time I would suggest normalising this further is if you had to attach extra information to the time which would be the same (so if there was information that would always be the same whenever any shop does any deal that starts at 6pm on a Sunday). A counter argument to this could be do you have shops in different time zones? If yes then 6pm could mean 6pm local time, but not at the same time, in this case what possible extra information could there be which would always be the same in every country, time-zone, shop and deal. 

If pg_clog is gone..... thats bad, this stores the commit log so the database knows what has and has not been committed. I would start looking at backups now, or if the data is disposable and there is no backup then building a new cluster. There are ways you can get the data out, but as far as I know they are very time consuming. The bigger question though is what happened to your machine to cause this? 

The standard streaming replication on PostgreSQL is single threaded and there is no way to change this. However the question is why would you want to? PostgreSQL's streaming replication works through the write ahead log which is kinda of like a set of instructions "change block 3525 to this", "change block 2424 to this", etc. This makes the replication process very fast as it not re-executing SQL, its simply doing the same data file updates that the master has done. Typically the slowness with replication on PostgreSQL is IO bound rather than CPU bound so executing the recovery in parallel will actually make it slower not faster. This is because the effect of interleaving the IO requests will potentially make sequential IO random. Of course modern SAS drives should be able to reorder the requests for data back into sequential order. I suspect the question came about because of the statement shipping type of replication MySQL and MariaDB can do, in this case yes of course it makes perfect sense to interleave the statements as there will be a much higher CPU cost and running this on multi-core hardware will offer a great performance improvement. 

This is simply not true, you should modify your belief to something like: "Often it is beneficial for a table to have a single-column primary key because ... " 

Which is fine, but introduces PATH DEPENDENCE -- you can not join with directly, must use in the join. 

Though there is nothing cyclical here it does have few problems. For example, the model has no relationship between and , although you do state that "District has many Counties". It is also possible to have such that that teacher does not teach in the district the county is located in. 

P2 Course number (PRE_NUM) is prerequisite for course (C_NUM). c2.1 For each prerequisite course that course may be prerequisite for more than one course. c2.2 For each course, that course may have more than one prerequisite course. c2.3 A course can not be prerequisite to itself. c2.4 If a course has a prerequisite then that course must exist. c2.5 If a course is a prerequisite then that course must exist. 

First thing to notice is that the PK on the LineItem table has three attributes , as opposed to just two in your example. Second thing to note is the confusion resulting from the use of the generic name for an attribute. The should ideally be (1,2,3..) for each customer and (1,2,3 ...) for each order. Well, this is nice if possible, but requires a query looking for the previous max value, like 

P1 Course named (C_NAME), assigned a course number (C_NUM), exists. .. and constraints c1.1 For each course name, exactly one course has that name. c1.2 For each course number, exactly one course is assigned that number. The predicate leads to relation; the constraints to -- well, constraints like: PK, AK, FK, CHECK etc. 

which is often not preferred in high-transaction-volume environments, so it is common to see these replaced by an auto-increment, essentially serving the same purpose. It is true that this auto-incremet is now unique, hence it can be used as a KEY -- but you may choose to look at it as a necessary compromise for the . So, with some renaming and -> you may arrive to this model 

If I fetch only one row, the query takes much longer: 1433 ms vs 23 ms Is there a work around? Slow: 

We have a PostgreSQL based system which is installed at 20 customers. Sometimes I run a SQL query over all systems. Up to now I do this with the command line tool like this: 

According to the docs a vacuum should help, but the autovacuum does not help. What can I do to get rid of the bloat? 

The size of the our PostgreSQL data directory is 100 GByte. Up to now we use traditional hard disk drives and hardware RAID 10. Which hard disk drives and RAID setup would give us maximum performance? The budget is at maximum 5000$. The load is like in most average databases. Maybe 1/5 writing (update or inserts) 4/5 reading (select). 

If or gets updated, then the table should get filed. The ticket.id of the changed ticket should get inserted into the transfer table. Here is the working code: 

I search for a simple way to select all columns except one in psql. With I mean the interactive command line. I would be happy with a tool that expands to to a list of quoted column names. Then I could remove the column to remove by hand. My question is just about the interactive usage of psql. It is not a duplicate of questions of people unhappy with the sql standard and who want to execute something like "select *-foo". 

Script creates some dummy tables Scripts inserts data to the tables Script does some queries Script shows matching values for random_page_cost and seq_page_cost Human or an automated system takes these values and updates the config. This step is not part of the question. 

If I have a simple ascii list of both sides, I can use a diff tool to compare both db schemas. I found ways to output all columns like above but the solutions don't support ordering by the schema of the table. Question How to show the difference of the column order in two databases? Other strategies are welcome. Implementation: I use postgres 9.3 

How can I dump this statement again? I looked at but only found a way to do a data-only dump or a schema-only dump. If I do the following, then I get both (CREATE TABLE and GRANT statements) 

| Teacher (TeacherId) teaches in school (SchoolId), in district (DistrictId). Each teacher may teach in more than one school in a district. For each school in a district it is possible that more than one teacher teaches in that school. If a teacher teaches in school in a district, then that school must be located in that district. If a teacher teaches in school in a district, then that teacher must be licensed to teach in that district. 

Note: I am using RDBMS wording for constraints, in general is an internal uniqueness constraint, foreign key is a subset constraint (inclusion), and is an internal value-comparison constraint. 

There is nothing circular in any of these cases. In "circular reference" scenario you have "a chicken and an egg problem" -- can not insert a row into a table because it is always missing a reference to some other table, like in: 

| Teacher (TeacherId) is licensed to teach in district (DistrictId). For each teacher, that teacher may be licensed to teach in more than one district. For each district, more than one teacher may be licensed to teach in that district. If a teacher is licensed to teach in a district, then that teacher must exist. If a teacher is licensed to teach in a district, then that district must exist. 

So, both R1 and R2 are in 6NF and therefore in 5,4,3,2,1. There is no in-between -- it may happen that in some specific example you may see "progress" 1, 2, 3, BCNF; but that is an exception, not the rule. 

And now a bit modified model where is a dependent entity (note rounded corners). Here can not exists outside of the context of the . 

| Student record (RecordId) was generated for student (StudentId) by teacher (TeacherID) in school (SchoolID). Student record is identified by RecordId. If a student record was generated for a student by a teacher in a school, then that student must attend that school. If a student record was generated for a student by a teacher in a school, then that teacher must teach in that school. 

This is the root cause of your problem. There is no such thing as a parent table in relational model; foreign keys are constraints, not navigation paths. You are dragging OO terminology into a relational DB and these two do not match -- paradigms are different.