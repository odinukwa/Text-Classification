I have an Oracle 11.2.0.3 about 700GB in size running in noarchivelog mode in a pretty slow storage setup. It barely gives IOPS and there is resource crunch in terms of hardware resources. The transactions hitting the database is heavily read/write intensive and redo generation is quite high (near to 8MB/Sec) and naturally it is finding difficult to write to the disk. What can be done in such a scenario? Can nologging in certain tables boost the performance? Data corruption because of nologging is a concern, I understand that and can be taken care of. But can someone give insight of how truly enabling nologging helps in this situation? or if it doesn't help, what are the other options I have? 

Should the service-name mentioned in TNS and the service which I create for TAF using srvctl be the same so that client need not make any changes in tns at their end? 

I'm running a master-master replication with read-only second master. Now since my binary logs are not getting replicated in my passive master. 

I'm planning to go for a 3-node active-active MySQL cluster which will not have more 100 databases. Many experts here have already told there are issues with MySQL 5.6 and 5.7 where circular replication happens which is very vulnerable due to increase in failures, in what way Percona XtraDB provides edge to MySQL cluster? Percona doesn't do the circular way? Just trying to understand. The application which i'm going to use is not very much resource intenseful. What is the best option for 3 node active-active cluster? 

I have two databases - one is 11g and another 12c. 12c db has the exact data of 11g (expdp/impdp). Now I'm facing an error in one of the tables with unique constraint error. I have checked the structure of the table and constraints enabled for the table in both the databases, that is same as well. Now how can I sort this out? I'm facing this error on the application which is running on it, when I click one of the tabs. is the error i'm getting 

I'm new to SQL anemometer. I need to know whether this tool would be able to query to the source database and analyze the slow query logs on real time or not? 

I have two 5.6 Percona servers in which I'm planning to setup Active master- Passive master replication. Secondary master will be in read-only mode. Caveat is that the servers in which i'm going to setup is live databases. Master is already running with server-id=1 and it is in place. Secondary master is newly created instance. Now to backup the production master and copy it to the secondary master, is it mandatory that I need to take backup the live database and then copy it to secondary? Or will it suffice if I take last night's backup? Also, when I set the Active master to be the slave for secondary, will it impact my production? I know I need to do this off-live hours but situation demands, hence I wanted to reconfirm before proceeding. Please highlight on what impact that could do in live database for setting up this replication. 

One of my developers is trying to perform insert into a table by selecting from a table. Below is the query that was run. The query takes extremely long time for execution (4hrs odd). Number of records on the table where it is getting imported is 1.2 million. Database - Oracle 12c on Linux with archivelog mode on. 

I have MySQL 5.5.44 running in RHEL server. It is a standalone server used for testing and offlate not much used. The instance is currently down. Hence, I tried to start the service. It got started but everytime I check 

How does Oracle perform in hyperconvergence systems such as nutanix, simplivity? Oracle doesn't certify the underlying storage which nutanix or simplivity offers (file level storage) but in reality case studies say those systems perform good in general but with Oracle databases, technically how sound it is to go ahead with it? 

I need to select PERSON_ACCOUNT.PAID_YEAR, PERSON_ACCOUNT.PAID_AMOUNT,PERSON_ACCOUNT.PAID_AMOUNT * multiplication of the YEARLY_RATES.RATE WHERE YEARLY_RATES.RATE_YEAR >= PERSON_ACCOUNT.PAID_YEAR. So for instance if I have the following data in PERSON_ACCOUNT 

Now, there might be multiple entries for one customer_id value in the table B. I need the latest date to be updated into the table A. I wonder, if I order the result by last_login_date column in Ascending order, will the merge statement eventually update the record in A with the latest last_login_date? 

EXP(SUM(LN(YR.RATE))) is just a trick to get the multiplication of the column values as there's no ready function available in Oracle. 

The title was best I could find to explain my question, I don't think it helps though. Anyways, I have two tables: 

After the process is over, I run queries against all the tables. Everything goes fine with 9 of them, but with one of the tables the executed query hangs. The next day, when we run the same query against the same table, the execution takes only a moment. I have no idea what the problem is. I tried not adding indexes but it didn't help. I know he way we copy table content might seem weird. 

I have two schemas namely A and B. I regularly copy contents of 10 tables from A to B. Here's is how I do it 

First I rename the original tables in schema B Then, using SQL Developer I copy the table to copy from schema A to B. (I right click the table to copy and select Copy and choose the destination schema) Then I create all the indices that exist in the original tables.(Copying tables does not copy indexes, so you have to create them manually) 

ACCOUNTING,FINANCE,HR columns of the the CONFIRMATIONS table correspond to the USERID column in the USERS table. I need a query that will put USERNAME corresponding the USERID if in any of the ACCOUNTING,FINANCE,HR columns have a value in it. So suppose we have the following data in the tables: 

Now if I want to show only the first ten rows between 50 and 60, the only way I can think of is to first run the above query with ROWNUM pseudocolumn and then select from the result of this query. Something like this: 

I think it's obvious what it does but to make it clear let me give a brief explanation. In my table there's DOCNUMBER column. I assign a value to this column in Before Update trigger. And in the above trigger, which of course should fire after the Before Update Trigger, I check if the DOCNUMBER has value (and if it's for the first time) and if it does, I write that value to another table called . The problem is, the above trigger sometimes, although very rarely, fails to insert the to the table. That is, sometimes I see a record in table with DOCNUMBER value that does not exist in table.The table has only one column called DOCID and it's part of a UNIQUE KEY constrsraint. Do you see any problem with this trigger? EDIT: I think you'll get a better idea if I post the BEFORE TRIGGER too: 

I know that there's a one to one relationship between the document types and Instructions, so according to database normalization I should not have a separate table for it. But on the other hand I'll have to include the same columns in two different tables. What do you think? P.S. I won't be able to create a foreign key constraint between Instructions table and the two other. 

Sorry for the title but I could not find anything better that could suit my needs. I'm designing the database of a Document Management (Circulation) application. There are two types of documents - A and B. I've created a table one for each. Any document independent from its type has Instructions information that has to be attached to it. Here are the details of the Instrcutions: 

I have 4 servers running MySQL 5.6. A,B,C and D. A and B are Master and slave whose default port is 3306. C and D are running in non-default ports 3360. A and C are in Master-Master replication mode. C and D are in Master-Slave setup. Now I need to change the ports on A and B from 3306 to 3360, what commands I need to run and in what order to have B,C and D back in replication? Is the below steps right? 

I have a primary and a standby database. Both two node RAC database. As some testing had to be done in standby database, I had to open it in read-write mode. I cancelled the recovery in standby and activated standby database and opened the two node database in read-write mode. Now, the DR is broken. And to make the standby as a proper physical standby, full reconfiguration of DR is required? If not, help me out in setting up my standby back in track! 

I have run mysqlcheck on all the databases as well which returned 'OK' for all the tables. Not sure where to start debugging. Any ideas? 

I have some 100+ Oracle/SQL server databases to manage. Need is that how can I put up the availability of databases (up/down) projected on to a monitor from where it can be seen if a database goes down, I should get an alert on it. What tools can I use. I use EM12c for managing everything, I know it does a pretty good job in doing everything, but still this is required from my boss's perspective of looking at things. So if there is anything that you guys help me out with, it would be great! 

I have two node RAC servers hosting 4 databases running on 11.2.0.3 version in RHEL OS. The underlying LUNs assigned to the ASM is not currently multipathed, meaning the disk sequence would change when my server node reboots causing my ASM not to mount the diskgroups and therefore I have planned to create new disks using ASMLib with newly added LUNs which would be multipathed. I got new LUNs and I created new disks using ASMlib as well in node 1. Once created in node 1 and scanned the same in node 2 for disks to be discovered in node 2. The disks are discovered in both the nodes. After creating diskgroups when I try to mount them, in node 1 it is getting mounted, but in node 2 it fails giving 

I have few doubts regarding MySQL replication (Master-Slave). Is it mandatory for a table to have primary query for replication to function properly? Referring this Percona link for the above question as it mentions that If there is no primary key or unique key defined then it’s even worse because INSERT may be re-executed and you will get multiple rows with the same data – which again means you’ve got inconsistent data with the master But with InnoDB as the storage engine, if a table does not have primary or a unique query defined, the engine itself creates hidden clustered index on a synthetic column containing row ID values as per Jeremy Cole's blog So, even in the case primary or unique not present, the replication should not have any impact it in itself creates a clustered index which should ensure the replication is smooth, correct? I'm not sure on this part. Would be great if someone can throw some light on the need of Primary key in Master-Slave Replication setup. 

So I have an Oracle database (standalone) running in RHEL and I have scheduled RMAN for backups on daily and weekly basis. Sometimes my file system (archive mount-point) becomes full because of high archive generation. Now what is the right way to delete the archives from the file system? My RMAN script has this