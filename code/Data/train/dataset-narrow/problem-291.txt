It's important to note that any classifications you define need to match what your WAN provider supports. Most providers offer only a handful of pre-configured QoS profiles from which you must choose which best suits your needs. You can classify however you'd like on incoming traffic at the WAN edge, but the provider's QoS controls are what control the the treatment of traffic during transit across the WAN. 

The first thing that jumps out at me is that you appear to be shaping everything to 4 Mbps. I imagine that the rate changes on routers/sites with different circuit speeds, but you generally want to avoid shaping when dealing with latency-sensitive applications like VoIP and RDP as it can cause excessive buffering and jitter during periods of congestion. Also, the command is a bit tricky: Each instance actually allocates n% of the remaining available bandwidth, not n% of the total. This graphic from an article by Arden Packeer should help illustrate the idea: 

TCP and UDP are two protocols that operate in the layer 4 (transport) of the OSI/DOD Model, however tcp might use different port number for different type of service, for example if you are sending a mail, tcp will use smtp tcp port 25, if you send large file without messaging system like mail, tcp will use ftp tcp port 20/21 

accessing your 2 networks with only one PC it ok, but if you want to fully Protect your intranet, I suggest to use a KVM, this will give you the impression of using a single monitor. 

I need to set up a modest iSCSI SAN with a few ESX hosts and one storage array. Can I get by using a Catalyst 2960-S or do I need to upgrade? Are there any special tweaks I need to make to the switch in order to handle iSCSI? The switch will be dedicated to the SAN; no other traffic except management will be present. 

The edge routers at sites A and B will both see their own MPLS link as the best path, because EBGP routes are preferred over IBGP routes. However, routers further inside AS 65000 will all prefer either one link or the other. My goal is to force all the routers at either site to prefer the closest link. (Unfortunately, I'm not able to split the two sites into separate ASes at this time.) Is there a sane way to accomplish this while still allowing failover connectivity to site C between the site A and B links? Edit: I should have noted that there is no IGP in use here. In fact, the networks at each site exist within a VRF as part of a much, much larger network. As such, any solution needs to be rely entirely on BGP. 

Media Endpoint Discovery that is an enhancement of LLDP, known as LLDP-MED, may help you doing that. 

If you want to add multiple devices to your network, I suggest to use Switch instead of HUB, switches have been invented to resolve many problems caused by HUB like "one single big collision domain, one big broadcast domain, speed/duplex limitation and so on". even with Switch sometimes it is necessary to create smaller broadcast domain wich is good for network performance by using vlan. so avoid using hub in your network if you can afford switch. 

In this situation, you don't actually have load balancing, both routers are set with a priority of 100, you should set a higher priority like 110 to the one you would like to become the active router. 

Traffic always follows the most specific (longest) route entry to its destination. So, any network knowing both the 46.246.32.0/19 route from AS37560 and the 46.246.0.0/17 route from AS42708 will prefer the former. If the route from AS37560 gets withdrawn for some reason, the remaining route (via AS42708) will become the preferred route, assuming no other more-specific routes are available. 

Per-prefix labeling is used for this VRF on both routers. Notice that the two directly connected routes receive a shared aggregate label (95) whereas the four static routes each receive a unique label. Router B agrees on the VPN labels to use: 

sometimes you need to reboot your router to affect election process during OSPF BR election, sometimes you do it after modifying the configuration register to actually modify the boot process or restoring password, if your network is experiencing congestion you need check it out, I don't think rebooting constantly your network/router is a solution. 

Each VLAN is a network, Basically according to your diagram you have 9 networks, with a Router you don't need to do routing with a layer-3 switch, However maybe you don't have 9 ports on your router for your 9 networks, in this situation, you can use a technique called router on a stick by creating virtual port for each vlan, here is an example. on the router Interface Fa0/1 ip address 192.168.10.1 255.255.255.240 interface Fa0/1.2 encapsulation dot1q 2 ip address 192.168.1.65 255.255.255.192 interface Fa0/1.10 encapsulation dot1q 10 ip address 192.168.1.129 255.255.255.224 

There are tools like WANem which allow you to simulate WAN links by artificially causing arbitrary delay and loss rates on a link. WANem works at a relatively high-level; you won't see physical errors on the link but packets will be dropped. It can be deployed on commodity hardware. I know there are a few other tools which serve similar purposes but I can't recall the names of any at the moment. 

Some vendors support IEEE 802.1ae/MACsec for encryption layer two between the access switch and its endpoints. I'm afraid I can't be any more help as I have no experience with it (and frankly it sounds like a nightmare to administer). 

A subnet mask is a 32 bit value that allows the device that's receiving ip packets to distinguish the network ID portion of the IP address from the host ID portion of the IP address, so without a subnet mask that can be represented in form of a 32 value like (255.0.0.0) or slah-notation(/8) it is impossible to identify the network prefix of an IP address. 

ICMP is a protocol used to report problems or issues with IP packets (or datagrams) on a network. The most popular use of ICMP is to send ping packets to test the network connectivity of remote hosts. The network device generates an echo request packet that is sent to the destination device. Upon receiving the echo request, the destination device generates an echo reply. However the term binding is used when you have a DHCP server. 

Hardware network taps provide one output port in each direction to ensure that traffic can be replicated at line rate. For example, a 100 Mbps Ethernet connection provides a theoretical maximum of 200 Mbps of total bandwidth; 100 Mbps in each way. If you tried to capture traffic from a line which was carrying 75 Mbps in each direction, you would need at least 150 Mbps of one-way bandwidth: more than a single 100 Mbps connection can carry. Hence, taps include two output ports operating at the same speed as the line being monitored. 

Both traceroutes above should be following the exact same path, and there are no filtering mechanisms in place along it. The same thing happens in the reverse direction as well. What am I missing? What's the difference between BGP routes learned by direct connection versus static configuration with regard to MPLS/label forwarding?