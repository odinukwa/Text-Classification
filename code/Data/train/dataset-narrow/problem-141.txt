Well. Since you've captured packets that show that your Trading Server is sending the TCP ACK's with a window size of 0, you at least know the problem is definitely on your side. Which is actually a good thing, because you are in a position to fix it. (There is one thing that might be the issue which would be a problem on their end, I'll talk about that later) You've also traced the issue to happening during times of increased throughput, also a good thing. You said the CPU/RAM usage on your Trading Server reported normal. The application you are using, is it by chance configured to use a limited amount of RAM on the host OS? Maybe a limited percent? Because it would stand to reason that if so, as you had more connections and more throughput, there was less RAM available to the application, and therefore less resources available for TCP. Either way, what OS is your Trading Server using? If you haven't already, you should look into tuning the OS to dedicate more RAM to TCP. In Windows, there are Registry values you can modify. In Linux, there are config files you can edit. It would also be wise to make sure your Firewall (and nothing else in between) is trying to proxy your TCP sessions. That way you know you are dealing with the full "client to server" TCP connection, and not something in between. The last thing I can offer is to study the TCP packets being sent from the Stock Exchange to your server just before your server sends a Window Size of 0. In particular, look for the incoming packets to have the value 11 in the IP Header's ECN field (Explicit Congestion Notification -- the last two bits in what used to be DSCP, bits 14 and 15 if you're looking at an IP Header). There is a chance that if both the Client and Server in the communication supported ECN, and a router in transit detected congestion, that it turned these bits on to tell the client and server to slow down their transfers. (This is that thing I said that might be a problem on their end) I think that (tries to) answer questions 0,1,3. I'll have to dig around a bit more to give you a reliable answer for 2. But I'm pretty confident there is a way. 

Symptom #1 Now, lets assume SiteB is misconfigured, and decides to use 10.1.0.0/23 to summarize SiteA. From a purely subneting perspective, that should be perfectly acceptable, right? I mean, two /24's definitely add up to a single /23. However, because of how IPsec negotiates its tunnels, it will cause some issues. If SiteB initiates by proposing a , SiteA will reject the request, because SiteB is trying to create a tunnel for something that is "outside" what SiteA intended to protect (remember, SiteA is still using the four, individually listed out /24 pairs). If SiteA initiates by proposing a , SiteB will accept the request, because 10.1.0.0/24 is within what SiteB is configured to protect (10.1.0.0/23). (1) So initially, the first set of symptoms will look like the tunnels can only build in one direction (if SiteA initiates). Symptom #2 If SiteB is configured with the /23, and SiteA initiates... the tunnel will build. And when 10.1.0.0/24 and 10.2.2.0/24 try to communicate.... everything will work just fine. BUT, remember, SiteB isn't considering 10.1.0.0/24 as a /24, it considers it as a /23. So if at some point in the future, SiteB tries to send some traffic to 10.1.1.0/24, it will use the pre-existing SPI/tunnel. Which means SiteA will receive something from SiteB with a source of 10.2.2.0/24 (expected) and a destination of 10.1.1.0/24 (unexpected). Which in the Cisco world, will cause a syslog message like this to be generated: 

This is happening because this is how Traceroute works. It takes advantage of what a Router does when it decreases a TTL to 0. Rather than continue forwarding the packet, it sends back to the original client a "ICMP TTL Expired in Transit message" (see packet #24 in your capture). So as a client, when you send the first set of packets with a TTL of 1, the first router in the path responds with the TTL Expired message. You then measure how long it took to receive the TTL Expired message against when you sent the initial messages, and that gives you your first three values in the Traceroute output. Then you send another set of three packets with a TTL of 2. The first router in the path decrements this to 1, and then forwards it to the next router in the path. Upon reception, when that second router gets it, it decrements the TTL to 0, which prompts it to drop the packet and send you the TTL Expired in transit. The process continues until your client has received a (well, three) TTL Expired message from every router in transit between you and the final destination you are running your traceroute against. 

If this doesn't make sense, I suggest reading more about the OSI model, and how each layer has different responsibilities that all work together to accomplish moving a packet across the Internet. 

OSPF has an administrative distance of 110 EIGRP has an administrative distance of 90 RIP has an administrative distance of 120 But where did 110, 90, and 120 come from? 

In the illustration above, notice all three hosts initiate connections to a destination on the Internet. All three hosts (A, B, and C) select their own source ports randomly (2222, 3333, and 3333, respectively). When their packets traverse the translation device, the router selects new source ports (7777, 8888, 9999, respectively). This is crucial, because the re-writing of the source port is what allows the return traffic to be forwarded back to the correct initiating host: 

Yes and no. Yes in the sense that the effect of two ports in an isolated PVLAN or two ports in two different community PVLANs can not communicate, as if they were in two different actual VLANs (considered Primary VLANs when discussing PVLAN). No in the sense that with Private VLANs, all four of the hosts I mentioned previously are able to speak to the same port, configured as a Promiscuous port. With "regular" VLANs (Primary VLANs), they may all be able to speak out the same trunk port, but each of their traffic will still be isolated from the other due to the VLAN Tag. That is why if you had four traditional VLANs, you would typically have four different IP subnets and a router handling the Routing between the VLANs. With PVLANs, all four hosts could be able to speak out the exact same Promiscuous port, that could be facing a Router that does not have to maintain four different IP networks. A step further, all four hosts could also be using IP addresses from the same IP network. Note: There are different games you can play with VRFs and multi-context devices that allow four different VLANs to use the same IP Subnet, but given the nature of the question I believe those technologies are outside the scope of what the OP is asking about. 

A NAT (Network Address Translation) does not actually translate the port. You are most likely referring to a PAT (Port Address Translation). Even more specifically, you are likely referring to a Dynamic PAT -- which is a type of translation which allows any number of internal hosts to share one or more public IP addresses: 

The Switch will not store the same MAC address on multiple ports. It will simply update its MAC address table with the location of the most recent frame arriving with the duplicate MAC address. If both hosts are transmitting constantly, that will cause the MAC address entry to bounce between the two switch ports (known as MAC flapping). On the receiving side, the hosts will never get all the frames that are intended for them. Its like being in one conversation but only receiving every other word (and someone else receiving the remaining words). Duplicate MAC addresses on the same L2 network causes both hosts to have communication issues. However, duplicate MAC addresses on different L2 networks (aka, separated by a router) will work just fine. 

*(Provided that it as an IP address configured) A switch is tricky, because it comes down to how it is configured: 

To add a different perspective to the already provided answers. When an application wants to do transfers between clients on the same network without proxying through some sort of remote server, the application typically makes use of Broadcasts to allow the clients to "detect each other" on the same network. This is how Windows NFS works, in fact. Windows machines broadcast to each other over the local network to determine what other machines are on the workgroup, and or what resources are available for sharing. Dropbox does the same thing. If my phone and my laptop are connected to the same Dropbox account and connected to the same WiFi. What I share on my phone gets synced to my PC with a local LAN communication. (My phone will still upload to DropBox on the Internet, but it would spare my PC from having to download the new file from the Internet, since it is available at a higher speed locally) 

Really need more detail to answer definitively, but generally... For IPsec, you will need to forward ISAKMP (UDP/500) and NAT-T (UDP/4500). Potentially other ports if you've configured your VPN to tunnel on other, non-standard, ports than these two. Also worth pointing out, most IPsec implementations today use ESP (IP Protocol 50), which is able to pass through NAT. Unlike its counter-part AH (IP Protocol 51), which is entirely incompatible with any sort of NAT. For SSL/TLS, you will need to forward TCP/443 through your NAT device. Unless, again, your implementation is specifically listening on another port. All of the above is assuming your SSL Server/VPN Termination point is behind a PAT IP (many to one NAT). If, however, you are simply behind a PAT and making connections outbound to a static/public VPN/SSL IP, then you typically won't have to do anything special, unless your IT/Network administrators lock down your outbound traffic as well (which isn't terribly uncommon, but I wouldn't quite call it common).