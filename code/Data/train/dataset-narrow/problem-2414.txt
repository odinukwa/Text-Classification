I think my original question was perhaps a bit misguided and I will need to revise the scope of what I'm asking, but I will share what I have learned. First, Peter Shor's answer was able to guide me to some publications by Shannon which opened up a number of different papers to pursue. I wouldn't have found this information without his reply, so I am grateful for the response. From the sources that I found, there is never any hint of skepticism about classical computation. What does happen to be a concern, however, is the reliability of complex systems built from unreliable components. Knowing what I do now, I think the question closest to my original inquiry that I am able to answer is something like 

Interestingly, in the final pages of the report Carhart claims that military equipment is approaching a critical complexity limit in terms of reliability, at least for serial systems. This is the only instance I found of anyone claiming a limit to extant complexity, though I think this is a rather soft claim, as the author proposes redundancy and parallel solutions to increase reliability. I found a small number of other papers that casually make claims against complexity and then refute these arguments. For instance, Lipp in [14] says 

CoC is most likely the way to go. Just dive into Coq and work through a nice tutorial like Software Foundations (which Pierce of TaPL and ATTaPL is involved in). Once you get a feel for the practical aspects of the dependent typing, go back to the theoretical sources: they'll make a lot more sense then. Your list of features sounds basically correct, but seeing how they play out in practice is worth a thousand feature points. (Another, slightly more advanced tutorial is Adam Chlipala's Certified Programming with Dependent Types) 

This started as a comment under Andrej Bauer's answer, but it got too big. I think an obvious definition of ambiguity from a Finite Model Theory point of view would be: $ambiguous(\phi) \implies \exists M_1,M_2 | M_1 \vDash \phi \wedge M_2 \vDash \phi \wedge M_1 \vDash \psi \wedge M_2 \nvDash \psi$ In words, there exist distinct models of your grammar encoded as a formula $\phi$ that can be distinguished by some formula $\psi$, perhaps a sub-formula of $\phi$. You can connect this to Andrej's response about proofs through Descriptive Complexity. The combination of the existence of an encoding of a particular model plus its acceptance by an appropriate TM as a model of a given formula IS a proof that the axioms and inferences (and hence an equivalent grammar) encoded in that formula are consistent. To make this fully compatible with Andrej's answer, you would have to say that the model is "generated" by the formula acting as a filter on the space of all possible finite models (or something like that), with the encoding and action of filtering on the input model as the "proof". The distinct proofs then witness the ambiguity. This may not be a popular sentiment, but I tend to think of finite model theory and proof theory as the same thing seen from different angles. ;-) 

I think this is a rather intuitive claim, that a complicated system made of unreliable components seems like it would be in a faulty state more often than a simple system, and as the system becomes more complicated, it should become less reliable (and I think this is what Scott Aaronson was getting at). Some literature of the time making this claim, Smith in [13] says 

The lecture series from von Neumann [6] is some of the earliest literature addressing how to make a reliable system from unreliable components, though Mullin [11] says the paper is an extension of earlier work by McCulloch and Pitts [1]. In section 10 of the paper, von Neumann says 

source (And here is a related question about where that paper first appeared). My request is for published research article (references) that are skeptical classical fault tolerant computing is possible, or names of individuals advocating for skepticism at the time. 

Early classical computing had skeptics, or at least cautious researchers, that were skeptical reliable computing results were possible. Scott Aaronson references this in a page on his site: 

I would recommend investigating the field of Finite Model Theory and more particularly its sub-field Descriptive Complexity. It can be used to model such sorts of problems. 

I'm wondering if anyone knows of a formalization (even limited) of any part of finite model theory in any of the major proof assistants. (I'm most familiar with Coq, but Isabelle, Agda, etc. would acceptable.) Especially of interest would be any of the results in descriptive complexity. 

I find that the most "natural" way to get an intuition of complexity classes is to revert to Turing's starting point and try to solve the problem "manually". Start with a sorting task. From a jumble of, say, five words have the class order them alphabetically. This should be easy. Then double the number of words, and repeat the exercise. It will be obvious that, though the second problem is harder, it isn't that much harder. Next try a traveling salesman task. Start with a grid of say three cities with distances between them. The class will probably be able to solve this in short order. Now double the number of cities to six, and continue with the exercise until everyone's head is spinning. An experience like this is very likely to leave a lasting visceral impression that a purely technical introduction may not. 

I haven't found any evidence of skepticism about classical computing. Instead, I did find a number of papers addressing concerns about system reliability, stemming from the original research done by von Neumann. The report by Carhart was the only instance of a claimed limitation on system reliability, but the author proposes solutions to address the problem. 

[1] W. S. McCulloch and W. Pitts, "A logical calculus of the ideas immanent in nervous activity," The Bulletin of Mathematical Biophysics, vol. 5, no. 4, pp. 115–133, Dec. 1943. $URL$ [2] A. C. Block, "A Redundancy Analog," IRE Transactions on Reliability and Quality Control, vol. PGRQC-12, pp. 1–7, Nov. 1957. $URL$ [3] R. R. Carhart, "A Survey of the Current Status of the Electronic Reliability Problem", white paper from RAND Corporation, 1953. $URL$ [4] Z. W. Birnbaum, J. D. Esary, and S. C. Saunders, "Multi-Component Systems and Structures and Their Reliability," Technometrics, vol. 3, no. 1, pp. 55–77, Feb. 1961. $URL$ [5] R. Gordon, "Optimum Component Redundancy for Maximum System Reliability." Operations Research, vol. 5, no. 2, pp. 229–243, 1957. $URL$ [6] J. von Neumann, "Lectures on Probabilistic Logics and the Synthesis of Reliable Organisms from Unreliable Components," Jan 1952. $URL$ [7] H. Mine, "Reliability of a Physical System," IRE Transactions on Circuit Theory, vol. 6, no. 5, pp. 138–151, 1959. $URL$ [8] L. Hellerman and M. P. Racite, "Reliabllity Techniques for Electronic Circuit Design," IRE Transactions on Reliability and Quality Control, vol. PGRQC-14, no. 0, pp. 9–16, Sep. 1958. $URL$ [9] J. C. Hudson and K. C. Kapur, "Reliability theory for multistate systems with multistate components," Microelectronics Reliability, vol. 22, no. 1, pp. 1–7, Jan. 1982. $URL$ [10] E. F. Moore and C. E. Shannon, "Reliable circuits using less reliable relays," Journal of the Franklin Institute, vol. 262, no. 3, pp. 191–208, Sep. 1956. $URL$ [11] A. A. Mullin, "Reliable stochastic sequential switching circuits," Transactions of the American Institute of Electrical Engineers, Part I: Communication and Electronics, vol. 77, no. 5, pp. 606–611, 1958. $URL$ [12] F. Moskowitz and J. B. McLean, "Some reliability aspects of systems design," IRE Transactions on Reliability and Quality Control, vol. PGRQC-8, pp. 7–35, Sep. 1956. $URL$ [13] T. A. Smith, "The background of reliability," IRE Transactions on Reliability and Quality Control, vol. PGRQC-8, pp. 55–58, Sep. 1956. $URL$ [14] J. P. Lipp, "Topology of Switching Elements vs. Reliability," IRE Transactions on Reliability and Quality Control, vol. PGRQC-10, no. 0, pp. 21–33, Jun. 1957. $URL$