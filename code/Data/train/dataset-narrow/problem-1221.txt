Yes-ish. The main loop takes into account collinear points: it wouldn't be too hard to do so here as well. 

I assume that you're using C# with .Net, whether .Net Standard or .Net Framework. They both have high-level data structures which can make code easier to read and, in many cases, faster. If you flip this round as then the bulk of can be rewritten as 

Um. If the method is called , I expect it to do output. Why is it throwing an input-related exception? 

If you want to improve the asymptotic performance, this is the problem. You need to apply combinatorics, and then you should be able to make the performance almost independent of . 

I could be missing something, but I don't see a need for this. If you're only using the minimum and maximum then you can find them in linear time rather than the quasilinear time which a sort requires. Although given your observations in your own answer about reusing values between loop iterations perhaps the optimal approach would be a binary heap to track the maximum and a separate variable to track the minimum. As far as C# style, the variable names should use camel case rather than underscores. And possibly I would use some Linq instead of some of those loops, but unless you're coming from a functional background that doesn't need to be your first priority. 

No, I'm afraid I don't get the point. Is the phone's version? If so, am I supposed to be able to guess that from the name? And how could the phone have version 1 if the earliest existing version is 2? 

If we consider the last one, because I think it will require the least adaptation: what symmetries can a solution have? The square has eight symmetries: 

So is the key? Given that the description of the program said that it was for storing passwords, that was not at all obvious to me. After reading just the encryption method I wondered how you could get the password out again. 

(I'm not up to date on streams: there may be more idiomatic ways to do this in Java 8). Note that this relies on a method . Your code effectively implements this as 

Document it clearly, especially before asking other people to review the code! Having computed , start at to avoid repeating all of the calculation you've done to generate 

Only 90? I'd expect worse! is really quite slow. In the worst case that's going to copy about as many elements are there are in the original array, which means that you've lost the benefit of using a binary search instead of a linear one. If you want to use this conceptually simple approach to binary search then you will get much better performance from . However, the standard approach to binary search doesn't bother with wrapping anything round the array. Instead it keeps two variables to represent the subarray and moves them towards each other until the value is found or the range is empty. (Incidentally that case seems to be missing: does your code have a bug when the value isn't in the array?) 

And then with respect to performance, SQL Server has pretty good profiling tools, but the obvious bottleneck is the matching: neither table has any useful index. I'm surprised that isn't a unique key, but since it isn't the obvious way to speed things up would be to add an index to the temporary table, either on or on . 

I concur with most of what the existing two answers say, but there are some other important issues which I think they missed. Learn to use layout managers Manual layout with is acceptable for an application which you are going to use once and then throw away, but it's hard work to lay things out correctly and it's extremely brittle. When you want to change a text, you have to recalculate everything. If you want to support localisation, you're really stuck. AWT has various layout managers which will do a lot of that hard work automatically. I personally prefer GridBagLayout for most purposes, but it's worth spending time to get to know the options. Don't let the user give you invalid input When I see 

I'm sure can be simplified further by someone who knows the Haskell standard library better than me. 

It seems that each derived hash is stored in a non-overlapping bucket. By my understanding of Bloom filters, what you have here isn't a Bloom filter. Finally, I suggest for your consideration unrolling the multiplications: 

Good comments make code more maintainable. I had to reverse engineer what this code was doing, when a few comments could have made it clear. 

Why loop down? If you loop up then you get the platform-independence for free, and also you loop fewer times when is small. Obviously the loop invariant would change, but it would be closer to school long multiplication and so might also be more maintainable. 

This is a class from my personal code library, and from a package which deals with integer sequences. It implements an interface 

was initialised as . C uses 0-indexing. So that condition should be , not : as it stands, it can access memory beyond the end of the array. In this particular case you probably get away with it, because the following chunk of memory probably belongs to , but that's not something it's wise to rely on. There is a similar bug in . Use descriptive names The name tells me nothing that I wouldn't already know from the type (i.e. that it's an array). What do the elements of the array mean? In this case it seems to be (or if you want to be pedantic). isn't as bad, but is still fairly undescriptive. would be an improvement; would be better still. , on the other hand, goes too far. There's nothing in the implementation which limits it to printing primes. It's really . Do you need to statically allocate so much memory? The number of primes will indeed never exceed , but you could go further and observe that they will never exceed (by considerations of values modulo 6), etc. However, the sieve tells you how many primes there are before you try to extract them. Consider this simple modification: 

Now, the key condition encapsulated by is that neither range is completely greater than the other. A direct refactor of the way you've expressed this is 

KISS My first thought when I started looking at the code was that the first few lines seemed unnecessary: 

The first of these names makes sense in the right context, but when you're reading the code you see it in the context of . How about ? The second makes sense only in the middle of a call to . I think it should be or something similar. Separation of responsibilities If the trie is intended for general use, I think that the way finding the prefix is integrated into it violates the principle of separation of responsibilities. If it's intended to be single-purpose and separation of responsibilities is intentionally sacrificed for better performance, it doesn't go far enough: the benefit calculation could be rolled into the constructor to avoid recomputing it for each common prefix. I think that you should refactor to separate trie building from prefix graph building for one simple reason: the documentation states that the complexity is O(N*max_length_of_string), but that's not true because the merging of responsibilities in trie building means that the strings have to be sorted before insertion, giving Theta(N lg N). KISS 

In my opinion it shouldn't be a list at all, but an from which the main loop removes used points. In the worst case that would be a significant performance improvement over the first . A small subtlety would be in the sign test, which would then have to use instead of . 

The second is to do the remote hashing remotely. Rather than fetch 500 files (of unknown size) across the network in order to calculate their MD5 sums, use remote PowerShell to calculate their MD5 sums and just return the filenames and the hashes. You might even be able to manage to get the two computers to calculate the hashes in parallel, giving a two-fold speedup. 

is just plain wrong. It turns a linear operation into a quadratic one through looped copying. The fast approach here, using Gray codes, would look something like: 

The obvious place to look for the performance issue is . The only operations you perform on are to add values and to test whether it contains values, but List is the worst* data structure available for testing whether it contains a given value. The minimal change to fix this problem would be to instead use a HashSet. However, HashMaps and HashSets are fairly general data structures, and not all of your code assumes that level of generality. In particular: 

That should strike terror into the heart of anyone who wants their program to terminate in a reasonable time. There are three possible cases: (a) could perfectly well be an ; (b) gets incremented by more than elsewhere; (c) this loop will execute more than \$2^{31}\$ times. Here it's not case (b), so which of the other two is it? (Aside: the rewrites correctly observe that you only need to go up to , but if is a long that could still be about \$2^{31.5}\$. It might be worth looking at faster factorisation methods, starting with Pollard's rho). 

But frankly the bit-bashing seems overcomplicated. Unless I'm missing something, you could simplify to 

This is buggy. Add a unit test which inserts more than 100 elements into a heap, watch it turn red, and then fix it. 

One thing which puzzles me about that regex is the : I'm sure there's a reason for wanting not to capture the keyword, but it's odd. However, looking at one of the examples you list (specifically ) I note that they're using lookaround for the whole keyword. In the example I picked above (more or less at random), the is outside the lookaround. I find that suspicious, and I suggest that you double-check the lookarounds. Oops: misread non-matching group as lookaround. 

I'm also not keen on exposing the class directly, although I'm not sure what API the enclosing class would have with respect to the links. 

and eliminating reduced the time from about 9.7 secs to 7.9 secs. Replacing with a simple array and with reduced it further to 5.3 secs. And that doesn't yet address the biggest obvious problem: 

If this is for a throwaway project, hard-coding the connection string like that is acceptable. If it's for a "serious" project then you should really get the connection string from with . That has the benefit of allowing you to have dev and prod configurations, as well as to handle server migrations, password cycling, etc. without recompiling. 

Overall looks pretty good. I can see you've put effort into documentation and it's good to see used to test Booleans. 

Some nice syntactic tricks in there which I didn't know about, so firstly thanks for that. Aside from that I don't have much to say about the code, but there are a few things about the design which don't convince me. Why one class without type parameters? This has two aspects. Firstly, I would prefer to use one instance per logical cache and eliminate the cast (which can quite easily fail if I don't enforce consistency between every call to ). Having multiple caches seems like a small cost compared to the gain which is compile-time type checking. If this class is only really intended for use cases where each value has a different type, that should be clearly communicated in the docs. Secondly, I agree that it's not very useful without the extensions, and I think that's because the extension method is more fundamental than the class method . Putting those together, I think it would make more sense to have and add extension methods along the lines of to box/unbox tuples. 

opens an output stream, but doesn't seem to close it. The "best practices" way of doing this nowadays would be a try-with-resources statement. I haven't used Java 8, so I can't do better than to point you at the docs. 

On the basis of coding to the interface rather than the implementation, the type should be . I personally would also prefer to hide the field and take the substitutions as arguments to the constructor rather than by modifying a public field after construction, but that's a subjective issue of style. If making that change, the type can become instead. 

is better still, because you can use it to find power sets of any set. 3. Generics remove the necessity to do most casts 

The best implementation I've thought of so far for the datastructure of unassigned indexes combines a linked list for fast implementation of with an array for fast implementation of . I'm not familiar with Python's OO syntax, so this is again pseudocode: 

I would find a comment explaining more useful than a comment explaining why you made a function, because everyone ends up writing a function which behaves sensibly. I don't know much about elliptic curves, but I have worked with finite fields. Are you sure it makes sense to take as though they were integers? The only makes sense to me if is also the characteristic (i.e. if it's a field of prime order). 

SVG paths have relative and absolute versions of the movement instructions. If you were to use the relative instead of the absolute you could eliminate the offsets, simplifying the code. Edit: to justify my claim that using relative movement rather than absolute simplifies the code, here's the full program using relative movement, minus the header comment: 

is used once, so I personally would inline it. However, this is a matter of taste, and I wouldn't be surprised if someone else has previously given you the opposite feedback. What I can say is that the code is consistent about always pulling out these intermediate values, and consistency is good, so well done for that. 

and the following s in the same style are very weird style. They make me suspect that you've come from JavaScript. A simple refactor gives a normal method: 

I'm not really a Python programmer so I'm not sure how Pythonic it is, but to me this overloading is a code smell. I would prefer to split out one function which takes just the line and another which does the real work. Also, what is ? I managed to figure it out by reverse engineering, but a short comment would have helped a lot. 

tells me that s will be accessed in LIFO order, but doesn't tell me what each means. Is it a count? An encoded permutation? 

There's no need to pattern-match a structure if you're not using the structure. This could be simplified to 

Looks like a mixture of tabs and spaces. It's better to be consistent and stick to one or the other, because otherwise changing tabstop (StackExchange automatically turns tabs into spaces with a tabstop of 4) makes the code hard to read. 

occurs twice, and by pulling it out to a separate method you would both ensure consistency and reduce the noise which makes it harder to see the core of the insertion. (Also, the error message doesn't make sense to me: the SQL checks that the table exists, so why do you think that an exception would be caused by the table not existing?) The SQL lines are rather long. I would try using to split them over multiple lines with indentation, because I think that would make them more readable. They would probably also be better pulled out of the method as fields or s. 

How long does each of those checks take? If the list contains strings, a check has to do up to string comparisons. is the wrong data structure to keep a collection of non-duplicate values: that is a . 

I'm afraid that you are very wrong. The code is performing \$O(n)\$ arithmetical operations on s, but an arithmetical operation on a is not \$O(1)\$. The fundamental problem is this: 

Why does this implement ? I can't see an abstract reason why this should be necessary, and if I comment out and the methods and the code still compiles, including the sample use cases. 

If you wanted to do it properly then you could extend the number theory research and learn about Euler's totient function. 

would be more Pythonic as . Spot the symmetry with the second line. The reuse of names is not particularly helpful, especially given that is a bad name. How about this? 

Therefore we can build a very short list of candidates by enumerating , skipping the terms divisible by , performing the extended Euclidean algorithm for the rest, and testing every pair for which we get .