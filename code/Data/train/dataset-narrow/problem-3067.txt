I understand precision at k and recall at k. It is a more useful metric for evaluating the success of a binary classifier when the positive class is overwhelmingly out-weighed by the negative class. I'm wondering how to choose an appropriate "k" value. According to resources like this the recall at "k" is bounded by the number of positive examples, so it is not a useful metric to use when evaluating the success of severely imbalanced classes. It also seem to me like this: Precision at K is also limited by the number of positive examples at K. Saw we have 100 examples total, and only 3 are positive examples. Say we rank these Scenario 1: we choose k=10. Then, the precision at K can at most be 3/10 = 0.3. And, the recall at k will be 0.03 because there are 3 in the entire dataset of 100. Scenario 2: we choose k=3. Then, the precision at K would be 3/3 = 1.0 !!!And, the recall at k will STILL be 3/100 = 0.03. Even though our binary classifier is performing perfectly, it's perfect performance only is reflected when we choose k=3? So, my question how do I choose K correctly? 

I know that a decision tree recursively splits along each attribute, greedily minimizing the wrong classifications/deviance at each split. But, what is the order in which the attributes are split? In other words, for a regression tree in N dimensions, what determines which attribute gets split first? 

I'm trying to predict additional recipients of a message given the content of the message (like subject and body) and the current recipients of the message. for ex: I have 4 users in the system U1, U2, U3 and U4 I have the following messages between them 

As you can see U1 only communicates (Send/Receive) with U2 and U3. Similarly, U2 communicates with U1, U3 and U4 while U3 communicates with U1, U2 and U4. Lastly U4 communicates with U2 and U3. My goal is when a user is composing a message and already entered some content and recipients on the To line, I want to suggest other recipients the user should include in the To line. The suggestion should be relevant to the message's content and also only contain users with whom the user has communicated with previously. So for U1 we should never recommend U4 as there is no communication between them before. Similarly, for U4 we would never suggest U1. I'm currently thinking of solving this as a multi-label classification problem where I generate a personalized model per user using Binary Relevance method. For U1, the data looks as follows 

Now, I can train a OneVsRest classifier (from scikit-learn) on this data using svm.LinearSVC (or some other classifier) to predict multi-recipients given a message. I'll use content and recipients of the message as features. This works. The problem is this needs a personalized model per user. Given I have 10's of millions of users and each user sends/receives 1000's of messages per month and communicates with 1000's of other users overall, how can I create a single global model with personalized features for prediction? I want to avoid creating millions of personal model per user if possible and want to train a single global model using data for all users and then do personalized predictions. Is multi-label classification not suitable for learning a global model? Should I instead use a ranking model approach? Please suggest how can I do this? 

Is it necessary to standardize your data before cluster? In the example from about DBSCAN, here they do this in the line: 

The function above is copied almost verbatim from the scikit-learn demo here. Yet, when I try it on the following: 

But I do not understand why it is necessary. After all, clustering does not assume any particular distribution of data - it is an unsupervised learning method so its objective is to explore the data. Why would it be necessary to transform the data? 

I have done some clustering and I would like to visualize the results. Here is the function I have written to plot my clusters: 

Sklearn DOES have a forward selection algorithm, although it isn't called that in scikit-learn. The feature selection method called F_regression in scikit-learn will sequentially include features that improve the model the most, until there are features in the model (K is an input). It starts by regression the labels on each feature individually, and then observing which feature improved the model the most using the F-statistic. Then it incorporates the winning feature into the model. Then it iterates through the remaining features to find the next feature which improves the model the most, again using the F-statistic or F test. It does this until there are K features in the model. Notice that the remaining features that are correlated to features incorporated into the model will probably not be selected, since they do not correlate with the residuals (although they might correlate well with the labels). This helps guard against multi-collinearity. 

I'm investigating various NLP algorithms and tools to solve the following problem; NLP newbie here, so pardon my question if it's too basic. Let's say, I have a messaging app where users can send text messages to one or more people. When the user types a message, I want the app to suggest to the user who the potential recipients of the message are? If user "A" sends a lot of text messages regarding "cats" to user "B" and some messages to user "C" and sends a lot of messages regarding "politics" to user "D", then next time user types the message about "cats" then the app should suggest "B" and "C" instead of "D". So I'm doing some research on topic modeling and word embeddings and see that LDA and Word2Vec are the 2 probable algorithms I can use. Wanted to pick your brain on which one you think is more suitable for this scenario. One idea I have is, extract topics using LDA from the previous messages and rank the recipients of the messages based on the # of times a topic has been discussed (ie, the message sent) in the past. If I have this mapping of the topic and a sorted list of users who you talk about it (ranked based on frequency), then when the user types a message, I can again run topic extraction on the message, predict what the message is about and then lookup the mapping to see who can be the possible recipients and show to user. Is this a good approach? Or else, Word2Vec (or doc2vec or lda2vec) is better suited for this problem where we can predict similar messages using vector representation of words aka word embeddings? Do we really need to extract topics from the messages to predict the recipients or is that not necessary here? Any other algorithms or techniques you think will work the best? Should I just use supervised learning instead? What are your thoughts and suggestions? Thanks for the help.