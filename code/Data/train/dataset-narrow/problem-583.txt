Index rebuild will update statistics of column with a equivalent of full scan. Reorganizing index will not update statistics at all. For more detailed explanation Ben Nevarez has written more in his blog 1) By default, the UPDATE STATISTICS statement uses only a sample of records of the table. Using UPDATE STATISTICS WITH FULLSCAN will scan the entire table. 2) By default, the UPDATE STATISTICS statement updates both index and column statistics. Using the COLUMNS option will update column statistics only. Using the INDEX option will update index statistics only. 3) Rebuilding an index, for example by using ALTER INDEX … REBUILD, will also update index statistics with the equivalent of using WITH FULLSCAN. Rebuilding indexes does not update column statistics. 4) Reorganizing an index, for example using ALTER INDEX … REORGANIZE, does not update any statistics. The same can be verified from Paul Randal Post 

Begin transaction--Transaction starts here Fetch Page--Page is fetched from Disk to memory Acquire Lock Acquire Latch Generate log record--Change to the page generates Log records Update page LSN to match that of the log record--When change to a page generates Log records They have LSN numbers identifying them and the same LSN number is stamped on header of the page change to which generated these log records. Change Data (dirty the page)--Since page changes as it was on disk. It is now dirty Release Latch Commit Transaction Starting--Commit issued for transaction FlushToLSN of Commit--LSN corresponding to commit is flushed to log disk and recorded. This is done before dirty data page is flushed to disk Release locks Commit Transaction Complete 

For above queries see it is all in GB. The first 3 queries running used approx 15 G of memory which almost used 50 % of memory. In SQL Server millions of process run which require memory in some way so you can see if 3 queries are using 50% of available memory OOM issue is bound to occur. Solution You should seriously consider tuning the first 4 queries in above screenshot Make sure you run index rebuild and stats update at least weekly so that skewed stats does not force optimizer to produce bad plan. Use resource governor and create a resource pool and workload group and run queries which are requesting large memory grant in this pool. You can limit the memory request with parameter . An example is shown in this Blog. This is just alternate method till you tune all your queries. 

So if there is any such constraint you might as well consider idea of restoring from valid backup. Before that you must run restore verifyonly for backup you are trying to restore to check whether backup is consistent. You must also note that only a successful restore can guarantee backup is consistent in ALL formats Lastly you must check SQL Server errorlogs and windows eventviewer as to find out reason why inconsistency came in at first place. A lot of time bad hardware is the cause. 

This makes me think that the package is nt complete and while you were converting ISO file to executable file all files related to installation were not extracted. You are trying to install SQL Server 2012 enterprise and Windows 8 machine not windows server. Its not supported on windows 8 please see hardware and software requirements but it wont stop you from installation. If you are installing SQL Server 2012 on windows 8 you MUST read this support article before proceeding 

Disable Windows security/windows defender on Windows 10 machine. The windows security is most likely causing this issue. Note that your installation waits on getting access to file where it can write something. The windows security is stopping the installation from getting the access Please also disable Antivirus for time being when you are installing the SQL Server software. After installation finishes you can again enable it. 

You need to use all above methods speacially one suggested by Remus to see and get idea when was it last accessed. Suppose in a big firm you want to figure out that database A is being used or not and who is using it. First shoot a mail to all required stakeholders, managers, and application owners that you are going to make Database A offline as you feel this is not used anymore. Make sure you include everybody and then wait for a day so that people would revert to your mail. If nobody reverts and make database offline(dont drop it). Wait for another week or a month. You can do that as you already have made DB offline and it is not causing any load on server. Yes there might be monthly jobs running which needs that database once so I added to wait for a month. Even after a month if nobody reverts go ahead and do whatever you want to do with it. 

Your code requires little tweaking. Where you are doing you just need to do . The changed code is below. Please note that ring buffer capacity is limited so it would not store information for complete day it would have information about specific time. 

I would like to post this as answer what is point in upgrading to SQL server 2000 which is outdated completely without any support. Even it is not good for testing purpose. Its like using typewriter in era or super computers. Dont uninstall personal edition first. Install enterprise move databses by backup restore method. If you restore master msdb databases you would not need to move logins and jobs. Please refer to below link $URL$ 

Please run below command in your SQL server database to check the level of corruption.If database is showing suspect it wont allow you to run this command 

After this you can have look into database how much data checkdb has deleted to recover database. Please note checkdb also removes constraints so I would not ask you to run it. Please read Books Online Document before proceeding At last please see SQL Server errorlog and event viewer to see why database got corrupted 

So Heap table is created with 50 records in it. Below is what fragmentation looks like after query DMV sys.dm_db_index_physical stats 

Restoring involves bringing data pages into memory so yes memory can be a factor but cannot be a show stopper. Things which really can affect backup performance are the drives on which data file and backup resides and the network connectivity. Ofcourse you will see faster restore speed on SSD's as compared to SATA disks. Read How SQL Server backup and restore operation works. This will let you know how memory is internally used while backup and restore operation If you read this BOL document it shows how you can improve performance of SQL Server restore process 

You can read about uninstall parameters from Books Online. You can also have a look at how to uninstall existing instance of SQL Server If you want to remove SQL Server 2005 This support article is very well written 

That is not exactly the place from where you can uninstall SP, you have to go to add remove programs and then on top left you would see 

I can only say please leave it to default, I am not sure how recovery time has anything to do with log file and its configuration Regarding Tempdb make sure you have Data files equal to number of physical cores. Paul has more to say about how many files you can have as per cores IMHO you can start with 4 tempdb files but keep monitoring for contention. Make sure that all tempdb data files have SAME INITIAL SIZE and SAME AUTOGROWTH setting. You can also enable TF 1118 to avoid contention To check contention you can run below query 

You are correct, I also believe that in most cases the should be set to true we should allow SQL Server to decide when to update stats and believe me it does good job. When this is set to true it make sure stats are updated about distribution of data in the field which would eventually help optimizer to prepare better plan. The important thing to note here is Auto update stats fire when 20% of data changes in table. So you should not feel that on a table with 100K rows if 10 rows are updated then status update will fire. A more deeper analysis is done by Paul Randal in the blog Understanding When Statistics Will Automatically Update. I have not seen any drawback if this option is set to true. Yes you can see some I/O activity when this option is set to true. Important conclusion which one can draw from the blog is 

No you cannot do this without breaking Logshipping. You cannot convert recovering database to read only without bringing it online and moment you bring it online Logshipping breaks. Instead configure logshipping with secondary in standby mode. Note that when you check the box disconnect user when restoring database while configuring Logshipping it would disconnect all users running query on secondary DB for restore. This is one of the drawback. 

No, reducing max server memory would be of help here. I would suggest you to look at query and the ' optimizer is looking when it is preparing the query plan'. You have enough amount of RAM. Sometimes when you run a query with outdated stats it requests large amount of memory and ofcourse SQL Server is not going to grant all of it. It would provide minimum amount so that query at least starts running. When SQL server creates a compiled plan, it calculates two memory grant parameters called "required memory" and "additional memory". The required memory is minimum memory SQL Server can give for sorting and hash operation and additional is what can be required by query to store temporary data which comes with . If Query start with minimum memory and requests more but SQL Server is not able to provide it all in on go query waits with wait type 'resource semaphore'. This does not means memory is less it means the statistics was outdated which forced SQL Server to create bad plan thus requesting more memory. I suggest you read Understanding Query Memory Grants 

I am looking for ideas on how to move two node cluster installed on to other location which is far away from current location. The two locations are of course connected. The source and destination would be exactly same in all terms. I am aware that the old and good approach would be to create exact same cluster on the destination and then move database by backup restore and then either change SQL server virtual name to old one or make changes in DNS or application to point to new cluster. But we cannot follow this approach because 

I have a hunch that you changed system date to workaround with evaluation period expired message and then you forgot to change it back. After this you did edition upgardea and this some how changed registries to incorrect value. As per logs the system has been upgraded with but problem lies with SSMS. SQl Server support team has written article to overcome this issue please read the article. I am posting a snippet which would help you, but before proceeding please read complete support article 

You can take differential backup also perhaps this would be very helpful if you have big database. anything that links LSN chains would do.See below link it has good information about switching between recovery models $URL$ 

This is not possible. In SQL Server 2012 if you are not using third party linked servers providers or if any DLL which is not Microsoft provided is not loaded in SQL Server address space there is less chance that SQL Server can consume memory outside max server memory setting. But the fact is you cannot control SQL Server not to utilize memory outside buffer pool. That is how it is designed. 

I am not saying with surety that you might be hitting the bug mentioned as it requires more thorough analysis. 

If you believe this is the case and you want SQL Server not be be victim of such issues you must make sure SQl Server service account has Locked Pages in Memory Privielge (LPIM). This will not let OS to force SQL Server page out its memory. If account running SQL Service is local system by default SQL Server will have this privilege in SQL Server 2012. Note: 

You did blunder by restarting SQL Server. You should have not done that.Unless SQL server will recover the database fully and comes to state where database finds itself in same consistent state as it was before the force shutdown it will show in recovery state. Your best bet is to wait and watch you cannot run any transaction on recovering database. Also since you manually killed SQL server process while it was rolling back a query its even more worse. Now when SQL server database will come online the whole rollback process will start from beginning not from point where you killed SQL server process/query. So it might take time and unless it fully rolls back the previous killed query it won't come online neither you can force it to. One advantage you can have is if you have Enterprise edition SQL Server will come online after redo phase of recovery. So that might be little relief to you. PS: Seriously avoid any such random suggesstion given on web. You should take this as a lesson to never kill SQL server process or restart SQL Server if certain query is taking time. You should wait and chec rollback status of query using below script