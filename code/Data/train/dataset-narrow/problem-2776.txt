You can model a Canvas interface to encapsulate a pixel buffer in RAM or a DirectDraw Surface. Here an idea: 

To create and present surfaces using old DirectDraw API: $URL$ Note: old DirectDraw code tend to fail in modern platforms due to headers change. Don't panic, just search each error and you will probably find a solution, usually involving changing an #include or add a define in your project compiler parameters. Alternatively, on modern Windows OSes, you can use Direct2D: $URL$ To draw a bitmap in memory using old OpenGL fixed pipeline (everything else, like drawing lines, you will do by software using your Canvas interface): $URL$ 2D Sprites with OpenGL, better than previous approach, hardware accelerated: $URL$ To create a drawable area in a window using GDI and draw a bitmap into it: $URL$ Line drawing algorithm: $URL$ Blit/Draw algorithm: just copy the pixels to the correct place, doing format conversion if needed. Tip: avoid format conversion by converting your assets to your current screen pixel format when loading them, this is specially needed if you develop a software renderer to improve performance of the game. Blit/Draw algorithm with scaling: if using OpenGL or Direct3D this is very easy to do. Take as an example the link on 2D Sprites with OpenGL. You will have the GPU doing everything for you. If done by software, it will be probably very slow, offer "nearest-neighbor" as an option to allow the game to run in slower hardware. 

If you decided to do as I say and create a class to represent the tile map then you can add some kind of get(x, y) method, a set one may be needed too if you plan to change the tiles values based on some game events (boss killed, a door opens). If you use a crude array for the map and have the logic somewhere else then simply do as with any multidimensional array to access individual elements. ([x, y], [x][y]). 

I don't see protection again spiral of death in your code. You understood the concept very well. You even decoupled the render cycles from the logic/simulation update cycles. I would suggest to try this, rename maxFrameTime to desiredTimeStep or timeStep. And change this: 

As storage format JPEG is probably the best choice for some textures like grass or walls, where the loss of information is probably undetectable. Followed by PNG when you need transparency or when you cannot pay with loss of information, for example sprites in a 2D game (the player, enemies, a treasury chest), you probably want to use PNG for that images. When talking about memory cost, the format used to store game graphics in the file system is not relevant at all. Either if you store pixel buffers in VRAM, or RAM (software renderer), you probably have them stored uncompressed, because games favor fast read of pixels vs memory used by each pixel buffer. Have compressed data stored in memory have no sense except you maintain some kind of cache to save disk reads, but you probably have to read from that cache to an uncompressed state for the images in use at a given time in your game. Compressed image data have a bit more sense if fast hardware decoding were possible. For normal mapping at least, I remember this $URL$ With that you can save some VRAM. I'm not aware of other examples of hardware decoding yet. In resume: whatever the formats used for your game to store graphics in persistent storage, you will have to decode that and maintain an uncompressed version in dynamic memory, video memory, or both, to be able to fast render them when needed. Finally: I'm a desktop guy. When I say "memory" I always referring to dynamic memory. When I say "disk", "file system" or "persistent storage" I always referring to whatever your device use as persistent storage, usually I think in hard disks. When you said "memory-efficiency" I took it for "dynamic memory" not "persistent storage". Lately, I see a lot of people using the word "memory" to refer to "persistent storage" (maybe that the terminology of mobile devices?). 

Now, we choose the lesser of them to displace the sprite back. If you want to understand why the lesser, do the opposite, run your program and have some fun watching the result. And we need a direction too, we know that we are always axis aligned but we still have 2 choices, left or right, up or down. 

Also I could not guess how to convert renderers to systems. My game separates logic updates from screen updates, my main class have a tick() method and a render() method that may not be called the same times. In my first attempt renderers were systems but they was saved in a separated manager, updated only in render() and not in tick() like all other systems. I realized that was silly and simply created a SceneRenderer interface and give up about converting them to systems, but that may be for another question. Then... something does not feel right, isn't it? If I understood correctly a system should not depend on another or even count with another system exposing an specific interface. Each system should care only about its entities, or nodes (as optimization, so they have direct references to relevant components without having to constantly call the component() or getComponent() method of the entity). Edit (answer chosen): I've chosen the suggestion to the IsVisible component. But I added the following optimization: First I created a IsVisibleOptimized class that descend from the original IsVisible. The IsVisibleOptimized instances share a list where they push all the entities that are visibles and remove the ones that are not. Most systems are already designed to use the IsVisible component, they not need to change, because the IsVisibleOptimized component registers with both names and can be casted to a IsVisible. But the RenderSystem that is a critical system of the game and need to work as fast as possible, it calls the static function IsVisibleOptimized::getAllVisibles() rather than iterate through all the entities in game to see which are visible. The CullingSystem uses the QuadTree that the SceneManagementSystem maintains updated each frame. First a call to the getAllVisibles() function and then to the quad tree selectRect(). If there are new entities they are set as visibles (causing them being added to the list too) and the ones that are not visible any more are set as not visible (this removes them from the list too). No more SceneManager with cull() function that had no sense. The reason to have both versions of the IsVisible component is that the optimized version may not suit all type of games. If I replace the IsVisibleOptimized for a simple IsVisible at entity build, the game still works (maybe not as efficient) and only the RenderSystem and the CullingSystem need to be replaced for implementations that don't use getAllVisibles(). IsVisibleOptimized makes sense in a game that have big maps with more hidden entities than visible ones and where the screen rect represents a small part of the game map. I happy with this solution. 

Task is a class, that have a run virtual method. Then during main loop you iterate through the task list and call it run method. You enqueue tasks following the same logic that sounds, I mean that you can do it everywhere in you code. Something like this: 

I don't think the collision should be handled by the entities at all, or by a component per entity, that need to be called by each entity. If you only have two generic type of objects, for example actors and walls. Each time you collision detection loop runs, it will check the type of each object (a component provides this information?), for actor-wall one logic is executed, for actor-actor, another logic is executed. Lets assume walls cannot move without being promoted to actors (by changing the value of the relevant component), to maintain the system as simple as possible. No message is sent, anything happens inside the collision detection loop. For actor-actor, for example, each involved actor moves back half the length of the penetration vector. For actor-wall, the actor moves back full the length of the penetration vector, the wall does not move. That is only an example. Having only two types of objects may not adapt to your game. And having the logic as part of the collision detection loop may not be suitable if you need many types of objects, or if all the types of objects are not known at design time (new types may be provided by loading a library later). In resume: When two moving objects collide, which one sends the message, and which one receives it? Answer: Do not use a message system at all. A message system is not suitable for this. The logic that handles the collision for a pair of entities must not by in the entity (or per entity component) and must run only once per pair, not two. 

ScenarioLoaderTask is a class derived from Task that implements run. Despite its name, tasks are not mean to spawn threads (while the AudioService may). Also they not must contains loops, because that may block the game for a long time. If you need a task to run in more than one game frame, then implement a way of tell the code calling the run method that you don't want it to be removed yet from the queue. Something like the run method returning a bool. I called it tasks, but don't get confused to that another pattern that exists, that is not what I proposing here. The disadvantage of this recommendation again a message system is that with messages, when you post a message you don't know how the game will react to it, you are only informing the game that something happened but how the game will react will depend of what objects are alive at that time listening to that particular message. So messages may be more versatile. 

move_x is set according to input processing, if not arrow key pressed then move_x = 0. Vales below zero mean left, otherwise to the right. Process all other moving sprites and decide the values of their "moves" component, they have the "moves" component too. Note: after collision detection and response, the move component must be set to zero, both x and y properties, because the next tick the gravity will be added again. If you not reset, you will end with a moves.y of two times the desired gravity, and in the next tick it will be three times. Then enter the displacement applying and collision detection code. The moves component is not really the current position of the sprite. The sprite has not moved yet even if moves.x or y changed. The "moves" component is a way to save displacement to be applied to sprite position in the correct part of the game loop. Process first the y axis (moves.y). Apply moves.y to sprite.position.y. Then apply AABB method to see if the moving sprite being processed is overlapping a platform AABB (you already understood how to do this). If it overlaps then move the sprite back in the y axis by applying penetration.y. Yes, as opposed to my other answer, now this move evolved method ignores the penetration.x, for this step of the process. And we use the penetration.y even if it is greater than penetration.x, we aren't even checking for it. Then process the x axis (moves.x). Apply moves.x to sprite.position.x. And do the opposite than before. You will move the sprite only in the horizontal axis this time by applying penetration.x. As before, you don't care if penetration.x is less or greater than penetration.y. The concept here, is that if the sprite is not moving, and was initially not colliding, then it will remain like that in the next frame (sprite.moves.x and y are zero). The special case where another game object magically teleports to a position that overlaps the sprite begin processed is something I will handle later. When a sprite begin to move. If it moving only in the x axis, then we are only interested if it penetrates something by the left or the right. As the sprite is not moving down, and we know this because the y property of the moves component is zero, we don't even check the calculated value for the penetration.y, we only see at penetration.x. If penetration exist in the axis of movement, we apply correction, otherwise we simply let the sprite move. What about diagonal displacement, not necessarily in a 45 degrees angle? The proposed system can handle it. You only need to process each axis separately. During your simulation. Different forces are applied to the sprite. Even if your engine does not understand forces yet. These forces translates to an arbitrary displacement in the 2D plane, this displacement is a 2D vector in any direction and of any length. From this vector you can extract the y axis and the x axis. What to do if the displacement vector is too large? You don't want this: 

Note that the position of each AABB is measured from its center, not from top, left corner. So if you are positioning your sprites like me, using left and top to mean the upper left corner of the rectangle containing the sprite, then you may need to calculate the AABB center like this: PlayerAABB.position.x = player.left + player.width / 2. And the same for y but replacing left for top and width for height. 

It seems entity systems are really popular here. Links posted by other users convinced me of the power of such system and I decided to try it. (Well, that and my original code getting messy) In my project, I originally had a SceneManager class that maintained needed logic and structures to organize the scene (QuadTree, 2D game). Before rendering I call selectRect() and pass the x,y of the camera and the width and height of the screen and then obtain a minimized list containing only visible entities ordered from back to front. Now with Systems, originally in my first attempt my Render system required to get added all entities it should handle. This may sound like the correct approach but I realized this was not efficient. Trying to optimize It I reused the SceneManager class internally in the Renderer system, but then I realized I needed methods such as selectRect() in others systems too (AI principally) and make the SceneManager accessible globally again. Currently I converted SceneManager to a system, and ended up with the following interface (only relevant methods): 

In 2.5D you use 2D assets/rendering techniques to give the sensation of a 3D environment. Now, with that definition, in the following potentially ambiguous scenario, some elaboration is required: Game A Using 3D graphics, GPU accelerated and all (the game objects are meshes, not images), with a fixed camera angle. Lets make it even worse, the projection is orthographic, the classical 63.43 degrees. The only way to notice at first glance that graphics aren't 2D is because 3DGC, except that you render them with extreme care, are easily differentiated from hand drawing sprites, not matter the projection used to render them. You may experiment with different render techniques, parameters, shaders, etc, and you will have a hard time trying to hide the fact that they are 3D meshes. Game B A port of Game A, but targeting platforms that are known to have hardware that does not handle 3D graphics very well or does not handle it at all. Then the port replaces meshes with sprites. It still uses 3D Bounding Boxes for collisions, for example, and objects have a position property with x,y and z values, as the game logic was mostly not touched or not touched at all, only the rendering code was altered. As the sprites of Game B are renders of the 3D assets of Game A and, to make things more ambiguous, Game A doesn't do anything that requires complicated shaders, in 99% of all GPUs out there you cannot differentiate a frame from Game B of a frame from Game A. In 2.5D, interaction between game objects are limited to the set of situations where the illusion of 3D cannot be compromised. To represent two characters hugging, for example, you will have to create a single image file with the two characters interacting, as trying to represent the hug action only using a single image per character would be too hard or impossible. Maybe you can come with a character body divided in parts and draw them in the correct order. In 3D this problem does not exists (there exists another, that is posing the two characters correctly so they do not penetrate in the mesh of the other character). Now, to visualize this, imagine that Game A and B have a bug that in some situation allows the player character to pass through another game object, allowing us to differentiate between the 2.5D one and the 3D one easily.