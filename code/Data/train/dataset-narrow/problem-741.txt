Yes there would be no information lost - unless in these few hours the primary server crashed or the backup becomes corrupted (due to I/O subsystem). As soon as the full backup is restored, logshipping will continue taking log backups on primary and start copying it to secondary server and restoring them. The minimum backup/copy and restore frequency is 1 min. Note: Once you configure a database for logshipping, you dont have to take any additional log backups - as this will break the LOG CHAIN and the logshipping will start failing. Full and differential backups can be taken, but NO log backups. Read up on more on How to Perform SQL Server Log Shipping BY BRAD MCGEHEE 

SQL Server (and Sybase as well :-) ) uses LRU (Least Recently Used) algorithm to keep track of pages that are aged in the buffer pool. It increments a counter every time a page is referenced and decrements the counter every time the lazy writer process sweeps the page. Any worker thread will check the memory status of Buffer Pool to make sure that there are healthy number of Free pages to honor incoming new requests. Note that : SQL Server will always keep a minimum number of free pages on the free list, so that it can serve incoming requests without any significant delay. The amount of free space is calculated based on Buffer Pool and amount of incoming requests. IF there are no free buffers or very little left then : 

Note: Enabling , you dont need to set the compatibility level of the database to a lower level. From KB2801413 : 

Perfmon is pretty light weight when it comes to data collection. Collect the data in files and set a sensible collection frequency. Jonathan has written about Essential PerfMon counters for DBA that will give you a good start. For automation part you can use and load data into sql server or as shown here You can even Setup Perfmon with PowerShell and Logman. Alternatively, you can use PAL or Get-PerfMonSummaryStats.ps1 - Powershell script from MSFT exposes perfmon counters in raw form. 

There is no mathematical formula to calculate your autogrowth settings, especially when you do not do a baseline of you databases. Now, as @ThomasStringer pointed out that you should not allow your database autogrowth to be in %, rather set it to MB, you can find out Autogrowth events happening on your server instance using the default Trace. 

Your error message is useful to know that the database you are trying to remove is not in mirroring. It is part of Availablity group. You can use below command to remove the database from Availablity group : 

Yes it has to do it again .. scan and fix the errors with potential data loss. Be cautious, use it as a last resort - repair & allow data loss ! Refer : Corruption .. Last resorts that people try firstâ€¦ from Paul Randal. Remember : SQL Server 2000 is out of support .. so microsoft is not going to help unless you upgrade to a supported version ! 

To overcome the performance problems that might result from missing or stale stats, SQL Server team came up with temporary statistics in TempDB. Refer to : Making latest statistics available on Readable Secondary 

follow the checklist/steps that I have listed here. stage the application connection string to include failover partner. This way when you do cutover to new 2016, the first connection of app will fail since 2014 will not be available, but the second attempt will succeed since you have specified failoverpartner 

I would suggest to use Restore Gene written by Paul Brewer. There is a T-SQL [] and PowerShell version [] of it and you can use it / customize it as per your needs. SQLServerCentral.com has an excellent article by the author on how to configure and describes the working of it as well - Restore Gene : Automating SQL Server Database Restores. 

There is no direct way of doing it in SybaseASE (as opposed to sql server - which exposes DMV data). You can get close to see if your is getting , and is not being . I use below query : 

The command that you posted just run the transaction in the SP with . Other connections will default to the default isolation level - read committed (unless specified a different isolation level explicitly). There is an excellent series by Paul White - SQL Server Isolation Levels : A Series which will help you understand in depth what different isolation levels mean and do when they are used. 

The gist of Blue-Green Concept is to divide your production into 2 environments and they are identical all times (data synchronization) wherein 

I normally, use and then delete the backup files older than X days. Ola's solution is a one stop solution and its very flexible, so you can tune it as per your needs. 

A is not a substitute for a FULL backup. Its just a snapshot that can be used to move a database from one server to another (or to cloud) and archiving an existing database in an open format. From my test, below are the results 

Supplementing to the current answer... Detach database will leave you without any backup. If for some reason, you cannot attach database, you will end up with a detached copy of mdf and ldf. A best practice should be to do a backup and restore of the database. This way you end up with at least a copy of the database. Read up : $URL$ 

Below is the result .. we are able to restore the log backup 1,2,3 and 5. We skipped Tlog4 as the LastLSN of Tlog3 was the firstLSN of Tlog5. 

Once you gain access to sql server, then create a login and map that login to a database. Make sure to NOT delete it again :-) 

Kevin Kline highlights the functionality here and there is a good article by Dale Kelly for migrating reports using RSScripter at MSSQLTips. Another way is to use the power of PowerShell. There are many script available like here and here. There is other utility (which I have not used) called reportsync 

Query Store is persisted to disk, so it survives a crash. But Query Store is also Async, it means if the data has not been persisted and a crash happens in the meantime, the data will be lost. Although, if SQL Server must be restart because of a maintenance routine you could force Query Store to be flush using the procedure: sp_query_store_flush_db. 

As a side note, depending on what version and edition of SQL server you are using, in 2012 and up, you can leverage AlwaysON with readable secondaries to offload reporting to the secondary server. Let me know if you want any further clarification and I will be happy to help you out. Edit: 

Forcing affinity means that you take away sql server's ability to move processes between schedulers. Consider below example : (using coreinfo from sysinternals) On a 2 socket, 12 CPU (24 logical cpu with hyper-threading enabled) with 2 NUMA Node machine, we get 12 CPU per NUMA node.