You'll need to compare the monitor handle returned to the list of screens found on the system. Screen.AllScreens is a list of all screens. As for the adapter mode comments above you should see the DirectX SDK and check out the DXUT classes, especially DXUTenum.cpp. This class is necessary for an application. It will enumerate all adapter display modes and build a collection of 'combinations' that can be used. Display Modes have specific capabilities. Certain modes cannot go fullscreen. Certain modes require a particular back buffer format for use with the adapter format. Certain depth/stencil buffer formats conflict with multisample types...and so on. Were you to try and create a device using improper settings the API will throw an exception...or return 'Invalid Call'. DXUT is very useful and is a great tool for avoiding conflicts. 

As you can see above, t0 is the Pos2 coordinates that i use to sample the texture...they are well above 1 ... the vertex they belong to is visible so this pixel should have valid normalized device coordinates. Are the coordinates being altered after leaving the vertex shader and arriving at the pixel shader? 

The above example is simple, the constant buffer only stores two 4 component colors. I want to set the constant buffer before binding the pixel shader. I do not want to use the ID3DXEffect interface. The IDirect3D9Device interface only provides methods for setting primitive types...I want to set the entire struct at one time. Is this possible? 

Make sure no unnecessary values are floating around. It might just be that you have other data that you're not using that's in memory. This is less of a solution and more of a quick fix. You're still loading a lot of data into memory and if you move to a device with less memory you'll hit the same problem. Load smaller backgrounds. It won't look as nice but if you stretch the textures a bit you'll save memory. This also doesn't perfectly solve the problem. If you want more backgrounds in the future you'll still probably run into the same problem again and then have to downgrade the quality further. That's a pain. Don't load all of your backgrounds at once. When you move to the next page, add a transition like a fade where you, in a separate thread, load all of the background images. Then as you fade back in, unload the previous page's textures. That way you have 24 textures loaded at most. Have fewer levels per page. This one may not be the most ideal but it will work. Heck if you lower it to like, 6 or 8 per page you can do something where you have the displayed page loaded, and the next and previous pages loaded as well. That's 18-24 textures loaded at once. Then when you move to the next page you don't have to load anything to display the page, but you can unload the page that's no longer 'adjacent' and load the next 'adjacent' page. 

I'm trying to parse a .x file using SlimDX. I can create the XFile object and register templates but I'm having problems with the enumeration object. The enumeration object has a child count of 0 for a file I know to have valid data. Here is code to create file, enumeration, and data objects: 

The pixel shader returns a color based on light contribution. The result of the lightmap generation for this test mesh looks like this: 

...There are no exceptions thrown by this function...the child count is 0 so the conditional loop breaks right away, the file objects are disposed of and the function returns... Here is .x file...a simple cube: 

The problem is that the depth/stencil texture is a D24SX format...How do I sample from a texture of this format? My original attempt which of course will not work: 

It will be up to you to manage these variables. Build a class to hold the variables, then you can access the key and mouse states at will. 

I have a list of indexed triangles for which I need to generate adjacency data. I've already written a brute force algorithm that creates 3 edge data structures for each triangle and then compares the edge structures with those of other triangles like so: 

When I set the depth stencil and render targets all at one time then nothing is rendered to the screen. When I set only the render targets everything renders normally...Why might this occur? 

There are two steps to solving this problem. First you need some extra data on collision. When two objects collide you want to know how far they've collided into each other. After that you want to move the two objects backwards. Depending on how accurate you want it you could just take the amount that they overlap, divide it in half and then just move each object back by that amount (not good if only one object is moving obviously). If you want to be more accurate you can try to determine how fast each object was going on impact and move them apart depending on which one was going faster. After you've separated the two objects from colliding you can apply your resultant forces. Again if you don't need to be SUPER accurate you can end here and just let further collisions sort themselves out. A way to increase the accuracy of your collision response here is to iterate this process. Each object will detect and react to collisions multiple times per frame so that if one collision results in another immediate collision you can account for it. You want to put a limit on this so that you don't end up with an infinite loop of collision detection. Objects that are more important will have higher iteration limits. There are a few different algorithms to determine object overlapping that can be done as apart of the collision detection step. If you use the Separating Axis Theorem (SAT) you can do this pretty easily but that's more for 3D. It's even easier to do it with circles and AABBs in 2D. Here's a quick example to get the overlap for two circles colliding: 

The light for this scene is floating in the center of the room... The problem is that the lightmap has 'cracks' due to the rasterization of polygons by the GPU. It appears as though that for a given face lightmap pixels are not included during rasterization because their pixel centers do not fall within the bounds of the face's UV coordinates despite the fact that the face overlaps those pixels. As a result a black( unset ) pixel is rendered and effectively blackens the diffuse color of the mesh during texture modulation. Here is a screenshot: 

Needless to say, time complexity is an issue here. What is the most efficient method for generating adjacency when comparing position data using an epsilon? 

Screen.FromHandle(): Retrieves a Screen for the display that contains the largest portion of the object referred to by the specified handle. (From MSDN) Also, the Direct3D9 object has a function that returns the handle(IntPtr) of the adapter monitor. I haven't worked with multiple monitors yet so I couldn't say that this method will work well but here is code for SlimDX: 

I'm using directx 9 and vertex shaders to rasterize triangles...I have vertex shader input structs like this: 

Compose an array of edges in uv space. For each edge: a. Compute the cross product using the edge direction vector and a point that lies on the edge. The resulting vector is the edge's normal(It should face away from the triangle, perpendicular to the edge direction vector) b. Compute the edge center position in uv space. c. Translate the edge center position along the edge normal by a distance of a half pixel(or desired dilation amount in uv space...it should definitely be a value between 0 and 1). After all edges have been translated, calculate the intersection points between each edge to determine the new uv coordinates for the triangle. Adjust the triangle's position data. Each position should be dilated as well. The dilation of triangles with acute angles may cause too great a change in the uv coordinates. You should calculate an axis-aligned bounding box for the original triangle in uv space. Then dilate the AABB by the same amount as the triangle. When computing the lightmaps just make sure that the uv coordinates lie within the AABB, if not then discard the pixel. 

My Google-fu is failing me: is there a site in the same vein as Rent a Coder, but for hiring artists? In particular, I'm looking for a site which fits the following criteria: 

The enforceability of these patents is another issue altogether. Just because the USPTO grants a patent does not mean it will be held as valid in a court of law. The video game industry is young and has relatively few patents, so there are, to the best of my knowledge, few historical precedents to indicate what a judge might rule if patents like these were exercised. 

When I first looked at your game I immediately expected that I'd be able to hold my phone in my hand like I would a dart and make a throwing motion, in order to throw the virtual dart using the accelerometer. However, it doesn't look like you actually have that feature. I think that would be a pretty neat thing to add. Of course, not being able to see the screen when you're throwing would be something of an issue, and you might want to look into what liability you could be facing for basically encouraging people to almost throw their phones... Even so, I think it'd be a very novel and Wii-like way to play the game. 

It seems that the original incarnation of Rent a Coder is dead (the above seems to be some sort of knockoff), and that it was probably killed by an unsustainable market full of unrealistically low bids for large projects by unskilled and unqualified "coders." That being the case, such a site might be poorly suited to art as well. The reason I'd like such a site, though, is that as a "bedroom programmer" with a small budget and little experience in this sort of thing, I have no idea where I should be looking for art or how much I should reasonably expect to pay. Thus, a site with good competition where market prices are somewhat transparent would be ideal. Any other suggestions about how best to acquire custom artwork as an indie developer are also appreciated. 

I am shadow mapping in Direct3D 9. I'm trying to avoid rendering depth to a 32-bit render target. So, I've created a depth/stencil texture( a texture w/usage Depth/Stencil ). When I render I do this: 

I'm programming a managed Direct3D 11 application with SlimDX. I want to use Intel Graphics Monitor to capture draw calls for a single frame. When I try to set a depth stencil state my application crashes...any ideas? 

This thread directly concerns lightmap generation; however, indirectly, the rasterization of polygons by the GPU. I am currently generating lightmaps using a pixel shader. To the shader I send 3 lightmap UV coordinates per mesh face. Those UV coordinates are directly rendered onto a lightmap texture( by setting the lightmap as the render target ). The vertex shader looks like this: 

Here is a screenshot of an auxiliary window which shows both the lightmap and a selected mesh face. This is generated by rendering the UV coordinates of the mesh face over a screen quad of the lightmap: 

I'm working on a radiosity processor in DirectX 9. The process requires that the camera be placed at the center of a mesh face and a 'screenshot' be taken facing 5 different directions...forward...up...down...left...right... ...The problem is that when the mesh face is facing up( look vector: 0, 1, 0 )...a view matrix cannot be determined using standard trigonometry functions: 

When compiling for a traditional Windows / Mac / Linux desktop setup, no this won't work. I dug through the SFML code and it turns out that the sf::Touch implementation won't really work unless you're on a touch-based device: From $URL$ 

If you really want to target OpenGL, GLES and WebGL you should reuse as much code as possible but it's not a simple task. OpenGL and OpenGL ES are fairly similar. In fact a lot of the code can be reused between the two. WebGL isn't quite as easy as, you're right, you need to recompile with emscripten which is a whole separate task. Your project organization can be really different but this is how I would organize it: 

My assumption based on my experiences with shader reflection in DX11 is that it's mapped by name. If you check out the DX11 shader reflection API you'll see that there is a struct that you can rip from the shader. Notice the LPCSTR for the name of the variable. OpenGL also handles variable mapping by name. Of course the best way to find out is to try it yourself! Try repositioning your constructors and see if it affects your cbuffer buffering. $URL$ 

What you would do is have a limited depth for your octree and allow multiple voxels per leaf. I used a depth of around 6-8 for spatial partitioning for collision detection but for voxels you'll probably need more; it's up to you. You'll also need a limit to stored voxels before splitting, say 10 for the sake of example. As your populate your octree when you hit 10 voxels in a leaf you'll split it and move the voxels into their new leaves. Once a leaf is at your maximum depth you should no longer split it and just let your voxels fill the leaves.