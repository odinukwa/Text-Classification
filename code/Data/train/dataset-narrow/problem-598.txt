followed by rebuilding the indexes on that table should do what you want. After 'moving' the table around, the indexes for the rows will become unusable (as you can verify with something like): 

This is elegant because it doesn't clutter the source code with statements and I'd like to keep this feature, if possible. On the other hand, is a perfact candidate for a virtual column. So, here's almost the same thing, but with being a virtual column: 

or something similar. Yet, in the documentation I am unable to find something in this direction. So, does that mean that this is impossible or am I looking in the wrong place? 

So, there is a possibility to find out if there was a coalescing done, but it's not straight forward and probably useless, depending on your context. 

The line in question, that is line 5, is with the parameter . I have run the script with a user that has DBA privileges. I have also created an Oracle directory named . The OS directory it points to exists and is writeable. The complete code that fails is (copied from the note): 

Probably, the question boils down to if and to what extent these features are regulated by an ansi standard. Practically, I'd like to know if there are "rule of thumbs" that would indicate if (and how) I can take an SQL DML-statement that runs on one database and let it run on an other database. 

Oracle says about Indexes and Index-Organized Tables under Full Index Scan: In a full index scan, the database reads the entire index in order. Yet, unter Fast Full Index Scan, it reads: A fast full index scan is a full index scan in which the database accesses the data in the index itself without accessing the table, and the database reads the index blocks in no particular order. (Emphasis mine) Now, probably, the question should be: why did the optimzier choose over . A hint to the answer of the latter question is given in under 11.2.3.7 Fast Full Index Scans: A fast full scan is faster than a normal full index scan because it can use multiblock I/O and can run in parallel just like a table scan. If you insist that Oracle use a full index scan, you might want to try the hint: 

Now, I am wondering if there is a possibility to change the text width when I am already connected. I would have expected something like 

I am trying to generate an SQL file with the api. This tasks is specifically adressed in Oracle support Note 1519981.1 (How To Generate A SQL File Using The DBMS_DATAPUMP API). When I copy/paste the code found in the mentioned document, it fails on line 5 with a rather obscure 

To measure the (what I believe is your understanding of the) allocated and used size of the index, I'd probably use 

In SQL*Plus, I try to run a script that is stored at a certain URL. From where I am currently, I can http(s) connect with the internet only via a proxy. So, if in SQL*Plus, I try 

Somehow, it seems that SQL*Plus (at least on Windows) is unable to locate a script with a relative path when called with and when the path starts with a single or double dot. For example, under I have the following directory structure: 

Does someone who has worked extensibly SQL-wise with at least two top DB products (such as Oracle, SQL Server, Informix, Sybase, DB2, Teradata) know how different the DB vendor's SQL dialects are from each other. Since I come from an Oracle background, I am especially interested in 

the double seems to change it's behaviour, in that it searches paths from where SQL*Plus was started, and the output will now be 

When I create an (invalid) view that selects from another invalid view, the view does not immediately show up in . I am wondering if this is expected. These are the steps to reproduce the behavior: First, I create a table 

It seems to me that it should be possible to parse existing PL/SQL with the packages and , but I have found nothing on the internet with the exception of a few scripts that seem to unwrap a wrapped package (and that is useless for my purposes). So, does anyone know about a pointer into the right direction? 

I don't understand the criteria that entails an additional record in the view. I have expected there to be at most one entry per and , that is, the following statement to return no record: 

It is not completely clear what your after with your question. I assume you want to know if and importantly when an was performed. I think without (an in other answers already mentioned auditing setup) it is impossible to get such a date (although I would want to know if someone knows better). That said, the effects of an can be made visible with a . 

I am wondering if it is possible to pass parameters to an SQL script from within sybase's isql utility. For example, I'd like to store a select statement in the file that would look something like 

Now, if the view's select statement contains a , it seems as though that characteristic is not inherited anymore: 

I now query to check whether I have objects that are dependent on . I would have expected to be reported, but the following query returns no record: 

Is this behaviour documented somewhere, and more importantly, how do I have to change so that it calls relative paths () correctly? 

I have an sql script that uses to extract the definition from a view. This script is run with sqlcmd: . Unfortunately, the length of the returned string seems to be truncated so that not the entire view definition is extracted. Is there a possibility to extend the length of the returned string? 

An *object_id* identifies an object (such as a table, or an index) within Oracle. The rowid can only be used for tables, or more specifically: the records within tables. It uniquely identifes such a record, that is, where the record can be found on the harddisk. Therefore, the function *DBMS_ROWID.Rowid_relative_fno* gives you an id that identifies the file, *DBMS_ROWID.Rowid_block_number* gives you the block within that file and *DBMS_ROWID.Rowid_row_number* gives you the "row offset" within that block of the actual record. In your case, you can query v$datafile with the file_id of 5 to find out which file "holds" the record. . 

I am looking for (preferably) an SQL statement that selects the table/and column names for any table with a foreign key to a given table in Sybase. I think it should be somehow possible with the tables but being completely new to sybase, I cannot make head nor toe of it. So any help into the right direction is highly appreciated. Edit: For completness' sake: returns 'Adaptive Server Enterprise/15.0.3/EBF 17156 ESD#3/P/Sun_svr4/OS 5.8/ase1503/2726/64-bit/FBO/Fri Feb 5 05:26:23 2010' Edit 2 Thanks a lot for your suggestions, especially Andrew Bickerton's comment. That allowed me to construct a rudimentary SQL select statement for a starting point to go further. In case someone else is interested in it, here it is: 

with the rule that 's value is the sum of the other four columns. So the table is filled accordingly: 

Now, the problem is with the last two records: Their is and this number is supposed (as I believe) to reference , yet, there is no record with . So, is this a bug? Or is there a way to include the missing record into the result set? I believe the problem is caused by the line . If I take this (and the corresponding ) out, the problem disappears, and usage_conext_id for references an existing . 

So, is this still somehow possible (and if so, how) to use this rowtype-variable along with virtual columns? 

I have recently had almost the same need, so I have written a simple script to create insert statements. It is located at github. However, the script does not create the table creation statements. You should use for this. 

This is a bit unfortunate for my purposes. So, is there a way to explicitely state that a column be for a view in Oracle? Note: I obviously used a simplified view defintion to demonstrate the problem, and I could re-write the view definition without using . Yet, my actual view defintion is much more complicated, requiring the . 

Tahiti about Authorization for Accessing Remote Schema Objects: To access a remote schema object, you must be granted access to the remote object in the remote database. That means you need to grant the privileges locally (to the database on which they are) to the user as whom a user connect via the database link. So, for example, if the database link was created like so 

Yet, it returns many records, indicating that it is not possible, but the normality, that the same sql statement is captured multiple times per . Additionaly, with more than one record per sql and snap period, how do I interpret the delta columns within this view? The documentation reads: 

This is expected, since the single is supposed to search paths from where SQL*Plus was started and is supposed to search paths from the containing script's directory. unexpected output Now, if I change so: 

Maybe, and this might be dependant on the command line environment you're using, you need to quote the string, something like 

means the select is failing. If the lock could not be established, would be -54. I am 100% positive that you had an exception (that obviously was caught somehow). If you want to catch the exception, you should try something like 

with the expectation that is repleaced with 900 and with 20. Is there a possibility to achieve what I want? 

Now, say, that there is a need to copy one row and change just one column's value. This can of course be done quite elegantly (imho, that is) with a rowtype-variable, like so 

If I create a view in Oracle, the column definition's not null characteristic is inherited from the base table: 

I believe I stumbled upon a bug with PL/Scope in combination with associative arrays, but perhaps I overlook something. I have the following package 

SQL*Plus won't find the script (as SQL*Plus doesn't seem to know about the proxy). Is there a way to indicate what proxy to use and how to authenticate with that proxy? 

I'd probably make the final decision of the design dependant of the distribution of the queried parameter_ids. That is, if there are a few parameter_ids that are queried almost exclusively, I'd put their values into a hot table and the remaining values into another cold table. Otoh, if their query-distribution is more or less even, I'd load a sample set worth a few days into a table where one records keeps all values in order to see what the ratio is between records/db-blocks (or if there is even a row chaining problem, which is likely). Depending on that I would then do a further design decision. Well, after reading it, I'd probably do both approaches for a desicion in parallel. 

The default output (text) width in sybase isql is 80. It can be changed with the flag when isql is started on a command line: 

This procedure measures the allocated and used size of an index named *TQ84_SIZE_IX*. For completeness' sake, I have also added the count of bytes as reported by . Now, this procedure can be seen in action: 

Ok, I didn't realise that creating such an export file consists of two steps. First, an ordinary dump file must be created, then this dump file is used to create an sql file. Since I didn't have such a dump file, the script as posted would not work. Here are the two steps, so that an sql file can be created 

As Mat has pointed out, I hit Bug 9164488 () which should be fixed in Release 11.2.0.2. In the meantime, running on 11.2.0.1, I was able to circumvent the bug with a purge job in order to do the work. As soon as I ran 

This doesn't really make sense to me. Update as per Justin's comment: this is not in a RAC environment: so even if I , the query returns multiple records per snap_id and sql_id. 

I am trying to color the result of SQL statements with SQLcl. I and execute a The output I get looks like this: 

I'd probably do what you need to do the way that Jack Douglas suggested. But if you really want to go fancy, you coud query and divide it by the number of s of the query, so you get the average execution time for a query. With the following function... 

Also, if I try to insert a record [] I get the (correct) error message . Edit: The version (v$version) is: 

I am confronted with a problem for which I have not found an elegant solution: I need to clone a schema within the same database, so I use datapump's import parameter. The problem is that the PL/SQL Packages contain lots of fully qualified object names (such as . These qualifiers are cloned. This makes the cloned package invalid. I could obviously to make the problem go, but this is not what I want. I'd rather want the qualified names to change as well. The export parameters are