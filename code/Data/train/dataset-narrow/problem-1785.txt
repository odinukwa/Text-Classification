Did you make updates without rebooting? You might want to check if you use firewalld instead of iptables and can just start that service again. 

For your setup this looks like the 2nd option. google for the exact error message "nss_getpwnam: name '0' does not map into domain" gives you plenty of results which might help you aswell (just pointed the most promising) 

The situation might happen on high load on the HDDs only, i did not test that yet as it would impact the server performance obviously. There is no load on the SSDs, they are mounted but not used by any of the processes. The RAM is ECC as far as i can tell. 

the file is in /etc/update-manager/release-upgrades i assume this happens because 13.04 is already end-of-life and therefor the next supported version is 13.10 though not 100% sure, see wikipedia change 

STA seems to be short for Station in the broadcom sense. I might however read it wrong. The not that high reliable source but it was the best i could find with a small search: Source: Openwrt Qoute: b43 This is the open source driver built by the community based on reverse engineered specifications of the proprietary Broadcom driver. This is the driver that is included in the current OpenWrt builds. It is also in the mainline Linux kernel. This driver supports most of the current available Broadcom WiFi cores. It has support for station (STA), AP, AdHoc, Mesh and other modes, but it just supports 802.11g rates and does not support 802.11g operating in the 5GHz band. 

try looking in the user folder instead of only looking for the system wide files. if you are logged in as root: 

Basically you should not (at least not only) read the logs on the same host but instead use some sort of logserver which would get all the logs of the servers centralised. i used this setup to be sure the logs aren't altered after they were entered. Additionally just use logcheck and let it check the logs for you. Basically its a check for lines you find acceptable and can be ignored and only sends you the ones you did not tell logcheck to ignore beforehand. you can easy install it on every server. for a graphical version , counting how many severe log entries etc is logzilla a nice option, thought not free anymore. 

The issue might happen if something caches your request and you do not flush your DNS cache. Often the OS caches DNS entries which makes changes in DNS not be seen directly. For Windows f.e. you can clear your DNS cache by something like. 

There is a way to disable the firefox internal DNS cache: I am uncertain about which version there is a cache and if the following will work for all versions, but you might want to give it a try. I had a similiar issue in that Firefox was caching a long time for me which was not helping me debug an issue. Howto: In the you have to create 2 new (or change the ones already existing). The Preferencename should be and Both have to get the value of . Restart your firefox and test again. This was basically taken from $URL$ though i remember it was mentioned on other sites in the context of Firefox DNS Cache disabling as well. 

This might be a Permission problem. under normal situations non-root users are not able to bind to ports <1024 in linux. However if the SNMPD drops it privileges after creating the socket/endpoint then this should not be your issue. 

Install f.e. SMARTmontools, SMART is especially designed for monitoring hard drives, and these days it can monitor SSD parameter the manufactured decied aswell Search for write cycles, power on hours, power on count. Find out what flash chips you have in your SSD, find the specs for that chip, and get the average write cycles. From my experience the SSDs did break only on controller issues, not on write cycles, where overprovisioning should take over and replace the broken ones with spares. 

First of all: SATA vs SAS drives (not discussing RPM) SAS drives do have better error-handling than SATA, so when you have the option, take SAS over SATA, so when you have a harddrive fail the chance of killing your raid will be reduce with SAS over SATA. Read some other questions here on SF about people loosing their raid over 1 failed sata drive. For the RAID : you have to decide what do you actually need, reliance, nearly no downtime, fast restore , access speed, etc. There are some nice questions here on those specific needs. For the speed difference: 15k RPM against 7.2K RPM make a lot of difference, though this depends on the server and your data. Basically if you anticipate a lot of IOOps and cannot afford or want SSDs go for the 15K drives. IF you really have only a handfull sequentiell access, and no further access 7.2K drives might be enough, but you have to measure that yourself. Depending how important every bit of data is you might want to consider the drives based on the bit error rate aswell. Keep in mind that a rebuild of a larger Raid might already trigger that bit error rate on bad drives. 

most likely is the logfile where your id is entered into. (replace your_user and the teamviewer version if needed.) 

you could enter both entries with different priorities. Once you want to switch to server2, just disable the mailserver on server1 (f.e. stop service) Just make sure every DNS has the additional 2nd entry. Qoute from google postini An MX record consists of three parts: the domain name, a priority, and an email host. The priority indicates which record gets looked at first when determining where to route a message sent to the domain. Normally, the primary server named in the record with the highest priority, is used. But if that server is not available, the next highest priority’s record is evaluated, which is typically a backup server. And so on. 

i do not know for additional csh files similiar to bash files (.bash_login .bash_logout) in the user folder, so you might need to check the existence with ls -a for showing the "hidden" . files. 

What i did already figure out (or believe to have figured out) The commands and are not important to the issue. While reading about 20 bugreports and lot of documentations, a few linked some did suggest to disable NCQ, which i did . First for one device, after waiting 1 day to check if the error repeats it happend again and i disabled it for all 4 devices 

Depending on your exact setup this might be an issue with having to type your password twice, so watch out for that. 

If you have something similiar to Intel® Server Board S2600CO Family TPS Specs PDF here this might be the shortform of "single-sideband modulation" See wikipedia for details 

Keep in mind that this all happens without encryption aswell. so encryption just makes it more likely that you loose the whole backup (if you do not encrypt only on file level) Additional deduplication of files, depending on how you encrypt it, will not work either, making the backups larger. For HD missing: just make sure the encryption is strong enough until the data has no worth for someone else anymore. Or you need to tighten your security so this cannot happen : F.e. Access control to the server room and full video monitoring etc tl,dr: prevent bitrod by monitoring every file + container, swap hdds before they get bad, video monitor the server room and prevent access without at least one other person knowing. 

it seems you have the vi or vim editor as default and this was used by dpgk. You can quit the merge window with: 

You have example.com in the resource (for example a MySQL database) referenced in the virtual_mailbox_domains directive in /etc/postfix/main.cf AND in the mydestination line (also in /etc/postfix/main.cf)! This doesn't work. You can list example.com either in virtual_mailbox_domains or in mydestination, but not in both. after the change restart Postfix