Andrew Smith is correct, but has an unnecessary step in his suggestion. You don't actually need to login to ssh with a password for Webmin to work; ssh and Webmin are unrelated services. Simply set a password for your root, or sudo ALL capable user, and that will be the way you login to Webmin. 

You'll need to insure the '--with-suexec-userdir' compile time option is enabled in your Apache build. 

The video isn't working for me. Paste in the last few lines before the bit about "displaying the last 15 lines of the log file", as sometimes that's actually where the problem shows up. The log, unfortunately, can't capture everything on all systems (apt-get doesn't like being run from scripts, and it makes capturing everything, while still providing feedback to the user about what's happening, really difficult, if not impossible). Check the last 100 lines or so of virtualmin-install.log for clues. What Dovecot error, specifically, are you getting? (I wrote the install script. I can usually spot the problem, if I see the actual errors. And, I can also probably fix the problem in future releases, if I understand why it is happening. My last Debian install two days ago worked great, so this is not a known issue.) Edit: OK, so it looks like dovecot isn't installing correctly for some reason. Maybe conflicts with other packages already installed on the system. apt-get is pretty hateful about changing packages to satisfy dependencies. So, try running: apt-get install dovecot-common dovecot-imapd dovecot-pop3d And see what happens. If it works, then you could try the Virtualm install again. 

I can't figure out exactly what you're saying Webmin is doing wrong here, but if it's a bug in Webmin you should file a bug in the bug tracker, rather than asking random people at Server Fault how to work around it. Webmin is very actively developed...there's never any reason to work around bugs or incompatibilities in Webmin: Tell someone who can fix it, and it will get fixed fast. You can use the bug tracker at Virtualmin.com or the SourceForge.net one (but the Virtualmin.com tracker is faster, works better, and will get Jamie's attention faster, so I recommend it). 

Yes, this is possible, though probably not in the way you're thinking of it. You're talking a lot about C, as though it matters; since you have no control over it, you should stop worrying about it. Unless there's more than one C, and that can be used to choose your origin servers, C is utterly irrelevant...it's just in the way (and does prevent you from using more direct methods of selecting origin servers). You don't/can't determine the origin server in this scenario with cache_peer directives; cache_peer configures how Squid talks to other proxies, not origin servers. Since you can't control the middle Squid, you can't perform any selection based directly on the origin server; i.e. the forward proxy is always going to go to the domain name you've requested, and that won't be based on your selection criteria at B. (If you had control over that other Squid, you would have more options.) One way to achieve what you want is to give your origin servers some additional names, so that your first Squid (B) can rewrite requests based on URI to new domain names, and the middle squid can make requests based on the domain name. You can use the url_rewrite_helper option to make use of a rewrite program to alter the URL in whatever way you choose. If it were me, I would probably create a new name for each origin server (a, b, c, etc.), and then rewrite based on whatever piece of data you have to those names. So, if your URI is "$URL$ you could rewrite that to "$URL$ and "$URL$ to "$URL$ You would, of course, need to configure the origin servers to answer on those new domains and possibly configure them to reconstruct the URI from the munged one it's receiving. References: $URL$ And, re-writer info and example rewrite program: $URL$ You could also skip having that first squid determine the origin, and let the origin app distribute your requests across domains in whatever way makes sense, by telling the client to request from whichever server is the right one. Hope this helps. 

After a lot of reading I found it. One need to start to create the nodes files. After this step I could also start with creation of the DRBD-device. 

Now comes the fun: I've started the sshd in debug/non-forking mode (in temp_sshd I've changed port to 12345): 

However there are no device files sdc1 and sdc2 in /dev/ directory. I can try but I'm not sure what parameters should I use. Of course, as there are no /dev/sdc1-2, so when I try to create DRBD on these I see following message: 

I know that ssh problems were already discussed here still before down-vote this question, please, read. :-) I have two freshly installed virtually equal servers under CentOS 6. They are used in DRBD/HA environment. All settings on both of them, AFAIK, are the same. Most of them where copied with rsync. I can log-in as root with my key being accepted to both servers; however I can log-in as normal user only on one of them (master1). Some more info. User: The permissions on users home-directory and his .ssh are 700. The files: authorized_keys, id_dsa, id_rsa are 600. Whole structure of /HOME is exactly the same on both machines (rsynced). Configuration: GSSAPI, Kerberos and PAM are deactivated. sshd_config and ssh_config files are exactly the same on both machines (rsynced). The same is true for /etc/hosts, /etc/passwd, /etc/group, /etc/shadow, network settings (except IPs and MACs), running services (except that these started with heartbeat are not running on master2)... A try to loggin as a user xxxx from master1 to master2 looks like: 

not perfect solution but I had this problem some 2-3 years ago with an older . What I did was to add on both hosts a script in that checked if actual host is an active master or a slave. If it was on a slave it checked if some known file in NFS directory is available. If not; I assumed that NFS is broken; it send over ssh command. You can try to work along this line. I'm sure they are better ways. This one was good enough for me. 

I have problem to localize the source of this error. I tried to google it out but couldn't find anything useful. I have noticed that samba and the system using for some, but not for all, users different UIDs. Most of them are the same. Some as shown below are not. 

As I want to set PasswordAuthentication NO in sshd, I need to have public-key loggin running. Any help most welcome. 

It happens for all the users that have UID higher than 589. Can somebody explain this to me? p.s. I'm using samba-3.5.10-125