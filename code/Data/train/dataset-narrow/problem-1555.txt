Your clients are currently using SMTP to send their email via the ISPs SMTP service. Don't change this, and definitely don't turn off SMTP authorisation unless your client wants to help spammers. If your clients trust their staff not to send spam or viruses, then you could just configure their email clients to send directly via the ISP smtp address, rather than via the McAfee filter. Incoming mail sent to their server will still get filtered through McAfee, which is probably all the client is bothered about. Outgoing mail never goes to McAfee at all. If you stop thinking about email as a single service, and think in terms of a sending mail service and a receiving mail service (which is still a bit of an oversimplification), this makes more sense. They only need filtering for the mail they receive, but not what they send. 

My VMware vCenter stores all its data in a SQL Server database. The database server resides on the same VM as vCenter itself. This means that vCenter is able to run independently of other servers, which seems like a good thing. However I am not 100% sure. Can anyone outline the pros and cons of this approach, and if strongly in favour of something else, please share details. I'm currently on ESX 3.5, but will shortly be upgrading to 4.1 - a point at which it seems a good idea to readdress the previous decision 

However, what I want to do is be able to return a table, or csv file of all in the profile, So far I am only able to get specific properties (see answer below). I have tried piping the output to and but this just returns blanks. I feel like I am so close. I don't want to replace the call with lots of calls and it doesn't feel like I should have to. Any ideas? 

You should be able to edit the defaults in the config file in the source code, then recompile and apply to your router. 

Another useful troubleshooting step is to connect a console cable to the ASA, get a console session up, and watch the output when booting - the ASA will report errors during the boot process, but you won't see them if you ssh in. Many errors will result in an ASA that functions, just not as expected. You could also view the logs, but I prefer the above, as it shows you the errors that occur during boot, as they occur. 

How do I get Windows 7 to automatically run dsac.exe as a specified user? I'm happy to fill in a password prompt for the specified user, but would be even happier if there was a solution that cached the password, so I didn't have to enter it more than once a day. Update The following worked, but feels a bit clunky: 

I guess you have your reasons for doing this, but taking Zoredache's question as a kind of answer - you could set up squid on your server (if you don't already have it) and have all the web requests run through that. Surely you are already running some kind of proxy server to allow this anyway - in which case more than likely there is some such functionality available to you through that. I don't think the fact the traffic is tunneled to the server is of much relevance here, but perhaps you can provide more details on the use case, and how you are currently achieving things. 

I deal with a lot of remote offices located in parts of the world where the local grid power supply is unreliable. 

I am working on an SCCM project that requires powering on computers in the middle of the night to run updates. SCCM can send the WoL packets, but I am struggling to figure out how to pass this across routers. Our core router is a Dell PowerConnect 6248. I see from the docs that the 62xx switches support forwarding directed broadcast, which seems like a good start. However, having this on globally (which seems to be the only option) exposes us to some attacks. Would the best way of setting this up also include setting up ACLs on the egress interface to only allow UDP port N traffic from host IP to leave the interface? Is there another way of achieving this? NB - I already looked into IP helper, but this only passes broadcasts from a subnet to a specific IP address, wheras WoL is the other way around. Example: We want to pass WoL traffic between 10.0.0.0/24 and 10.0.1.0/24, which are separated only by a router. So the computer sending the WoL packet is 10.0.0.1, router is 10.0.0.254 and target could be any computer in 10.0.1.0/24 (specified in each WoL packet). 

As Khaled said, you can use check_snmp to monitor the printers - you'll need to check the docs for your printers to see what OIDs to check for the things you want to monitor. I expect that most of the things you are looking for will be snmp trap alerts rather than exposed through passive checks (checks initiated from Nagios) - I always struggled to get traps working with Nagios. Alternatively, a lot of printers that support snmp also support email alerts for the same events. That may do all you need without requiring Nagios. Also note that if you want to monitor other printer counters, you may actually want to monitor the print queue on your server if you are using windows print queues. 

Our AD is a basic hub/spoke design. We have a headquarters in London, and remote offices. The remote offices are connected via VPN to HQ. We have 3 domain controllers at HQ, and one in each remote office. We have had Windows 2000, Windows 2003 and Windows 2008 R2 domain controllers in place. Over the years, any automatic configuration put in place by AD itself has been eroded, and we now have a situation where the NTDS settings for each server has been manually set. I see that some remote servers are connected to all 3 of our HQ Domain Controllers, some are connected to 2 and some to only 1. Looking at the connections back from the HQ Domain Controllers, these are similarly variable. Here is a picture of how some offices are setup: 

When I run this on Windows 7, the cmd style windows pops up and asks for the password for DOMAIN\user, but I get the following message: 

You can edit the local hosts file to point specific names to 127.0.0.1 to prevent access. This works because (in most cases) the lookup will check the local hosts file before the DNS servers - and if a value is returned it won't look any further. However, verifying this using nslookup on Windows won't work, as nslookup queries the nameserver (hence the name). You can check using ping on the hostname - ping does a normal lookup. 

My organisation delivers a number of applications via Citrix which on the whole works very well. However, some applications require uploading of files from the users local Windows filesystem. The experience of this is very confusing for users. They do not realise that the file dialog invoked from a Citrix application is showing the Citrix server filesystem, and are understandably confused when they can't find their own documents. Citrix does provide access to the local filesystem through drive mapping - C: becomes "C$ on Client(V:)". However, the My Documents shortcut then goes to the user folder on the server. How have other people tackled this problem? Is there anyway to automatically map the My Documents link in the Citrix file dialog to %CSIDL_MYDOCUMENTS% on the client computer so the users don't have to navigate through this foreign looking file system? We are using Citrix Presentation Server 4.5, but happy to hear about solutions that work on more recent versions since others may face the same challenge. As if that wasn't fun enough, some of our users are on Macs. The C$ on Client mapping actually maps through to the root of the Mac filesystem, so it isn't a lost cause. Has anyone done anything smart for Mac clients in regard to this? 

We have an ongoing problem where staff book meeting rooms for recurring meetings, but set no end date for the recurrence. Eventually the member of staff leaves, and the meetings no longer happen, but the rooms remain booked until someone realises this has happened and we manually clean it up. Is there a way to prevent open ended appointment recurrence, or otherwise manage this better? We use Exchange 2003. 

I found a blog post detailing this problem and how someone resolved it. Don't know how this will affect log analysis, but noting it here as I found it useful. 

I've long been thinking of using something like Subversion with TortoiseSVN as the client for document management. Provides version control with commenting, through an Explorer interface. Doesn't quite fit as a centralised document management, as the model involves each client downloading all the documents they would work on to their machine, then checking in from there (Sharepoint works in a similar way, but on a file level rather than repo/folder level - hidden from the user by using temp folders). Handling for binaries like Word Docs wouldn't be great, but then again, Sharepoint doesn't do anything special here either. Simple, well tested, but not quite there. Seems like a great opportunity for development though. 

I have a situation where computers in some of our remote offices from time to time lose the ability to use our DNS server (in head office) to resolve hostnames. The offices are connected via VPN using Cisco ASA 5505 (VPNclient config rather than Site to Site) connecting back to an ASA 5510 at head office. Ping to the IP address of the DNS server works. But nslookup will get a "no response from server" message. Computers in other locations can use DNS fine. This is an intermittent problem. One day/hour it works, another it doesn't. Other offices connected in the same way work when another doesn't. No config changes have been made on routers around the time we see the problem. The DNS server that drops out for the clients is on our private address space in the 172.16.0.0/12 network. The ASA 5505s and the clients behind them are each in a 10.6.x.0/24 private address space. Each ASA 5505 has its DHCP server configured to assign addresses and DNS config to clients behind them -these are generally Windows XP clients, with a growing number of Windows 7. The primary DNS is our one in the 172.16.0.0/12 space, the secondary is 8.8.8.8 to allow access to the internet in case the VPN tunnel drops for any reason. Some users have reported that the problem goes away after doing a repair connection in Windows XP. I think this could be caused by the DNS cache being flushed as part of this - the Windows DNS cache makes the intermittent problem look less so because it caches failed lookups as well as successful ones. However, it is possible some other aspect of Windows is involved. Windows 7 clients have also had the same problem. Any pointers on deeper troubleshooting, or anyone else found this? 

The DHCP Client FQDN option (option 81) allows the client to send it's FQDN to the DHCP server, and the DHCP server can be configured to register this with DNS. This gives a mapping between IP address and Hostname independent of the DHCP server - so you could then use reverse DNS to get the hostnames from the IP addresses. 

It seems a lot of people out there don't realise the important difference between IP protocols and TCP/UDP ports. The following packet captures focussed on the above types of traffic. These were set up on both the remote and HQ ASAs: 

The checks don't report the percentage of space remaining, but the percentage of space used. A close look at the screen shot above shows what is returned by the checks. Most Nagios checks return critical or warning results when something goes over a figure rather than under. It is a bit confusing. So you need to change your critical and warning levels to 80 and 95 or 90. E.g. 

Not sure exacrtly what you mean by "setting the share permissions removed the local folder permissions for the IIS user" (did the permission disappear, or just not get applied as expected?), but you should understand that Windows applies the most restrictive permission of the NTFS and Share permissions set on the object. Perhaps this explains what you experienced. The Microsoft Technet article on Share and NTFS permissions in Windows 2008 suggests: 

What am I missing here? The same account can log in to other Windows Server 2008 R2 Domain Controllers fine. Update: found this technet article which discusses various error messages to do with login and why they appear. Looking at the settings for RDP-Listener I see that there is a local group called Remote Desktop Users on the server, but the domain group is not listed. A local Administrators group still exists too. On other Domain Controllers the Domain version of the group is listed. 

I've just installed and configured monit according to the monit documentation. All services apart from Apache are listed as Running, but Apache says Not Monitored. The relevant lines in monit's config are: 

Whether or not the hardware will run all that, running production systems on a single virtualisation system alongside test and development systems which are going to be powered up and down fairly sporadically sounds like a bad idea to me. 

I am designing our vSphere farm - we'll be migrating from ESX 3.5 to 4.1. I plan to set up a new farm using ESXi 4.1, and move the Virtual Machines on the 3.5 farm into it by shutdown, then import. In ESX 3.5 there is no distributed networking, so each host has a vSwitch connected to my SAN NICs, and a port group for the vmkernel. In vSphere (ESXi 4.1) I have the extra option to set up a distributed vSwitch and distributed port groups for vmkernel to access iSCSI storage. Is there any benefit to this, or should I stick to non-distributed networking for iSCSI. 

Every so often we encounter a problem where we cannot get an IPSEC VPN tunnel to work. Sometimes we know the local authorities restrict use of IPSEC (e.g. Bangladesh), and have to get some kind of exemption. Other times the ISP changes something and the connection drops (e.g. Haiti). I assume there are a bunch of things that might prevent IPSEC from working. For example, blocking UDP port 500 would prevent IKE. Rather than looking for a resolution for a specific problem, can anyone give a list of what different things an ISP might do to block IPSEC traffic, either on purpose or by accident? The answer to this question will be useful in troubleshooting, but also letting ISPs know what specific things they need to fix when we can't get our VPN up! 

Have you tried doing an nslookup for the fqdn from your own computer? Just because the primary name server are working doesn't mean your DNS lookups to a different server are returning the correct details. Remember also that your computer will check hosts file for a domain name, then the first DNS server in your settings. If the first DNS server returns ANY kind of response, including that it couldn't find a record, then the DNS lookups stop. Eliminate any DNS causes for the problem, and if that doesn't show any issues, check the web server is handling the hostname in the request properly - but if you didn't change anything I'd say 99% chance it is DNS issue.