Welcome to the site! As you have mentioned that you are an Instructor of Statistics I think you can directly start with different methodologies/techniques available. As @Emre has suggested it would be better if you can work on different project available on Kaggle, Analytics Vidya. You would be exposed to most of the necessary things in Data Science field. Following R-Bloggers, will expose you to the latest packages. Ofcourse following Data Science Exchange. You can doing small projects on different datasets on UCI. For experimenting using different techniques. These are just couple of things which would help you to be updated. Follow them for atlest next 2-3 months then you can access yourself. 

Procedure-1 : I think it would be better if you can try combining some geners, it is most likely that some follow similar trend, once you identify them try combining them. You can use some Dimensionality reduction, then you can make more sense out of the data, as of now even if you give directly also it might take time for the model to understand and give some useful results. Once you get the outcome of Dimensionality reduction you can directly apply multi class classification algorithms like SVM, RF and many more. Procedure-2: Another thing which you can try is, You can concatenate all the features(Gener's) into 1 single feature and try try understanding and see if does makes any sense/ get some good insights(Exploratory Analysis). Do let me know if you have questions. SVM : Support Vector Machine RF : Random Forest 

I don't think you need some classification algorithm, you can use your basic understanding on data/ Business Knowledge to do the classification. As the number of data points are too low, the model cannot give you good/generalised results. Even if you try applying some complex algorithm like SVM/NN, it is of no use as the data is too low. If you still want to apply some machine learning algorithm and then you can apply Naive Bayes, Decision Tree as these are the basic algorithms, can do the job. 

you are getting some result but I'm not sure if this is what you are looking for. Let me know if you need any clarifications. 

It means your model could predict 100+300 correctly out of 100+150+100+300 Actual number of males where 250 but you could classify 100 correctly and 50 wrongly. Similarly, Actual number of females where 400 but you could classify 300 correctly and 100 wrongly. If you any need more detail let me know. Go through this Link, you will get better idea. This Link is an interactive chart, which will give you better understanding. 

There is package named Boruta in R/Python. This is also called as predictor importance test. Used to pick the important variable. Uses of this package: Boruta is a feature selection algorithm. Precisely, it works as a wrapper algorithm around Random Forest. This package derive its name from a demon in Slavic mythology who dwelled in pine forests. We know that feature selection is a crucial step in predictive modeling. This technique achieves supreme importance when a data set comprised of several variables is given for model building. Boruta can be your algorithm of choice to deal with such data sets. Particularly when one is interested in understanding the mechanisms related to the variable of interest, rather than just building a black box predictive model with good prediction accuracy. The outcome would be a box whisker plot with their importance with the target variable. You need not worry about categorical and continuous variables. you just need to cast them correctly before passing the data to the algorithm. You can go through this Link for better understanding on the package and implementation of the same. This is the sample plot: 

As we were discussing above regarding the correlation, yes it is very important factor which would play an important role in selecting the features which are useful in explaining the Target Variable. The RFE works like this, it would take all the features which ever are significant is explaining the Target Variable, if you take these 2 features separately and do the check then obviously they both are shown as significant features. Before going to that step as you have done Correlation analysis and you should have eliminated one of the variable before giving to the model. The outcome of RFE is also correct as it was treating all the features independently. Now you need to remove the features which are strongly correlated because if two features explain the same thing then the model would be biased towards those features and you might end-up getting Wrong Insights. So, strongly correlated features are highly recommended to be eliminated before doing RFE. 

Based on the explanation you gave I think you are talking about k-fold Cross validation. Assuming it as k-fold cross validation then you need to take mean of all the error rates. And the mean outcome would be your final error rate. 

Yes, you can do that by add them to the existing NLTK Stop-word dictionary for all such words/Creating a Custom Stop-word dictionary. for Custom Stop-word dictionary you need to include all the key words in the dictionary before processing, make sure to check if the words are present in the stop-word dictionary. If yes, remove them from the text else nothing needs to be done. 

Welcome to the site! I think Ensemble Method is very tricky. when one of the model doesn't work well then the accuracy of the Ensemble also goes down. For instance let us consider that you are using RandomForest(RF) and Rpart for classification and RF accuracy is 90% and Rpart accuracy is 60%. If you ensemble these 2 models then the Ensemble accuracy goes down. Coming to your scenario, you need to be very careful at the time of stacking, you need to select the models that are performing moderately and then stack them to improve the accuracy. How is the distribution of 0/1's, if they are imbalanced then you need to balance to improve the accuracy of the model. To handle imbalance data situation we use packages like SMOTE,ROSE etc. Feature Engineering like adding external factors or adding new features, might help you to improve your models accuracy. Do let me know if you have any additional questions. 

Here you need to do more exploration on data, so that you find some unique feature which helps us in understanding why that record has been classified into that particular cluster/segment(on training data). You need to balance the data so that the model can understand and can predict accordingly. As @David has mentioned above such situation can be played around by giving weight-age to the classes and so on. Do let me know if you have any additional questions. 

To answer this I think you need to derive AIC and BIC values and finally you can decide on which model to choose. To derive the AIC value for Linear Regression can be done by using OLS, as the value of AIC is directly available. If you want to derive, you can go through this Link AIC: $AIC= 2k - 2ln(sse)$ where k= number of variables BIC: $BIC = n * ln(sse/n) + k * ln(n)$ Do let me know if have any additional questions. 

Welcome to the site! Firstly, when we use any kind of predicting algorithm, then you need to have the future values of the independent variables(features for explaining the target variable), for Prediction. Secondly, If you don't have such values then you cannot use predicting algorithms, we have forecasting algorithms to do such task. To apply this you need to have data which is time series data. From the sample and graph I think your data is time series data. FYI, you can also use additional features even in time series. For Feature Engineering on Time Series data you can go through the link. If you need any additional information let me know. 

$-x_1 + x_2 ⩽ 1 $ for the coefficient of $x_1,x_2$ are -1 and 1. The values of Matrix A row 1 values are -1,1 Similarly for row 2 to row 4 as you have 4 contraints. 

Rest are not so important at the start, you can conduct another session if necessary based on the outcome of the 1st session. Where you can cover all the topics like Linear Algebra (advanced), Vector calculus, Optimization techniques, Maximum likelihood methods. As you know these techniques would come into play after getting the basic models ready and you would use these if you want to improve the accuracy of the model or tweaking the model WRT to your Business Problem. I hope this answer may help you. 

Let me know if you have any doubt, would help you. If you got what you are looking for, you can accept the answer by clicking on the green tick mark. 

Match users to people with similar tastes –recommend what they like Commonly used in e-retail Avoids the issue of users only being recommended more of what they already like (allows serendipity) 

Important thing to remember is, Logistic regression works by converting Categorical variable to dummies before applying model, because of this it is unable to return you anything.Since you have more Categorical variables in your data I would suggest you not use Logistic Regression. To get Predictor Importance(Important Independent Variables), you can use a Package in R called Boruta, this link has the implementation in R. Once you get important variables then you can apply Random Forest, Decision Trees(Rpart) and see how they perform. Let me know if you have any issues. 

Under Ensemble you can use Majority Votes, Average, Weights etc to get the final outcome from Ensemble model. To understand it better you can go through this Link, explained well by Alexander. Now, let us consider that you have 3 models which has an accuracy of 65-70%. Now by stacking these 3 models there is very high chance that you models accuracy would increase. In another scenario you have 3 models model-1: 95%, model-2: 55%, model-3: 45% accuracy, then if you stack them then there is a very good chance it can worsen the result. Conclusion, it all depends on the individual models performance, Ensemble performs well when you combine moderately performing models. Technically there is no proof saying that this method is suitable for this scenario but trail and error might help you to get good results. It is subjective to the business scenario. Similarly, for bagging and boosting. In my experience with Bagging when the model accuracy is bad, I tried using bagging to fit the data better but EOD training accuracy(20% to 10% approx) was decreased but test accuracy was worsened(11% to 20% approx). So, you have to decide which suits your business problem better and take it forward. 

I think you need to do couple of tests to see what all variables are important with respect to your Target Variable(client can be insured: Yes/No) - this kind of test is called Predictor Importance test. As you you have mentioned this is sector is new for you, I would suggest you to take all the variable you think are useful. Convert categorical variables to factors using numeric variable to numeric as . The reason for explicit transformation is sometimes algorithms cannot understand like: 

You can use ANOVA in this case to get the relation between different features(categorical variables) within them and with respect to the target variable. If you want to check the feature importance with respect to target variable then you can this package Boruta in R, implementable in python too. If you want to know more, which test when can you use it, go through this link Do let me know if you have any doubts! 

I think you need to do some Feature Engineering, i.e., as you explained in the question, those values mean something to your application. For example : 1-3 : Bad, 4-6 : Average, 7-10 : Good 

Example: Your Scenario. Methods: Euclidean Distance, Cosine Distance, Pearson Correlation Coefficient (most common). Content-Based Recommendation: 

The outcome of Feature Selection would be the same features which explain the most with respect to the target variable but the outcome of the Dimensionality Reduction might or might not be the same features as these are derived from the given input. 

Before doing my master in Analytics, I was suggested by my seniors to go through these couple of books to know more about Machine Learning and Statistics. Namely: