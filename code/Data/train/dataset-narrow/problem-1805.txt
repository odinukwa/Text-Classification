A2: This depends on what you want. If there are only two or three of you working together - then there really isn't much reason why sharing an account would be a problem. On a side note, depending on who you are working with and your trust level with these folks, you really want the ssh/sftp account that you are all sharing to NOT be a root/administrative user. 

You can delegate control of IIS sites and applications to users, much like you can delegate rights to objects in Active Directory. See the link for instructions. A few more links to help out: $URL$ $URL$ $URL$ $URL$ 

You may want to ditch DHCP on the wireless router and use the Windows DHCP Server. It's a bit more robust than your average wireless router (though, I don't know what you have so that may or may not be true). Either way, there are two things you may be missing that is preventing users on the domain from accessing the internet: a default gateway, and dns servers. In your DHCP server, make sure you are passing out a default gateway with the address of your wireless router, and also the address of whatever is serving DNS for you. If it's your domain controller, then hand out that address. If it's your wireless router, then hand that address instead. You can check what these values are on your desktops by doing an ipconfig /all command from the command line. If you are missing one or either, or they are pointed to the wrong place, the "internet" won't work as expected. Look for Default Gateway and DNS Servers ip addresses. It should look something like this (this is a Windows 7 snapshot on my LAN): 

Longer answer: the disk file system (ext4) appears to have reached some unstable state when the disk's snapshot had originally been created. When later the original snapshot of 200GB had been extended (using ) to 1TB, it appears that in some sense it kept remembering internally the original size of 200GB, creating all sorts of weird phenomena which ended up with the OS unable to close handles, thus making the Tomcat reach its file limit, thus having all hell break loose. 

Some pointers and clues that I've gathered: The setup is CentOS 6.5 running under AWS with the said tomcat disk mounted from an EBS volume. Running shows that the disk is evidently not full: 

In fact, I get the same error under multiple different folders that reside under , but not under directly, and not - for example - under . I can't explain it for the life of me, and can only resolve using . Any suggestions on how to fix the issue and be able to again without restart? 

Running returns (62M), which could reach some OS limit; on a similar healthy system it's more like 1800000 (1.8M). The hugely occupied subfolder appears to be (~62M items compared to ~1.7M on the healthy system). This is likely just a reflection of my 100K fds (x2, for both fds and fdinfos) over 300 individual "task" folders. This appears at the end of my dmesg dump (my java pid in this example is 105940) - not sure how this might relate: 

Now, this didn't catch our attention before, because the disk still has plenty of space left. But it was the exact same disk usage (197G) on both setups, and that has no reason to happen. From here things quickly unfolded. As mentioned before, our AWS instances had been created from an image that has a disk snapshot of 200GB, which is extended on individual instances using - usually to the maximum size of 1TB. We were finally able to recreate a "bad state" by launching a new instance, resizing to 1TB, and creating a big file of 300GB. When this was done, the system didn't freeze, but it did show the same strange behavior: 

72.165.117.130 is one of our private (MPLS) WAN addresses that routes to 63.145.168.58. I'm trying to forward traffic sent to that address to an internal device at 10.0.1.40. Is that all there is to creating a one-to-one NAT, or am I missing something? 

I'm trying to gather a list of all e-mail addresses being used by our Exchange 2003 system, which includes not only the normal user addresses, but distribution groups and aliases as well. I also need the output formatted like: user@domain.com - although, we only have one domain, so even if I can get the user part, that would work. I don't care about account-association here, I really just need a list of addresses. How can I go about doing an export of all smtp e-mail addresses from Exchange 2003, including distribution group and alias addresses in the user@domain.com format? I would prefer something that can be accomplished via the command line so that it can be generated by a script, but it would be just as useful if there is a way to do this manually (read: point and click) as well. Any ideas? I don't see anything within System Manager that can do this, and my searching isn't turning up anything that can fulfill all the above requirements. Solved This is how I'm using the accepted answer: 

However, when trying to e-mail these addresses, I get a local "NDR" telling me that the mail account doesn't exist. I've used aliasing extensively (just never for this reason) to provide additional e-mail addresses for employees (such as when they get married and change names, or need temporary mail addresses, etc.), so this is not new to me. However, I don't understand why this isn't working. Is it because these addresses used to be associated with an Active Directory account and Exchange has yet to purge them from the GAL? The old accounts are still showing in the current GAL, but if I look in System Manager > Recipients > All Global Address Lists > Default Global Address List > Properties > Preview, the two accounts in question do not show up. Do I just have to wait until the next update interval? Is there a way to force this update to happen? Update: Upon further research, I'm able to send these e-mails while using a client that isn't running in cached mode, and they end up being sent to the primary address for the account they are assigned to. Trying to send to these former addresses while using cached mode results in the message being rejected. Pretty positive this has something to do with the GAL on these cached mode clients. The clients we are using are Outlook 2003, 2007 and 2010 and it is policy to use cached mode on all Outlook clients. 

The question: I have a tomcat running a java application that occasionally accumulates socket handles and reaches the ulimit we configured (both soft and hard) for max-open-files, which is 100K. When this happens, the java appears to still be alive, but we can no longer access it. However my question is about a bizarre phenomenon that accompanies this situation: I cannot inside the tomcat folder. 

I would be happy to share/provide any other suggested findings. Secretly I hope that understanding this weird behavior would shed light on the pathology causing this whole mess. But, that's just my private hope :) 

And that when there was clearly more than 197GB of data on the disk. So, we tried out the two methods mentioned above (chkdsk and recreating the disk) on two individual clean setups, and on each of those the weird behavior would no longer appear. Our best guess is that at some point, when the AMI was created, something went wrong in the snapshot process - most likely because we had taken a "snapshot without restart" (though we don't usually, and I have no evidence to back this up, so I hope our DevOps don't go mad at me for blaming her without cause!). All in all, an interesting experience. 

Longest answer, with a bit more of the detective work details: the breakthrough happened when we had this pathology occur in parallel on two separate setups. Checking out all the parameters on those setups and comparing, we realized that on the drive was showing this result: 

I am running into the following Linux error: . This seems to be caused by the system limit of 8 maximum link-chain size, and I'm looking for a way to increase this limit. Some background: I am writing a system which makes use of symlinks to pass on file resources between working elements. This results in long chains of symlinks (e.g. ). I am creating a chain intentionally, as I'm interested in preserving this structure of who-provided what. It should be noted that this system is physically disconnected from the outside world, so I have practically no concerns for security or exploit prevention. All help would be greatly appreciated! 

FTP data (including login credentials) is transmitted in plain text, which is why it is so insecure. You definitely want to start making a habit of using SFTP as your data would be encrypted then. 

Our Exchange server is running on the . We're dealing with the mail store size issue, where if the mail store goes over the limit, it gets dismounted. While we are working with the powers-that-be on a policy that will prevent this happening in the future, I would like to see if it is possible to re-mount the mail store via the Windows CLI. I'm already monitoring the Event Logs and alerting on mail store warnings and dismounts - I'm just tired of getting up at 5am to manually re-mount the store while the political wars ensue. My alerting tools have the ability to execute a batch script when an alert is generated. I would greatly prefer a native CLI option. I'm not too keen on running some random vbscript found on the Internet and I don't really care to spend my time debugging someone else's code. PowerShell might be an option, if it can be triggered from the CLI. 

A1: Media Temple offers a way to create multiple users with access to SSH/SFTP in their "shared" hosting plan - they call it the Grid. $URL$ 

I know you already accepted an answer, but I hate Putty and there IS another tool out there for Windows users. A lot of people say Putty is the best - probably because it's the only tool they know about for Windows clients. I thought it was the only option as well until I found Poderosa. It offers multiple panes/sessions per window, multiple tabs, simple font/color customizations, background images/colors - and probably a few more things I haven't found yet. It's the only tool I use now for telnet/ssh/console(serial) terminal shell sessions. It might be what you're looking for.