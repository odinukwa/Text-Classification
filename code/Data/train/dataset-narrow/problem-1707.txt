I am curious to see what other third party tools people are using to administer Windows AD. My own research has found Quest and NetIQ seem to be front runners. Any others? Any experience or Pro/Con list of why NetIQ or Quest makes good/bad tools? I am specifically looking for tools to manage users and create reports for things like SOX/PCI and various inane management requests ("Can you tell me all the phone numbers for users with the letter Z in their name") 

Short of a tool like SCCM you are not going to be able to discover an exact listing of machines on the network. First task will be finding the hosts: 

All, we are working creating a shared secret library in Sharepoint. basically the idea being, a user fills out a "Shared Secret" infopath form (AKA "What is your highschool mascot") and then that form is sent to a secure library that only the helpdesk can read. Currently it looks like our sharepoint admin doesn't know how to create a secured library. Has anyone done anything similar in sharepoint? Or does anyone know of some good tutorials for creating something like this? 

I am not sure about the CPU monitoring, but you should also look at getting environmental monitoring in whatever space you are putting this server. It will allow you to have a better idea of what is going on in the space, and have more checks other than just CPU temp $URL$ 

Get the Serial number for the server, find the manual online and see what the beeping could indicate. Look to see if there is a LED panel. Usually beepings are with LED alerts. Or any Hard Drives have Lights. 

I am trying to create a template in ESX that I can automate with PowerCLI. Everything works great so far, but because I have some specific settings, I had to create my own sysprep.inf. Now, the computername and the VM guest name are out of synch. I need to automate this for a sandbox enviornment, so I will constantly be deleting and rebuilding boxes. Thus, I need the VMhost name and the computername to be the same. Am I missing something? 

In the graphic Xen Server and the VM DRBD/NFS server is hosted on an internal USB flash drive. Hard drives are a local MDRAID10 array. The other VMs would be stored on a storage repo via NFS on a DRBD via a VDI attached as a block device on the MDRAID array. VMS are typically Debian. We DO NOT have a dedicated shared storage device (NAS, SAN, etc.). If performance is not a concern (5-10 low use users for sporadic web access to a company site from the field), will there be stability concerns based on the data path being a storage repository served by another storage repository via NFS on DRBD. TL;DR In lieu of dual SANs with supporting networking, we are trying to use DRBD on two servers with local storage to allow for easy manual failover during an outage on the primary server. During an outage the secondary server would become the primary and the VMs could (theoretically) be instantly be fired up with very little configuration. The servers are same RAM and CPU generations even. Xen seems to have its quirks and I forsee Xen Server having a problem that wipes out the entire server until it gets "fixed" given Xen is running EVERYTHING. I doubt we would have permanent data loss, but storage repositories disappearing happens more often than I would think based on the reading; and unless all your disaster recovery ducks are in a perfect little row, it could take a bit of time to bring things back up correctly if we had to reinstall Xen from scratch while carefully filling in the holes we were missing in our documentation as we went. With DRBD thought, in the event of a problem we could be running on our backup server very quickly with active file and VM mirrors. Then worst case we could easily just start from scratch on the primary server if need be and not have to worry about "fixing" anything. What is not shown are a couple more VMS to serve files, but the data would be housed on another SR, so only the VM data itself which is rather static would be served by the same path depicted in the graphic. 

Also, if you need more flexibility, think of putting a bash script in between nagios and you. This can let you send out messages with greater flexibility, for example you don't want recovery emails sent to your automated ticket creator. 

If you can use a startup script in a GPO this is easy If not, then if you are not too skillful with scripting, I would do a laymans approach. First use a tool like angryIP to get a listing of all of the windows desktops you want to modify the tool with 

My network Admin asked me if I had heard of any opensource competitor to Ciscoworks and Solarwinds for Network Administration/Management. We have a full implementation of Cacti and Nagios for monitoring, but I haven't really delved much into the realm of Cisco/Checkpoint/HP procurve management. Anyone use anything that fits the bill? 

If you have the GPO, I would just write a batch file that has something like If you don't have a GPO, look at PStools (specifically PSexec). Copy the hostnames discovered with angryIP into a hostfile and then use psexec to run the command with the hostname file as the array it would look something like this psexec @hostfile "echo 192.168.0.2 hostname > %systemroot%\system32\drivers\etc\hosts" 

Ok, So I have been doing more research and I think that the Microsoft tool SQLIO is going to be what will give the most info for my needs. I am going to start this tonight and let everyone know how it goes as far as usefulness. I found a fairly good tutorial online tha tI am going to follow. If anyone else has any ideas, please let me know! 

Not sure what your budget is, but globalscape works pretty well. It also allows for upload/download via a web interface OR using a client. 

Length of System Up Time If you want to find out how long the system has been online you can do this (this is also an alternate code style): 

Exchange servers were designed to be constrained endpoints. The session configuration is a bare bones configuration schema with limited exposed methods. As Exchange servers are exposed to the outside world the designers are obsessed with security. The command you're trying to use is trivial in your existing context as you specified the environment you wanted with your instantiation. It is strongly recommended that you work within the existing session configuration (for remote) or run code locally for access to all methods. However, if your risk tolerance affords it you can create a custom session configuration schema using information you find here. 

If the array count is short eyeball the provider names. Microsoft didn't use a standard naming convention so you can forget filtering with something useful like "MSProvider". 3rd parties were advised and asked, yet not required, to create their providers for their own namespaces. Anything not in "CIMV2" should stand out and be looked at more closely. For reference you can review how 3rd parties register a WMI provider and what information is required when doing so here. The objects returned by the code above have a CLSID property which corresponds to their entry in the Windows registry. You could loop through them and query the registry and see if a 3rd party added any values to the key you could use to identify them with. Happy hunting. 

I think there's more than one way to tackle your problem, at least from what I see as the cause. Here's how I'd do it: 

You'll need to ensure your Linux servers are CIM enabled and then use the CIM powershell cmdlets to interact with the Linux server remotely. You can read more about it here: CIM Cmdlets for Non-Windows OS If you're new to CIM, as in this is the first you've heard of it, you'll want to familiarize yourself with what CIM is and how it works. Then attempt to try the CIM cmdlets. 

This question really depends upon the individuality of your hosts. If you can get all of our hosts to a nice little standard, you can really work some magic with templates. Personally I find that it works for only the very basics (for example, Mem/Proc/Services on windows) Then it starts getting harder (one server has a File system that needs to have alerts sent to a production support group for space size violations, but it also has other File Systems that need to go to the development support group. And oh by the way, this server has unique drives because it was bought on a golf and shop trip by your boss) Personally I used a combination of Nagios 2.0 and 3.0, with a mix of Host groups. I separate hosts out into OS grouped configs (windows with windows, Solaris with Solaris, Linux with Linux). Then I break out the core checks into a core_checks.cfg (Memory, Processor, essential process checks) then I break the services that I monitor down into different config files (Oracle Database checks, My Sql Datbase checks, Very Specific File system checks, Website checks). This lets me have my config files organized logically for myself and anyone who comes after me. Note I do have 4400 checks these days so this might be overkill for other people. In the long run, I have a structure something like this nagios\etc\core_checks.cfg nagios\etc\hosts\windows_servers.cfg,solaris_servers.cfg nagios\etc\services\oracle_databases.cfg,MSSQL_databases.cfg 

Agree with everything above. The only thing I would make sure to look at is checking to see if you somehow enabled SSL on the check (that will cause havoc) or visa versa, if you are requiring SSL that it is enabled. And as previously mentioned, review the local config (nsclient.ini or nrpe.cfg) and find out what port you are trying to connect to. Then run a telnet from a remote machine and see if you are able to get to it. 

Virtualizing will help with your needs tremndously. We have a small business and virtualizing allows us to consolidate hardware, increase segregation of services to help with security, and helps with uptime because we can migrate VMs between hosts (hypervisors) very easily; something that is very difficult with baremetal. We use dated enterprise hardware in pairs with backup parts kept on site (fans, drives, etc) but have both a primary and secondary host; Our host runs VMs serving DRBD, Apache, MYSQL, Samba, NFS, Reslio Sync, Dropbox, etc. We let our host manage RAID arrays using MDADM. Utilizing DRBD the VMs are kept in sync on a backup server so downtime is almost a non-issue even with a catastrophic hardware failure on the primary host. But being a small business it simplifies hardware management, allows us to run less hardware which has far reaching implications on budget and IT resources, and consolidates the management of our services because it is natural to administer all the VMs from a single console on a workstation; for us through Xen Center as we use XenServer. Further it allows us to segregate things so things like cloud services can be virtually segregated from internal services providing a high degree of security. For example we serve two separate cloud file services in two separate VMs; one for field personel accessible via mobile devices and one for office personel accessible via the internal network. As a note, our backup server (not secondary host) is not virtualized purposefully so we have baremetal access to our files in case of a software or configuration failure with our host. That is if our host corrupts our VMs or data stores somehow we have baremetal access to the files and VMs still. In the end we can provide our company with enterprise grade file, backup, web, cloud, and other services all in house for minimal cost and maximum uptime. It also allows us to expand as we can integrate other services; planned in the near future are VPN services for remote book keepers and Android form services for field personel that needs a windows software intermediary to interface with MySql. Without virutalizing we would need to buy, run, and administer more hardware; virtualizing has eliminated the problem of hardware all together when adding such services and we can simply focus on integration of the software/service which can be daunting enough. 

DHCP Server Not Offering to PXE Client BACKGROUND: I'm in the process of adding PXE services to an existing SCCM 2007 server. The SCCM server is separate from the DHCP server (Server 2008 x86) and did not have PXE services or WDS installed. I added PXE services in the Config Manager before adding WDS as a role. Because DHCP is on a separate server, I did not make any changes to DHCP Options (there is not a current 60, 66, or 67 configured). The WDS is configured with both a boot image (ripped from the Win7 install dvd and an install image which was created by someone else). SCCM has a TS configured and advertised to the Unknown Computers collection. The DHCP server is configured for both DHCP and BOOTP requests (I added BOOTP as part of my troubleshooting, the default lease time is set to 5 minutes). It also has NAP enabled for the IPV4 addresses but disabled for this SCOPE. My host, the VM, the DHCP server, and the SCCM/WDS server are all on the same subnet. Juniper routers move the packets. I'm testing PXE using a VirtualBox machine configured to network boot and it has an empty dynamically allocated disk attached. Wireshark is installed on both my host computer (running VirtualBox) and the DHCP server. PROBLEM: When the VM starts it performs a network PXE boot. I can see the discover request by the VM in Wireshark on both my host and the DHCP server. However, the DHCP server is not responding with an IP offer. If I could get some guidance as to where else to look for an error, or possibilities as to why it's not working, I'd appreciate it. EDIT: The dhcpsrvlog does not record an event regarding the request for an IP from the pxe client.