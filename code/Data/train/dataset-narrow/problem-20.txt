What is Value Stream Mapping A Value Stream Map is a representation of the flow of work, inventory and information from supplier to the customer through your organization. The VSM enables you to see at a glance where the delays are in your process, any constraints and excessive work or inventory. For IT organizations, one common notation is that inventory is a number of tasks in the backlog. Joel Spolsky wrote an amazing article that explains and expands on this this concept. Usually a VSM is a graphical chart that includes: 

You can imagine that the relationship between these two functional areas was not exactly lovey-dovey. These cross-functional conflicts are driven by the silo approach, where the organization measures each silo in improvement independently. If you are a cost center, improvement naturally means greater efficiency or cost reduction within your silo. In this frame of reference, costs are seen as obeying the "additive" rule. The costs of each silo added together, equal the total cost of the organization. Therefore, managers see any cost reduction in their area as "good," since they see a direct translation to cost savings for the company as a whole. In this frame of reference, improvement efforts are spread everywhere to attack cost and waste throughout the organization. A great example when the development team/s start working Agile and pushing code to QA and Operations every two weeks instead of every quarter like they used to. The QA and Operations are not ready for such a change and are blamed for slacking off. Again, does not contribute to much love between the people in development and operations. 

Centralized - non-restrictive, allows everyone to shoot anyone to "break the build" by pushing changes, least overhead and process involved. The advantage is a continuous integration of changes, even when those don't work. Feature branch - allows anyone to add changes by adding some overhead process, but integration into main collaborative work is a controlled process. Has the disadvantage of integrating changes late, when requests to merge are forgotten or not attended. Gitflow - huge overhead in managing the various branches, causes a lot of confusion for regular people who just want to get their changes into the branch. Can work well when most developers only see the "feature branch" part of this. Merging between the development and stable branches often happens late, and integration is not trivial. Adds a lot of extra overhead and terminology that everyone must understand well. Forking - the wild west, requires a server that supports managing multiple repositories and repositories per-user (GitHub, GitLab, BitBucket Server, etc...). Allows most freedom for each contributor to do whatever he wants, but does not force integration. Demands that integration is done piecemeal in small bits and very controlled, usually by using pull requests across repositories. Works well in unorganized teams such as OSS project contributors. 

source: $URL$ Back in the day, complex programming projects would mean big monolith systems. And Brooks claims that these cannot be perfectly partitioned into discrete tasks that can be worked on without communication between developers and without establishing a set of complex interrelationships between tasks and the people performing them. This is very much true in highly cohesive software monoliths. No matter how much decoupling is done, still the big monolith mandates time required for the new programmers to learn about the monolith. And increased communication overhead which will consume an ever increasing quantity of the time available. But does it really have to be this way? Do we have to write monoliths and keep communication channels to where is the number of developers? We know there are companies where thousands of developers are working on big projects ... and it does work. So there must be something that changed since 1975. 

Some great books are talking about the subject, and it would not be a good answer without mentioning them: 

The tool, released by Netflix might be restricted to AWS at this time. But the approach is definitely not restricted and can be implemented anywhere where there are distributed systems comprised of a multitude of redundant parts, hopefully with automated healing ability. 

You are already building and testing code on each of the pull-request and hot-fix branches. This means that in aggregate, the sum of all branches pending on pull-request are your virtual branch. You can create a system when in a test environment, several pull-requests are cherry picked into a temporary branch that is not published to the main repository. This branch is used to integrate a test environment that includes and several additional pull-requests, but once the testing is done, this branch is no longer available anywhere. When you create a release from , you would usually create a tag on that release. Later hotfixes can use that tag to create a new hotfix branch from which a deployment will be made, even though the edge of is already ahead. On this hotfix branch you would probably also tag a minor release, and make sure that the changes were merged into . Removing merged features from a release is quite hard to do with git. The best mechanism for this would be to use on the merge commit. But that makes it almost impossible to get these features/changes back, and history becomes all muddled. A much better way to handle separation for deployment of code, and release of features, is feature flags. If your developers can hide their features behind some conditions in the code itself, you could deploy their code, but turn off the feature. This is a separate topic, but a lot of information about this exists (including a Q&A on devops.SE). 

Implications of Westrum model to clinical practice, most of which apply directly to IT organizations: 

These two presentations show all the things that Amazon did to decrease the time it takes them to deploy code to production. According to Gene, the only thing that is changed across time in these high-performing organizations is the number of developers. So from the Amazon example, you could say that in four years they increased their deployments ten times just by adding more people. 

Let us define a constraint as anything that prevents the system from achieving its goal and then look at the goal of DevOps in an organization. A good definition is "DevOps enables a fast flow of features from development to IT operations to the customers." Improving DevOps can be achieved by removing impediments to flow. First, we must find these constraints in the flow. And maybe there are multiple obstacles, how can we decide on which one to remove first? A famous quote from Dr. Eliyahu M. Goldratt is 

A team of IT sysadmins that have exprience using shell scripting to solve their problems, are contemplating to start using Ansible instead. Are there substantial differences and good reasons to start using Ansible vs. to continue writing shell scripts? 

Most probably your user does not have the required permissions to the API. You can check using the IAM Policy Simulator at $URL$ using policy simulator is explained in depth here $URL$ 

The API for creating a function includes a section to choose which VPC to use for running that function. source: $URL$ It doesn't have to be the default VPC, it can be any VPC. Consider that "EC2 server inside a VPC" only means that it is some virtual machine that has a NIC connected to a network you have control over in your AWS account (the VPC). With Lambda, you can choose to run functions on instances that have this NIC connected to a VPC under your control, or you can forego this control and let the Lambdas run where ever they usually do (default system-managed whatever) and just not care about it. 

Most organizations deal with complexity by breaking down their organization info functional parts and demanding that each part figures out how to improve itself. This is often called the "silo" approach. It is important to understand why this silo approach blocks the success of the business and often fails to improve the organization as a whole. And it doesn't affect just development and operations. It affects all the other functional silos within a large organization, quality assurance team, finance, product and project management. As managers of each functional silo are commanded to improve, by cutting cost or increasing speed, their reaction is often: 

So a simple mechanism called feature flag toggles enables much better IT performance, and in turn improves organisational performance overall. Great example of how this is done in real companies can be found at Flickr (on of the earliest public posts on the subject), and at Etsy. But many others have adopted the practice and talked about it in length, for example the famous engineering culture at Spotify videos. Etsy are showing off their internal tool to manage feature flags, called Catapult, in multiple presentations found around the web. And Intuit release an open-source tool called Wasabi that helps manage feature flags. 

I have done this in the past using $URL$ What does it generate a configuration file (for nginx) based on a certain template you provide. And the values that it fills into this template are coming from the configuration stored in . Each time your micro-services register themselves in and need to be addressed in the nginx configuration file, does it for you by changing the file and sending a () to the nginx process that makes it reload nginx configuration. The repository for contains an example of managing $URL$ 

Definitely. Especially when using AWS services, the for JavaScript is superb. Writing code using JavaScript in a shop that has both frontend people writing JS in some framework (Angular/React/Vue/...) and backend people using Node.js removes barriers. Just pushing to use JS provides the org. with even more developers who don't have barriers to reading and fixing infrastructure code. For example, I am quite proficient in using Python, Ruby, Shell, JavaScript (even Perl). But when it comes to fixing or adding something to HashiCorp's tools like Terraform, I just don't have the time to learn Go sufficiently enough - so I don't do it. If a tool like Terraform was written using JavaScript, I would have added my contribution for that missing service a long time ago. JavaScript support is excellent in AWS Lambda as well, and that is quite a big deal. For example, one of the ways to make CloudFormation do things you never thought it could is to write an implemented in a Lambda function. Another good example is streaming CloudWatch Logs into ElasticSearch. If you ever try to press that button you discover that AWS just creates a JavaScript function for you in Lambda. JavaScript is everywhere in DevOps and AWS, doing the same thing with Java, or C# or even Go would take much more time. Should you bring a "DevOps Engineer" in the future (please don't), and that person does not know JavaScript while all your code is the backend and frontend is in JavaScript then simply don't hire such a person. It is a bad fit for both you and them.