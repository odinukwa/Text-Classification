I am experimenting with k-SAT. I'm using an oracle that returns the total number of satisfiable truth assignments, which is in #P. The interest here is that this total is returned modulo a natural number, say N. There is therefore a 1/N probability that the oracle mistakes a satisfiable problem for one with zero satisfiable truth assignments. I'm wondering if this oracle could be non-relativizing. I'm also wondering if there has been research concerning oracles with similar types of "errors". 

I'm wondering what the best method obtained for the Valiant-Vazirani theorem is. We can state the following criteria: (1) First and foremost, has anyone been able to derandomize it? (2) If not, what is the best running time for converting a SAT instances? And how does this method work? Can we somehow do better than the technique mentioned here? (3) Out of curiosity, I'd also like to know the size bounds of the converted SAT formula. The reason I ask is that I'm studying an algorithm that makes use of this, so I'd like to have the best technique available. 

In this case, it's another way of saying that the algorithm runs in time $O(n^{2+o(1)})$; for example $O(n^2 \log^6 n)$ or $O(n^2 2^{\sqrt{\log n}})$ would both qualify. Sometimes there are parameters other than the running time involved in an algorithm, for example quality of an approximation, that depend on $\epsilon$. In such cases, an algorithm may be designed to accept a parameter $\epsilon$ as a part of the input and adjust its performance accordingly. 

The matrix multiplication exponent being $\omega$ does not guarantee that there is an algorithm that runs in time $O(n^\omega)$, but only that for each $\epsilon > 0$, there is an algorithm that runs in $O(n^{\omega+\epsilon})$. Indeed if you can find an algorithm that runs in time $O(n^2 \mathrm{polylog}(n))$, then this shows that $\omega = 2$. You can find the formal definition in the book Algebraic Complexity Theory by Peter Bürgisser, Michael Clausen, Amin Shokrollahi. 

This procedure samples an edge of $H_n$ with some probability distribution. It is possible to show that every edge is sampled with the same probability (this is somewhat annoying to prove, but you could argue this by symmetry). Therefore, this procedure can be thought of as a method of uniformly sampling an edge from $H_n$. We will prove below that for any fixed $v$ and $i$, the probability that a two random vertices from $V(v, i)$ have different colors is always at most $\epsilon_n$. Then if we sample an edge using the above procedure, the conditional probability that the two vertices at the third step have two different colors (given the outcomes of the first two steps) will be at most $\epsilon_n$. We conclude that the unconditional probability is also at most $\epsilon_n$. But then we have that the probability that an edge has two different colors at its endpoints when the edge is chosen uniformly at random is at most $\epsilon_n$. Thus, no coloring can be an $\epsilon$-approximation for any $\epsilon > \epsilon_n$. All that's left is to show that two random vertices from $V(v, i)$ have different colors with probability at most $\epsilon_n$. There are $n$ vertices in $V(v, i)$. If $a$ vertices are colored in one color, then there are $a(n-a)$ pairs with different colors. Thus, the probability of choosing two vertices with different colors is $a(n-a) / {n \choose 2}$. But the closer $a$ gets to $\frac{n}{2}$, the larger $a(n-a)$ gets. In particular, for $n$ even, $a(n-a)$ achieves a maximum value of $n^2/4 = \left(\lceil\frac{n}{2}\rceil \times \lfloor\frac{n}{2}\rfloor\right)$ at $a = \frac{n}{2}$ and for $n$ odd, $a(n-a)$ achieves a maximum value (for integer $a$) of $(n^2-1)/4 = \left(\frac{n-1}{2}\times\frac{n+1}{2}\right) = \left(\lceil\frac{n}{2}\rceil \times \lfloor\frac{n}{2}\rfloor\right)$ at $a = \frac{n\pm 1}{2}$. In all cases, the maximum value of $a(n-a)$ is $\left(\lceil\frac{n}{2}\rceil \times \lfloor\frac{n}{2}\rfloor\right)$, so we can conclude as desired that two random vertices from $V(v, i)$ have different colors with probability at most $\left(\lceil\frac{n}{2}\rceil \times \lfloor\frac{n}{2}\rfloor\right) / {n \choose 2} = \epsilon_n$. 

A typical case is when a problem in $\mathsf{NP}$ also lies in $\mathsf{coNP}$ or $\mathsf{coAM}$. Assuming that the polynomial hierarchy does not collapse, such a problem cannot be $\mathsf{NP}$-complete. Examples include integer factorization, discrete logarithm, graph isomorphism, some lattice problems, etc. 

I still think Suresh's comment below the question is enough to show that any ratio is possible. If you are not convinced with that, you can look at Boolean Constraint Satisfaction Problems (CSPs), for example. Background: Let $P: \{0,1\}^k \to \{0,1\}$ be a predicate of arity $k$. An instance of Max-CSP(P) is over $n \gg k$ Boolean variables $x_1, \ldots, x_n$. A literal is any variable or its negation. The instance consists of $m$ constraints, each of the form $P(\lambda_1, \ldots, \lambda_k)$ where the $\lambda_i$ are some literals, and the goal is to find an assignment of the variables that maximizes the fraction of satisfies constraints. For example, in $3SAT$ we have $P(x_1, x_2, x_3) = x_1 \lor x_2 \lor x_3$. Define $\rho(P)$ as the fraction of $2^k$ possible inputs that satisfy $P$ (for $3SAT$ it is equal to $7/8$). It is trivial to approximate any Max-CSP(P) by a factor $\rho(P)$ by assigning random values to variables (and then derandimize using the method of conditional expectations). Note that here we have the convention that approximation ratios are positive reals no more than 1. A predicate $P$ is Approximation Resistant (AR) if it is NP-hard to solve Max-CSP(P) better than by a factor $\rho(P)$ (i.e., $\rho(P)+\epsilon$ for any fixed $\epsilon > 0$). Note that any AR predicate demonstrates a tight approximation threshold $\rho(P)$. It is known that there are predicates $P$ with arbitrarily small $\rho(P)$ that are approximation resistant, and remain so even if you add to the accepting inputs of $P$. For example, the following paper shows one such result: Per Austrin and Johan Håstad, Randomly Supported Independence and Resistance, SIAM Journal on Computing, vol. 40, no. 1, pp. 1-27, 2011. So this takes care of all rational thresholds whose denominator is a power of two. For other thresholds, observe that if suffices to show that for every $\alpha$, there is an $\alpha' \leq \alpha$ for which there is an AR predicate with $\rho(P) = \alpha'$ (since it is always possible to add dummy variables and constraints of them that are trivially satisfiable so as to increase the approximation threshold). 

Reduction The decision version of your problem (where $k$ is given and we wish to know whether a hub exists for that $k$) is NP-hard by reduction from dominating set. Let $G = (V, E)$ be the given graph for the dominating set problem and let $k$ be the target number of vertices to be selected for the dominating set problem. Then construct the instance of your problem (a graph $G'$, a distance function, a set of source vertices $S$, a set of exit vertices $EX$, a target number of hub vertices $k'$, and a pair of values $\gamma$ and $\delta$) as follows: 

A (rather cursory) search brought up only this cs.stackexchange post which is relevant but doesn't answer my questions and this paper, which I haven't read in enough detail to be sure that it concerns exactly the class $C_3$ rather than a similar but different class (the paper claims to prove that (1) every language in $C_3$ is decidable and (2) that $C_3$ and $Regular$ are distinct classes with non-empty intersection). As pointed out in the comments of the cs.stackexchange post, these kinds of TMs can be thought of as very particular cellular automata, so maybe someone who knows the literature on cellular automaton theory could help. 

Yes. For example, a Reed-Solomon code contains a BCH code, which is a binary linear code, as a sub-code. These are called subfield-subcodes. 

The story behind the author ordering of the first paper is explained here. For the other cases I believe there's not much beyond an agreement between authors. 

If you have a polynomial time oracle for solving an NP-hard problem, you can use it to solve any other problem in NP as well, including what you want in your "sequential algorithm": Given a graph and a path of length $i$, whether the given path can be completed to a Hamiltonian path. 

The Eulerian Tour problem is of course a well-studied classical problem in graph theory (Wikipedia article). This question concerns non-Eulerian graphs; i.e., graphs that contain one or more odd-degree vertices. In a nutshell, I wonder what is the best "Eulerian-like" way of traversing non-Eulerian graphs. Given an undirected connected graph, let an Eulerian "semi-tour" be defined as a "cycle" that passes each edge at least once and can visit any vertex or edge multiple times. Consider the following costs for a given semi-tour: 

Suppose we are given a graph $G = (V, E)$ with $n$ vertices and $m$ edges and a value $c$. We wish to know whether $G$ has a clique of size $c$. We use $G$ and $c$ to construct an instance of your problem. Define $t_1 = n + m - {c \choose 2}$ and define $t_2 = {c \choose 2} + c$. Then we set the threshold value $T$ to equal $2t_1 + 2t_2$. We set the universe of elements $U = \bigcup_{i \in I} S_i$ to equal $$\{a_1, a_2, \ldots, a_{T-t_1}\} \cup \{b_1, b_2, \ldots, b_{T-t_2}\} \cup V \cup E$$. We create exactly $m + 2$ subsets $S_i$: 

Consider the following reduction from coNP-complete problem $k$-UNSAT to your language $L$ (where $k$-UNSAT is the language of all unsatisfiable $k$-CNF formulas): On input a $k$-CNF formula $\psi$, create new variables $x_1, \ldots, x_k$ and output formula $\phi = \psi \land (x_1 \lor x_2 \lor \cdots \lor x_k)$. If $\psi$ is unsatisfiable then $\phi$ is also unsatisfiable. In that case, it is vacuously true that every satisfying assignment $x$ of $\phi$ is a NAE assignment. (Equivalently, $\phi(x) \implies \phi(\neg x)$ is always true since $\phi(x)$ is always false.) This shows that $\phi \in L$. Thus, we see that if $\psi \in k$-UNSAT (that is, $\psi$ is unsatisfiable) then $\phi \in L$. On the other hand, if $\psi$ is satisfiable then $\phi$ is also satisfiable by keeping the old assignment for the variables in $\psi$ and setting $x_1 = x_2 = \ldots = x_k = 1$. Notice that this is a satisfying assignment of $\phi$ that is not NAE. In other words, $\phi \not\in L$. Thus, we see that if $\psi \not\in k$-UNSAT (that is, $\psi$ is satisfiable) then $\phi \not\in L$. The above shows that $\psi \in k$-UNSAT if and only if $\phi \in L$ and therefore that the reduction is correct. Since $k$-UNSAT is coNP-complete, we can conclude that $L$ is coNP-hard. 

There are many problems which have implications on P vs. NP and other complexity classes. Supposing that we're interested in Fourier transforms and/or multiplication algorithms, do faster Fourier transforms carry any implications for P vs. NP or other complexity classes? For example, I seem to recall seeing something regarding faster matrix multiplication as it relates to P vs. NP. I'm really trying, although I may be somewhat vague, to determine if any Fourier-related transforms have P vs. NP implications, even if we have to trace implications through several problems or complexity classes. 

MAX3E SAT is defined as SAT with all clauses consisting of 3 literals and their possible negations. We define clause counting, for this question, as the ability to count the total number of satisfied clauses for all remaining possible truth assignments. Let's say that we are allowed to pick a single variable and assign it a value, and then perform clause counting to get a total for all remaining possible truth assignments. Further, we can do this for all variables and their negations. Let's consider this clause counting ability for MAX3E SAT with an equation that is garaunteed to be satisfiable by at least one possible truth assignment. Now, the clause counting from above can be used to help predict part of a satisfying truth assignment. The variable we pick with the highest clause count should (probably) be part of a satisfying truth assignment. I'd like to construct the smallest example (in terms of clauses) where this notion of clause counting fails. Can someone please help? 

Place all non-split vertices (under the ordering) into $A$ and $B$ by putting the vertices with 3 successors into $A$ and the vertices with 3 predecessors into $B$. Tentatively add all split vertices (under the ordering) into $A$. Repeat steps 4 and 5 until step 4 fails: Identify a split vertex $v$ that has more neighbors in its current set ($A$ or $B$) than in the other Move $v$ to the other set 

There are only two $G_j$s. Note that $S_1$ and $S_2$ cannot be in the same $G_j$ because $|S_1 \cup S_2| = 2T -t_1-t_2+n = T + t_1 + t_2 + n > T$. As a result, the two $G_j$s will contain one of $S_1, S_2$ each. Without loss of generality, suppose $G_1$ contains $S_1$ and $G_2$ contains $S_2$. Let $E_1$ be the set of edges $e_i$ such that $S_{i+2}$ is in $G_1$ and similarly let $E_2$ be the set of edges $e_i$ such that $S_{i+2}$ is in $G_2$. Then consider the value $|\bigcup\{S \in G_1\}|$. $G_1$ consists of $S_1$ together with the $S_{i+2}$s for those $i$ for which $e_i \in E_1$. Each $S_{i+2}$ has exactly three elements: two vertices and one edge. But $S_1$ already contains all of the vertices. In other words, we see that the set $\bigcup\{S \in G_1\}$ is equal to $\{a_1, a_2, \ldots, a_{T-t_1}\} \cup V \cup E_1$. Then the size of this set is $(T - t_1) + n + |E_1| = T - (n + m - {c \choose 2}) + n |E_1| = T - (m - {c \choose 2}) + |E_1|$. Next consider the value $|\bigcup\{S \in G_2\}|$. $G_2$ consists of $S_2$ together with the $S_{i+2}$s for those $i$ for which $e_i \in E_2$. Define $V_2$ to be the set of endpoints of edges in $E_2$. Then the set $\bigcup\{S \in G_2\}$ is equal to $\{b_1, b_2, \ldots, b_{T-t_2}\} \cup E_2 \cup V_2$. The size of this set is $(T -t_2) + |E_2| + |V_2| = (T - {c \choose 2} - c) + |E_2| + |V_2|$. A partition of edges into $E_1$ and $E_2$ solves this problem if and only if both $T - (m - {c \choose 2}) + |E_1|$ and $(T - {c \choose 2} - c) + |E_2| + |V_2|$ are at most $T$. But $$T - (m - {c \choose 2}) + |E_1| \le T$$ is equivalent to $|E_1| \le (m - {c \choose 2})$, which in turn is equivalent to $|E_2| \ge {c \choose 2}$. Furthermore, $$(T - {c \choose 2} - c) + |E_2| + |V_2| \le T$$ is equivalent to $|E_2| + |V_2| \le c + {c \choose 2}$. In other words, this problem is solvable if and only if we can choose at least ${c \choose 2}$ edges such that the number of chosen edges plus the total number of vertices incident on those edges is at most $c + {c \choose 2}$. It is possible to choose at least ${c \choose 2}$ edges satisfying this constraint if and only if it is possible to choose exactly ${c \choose 2}$ edges satisfying this constraint (since choosing extra edges can only make it harder to satisfy the constraint). Thus, this problem is solvable if and only if we can choose exactly ${c \choose 2}$ edges such that the number of chosen edges plus the total number of vertices incident on those edges is $c + {c \choose 2}$. In other words, this problem is solvable if and only if we can choose exactly ${c \choose 2}$ edges such that the total number of vertices incident on those edges is at most $c$. This is equivalent to saying that the graph $G$ must have a clique of size $c$. Thus the given reduction is answer preserving. 

Cayley graphs of codes and derandomized code products can be a good example. See the following thesis (Chapter 6) for details and references: $URL$ 

Seeing that you are a computer programmer: Without all the theoretical developments, your C++ compiler would take forever to compile your program and even then would most likely crash. That is assuming that your OS could keep running by that time, not using countless clever data structures and algorithms developed in theory. Whatever you look at, be it a compiler, operating system, database, a video game, a web service, or the web browser you are using now to read this text: There is a lot of theory behind its working. 

Your question is equivalent to tail bounds on the weight distribution of Reed-Muller codes. Understanding weight distribution of Reed-Muller codes is an old and challenging question in coding theory, and several interesting results are known about it (the weight distribution is completely understood only for $d=1$ and $d=2$). As a great starting point, see "Weight Distribution and List-Decoding Size of Reed-Muller Codes" by Tali Kaufman, Shachar Lovett, Ely Porat, and the references therein.