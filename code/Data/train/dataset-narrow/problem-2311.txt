In the unbounded-error case, it is known that both realtime quantum and probabilistic finite automata can recognize some uncomputable languages if they are allowed to use arbitrary real numbers in their transitions (Rabin, 1963; Yakaryilmaz and Say, 2011). In the bounded-error case, we have a similar result for poly-time quantum Turing machines as well, i.e. the cardinality of $ \mathsf{BQP}_{\mathbb{C}} $ is uncountable (Adleman et. al., 1997). My question is whether any bounded-error probabilistic space (time) class defined with unrestricted real numbers contains an uncomputable (or a recursive enumerable) language. It is also known that (Watrous, 2003) if we restrict ourselves to algebraic numbers ($\mathbb{A}$), for any space-constructable function $ s(n) \in \Omega(\log n) $, \begin{equation} \mathsf{PrQSPACE}_{\mathbb{A}}(s) \subseteq \mathsf{DSPACE}(s^2), \end{equation} where $\mathsf{PrQSPACE}$ stand for unbounded-error quantum space. Any partial answer (for the case of bounded-error probabilistic computation using non-algebraic transitions) violating this upper bound would also be nice. 

Similarly, we can define some complete problems for each level of polynomial hierarchy (PH). But, of course, in case of being complete at some level of PH, we need to release the condition of having only two natural numbers after each quantifier. 

To get more, I think this paper is a good starting point. To check the related recent developments, I can also recommend to check the papers listed here: dblp: Christos A. Kapoutsis. 

As far as I know, it is not known whether $ \mathsf{NP} \subseteq \mathsf{IP(2pfa)} $, where $ \mathsf{IP(2pfa)} $ is the class of languages having interactive proof systems with some two-way probabilistic finite automata verifiers (Finite state verifiers I: the power of interaction by Dwork and Stockmeyer). Does anybody know any progress on this issue? I know the following results: 

It's called finding a minimal model of a Horn formula. This model is unique because the intersection of two models of a Horn formula is itself a model. In fact, [Horn, On sentences which are true of direct unions of algebras, 1951] proved the following: A boolean function can be expressed as a conjunction of Horn clauses if and only if its set of models is closed under intersection. 

I see that previous answers explain why it is important to know if a problem is or is not NP-complete, but none seems to directly address the question: The proof of "$p$ is NP-complete" is not considered a research success for all $p$. It depends on various things, such as whether $p$ is interesting, whether the proof has new techniques, whether "$p$ is NP-complete" has interesting consequences, etc. 

After all those impossibility results, I think it's reasonable to settle for the question: "How do I implement a hash function without collisions for some given type $t$?'' The standard solution is hash-consing, a technique first described by Ershov in 1957 (in Russian, and in 1958 in English) that should be much better known than it is. If the equivalence relation is (reference) equality, then there is a very simple hash: Just take the address of the object. So we can recast the problem as follows: "How do we ensure that we build at most one element from each equivalence class?" Let's use structural equality as equivalence relation. If we want to build an object whose parts are $x_1,\ldots,x_n$ we call $\mathit{mk}\;x_1\ldots x_n$. In that function, we first lookup the tuple $(x_1,\ldots,x_n)$ in a dictionary and, if a value is found, we return it. (Since $x_1,\ldots,x_n$ were built before, they are class representatives.) Otherwise, we construct a new data structure. For a different equivalence relation you need to adapt hash-consing, exploiting properties of your particular equivalence. The implementation is a bit trickier than this description might suggest. Some (hidden) test data is here. PS: I mentioned some people from which I learned some parts of the answer. Naturally, if those parts are wrong, it is likely I misunderstood what I've been told. 

This language is in $ \mathsf{SL}^=_\mathbb{Q} $, the class of co-exclusive rational stochastic language (YS10). (More details were added below as Appendix 1!) A language L is in $ \mathsf{SL}^=_\mathbb{Q} $ if there exists a probabilistic finite automaton (PFA) $P$ defined with only rational numbers such that every member is accepted by $P$ with probability $ 1 \over 2 $ and every non-member is accepted by $P$ with probability different than $ 1 \over 2 $. $ \mathsf{SL}^=_\mathbb{Q} $ is also exactly characterized by 

Although this is not a direct answer to your question, I would like to recommend the following book: 

You can check the following paper: Translational lemmas, polynomial time, and $ (\log n)^j$-space by Ronald V. Book (1976). Figures 1 and 2 in the paper give the summary of what is known and what is unknown. I put Theorem 3.10 in the paper here: 

Edit: I choice the answer with highest score by December 06, 2012. This is a soft question. The concept of (deterministic) algorithms dates back to BC. What about the probabilistic algorithms? In this wiki entry, Rabin's algorithm for the closest pair problem in computational geometry was given as the first randomized algorithm (year???). Lipton introduced Rabin's algorithm as the start of the modern era of random algorithms here, but not as the first one. I also know many algorithms for probabilistic finite automata (a very simple computational model) discovered during 1960s. Do you know any probabilistic/randomized algorithms (or method) even before 1960s? or Which finding can be seen as the first probabilistic/randomized algorithm? 

C.A.R. Hoare, An Axiomatic Basis for Computer Programming. From the abstract: In this paper an attempt is made to explore the logical foundations of computer programming by use of techniques which were first applied in the study of geometry and have later been extended to other branches of mathematics. It has six pages that are quite easy to follow. 

The article by Gardnera et al. seems to reduce from more standard NP-complete problems. I don't understand well enough either reduction to explain it here, so I'll just leave the pointers from above for you to explore if you wish. This could all be useless, unless somebody figures out how to reduce BINARY DIGITAL TOMOGRAPHY to the question being asked. 

First, I believe your implementation is not polymorphic. Second, and more important, even if there is no injection from $\mathbb{Z}\to\mathbb{B}$ to $\mathbb{Z}$, there is one from the elements of $\mathbb{Z}\to\mathbb{B}$ that your program constructs in some finite time. (If you give up polymorphism but not state, then there is a way to find a counterexample to any potential implementation. I learned this from Paulo Oliva, but I don't know how yet.) 

The answer is negative. Neel Krishnaswami noticed that $f\;(=_{t'})$ is an injection only if $|t'|\le|t|$, which is not the case when $t'$ is $t\to\mathbb{B}$. Tsuyoshi Ito noticed that an even stronger statment must be true: $f\;e$ is a constant function. Here is a proof that was shown to me by Rasmus Petersen. Go to the free theorem generator and type in "(a->a->Bool)->(a->Integer)". (The last type is instead of $t$ so that the website knows that it is a type, not a type variable.) The free theorem for this type is $$\forall t\,t'\,\forall R\,\forall p\,p',\;\bigl(\forall (x,x')\,(y,y'),\;p\;x\;y=p'\;x'\;y'\bigr)\Rightarrow\bigl(\forall (x,x'),\;f\;p\;x=f\;p'\;x'\bigr).$$ Here, $t$ and $t'$ are types; $R$ is a relation on these types; (in our case) $p$ and $p'$ are equivalence relations on $t$ and, respectively, $t'$; and we have $xRx'$ and $yRy'$. We now pick a relation $R$ such that the premise is satisfied and the right hand side of the conclusion reduces to a constant: $R=\{(x,())\}$, where $x$ is some fixed but arbitrary element of $t$, and $t'=\mathbb{U}=\{()\}$ is the unit type. $$f\;p\;x=f\;(=_\mathbb{U})\;()$$ Q.E.D. The notes I posted in a comment contain a longer proof, and more explanations. 

If the number of matrices is fixed (i.e., given a part of the input), then the problem was shown to be NP-complete in The complexity of the max word problem and the power of one-way interactive proof systems by Condon (1993). You can download the related technical report (1990) for free. The first paragraph from the technical report is as follows: 

The language $ \mathtt{MOD_p} = \{a^{ip} \mid i \geq 0\} $ (for some prime number $p$) can be recognized by a $ O(\log p) $-state bounded-error quantum finite automata (QFAs) but the proof is non-constructive. The best known constructively obtained number of states is $ O(\log^{2+o(1)}p) $ for bounded-error QFAs recognizing $ \mathtt{MOD_p} $. REF: Section 4.2 of (Ambainis and Yakaryilmaz, 2015). 

What is the simplest computational model for which the emptiness problem is undecidable? Emptiness problem for a computational model (e.g. finite state automaton, alternating pushdown automaton, bounded-error quantum automaton with a counter, deterministic LBA, etc.) is to determined whether, for a given such machine, the language recognized/defined by this machine is empty. Here the description of the machine should be finite! I know that the word "simplest" is a little vague. There could be more than one answer for some incomparable computational models. As a special remark, I believe that the question would become more interesting by focusing on unary and binary alphabets separately. Note that there are many computational models for which the halting problem is decidable but the emptiness problem (and some other problems) is (are) undecidable, e.g. Linear bounded automata (LBAs). 

CTL properties can be checked in linear time (see Clarke et al). Long time ago I used to work in a company where many colleagues used Rulebase to verify integrated circuit designs. The property language is PSL, it is standardized by IEEE, and is a kind of CTL on steroids. 

It's not clear to me how to reduce this to your problem. One observation that might help is that the output of your problem also depends only on the sums, not on the exact positioning of the queens. (See Theorem 2.4 in [Rivin, A Dynamic Programming Solution to the n-Queens Problem, 1992], although perhaps this is easy to see.) Knuth proves that BINARY DIGITAL TOMOGRAPHY is NP-complete by a reduction from the BINARY CONTINGENCY PROBLEM. This is a very similar problem, except in 3 dimensions, and without diagonals. 

There are several algorithms for estimating cardinality. This problem seems to be important enough in practice. For example, Redis, which describes itself as a ‘data structure server’, supports it. I suspect students would find this a good motivation. The algorithm that Redis uses, HyperLogLog, may be too difficult to analyze in an undergrad course. But, there are some alternative algorithms that seem good for an undergrad course. One is to use the minimum value of all hash values seen. Another is to keep the maximum $k$ such that $2^k$ divides at least one of the hash values. The HyperLogLog paper is a good starting point for even more alternatives: 

In Model Checking Recursive Programs with Numeric Data Types, Hague and Lin presented a NEXP-complete language under logspace reduction, called $ \mathtt{SUCCINCT~0\mbox{-}1~KNAPSACK} $ composed by strings \begin{equation*} a^m \# a^k \# \theta, \end{equation*} where $ \theta $ is a Boolean formula with variables $ x_1, \ldots, x_{m+k} $ satisfying that the string $ b \# a_1 \# \cdots \# a_{2^k-1} $ defined based on $ \theta $ (described below) is a member of $ \mathtt{KNAPSCAK} $, i.e. $ \sum_{i=1}^{2^k-1} a_i z_i = b $ for some $ z_1, \ldots,z_{2^k-1} \in \{0,1\} $, where $ b $ and each $ a_i $ are precisely $ 2^m $ bits (leading 0s permitted) binary numbers. The string $ b \# a_1 \# \cdots \# a_{2^k-1} $ is defined based on $ \theta $ as follows. Let $ (i)_{2,k} $ be the $ k $-bit binary representation of $ i $. 

One-way alternating pushdown automata (1APDA) can recognize any language in $ DTIME(2^{O(n)}) $ (Alternation by Chandra, Kozen, and Stockmeyer, 1981). By replacing a pushdown storage of a 1APDA with a counter, we can obtain a one-way alternating automaton with one-counter (1ACA). My question is about 1ACAs on unary languages. Can 1ACAs recognize some unary non-regular languages? Note that one-way nondeterministic pushdown automata can recognize only unary regular languages. 

There are also some computational models: Here is the first paper: Rusins Freivalds: Ultrametric automata and Turing machines. Turing-100 2012: 98-112 

Background. I bumped into this conjecture while trying to prove a lower bound for a problem discussed in a program analysis paper, [Yang, Grigore, Abstraction Refinement Guided by a Learnt Probabilistic Model, 2016]. 

Most automatic theorem provers handle EUF in some form. In particular, provers based on the Nelson-Oppen architecture do so. For big systems, however, EUF is usually not enough. One needs specialized decision procedures for arithmetic, arrays, bit vectors, and so on to get better performance. Take a look at SMT solvers. If you follow the links to solvers and where they are used you'll find many applications to real world problems. For example, Z3 is used in VCC, which in turn is used to fully verify Microsoft's (baby) hardware simulator Hyper-V. 

Here is how to solve the basic task in $O(n)$, at the expense of possibly lots of preprocessing. (This expands a comment I made.) Example. Suppose that $n$ is 3, and the given sets are {1,2}, {2,3}. Represent the boolean function $f(x_1,x_2,x_3)=(x_1\land x_2)\lor(x_2\land x_3)$ as a BDD: $$f(x_1,x_2,x_3)=x_1?(x_2?1:0):(x_2?(x_3?1:0):0)$$ (Here $x?a:b$ means 'if $x$ then $a$ else $b$'.) Clearly, evaluating $f$ written in this form takes time linear in $n$, which is possibly much smaller than the size of the input. The problem, of course, is that going from DNF to BDD may take an exponential amount of time (and space). But this is just preprocessing. Suppose the query is the set {1}. We evaluate $f(0,1,1)$ to get 1, so we conclude that one of the given sets is disjoint from the query. Suppose the query is the set {2}. We evaluate $f(1,0,1)$ to get 0, so we conclude that none of the given sets is disjoint from the query. The general case. Given sets $S_1,\ldots,S_m\subseteq[n]$, represent the function $$f(x_1,\ldots,x_n)=\bigvee_{i=1}^m\bigwedge_{j\in S_i}x_j$$ as a (RO)BDD. To answer a query $X$ evaluate $f(x_1,\ldots,x_n)$ with $x_j=[j\notin X]$ for $1\le j\le n$. Comments. One way to view this construction is as a systematic way to precompute all answers. ‘Precompute all answers’ sounds dissatisfying, but I think the keyword should be ‘systematic’: it's not a priori obvious how to do it for this problem, given the comments on the question. Another thing to note is that there are many negations going on here, which some people say are obvious, but they tend to make me dizzy. Probably the only reason I saw this construction quickly is that minutes before reading the question I was looking at the Monotone Duality problem, which is closely related to the question. Monotone Duality comes in many guises. One of them is Hitting-Sets: Given a family of sets, compute the family of all the hitting sets. This is clearly related to the question posed here, in which we are asked whether a given set is not a hitting set. (It's not the same though.) Another guise is Monotone-DNF-Dual: Given a monotone $f$ in DNF, find a $g$ in DNF such that $\lnot f(x_1,\ldots,x_m)=g(\lnot x_1,\ldots,\lnot x_m)$. I thought of the construction above because I knew that this is an equivalent formulation. So, perhaps a reference to a survey of the Monotone Duality problem would serve as a suitable reference: 

P, NP, and NP-Completeness: The Basics of Complexity Theory by Oded Goldreich would be an another good introductory book. After introductory contents, I would like to also recommend The P=NP Question and Gödel’s Lost Letter by Richard J. Lipton. 

The main credit should go to John Fearnley! Here is a PSPACE-complete problem given in (John Fearnley, Marcin Jurdzinski: Reachability in Two-Clock Timed Automata Is PSPACE-Complete. ICALP (2) 2013: 212-223): \begin{equation} \mathtt{SUBSETSUM\mbox{-}GAME}=\{ S~ \forall(a_1 , b_1) \exists(e_1,f_1) \cdots \forall(a_n , b_n) \exists(e_n,f_n) \}, \end{equation} where 

It is not hard to show that $ \mathtt{SUCCINCT~0\mbox{-}1~KNAPSACK} $ can be reduced to NP-Complete $ \mathtt{KNAPSCAK} $ via linearspace reduction. Moreover, since any language in NEXP is logspace reducible to $ \mathtt{SUCCINCT~0\mbox{-}1~KNAPSACK} $, we can say that any language in NEXP is polyspace reducible to $ \mathtt{KNAPSACK} $. (Here we can combine logspace and linearspace reductions. Since the output string after logspace reduction can have polynomial length, we can use polynomial space overall.) 

Most of its chapters are related to complexity theory. The book can be seen as a nice collection of the results from some important research papers. You can get the papers from the results! 

Appendix 1: More details on $ \mathsf{SL^=_\mathbb{Q}} $. Here I use another model, which is simpler than PFA to program in our case. An $n$-state Turakainen finite automaton (TuFA) $ T $ is a 5 tuple $$ T = (S,\Sigma,\{A_\sigma \mid \sigma \in \Sigma\},v_0,f), $$ where 

While an EE undergrad I attended some lectures that presented a nice characterization of boolean circuits in terms of how many nested loops they have. In complexity, boolean circuits are often thought of as dags, but in real hardware cycles are common. Now, modulo some technicalities regarding what a loop is and what constitutes a nested loop, the claim was basically that in order to implement in hardware an automaton one needs two nested loops, and in order to implement a processor one needs three nested loops. (I might be off-by-one with these counts.) Two things bother me: 

Random observations, from foggy memory. A. The recursion for minimum vertex covers is similar to the recursion for minimum decision trees: $$\begin{align} {\it VC}(G) &= \min_{x \in G} \bigl( 1 + {\it VC}(G -x- N(x)) \bigr)\\ {\it DT}(G) &= \min_{x\in G} \bigl( 1 + {\it DT}(G-x-N(x)) + N(x) + {\it DT}(G-x)\bigr) \end{align}$$ Here, $N(x)$ is the set of vertices that are adjacent to $x$. (The recursion for decision trees is not completely obvious. One needs to show that in the true branch of the decision tree it's OK to first greedily check all the neighbors of the root $x$.) B. If $G$ is a tree, then one can build a minimum decision tree by using an algorithm similar to that for finding vertex covers of trees: always label the root of the decision tree by a vertex that has a neighbor of degree 1. C. The size ${\it DT}(G)$ of a minimum decision tree can be exponential in the size of $G$. For an example, consider path graphs. D. Consider two graphs $G_1$ and $G_2$ that share no vertex. Somewhat surprisingly, there seems to be no simple way of obtaining a minimum decision tree for $G_1 \cup G_2$ by combining two given minimum decision trees for $G_1$ and $G_2$. For an example, let each of $G_1$ and $G_2$ be path graphs on 4 vertices. Each minimum decision tree of $G_1$ has 5 decision nodes; thus, there are 6 leaves. It turns out that out of these leaves, 3 are labeled by true and 3 are labeled by false. Since $G_2$ is isomorphic to $G_1$, its minimum decision trees have similar shapes. Composing a minimum decision tree for $G_1$ with a minimum decision tree for $G_2$ (using the obvious algorithm for disjunction between decision trees) gives a decision tree with $5 + 3\times 5=20$ decision nodes. However, there exists a decision tree with only 19 decision nodes.