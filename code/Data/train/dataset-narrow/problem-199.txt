On a chassis style switch, it's even simpler. Just issuing the command gives detailed output of what your system can offer. 

This is the preferred Juniper way of handling this. Running this with the option will show you what will be deleted ahead of time. You should do this first. 

I can't find any documentation that says you can do this, so I would imagine per-ip based bandwidth management is about as close as you can get to evening the playing field for everyone. This is usually sufficient as you wouldn't stand to benefit much from limiting someone who has reached this limit if they aren't effecting anyone else (because you're already guaranteeing bandwidth evenly). 

NTP isn't particularly jitter-sensitive because it uses and timestamps to keep track of delay. Ntp.org explains in detail how it keeps delay in check, but here's a snippet: 

1. I am aware that this pid was induced with , which was intentional to replicate an issue we have had in the past. I noticed a device getting near the limit and want to share a common issue we have. Command used: . 2. Some log configuration removed for organizational restrictions, such as and . 

That is the default behaviour. Adding NAT translation between neighboring subnets would not be an 'enabled by default' feature. Simply adding those subnets into your SonicWall would allow them to communicate as long as your hosts are pointing to it as a default gateway. 

Yes, it absolutely is. HP’s Intelligent Redundant Framework is just another system virtualization technology like Cisco’s StackWise and Juniper’s Virtual Chassis, just painted a different color and tagged with ‘the most disruptive technology in ages’. Every vendor will tout how much better theirs is than the competitor, but it’s not a game changer or anything to write home about. 

This is absolutely possible. Dell has an article outlining this specifically; How To Configure Bandwidth Management with limits Per IP (SW12385). 

A LAN that has no other exits will have a default route (i.e. static route) that points all unknown traffic to the edge. Since routers match on the longest prefix matching the destination address, this is your gateway of last resort. 

Your Linux-foo is commendable. Unfortunately, this isn’t the most ideal solution, as you can probably tell, and pigeon-holes you into continuously developing your own applications. You’re obviously on the right track; you’ve come here to figure out a more scalable solution. 

Full-duplex basically means communication can happen both ways, negating the possibility of a collision. The below diagram should make it a little more clear. One pair is designated a transmit pair, and the other a receive pair. In most environments now, it isn't even necessary to match up transmit/receive pairs, as MDIX handles that for you. 

Take note of the priorities as the higher, the more preferable a it will be. One thing that always screwed with me was the configuration statement. A VRRP speaker will not accept data on a virtual address unless it has that explicitly configured, or if the virtual address is the same as the interface address. Now verify that the master is talking. 

I’m not entirely sure what you mean. If you are talking about needing to connect pfSense to your ISP connection, then no. Remember one persons WAN is anthers LAN. In this sense, your Cisco Firewall’s WAN is the ISP, and it’s LAN is everything behind it. Your pfSense’s WAN is the Cisco Firewall, and it’s LAN is all networks residing behind it. 

I can't imagine you'll have any issues with using the RV042. Using the built-in load-balancing methods automatically set up a WRR scheduling profile for you. Check out the RV042 User Manual for more information on how to set that up and a snippet of what's happening under the hood. 

The only real security concern is where that SPAN port's destination is (i.e. the server). Secure the server and you're good to go. Something to note, this is a fairly common method of intrusion detection. 

This isn’t just the Cisco world, this is the Networking world overall. Network engineers work to eliminate STP in as many cases as possible because they know of the limitations it drags along with it. Routing to the access layer is recommended nowadays: 

The instance you're talking about is called Pass the hash, which involves sniffing a hash, and then sending it back with the rest of the modified data without any actual knowledge of what was used to generate the hash. EIGRP would be vulnerable to this if if didn't use the local interface and the data inside the packet to generate its hashes. So no, an attacked really couldn't perform any of this unless he had prior knowledge of the shared secret. He could, however, capture a hello packet between neighbors, and then attempt to crack it. If you're key-length and complexity are high, though, you won't have much to worry about. 

RFC 5798 - 6.3. State Transition Diagram When a router with a higher priority becomes active and has the preemption flag set, it actively tries to usurp that state. But in some instances, that router might have something wrong with it. Maybe it’s flapping for some reason. That problem is even more aggravated when you have sub-second operation; a couple missed packets result in a network-wide flooding of gratuitous ARPs. To protect from this, some vendors offer the ability to back-off that preemption time a bit. In networks where you're utilizing aggressive timing, you’ll still have the power to react to offline nodes at sub-second intervals. In addition to that, you can also make sure devices coming on/off at a rapid pace don’t affect the overall state of VRRP within your boundary. 

I can, however, tell you that getting your version up to current will render this issue obsolete. Iperf version 2.0.5 (08 Jul 2010) makes no distinction between the 2 different types in those fields. Here is your exact cli syntax working for one of my private servers. Server: 

When a router receives a packet, it gets inspected, then forwarded out the appropriate interface or it gets dropped. When a router receives a broadcast packet, it drops it (excluding directed-broadcasts, dhcp, etc). When a switch receives a frame, it either forwards it on to a known interface or floods it out all of its ports if it doesn't know where to go. When a broadcast frame comes along, it get's flooded out all interfaces. Every machine in your segment sees it. Excessive amounts of these constitute a storm. The most common way for a broadcast storm to happen is from a switching loop. If you somehow get a switching loop on your network, these broadcasts will perpetually send this data back and forth forever, or until you remove the loop. This will cause data to hit every machine on your segment. This can cause your network to stop. When you have a router in between multiple layer 2 segments, each is inherently protected from the other. Remember, a router won't forward on broadcasts. For instance: 

Force10 This information should be obtainable under 1.3.6.1.4.1.6027.20.1.3.4.1 (f10BgpM2PathAttrEntry). 1.3.6.1.4.1.6027.20.1.3.4.1.12 (f10BgpM2AsPathString) - This is a string depicting the autonomous system path to this network which was received from the peer which advertised it. The format of the string is implementation-dependent, and should be designed for operator readability. 

I'll piggy-back what Ron said; HSRP with an IP SLA is the way to go. This will allow you to fallback on your alternate ISP if your primary link goes down. Here's a reference to work off of. R1