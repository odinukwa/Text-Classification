When logging to an external or syslog server, only new log entries are sent to the server. Old log entries will not be sent. You probably only have 14 log messages because that is all that have been generated since you installed the syslog server. 

No. It is measure of the strength of the signal it receives. A higher gain antenna would simply result in a higher RSSI as the signal would be stronger. 

The default gateway is only used by a device if there are no better routes to the destination network in the routing table. If the device doesn't communicate to networks that aren't in the routing table, then the default gateway will never be used. Routing tables can be updated on a device by making static changes or through the use of a dynamic routing protocol. Static entries don't scale well and can be problematic to maintain so most often a dynamic routing protocol is used. Routers acting as gateways to a network can advertise the networks (possibly including the "default" network of 0.0.0.0/0) to which they have access. Client devices that are configured to listen to these advertisements can learn about these networks and update their routing tables accordingly. Not knowing more about the specific environment you mentioned, I would suspect Ricky's answer about proxy-arp is far more likely, but I figured I would add this as a possibility as well. 

WLAN controllers (or more commonly WLCs) are platforms for central operation of a wireless network. They are not wireless devices themselves as they do not generally connect to devices wirelessly (the exception would be systems that use the APs as a distributed conroller, but that is merely additional functionality placed on the AP, not a direct function of the AP itself). WLCs allow for central configuration management, monitoring and reporting. They also provide coordination between the APs on a wireless network and for client devices connected to the wireless network. They can provide many functions including dynamic channel/power settings for APs, roaming, authentication, captive portals, or any number of other features. 

With five more computers, we have now hit 960Mbps of traffic being flooded out all ports. Again, this is below our 1000Mbps per second limit, but not by much. Again, most of the devices on the network will be receiving this traffic and have to process it to some degree. With only 6 active computers and one server, we have almost reached the capacity of the flooded network. There is almost no capacity left for the remaining devices on the network, say if Computer07 wants to start an FTP download from Server22. What happens when we hit that 1000Mbps limit? Which traffic doesn't get flooded? How does that impact performance? Now imagine this on a fully populated 48-port switch (i.e. more computers/servers/end points). How about with a stack of 7 48-port switches? An enterprise network with 1000's of switch ports? Or, take a mixed environment where you may have 10baseT, 100baseTX, and 1000baseT ports all on the same network. Computer01 above would fully saturate a slower device on the network all by itself. 

This is from the comment included in the bounty from another user. While the bounty did bring this back up for attention, what the OP asked and what the user placing the bounty is asking are two different questions. This comment is about the modes of operation that can be configured for an 802.11 client, it does not relate to the general nature of the OP question about WSN and ad hoc networks and really should be asked as a separate question. 

There is a lot of theory in firewall design and the old outside/dmz/inside model, while still common is not by any means as popular as it once was. This question also borders on being closed as "opinion based," but I won't vote it as such personally. In my opinion (since this sounds like a smaller deployment), you should be looking at for four zones, which would be much easier to manage/support, as well as more cost effective, on a single firewall that supports it. In order of security (lowest to highest), I would structure the zones as follows: 

Yes, this is the exact purpose of the second "a" in "aaa". Authorization is the process of limiting which commands a user is able to execute based on their user/group profile. There are many different products that provide aaa services in a centralized manner, some paid and some free. 

Possible? Yes under the right set of circumstances. To begin with, you would need to be on a short fiber run (per your description, check) and very few insertion points (again by your description, check). Beyond that, any interference created would have to be nearly perfectly constructive. To understand the last, you need to know that part of the signal is reflected back at the end of the cable. When this reflected signal reaches the original source end of the cable, again part of it will be reflected back. If the wave forms align correctly, you can then have a form of constructive interference. Let's put this in VERY simplistic and unscientific percentages to illustrate the effect. You transmit on side A of the cable at 100%. Some signal is lost along the way, but being a short cable, 98% reaches side B. A tenth of that, 9.8%, is reflected back toward A. 9.6% reaches side A, and a tenth of that, or 0.96% is reflected to constructively interfere perfectly with the new 100% source, becoming 100.96%. As this happens in a continuous cycle, the gain can be significant. Again, that is simplistic and not reflective (pun intended) of the real life math/physics, but it was meant more as an illustration of the effect, not the full details. In real life, the numbers change depending on a wide range of factors and there are limits to the medium. Of course, you could just have faulty hardware or a bug in the software was well. 

If there is no configured default route/gateway, then a ping will fail with a "no route to host" error. In a little more detail, PC1 will compare the destination address to it's local subnet, which is calculated from the IP address and subnet mask. Since the IP address for PC2 is outside the local subnet, it will go to the routing table to find the route it must use for PC2. If there is no route, it will not send the traffic and return an error. 

Capture device starts monitoring on channel 5. Client device send probe request on channel 5. Client device moves to channel 6 and sends probe request. Capture device moves to channel 6 and starts monitoring. AP sends probe response on channel 6. 

Different hardware/software may have limits that are imposed, but there is no limit as defined by the standards. However there are maximum recommended limits and the general rule of thumb is to use the fewest SSIDs as possible. Cisco's best practices document recommends 1-3 SSIDs: 

Possible? Certainly, but before you get worried, lets get into this a bit more. Ethernet contains a CRC value to help prevent corruption. IPv4, TCP, and UDP all use checksum values to help prevent corruption (note: IPv6 does not). CRC and checksum are two different methods to calculate the data is unchanged. So a single IPv4 packet will have a CRC and two different checksum operations performed on it. Any single bit error introduced in the data will be detected by both methods. The issue comes when you have multiple bit errors in the data. It is possible to have multiple bit errors that will provide a valid CRC. It is also possible to have multiple bit errors that will provide a valid checksum. However, it is very unlikely (but yes, possible) to have multiple bit errors that provide both a valid CRC and checksum. In all cases, when corruption is detected it causes the data to be dropped. TCP contains a mechanism for retransmission of dropped segments, no normally you experience no data loss when it is in use. However if UDP is used instead of TCP, if there is corruption detected any any of the three levels (Ethernet, IPv4 or UDP), then the data is dropped and it is up to a higher level process (i.e. the application, file format, etc) to detect and remedy the lost data. All of this so far is based purely on the network, but applications transferring data often have some means of checking data integrity as well. Further some file formats may have some means of validating integrity as well, especially if they are compressed. So again, yes it is possible, but unlikely. You are probably just as likely to introduce data corruption when your computer or server is reading/writing data to disk or memory. I will also note that data corruption in image files will generally either cause a serious problem or be unnoticeable.