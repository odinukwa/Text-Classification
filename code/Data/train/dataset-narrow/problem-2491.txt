There isn't a one word answer to your question, but you can have a look at Xiaotong Ni's master thesis, where commuting circuits with several restrictions are considered and compared to classical classes. There you can also find the definition of the class IQP, which is a subclass of polynomial size commuting Pauli circuits. 

This paper came up on the arXiv today and it improves on the upper bound on $bs(f)$ in terms of $s(f)$. They prove the following bound: $$ bs(f) \leq 2^{s(f)-1}s(f). $$ This along with the connection that Marcos mentioned in his comment should give better bounds than previously known. 

Basically everything that is known about the Quantum PCP conjecture has been collected in this survey by Dorit Aharonov, Itai Arad, and Thomas Vidick: The Quantum PCP Conjecture See also Thomas' blog post on the topic. 

This doesn't directly answer your question about a definition of a complexity class that represents the model you describe. Still, the notion of quantum oracle has relevance in complexity theory: in their paper Aaronson and Kuperberg use a quantum oracle to give a separation between QMA and QCMA. 

I am talking about publications in journals, not blog posts or technical reports. Also, I tagged it as big-list, with the hope that it will actually be. 

Green [1] showed that $PP^{PH}$ is properly contained in $PSPACE$ relative to some oracle. Around the same time, in the famous "voting polynomials" paper [2], it was shown that $PP$ is properly contained in $PSPACE$ for a random oracle. Question 

First of all, there is a formal definition of "quantum-NC", see QNC on the zoo. GCD is indeed a good candidate for a problem that could be shown to be in QNC, but it's not known to be in NC. However, finding a QNC algorithm for GCD is still an open problem. The feeling for which this is believed to be true comes from the fact that the Quantum Fourier Transform can be done in QNC. Reference: Conclusion section of "R. Cleve and J. Watrous, Fast parallel circuits for the quantum Fourier transform", arXiv:quant-ph/0006004 

Something that has not been mentioned so far (as far as I can see) and that holds in the unrelativized world is the following: $$PH \subseteq PP \quad\mbox{ if }\quad QMA = PP.$$ This was observed by Vyalyi in this paper and comes from the strengthening of two theorems: 

M. G. Parker and V. Rijmen have studied the quantum entanglement of binary and bipolar sequences in arXiv:quant-ph/0107106. I remember reading their paper long ago. They use a lot of terminology from coding theory, so now by just skimming through, I can't understand exactly what their result is, but you can have a deeper look. Notice also that graph states are a special case of your states. In particular, $\psi$ is a graph state if and only if the sequence $x$ is generated by a quadratic polynomial in GF(2). 

Frederic Green, An oracle separating $\oplus P$ from $PP^{PH}$, Information Processing Letters, '91 James Aspnes, Richard Beigel, Merrick Furst, and Steven Rudich, The expressive power of voting polynomials, STOC '91 Adam Klivans, On the Derandomization of Constant Depth Circuits, RANDOM '01 

Moved my comment here after Suresh's request. An example of a natural problem for which we only know algorithms that require error on both sides is the following: given three algebraic circuits, decide whether exactly two of them are identical. This comes from the fact that deciding whether two algebraic circuits are identical is in co-RP. Reference: see the post How Many Sides to Your Error? (Dec 2, 2008) about the very same question on Lance Fortnow's blog and the comments below his post for a discussion about the naturalness of the problem. 

This is amazing and it's the first time that I have seen it. I have always wondered why authors of paper don't write how they got to the proof, including the failed approaches they tried before getting to the track that led the solution. When I saw Ryan's paper on the arXiv, I felt very motivated to read it. I consider it a revolutionary paper from this point of view. Most of the time the only thing you can do with a paper is verifying its correctness. The question is the following: 

I've never done an exact solution for a "change of variable" problem with a recursive function, but I can give you a formula that might help. If $p : \mathbb{Z}_p \times \mathbb{Z}_p \to [0,1]$ is a probability mass function (i.e. sums to one over its domain), then the probability of any specific output for $G$ is $$\mathrm{Pr}[x]\ =\ \sum_{(n,m) \in G^{-1}(\{x\})} p(n,m)$$ where $G^{-1} : \mathcal{P}(F) \to \mathbb{Z}_p \times \mathbb{Z}_p$ computes preimages under $G$ by $$G^{-1}(A)\ =\ \{(n,m) \in \mathbb{Z}_p \times \mathbb{Z}_p\ \lvert\ G(n,m) \in A\}$$ In other words, it's the sum of the probabilities of the pairs $(n,m)$ for which $G(n,m) = x$. Despite the size of the formula, there are advantages to having it in terms of preimages. Unlike inverses, they always exist. They are often compositional, meaning that preimages under a function can often be defined in terms of preimages under its defining subexpressions, which is often necessary when dealing with recursion. For example, if $f : A \to B$ and $g : B \to C$, then $$(g \circ f)^{-1}\ =\ f^{-1} \circ g^{-1}$$ Another: if $f_1 : A \to B_1$, $f_2 : A \to B_2$, and $f : A \to B_1 \times B_2$ is defined by $f(x) = (f_1(x),f_2(x))$, then $$f^{-1}(B_1' \times B_2')\ =\ f_1^{-1}(B_1') \cap f_2^{-1}(B_2')$$ for all $B_1' \subseteq B_1$ and $B_2' \subseteq B_2$. For addition... well, there might be something for your specific problem. At the very least, it leads to a nice way to factor a program that enumerates the probabilities of each $x \in F$. 

One apparent strength of his approach is that it allows higher-order functions (i.e. lambda terms) to be observable outcomes, which measure theory generally makes quite tricky. (The basic problem is that spaces of measurable functions generally have no Borel $\sigma$-algebra for which the application function - sometimes called "eval" - is measurable; see the intro to the paper Borel structures for function spaces.) Scott does this using a GÃ¶del encoding from lambda terms to natural numbers, and working directly with the encoded terms. One weakness to this approach may be that the encoding could be difficult to extend with real numbers as program values. (Edit: This is not a weakness - see Andrej's comment below.) Using CPS seems to be primarily for imposing a total order on computations, to impose a total order on access to the random source. The state monad should do just as well. Scott's "random variables" seem to be the same as Park's "sampling functions" in his operational semantics. The technique of transforming standard-uniform values into values with any distribution is more widely known as inverse transform sampling. I believe there's just one fundamental difference between Ramsey's and Scott's semantics. Ramsey's interprets programs as computations that build a measure on program outputs. Scott's assumes an existing uniform measure on inputs, and interprets programs as transformations of those inputs. (The output measure can in principle be computed using preimages.) Scott's is analogous to using the Random monad in Haskell. In its overall approach, Scott's semantics seems most similar to the second half of my dissertation on probabilistic languages - except I stuck with first-order values instead of using a clever encoding, used infinite trees of random numbers instead of streams, and interpreted programs as arrow computations. (One of the arrows computes the transformation from the fixed probability space to program outputs; the others compute preimages and approximate preimages.) My dissertation's chapter 7 explains why I think interpreting programs as transformations of a fixed probability space is better than interpreting them as computations that build a measure. It basically comes down to "fixpoints of measures are way complicated, but we understand fixpoints of programs pretty well." 

By the definition in the linked paper on page 5, the statement is wrong. Binary space partition (BSP) trees have been used for decades on computer graphics to speed up spatial queries, as have quadtrees and octrees. K-d trees are used extensively in machine learning to speed up nearest-neighbor searches. If you squint just a little, decision trees also fit the general definition. 

Have you tried to look for what already existed in the field of Scheduling with Communication Cost? If you choose some of the communication cost to be $+\infty$, then it seems to me that it is exactly your problem. A communication cost is defined on an edge between two tasks $T$, $T'$ as: $$ \text{comm}(T,T')=  \left \{  \begin{array}{ll} 0 & \text{if alloc}(T)=\text{alloc}(T')\\ c(T,T') & \text{otherwise.} \end{array} \right. $$ Where the function $c$ is a well-defined cost function (in your case it could be $0$ or $+\infty$, depending on your constraints), and $\text{alloc}(T)$ is the function that states the processor on which $T$ is scheduled. You can read the work of Hanen, and Munier which is more adapted for small communication delays, however since in the general case your communication delays are small, it might be possible to adapt their algorithm. In the worst case you can check on scholar who cites their paper, it may be a good start for bibliographical work. 

There are venues that are interested by elegant proofs of existing results, see for instance the Symposium on Simplicity in Algorithms. So yes, in some cases an elegant proof can be considered as a contribution, especially if it offers new insights. 

If this is the case, then your problem is NP-hard: you can see it as a generalization of Minimizing total tardiness on a single machine with precedence constraints. Indeed this paper states that for multiple linear chains, it is NP-hard on a single processor. The easy transformation is to take the trees of the form one root, and linear chains starting from the root. However I am surprised because you seem to say that for the case of a single linear chain, you would use Dynamic Programming. I don't see why you would need DP, since it seems to me that when scheduling a single linear chain you do not have much choice because of the precedence constraints: only a single choice. So maybe I misunderstood your problem. 

But I suggest the best will be to check the Complexity Zoo because it has many more information and references on those examples, even Wikipedia Furthermore, as stated in the comments the tight bound when $\alpha=O(1)$, was shown for many problems such as bin packing, machine scheduling (see iris.gmu.edu/~khoffman/papers/set_covering.html). 

During the talk you are not so much interested in, you don't necessarily need all the pre-talk stuff, but always have the paper about the talk open, otherwise you will be lost at some point. Anyway, I think the definite focus would be but not only by listening to talks, also by talking with people, asking questions (to anyone, do not be afraid, usually people are really open to discussion even if they are well-known (might be busier however)). Final advice, be careful, there are many talks so it is easy to lose focus. Some will be much more important for you; it is better not to follow a talk you are not interested in and fully follow one you are interested in than follow half of them (IMHO). 

Encourage CouchSurfing as an accommodation I am not saying to bind people to CouchSurf, however imagine that with the hotel recommendation you add a page where local researchers (or student as I imagine this would be mainly used by students) could post a message saying "I can host so many people, mail me". Only people ready to do it would use it. For example, for students going to the conference it may be a good way to: 

In Spaa'11 there was a paper about what was called the Car-Sharing problem, where what they handover is the car :). 

There is an approximation hierarchy, the main known examples: FPTAS $\subseteq$ EPTAS $\subseteq$ PTAS $\subseteq$ APX. But for inapproximability there also is NPO-PB. There are a lot of results about the set of possible ratios, going from results like this one: 

Read the summary of the proceedings as soon as it is given to you (bring your laptop, sometimes it is on a USB stick) See which talk may interest you, read the abstract+paper if you are interested Then listen to the talks that you are interested in, after having read the paper (keep the paper open during the talk in case you need to catch up) As much as possible, go talk to people, meet new people, especially people working on similar stuff, ask question.