Actually Lights does not contain colliders, but what you can do is add a CircleCollider2D component to a light, then track if your object collide with the collider of this light and only then trace a ray from your object (character) to the light, if the ray hits a collider before hitting the light then you know your character is in the shadow part of this light! I am not sure you could go away with this without using raycast2D, but dont be afraid once you get a hold on it it can be very straight-forward. For example to put on your character : 

Actually for that particular case for future reference i want to add as answer that restarting my computer did gave me 60FPS after reboot on the emulator, without changing anything, with more optimization it could go even faster. @concept3d answer is still the valid one though and the article about why FPS is an incomplete indicator is a perfect reference 

Lazy loading! Add a method to SpriteComponent to let it store the name of the new sprite to load, then let the SpriteSystem load the actual data whenever it comes into play. To smooth out the loading laggies, preload. 

Color keying: Check if the alpha or color is equal to a magic cutout value. Alpha partitions: Obtain separate specular and transparency values using line equations. 

Sampling the heightmap with a clamping mode produces an output like such: Or with a wrapping mode, produces what was shown in your comment: (Including the errors around the border) 

This answer will focus on statement #3 in the original post, and is meant to supplement ToddersLegrande's answer 

I arrived at my assumptions because your offsetting code in the vertex shader seems to indicate that your variable is measured in pixels, not normalized: 

The Pannini projection, for example, can capture wide fields of view in nice ways. (totally just my opinion) I think implementation details would be beyond the scope of this specific question. 

Is this game actually licensed? I see it's available under two names (perhaps even more). Does this mean the game idea can be used freely? Is there an article about it? I have not been able to find it on Wikipedia. I would like to gather some information about the game so as to understand more details of it. Is there some database with puzzles available? I can just check the puzzles of existing games, but that's a pain because I have to finish a level to get on to the following one. I was wondering whether there is a general list of puzzles somewhere. 

A while ago I asked how to determine when a face is overlapping another. The advice was to use a Z-buffer. However, I cannot use a Z-buffer in my current project and hence I would like to use the Painter's algorithm. I have no good clue as to when a surface is behind or in front of another, though. I've tried numerous methods but they all fail in edge cases, or they fail even in general cases. This is a list of sorting methods I've tried so far: 

Long answer: (pre-calculus required) Define your jump function which is a simple integral over time: 

Step 1: Load your color and alpha images into two different OpenGL textures. Step 2: Use glActiveTexture to switch to between and bind both color and alpha to GL_TEXTURE0 and GL_TEXTURE1. Step 3: In your fragment shader, define texture samplers for color and alpha, and use the right one to get the right channels in your shader. Step 4: Set "color" and "alpha" uniform variables using glUniform1i to 0 and 1, for textures 0 and 1. This will let you pick different memory layouts for color and alpha, and should still save memory over a standard 32-bit, while providing perfect alpha gradients. 

Basically the same as JasonD's answer, except using bitwise operations instead of absolute value function. This is assuming you have 16-bit short integers! 

(although, I think maybe you wanted this one that accounts for gravity but can be used to calculate any possible jump) 

Which is our answer, notice that time is still unknown in this system. This means there are infinite trajectories that will land on the purple rectangle. You have to decide how long it should take. 

Unity (or any other 3D engine i believe) is not using pixels for positioning objects in space (maybe mostly because there is no Z axis in pixels and also because it brings thousands of other issues) Unity uses Unit system (i personally see it as metric) you should take the unit cube as one meter, this means few things : 

Re create Triangles in Index order or with a home made algo fitting the mesh shape. then Interpolate mesh B vertices over time until it fits the state you want WARNING : If you mesh counts are too far apart of course you will have some weird results, try looking for Tesselation then to make your mesh with less poly conform to the one with more poly without "actually" being forced to keep the exact same number of vertices when you create your meshes. A mix of tesselation and approximation algorithm could do the trick i believe 

In unity, SortingLayers (or camera layers for that matter) are not groups of object you should see them as tags : specifically for the sprites, sorting layers are used to define the order of render of the objects. you can go through all the sprite-renderers and check their layers and apply something to their transforms but that will consume "a lot"* of resources. better solution is to really group your objects by parenting them to the same transform, and then you move that transform. For ex : 30 objects and you want to make three "layers" (but once again it is parallax layers not sorting layers (they can be related (you want stuff to be drawn in order) but are not the same thing)) what you would do in that case if create three empty game objects and drag 10 object onto each of them, then you'd move those 3 game objects according to the camera to achieve the parallax effect 

Which appears to be right on target, crossing 4 times to achieve a peak value of 0.01, after 5 seconds of simulated time. 

The fix is simple, integrate position in the middle of integrating velocity. (As in, add half of the force, update, then add the other half.) Here is a more in-depth explanation: $URL$ 

Then we also assert that the player's position after velocity is on the same line: With enough information to define the line now available, we can solve for the slope and intercept of the players line of motion to find: Applying the same technique to finding the slope and intercept of the wall yields: By solving the system formed by these two line equations, we find a (rather large) formula which directly computes the intersection, I've formatted this as code just in case you aren't familiar with maxima 

It looked logarithmic to me so I went ahead and fitted the natural logarithm to your points, then plotted to verify (and adjust coefficients). 

I'm trying to explore a little as to how I could make a simple 'dots and boxes' game. The problem I'm facing is in what way to store which lines are allocated by who. The problem lies in the fact that all inner lines are shared by neighbour boxes. So I can't just have four variables on each box because the right line of upper left-hand box is actually the same as the left line of box next to it. So I'd need them to be stored in one variable. What technique of saving this data would be practical in this case? 

I would very much like to build a game that is known as 'Unblock' or 'Yellow Out'. It is a puzzle game in which the task is to move a car out of a parking space by moving other cars in certain directions. These are links where the game can be played: 

The problem is that a face might have a closer distance but is still further away. All these methods seem unreliable. Edit: For example, in the following image the surface with the blue point as midpoint is painted over the surface with the red point as midpoint, because the blue point is closer. However, this is because the surface of the red point is larger and the midpoint is further away. The surface with the red point should be painted over the blue one, because it is closer, whilst the midpoint distance says the opposite. 

function does not execute the pixel shader. Instead: Set up your render target and draw a polygon to cover the entire screen. This is the common way to perform a "full screen shader" pass. 

One way to circumvent the accumulation of rounding errors is to re-normalize your vector when you calculate . This might look like such: 

The texture sampling function expects texture coordinates to be normalized into the [0 - 1] range. You can divide by the size of the DuDv map in pixels, to normalize your texture coordinate into the [0 - 1] scale. For the sake of efficiency, I prefer to evaluate on the CPU, and use multiplication instead of division in your shader. 

The "best" option is to try it yourself and see what's faster. I will put my money on option 1 being faster. You will only gain performance benefit this way if the pillar is incredibly expensive to draw, and you use effective culling. 

I didn't check thoroughly, but one major problem I see here is that you aren't following the OpenGL manual: This line of code is never valid: 

According to those docs over here, you should be able to create a basic surface shader with diffuse and lighting. And by tricking the in doing no specific action except getting vertex position and converting it to color you want (using an struct which could be a bit more evolved). After doing that and getting back the color you got in inside your albedo infos, you just let surface shaders do their job and take care of the lighting (you can specify it there ) EDIT : I think i'm starting to get what you mean by vertexColor, you mean Weight Shade : giving a vertex a 0-1 value and from this value get the color mix which correspond? or you just need access to the property in your input data for : 

Why multiplying by DeltaTime might fix the issue?? : Because AddForce() ADD a force to the sum of forces applied to your rigidbody, and then each force applied will diminish with time (except if you have no gravity and even ther i'm not sure) and if used in Update() it will add every frame the amount of force you want but frames are NEVER evenly timespaced so sum of forces will have different value each time you apply a new force so even if you add every time the same force, because you do not add it at the same interval of time it will stutter. What delta time does is that it will multiply your force by the timespan between the previous frame and this one so the final value will compensate this timegap between the two frames It is worth noticing that in this particular case you might try : 

Sounds like you are asking for a convex hull, this is sortof like "gift wrapping" all your vertices. (Otherwise, if the shape can be concave you cannot imply it by the vertices alone) Wikipedia has a good list of techniques here: $URL$ And google code even has an implementation (I haven't tested this): $URL$ 

You're right on track with using the context only from a single thread. You can only use an OpenGL context from one thread at a time, but you can do everything else in another thread. 

But in order to retain flexibility in situations where multiple handlers may need to observe the event, "Bubbling" can be applied so that all handlers get to see the event: 

You are using sampler 0 for every single texture, you should fix this call so that it looks more like: 

Ugly. But we have a closed form solution in time :) Before we can solve for the parameters you're interested in, we have to address one small ambiguity: The damped harmonic oscillator never stops, only decays. I will use a threshold where we consider motion "stopped", and solve for the peak which attains this amplitude. Now, from the solution above, I have obtained that the set of peaks are generated by: 

What is a good equation that results in such a graph? The transformations I can do myself I guess, but I'm just looking for the kind of equation. 

What exactly is used in the Painter's algorithm to determine the order in which objects should be drawn? 

Now I'm a little lost what I could add. Obviously, tic-tac-toe isn't that exciting or advanced, but I just miss something to salt it a little bit. Therefore, could anyone please suggest some ideas that would be worth implementing? Thanks! 

I basically want my camera in 3D move automatically. Currently, I have linear movement which is rather dumb, so I'd like to do a bouncing movement. However, what is a good equation for bouncing? I mean, for a circle you can do , but if I were to have a bouncing graph, what would the corresponding formula be? I guess it's something with as it has to 'bounce'. Something like (I made this up with Paint):