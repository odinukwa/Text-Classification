A normal replica set failover situation involves one or more members being unavailable, subject to the fault tolerance of your replica set configuration. As long as a majority of configured voting members in the replica set are healthy, they should be able to automatically elect a new primary without manual intervention. If a majority of members are unavailable and you need to manually reconfigure the replica set to recover write availability, the correct process to follow is a forced reconfiguration with the surviving member(s). This process will ensure that the replica set version information is updated so when former members rejoin they will detect the new configuration and resume syncing if possible. In this disaster scenario, you are effectively reconfiguring your replica set to have a single member (), and later re-adding other members to rebuild the replica set. 

All data dumped via has to be read into memory by the MongoDB server. It's also worth noting that backs up data and index definitions; the time to restore can also be significantly longer as compared to other approaches since will need to recreate any secondary indexes after the data is loaded. As noted in the MongoDB documentation, is useful for backing up and restoring small deployments but is not ideal for capturing full backups of larger systems: 

If you don't have many user accounts on the config servers, recreate the administrator & user accounts. This isn't ideal, but is probably the fastest approach. Export the users from your mmap database. This is more involved, but saves you recreating the users & roles. I've described steps for this below. Redo the config server migration with the user & role information included. I expect this is the least desirable option. 

The strict mode is only only intended as a data interchange format (for example, transferring a collection via and ). For queries in the shell you should use the representations as noted in the MongoDB Extended JSON documentation. 

The role does not grant access to run the command. Your command is returning an authorization error and you are then referencing a non-existent property which results in the "no results to show" message. You can confirm this by running , which should return something similar to the following if the current user is not authorized: 

The provenance of information on the MongoDB production notes isn't apparent at the moment, but WiredTiger and the recommendation to use XFS was definitely added much later than the Linux kernel details. The production notes share collective experience from known issues, but are typically recommendations rather than strict guidance. Most notes are added at the time a widespread problem is observed, but circumstances could certainly change. 

In general, large values of skip are discouraged (see: documentation). Depending on your use case for , alternative approaches to consider include: 

Note that doesn't have any data yet, because it has just been started up with the new WiredTiger dbpath. Use to load the config database backup you created in step 3. At this stage you should have: 

Balancer setting updates will not take immediate effect if there is currently a balance round / migration in progress, so you may want to disable & re-enable the balancer. For normal usage the default behaviour is recommended to ensure documents have propagated and reduce the impact of balancing. If your replica sets have more than 3 members, you could also consider increasing the to (see: Write Concerns for Replica Sets). 

For production systems it is typical to adjust the settings on Linux to allow more concurrent connections. For more best practices, I would recommend reviewing the Production Notes in the MongoDB manual. Provide an API If you are managing a shared server with resource limits, it is common to provide your own API rather than direct database access. This approach gives you an extra layer of abstraction so you can manage resource usage and server deployment independent of the client configuration. For example, you could move your database server or reconfigure from a standalone to a replica set, and the clients would not have to be aware of this. You can also manage custom resource limits (such as connections per client) via your API, based on the credentials the client uses to connect. Reduce the connection pool size in the clients MongoDB (as at 2.6) doesn't have an option to limit the connections per client. Normally client limits would be imposed via the driver (i.e. setting the connection pool size). For example, in the Java driver the default maximum pool size is 100. You've already suggested this isn't a desirable option as you don't want the clients to mess with the connection limits, but if you are going to impose a server side limit it would still be reasonable to have them set the pool size appropriately. Otherwise their applications will get frequent exceptions as you kill off excess connections. Monitor client operations If adjusting limits on the client or server isn't an option, an alternative to consider is implementing a script to count concurrent client connections (by IP) via and kill excess connections via . You'd have to be very careful to only kill client requests. The command is a superuser command that will let you kill internal database threads as well (which can lead to unpredictable outcomes). NOTE: This approach will be unsuccessful if your clients are connecting via a shared gateway (i.e. where the source IP does not uniquely identify a client). 

If the problem is easily reproducible, I would raise a bug report in the MongoDB Jira TOOLS project including more details such as the specific versions of and and command line parameters used as well as how long you waited. It seems reasonable for to have some sort of timeout or error handling for this case rather than hanging indefinitely; I also wouldn't expect to create files that the same version of cannot handle. 

This error indicates the process is unable to open any more file handles because the configured operating system resource limits (aka on UNIX-like operating systems such as Linux) have been reached. The settings are meant to constrain individual users or processes from consuming excessive system resources. Verifying and increasing ulimits is an admin task outside of MongoDB. See: UNIX ulimit Settings in the MongoDB manual for more information.