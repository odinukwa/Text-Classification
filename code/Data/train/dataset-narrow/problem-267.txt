In one of the articles i read the following regarding Bridge assurance: "When enabled, BDPUâ€™s are sent out all ports including the backup and alternate for each Hello Period. How this feature works is that it monitors the receipt of BPDUs on point to point links. If it does not hear a reply it changes the port state to an inconsistent state. This prevents any frames forwarding and a loop is avoided. The same is true of UDLD aggressive mode where a port err-disables." Q: When bridge assurance is enabled on a port, does that mean that it will start sending out BPDUs(irrespective of it's STP state)? If Bridge Assurance is enabled on a BLOCKED port, will the Blocked port also start sending BPDUs? If so, why? From what i know, the BPDUs are sent out ONLY from Designated ports once the STP is converged. Please correct me if i am wrong. 

ICMP is the result of initiating the ping from a source to a destination.It has got nothing to do with ARP as such. But for any 2 devices to talk to each other, each device would need to know the or layer 2 address of the other device(assuming the devices are in same network; if not in same network,they need to reach their gateway at least). This is where ARP comes in. ARP says, can you give me the mac address for this IP address? ARP helps in building the control plane(say building a road), before the actual ICMP traffic in this case(the data plane) starts moving. 

but now when I try telnet to the switch I get message saying,password required but not set I am wondering if there is way to stop the switch totally from listing to the telnet port 

What is the recommnded duplex and speed configuration for giga ethernet port connected to legacy ethernet (10 mbps) port and there is no available duplex command available on the etgernet side? If we keep the giga ethernet side with auto it will negotiate to 10 mbps half duplex and if we configure it with 10 mbps full duplex we will get alarm about misconfiguration on the switches, so what is the recommended? 

It is better to set the inter vlan routing on the coore switch only. Otherwise it will be very complicated and you will set the gateway for each vlan based on the switch and if you have DHCP that will not be possible . I do not see any nenifit to set the intervlan routing on each access switch 

Yes there is ICMP which did not have the concept of port number , and instead use the ICMP ID just like the port number and for more details you could see the below RFC: NAT Behavioral Requirements for ICMP 

Although enabling nat-t is global command but you can disable NAT-T on a per VPN basis, on crypto map entry: EX: crypto map outside_map 5 set nat-t-disable but anyway enabling nat-t is not going to impact your other tunnels at all. NAT-T functionality will allow the ASA to detect devices behind a NAT and will use UDP port 4500 instead of UDP 500. The current peers that are not behind a nat device will just work as usual with UDP port 500. 

I am trying to understand the difference between address-family vpnv4 and address-family ipv4 vrf So to test the scenario, i connected 2 routers(R1 and R2) linearly back to back. R1 has the loopback as 11.11.11.11 R2 has the loopback address as 22.22.22.22 On R2, i have the vrf TEST22. On R2, i also have a static route to network 100.0.0.0 in vrf TEST22 as shown below 

Broadcast domain : Every network represents a broadcast domain. E.g 10.0.0.0/8 is one broadcast domain; 20.0.0.0/8 is another broadcast domain. In general, every interface of a router represents a broadcast domain. For devices in one broadcast domain, to talk to devices in another broadcast domain, we need a Layer3 device (called a Router). 

While reading up on front-door vrf concept here, i am just wondering , what if we made the network statements more precise/specific or used different subnets altogether, we would never have our tunnel go down due to Can you please confirm if this is a good approch to understanding concept? 

So essentially, as we place a router in a network and assign ip addresses, we are creating new broadcast domains. 

Similary for X.600 part. Q1:What exactly is the bridge group part used for?What if i remove it? Q2:I understand that any frame coming to the switch with a tag of 500, will be put onto interface Bundle-Ether1.500 and also onto interface Bundle-Ether2.500. This tag will be stripped(at ingress ) and pushed back at egress(when the frame exits these interfaces(because of symmetric command). Is that correct understanding? Q3:Bridge-domains represent ONE broadcast domain.So all the interfaces under one bridge domain are part of SAME broadcast domain? As for above, the Bundle-Ether1.500 and Bundle-Ether2.500 are part of SAME broadcast domain BD1. Is that CORRECT understanding? Q4:Why at all do we need to group these Bridge-domains? What advantage am i getting?Why are we tying all the Bridge-domains under a single bridge group? Q5:What role is l2vpn command playing in above? 

CDP will be sent as untagged only and it will be recieved by the physical interface not by sub interfaces so in all cases it will be recieved 

If you connect server to 10 gbps uplink and you push data from your server to the aggregated uplinks you will have 1 gbps speed for single flow, speed will not be aggregated for any single TCP flow but it will use single uplink. For the uplink module it can be configured to support up to four 1-gigabit SFP transceivers or up to two 10-gigabit small form-factor pluggable (SFP+) transceivers. 

L2tp and GRE are totally diffrent protocols GRE is a simple IP packet encapsulation protocol. a GRE tunnel is used when packets need to be sent from one network to another, without being parsed or treated like IP packets by any intervening routers. a GRE tunnel interface comes up as soon as it is configured and it stays up as long as there is a valid tunnel source address or interface which is up. L2TP is a tunneling protocol (used to support VPNs) that allows multiplexing of multiple PPP sessions between two IP-connected endpoints, and a control protocol for dynamically establishing and maintaining the emulation of these PPP sessions. This is very different than GRE. 

The root bridge will keep sending Periodic configuration message with the Root Identifier and the Bridge Identifier would be the same as the Bridge think it is the root, This message will be relayed to all the bridges participating in the spanning tree and each bridge will add its cost to the root before sending it out to all its neighbours on the designated ports, this message will be like keep alive message from the root bridge to all the bridges and in case the root stop sending for max-age time that will trigger new root election. 

Not sure if this is is the right place to ask, but i will still go ahead.I have been reading up on Cisco's VMS solution and i see that the main stress is laid on the fact that things which were done using dedicated ASICs(burnt-in hardware into the box for dedicated application), can now be performed using software. Q1:How can a software ever do a piece of work that a hardware initially did?A software is nothing but a piece of code. I fail to understand how it works. Can you please give a real life example. Q2:Assuming the software can do the job of a hardware, how would it make that better? Is it because of --ease of update, ease of management and ease of shipping? Please clarify. 

Q1:As you see R1, learns the route 100.0.0.0 in the vrf TEST11. Even though i did not activate the neighbor under , but still R1 learns that route. How? Is the acting as the transport carrier for that route? Q2:In another scenario, i removed the neighbor from the vpnv4 address family on both R1 and R2 as seen below On R1 

As you see, on R1, the route to 100.0.0.0 no longer exists. Moreover, the BGP vrf peering is in Active state. Why is this happening ? is there any relation between and ? Is it mandatory for to have neighbor activated for vrf routes to be exchanged? 

I have questions regarding the following designs in my test lab: 1.Ethernet port of one switch is connected to TenGig port of the Firewall.Why would anyone do this(connecting Ethernet and Tengigabit Ethernet)? 2.N5k E1/4 (LC type) connected to E1/4(LC type) with MMF as the media. The speed shown is 10Gb. Is this possible? If so, how? 

Let us say we have switch with multiple gigabit interfaces and there is two machines connected to that switch, one with gigabit NIC and one with 100 mbps NIC and we start copying file from the gigabit machine to the fast ethernet machine. The file copy speed will be maximum 100 mbps but how the 1 gbps machine will know about the second party speed and send slower? Is it through TCP messages? And in case we are sending ICMP/UDP packets what will happen? 

For the required license this depend on the country regulations where you are setting . from technical perspective there is many things to consider but in simple answer you have two parts : 

assign the interface for security zone : EX: set security zones security-zone untrust interfaces ge-0/0/1.0 you have to enable ping in the security zone : EX: set security zones security zone host inbound traffic system services ping 

Enhanced Ethernet modules on ISR are hot swapable, but please note you need to Use the hw-module slot <1-4> oir-stop command when removing or replacing a hot-swappable Cisco enhanced EtherSwitch service module duringonline insertion and removal (OIR). 

As per Cisco : The console and auxiliary ports on Cisco IOS routers are . The console port and the auxiliary port are configured as data terminal equipment (DTE). For Cisco 1000, 1600, 2500, 2600, and 3600 Series Routers, the console and auxiliary ports both use RJ-45 connectors. Adapters are available for connections to PC terminals, modems, or other external communications equipment. 

the connection between your ISP and the internet and here you have two options, either you have direct connection to the internet or through bigger ISP the connection between the customers and the ISP and this will be the most difficult part , you need to decide how you will be connected to the end customer? through air or using some type of cabling ? in some country the last mile will be provided by the communication provider in other you need to reach your customer physically 

I want to ping from R2 to vrf lo0 of R1; but it fails, even though i have configured static route leaking. Please suggest why it fails 

By default,all the devices connected to a switch are part of same broadcast domain.They can talk to one another without the need of a layer 3 device. 

From the cisco docs i have: "vPC and HSRP/VRRP Object Tracking As Figure 67 suggests, itâ€™s important not to use HSRP/VRRP link tracking in a vPC configuration. Assume HSRP/VRRP object tracking is configured on both vPC peer devices and L3 uplink failure occurs on switch 7K2. This event triggers the HSRP/VRPP object tracking and the resulting SVI with associated HSRP/VRRP configuration is set to DOWN state. So everytime 7K2 receives a frame destined to HSRP/VRRP vMAC, it bridges this frame over vPC peer-link because the other vPC peer device is able to process this frame (as SVI with associated HSRP/VRRP configuration is still in UP state). Using vPC with HSRP/VRRP object tracking may leads to traffic blackholing in case object tracking is triggered: the reason is that vPC systems will not forward a packet back on a vPC once it has crossed the peer-link (because of the vPC loop avoidance rule), except in the case of a remote vPC member port failure. " Refer the attached image: 

I was going through the use cases of GRE tunnel and see that it is also used to carry multicast traffic over the internet.I understand that multicast IP belongs to address which is a public IP and can be routed. Q1:Why is multicast not supported over the internet ? Why do we need to encapsulate in GRE ? Can you please explain in laymen terms ? Q2:When we use the term 'internet', what exactly does it refer to? Would it be collection of all ISPs across the world?