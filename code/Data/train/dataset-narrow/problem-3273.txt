I started to try to read an MCP3008 ADC using SPI bit banging with pigpio. I wrote the unattractive little script below, starting from the example in the pigpio documentation and here is a screenshot of my output. I believe that this should read the lowest four channels of the ADC and print the output. Channels 0 to 3 are connected to +5V, GND, +5V, floating, so I expected to see values like 1023, 0, 1023, xxx where the last would be noise. Instead I see all 1023's. Have I done something terribly wrong? 

I'm trying to learn how to safely and reliably start and stop the pigipod DEOMON process from within a python script. If pigpiod happens to be running already, then this script is always successful. It stops pigpiod and then starts it again. But if pigpiod is NOT running when I run this, then MOST of the time it fails, and the standard message block that starts with "Can't connect to pigpio at localhost(8888)" appears when I try to instantiate pi = This happens even though returns , there are no exceptions, and a was executed "just to make sure". 

I've turned the WiFi off about five minutes ago so that explains the watchdog timer being 372 seconds. Is the value for frequency what I'm looking for? Question 1: Is using the lowest value for "when" a reasonable way to gauge roughly how long it's been since the system time has been checked against internet servers? Question 2: Does the ntp daemon make an estimate of system clock drift rate available in any way? If it's say 10 ppm or 100 ppm, is this reported somehow? Question 3: What do the characters in the first column such as '+', '*', '-', or absence thereof indicate? System: using Raspbian GNU/Linux 8 (jessie) 

You might want to check what GitLab actually put in your apt sources. if you take a look in you should see a gitlab entry. It should include raspberry pi in it somewhere. It may have mistaken Ubuntu Mate as the x86 version and apt is giving up. The link you posted looks a lot like the instructions for x86 (rather than ARM). The Pi instructions are here The install script itself more-or-less just runs: (you can view it here $URL$ - my line numbers are as per this file) Add signing key (line 107): 

When you installed docker did you just install the one from the Repos (on raspbian)? The output of would be helpful. I seem to remember there is old (1.3 or thereabouts) version of docker in the Repos for raspbian which predates swarm. If you setup docker via the foundations guide it adds newer repos to apt in order to get the latest versions. You'd then install docker as to get a version with swarm. 

See if adding a into your pipeline helps, it does some automatic 'magic' and works out a lot of the pipeline for you by matching input and outputs. This doesn't help if you want to do more interesting things or have much control but should get an image on the screen. its from the gstreamer base plugins so you may have to 

This acts to enable your service to run (as root!!) when the system reaches multiuser mode (after its done its basic setup). It will invoke python and your script in the background and just run it until it blows up or stops. It won't restart it or do anything else. If your script writes to the console it'll instead end up in the log accessible under . You'll almost certainly need to adapt the unit file to however you run your script. If you update the unit after you've enabled it then you'll need to let the system know via . Gory details of the unit options here. 

For the next 1000 milliseconds, a transition in either direction on pin 22 will result in a call to , passing the new level and the tick number (microseconds). If I understand correctly, in pigpio one can set up one watchdog per GPIO pin, so there could in principle be many running at the same time. My question is what are these watchdogs? Are they CPU threads, or are they running in the GPIO electronics itself, or something else? Like real dogs, can they compete, conflict, or collide (say two watchdogged GPIO pins experience edges at exactly the same time), or do they get along nicely with each other? This is from and may be of some help: 

I'm trying to check on the status of the pigpiod process from within a python script. These two methods both appear to work so far. Are there any significant advantages or disadvantages of one over the other? Are these likely to be reliable ways to do this? 

After turning WiFi on again and letting it run for a bit, I see the following, which suggests that it's periodically checking. 

My PiBox module, I've left the verbose print statements in to help explain what I believe each step is doing. It's certainly safe to ignore or delete them: 

The scripts and the results mostly speak for themselves. returns good data when I use the standard I2C GPIO pins, but the bit banging I2C returns what looks like random data. What might I try to debug this? note: I didn't forget to move the SDL and SCA leads to the appropriate pins. Using 3.3V to supply the DS3231 Real Time Clock. 

edit 1: I've taken a look at Install NTP on CentOS which turned up in a search for help trying to understand what "lithium.constan" meant, and I found the command: 

Assuming you already have said loop to fetch those strings and you only want the GPRMC and not GPGGA bit of it. Then, in python3, something like 

in Then Then you should see gitlab-ce available. My experiance with GitLab on the Pi wasn't too good, GitLab itself is great but i don't think the Pi is really up to it, mostly due to the limited memory. 

Best bet is to ask the supplier for support since by the looks of this was built for the Pi. There doesn't like like anything in that script that should cause problems but since it is, a few suggestions that might work. The blunt approach would be to just run it as root via then and see if that makes it happy. I'd tried this in a Raspbian Jessie Docker container as root after copying in boot and creating some of the directories that you should have if you have have the GUI and the script ran to completion. That said, it worked fine for a normal user + sudo too. You could try running the command as in case its relying on some special environment variable, which i can't see... or might work in case the shell isn't quite interpreting the lack of shebang directive at the top correctly. 

I'm setting it for 50%, you should be able to control it via the UI though. Now you should be able to fire up whatever you want on your phone and it'll play over Bluetooth. I had issues where pulseaudio (via pactl) needed muting and unmuting a few times before it would co-operate. If you aren't using a desktop (Raspbian Lite / Arch) then you probably won't have PulseAudio running by default and you'll have to do some extra work. I've got this working too but it's a little more involved - I can update this with those steps if that's what you are after. There are errors in the Bluetooth log will probably show them. The Sap one can be made to go away if you really want (you tell bluetoothd to not load that). I've never looked at the RFCOMM voice gateway one.... 

I'm using pigpio bit-banging script (download, GitHub) that interprets the pulse durations generated by the DH22 Temperature/Humidity sensor. It sets a 200 ms pigpio watchdog to the GPIO pin and attaches a callback, passing the tick count and new level. Here's a generic example: 

edit 1: per @Joan's comment: pigs, the socket interface to pigpio also returns random bytes. The following are the pigs equivalents to bb_i2c_open, bb_i2c_zip, and bb_i2c_close. All bytes are non-repeating. 

smbus works. When I convert these back from BCD to ints, I get a reasonable time object, with seconds increasing at 1 Hz. 

I am writing a data logging python script and I would like it to find out if the system clock has been synchronized via NTP recently, and if not, to attempt to cause it to happen before proceeding. Starting from this answer, I've found that for the status 

After disconnecting the WiFi, I captured a few responses. According to the page 22.13. Checking the Status of NTP the column labeled is "how long since last poll (in seconds)" and it increases with time as expected. But I don't understand why between 155 and 434 seconds that "jitter" changes, or between 434 and 687 seconds "delay" changes. Right now I'm classifying that as an inconsequential bug and ignoring it. To me, the value of "when" is most important 

What caught my eye is the "stability" measurement. I'll let it run for a while to see if it becomes non-zero, hoping it might address Question 2 below. edit 2: Looking at the question timed out, nothing received on ntpdc> loopinfo? I found the command 

appears when trying to kill it. So for almost a minute, the DAEMON is a zombie (so to speak). This means that the idea of quickly turning it off and then on again is a bad one. Instead, if the OP (me) really wants to do this with Python, the script has to honor this transient zombie status and not just start and stop it willy-nilly. 

You need to add a condition in that While loop to let it break and then process your Flask code. Currently, its just going to spin in there forever and never complete to allow the flask route method to end and return the result to the client. You might want to consider pushing the while loop into a method and having the start that as on a thread via add to top 

It doesn't handle sending nothing, or expections or anything like that and I am assuming you are sending in Ascii (if not swap that for utf-8 or whatever) but otherwise this should grab your length int then wait until its received all the rest. My test client was this python 3.4+ code from a remote host (to get over the UWP localhost problem). It breaks the sends to demo the waiting bit. 

Both DD and the disk imager will 'naively' just create an exact replica of the SD card, empty space and all hence why they are 16GB. These backups you can simply image directly onto SD card and its back where you left off. If you want to snapshot your compilation process outcomes you might want to look at alternatives to entire backups. Using Docker containers would let you incrementally build on what you have done by committing the containers at each step and only pay for (in storage terms) the differences between each version. There is a recent Raspbian base image on the docker hub for the Pi which should give you an accurate enough base system, you can even copy your existing work directly into it to avoid starting from scratch. If you want to backup your work now, you only have to export your docker containers which will be Base Image size + changes, probably under 1gb. This way you can test anyway and if it goes south just bin the image and return to a known good state. 

Question: What could cause to fail to start pigpiod successfully some of the time, but still always return and throw no exceptions? edit: RPi 3, Python 2.7, Raspian 8.0 jessie Failure looks like this: 

Today's announcement at raspberrypi.org: Raspberry Pi 3 Model B+ On Sale Now at $35 describes several improvements. In the linked YouTube video changes to the power supply are discussed between and , but I'm not quite sure which parts are historical review, and which are related to the most recent changes. Could someone point out which are the main points they make here about the new Pi 3B+ power supply? 

Questions are at the bottom. When adding a time stamp based on the Pi's system time to a data file, I'd like to include some information about how reliable that time is. For example, if the Pi has not yet made an internet connection since power up, the system time will be quite wrong by hours, days, or worse. If the last opportunity for synching to ntp servers was say 24 hours ago, it could potentially be off by many seconds, and if it were ten minutes ago, it's "good" as far as I'm concerned. I'm using the following python to capture all of the lines in the response so I can decide later how to interpret them, the suppresses the header of column labels 

but it seems like a bad idea to do that if it wasn't necessary. edit: using Raspbian GNU/Linux 8 (jessie) Question: How can I test the status and then conditionally force a synchronization only if needed? This answer suggests the package $URL$ but I'm not sure if this is advisable or not, so I thought I'd ask before installing and running it, and I'd still have to guess the status by comparing the results to the system clock and deciding if the agreement were good enough or not. I'd still like to know if ntp is active and that it believes the synchronization is close. 

Add the following method to your calling code and pass it the object you were using for . Then you can call this method instead of to handle the timeout case. 

you'll get the raw output - this needs a GUI for the ximagesink, I seem to recall you can encourage to jam the video straight onto the screen even from the terminal but i've forgotten the threats you need to make to get it to co-operate. you can test this (crudely :) ) by comparing outputs of 

I've just gone a roundabout way of flashing an SD card with IoT core as my Win10 machine has no SD card reader. Using the IoT dashboard I've downloaded the image onto a USB stick and cloned it onto SD using a linux laptop (using dd with error checking disabled , otherwise it blows up a little past 8GB). However, the IoT image is resolutely read-only, I can make any changes I want, hostname (via PowerShell or the web interface), adding new files, changing the password (which then sticks for that session) but after I restart it's exactly back to stock . Is there something in the imaging process that ties the image to the SD card? Seems like that would prevent you restoring a device from a borked SD or is that all part of the IoT dream? None of the settings provided from the Dashboard installer are reflected in the image either? Edit: Bad SD card - could not get it to perform any write operations, gparted, and fdisk would all happily report it was blitzed only for the partitions to still be there. Very odd. I would expect flashing the card this way would in fact work, coincidence proved its undoing in this case however.