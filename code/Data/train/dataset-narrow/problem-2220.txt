Let machine M solves the $\Sigma_2^p$-complete problem. We can use this machine to solve any "NP-Hard" optimization problem (which includes MAX-CLIQUE and MIN-COLORING) in additional time polynomial in size of input as follows: The solution is described for MAX-CLIQUE but the same idea works for any NP-Hard optimization problem. Let G = (V, E) and O = { $<G,k>$ : the size of largest clique in G is k } D = { $<G,k>$ : there is a clique of size >= k in G } Observation 1: Problem of deciding language O can be solved by making $\log{|V|}$ calls to the machine that decides D [Using Binary search] 

A new approach to dynamic All pairs shortest paths, Demetrescu. et. Al, JACM 2004 Voume 51 issue 6, 2004 Slide of Talk on Dynamic graph Algorithms by Dr. Surender Baswana in "Recent advances in data structures and algorithms" workshop held at IMSc, Chennai. Camil Demetrescu and Pino Italiano, Dynamic graphs, Handbook on Data Structures and Applications, Chapter 36. Dinesh Mehta and Sartaj Sahni (eds.), CRC Press Series, in Computer and Information Science, January 2005. [Draft (pdf)] 

I was curious to know whether there has been any progress/work in the direction of getting lower bounds for problems like: Shortest Paths(with/without negative weights), Mincut, s-t Maximum flows, Maximum (cardinality/weighted) matching. Any references related to this are very much appreciated and helpful. Reference [ L92 ] N. Linial, Locality in distributed graph algorithms, SIAM Journal on Com- puting, 1992, 21(1), pp. 193-201 EDIT: As suggested by Robin Kothari in the comments, I am making the question more directed. 

2-3. $\Psi(\mathcal{C})$ will typically become more difficult than $\mathcal{C}$ and this is a good thing. The difficulty of a proof-of-work problem needs to be finely tunable, but the original problem $\mathcal{C}$ may or may not have a finely tunable level of difficulty (remember that the difficulty in mining Bitcoin is adjusted every two weeks). The difficulty of problem $\Psi(\mathcal{C})$ is equal to the difficulty of finding some suitable $(k,x)\in D$ multiplied by $\frac{2^{n}}{C}$. Therefore, since the constant $C$ is finely tunable, the difficulty of $\Psi(\mathcal{C})$ is also finely tunable. Even though the problem $\Psi(\mathcal{C})$ is more difficult than the original problem $\mathcal{C}$, almost all of the work for solving the problem $\Psi(\mathcal{C})$ will be spent on simply finding a pair $(k,x)$ with $(k,x)\in D$ rather than computing hashes (one cannot compute whether $H(k||x||\textrm{Data}(k,x))<C$ or not until one has computed $\textrm{Data}(k,x)$ and one cannot compute $\textrm{Data}(k,x)$ unless one verifies that $\textrm{Data}(k,x)\in D$). Of course, the fact that $\Psi(\mathcal{C})$ is more difficult than $\mathcal{C}$ presents some new concerns. For a useful problem, it is most likely the case that one would want to store the pairs $(k,x)$ where $(k,x)\in D$ in some database. However, in order to receive the block reward, the miner must only reveal a pair $(k,x)$ where $(k,x)\in D$ and $H(k||x||\textrm{Data}(k,x))<C$ instead of all the pairs $(k,x)\in D$ regardless of whether $H(k||x||\textrm{Data}(k,x))<C$ or not. One possible solution to this problem is for the miners to simply reveal all pairs $(k,x)$ where $(k,x)\in D$ out of courtesy. Miners will also have the ability to reject chains if the miners have not posted their fair share of pairs $(k,x)\in D$. Perhaps, one should count the number of pairs $(k,x)\in D$ for the calculation as to who has the longest valid chain as well. If most of the miners post their solutions, then the process of solving $\Psi(\mathcal{C})$ will produce just as many solutions as the process of solving $\mathcal{C}$. In the scenario where the miners post all of the pairs $(k,x)\in D$, $\Psi(\mathcal{C})$ would satisfy the spirit of conditions 2-3. 

Check this book, Computational Complexity: A Quantitative Perspective, it studies the size of some complexity classes using resource-bounded topological tools. It gives interesting topological view on the $P$ vs $NP$ problem. Basically, If $P \ne NP$ then $NP-P$ is topologically not small. The class $NP$-complete is topologically small. According to the author, topological not smallness of $NP-P$ means that it is of the second Baire category. 

Check this link for pointers to several network analysis and visualization tools. They include: GINY: Graph INterface librarY 

Here are several open problems: 1-Major open problem is the problem of computing approximate Nash equilibria. 2- Existence of efficient algorithm for computing pure Nash equilibria in congestion games? 3-finding equilibria with minimum inefficiency? 4-Tim Roughgarden, in Communications of the ACM , posed the following open problem: 

Avi Wigderson, in Knowledge, Creativity and P versus NP, argues that the philosophical question: Can creativity be automated? is equivalent to P = NP?. 

This survey book, Satisfiability Problem: Theory and Applications, is appropriate for introducing k-SAT to mathematicians. It is not very recent but still very valuable resource. 

An $NP$-complete structural problem is to decide the existence of odd (even) hole in directed graphs. Anna Lubiw proved the $NP$-completeness of the above two problems. A hole is chordless cycle of length greater than three. A cycle in directed graph is chordless if its length is greater than 3 and no two of its vertices are joined by an edge of the directed graph which does not belong to the cycle. As for undirected graph, testing for the existence of odd hole passing through a given vertex is $NP$-complete. Specifically, the problem is to decide whether a graph contains an induced odd cycle of length greater than three, passing through a prescribed vertex. (Odd hole in a graph is an induced cycle of length at least five). However, the complexity of deciding the existence of odd hole is a long standing open problem (if we drop the requirement of passing through a given vertex). In contrast, the task of finding an even hole in a graph is in $P$. The structural property of the cycle is the property of being chordless. In directed graph, this is enough for NP hardness (in addition to parity requirement) while in undirected graphs odd parity of the chordless cycle is required for $NP$-completeness. The importance of detecting odd-hole structure in graphs is highlighted by the recent breakthrough of the Strong Perfect Graph Theorem. It shows that a graph is perfect if and only if neither it nor its complementary graph has an odd hole. 

Suppose that $p$ is a polynomial. Then does there exist a polynomial $q$ where if $f:\{0,1\}^{n}\rightarrow\{0,1\}^{n}$ is a bijection where both $f$ and $f^{-1}$ are computable by circuits with at most $p(n)$ gates, then there exists involutions $\iota_{1},\dots,\iota_{k}:\{0,1\}^{n}\rightarrow\{0,1\}^{n}$ where $$f=\iota_{k}\circ\dots\circ\iota_{1}$$ and where each $\iota_{i}$ is computable by a circuit with at most $q(n)$ gates and where $k\leq q(n)$. 

$\textbf{Other Advantages of this technique:}$ The SLT offers other advantages than conditions 1-4 which are desirable or necessary for a proof-of-work problem. 

Improving the security/efficiency balance: The SLT will help in the case that $\mathcal{C}$ may be too easy to solve or too difficult to verify. In general, $\Psi(\mathcal{C})$ is much more difficult to solve than $\mathcal{C}$, but $\Psi(\mathcal{C})$ is about as easy to verify as $\mathcal{C}$. Removal of a broken/insecure problem: The SLT could be used to algorithmically remove bad POW problems in a cryptocurrency with a backup POW-problem and multiple POW problems. Suppose that an entity finds a very quick algorithm for solving problem $\mathcal{C}$. Then such a problem is no longer a suitable proof-of-work problem and it should be removed from the cryptocurrency. The cryptocurrency must therefore have an algorithm that removes $\mathcal{C}$ from the cryptocurrency whenever someone has posted an algorithm that solves problem $\mathcal{C}$ too quickly but which never removes problem $\mathcal{C}$ otherwise. Here is an outline of such a problem removal algorithm being used to remove a problem which we shall call Problem $A$. 

Mining pools are more feasible: In cryptocurrencies, it is often very difficult to win the block reward. Since the block rewards are very difficult to win, miners often mine in things called mining pools in which the miners combine their resources in solving a problem and in which they share the block reward in proportion to the amount of “near misses” they have found. A possible issue for $\mathcal{C}$ is that it may be difficult to produce a qualitative notion of what constitutes as a “near miss” for the problem $\mathcal{C}$ and the algorithm for finding a near miss may be different from the algorithm for solving $\mathcal{C}$. Since the pool miners will be looking for near misses, they may not be very efficient at solving $\mathcal{C}$ (and hence, few people will join mining pools). However, for $\Psi(\mathcal{C})$, there is a clear cut notion of a near miss, namely, a near miss is a pair $(k,x)$ where $(k,x)\in D$ but where $H(k||x||\textrm{Data}(k,x))\geq C$, and the algorithm for finding near misses for $\Psi(\mathcal{C})$ will be the same as the algorithm for finding solutions to $\Psi(\mathcal{C})$. Progress freeness: A proof-of-work problem $P$ is said to be progress free if the amount of time it takes for an entity or group of entities to find next block on the blockchain follows the exponential distribution $e^{-\lambda x}$ where the constant $\lambda$ is directly proportional to the amount of computational power that entity is using to solve Problem $P$. Progress freeness is required for cryptocurrency mining problems in order for the miners to receive a block reward in proportion to their mining power to achieve decentralization. The SLT certainly helps mining problems achieve progress freeness. 

I stumbled on an open problem posed by David Eppstein and I am interested in its complexity status. He conjectured that it is NP-complete. Input: $n$ by $n$ matrix of 0’s and 1’s, sequence of $n^2$ 0’s and 1’s Question: Is there a path through adjacent matrix entries, covering each matrix entry exactly once, with values matching the given sequence? 

The complement of your problem is known as graph automorphism problem (GA). It is a candidate for $NP$-intermediate problems. The problem is not known to be solvable in polynomial time. Also, It is not known to be $NP$-complete. It polynomialy reduces to the graph isomorphism problem (GI) but no known polynomial reduction from GI to GA. Unique-GI is equivalent to GA. 

Several hard graph problems remain hard on planar cubic bipartite graphs. They include Hamiltonian cycle problem and perfect P3 matching problem. I'm looking for a reference on interesting subclasses of planar cubic bipartite graphs. An interesting subclass contains infinite number of graphs and excludes infinite number of graphs. More importantly, Which hard problems do remain hard on nontrivial subclasses of planar cubic bipartite graphs? 

The actual proof of the $NP$-hardness of computing Cheeger constant ( or edge expansion) was given by Kaibel in a technical report by a reduction from MAX Cut problem (See theorem 2). The proof is an extension of the proof of the $NP$-hardness of the equicut problem given by Garey, Johnson, and Stockmeyer in Some simplified NP-complete graph problems. V. Kaibel: On the expansion of graphs of 0/1-polytopes. Technical report arXiv:math.CO/0112146, 2001 EDIT: The argument below is incorrect, as pointed out by Chekuri, and left for educational purpose. This is not a reference as you requested but it explain the folklore status of the hardness result. Here is a proof idea of the CoNP-completeness of deciding whether a connected cubic graph is edge-expander and therefore determining the Cheeger constant $h(G)$ is CoNP-hard. The minimum bisection problem is $NP$-complete for connected cubic graphs. Here we want to decide whether a graph $G$ with an integer $k$ can be partitioned into two equal size parts such that the number of cut edges is less than $k$. Note the complement of this problem is equivalent to deciding whether the graph $G$ is expander or not ( every balanced partition of $V$ has cut edges more than $k$). P.S. Arora in this seminar states that it's $CoNP$-hard to recognize $\alpha$-expander graph ( edge-expansion). $URL$ 

It is well-known that every permutation can be written as the composition of two involutions. Suppose that $p$ is a polynomial. Then does there exist a polynomial $q$ such that if $f:\{0,1\}^{n}\rightarrow\{0,1\}^{n}$ and its inverse are permutations which are computable by combinatorial circuits with at most $p(n)$ gates, then there exists involutions $g,h:\{0,1\}^{n}\rightarrow\{0,1\}^{n}$ such that $f=g\circ h$ and where $g,h$ are computable by a combinatorial circuit with at most $q(n)$ gates? 

a. Alice pays a large fee (the fee will cover the costs that the miners incur for verifying the algorithm) and then posts the algorithm which we shall call Algorithm K that breaks Problem $A$ to the blockchain. If Algorithm K relies upon a large quantity of pre-computed data $PC$, then Alice posts the Merkle root of this pre-computed data $PC$. b. Random instances of Problem A are produced by the Blockchain. Alice then posts the portions of the pre-computed data which are needed for Algorithm K to work correctly along with their Merkle branch in order to prove that the data actually came from $PC$. If Alice's algorithm fed with the pre-computed data $PC$ quickly, then the problem is removed and Alice receives a reward for posting the algorithm that removes the problem from the blockchain. This problem removal procedure is computationally expensive on the miners and validators. However, the SLT removes most of the computational difficulty of this technique so that it can be used if needed in a cryptocurrency (instances which this technique is used will probably be quite rare).