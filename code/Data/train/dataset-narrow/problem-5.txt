Give me a red button, so that if anything else fails (and production is impacted), I just have to push a magic button, be patient (for a few secs) and be 100% sure a rollback completed with 0 rebuilds of any kind (= Backout is the name of the phase we use for it). This boils down to "component level backups" of any files/components you will be updating by your change in production, whereas these backups are made at the very moment the change is going to be applied. and this for any type of artifacts included in the change. If later on (5 mins, 2 days or 1 week later) something goes wrong in production, and it turns out to be caused by your change, all you have to do is to have an automated procedure (the red button!) in place that you can launch, and which simply restores the backup you should have available. Attention, if there were database updates involved, this backout may not be an option anymore. While things like "backups overlaid" (because of concurrent changes/fixes got applied to production) is another scenario where the red button is no longer available. 

Back in the days, before DevOps was called DevOps, we used terminology which might possibly help to understand these new DevOps terms, such as: 

Part of what (I think) CI and CD is about, is processes that get repeated over and over again (= the "continuous" part of it). However continuous in this context is not exactly (I think) like a river where water keeps going (flowing) all the time. Instead it's rather something happening every X seconds, minutes, hours etc. So assume some test-environment where every day, eg, from 5 pm to (max) 6 pm all required processes are executed to rebuild all executables that are impacted by the changed dependencies (sources, includes, etc), combined with appropriate CI/CD processes related to them. While before 5 pm and after 6 pm, none of these kinds of processes are allowed to be executed (eg to ensure the stability of the related environments). Does such kind of periodicity (= between 5 pm and 6 pm, every day) fit with CI/CD or not? Or is it rather that periodicity has nothing to do with CI/CD? 

The benefit of unikernels is managing a large number of applications in a protected space. (Some might say all the benefits of Docker without all the overhead). (Please don't get me wrong - I'm a huge fan of docker and use it 20 times a day in my work - I'm using this question as a a way to explore an idea). The following commentator writes: 

I've been evaluating Netflix Ice - as a billing tool - but it appears to only work at the Machine instance level - not at the container level. I'm looking for a tool to help generate billing reports for using docker containers across a cluster of docker servers on EC2. (Non ECS) My question is: How to track (non ECS) container costs on EC2? EDIT: I have different groups each running their container on the same host. So I want a way to split instance costs by container usage. 

I'm having a discussion with a friend about use cases for Docker. One guy in the team wants to use Docker for everything - like a kind of universal unix process wrapper. The other thinks that Docker should only be used for stateless applications like Microservices and AWS Lambda style apps. We've engineered proof of concepts for both. On our docker cluster we have a shared drive that gets mounted when the Docker host is mounted, and if a Database in a container is mounted, it simply mounts a volume to the shared drive. My friend still sticks to his position, despite being shown the contrary evidence. (He also argues that Docker adds unnecessary risk by adding complexity to the stack.) I'm trying to listen and understand his point of view, both in an act of empathy, but also to better reason with him. (We all get on quite well - so this is a mix of in-jest and serious discussion). Kind of the question behind the question is: are databases cattle? This comment suggests that a good automated backup and retrieval strategy for your database is indistinguishable from a cattle server. My question is: What are the reasons Docker should not be used for databases? EDIT: People have asked me to clarify my terminology. I was assuming that the database application was in the container, and the storage was in the volume. What I meant was, the RDBMS is in the container, and the database storage is in the volume. Some commentators have suggested that the docker volume drivers aren't going to work with database writes very well. (Or something to that effect). Could you please expand on that? 

Get Required Budgets An effective way to get Required Budgets, is to create/submit an appropriate business case which explains the tangible and intangible benefits of various DevOps practises by applying them to some real world cases that apply to the company itself. Below are some real world cases I experienced myself, as an SCM consultant hired by some companies where these things had happened. I know, SCM is only part of DevOps, but it's the area where I have some expertise ... 1. Benefits of automation Due to some strike from only 2 (!!!) computer operators (who did not type the console commands anymore that they where expected to type), trains had to be halted somewhere half the way between 2 factories (since the system at the factory where the train was heading to was down, crucial data about handling the train was not available). By implementing an SCM system, many operator commands were automated. 2. Reduce software license costs Some software vendor had decided to increase some yearly fees for the (outdated) SCM software, which management didn't agree to. Therefor they created a special project to get it replaced by some alternative SCM software. The budget of the project was equal to the yearly fee they didn't want to keep paying. That included flying in engineers from other continents (like me) to make the project succeed. 3. Reduce operating costs Some major insurance company was using some FTP software to transfer software fixes to about 13.000 midrange computers (AS/400s) throughout the country, and this whenever "a" fix became available. The cost of 1 such transfer was about 4 USD (13.000 x 4 = 52.000 USD for a single transfer ...). The software consisted of 120.000 components, developed/maintained by about 150 developers. Do the math about the probability that 1 developer made 1 (tiny) mistake in any of these 120.000 components, which made it to production, and required an urgent fix, which would cost another 52.000 USD (just for the transfer!). By implementing an adequate SCM system (with managed test environments, approvals, etc), this company achieved a major cost reduction. Think about it, if the SCM system could prevent the need for only 20 transfers of urgent fixes, it resulted in a cost reduction of 52.000 x 20 = 1.040.000 USD (quite a budget to implement an SCM system, they only needed a fraction of that amount to get the job done). 4. Reduce costs of unavailability If the above cases are not convincing enough, then think of the system(s) of a major credit card company being unavailable around the world. I've been told that 1 second of unavailability costs them 1.000.000 USD. That's probably also the reason why, for a very long time, such companies have sophisticated DevOps tools in place, for many decades already. Because each second they are not in business costs them a fortune. 

There is a great discussion of the Cattle vs Pets distinction from Randy Bias here. Martin Fowler talks about a SnowFlakeServer. In a series of talks, Adrian Cockcroft talks about how they moved toward Cattle Servers for solving a scalability problem at Netflix. The challenge with this distinction is always managing persistent state. Does it make sense to treat your database servers as Cattle? It does if you (a) manage the state outside of your cattle model (external volumes for your docker containers), or (b) use a distributed database like Cassandra that allows for individual nodes to fail, but still maintain state in the cluster. I get that you can get very close to the 'disposability with persistent state' of Docker containers mounting a shared volume, with launching AMIs to machine instances mounting a shared drive. You can get closer this this idea of scheduled cluster management by having an autoscaling group that recreates machines that you've blown away. To me - the machine instances lack the granularity of a docker container. They gravitate more towards the 'pets' end of the spectrum. My question is: Does the "cattle not pets" distinction apply as equally to machine instances as to containers? 

I'm trying to wrap my head around the Azure confidential computing offering. It appears that that AWS does not offer encryption at the application level (see diagram for what I mean by this:) 

I've got an ec2 autoscaling group that starts in the morning and finishes in the evening. I'd like to create a 'button' that people can click to warm up the autoscaling group to run jobs in the middle of the night (only on an on-demand basis). My question is: What is the ec2 cli command to modify the minimum number of nodes in a scaling group? 

Assume you want to implement continuous-integration (= CI) and continuous-deployment (= CD) for building and maintaining websites using Drupal (let's assume for Drupal Version 7). Often times Jenkins seems to be recommended as one of the most appropriate solutions for doing so. But what kind of CI/CD related functionality can I actually use it for? Here are some of things I'm thinking of, but I'm not sure if I'm correct on that, and/or if these are the only things: 

So you may want to give "that" a try ... PS: I'm assuming your question is about Endevor SCM, and not Endevor DB (that a completely different story, and a challenging one ...). 

You can even configure the monkyes, so that they fit your business needs. If you dig deep enough within those Github links (i.e within the Support link), you'll also find a link to join the SimianArmy Google Group. 

Access to perform updates to the target deployment areas (i.e. production) is limited to selected automated systems, which have appropriate audit trails (= logging) of any kind of updates to the areas they manage. Manual updates to the target deployment areas, for whatever reason, are no longer allowed by the typical team members (user ids) that used to be able (authorized) to perform these updates. Instead NEW (additional) user IDs will be created which will have all required permissions to (still) perform such manual updates, whenever needed. But to actually be able to use those new user IDs (= perform a logon with them), the team member who wants to perform a logon with such new user ID will have to perform "some" extra step to get access to the password for such new user Id. Ideally this extra step is automated also (use your own imagination how it should look like), but if anything else fails: just contact (= eMail, call, etc) the gate-keeper of the required password, including "which issue they have to get fixed" (similar to your question). Getting such gate-keeper in place is not an easy job. And the most resistance will come from ... the team members (for all sorts of reasons). Therefor a variation of those new user IDs (as in the previous step) is that each team member gets an extra user ID (with the password they decide themselves), but with an extra string attached to it: they are only allowed to perform a logon with that (extra) user ID if they actualy have a good reason to do so. And each time they perform such logon, they are required to file some type of report about "which issue they fixed" (similar to your question). 

In an environment of Secured Virtual Private Clouds, in a Cluster of Docker Containers, we have to setup some routes. We can do that with the Ambassador pattern, which is simple and easy to maintain. (Docker does have some usage of IPTables under the hood - but from what I can see the Ambassador pattern uses socat, and not IPTables to achieve its forwarding. We can setup NAT rules with IPTables to achieve a similar goal. My question is: When would I choose IPTables over an Ambassador pattern for port forwarding? 

In our work environment we have a standard Corporate Intranet with Active Directory. We've been granted limited access to an AWS VPC. Our connection allows outbound (from the Intranet to the VPC) but not inbound. That is - if we run a webserver in the AWS VPC, then a client in the Corporate Intranet can connect and browse to it. But a client in the AWS VPC cannot connect to a webserver in the Corporate intranet. Note that this 'outbound connections only principle' applies to all ports, not just http port 80. An associate has suggested we need to replicate our Active Directory down to the AWS VPC AD. I think it is not possible to do a one-way replication. My question is: Can you replicate Active Directory from a Corporate Intranet to an AWS VPC where there is an outbound-only link? 

Now to me, a server application written in C++ (not memory managed) vs Java (memory managed) has no impact on the utility of a unikernel. In both you get the isolated protected way to manage your application lifecycle. Perhaps I'm missing something. My question is: What does it mean that "outside of memory-managed code execution runtimes (JVM, Go, etc.) the usefulness of unikernels starts to rapidly decline"?