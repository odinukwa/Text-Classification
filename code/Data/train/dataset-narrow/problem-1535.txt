shame that so many monitors are 'widescreen' these days... I wish the 4:3 form factors were more common (and cheaper at resolutions of 1600x1200 or higher)... not everyone wants to watch a movie on their PC. I have a 1200x1600 (portrait mode) 20" and while I enjoy (and depend) upon the vertical size, it still feels a wee bit cramped horizontally. 

This works pretty well for me on linux only: -a = All sockets -n = doNt resolve IPs -p = show Pids/Programs associated with each 

Sounds like you have a policy problem... ... and presumably this was caused by a real problem vs you being paranoid. Aren't you limiting the effectiveness of the computing platform by doing this? many scripts can be run by simply invoking the interpreter directly: sh ./mybashscript.sh perl ./myperldaemon.pl So presumably you are trying to prevent a native executable from running? Best to deal with this problem via policy and policing/auditing... at best, you'll only keep the less experienced users at bay anyway. 

7.5% for a single child doesn't sound too abnormal, but it all depends on what the child is supposed to do... I run systems with apache and mod_perl and those children get huge. Watch your apache children memory footprints over time to see if they stabilize. If not, use MaxRequestsPerChild to control how often they are restarted. Use MaxClients to limit how many concurrent children you have (to avoid swap or out of virtual memory issues). In my experience, it's generally a memory bottleneck on the webservers. 

I always run the above to make sure it works, then remove the 'n' flag that once I'm happy with the results. The key features of the above combinations: 

The process is waiting on some system resource, perhaps NFS? that is not allowing it to 'let go'. Would love to hear some solutions to this beyond mine... reboot the box, or let the process sit around. I wonder if you might be able to 'STOP' the process via kill -STOP {PID} to prevent it from consuming more cpu. Restarting it should be possible even with another stopped process sitting around, but it may require a list port or shared memory segment that is still in use by the other process. 

Notice the *:65535 in the NAME column. Does anyone know why lsof is not reporting the port in use? I am running as root. I am using a mix of lsof and os versions: lsof v4.77 on Solaris10 sparc lsof v4.72 on Redhat4.2 etc I know that linux solutions can use "netstat -p", so I guess I'm only looking for why solaris isn't working, but I find lsof is frequently silent and not showing me expected data. 

We run into this when editing CGIs... the #! interpreter line gets Ctrl-M on it somehow, rendering the executable not found. It looks like a perl error but is really the 'she-bang' interpreter line having 'nearly' invisible characters at the end. In our case, we found this after the file was written. try using dos2unix command to copy to another name and try hitting that. If it works, you've found your root cause. Sorry to say that I have no real workaround except to recognise the problem when I see it. --edit-- Our error message is usually: scriptname: file not found NOT the 'file busy' mentioned in the question. 

Then you must force authentication for your restricted area by denying all, then allowing just those subnets, followed by any requirements for how they actually would authenticate. Satisfy all is used to insure both policies of access are required. 

The ssh process likely daemonized, disconnecting from the shell. You can think of it like this (but possibly not in this order): The 'ssh' process you launched actually closed all it's file descriptors (stdin,stdout,stderr), disconnected from the tty, and forked another child ssh. then called exit on itself. This orphaned the child process and the original ssh process actually 'completes'. As a result, the original ssh process is complete and the orphaned process is no longer a 'child' of your shell. Use 'ps -ef' or 'ps -fu$USER' instead to see the ssh process you are interested in. 

I'm monitoring the TCP stack on a server hoping to generically infer problems with application on the box. My first inclination is to measure the number of sockets in all reported states (LISTEN,ESTABLISHED,FIN_WAIT2,TIME_WAIT, etc) and detect some anomalies. A teammate suggests that 'lsof' would be a better tool to see what state the TCP stacks are in. Any preferences or experience tips from the serverfault crowd? 

Sometimes it's hard to decide if you want to REPLACE the timestamps in your 'filter', or if you want to preface the line with the timestamp found. I flip back-n-forth on that one. 

The number one tool I wish I had when running a small site is 'push-button' builds. It makes patching, updates, and rebuilds easier, which can address a myriad of other problems in the future. No ssh properly installed on all boxes? no curl/wget/vim either? what about other in-house tools you'd like to have on each box? Having central management of your servers is one of the first tools you should have working to make future efforts much easier. 

bugfix response for chrome has been slower than other browsers, thus they prevent it from running at work via windows policy controls. Now that updates have started, wonder if they'll ever reverse that policy :-( 

I would recommend against using 'tcsh' as a shell. It tends to make you think that writing shell scripts in tcsh is ok. It's not. The real attraction seems to be the 'up-arrow' command line ease-of-use, but with bash you get that anyway. Also, coding scripts is much easier in 'sh' and it's derivatives (like bash and ksh)rather than csh and tcsh. I've also found that sh is on ever flavor of unix, and bash is easily obtainable as a first choice add-on. I'd warn against using the features of ksh and bash (like variable arrays and hashs) unless you can guarantee it's existance throughout the enterprise. 

TO epoch: If you have Date::Manip module installed for perl (which usually ISNT there by default), you can use: 

RLimitCPU doesn't always help because not all portions of the apache code have checks for it. MaxRequestsPerChild may not help either, as I've seen this with relatively 'fresh' children. In my case, I suspect it's something to do with the module we're using (mod_perl) and perhaps something with a broken socket connection. We only seem to see this problem with browsers connecting, not from wget or curl (which we use heavily for 'data delivery'). 

Always in the middle... both vertically and horizontally... Avoid the top floor, ceilings leak Avoid the bottom floor/basement, too easy of access (broken window) and/or flooding. presumably they have a freight elevator, so loading servers wont be an issue you might try not-too-far from the external A/C units, which may reside on the ground, on the top, or sometimes in the middle if the building is tall enough. Farther distance to the A/C unit will cost you in some way, but I suspect it's negligible. 

When I ran a group of admins the issue of who was oncall was always a concern. At the time I felt that it was all part of the job of being an admin, but alas, in hindsight, while I loved the job, it didn't mean they did. Not paying a stipend or some other acknowledgement of required ad-hoc hours (either onsite or remote) is just a slap-in-the-face. Regardless of budgeting, folks asked to carry pagers and response in a timely manner should be given credit either as pay, flex hours, paid cell plans, etc. Where I work now it's a flat-fee stipend. You can spend it on your cell plan, internet connection, laptop, etc... if you do your job well, 'in theory' you wont get calls that could be avoided, just 'acts of god' ;-) Luckily all the stuff I do now does not require on-site presence (whew). 

smashing magazine (online) has several articles on favicons: $URL$ While not required, favicons will often be requested by modern browsers to add some eye-candy to the location bar, table labels, and bookmarks. Once you are inspired by the examples from the link above, you can try using an online generator to build your own: $URL$ (look down the page for favicon generators). I found the following one pretty nice: $URL$