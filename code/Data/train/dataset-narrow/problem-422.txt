Since you have Change Tracking = AUTO configured you are telling the SQL Server to check on the changes that being made in the . That means that the process is still running at a low level. I would not be at all surprised to see some activity as the Full Text Indexing service is checking for changes. Populate Full-Text Indexes for SQL Server 2012 A similar question was asked here back in 2013: Full Text Search Populate Status - Processing notifications Quoting from Frank J Garcia's answer: 

That is all there is to it. You can, of course, automate the distribution across several dataases on a server or even several servers. Depending on your landscape the details are different. Assuming that all databases are on a single server it could be: Companies like Red Gate, Apex, etc have tools to help you automate this if you choose to acquire a tool. 

It is certainly possible to use a Maintenance Plan to handle the fragmentation issues. However, many people use the free scripts at: $URL$ I am part of the 'many people'. These scripts by default implement the suggested standards for reducing the fragmentation of indexes. So, if you implement the script with one of the many sample settings further down the page, it should bring your indexes into better order. Your database is not particularly huge, so scheduling an online index rebuild on a relatively quiet time, perhaps Saturday night if that is a low use time, and let it run. If you link to the home page ($URL$ you will also find scripts for database backups and integrity checking. It seems that you have a good backup schedule overall, though I do not know your retention period, so you do not need to change unless you personal see the need. Second, regarding the large LOG file, you can look into the DBCC SHRINKFILE() command to reset the size of the log file. On the other hand why bother unless you need the space. DBCC SHRINKFILE ('LogFileName', ); If it does not shrink the first time, run CHECKPOINT, backup the log again, and try to shrink the file again. Once the high order portion of the log is empty (through the log backups) the file will be able to shrink. 

In this case, especially if dealing with several other collations, it will simplify the code on your server. 

Your comment seems to imply that the first two columns combine into a single key value. Assuming the format to be two 0-justified 7-character columns becoming a 14-character column you would just concatenate the two columns. Snippet: 

Then here is some code to get the answer. I handled (after a fashion) unscheduled breaks as well. See: 

You can do it on the fly without storing the stripped down name, but that would mean recalculating the strings (e.g. Lisa's Nights, Lisa's Night, LISASNIGHTS) each time a new entry should to be checked against an existing string. On the other hand, if your table also has a column for the STRIPPEDDOWNNAME, you can leverage SQL Server's constraints. Create a (or a ) on the STRIPPEDDOWNNAME column. Then you will calculate the stripped down name only once, when you insert it into the table. With the the SQL Server will immediately let you know if an inserted string is a duplicate. You can then capture the error and respond as appropriate to your application. I encourage you to let the SQL Server manage the duplicate check whenever possible. 

Although you limited the memory to 28 GB out of 32 GB, this is not the only memory that SQL Server uses. The running programs and needs within Windows take some additional space. If you want to closely tune the memory use, I recommend reading this, which works well for my servers. See Jonathan Kehayias at: $URL$ It basically says "reserve 1 GB of RAM for the OS, 1 GB for each 4 GB of RAM installed from 4â€“16 GB, and then 1 GB for every 8 GB RAM installed above 16 GB RAM." This suggests that your Maximum Memory should be tuned to 25 GB. You can dynamically alter the min/max by setting a new value for those measures. The OS will adjust in a relatively short time without a reboot. EDIT: Of course, as both Jonathan and Shanky mention, you still need to monitor your performance counters, since any general answer will likely need tuning. 

If you have the default trace configured, and if the change was recent enough, you might be able to find the change. The default trace only maintains a certain amount of trace, but I have found unexpected changes by examining its contents. See: $URL$ This describes how to read the default trace so that you can research problems. There is no backward looking tool to find database growth and other changes. If you want to have a persisted history of changes you will need to periodically query the needed data and store it in a database table. With SQL Server 2012 Change Tracking can also answer questions like this. 

Overall, the database metadata and the user data that you insert/select/update/delete are in general protected by Transactions, Isolation Levels, Latches, and Locks. Since your question is about metadata, a simple example: 

Almost certainly it does trim the transaction log. (Otherwise the Amazon cloud will fill up with transaction logs.) Some details from the Amazon site include this topic and two sub-topics that you can investigate: $URL$ 

The restore will be followed by some upgrade steps to bring the SQL Server 2005 database format up to the SQL Server 2008 database format. (Note: You will not be able to restore the 2008 database back to 2005.) There are limits to how early a version of SQL Server can be restored to 2008, but 2005 should work fine. Here is a link to the supported upgrade paths to SQL Server 2008: $URL$ 

You cannot change the Instance Name after it has been installed. But you can uninstall that SQL Server instance and reinstall as a DEFAULT instance. Ideally you should make a backup of the server, then restore the backups to the new server. You can technically detach databases and attach again after the reinstall, but that includes the risk of losing your detached databases. See Aaron Bertrand's post: $URL$ When installing a default instance of SQL Server Express at the Instance Configuration page, you must choose the Named Instance radio button and type in the default instance name of MSSQLSERVER. All default instances use the MSSQLSERVER internally, but they just do not make it visible to you. 

Are you also checking for blocking? Blocking could certainly contribute to timeouts and can be fairly easily tracked. A timeout that is not related to a block has some other issue. The 30 second timeout is a common clientsetting, but it can be controlled by the command object. If you set it to 0 then the connection will not timeout. To set up monitoring for blocking using Event Notifications and Service Broker read Tony Rogerson's post: $URL$ In his example, he monitors for blocks of 10 seconds or longer (and for every period increment, 20, 30, 40 seconds, etc.) I monitor for every 25 seconds, which gives me a close to the timeout look at what is running. Both the blocked and the blocking processes will show up in the XML description of the block. Keeping the information in a table also provides history that you can review over time. 

Selecting and deleting a large number of rows will lead to blocking, which is probably why you cannot use the system for a couple of hours. The easiest way in SQL Server Express to control blocking is to control how many rows you are deleting at one time. For example, you might read Aaron Bertrand's notes here: $URL$ He points out that deleting (or, in your case, copying and deleting) smaller numbers of rows at one time allows the deletes to succeed, then frees up the locks so that other work can progress, and so on. See Aaron's code samples and the approaches that you might use. As he notes, one size does not fit all. 

If the users are administrators, there is no way to keep them out. This could be sysadmin on the server, dbo on the database, etc. The easiest way to keep other (non-Administrator) logins out of your database is to never grant them rights or (as one part of your code suggests) drop any users that are not 'automacao' or some other needed service logins. Also, rather than cycling through every securable, you can use (assuming SQL Server 2005 and forward) is to grant at the database level. E.g. 

Since one potential 'band aid' to the NOLOCK issues is to stop using NOLOCK and begin using READ_COMMITTED_SNAPSHOT isolation, I want to point you to the blog post at $URL$ by Kendra Little: Implementing Snapshot or Read Committed Snapshot Isolation in SQL Server: A Guide. Kendra provides a fair amount of detail on benefits and risks with using the READ_COMMITTED_SNAPSHOT isolation level. 

The real problem with using one Service Account for all of your servers is: How secure do you want to be? If someone is able to hack that one account, then all 35 servers are exposed in one swoop. I much prefer at least a Service Account per server. And having several Service Accounts for different uses is also recommended for security. See: Configure Windows Service Accounts and Permissions This offers extensive suggestions on service accounts. It is, of course, up to you to determine how much you need or want to do. Of course, you can grant local permissions for a service account on another server. This would allow it to make changes according to the permissions you have granted. 

You can only get data from a SQL Server that you are logged into. The metadata of table definitions, stored procedures, and so forth is also data. So, your login through the linked server must be successful. This can be done by granting your login rights on the other server. Or, the security of the linked server could be through a specific login that has the needed rights. However, getting rights to the metadata of a database does not imply that you need rights to the data in the database. For example: 

This certificate is used as a mechanism to protect SQL Server's login information(including password) when using SQL authentication. By default this self-signed certificate should only affect the login information and only when using SQL authentication. Edit: My certificate name usually matches the SQL Server's login account. Export the certificate and delete it by using "certmgr.msc". Then run "setup.exe" to install SQL Server 2008 again. You also can add this certificate to the Trusted Root Certification Authorities store to solve this issue. In order to do this, please execute: