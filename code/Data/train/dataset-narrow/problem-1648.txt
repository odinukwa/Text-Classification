I think your title is incorrect. Should it be "How do I send eMail from another Domain?" or something like that. There are any number of reasons you get classified as spam: 

An authoritative answer should come directly from a one the name servers for the domain. Non-authoritative answer can come from any server which has an answer. Unless the configuration has been recently changes the answers will be the same. Requests can specify that they require an authoritative answer. These may require additional lookups as an authoritative server must be contacted. When changes are being made it is possible to get differing answers from different authoritative servers. The answer with the highest serial number should be the most recent answer. (In rare cases where the serial number is being reset, this is not the case.) Non-authoritative answers should be answered by the first server contacted which has an answer. This is the fastest possible response. These answers are sufficient for most uses. Services like Google are a special case. They use special servers which provide different answers depending on your location. They may also do load balancing. Both of these will result in different answers over time. Cached (non-authoritative) answers will likely be older and reflect the preferred servers at the time the result was cached. Google tries to direct you to servers which have the best connectivity to your location. These servers should have lower RTTs than other Google servers at other locations. 

Looks like you have a good set of check in place. Securing your files so the server can not write them stops a number of attacks. Changing the ownership to a user id other than and limiting write access to the owner will prevent most attempts to change your content. Limit write access by www-data (the web server) to as few directories and files as possible. If your content is mostly static you could consider a checksum database like Tripwire. If your content is in a revision control system, then you can use a read-only id to update the website. Using the your RCS's diff utility will find any changes. A log scanner such as can report some attacks. 

This should block most of the servers hitting you. You can logscape with fail2ban or CSF and block those IPs at the firewall for a few hours. You may want to rather than connections which fail reverse DNS validation. This will give you a chance to whitelist legitimate hosts. Use a caching DNS server with a large cache (several thousand entries) on your mail server. With the load you are experiencing you will be generating several queries for each host that is hitting you. 

There appear to be two handlers for php: and . Check you configuration to see which is being used when files are processed. An alternative would be to do internal redirects from to such as: 

The jobs you are running under should handle expected errors. It is unusual to have jobs that periodically fail. Fix the programs so that they don't fail. That may mean you need to wrap them in retry logic that waits a short period of time, then retries once or twice. However, I don't really like the retry solution. If you have jobs failing routinely because of a "network hiccup", address the network issues. If it is for other reasons, address that issue. If you want to alert only if the cron job is no longer working (definition required), don't alert on the cron job failure. Build a monitoring process that can detect the problem. This can be difficult. If you are monitoring an update process, there can be a period where there are no updates that triggers a false positive on the monitor that assures updates are being done. Make sure you have scheduled your cron jobs so that you don't have conflicting jobs running at the same time. A timeline chart may help. You may be able to cobble together a monitor for your critical jobs that counts the failures and successes and alerts if there have been too many successive failures. This will require an extra step in the job to report its status. 

can be quite effective for this kind of trouble shooting. Try leaving it running with an interval of 15 seconds or 60 seconds. The statistics will give you information on which routers or segments may be causing problems. With the recent trend to use of level 2 routers, these will be invisible to MTR (and other tools). Many TCP stacks have counters available which can be used to identify problems. Retransmitted and out of order packets may be indications of problems, especially if the percentage is out of normal. If you are sending large blocks of data, then TCP windowing can cause problems. Check to see if you may be experiencing Bufferbloat issues. There are tools like which can do similar tracing to that provided by over TCP, This can work around restrictions on ICMP echo packets. Tools like , , or can be used to monitor your network and database server on an ongoing basis. They can also send alerts if problems are identified. 

Per domain aliases (may be documented as virtual domains). Global aliases (apply to all domains) which are ideal for addresses like postmaster. 

The remaining packet loss may be due to packet buffering switches either upstream, or in your network. You may find configuring bandwidth limitations at 80 to 90% of the network capacity reduces the packet loss. Try verifying the packet loss with the backup router out of the configuration and the other router connected directly to the EDD. If you still get occasional 2% packet loss the problem isn't your switch. The switch may be your most likely single point of failure, so document procedures for removing it from the configuration if it fails. 

If you are registering your DHCP clients in DNS, then you may show stale information in DNS. You should be careful when allowing DHCP to be registerd in DNS. It is possible, for DHCP clients to register using service names like , , etc. This could allow them to replace services or perform man-in-the-middle attacks.