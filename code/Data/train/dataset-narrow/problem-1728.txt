I'm new to cloud/virtual hosting and having a difficult time finding much useful information on google about this question. Are there any reputable hosting providers out there, aside from hosting.com, who allow you to upload and manage your own vmware server virtual machines, rather than providing you with their standard images? Is this a viable option for scaling a web application in transition between shared and dedicated hosting? Any major downside? edit -- found this: $URL$ $URL$ $URL$ After talking to some reps I'm getting the impression that these services are highly overpriced. Is this typically the case? 

Any ideas? edit - upon further inspection, this is only happening on the host computer. Another network computer doesn't experience the problem -- at least not at the same time, although there is the occasional lone timeout every 30 attempts or so. On the host computer, it normally stops responding like clockwork every 20-second or so. I'm very confused, but I'm starting to think my windows configuration is to blame. edit2 - tried setting a different ip for the vm, no luck ... only the host computer is having trouble. Host computer talking to the router and other computers - no interruption Other computers talking to the vm - no problem Deferred host computer's dns to the router and told the router to connect to the vm's dns - host is getting uninterrupted dns now Host trying to reach the vm 'directly' (ie. by network ip) - 15-seconds on, 15-seconds off. If it's an ip conflict, I have no idea the source. Tried assigning the host computer a static network ip address. No difference. Feels like someone's playing a cruel prank on me or something... anyone have a guess at all as to what I should test at this point? 

BeeGFS (Parallel networked filesystem) NFS (oldschool "network file system") Lustre (Parallel networked filesystem) CIFS/Samba (More often used to "share files" among workstations) 

Yes you should add NS records for all of your DNS servers in your zonefile. You should be able to ask all of your DNS servers: "what are the DNS servers for example.com" For example: 

We have a solution for this at work where we use SSH host certificates signed with a known CA to get rid of this problem. If you are not familiar with ssh certificates you can read about it in the ssh-keygen manual and also there is a lot of nice guides out there: 

Like the comment says OpenSSH is pretty strict about what permissions it allows on chroot directories (for good reasons). So the solution is to have a subfolder with the permissions you want to use for your particular case. 

This post is very unclear and not very specific. It also contain several questions. But I will try to give you some pointers where you can start to look. The first one is how you should handle the storage at the storage server. If you want to have a single namespace for the whole amount of disk space it would be easier to have some sort of raid solution. This could also be good for data integrity or data availability (or both) depending on what raid level you choose. There is multiple ways to implement raid (both in hardware and software) so you need to investigate what suits your needs. If you want to have it simple I would recommend some sort of software raid that doesn't require any specific hardware to start with. The other question is how you will share this data among the cluster nodes. The simplest way to do this is probably by setting up a NFS server on the storage server. But there is multiple network file systems out there with different characteristics. Please have a look at: 

I'm running an ubuntu server (bitnami lampstack) vm in vmware-server on a windows host machine. The vm every 10-20 seconds stops responding to the host computer for no apparent reason. I can still access the vm and ping it on other network machines and over the remote console on the host, but it will periodically stop talking to the host in every other way -- no ping, no response from the webserver, no dns -- even though all are alive and kicking at the time. Bridged networking, /etc/network/interfaces is pretty straightforward. 

(sorry about the images -- no SSH at the moment) When I ping the machine from the windows host, it looks like this: 

I've set up dnsmasq on a virtal machine server in order to handle static wildcard subdomains on my local home network for development purposes. The idea is to have *.local.myapp.com resolve to the VM itself (bridged networking), running the http and dns server. I've installed dnsmasq on the VM. And edited dnsmasq.conf to resolve to the VM's network IP: 

I know this is a horrible, generalized question with no good answer, and I apologize ahead of time, but I wonder if someone could take a stab at a very broad estimate. Let's say you have a dedicated MySQL server running on about $1K worth of modern hardware. Let's say the average user makes 20 read requests and 5 write requests per minute -- all straightforward queries, no joins; mostly along the lines of 'select this row by UUID' out of an indexed table of ~10,000,000 rows. Very, very, very, very roughly how many concurrent users would you expect a server like that to handle before you're 'pushing it.' 

There a a few questions related to using DFSR and Shadow Copies together, but none that indicates if Shadow Copies replicate or not. Meaning, if I have a a pair of DFS replicas with Shadow Copies on Server-A, can I revert that file to a previous version on Server-B? If so, will that reversion be replicated back to Server-A? I suspect not- that VSS is a local NTFS feature and outside the scope of replication, but I cannot verify that myself at the moment. 

I have a situation where I need to make the best of a bad DSL situation. The CPE is a black box with no access to DSL diagnostics. My plan is to get some sort of DSL hardware that exposes link-layer state and gives me knobs to tweak. I'd like to be able to mitigate bufferbloat as much as I can while I'm at it. The obvious choice would seem to be a Sangoma card in a linux system. I have no way of knowing if that will do anything for me without testing it, however. I have no other access to WAN troubleshooting equipment. Are there any other options avail to me as a consumer? 

The cloud part In order to have the ssh host keys unique and generated at the host we have the private host CA key stored in the images we use. When the image boots the first time sshd generates new keys and then we have a "firstboot" script that basically does this: 

But if youÂ´re not used to this kind of stuff I would recommend to have a loo at BeeGFS or NFS. NFS have support of of the box in *nix operating systems and BeeGFS should be pretty easy to set up. 

Then all you have to do on your side is to trust this single CA key by adding it to your either personal or global known_hosts file. You will now be able to log in to the machines without and having them automatically trusted. This may give you some security concerns because the CA is available inside the image at first boot, but it works for us because we have very good control over the infrastructure and we think its good enough to remove it once the certificates are generated. Possible alternative solution using SSHFP Another solution that just came to mind is the use of SSHFP records. If you have a DNSSEC signed zoned you could have the VMs report their key by some method to your DNS server and then publish their keys in DNS using the SSHFP record type. The OpenSSH client will trust these records if the zone is signed. I have writted a short guide on this: