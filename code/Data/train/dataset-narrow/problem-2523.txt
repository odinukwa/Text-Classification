We have been working on one for the last few years: Lem, a higher-order, typed language with backends for OCaml, Coq, Isabelle/HOL, HOL4, LaTeX and HTML. Lem has been used internally in the group to formalise various machine models (PowerPC, ARM, and so on), memory models (the C memory model, etc.), programming language semantics (OCaml Light), and so on. 

If you're interested in writing a purely functional database, you should probably check out Phil Trinder's PhD thesis which was on this very subject. He has a chapter on the use of B-Trees. 

You might want to take a look at the compiler literature for some ideas. What you're describing is akin to a well-known compiler optimization (virtually any modern compiler worth its salt will do it) called constant folding. Of course, constant folding goes further in not just identifying constant expressions, but replacing them by their value. In particular, compilers use a dataflow analysis to identify such constant expressions. Any good compiler textbook will discuss this. 

[1] Tight Bounds on the Fourier Spectrum of $\mathsf{AC}_0$, A. Tal. CCC'17. [2] On polynomial approximations to $\mathsf{AC}_0$, P. Harsha and S. Srinivasan. RANDOM 2016, 

On the other hand, Blais [2] showed that non-adaptive testing of $k$-juntas had query complexity $\tilde{O}(k^{3/2})$, hence the separation. 

Here is a detailed outline, not entirely made rigorous. Setting $b_n \stackrel{\rm def}{=} \frac{1}{6}-Y_n$, with $b_0 = 1/6$, we have $$ b_{n+1} = \frac{4}{3}\left( \sqrt{1+\frac{3}{2} b_n - \frac{9}{2} b_n^2} - 1\right)\tag{1} $$ (I like to set things near zero.) By induction, $b_n \geq 0$ for every $n$, and a simple computation shows that $b_{n+1} - b_n \leq 0$ for all $n$. By monotone convergence, $(b_n)_n$ converges, and the fixed point being zero we have $$\lim_{n\to \infty}b_n = 0\,.\tag{2}$$ We can do a Taylor expansion of (1) to get $$ b_{n+1} = b_n - \frac{27}{8}b_n^2 + o(b_n^2)\tag{3} $$ i.e., summing, $$b_{n} = b_0 - \frac{27}{8}\sum_{k=0}^{n-1} \left(b_k^2 + o(b_k^2)\right)\,\tag{4}$$ Solving the recurrence $$ \tilde{b}_{n} = \frac{1}{6} - \frac{27}{8}\sum_{k=0}^{n-1} \tilde{b}_{k}^2$$ yields $\tilde{b}_{n} = \frac{1+o(1)}{6+\frac{27}{8}n} \displaystyle\operatorname*{\sim}_{n\to\infty} \frac{8}{27n}$. (For instance, solving the continuous version $h' = -\frac{27}{8}h^2$ with $h(0)=1/6$.) "Therefore", $b_n \displaystyle\operatorname*{\sim}_{n\to\infty} \tilde{b}_{n}$ and $$ Y_n = \frac{1}{6} - \frac{8}{27n} + o\left(\frac{1}{n}\right)\,.\tag{5} $$ 

Luo's book on the Extended Calculus of Constructions is also a good reference. ECC was quite influential in the design of Coq's type theory. 

Levy's call by push value calculus makes a distinction between values and their thunks. For a value of type the computation has type . Lindley and McBride's Frank language, inspired by CBPV, also makes this distinction between computations and values explicit, though unlike Haskell, Frank is strict. 

For verified complexity analysis in other theorem proving systems, see e.g. Tobias Nipkow's paper on this subject using the Isabelle theorem prover ("Amortised Complexity Verified" at ITP 2015) which presented a framework for deriving amortised cost bounds of functional data structures and applied it to a number of well known data structures. The code is freely available on the AFP. I don't think anything Nipkow does is tied to Isabelle and could be easily ported into e.g. Coq. 

using the notation of the book. However, if you look at the proof of Theorem 6.7, $(4) \Rightarrow (6)$ follows from the Np-Free-Lunch theorem (Theorem 5.1), or rather its implication in terms of VC dimension (Corollary 6.4, and then Theorem 6.6). I'll let you check the details, but essentially it proves the stronger-looking statement you need: 

[1] A. Blumer, A. Ehrenfeucht, D. Haussler, and M. K. Warmuth. Learnability and the Vapnik-Chervonenkis dimension. Journal of the ACM, 36(4):929â€“965, 1989. [2] S. Hanneke. The optimal sample complexity of PAC learning. J. Mach. Learn. Res. 17, 1, 1319-1333, 2016. [3] S. Arunachalam and R. de Wolf. Optimal quantum sample complexity of learning algorithms. In Proceedings of the 32nd Computational Complexity Conference (CCC), 2017. 

For type theory, the TYPES/announce mailing list appears to be the place where these are announced. There's also the LOGIC mailing list where theoretical jobs are announced in the German speaking world. The Haskell subreddit at Reddit.com also has some announcements from time to time related to functional programming and type theory. The best thing to do is probably to subscribe to a big university theory group's announcement mailing list. Announcements get CC'd to those as a matter of course. 

I suspect this answer will be a bit of a ramble. First, it isn't enough to ask "how tactics work in proof assistants" because they work differently in different proof assistants. There's two main classes of assistant used today: those derived from the original LCF, like Isabelle, HOL and HOL light, and type theory based proof assistants like Coq and Matita. In these two different classes of proof assistant the tactics work in different ways, a reflection that what's going on under the bonnet in e.g. Isabelle is quite different to what's going on under the bonnet in e.g. Matita. Ask yourself: what's going on when we attempt to prove a proposition P in Matita? We introduce a metavariable X with type P. We then play a game, so to speak, where we refine X, adding more and more structure to the incomplete term, until we get a complete lambda-term (i.e. containing no more metavariables). Once we are in possession of a complete lambda-term, we type check it with respect to P, making sure it inhabits the required type. We then see that in Coq and Matita, a tactic is merely a function from incomplete proof terms to incomplete proof terms, which hopefully adds a bit of structure to the term after application (this observation has motivated quite a bit of recent work by e.g. Jojgov, Pientka, and others). For instance, the Matita tactic "intro" introduces a lambda-abstraction over the existing term, "cases" introduces a match expression in the term, and "apply" introduces an application of one term to the other. These basic tactics can be strung together, using higher-order functions, to create more complex ones. The basic idea is always the same though: a tactic is always aiming to add a bit of structure to an incomplete proof term. Note that, implementers aim to give back a term that typechecks again after every tactic application. Strictly speaking, there's no requirement for them to do so, as all that matters for type theory based proof assistants is that, when the user comes to Qed the proof, we are in possession of a proof term that inhabits the proposition P. How we arrived at this proof term is largely irrelevant. However, both Coq and Matita aim to give the user back a (possibly incomplete) proof term that typechecks after every tactic application. Yet this invariant can (and often does) fail, especially in regard to the two syntactic checks that CIC based proof assistants must implement. In particular, we can carry out what appears to be a valid proof, applying a series of tactics until there are no open goals left. We then come to Qed the supposed proof, only to discover that Matita's termination checker, or its strict positivity checker, complains, as the proof term that was generated by the tactics has invalidated one of these syntactic checks (i.e. a metavariable in argument position to a recursive call was instantiated with a term that is not syntactically smaller than the original argument). This is a reflection that the CIC type theory is, in some sense, not "strong enough", and does not reflect the positivity or size syntactic requirements in its types (an observation that motivates Abel's sized types, and some recent work on positivity types). On the other hand, LCF-style proof assistants are quite different. Here, the kernel consists of a module (usually implemented in a variant of ML), containing an abstract type "thm", and functions that implement the inference rules of the proof assistant's logic, mapping "thm" to "thm", and so forth. We rely on the typing discipline of ML to ensure that the only way of constructing a value of type "thm" is via these inference rules (basic tactics). Isabelle's kernel is here. Proofs then consist of a series of applications of these basic tactics (or more complex, larger tactics, which are again made by stringing together simpler tactics using higher-order functions --- in Isabelle, the higher-order functions, called tacticals, can be seen here). Unlike type theory based proof assistants, there is no need in an LCF-style assistant to keep an explicit proof term witness lying around. Correctness of the proof is guaranteed by construction, and our trust in ML's typing discipline (many assistants, e.g. Isabelle, do, however, generate proof terms for their proofs). 

As mentioned in a comment above, you can contribute to the TCS Wikipedia Project led by Shuchi Chawla: 

(Sorry, this is a bit biased towards papers I have co-authored, mostly due to my familiarity with those.) 

TCS+ (an online biweekly seminar series, using Google Hangouts as medium), has a YouTube Channel, as well as a listing of previous lectures: $URL$ (This listing also includes the slides of the talks). The topics are quite diverse, and meant to cover all areas of TCS. 

Let $f\colon 2^{[n]} \to \mathbb{R}$ be a submodular function (one can assume $f$ is bounded, if this helps). We are given noisy oracle access to $f$: on any $S$ and for any $\tau > 0$, one can obtain an additive $\tau$-approximation of $f(S)$ (at cost $\operatorname{poly}(1/\tau)$). I am interested in what is known in minimizing (up to some arbitrary (additive) accuracy $\alpha>0$) $f$, given this sort of access: If we had exact oracle access, then this could be done in polynomial time, exactly; what about robustness to approximate queries? Is there any algorithm (or, on the other side of the spectrum, lower bounds) for it? 

JHC uses a different approach. The compiler's intermediate language is a dependently typed lambda-calculus where there is no distinction between types and values. JHC therefore can perform a case analysis on the type parameter of a function and call the correct overloaded function directly. The JHC website goes into some depth on the implementation, as well as its advantages over the standard dictionary passing implementation. 

I think what you are looking for, in the context of verified transformations in a proof assistant, is known as "refinement", wherein a very-high level, inefficient implementation of some algorithm is gradually refined down into an efficient, low-level implementation, proving that the transformations preserve certain properties along the way. Various tools have been developed to help the user do this without being overcome by tedious book keeping. In terms of the state of the art, I think Lammich's tool in Isabelle/HOL has been used successfully in at least two significant developments (a verification of Hopcroft's algorithm by Lammich and Tuerk, and a verified implementation of an LTL model checker by Esparza, Lammich et al). Ironically, I was also reading this paper this morning, about a similar tool, newly developed, in Coq, courtesy of the dependent_types subreddit on Reddit. 

As mentioned in a comment above, the Boolean Hidden Matching Problem introduced and studied in [BJK04,KR06] seems to (almost) meet your requirement. The input size is roughly $n\log n$ (as an input is of the form $(x,M,w)\in\{0,1\}^{2n}\times\{0,1\}^{n\times 2n}\times \{0,1\}^{2n}$, where $M$ is a very sparse matrix that can be encoded with $n\log n$ bits); and $\textsf{yes}$- and $\textsf{no}$-instances of the promise problem have distance $\Theta(n)$, The one-way randomized communication complexity of $\textsf{BHM}_n$ is $\Omega(\sqrt{n})$, as shown in [KR06]. 

[BCOST15] Eric Blais, ClÃ©ment L. Canonne, Igor Carboni Oliveira, Rocco A. Servedio, Li-Yang Tan. Learning Circuits with few Negations. APPROX-RANDOM 2015: 512-527 

There is a second proof, somewhat more fun, given in that short note (credit to John Wright for pointing it out, and emphasizing it's the "fun" one). Here it is: Proof. Again, we will analyze the behavior of the empirical distribution $\tilde{p}$ over $m$ i.i.d. samples from the unknown $p$. Recalling the definition of total variation distance, note that $d_{\rm TV}({p,\tilde{p}}) > \varepsilon$ literally means there exists a subset $S\subseteq [n]$ such that $\tilde{p}(S) > p(S) + \varepsilon$. There are $2^n$ such subsets, so we can do a union bound. Fix any $S\subseteq[n]$. We have $$ \tilde{p}(S) = \tilde{p}(i) = \frac{1}{m} \sum_{i\in S} \sum_{j=1}^m \mathbb{1}_{\{s_j=i\}} $$ and so, letting $X_j \stackrel{\rm def}{=} \sum_{i\in S}\mathbb{1}_{\{s_j=i\}}$ for $j\in [m]$, we have $ \tilde{p}(S) = \frac{1}{m}\sum_{j=1}^m X_j $ where the $X_j$'s are i.i.d. Bernoulli random variable with parameter $p(S)$. Then, by a Chernoff bound (actually, Hoeffding): $$ \mathbb{P}\left\{ \tilde{p}(S) > p(S) + \varepsilon \right\} = \mathbb{P}\left\{ \frac{1}{m}\sum_{j=1}^m X_j > \mathbb{E}\left[\frac{1}{m}\sum_{j=1}^m X_j\right] + \varepsilon \right\} \leq e^{-2\varepsilon^2 m} $$ and therefore $\mathbb{P}\left\{ \tilde{p}(S) > p(S) + \varepsilon \right\} \leq \frac{\delta}{2^n}$ for any $m\geq \frac{n\ln 2+\log(1/\delta)}{2\varepsilon^2}$. A union bound over these $2^n$ possible sets $S$ concludes the proof: $$ \mathbb{P}\left\{ \exists S\subseteq [n] \text{ s.t. }\tilde{p}(S) > p(S) + \varepsilon \right\} \leq 2^n\cdot \frac{\delta}{2^n} = \delta $$ and we are done. $\square$