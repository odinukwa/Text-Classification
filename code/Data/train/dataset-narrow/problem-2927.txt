This is only a small part of it; the full output leaves a lot to explore. Nonetheless, at this point, students will see fewer differences than similarities (hopefully). Additionally, consider this SO question: "Compiled vs. Interpreted Languages". It's not quite so black-and-white, and forcing it into a pure dichotomy may do more harm than good. Let it be a bit messy. That's what learning is all about. 

Context: Over the past school year I spent a significant portion of my time preparing to teach AP CS A next year. From choosing textbooks to writing the College Board syllabus, I essentially started from scratch in designing my course. I'm pleased with all aspects of it as it currently stands, but there is one nagging element: the programming environment. All students taking AP CS A next year have experience using Cloud9 because that's what we used for C/Python/HTML/CSS this year in AP CSP. Only in the last couple weeks did I discover how easy it is to install the JDK in a Cloud9 workspace and write, compile, and execute programs in Java from the command line. (I had read somewhere a while ago that Java and Cloud9 didn't play nicely.) I had been BlueJ all the way until that point, and I do still very much like BlueJ. However, not having taught the class before, only designed it, here's my (hopefully specific enough) question: Will students lose anything in their understanding of and proficiency with Java, especially in terms of the AP Exam, if the class only uses a command-line environment for program compilation and execution? There are many pros/cons to one IDE over another -- a topic which I think is too broad for this community. I just want to make sure, from those who have experience with this course, if there's something that the command-line environment lacks for students that an IDE like BlueJ doesn't lack. I don't want to end up doing students a disservice with respect to the objectives of the course based on this decision. Edit: Cloud9 is a cloud-based IDE, which makes it ideal for my 1:1 Chromebook environment (however, I do have access to a PC lab for additional software, so that is not a restricting factor for me). As they define it, "Cloud9 combines a powerful online code editor with a full Ubuntu workspace in the cloud." You essentially get a text editor and a terminal for compiling and running programs. I've found that anything I can do via a Linux command line, I can do in Cloud9. It has a number of additional features that make it great for classroom use. I originally chose it because it's the environment used for the CS50 IDE. See more here. 

Re too broad: I don't think the question necessarily is, but "Azure" is. I think you could spend an entire 5-hour session just listing Azure services without going into any detail on any of them (and in evidence of that I've been to a two-day MS training course on Azure which only managed to scrape the surface of less than 5% of the available services: it was more a starting point for research back in the office than training. And that was aimed at experienced developers). IMO pricing considerations should be a small subsection of "Why cloud?". People signing up for a workshop, and especially if it's part of a technology club, expect to be doing hands-on practical training, and (excepting the introduction/overview) for the teaching to be geared towards the specific things they will be putting into practice. They can read price lists at home. With regards putting into practice, are they going to be working on a project which you define or bringing their own ideas to the table? If the latter, I'm not seeing where exactly you brief them on the right kind of project for the specific services you're going to cover. Or are you intending to choose the two or three data services which are the best fit for the majority of the projects after talking to the participants about what they're trying to build? But then point 3 looks like PAAS and point 4 like IAAS, so maybe they're going to be working on different projects in the different sections? 

I'll enumerate how I used each of them and for simplicity refer to them by the number listed above. I pulled questions from #1 throughout the year. The first unit covered a basic intro to binary, so as a short formative assessment, I gave students the four sample questions they could answer having studied the basics of base systems. This was within the first two weeks, so right away we could talk about exam-style questions, specifically the ones that required selecting two right answers. I used sample questions a few more times during the first semester, but I didn't make it a priority (see disclaimer above). However, on the last day of class in the fall, I gave students a modified exam. We had studied three of the six Big Ideas tested on the multiple-choice exam in depth, so I selected questions equivalent to half the exam (enough for the allotted time and perfect for matching the pace of the real exam) and surprised them with this practice exam. There was no warning; students just had to trust what they had learned up to that point. We started the second semester going over this exam. I did an item analysis over break, so I could hone in on strengths and weaknesses and address them in the spring. In the second semester, I started to use #3 at certain sporadic moments. Since The Internet is arguably the most fact-driven of the Big Ideas, I used it as a resource for designing an exam on my Internet unit. Students were encouraged to buy it, but it was not a requirement. So much time in the second semester is taken up by Explore and Create that the multiple choice test is a lower priority until after spring break. Based on this year's Easter timing and AP schedule, I had two weeks of classes to devote strictly to exam preparation. This amount of time was more than adequate to build students' confidence and familiarity with the exam format. During these final two weeks of prep, I went through each question from #2, discussing how each Big Idea could be assessed. As a class we went through each Big Idea on the exam and connected the learning objectives to potential exam questions. The sample questions were great talking points for reviewing course content. I also gave an in-class exam using all the questions from #1 that didn't make it on the first practice exam. I paced it such that students had the same time/question that they would have on the exam. I wanted to make sure students had seen every official practice question and had the opportunity to ask about each one, especially the ones from the secure document that they couldn't take out of the classroom. The last big exam review I did was an optional exam review the Saturday before the exam. I had >50% attendance, and by the end the students felt more than prepared for the exam, and I felt confident I had done enough to get them ready for it. That day (and the following week) I made heavy use from #3 and #4. We basically went Big Idea by Big Idea, gaining more practice and focusing on particular tips and tricks for each. In particular, we went through a number of the robot questions and those questions that required analyzing segments of code. At the end of the course, I asked students how prepared the felt for the multiple choice. To a person they said that we had done ample review and that they felt confident in how they had done. (Now I will know more about specific students later this week when the scores come out for teachers, but I do value this piece of student feedback.) Bottom line: trust the quality of your instruction and your curriculum. Extra resources are nice, but the College Board's official practice is sufficient for getting students ready. A little exposure in the first semester and a week or two of focused multiple-choice review is plenty. Given that students will also prepare for the exam in the work they do for Explore and Create, they will be plenty prepared by course end. Also, the more students read, write, and understand code on whatever language you use, the stronger they will be come exam time; there is no substitute for this. 

It seems to me that the mistake is using C++ for an introductory course. Complete beginners do not need help shooting themselves in the foot. The curriculum may be out of your control, but if you have the option then teaching the introductory course either in a strongly typed LISP (SML, Haskell, or something similar) or at least in a concise portable language (Python, Ruby, etc.) should make it easier for both the students and the graders. 

I don't quite see the logical connection here. Becoming better speakers won't make them louder speakers, and the louder speakers will continue to be heard more even if they're terrible at actually speaking. 

There's pipelining, parallelisation, maybe even branch prediction (cashier fetches tray before asking whether it's to eat in or take away). * Speakers of en-US: read "fries". 

There's no "may" about it. With brief training they will be able to offer positive comments as well as negative ones, but to give constructive advice they need to know what they're talking about. For example, anyone can tell you "I couldn't follow the thread", but to suggest specific structural changes you need to know the broad types of structure which could have been used. There are various organisations which are dedicated to training in public speaking: Dale Carnegie and Toastmasters being perhaps the best known. (Disclaimer: I'm a member of Toastmasters and have previously held various offices in my local club, so I'm not unbiased). You could look at their approaches, and if you have a branch of such an organisation in your city (or even in your school/university) you could see whether they'd be interested in helping out. Speaking from the Toastmasters perspective, there are one or two projects which people on the leadership track can complete by running a training session with a recruitment plug: you may or may not consider that appropriate for your setting. In addition, particularly if there's a club in your school/university, you might be able to get a couple of members to come along to a lesson on the basis that one of them gives a speech for evaluation, your students offer their feedback, and then the other gives an evaluation which confirms or corrects the students' feedback. (If necessary, explain that the rules allow one project in five to be done outside club meetings provided that another member is present and gives a written evaluation. I haven't seen this option used much, so the members of your local club might not be aware of it). The good thing about this is that someone who's done a few projects in Toastmasters will be used to being evaluated by people with differing levels of experience, and being a volunteer will find it less stressful than your students. That way they can learn to give feedback without destroying their peers' confidence. The second visitor will also (I hope!) demonstrate how to give suggestions for improvement sandwiched between affirmation of positive observations in order to (quoting the title of the manual) "evaluate to motivate". Since you probably won't have volunteers to come to every lesson for several weeks in a row, this might be best saved as a final practice before getting into real peer evaluation. You could build up to it with a series of lessons in which you teach a specific skill (speech structure, body language, word choice and sentence structure, visual aids, ...), watch a video (maybe a talk from TED, Ignite, or something similar), and then ask the class to give feedback. 

Since most of the answers here already provide a good pedagogical approach, I'm going to add one element you can use to completely shift the tone when these moments occur: use a meme. Find humor in the absurdities. I strongly believe that well-placed humor in the classroom is of instructional benefit. My reasoning as humor applies to this particular topic comes from the "Wat" talk given by Gary Bernhardt. In it he uses the "Wat" meme to point out some rather absurd characteristics of Ruby and JavaScript. The video is only a little over four minutes long and can be found here. Teaching with memes can be a memorable and funny experience for students, and it then becomes something they can continue to reference. Befuddled by why a language has a quirk that it does? Make a meme of it. Share it. Tweet it. Put it up on a classroom wall. The drastic difference in tone will help students create that cognitive separation between those big picture items and those more quirky items by which you don't want them to be distracted. Sometimes we don't need to take a serious, intellectualized approach; comedy can work in aiding the learning process. Here's an example based on what you list above: 

This is the wrong question, and by trying to answer it you're falling into a trap of accepting and reinforcing the students' misunderstanding of what university is. If I had applied that standard of value to the courses in the bachelor's degree I studied, I think I would only have attended 30 hours of lectures over the three years. You may be right that most of them will not end up earning their living by programming in functional languages, although given current industry trends I wouldn't be entirely surprised if you turn out to be wrong in the long term. But if their goal is merely to gain a superficial knowledge of whatever is currently popular in industry, they're not just in the wrong course: they're in the wrong institution, and should drop out and find a bootcamp. 

Most of the maths in undergraduate CS is proof by structural induction (and we do at least in part deserve the reputation we have among mathematicians of not knowing that there are other proof techniques). That technique apart, the "non-CS" maths can be more than covered by chapters 2 and 4 of Concrete Mathematics, Graham, Knuth, and Patashnik, ISBN: 0-201-55802-5. This book contains many exercises and solutions thereof, or hints in the case of unsolved problems. There are PDFs available online, but I'm not sure whether they're authorised so I won't link to any. 

I have a few suggestions based on my experience this year. I have one prep over two blocks, which meant that for every exam I wrote, I wrote two versions. Moreover, because I take a standards-based approach, students end up retaking the exam but a modified version at that. For some exams, I ended up with 4 versions. Here's how I sped up my own process: Focus on proficiency. Not every questions needs to "trick" students. (Indeed, "tricking" should never be the goal of an assessment: it should be an accurate measure of what a student knows and can do at a particular moment in time.) If I believe proficiency is 70%, then 70% of the points should be relatively straightforward questions that all students should earn. Maybe another 20% consists of slightly more challenging questions, saving the final 10% for the questions that might focus on the most subtle of details. By focusing on what all students should be able to do, I can worry less after the "craftiness" of my questions and get right to the heart of the matter. Write questions designed with substitution in mind. Let's say I'm asking questions to test a student's knowledge of basic Linux commands since it's necessary for our IDE. Whether I ask about , , , , etc. should be irrelevant; they are all fair game. Thus, one approach is to tell students to review from a list of terms, and come up with a potential set of 4-5 answers. Then, from class to class, you can simply change what term you are asking about. The answers don't change, but the questions do. No student will know in advance which terms will be asked about just that they will be asked about. Keep the method, but change the input. I recently assessed students on Python, and I wanted them to be comfortable with two key concepts: the use of for iteration and the basics of string access and manipulation. I didn't have to change the instructions from class to class very much, but by changing the input, I gave the two classes unique exams. They knew to expect questions on strings and iterations, but until they are faced with the actual input, this bit of information does not necessarily help them answer the question. I may have more ideas come to me as I read more responses, but here's my final, overarching thought: EXAMS ARE NOT SURPRISE PARTIES. Students, assuming they have been present and attentive in class, should not be surprised by the content of your exams. Let them be occasions for students to show you what they can do. While we as educators might stress over the perfect question to ask about, say, an , it should always come back to this: "How I can fairly and accurately assess what a student knows?" It is not, however, a chance for us to show how clever we are. Get to the point. Be clear; be fair. Let students prove how much they have mastered. Keep that mantra at the forefront, and test design can become simpler and faster. 

There's an easy way to teach them to do code review without thinking that you're ditching work: ask them to review some code which you wrote for the express purpose (or, if you have some suitable code from the previous year's homework, use that). This can be set as homework. For what it's worth, I have had to identify errors in code printouts both in exams and in job interviews, so this isn't an original idea. 

These are very different situations. As you observe, the use of in C# is controversial, but using as the type of all variables (and then needing to cast any time you want to actually use the variable) is not controversial: it's just wrong. The first page of answers on the linked SO question about in C# is incomplete. It doesn't mention that using can avoid bugs due to typing in one edge case: vs . For legacy reasons, if is a but not a the latter is equivalent to , which is not especially obvious. (In fact I misremembered and was corrected in comments, which reinforces the advantage of using here). TL;DR: blanket prohibitions on are almost certainly going too far. 

The teaching philosophy I came to as a young teacher (i.e. in my first year) was that I would ground myself in two qualities: passion and humility. (I've since added gratitude as an important third, but that's another topic.) Humility is essential regardless of the discipline. Teachers are, after all, human. We make mistakes. We forget. We may occasionally forget whether a language uses or or . The difference for us though is that we also model what it means to be a student. The phrase "life-long learner" is a bit cliche, but it does speak to an important truth: teachers should always model what it means learn. Part of that is showing an innate curiosity and interest with respect to the subject manner. Another aspect is never being okay with resigning oneself to just not knowing something. If I make a mistake, I acknowledge it, but I do not stop there. If I err when it comes to, say, operator precedence (a recent topic here), I do all the research I can to crystallize that concept in mind and re-teach it so that it is just as clear for my students. I want my students to see that as their teacher, I too am always learning. The classroom should be a safe place to fail, to make mistakes, because of the role said failure can play in the learning process. It's fine to make a mistake; it's not fine to be okay with it. Also, one thing that can be meaningful in class is to show old code I have written. When I look back at some of the first CS50 solutions I wrote, I absolutely cringe. However, they can be effective teaching tools since students are beginners as well. Explicitly teaching prior "mistakes" emphasizes the benefit of reflecting on past work and the importance of having a "growth mindset." Note: one caveat would be that some things just aren't okay to mistake. For example, a teacher of Java probably should know the difference between and . There's a level of basic competence that should be mistake-free, but when it comes to more complicated material or language nuances, then there's a little more freedom I think. Where that line is...there might be a bit of grey. 

One which most of your students are likely to have seen, and some of them may have participated in: production of an order in a fast food restaurant. 

On the basis of my industry experience, which includes all of the above, I opine that option 3 is the easiest, not the hardest. This comes with the caveat that by "C# with Dot Net" (which I think should really be ".Net with C#") you may actually mean a set of specific APIs which are hard to learn. However, there is another consideration. A little knowledge is a dangerous thing. There are enough subtopics of web security to make an entire course; but if you take the .Net/C# option then there are ways to steer it which will support an accompanying project which isn't a Swiss cheese of security holes. E,g, the accompanying project goal could be a WPF application which consumes a third party public REST service, and the relevant security issues will come up in relation to the (hopefully securely designed and implemented) third party service. 

What are the objects? You've sketched a database table definition and a visualisation, but I don't see a sketch of the application program's structures. As far as I can see, all of the additional information in the visualisation can be made available in a purely relational database view. I've done this kind of hierarchy visualisation with CTEs.