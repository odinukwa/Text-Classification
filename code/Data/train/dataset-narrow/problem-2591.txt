I'm learning OpenGL and really like to know how the interaction with the Graphics card will be. I feel understanding how it was implemented in the Graphics driver, will let me know complete internals of the opengl(With this I can know what stages/factors influence my decisions regarding performance in opengl). Are there any ways for this path to proceed.Does exploring the 'Mesa lib' will help me in this aspect? Am I in the right path? [I posted this question in SOF but it seems here is the right place for this Question.] 

To my knowledge the best project i have seen is Burger Engine. jst download the code and check how well they have implemented.The whole thing is data-driven from xml and they used very well entity based architecture.worth looking at it. $URL$ 

Check these frameworks I found out related to this architecture... www.burgerengine.com PushButtonEngine Arthemis Framework - $URL$ Having a look at Unity Api. You can find a lot of stuff regarding the Component based architecture. (Will update the list as soon as I find somemore...) Update: 

I haven't worked on pyGame before.But , A quick look on souce code of it, lead me to assume that it is using 'sdl' Blit functions under the hood. Usually Sdl blit will be very faster and optimized so, just make a not of the above points and profile once again! Good luck! *Update:*Setting color key is like adding one extra check when blitting each pixel to the surface.Some thing like this - 

From your code I can understand that you might be comparing the floats directly. Comparison will not directly as you think in case of floats. Try checking for the difference and decide whether they are equal or not. Because floating point precision is a problem all the times. Just go through these links which a programmer must know. $URL$ PS: As its tagged XNA, vector2 has floats as attributes. Please complete your question for clear details. Hope this helps. 

I'm reading a fantastic article about game timer precision and here is a quote about 2/3 of the way into the article: 

He doesn't give a concrete example of this though. Does this mean I would want to add 2^32 to the game clock value that I store at the beginning of each frame? Or is there a way to actually set the clock in Windows so that the numbers start at 2^32? 

When programming Windows games, do you use multibyte character settings or Unicode character settings? I'm under the impression that professional companies today use the Unicode setting to make future localization and translations as easy as possible. Is using wchar's a good practice for modern games? While I'm thinking about the subject, what is the difference between multibyte character sets and Unicode sets in Windows? Is it UTF-8 vs. UTF-16? 

$URL$ Here's a link to a few tutorials that show how to use OpenGL in LISP. Beyond that, so long as you are practicing, you should be able to structure some samples and eventually some games once you learn how to use OpenGL properly. Also, though they are old, the old NeHe tutorials at $URL$ have some LISP translation of at least their earliest tutorials. 

Lots of answers here, but I want to chime in with my personal experience. I'm in the grad program at DePaul University in Chicago. They have a number of degrees, but one of them is Computer Game Development. In my personal experience, this program is spectacular and I can personally vouch for it to anyone who is considering DePaul. The main reason is that the degree is teaching game programming from a low level. It teaches the ins and outs of C++, to the point that I'm referring to the spec rather than online tutorials. It teaches OpenGL, both fixed and programmable pipeline. The goal of the program is to make you an excellent problem solver in the framework of video games. The people who leave this school can dig into call stacks, disassembly, and really get down into the nitty gritty. I would be hesitant to recommend anyone get a game degree that does not teach low level programming like this. On the other hand, I think anyone who wants to get into the game industry would do extremely well for themselves if they looked for any kind of computer science degree that digs into low level stuff like that. When you go to apply to game programs, showing an incredible knowledge of C++, and how the code you write in it translates into assembly, will really impress them. They're looking for engineers and problem solvers, not just people who have a degree that says 'Game Programming' on it. 

So here you need to understand a VBO like - "It can be able to store the whole vertex attributes". Basically a VBO is a "buffer" that you can bind to any of the vertex info. Answer 1 : Yes (Check the above description) Answer 2: VBO's are usually "faster" than usual vertex lists, as there is no need of pushing the vertex info every frame(if the data is static). Even If the underlying architecture is unified memory architecture, it will have benefits as there is no "overwrite" of data unnecessarily. Answer3 : STATIC_DRAW/DYNAMIC_DRAW are just flags to tell the underlying GPU where to keep the buffers.The underlying GPU will decide where to keep the buffers based on the flags you give.So this should be in mind for better throughput.But, in Unified Memory Architecture(where GPU will be sharing Main RAM),I think it will not make any significant difference. 

Currently i'm working on a sprite system which will have frames which make animations. Usually a sprite contains current position, current frame number to be displayed in the running animation, etc... This is what I mean is STATE. Let's say there are 100 NPC characters in a game which will have different animations running at any time.If we are maintaining the state in Sprite class, we usually create 100 sprites and draw it as each sprite has its own state. But I feel the same thing can be done like this, Imagine, position and animation state is separated from the Sprite class.When ever we want to draw we will just set it and draw the frame at certain position.With this approach there is no need to have 100 sprite instances.We can make the exact above situation with one single sprite instance. For me I feel separating the "state" kills encapsulation.But at the same time it will have a benefit in terms of huge memory! Please give your Pros/Cons on this kind of approach? 

The DXUT Framework requires you to define a number of functions in order to plug into it. Each of those names - IsD3D9DeviceAcceptable, OnD3D9LostDevice, ModifyDeviceSettings, and OnFrameMove - are functions that YOU need to define in your code. The signatures are as follows: 

Allegro 5 is quite adept - I like it personally. The initialization code is simple to use, and easy to stuff away in a class or an Init() function. Really, if you write a wrapper function or class, you won't even have to directly call anything from any of these libraries. Are you interested in game graphics or game development? Because if you want to make games, you should just pick one of these libraries and run with it. I'd only sweat these small steps if you're particularly interested in learning the nitty gritty of graphics development. 

Let's say you wanted it to spin 360 degrees in one second. Let's also say that iTime determines how many seconds since the function was called. So if iTime was .01 then 1/100 of a second had passed since the last time the function was called. Then you would use iTime / 360 to figure out how much rotation you'd need to apply. 

So in the first function you determine if the d3d9 device will work for your program or not, and return true if it does. In the second you tell it what to do if it loses the device (if someone minimizes the screen for instance). In the third you allow the user to change the device settings, and.... I'm actually not too sure about the fourth, I use DXUTOnFrameRender instead. It's annoying that Microsoft took down the documentation for the DXUT library. If you Google any of those function names you'll find the Japanese version of MSDN, which somehow survived the purge. If you really want a complete example of the DXUT library in use, try the Game Coding Complete code: $URL$ The file GameCode4.cpp is the initializer, where they use these function declarations just like you typed them in. The bodies of the user-defined functions are in gamecode.cpp and gamecode.h I believe the DXUT tutorials are also in the DirectX SDK for DX9 

I haven't used Corona.It needs a license if you need to publish.Cocos2d on the other hand is really flexible and stable 'graphics' engine right now. I would suggest Cocos2d-x (C++ version) as objective-c version has some performance issues when your update cycle is Overloaded.This performance issues is ONLY because of the message passing System in Objective-C. As others said,You need to depend on the support of 'third party Engine' if any thing NEW comes up!But cocos2d is flexible at that moment! If you are targeting multiple platforms,Cocos2d-X is ready for that as well! Check this link - $URL$ 

I was earlier in the same confusion and finally found out there is no proper solution for this. My consideration for Google play was not for ranking but for using the leaderboards and multiplayer features. And again If I go with Google Play Services alone, I miss a-lot with Facebook login. So you decide which has more weightage and pick one of it. If you are targeting only for Android I suggest going alone for Google Play services as most of the users will have an account. I picked Parse.com and implemented my own leaderboards and used Facebook for logging in (as I targeted iOS as well, I see FB has more reach). In between, I tried OpenKit and dropped as its getting closed soon. Now i'm checking NextPeer which is a bit close enough to solve my problem. Will update once I play with NextPeer. Hope this helps! 

I gave a quick try(infact took some time to get used to shader lab syntax ;) as i was trying after quite some time). Let me know if this shader works for you. Basically checking the frag color by sign value of dot product of view direction and normal of the vertex. Btw, I set the culling to off. Thanks for letting me trying this out. Very happy with the output ^_^ . I'm aware of doing without shader but thought of giving this a try with shader. Sorry for replying abit late to your post. Link : $URL$ Update: Here is the explanation of the code. This is infact how Back-face culling works. The Dot product between The camera view direction and the vertex normal will tell which way the vertex is oriented. Whether its away from camera or towards the camera. Dot product value of those two vectors goes negative if the vectors are away from each other. So , the same math is used to find out which texture we need to show. In the code, I took two texture samples (_FirstTex,_SecondTex) as properties. Vertex Shader 1) First we need to convert vertex co-ordinate which is in object space to Clip Space. 2)Next we use world View space direction(_WorldSpaceCameraPos) provided by unity cg includes(UnityCG.cginc,UnityShaderVariables.cginc) and normalize it. (Infact there is no real importance of normalising here as we just need sign of dot product.) 3)We then need to convert vertex normal to world space.(Please check the comment there for converting to same co-ordinate system). We can do the other way as well(converting view direction to object space). 4)Find the dot product and save the value in color.w to pass it to fragment shader. Fragment Shader: 1)We find out the sign of the dot product value and based on that decide which texel to fetch. 2)Return the texel color. Let me know if you need any further clarification. 

That will keep you from having to do a large if ... else sequence. Also, do rand()%4, or else you will never get a 4 as a result. Other than that, it looks like it should be doing what you say you want it to do. 

From here, you can use the GetNodeLocalTransform() function in KFbxAnimEvaluator to get the transform matrix at specific times. It will give you a final answer matrix that you can pull the TRS info out of. I know that's vague, but my specific code is not on this computer. Hopefully it's high-level enough to help though. 

The FBX documentation is painful at times, and this is definitely one of them. There are two ways I've used to access animation data. The first is used in the ImportScene sample that comes with the SDK, and it's the way you seem to be trying to do things. In your sample, now that you have a valid lAnimCurve, you would need to query the number of keyframes that are stored in that curve, and then access them one at a time. It's a fairly complex process, I would refer you to the DisplayAnimation.cxx file in the ImportScene sample to see how they do it. The problem with this is that you then will need to go through and determine any missing information. In the animation I'm working with, I have keyframe data for frame 0, 35, and 70. So now I would need to determine if the interpolation is linear or cubic, which involves more complicated and error-prone programming. I also don't know at this point how fast the animation runs - 30fps, 24fps, 60fps, or some custom number - so even though I know I have 70 frames, I don't actually know how long the animation is supposed to last. Instead, I would suggest digging into the KFbxAnimEvaluator class. This makes life much easier, because it will figure out all sorts of animation stuff for you. Really, that's the SDK page to keep an eye on. So here's some sample code for how I break the times down. Assume lAnimStackCount is the number of animation stacks my file has.