the C++ program from Figure 6.3. A C++ program for the graph isomorphism algorithm in $URL$ delivers the following output: 

More or less similar to the consequences of the deterministic polynomial time algorithm for primality testing, the deterministic polynomial time algorithm for linear programming, and the other case where practically efficient (randomised) algorithms (with rare pathological examples where the algorithm became inefficient) were know and in use for a long time. It confirms the conjecture that practical efficiency is a good indicator for the existence of deterministic theoretical algorithms overcoming the issues of the rare pathological examples. 

The fact that P-uniform $\mathbf{AC}^0$ circuits are needed is slightly unexpected, since uniform $\mathbf{AC}^0$ normally means Dlogtime-uniform $\mathbf{AC}^0$ (i.e. FOL and LH are only known to be equal to Dlogtime-uniform $\mathbf{AC}^0$, not to P-uniform $\mathbf{AC}^0$). Manindra Agrawal, The First-Order Isomorphism Theorem. FSTTCS 2001, LNCS 2245: 70-82, is mentioned last in Immerman's survey, since it seems to prove that P-uniform can be replaced by Dlogtime-uniform. But it doesn't preserve the depth-three part of the theorem. There are surveys by Manindra Agrawal (2009) and Eric Allender (2014), but I only found them after writing this answer (while trying to understand whether Kaveh's point about the supreme importance of FOL is correct), and I have not read them yet. 1M. Sipser. Borel sets and circuit complexity. In Proceedings, 15th ACM Symposium on the Theory of Computing, 1983 

Making sense of the word "probability" would be part of an attempt to show that Kolmogorov randomness works for RP. However, let me try to describe one possible approach, to clarify what it could mean, and why I talked about upper and lower bounds: Let $s$ be a (Kolmogorov random) string. Let $A$ be a the given probabilistic Turing machine corresponding to a language from RP. Run $A$ with $s$ as source for random bits $n$ times, continuing to consume previously unconsumed bits from $s$ one after the other. For $p_n^s:=\frac{\text{#YES result in first $n$ runs of $A$ on $s$}}{n}$, let $p_+^s:=\limsup_{n\to\infty}p_n^s$ and $p_-^s:=\liminf_{n\to\infty}p_n^s$. Observe that $p_+^s$ and $p_-^s$ are well defined for a given string $s$, even if it would not be random. But one may wonder whether $p_+^s=p_-^s$ in case $s$ is Kolmogorov random, or whether $p_-^{s_1}=p_-^{s_2}$ for two arbitrary Kolmogorov random strings $s_1$ and $s_2$. Or whether there exists a $p\geq 1/2$ such that $p\leq p_-^s$ for any Kolmogorov random string $s$. 

So we may assume that this is a counter-example to the Dharwadker-Tevet Graph Isomorphism algorithm. As suggested by Bill Province, the problem is 

From the introduction of On the Group and Color Isomorphism Problems by François Le Gall and David J. Rosenbaum 

The (uniform) circuit classes $TC^0$, $NC^1$ and $sAC^1$ seem to lend themselves to efficient hardware implementation. But using an FPGA approach to create the circuits on the fly seems problematic, because the wiring could destroy the theoretical speed benefits. A more promising approach could be to look for problems complete under appropriate many-one reductions for these classes. The word problem for $\bar{A}_5$ (or $\bar{S}_5$) would be such a problem for $NC^1$. The solution of that word problem is nicely scalable, since one can subdivide the word into smaller parts, and thereby generate a smaller word on which the same procedure can be applied again. Is something similar also possible for LogCFL ($= sAC^1$)? Does it have a nice problem (probably some CFL) complete under $NC^1$ reductions? And is the solution of that CFL scalable in a way that hardware solutions to subproblems can easily be combined to the total solution? Or does the dynamic programming algorithm which can solve LogCFL allows scalable hardware support in some way? 

The logarithmic time hierarchy (LH) is equal to uniform $\mathbf{AC}^0$. A natural thought process that leads to LH is to look for an analogy of the polynomial time hierarchy (PH) for logarithmic time. You can prove that LH does not collapse1, and that its level structure carries over to $\mathbf{AC}^0$. Some problems like addition are in $\mathbf{AC}^0$, but provably not in $\mathbf{NC}^0$. Neither addition nor any other single problem is complete for uniform $\mathbf{AC}^0$, since otherwise LH would collapse. Barrington et al. showed that Searching constant width mazes captures the $\mathbf{AC}^0$ hierarchy, so this class arises intrinsically at least sometimes. But that is not the normal case, where $\mathbf{AC}^0$ is used out of convention (instead of a specific depth $k$-subclass). I guess the reason for that convention is that $\mathbf{AC}^0$ is provably a proper subset of $\mathbf{ACC}^0$, so it is weak enough to convey the important point. And $\mathbf{AC}^0$ is closed under composition, which is nice for $\mathbf{AC}^0$ reductions between problems. 

I believed I knew that all isomorphism testing problems of finite structures can be reduced to the graph isomorphism problem. Hence I believed that graph isomorphism was the "correct general" isomorphism problem to rule them all. The string isomorphism problem used in Babai's paper revealed that my belief was not fully justified, since it is still unknown whether the string isomorphism problem can be reduced to the graph isomorphism problem. Hence the generalized graph isomorphism problem $\mathsf{GI}^*$ and the generalized group isomorphism problem $\mathsf{GrI}^*$ are defined (in the above paper, but the authors rightly wonder why nobody did it before), which add the missing pieces from the string isomorphism problem. (And color isomorphism problem is just a different name for the string isomorphism problem. The name color automorphism problem goes back to the initial papers of Babai and Luks, the name string isomorphism occurs later in their paper on canonical labeling.) Since Babai's algorithm was a quasi-polynomial time algorithm for the string isomorphism problem (i.e. for $\mathsf{GI}^*$), the consequence was that isomorphism testing for most types of finite structures should be expected to be quite doable. One application of such isomorphism testing is to list all different types of non-isomorphic structures with certain properties within a given range. Well, actually that application works much better with algorithms for canonisation (as opposed to mere isomorphism testing of two given structures), but the additional slowdown wouldn't change the principal polynomial or quasi-polynomial time bound for those problems. 

A similar definition can be found in "J.-E. Pin, Mathematical Foundations of Automata Theory", and already "S. Eilenberg, Automata, Languages, and Machines" defines rational sets. A nondeterministic $M$-automaton $\mathcal A = (Q,\delta,I,F)$ consists of a set of states $Q$, a transition relation $\delta\subset Q\times M\times Q$, a set of initial states $I\subset Q$, and a set of final states $F\subset Q$. If $\delta$ is a finte set, then we say that $\mathcal A$ is finite. A run on $\mathcal A$ is a sequence of the form $$r=q_1u_1q_2\dots u_nq_{n+1}$$ with $(q_iu_iq_{i+1})\in\delta$ for all $1\leq i\leq n$. If $q_1\in I$ and $q_{n+1}\in F$, then we say that it accepts $u=u_1\dots u_n$. The set accepted by $\mathcal A$ is defined as $$L(\mathcal A):=\{u\in M|\mathcal A \text{ has a run } r \text{ that accepts }u\}$$ I found this definition in chapter 7 Automatentheorie of the German text book "Volker Diekert, Manfred Kufleitner, Gerhard Rosenberger: Diskrete algebraische Methoden: Arithmetik, Kryptographie, Automaten und Gruppen”. There we also find the following theorem: Theorem 7.15 Let $M$ be a monoid and $L\subset M$. Then the following are equivalent: