Note: is the logical name of your data file, not the physical file name on the filesystem. You can find the logical file names of your database files with the system view: 

Backup the registry key Stop SQL services Go to (must do this for each SQL instances on the server) Find the IP# key that contains the value of the address you want to remove where # is a number from 1 to the number of IP addresses SQL found on your machine during install Delete the IP# key found in step 4 If the number in the keyname is not the last one, rename the remaining IP# keys to be sequential starting with 1. Restart SQL Services 

From what I've been able to discern, the in Job1 is still executing when the from Job2 is evaluated resulting in Job2 trying to insert a duplicate key value. It seems to me that the locking for is not happening as expected. I'm at a loss as to why this is happening. Would this have anything to do with the hint used in the ? I didn't think that that hint would include in its scope, only . I know I can mitigate the duplicate key error by setting to for the index, and that would be fine for us in this situation. I would like to know, though, why the duplicate is showing up in the 2nd INSERT. 

Your "1000 rows" isn't helpful because your row can be 10MB wide, or you could be loading , loading , etc. An actual load size is more valuable. On a typical DL380 Gen2, you should see around 350GB/HR/node. 

Without knowing your environment, there are a couple things you can try. The first being adding an additional filter to make the output file smaller. The other is using a pipe viewer to monitor the progress. If you're using the enterprise edition, you should report the issue to support. 

Vertica supports ANSI SQL-92 isolation levels with standard ACID properties. If a is terminated, interrupted, or an error occurs, it will be rolled back. 

Given that the referenced paper is 10 years old, I would recommend looking at a The Vertica Analytic Database: C-Store 7 Years Later since Vertica has more automatic epoch advancement mechanisms. For reference, the acronyms used now are: 

Assuming that the refers to the vendor or buyer, this design allows to be both a buyer and a vendor. When an order is placed, you would simply need to on the and tables to ensure that does not exist in both. 

I am using event notifications to capture data and log file autogrowth events for all databases on my servers. I'm using the data to for analysis of database storage configuration. In looking at the data I've noticed that the average duration for transaction log growth is well above anything I would expect which leads me to think that I'm either misinterpreting the data or overlooking something related to how transaction log autogrowth works. This is an example of a log file growth event that was captured today: 

You can set the database's max file size to 9GB, but you will need to do the purging yourself. This is not something that SQL Server supports. You could get notified of the limit being reached using extended events, but there is no way for SQL Server to know what records to delete without you telling it. SQL Server does not log or otherwise keep track of how old a row in a table is. You have to build it into the table schema and maintain your own aging logic. To set the file size in SQL Server Management Studio: 

Vertica will automatically advance the epoch as a background process. In the example below, once data is committed, it will belong to the current epoch. 

The with s is highly suspicious. Is the load more than 100MB? If yes, use . Are the projections optimized for load? Is the query profiled and no locks being used on the target table? Most importantly, is the load local? From a client across a wide network? Test a load from a local file as a benchmark. 

You shouldn't be surprised that a load takes longer when there's more resource usage. However, there's probably a simple explanation for your poor performance. I would examine the following: 

It does not. WOS is just a temporary storage location until the data gets moved to ROS. The epoch is just a way to manage transactions. 

You can create views using and give those view names to the end users. If you're using a development tool such as DBVisualizer, you can set the number of records to limit. As always, query labels allow for easy tracking of any requests. 

If you know what you're searching for, Red Gate has a really good free search tool called SQL Search that is a plugin to SSMS. It's easier and less error prone than any attempts I've made at looking through syscomments. Give it a shot. Download it here. When searching for references within jobs make sure you include msdb in the search. If you want to query SQL Agent jobs directly then you can use this: 

After doing this the old IP address was no longer available in SQL Server Configuration Manager and SQL Server no longer tried to listen on that IP address. There were no longer any "Listening on [old address]" entries in the SQL Log and showed no listeners as well. 

Since duration is reported in miliseconds I'm reading this as it taking 69.54 minutes to grow the file. Autogrowth for this log file is set to 512MB (limited to 2TB) 

Having searched quite a bit and come up empty I decided to just go ahead and remove the registry keys for the IP address I wanted to delete from the configuration. Steps: