Use fog coordinates. $URL$ Normally, the fog value is computed using a distance factor from eye to the pixel 'c'. In effect, the fog density is a function of distance. f = exp(-d*c) -- GL_EXP2 f = exp(-(d*c)^2) -- GL_EXP f = (e-c)/(e-s) -- GL_LINEAR Fog coordinates allow you to set the 'c' value of the equation and specify values directly for this. If you want to set up fogging so that 0 -> no fog, 1.0 -> most fog, then do: 

I think before you go pointing fingers, you make sure that this is in fact the problem. It might very well be, but before you invest a lot of time an effort in the number solutions below, try profiling your code. You should be looking for large CPU usage areas. If improving that improves performance, then awesome, mission accomplished. Some devices ship without FPUs, so the performance with floats are very poor. You might try different graphics rendering modes to make sure that you are in fact limited by vertex transfer rates, i.e. using the same number of vertices in a static mesh is dramatically faster. If it isn't, then your model(s) are too detailed and filling a buffer faster won't fix anything -- your GPU simply can't handle the geometry + any other stuff you have enabled. You can turn down/off many of the effects like fog/lighting (lighting is especially expensive if your GPU does not have TnL and your CPU does not have a FPU). As for actual methods of improving performance that take a while to implement, you have a few options: 

There are a lot of synchronization issues here, tread carefully! You can't update information the renderer is rendering! A less direct but more elegant way would be to submit stuff to the renderer to do. Each frame, some presentation layer code would queue up tasks for the renderer to do. At the end of the queue might be a "swap buffers" message that tells the renderer to swap buffers. In this way, the renderer runs on a separate thread but acts similar to directly calling functions like glDrawArrays(). Normally, the logic updates stuff, the presentation layer decides what to draw, and the renderer draws it. A more full example would be this: 

This is possible using GL 1.x and here's how. So as you've found using vertex colors, a smooth transition is where it blends the two colors. This is a called a linear interpolation, or a "lerp" for short. It can be generalized to any dimension by operating on the elements of the vector individually and indeed colors are treated like a lerp in 3D -- blend R1 with R2, G1 with G2, B1 with B2. The lerp() function has an "alpha" parameter, such that alpha = 0.0 yields fully color 1 and alpha of 1.0 yields fully color 2, and somewhere in-between creates a mixture. So you'll see then that if you have color 1 (C1) and color 2 (C2) and some alpha value (A), then would do it as: . As many people will tell you, you can simplify this formula, but keeping it as is will help you understand how to do this with GL 1.x. To do this with two textures using GL 1.x, you will be drawing two rectangles on top of each other, one with texture 1, one with texture 2. However, you will be adding the two colors. If you do this as-is you'll end up with a final texture that looks like 

I've noticed you're asking a lot of questions that are getting negative or zero votes, and they seem to be related to modeling. I don't know if it is a language barrier, but people here find your questions difficult to answer or somewhat off-topic. To answer the title question directly, a modern CPU with a reasonable amount of RAM, say 1-2GB is more than sufficient. You can always check the modeling program's minimum requirements and go up from there. However, judging by the questions you ask, I think you need to spend less time asking "How much RAM or CPU configuration is required for good rendering", "Should i learn 3ds max or maya", "Should i learn 3ds max or maya", or "How much time it will take to learn 3ds Max", and just pick something and do it. Don't focus so much on the prerequisites of learning -- cut straight to the learning and doing. Truth be told, you can use a Pentium III with a GeForce4 to model a small village if you did it in something like Wings3D. Is it ideal? For most people, probably not. Is it doable? Yes, very likely. Having a computer with more RAM/faster CPU/"Super3D Package 2011" won't make you better at modeling or learn the skills, which you seem to want to build up. It's going to take time, blood, sweat, and tears, not computing hardware, to build a small village. Spend some time learning your programs, reading tutorials, and becoming a master of your modeling environment -- worry about your computer later. I think you'll find mundane (and mostly irrelevant) questions like "one file or many scenes" to be answered as you gain experience with you program of choice. I'd imagine the answers have a lot less to do with computer hardware and more to do with manageability and project scope. 

Edit: An extensionless alternative is to disable fog when rendering everything, then enable fog with appropriate start/end distances when rendering your character. 

I have a questions about how to better implement resource management when integrating with Lua. I have an entity system that has gameplay logic done in Lua. One of the design points was that I wanted to simplify the script code as much as possible. To that end, things like sprites and sounds are generic "resource" handles (currently just integers) that are referenced, e.g. 

Ignore responsiveness. On a LAN, ping is insignificant. On the internet, 60-100ms round-trip is a blessing. Pray to the lag gods that you don't get spikes of > 3K. Your software would have to run at very low number of updates/sec for this to be a problem. If you shoot for 25 updates/sec, then you've got 40ms max time between when you receive a packet and act on it. And that is the single-threaded case... Design your system for flexibility and correctness. Here is my idea on how to hook a network subsystem into game code: Messaging. The solution to a lot of problems can be "messaging". I think messaging cured cancer in lab rats once. Messaging saves me $200 or more on my car insurance. But seriously, messaging is probably the best way to attach any subsystem to game code while still maintaining two independent subsystems. Use messaging for any communication between the network subsystem and game engine, and for that matter between any two subsystems. Inter-subsystem messaging can be a simple as a blob of data passed by pointer using std::list. Simply have an outgoing messages queue and a reference to the game engine in the network subsystem. The game can dump messages it wants sent into the outgoing queue and have them automagically sent, or perhaps when some function like "flushMessages()" is called. If the game engine had one large, shared message queue, then all subsystems that needed to send messages (logic, AI, physics, network, etc.) can all dump messages into it where the main game loop can then read all of the messages and then act accordingly. I would say that running the sockets on another thread is fine, though not required. The only problem with this design is that it is generally asynchronous (you don't know precisely when the packets are being sent) and that can make it hard to debug and making timing related issues appear/disappear randomly. Still, if done properly, neither of these should be a problem. From a higher level, I'd say separate networking from the game engine itself. The game engine doesn't care about sockets or buffers, it cares about events. Events are things such as "Player X fired a shot" "An explosion at game T happened". These can be interpreted by the game engine directly. Where they are generated from (a script, a client's action, an AI player, etc) doesn't matter. If you treat your network subsystem as a means of sending/receiving events, then you get a number of advantages over just calling recv() on a socket. You could optimize bandwidth, for example, by taking 50 small messages (1-32 bytes in length) and have the network subsystem package them into one large packet and send it. Maybe it could compress them before sending if that was a big deal. On the other end, the code could uncompress/unpackage the large packet into 50 discrete events again for the game engine to read. This can all happen transparently. Other cool things include single player game mode that reuses your network code by having a pure client + a pure server running on the same machine communicating via messaging in shared memory space. Then, if your single player game operates properly, a remote client (i.e. true multiplayer) would operate as well. Additionally, it forces you to consider ahead of time what data is needed by the client since your single player game would either look right or be totally wrong. Mix and match, run a server AND be a client in a multiplayer game -- it all works just as easily. 

This is done by . Again, this is the default mode, so you shouldn't need to do this. If we specify a color of { 1, 1, 1, 1} (pure white) on side of the rectangle in the vertex data, and then { 1, 1, , 0} (transparent) on the other side, the colors will be smoothly interpolated by OpenGL as you've already noticed. Generalize that to alpha, which isn't "visible" per se, but can be used in graphics techniques such as this. So in effect, you'll end up with the alpha value of the color varying from 0..1 smoothly as desired. Now we have to use this value. Simply having the alpha value varying across the rectangle doesn't do anything, because alpha itself is not visible like red, green, or blue. So we have to somehow multiply this alpha value with each color. Enter blending. Blending in the GL 1.x fixed function does just that. It takes the incoming pixel (call the source) and blends it with the destination pixel (i.e. what is already in the framebuffer) by some function, so you can look at mathematically as: First, you must enable it: . Then, you must give it the function for the first rectangle. The first parameter to is what gets multiplied with the source color. We're saying the alpha value of the color. The second parameter is what is multiplied with whatever is already in the framebuffer. We're saying 1.0-alpha. This effectively means we're doing a lerp(). When drawing the second rectangle, you must give it the function . This preserves the previously calculated value (GL_ONE meaning multiply old value by 1.0) and then blends the incoming (new rectangle) value by its alpha, performing the lerp(). Let's go other all of this, mostly so you can appreciate shaders. 

If you look at the lerp() function, you'll see that we're missing the multiplication by and . So to do this, we're going to using colors. In OpenGL 1.x, the default way that colors and textures are combined is like so: 

In short game event logging and replay is how you automate this. I don't know of any 3rd party software that does this (qualifier: SDK to integrate into app), but doing it yourself is both really easy and perhaps really hard. You use game events to mean stuff like "pressed the X key" or "moved the mouse by (10,2)" You play the game once recording each keystroke/mouse movement and the precise time it occured relative to the start of the recording. Once you are finished recording, you run the program again, but instead of generating the events from the mouse/keyboard, you simply play back the events you recorded, in order, at the right time. So, say if you found a reproducible bug that takes a few minutes of running around waving a sword or jumping into a wall, then you can record all of your actions and replay them again and see if you get the same results (if you have a deterministic engine, you should). Then you can make fixes, play it back again, etc. until the bug is fixed. Though it isn't the same purpose, you've probably seen this method in old arcade games ('demo mode' before you insert a coin). It would have been too expensive to simply record a fullscreen demo to playback when the machines have < 1024KB of RAM, so the they record the actions and play them back as a sort of "real-time video" or "compression". Getting the game/engine to be deterministic is a lot harder though.