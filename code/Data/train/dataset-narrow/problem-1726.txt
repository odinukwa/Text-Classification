What are the pitfalls of each ? My feeling is that the second option actually has less overhead ( no Virtual layer and no VM required), but it does mean the hosts in the cluster are providing both a Clustered Hyper-V and a Clustered File Server service at the same time - is that going to be an issue ? I also think I could even leverage in some crude load-balancing, by splitting my File shares across 3 File Server roles on the cluster each set to principally run on one node ( when all is working !), and each using separate LUNS. I appreciate the answer will rely on just how many VMs and such like that I plan to run, but just assume I will keep an eye on resources ( e.g. making sure the VMs don't take up all the host RAM) and I manage the NIC allocation properly so there are no bandwidth issues. Is there any technical reason, at all, why I can't do option 2 ? Many thanks ! 

I found that Unbound meets all my criteria with the configuration directive . It even covers things like SRV records, etc (which I need). And it's super easy for even a simple Windows administrator to update the configuration file. I'm a fan. 

Don't bother with reverse proxy... just set up two instances in Apache. You can use a simple DNS server like dnsmasq on the Ubunutu server. Edit the /etc/hosts file to have two entries (assuming serverpc is 169.254.10.10): 

It wants to know the domain name of the system, so that it can pair that with the hostname to come up with the system's full-qualified domain name (FQDN). See here. I'm guessing this is an installation for your home, where you don't have a default DNS domain, per se. As such, this should probably be asked on Super User rather than Server Fault. The impact this will have is that software that looks for the FQDN will find it, e.g., mail server software.. It will also impact the domain that gets appended to a lookup. For example, if you type "ping systemxyz" it will actually try based on what you entered. Running will also help you understand some of the DNS resolution things that go on behind the scenes of your operating system. 

The 1st main way I could do this is create a 'guest cluster' - that is 2 VMs as the cluster file server nodes (on different hosts). Their OS volumes would obviously be separate, however there are 2 ways I could get them to share their file storage volumes (i.e. where the shares reside) a. They both share a common VHDX that obviously resides on the Hyper-V CSV b. Or they use their iSCSI initiators and directly access a dedicated LUN on the SAN The 2nd way is to not use Hyper-V at all for the File server nodes, but create a File server ( general Purpose) role (alongside the Hyper-V role) on the same hosts in the cluster : these would then access the shared storage on dedicated (non-CSV) LUNs presented by the SAN. 

I am in the process of creating a Hyper-V 2012 R2 Cluster. I have 3 physical hosts (128GB RAM , dual Hex-core and 12 NICs each) and a SAN to play with. The SAN is a Virtual Storage system (Datacore), serves its virtual disks through iSCSI and I have the ability to create as many virtual disks (i.e. LUNS) as I require (and that I have capacity for !). We have used the Datacore SAN successfully for several years with an ESX cluster, but we are moving to Hyper-V due to licensing costs and the fact that is now offering features on par with what we currently use with ESX (we have also run a a couple of standalone Hyper-V servers for some years as a backup, so are so familiar with that technology too). So this question is specifically about mixing clustering roles in 2012 R2 I have already created the Hyper-V cluster which use CSVs ( to store VM files) on several iSCSI LUNs from the SAN that all the hosts can see, but my next step is to configure some Highly available File Servers for general user use. I should point out that I do know the difference between using CSVs which are active-active and principally designed for application use (like Hyper-V) as opposed to shared storage as used by a file server cluster which is active-passive and I don't propose to do anything different from that: however there are a couple of different ways I could implement file servers. 

In that link you sent, they have a section entitled, Sending mail through corporate mail servers. It describes using a VPN. So you would just relay to a mail server on the inside of your ASA and Google traffic filters wouldn't even see port numbers--they would just see ESP or UDP/500 (ESP over UDP). Concerning two subnets on one tunnel, I can only speak to the ASA side of things. I typically create a one-line access-list that defines two object-groups, then just load up the object-group definitions with the subnets you need to traverse the tunnel. For example: 

I'm showing my age with the L2L-xxx-Local/Remote parlance. That's the way the old 3000 VPN concentrator to used to define each side. :) 

The only way to do redirection of a web request is using a web server. When a DNS resolver, like the one built into a user's system, requests an address, it gets an address. A CNAME just tells it the other place to get the address from, but it wants an address, period. It will then initiate a request to the web server for the domain it asked for, using the address it got as a means to initiate the TCP connection. There is no connection between your browser and your DNS resolver. Therefore, what you are asking for is not possible in a pure DNS scenario, even using DNAME (which is just CNAME on a bigger scale). I am not familiar with the configuration of nginx, but in apache, you can create a virtual host to service domain-b. The top virtual host acts as a "catch-all" for any other way the site is accessed. You can redirect all those catch-alls to domain-b using some rewrite rules. So you can capture aze.domain-x.com, or aze.domain-y.com, etc, and grab the host part and redirect it to aze.domain-b.com. You'll have to use some regex, etc, but it's the right way to do it. See Apache 2.4 Redirecting and Remapping with mod_rewrite. I'm sure nginx has the same functionality, though perhaps executed in a different way. 

Is there a way to get a more verbose error, one that tells me what is wrong and where? What is wrong? Do I need to change the content of the include file? Do I need to move the section? 

Apache 2.3/2.4 has mod_auth_form that allows to display a HTML form for users to login. Can I, instead of using a plain HTML form use an application server to provide the form (J2EE, node.js, PHP, Vert.x etc) and the authentication logic and just return the session cookie (how would that need to look like?) 

I'm moving a site to a new structure and want to use nginx's map to map old URLs to their new locations. For simple cases that works like a charm, but I have trouble with some values. This is what I tried: 

A little thinking (and reading the documentation) later: The mod_rewrite matches use the location part of the URL only. The "?" marks the end of the location and the beginning of the parameters (a.k.a QueryString). Once I realized that, it was just a Google away. So to transform correctly you need a rewrite condition: