Your problem (as stated) seems to be NP-hard. Here is a reduction from Partition. Given an instance of Partition (a collection $x_1,\ldots,x_n$ of positive integers), construct a graph with $n+1$ vertices $v_1,\ldots,v_{n+1}$ and, for each $i$, two edges from $v_i$ to $v_{i+1}$: one of cost zero, one of cost $x_i$. Suppose the Partition instance is satisfiable. That is, there is a subset $S$ of $[n]$ such that $\sum_{i\in S} x_i = \sum_{i} x_i/2$. Then there are two paths that together cover all the edges, with each path costing $L=\sum_{i} x_i/2$. Conversely, if there are two paths each of cost at most $L$ (that cover all the edges), the two paths together must cover each $x_i$ exactly once, and the total weight on each must be exactly $L$. So there must be a subset $S$ such that $\sum_{i\in S} x_i = \sum_i x_i/2$. That is, the Partition instance is satisfiable. Perhaps you have further restrictions (e.g. polynomially bounded integer edge weights)? 

The algorithm returns a $(1-O(\varepsilon))$-approximate solution in $O(n\log(n)/\varepsilon^2)$ iterations. (This is because each iteration increases $|x|$ by $\varepsilon$, and finally, before normalization, $|x| = O(N n)$.) Just for fun, here is a curious alternative algorithm for Perfect Bipartite Matching. Recall that $G=(U,W,E)$. Let $n=|U|=|W|$. 

The algorithm returns a $(1+O(\varepsilon))$-approximate solution in $O(n\log(n)/\varepsilon^2)$ iterations, where $n$ is the number of covering constraints. (Each iteration increases some remaining $A_e x$ by $\varepsilon$; this can happen only $N/\varepsilon$ times to a constraint before it is deleted.) The proof of correctness is via essentially the same invariant as for Set Cover. Weighted Vertex Cover is a special case. Maximum Fractional Bipartite Matching Given a graph $G=(U,W,E)$, the natural LP for the problem is $\max\{|x| : \forall v.\, \sum_{e\ni v} x_e \le 1\}$. In matrix representation, this is a packing LP $\max\{|x| : Ax \le 1; x \ge 0\}$ with 0-1 coefficients ($A_{ve} = 1$ if $v\in e$). Such problems do not require non-uniform increments, so a simple algorithm analogous to the unweighted Set Cover algorithm (but for packing) will do: 

The green and blue circles are the two circles from the example above. The intersection points $a$ and $b$ are the same $a$ and $b$ as in the example above. The red circle is the new "extraneous" circle. The previous sequence alternated between the blue and green circles. The new sequence will be this sequence, but with the red circle added before every circle in the old sequence: red, blue, red, green, red, blue, red, green, red, blue, ... Suppose the bug is sitting at $a$ after blue is placed. The next circle placed is red. Red contains the bug, so the bug doesn't move. The next circle placed is green. Now the bug moves to $b$ (which is the closest point on the intersection of the green and red circles). By repeating this, the bug travels as before. 

For non-metric $k$-medians, I think the best poly-time approximation known is here, Theorem 5, which gives a solution that opens $O(k\log n)$ centers and achieves cost at most the optimum cost possible with $k$ centers. Or, if you'd rather relax the distance constraint (say, if your $d_{vc}$ is metric, and your approximate solution can only use $k$ centers but can assign cities to centers that are $2D$ away), you might be able to get a constant-factor approximation to OPT (where OPT has to assign cities to centers that are at most $D$ away). I'm not sure for this particular problem, but I know there are existing results of that kind for problems similar to that, such as Jain and Vazirani's 6-approximation for metric k-medians and 2-approximation algorithms for metric k-center. 

EDIT: Adding the caveat that Roger's fixed-point theorem may not be a special case of Lawvere's. Here is a proof that may be "close"... It uses Roger's fixed-point theorem instead of Lawvere's theorem. (See comment section below for further discussion.) Let $K(x)$ be the Kolmogorov complexity of string $x$. lemma. $K$ is not computable. Proof. 

This takes care of all positions $n$ in the set $\{N(k) : k\in\{1,2,\ldots\}\}$. For arbitrary $n$, trim the bottom of the solution $P(k)$ for the smallest $k$ with $N(k)\ge n$. The desired bound holds because $S(k) / S(k-1) = O(1)$. QED 

Give each set $s$ weight $X_s = 2/pk$. For each element $e$ such that $\sum_{e\in s} X_s < 1$, choose any set $s$ containing $e$ and raise $X_s$ enough to fully cover $e$. 

As an aside: if the algorithm were to choose $k$ randomly up to $\min(n,m)$ instead of $\min(c,n)$ and then do $O(m n)$ work in each call (instead of $O(m+n)$), the total time would still be $O(mn)$ in expectation. Proof. First note that the total time would be proportional to the sum of the areas of all the rectangles. This sum equals the sum, over the integer coordinates $(i,j)$, of the number of rectangles that $(i,j)$ occurs in. This is $O(nm)$ in expectation because, in expectation, any given $(i,j)$ in the original rectangle occurs in $O(1)$ rectangles. To see this, suppose $(i,j)$ is contained in a rectangle $r$, and consider the call to partition on $r$. Let $q(r) = \min(n_r,m_r)$. Let $r'$ be the rectangle that is the child (containing $(i,j)$) of $r$. With probability at least $1/3$, $k$ is chosen to be at least $(2/3)q(r)$. Conditioned on that, $E[q(r')] \le 3/2$, so with constant probability $q(r')$ is at most 1. If that happens, then $r'$ is a leaf (has no children). It follows from this that the expected number of rectangles that $(i,j)$ is in is $O(1)$. QED (Whether the $O(nm)$ bound would hold with high probability is an interesting question.. I think it would. Certainly $O(nm\log(nm))$ would hold w.h.p.) 

Proof of Lemma 2. Let $\pi$ be a random permutation. Recall that $P$ equals the probability that its cost $c(\pi)$ is at most $n^{2-\epsilon}$. Say that any pair $(i,i+1)$ is an edge with cost $|\pi(i+1)-\pi(i)|$, so $c(\pi)$ is the sum of the edge costs. Suppose $c(\pi) \le n^{2-\epsilon}$. Then, for any $q>0$, at most $n^{2-\epsilon}/q$ of the edges have cost $q$ or more. Say that edges of cost less than $q$ are cheap. Fix $q=n^{1-\epsilon/2}$. Substituting and simplifying, at most $n^{1-\epsilon/2}$ of the edges are not cheap. Thus, at least $n - n^{1-\epsilon/2} \ge n/2$ of the edges are cheap. Thus, there is a set $S$ containing $n/2$ cheap edges. Claim. For any given set $S$ of $n/2$ edges, the probability that all edges in $S$ are cheap is at most $\exp(-\Omega(\epsilon n \log n))$. Before we prove the claim, note that it implies the lemma as follows. By the claim, and the naive union bound, the probability that any there exists such a set $S$ is at most $${n\choose n/2} \exp(-\Omega(\epsilon n \log n)) ~\le~ 2^n \exp(-\Omega(\epsilon n \log n))$$ $$~\le~ \exp(O(n) -\Omega(\epsilon n \log n)) ~\le~ \exp(-\Omega(\epsilon n \log n)).$$ 

$E[m]$ equals $n(H_n-1)$. Here's a more complete proof sketch, following the argument suggested in my comment. We start by showing that each permutation of the first $k-1$ elements is equally likely. More precisely, let $X^*=(X_1,X_2,\ldots,X_K, \ldots)$ be an infinite random sequence where each $X_i$ is drawn independently and uniformly from $S$. Let r.v. $K$ be the first index at which all elements of $S$ have been seen. Let r.v. $X'=(X_1,X_2,\ldots,X_{K-1})$. Let $i$ denote any positive integer. Let $s$ denote any element of $S$. Let $x=(x_1,x_2,\ldots,x_{i-1})$ denote any value of $X'$ that can occur, given that $K=i$ and $X_K = s$. (That is, $x$ is any length-$(i-1)$ sequence in which each element of $S-\{s\}$ occurs, and $s$ does not occur.) Let $\pi$ be any permutation of $[i-1]$. Let $\pi(x)$ denote sequence $x$, permuted by $\pi$. Lemma: Fix any such $i$, $s$, $x$, and $\pi$. Conditioned on $K=i$ and $X_k=s$, the probability that $X' = x$ is the same as the probability that $X' = \pi(x)$. Proof. To save typing, let $(i,s)$ denote the event that $K=i\wedge X_K=s$. We want to show $\Pr[X'=x ~|~ (i,s)] = \Pr[X'=\pi(x) ~|~ (i,s)]$. Let $x\prec X^*$ denote that $x$ is a prefix of $X^*$. Let $x,s\prec X^*$ denote that $(x_1,\ldots,x_{i-1},s)$ is a prefix of $X^*$. Note that $$\Pr[X' = x ~|~ (i,s)]\,\Pr[(i,s)] ~=~ \Pr[X' = x \wedge (i,s)] ~=~ \Pr[x,s\prec X^*] ~=~ \frac{1}{n^i}.$$ Thus, $$\Pr[X' = x ~|~ (i,s)] ~=~ \frac{1}{n^i \Pr[(i,s)]}.$$ Since the right-hand side is independent of $x$, and $\pi(x)$ is also a possible value of $X'$, $\Pr[X' = \pi(x) ~|~ (i,s)]$ also equals the right-hand side above. QED Corollary: Randomly permuting the first $k-1$ elements of $X$ (as described in the question) does not change the distribution of $X$. This implies that the distribution of the r.v. $m$ as defined in the question (with permutation of the first $k-1$ elements) is the same as the distribution of $m$ if the elements are not permuted. That is, $m$ is distributed as the first index at which $n-1$ distinct elements in $S$ have been seen. By a standard calculation, $E[m]$ equals $n(H_{n}-1)$. 

It's possible to sort with $O(\sqrt n\log n)$ calls to the black box and no comparisons. First, consider the following balanced partitioning problem: given $m$ elements $A[1..m]$ (where $\sqrt n \le m \le n$), partition them into two groups, the smallest of size at least about $m/4$, so that all elements in the first group are smaller than all elements in the second group. This can be done with $O(m/\sqrt n)$ calls to the black box. (I'll describe that later.) Then use quicksort with this partitioning algorithm: 

This is not an answer. It is just the somewhat trivial observation that WLOG you can relax the requirement that there be exactly $p$ edge subsets $\{E_i\}_i$ of exactly the same size, and instead just look for any number of edge subsets of of size $O(\textsf{the desired size})$. Maybe this helps think about the problem. Fix any graph $G=(V,E)$ and integer $p\ge 1$. Let $s=\lceil |E|/p\rceil$ Lemma. Suppose there are subgraphs $\{G'_j=(V'_j,E'_j)\}_j$ such that $\{E'_j\}_j$ partitions $E$ into (any number of) parts of size $O(s)$. Let $$M = \max_{v\in V} |\{j : v\in V'_j\}|$$ be the maximum number of parts that any vertex is in. Then there are $p$ subgraphs $\{G_i=(V_i,E_i)\}_i$ such that $\{E_i\}_i$ partitions $E$ into exactly $p$ parts each of size at most $s=\lceil |E|/p\rceil$, and $$\max_{v\in V} |\{i : v\in V_i\}| = O(M).$$ Proof. Starting with the sequence $E'_1, E'_2, \ldots, E'_{p'}$, replace each part $E'_j$ in the sequence by any ordered sequence of the edges contained in that part. Let $e_1, e_2, \ldots, e_m$ be the resulting sequence (a permutation of $E$ such that each part $E'_j$ is some "interval" $\{e_a, e_{a+1}, \ldots, e_b\}$ of edges in the sequence). Now partition this sequence into $p$ contiguous subsequences such that each except the last has size $s$, and let $E_i$ contain the edges in the $i$th contiguous subsequence. (So $E_i = \{e_{i\,s+1}, e_{i\,s+1}, \ldots, e_{(i+1)s}\}$ for $i<p$.) By assumption each part $E'_j$ has size $O(s)$, and by design each part $E_j$ except the last part $E_p$ has size $s$, so (because of the way $\{E_i\}_i$ is defined) the edges in any given part $E'_j$ are split across $O(1)$ parts in $\{E_i\}_i$. This, and the assumption that each vertex occurs in at most $M$ of the parts in $\{E'_j\}_j$, imply that each vertex occurs in at most $O(M)$ of the parts in $\{E_i\}_i$. QED