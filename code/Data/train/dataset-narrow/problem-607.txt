Help in sizing oracle 10g database sga We've an Oracle 10g r2 database, size = 4.5TBASM is used to manage the storage. It uses "External Redundancy" option on "Raw Device" (i.e. no os file system caching).Server Configuration is Intel Xeon 4CPU (8core per cpu) i.e total 32 cores; Total Internal Memory is 128GB. Operating System is Solaris 10 update 9. The SGA size is 80GB, if we increase the SGA to 84GB~85GB the cpu utilization shoots upto 99%~100%. With 80GB SGA the cpu utilization is 20%~50% depending upon the load. What is the relation between cpu cores and sga size? I used 4GB memory per core, is this a correct estimate for the Intel Xeon platform Why does the cpu util shoot to 100% with an increase in SGA?Is there a rule of thumb for sizing the oracle sga for oltp environment? vmstat output: r   b   w   swap          free         sr   s0 s1 s2 s3 us 0 26 27 128146676 6448872 115 0 3 0 94 19 1 74 31 123050360 4031544 0 0 2 0 56 16 0 83 31 122930884 3921080 0 0 0 0 31 10 1 75 31 122934416 3921480 0 0 0 0 61 13 0 78 31 122787016 3802200 0 0 0 0 104 25 0 84 31 122595368 3626344 0 0 0 0 110 22 0 91 31 122717320 3759480 0 0 0 0 108 25 0 88 31 122831348 3889744 0 0 6 0 111 27 0 79 31 122581408 3647472 0 0 0 0 101 44 1 84 31 122306816 3388964 0 0 0 0 71 27 The "sr" column reports zero for most of the entries (but the first where it shows a high value 115)Moreover the vmstat shows an unusually high blocked and swapped out processes. 

A web edition seems enough for me when I read this. I thought it had a 2gb size limit before? I have three databases our current db and am not doing anything fancy. Just some server agent jobs from $URL$ This is our current db: 

I have a dedicated windows 2008 r2 server at the moment and I am thinking about migrating to a virtual server because of the costs. Now I know that SQL should be on a dedicated server, but the flexibility and costs are a great advantage for our situation. I would like to compare both servers. I know it is hard because one is a production server with actual load and the other is a test server with one user. Both run Microsoft SQL Server 2008. dedicated has 12 GB ram, virtual has 12 GB ram dedicated has a dual quad core CPU and virtual has 4 CPU's both have the exact same database (I restored a backup from production on the virtual test) I executed a heavy select query with a heavy view and made the Microsoft SQL Server Management Studio include the . That displays the Total execution time Somehow the virtual shows a zero there now (since we added 2 virtual CPU's) but in the bottom right of the management studio it shows that the virtual server took 3 seconds and the dedicated server(production) took 2 seconds for the query to complete. How can I make a good comparison between the virtual and production? Edit: I have been told that the paravirtual setting in VMWare makes it better to compare the performance of the two instances. 

We need to migrate the storage of our production database. What is the appropriate method of doing so and what specific/generic precautions do we need to take?? Database Configuration: Volume Manager - ASM using Raw Disks. ASM External Redundancy as storage is published from storage subsystemDatabase version - Oracle 10g R2Database Size - 5TB approx. Existing Storage (source): HP MSA 2312sa Dual Controller. Directly connected to our database server (no fc or ethernet switch). The Oracle binaries are also on this storage New Storage (Target): HP EVA6300 FC storage. This storage will be connected to the hosts via FC switches. Can we use host based storage migration like VxVM Plex attach/dettach to copy data from source LUNs to the target LUNs? Do we have to use Oracle RMAN backup and recovery method for storage migration? 

One of our Production database has a rather peculiar block size of 16KB. This database was created about 2 years ago and at that time the size of the db was approx 1TB only.However over the past 2 years the db size has grown to approx 5TB. The workload is a mix of OLTP (transaction) as well as OLAP (reporting). This db block size is causing our DB Buffer Pool to be constantly filled up (95%~100% full).The db uses ASM on Raw Devices. Is the 16KB db block size sub-optimal?Can this large block size be adversely impacting our storage sub-system performance?If so what can be done to remedy the situation? Noteworthy here is that we do in fact perform huge full table scan for reporting as well as for our application (business logic).The OLTP nature stems from the fact that our application also has transactional (financial transaction) module. 

Running an S0. @@version = The stored proc uses 3 tables. One main object with a relation to prices and a relation to features. 

I have about 10.000 main objects with per piece 10 features and avg 3000 prices. So that will cause the prices table to have 30 million rows. I have a C# console app which runs my stored proc per and have speed up price and feature storage by using types and table values. I have a dictionary in my app with mainobject code and id so I can fill the id of items which do not need an insert. So that I can preserve the primary key, since they don't change much. I had 3 stored procedures at first. One per table, but instead of 3 stored proc executions, I moved to an all in one sp. Here is my SQL code: 

Did I make a mistake in my parameters? It did run and rebuilded and reorganized several indexes. It took down the list from about 25 to 19 rows. (4x foreign keys, 3x primary keys, 4 indexes and the rest without a name) 

db3: (can be removed I hope) and seems similar to db2 it all runs on an xeon e5-2650 v3 @2.3ghz (4 cpu's) and 8gb ram. So I thought that a D2 on azure will perhaps be similar and a web edition of sql 2014. (west Europe) $URL$ or is it recommended to move away from running a sql server on a vm and towards hosted sql. $URL$ 

edit as @S4v1n suggested, I had to post the execution plan. I used $URL$ this code to get the full SQL command and pasted that in SSMS and got this queryplan for one of the mainobjects: