No problem at all proxying Tomcat via an existing Apache httpd instance. You might want to look into mod_proxy- it's easier than mod_jk. You might also want to look at this article: $URL$ 

Use Ant or a similar tool to build your web application and package it into a war. Drop war in webapps folder. Note that from time to time you will have to restart Tomcat due to PermGen leaks. Packing your application as a war is neat and keeps things tidy and nice (i.e. if your Ant build is sane, your webapp will be easy to deploy for other people). However, this is slow for development. I would look for ways to run your webapp inside your IDE. 

You could make it work using your current method, but it's probably more work. I know by certain that these two methods are more easily "scriptable". If you choose /etc/fstab, you just need to distribute the line required to mount your network share to all your hosts. If these are not too much, you could do it by hand, but as the number of hosts grows, or the maintenance required increases, you should automate it. You can also distribute the required files to make fusesmb/smbnetfs to work across a network easily. You might want to look into either: 

You could use log recovery in most RDBMS, but it is not as "easy" as Oracle's. Basically, all RDBMS can keep track of all executed queries. So you could use this on a separate server to replay executed queries from a full backup and restore the state of the database at any given point in time (i.e. you could see the state of the database at December 3rd, 13:53 after transaction xxx). You could also analyze the logs and see what happened. This is very limited and not very practical. Check PostgreSQL docs here: $URL$ 

$URL$ lets you set up restricted ssh so that only SFTP/SCP are run; it also helps setting up the chroot. As CarpeNoctem points out, FTPS sometimes is a better solution. ssh, SFTP, scp are very "low-level", FTPS (like the unsafe FTP) are normally higher-level (virtual directories, virtual users, etc.). I think for the scenario you describe, both approaches would work. 

If you want to setup clustering anyway- and in Postgres land I'm inclined to think it should be more for availability purposes than for performance- pgpool provides some tricks to replicate the databases with very little downtime ($URL$ 

We have a client we host a web for (blog.foobar.es). We do not manage foobar.es's DNS setup, we just told them to point blog.foobar.es to our web server's IP. We have noticed that sometimes we cannot browse to blog.foobar.es, but we can browse to other sites on that server. Troubleshooting a bit using host(1) yields something funny: 

I'm pretty sure they don't. I use Apache httpd with mod_proxy and mod_cache and it works pretty well. If you take the time to send proper HTTP response headers, it's better... 

If the website is identically served by the three servers, make it transparent and do not redirect. It does not make sense to have identical content on different domains. Also, the techniques used to do that will let you fail-over if one of the servers fails. 

If you ever wish to separate services into different boxes, you'll want to use subdomains. Think about what happens when you run LDAP and a web server on mydomain.com and later on you decide to move the web server somewhere else, but LDAP stays in the same box. 

On paper, storage is one thing you can judge on; storage in VPSs (in my experience) tends to get expensive past, often being cheaper per gb. on some dedicated servers on the same provider. People often comment on lousy disk performance on VPSs. My extra low end VPS's disk, according to hdparm is nearly 9x slower than the hard drive in my 5-year old Thinkpad... 

You have to think outside the box. As in, you can't really trust what's inside the box. For instance, get your provider to monitor outgoing traffic. Traffic you can't explain => assume the server has been compromised. Get an image of the hard drive (extracted using trusted binaries) and run forensics. 

If you just want to replicate a single system image across multiple boxes, I would look at the latter; you just configure one box "just the way you like it" and then either boot all boxes from the same image via the network or copy the same image easily to all boxes. Roughly, imaging is easier; netbooting tends to be more convenient. I guess Puppet is much more complex, but depending on what you are doing, it might be absolutely worthwhile. 

Webmin, probably. Although it being a web-based application I'm not sure it will work gracefully with all network configuration changes. 

Yes, you can. It's pretty easy to configure and fairly non-problematic (as long as you keep your clocks synchronized!). The instructions to do so are in the RHEL deployment guide. If you have AD, I suggest you use that, as I believe synching Linux to AD might be easier than synching Windows to anything else than AD. 

Try activating verbose garbage collection and see if it's a garbage collection pause. I guess a huge heap, lots of object allocation and swap might cause a long pause, but that long sounds quite unusual. 

Have them fix it. Any solution other than that will cause problems down the road. Tell them its bad for SEO. If you cannot, you might want to look at something like $URL$ 

Keeping your system patched should be easy. I suggest you use "stable" distros with long term support (meaning you get no updates to software beyond security patches and major bug fixes). These mean that their package manager 'update all' operation will probably be smooth and easy. You should also subscribe to the distros security mailing list and evaluate all messages concerning software you have installed. You should also audit all means of entrance to the box, make sure that there are no unnecessary net-accessible apps running and that necessary net-accessible apps are properly secured (i.e. use encryption as necessary and have strong authentication). Watching log files is somewhat overrated, but you might find packages that simplify this. E.g., Redhat Enterprise (and CentOS) install by default logwatch which sends you a daily report by email of your log files. Also, for systems that need to provide services 24/7, you should set up monitoring and, if needed, fail-over measures. Also, backups!