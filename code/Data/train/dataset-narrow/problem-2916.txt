This is not actually possible. When you create the D3D device, it binds to the graphics adapter, which can't be changed on the fly. 

The answer is that you have to SetPhysics(PHYS_NONE) before basing it. Apparently this is not necessary if you are basing it on another descendant of KActor, since they will then be handled at the same time in the Tick cycle. 

Got it. You create all the Sprites up front and keep them. Each Sprite object takes about 500 bytes of RAM, and you just set the Image.Sprite attribute to the frame you want. 

It was not the sound. It was the score object updating, which has a problem on iOS if your font is set to Dynamic. Lesson: always check the profiler before trying to fix performance issues. The big spike in the image is the first call to changing the score, and you can see that takes a long time. 

I want to set the Target location when the effect plays, but I can't figure out how to do that from UnrealScript. I've looked at the UDN page on it: link But this doesn't seem to explain how to access the relevant info from script. I am currently able to get the effect to play, but I just can't set the endpoint. 

Try this: $URL$ Down the page is a thing called FBX 2013.3 Plug-in for QuickTime I think this will allow you to open FBX files in Quicktime. 

This means your function will only ever see levels 1-5. It's not super-elegant, but it's easy to understand and it will work. 

On the call immediately following releasing the key, your clause sets . This stops the walk animation, I presume. 

No, this is just a coding convention on the part of the people who wrote the code. You can name your objects however you want (within reason... I'm sure would not be a legal name). The idea behind this convention is that you know what type an object is just by looking at its name, which is supposed to aid understanding while reading code. I don't really like it, either. :) 

Game rules and mechanics cannot be copyrighted. Specific implementations, writings of the rules, names, and associated art CAN be copyrighted. So if you don't call it Risk, and don't use any of Risk's art, I think you're fine. The company I work for has had serious problems with dealing with the versions of our games people make for free thinking that alone makes it legal. But as usual, I say this: "Getting legal advice from random people on the Internet is not a good idea." Do your own research, and consult a lawyer if you want to be sure. 

If your game architecture doesn't support info coming in over the wire, it is a real hassle to add MP later. Make the decision early whether or not your first published version will have MP or not, then develop toward that goal. It's always easier to drop the MP later if it's going to be too expensive than to tack it on if you decide you want it. 

I can call that function directly from Unity, and it works; I'm sure I've built the plugin correctly, and included it in the project correctly. But when I do , nothing happens. Some idea what I could be doing wrong? According to Unity's demo, this is all that has to be done. I think. I know that in their example, they have it defined as , but I found this in their code example: 

The answer to the question "Is it possible, or even feasible, to have graphics engine completely decoupled from game logic?" is "yes". I would say it is even "advisable". But in general, you'll find a lot of your game ends up tied to the engine you choose for other reasons, like input handling or use of their facebook integration or other cross-platform services. 

If you get into 3D game development, you had better know the basics of Linear Algebra so you can deal with vectors and matrices well. Knowing basic calculus will help, as you'll want to know what derivatives are and how they relate to position, velocity, and acceleration. Very strong knowledge of algebra will help, as you'll need to construct formulas for things. 

Music was made using "tracker" software. You'd have a small bank of samples, and would set up a list of times and pitches at which to play those samples. So the memory taken up was a fraction of what it would be if you encoded the final audio itself. If you listen to the music from the Amiga game Agony on level one, this is readily apparent: $URL$ You can hear it's the same short orchestral sample played over and over at different pitches. 

In addition to making it yourself or hiring someone, you can go through a music licensing site: $URL$ Another good place (we used this for The Greatest Heist) is www.shockwave-sound.com. You pay a small amount for royalty-free use of music there. 

I have a KActor descendant, which is a carging shot, kind of like in R-Type. When it starts charging, I do projectile.SetBase(Pawn) in the PlayerController where it is spawned. I've checked in the debugger, and its base is in face the pawn. But it does not move with the pawn. I have done this before, where I base KActors on a moving entity, and it moved with them. I must have done something differently, but I can't figure out what it was. Looking at the old code, I just did SetBase like I am now. Any ideas where I might be going wrong? 

Ok, I've been asking various questions and getting some good answers, but I think I need to rethink my method, so I'll describe the problem. I have a player who has a big blue box in front of him. This box shows which KActors will be pushed when he pulls the trigger: 

I have a golf ball on the ground, and from a raycast, I have the normal which gives me the slope of the ground by the ball. I have an object which is rendered on the HUD to show that slope to the player. I have a parent object rotated -90 degrees around X, so that the indicator's Z-axis points up. This way I can do this: 

My personal opinion on this is that if it's a competitive game, the information should not be available on the client until it's ready to be shown to the player. The League of Legends launcher at one time knew the names of your opponents, but displayed "Summoner 1", "Summoner 2" etc. So a few times someone said in the pre-game chat "Hey Summoner 1 is an Ahri main. Ban Ahri." Give your players as little opportunity to cheat as possible. 

lineSpacing = 220, characterSize = 10 lineSpacing = 220, characterSize = 25 lineSpacing = 220, characterSize = 30 lineSpacing = 110, characterSize = 25 

My answer is "it depends". My current phone game project at home would totally not benefit from a level editor. This is because my levels are a set of very simple parameters that are used to procedurally generate the grids. That's on one end. On the other end, there are high-level AAA games which are so large and complex, you really, really need quality editor. One reason Unity and Unreal Engine are useful is because the include an editor. So where you are on this scale determines how much time should go into your editor. If your game is simple enough so that you'd spend 5 times as long making the editor as the game without the editor, then it's not worth the trouble. But if making the editor was say 50% of your dev time, but your total dev time would triple if you didn't make the editor, then it's definitely worth making. 

But I'm unable to do this since .textureRect is readonly. I could create a new Sprite each frame, but I suspect this is not going to perform well with tons of Sprites. 

You can see what's in an apk file by renaming it with a .zip extension and using the usual tools to look inside it. That way, you can see the size of everything included in your build. 

Circular motion already has velocity; what makes it circular is the continued application of a rotating acceleration of constant magnitude. So to let the object leave the circle at the proper velocity, just stop applying the acceleration. 

When I do this, the thing only collides as if it were not scaled. If I leave the actor spawned so I can see it, it is scaled. If I also "show collision", the collision displays correctly as well. Is there a prohibition against scaling collision shapes at runtime? 

3G is optimized for stuff like streaming video. It's terrible with regard to latency when talking about small bits of data. There's a reason multiplayer mobile games over 3G with split-second timing don't exist. 

The problem is, if you check for touching between Actors and KActors, it looks like it does a plain axis-aligned bounding-box collision. The power will push the box on the lower right, when it's clear it's not touching the blue box. How should I do this properly? I just need a way to find out which KActors are touching that area, on a poly-by-poly level. These collisions are only done with rectangular boxes and simple sphere collision; we are aware of the potential for performance issues with complex objects and poly-collision. I've tried making the collision checker a KActor, but it doesn't report any TouchingActors. This issue is causing us trouble in a lot of other places as well. So solving this problem is a core issue in our game. 

Ordinarily, the actor gets spawned, anything touching it gets bumped, and the actor despawns itself. If I set the Scale3D as a default property, everything works as I expect. But I want to scale it at runtime, like this: