Get a new CompactFlash card to replace the dead card. They don't last forever, and from the sound of it, that one is almost certainly long past its useful life. 

Yum doesn't provide a way to follow a specific semantic version, but there is a way to lock a particular package version in place, using the yum plugin. 

You don't need to switch back to a Generation 1 virtual machine. You can use a Generation 2 virtual machine, so long as you disable Secure Boot. To quote from Microsoft: 

Cause Red Hat upgraded the version of OpenSSL in EL6 from 1.0.0 to 1.0.1 in the 6.5 update, in order to resolve a years-old feature request to add elliptic curve cryptograhpy support. This package is no longer binary compatible, and programs that were built against OpenSSL 1.0.0 must be rebuilt from source against 1.0.1. Unless you're installing third party applications, of course, which almost everyone does. Those have to be recompiled, too, and at this point most third parties have done so, and built new packages against 6.5. It is these packages that third parties are generally shipping today. Resolution Identify all of the impacted third party packages and contact the third-party package vendors for updates. Once updates are available for all packages, you can safely update your system to 6.5, installing the third party package updates at the same time, which will complete the resolution. For packages installed through the package manager and yum repositories, this is trivial; simply attempting to upgrade and being able to do so without dependency problems means that the packages are ready. For packages manually installed, you will need to check these yourself and apply whatever updates the vendors have provided. You should also pressure these vendors to supply proper RPM packages and yum repositories in these cases. Most users can update to 6.5 with a command such as: 

Windows 8 and Windows Server 2012 computers joined to the domain can access the Windows Store, and users can install apps from the Store, unless you have set Group Policy to disallow access to the Store. Like any other GPO the restrictions can be applied to users or to computers. The article to which you linked describes a process by which you can deploy Metro apps when you want to be sure they are preinstalled on users' computers, and/or when you are disabling access to the Store. In these cases you would obtain the app directly from the vendor, rather than from the Store, or develop it in-house, since you cannot sideload apps from the Store. For more, see Managing Client Access to the Windows Store on Technet. 

You are only listening to the loopback address, so it can't receive connections from other servers in your VPC. Try instead: 

Open vSwitch support requires libvirt 0.9.11 or later. Your libvirt is too old. To resolve the problem, upgrade your system. 

This permits root to use any authentication method except password. For a single-sysadmin scenario this is fine. Though, as has been discussed ad nauseam here and elsewhere, if you have multiple sysadmins, none of them should be logging in as root. 

Your APC cache looks fine; it's certainly not excessively fragmented, and if you aren't having performance problems then there's no real need to worry about it. Let it run 24 hours, and then take a look at it to see if you still have good performance and enough free space in the cache. 

The first two look OK for a Shopify site; the last two are definitely wrong as they return an A record direct instead of the CNAME shops.shopify.com. In my tests I also saw several other IP addresses returned. A survey of those addresses on TCP port 443 indicated that not all of them had a web server running on port 443. You need to figure out which DNS provider you want to use, and have only that provider's DNS servers listed in your whois record. You make this change at your domain registrar: 

Your log shows that some process sent a signal to systemd causing it to shut down, and that the name of the process was . 

Who cares about ? All your important stuff should be in the other logical volumes, and as long as you never touched those, you should be able to access them without issue from a rescue CD. Of course, you're lucky this time. Next time, you may not be. Before you do anything else beyond this, get backups in place. 

You can't use switch port security on the Cisco since all the VMs will be sharing a physical switch port. And you can't use Linux because the traffic is being bridged, not routed, through the hypervisor machine. But you can emulate switch port security on the hypervisor with Linux , which is a lesser-known layer 2/3 firewall on the Linux bridge. A quick and dirty example (and likely incomplete; I don't generally bother with this): 

New Windows Azure customers have a spending limit of $0.00 applied to their accounts. You can change this amount to any dollar amount you wish. If your balance exceeds the spending limit, all your instances will be shut down for the remainder of the billing cycle, and all of your data will be read-only. You can also remove the spending limit entirely and re-enable it starting with the following billing cycle. 

For the processor to be usable in a multi-socket configuration, it must expose the QuickPath Interconnect externally. Intel desktop processors do not do so. You'll need to use a Xeon, and not just any Xeon; some of the lower end ones can only be used in single socket configurations. Check its specifications at Intel's ARK site to make sure that it can be used in a multi-socket board. For modern processors, this will be listed as Scalability with a value of e.g. 1S, 2S or 4S (sockets). 

The most obvious effect is to keep firewall rules to a manageable level, which does not have a significant impact on performance. At a certain point, you may end up with too many firewall rules and not enough CPU to process them quickly enough. The default limits may seem low, but they're sufficient for most people, who will never create more than a few security groups with perhaps half a dozen rules each. 

Docker doesn't have authentication on its socket. Anyone who can access the socket can control all containers, and can effectively break out of the container and become root on the container host (if SELinux is not in use). First, be extremely careful if you decide to do this, that you are only running trusted code. Second, forget about TCP; just bind-mount the Docker socket to the container. This way, only that specific container can access Docker. 

And you must start a command with if you want the command to have access to the software collection. 

This is not the default behavior of . The default is to wrap long lines. You are seeing this behavior because you have the option (and several others) set in your environment variable. 

The third thing is that it uses a third party repo called atomic, which provides packages that conflict with packages in normal repos such as EPEL - which already provides redis and OpenVAS! It's not clear why atomic have done this, nor why this tutorial uses atomic to begin with. Using repositories with conflicting packages is potentially dangerous. If you continue with using atomic packages, you will need to be absolutely certain that this (virtual) machine is never used for anything else for any reason whatsoever. Finally, once you get it installed, the web interface isn't actually reachable because the indicated port isn't open in the firewall. You also have to do this yourself. 

If the init script is already there and properly written, it should suffice to enable it normally like any other init script: 

In practice, two days is utterly absurd for this. Suppose you are about to add a new hostname to your record, but it doesn't currently exist. So you look it up, and you get . Now that will be cached for two days, even if you add it to your zone file five minutes later! I have this set to (one hour) for most of my zones. 

You're using an OpenVZ virtual machine. The hosting provider must specifically enable support for PPP for your virtual machine. Contact your service provider. 

When your instance is stopped, you are only charged for its associated storage (e.g. your personal AMIs or EBS volumes), but not the hourly compute charge. The hourly compute charge applies only when the instance is running. 

There's no way for MySQL to know what PHP script was running. All it knows is it got a connection from username, password, host, and was asked for some query. So it logs what it has available. If you're the developer, you should hopefully be familiar enough with your application to locate the code making the query within a few seconds. If you aren't the developer, or aren't familiar with the application, try . Or contact the developer who is familiar with it. 

Add to your directive in . This will send a copy of all of the message headers to postmaster. (For privacy reasons, Postfix truncates the message body on the copy sent to postmaster.) 

You can test the configuration by adding to the line that begins with , immediately after that keyword. The next time you restart smartd, it will send out an email notification. 

Note that refers to qemu's idea of the drive, which will vary depending on the driver in use (e.g. virtio or virtio-scsi) and which virtual drive it is in order (the 0 will change to a 1, 2, etc.). For a SCSI drive, you would have something like where the numbers refer to the virtual controller, bus, target and LUN as defined in the libvirt XML. 

IIS uses the HTTP Host: header to determine which web site to serve, just as with any other request. 

The SELinux reference policy already contains a user role which (slightly) confines root when confined users are being used on the system (they are not by default). It should be possible to design a user role which can start/stop services and no other admin tasks, based loosely on , though I've never had to do this before and so I hesitate to give you a line-by-line. As much as I hate to say it, this is a question I would probably take to the selinux mailing list. 

Disable or uninstall cloud-init. This is the easiest option and if you aren't running in a cloud service then you should do this. For example: 

Most likely that socket doesn't actually exist. This is probably a simple typo. By default the socket is located at on a Fedora box. So, in your file you should have: 

If I'm reading your question right, I think you're looking for DRBD. This will transparently keep the two servers' disks in sync, allowing one to fail over to the other without data loss. 

This is W3C Logging, the IIS logging service. The Italian translation is slightly too literal, I think... 

"Corruption of in-memory data detected" doesn't necessarily mean that the hardware RAM is bad. It could also indicate a block was read or written incorrectly, the storage flipped a bit or is otherwise failing, possibly filesystem bugs, and a few other causes. Reverting to a snapshot probably won't resolve the problem if there is some latent filesystem corruption; it'll just show up again later. Instead, you should the filesystem, but since it's the root filesystem you'll need to boot from installation media or a rescue environment provided by your VPS provider. If fails to repair the filesystem, you may run which will clear the XFS log (which may itself be corrupt) and then try to repair the filesystem again. 

You can't use a transparent proxy in this scenario. A transparent proxy must be in the network route of the traffic so that it can intercept and rewrite all of the traffic to redirect it to squid, and since your server is outside your network path, you have no way to do this. If you want to use this server as a proxy, it will have to be a normal forward proxy. 

The problem is indeed on your customer's end. Your Postfix is configured to reject invalid hostnames provided by anything that attempts to deliver mail to it. This is a reasonable measure and prevents a lot of spam. But, your customer's mail server connected and provided an invalid hostname in the EHLO greeting. When Postfix tried to look up the hostname, it was unable to find any record of it in the DNS. The customer needs to configure their mail server to provide a valid hostname in the EHLO/HELO greeting. 

You have an incompatible repository "rpmforge". This only works on RHEL and clones, and isn't compatible with Amazon Linux (which used to be a RHEL clone, but isn't anymore). You have a couple of options: 

The installation instructions you linked to gave two separate and distinct installation methods, one involving EPEL and the other involving OBS. You seem to have done both of them, but they are mutually exclusive. To resolve the problem, remove the x2go repo file that you installed and try again using only EPEL. 

You don't need different sockets for each virtual host. You do, however, need different sockets for distinct php-fpm pools. If you're running all your virtual hosts in the same php-fpm pool, then you only need a single socket. However, if you move some of them into a different pool, that pool is a completely separate process group and needs a different socket. 

to print every line of the script as it is executed. Can't run the script like this? You can also add it to the shebang at the first line of the file. 

You're using the third party city-fan repository. This repo has dependencies which are in the EPEL repository, one of which is libnghttp2, so you must have EPEL enabled to use city-fan. 

The OS variant isn't really that important. It just sets some defaults like the default amount of RAM and CPUs. You can safely set it to the closest available match (e.g. RHEL 7.0 for 7.1). 

Those are both telltale signs of a KVM virtual machine. It is almost certainly running on an Ubuntu host, based on the presence of the "Canonical" brand. 

is a pretty obvious one. It means your backend (in this case, gunicorn) is not running on the port you've specified in your nginx config (in this case, 8020). One of two things is going on here. Either: 

You have an incorrect setting in your file: The value is set to in the default file and needs to be changed. should be defined and set, either to which inserts public cache-control headers, or to (blank), which doesn't insert any cache-control headers, and the headers sent by your application will then be used, if any. 

You have some serious firewall/NAT misconfigurations. You aren't actually running a web server on port 443... 

Make sure your Red Hat subscription for this machine is active. Not having an active subscription is usually the cause of this. (If it is active, call Red Hat.) And if you're compiling your own version of PHP, you don't need to do any of this. 

The virtual machine host can see and defeat any security measure you mentioned, including encryption of the virtual disks or files within the virtual filesystem. It may not be trivial to do so, but it's much easier than most people think. Indeed, you alluded to the common methods of doing exactly that. In the business world, this is generally dealt with via contracts and service level agreements, specifying compliance to legal and industry standards, and so is usually considered a non-issue as long as the host is actually compliant with the relevant standards. If your use case requires security from the host, or more likely, from the host's government, then you should strongly consider obtaining your service in another country.