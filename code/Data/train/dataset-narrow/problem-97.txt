PPPoE requires a continuous network segment, so the PPPoE server/endpoint and both clients all need to be in the same VLAN. PPPoE connections are (usually) limited to one session at a time. So, while there's a valid session, a 2nd login will either be rejected or kill the 1st session. The problem is not that dev1 and dev2 can see each other (at least not likely, you're very scarce on details). If you need both "devices" to simultaneously access the uplink, you'll need to not establish the session themselves but delegate that to a router which in turn lets both devices share its session. Usually - with a single public IP address - this will be a NAT router. With multiple public IPs you don't need NAT. Another option would be to obtain a 2nd PPPoE account from your ISP to log into in parallel. Why don't you just put the Windows machine behind the router? 

9.9.192.1 is an address owned by IBM - so unless they've given it to you, you can't use it on your LAN without causing problems. A subnet mask of 255.255.240.0 or /20 is completely fine as long as the address range you're using is large enough and either private (192.168.0.0/16, 172.16.0.0/12 or 10.0.0.0/8) or granted to you. Mixing devices with differing network addresses or masks doesn't usually work as you've already noticed. Usually, your network devices are configured by DHCP, so possibly you just need to correct the scope there. If you're not using DHCP now is a good time to start. edit 1: You might want to read up on how subnetting works in this good question/answer: How do you calculate the prefix, network, subnet, and host numbers? edit 2: The subnet mask defines the size of the subnet. Your mask 255.255.240.0 allows for 12 bits = 4,094 host addresses which might be a bit oversized. It doesn't hurt though, except that /24 might be slightly easier to handle. edit 3: If your can't change the LAN subnet mask on the router just don't do it. Change the mask in the DHCP options and simply don't use the extra 4 bits of host addresses. edit 4: your screenshot in the other comment - you should add additional details to your question instead - shows the DHCP options. These are most probably inherited from the NIC's network settings which may be the reason why you can't change them. Check the NIC's IP settings and correct the mask there if possible; the DHCP scope is likely to follow. 

When a device behind the switch in question is reachable and the switch is reachable locally, this can practically only be a routing issue. Double check the default gateway on the switches in question (static or DHCP) and that the switch can ping the router (or vice versa). Also check possibly involved firewall/VPN rules (I'm assuming "remote" means accessed through a VPN link). Less likely scenarios are ARP cache poisoning (on switch or core router), a rogue DHCP server changing the switches' default gateway, route manipulations on the switches through SNMP, ... These may need to be ruled out one by one while the problem occurs. A simple traceroute doesn't produce enough information. 

The J4858C is a 1000BASE-SX transceiver. 1000BASE-SX is specified for 550 m reach over 500 MHz*km fiber (OM2). OM3 (1500 MHz*km) will probably go quite a bit further. 

Not sure what you're aiming at, but the main point is scalability: you bind your L3 interface to a VLAN. A VLAN is a virtual entity as large as the L2 segment - not even limited to a single switch. Essentially, you can keep adding physical interfaces to it as long as you like. 

auto-100 on the switch (leaves autonegotiation active) 100 MBit/s full-duplex on both sides (only when this is possible on both the switch and the computer's network interface) 100 Mbit/s half-duplex (only with a non-managed switch) 

Only Discover and Request packets are broadcast, Offer and Acknowledge are unicast. Unicasts are forwarded only to the switch ports they are required on, so you can't simply capture them across the network. You need to capture the unicasts on either the DHCP server or the client, or set up a monitor port on your switch (or use a repeater hub instead of the switch). 

Using different frequencies for transmission from multiple sources or in opposite directions is called frequency-division multiplex (FDM). This implies that each transmission sources has hold of a dedicated frequency band it can use. Nearly all Ethernet PHYs use baseband signaling - baseband means the frequency starts at (close to) 0 Hz and reaches up the maximum frequency that is used. Therefore, baseband signaling provides no room for FDM. (Optical fiber can be considered a special case: the baseband signal modulates the amplitude of a light source - using different light colors/wavelengths you can very well multiplex various sources into a single fiber. This is used for e.g. 1000BASE-BX10 or 10G/GE/PON.) 

You should check the cable for any markings. Usually you can then find the type by Google. Additionally, your switch should show which kind of SFP is inserted, regardless of DOM. What's the approximate length of the cable? Multi-mode (orange patch cable) supports 1000BASE-SX GbE for a few hundred meters (FDDI: 220m, OM1: 275m, OM2+: 550m). From ten years ago it's probably OM2 or OM3. For 10GBASE-SR the ranges reduce to FDDI: 26m, OM1: 33m, OM2: 82m, OM3: 300m, OM4: 400m. If you require more reach on FDDI to OM2 you could try 10GBASE-LX4 (550m) but it is rare and costly. These reaches are by standard, you can often go somewhat further, depending on the exact fiber quality. For single-mode fiber (yellow patch cable), you're probably good to go. 10GBASE-LR has the same reach as 1000BASE-LX(10) and you can buy higher-power transceivers with more reach. On HP switches, you can query the transceiver models by - 1000SX stands for 1000BASE-SX (multi-mode) and so on. For 1000BASE-LX transceivers (single-mode), those equipped with DOM may show the Tx and Rx powers which gives you some estimate to what the link attenuation is. 

All Ethernet ports count the contacts in the same way, so with a straight, 1:1 cable you connect port A's contact 1 to port B's contact 1, A's contact 2 to B's contact 2 and so on. Crossover cables connect two ports in such a way that transmitter contacts on the one side are connected to receiver contacts on the other side and vice versa. This is only necessary when connected two ports of the same type to each other (MDI to MDI or MDI-X to MDI-X). Most often MDI ports are connected to MDI-X port which already have swapped contacts, so you use a 1:1 cable. Note that due to today's Auto MDI-X and Gigabit+ Ethernet, crossover cables aren't usually required anywhere any more. 

As it seems, Cisco uses a "predictor" in the Application Control Engine (ACE) to control the load distribution: 

This is nonsense. Whether you call it link layer or make a distinction between data link layer and physical layer, the functionalities are exactly the same. The OSI model doesn't define a specific physical layer it just defines its functionality. ARPA/DoD/IETF just don't care about the hardware side and throw everything together. The OSI approach is very helpful for providing a good structure for the lower four layers (which actually need some sublayers as well). The upper layers are pretty much mashed together in practice, so the OSI model can't be easily applied - however, it may still be helpful for modelling a new protocol or application. A good layer structure opens to door to flexible enhancements and replacements in an isolated layer while preserving all the other layers. As with any model, you have to keep in mind that it's a model and you don't have to stick to the letter at all times. 

In reverse: when a VLAN interface doesn't exist the switch can't route. The VLAN will still work as a separate L2 segment and of course, you can route elsewhere (set the default gateway to the Sonicwall). 

Short answer: A-type or B-type cables don't matter as long as both sides of a cable are the same Long answer: Although there are T568A and T568B terminated cables, both types can be used interchangeably. The difference is in color code only - the important detail is that the pairs match which can be taken for granted with retail cables. The only actual difference is when one end of a cable is terminated in T568A order and the other in T568B order - this is a crossover cable that used to be necessary for switch-to-switch or computer-to-computer connections with early 10 and 100 Mbit/s equipment up to ca. 1999. Later devices usually support Auto MDI-X which makes crossover cables unnecessary. For the problem at hand and assuming the trouble started once gigabit speeds where used, you can try the following: 

There are variations, but DPCM usually means the difference between the current and the predicted value ("Option 2"). "Option 1" using the simple differences between two values requires a higher bandwidth. 

You'd need what with Lancom is called N:N NAT: translate both subnets to each other, so that one thinks it's talking to 192.168.11.0/24, the other to 192.168.12.0/24 (or any other unique range). It's not easy to set up and can be a major pain to debug, so if there's any chance I'd rather change the subnet address on one side and route them without NAT. If there's no easy way to change a subnet, maybe you can get away with adding another, unambiguous subnet on top on each side, so that each PC has two IP addresses, one of which can be routed from the other. Changed or at least additional unique addresses would also solved the problem with the single NAT router: you assign the default gateway only to the unique address binding, then you can NAT to WAN without problem. Alternatively, you'd need at least one additional NAT router before the central one. 

Early Ethernet did use coax cabling. It generally works both ways. Modern (copper) Ethernet uses twisted pairs to eliminate EMI, but only 10 and 100 Mbit/s have dedicated pairs for transmit and receive - Gbit upwards uses all pairs in both directions simultaneously. 

I'm not sure if I get your approach but most probably you're not doing it right. Anycast is termination of the same IP address/subnet in multiple points in your network. For this the subnet in which the IP address is contained cannot be used for anything else than multicast - you need to be able to route it off multiple routers without breaking anything. You'll need a dedicated anycast subnet that you may just put on top of your normal subnet. For instance, you configure the anycast address 10.99.50.2 as a secondary address on the host 10.0.50.2. On another host 10.0.60.2 a bit further down the road you also configure 10.99.50.2 as secondary address. Now, on the router 10.0.50.1 (close to 10.0.50.2) you add an IP address 10.99.50.1/24 to the same interface it's got 10.0.50.1 bound on. For the router 10.0.60.1 (close to 10.0.60.2) you do the exact same thing. The result is that clients using the router 10.0.50.1 will be routed to the host with the primary address 10.0.50.2 and clients using the router 10.0.60.1 will end up on the host with the primary address 10.0.60.2. In a corporate network, it is usually easier to use split-brain DNS and resolve the DNS name depending on location to point to the nearest server. On the Internet, anycast is more practical than split-brain DNS as you've got no control over which DNS server your clients use. 

Both. I guess that bloke is serious and he doesn't get what ridiculous schemes he's proposing. The joke's on him. 

What you're describing is an access point / wireless access point / WAP - it (usually) bridges 802.3 to 802.11 and vice versa. 

host A's IP stack encapsulates "Hello" in a UDP datagram, labeled for the destination application's UDP port the stack encapsulates the datagram in an IP packet, labeled for host B host A's NIC encapsulates the IP packet in an Ethernet frame, labeled for the router the NIC line-encodes the frame, encapsulates it in an Ethernet packet, and transmits it to the switch the switch decodes the Ethernet packet, forwards the frame through the router's port, and line-encodes the frame once again into an Ethernet packet the router decodes the Ethernet packet, extracts the frame, extracts the IP packet, and forwards the packet through the port facing host B; the packet is Ethernet framed (labeled for host B), line-encoded and transmitted to the switch see 5. on host B, steps 4. to 1. are reversed and the UDP payload is passed to the application 

The ping echo request and its reply follow the current routes on the hosts and routers they cross. So, it's definitely possible that each follows a different route - depending on what exactly you're trying to achieve, using asymmetric routing may be seen as bad practice by some. 

A switch forwards frames based on their destination MAC addresses, on layer 2. CSMA/CD/CA are access schemes for the physical layer (L1) - they have little to no impact on L2. 

How do you know this is incorrect? They might have direct peering or there's a tunnel in that last hop. Alternatively, the NAT router is resetting the TTL, so tracert is no use.