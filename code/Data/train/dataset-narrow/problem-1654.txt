If the NS server don't have an A record how can BIND find out their IP address in order to query them? It can't, so it can't resolve domains served by them. On a side note I've run a test myself and I've noticed that I can resolve 10gb.co.il using the DNS servers of my ISP, but I can't by running (this uses the root name servers). Your issue is caused by an improperly configured domain. My guess would be that the DNS servers of my and your ISP have the address of 10gb.co.il in their cache, while the current setup of the domain is incorrect. 

You could try making it harder to reset the permissions of the root directory by making it append only with chattr: 

Most Unix programs don't use locking or when they use it, it's not mandatory, so I doubt locking is stopping your log from growing. More likely the SCP transfer is slowing down the log writing. 

The manual for ST32000641AS (alternative link) says that the drive has 3,907,029,168 guaranteed sectors, while the specifications for WD2003FYYS (alternative link) say it has 3,907,029,168 sectors. Therefore the drives have the same capacity. 

Make the file immutable with chattr i.e. . Then no one will be able to change it, not even root, unless the attribute is unset. Note that only root can set or unset this attribute. 

Enable the modules. I suggest starting with the corresponding file underneath the directory (I used ). Prepare the kernel for modules: 

dislocate is a command that comes with Expect (at least on Fedora). Answer with when asked . You could also try using pexpect, a pure Python Expect-like module. Check out its hive.py and sshls.py examples. 

The link needs to be created where you're building the RPM and it also needs to point where you're installing the RPM. Before creating the link make sure that the destination directory exists, i.e. . You can use or for this. 

If you use Postfix, you can set the mailbox_command option to run your Python script on every message, but I think you'll have a lot of functionality to implement. Another solution would be to use procmail for local delivery and configure it to send (pipe) the messages to your Python script. This autoresponder example might help you. The advantage of this solution is that your script can be simpler. There's no need for it to be a full local delivery agent. 

Install one system, boot it and check out the block layer statistics from e.g. . Quoting from the documentation: 

Use the EPEL (Extra Packages for Enterprise Linux) repository. The easiest way to enable it is by installing the package. Here's how if you have RHEL 5 x86_64: 

then start Apache. Note: On the Fedora Linux distribution and probably others using systemd, some services don't see the mounts done after they were started because of some security features enabled by default. For more details read systemd for Administrators, Part XII. Also if using SELinux, the files need to have a proper label like for example. 

This sound to me like a DoS attack, which means that you can't do anything except ignoring the attacker which you've already done. You might also want to ask your ISP to block him. As for tcpdump still seeing those packets, this is normal. They still exist on the network, but the kernel makes sure that a regular application doesn't see them. 

Results for Scientific Linux 6.1 i386 I tested this on a KVM/qemu virtual machine running Scientific Linux 6.1 i386 (which is similar to RHEL). The following services were enabled: acpid, auditd, crond, network, postfix, rsyslog, sshd and udev-post. The swap is on a separate disk, so it's not taken into account. The stats for 85 boots, taken remotely with SSH a couple of seconds after the login prompt appeared, were: 

This could be caused by hard links which means that the files you deleted still exist under other names. To find them, run . 

How about a plain ? After all most devices are just a file located under . LE: You need to do the renaming every time you boot. 

I want to manage the mounted partitions from puppet which includes both modifying and creating the directories used as mount points. The resource type updates just fine, but using for creating the mount points is a bit tricky. For example, by default the owner of the directory is root and if the root (/) of the mounted partition has another owner, puppet will try to change it and I don't want this. I know that I can set the owner of that directory, but why should I care what's on the mounted partition? All I want to do is mount it. Is there a way to make puppet not to care about the permissions of the directory used as the mount point? This is what I'm using right now: 

A better solution would be to have multiple backend servers and balance the load over the members and detect offline servers using the parameter. So, when you reboot a backend server, another one could take the relay. 

When looking at the WSUS 3.0 API, there is no way I can find if a given update is needed or not. The UpdateInstallationState enum has a value with the following description: "The update is not applicable to the client computer". Meeaning, that update may be already installed and therefore is not applicable anymore to the target computer. The Powershell code will count for each update the number of computer target on which the update is applicable. 

If no email is sent using your ISP assigned IP addresses, you don't really have to provide them with a record. As I understood, you are using Godaddy to send your email so their configuration should be OK. You must however setup an SPF record in your DNS zone stating that the servers from Godaddy are allowed to send emails using your domain name. 

You can simply configure Exchange to forward emails for the support desk to your ticketing system and keep the emails in both mailboxes. 

This question has already been answered here. On most POSIX systems, multiple slashes are simply ignored. 

Using this configuration, anything like , and will be resolved to which should be your Web server's IP address. Then, in your Nginx configuration you put this: 

Your hosts will try to locate the Active Directory servers by querying the DNS server for records. For example, . This kind of records use the canonical name to your Domain Controller so their should be no issue. However and both reference the IP address of the Domain Controllers. So when changing your Domain Controller IP address, you should also update the DNS entries. How to setup your DNS zone depends on your Active Directory domain. Windows provides some tools to fix this. Try to run on one Domain Controller the following commands: 

Some registrar asks for the hostname instead of IP address. Your name server should therefore have an record like . 

I think you should use the physical interface only as a physical layer. You don't assign any IP address to this interface but instead, you create virtual interfaces bounded to which will take care of the IP transport. 

This happens only with some files and newly created one. When I look at the file defined and effective permissions, everything is all right. And to conclude this seems to be related to my user's computer. I logged him on another computer with the same configuration and it worked fine until the first caching. The only enabled policies are redirected folders and offline files cache encryption. Thinking of a problem with the user's profile, I removed both local and remote folders with no effects. Now I have no idea how to solve this issue. For your information, a Windows Server 2003 is running the Active Directory service while the files are stored on a Windows Server 2008. 

By default, creates the authentication key in or similar. You can however specify a different file name. 

To setup the scene, I have one of my users for whom roaming profile is enabled as well as folder redirection. My issue is that the user cannot open some files in the redirected folders (AppData, Desktop & Documents) for reading. It's possible to create a file and save it but impossible to open it again or even write in it again once it is created. 

Windows firewall is fully disabled. I can successfully ping the remote host. I can even access the remote host admin share It fails even on local network. 

The record will not impact your emails as long as you setup the correct record. If you want to receive emails for @example.com, you can setup your zone this way: 

In the administration page of alwaysdata, go to Sites then edit your site properties. You can here add addresses that match your site. Just add as a new address and save. 

The solution was in the Update object itself with its member. The state is set only if the update server stores the packages locally so this needs to be checked from the configuration. Also the state of the package is bound to the approval state. So if the package has been approved but is neither downloaded nor installed, the package is assumed not needed. I checked and this reflects the behavior of the WSUS Administration Console. 

You can create a DNS alias (pointing MyPhone to the DNS name of your web server) by selecting New Alias (CNAME) from the Action menu in DNS Manager. However, you'll also have to configure your web server to recognize the name MyPhone as a distinct web site, and create a redirection from that web site's home page to the URL you want, or, depending on your needs, put the content in question on the home page of that site. How you do this depends on what web server you're using. 

Microsoft Windows does not prohibit the underscore in the name of a computer. Some system administrators, either not knowing or not caring about RFC952, use underscores in the name of a computer that is connected to the internet, and either put this name in the DNS explicitly or allow it to be published via dynamic DNS. There's nothing particularly strange about these names. Examples might be JOHNS_COMPUTER or ACCOUNTING_DEPT_PC1. 

Almost certainly a permissions problem; if not on the folder containing the executable, then on one of the files, or somewhere else on the file system. The most effective way to troubleshoot this sort of problem is usually Process Monitor, available for download from the Microsoft web site. If the problem does not occur on other servers, the root cause might be something specific to the server, e.g., perhaps the permissions have been changed on the root of the C drive or on the Program Data folder. Process Monitor is still the best bet for identifying the problem. 

I suggest you look into the Sysinternals tools (now part of Microsoft) in particular AccessChk and AccessEnum. I haven't used them myself, but they sound appropriate to your needs. 

This is one of the rare cases where using Deny permissions is actually useful. It may be more convenient to add a deny permission than to change the allow permissions. You can do this from the command line (on Vista or later) like this: 

OK, since you only want to reduce your access rights (rather than actually running as Peter per se) you may have some options. In Windows 7 (and Windows Server 2008 R2) the task scheduler supports this directly (via the "Do not store password" option) but I don't think there is any built-in equivalent for Windows Server 2003. Running the task this way on a different machine probably won't help because you don't get network access. It can be done in software, though, even on Windows 2003, via the CreateRestrictedToken Win32 function. A Google search found a piece of software called ulimitnt which appears be able to do what you want (via the option). Note that I've never used this program so I can't vouch for its reliability. Using this approach, the script only has access to files that grant access to both local system and to Peter. (Note that the local system account implicitly belongs to the Administrators group, so if Administrators has access that will be sufficient.) 

In Windows Setup, you can press Shift+F10 to get a command line window. From there you can navigate to \boot and run memtest. You may need to use trial and error to see which drive letter the USB key has been assigned. This will vary depending on what partitions are on the internal drives. 

However, the licensing server is already configured in Remote Desktop Session Host Configuration and the Licensing Diagnosis shows no problems. Resetting the grace period as described here allows logons to succeed again but does not permanently resolve the problem; event ID 1130 continues to appear the first time someone logs in via Remote Desktop after a reboot, and after another 120 days logons will start failing again. As described here, the failing server(s) do not have X509 Certificate entries in 

Workstation SAMs act in many ways like separate domains with a one-way trust relationship. So while I can't find it explicitly documented, I don't find it surprising that this doesn't work, as it is analogous to adding a domain local group from one domain into a domain local group from another domain, which isn't allowed (see table 7-1). (The only odd thing is that it seems to work if the domain is Windows 2003 functional level, and I can't find this change documented either.) In any case, you should be able to solve your problem by changing the domain local group into a universal group. Assuming you are at least running in Windows 2000 native mode and not Windows 2000 mixed mode, universal groups are supported, and they are specifically designed for this sort of scenario.