The bounds... We have in fact $NFA(L) \ge Cov(M) + Cov(N)$, see Theorem 4 in (Gruber & Holzer 2006). For an upper bound, we have $2^{Cov(M)+Cov(N)} \ge DFA(L) \ge NFA(L)$, see Theorem 11 in the same paper. ...cannot be substantially improved There can be a subexponential gap between $Cov(M)+Cov(N)$ and $NFA(L)$. The following example, and the proof of the gap, is an adaptation of a similar example illustrating the limitations of 2-party protocols for proving lower bounds on nondeterministic state complexity from (Hromkovič et al. 2009): We use the alphabet $[n]= \{\,1,2,\ldots,n\,\}$. Let $L=\{\,xyz\in [n]^3 \mid x=y \vee x\neq z \,\}$. We first take care of $Cov(M)$. Observe that if $w=xyz$ with $y=z$, then $w \in L$: in case $x=y$, $w\in L$ and in case $x\neq y$, we also have $x\neq z$ and thus $w\in L$. Also, if $w$ is of the form $xyz$ with $y\neq z$, then $w\in L$ iff $x\neq z$. So we can write $L = L'\cup L''$, with $L'=\{xyz\in [n]^3 \mid y=z\}$ and $L''=\{\,xyz\in [n]^3 \mid y\neq z \wedge x \neq z \,\}$. Now consider the bipartite graphs $G' = (U',V',E')$ with $U'=[n]$, $V'= \{yz \in [n]^2 \mid y=z\}$, $E' = U' \times V'$, as well as $G'' = (U'',V'',E'')$ with $U''=[n]$, $V''= \{ yz \in [n]^2 \mid y\neq z\}$, $E'' = \{(x,yz) \mid x\neq z\}$, and $G = (U' \cup U'',V' \cup V'', E'\cup E'')$. Then a biclique edge cover for the graph $G$ gives rise to a covering of $M$ with $1$-monochromatic submatrices, and vice versa (Theorem 21 in Gruber & Holzer 2006). A simple kernelization trick for computing a biclique edge cover for $G'$ is to put the twin vertices from $U'$ into equivalence classes. Then we do the same in the resulting graph for the twin vertices from $V'$. Twin vertices are those with identical neighborhood. This step does not alter the minimum number of bicliques needed to cover all edges in the respective graph. The kernelization step collapses $G'$ into a graph with two vertices and a single edge. Thus, the edges of $G'$ can be covered with a single biclique. Applying the kernelization step to $G''$ yields a crown graph on $2n$ vertices, whose bipartite dimension (the minimum biclique edge cover number) is known to be $\sigma(n)$, where $\sigma$ is the inverse function of the middle binomial coefficient (De Caen et al. 1981). Notice that $\sigma(n)=O(\log n)$. Thus the bipartite dimension of $G$ is $1+\sigma(n)$, which is identical to $Cov(M)$. Now consider $Cov(N)$. Observe that if $w=xyz$ with $x=y$, then $w \in L$. If $x\neq y$, then $x\in L$ iff $x\neq z$. So we can write $L = L''' \cup L''''$ with $L'''=\{xyz\in [n]^3 \mid x=y\}$ and $L''''= \{xyz\in [n]^3 \mid x\neq y \wedge x\neq z\}$. Almost the same argument as above yields $Cov(N)=1+\sigma(n)$. It remains to give a lower bound on the nondeterministic state complexity of $L$. Observe that $L$ contains all words of the form $xxx$ with $x\in[n]$. For each such word $xxx$ fix an accepting computation of a minimal NFA accepting $L$. Let $p_x$ denote the state reached after reading the prefix $x$, and let $q_x$ denote the state reached after reading the prefix $xx$ of the input word $xxx$. Then all pairs $(p_x,q_x)$ must be different. For the sake of contradiction, assume $(p_x,q_x)=(p_y,q_y)$ for some $x\neq y$. Then we can construct an accepting computation on input $xyx$, such that the NFA is in state $p_x=q_x$ after reading the prefix $x$, and in state $q_y=q_x$ after reading the prefix $xy$. But the string $xyx$ is not in $L$. For the state set $Q$ of the NFA, this shows that $|Q|^2 \ge n$. Thus, for large $n$, we obtain a subexponential separation between $Cov(M)+Cov(N)$ and $|Q|$ (the nondeterministic state complexity of $L$). References 

Some important challenges that practically all distributed data structures face, are handling dynamic changes, implementing a scalable design, and being fault-tolerant. This includes finding answers to questions such as: 

You might want to look at the work of Gadi Taubenfeld. Many of his papers deal with impacts of different progress conditions such as (generalized) wait-freedom or obstruction-freedom on the computability power of shared objects in distributed systems, which includes registers. 

So for $f$ weakly Byzantine agents any number of good agents will do if the network size is known. Alternatively if it is not known, $\ge f+2$ good agents is a lower bound and they also show the matching upper bound. 

Finding a maximal independent set in a distributed network of $n$ nodes with maximum degree $\Delta$. There's a known lower bound [3] of $\min(\Omega(\log\Delta),\Omega(\sqrt{\log n}))$ that holds for randomized and deterministic algorithms. The following is a simple randomized distributed algorithm [1] that proceeds in synchronous rounds. (In a round, every node $u$ can perform some local computation and send messages to its neighbors. These messages are guaranteed to be received before the start of the next round.) 

In the strongly Byzantine case, they show that $f+1$ is a lower bound on the number of good agents required when the network size is known, which implies that this is true when the network size is unknown. These lower bounds aren't tight it seems as their best algorithms require $\ge 2f+1$ good agents in the case where the network size is known, or $\ge 4f+2$ good agents if the network size is unknown. 

The notion of "timing out processes" refers to the ability of knowing when to conclude that a process must have crashed. If you have a completely asynchronous system, then it does not help to equip processes with perfectly synchronized clocks, as these cannot be used to distinguish a slow process from one that has crashed. 

There are also locality issues since, in a distributed system, each node runs its own instance of a distributed algorithm and has only a local view of the network due to being directly connected to only a small number of other nodes. (Typically you would want a node degree of $O(\log n)$ to make the system scalable.) These issues come into play when maintaining global state such as counting the number of data items, finding the maximum, etc. 

In his monograph on graph theory, Reinhard Diestel traces the concept of treewidth and tree decompositions back to a 1976 paper by Halin (albeit not using these names). He also attributes to this paper the result that planar grid graphs have unbounded treewidth. Of course, he also mentions the later paper by Robertson and Seymour, who "rediscovered the concept, obviously unaware of Halin's work" (sorry if my translation is poor). 

Devdatt Dubhashi and Alessandro Panconesi: Concentration of Measure for the Analysis of Randomised Algorithms. A first draft is available at $URL$ (via geomblog) 

EDIT (2017/09/18): Concerning upper bounds, the PhD thesis of Christos Kapoutsis provides a valuable source (thanks goes to András Salamon for his valuable comment below). Section 2 of the PhD thesis mentions the following: 

Hisao Tamaki recently devised an exact algorithm for directed pathwidth (WG 2011). There he refers to some successful practical application of his approach (ISCIT 2010), so I guess he also has an implementation of the algorithm. Hisao Tamaki: A directed path-decomposition approach to exactly identifying attractors of boolean networks. International Symposium on Communications and Information Technologies (ISCIT 2010), pp. 844-849 Hisao Tamaki: A Polynomial Time Algorithm for Bounded Directed Pathwidth. In: 37th International Workshop on Graph-Theoretic Concepts in Computer Science (WG 2011), LNCS 6986, pp. 331-342. 

The following argument is essentially from (1): The decision versions of the two problems are contained in the second level of the polynomial hierarchy (more precisely: in the complexity class $\Sigma^P_2$), as follows. Guess a regular expression of size at most $k$, and check if it is equivalent to the given deterministic finite automaton (respectively: to the language given as a list of words). I believe that no further results regarding your problems are known. For a similar-looking optimization problem, where the objective is to find a minimum equivalent nondeterministic finite automaton instead of a regular expression, the following results are known: 

You can find the proof in Penttonen's original research article: Martti Penttonen, One-Sided and Two-Sided Context in Formal Grammars. Information and Control 25, pp. 371-392 (1974). $URL$ 

Is the graph coloring problem complete for poly-APX under C-reductions (alternatively, under AP-reductions)? For the graph coloring problem, speaking of a feasible solution means a proper coloring for all vertices of the given graph. The complexity class poly-APX contains all NP optimization problems that can be approximated within a factor that is polynomial in the size of the input. The notion of C-reducibility concerns approximation preserving reductions, which keep the performance ratio of the feasible solutions under consideration within a linear factor. For definitions regarding approximation preserving reducibilities, see P. Crescenzi: A short guide to approximation preserving reducibilites, CCC '97. EDIT (1.8.2014): Somewhat related, I've found in the paper "on syntactic versus computational views of approximability" by Khanna, Motwani, Sudan and Vazirani (SICOMP 28(1):164-191) a remark stating that GRAPH COLORING and MAX CLIQUE are both in poly-APX-PB and interreducible (Remark 6 in that paper). I understand this is meant with respect to E-reducibility defined in that paper. Later, in the sketch of proof of Theorem 6 in that paper, I understand that they imply that MAX CLIQUE is complete for poly-APX-PB under E-reductions. I would also be grateful for a proof that GRAPH COLORING is complete for poly-APX-PB w.r.t. E-reducibility. 

Edit: The answer below was written assuming that the ring is synchronous. Note that if node ids are chosen from some countable set and you don't care about time complexity, the $\Omega(n\log n)$ messages lower bound for electing a leader in a synchronous ring does not apply. In that case, there's an $O(n)$ messages algorithm that solves your problem: First, elect a leader using the $O(n)$ time-slicing algorithm of [1], and then, as mentioned in your comment, use the leader to orient the ring. Moreover, $\Omega(n)$ seems to be a trivial lower bound: If $o(n)$ messages are being sent, then there is a segment of $2$ neighboring nodes that do not send/receive any messages throughout the run. By an indistinguishability argument, you can show that there is a run where you get conflicting orientations. [1] Greg N. Frederickson, Nancy A. Lynch: Electing a leader in a synchronous ring. J. ACM 34(1): 98-115 (1987) 

Sure, if you can solve consensus, you immediately have an algorithm for leader election: Simply use the ID of each node as the input for the consensus algorithm. The opposite way only holds in models where it is guaranteed that the leader is eventually known to all. [1] Pierre Fraigniaud: Distributed computational complexities: are you volvo-addicted or nascar-obsessed? PODC 2010. $URL$ [2] Fabian Kuhn, Thomas Moscibroda, Roger Wattenhofer: Local Computation: Lower and Upper Bounds. CoRR abs/1011.5470 (2010) $URL$ [3] Tushar Deepak Chandra, Sam Toueg: Unreliable Failure Detectors for Reliable Distributed Systems. J. ACM 43(2): 225-267 (1996). $URL$ [4] Prasad Jayanti, Sam Toueg: Every problem has a weakest failure detector. PODC 2008: 75-84. $URL$ [5] Tushar Deepak Chandra, Vassos Hadzilacos, Sam Toueg: The Weakest Failure Detector for Solving Consensus. J. ACM 43(4): 685-722 (1996) $URL$ [6] Michel Raynal: Failure Detectors to Solve Asynchronous k-Set Agreement: a Glimpse of Recent Results. Bulletin of the EATCS 103: 74-95 (2011) $URL$ 

Leader Election in an Anonymous Ring of Processes Suppose that you have a ring network of processes that do not have ids and that communicate by message passing. Initially, every process is in the same state. You want to design a distributed algorithm such that eventually exactly $1$ process enters the elected state and all other processes enter the non-elected state. This is the so called leader election problem which is one of the fundamental symmetry breaking tasks in a distributed system and has many applications. There's a simple argument (e.g. [1]) that there is no deterministic leader election algorithm for an anonymous ring. Model: We assume that the computation advances in synchronous rounds where, in each round, every process performs some local computation, sends messages to its neighbors in the ring, and receives messages from its neighbors. For the sake of a contradiction, let's assume that there is such a deterministic leader election algorithm $A$. It is sufficient to show that, at the start of any round $r\ge 0$, all processes are in the same state, since this implies that there cannot be exactly $1$ process in the elected state. Since processes do not have ids and the network is symmetric, every process is in the same initial state, which provides the induction base. For the induction step, consider some round $r\ge 0$ and assume that every process is in the same state at the start of round $r$. Therefore, since algorithm $A$ is deterministic, every process performs exactly the same computation and sends exactly the same messages during round $r$. This in turn implies that every process receives exactly the same messages during $r$ and, by the start of round $r+1$, is in the same state. Thus, no such algorithm $A$ can exist. If $A$ is a randomized algorithm on the other hand and processes know the size of the ring $n$, there's an easy way to break symmetry, by generating a random id from the range $[1,n^4]$, which will result in unique ids for all processes with high probability. A simple and naive algorithm proceeds by letting every process send its id along the ring and instruct processes to forward only messages containing the largest id seen so far. This guarantees that only the process who generated the largest id will receive its own message once it has traversed the entire ring and elect itself as the leader. 

As another answer already states, the standard approach is: converting to a DFA, complementing, and converting back to a regular expression takes two exponential steps in the worst case (one for obtaining the equivalent DFA, and one for converting its complement to a regular expression). This is essentially optimal in the worst case: There are examples of regular expressions of length $n$ such that the shortest regular expression describing complement provably has length at least $2^{2^{c \cdot n}}$, where $c$ is some fixed constant; Such examples are known already for alphabets of size $2$. (Gelade & Neven 2008, and Gruber & Holzer 2008). 

The class of regular languages that can be described by regular expressions without union (and without complementation) are known as union-free regular (also: star-dot regular) languages. This class of languages apparently has received some attention recently: Benedek Nagy: "Union-free regular languages and 1-cycle-free-path-automata", Publicationes Mathematicae 68(1-2), 2006. Sergey Afonin and Denis Golomazov: "Minimal Union-Free Decompositions of Regular Languages", Language and Automata Theory and Applications, Springer 2009. Galina Jirásková and Tomás Masopust: "Complexity in Union-Free Regular Languages", Developments in Language Theory, Springer 2010. 

The following book covers some material related to the proof of the graph minor theorem (Chapter 12). Reinhard Diestel: Graph Theory, 4th edition, Graduate Texts in Mathematics 173. The author states: "[...] we have to be modest: of the actual proof of the minor theorem, this chapter will convey only a very rough impression. However, as with most truly fundamental results, the proof has sparked off the development of methods of quite independent interest and potential." An electronic version of the book can be viewed online. $URL$ 

If you want to go beyond context-free grammars for parsing programming languages, but still parse in polynomial time, you can resort to parsing expression grammars, or boolean grammars - the latter are also available in LL and LR flavors (see here). In formal language theory, also the powerful yet linear-time recognizable Church-Rosser languages are studied, but I am not aware of any implemented parser generators for these. In natural language processing, tastes are different, for instance, dealing with ambiguity (also: inherent ambiguity) and free word order plays a very prominent role. Here the keywords mildly context sensitive languages and restart automata might help you to start reading. 

There is a new preprint by Stephan Kreutzer and Ken-ichi Kawarabayashi, in which they apparently show that the statement (5.1) is true for all digraphs. Stephan Kreutzer and Ken-ichi Kawarabayashi: The directed grid theorem. arXiv:1411.5681 [cs.DM] EDIT (June 16, 2015): A short version of their paper appears here: Ken-ichi Kawarabayashi, Stephan Kreutzer. The Directed Grid Theorem. In: Rocco A. Servedio, Ronitt Rubinfeld (eds.), Proceedings of the Forty-Seventh Annual ACM on Symposium on Theory of Computing 2015. pp. 655-664 

Applying Koenig's Infinity Lemma It's not always straightforward to see whether a specific property is a safety property: Consider the implementation of read/write atomic objects on top of basic shared memory variables. Such an implementation should handle requests and their responses in a way that makes them look as if they happen at some instant in time and don't violate their order of invocation. (Due to the asynchronous operation, the actual duration between request and response might be nonzero.) Atomicity is also known as Linearizability. Section 13.1 of [A] gives a proof that Atomicity is a safety property. The proof uses Koenig's lemma to show that the limit of any infinite sequence of executions (each of which satisfies Atomicity) also satisfies Atomicity. [A] N. Lynch. Distributed Algorithms. Morgan Kaufmann, 1996. 

Suppose that you've implemented a shared memory machine $M$ that only satisfies eventual linearization, defined as follows: in every run $\alpha$ of $M$, there exists some point in time $T_\alpha$, such that linearization holds from time $T_\alpha$ on. Note that there is no upper bound on $T$. (*) (This is an artificial liveness counterpart of the standard safety property definition of linearizability.) Such a shared memory implementation wouldn't be very useful to the programmer: Note that if only eventual linearizability holds, there are no guarantees whatsoever on the consistency of read/write operations in any "early" prefix of a run (before the unknown time $T$). Or, in other words, whatever has happened until now, you can still extend the current prefix of a run to one that satisfies eventual linearizability. (*) If there was such an upper bound, then eventual linearizability would become a safety property. 

I'm unaware of such a published list of problems. Keep in mind that there are many different (and somewhat incomparable) models in distributed computing, ranging from the "benign" synchronous (fault-free) model where nodes execute in lock-step rounds and all messages are delivered reliably in each round, to the asynchronous model where there are no bounds on processing speeds and message delays and nodes themselves might crash or send corrupted messages. To further add to this variety, there are other requirements and assumptions that are orthogonal to synchrony and faults: the initial knowledge of nodes (network size, diameter of the network, maximum node degree, etc.), the ability to query a failure detectors, whether nodes have unique identifiers, atomicity of send & receive steps, the maximum size of a single message, and many more. The actual model at hand often implies a very different nature of question. (See [1] for more elaboration on these $2$ sub-communities in distributed computing.) In models that are close to the fault-free synchronous model, researchers often look at the complexity of local computation, for example, "What is the time and message complexity for computing a vertex coloring?" When looking at failures on the other hand, the questions are more related to solvability issues like "Is consensus solvable in this model?" or "Can we implement this fancy failure detector under these assumptions?"