My understanding is that PPTP does do encryption (contrary to other answer), but it's not good. It's also poor at routes. Ref. I also believe it's the only thing which still shamefully uses classful addressing. For the addressing scheme, we have something basically like this: Site N has a router RN with NAT 

If you are using a separate IP network (ie, with disjoint addresses), then something must have an address, and a connection, on both sides. 

As said in comments, with professional routers it is pretty easy. It sounds like you want to keep much of the flexibility and simplicity of two links, so here are some thoughts if you're setting out along that road. The following is imagining you have two small SOHO-type routers, for illustration Cisco 860-series or similar. Consider two routers each with two ethernet interfaces and two ethernet switches: 

I am certainly no expert here but my searching found ... There is a U.S. military protocol called TACFIRE protocol, which appears to be a fixed format textual representation of battlefield events. It appears to be named after the TACFIRE military computer (wikipedia) Could that be what you're looking for? A report on converting this to/from other formats is available from the George W. Jr, 1995, "Automated Translation of Bit-Oriented Messages (BOMs) into Data Kernel Representations (DKRs)", U.S. Army Research Laboratory, 1995. Available online at $URL$ There is also good description of it (including some transport level description) here Jacques,R G, 1984, "Real-Time Message Process Simulation Capability.", $URL$ The U.S. Defense Technical Information Center has many documents about it, and the documents show fascinating early uses and motivation behind TCP/IP. Search here $URL$ Quick reading of those documents show they call "TACFIRE protocol" pretty much anything from L1 to L7 which is used on the TACIFRE computer. Any use? 

There is no practical difference whatsoever. It is just that IEEE no longer calls them by the old name (MAC-48), it now calls them by the new name (EUI-48). The reason for this is that they are now used for more things than just media access addressing. In the up-to-date terminology, we'd say that the device has a burned-in EUI-48 which you have changed in software. The point of the change is that the device doesn't need to be a network card doing media access, and we'd like terminology which doesn't presume it is. 

It's very easy to think that internet packets go on the wire in a very simple "serial port" kind of way. In practice there is nothing inherently serial about it. If you think about some interface details it might make this clearer: 

Depending on the sophistication of your network, you may find the abundance of private addresses allows you great simplicity in your numbering. Simplicity will pay back time and again. 

Use switch ports, with lots of VLANs [EDIT: corrected this to a config which is correct, from an 867VAE with 15.2] 

It was a standards battle, like all the others, with a complex play of technological, economic and social effects. You might usefully read Metcalfe's views about what economists usually call "network effect" or "Metcalfe's law". 

Certainly lua has globals which are accessible from different dissectors of a different packet. Following is a trivial dissector based on that in $URL$ with the addition of a variable counter, which is local to the file and global to the dissector: 

I am struggling to configure some Cisco routers with NAT out of multiple outside interfaces. The interfaces are considered as alternatives: use the first one that works. Question: what's the configuration for "NAT with the outside interface that you're routing out of" ? The equipment is a WAN of telemetry networks, each consisting of a Cisco 867VAE with a number of telemetry devices underneath. These per-site routers are connected to the internet on a variety of ADSL, Fibre+ONT, ethernet methods. I am configuring them for a "backup route" mechanisms, so that if the main link goes down, they can be connected temporarily to some network supporting DHCP. Then they reconnect and central staff, not on site, can figure out what to do. A critical part of the problem is that the site-visiting person doesn't know how (and isn't permitted) to change the Cisco config. If it's plugged in and working, we want all traffic to go through isp1. If for some reason that's down, and isp2 is working and up, then use that. There is no load sharing, balancing or anything like that. In the following image, any packet leaving dialer1 should have dialer1's PPP-assigned address; any packet leaving vlan1000 should have vlan1000's DHCP-assigned address. 

If it was me, I think I'd avoid the VLANs except on the core switches, and run two cables per edge switch. Edge switches are just access then, and maybe the simplicity would help. 

NAT requires considerable complexity and remembers a great deal in order to remember which connection is supposed to go where; NAT for ping is especially complex in maintaining the table of mappings. NAT might be very common on domestic routers and inside 4g networks and so on, but you've really got to get the base case super clear before understanding NAT. Hope that helps, Jonathan. 

On the other hand, in UDP the upper protocols have to handle the error cases, but with the freedom of connectionless communication. For some protocols, this gives great simplicity. The statement that UDP is unreliable is not to be taken at face value. 

As well as the IP addressing, covered already by other answer, you have to consider the level 2 behaviour. What makes a packet broadcast is really whether it is sent to "all hosts within range". I'm speaking about the mechanism by which the signal actually arrives on the hosts. In the case of a broadcast medium such as radio, coax, or hub, it just goes to all hosts by the property of the medium. But in the typical deployment of twisted-pair ethernet, the intervening switches need to see the destination broadcast address ff:ff:ff:ff:ff:ff to forward to all ports. (Same would be true of most bridges.) Additionally, once the frame arrives on the target nodes, most interfaces do ethernet address filtering themselves. So unless the incoming frame is for this interface or the broadcast, it won't be sent off the interface to the CPU for processing by the IP layer, which decides if this packet is for this host. It's up to the detail of the OS and its configuration to know whether such directed broadcast IP addresses are actually broadcast at L2. (Ie, at the stage of deciding whether to look in ARP cache for the ether address.) As far as I am aware, all modern OS will correctly L2-broadcast the L3-directed broadcast address. But I've certainly seen older ones which do not. And clearly, if the packet arrives via a router, it's the router which decides whether to broadcast it, or more usually, throw it away. 

100baseT is usually actually "100base-TX" and works the same, but more complexity applies to less-common variants and to 1000baseT. Obviously the same is the case for switch-to-switch connections, except that before auto-crossover was common, there was usually an "uplink" socket, which was MDI, for plugging into the upstream switch. 

Because you had some hosts with addresses 9.9.192.X, some with 9.9.193.X and some with 9.9.194.X, for them to be in the same local network, you must use a network mask of /22 or below. (Many find multiples-of-four netmasks easier to deal with, and so /20 isn't that uncommon on private networks. Your predecessor apparently was in this group.) For 20 hosts, this is all pretty strange. 

If the ethernet payload is short, it's padded. There's nothing special about IGMP, here's a UDP packet with a 1-byte payload 'x'. You see the IP packet is length 43: this would be transmitted in a minimum-sized ether frame. Note 60 bytes on wire IP packet of 29 bytes + 14 = 43 The UDP payload is 0x78 at 0x002a, what follows is the padding. Trimmed output of . Tshark shows the padding as "trailer", garbage after the IP packet that was sent in this ethernet frame. 

If you want to tunnel layer 2, the first one that comes to mind is the Layer 2 Tunnelling Protocol per RFC 2661 which isn't trivial as it's built on top of PPP. However lots of equipment already supports it. A simple one which comes to mind is EtherIP, which tunnels ethernet frames in IP packets in a very straightforward way, per RFC 3378. I don't think it's widely used, but I believe Cisco wireless LAN controllers use it to implement mobility groups. EDIT: You say you're adding some information at magic box, transporting it, unwrapping it and delivering it. Although of course tunnels are a possible way, if the added information is small, you could use standard IP options, perhaps using an experimental option code per RFC 4227. As noted in other answers: watch for MTU, and are you sure you're in the right forum? 

Latency is really just distance: the time it takes for the beginning of a bit to leave here and arrive there. (As perfectly explained in the other answer) this is entirely unrelated to speed: it takes approx 240 ms for the signal to start arriving on a satellite link, whether it's going at 1 bit/second or 1 Mbit/second. The beginning of the message takes 1 lag period to arrive. The end of the first bit takes 1 lag + 1 bit time. If you're waiting for an answer, it usually takes 1 lag + N bit times out, 1 processing time P and 1 lag + M bit times for the answer (N and M being message and answer bit lengths) = 2 * lag + (N + M) bit times + P. Note that lag is often much bigger than packet time, and often dominates the transaction. I usually use the example of a small horse. It goes approx 20 metres/sec and it's approx 2 metres long. Racing over a 1 km, it takes 1000/20 = 50 sec for the nose to arrive, and the tail arrives 2/20 = 0.1 sec afterwards. If you change the distance of the race, the tail still arrives 0.1 sec after the nose. The analogy breaks down very slightly because the speed of propagation and bit time are basically unrelated in electrical and optical signals. The propagation is extremely fast and pretty uniform (ranging from approx 0.6 c to nearly 1 c) and so latency only depends on distance. Whereas the bit rate varies enormously (as it costs money to engineer speed and reliability). Non-specialised speeds in common commercial use are as low as 9600 bit/sec and as high as 10 Gbit/sec. Note that measuring propagation delay can be tricky, and often we measure from the beginning of transmission to the end of reception, ie the delay from issuing the order to transmit to the beginning of the intended action. A proper understanding of the importance of lag tells you why