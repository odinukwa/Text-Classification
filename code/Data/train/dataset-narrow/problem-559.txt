Identify threads that are not unkillable (e.g. a thread that is rolling back a transaction is unkillable). Find the thread with the lowest deadlock priority. Chose the one that is cheapest to roll back, i.e. the one that has done the least work so far. 

The original log file might be truncated so the space can be reused, but it's size might stay the same. 

Both statements would be evaluated to , thereby we have found out the individual values. Note: In the real world, we would iterate through all values from 1, 2, 4, 8, 16 and so on to the maximum value of an integer (or whatever datatype the parameter was set to). 

Because when you're creating a full backup you're creating a backup of the data (as it is physically and as it is materialized from the log). Restoring it somewhere else restores it as data, not log. 

and after that the call from the web server also completed in time just fine. I would suspect that the same plan should be used since I was using the exact same parameters from both connections, but I'm not sure. My question is: Can there be different plans or buffers for different connections? Or could it have been some other side effect caused by me running the above dbcc-commands? 

I would like to know more about the data-driven subscriptions on our ReportServer. I am specifically looking for what shared data sources are being used, but the connection string would also suffice. I have poked around the and tables, but nothing seems to give me the information I need. Any ideas? 

Here's a bit of a challenge. I am working with the table and there is a column called . I may not be using the proper terminology here, but this is an integer from which one can derive the days of the week an SSRS subscription is set up to run. Each day is assigned a number as follows: 

I have an SSRS report that can I access from the Web Portal but once I try to access it directly through the URL, I get the following error: . I looked at the logs on the Report Server and the error there says . But, of course, it is in the database - I can access the report from the Web Portal. Any ideas? UPDATE The same link now works, two days later. 

I want to know if it is possible to create a group "internal" to SSRS without having to add the group to the ReportServer box itself. I do not have permissions to the box to create groups and/or add users to existing groups. I know that this is a way (the only way?) to have groups that can be assigned permissions in the SSRS interface. I do have all the permissions I need within the SSRS interface. I have the System Administrator System Role on the ReportServer instance, as well as full sysadmin rights to the ReportServer database. I am trying to simplify our security structure and it would be peachy if I could create a group, assign users to that group, and then permissions to the group. But all I seem to be able to do is assign permissions to the groups set up on the box. Any ideas? EDIT: Active Directory groups are not an option for me. :( 

The others are combinations of the documented flags, e.g. 24 is 16 and 8. This is a method for simulating optional parameters and is used in e.g. C iirc, the numbers and so on are structured like that because they correspond to binary values that combined in any unique way create a unique number. The function that accepts them then use bitmasking to extract each individual number. E.g. if you send the value 6 to a function, then we know that this is a combination of 4 and 2, to find this out using a bit mask we would do: 

In SQL Server there is a separate thread that periodically (default 5 seconds, lower interval if a deadlock has just been detected) checks a list of waits for any cycles. I.e. it identifies the resource a thread is waiting for, then it finds the owner of that resource and recursively finds which resource that thread is in turn waiting for, thereby identifying threads that are waiting for each others resources. If a deadlock is found then a victim is chosen to be killed using this algorithm: 

I'm using Red Gate SQL Compare to create a release script based on differences between SVN and a database. This results in a script containing a bunch of table- and procedure-changes and it works fine. However, one thing puzzles me, it's using transaction isolation level serializable. I know what it does to dml-statements, but I'm not sure what it means for ddl. Can someone enlighten me, perhaps with an example? 

Is it possible to set up an alert in SQL Server 2008 that will send an e-mail anytime a job in a specific category fails? I am wondering because I would like to set up an e-mail anytime an SSRS subscription fails - and all of these subscriptions are jobs in the category Report Server. EDIT - it turns out that when an SSRS subscription fails, the job itself does not fail, so my question will not apply to the SSRS subscription monitoring use. However I would still like to know for other jobs that we run in our environment 

Try using a bind variable. You can declare it as a number and that should prevent a damaging SQL injection. ADDITION: bind variables also increase performance and scalability because the query plan is compiled and stored for re-use. Just something else to add to your argument. :) 

Our SQL Sever 2008 application database is replicated from Server A to Server B (push replication). We use the copy, let's call it database_b, on Server B to create reports and run other queries so that our reports do not interfere with the application. Currently we leverage inefficient views to combine data across multiple tables in database_b so that report writing is simplified for our report writers (who have basic SQL skills). 99.9% of the database activity is INSERTS, so we are exploring a way to replace the inefficient views with tables we can optimize. Here is a simplified example: There is an table and a (lookup) table. Every time a new appointment is scheduled, a row is added to the table. Every time this INSERT happens, I want to take that and insert it and its corresponding location name (join on from both tables) into a reporting table. I have accomplished this with a trigger on the appointment table in database_b on Server B. My question is - are there any particular considerations given that database_b is a replicated copy? Do I need to worry about a failing trigger mucking up the entire (push) replication process? Anything else I am missing? Unfortunately it's difficult to test this in our development environment, so I don't have the opportunity for a lot of trial and error. 

Below a complete solution for sql-server. I was trying analytical functions, but didn't succeed. I'm tempted to repost the question to SO requiring a solution using analytical functions. I think there must be one. And here is my working solution. I'm proud not to have used cursors. 

We just had a similar problem and noted that we could use UNC-pathes to specify the source of a restore. The restore is done by some account with rather restricted permissions and therefore it does not see the drive mappings you see. To make it work in domain context, allowing read access to the backup file to the computer. In other cases, when the machines aren't in the same domain giving read permission to the file to everyone might be the last resort. Edit: Good to know that there is a build in option to add backup devices. For DBAs it might be the preferred way, developers in restricted environments have sometimes to try other options depending on the rights they where given. For the German version of SSMS. You find the tool mentioned by mKorbel at 

Background to this question: I did the transformation of the Select-statement to CTE on SQL-Server an I wanted to add row-numbers to the result. I simply forget that add an alias to the * 

(I fear what I wish to accomplish shall not be easy, but a lot of my googling around about it yielded rather dated results, so here it goes...) I have a Postgres 8.4.x database with over 100 tables. I need to recreate these tables in SQL Server 2008. I'm not concerned about the data, just the structure. Are there any slick tools, shortcuts or suggestions to accomplish this? Heck, I'll even take the find-and-replace values to run on Postgres CREATE TABLE scripts! Thanks! 

We use partition switches to quickly load data, switching entire tables. We load an empty Table A with INSERTs and then switch it with empty Table B. These tables have identical indexes. What I don't understand why Table A's index as no fragmentation but Table B's index has fragmentation (16% in one example). I assume because both tables had to have the same indexing, the indexes also got switched, but clearly that's not the case. I am looking for an explanation as to how this works and why this happens. 

It is a bit kludgey, but here's an idea sketch... instead of merging the cells, could you fake it by placing an A in the left cell aligned to the right and a D in the right cell aligned to the left? You could then use expressions to control value, alignment, color, and borders of the two separate cells. Let me know if you need more details. I think this would give you the visual you want. Good luck! 

The gender in the records seems often be derived from First Name. I have seen increased variance in gender for foreigners, when we can't derive the gender from the name. In Germany we have some further variances with names containing the 'Umlaute' like 'äöü', which are sometimes replaces by 'ae oe ue'. 

I'm just testing my PowerShellScript to do bulkcopy of multiple tables between sql-server and oracle Databases. When the destination is Oracle, than I can monitor the progress by by executing select count(*) from Mytable the single batchsize chunkss individual committed. Using a sql-server destination, there seems to be a single transaction. Which was rolledback due to network error at first trial. The second is still in progress. Will the use of internal transaction commit the individual chunks? The use of bulkcopy seems a bit of an all or nothing, if it fails you can restart from the beginning. 

I think it is equally important to look at the explicit added denormalisations, either added aggregate values or some fields from a master table copied to a detail copy. The argument mostly being some performance argument. If you do so enforce, that those fields are updated by triggers and it's up to the database to keep them consistent. 

We found a solution for this that ended up being super-fast: using a wizard in our ETL tool Pentaho Data Integration (Kettle). Open a new job then Tools -> Wizard -> Copy Tables. I wouldn't be surprised if other ETL tools had similar wizards. 

I have a number of Oracle stored procedures whose activity I want to be able to audit, so I am having them INSERT some data into an auditing table. It would be swell if I could list the variables and their values as well. Is it possible to get this list in an automated way? I am already using to get my procedure name. 

I would like to know if it is possible to add a custom delivery extension(?) in SSRS that will enable me to force a value into the "TO" address for particular subscriptions? Big picture: I am exploring ways to schedule reports that would only permit them to be sent to a specific email address. EDIT: Somewhat related, I would also like to know if I can create a second e-mail delivery extension without having do any programming. i.e. I would copy the extension details from RSReportServer.config for the "Report Server Email", give it a new name, and change a single configuration value. SECOND EDIT: In the hopes of getting some additional input and ideas, the big BIG picture is I want to create a method to create an SSRS subscription that would guarantee the recipient is a particular e-mail address. This method should be usable by all users, but even knowing how to let one user might be workable. Subscriptions to other e-mail addresses must still be permitted. 

Make sure to keep transactions as short as possible. E.g. don't show a login form after starting a transaction and wait for user input, instead gather all the info you need and then run the transaction. Use the lowest possible isolation level, e.g. don't set serializable when you just want to temporarily show some values to the user. Please note that setting correct isolation level is a science in itself and out of scope in this answer. If you are the victim of a deadlock, i.e. you get error# 1205, then re-run your transaction transparently to your user. Since the other, competing, transaction has now hopefully acquired the resources it was waiting for and finished, it is unlikey that you will encounter the same deadlock again. 

Sometimes when inserting data in a table with many columns it could be useful to know which columns must be specified if the insert-statement shouldn't fail. I wrote this query to find out which columns are not nullable, identity, computed, timestamp and have no default value. 

The transaction owner/application developer is responsible for minimizing the risks of deadlocks occurring, and to do that they should: 

We had an issue in our dev environment where a procedure call timed out from the web server after 30 seconds. I traced the query and ran it manually (same params and all) from SSMS and it executed in about 2 seconds. I then ran 

I want to access data in an Oracle 11g database from SQL-Server 2008 I set up a linked server and when I execute 

I have a database with about 50 tables with use together about 1 GB space. The SQLite database will be readonly. This copying will be done once each month. EDIT: I see one possible solution using linked server via SQLite 3 ODBC Driver which results in rather simple t-sql scripts. I don't know about its performance. I guess that other solution require more work, but obtain better performance. 

Oracle it is in some sense some string type. Thats what ADO Reader tells me. here is a Powershell Script: 

From msdn I learn, that the Variable Precedence of :Setvar X Y is higher, than that of sqlcmd -v X=Y. I want to write a script, that uses the variables supplied to sqlcmd with the -v option, but which uses some default values, when run in Management Studio using SQLcmd mode. Best there would be some way to supply the values to use somehow to the Management Studio without having to provide them in the script. 

Inspired by Erics answer, I found the following solution which only depends on the table names and doesn't use any specific column name :