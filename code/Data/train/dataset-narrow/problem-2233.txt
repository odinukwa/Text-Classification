By the Ky Fan minimax theorem, if you can identify the strategy spaces of the two players with convex compact subsets of a locally convex topological vector space, and the payoff function $M(x, y)$ is convex and continuous in $y$ for any $x$, and also concave and continuous in $x$ for any $y$, then the minimax theorem holds. 

To get the obvious out of the way first, to show that the $n\times n$ matrix $M$ is PSD, it is enough to show that it is the Gram matrix of $n$ vectors, i.e. $m_{ij} = \langle u_i, u_j\rangle$ where $u_1, \ldots, u_n \in \mathbb{R}^n$. (This is a "sum of squares" proof of positive semi-definiteness, because it shows that the bi-linear form $x^T M x$ can be written as a sum of squares of linear functions of $x$. I am wondering if you meant something more sophisticated by "sum of squares".) You get a useful class of PSD matrices from positive definite functions. A function $f: \mathbb{R}^d \to \mathbb{R}$ is positive definite if for all sequences $u_1, \ldots, u_n \in \mathbb{R}^d$, the $n\times n$ matrix $M$ defined by $m_{ij} = f(u_i - u_j)$ is PSD. It is not very hard to see that if $f$ is the Fourier transform of a finite measure, then $f$ is positive definite. I.e. it is sufficient that there is a finite Borel measure $\mu$ on $\mathbb{R}^d$ such that for all $x$ $$ f(x) = \int{e^{i\langle x, y\rangle} d\mu(y)}. $$ A classical theorem of Bochner shows that this condition is necessary as well. A special class of positive definite functions are the functions $f(x) = g(\|x\|_2)$, for which the matrix $M$ becomes $m_{ij} = g(\|u_i - u_j\|_2)$. Another classical result of Schoenberg shows that such an $f$ is positive definite if and only if there exists a finite Borel measure $\mu$ on $[0, \infty)$ so that for every $t \geq 0$ $$ g(t) = \int_{0}^\infty{e^{-t^2s}d\mu(s)}. $$ The original motivation for Schoenberg's theorem was to determine what functions $g$ have the property that for any $u_1, \ldots, u_n \in \mathbb{R}^d$, the metric space with metric $d(u_i, u_j) = g(\|u_i - u_j\|_2)$ embeds isometrically into Euclidean space. This blog post has a simple proof of Schoenberg's theorem and many links. 

This is more of a 'meta' question as I cannot give a precise formulation of my question. Consider for example the category of total quasi-orders: we can then distinguish between a 'strict' order (where no two elements are equivalent) and a 'weak order' (where some elements may belong to the same equivalence class). It doesn't possible to define an intermediate notion of 'mild order' in this setting, so do you have any suggestions for other structures allowing a natural notion of 'mildness' which is well-behaved? I'd like to add a self-evident comment: in science the qualificative of 'mild' can be applied to certain notions, e.g. 'mild necessity', 'mild difficulty' or 'mild formalism' which describes well the questions that I'm asking. OTOH I guess we can't speak of a 'mildly correct' statement without resorting to statistics? 

is it possible to define a corresponding notion of tree-width that is well-behaved? E.g. we would expect forest posets to have tw at most 1, and series-parallel posets to have tw at most 2. is it possible to get a width measure that is algorithmically useful? A possible application would be the counting of linear extensions: it is feasible in $n^{O(w)}$ for a poset of width $w$, but the extension to path-width / tree-width seems unlikely at this point. 

As far as I know, the parameterized complexity of the counting problem is still open. It is known that ILP solving is fixed-parameter tractable in the number of variables ('Integer programming with a fixed number of variables', H.W.Lenstra Jr), although ILP solution counting is expected to be $\# W[1]$-hard. The question was first asked by N. Betzler if my memory is correct. 

It is an open problem to lower bound the difference between two distinct Euclidean TSP tours by an inverse polynomial in the input size. Such a lower bound would show that Euclidean TSP is an NP optimizaition problem, which is not known. Let us assume that a Euclidean TSP instance is given by a collection of points in $(\mathbb{Z} \cap [-N, N])^2$ (i.e. points with integer coordinates bounded in absolute value by $N$). It is not known how to decide the following problem in polynomial time: given two tours $T_1$, $T_2$ over the same set of points, is the cost $c(T_1)$ of $T_1$ less than the cost $c(T_2)$ of $T_2$. To solve this problem it is sufficient to upper bound $-\log |c(T_1) - c(T_2)|$ by a polynomial in n and $\log N$, which is equivalent to your question. The even more basic problem of deciding if $\sum_{i = 1}^n{\sqrt{a_i}} < \sum_{i = 1}^n{\sqrt{b_i}}$, for $a_i, b_i \in \mathbb{Z} \cap [1, N]$ (i.e. positive integers bounded by $N$) in time polynomial in $n$ and $\log N$ is also open, see $URL$ If all distances between points are rational, i.e. $\|v_i - v_j\| = a_{i,j}/b_{i,j}$ for integers $a_{ij}$, $b_{i,j}$, then $$ |c(T_1) - c(T_2)| >= \frac{1}{\text{LCM}(\{b_{i,j}\}_{i, j \in [n]})}, $$ where LCM is the least common multiple function. 

A typical problem is MaxCut: output a cut in a graph that (approximately) maximizes the number of edges cut. Goemans and Williamson showed an SDP approximates the value of MaxCut to within a factor at least 0.878. Recently, Chan, Lee, Raghavendra, and Steurer showed that for a natural linear encoding of the MaxCut problem, all polynomial size LPs achieve approximation no better than 0.5. It's hard to say concisely what kind of problems usually benefit from an SDP. A systematic approach to constructing SDP relaxations is through hierarchies, the most powerful of which is the Lasserre hierarchy: see Rothvoß's survey for a nice introduction. By now there are too many examples of successes of SDPs in optimization to list. Also, Raghavendra showed that one particular SDP gives the best approximation to all MaxCSP problems, if the Unique Games conjecture is true. Check the books of Gaertner and Matousek, chapters 6 and 13 of Willimson and Shmoys' book, Lovasz's survey. 

Background I was looking for a formulation of 'free sets' and 'independent sets' from linear algebra that would extend to groups. This question was considered here but I couldn't find a satisfactory definition in the literature so I'd like to suggest the following simple approach. Let $G$ be a finite group, and for each $x \in G$ let $o(x)$ denote its order, i.e. the smallest positive integer $p$ such that $x^p = 1_G$. Core definitions Let $X = \{x_1,\ldots,x_k\}$ be a $k$-subset of $G$ and let $A_k = \{a_1,\ldots,a_k\}$ be the $k$-letter alphabet. Let $\Sigma_k$ denote the free monoid generated by $A_k$, and let $\Pi_k = \prod_{i \in [k]} \mathbb{Z}_{o(x_i)}$ viewed as an abelian group. Consider the homomorphism $\phi_k : \Sigma_k \rightarrow G$ that maps each $a_i$ to $x_i$, and consider the homomorphism $\psi_k : \Sigma_k \rightarrow \Pi_k$ defined by $(\psi_k(w))_i = |w|_{a_i}$. We can then give the following definitions: (1) $X$ is a 'generating set' of $G$ if $\phi_k$ is surjective; (2) $X$ is a 'free set' of $G$ if there exists an homomorphism $\eta_k : Im(\phi_k) \rightarrow \Pi_k$ such that $\psi_k = \eta_k \circ \phi_k$. We observe that some properties from linear algebra carry over to this setting. For instance, any superset of a generating set is also generating, and any subset of a free set is also free. We may then define a 'free generating set' of $G$ the obvious way. Note that such a set may not exist, but when $G$ does admit a fgs we may define $rank(G)$ as the cardinality of this set. Basic remarks Similar to linear algebra, it turns out that two fgs always have the same cardinality. Here is a proof sketch for a special case. Suppose for contradiction that $G$ had two fgs $X,Y$ with $k = |X| < |Y| = l$, and suppose for simplicity that each element of $X \cup Y$ has the same order $p$. Consider the surjective mapping $\phi_k : \Sigma_k \rightarrow G$ obtained from $X$, and the surjective mapping $\phi_l : \Sigma_l \rightarrow G$ obtained from $Y$. As $Y$ is free, we obtain an homomorphism $\eta_l$ by (2). Given an element $x_i \in X$, there is a word $w_i \in \Sigma_l$ such that $\phi_l(w_i) = y_i$. Define the $k \times l$-matrix $M$ by $M_{i,j} = \eta_l(x_i)[j] = |w_i|_{a_j} \mod p$. For every $z \in G$, we can then write $\eta_l(z)$ as a combination of the column vectors of $M$. It follows that the image of the $\eta_l$ must be included in the subspace spanned by $M$ and thus has size at most $p^k$; therefore $\eta_l$ cannot be surjective contradicting the assumption that $Y$ is free. Some examples follow. For a finite abelian group $G$, we know that it is isomorphic to a product $\mathbb{Z}_{n_1} \times \ldots \times \mathbb{Z}_{n_k}$ and then $rank(G) = k$. For the permutation group $S_n$, it can be seen that $rank(S_n) = n-1$ as the transpositions form a free generating set; indeed, for a permutation $\pi \in S_n$ we can define a tuple $\eta(\pi) = (s_1,\ldots,s_{n-1}) \in \mathbb{Z}_2^{n-1}$, where $s_i = 0$ if $\pi(i) < \pi(i+1)$ and $s_i = 1$ otherwise. More generally, if $G \subseteq S_n$ is a permutation group, I conjecture that a free generating set can be obtained by the Schreier-Sims algorithm. Questions 

This is the Min-Disagreements version of the correlation clustering problem (on complete graphs), defined by Bansal, Blum, and Chawla (full version). They give a (huge) constant factor approximation for the problem and prove it's NP-hard. Charikar, Guruswami, and Wirth show the problem is APX-hard, and improve the approximation factor to 4 via region growing. There is a beautiful and simple combinatorial algorithm (a variant of QuickSort), due to Ailon, Charikar, and Newman, that gives a factor 3 approximation. I believe the current best known approximation ratio is due to Chawla, Makarychev, Schramm, and Yaroslavtsev, and is around 2.06. 

You can find another view of the "bait and switch" argument in the natural proofs chapter of Arora-Barak. They use the same argument to argue that a "formal complexity measure" style lower bound argument must apply to random functions with high probability. But if a formal complexity measure 

The CountMin Sketch and Count Sketch, from data streaming algorithms, are used in industrial systems for network traffic analysis and analysis of very large unstructured data. These are data structure that summarize the frequency of a huge number of items in a tiny amount of space. Of course they do that approximately, and the guarantee is that, with high probability, the frequency of any item is approximated to within an an $\varepsilon$-fraction of the total "mass" of all items (the mass is the first or second moment of the frequency vector). This is good enough to find "trending" items, which is what you need in a lot of applications. Some examples of industrial uses of these data structures are: 

Are there linear-time recognition algorithms for these classes? By the previous remark, an algorithm for class 2 would immediately yield an algorithm for class 1, although I suspect a more direct algorithm to exist in that case. What is the complexity of the subpattern problem for two skew-merged or two vexillary permutations? The subpattern problem is known to be polynomial for separable and 2-increasing permutations, and these classes seem the next to study. 

An OH relation is then a conjunction of OH clauses. The authors state in Theorem 5 of the paper that the satisfiability of an OH relation can be decided in polynomial time, but the algorithm doesn't seem 'self-contained' as it relies on a generic algorithm for propositional Horn theories. In relation to a problem I'm currently studying, such a self-contained algorithm seems desirable but it's unclear to me whether it is possible. To tell the truth, I have an algorithm for a subclass called Restricted Ordered Horn (containing the relations expressible using clauses without $\neq$ in the rhs) but unfortunately it can't be adapted to the full $OH$ class. 

Consider the following problem. We're given a circuit $C$ with $n$ binary inputs and $n$ binary outputs, computing some boolean function $f_C : \mathbb{Z}_2^n \rightarrow \mathbb{Z}_2^n$. We assume for simplicity that $C$ only contains binary AND/OR gates, except for the output gates that can be OR gates of unbounded fan-in. We want to ensure that $C$ is 'disruption-resistant' in the sense that modifying a small number of gates does not change the output. Formally, fix an integer $k$ and a circuit $C$. Call a '$k$-disruption' of $C$ a circuit $C'$ obtained from $C$ by modifying $k$ gates, except for output gates. Say that $C$ is '$k$-resistant' if, for any $k$-disruption $C'$ of $C$, it holds that $f_{C'} = f_C$, i.e. the two circuits compute the same function. Consider the function $\chi_k : \mathbb{Z}_2^k \rightarrow \mathbb{Z}_2^k$ such that $\chi_k(x) = y$ with $y_j = 1 \Leftrightarrow \sum_{i = 1}^{k} x_i \geq j$. Given two tuples $u,v \in \mathbb{Z}_2^k$, say that $v$ is an $l$-perturbation of $u$ if $d_H(u,v) \leq l$. Consider the following question: given $l < k$, can we find a circuit $X_{k,l}$ such that for each $k$-disruption $C$ of $X_{k,l}$, for each $u \in \mathbb{Z}_2^k$, there is an $l$-perturbation $v$ of $u$ such that $f_C(u) = \chi_k(v)$? That is to say, $C$ would count the one-entries of $u$ up to some additive error $l$. Suppose that we can find such a circuit $X_{4k,k}$ for any integer $k$. We can then solve the first problem using replication as follows. Take $4k$ copies $C_1,\ldots,C_{4k}$ of the given circuit $C$, and let gate $g_{i,j}$ be the $j$th output gate of $C_i$. For each $j \in [n]$, insert a copy of the circuit $X_{4k,k}$ with input connected to the gates $g_{1,j},\ldots,g_{4k,j}$, and with output gates labeled by $h_{1,j},\ldots,h_{4k,j}$. Finally, let the output gate for the $i$th bit be an OR of the outputs $h_{2k-1,i},\ldots,h_{4k,i}$. Let $\Gamma$ denote the resulting circuit. It is then easy to see that for any $k$-disruption $C'$ of $\Gamma$, there are at least $3k$ circuits $C_i$ that are not affected. Thus, if we consider a fixed input $x$, for each $i$th output bit the following holds: if the gates $g_{1,i},\ldots,g_{4k,i}$ evaluate to a constant tuple $t$ in $\Gamma$ and to a tuple $t'$ in $C'$, then $t'$ is a $k$-perturbation of $t$, and by definition of the circuit $X_{4k,k}$ it then computes a value $\chi_k(t'')$ with $t''$ a $2k$-perturbation of $t$. As this circuit has $4k$ outputs it follows that taking the OR of the last $2k+1$ values yields the desired result. It it thus desirable to construct a circuit $X_{k,l}$ fullfilling the above requirements. I'm working on it but I welcome ideas or advice you may have. 

If you have a graph with maximum degree $\Delta$, then the greedy algorithm finds a coloring with $\Delta+1$ colors, so for $k = \Delta+1$ the assumption that you are given a proper $k$-coloring does not change the complexity of the problem. It is known that independent set is NP-hard to approximate within factor $\Delta^{1 - o(1)}$, and Unique Games-hard to approximate within factor $\frac{\Delta}{O(\log^2\Delta)}$, which, for $k=\Delta$ is within a $\log \Delta$ factor from the upper bound you cite. (I prefer to write approximation factors as bigger than 1, so I am thinking of the upper bound you cite as $\frac{k}{2}$.) However, it's still interesting to close these logarithmic gaps. This paper by Bansal may contain useful ideas. 

Planar separators easily give an $n^{O(\sqrt{n})}$ algorithm. This can be improved to $2^{O(\sqrt{n})}$ which is optimal (up to the constant in the exponent) for general planar graphs assuming ETH. I am not sure if being cubic helps or not. 

For any language in $\mathsf{NP}$ there exists a proof that can be verified using $O(\log n)$ working space. One just needs to use the same ideas used to prove SAT is $\mathsf{NP}$-complete. By definition, given an $\mathsf{NP}$ language $L$, we know that there exists a turing machine $M$ such that for any $x \in L$ there exists a $y$ such that $M(x, y)$ accepts. We can construct a logspace verifiable proof for $x$ by writing down $y$ and the computation tableau of $M$ on input $x, y$. It is easy to verify in logspace that the tableau describes a valid accepting computation of $M$. Similarly, for any $x \not \in L$ and any $y$, no valid computation of $M(x, y)$ accepts, so the logspace verifier won't accept any tableau. Of course this does not show that $\mathsf{NP} = \mathsf{NL}$ (because that would imply $\mathsf{NP} = \mathsf{P}$). The reason is that the verifier has two-way access to the proof (can go back and forth). The proof-verifier definition of $\mathsf{NL}$ gives the the logspace verifier only one-way access to the proof (once a bit of the proof is read and the head moves right it cannot move left). 

I'm interested in permutations classes defined by one or several excluded patterns of length 4. In particular, the following classes seem interesting but not so-well studied algorithmically. 

A partial semigroup (or PSG) consists of a set $X$ and of a partial composition law $*$ defined over $X$, that is to say: (1) $x*y$ is not always defined, (2) if $(x*y)*z$ is defined, so is $x*(y*z)$, and the two values are equal, (3) if $x*(y*z)$ is defined, so is $(x*y)*z$, and the two values are equal. Let $\mathbb{R}$ be a ring. We may then define a convolution product over $\mathbb{R}^X$ : given two functions $f,g$, we define a function $f*g$ such that 

Let $G$ be a complete graph edge-colored with $k$ colors. We say that $G$ is Gallai-colored if no triangle is colored with three distinct colors. Fix a tuple of integers $c = (c_1,\ldots,c_k)$. We may then define the polytope $\mathcal{P}(G) \subseteq \mathbf{R}^V$ by: 

Let $w_r$ be the random word assigned to the root at the end of this process. Can we devise a polynomial-time strategy to maximize $Var(w_r) = \sum_{i \in [n]} Var(w_r[i])$? This could be done either 'globally' (by constructing the tree at once) or 'online' (by selecting a 'locally optimal' matching for each generation). The intuition is that a node $u$ represents a 'genetic group' which profiles is described by the distribution of $w_u$, and that we would try to mix groups at each generation in order to maximize the genetic diversity. This is probably NOT desirable in practice due to the possible effects of dominant/recessive mutations. 

Most streaming algorithms In the streaming model of computation (AMS, book), an algorithm processes an online sequence of updates and is restricted to keep only sublinear space. At any point in time, the algorithm should be able to answer a query. For many problems there exist sublinear space randomized streaming algorithms while provably no deterministic algorithm can solve the problem in sublinear space. This is related to gaps between randomized and deterministic communication complexity. A simple example is the distinct count problem: at each time step $t$ the algorithm is given an integer $i_t \in [n]$, and it should be able to approximate $D_m = |\{i_t: t = 1\ldots m\}|$, i.e. the number of distinct integers seen up to time step $m$. It's relatively easy to show that any deterministic algorithm achieving constant approximation must use $\Omega(n)$ space (see e.g. lecture notes by Piotr Indyk). On the other hand the clever sampling algorithm of Flajolet and Martin (simple analysis with limited randomness in the AMS paper linked above) achieves constant approximation in $O(\log n)$ bits. The latest work on the problem gives an optimal $O(\frac{1}{\epsilon^2} + \log n)$ algorithm that computes an $1\pm \epsilon$ approximation. 

I didn't mean this to be an answer but it would require too many comments. Hope it's useful. As Tsuyoshi points out, it's tempting to conjecture that all "non-trivial" properties are hard (NP-hard for example). However, to show this, you need to define non-trivial. In Rice's theorem, the nontrivial properties are all properties except the property which includes all computably enumerable languages and the property which includes no computably enumerable language. It's less clear what the right definition of non-trivial is for succinct problems. Definitely the properties which contain all strings or no strings are in P. But there are others in P as well. For example, the property $\Pi$ that matches strings whose middle bit is 0. Or $\Pi$ contains all strings of $2^n$ bits such that every $2^n/x$-th bit is 1, where $x = n^{O(1)}$. So how do we define "trivial" to encompass this type of properties? One idea is to look at those $\Pi$ which are "symmetric": if a string $s$ is in $\Pi$, then any permutation of the bits of $s$ is also in $\Pi$. Such properties depend only on the number of 1 bits in a string. In an answer to the question Tsuyoshi linked, Ryan Williams gives a link to this paper which shows that all such problems are UP-hard. Other ideas how to define "non-trivial property"? We can look at $\Pi$ as a family of boolean functions (the indicator functions of the property for each string length). It seems to me that the non-trivial properties are those for which the corresponding family of boolean functions has non-trivial complexity. For example, can we show that properties whose associated boolean function family has linear decision tree complexity are hard? 

is it possible to adapt the above proof to handle distinct orders? if so, what part of linear algebra carries over to this setting? if we can compute the rank for permutation groups as suggested above, are there other, presumably infinite, groups for which this is doable efficiently? are there any algorithmic applications of this notion to problems involving graphs or permutations? 

I'm not sure this question is appropriate for this site, but it might have some connections with computational algebra. Consider a fixed "category" $\sf{Cat}$ (in the sense of category theory, but the precise notion is not important), e.g. groups or fields. Given an object $\mathbb{S}$ of $\sf{Cat}$, we say that a "composition series" for $\mathbb{S}$ is a chain of objects $C = (\mathbb{S}_{\alpha})_{\alpha}$ indexed by some ordinal $\lambda$, such that $\mathbb{S}_0$ is an initial object and for every $\alpha < \beta$, $\mathbb{S}_{\alpha}$ is a subobject of $\mathbb{S}_{\beta}$. We may then define the length of $C$ as the ordinal $\lambda$. We say that the structure $\mathbb{S}$ is isogenic if all maximal composition series have the same length. For instance, this is true for finite groups ordered by the normal subgroup relation (according to the Jordan-Hölder theorem). My question is: what are the structures known to have this property? 

That is to say, $\sigma_i$ combines the effect of a swap and a conjugation at positions $i$ and $i+1$. It might be possible to solve this problem optimally in polynomial time, which would answer to your question.