In addition to Rolando's general description I would recommend your script maintains and expected configuration definition to compare against the active process list. Rolando's steps only very connected slaves. A likely scenario a slave would fall so far behind many bin logs is replication broken or was administratively stopped and not in the masters process list at all. Treat an event of a missing slave as an error state in which no binary logs are purged from the master. This does add the additional admin overhead of needing to keep that config list in sync when adding/removing slaves but required for your script to work as desired. Further consider your retention policy. If you want to spin up a new slave you might do that by restoring a recent backup and restarting replication from when the backup was taken. For the scope of this discussion we'll assume you have daily backups and are certain the binlog position stored with the backups have been proven to be working correctly. If you have daily backups you'd probably want to keep at least 2 days of bin logs. Edit: After rereading your post it sounds like your question is more a long the lines of "how to write scripts". Python is certainly a viable option suited for the task. Whether it's perl, python, php or other you'll need to look up how to work with their MySQL API clients. More specific questions of how-to-code in these languages are probably better placed in stackoverflow.com after googling some basic intro's to the language to gain that literacy. 

Can someone explain why the data_free is magnitudes larger than the innodb version. Is data_free for tokudb expected to mean the same thing as it does for innodb? 

Look toward getting slaves setup at different physical datacenters across the country/world/what ever's applicable to your demographic. Load balance connections to the nearest one. (This assumes traffic is first routed to your front end in these locations otherwise the problem might just be worsened). 

I have a replication setup with 1 master and 3 slaves. I promoted the current master to one of the slaves using MHA. That went seemingly flawless, not errors reported, everything marked ok. Spot checking after the promotion the old master is now replicating and catching up from the new master. I check back later and replication is falling more and more behind, seemingly not making much progress. Thins like single row inserts are starting to fill up the slow query log taking as long as 8 - 10 seconds. Being this was the old master I figured if anything the new master would be slow to service activity not having the buffer pool primed. Checking the runtime server config differences using pt-config-diff between the two servers are things you would expect: log file names, server ids, host names, read only mode. The other two prexisting slaves switched over fine and are not showing such problems. Disk I/O on the problem slave is not pegged. The mysqld is showing a lot of activity CPU wise (200-300% in top). I'm at a loss for what could be causing this. Anything else to check? Anything to help it catch up? UPDATE Out of frustration, with out making any config changes I simply tried restarting the problematic slave. That seemed to solve the problem, it started making progress instead of continuing to fall behind. I guess my question still remains, what would cause that? 

The simplest option is to just back up everything in the filesystem and carry it over. To find out where your data is, look at the datadir variable with in mysql 

Prior to the grant statement. I don't recommend doing this because slaves are generally around in the event of an emergency fail over. The risk of recovery time problems because grants weren't consistently applied out weighs any risk of the password making it into the binlogs. Think about it, if some unsavory user gets to your binlogs, they have access to all the data that was streaming through at the time anyway. Just be sure the file system permissions aren't world readable and keep any actual system level accounts to actual sysadmins to true "need to have" basis. Try to limit system level accounts on your db servers to developers for example. If you find some reason your stack setup necessitates many people have system level accounts, eliminate or minimize those reasons as much as possible, have a dedicated host (could be a VM) that's only job is running mysqld and related tools. (Apps should be on their own segment) This goes for development and production servers. Sure devs will need access to the dev environment to dev, but you can get them individual mysql level user accounts that their apps can connect to (restricted to your local network segment; don't use % for the host). 

I've made sure the actual file is world readable (and writable even). I've tried both the stock SQLite command line client as well as the Firefox plugin suggested in the doc mentioned about. I'm pretty sure this file is a SQL lite database file 

I've read the docs saying log_slave_updates is required. It makes sense for a general promotion situation. But is that really still required for something you're intending to be a read only slave that will never get promoted? 

In order to do rate limiting the script will need to connect to each of the slaves to look at the slave status. Make sure you have the same username, password, grants for this user on the master and all slaves. Ensure you can connect to the slaves via mysql client on the master. If you can but the tool still cannot for some reason first run 

You don't want your logs in you data directory. This will show a "mysql-bin" database when you start mysql. You'll probably get some unneeded errors in the error log on startup. Best to keep that as clean as possible so you can pay attention when something does show up there. It's general convention to put logs in /var/log anyway. Further, when possible it's nice to have the logging file system on a separate set of spindles than the data directory. While it doesn't sound like that would be possible there could still be some gains in keeping the data directory and logging on different file systems, even if still on the same underlying disks. Be aware that expire_logs_days will purge binary logs regardless of weather slaves are up to date. Granted if you have a broken slave that's been off for more than 14 days you have larger problems. In general you'll want to keep enough binlog buffer around so that you can easily spin up a new slave based on your backup schedule. You might consider having an archiving script that offloads the binlogs to a more permanent archive server and manages the purging. 

Yup, you'll need to remove the log files to change their sizes. They're in where ever your DATADIR is. Just make sure you remove them when the server is shutdown. Then restart and you'll be fine (it will recreate them). DO NOT remove any ibdata files, though. That has your actual persistent data. 

You will probably want to modify the example further to account for specifying all the destination columns with either a literal value such we did for country, a transform like we did for is_estado, or just the basic column name in the select portion to copy values. You should specify some value for every destination column without a schema default defined. 

This isn't directly related to ORDER BY, but be careful using the LIMIT N,M pattern. This is often used for paginating results, e.g. 

The ultimate solution looks to be migrating to 5.5 which supports UTF-8 > 3 bytes Unfortunately this wouldn't be as simple as bouncing the instances under newer binaries. Being a major version dump we'd need to do a full dump reload which will require some scheduled downtime. Has anyone else had to deal this situation before? Are there any good work arounds? The naive approach seems to be have the app search and replace multi-byte sequences with question marks or ï¿½ . This seems pretty hacky and not a very palatable option to me or the developers. 

First, if your end query was being generated like that it seems to imply your taking straight user input and pasting it into a query template which itself is the problem for sql injection. Further, even if you were doing that the query template would need to be in quotes for legit requests of charish inputs to even be syntactically valid. What ever language your application is using, ruby or otherwise, look up how they do parameterized queries and prepared statements. The API will handle all the proper escaping for you. 

Let me restate what you're asking for to make sure I'm getting it right: You want to pull all records for the past 7 days a specified date? It could look like: 

Well much to my surprise the script I mentioned did find a good starting position and I was able to successfully recover a large portion of the binary log after the problem point. Not the most elegant script but in case it's of use to anyone else. Note it is very slow restarting a new process to scan byte by byte but got me results. And yes I recognize the potential of infinite looping by never finding anything, might want to add additional check based on start position vs filesize 

Mysql replication won't address performance issues on large tables. It just allows you to have another copy you might use for failover, backup or reporting in cases of heavy hitting queries. Your table schema is tiny. Even with 14 million rows you could fit that in ram on even modest hardware. All the same, if you want to look at sharding you could read up on mysql partitioning You say you expect 14 million rows; you're dangerously close to the max value for your medium PK there. Just go head and make that an int instead of worrying about the extra byte/entry. 

This will prevent the accidental creation of a nopassword user. You had mentioned keeping general_log off to prevent storing set password commands there. Another thing to keep in mind is if you have any kind of replication running that statement will get written to the binary logs to be pushed out to the slaves. Depending on what your needs are you could prevent the inital grant from getting written to the binlogs by running 

Big Percona fan here. I'm really excited about a lot of 5.6 features (although many seem to be things Percona already provided). At the same time there's no way i'm rolling out an alpha into production and no way I'm going back to stock and loosing thing I get from percona 5.5 Largely I suppose those "things" are related to information schema (which is just for my DBA satisfaction; not performance implications) as well as knowing I have a trusted xtrabackup situation going on w/ percona builds. I'm personally waiting for Percona's 5.6 GA before even deploying to QA for evaluation. As for the fulltext feature you're wanting I'm of the opinion search like that is not the role of a relational database and should be delegated to a lucene solution such as an in house elastic search install, or searchify for a cloud based solution if you don't have the resources to manage your own search service. My opinion on your implementation isn't really an answer though, so to get to that more directly: Do not deploy alphas to production. Alpha is the disclaimer saying "play around if you like but we're not sure we trust what we've built yet ourselves" 

You have an order by so running a basic commandline diff should quickly highlight differences. The pt-table-checksum tool is also handy for finding differences. 

(replica set and host names have been sanitized for public posting) To attempt the repair I shut down the mongod and started it up with 

What I'd like to be able to get the SQL statement by 'show create table' as something I could do something with along the lines of 

Snapshot are a common practice for backups. See $URL$ For this to work safely though you'll want to ensure innodb_flush_log_at_trx_commit is set to 1. That being said, the general practice with backups is test restoring them. You want to be sure your backup method is working functionally and you want to be sure you know the steps to restore them. If you're having to restore a backup it likely means your in a situation you're loosing money while it's down. You should be able to restore a backup while being groggy after getting a 3am wake up call. If you have a dev environment you might setup a weekly script to restore the backup into your dev environment. 

This might be better placed on stack overflow. This isn't something you'll accomplish with MySQL. What you're talking about is referred to as 'stemming' in search. Similar to matching different conjugations of a regular word e.g. run => runs ,ran. I don't know of any such applications for proper names off hand but when you find one that will sit alongside your primary application to "normalize" the name before inserting the record into your database. Mysql, sqlserver, mongo, whatever. The DB technology is irrelevant as your task is out side the scope of storing data/documents. Lucene would be a better tool for your task. But I couldn't speak to it's prepackaged ability to stem names like you want. Edit After thinking about it I think I misspoke when I said Lucene would be a "better" approach in of itself for what you want. My understanding is stemmers exist outside of core lucene and then proxy a search for "bob" into ("bob" or "robert") to feed into the lucene engine. 

The general approach was to fabricate an ObjectID with the time stamp prefix of what I wanted. The general query looked like 

I have a couple questions for those more familiar. Most of my instances have been running Antelope despite having support for Barracuda. I was looking to play around with some compresses innodb tables. My understanding is this is only available under the Barracuda format. 

It seems maybe there's a config option that didn't come through in what you pasted that's looking to work with /run (instead of /var/run) ? 

The problem though is by step 4, there might have been writes on M2 which had since propagated to S2 but where blocked from getting to S1 b/c of M1's read lock. Another idea: 

That will scan you're entire disk where non priviledged access is allowed (which is fine; it should find it, i'm assuming your distro came with it and you're able to connect or you wouldn't be asking this much; but it will tie your disk up) 

I'm not sure about your package management issues but wanted to point out that the docs Say that you should completely reload your data using mysqldump when upgrading from a previous minor version. So once you have your complete mysqldump w/ --all-databases --events --routines, be sure to import that into the new binaries. 

If these don't suit your needs please elaborate on your use case on what you are trying to accomplish. 

When I'm using multi byte characters however, the expected warning state occurs but the message is different: 

Stop slaving on S1, M2. Flush tables with read lock on M1. Start slave until M1's master log pos on S1,M2 Stop slave on S2, M1. Flush tables with read lock on M2. Start slave until M2's master log pos on (S2,M1) Start slave on M1, M2, leaving s1,s2 stopped