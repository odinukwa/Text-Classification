then $R = R \cup \{ 122 \rightarrow 1 \}$. During the scan of each iteration you check that the new rules added are not in conflict with those already in $R$, otherwise you restart with the first iteration, $R = \emptyset$ and $(k+1)$-neighbourhood. If you reach $X_t$ without conflicts the you can fill the missing rules randomly. The resulting CA is minimal with respect to the given spacetime history. The time complexity is $O(|n|^2)$ (assuming $O(1)$ access/update time to the current ruleset $R$). 

EDIT: after thinking a little bit about it, there is a problem with the pointers ... if every call of the recursive function can mantain a valid pointer to a variable defined locally in the caller then everything is fine; otherwise my algorithm cannot mantain a valid double-linked list on the unlimited recursion (and in this case a don't see a way to use recursion to simulate an unlimited random-access storage). 

In the figure a triple $(x,y,z)$ is represented with two edges $(x,y),(x,z)$ of the same color. As an example, if $x^1_{S_1}$ corresponding to $S_1 = \{a_1,a_2,a_3,a_4\}$, must be used to include $y_{S_1}$ (blue edges), then it cannot be used to include the elements $z_{a_1},y_{a_2},z_{a_3},y_{a_4}$ (red edges). 

This is not an answer, only an extended comment on a possible transformation of the problem (hope it is correct :-). Each row can be "mapped" to a $n \times (n-1) / 2$ "extended" row. Each element of the extended row represents a pair of elements in the original row and is set to 1 if the two elements are different, set to 0 if the two elements are the same. For example: 

We can represent a single number $v$, with the corresponding index $I(v)$ in the above enumeration plus the lengths of the non-empty interleaving 0 sequences. For example: 

each step of Prog is primitive recursive (i.e. doesn't contain while / until); note that g used in the FOR statement is by hypothesis primitive recursive. Prog is guarantee to end and correctly output $TM_{PR}(x)$ because $g(|x|)$ is a time bound for $TM_{PR}$. Since $LOOP \setminus WHILE \equiv PR$ then the function computed by $TM_{PR}$ is in $PR$ 

Only an extended comment with a trivial example; you can pick the one-element language: $$L_k = \{ M \mid \sigma(M) = \Sigma(k) \}$$ i.e. $L_k$ contains the first (in lexicographical order) busy beaver Turing machine of size $k$ (the Turing machine of size $k$ that attains the largest number of 1s on its tape after halting). For every $k$ the language $L_k$ is regular ... but we have no idea on how to build the small DFA that recognizes it (though it has only $\leq 2*k(\log k+2)$ states) :-) 

Perhaps the corresponding decision problem is NP-complete; given an instance of SUBSET-SUM: Given $K, x_1,...,x_n$ does exist $A \subseteq \{x_1, x_2, ..., x_n\}$ s.t. $\sum_{x_i \in A}x_i = K$? Suppose that $k > 0, x_i > 0$ and let $k' = \sum_{i=1..n} x_i - K$ Now, if you pick two bins $B_1, B_2$ with sizes $k$ and $k'$, then $n$ items of sizes $x_i$ can be packed with cost $numparts = n$ if and only if the corrsponding SUBSET-SUM problem has a solution. 

A graceful labeling of a graph with $m$ edges is a labeling of its vertices with some subset of the integers between $0$ and $m$ inclusive, such that no two vertices share a label, and such that each edge is uniquely identified by the positive, or absolute difference between its endpoints. The Graceful Tree conjecture (all trees are graceful) is a well known open problem. Finding a graceful labeling seems not so easy; some time ago I made a few tests with a Constraint Programming language and the solver got stuck even for relatively small highly symmetric trees. A natural variant of the problem is the following: 

There are a lot of classic and popular two player games (that were invented before the computer age); and most of them have very different rules and settings: e.g. chess, go, card games, mancala, othello, hex, risk, master mind, scrabble, and so on. Many of them have been proved to be at least PSPACE-complete (the generalized version). So, returning to your question, I think that there are enough evidences that: 

It has 3 "interface points" $[W,N,E]$ (on distinct columns/rows), and an inner border of $C \times C$ points. A polyline that traverses the gadget from one interface point to another can have a number of corners that is proportional to $C$ (three traversals of the gadget are shown in the figure), in particular the number of corner points is between $2C$ and $2C+2$ (the total number of points of the gadget is $C \times C - 4 + 6$). The gadget can be rotated to get other interface point combinations ($[N,E,S]$, $[E,S,W]$, $[S,W,N]$). Now we can shift the planar grid graph in such a way that for every pair of nodes $(x_1,y_1), (x_2,y_2)$, $x_1 \neq x_2$ and $y1 \neq y_2$. See the following figure of a simple $4 \times 3$ grid. Next, we can scale the graph and replace each node with the gadget above. At this stage each gadget is "isolated": a polyline cannot go from one gadget to another. 

Note: the enumeration of the deterministic Turing machines $M_i$ is different from the enumeration of the nondeterministic $N_i$ (due to the nondeterministic transitions), so, to make $J$ and $J'$ directly comparable, we can follow this alternative approach: $J$ simulates $M_i$ on input $x_j \# 0^{|x_j|}$; $J'$ can take as input a deterministic Turing machine $M_i$, too but simulates it on inputs $x_j \# y$ for all $y \in \{0,1\}^{|x_j|}$ and stops its search if at least one computation accepts. In this setting that seems equivalent to the formulation above (indeed $J'$ seems to capture all the power of NP), it is easy to see that $j(n) = j'(n)$. 

Reduction example from the unary 3-partition problem $m=2, A = \{3,3,2,2,2,2\}, B = 7$ Note: as observed in the comments the blue intervals L in S and T are not essential for the reduction. If the reverse condition is also required, then you can build two DAGs using the relation $I_i \subseteq I_j$ to build arcs $(I_j \rightarrow I_i)$. A bijection that preserves interval inclusion in both directions exists iif the two DAGs are isomorphic. So the problem cannot be harder than the DAG isomorphism problem, which is GI-complete (and if you prove that it is NP-complete then you prove that GI is NP-complete, too). 

From the comment above: $p$-HYPERGRAPH-(NON)-DOMINATING-SET is W[3]-complete under fpt-reductions: A hypergraph $H = (V,E)$ consists of a set $V$ of vertices and a set $E$ of hyperedges. Each hyperedge is as subset of $V$. In a 3-hypergraph all edges have size 3. If $H = (V,E)$ is a 3-hypergraph, every $a \in V$ induces a graph $H^a = (V^a, E^a)$ given by: $V^a = \{ v \in V \mid v \neq a \text{ and there is } e \in E \text{ with } a, v \in e \}$ and $E^a = \{ \{u,v\} \mid \{a,u,v\} \in E \}$ Input: A 3-hypergraph $H = (V,E)$, a set $M \subseteq V$, and $k \geq 1$. Parameter: $k$. Problem: Decide whether there exists a set $D \subseteq V$ of cardinality $k$ such that: 

There are TMs that compute Collatz-like sequences for which the decidability is still an open problem: $TM(5,2)$, $TM(3,3)$ and $TM(2,4)$ (where $TM(k,l)$ is the set of Turing Machine with $k$ states and $l$ symbols). I don't know if the results have been inproved. From the comclusion of the paper: ... The present Collatz-like line is already on its lowest possible level, with the possible exception of $TM(4,2)$, but we conjecture that all machines in this set can be proved to be decidable... See also "The complexity of small universal Turing machines: a survey" by D. Woods and T. Neary (2007). Another example of Collatz-like problem for which decidability is an open problem is the Post's tag system: $\mu = 2, v=3,0\rightarrow 00, 1 \rightarrow 1101$; for a recent analysis see "On the boundaries of solvability and unsolvability in tag systems. Theoretical and Experimental Results" by L. De Mol (2009). 

I realize that it is not easy to formalize the notion of "small theory" (or "simple" theory), but it should include the number of axioms of the theory and the size of the signature. For example Andrzej Grzegorczyk in “Undecidability without arithmetization” (Studia Logica 79(2005)) proved that Tarski’s theory of concatenation (TC) is already undecidable; the axioms are: TC1: $x*(y*z) = (x*y)*z$ TC2: $(x*y = u*v ) \to \exists w((x*w = u \land w*v = y)\lor(u*w = x \land w*y = v))$ TC3: $\neg (\alpha = x*y)$ TC4: $\neg (\beta = x*y)$ TC5: $\neg (\alpha = \beta)$ 

From the comment above: there are two interpretations to your question: 1) The Cook-Levin theorem does not relativize in this sense: there exists a language $L$ and an oracle $A$ such that $L \in NP^A$ but $L$ is not polynomial-time many-one reducible to $3SAT$ even if the polynomial time Turing machine that performs the reduction is allowed to access the same oracle $A$ (i.e. $L \nleq_m^A 3SAT$). The proof is a standard exercise (see for example Arora and Barak, Computational Complexity); hint: play a little bit with the oracle that separates P from NP, the only difference here is that you must "fool" polynomial-time oracle Turing machines that output 3SAT formulas instead of deciders that output yes/no (let me know if you need the full proof); 2) The Cook-Levin theorem does relativize in this sense: you can extend the circuit model with oracle gates, i.e. $k$-inputs gates in which the inputs are ordered and the output bit is the result of the associated oracle on the query formed by the ordered input bits (there is also a variant in which every bit of the query is represented by two input bits, in order to allow queries shorter than $k$). With this extended oracle circuit model you can build in polynomial time a polynomial-size oracle circuit $C^A$ that "simulates" - in a similar way of the Cook-Levin theorem - the computation of an oracle polynomial time machine $M^A$ and on input $x$ evaluates to 1 if and only if $M^A(x)=1$. So, if $\text{Circuit-}SAT^A = \{ C \mid C $ is a boolean circuit equipped with oracle gates for $A$ and for which there exists $x$ such that $C(x)=1 \}$ you say that: for every oracle $A$, $\text{Circuit-}SAT^A$ is $NP^A$-complete. 3) Finally with a TQBF oracle we have $P^{TQBF} = NP^{TQBF}$, so if we add a TQBF oracle to the polynomial time Turing machine that performs the reduction (interpretation 1) we give to it the power to solve the original problem directly, so we have: $NP^{TQBF} \leq_m^{TQBF} \{1\}$ i.e. every trivial set is $NP^{TQBF}$-complete under polynomial time many-one TQBF-oracle reductions (except $\emptyset$ and $\Sigma^*$ :-), so Cook-Levin theorem does relativize for the TQBF oracle (solve the source instance and output $(x_1 \lor x_2 \lor x_3)$ if it belongs to the language, output an unsatisfiable 3SAT formula otherwise). Addendum: related to your question, it is interesting how the (old but great) Computational Complexity by C. Papadimitriou explicitly faces the problem of the relativization of another well known thereom, the Ladner's theorem, in this way (probably the oracle gates were introduced later): [From Chapter 14]: ... "If $P^A \neq NP^A$, then there is a language in $NP^A - P^A$ which is not $NP^A$-complete". But when we say "$NP^A$-complete", do we also allow the use of oracle in our reductions? With a little reflection we may decide that the right way to state the result is in terms of ordinary reductions... ..... There seems to be no reasonable definition of $SAT^A$. To get around this difficulty, we must replace the usage of SAT with an $NP^A$-complete problem. Such problem exist; for example: $C^A = \{ (M^A,x) \mid $ nondeterministic oracle machine $M^A$ accepts $x$ in time $|x|\}$ 

Just an extended comment trying to interpret the question. Given a Turing machine $M$ that is promised to halt halts on all input strings; $M$ is called incomprehensible if and only if for at least one positive semidefinite real number integer $r$ the following question decision problem $Q_{M,r}$ is undecidable (i.e. it is impossible to construct a single algorithm that always leads to a correct yes-or-no answer): OPTION 1 $Q_{M,r}(n)$ = "Does $M$ halts in less than $n^r$ steps on all inputs of length $n$ ?" Trivially decidable (finite $2^n$ strings and $M$ always halts by hypothesis) $\Rightarrow$ there are no incomprehensible TMs OPTION 2 $Q_{M,r}$ = "Is $M$ running time $O(n^r)$ ?" Trivially decidable (1 or 0) $\Rightarrow$ there are no incomprehensible TMs And if you ask: "Ok, but can we calculate the value 1 or 0 to build the algorithm that answer the question of Option 2?", then we fall back to this: $Q_{r}(M)$ = "Is $M$ running time $O(n^r)$?" which is undecidable (using the standard definition of undecidable) as showed by Emanuele. But in this version M is an input of the problem and not the fixed $M$ for which you are defining the notion of "incomprehensible". 

If you know $h$, in order to build $s$ you can simply simulate all TMs between $1$ and $n$ and when $h$ of them stops you have enough information to reconstruct $s$ (you have the positions of the $1$s, the other can be set to $0$s). So $K(s) = \lceil \log h \rceil + c$ If you interpret $HALT(k) = 1$ iif $TM_k$ halts on all inputs, then: $K(s) = min\{n, K(\lceil \log n \rceil, \lceil \log z \rceil )\} + c$ Where $z$ is the minimum number such that for every non halting $TM_k$ in 1..n exists $y \leq z$ such that $TM_k(y)$ doesn't halt. Informally you can simulate the $n$ TMs on inputs $1..z$ being sure that those who halts are the only TMs that always halts on all inputs. Perhaps the same reasoning can be applied to points 2. and 3. 

Just an extended comment ... (perhaps trivial and/or wrong :) If $x_i = a_i / b_i$ and $M$ is the least common multiple of the $b_i$s, then we can get rid of the rationals: $x'_i = M*x_i$. If $y_i \in \{ \lceil x_i \rceil, \lfloor x_i \rfloor \}$ (floor,ceil restriction) then we can use binary variables $v_i$ to express $y'_i$ using its distance from $x'_i$ ($L_i = x'_i - M*\lfloor x_i \rfloor$ or $R_i = x'_i - M*\lceil x_i \rceil$): $y'_i = x'_i + L_i * v_i + R_i * (1 - v_i) = x'_i + (L_i - R_i)*v_i + R_i = x'_i + D_i *v_i + R_i$ And the original problem should (?!?) be equivalent to finding the $v_i$ that minimize: $\sum_{1 \le i < j \leq n} | D_i * v_i - D_j * v_j |$ with $v_i \in \{0,1\}, D_i \in \mathbb{Z}$ 

In my opinion there is a clear common insight in the opposite direction: if the conjectures are true then the corresponding problems are not NP-complete and turn out to be trivial in both cases (they switch from NPC to $O(1)$ ). And the common insight is that the natural problems, Hamiltonian cycle and nowhere zero flow in general graphs, are "strutured and powerful" enough to efficiently "simulate" the trace of a Turing machine (à la Cook-Levin) . Then you start adding more and more constraints until you get no "computational power" at all. To me it's like adding more and more constraints on the transition graph of a Turing machine (or on the read/write tape device) until you get something trivial like "the transition graph doesn't contain a cycle". 

Proof sketch: $(\Rightarrow)$ It is easy to see that, by construction, if an exact cover $C' = \{ C_{j_1},...,C_{j_q} \}$ exists we can set $y_j = 1$ if $C_j \in C'$, $y_j = 0$ if $C_j \notin C'$, and equation $(1)$ holds. $(\Leftarrow)$ Suppose that $(1)$ holds. Then at most $q$ from the $y_j$s can be different from $0$, otherwise the sum is greater than $(q+1)2^{6qn}>b$ (leftmost bits in the figure). Furthermore every $y_i$ must be $< 2^n$ otherwise $a_i y_i \geq 2^n 2^{6qn} \geq (q+1)2^{6qn} > b$. But if $0 \leq y_j < 2^n$, the bit at position $2(i-1)n$ in $a_j$ corresponding to element $x_i$ of $X$ cannot be shifted to the left by the multiplication and "reach the position" $2(i-1)+n$, so even if $q$ of them are summed, they cannot reach and alter the bit $2in$ which correspond to the element $x_{i+1}$: $2^{2(i-1)n}y_jq<2^{2in}$ (informally the bits corresponding to elements $x_i$ cannot interfere with each other). Every bit $2^{2(i-1)n}, i < 3q$ of $b$ must be "generated" by exactly one of the $a_j$, so $0 \leq y_j \leq 1$ and the $y_j \neq 0$ identify an exact cover of $X$: $C' = \{ C_j \mid y_j \neq 0 \}$. 

Perhaps you can use an "information retrieval" technique: in the preprocessing phase, build an inverted index (in your case a simple $n \times | {\cal X}|$ bidimensional array is enough) that maps an element $x_i \in \{1,...,n\}$ to the sets in $\cal X$ that contain it: $inv(x_i)= \{ X_j \in {\cal X} \; | \; x_i \in X_j \} $. Set up an integer array $occ$ of length $|\cal X|$. Then for each $y_i \in A$ retrieve $inv(y_i)$, and for each $X_j \in inv(y_i)$ do $occ[j] = occ[j]+1$ At the end the sets you need are those for which $|X_j|=occ[j]$. You can arbitrarily speed up the process (at the cost of exponential space) by indexing two or more elements together.