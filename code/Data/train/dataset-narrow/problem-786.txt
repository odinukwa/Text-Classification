On the other hand, if you just have as a property of the document and it indicates "how many times the document has changed", then I would go for the optimistic locking approach, something like: 

and are commands of the MySQL client; you can't prevent users from using them. is only allowed if the user has the system privilege. See dev.mysql.com/doc/refman/5.1/en/grant.html#grant-privileges 

My standard backup regime for Oracle databases revolves around rman, flash recovery area and rsync. Basically as follows: 

It makes a difference... SQL*Plus can use variables, but they're a SQL*Plus feature and you can just grab that block of code and pass it to an Oracle backend to execute (like you could with a Transact SQL block for example). You can choose between using bind variables in SQL*Plus as follows: $URL$ Or use SQL*Plus's own variables with DEFINE and COLUMN commands: $URL$ If you really need the code to be executable in other environments, you will probably have to go down the PL/SQL route. 

You'll need to decide whether you want to use OS authentication or use a password file. See $URL$ to help you decide. Will users administer the database by first logging in to the database server using eg ssh? Then you can use OS authentication. Best practice for OS authentication: No-one should be logging in as the OS user. Each DBA should have their own OS account and login as that. Their OS account should be a member of the OS group (remember that only members of the OS group can login using ). If you want to allow remote administration, then you'll either need a secure connection to the database (just like SSH provides that to the server when administering locally) or you'll need to use a password file. 

In general, no, not possible to turn the original master into a standby of the new master without making a copy of the new master, replacing all the data files of the old master with said copy, and resuming log shipping. This is because, in general, there will be lost transactions on the old master that didn't make it to the standby. You could use rsync to make the copy go faster -- as the contents of the two databases will likely be very similar. The tool was invented for this purpose: it will "rewind" the old master to the point at which the failover happened. See Heikki Linnakangas' excellent presentation about the whole topic at $URL$ 

Like many things, the answer to this question is "it depends". In this case, what it depends on is how many transactions each product will get. With low to moderate volumes of transactions, it will be very fast to compute the running total on the fly and you don't have to write lots of code to compute, store and maintain the totals. Index your table! 

I want all the data in the database to be subject to the same constraints, not just the new data to be subject to the constraints in the version of the code that's running today. I want declarative constraints, not programmatic constraints. Data in the database often outlives the code that's written to interact with it today. And that data -- not the code -- is the organisation's asset. My code becomes much simpler when I know that all data is subject to rigorous constraints. I no longer have to consider special cases which I know that the database guarantees to be impossible. 

A PL/SQL table is NOT the same as a temporary table in Oracle. An Oracle temporary table is created with they syntax 

The error message is somewhat strange as presented, but when you get this message creating a virtual column, the value for is the minimum length that you need to specify to be able to create the column. The reason for this is that Oracle doesn't know the maximum length of the expression and assumes that it will be 40 characters: 38 places of precision for the number, plus 1 for each of the decimal point and positive/negative indicator. Add 2 characters for "A:" and the minimum length that Oracle judges as "safe" is 42. 

The case where you can achieve performance benefit using a view (or common table expression = "inline view") instead of a subquery is if you have to repeat the same subquery several times in your query. If instead you can replace each subquery with the same view name (or named common table expression) then the optimizer knows it's the same thing and can either cache the result or restructure the execution path so that the result only needs to be queried once. 

Install the exact same version of the software on the other PC using the same installation options (same directory structure, etc). Shutdown the instance on the original PC. Copy all the files from the original PC to the same location on the other PC. Start the instance on the other PC. 

Like I mentioned in the comment above, an alternative answer would be to put the subqueries in the select clause, as follows: 

? But beware that this will retain the first row for every distinct combination -- which might not be the right thing without an clause this. But since you don't order in your question I presume you either don't care or haven't thought that far yet. 

Conversely, if you are designing or working on a distributed system or in any system where parts of the system will be distributed across different timezones, it might be considered to be an anti-pattern to not use , although some systems might be designed to run in one timezone, eg UTC. In this case the timezone logic may be being pushed into the application layer -- but I would consider this an anti-pattern, yes. 

In all cases when writing a delete statement consider that in general the where clause is usually either 

makes it work for me. See $URL$ Changing the definition in the SQL Fiddle back to the one included in the question will cause the to be . Personally, I would classify this as a work-around rather than an answer. 

deleting child rows in a trigger. constraints. execute multiple delete statements on the various tables involved, in the right order. 

Minimal performance benefit, the only benefit in this regard is from reduced fragmentation. But Oracle and most filesystems handle this much better these days than in the past; Oracle handles this better with "automatic segment space management" and the Oracle "filesystem" ASM, though you don't need to use the latter. It's more a manageability choice these days; personally I wouldn't bother with separate tablespaces, but I do often create one per application. This allows you to use a transportable tablespace export if you so desire.