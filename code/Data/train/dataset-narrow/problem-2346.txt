I think your focus on the rigid case of GI limits you too much. Instead phrase (non-rigid) GI as an HSP in the same way, but now the goal is to determine the size of the hidden subgroup, or a generating set. The difference between the isomorphic and non-isomorphic cases will be a factor of 2 in the order of the hidden subgroup. If you phrase the problem as finding generators of the hidden subgroup, then the question is just whether any generator switches $\Gamma_1$ and $\Gamma_2$. Now, an instance of "HSP-GA" corresponding to a graph $\Gamma$ is given by the function from $S_n \to M_n(\mathbb{C})$ defined by $f(\pi) = A(\pi(\Gamma))$ where $A(\cdot)$ denotes the adjacency matrix. In particular, $f(1) = A(\Gamma)$. Then apply the usual Karp reduction from GA to GI to get a pair of graphs $\Gamma_1, \Gamma_2$, and consider the HSP-GI instance, of the type described in the preceding paragraph, corresponding to the pair $\Gamma_1, \Gamma_2$ (that is, the disjoint union $\Gamma_1 \cup \Gamma_2$). 

Determining if a graph has a nontrivial automorphism Cook-reduces (polynomial time Turing) to Graph Isomorphism (determine if a pair of graphs is isomorphic) (exercise for the reader). It is not known to be equivalent to graph isomorphism. In turn, graph isomorphism can be solved in $2^{\tilde O(\sqrt{n})}$ time and lies in $NP \cap coAM$. In particular, it is not $NP$-complete unless the polynomial hierarchy collapses. 

This problem is precisely the canonization problem for isomorphism of bipartite undirected graphs. While the lexicographically maximum form may be harder, any canonical form will be GI-hard (and so, in particular, it doesn't matter whether the $P$ and $Q$ are restricted to satisfy $P=Q^{-1}$ or not, as asked in a comment above). In particular, there is a canonization procedure that takes only $2^{\tilde{O}(\sqrt{n})}$ time (much better than $n! \sim 2^{\Theta(n \log n)}$), by Babai-Luks 1983, though in practice I'd recommend just using nauty. 

The only other ones I know of are also isomorphism problems: group isomorphism and ring isomorphism. The $coAM$ protocols for both of these are essentially the same as for graph isomorphism. Group isomorphism reduces to graph isomorphism reduces to ring isomorphism. Interestingly, unlike (what is known for) groups and graphs, for rings, determining whether a ring has a nontrivial automorphism is in $P$, while finding a nontrivial automorphism is equivalent to factoring integers. See Neeraj Kayal, Nitin Saxena. Complexity of Ring Morphism Problems. Computational Complexity 15(4): 342-390 (2006). 

They are equivalent. For any $x$, let $g_x$ be a permutation with just two cycles: one consisting of $\{i \in [n] : x_i = 0\}$ (say, in ascending order) and one consisting of $\{i \in [n] : x_i = 1\}$ (also in ascending order). Then the "GC" description is just $01enc(g)$, whose length is $2 + K(g)$. But $K(g) \leq K(x) + O(1)$, since the above description of $g_x$ gives a uniform construction of $g_x$ from $x$. So we have $GC(x) \leq 2 + K(g) \leq K(x) + O(1)$. 

While the second half of this corollary is kind of in a similar spirit to this question, it is a far cry from proving that every $\leq_T^p$-degree contains a word problem. 

This is essentially the problem that motivated Valiant to introduce matrix rigidity into complexity (as far as I understand the history). A linear circuit is an algebraic circuit whose only gates are two-input linear combination gates. Every linear transformation (matrix) can be computed by a linear circuit of quadratic size, and the question is when can one do better. It is known that for a random matrix one cannot do significantly better. Some matrices - such as the Fourier transform matrix, a matrix of low rank, or a sparse matrix - can be done significantly better. A sufficiently rigid matrix cannot be computed by linear circuits that are simultaneously linear size and log depth (Valiant), but to this day no explicit matrices are known for which there is a super-linear lower bound on the size of linear circuits. I don't recall seeing results saying that it's hard to compute the size of the smallest linear circuit for a given matrix, but I wouldn't be surprised if it were NP-hard. 

Finally, the Mulmuley-Sohoni Geomectric Complexity Theory program is essentially about using symmetry to prove hardness, though the symmetry-hardness connection there is more subtle and less direct. 

While I don't know about the complexity of matrix polynomials in general, the state of the art in the complexity of matrix multiplication is nicely summarized in a recent ToC Graduate Survey by Markus Bläser. Computing entries mod $p$ is basically the same as the question of the complexity of performing the computation over the field $\mathbb{F}_p$, which is fairly well-studied (though perhaps not as well-studied as characteristic zero). Most matrix multiplication research works in the nonuniform setting anyways, so it should almost all be relevant to the question of circuit size. 

In terms of these complexity classes as a whole, not much is known that distinguishes characteristic 2 from other characteristics. The most frequently arising difference is that the permanent is easy in characteristic 2 (so not VNP-complete unless VP=VNP). (In contrast, the Hamiltonian Cycle polynomial is VNP-complete in all characteristics.) The relationship of the VP vs VNP question in different characteristics to Boolean complexity classes depends on the characteristic, but in an obvious way (e.g. Boolean complexity classes defined in terms of a similar characteristic, like $\mathsf{Mod_n P}$). Aside from these (and a few other similar examples like permanent), I'm not sure I know of any proven differences between the different characteristics. I'd be interested to see some! (Another caveat to be aware of is the distinction between functions over $\mathbb{F}_2$ and formal polynomials over $\mathbb{F}_2$. As functions, $x^2 - x$ and $0$ are the same, but as formal polynomials over $\mathbb{F}_2$ these are distinct. VP and VNP are usually defined in terms of formal polynomials.) 

The massive tome of Burgisser-Clausen-Shokrollahi is the standard reference for algebraic complexity theory (and I'm not really sure there are others from the complexity point of view, though there are definitely others about algebraic algorithms), but doesn't do much of PIT. The surveys of Chen-Kayal-Wigderson (freely available from Wigderon's webpage) and Shpilka-Yehudayoff (freely available from Shpilka's webpage) cover much more of the recent results on lower bounds and derandomizing PIT for small algebraic circuit classes. Agrawal's 2006 ICM address gives a good overview of the permanent versus determinant problem, and despite being 8 years old is still fairly up to date. (I think the only more recent lower bound is Landsberg-Manivel-Ressayre, which gets the same lower bound but for approximative determinantal complexity instead of just determinantal complexity.) 

For more uses of forcing (via so-called generic oracles) in complexity theory, see The Oracle Builder's Toolkit (freely available from Fortnow's homepage) by Fenner, Fortnow, Kurtz, and Li. They give a general theory of generic oracles, and show its many applications in complexity. If you're interested in how oracles in complexity are like independence proofs in set theory, you might be interested in the following papers: 

That paper, as with Mignon-Ressayre, uses the rank of the Hessian, rather than explicitly from a determinantal identity. However, the rank of the Hessian can be seen as closely related to Segre's identity $\det_{n^2}(Hess(\det_n(A)) = (-1)^{\binom{n+1}{2}}(n-1)\det(A)^{n(n-2)}$, which is the identity reportedly used above. You might also be interested in the following paper, which shows that any reduction from perm to det which respects the symmetries of perm (see the paper for precise definitions) must have exponential blow-up: 

For general equivalence relations, not those arising from permutation group actions, even finding lexicographically least is still "too" general. Finding the lexicographically smallest element in an equivalence class can be $NP$-hard (in fact, $P^{NP}$-hard) - even if the relationship has a polynomial-time canonical form [1]. However, for permutation group orbit problems as you describe, deciding whether two points lie in the same orbit is not likely to be $NP$-hard: it is in $NP \cap coAM$, and hence not $NP$-hard unless the polynomial hierarchy collapses to the second level. A canonical form for graph isomorphism is also a special case of the second problem you state. The best known canonical form for graph isomorphism runs in time $2^{\tilde{O}(\sqrt{n})}$ [2]. Since you said in the comments that any canonical form will do, you might also be interested in my paper with Lance Fortnow [3]: in its currently generality, I think your question is related to our results. We show that if every equivalence relation decidable in $P$ has a canonical form in $P$, then "bad" consequences result, such as $NP = UP = RP$, which in particular implies that the polynomial hierarchy collapses down to $BPP$. On the other hand, the equivalence relations you're interested in may not be in $P$, but this result suggests that even if it lies in a higher complexity class other hard problems may still stand in your way. So I think if you want some better upper bounds you really need the problem to be more specific. [1] Andreas Blass and Yuri Gurevich. Equivalence relations, invariants, and normal forms. SIAM J. Comput. 13:4 (1984), 24-42. [2] László Babai and Eugene M. Luks. Canonical labelings of graphs. STOC 1983, 171-183. [3] Lance Fortnow and Joshua A. Grochow. Complexity classes of equivalence problems revisited. Inform. and Comput. 209:4 (2011), 748-763. Also available as arXiv:0907.4775v2. 

The only downside (but I think it's worth it): although using sharelatex is free, some of its features are not. Notably, to use Dropbox sync (when they release it), or if you want more than 6 coauthors to work on the same sharelatex project, you have to pay \$8/mo. or \$80/year [as of April 2013]. Once they release Dropbox sync though, it seems like a very fair price to me. [Disclaimer: I have no relationship with sharelatex or its employees other than that I use their product.] 

(On the other hand, there are some properties that are known not to be shared between the two, see Muchnik & Vereshchagin, Shannon Entropy vs. Kolmogorov Complexity.) 

The reason step (2) works it that, for sufficiently large input lengths, if there is a string $y \in K$ of that length, $M^K$ cannot query $y$, so we can simulate all such queries with a NO answer. If it did query $y$, then we would have $y \in K[\log n, n^k]$ (where $n^k$ bounds the run-time of $M$), contradicting the fact that we chose $y$ to be not in $K[\log n, n^{\log \log n}]$. 

[This answer was in response to the version prior to Revision 6 of 29 Oct 2010.] I think the question more-or-less works now, but there is a technical issue remaining. Namely, how to formalize "it is trivial to enumerate every single solution by just looking at such structure." A perhaps naive formalization (but the only one I could come up with at the moment) is as follows: let $R(\varphi)$ denote the representation of the solution set $S(\varphi)$ of $\varphi$. At the moment I put no restriction on $R$ other than that $|R(\varphi)| \leq poly(n)$ where $\varphi$ is a CNF on $n$ variables. Then we want there to be an algorithm $A$ such that $A(R(\varphi)) = S(\varphi)$ and $A$ on input $R(\varphi))$ runs in time $poly(n, |S|)$. Under this formalization, the only difficult cases are the ones where $S$ is super-polynomial but sub-exponential. The remaining cases are handled by the following representation $R$ and algorithm $A$: if $|S| \leq poly(n)$, then let $R(\varphi) = (0, S)$. If $|S| \geq 2^{\Omega(n)}$ then let $R(\varphi) = (1, \varphi)$. $A(0, S)$ simply outputs $S$, and $A(1, \varphi)$ simply computes $S$ by brute force from $\varphi$. Since $|S| = 2^{\Omega(n)}$ in the latter case, this still runs in time $O(|S|)$. However, the difficult cases are in general impossible under this formalization. If such an $R$ and $A$ existed, it would mean that the $p$-time-bounded Kolmogorov complexity of every $S$ was bounded by $poly(n)$, which is absurd (since almost all sets $S$ have maximal $p$-time-bounded Kolmogorov complexity, namely $|S|$). (Here $p$ is the running time of $A$ as a function of $|S|$.) (Note that if we additionally require that $R$ run in time $poly(n, |\varphi|)$, then the answer to the question is no in general, assuming $P \neq PromiseUP$: if $\varphi$ has a unique solution, then $A(R(\varphi))$ would solve $\varphi$ and run in time $poly(n)$.