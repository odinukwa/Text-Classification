Also, virtual methods tend to be slow as well. It may not be the most professional way of dealing with this, but I think it's the fastest. 

Texture coordinates are expressed as floating points values between the limits 0 and 1. What you are doing is sending 5 and 32 which get clamped to 1, resulting in the image becoming transparent between 0 and 1, which encompasses the whole thing. What you need to do is divide, either in the shader or outside (preferably outside, on the cpu) by the actual width and height of the texture. For example, say you have a 32x64 texture, and you want it to be transparent in the rect x1=0, y1=0, x2=5, y2=10. You have to divide x1 and x2 by 32 and y1 and y2 by 64, and then do the comparisons. Something like this: 

I'm applying phong shading onto a single giant triangle, and I'd like the light's coordinates to coincide with the camera's coordinates in 3D space. In order to do this, whenever I update the camera's coordinates, I also update the light's coordinates. However, diffuse and specular lighting don't "focus" exactly at the camera position when I bring the camera close to the triangle, instead they do it a few units too far. The triangle is .5 units below the XZ plane and parallel to it. Here is a picture demonstrating this effect. 

I'm trying to get an object from object space, into projected space using these intermediate matrices: The first matrix (I) is the one that transforms from object space into inertial space, but since my object is not rotated or translated in any way inside the object space, this matrix is the 4x4 identity matrix. The second matrix (W) is the one that transforms from inertial space into world space, which is just a scale transform matrix of factor a = 14.1 on all coordinates, since the inertial space origin coincides with the world space origin. 

on IOS as far as i know you can't create a framebuffer with a different resolution than the screen so the only approach is to render everything into a texture and draw it afterwards on the screen. Also targeting different resolutions is quite hard and there are a couple of things to take into accound: Aspect ratio of the screen: The texture you create should have the same aspect ratio as the screen otherwise thing will look stretched afterwards. If you don't want to do this you can fake the aspect ratio of the game from the projection matrix but in this case the pixels from your texture will be stretched unevenly creating aliasing artifacts that will just look bad. Aspect ratio again: It is important that the projection matrix takes into the account the screen also because on a wider screen you will see more on width so the projection has to be wider otherwise the content will look differently. Menus: This is a really hard topic but the general approach is to have the elements scaled evenly on width and height but this is not possible if you have different aspect ratios unless you split the menus into parts and apply uneven scale only on salable elements(like the empty space between buttons). Much like how html pages are made , you have the content that is fixed(or scaled evenly) and the borders are stretched until it fill the whole screen. Artifacts generated by scaling: When rendering to a texture and scaling it up you will get aliasing artifacts and they are hard to remove. You can use an upscale filter, but this can be expensive on mobile devices. 

the easy option to integrate is to store 2 texture coordinates into one float using the int part and the decimal part: 

The application is usually tested on the targeted platform with the worst case scenarios and you will always be prepared for the platform you are targeted. Ideally the application should never crash, but other than optimization for specific devices, there are little choices when you face low memory warning. The best practice is to have preallocated pools and the game uses from the very beginning all the needed memory. If your game has a maximum of 100 units than have a pool for 100 units and that's it. If 100 units exceeds the mem requirements for one targeted device then you can optimize the unit to use less memory or change the design to a maximum of 90 unit. There should be no case where you can build unlimited things , there should always be a limit. It would be very bad for a sandbox game to use for each instance because you can never predict the mem usage and a crash is a lot worst than a limitation. Also the the game design should always have in mind the lowest targeted devices because if you base your design with "unlimited" things in it then it will be a lot harder to solve the memory problems or change the design later on. 

I'm implementing a software renderer with this rasterization method, however, I was wondering if there is a possibility to improve it, or if there exists an alternative technique that is much faster. I'm specifically interested in rendering small triangles, like the ones from this 100k poly dragon: 

where d is the distance from the eye to the projection plane, so d = 1. I'm multiplying them like this: (((P x C) x W) x I) x V, where V is the vertex' coordinates in column vector form: 

I'm making a software renderer which does per-polygon rasterization using a floating point digital differential analyzer algorithm. My idea was to create two threads for rasterization and have them work like so: one thread draws each even scanline in a polygon and the other thread draws each odd scanline, and they both start working at the same time, but the main application waits for both of them to finish and then pauses them before continuing with other computations. As this is the first time I'm making a threaded application, I'm not sure if the following method for thread synchronization is correct: First of all, I use two global variables to control the two threads, if a global variable is set to 1, that means the thread can start working, otherwise it must not work. This is checked by the thread running an infinite loop and if it detects that the global variable has changed its value, it does its job and then sets the variable back to 0 again. The main program also uses an empty while to check when both variables become 0 after setting them to 1. Second, each thread is assigned a global structure which contains information about the triangle that is about to be rasterized. The structures are filled in by the main program before setting the global variables to 1. My dilemma is that, while this process works under some conditions, it slows down the program considerably, and also it fails to run properly when compiled for Release in Visual Studio, or when compiled with any sort of -O optimization with gcc (i.e. nothing on screen, even SEGFAULTs). The program isn't much faster by default without threads, which you can see for yourself by commenting out the #define THREADS directive, but if I apply optimizations, it becomes much faster (especially with gcc -Ofast -march=native). N.B. It might not compile with gcc because of fscanf_s calls, but you can replace those with the usual fscanf, if you wish to use gcc. Because there is a lot of code, too much for here or pastebin, I created a git repository where you can view it. My questions are: 

This method stores the first value in the integer part (by multiplying by 1000) of the float, and the second value in the fractional part. Using the magic number allows you reliably to store values from up to and for texture coordinates this is more than enough. For a 2028 texture there is almost no precision loss using this method compared to the classic approach. The computing cost if the unpacking is unnoticeable. 

Here is a simple solution: Instead of calling everywhere , replace that with a function what has the following code: 

Changing to should solve the problem in this case but it's not a general rule. Here is why: Some math facts first, for matrix multiplication ; also So when you take a tutorial or code and you see in code and you want to do the same in the shader you have to think how and will end up in the shader code (transposed or not transposed). If it will end up transposed then you need to do to achieve the same result, otherwise A * B. If a matrix ends up transposed or not is dependent on the rendering Api and the matrix library you used. When you sent the matrix to the shader the api will copy a series of floats and interpret that as a matrix, but it doesn't know if the first 4 floats represent a column or a row in the matrix. 

I would not call this a that simple but here is now you can do it: Let's first have some notations (given the picture you provided): 

Here is an approach to get the direction regardless of the how many directions you have and how many space dimensions: 

To simplify the problem i think you want to check if any point ,, is visible from the players's perspective and in this case you don't have to take a reference point you can just do , 'BD' and . You would basically have to do this for each polygon in your scene which is not that efficient in the end (if you have a big scene). The best approach is to use spacial partitioning like a BSP tree (best for your case) but this is not that trivial to implement. If you scene is small or relatively small you can use the approach described above and you can even improve this by adding a 2d Grid to store references to polygons that you want to test. 

Set your target version level higher at manifest. You are setting it too low and that cause app start as combatibility mode. This is just android behaviour nothing to do with libgdx. 

At lower level optimization you can compare distance squared instead of distance. if (range^2 < distance^2) saves expensive sqrt. If you don't need to compare O(N^2) range checks this might be enough optimization for you. Reading linear data is fast. Doing simple range check (its just sum, dot and compare) is fast as hell you probaly just want simple and efficient code. If N is really large then spatial stuff is once again good choise but then you need to use time coherency too to gain something. Putting debris to buckets is O(N) too so you dont lose nothing but you gain memory efficiency and simpler code which mean faster devepment and easier debuggin. You can do this kind of math with linear data (even with mobile devices) around 100k without even noticing the time used, computers are fast with these kind of things. 

To make this work with matrix stack you might have to peek there $URL$ Zooming is just multiplier for viewport size there. I have done this with matrix stack too but its much cleaner to use camera class. 

So you want zoom just like in google maps? If you hover over city and zoom there cursor stays top of that city. This give smooth transition. 

Try to create new bodies so that they don't collide right away with others. Eg. its big problem if you create many bullets to same location at once. Another note: Libgdx have java to native wrapper for box2d. Performance is so much better that maybe you could swap there. 

Just use bounding sphere check.(you can calculate radius using pythagoras ) It fast as hell and also work with rotation. It's not perfect but never cause false culling. For ad hoc optimized version Intersector have some rectangle contain rectanle methods these can work too. But you need to calculate rectangle for camera frustum your self. 

EDIT In.LightDir is computed for each pixel. It is first computed for each vertex in the vertex shader Out.LightDir = normalize(mul(lightPos - In.Pos, Matrix3));, then it is interpolated across the whole triangle. lightPos is just the camera's position (which coincides with the light): 

After I get the result, I divide x and y coordinates by w to get the actual screen coordinates. Apparenly, I'm doing something wrong or missing something completely here, because it's not rendering properly. Here's a picture of what is supposed to be the bottom side of the Stanford Dragon: 

I'm making a collage of lots 16x16 renders on a 512x512 texture, of the same scene, from various viewing positions and angles, preferably lots of times per second. I've profiled my program (which contained a glDrawElements call per mesh), and the multiple glDrawElements calls seemed to slow it down a lot. In order to optimize, I've resorted to instanced rendering. However, the main problem I'm having is changing the viewport between, say, every 3 instance renderings, or so. I was thinking of adding a fourth matrix, which would scale the perspectively-projected vertices of a would-be 16x16 picture, translate them so that the little images don't overlap, and based on the little picture's position and size (16x16 pixels) on screen, use the `discard' command in the pixel shader. How do I scale the projected vertices from the current large viewport into a 16x16 smaller version of it and translate them inside the former at a certain position? Or, more clearly, how do I change the viewport during a glDrawElementsInstanced call, every N instances? EDIT Here's a visualization of what I'm trying to achieve: Keep in mind, I can't change the viewport as I want to do this during a call to glDrawEleemntsInstanced, every 3 instances, or so. How do I compute a matrix or what do I have to do to get the post-projection vertices scaled and translated so that I'll have the full image scaled in a 16x16 portion of the screen? 

Requirement: and must be normalized, and must be in the same space(radians or degrees) Also for 8 directions you must specify all 8 directions vector and the angle_threshhold must be 

interleaved: if is easier to understand and to manage memory wise and code wise. Instead of having 4 buffer you have just one and that's it. separate: there is no practical advantage in sharing resources, managing 3d stuff is difficult as it is and by having the separate streams shared would only create a nightmare. You might gain some memory by doing that but it's not worth it. on performance there might be a difference , at least on some Android GPU i know that you will have different results. 

So basically you want to know if any line , , , or intersects your polygon The naive way to do this is to define the polygon with a a set of segments you can use line-line intersection to test this: 

There is not ideal way of doing it, this is a common problem with meshes. To solve this there, are two different approaches: Considering that you have a vertex that has to be used with two different textures coordinates here is how you can approach the problem: 1:Duplicate the vertex and assign to each one the different texture coordinates. As a result you will have two vertices with exactly the same position but two different texture coordinates. How you store the vertex data is not really relevant at this point (interleaved or not). There is no way i know right now (someone correct me if i'm wrong) to be able to represent an indexed vertex buffer in order to share vertex position and different texture coordinates. 2:Separate the geometry in multiple parts and draw it with two (or multiple) draw calls but this has a couple of drawbacks. First need to create extra code to be able to share the vertex position, second you need to make multiple draw calls and this hurts performance especially on mobile devices. I think the first approach is the industry standard because in the end the extra memory used is not much of a problem. One way to overcome the memory usage is to use streaming and it's much easier to use that (not to mention that you can significantly increase the amount of geometry) instead of the second approach in which adds a lot of code complexity.