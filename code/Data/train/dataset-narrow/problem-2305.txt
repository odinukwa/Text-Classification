I previously wrote "So if a theoretical machine had access to a random source which its opponent could not predict (and could conceal its internal state from its opponent), then this theoretical machine would be more powerful than a Turing machine." But that argument takes place in a game theoretic setting (and idealization of some real world scenario) different from the context of the Church-Turing thesis. The simulation argument (explained by Martin Berger in the above discussion) could reduce that setting back to TMs by simulating all interactions between the random source enhanced Turing machines, but that misses my original point, about the random source being a separate idealization which can fail in its own ways. But if already clear concepts like higher-level formalisms gets dismissed, then there is little point in elaborating such fine interpretative points. 

As yet, only a theoretical algorithm exists, with a running time of $O(n^{42})$. (That is not a typo, and it is obtained through a “natural” dynamic programming solution to the problem stated there.) 

For $S\cap T$, you run both the machine for $S$ and for $T$, and accept if and only if both accepted. For $S^*$, see below for a proof that this is equivalent to the L=NL question. For $S.T$, you run a counter separating $S$ from $T$, and accept if there is a counter position for which the first part is accepted by the machine for $S$, and the second part is accepted by the machine for $T$. 

This seems to assume that $f(x_1,\dots,x_n)=\prod_i(\sum_j a_{ij}x_j)$, which might be yet another interpretation of "union of hypersurfaces". The hole in the proof here is that the "(worst case)" claim isn't proved. Note that $f(x,y,z)=x^2+y^2-z^2$ is a homogeneous polynomial, but it cannot be written in the assumed form. 

The last post reviews a paper which achieves $n^{O(\log \log n)}$ runtime for certain important families of groups, exploits much of the available structure, and acknowledges the above mentioned paper from 1994. Because the $n^{O(\log \log n)}$ runtime bound is both compatible with the experience that graph isomorphism is not hard in practice, and with the experience that nobody is able to come up with a polynomial time algorithm (even for group isomorphism), this can be counted as evidence that GI is not in P. 

Let $M$ be a monoid. The family $\operatorname{RAT}(M)$ of rational sets over $M$ is defined inductively: 

A non advancing input operation with $\epsilon\in\Sigma\cup\{\epsilon\}$ that doesn't read any input can be reversed 

Yes, in the same sense that if you prove that a specific NP-complete problem can't be reduced to a specific P-hard problem, then you also prove P!=NP. The only issue is that the reduction for which P-hardness hold must be "compatible" with the allowed encodings. From the information you give in the question, I conclude that LAL is P-time hard. The article Light types for polynomial time computation in lambda calculus by R. Baillot and K. Terui confirms this, by showing that DLAL (dual light affine logic) is a P-complete subset of LAL. 

Here is a clumsy description of the square removal and factoring tasks: Let $n\in\mathbb{N}^*$ be given in binary representation. Let $n=\prod_i p_i^{\alpha_i}$ with $p_i$ prime, $\alpha_i\in\mathbb{N}^*$, and $p_i\neq p_j$ for $i\neq j$ be the prime factorization of $n$. 

In Polygon rectangulation, part 2: Minimum number of fat rectangles, a practical modification of the rectangle partition problem motivated by concerns in VLSI is presented: 

The critical part to get the intended theoretical (scaling) behaviour of quantum computer is probably to achieve and maintain the coherence between the different qubits in the computer. Let me illustrate this with a hypothetical architecture. Assume that you have ready made modules with a fixed number of qubits (say 49=7x7). Further assume that each module for itself is able to maintain coherence between its qubits (by using quantum error correction), and reliably operate on its qubits controlled by a classical computer (my mental model is similar to this simple model of a finite quantum coprocessor I asked about before, but it doesn't really matter for this illustration1). Now assume that you scale your quantum computer by putting many of those modules together, using some suitable topology. The modules cannot talk directly to each other, but we may assume that the classical computer controlling those modules is able to freeze any quantum operation of the modules and then permute qubits between those modules according to the topology. Now assume that the quantum operation of each module randomly changes its global phase in a way uncontrollable and unmeasurable by the controlling classical computer. This is not even true decoherence (as would occur in practice - the density matrix formalism could be used for a better model), but I guess it will be sufficient to destroy the intended theoretical (scaling) behaviour of quantum computer. But if the qubits of the different modules stay perfectly coherent with each other, and the global phase differences between the modules are known to the classical computer, then I guess it will be possible to achieve the intended theoretical (scaling) behaviour of quantum computer. 

Edit: This answer was given in the context of the retraction of Babai's result, before he announced a fix. It suggests that the slight generalization of the graph isomorphism problem suggested by the string isomorphism problem is the really important problem. The implicit expectation here is that any reasonable algorithm for the graph isomorphism problem will lead to a similar algorithm for the generalized graph isomorphism problem. The generalized problem is polynomial time equivalent to the set-stabilizer problem, the group intersection problem, the coset intersection problem, the set transporter problem, ... The idea behind this expectation is that the generalized problem will occur in the recursive part of any reasonable algorithm, so it has to be addressed anyway. (And it is quite possible the the generalized problem is polynomial time equivalent to graph isomorphism.) Now Joshua Grochow's comments indicates that I wasn't successful in explaining the conceptual importance of the missing pieces from the string isomorphism problem. For infinite structures, it may be easier to appreciate that a valid isomorphism should not just preserve the given structure, but also belong to an appropriate category of functions (for example the category of continuous functions). For finite structures, the analogous phenomenon mostly occurs for quotient structures, where the appropriate category of functions should be compatible with the given quotients. The Johnson stuff is a typical example of such quotients, for example partition logic is working over the two element subsets of some base set. Also note that restricting the allowed category for the isomorphisms often makes the isomorphism testing problem easier, and that this might be the really crucial point for the importance of the generalized problem. The problem with generalizations of the graph isomorphism problem is where to stop. Why not generalize so far as to encompass the permutation group isomorphism problem? This question is really hard, since many non-trivial results for graph isomorphism will probably carry over to permutation group isomorphism as well. But here it feels more reasonable to treat computational permutation group theory as a subject in its own right, even if it has indeed close connection to the graph isomorphism problem. 

Bill Province's objection is that the proof of Proposition 4.1. doesn't use any special property of the sign matrix that wouldn't also apply to the adjacency matrix. More precisely, the following step in the proof is wrong: 

We don't even know how to reduce the string isomorphism problem to GI, and this is at least an isomorphism problem. Babai's proof showed that string isomorphism was in QP, so ... And what is being hard for QP even supposed to mean? Hard under polynomial time reductions? 

After detailed reading, I often end up with the conclusion that the approach is interesting and might have some merit, but that it is insufficient to reach to huge ambitious goal announced or hinted at in the abstract. I sometimes write the authors of such papers my thoughts, but the typical reaction is to totally ignore my email such that I don't even know whether a spam filter eliminated it before reaching the author, the best reaction is an "thanks for your kind words, I'm used to much more insulting feedback". Being totally ignored feels bad, but maybe it is an appropriate reaction to "proof refutation"? Are there good ways or places to post general feedback on "arbitrary ambitious CoRR papers"? What else can I do after I invested the effort to read such a paper? (And the hypothetical question: What could I do if I came to the conclusion that the result announced in the abstract is indeed correct?) 

I guess that I read too many ambitious CoRR papers. The problem is that those papers are not peer reviewed, but often sound interesting and pass basic plausibility checks. Or maybe they don't, and I just need to improve my plausibility checks. Here is a recent sample of such papers: 

No proof sketch that this is a polynomial time algorithm is given. The point where the algorithm might stop being a polynomial time algorithm is step 3: 

My own experience is that many P-complete problems look attractive and natural. My favorites are linear programming and Horn-satisfiability, but I guess that DLAL (or LAL) look even more attractive to you. But even so they are attractive, using them for resolving N!=NP is probably futile. More than one reduction of specific NP-complete problems to linear programming has been published, but the reductions turned out to exponentially increase the size of the problem. 

Even so normalising a univariate polynomial is trivial from a conceptual point of view, it's unclear whether it can be done in polynomial time (or even polynomial space). For multivariate polynomials, it's obvious that polynomials like $(1+x_1)(1+x_2)\dots(1+x_n)$ can't be normalized in polynomial space. For univariate polynomials, the details of the problem formulation become important. If the input polynomial is given by an arithmetic circuit and the coefficients are from $\mathbb Z$, then repeated squaring will give you abundant examples of polynomials which cannot be normalized in polynomial space. (PIT is often done over finite fields, which avoids this sort of space explosion.) The proof sketch that the algorithm works as intended has too many holes for being a valid mathematical proof. However, it is quite possible that there is a proper mathematical proof showing that the proposed algorithm works as intended, and this wouldn't even be a surprise. Here are some of the holes: 

It seems to me that the square removal task can be reduced to the factoring task, but that there is no way to reduce factoring to square removal. Is there a way to make this "feeling" more precise, i.e. some commonly believed hypothesis which would be violated if factoring could be reduced to square removal? But if square removal should indeed be easier than factoring (in the sense outline above), then the next question is whether it is an NP-intermediate problem (i.e. whether a polynomial time algorithm for it is known or not).