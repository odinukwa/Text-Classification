Now client1 can ping the server on 10.0.0.1 and client2 can ping the server on 10.0.0.3 despite the fact that the two clients share the same IP address. That's cool and all but our aim was to get the clients to talk to a single-homed box behind our multi-homed server. Lets add the single homed box, enable IP forwarding and set up NAT. 

The term VLAN is a bit confusing because it's used in two related but subtly different ways. Depending on context it can refer to. 

Putting connectors on the end of fiber is a specialist job. If you don't want to involve any specialists then you need to buy pre-terminated fiber terminated with the right connectors. You should avoid sharp bends in the fiber, I would also suggest running a duct rather than direct burial even if the cable you buy is advertised as suitable for direct burial. The individual fibers breaking out of a fiber installation cable will have very little protection against damage (far less than a patchcord does). If you buy a pre-terminated cable it should come with a preattatched gland that you can use to attatch the sheath and reinforcement of the cable to something solid and then a cover that covers the breakout section during installation. The proffesional way to deal with this is to fix the cable to a patch panel and then use patchcords to connect to the media converters. For a single link that is IMO overkill but you should take reasonable steps to ensure that the individual fibers don't get disturbed. Multimode fiber comes in different grades. I would suggest getting the higest grade (OM4) to minimise the risk of problems. Media converters are often fixed speed and will not work at lower speeds. So if one or both of the devices at the ends of the fiber links only supports 100 Mbps then you should buy 100 Mbps media converters. Remember to cross transmit and receive between the two media converters. The general convention with duplex patchcords and couplers is that they are always crossed (so you get an odd number of crosses between the end devices) but your installation cable will likey have single connectors on it so you will have to thing about the crossing yourself. 

Most mobile networks don't give out public IPv4 addresses to their users. Instead they run NAT at the ISP level. 

I do not know if the same trick will work on other operating systems. Here is an example that creates two network namespaces and a virtual network between them using the .0 and .255 addresses. 

"Socket" in this context does not refer to a physical socket, just to a data structure within the operating system. Still there are limits, thousands is easilly doable on a modern server, millions gets difficult. 

Is the bonded DSL system failing to deliver it's headline speed due to either poor line conditions, congestion on the network (either the DSL backend network or the ISP network) or traffic shaping by the ISP? Do you have an unusual workload (maybe lots of creative types uploading data) that means you are being limited by upload rather than download bandwidth? Do you have a small proportion of users who are using an disproportionate amount of data and/or using aggressive protocols like bit torrent? Or do you simply need more downstream bandwidth than the headline speed of your current bonded DSL setup. 

I will assume from your questions tag that you are using TCP. A likely explanation that does require some assumptions about your code is that it's an interaction between Nagle's algorithm (an algorithm designed to prevent unnessacery small packets) and TCP delayed acknowlagements (an algorithm designed to avoid sending unnessacery bare acks when an ack could share a packet with application data). Lets say your applicaiton sends data to the OS in two (or more) parts, first it sends a header, then it sends the actual data. I don't know for sure that this is what you are doing but it seems the most plausible explanation to me. For small messages the following sequence of events happens. 

Android's location services do not rely on IP geolocation. They use a combination of data sources including GPS (if enabled), cell tower IDs and wifi access points in the vicinity. 

Make sure you don't have any IP conflicts, renumber if nessacery (if you really have to there are ways of dealing with overlapping IPs but they are beyond the scope of this answer). Establish the tunnel between the two firewalls. The tunnel should have it's own IP addresses which are distinct from those used on any other network. Check that the firewalls can communicate with each other over the tunnel. Add routes on the two firewalls to send traffic down the tunnel. Add firewall rules to permit the traffic to be forwarded to/from the tunnel. 

This is a university so most likely originally everything was on public IPs but as a result of the IP crunch there was a need to introduce private IPs. Having the NAT at the network edge means that within the University's network traffic does not get natted. That means that internal connections within the University work just like they did in the old days when everything had a public IP. Hooking up a couple of NAT boxes to the edge routers and adding source-address based routes to direct traffic to the correct NAT was presumablly the easiest way to introduce NAT at the network edge for traffic sourced from private subnets while allowing the traffic sourced from public IPs to continue flowing as before. 

Each fills a different purpose and all three may be part of an overall solution. Lets start with the oldest concept first. Subnets are the IP worlds way of determining what devices are "assumed to be on-link". Devices within the same subnet will send unicast traffic directly to each other by default while devices in different subnets will send unicast traffic via a router by default. You could put each subnet on a separate physical network. This forces traffic to go via the router, which can act as a firewall. That works fine if your isolation domains match up with your physical network layout but gets to be a PITA if they don't. You can have multiple subnets on the same "link", but doing so does not provide a high degree of isolation between the devices. IPv4 unicast traffic and IPv6 global unicast traffic between different subnets will by default flow via your router where it can be filtered but broadcasts, IPv6 link local traffic and non-ip protocols will flow directly between the hosts. Furthermore if someone wants to bypass the router they can trivially do so by adding an extra IP address to their NIC. VLANs take an Ethernet network and split it up into multiple seperate Virtual Ethernet networks. This lets you ensure that traffic goes via the router without constraining your physical network layout. VRFs let you build multiple virtual routers in one box. They are a relatively recent idea and are mostly useful in large complex networks. Essentially while VLANs let you build multiple independent virtual Ethernet networks on the same infrastructure VRFs (used in conjunction with an appropriate virtual link layer such as VLANs or MPLS) let you build multiple independent IP networks on the same infrastructure. Some examples of where they might be useful. 

I would assume that the "IP Address WAN" is the IP that should be used on the outside port of your router. The "LAN" block will then be routed to that IP with the assumption that your router will pick it up and forward it to the LAN. Theres a couple of ways you could handle this, you could set up your router to have two subnets on the LAN, the public block your ISP has given you and a private block. The router would then be configured to do NAT for traffic between the private subnet and the internet while leaving traffic to/from the public subnet and traffic between the two lan subnets un-natted. Another option may be to have a single private subnet on the LAN and use explict NAT rules to map the additional public IPs to particular private IPs. Whichever option you go for your router needs to be flexible enough to support it. If you have bought a typical home router it may well not have the options you need. 

Look into the port protection features on your cisco switch. There are "storm control" options that can block a port if it sources too much broadcast traffic. There are mac address limiting functions that can block a port if it shows two many source MAC addresses. Try and find a middle ground switch that is cheaper than the ciscos but still high enough up the market to support the spanning tree variant you use. If you have a spare router/firewall port put the trailer on that with it's own subnet. Ethernet storms won't cross a router. 

You can bring up a BGP session (though you will likely have to override the default TTL limit), the problem is actually sending the data. "next hop IP address" is a local concept, used to look up the interface and MAC address (or equivilent for other interface types), sometimes used to look up a route in other routing protocols (for ibgp used with an igp) it never actually appears on the wire. So to have meaningful peering you really want a connection between you and your peer that lets you send IP packets to each other without any intermediate routers looking at their IP headers and making routing descisions. That connection could be a dedicated point to point link. It could be a peering lan provided by an exchange point. It could be a tunnel of some sort. Note that peering over tunnels has it's downsides, particularly if you ever get any downstreams it can easily cause loops. 

Wallports with punchdowns are generally only suitable for solid core cable. Plugs may be suitable for solid, stranded or both. Check the datasheets carefully before buying any plugs (and if the datasheet doesn't say go with a different brand. Criming plugs is a fiddly PITA, punchdowns are much easier. Generally running cable is much easier if it doesn't have plugs on the end. 

There are various reasons for using NAT but the big one is to allow you to use private IP addresess on your internal network while using a smaller number of public IPs (maybe only one) to talk to the Internet. Whether or not your internal network is carved up into subnets is orthogonal to whether you use NAT at the gateway between your network and other networks. 

Note that the next-hop IP address is a purely local concept, it never becomes part of a packet sent on the wire. If the packet is to be sent out on a multipoint link layer (e.g. Ethernet etc), the OS then looks up the next hop in it's arp (ipv4) or neighbour discovery (ipv6) table. If it finds a non-stale entry there then it has the MAC address it needs and can send the packet. If it doesn't have a usable entry it puts packets destined for that next-hop on hold and sends out a request to find the MAC address. The mechnisms here differ a bit between v4 and v6. In v4 arp requests are sent. This is normally broadcast but in some cases if the host has a stale entry it may try a unicast request first and only fall back to broadcast if that fails. The reply is normally unicast. In v6 neigbour solicitation requests are sent to a multicast address generated from the next hop address. The target replies with a unicast neighbour advertisement. Hosts can also send neighbour advertisements to the "all-nodes multicast" (aka effectively broadcast) group to refresh entries in their peers neighbour discovery caches. 

The answer will almost certainly be found in the routing table of the router that sends the packet in an unexpected direction. In your case that seems to be the "central router". 

Routers don't "ask" each other about routes when deciding where to send a packet. The routes a router knows about are determined in advance, either statically or by routing protocols. To reduce the size of routing tables summarisation techniques are employed. Within your site you need routes for each of your subnets. Ideally your ISP only needs a route for your site as a whole and the internet only needs a route for your ISP as a whole. In reality things are messier than that. Sites and ISPs will grow and therefore end up with multiple IP blocks that cannot be aggregated. This is especially a problem with IPv4 due to address shortages and the resulting tight allocation policies. The extreme case of summarisation is the "default route". A place where all packets for which no other route is known get sent. Some routers have no default route. They have an explicit routing table built over BGP that covers the whole internet. This is a big table (over half a million routes) which needs a beefy router to handle. This would be the normal setup in the "core network" of a provider. Other routers will only have local routes and a default gateway. Any traffic heading towards other providers will be sent to the default route. This would be the normal setup in the "access network" of a provider. And of course there are possibilities in-between. For example a smaller ISP using older routers that can no longer handle the whole internet routing table may choose to pull in only part of the internet routing table and use a default route to a transit provider to handle the rest.