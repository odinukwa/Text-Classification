Generally, to render extremely large meshes you want to subdivide the data into smaller, separate meshes and render each of those individually. This can be useful to alleviate memory pressure (although it won't always do so, in practice), but it also allows you to perform some culling on the large geometry to avoid bothering rendering huge chunks of geometry that are not, for example, visible. Note that you probably don't want to just split the buffer by taking the "first N" vertices followed by the "next N" vertices and so on, as in general this will produce a subset of vertices that isn't logically grouped well for culling. You'll have to load the entire set and intelligently subdivide it, perhaps into a 3D spatial partitioning structure like an octree. (The reason this doesn't always alleviate memory concerns is you still need to keep the data somewhere on the GPU if you want to be able to quickly render it, and that might actually introduce more memory pressure due to the small per-buffer overhead. You can evict things onto the CPU but then you start trading on the performance cost of resubmitting the geometry when you need to render it, and potentially fragmenting the GPU's memory space, and so on.) 

In addition to GDC, which you already noted, there are the spin-off conventions (GDC Europe, GDC China, and GDC Online in Austin, plus the Serious Games Summit). There's also the LOGIN conference, which caters specifically to online games (casual Facebook games and MMOs, et cetera). You've also got Microsoft's Gamefest and the recently-launched PAX spinoff, PAX Dev. Then there are the more localized conferences, such as the Christian Game Developers Conference or the Russian Game Developers Conference or something like IndieCade. Finally, many game developers would also be interested in more generalized programming/software/technology conferences such as Build or GoingNative. Most conferences offer a variety of different sessions or talks that will cater to a range of skill levels, so you can usually get something out of them if that's your thing. If you are unsure, try browsing the session material from previous years to get a feel for what the conference might involve -- many of them are expensive so it's good to have an idea of what you're going to get out of them beforehand. I personally feel like the best benefit from most of the conferences I ever attended was networking, and not so much the sessions themselves -- unfortunately, very often lectures and presentations will be necessarily high-level. But the people you meet can be valuable contacts elsewhere in your career. 

The "pure aggregation" approach described by West in that linked article eschews an "entity" object altogether. There are components, floating around in memory, but they are tied together only by implicit relationships, if at all. One way to do this is a so-called outboard approach. In such a system, components are held by systems that manage or otherwise control them (I use the term "manage" here, but you shouldn't take this to mean I'm suggesting that you have a bunch of *Manager classes to hold component types). For example, your physics system may hold on to a bunch of things representing each rigid body in its simulation world, and may expose those things as PhysicsComponents. The components can be the actual objects handled by the subsystem in question, or they can be proxies for those objects, as needed. In such a system there isn't necessarily a need for an "Entity" class to hold a collection of references to the components that comprise it; instead a notification is raised concerning the creation or destruction of an "entity" and each subsystem that handles components looks at the description of the created/destroyed entity (which is typically loaded from some data) and determines if a component is necessary for it. One of the advantages to this approach is that you get really good locality of reference for each component. Unfortunately it's a bit weird, overall, and not the most friendly flavor of component-based entities I've encountered. Sometimes it is really convenient to have a real object that represents an entity, even if that object does little more then aggregate weak references to components that are still held by other subsystems (if nothing else it provides a easy way to route messages between components). There are several good ways to implement component oriented game object systems; it really, really, really helps if you have a solid idea of the requirements you want out of your system -- you can look at what popular frameworks like Unity do for examples. Without setting strict requirements for yourself, you may run into the problem of endlessly "designing" the system without ever really building it, trying in vain to hit upon the perfect implementation. For whatever reason I've seen this a lot with component systems. 

Beyond the given ranges, it is up to you to interpret the data as whatever "units" you see fit, depending on the data you wrote into the depth buffer in the first place and what it means to you. 

Brainstorming is sort of supposed to be loose and unstructured in order to facilitate a free flow of ideas. That said, it's usually possible to have an agreed-upon, firm guideline for what you're brainstorming about (game ideas, solutions to a technical problem, et cetera). Everybody should be aware of this guideline and do their part to ensure the meeting doesn't drift too far into the territory of brainstorming about things that are not germane to that guideline. During the meeting you should encourage people to both propose new ideas and to build upon ideas others have proposed. Usually you'll want to avoid criticizing ideas too much, though. One way I've seen to do this (although I've never done it myself) is to do things in two phases, where people first propose ideas by writing them on sticky notes and quietly sticking them to a whiteboard and afterwards all the ideas are discussed and built upon. Tools like whiteboards and sticky notes can be invaluable as means of expression in these sorts of sessions. Almost as important as how you run the meeting is what you do afterwards: even the most haphazard meeting will probably produce at least one reasonably actionable idea, so it's important that you have somebody dedicated to capturing all of the decent ideas and recording them in some notes somewhere. If you search Google for "brainstorming meetings" you get a lot of results. These two seem potentially interesting: 

When you draw your 3D background model, represented by the ASCII , it normally ends up looking something like this: 

So, it sounds like you don't actually want a texture atlas per se, but instead just a generalized technique for performing a UV unmapping of an arbitrary mesh. Unwrapping can be used to create texture atlases, but not all texture atlases are UV unwrappings, which I why I bring up the distinction. Unwrapping is a mesh parameterization problem. Specialized solutions exist for simple cases, such as spheres, but arbitrary polygonal meshes are non-trivial. That said, it is a solvable problem because most modelling tools have the capability to do this kind of unwrapping. For example, you can check out Blender's documentation on unwrapping for example (in fact, were you particularly adventurous you could even poke around in Blender's source code to check out their implementations -- but that's probably crazy talk). There's also this tool. Blender uses the Least-Squares Conformal unwrapping technique, which you can find several academic papers on. This paper is one of the better ones. There is also the Angle-Based Flattening technique, which is related (though older, I believe). This page may also be of some utility. In particular, on that page you can find the OpenNL library which provides a C++ implementation of an iterative LSCM solver (it's the only one I know of outside of perhaps a few papers that might include a pseudocode implementation). 

There are no overloads for that take a pre-allocated memory buffer. D3D will generally want to own the memory its resources, for various reasons. Even methods that accept "user" data pointers, like tend to guarantee that the data referred to by the user pointer has been "completely accessed" by the time the function returns, which allows for the API to copy the data if needed. If there was such a method of creating a surface with a pointer to the surface bits, you wouldn't actually avoid the copy by using it. You'd just avoid having to write the copy yourself; D3D would do it internally. 

There are plenty of resources for culling techniques of this nature -- ideal search terms include phrases like "2D culling quadtree" and "2D spatial partitioning." A basic approach will use frustum culling (the link describes a 3D approach, but in 2D this boils down to basically a rectangle-in-rectangle test) and a quadtree to partion space hierarchically -- the hierarchical approach allows you to trivially reject large batches of objects, testing only those that are near the viewable area. As long as you update the spatial partitioning structure as objects update, this is suitable for dynamic scenarios as well as static ones. You may also be interested in this article on an alternative approach (although its old), or this article on using the slightly-more-advanced kd-tree for partioning space. See here for a handful of other scene management structures. 

A simple way to avoid turning off players who don't have the time available to invest in grinding is to remove grinding from the game as much as is reasonable; keep progression curves linear or shallow. But, I think you're conflating "casual players" and players with players who simply don't have as much time as they'd like to play. There's an overlap, certainly, but fundamentally they are different demographics. Casual players tend not to care that other players have invested more time, except if those other players are their friends and such they feel like they "can't play together." You can help reclaim their good will by including mechanics that make it worthwhile for higher-leveled players to return to previously-visited or otherwise under-levelled content and play with their low-level casual friend. You can also include mechanical benefits for activities casual players are more likely to do, such as explore the world. Simply providing experience for discovering areas or engaging in social activities can go a long way. In Guild Wars 2 we did both of these things (downleveled players to content so it was always at least marginally challenging, and reward non-combat gameplay), and it worked rather well. The other market you're looking at are those who would love to invest entire weekends or more into your game, but can't. Maybe they have a family or other responsibilities, for example -- a very common method for appealing to these players is to offer microtransactions allowing them to catch up to players with more time. This also has the advantage of providing residual income; income via microtransactions can often dwarf that of subscription fees if implemented in a fashion that does not offend the majority of your player base. Of course that last part is the tricky one. When considering a microtransaction that is designed to catch up players without as much gaming time, you have to make sure you're offering them an acceleration of some progress and not a direct purchase of that process -- in other words, sell experience boosters that increase XP gain rate, but don't sell levels or experience directly. This reduces the likelyhood that it will be used by both the time-constrained and extremely hard-core players, which in turn reduces the likelyhood you'll have to field a slew of "pay-to-win" complaints. Allowing progress to be gained in some limited fashion while not active in-game is something else you could look at -- EVE Online does this, allowing skills to be trained regardless of whether or not a player is logged in, but requiring you to log in to change what is trained. 

is an abstraction over some concept in the underlying graphics API. In OpenGL that concept is the context and in D3D it's the device. In these underlying graphics APIs, creating textures is an operation you do from a context or device, and so the SDL abstractions over those APIs must carry forward that relationship (or weaken the API). Why do the underlying graphics APIs work that way? Because the context or the device is sortof like a representation of the graphics card itself, and the graphics card will be where most of the important texture data actually lives, and thus creating textures has to be done via the interface to the graphics card. 

Personally, I've never seen a "generic component" like you proposed out in the wild for anything real. It seems like a terribly poor choice, if for no other reason than when you have generalized the component so much you might as well reduce the overhead by making the entity the thing that stores all those properties, and namespace them: 

But I know of no cases where a game operating in the US (at least) has tried to go up against this law and get it sorted it out in the courts. Consequently, everybody seems to feel like the safer thing to do is simply avoid the possibility by preventing cash-outs and prohibiting secondary markets, rather than deal with having every aspect of the game scrutinized constantly and possibly repeatedly by gambling lawyers. But the legal specifics are just one aspect of the problem. Another major part of the issue is that when you start allowing cash-outs, you're building more than just a game. You're building a game with a pseudo-bank attached to it. The logistical implications are many. Primarily though, this means you need to be able to keep sufficient liquidity of assets in order to serve all your potential cash-outs. Game studios aren't really banks (and even then, banks are only required to keep 10% of their outstanding liability in the US at least), so they're not FDIC-insured. If everybody tried to withdraw what they're owed from the game at once, the studio would probably fold unless they kept all of that money readily on-hand. And since nothing like the FDIC backs game studios, most of those players would get nothing. Even having that money is a problem. If a game allowed you to generate real money from in-game currency or items that did not at one point originate from putting real money into the system, you'd have to produce that money from somewhere (your profits or savings from elsewhere). Even if you do restrict the system so at any given point, only cash that has been put in (by somebody) can be taken out (possibly by somebody else), backing 100% of cash-out severely curtails your ability to make any profit off that money... and micro-transactions are an appealing and reliably form of generating profit for a studio. This means the studio can't funnel that profit back to shareholders or employees (in the case of a profit sharing plan). The studio could invest the funds, certainly, but you wouldn't want it invested into anything high-risk because of the chance of dropping below the balance required to back 100% cash-out. The potential earnings on a very stable investment are much less attractive because of the typical lifetime of a game studio (short), to the point where that investment capital (that money players are putting in to your game) seems like a far better place to take profit from than a piddling amount of interest on said capital. So games just stay away from it. It's less stressful.