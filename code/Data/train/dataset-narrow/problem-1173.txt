First of all, please check whether it is possible to use a newer version of SVNKit. According to mvnrepository, the used version is dated of March 2009, which is quite dinosaurian in our days. The obsolete version might explain the long delays you are experiencing (I underline might explain, because there might have been a lot of optimisations compared with the most recent version, but I don't have any precise idea about it). Another explanation may be the network communication lags with the SVN server the app is connecting to. It hugely depends on your network conditions and it is possible that there is no remedy for that. To prove that the problem is related with networks, roughly and manually, the calls of methods on field can be surrounded with time measurements, as well as method entries and exit points, for example: 

I made a implementation using pattern in . I was wondering if this could be improved. I have states - , , , , and . A has the task of looping through events which would cause a change in . The itself is a , where one of the input is from the user via Command line whereas another input is using . 

I have written some basic implementation of a Minimum Spanning Tree using a indexed minimum priority queue. For the implementation of the Priority Queue I used Sedgewick's Tutorials. However, it seems that I am passing a lot of arrays around for the priority queue. Here, is my code snippet. Could someone point out the obvious faults and also suggest a better abstraction for the priority queue. (Since Sedgewick's Tutorials were in Java, I translated them to C and I think that my implementation is not good.) 

It looks like the good/bad old imperative style. In Scala, and others are functional style replacements for traditional . The for-comprehension is a sort of shortcut allowing to iterate, filter and map (with ). For example: 

This will need only two loops, one on and another on . The main logic of the improved method will make a single iteration on the keys of map. The matching of keys in the maps will perform much faster: 

The methods prefixed with should be renamed to because assertions are what they actually do. The prefix is often used for test cases annotated with . 

Here I suppose that member of this class can take only a predefined set of values (and even should be transformed into an !) and any value that is not in this set denotes an internal problem that puts the application into an invalid state. BTW, since the original method is , I suppose that is also a static member and therefore should be renamed according to style conventions. And I also suspect that there is some misuse of statics, but can't say more about it without having the entire code. Second, we rewrite the original method: 

It's possible to improve on this using gwnum instead of GMP. The former is much faster at compositeness tests for large inputs (over 4000 digits). The downside is that programming correctly using it is much harder than GMP. Typical use in 2016 would be using something like the GMP program to do the selection and sieving to output candidates, then use a script running PFGW to weed out composites using its fast Fermat test, then using GMP again for a good primality test on the results to confirm. 

Unless I'm misunderstanding what your iterators are doing. A simple SoE will have something that looks like: 

In general it looks good to me. I'd clarify the comments a bit more. Q=1 is typically used for the extra strong Lucas test, P=1,Q=-1 is used by about half the cases for the standard or strong Lucas test (the rest have a different Q). Some info on the various tests can be seen on my Pseudoprime Statistics page. What happens if n is even? For example, Lucas_5(6,1) = (1189,6726). Mod 1000 should yield (189,726). But the routine gives us (689,726). This is an artifact of the halving method used. My solution was to use a different, slower, method in that case, since it's rarely used (never by a standard primality test, but there are more uses that just those). For D=0, we can return a solution. See the Wikipedia page. Check the cases where P and/or Q and/or D exceeds n. It looks from a quick test that the returned Q_k values are out of range for k={0,1}. Doing a check and mod up front may improve performance. Consider instead of using libmp. Up to you, but I like fewer dependencies. I don't know all the tradeoffs between the two however. For the Q=1 case (used by the extra strong Lucas test) there is yet another method that can be faster. If D can be inverted mod n, then we can calculate V_k with 2 mulmods per bit, then compute U_k using the inverse. I hate to add more cases, and of course you'd need to benchmark to see if it worked better for your infrastructure and use. 

Moreover, other referenced functions (, ...) are flat, so all of the pieces are well kept at same level. Other Considerations Returned values. The return type from seems suspicious. I hope to understand the meaning ( for successful result, for no solution found), but the returned values are hugely falsified. will return an Int only from the last call of , the others will remain hidden. Since the solutions are output into the console, I'd suggest to return nothing from : 

2) Implement instead of creating an instance of from another. Calls of will thus be replaces with 3) Do not check for strict class equality in , but use : 

2) It looks like you are using JPA. In a Spring repository, you can achieve the same result by using , without detailing the implementation: 

I was going through this tutorial for Pretty Printing a binary search tree and decided to implement my own version. Here is my implementation. This version works only for trees that are complete binary tree. I would like to know what all optimisations can be done (errors present can be removed) in the code. 

My program doesn't work for all the test cases though the logic behind it seems to be working. In my implementation the list of number for any value becomes so big that I get a for larger numbers ( onwards). I will try the algorithm suggested there, however, I wanted to see what I could improve in my code. This is how my implementation looks like - 

Once happy with what you have, you may find it entertaining to look at some other solutions, e.g. Haskell, Perl serial / parallel, PARI and Mathematica Additional info Dec 2016: Example times for fast implementation in serial, time for first n Fibonacci primes: 

The problem is that for arbitrary 18 digit numbers this is still going to be slow and may or may not hit your target time (it's about 0.11s each for 1000 numbers on my computer with 10 other computations running). I can speed that up about 3x using primes to 2000 then a mod-30 wheel. Going to Pollard-Rho makes it run thousands of times faster. If you really need it fast, you're going to want something like Pollard's Rho, Brent's improvements to Rho, P-1, or SQUFOF. Trial division (even efficiently done) is just too slow for general numbers this size. The basic Pollard's Rho is pretty simple -- the only real trick is doing an efficient . Brent isn't too hard -- more or less just running the gcds in batches with backtracking when needed. For this size, P-1 is probably going to be slower than Rho/Brent. SQUFOF is more complicated to implement. An additional complication is that now you need a primality test to know when you're done (deterministic M-R with at most 7 selected bases, or BPSW). It's possible to skip that by just using Rho etc. opportunistically, but that doesn't fully utilize the idea. 

I have moved some code around (I didn't have enough time to fork your repository, will do that later), so that it appears cleaner. Here is an example how you can abstract repeating code into new methods. 

I was solving this problem on HackerRank and managed to make a working implementation. The question in brief can be described as follows - 

There have been suggestions that for Swing we should use something like for making the UI visible. So instead of using 

For e.g. Consider the number - , I first get all the decbinary representations of ( to positions) i.e. 5 and prepend (the value at position). The numbers formed are . Then I reduce to and get all combinations for - , then is reduced to and all combinations of are - . Thus finally, all the combinations of are - .