to ensure that when you calculate the normal of a triangle it points in the right direction. To use the triangle example from above, if you always calculate your normal vector as follows, the normal will always point out from the front of the triangle (towards you for the left triangle, away for the right). Note that to obtain a unit normal, which is desirable for lighting and collision, you also need to normalize the vector. 

I'd leave that up to the physics system. When it's integrating the acceleration and velocity, it can also add gravity. Something like this could work (don't actually use Euler integration, this is just for simplicity's sake): 

According to OpenGL Insights there are a couple ways to efficiently stream data to a VBO. A simple but efficient method is to "orphan" the buffer (allocating a new piece of VRAM in the process) and refill the entire thing. This allows the current frame to use the old data while you can upload the new data. 

Copy the depth information to the la-buffer and then render normally to the la-buffer using forward shading. All you need to do to copy over the depth information is add this to the light accumulation fragment shader: 

In lieu of a typical implementation of entity-component systems, I've gone the data-oriented route described by Jason Gregory in Game Engine Architecture. This works really well for common properties that need to be present in practically every entity, like position, model information, and health. 

This new heuristic will make your actors try to path-find around areas they perceive as dangerous. This technique is really great because it works with any heuristic-based path-finding algorithm. Note: Path-finding algorithms like A* may need a little tweaking to allow the algorithm to back-track in case it comes across an area deemed too dangerous to cross. 

I think I have figured it out. I'll process the content using a job queue and send thread-safe messages to the main thread to tell when an asset has loaded. When the assets are needed, the engine will wait (if necessary) for all the required assets to load and then continue with business as usual. 

SDL2 provides no facilities for computing lighting, so yes, if you don't use shaders through OpenGL, D3D, etc. to do deferred rendering, or rendering a scene of any complexity for that matter, you're going to leave all that embarrassingly parallel and SIMD work to the CPU. The concept is exactly the same whether you're doing it on the GPU or the CPU. Instead of summing each light's contribution in a loop over the objects, you're summing each object's contribution in a loop over the lights (where much of the object's data is cached using the G-buffer). What you should get out of this is that you don't want to do any sort of 3D rendering without hardware acceleration, which on the PC requires you to use either OpenGL or D3D. 

Because operations dealing with objects and their locations, such as collision detection and filtering nearby objects, are so heavily used in games, it is common practice to use one or more spatial data structures to describe your world. Some examples of these structures are grids, octrees, or the classic scene graph - a tree storing relative transformations in each edge. They are a perfect example of the tradeoff of using a little more memory to reduce algorithmic complexity. These structures are useful because they allow you to exclude large numbers of objects from queries simply based on their approximate locations. For example, with an octree or a grid, you only need to be concerned with objects in the cells that intersect your query volume, and you can discard the objects in other cells, allowing you to prune lots of objects using only a few AABB checks. However, I would refrain from having these structures actually store the objects themselves, and instead store pointers or references. If you do this, you can keep your objects tightly packed to improve iteration performance while allowing your scene graph to constantly adjust as your objects move around. 

While a tank is not quite an ideal differential drive machine, this should be a sufficient approximation. Translating this into code using a simple Euler integration: 

I've added functionality so that I can render to a framebuffer (for post-processing and stuff). I can successfully render to my framebuffer and then render that framebuffer, but anything with a shader does not render to my framebuffer. Rendering with the same shader worked before I added the framebuffer step. Here's how I create my framebuffer: 

With CSM, you have a number of shadow volumes of different sizes that overlap so as to cover the entire viewing frustum. Ideally, they would be sized and placed so that each screen pixel maps to at least one shadow texel while minimizing overdraw. 

The easiest way would be to use the flood fill algorithm. In your specific case you will probably want to fire off two different flood fills, one to the right of Pacman and one to the left. Whichever one is suitable to fill (the smaller one, the one with no obstacles detected, etc.) is filled and the other is discarded. 

A view matrix originating from the light's position and pointing in the direction of the spotlight A perspective projection matrix that encompasses the light volume 

A naive (and inefficient) approach would be to calculate the distance to every enemy unit, find the minimum, and ensure that it's within 100 m. Then you have your target. However, this means that for every N buildings and M enemies, you have to do N*M distance tests. One optimization you can make is to use a distance squared check to eliminate the relatively expensive square root operation. So instead of checking the distance against 100 m, you check distance^2 against 10,000 m^2. This will save a bit of time but you're still working with an O(N*M) complexity. Here is where spatial partitioning comes in. Now, you can do a broad test to first find which partitions may potentially intersect with the building's range, and narrow down the list of candidates for enemies to attack significantly. Applying both of these optimizations should give you a significant average-case cost reduction. 

If you're running your server from a remote host, you'll absolutely need to use the first option. Otherwise, I would go with the second option for simplicity's sake. Keep in mind that if you use the first option, it's possible that hackers will be able to shut down or modify your server. At the same time, though, you also get the added benefit of allowing administrators other than you to perform these operations. 

The game‚ü∑HUD relationship can be pretty well-expressed using the Model-View-Controller (MVC) paradigm. The Model is the programming logic, and has no concept of user interaction. A View is a way of somehow communicating information from the Model to the user, while a Controller is used to let the user interact with the Model. 

Since the vector cross product is conventionally right-handed, you can verify the normal direction yourself using this method with your right hand: 

In this example, OnCollision is registered to the collision system, which activates it (and the other collision handlers) when two entities collide. As you can see, this simple Unlocker class added a new set of behaviors dependent on the player, keys, and doors without creating any coupling between the entities themselves. This is especially important for object models like composition where entities are not able to implement their own behaviors. 

To "launch" a projectile at a certain direction and speed, you can calculate the velocity like this (assuming direction is in radians): 

I would create an input component and various other action components, like walk, jump, crawl, weapon, etc. The input component would have fields that describe how the entity wants to move, such as: walk left, jump, and attack. This can be supplied by the keyboard, by an AI, or over the network, which is implemented as a control component. This three-tiered system allows for easily customizable abilities and swapping input sources. Want an entity to not be allowed to jump? Remove its jump component. Want to allow an entity to do a charge dash? Give it a component that does that, and acts on the attack+run signal. Want to allow the player to mind-control an enemy, like the Ghost ability in Kirby Squeak Squad? Just swap out the AI component for the keyboard component. 

I think that the most important thing a boss fight brings to the table (in the gameplay sense) is a test of new abilities under stressful conditions. For example, if the player learned to climb and shimmy in that level, the boss of the level requires the player to climb up, possibly jumping between moving limbs, to hit its weakpoint. This is common in item-based games like Zelda or Metroid where the boss of an area requires you to use one or more items that you acquired in that area. Another common use of bosses is to serve as "guardians" of the next area. Many RPGs use bosses as barriers between two levels, but they are mostly just damage sponges because the player doesn't really acquire new abilities as they progress. This still allows the player to feel a sense of progression because the bosses have increasingly greater health and damage output to match or induce a character's level. 

This depends on how you are going to structure your framework. I prefer keeping components as pure data and defining behaviour through systems. If you need two components to interact, just make a system that operates on those two component types. 

To store the components, I use a struct-of-arrays approach where each component type is an array (possibly with another layer of indirection) and each entity is an index into all the component pools. All the systems have access to this data, and accessing components is as easy as . 

You can split up your data into heavy and light. Heavy resources are things like shaders, geometry, and textures, which use a lot of memory and have a high cost associated with changing them. However, light data like texture offsets and blending colors are often changed and quick to change. Thus, you can split up your "renderables" into two distinct sections. One section holds references to the heavyweight resources, and the other section holds unique, lightweight data. This carries some additional benefits as well. For example, the sharing of heavy resources means that renderables can easily be batched together to cut down on state changes. As well, if enough objects have the same lightweight data signature and the same heavyweight resource references, they can easily be selected for instancing. Finally, the heavy resources, which would probably be handled by one or more resource caches, could be reference counted. 

I don't know how else to describe it in the title, sorry. My sound engine currently works perfectly with listener positioning and sound positioning to create the attentuation and panning effects. At least, for short sounds. I converted an .mp3 to .wav to test out playing a song from a specific point, but suddenly OpenAL ignores that the sound and the listener are not at the same place and just plays the song at full volume right in the center. Has anyone ever had this problem before? If so, just what is the problem? EDIT: If it helps, the song is stereo and the sounds are mono, all at 16 bits per sample. 

Disable writes to the depth buffer (although you may want to have a separate depth buffer for effects, I'll explain later) Decompose your object into convex pieces (unnecessary in this specific case, a box is already convex) Sort the parts of all objects from farthest away to closest For each part in order, draw the backfaces and then the frontfaces (or just the frontfaces) 

I'd send "jump", reason being that it applies to each keyboard, gamepad, and AI. "space keydown" might be useful in some cases, but I can't think of any right now. 

Using a tessellation shader, you can efficiently build useful representations of Bezier curves and surfaces all on the hardware. You can do this in conjunction with fully dynamic tessellation levels to implement automatic level-of-detail. It's a very simple concept. I'll illustrate using a Bezier curve tessellation although the principles extend trivially to Bezier surfaces. 

I would create a system where there is a central object, , that keeps track of all objects with a certain interface, . If a class implements this interface, it will be able to save its persistent data and then read it in again when the object is loaded, thus enabling save games. The interface will have two functions: one for saving, one for loading. Both functions will have a stream parameter so they can write and read their own data without needing to know where that data is going. The is responsible for managing those streams. This decoupling allows 99% of the code to stay the same even if you decide to change to save games stored on the cloud; simply use a network stream instead of a file stream. You could also then apply compression or encryption through the . Additionally, each unique serializable object should have its own unique ID. This way, the can map an ID to an object and be able to load the objects in the correct order or at least be able to hand the correct data to the correct object. These IDs can be determined automatically by the game's level editor. For example, a treasure chest object will have a boolean flag that indicates whether it has been opened, or, like in most Zelda games, a flag to indicate whether or not it has appeared after the player has solved a puzzle. The chest class will inherit from the interface and implement the two functions. The function will read the two flags from the stream, and the function will write the two flags from the stream. Remember to always read the data in the same order that you write it in. 

I would allow the player to choose which video card to use, i.e. through a drop down list in the options menu. You can use the GPU with the highest detected VRAM, clock speed, etc. as a sane default. You could go further and prompt the player to choose between "high performance" and "power saving" (chooses the lowest-spec card) for the default when the game is first started up, and then let them be more specific with their choice in the options menu. This is a simple solution that also won't annoy the player if it chooses the undesired video card, as it is easy enough for them to change it if it picked the wrong one. 

We can think of the game logic as the Model in this instance. Actually, many game architectures already use an approach similar to MVC. The rendering, sound, and input systems are usually decoupled from the physics and logic, and so it is easy to fit in the HUD as a combination of a View and Controller (in many games the HUD doesn't even need to be a Controller). The implementation of an MVC architecture varies wildly. A simple game will likely have the Views directly read data from the Model and the Controller will call certain functions that the Model exposes. If your game uses a physics engine, it's likely that you'll have split up your game loop so that the physics and logic runs at a constant rate, while the input and rendering are synchronized with the monitor refresh rate. In this case, the Model will spit out game state snapshots which the View will read and interpolate between, and the Controller will queue up events into a buffer. The advantage of using MVC is that your game engine is separated into two main decoupled areas. The Model is one, and it is isolated from the workings of the View and Controller. In many cases, the View and Controller overlap, such as with the HUD, so they are the second layer. It's usually fine for stuff like that to be coupled more tightly, as the Controller needs to know that you've actually clicked within some rectangle to build a unit, for example. Incidentally, the View-Controller layer is the only one that should need to change if you are porting from one platform to another. The Model doesn't care whether you're playing on a PC, a Mac, a Playstation, or an iPhone. You can build different Views and Controllers to deal with different rendering libraries or input devices, and use them with the same Model.