You could use a lookup texture for the alphabet. Then draw a quad for every letter and select the right letter by texture coordinates. You don't use transformation matrixes on this of course. This is a simple way to get started. Advanced font rendering is a complex topic and you might want to use a library like FreeType for that. However, the basic principle stays the same. It just generates the lookup texture for you from font files. The second part of your question about graphical user interfaces is another story, so I won't explain that in much detail here. Please open another question for this if you have further questions. But basically it is the same, you draw an unprojected quad and texture it with whatever you like your interface to look like. You can then draw text on top of that. Another interesting approach is to use web technology to define your interface, there is a webkit based library called Awesomium of this. 

Just for interest, when sampling simplex noise in any given dimension, would the sum of all samples run towards zero? 

Normally, physics simulation is done in three phases. First, in the so called broad phase, possible colliding bodies are determined. That is just to save computation time in the next step. Then, in the narrow phase, actually collisions and constraints are detected. Afterwards, they get resolved. Implementing such a physics simulation is a big effort, which I don't advice you to take yourself. Since you used the tag, you may use the physics simulation integrated in that engine. Otherwise, there is a very popular open library called Bullet Physics. If you want to implement something yourself, especially for learning purpose, you can drastically simplify things for now. For example, don't calculate triangle accurate collisions for your bodies, but just check their bounding boxes. Those can be constructed by their minimum and maximum coordinates in all directions. Or instead, you might want to treat every body as a sphere in the physics simulation, only represented by a radius. 

To provide you some advice nevertheless, I recommend to start with low level graphics programming. There are a handful of great OpenGL beginner tutorials out there on the internet. It is not that hard to learn the basics yourself without having worked with third party engines before. The math behind isn't that challenging, and you even took a high level course at school. Programming experience in C++ is a big plus. I would advice people who haven't worked in C++ before, to first learn the language and after that dive into graphics programming. Trying to handle both at the same time might be hard. Depending on your interests, you could later on change to an engine like Unity which handles graphics for you, so that you can focus on your other fields of interest. That is not necessary if you're coding for learning and fun, since at that point you will already have built a working renderer system on your own. But if you consider releasing the project as a game, you could benefit from the increased graphics provided by such an engine. By the way, what is wrong with C++11? It brings some really handy tools, like futures, lambdas, filesystem access, and more, which can increase productivity also in game development a lot. 

I ended up using the stencil buffers. Basically, this are the steps my application goes through every frame. 

This line costs you 60% of the time you have each frame. So never stop the whole game thread for a fixed delay. With this error, it might even help to use another thread, but that won't solve the cause but the symptoms in your case. What you want is maybe vertical sync. This is a technique which limit the frame rate to the refresh rate of the monitor, or to a fraction of it. But this feature requires the delay to be dynamically based on the actual frame duration. What it basically does is to let the thread sleep as long as it needs to take the whole 16 milliseconds. Note that most window managers provide an option for vertical sync. I am not familiar with Java but it should have provide it for you, too. Using vertical sync, it makes sense limit at least to renderer thread and the window thread, since it doesn't make sense to render more frames than the monitor can show. Although it can make sense to run physics simulation in another thread to not slow it down. Despite that, multiple threads in game development are used mainly for the reason of making use of multi core processors. But accessing only one of your cores isn't a bottleneck if you are just working with a couple of sprites. 

The common approach for that are configuration files. They can be of whatever structure you choose, INI or XML for example. Making use of configuration files makes your game a bit more data driven. So you can make changes to the configuration without recompiling the whole source code. That saves time and moreover, you can divide the work of programmers and game designers who balance the hit points of enemies. 

Byte56 already listed the most popular ways to monetize a game engine. I just like to add some maybe less common though interesting ways. 

Usually, you define two routes for a camera flight. The first defines the position of the camera and the second defines the point the camera looks at. Both curves may be smoothed using Beziers or B-Splines. I don't quite understand the part of your question about the quaternion. Quaternions are representations of rotation, like angles but unambiguous. You would find the rotation from orienting the camera to the current point on the lookat curve. Another option would be to stay with one curve for the position and always looking forward. Then you would get the rotation from the derivative of the curve, strictly mathematically speaking. Practically, you would approximate this by choosing a point on the curve little ahead and one little behind the current position. For example, see this animated image from Wikipedia, which illustrates the slope what is very similar to your lookat direction. 

Basic chunking is a good way to start. You can move to more sophisticated data structures like octrees later, if you need. For now, simply divide your terrain into chunks of given dimensions when loading the model from disk. Depending on your data, you might either want to split your terrain into pillars on a plane spanning the full height, or in cubes in space. The code isn't complete (fmod, vector initialization, indices, ...) but should give you a start. 

I consider using OpenCTM files for my game. Since the format only claims to store raw mesh data, my question is if there is a associated file format for material data and paths to texture maps. For example material of meshes are stored in files. Is there such a format for OpenCTM, too? 

I implemented SSAO in my game based on the tutorial at gamerendering.com. But the results I get are disappointing. Instead of a smooth effect as seen in the nvidia demos, my implementation causes either squashy dark noise or results in a huge performance hit for all the blurring. This is my scene without SSAO applied. 

Then you could expand this to an easy manager by providing functions to create, get and delete textures. I wrote down this three functions without testing, but I think it is helpful anyway. Function to create a new texture, load image data to it and add it to the system. 

As you can see we only depend on the view direction for the X and Z coordinate. Otherwise the player could fly if the player walks facing the sky. Because you haven't especially asked about rotation, I guess you already implemented that. But as a reference this might help other users. The negation because of the different direction of the world coordinates and the mouse coordinates. 

Grouping faces of different voxels make me think of how to still handle distinctive textures for each block. Is my worry right and how can this be handled? 

I multiply the mouse movement by a given number to get camera rotation of a desired speed. But it only works at 60 FPS. When I don't limit the frame rate I get around 350 FPS and the camera rotation is significantly too slow. In my calculation, I already consider the frame time. 

I am developing a desktop game in C++ and OpenGL. Frameworks I use are GLM and SFML. Since today I used the console window for debug messages. But I want to get rid of that and display debug information right into the render window. Since I also want to implement a generic way to realize user interface, I decided to use web technologies for that. Note that the user interface will be only a two dimensional overlay on the rendered three dimensional scene. I consider using the webkit browser engine but that might be overkill since I do not need page loading and networking but only HTML and CSS rendering (and maybe JS execution). Because the user interface and debug messages will change every few frames, this is performance related. How to render fullscreen webpages (with a transparent background) over my OpenGL scene? I would like a cross-platform solution. 

Images are from $URL$ Do you want to end up with several convex shapes for a single model? Then convex decomposition is what you want. For example Bullet Physics has an algorithm called HACD built in to perform convex decomposition. There is also a standalone version you could integrate in your own application. Furthermore, the algorithms allows you to specify the amount of detail and number of clusters in the result. 

Yes, you can encounter texture coordinates greater than and smaller than . This depends completely on the model, you loaded. Normally, for each vertex there is position, normal, and texture coordinate stored. In most mesh file formats, the texture coordinate is not restricted to any range. This is used to repeat a texture. For example, to span a texture four time between a quad of vertices, the texture coordinates would be , , and . Without texture wrapping, you would need additional vertices to split the surface into 4 times 4 sub surfaces with each the texture coordinates , , , . Fewer vertices results in better rendering performance. Typically, it is not desired that the user notices the edges of a repeated texture. Therefore, repeated textures are tileable in most cases. Than means, the right edge fades seamlessly to the left one and the top edge to the bottom one. This way, the transition is smooth and hopefully not notices by the user. A more advanced, but related topic is, to cleverly obscure the fact that the same texture was repeated multiple times. For example, blending repeated textures of different size, for example a wall texture and a dirt decal, is a common technique. 

For now I use the same code as provided in the example I linked above. How can I improve the result of the ambient occlusion shader? A lot of blurring seems to be very slow on the GPU. I would like to get a result similar to this by Nvidia. How do they do that? 

You could even extend this event manager to allow passing values as additional arguments. C++ templates are great for this. You could use such a system to, say, for a event pass the new window size, so that listening components don't need to fetch it themselves. This can reduce code dependencies quite a bit. 

First of all, try to implement features so that objects stay independent of each other, whenever possible. Especially you want to do that for multi threading. In your first code example, the set of all objects could be divided in sets matching the number of CPU cores and be updated very efficiently. But as you said, interaction with other objects is needed for some features. That means that the state of all objects must be synchronized at some points. In other words, your application must wait for all parallel tasks to finish first, and then apply computations that involve interaction. It is good to reduce the number of these synchronization points, since they always imply that some threads must wait for others to finish. Therefore, I suggest buffering those information about the objects that are needed from inside other objects. Given such a global buffer, you can update all you objects independent of each other but only dependent on themselves and the global buffer, which is both faster and easier to maintain. At a fixed timestep, say after each frame, update the buffer with the current objects´ state. So what you do once per frame is 1. buffer the current objects´ state globally, 2. update all objects based on themselves and the buffer, 3. draw your objects and then start over with renewing the buffer. 

Since asked by the thread starter, I elaborate on event managers. I think this is a good way to handle input in a game. An event manager is a global class which allows to both register callback functions to keys and to fire off those callbacks. The event manager stores registered functions in a private list grouped by their key. Each time a key gets fired, all registered callbacks are executed. The callbacks could be objects which can hold lambdas. The keys could be strings. Since the manager is global, components of your application can register to keys fired from other components. 

Use a slice of higher-order noise. If you used 2d noise for a height-map before, use 3D noise with the last coordinate fixed instead. Now you can slowly change the position in the last dimension to modify the terrain. Since Perlin noise is continuous in all dimensions, you'll get smooth transitions as long as you smoothly change the position where you sample the noise function. If you want to only change the terrain far from the distance to the player as offset for example. You could also store the offset for each coordinate on the map and only increase but never decrease it. This way the map only gets newer but never older. This idea also works if you're already using 3D noise, just sample from 4D then. Also, take a look at Simplex noise. It's the improved version of Perlin noise and works better for more dimensions. 

Do you really need a high resolution mesh of your shopping cart? You could also use a model looking more or less like a simple box and apply textures which are transparent at positions where no rods are. Which technique to use depends on how detailed the model should be. But if the player don't take too close looks on the model, I advice you to use the latter approach since it is much faster. Otherwise you could only minify the vertices of your mesh to increase performance, I guess. You could also combine both approaches by providing one of them depending on how far the camera is away from the shopping cart. This is called level of detail.