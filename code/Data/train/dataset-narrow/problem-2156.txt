As a general rule, no it won't make your computer silent. In general, unless you're dealing with 15k RPM enterprise hard drives, your fans are going to be noisier than your hard disk (if you have no fans though, and have a power supply that doesn't make any noise (a lot of cheap ones hum), it might make the system silent other than the keyboard and mouse). An SSD will probably reduce the noise your system produces, and is likely a good investment for other reasons too (it will reduce your power consumption and most likely speed up your system). 

Accounting for both the USB overhead (which is actually pretty significant), and the PCI-e overhead, the eSATAp connection will almost certainly be faster. It's not normally an issue for things that only do small transfers (like mice and keyboards), but with the constant bulk streaming usually seen with block storage devices (like hard drives), it starts to become pretty significant. I would expect the SATA connection to be measurably faster in terms of throughout and latency. Additionally, USB is kind of notorious for poor reliability for long term usage. A bus reset (as happens when you bump the connector and interrupt the connection for a split second) is extremely expensive with USB compared to SATA, and is much more likely to cause data corruption. 

I'm not quite sure exactly what it does myself, and I actually work in the IT industry, so don't feel bad that you can't find much info, it just isn't there. Based on what I do know, I'm believe that it actually does a couple of things, namely: 

In consumer product names (for example 'GeForce GTX 1080'), it's just branding. For Intel's hardware designations, it refers to the particular GPU core (just like the R numbers for older ATI/AMD cards, and the letter plus number codes for NVIDIA cards). 

Teach your program to detect if the share is mounted or not and then have it cache the files if the share isn't mounted and then write them out when it is. Have your program write data to a separate location, and use a periodic task (using a cronjob or systemd timer) to copy the files into the share if it's mounted. 

As far as I know, there isn't any way to do this directly with git. However, you can use the following shell script fragment to check much more quickly: 

How likely it is that the designers hadn't thought of this is a generally a function of how cheap the device is. THe lower the cost, the more likely they didn't think about it. There is no way to know for certain without looking at schematics to know for certain if it could be damaged by being used this way, but given that it worked without issue the first time, I would say you're probably reasonably safe. The only thing I would look out for is if you see one or two sound cards when it's connected like this. If you see only one, then you're probably fine, but if you see two, that means the device isn't smart enough to properly disable one of its interfaces when the other is being used, which in turn opens up the possibility that two different things will try to use the hardware at the same time (one through each interface), and it probably wasn't designed to handle that. 

What this does is get machine parseable output from the command (which runs faster than on large repositories because it is only checking for the presence of changes, not what they are), counting the number of lines (the format will return exactly one line for each modified file, and no lines if none are modified), and then exiting with a non-zero exit status if the number is non-zero. You could also just embed this directly in whatever script is generating your prompt by pulling out the conditional expression (the bit in the ) and using that in whatever if statement is checking the exit code for currently. 

As you appear to have concluded, 'suspended' is not the same as 'powered off'. Depending on how the firmware implements this 'suspended' state, quite a lot of the system may actually be powered on (in fact, if it's an ACPI S1 suspend, most of the system is probably still powered on, but that's unlikely for a laptop since most of them use ACPI S3 as the basis for suspend). As far as fixing this, try: 

The short explanation is that I'd like to have the lock screen on my Windows 10 systems behave like the desktop background slideshow, only displaying one image at a time, (ideally) crossfading between them, and not tiling, cropping, or zooming. I've got a number of custom desktop background images derived from astronomy images (mostly composites). By their very nature, they can't be auto-cropped or zoomed and still look reasonably good simply because I've already cropped them such that there's essentially nothing but the subject anywhere in the picture. As a result, when tilted or zoomed by the lock screen slideshow in Windows 10, they look pretty bad (tiling in particular often results in it looking like one very poorly made composite mosaic). I would really love to have these backgrounds playing on the lock screen in a slide show, but there's no point if they look horrible half the time. If anyone knows of a way to do this on WIndows 8 or 8.1, that may actually be helpful here too (not much has changed about the lock screen in 10 relative to 8 and 8.1). Also, while I would prefer a solution involving static settings (even if it's a registry or GPO hack), I'm also open to scheduling a PowerShell script to do this (I just don't have the skill with PowerShell to get something like that working). 

Most likely, the user ID for your regular user in the Debian installation is not the same as your user ID for your regular user in the previous Ubuntu installation. The way to fix this is to call the following on your home directory: 

The values indicate how much space has been allocated to that type of chunk, while the value shows how much space is in use within those chunks. In your case, you have 446.32GB of space allocated to data chunks (almost the whole disk based on regular and output), but only 133.29GB of that space is actually in use. Given this and the symptoms described, BTRFS is trying to allocate a metadata chunk but has no space to do so (because all the free space is inside already allocated chunks), so you're just getting an error instead. To recover from this, you'll have to run a balance. A balance quite literally sends all the data from selected chunks (or all of them if you pass no options) back through the allocator, which has the net effect of freeing up empty or mostly empty chunks because it packs things back into partially full chunks. I would start with: 

It's 'just' a rename, as pointed out in the comment. However, there's more than just moving the file involved in putting it in the Trash. You also need to copy out the metadata to the appropriate location in the appropriate format, otherwise restoring the file won't work correctly. See the FD.O/XDG trash specification for more info on what all is going on. Note that pretty much everything uses the optional support for putting a trash directory at the root of removable media, precisely to avoid the issues with trying to trash files you don't have read access to but otherwise can move on that filesystem. 

Based on the discussion in the comments, all the files are sparse. This type of thing actually confuses a lot of people the first time they deal with it, so don't feel bad. What's actually going on here with the values reported by and ? This is most easily explained with an example. Say you create an empty file, and then write 1MB of data to it starting right at the beginning. The resultant file will be 1MB in size, and take up 1MB on disk. Both and will report the same 1MB size for the file. Now say instead you create an empty file, and then call to move 1MB into the file, and then write one byte. The resultant file will appear to be 1MB + 1 byte long, but there's only actually 1 byte of data in it. On older filesystems, the second file would have taken a very long time to write that 1 byte of data, because the OS would be busy writing out 1MB of null bytes before it wrote out that final 1 byte of actual data. This inefficiency (both in terms of time to create the file, and space used on disk) is where sparse files come in. Instead of writing out that 1MB of null bytes, an OS that supports sparse files (like all modern UNIX systems) will annotate in that filesystem's metadata that the region form 0-1MB is empty, and then only store that single byte you wrote. As a result, the file will appear to be 1MB + 1 byte long, but on disk it will only take up 1 byte. Additionally, when something goes to read that file, any regions the OS has annotated as empty will just read back as null bytes (so it looks no different to user programs from the first file). This is where the discrepancy between the values reported by and comes from. By default, reports the apparent size of files (that is, how much data would you read if you started reading the file at the first byte and read all the way to the end), while reports the actual space used on disk by the file (usually not including other space saving tricks done by the OS like transparent compression). agrees with in this case because only reports the amount of space that is actually physically being used on disk. By changing that command to , you will get an extra column showing the actual on-disk size for files, which should agree with . 

That will remove the whole concept of privileged ports from the system starting the next time you reboot. Make sure you're extremely careful doing this however. A lot of the low numbered ports are used for core networking infrastructure, and ths access to them by unprivileged users is an easy way to allow for abuse. Especially be careful if you go with the sysctl method, as that will allow anyone to bind to any port. 

At the hardware level? Probably not (assumption based on the existence of the error injection framework I mention below). You can however simulate the error paths in software with some operating systems. Linux in particular includes an error injection framework (I believe it's called HWPoison) that will let you directly trigger the in-kernel error paths that get executed when a correctable or uncorrectable error occurs (this is actually part of how those code paths get tested). 

Replace with your user name and with the path to your home directory. Also, slightly OT, but it would be a good idea to start using instead of ( has a bunch of known security issues and also isn't the most reliable thing around). 

To understand what's going on here, you need to first understand that BTRFS uses a two-stage allocator. The first stage allocates large chunks of space (actually called 'chunks' in most of the documentation) which get used for exactly one type of allocation, either data (used for the data in files only), metadata (things like file names, directory structure, access times, ownership, permissions, etc), or system (used solely to store data about chunk allocations). Once a chunk has been allocated, the space in that chunk can only be freed by moving all the data out of it. So, what exactly does this mean in terms of your filesystem? Well, your output from shows the following: 

Outside of very specific cases dealing with protocols below TCP or UDP, applications don't send data to a specific network adapter, they send the data to a specific remote network address. It is then up to the OS to figure out which adapter the resulting packet needs to be sent from to reach its destination, although each OS does this a bit differently (although the general terminology is mostly the same, you can search for information about 'routing tables' for your OS of choice for more info). In most programming languages, you can explicitly bind a socket to a given address. Most of the time, this needs to be an address assigned to a local network adapter (in which case all the traffic from that socket will go out via that adapter), though in some cases it is possible to bind to a non-local address (this is used in some situations for certain types of transparent proxy or captive portal).