There is no reason to use String as keys in . By default an object can be used as a key in a hashmap based on it's uniqueness. There is no reason that the values have to be ArrayLists instead just use List. 

It's simpler to just return the result immediately then need another method. Also the caller is probably going to need them as File objects eventually so lets just return them as those. Then there are 2 options, just return a List and use addAll each recursion step: 

the is not thread safe but you use the global from each thread without synchronization. Instead declare an initialize it in to give each thread its own RNG. Same with surround each copy to and from it with a mutex guard like you do when printing out. The following for loop doesn't quite do what you think it does. 

If you define a destructor you should also define (or disallow in this case) the copy construct and copy assign. Failure to do so will result in dangling pointers and double frees: 

First thing, memory leak if you delete ; use a to hold the . Same for the ; use a . There is no need for the contains functions of to take a root for it's first parameter instead use . The vector could be sorted by the letter to allow you to do a binary search for per child, or you can use the char value as index and pre-size the vector to 256 for a lookup per child. 

I would also store the value directly. This requires to be a reference type but that's already the case. You do need to pass which state is the final state. It is very likely that the tape would need to grow. If the tape can't grow then you technically don't have a turing machine. Also it may be handy to be able to initialize the state of the tape before starting. 

is sorted at the start of each while loop and the sorted list thrown away (if I read that selection syntax right). This is a cost of O(n log n) on each iteration. It is then followed by a remove which takes O(n) time. You don't need the full sort, only which element has the smallest cost. And the priority heap will let you get that efficiently. If you don't opt to go for a prio heap then keeping the sorted list around can speed up maintaining the list sorted. As sorting a partially sorted list can be faster than sorting a completely randomly ordered list. Especially when you take into account how nodes get out of order. 

Your is not thread-safe, meaning that different threads tying to push data into it will step on each others' toes and corrupt the tree. doesn't actually do anything if the thread doesn't check itself if it has been interrupted periodically: 

It's not recommended to inherit from Thread. Instead implement Runnable and pass it to a new Thread which you store in a member and provide accesses for what you need. This also lets you pass a for some customization options for the threads used. 

in the constructor it's better to allocate an empty array to avoid an unexpected null pointer. In you should just at least initialize to 0 before the loop. You have no other way to add a element to the heap. This would be something like this: 

With the most common way is to return the index (or iterator) of the found value and -1 if the value is not found. This is exactly what List.FindIndex does. However C# has a feature called Nullable types which you can use: 

should have a in the second parameter. This primarily prevents windows from replacing any byte with which would corrupt the file. 

The initializer can be replaced with or the static value . This removes the hard wire and the slow pow function. 

Or you can simply seek to the end of the file (with ) and use Besides that files nowadays can easily exceed 4 gigabytes which will overflow the int, both posix and windows have (differently named) variants on ftell that returns a 64 bit number. 

You let the user pass in a but you don't use it. you might as well remove it and declare it as a local variable. 

Or you can use a second slower timer that doesn't get reset and just runs every so often to purge the list anyway regardless of how long actions have been waiting and how many may still follow. 

This ensures that the writer is closed should an exception occur. Second appending Strings for output is not the most performant thing that should be done instead pass each string separately: 

I return 1 here to signal to the OS that the program didn't finish successfully and a script using it can then react to it. 

here there is only 1 branch compared to the 2 you had before (possibly 3 depending on how was implemented) 

This will recompile a regex each time it is called. Instead you can create a constant to hold the pattern: private static final Pattern END_OF_LINE_WHITESPACE = Pattern.compile("\s+$"); and then use it with 

As a first step instead of 20k graphics objects containing each a single line use a single graphics object and put the 20k lines in it 

You can put the in a so RAII can delete them safely. This is safe because you will not be copying it around. 

First did you compile with optimizations enabled? If not then do so when profiling. A good optimizer will produce equivalent code after unrolling the loops. The first double for loop is superfluous. It is doing busy work that is overwritten in the second loop. 

If you have a destructor you should also define the copy constructor and copy assign + the move variants. Otherwise the compiler will generate its own (incorrect) copy and move facilities which will lead to dangling pointers and double frees. When pushing the element is copied. You should also provide a move variant of push: 

Instead of messing with string I suggest looking up the binary operators ( ). They work per bit to or them. This means that is a integer where only the bits that differ in and are set. Then you just need to count those for which there is a special function in the Integer class: 

If you destroy a non empty list you leak all nodes still in the list. Similarly the in just gets its values overwritten. 

Whenever I see a callback in an API there is a high chance that there is a way to pass at least a custom through to that callback. In glfw that's embedded in which has a user specified data in and . You can use this to keep a pointer to the state per window and it to a struct pointer of your choice. In your case this will probably be the GLContext class. 

You don't reset the when you return the result. This means that between calls you need to reset the state manually. Instead you should reset the state: 

A simpler solution would be to let the calling code be responsible for all memory buffer allocations. This changes the example code to: 

You can swap JEZ and JNZ and then remove the noop jump to check, and because the instruction before start is the same as before the JMP to it at the end you can remove the two instructions: 

Besides that all your algorithms use the standard comparator. you should let the user supply a comparator (a mapping function for ) for types that don't have a default . 

You use lock locks in the get and release methods. This somewhat defeats the purpose of using the threadsafe pool. The getPoolSize doesn't need to wait on finishing the get or release as is thread-safe and the pool's size is fluid anyway when multiple threads are contesting over it. For shutdown you can use to clear the pool to another collection when shutting down: 

When grabbing the items most code will simply iterate over them and then discard the vector. You can avoid the allocation and copying cost by using a visitor pattern. 

Multithreading is not a silver bullet. As it is your code is I/O bound and the only way to speed that up further is getting a faster harddrive. There is one little thing you can do: In your current code there are 3 distinct phases; reading the file into memory, removing duplicates and validation+output. What you can do is interleave the phases so you can get to work with output while you are still reading in: