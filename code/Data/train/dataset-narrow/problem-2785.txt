Basically you want to test on as many other machines as you can - from your friend's hard-core gaming rig to your gran's email-and-internet-only machine. Especially your gran's email-and-internet-only machine, because it's probably loaded with cruftware and other stuff that will interfere and slow your game to a crawl. PC compatibility testing is a big nasty can of worms, and there's a reason why professional testing is expensive. So you want as many different odd scenarios tested as you can. Beta testing is the way to go I think, both with friends and family and a wider circle in your fan community. Key thing - don't rely on anecdotal reports. Your friends might be relied on to actually reply, but the wider community will not, unless you make it easy for them. Build logging into your app to give you hard facts on FPS, startup time, etc. Give the user an easy questionnaire, ideally built into the game, where they can report whether or not they though it played okay. And have those statistics and logging easily emailable / transmittable back to you, for you to pore over later. The more stats you get back, the better a sense you can have of whether your title is a) working at all on other systems, and b) working well on other systems. 

The 3rd case is just a closest-point-on-triangle-to-point, for which you project the point onto the plane of the triangle (i.e. find the closest point to your target on the plane which contains the triangle), and then constrain it to be within the triangle. If the projected point is within the triangle, then you have your closest point, otherwise you now have 3 closest-point-on-line-to-point problems, which you can solve with dot products (and pick the smallest of the three solutions). Again you can brute force the triangle-triangle check, by iterating every vertex in triangle X and doing a closest-point-to-triangle check against triangle Y; then iterating every vertex in Y and doing a closest-point-to-triangle check against X. Now for each vertex you have a distance to the other triangle. If you have one vertex which is strictly closer than all the others, you're in case 3, and you're done. If you have two vertices on the same triangle equally close to the other triangle, you're in case two. If all three verts of one triangle are equally close to the other, you're in case 1. In terms of optimisations / early outs, you need to find a cheaper way of testing two triangles for rough closeness, so that you can discard all but the few potential options. I think you could probably get a lot from AABB checking. E.g.: 

NauticalMile's answer is great (and bonus points for the killer animated diagrams). To give an alternate suggestion that doesn't suffer from the same problems (the wheel collision stopping you from moving past objects that a floating body should be able to traverse effortlessly, I suggest modelling something more closely matched to the reality of your situation. I.e. don't use rigid body collision and springs. Model your character as a rigid box as normal, but every update do a raycast directly downwards (in the direction of your jet thrust) and measure the distance from the character to the nearest collidable object. Then, apply an upward impulse to your character's body, inversely proportional to the distance from the ground. So the closer you are to the ground, the larger the impulse. That can be a linear proportion, or an exponential proportion, but you don't want it to be too large (i.e. shooting off into the sky) so you'll want to damp it beyond a certain range. But basically it should achieve equilibrium against the effects of gravity, to give the effect of a spring - the closer you get to the ground, the more energy the spring imparts, the further away the less it boosts you. Combined with a damping factor on the motion, you should achieve a balance point some height off the 'ground'. NB: this force should be constrained to only act vertically on your body, otherwise you start getting into real-world issues where your character is unstable and wants to lurch forwards or backwards depending on what's underneath or what angle the character is at. Jumping is then simply adding an extra vertical factor to that force - you can't jump infinitely high, but it does have the extra nuance that if you time the jump right (say just after dropping down from a height), you can get extra height on the jump by taking advantage of the bounce effect. This should have the effect of allowing smooth motion over small obstacles without taking anything away from your horizontal velocity. As the obstacle comes under the jet raycast, the character will shift upwards, but not slow down at all. Actually, a single raycast may be unstable, especially if you're moving over rough terrain. I'd perhaps do two or three raycasts and take an average of the distance; weighting it if you want to maybe, or discarding measurements outwith a certain deviation from the average. What you're don't want a case where the character moves over a very slim gap in an otherwise flat surface in the world and drops downward sharply because the ray happened to pierce right into that gap. 

First we initialise at time 0 (so currentTime = 0) We render with a proportion of 1.0 (100% currentTime), which will draw the world at time 0 When that finishes, actual time is 3, and we don't expect the frame to end till 16, so we need to run some updates T+3: We update from 0 to 5 (so afterwards currentTime = 5, previousTime = 0) T+4: still before the frame end, so we update from 5 to 10 T+5: still before the frame end, so we update from 10 to 15 T+6: still before the frame end, so we update from 15 to 20 T+7: still before the frame end, but currentTime is just beyond the frame end. We don't want to simulate any further because to do so would push us beyond the time we next want to render. Instead we wait quietly for the next render interval (16) T+16:It's time to render again. previousTime is 15, currentTime is 20. So if we want to render at T+16, we are 1ms of the way through the 5ms long timestep. So we are 20% of the way through the frame (proportion = 0.2). When we render, we draw objects 20% of the way between their previous position and their current position. Loop back to 3. and continue indefinitely. 

I think your implementation assumes that the sound level in a cell is cumulative, and that the amplitude simply moves outwards evenly in all directions. Sound doesn't spread out, frame by frame, it's either playing or it isn't, and you want to find out the amplitude to play it at for any given point. Raycasting through the tiles is one way (and probably the most effective way) of doing it. Just draw a line between emitter and receiver, and subtract the dampening value of each cell along the way. If the number is positive, you play the sound. If you want to model indirect sound, then you'll have to path-find. Treat the emitter as the root of your tree, and model each adjacent cell as a linked node. Each link has a cost, subtracted from the current volume. Keep traversing through the graph until either you find the receiver or your volume drops below zero (if it does, backtrack and try another path). If there are no paths to the receiver with a positive volume, your emitter can't be heard. NB: you can't just give up traversing when you find the receiver, because there may be multiple paths from emitter to receiver, and you need the one with the highest volume. If you're modelling AI that care about where the sound came from, the latter approach will help - an AI would be 'hearing' the sound come from direction of the last segment on the path. Nicely, if there are two audible paths to the receiver, they AI could be confused about the multiple sounds and which direction to take. 

Instinctively I'd say that we're missing a substantial part of the context needed to answer, which is "why does the multiplayer aspect prevent you from changing the timestep?" If you are trying to share a physics simulation over a network connection, well, that's usually a pretty hard thing to do. The simulations diverge very easily, and especially with network connections that can lose packets, it's very hard to keep things together. The simple and most robust answer to your question is to use a variable timestep. When you approach the moment of decision, instead of updating your physics simulation by one second for every real-world second that passes, update it by half a second, or another suitable number. As it's an integration effect, you'll probably be able to get away with simply snapping the update rate down to the lower rate during the decision window, but you can also interpolate quickly downwards to the lower rate. Either way, you are essentially playing back the physics simulation in slow motion. It should behave perfectly accurately, just slow enough that the player can make their decision. I wouldn't consider any other means of fudging the physics to make it work, they'll most likely all work out horrible and not feel 'right'. Keep the physics pristine, and counter the decision window problem outside of the simulation. So we come back to the networking implementation. Without further information, I'd guess you have two choices. Firstly, if you're operating in lockstep with the other networked party. So when one player has to slow down to make their decision, slow down both players equally. This will probably feel annoying and weird for the player who isn't firing, because it'll confuse their own reaction times. For the second, imagine two trebuchets firing at each other. The trebuchet takes 10 seconds to throw, and the firing window starts at T+5s. P1 starts the firing cycle at T+0s, and at T+5s slows their local physics simulation down by 50%. It'll take them 15s to play through the whole cycle. So at T+5s, P1 tells P2 to start playing back the 10s launch cycle at full speed. So P1 sees the trebuchet cycle take 15s, P2 sees it take 10s, but both players see the cycle finish at T+15s. When P1 actually releases, they tell P2 when in the notional cycle they released. So if P1 releases at T+10s, that's actually at 7.5s through the 10s launch cycle. P2 can then show the release at T+12.5s (7.5s into its local playback of the cycle), and both players simulations should have launched the projectile at the same physical point in the cycle. So in this second approach, you're no longer simulating in lockstep. You're running two independent simulations, but tracking player inputs instead. If both are told that the player released at 7.5s into the launch cycle, they should both agree on where the projectile will land. In practice though, that's likely to diverge very fast, and you're going to need to synchronise simulation states somehow. 

Start with it straight away (like mobile first). It is a fundamentally different platform, with its own very unique design constraints. If you start with a non-VR game and try and tack on VR support later, you will end up with a very poor experience that probably makes your users feel ill. If you start with VR, then it will be possible to make a pared down non-VR experience later, far more easily than the other way around, but depending on how much you take advantage of what VR gives you, you need to face the possibility that you might not be able to support both in the same game. 

I'm going to say yes, to your question as phrased, but with important caveats. Yes, you need to know how to sort things in programming game development. There's lots of sorting goes on, in a wide variety of situations. No, you don't need to know the details of how all (or even many) the various sorting algorithms work, it's almost always sufficient to look it up in a reference (online or book) when you need to. What's important is not the how and why of each algorithm, it's a deeper understanding of why some algorithms work better in some situations. It's understanding exactly which situation you have (do I need to sort in-place, can I insert items in the list cheaply). It's knowing the most common and flexible algorithms, not so much the details of how they work, but more the situations where they should not be used. And finally, it's knowing when sorting performance is important (when you have many, many items and you need to sort them a lot) and when it's not so important (when you have just a few items, and/or you only need to sort when the list changes). In the latter case, just throw the list through quicksort. If your objects are large, then sort a list of indices to the objects rather than the objects themselves. In the last dozen or so years I've been developing professionally, I can count the number of times I've needed a more tuned or specific sorting algorithm, and it's probably less than 20. 

As the commenter said: check to see if your app runs fine when running as administrator, because if it does, that suggests something different. Otherwise, I think you're running into a straightforward access rights issue. You don't, as a rule, have the right to open any files under "C:\Program Files" with write access. So you don't get to save any files there at all. Your question suggests though that it's not the saving that is causing you problems, but the loading. Still, you need to make absolutely sure that you're not trying to open the files with the wrong access permissions. You don't say what functions you're actually using to do the loading, we'd need to see that code to confirm. But as an acid test, you should be able to call: 

You don't really need a full on resource manager in this case. But yes, it's pretty common to have your assets to be arranged in a particular structure under some root, but for the code to all be written in ignorance of what that root is. Rather than a resource manager though, you can just have an indirection step that resolves a relative path into an immediately usable path. So: 

I think you are probably misunderstanding the coordinate system in which you are working. Higher numbers for X and Y are not necessarily up and right on the screen. So you're most likely seeing an upside down quad, or your camera is behind the thing you're looking at and you're seeing its back (a double-sided quad will show the mirror image of your texture if you look at it from the back). Turn your quad upside down (by changing the order of vertices in the vertex buffer declaration), or change your camera position. 

There are two things crucial to get motion appearing smooth, the first is obviously that what you render needs to match the expected state at the time at which the frame is presented to the user, the second is that you need to present frames to the user at a relatively fixed interval. Presenting a frame at T+10ms, then another at T+30ms, then another at T+40ms, will appear to the user to be juddering, even if what is actually shown for those times is correct according to the simulation. Your main loop seems to lack any gating mechanism to make sure that you only render at regular intervals. So sometimes you might do 3 updates between renders, sometimes you might do 4. Basically your loop will render as often as possible, as soon as you've simulated enough time to push the simulation state in front of the current time, you'll then render that state. But any variability in how long it takes to update or render, and the interval between frames will vary as well. You've got a fixed timestep for your simulation, but a variable timestep for your rendering. What you probably need is a wait just before your render, that ensures that you only ever start rendering at the start of a render interval. Ideally that should be adaptive: if you've taken too long to update / render and the start of the interval has already passed, you should render immediately, but also increase the interval length, until you can consistently render and update and still get to the next render before the interval has finished. If you have plenty of time to spare, then you can slowly reduce the interval (i.e. increase the frame rate) to render faster again. But, and here's the kicker, if you don't render the frame immediately after detecting that the simulation state has been updated to "now", then you introduce temporal aliasing. The frame being presented to the user is being presented at slightly the wrong time, and that in itself will feel like a stutter. This is the reason for the "partial timestep" you'll see mentioned in the articles you've read. It's in there for a good reason, and that's because unless you fix your physics timestep to some fixed integral multiple of your fixed rendering timestep, you simply cannot present the frames at the right time. You end up either presenting them too early, or too late. The only way to get a fixed rendering rate and still present something that's physically correct, is to accept that at the time the rendering interval comes around, you will most likely be mid-way between two of your fixed physics timesteps. But that doesn't mean that the objects are modified during rendering, just that the rendering has to temporarily establish where the objects are so that it can render them somewhere in between where they were before and where they are after the update. That's important - never change the world state for rendering, only updates should change the world state. So to put it into a pseudocode loop, I think you need something more like: