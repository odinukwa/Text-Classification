to see the kinds of arguments that support the major solvers. If you have new ideas that are not yet optimized to perform as well as the top solvers, you would need to explain the potential advantages of your approach to someone who knows the long sequence of theoretical reasoning that has led to the current set of "best practice" design decisions. If your contribution is purely theoretical, then you need to be aware of the many papers in this area, and explain in your paper why your approach is better in at least some way. Have a look at recent work by for instance Amin Coja-Oghlan or Alan Frieze to get a feel for the state of the art and for useful pointers to important papers. 

Consider the following decision problem. Let $q = \sum_{i=0}^{n/4} \binom{n}{i}$ and let $(C_0^n, C_1^n,\dots,C_{q-1}^n)$ be a suitable enumeration of those subsets of $\{0,1,\dots,n-1\}$ that have at most $n/4$ elements. 

You seem to be really asking: is Nurikabe in NP? Nurikabe is NP-hard, since one can build polynomial-size gadgets that can be used to reduce an NP-complete problem to a Nurikabe decision problem. This is what Holzer, Klein, and Kutrib do, and also McPhail and Fix in their poster (both referenced from the Wikipedia article). Both groups of authors assume that the problem is trivially in NP, and wave away the question of membership. Your unease about succinct instances seems spot on -- I do not believe the problem is in NP. Consider the following way to formalise the decision problem: 

(Structural tractability) Any class of SAT instances where the variables interact in a tree-like fashion can be solved in polynomial time. The degree of the polynomial depends on the maximum width of instances in the class, where the width measures how far an instance is from being a tree. More precisely, Marx showed that if the instances have bounded submodular width, then the class can be decided in polynomial time using a divide-and-conquer approach. (Language tractability) Any class of SAT instances where the pattern of true-false variables is "nice", can be solved in polynomial time. More precisely, the pattern of literals defines a language of relations, and Schaefer classified the six languages that lead to tractability, each with its own algorithm. 2-SAT forms one of the six Schaefer classes. (Hybrid tractability) There are also some classes of instances that do not fall into the other two categories, but which can be solved in polynomial time for other reasons. 

Denote the $k$-variable fragment of logic $L$ by $L^{(k)}$. The model-checking problem for a logic $L$ with respect to a class of structures $C$, denoted $MC(L,C)$, is the decision problem 

As far as I understand, the submodular minimization case captures all there is to be said about the monotone Boolean case, and binary submodular Boolean functions can express all submodular Boolean functions. However, if the domain is non-Boolean, then binary submodular functions are not enough to express all submodular functions, even if hidden variables may be introduced. (Apologies if I have missed a subtlety in your precise problem phrasing.) The state of the art is discussed in this nice paper which has lots of links to related work, and that also makes the links to computer vision quite explicit: 

This means that one can use $O(N^4)$ space to guess a solution up to the bound, and then check in $O(N^8)$ time whether it is a solution. The precise polynomial depends on whether one uses Tyszka's or Cipu's result for the bound, and how one expresses the Diophantine system of equations representing the magic square. In either case, the number of variables required in a Diophantine system of the form posed by Tyszka is no more than $n^2 + 2(n+1)(n-2)+1 = 3n^2-2n-3$. This is achieved with $n-2$ variables for partial sums for each row, column, and diagonal and a grand total variable linking these together. Beyond the magic square itself, a further polynomial number of variables is required for the numbers in the square: a number requiring $m$ bits can be represented by using $O(m^2)$ intermediate variables. For the second part of the question, as far as I can tell either version of MAGIC SQUARE COMPLETION should be NP-hard, but I do not have reductions. It is worth noting that there are procedures to construct normal magic squares of arbitrarily large size; moreover, the number of normal magic squares seems to grow superpolynomially with $n$ (see OEIS A006052) so the underlying language does not seem to be sparse. 

It is also interesting that quite tight bounds are known for $f(k)$. The above paper derived a lower bound from the Lovász Local Lemma, and unsatisfiable instances have been explicitly constructed more recently for the upper bound. In short, $f(k) = \Theta(2^k/k)$. 

Alexander Razborov's introductory survey on communication complexity proves this result and states "the following beautiful construction [is] usually attributed to Rabin and Yao". The idea is to consider the bit strings as coefficients of a predetermined polynomial $P(x)$; Alice then picks a random integer $q$ from 0 to $p-1$ for some predetermined prime $p \in [3n,6n]$, where $n = \lceil \log N\rceil$, and sends $(q, P(q) \mod p)$ to Bob. 

Benjamin Rossman's recent paper summarises the state of the art for the monotone circuit complexity of k-CLIQUE. In short, Razborov proved a lower bound in 1985, later improved by Alon and Boppana in 1987: $\omega(n^k/(\log n)^k)$, versus the brute force upper bound $O(n^k)$. Rossman shows a lower bound of $\omega(n^{k/4})$ for the average-case complexity in the Erdős-Rényi model of random graphs; Amano previously showed this was essentially also the upper bound. The quasi-sunflower lemma that forms a key part of the paper is rather neat. So the natural proofs barrier does not seem to apply to monotone circuit complexity. Norbert Blum has discussed why lower bounds for monotone circuits are essentially different from circuits with negations. The key observation of Éva Tardos is that a small modification of the Lovász theta function has exponential monotone circuit complexity. 

The result for Cartesian product is then improved to $O(m\log n)$ time and $O(m)$ space in Chapter 7. As pointed out in other answers, this has since been improved to linear time. For the lexicographic product: 

As far as I can tell, UniqueSAT is exponentially dense, in the sense that it contains $2^{\Omega(n)}$ instances of size $n$. (This is a stronger requirement than $2^{n^\varepsilon}$ for infinitely many $n$.) The following argument works even for the revised definition of "dense" introduced in version 5 of the question, where all instances of size up to $n$ are taken into account. Note that $\sum_{i=0}^n 2^i = 2^{n+1} - 1$. Consider formulas in CNF with $v$ clauses, each clause containing exactly one literal, such that each variable occurs precisely once in the formula. An example of such a "complete 1-SAT" formula for $v=3$ is $x_1\land x_2 \land \lnot x_3$, completely specifying the solution $x_1 = 1, x_2 = 1, x_3 = 0$. We establish an exponential lower bound for the number of complete 1-SAT formulas of size $n$. Logarithms are base 2. Complete 1-SAT formulas each have precisely one solution, and with $v$ variables such a formula has size $v(1+\log v)$. There are also $2^v.v!$ distinct complete 1-SAT formulas over $v$ variables. We then just need to ensure that $v$ is as large as possible in terms of the instance size $n$. Let $v = n/(\log n)^\delta$ for some $\delta = \delta(n)$. For the size of complete 1-SAT formulas with $v$ variables to be precisely $n$ bits, we require that $n = v(1+\log v) = (n/(\log n)^\delta)(1+\log n - \delta\log\log n)$ so $1+\log n - \delta\log\log n = (\log n)^\delta$. We can always choose $\delta$ appropriately to satisfy this expression; note that $1/2 < \delta < 1$ for large enough $n$, with $\delta \to 1$ as $n \to \infty$. This already shows that there are at least $2^{n/\log n}$ such instances, so UniqueSAT is not sparse. Moreover, the high order term of the exponent of $2^v.v!$ is then $n[(u/(1+u))-(\log e - 1)]$, where $u = \log n - \delta \log\log n$ and $\log e - 1 \approx 0.4427$. (For instance, this follows from Robbins' bounds for the factorial function, $\log n! = n\log n - n\log e + 0.5\log n +r_n\log e + 0.5(1+\log \pi)$, where $1/(12n+1) < r_n < 1/(12n)$ for $n \ge 1$.) Now $u/(1+u) > 1/2$ for large enough $n$, so there are $2^{\Omega(n)}$ complete 1-SAT instances, and hence $2^{\Omega(n)}$ UniqueSAT instances.