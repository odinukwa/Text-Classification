This will mount the CD disc, make it the only package repository and install a kernel that has support for more than just a handful of vmware/xen/etc virtual devices. After you get it working, restore /etc/apt/sources.list file from the backup and update aptitude again. 

We're trying to access Foxpro file-based database files via MSSQL Server's linked server feature, using Foxpro ODBC driver. For this, we've 

I have OpenFiler storage server. Without installing Windows and MSM, I want to create raid10 array from disks 2 to 21. I have already successfully installed MegaCli to OpenFiler but I'm stuck in figuring out the correct command line for creating a raid 10 array. The documentations says that the syntax for creating a raid 10 is: 

I have a Strongswan IKEv2 server and I can connect to it from Windows 10 using built in VPN client but I cannot ping the subnet behind the vpn server. It only works when I manually add a route to the subnet with route add 192.168.12.0 mask 255.255.255.0 10.100.0.1. Basically the same issue that strongSwan server with Windows 7 clients doesn't route traffic. Is it possible to automate it from the server side (i.e. I don't have to create a bat file on every client desktop to add the route)? 

I have an Openbravo POS workstation with a customer display pole. The pole is VFD-860. When I click on the products on the Sales page of Openbravo, the display responds but displays garbage: 

I have a 2.7 TB virtual disk (LSI MegaRAID controller with ten 600GB SAS drives configured in RAID10) under Linux. I am sharing this disk to a remote ESX host via ISCSI. Unfortunately ESX will only make a 740GB VMFS partition if you present it LUN greater than 2TB. I could make a 6 disk RAID10 (which would be smaller than 2TB) but I really don't want to lose spindles (IOPS). Is there a way to split this big RAID10 virtual disk up (for ESX) in Linux? 

I am trying to collect azure diagnostics data from some resources in Azure on one separate subscription and directory, and ship them to an OMS / log analytics workspace on another subscription / directory. The account i'm using has access to both organizations, however when I am running the commands to "To enable sending of Diagnostic Logs to a Log Analytics workspace" (as described here) 

You think it's originating from your PC? Have you tried unplugging your Ethernet cord and seeing if it fixes the network wide issue? I think you may be taking a too narrow view on a network wide issue by only looking at individual Wireshark logs, have you tried reviewing your switch and router logs and seeing if there are any errors? To find the source of SMB traffic that is suspected to cause the issue I would run a and look for what program is using TCP port 445 (Wikipedia also says UDP ports 137, 138 & TCP ports 137, 139) I would do this on both your workstation and on the file server. I would also set up some network related performance monitors on the file server to see if that is spiking during this time as well. I don't think it would be safe to settle on SMB just yet without seeing the same sort of traffic on multiple workstations. The fact that it is happening at a specific time makes it seem like there is a scheduled task , program, or backup running at that time. WSUS settings and Windows Update GPOs have caused this issue for me in the past, I would double-check those. It really sounds like the best solution would be to set up some sort of SNMP monitoring / NMS on all of the workstations / servers and their NICs. Quest Foglight and Solarwinds NPM, can do this. After monitoring SNMP traffic you would be able to see what interfaces are having high utilization during those trouble times. Buyer beware, this can be expensive. Quest Foglight will let you monitor up to 200 interfaces, so that may be enough for a good sample. 

We have a small network of servers for which DNS service is critical. However, it seems to be a pain to set up redundant DNS service. What we currently have is two caching/forward resolving servers set up running Ubuntu with Unbound. With the standard set-up, it seems the best we can do is configure a very short timeout. I'm finding very little help with Google. The solution that seems to be most common is to create a virtual IP or set up heartbeat. But I'm not sure that'd work in our case, because the forwarding servers are in separate subnets and physical locations. Regardless, I'm wondering: 

The and table concern the local machine itself receiving and sending packets respectively, no matter which interface or address is involved. You probably want a rule that accepts everything received from interface in , and accepts everything sent on interface in . In plain iptables: 

I'm trying to fix a very strange problem remotely on a machine at a customer site. The machine is a Dell PowerEdge 1950. The machine's NIC is a dual-port on-board Broadcom NetXtreme II BCM5708 Gigabit Ethernet, using the bnx2 driver. The primary interface eth0 works perfectly, and is in fact how I am ssh'd in. However, the secondary interface eth1 is not transmitting. I can see this in ifconfig output, for example, where the TX field is always 0. However, it is receiving, and tcpdump shows ARP requests coming from the ISP's gateway on the other side. The interface is physically connected to a Siemens BSTU4 modem, configured by the ISP. The link is properly set to 10MBps and full duplex, without negotation, as the ISP requested. A small subnet is configured. For the sake of anonymity, let's say the machine is , and the ISP's gateway . The machine has no firewall settings whatsoever. Even running something like , and running tcpdump alongside, shows no traffic whatsoever being transmitted on the interface. (But the other side keeps steadily sending ARP requests, and that is all that can be seen.) What could be causing this? 

I am building a small setup of ESX5 servers. There will be different apps running for different companies on them. Each company has a VM that has one Internet facing vNIC and one vNIC facing to this company's private virtual network (backend). The backend networks are for separate web server and database VMs. The question is: would it be performance and/or security wise better to create a separate virtual switch for each company or just use VLAN tags? I mean if all the private networks are load-wise fully utilized, would it make a difference if they used separate virtual switches? 

How would one see conveniently which users exactly have which permissions on a folder when a folder's Security tab has many usergroups? I'm specifically looking for some technique or a GUI/CLI tool which lists individual users and their permissions for the folder. I googled and checked out DumpSec and Hyena but they didn't seem to have an option to dump individual users. 

Both machines run Windows Server 2008 R2 now and have 10Gbit Supermicro AOC-STGN-i2S (actually they are Intel 82599 bearing Supermicro logo) in PCIe x4 slots- with a SFP+ direct attached twin axial cable between them. The second server is for testing only. First I installed ESXi on the 2nd and used the 1st as a datastore. I noticed that according to CrystalDiskMark, a VM on ESX only got 325 MB/s seq transfer rate (tried with both NFS and ISCSI). I ran the same test on the first server locally and got ~1000 MB/s. I wondered if the network link really kills 2/3 of speed, so I replaced 2nd's hard drive and installed Windows Server 2008 R2 and tried Jperf and NTTtcp. Jperf showed 400 MB/s and NTttcp showed 4300-4600Mbit/s. Windows Task Manager showed some 600 000 000 bytes per interval which translates to 4.47 Gigabits. I verified that both ends had full duplex and tried toggling jumbo frames on and off both ends but the difference was only 580 000 000 vs 600 000 000 bytes per interval. Why the throughput I'm seeing is only about half the theoretical maximum of 10 gigabits? ADDENDUM NTTtcp command lines: 

Download the Windows Debugging tools from the wizard only instal the WinDbg tool. Launch the tool and configure the symbol path to use 

If all of those critera are met, I would review the the following: 1) Are the VSS providers / writers in a healthy state on both the host and the guest VMs? This article from Veritas will show you how to check. It's essentially these two commands. 

There is an azure-quickstart-template named 201-vmss-windows-customimage that will give you a template to accomplish this. From the readme.md 

Currently we have set up a test VDI environment that hosts several Windows 7 client computers. We are using the "Personal" desktop option and everything seems to be running fine except... The only way to access the virtual desktops seems to be from either logging into the Remote Desktop Web server that is hosting the file and then opening that .RDP file or Alternatively saving that .RDP file and opening it from another PC. We have several Linux based HP t5145 thin clients running "Thin Pro" that we were looking to utilize to connect to these VDIs, but I cannot seem to find a way to open the .rdp file or to connect to the VDI through the pool. The only DIRECT message from Microsoft I could find was here: 

So is connecting to client VDI only supported from that darn RDP file? Is there anyway to open that file with rdesktop or another linux alternative? Is there any documentation from Microsoft or HP on the matter? (I couldn't find anything but this sales document that assured me that it was "Fully Tested, Ready to Run") Thanks. 

2) Are the integration services up to date on the guest VMs? Try to install the integration services, if it is out of date you will be prompted to upgrade. 3) Have you reviewed the Windows backup logs to determine why this is occuring? The default log location is %windir%\logs\windowsserverbackup - additonal logs are outlined in this Technet post. 

The company I work for recently got hands on a batch of second hand PowerEdge SC1425 machines. We'd like to put these to good use. Our operating system of choice is Ubuntu Server 10.04 64-bit, which installs just peachy on this type of machine. Now I'd like to install the firmware updates from Dell, which are apparently marked as recommended. This includes the updates for the BIOS, the BMC, and possibly some other hardware. I find it incredibly difficult to locate the files on the Dell website, and install any of them on an Ubuntu system: 

If you are using addresses other than (or ), then you may need specific rules. But if so, perhaps you can explain the reason why you are using such addresses, because your problem domain may very well end up matching your network domain. (Or at least make you consider other options.) 

“Administratively prohibited” is also one of the ICMP control messages. Is it possible a router between the SSH server and the tunnel destination is sending this? If sniffing is possible, a simple pcap filter with just can show you all ICMP traffic. 

You can set up a reverse proxy to serve at port 80, and forward all requests to 8080. Apache is one of the web servers that can do this for you. There is a basic reverse proxying example in the mod_proxy documentation. 

I'm specifically NOT looking for instructions for any given mail server, such as Exchange or Postfix. But it's okay to say: “you should have X and Y in your set-up, because when talking to server software Z, it typically tries to weed out open relays by checking for these.” 

The username will be available in the environment variable . This works for nearly every authentication method, should you ever start using digest or maybe even kerberos authentication. 

I managed to solve this by having sign the files. For reference, this is done with the option in , and is documented in the manpage.