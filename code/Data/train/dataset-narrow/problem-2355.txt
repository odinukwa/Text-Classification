In "Domains and Lambdi Calculi" by Amadio and Curien, in the section on solving recursive domain equations (section 7), they give sufficient conditions on a cpo-enriched category so that the category of embedding-projection pairs has $\omega$-colimits. Specifically they say it is sufficient for the category to have $\omega^{op}$-limits. They then have a theorem that the category of CPOs has all $\omega^{op}$ limits, but the proof is incomplete and I don't see how it could be completed. To be clear in their book the category CPO has as objects directed complete partial orders with a least element and as maps continuous (not neccesarily strict!) functions. Their proof proceeds as follows. Given a diagram ${D_n,f_n}_{n\in\omega}$ ($f_n : D_{n+1} \to D_n)$, their proposed limit is $$D = \{ \alpha : \Pi_{n\in\omega} D_n | \forall n, f_n(\alpha_{n+1}) = \alpha_{n} \}$$ with the pointwise ordering. This is definitely the product of that diagram in DCPO, but I don't see why $D$ must have a least element. In particular, you can't pick $\alpha_n = \bot_n \in D_n$ since the functions $f_n$ are not assumed to be strict. However, restricting to strict continuous functions is all they need anyway because embedding-projection pairs of CPOs are strict anyway (embedding because it's a left adjoint, projection because it's a retract of the embedding). However this doesn't seem quite right either because for example a right adjoint wouldn't necessarily have to be strict, so it seems less general. So to summarize 

In fact, I'm probably content with a easy quadratic program that finds the midpoint of the entire polytope since centrality matters more than minimality, just vaguely curious if other linear programming algorithms offer relevant properties. Update : I've reduced the underlying problem to a simple constrained minimization problem solvable with Lagrange multipliers, but the question above remains interesting anyways. 

There are a wide variety of determent-like constructions. Some like the permanent or immanents are variations on the ordinary determinant for matrices over fields or commutative rings. Some like quasideterminants extend the theory of determinants to non-commutative rings. At least permanents have a rich complexity theory, perhaps the others do to. For any of these constructions, is there a quantum algorithm that asymptotically out preforms the fastest classical algorithms for computing it? I'm asking because some post-quantum crypto systems like $URL$ and code-based crypto suffer from extremely large key sizes due to representing public keys as matrices. A priori, it might be possible to "compress" that large matrix into something like a characteristic polynomial but using some non-commutative analog of the determinant. This approach sounds less viable if quantum computers could compute some analogs of the determinant more quickly. 

I know I could go back through Wand and Plotkin and Pitts and probably find the answers to (3) there, but it would be nice to have a succinct general construction like in their book chapter. Specifically I would like a reference that includes Pitt's minimal invariants work (otherwise Abramsky-Jung is probably sufficient). 

In the months since I asked this question, I think I have found a sensible answer. Often, the type of relations considered do not compose. For instance, if your notion of a relation $R : D \to E$ between $\omega$CPOs is an $\omega$-chain complete subset of $|D|\times |E|$, then the relation $R : \omega + 1 \to \mathbb{N}$ between the ordered naturals plus infinity $\omega+1$ and the flat CPO of naturals $\mathbb{N}$ given by $R(n,n)$ holds and nothing else, then $R$ is admissible, as is its converse, but the composite $R;R^T : \omega+1 \to \omega + 1$ is not chain-complete, since $n R;R^T n$ for every natural, but we don't have $\omega R; R^T \omega$. 

I'll concur with JɛﬀE that MS degrees are viewed as "consolation prizes" in the sciences in the U.S. because people usually take them when they fail qualifying exams in Ph.D programs. And who pays to do an MS when they'll pay you to do a Ph.D directly? I'd also concur with David Harris that mathematics might prove the most efficient route to doing serious theoretical work, but this depends entirely upon the program. Ask any math or comp. sci. departments who make offers how they feel about students taking courses outside the department though. I do recommend that you broaden your interests in more applied computer science of course, but do so by reading something. There are mathematically entertaining topics around databases, like Bloom filters, as well as fun applied papers, like the CryptDB articles. 

I have recently been working with polynomial functors and monads based mostly on Gambino-Kock. There they define polynomial functors in a Locally Cartesian Closed Category (LCCC) and extensively use dependent type theory to define constructions on polynomials because working in the internal language is much easier than the diagrammtic language. However, I am interested in polynomial monads for their application to defining flavors of multi-category and for that I need to use polynomals in Cat and similar categories, which have pullbacks, but are not locally closed. There you instead require in the polynomial diagrams $$I \leftarrow E \to B \to J$$ that the middle arrow $E \to B$ is exponentiable, since that is the only $\Pi$ you use. The only paper I know of that does this is this which doesn't use the internal language at all and is much more difficult for me at least because of it. Is there some kind of restriction I can put on dependent type theory so that I can use it as an internal language for a category with pullbacks rather than an LCCC? Specifically I want to be able to manipulate exponentiable morphisms as dependent types that I can take $\Pi$ of, but not every dependent type should be exponentiable. Then hopefully the usual proofs using dependent type theory would still be valid, because every use of $\Pi$ would be modeled by an exponentiable morphism. My own idea would be to have dependent types interpreted as exponentiable morphisms and other terms interpreted as arbitrary morphisms, but since you can define from any $x : A \vdash t : B$ (where $\cdot \vdash B$) the dependent type: $$b : B \vdash \sum_{x:A} t = b$$ it seems like the type theory would make every morphism exponentiable. 

There is a sound theory of overloading operators and functions realized by type classes in Haskell, and to rougher extent by traits in Rust, etc. In mathematics however, there are many situations where one set carries the same structure in multiple ways, like the integers being a monoid under both addition and multiplication. We normally just give these different names, but potentially one wants to abstract some tougher mathematical function, or a proof done in the type system. In principle, one could do this the way mathematicians do it, by applying a type class to a type that associates the operations to the base type, as opposed to just the set itself with a fixed association. Is that the "right" or "only" way to gain this flexibility? Or is there something else? In particular, there are a bunch of languages like Scala that do overloading of overloading rules in a rather dangerously complex ways, well even incoherent instances in Haskell probably. It'd be interesting if there were clearer "more parametric" way to achieve the ends that motivates those design decisions. 

For ordered enumeration instead of random generation you are getting into the realm of combinatorics. I don't know of any generic results, but this paper Counting and Generating Lambda Terms describes an enumeration of untyped terms and empirical data on the sieve approach to enumerating typed lambda terms. It looks like they use a hindley-milner type system so no annotations are needed. On the other hand if you want to generate typed terms directly, there are libraries like SciFe (website,paper) and data/enumerate (docs,draft paper) that support "dependent enumeration" where you enumerate one thing and then select what enumeration to use based on that (essentially enumeration of Sigma types), that is essential for enumerating typed terms in non-trivial languages. Dependent enumeration isn't fast either, but it might be faster than a sieve. 

A Turning machine with insertion and deletion operations can be simulated by an ordinary Turing machine with a quadratic time cost. Do we know how insertion and deletion fit into the polynomial time hierarchy though? In particular, does anyone know a quadratic single-tape Turing machine that cannot be simulated by a linear time single-tape Turing machine with insertion and deletion? I've gathered that separation results are often more powerful, and maybe easier to prove, for the nondeterministic time hierarchy. Is that perhaps an easier place to attack this? If so, that's great because I'm ultimately most interested in rewrite systems anyways. 

How much is known about nondeterministic linear time? I'm aware that $$ \mathrm{NTIME}(n) \neq \mathrm{DTIME}(n).$$ Is there an $m > 1$ so that $\mathrm{NTIME}(n) \not\subset \mathrm{DTIME}(n^m)$? Are there any arguments that $\mathrm{NTIME}(n) \subset \mathrm{P}$ should be unlikely?