First, get rid of phpMyAdmin. It's just a giant security hole, and doesn't even have a very pretty interface. You'll find that almost no professional DBAs or system administrators will go anywhere near it. It's not even really necessary, since the basics of SQL aren't hard to pick up. Second, the database files themselves are in MySQL's , so just check that in or ask MySQL where it is. 

There are plenty of ways to deal with brute-force attacks on various services, the most commonly used of which is fail2ban, but this proposal seems like a Very Bad Idea. 

RHEL users who have set a specific minor release must first set 6.5 as their release target before running the above update: 

I can tell that you didn't actually install the packages, or you would not have asked this question. Generally, yum gets this right already, installing dependencies before the package that requires them. It is only when listing the packages to be installed that they are sorted, for convenience. 

The obvious workaround is to install an IPv6-capable firewall (e.g. Comodo, ZoneAlarm) on the server. You could also try configuring it to allow access by domain, rather than by IP address ranges. Of course if you have Server 2003 then you have absolutely no business running IPv6 on that thing at all; the IPv6 stack wasn't ready for production use and MS never updated it for XP/2003. 

OK, this is a very strange scenario, and you seem to be on the right track. Instead of the , though, I would and use an to define the 404 error page. For example: 

Run a malware scanner, such as maldet, or AVG, or both, on your user's data. Most malicious scripts are picked up by such tools. 

Beware that the RPMs distributed by MySQL themselves are not binary compatible with your system and will break compatibility with other existing software, as well as breaking the dependency chain that yum maintains. (MySQL intends to fix its RPM packages in version 5.7.) For people needing an updated version of MySQL, I generally recommend using the remi repository, since he provides packages with maximum backward compatibility that will not break yum (or other things!). 

Your resources (such as virtual machine instances) are stopped when your free trial ends, and you had not upgraded your account. After upgrading your account, you simply need to restart them. 

Just run each version of php-fpm on a different port (or socket) and configure the appropriate port in your parameter in your nginx block. For instance, you might have 5.3 run on port 9000 and 5.4 run on port 9001. 

The first tile is Automatic and Windows will derive the colors from the desktop background wallpaper. (Assuming all the bugs are fixed.) Selecting any other tile will allow customization. 

Fedora is really not meant to be upgraded this way. And you haven't even gotten to the difficult one yet (16-17). That said, I've done this dozens of times and run into just about every conceivable thing that could go awry. Here are my recommendations. If at all possible, the best and fastest way to do this is to create a new cloud instance with the latest vesrion of Fedora (17) and then transfer your data and configuration to it. Then destroy the old cloud instance. Of course this relies on Rackspace having a Fedora 17 installation image, and I don't know if they do. I have two custom shell scripts just for this purpose, one of which copies all of the config files I need and the data being served from the old system, and the other of which unpacks all the data created by the first script and then installs any necessary packages. If you're set on continuing down this path of madness, then keep reading. The error usually occurs when you have two different versions of a package on your system, and sometimes one of them is of one architecture and one is of another (e.g. the old package is i686 and the new is x86_64). It can also occur if a previous run of yum was interrupted and you tried to do another yum transaction without resuming the interrupted one. This suggests to me that your upgrade from Fedora 14 to 15 was not as complete as you thought it was. First, stop trying to update to 16 or higher until you resolve this issue. Run to finish any pending yum updates. This is the easy fix. If this fixes the issue, skip the rest of this. If not, continue... Now, for each package throwing this error, check to see what you have installed: 

This specifies whether and for how long OPcache should wait before checking to see if a file on disk has changed. In this case, yes, and after two seconds. First, try re-enabling this option, as it sounds like you have turned it off. 

Your PHP session files must be readable by PHP/the web server, not necessarily by all users (this is a security risk). To fix this issue, check what user your PHP (or apache with mod_php) is running as, and set the file ownership to that user for all of the session files (and the directory containing them, usually /var/lib/php/session or something similar). 

Don't even think about giving the root user a blank password. If you do this, it's trivial to leverage a non-root compromise into a root compromise. Consider one of many possible scenarios: An attacker uses an unpatched vulnerability to compromise the web server or the application the web server is serving. He gets a shell running as the web server's user. With a blank root password, he merely needs to execute and he now has root. 

Things just go downhill from there. This means Apache hit the limit of the maximum number of processes allowed to run. You can view the limit by running . To increase the limit, run or edit (probably Red Hat specific) and add a configuration directive for Apache's user to increase the value for to something more reasonable. You can also try reducing Apache's and directives. 

Why change the data directory? That just makes your life complicated. You could have mounted the filesystem at the point of the default data directory, and everything would have just worked. It would also be easier to understand and maintain. 

It looks like you're trying to log in to your own mail server to send outgoing mail. To do this securely and properly, you need to set up SMTP authentication for Postfix. This is a non-trivial task, but the Postfix docs should get you started. Once set up properly, you will connect to your mail server on port 587 (instead of 25), authenticate to it with your username and password, and your mail will go through. The benefit of this is that when you have SMTP authentication set up, authenticated users do not have to deal with the usual restrictions of having an IP address with a reverse DNS entry or a fully qualified hostname or the other restrictions that mail servers impose for security reasons. 

I got similar results pinging your IP address from the US. When I pinged 81.212.77.58, the next hop upstream from you, which I presume is your ISP's equipment, I got back a TTL of 243 every time. This is obviously wrong. The next hop upstream from that acted reasonably, with a TTL of 54 every time. My strong suspicion based on these results is that your ISP is mangling the packets. 

means that the recipient email server believes that the email address does not exist at the destination domain, and therefore has no way to deliver it. Unless you simply made a typo in the email address, this is not something that you can fix, and must be addressed at the other end. 

It looks like your files have the wrong SELinux security contexts. When I install the package (it appears to come from EPEL) and inspect those files, they all have the type, rather than . Try fixing the security labels: 

I don't see specified in your Postfix configuration . If this is not specified, then anyone on the same local network as you can relay mail through your server without authentication, making your mail server at least a somewhat open relay. If your system has a global IP address, for instance because you're hosted at a VPS provider of some sort (like Digital Ocean), then that makes it open to attack from machines nearby, hosted at that same provider. This should be fixed immediately. To lock it down so that only the local host can send unauthenticated mail through the server: 

You can perfectly well manage your DNS within CloudFlare. Just use its DNS manager to set your MX records to whatever they need to be. 

You don't have anything installed on your system that is capable of sending mail. Thus, the output is thrown away. Consider installing an MTA so that you can have the output emailed to you and then find out what is actually happening. 

I was able to ping these machines, so I suspect they are simply dropping the queries. This suggests that these servers haven't been set up correctly to serve your domain. This makes your next step to contact them and find out why. 

No, that won't work. In order to sign certificates you need your own certificate authority certificate. The certificates you purchase are signed by a certificate authority, but specifically marked as not being a certificate authority certificate. Check the "Certificate Basic Constraints" in your certificate, and you will see that it "Is not a Certification Authority". 

MySQL is not starting. To find out why, check MySQL's own error logs, generally located at , and the general system log (which should be on a Debian based system). 

You've mistyped the domain name. It should be , but you entered . Correct this in your Postfix file. 

You defined two virtual hosts for your domain, and so only one of them is used. Fix this by removing one of them. 

Keep in mind you'll have to wrap this in an to test for IE 10, and If is evil, so this configuration will probably come back to bite you. If you only have one in the block, you'll probably be OK... 

I have never seen anyone try to use service names in that argument. Try using the equivalent numeric port numbers instead: 

Since you're binding to a port below 1024, it must be started with root privileges. Try something like: 

If you want to use extundelete on the root filesystem, you have to boot the server from installation/rescue media. You will also need a second disk to store recovered files, otherwise you risk destroying the very files you intend to save. All in all, it's easiest to just restore the files from backup. 

You can ask the host to install the module for you. You can switch to a different VPS which is not based on OpenVZ. 

You can't give a specific value for an environment variable in , but you can certainly send the existing environment variable only to specific hosts. 

Place your rules in a file in the directory, with a filename ending in . This requires systemd 226 or higher, which in Ubuntu means 16.04 LTS or later. (And if you think that looks like JavaScript, that's because it is JavaScript.) You can also limit it to specific users by checking , e.g.: 

The documentation states that you can set and to whatever you want. They default to the journal, but you can redirect them to any of several places. 

A CNAME record won't work in this scenario. The web server you redirect to has to be aware of the redirect and set up to support it. Instead, set up an AAAA record with your IPv6 address. 

You can easily fit all that into a "micro" EC2 instance. I recommend against Amazon Linux, though; it often has bizarre problems caused by a lack of quality control in packaging. Choose something more stable, such as CentOS, Debian, Fedora or Ubuntu, depending on your specific needs. Also keep in mind that it's only free for a year. After that, you'll be paying around $17-$20 per month, give or take, depending on how much bandwidth you consume. (And remember they charge per gigabyte, so you could pay a lot more...) When your time is up, you may want to go shopping elsewhere. One of my favorite places is Low End Box. 

You should have this in , and you don't have to reboot. Just . As for agetty in a shell, it really was not designed to run in the foreground and control some other terminal; while you could pass it a tty argument of , this would cause it to print a login prompt in your terminal, rather than on the serial port, which isn't what you want. 

The problem is not Fedora 20, nor is it Mock. It's RHEL 5. The RPM macro was set to in both RHEL 4 and RHEL 5. The problem is that the macro was never used to build those distributions, so nobody paid any attention to its value. It only became an issue when people began backporting packages from later Fedora which did use the macro. And, of course, because RHEL is a "stable" enterprise distribution which aims to not break compatibility during its lifecycle, this will never be changed. The macro works as you expect in RHEL 6 and 7. If you still have to support RHEL 5 boxes, you (and everyone else) are stuck with workarounds like the ones you already proposed. The simple and clean one is the first one you suggested: 

These are the reasons why using nginx on Windows for high performance, high scalability environments is a bad idea. Switch to nginx on a non-Windows operating system as soon as possible. 

The obvious thing is to make sure that your WAN router, whatever it is, is sending inbound port 80 traffic to the server you want. 

is fine, but you will want to add the package so that the hypervisor can cleanly shutdown and reboot the virtual machine. That's about all I can think of. 

You're trying to install packages from the spacewalk-client repository for CentOS 7 on CentOS 6. This has no chance of working. Install the correct packages instead. 

I'm setting up a FreeIPA domain. In my lab are three virtual machines: the domain controller , and two clients and (creative, yes, I know). All three VMs are running freshly installed CentOS 6.4 (FreeIPA 3.0.0). I've installed the IPA server, creating a domain which we'll call here, with DNS service and automatic DNS updates enabled. I've successfully joined the two VMs to the domain. But the dynamic DNS updates are only putting AAAA records into the DNS. No A records are ever inserted.