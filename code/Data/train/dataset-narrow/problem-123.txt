This entirely depends on the chipset in your device, as not all of them have equal capabilities on Tx/Rx rates. I personally have found no better resources than wikidevi.com for looking up the capabilities of wireless network adapters. To understand wireless that is 802.11n or newer, you need to understand the shorthand often used in their technical capabilities, namely AxB:C. A represents the number of Tx radio chains are available to the device, B represents the number of Rx radio chains, and C represents the number of spatial streams. A device will need to have a number of antennas equal to the highest of either A or B to make use of its capabilities (i.e. I have seen a 3x3:3 adapter in a laptop with only two antennas and in such a case it will operate no better than a 2x2:2 device). You can never have more spatial streams than you have either Tx or Rx radio chains (i.e. you need at least one radio chain to make use of a spatial stream). You can however have more radio chains than spatial streams, and in these cases they can provide other benefits (resistance to interference, extended range, etc). To your specific question, I know of several Intel wireless chipsets that do not have equal capabilities on Tx and Rx. The Intel 5100 is an example of a 1x2:2 network adapter. This device can transmit up to 150Mbps and receive data up to 300Mbps. (Edit: I was mistaken in the second device as I thought it was a 2x3:3, but when I looked at it again, it is a 2x3:2 so correcting that here.) The Intel 4965AGN is an example of a 2x3:2 device. While this device can transmit and receive up to 300Mbps, its actual Rx performance will tend to be better than the Tx due to the added capabilities the extra Rx radio chain provide. I also believe I have seen other vendors with this type of lopsided Tx/Rx configuration as well, I just don't remember example chipsets off hand. For your second question, the data rate used by Tx on the device and Tx on the AP can never exceed the capabilities of either device. 

The previous is based on definitions that may be a bit lacking. Simply stated, a WSN is neither infrastructure based nor infrastructure-less. A WSN is simply a network of sensors that have some means of communicating data. The method of communication may be 802.11, Bluetooth, Zigbee or any of dozens of standard wireless communications methods (or a much larger number of proprietary ones). The mode of operation with the sensor network can also be of any type, whether that is some sort of infrastructure, ad hoc, or mesh topology. They may use some sort of base station/gateway, connect to a traditional network directly or connect directly to some sort of data collection point. 

What you describe is actually similar to the way that Meru Networks enterprise wireless works. The controllers actually attempt to determine the best AP and move the station assignment between APs. The detractors of this approach will point out that 802.11 doesn't always lend itself to this design. While the system may determine that a certain AP is "best," there is no way it can actually determine the conditions where the client is actually located. This is born out by many wireless troubleshooting tools where most professionals will tell you you need to run them as close to where the clients are to gather the correct information. Personally, I see flaws on both sides, as the client also can't determine conditions at the AP location so is just as likely to select the wrong AP itself. However, 802.11 is always advancing and improving, especially when it comes to sharing information between station/network and faster roaming. Several amendments of note in this aspect are 802.11k, 802.11r, and 802.11v which have all been approved and rolled up in the 802.11-2012 maintenance release. Two additional amendments going through the approval process are 802.11ai and 802.11aq. 

Host A will either send the ICMP after ARP or omit ARP depending on the status of the entry for Host B in it's ARP table. 

Certainly, but this is generally not the case in a well engineered network. You should be able to design your network in a way that would allow the majority of your internal server-to-server traffic ("east-west" as you put it) even if it does need to cross your core or between data centers. While often the load balancer is the default gateway for the servers behind it, I have seen setups where a routing protocol (i.e. OSPF or RIP) is run to allow the "east-west" traffic to circumvent the load balancer, or in smaller deployments where static routes were used. If the load balancers are going to be a bottleneck even in with a good design (i.e. the volume of traffic is just that high), then there are ways of load balancing across multiple load balancers as well. 

Yes, but does it really matter? I have known network professionals who haven't run OSPF in any of the networks they managed. What any given network professional has seen or not seen doesn't really make a difference to what makes good network design for a particular network. 

If you use Cisco transceivers, then yes it does depend on the SFPs. AFAIK, all Cisco transceivers operate at only one speed or the other. Some third party vendors do sell transceivers that operate at either 100Mbps or 1000Mbps. Keep in mind that these are not officially supported by Cisco and you will have to do your research to make sure they will work in your switch. Also, since it seems you are somewhat new to fiber, make sure you are using compatible transceivers. In your case, if your existing devices are using 100base-FX, you would not be able to use a third party 100/1000base-SX transceiver. 

First, to clarify, the 802.11 standards are proposed and maintained by the IEEE, specifically the 802.11 working group. Wi-Fi is a trademark of the Wi-Fi Alliance which provides a voluntary certification program for devices to be Wi-Fi Certified. Devices do not need to be Wi-Fi Certified to operate as 802.11 devices. 

The speed of the flow of data makes no difference in the physics of the medium. By this I mean that it takes the same time for an electric signal to flow from one side of a 100 meter copper run to the other, no matter if that signal is part of a 10Mbps or a 1Gbps link. If you change from copper to fiber, then you may notice a small improvement, but it really should be only a marginal difference. Now, there are other factors that may come into play, for instance the equipment that can do 10Gbps is generally more capable of processing the frames/packets than equipment that is designed to do 10Mbps, so the latency added by the equipment may be reduced as well. But this is entirely dependent on the capabilities of the equipment and not on the speed of the link. 

While there are many ROM only components in many Cisco devices, usually this is used as a misnomer for persistent storage on the device (i.e. where the bootable images, configuration, and other such files are stored), also often referred to as flash or NVRAM. After all, we don't really care how much ROM is installed as you can't use ROM memory. The line clearly indicates how much you have installed. Now some routers and switches will allow you to use other sources of flash as well, such as compact flash. So this is another source of storage that may not be represented on a show version. 

In this case, you are wrong. Since the link between the two switches is an access port, there is no VLAN tagging involved. Think of it this way, switch two is a unconfigured switch (i.e. operating like a dumb switch) so all ports are in VLAN 1. This would still provide connectivity as well. 

Frankly, there is no good choice in an environment that doesn't have the staff with the knowledge to maintain it. Without knowledgeable staff, even the best and most mainstream equipment will fail spectacularly. This is where I am personally split on solutions such as Cumulus Linux. It is marketed as fitting within potential *nix skill sets that may already exist in an organization. While this is true, I have my concerns. While most of the good *nix admins I have worked with have at least a decent understanding of networking, they aren't network engineers. Same as most of the good network engineers I know have a decent understanding of *nix. That doesn't mean I want a network engineer designing, implementing, operating, and troubleshooting my *nix environment, nor do I want a *nix admin doing the same for my network. The flip side is that if you only have the resources to hire one or the other, it is the organization that has to make the decision on which is more important. If they do choose the *nix admin, then perhaps Cumulus Linux may be a better platform for them to operate than having to learn a new OS. 

There is the potential for both risks and rewards with choosing such a solution. Will the company disappear leaving the product abandoned? Possibly. Are there greater chances of bugs/problems with the code that aren't resolved in a timely fashion? Likely. But on the other hand, you could be on the cutting edge of new features, performance or other benefits. Larger vendors acquire smaller companies all the time to acquire innovative technology and intellectual property they develop. You could benefit from this innovation before it makes a wider impact on the industry. Even if it never does, there are many examples of technologies that may have been better but fade away due to other market considerations. Additionally, most of these types "commodity" or "merchant" silicone products are delivering high performance devices at much lower costs than the more established players in the market. Each organizations needs to balance their costs vs. their risks and make their own judgement. 

One of the uses of broadcast ARP is the gratuitous ARP replies sent by some clustering or link aggregation (i.e. teaming) solutions. This is the process they will typically use when they want to move traffic from one interface to another. This process will update all hosts on the local subnet (including the gateway) as well as causing the L2 switches to update their MAC address tables. The result is that all the traffic should switch over to the new interface smoothly and quickly. 

Wireshark uses dissectors and lua scripts to analyze and classify capture traffic (or parts thereof). What is displayed in the Protocol field of Wireshark's Packet List Pane is the information returned that is most specific after analyzing the data and will determine how the data is presented. If the UDP dissector is the most specific dissector for the captured data, than the Protocol column will show UDP. However many types of UDP traffic will be identified (SIP, RTP, DNS, etc). The same is true for TCP traffic as well. Typically you will see this as HTTP, FTP, IRC, etc. 

Generally speaking, the direction of the traffic is determined by the location of the host establishing the connection. In your example, as you indicated, the original VPN connection (#1) is inbound because the traffic originates at a host outside the network which establishes a connection to an internal resource. Once this connection is established (#2), while the data flows in both directions, it is still an inbound connection because it was still initiated from the external host. All return traffic is considered to be part of this original connection. When a client is connected to VPN, this establishes a "virtual" presence inside the network. So, for the VPN client accessing the web site (#3), the physical host uses the inbound connection to the virtual host that was already created, and the virtual host establishes an outbound connection through the firewall to the web site. Again, this may not be universally true with all vendors, but generally this is how inbound/outbound connections are treated. 

Edit to add means to test: Gave this a bit more thought and how I would go about testing this is as follows: 

As pointed out in the comments while the drop count looks high, when compared to the total traffic it is actually quite low. The output drop rate is 2.4e-5 or 0.0024% so if the drops occur at regular intervals your test stream would experience a missed packet approximately every 41.7k packets sent. Even multicast should have no trouble recovering from a drop rate that low and an end user will likely not notice anything to complain about. That is also assuming any or all the drops are multicast. You also seem to be trying to understand how/why the drops are occurring and are looking at bursts as a source of the drops. Is there any reason you believe this to be the case? You haven't provided your version of code or the configuration from the ASR, but I would lean more towards something like a bug such as CSCuw45886 to be the source of your problems. 

It sounds like you are just disconnecting and reconnecting. Disconnecting is not a "hang up" and does not cause the user on console to logoff. Use the "exit" command to log off and you should be prompted for the password. This is also why you always want to set the "exec-timeout" on your lines. Otherwise, if someone connects to the console and forgets to log off, someone else may come along after them, connect and get access they shouldn't. 

In essence, the same question, but you are correct. Both the notebook and cellphone will communicate with the AP. The AP would pass traffic from one client device to another (unless it is configured to prevent client to client traffic). 

If your switches are all Cisco and running in VTP server or client mode, then you can enable VLAN pruning on the VTP server(s) with the command. This will prune unnecessary VLANs from your trunk links automatically. If any of your switches are in VTP transparent mode or you use multiple vendors, you may need to manually prune unnecessary VLANs by using command to the trunk interfaces. Reduce the number of active trunk ports or access ports. Trunk ports will make the largest difference. For instance, if you have multiple trunk ports between the same two switches, converting them to a single link aggregation group will reduce the number of logical connections. Remove unnecessary VLANs. Maybe you have some old unused VLANs that are no longer needed? Remove them. 

To understand the answer to this question, you need to understand some wireless terminology. The service set identifier or SSID is the logical (i.e. human readable) name used by a wireless network. The basic service set or BSS consists of a single access point (or virtual access point) and any stations associated to the AP (VAP). Each WLAN that an AP provides service for will use a 48-bit address as the BSSID for the BSS, which is very similar to a MAC address (and may use the MAC address of the AP). The extended service set or ESS consists of one or more BSS connected to the same network. The SSID is actually more related to the ESS than the BSS, and most client devices don't care which specific BSS they join, rather they look to join the ESS. This is very advantageous in multiple AP environments as this allows the station to choose a better AP to connect (rather than a specific BSSID which may be further away with weaker signal/lower performance). Some clients (especially most *nix based clients) will actually allow you to optionally select a BSSID as well. This can be more secure as it will prevent your client from connecting to a "rogue" access point that is broadcasting the same SSID as the network you expect to connect. 

Quality of Service (aka QoS) - this could include rate limits, policing, marking traffic, etc. Depending on the capabilities of the device in use, this can take on a number of forms. Storm Control - depending on you device, this can provide hard limits and/or scaled limits on the amount of traffic that is received from a host. This will typically at least include broadcast traffic, but may also include multicast and/or unicast traffic as well. 802.1X/RADIUS - not only does this provide limitations requiring devices to authenticate to the network, you can configure policies that the host will be limited by, such as the amount of traffic allowed over a given period of time. IDS/IPS/SEIM - this would be a security based solution that would be looking for various types of events or abnormal behaviors. It can generally be configured to alert and/or take action when certain types of events occur.