Apparently for iOS specifically, there is no Bluetooth API exposed via the SDK. While the rest of this answer may apply to other platforms, you aren't going to be able to make it work in the iPhone. For other platforms... as far as I know there's is no API for Bluetooth access in Flex. You have a few other options though: 

"What happens" depends entirely on how you process the keyboard event queue you're producing. If, during the processing of the queue, you dispatch handling for both the key down and the key up event, nothing interesting happens: the things you do on key-down and on key-up still happen normally, they just happen with less of a delay between them. If you instead process the queue once a frame and resolve it into a "current keyboard state", then the key state will probably, as you note, "cancel out" resulting in the key state showing "not pressed." Chances are, however, if all you're doing with the queue is turning it into a current state you're wasting your time (you could use the APIs that feed the queue to do that directly with no loss of functionality). If, however, you're using the using the queue to get a higher-level keyboard state for the frame, one that for example distinguishes between a key being held down versus tapped, for example, you'll want be tracking event times in the queue so you know how long it was between key down and key up. If it was short enough, consider that a key "tap" and dispatch accordingly. If it was longer, maybe consider it "held" for the purposes of the frame. If you just doing the second thing and want to avoid losing the key state for events that occur in a single frame, tracking the down/up time can let you do that as well. 

This is kind of a dangerous question, as Kylotan commented. Of the three options you've posted, the first sounds the most ideal to me based on how I've interpreted what you wrote (which may be wrong). However I would advocate in fact for an option you haven't listed when you actually have fewer components that accomplish a broader range of functionality. Having individual components for stat modification seems granular to an extreme, and is essentially taking you down the path of shoehorning your component composition system into a domain-specific scripting language. Rather, I might consider abandoning some of these overly-granular components for a simple "script" component instead, which simply executes some Python (or Lua, et cetera) code of the author's choice, passing an interface to a script API for the component/entity in question that allows it to do things like affect statistics or create explosions or whatever. 

As for Entropia Universe in particular, you're right that being based out of Sweden is probably the key factor in allowing it to operate the way it does. Swedish law regarding online gambling appears to be far more amenable to the scenario than US or UK law. 

Guns tend to recoil vertically far more than they recoil to the left or right (at least the few I've fired -- pistols and a shotgun -- have done so to the best of my recollection). I have a feeling the random variance in X would just feel unusual. I would start with an implementation that kicks the gun/view upwards only, probably based on the power of the gun. When fired, a cooldown timer starts. If the gun is fired again while the cooldown timer is still counting down, the vertical kick is applied again, with intensity proportional to how much time is left on the timer. After a certain threshold it might be appropriate to add X axis variance to indicate that the player is really losing control of the (probably automatic) weapon. I've never fired such a thing so I don't know what that is supposed to feel like, but I imagine "chaotic" would fit nicely. The cooldown should probably scale a bit -- but nonlinearly -- as you continue to fire and the intensity of the kicks should probably be similarly damped or smoothed. Pure linear measures might feel too harsh. Whatever you do, it sounds like your initial plans called for a fair bit of randomization and I don't think that would be appropriate -- a small bit, certainly, but sudden large recoils amidst smaller ones seem like they'd be unusual. 

Hire a lawyer. The earlier the better -- you should have done it already to draw up contracts concerning who retains what IP if people leave or disagree, et cetera. See this article on the legal issues related to ad hoc, indie development teams (written by a real lawyer, which I am not, so my advice is not legal advice). 

For slightly more advanced scenarios, you may find Sean Middleditch's article on slot maps interesting. 

To say "Python is slow compared to C++" is a generalization that ignores a lot of real-world practicalities and is usually a poor kind of judgement to rely on. What you really want to do is look at what a particular language or technology can bring to the table in terms of your needs and, similarly, evaluate any potential downfalls of that technology against your needs. If you are having to ask this kind of a question, there is a very good chance that the limiting factor in terms of performance of any game you make will be you and not the technology choices themselves. Consequently the optimal choice is the one that empowers you the most, in other words, the technology or language you already know best. As for the poor performance of the Game Maker game you played, that could be attributable to a number of factors, some of which are specific to that game, such as specific poor code that may have been written via Game Maker's tools or scripting languages. It isn't necessarily a fault of Game Maker itself. 

This was a bug in SlimDX; we just left the method out. It was fixed in revision 2134 and should be in the binaries for our September release (which, the name notwithstanding, was shipped in October a few days ago). You can simply call with an array of shader resource views on any now. 

Presumably you have a coordinate system for your level, so that you always know where any individual entity in the level is (or, more likely, where those entities are spawned so that you know when they should become active and start engaging the player). You've also got your player entity in there, and that's the one you want your camera to track. The camera itself needs a position in the level, too -- I will assume here that the position of the camera in the world corresponds to the center of the screen, but you could just as easily choose another point of reference. The simple solution is to always have the player centered in the screen, so the camera's position is always set to the player's position every frame. This tends to be somewhat unpleasant for player's, however. A better solution is to allow the player to move around within the center region of the screen and only scroll when the player character gets near the edge of the screen -- since you know the camera's position and the width of the screen, you can use that to compute two borders. When the player's X coordinate falls outside of the range of one of those borders, adjust the camera's X coordinate appropriately. To scroll your background, you can do what notabene suggested and simply adjust the UV coordinates of the quad rendering the background (ideally this would be done by setting a shader parameter and doing the offset in the shader, instead of mapping and unmapping the quad's vertex buffer every frame, but you could do either). The important part there is that the addressing mode be set to wrap. 

The clear color is part of your OpenGL context state and, once set, will not be changed or reset unless you (or some code you call) does so. Consequently, you need only call once during initialization if you know you (and all code you call) will never again change it. You can call it per-frame if you like, especially if your code calls out to external code you aren't in control over and whose actions cannot be determined when you write your own code (such as plugins). But you don't need to. Generally the "performance impact" of doing so will be non-measurable. The same is true of setting the state for the projection matrix; you only need to do it once, unless you need to change it or restore it after some other code has potentially changed it. That sample code is just that: sample code. It's design to clearly and concisely illustrate a point. 

D3D10 core didn't have a mesh class; you're probably thinking of ID3DX10Mesh, which is actually part of the D3DX API. D3DX itself was wholly deprecated with Windows 8. The relevant math bits were moved into another library. The higher-level utility interfaces, like mesh, were not ported. The API was removed because it was a continuation of the evolving focus of D3D and its related APIs: to become narrower in scope, more representative of only the underlying graphics hardware. APIs like the mesh interface were an attempt both to provide something much higher level than the GPU actually does, and to be a one-size-fits-all solution (which is often a lowest-common-denominator solution). Furthermore, by divorcing the graphics library from the utility library, it's easier for Microsoft to utilize separate (and more appropriate) release vehicles for both, and easier for the components to be updated and versioned independently. All of the above factors contributed significantly to the decision to deprecate the functionality (which had been underway since the 9-to-10 transition, when the built-in functionality to load meshes from files vanished). You should look at the DirectXTK for potential replacements to interfaces you miss from D3DX. 

It sounds like you essentially want to have specific objects ignore gravity, is that correct? Since gravity is a property of the world object, it looks like the way to do this is to either 

A breakdown of capabilities by feature level is available here. You'll note there is no explicit mention of MSAA support. However, the documentation does point out that for the 9.3 feature level, no guarantee is made for MSAA support. 

Practical Linear Algebra and Fundamentals of Computer Graphics are two very good books that will cover the topics you mention (and their use within computer graphics), if you're in to books and such. 

I am pretty sure you can't do this -- you have to change the render target between passes from the CPU side of things. The list of effect states that can be manipulated by effect files does not include anything regarding the render target. 

It really depends. You're likely to gain the most benefit by performing operations with no data interdependence on each other in parallel, but as with anything you should profile beforehand (and afterwards) to make sure you're getting the most benefit from your efforts. For example, to give some concrete advice regarding one of your examples, loading data: If you can factor your resource loading into independent chunks, this can be beneficial. However, you'll want to investigate whether or not you're already disk-bound. If the slow part of your loading operations is reading from the disk (more likely with non-SSDs, such as platter drives or optical media) you may not improve your situation. Similarly, if the ultimate destination of the data you read from the disk isn't independent, you should verify that the synchronization cost of installing all the loaded data into it isn't a bottleneck. At work we all have SSDs in our development machines, and content containers store their data independently in memory, so switching our toolchain to a multithreaded loading system did have significant performance implications (a 600% improvement in load times). But your mileage may vary. Similar caveats apply to other operations, such as game logic updates. If you can organize the problem into discrete chunks of computation that don't depend on eachother, you can probably see some benefit from a concurrent model. But if you find yourself having to employ lots of locks or other thread synchronization primitives, chances are you're actually trying to parallelize the serial part of the task and will introduce more overhead than you'll remove. You want to approach concurrency at the large scale, not the small one. Think about splitting operations into multiple concurrent tasks on the scale of "loading data" and "per frame game updates." Generally, looking at the scale of "this big screenshot function" is too small to be useful -- thus, your "occasional heavy method" category of operations is not likely to gain much benefit. Screenshots are inherently serial, except for the actual disk IO portion (covered earlier in our discussion of loading), per-pixel operations are already best handled by the GPU, and I don't think a "full world update" is an "occasional heavy method" but rather a synonym for what was discussed previous regarding updating the game world. 

If the isn't successful, compilation errors can be recovered from the buffer (it's just a string; you can case the returned from ). 

When you resize a window that you are rendering to, you generally also need to adjust the rendering viewport bounds and potentially the bounds of any intermediate render targets (depending what you are doing with them). In OpenGL, you can make use of the function to handle the viewport adjustment. Update it when your window size changes. The values of the graphics API's viewport are used to compute the window-space coordinates of your rendered geometry prior to the rasterization of that geometry, if your viewport bounds (and again, potentially render target bounds, depending) do not match the physical bounds of your window, you'll get distorted results. If you have any intermediate render targets to resize, this is usually more involved, and usually means having to destroy and recreate the render target at the appropriate size or maintaining a separate set of bounds information allowing you to reuse the target if you decrease the render target size and keep reusing it as long as you don't expand beyond the original (at which case you reallocate and update the bounds). This also may require some clamping on your part within your rendering.