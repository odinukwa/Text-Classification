The reason you need to explicitly inject a default route into a NSSA area is because the external route(s) you are injecting could also be (and often is) a default route. If you redistribute a default route (for example, a static route) into an NSSA, that would conflict with the type 3 default route from the ABR. To avoid that problem, the type 3 default route is optional. 

“Best” is in the eye of the beholder, but if you use one router for both providers, that becomes a single point of failure. With a router for each provider, you are protected if one router fails. Yes, I’d announce your network to both peers. Otherwise, what’s the point of having two peers? Lots of options here. To keep things simple, you can have your two routers run VRRP on their inside interfaces on a single VLAN. All your servers will also be on that VLAN with the VRRP address as their default gateway. The routers also peer with each other. So if a router fails, or a link fails, you still have connectivity. There are other ways to go depending on how complex your servers are. You haven’t mentioned any security concerns. Do you plan to have firewalls, ACLs etc? Yes. Your switches will connect your VLAN(s) via a trunk. Logically, all your switches will have all VLANs. The Juniper switches will also allow you to manage all the switches as a single logical entity. 

If you think about it for a moment, you'll realize that the congestion is happening at the far end of your WAN circuit (i.e., at your provider). Their interface is not prioritizing real-time traffic, so you are seeing poor audio and video performance. It is as if you are at the finish line of an auto race, but your team can't get out of their driveway because of all the big trucks on the highway. Unfortunately, this means that there is not a lot you can do from your end. The traffic has already been delayed by the time it gets to you. One possibility is to use a packet shaping appliance. This will control your FTP traffic by modifying the window size in the ACK packets your ftp server sends back. If the window size is reduced, the sender will have to slow down. This of course means buying another appliance, which you may not be able to do. But there isn't much you can do on the ASA. You could also talk with your provider -- perhaps they would be willing to add some QoS on their side (doubtful, but worth asking). 

What you are seeing is Wireshark trying to detect and decode the data stream. It makes its best guess what the application is and tries to decode it. OFT2, for example, is a file transfer application. You can find details on it just a quick Google search away. You can also search for file signatures, which Wireshark uses to detect the application in use. 

You need an access list to block inter-VLAN traffic. There will be one for each subinterface. For example 

I will assume you're using a Windows PC. When you "ping," your computer sends (by default) four ICMP echo requests. Each request will get a reply (if everything is working properly). So you see each of the four replies. You can change the number of echo requests with the "-n" switch. 

Again, the router doesn't distinguish between private and public addresses. It simply looks in its routing table and forwards based on the destination IP. 

Sometimes, I wish they'd stop teaching the OSI model. It seems to confuse more than it helps. When we say that layers communicate with each other, we mean the data created by a particular layer (say, transport) on host A is processed by the same layer on host B. This is a logical connection. The actual data (in this case, the segment containing the SYN flag) is encapsulated in the Network PDU (IP packet), then encapsulated in the data-link PDU (Ethernet), then finally transmitted on the Ethernet cable (Physical layer). Host B reverses this process, unencapsulating the PDU at each layer until it reaches the transport layer. The transport layer processes the SYN flag and creates a new PDU containing the SYN, ACK flags. Then it sends it to A using the same encapsulation process. The only way data is actually sent from one host to another is via the physical wire. Layer to layer communication is just a mental construct. 

I did a search on both Cisco and Juniper's sites for S-BGP configurations. I didn't find any, which leads me to conclude that it is not a protocol in wide use. 

It’s not so much a matter of spending time processing unwanted signal, but that unwanted traffic is “noise” that reduces your signal to noise ratio. Signal to noise ratio (SNR) is more important than absolute received power, and really determines the maximum transmission rate that you can reliably decode signal. The unwanted traffic (i.e. noise) causes errors in the decoding of your desired signal, causing retransmissions. So your throughput drops off, not because your receiver is “too busy” decoding the unwanted noise (you can only decode one signal at a time), but because the noise causes decoding errors. In theory, a lower sensitivity will reduce noise, but at the cost of not being able to decode weaker signals. But even if your receiver isn’t activated by the noise, the noise can still cause distortion and errors in the received signal, especially when the signal is marginal. Since 802.11 uses collision avoidance, at a certain noise threshold, the AP or station won’t transmit because it considers the channel “in use.” It will wait until the channel is idle before transmitting. So this also reduces throughput, much like not being able to say something with a group of friends because one person won’t stop talking. Also remember that the receiver’s sensitivity is measured at the center of the channel, and drops off as you move higher or lower. So the receiver is less sensitive to interference as you move away from the center of the channel. 

It means you have made a DNS query to Google. If it were a website, you would see a connection to TCP port 80. 

I'm unaware of any command that shows the maximum number of SPAN sessions allowed (on a Cisco switch), although I've also never seen more than two allowed. You can see how many SPAN sessions are configured by the command 

Dijkstra's Algorithm doesn't define what the weight should be. The weight value lets you decide which links are preferred. If, as you say, all the links have the same bandwidth, then perhaps you don't have a preference. All weights should be the same. 

Wireshark will display packets for you, but it only shows the packets sent or received by the computer. If you want to see packets going to other computers, then you will either need an Ethernet hub, or configure your router to send you a copy of all packets. Commercial routers can do this, but consumer grade cannot (Note that consumer devices are also off-topic here). 

Think of the loopback as a separate network interface on your computer. You can ping, or open TCP or UDP connections to it. If you create a web server on that device, you tell it to listen (bind) on one or more interfaces. If it is listening on the loopback address, you would browse to 127.0.0.1 to access the server. 

When a switch receives a frame from an interface, it creates an entry in the mac-address table with the source mac and interface. If the source mac is known, it will update the table with the new interface. 

0.4% packet loss is quite high on an internal network. Packet loss will definitely affect performance, but the effects are also dependent on RTT. The Mathis Equation describes the maximum TCP theoretical throughput for a given RTT and Loss Rate: 

In a connectionless communication, the only association is made between the end parties. The Internet is a good example of this. When you browse a website, you send data to the web server, and it send data back to you. No one else is involved or is even aware that you are talking to the web server. In a connection oriented communication, there are three parties involved: you, the party you are communicating with, and the provider that sets up the communication channel. A telephone call is an example. When you call me on the telephone, you first ask the telco to set up a logical (or physical) channel between us. The telco signals to you if the communication is set up (ring tone or busy signal). Only then can we start communicating. When you are done, you "hang up", telling the telco to tear down the connection. The communication between you and the telco (and me and the telco) is the third party communication the standard is talking about. 

You don't need area 1 to be NSSA if it is not a stub area. In that case, the external routes are flooded into both area 1 and 0. But if you want area 1 to be stubby, meaning that it doesn't receive any external LSAs from other areas, then it must be NSSA, because it is injecting external routes. The external routes are flooded in both areas. But if area 1 is a stub, the routers don't forward type 5 LSAs The only external routes that can be flooded in a stub area are type 7, which by definition makes it a NSSA area. The reason the P bit is not set is because the router is already injecting type 5 LSAs into area 0, so there's no need for translating type 7 to type 5. By the way, area 0 is never a stub or nssa. 

You can enable or disable classes or specific messages, but you can't change the message format. You will have to do that with an external program. 

There is no longer a /23 network, because you have divided it into two /24s. You can summarize the two /24s as a /23, but the /23 subnet no longer exists as a subnet. In other words, you don't have some hosts with a /23 mask, and others with a /24 mask. All your hosts will be on one or the other of the /24s. You have also discovered a (small) drawback to subnetting: as you divide networks into smaller and smaller subnets, you lose space to network and broadcast addresses. If you take a /24 and divide it into /30's, you will lose half of the available address space. 

Access control lists operate at layers 3 and 4 of the OSI or TCP/IP model. File operations like reading and writing are application layer functions, so network ACLs have little or no control at that layer. If you think about it, reading a file can be very different depending on the application. Are you using FTP? A word processing program? A database application? Each one has its own unique ways of reading a file. At the network layer, these are all invisible to you. 

"nat 0" tells the firewall not to do translation. you should say "nat 1" to associate the nat with the 

Let me make up some numbers: Assume a network bandwidth of 4.8Mbps. That works out to 600kB/sec, ignoring overhead. So one user would get the file in 1 sec (again, ignoring overhead). 2 users would take 2 sec and so on. 

The speeds are usually higher, making equipment substantially more expensive. Not all data flows traverse the core. 

You should put your DHCP server on whatever network you put your infrastructure services for your clients, such as DNS, Active Directory, etc. Assuming for example, you put it on network A, you configure the pfSense router to enable DHCP relay on Networks C, D, and E. When clients broadcast a DHCP Discover message, the router will forward those packets as unicast to the DHCP server. In essence the router relays the DHCP data between the clients and the DHCP server. If you separate A and B, you would configure on the router interface on the B network. 

Let's use a more correct term "transmit" instead of "broadcast," which has other meanings. A radio can only transmit on one channel at a time. Some radios can change frequency very rapidly to give the appearance they operate on more than one channel, but that technique is too complicated and expensive for something like WiFi. To answer your second question, it depends on the AP manufacturer. Most have some sort of algorithm to pick an unused channel, but how they do that is a proprietary secret. Generally, changing channels in the middle is a bad idea, since there will be an interruption in service until the user can "find" the new channel. 

Here's a strategy: Start by capturing a web session with Wireshark when the response is slow. Are you seeing timeouts/retransmissions? If you see retransmissions, then you are losing packets somewhere. Look at your switch interfaces for errors or drops. If not, it may be the web server. Is it the web server that's slow, or is it the DNS server? Check your firewall logs to see if there's any important information there. 

Assuming router0 and router1 know about all networks, this is normal behavior. Routers (Cisco) use the following algorithm to determine where to forward packets 

Your unmanaged switch doesn't understand vlan tagging. You need a managed switch that supports vlan tagging in order to make this work. You need an ACL or other method of filtering traffic to block access to your management interface. As you have it now, anyone can access it. You need to insure that your static routing is configured correctly so that your management traffic only goes to to internal network. 

Assuming you don't route between VLANs, you can create multiple subinterfaces (one for each VLAN) and connect them to the ring as a trunk. The physical interface won't have a name, only the subinterfaces will. 

You answered your own question. GNS3 emulates routers and switches, so it can't work as fast as dedicated processors. In this case, you have one processor trying to do the work of eight, and emulate a Linux box. I'm actually impressed it's working as fast as it is.