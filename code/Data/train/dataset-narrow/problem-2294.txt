While not exactly what you want, esoteric languages Jot, Iota and Zot could be good starting points. They are all Turing complete. In particular Iota language is defined as 

The name coroutine suggests that in some sense they should be dual to (sub)routines. Is there a real mathematical duality? I'm hoping for something like "in category theory subroutines are X and coroutines are Y, where X is dual to Y". 

Suppose we don't know Joe B. Wells's result from 1994 that both typability and type checking are undecidable in System F (AKA $\lambda 2$). In Barendregt's Lambda calculi with types (1992) I found a proof due to Malecki 1989 that type checking implies typability. This is because 

It depends how you define simplest. One of the simplest languages I know are Iota and Jot. A detailed description can be found here. Both are Turing-complete languages that use just two symbols (no variables etc.). Iota programs can be viewed as binary trees with $*$ at nodes and $i$ at leafs. So the whole program is solely determined by the shape of its binary tree. Any such a binary tree forms a valid program. Jot is similar, but slightly different. Programs in Jot are (arbitrary) sequences of 1's and 0's. Any such a binary sequence forms a grammatically valid program. 

Contraction: $\Gamma, A, A\vdash B$ can be transformed into $\Gamma, A\vdash B$. That is, a single input can be used twice. Weakening: $\Gamma\vdash B$ can be transformed into $\Gamma, A\vdash B$. That is, it's possible to add arbitrary, unused inputs. Exchange: $\Gamma_1, A, B, \Gamma_2 \vdash C$ can be transformed into $\Gamma_1, B, A, \Gamma_2 \vdash C$. That is, the order of inputs doesn't matter. 

There is no way to choose the parameters A, B, C, D properly; as it is the case for most heuristics, the parameters are chosen ''by experience''. Worse, there is no guarantee that the solution (the array of the outputs) of this heuristic is indeed a feasible TSP tour! In this context, perhaps interesting to read: Wilson and Pawley, On the stability of the Travelling Salesman Problem algorithm of Hopfield and Tank, Biological Cybernetics 58 (1988) 63-70. To your first comment: I don't think that this TSP energy function is useful for practical purposes. If you want to solve TSP in practice, maybe here is the right starting point. 

I recommend Lectures on Proof Verification and Approximation Algorithms, E.W.Mayr and H.J.Prömel and A.Steger (Eds.), Lecture Notes in Computer Science, vol. 1367, Springer Verlag 1998. These lectures are very suitable for studying these topics from the basic. 

An (optimal) $r$-domination for $G$ is an (optimal) domination for the $r$th power $G^r$ and vice versa ($G^r$ is obtained from $G$ by adding new edges between distinct vertices of distance at most $r$). The following facts are well known: (1) All powers of a strongly chordal graph are strongly chordal (A. Lubiw, Master thesis; see also Dahlhaus & Duchet, On strongly chordal graphs, Ars Combin. 24 B (1987) 23-30), and (2) Domination is solvable in linear time for strongly chordal graphs (M. Farber. Domination, independent domination and duality in strongly chordal graphs, Discrete Appl. Math., 7 (1984) 115–130). Hence $r$-domination is solvable in polynomial time for strongly chordal graphs, in particular for trees ($r$ fixed or not). Gurski & Wanke proved in this paper that the clique-width of $G^r$ is at most $2\cdot (r+1)^{\text{tw}(G)+1}−2$, where $\text{tw}(G)$ is the tree-width of $G$. Thus, for fixed $r$, the $r$th powers of bounded tree-width graphs have bounded clique-width. Hence, for fixed $r$, $r$-domination is solvable in polynomial time for bounded tree-width graphs (by Courcelle's theorem). 

Any monad is also an applicative functor and any applicative functor is a functor. Also, any comonad is a functor. Is there a similar concept between comonads and functors, something like co-applicative functor, and what are its properties? \begin{array}{c} \end{array} \begin{array}{cc} \mbox{Functors} & & \mbox{Functors} \\ \uparrow & & \uparrow \\ \mbox{Applicative functors} & & ??? \\ \uparrow & & \uparrow \\ \mbox{Monads} & & \mbox{Comonads} \\ \end{array} Update: I'd be also interested in possible uses of such a concept. 

When learning about generalized arrows, a question arised to me: Are there any languages (or potential languages) that lack one or more of the structural rules: contraction, weakeing and exchange? Under Curry-Howard isomorphism, these rules, used frequently in logic, map into programming concepts. If we denote $A, B, C \vdash D$ a program (corresponding to a natural deduction proof) that computes a value of type $D$ from inputs of types $A$, $B$ and $C$, we get: 

What are the morphisms of adjunctions in $\textbf{Adj}(C,T)$ and what is meant by ... which are the identity on $C$? 

I know that's impossible to decide $\beta$-equivalence for untyped lambda calculus. Quoting Barendregt, H. P. The Lambda Calculus: Its Syntax and Semantics. North Holland, Amsterdam (1984).: 

so it satisfies the prefix property. It's extension Zot adds input and output, where the input is the sequence of bits that follow the valid program description. By restricting Zot to programs with empty input you get a language that should satisfy your requirements. (Or alternatively adding just output to Iota.) There is Haskell implementation of Zot. 

$2$-coloring $s$-uniform hypergraphs is also called Set Splitting, problem [SP4] in Garey-Johnson book. The hardness proof is due to Lovasz in this paper. 

The manuscript contains also similar results for other problems such as Dominating set, Max cut, VFS, etc. 

Could you give a reference for your claim that IDS is polynomially for line graphs? Indeed, your proof for this fact would imply P=NP. Yannakakis and Gavril proved in this paper that the the minimum maximal matching problem is NP-complete. This is exactly the independent domination problem on line graphs. 

I think, your problem is NP-complete. It is a special case of a theorem by Farrugia, stating that it is NP-hard to test if the vertex set a graph can be partitioned into two subsets $V_1,$ and $V_2$ such that $G(V_1)$ belongs to the graph class $\mathcal{P}$ and $G(V_2)$ belongs to the graph class $\mathcal{Q}$, provided $\mathcal{P}$ and $\mathcal{Q}$ are closed under taking vertex-disjoint unions and talking induced subgraphs, and at least one of $\mathcal{P}$ and $\mathcal{Q}$ is non-trivial (meaning not all graphs in the class are edgeless). 

It is NP-hard, even for $k=2$. This is a special case of a theorem by Farrugia (Alastair Farrugia, Vertex-partitioning into fixed additive induced-hereditary properties is NP-hard, The electronic journal of combinatorics 11 (2004), #R46), stating that it is NP-complete to test if the vertex set a graph can be partitioned into two subsets A and B such that G(A) belongs to the graph class P and G(B) belongs to the graph class Q, provided P and Q are closed under taking vertex-disjoint unions and talking induced subgraphs, and at least one of P and Q is non-trivial (meaning not all graphs in the class are edgeless). 

It's not entirely clear what do you mean by a functional programming language without closures. Can you give an example? Functional programming languages are usually based on lambda calculus, whose essential part is that you can have open lambda terms. For example the term for the constant function (the K-combinator) $\lambda x . \lambda y . x$ can be viewed as a function that given $x$ returns a constant function that returns $x$ on any argument - a closure of the open term $\lambda y . x$. However you can use another basis, a combinatory calculus such that it's power is equivalent to the lambda calculus. Then you can take a lambda term and convert it into an equivalent combinator that doesn't use any variables at all, so there are even no closures to talk about - see Completeness of the S-K basis. Which I believe answers yes to your question. This is actually what Haskell compilers do under the hood. Evaluating lambda terms with variables is very inefficient and cumbersome, so they convert the program to a representation without variables and use techniques such as combinator graph reduction. I can recommend two books on the subject which are both available online, the first one more theoretical, the second one focused more on the actual implementation techniques: 

A useful technique is to find a property $P$ that is preserved by isomorphism, that is if $X\cong Y$ then $P(X)=P(Y)$. Then if we can show that $P(X)\neq P(Y)$ then also $X\not\cong Y$. In your case, let's pick $P(X)$ to be $X(\bot)$ is isomorphic to 1 where $\bot$ is the empty data type. Clearly, $P$ is preserved by isomorphisms. Now $T_1(\bot) \cong 1 + \bot + T_1(\bot) \times T_1(\bot) \cong 1 + T_1(\bot) \times T_1(\bot)$ which has obviously more than one value, but $T_2(\bot) \cong 1 + \bot \times T_2(\bot) \times T_2(\bot) \cong 1$. Therefore $T_1$ and $T_2$ aren't isomorphic. 

My favorite example is the independent domination problem (given graph $G$ and integer $k$, does $G$ have an inclusion-maximal independent set of at most $k$ vertices?). By a nice result due to Martin Farber (see here), the unweighted version is polynomially solvable in chordal graphs. Gerard Chang proves that the weighted version is NP-complete for chordal graphs (see here). 

This problem is NP-hard and APX-hard; see: Adamaszek and Popa, Approximation and Hardness Results for the Maximum Edge $q$-coloring Problem, Lecture Notes in Computer Science 6507 (2010) 132-143. The parameterized complexity aspects of this problem is addressed in this recent paper. 

For a given graph $G$ and an integer $k\ge 1$, the $k$-th power of $G$, denoted by $G^k$, has the same vertex set such that two distinct vertices are adjacent in $G^k$ if their distance in $G$ is at most $k$. The $k$-th power of split graph problem asks if a given graph is the $k$-th power of a split graph. 

Are NP-completeness in the sense of Cook and NP-completeness in the sense of Karp different concepts, assuming P $\neq$ NP? 

This unpublished manuscript by Hougardy, Emden-Weinert and Kreuter in 1997 provided a simple proof for the following result which is much stronger than the result pointed out in Kristoffer Arnsfelt Hansen's answer: 

Golden ration in the base: A very recent FPT algorithm by Kociumaka and Pilipczuk, Faster deterministic Feedback Vertex Set computes a FVS of size $k$ in $O^*\left((2 + \phi)^k\right)$ time. (They then improves their algorithm to run in time $O^*(3.592^k)$.) 

You've basically answered the question yourself. $\lambda K$ is just another name for the standard, untyped lambda calculus. $\lambda I$ is a strict subset of $\lambda K$. $\lambda I$ doesn't allow terms where one abstracts over a variable but doesn't use it. So $$K = \lambda xy.x \in \lambda K$$ but $$ K \not\in \lambda I$$ Thanks to this restriction, $\lambda I$ has some interesting properties, in particular if $M$ has a normal form then so do all its sub-terms. Barendregt, H. P. The Lambda Calculus: Its Syntax and Semantics contains some notes about $\lambda I$, namely: 

An example for language lacking contraction would be quantum computing. There the allowed operations can be described with unitary matrices, and duplicating a value can't be expressed as such. It also seems to me that weakening isn't an admissible rule for quantum computing, at least in the above form, as we can't forget a value with a unitary matrix. But we could have a weaker rule such as $\Gamma\vdash B$ can be transformed into $\Gamma, A\vdash A\otimes B$, and the $A$ in the output can be dropped when extracting the results of such a computation. The exchange rule is clearly permissible in quantum computing. Are there any other examples, in particular a language that doesn't allow exchange, or where weakening isn't allowed even in such a weaker form?