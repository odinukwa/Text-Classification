Please do yourself a favor and use something designed for this. You already know about mcollective, but you and I both know that it needs some infrastructure to work. As do puppet and chef. clusterssh, parallel ssh and dancer shell are small simple improvements over a shell for loop. They don't need more infrastructure. But there's also ansible, which let's you do that, but also write reusable "playbooks" with several steps. It does need python installed in addition to sshd, but in practice I've never had to separately install that, it's always been available. Ansible is the only configuration management system I've tried that also works well as a deployment and orchestration tool (puppet needs mcollective and maybe capistrano/fabric for that, ...) (Yes, Puppet and Chef and all the rest can be run without central servers, but you need to install packages on the hosts to manage, which ansible doesn't need) 

GSSAPI or the Generic Security Services Application Programming Interface is used by NFS (versions 3 and 4) when using Kerberos for authentication and encryption. The ubuntu config file has a few lines about this: 

Yes, as long as you are talking about update and not upgrade. Apt will even do it for you if you put the line: 

If not, you need to insert the contents of ~/.ssh/id_rsa.pub on the client to ~/.ssh/authorized_keys on the server. E.g. (assuming you have no other keys set on the server): 

Try using instead of . It's much better at finding readable strings than just replacing NULs with newlines. 

Source or Policy based routing maybe? Linux can have several routing tables and choose which one to use based on several conditions. Check out the OpenVZ documentation on Source based routing 

I would recommend using Samba instead of NFS when sharing files to windows. You can see what UID nobody is with 

The cat would be run on server, stdout piped to workstation and ip-tally run locally on workstation with cat output as stdin 

OpenVZ is lightest, followed by Xen and KVM/VMware are the heaviest. On the other hand, I've had problems with OpenVZ (very flaky during NFS, not really isolated etc.) and Xen, while KVM is very simple and adequately performant. 

When Network Manager is disabled for sure we can take a look at . Interface aliases are no longer recommended, but (8) can add more than one address to one interface. This can be done in as follows: 

Yes! Linux (and Debian) software RAID is arguably more reliable than hardware RAID. You can back up /etc/mdadm/mdadm.conf Read mdadm(8) documentation. I can't remember if squeeze will automatically install grub on both disks, but you can verify and do it easily enough your self afterwards. Just 

As others have stated, look into your shell history control for hiding the information from history. But one thing nobody seems to have suggested yet is to mount with the parameter. Try modifying your line in to include , like this: 

Bus error can also mean faulty hardware. Be sure to run memtest. Especially if reinstall doesn't work. And if reinstall does work, check your filesystem and underlying device. 

Not required, but you should partition. The partition table eats up very little space, but it is universally recognizable. Windows will know that there's a filesystem there if you put it in a Windows box. If you have no partitions, other operating systems will just treat it as an empty drive. 

I see two non-obvious solutions. Backup using BackupPC, which lets you easily check out previous versions and restore them. Can be done remotely or locally. Configuration management using puppet. I don't version control all the files on the server. I version control puppet modules and manifests which describe what changes should be applied to the server. I avoid touching the servers by hand at all, and if I do, I duplicate the changes in puppet. I use both. Configuration comes from puppet, versioned with git and versioning of "user data" (served webpages, home directories etc.) is handled by backuppc. 

While it is possible to build the kind of setup you want using pam-ldapd/pam-ccreds etc. it is much easier to get the same result using sssd (and pam-sssd, and nss-sssd). See e.g. $URL$ 

VZFS is a virtual file system. It is used by OpenVZ (and Virtuozzo) to export a directory as the filesystem to a virtual machine. Therefore maximum file size is likely determined by the filesystem whose directory it actually is. 

.MDB is MS Access, right? I doubt pgAdmin 3 being able to do that. If Access can handle SQL then you can probably dump the Postgres databases to plain text SQL and load it into Access (with small changes, I'm guessing). If not, then you probably have to write a small program that reads from Postgres and writes to Access/MDB. Maybe there exists one already. Most converters I found using Google go in the other direction. 

Specifically I do not fill up the entire VG, as that gives me more room to play as requirements change. And growing filesystems can be done online using LVM. 

Why not use rsync, rsnapshot, rdiff-backup or something else that does syncing. That way you don't have to wait for the whole 1TB to copy each time. 

If you have enough disk space available, have you thought about installing debian in a chroot? That way you still would have the original software available but also a complete debian installation. 

You need at least 711 permissions on . A user has to have execute rights (+x or 1) on a directory to access anything under it. 

You didn't specify the file system or operating system. In Linux ext2 (and presumably ext3 and ext4, as they are based on it) has a theoretical limit of 1.3 Ã— 10^20 directory entries. 

How many machines? Puppet resource usage on the client is pretty irrelevant if you are only going to run it every now and then. The amount of clients and frequency of contacting the server are much more important, because the server can use quite a few resources. I have tens of machines contacting the puppet server every hour, and I've gotten around fine using just the trivial and poorly performing built-in server without any special setup. 

Is Network Manager managing the interface? I have configured network manager not to touch the interfaces that I manage through by having the following in : 

MIT Kerberos is well supported. It is the reference implementation and default on RedHat and I believe Debian as well. OTOH, Heimdal had slightly nicer administration tools IIRC, but I've gone with MIT. 

Reinstall the purged package (sysv-rc). If that isn't enough, try to recreate the links using or something similar. 

The drobo-utils FAQ doesn't list support for ext4. Maybe you should try using ext3? Drobo support states that Drobo doesn't support ext4. 

Sure it is possible. You might have to compile another copy of pam_* whatever to look into another set of config files, but it is doable. Another way would be to use the proxying capabilities of OpenLDAP server (or another server that does proxying). 

That is not up to SSH. You will typically have your CWD set to HOME on login. May I suggest reading the man-page of your shell and putting a cd command in the initial login file? 

GRUB2 can handle /boot on LVM. I use it on some of my machines. But it's probably safer to have /boot on a partition outside LVM. 

Check out the config variable in . Setting it to group might do the trick. Another option might be to use something like gitosis to manage the repository. 

ErikA is giving you sound advice. Instead of guessing what you have running, you should specify what you want running. But maybe blueprint can help you get from your current state to the one you should be in. 

I don't really get what you're asking. Files served from a server should go under according to FHS. But why would several users need to have access to those? I suggest you start using version control and give developers access to that. Then automate deployment using a script or func or capistrano. Give those who need the right to trigger a deployment. Maybe using continuous integration so that it is only possible after all tests pass. 

Basically those can be mounted by anything that is run during system startup. Have you grepped for and under ? Are you running automounter (autofs)? 

You need something on port 80 that can forward requests to Tomcat (and maybe even to whatever you use to serve PHP). For example Apache can work as a reverse proxy. And nginx. And varnish was made for the exact purpose. 

APT can't install RPM packages (there used to be an apt-rpm fork, used in Linox, but I doubt it is maintained). You can however install the program using or use to convert rpm packages to deb packages. RPM packages which have been built relocatable can be installed in a different prefix, including the home directory of a user. In this case it can be done without root access. 

I'm not quite sure if I understand you correctly, but maybe source based routing is what you want? Basically you do the following: 

With a recent debian or ubuntu release it is trivial to install redmine, which I like better than trac. 

But take a look at tripwire and aide, since that seems to be what you are aiming for anyway. Also note that rpm can check files against checksums and for debian based distributions there is debsums. 

I specifically don't document anything on servers. We use puppet, which is the canonical configuration resource for servers. The configuration for puppet is in version control. If a server needs to be rebuilt, we use puppet to do that. Any configuration that wasn't in puppet is lost. Therefore most configuration is in puppet and the changelog is in puppet commits. 

I tend to just dump stuff to one place on the filesystem (typically /var/backups) and then backup the filesystem using something like for example duplicity that happens to support S3. 

AFAIK netfilter does not "understand" HTTP well enough to make choices based on hostname in the HTTP request. You should do it in the HTTP server instead. 

Are some of the services bound to localhost on the guest? If you do an ssh forward from (host) localhost:8080 to (guest) 10.x.y.z:80 and the service is listening on (guest) 127.0.0.1:80 , it will give you connection refused. Try making a tunnel from 127.0.0.1:port to 127.0.0.1:port , where the first is host and the second is guest.