You can use Blender for that. But it has nothing to do with matrixes, the only thing you need to set up is the ortographic camera. See this blog post for a generic approach in making graphics from 3d models. You will need the same approach except for a custom camera with orthographic view. 

I am fortunate being able to use the same programming language on both the server and client (javascript). I would therefore like to share my code and classes between server and client, like Half-Life (and possibly others) did. To make things simple, suppose I have an MMO with a Player and an Enemy class, with a position, velocity, and health. 

My character needs to slide and not bounce off a slope. The solutions I found here use a Reflection vector, but they make my character bouncy when they run downwards a slope. 

If you're building in HTML5 I suggest you look into Node.js and Socket.IO, as they fit well for your type of gameplay and are easy to implement due to Node.js' event loop. On top of that, you only need to use javascript for the client and server. 

I'm building an MMO using Node.js, and there are monsters roaming around. I can make them move around on the server using vector variables acceleration, velocity and position. acceleration = steeringForce / mass; velocity += acceleration * dTime; position += velocity * dTime; Right now I just send the positions over, and tell the players these are the "target positions" of the monsters, and let the monsters move towards the target positions on the client with a speed dependant on the distance of the target position. It works but looks rather strange. How do I synchronise these properly with the players without looking funny to them, taking into account the server lag? The problem is that I don't know how to make use of the correct acceleration/velocity values here; right now they just move directly in a straight line to the target position instead of accelerating/braking there properly. How can I implement such behaviour? 

There are good answers here. I had to figure it out for myself on the project I'm on, but came to the same conclusions as the Sucker Punch guys (and I had thought I came up with something novel. Baww :( ). I find it useful to consider your entire first person 360x180 degree "panorama" as an "acceleration field". All valid targets create gravity wells which bend the player's input (only subtley) such that macro motion (turning to face targets) feels as though it's a "greased" path. However, this is not affecting the crosshair all of the time - only when the player's turn delta is pointed with the slope of the well (as it were). That's really key though - you're only giving this extra turn speed when the player is turning roughly toward a target. That's about the only inference you can make from the player's input. Much more, and you get too much of a noticeable "ouija effect". You want the exact opposite of ouija: Where a ouija board is moving unintelligently due to a user, without their conscious knowledge, you want a player's crosshair to move in an intelligent way without the user realizing that it's NOT purely their input. It really is a bit of a magic trick. Use the dot product of the player's pitch/yaw turning delta vs. the pitch/yaw delta from the crosshair to each target. Clamp the value between 0 and max speed (so you ignore the input while pushing away from the target), then use a function of distance as a falloff modifier. I found that increasing this "macro movement" bonus when the crosshair vs. target angular delta is large (i.e. when an enemy is behind you) really helps with the classic console controller problem of not being able to turn-to-face quick enough. In terms of "targetting choices", if you're being attacked from behind, and there's no targets infront of you, that panorama ahead of you is "dead space", and you might as well give the player the ability to fly across it at great speed with their cursor. And if there ARE targets ahead, well, they're probably higher in the player's mind and due to dampening/sticky aim, aren't unduely affected by the weak macro force. There's not much need for you to dampen sensitivity when the player tries to turn away from an object (this will result in a feeling of trying to "escape" a target's orbit). Dampening is used more for precision aiming, and also to stop players' aim overshooting when moving from macro to micro precision - It's the darnest thing: players (especially novices) have a tendancy to only use the extremes of a stick's deflection, so you have to do a lot of finessing for them. Sticky aim is a relative movement compensator. Watch the difference between the angle to your target (from the camera, not from the entity origin), this frame, and last frame. See how closely you are aiming to the target. To avoid the ouija effect when there is no user input, check both sticks' deflection: See if you have physically moved (left stick actuation) OR if there is active aiming "with" the direction of the target. Add the yaw/pitch delta step * aim closeness * Max( move.length , aim.length ) for rudimentary sticky aim. Where the issue of target confusion comes in (i.e. a target strafes across your view while you were aiming at something behind, "stealing" your focus), simply keep track of your targets, and "heat" a single one while it is being actively aimed at. Then, multiply the dampening and sticky components by this heat parameter so that unheated targets get ignored. If the player WANTS the help on that other target, they'll manually aim toward it, and very quickly, that becomes the most prominently heated target while the previous one is forgotten. We also create "phantom" aim assitance targets to help you turn away from uninteresting things (i.e. facing a wall - no need to hang around looking at a close up blank surface if it's not usefully interactive), but it's probably more than I can talk about - you can apply this stuff to anything that's interesting for the player to point at, be it explosive barrels, interactive objects (bioshock uses dampening when aiming over interactable objects at close range... but doesn't do sticky aim on them, I don't think). Once you realize that this is all just to compliment the core concept of aiming, you realize it's not just about aiming shots, but a general useability improvement which feeds into any mechanics reliant on aiming. And in an FPS, really, movement and aiming are the fundamental core concepts you need to nail before developing onward. The improtant thing with all this is tuning. Takes a long time to just get right, and to deal with target interference, and issues with targets being so close range that their "targetting zones" swamp the player's panorama, slowing 60 degrees of rotation down to a crawl. Oh man, I should get to bed. Sorry if some of the maths is not to clear. It's really late, but I was excited reading this post. 

How do keep my character aligned properly with the boat? It is exactly like in World Of Warcraft, when you board a boat or zeppelin. This is my physics code for the guy and boat: 

The boat changes velocity and orientation and heads off. My character however has a velocity of 0,0,0 but I would like him to stay onboard. When I move my character around, I would like to move as if the boat was the ground I was standing on. 

I know ideally these should inherit from each other (or use a CES system). But my question is as follows: Since these classes will be used on the client and server (since both client and server needs to know about these entities) with some but not all shared logic, would it not be crazy to define two separate classes on both the server and client? What are the advantages and disadvantages of sharing classes between server and client? Are there any helpful websites with tips/tricks for this approach? 

In the following example there is a guy and a boat. They have both a position, orientation and velocity. 

The guy is standing on the shore and would like to board. He changes his position so he is now standing on the boat. 

Then, I simply test the rays against the terrain and possible 3D meshes on the terrain, and check if the ray distance from one of the raycasts is smaller than the AABB box size. This would mean a collision occured. Rays around the character $URL$ So far so good! I cast a ray from the character's position with every rayDirection and check if one collides with the meshes array (which contains the terrain and other 3D objects on the terrain) Once I have a collision, what to do now? Should I calculate a reflection vector? If for instance I simply walk on a flat terrain, the four rays at the bottom should trigger a collision. How do I use this reflection vector in my situation? 

The error says it all, you need to check if the world is locked in the moment that you want to remove the body 

In the "onCompletion" method, I use the intent to call my new activity where the "initialize" call for the libGDX engine to work And a new layout for the videoView 

As Byte56 said, in libGDX you cannot play videos :( so i did this: I created a new activity "SplashScreen" 

but when i want to resize another label, all the labels containing that font resize (I create a new LabelStyle). So i resize the label instead of the font, but that doesnt solve the problem, because it doesnt resize the label, any idea? 

I am using BitmapFonts, LabelStyles and Labels for my texts. I want to resize some labels, so i use this. 

In your render method check if the world is locked, with world.islocked(), if it isnÂ´t locked, and call immediatly the destroy body. I suppose that you error is an assertion from Box2D 

I override resume() in the class tha extends Game in libgdx, and when i press the home button and enter the app again it executes and it enters that method. 

I am trying to make an object child of a Group, but this object has a draw method that calls opengl to draw in the screen. Its class its this 

Is there a way to play videos with LibGDX? I want to put a video as my splash screen in Android, but I dont want to use the Android SDK, because I am using LibGDX and I am almost finished :/ 

I want to wait a moment (.5 seconds) before I increase the sound, how can i achieve this without using Thread.sleep, because i want my game to keep runnig. 

Is there a way to scale the bodies made from vertexes (like a guitar), i was trying to multiply each vertex point by the scale value but c++ mark an assertion failed, is there a mehtod to do this? I have done it, but i want to make a mirror body, but i cant do it :/ just multplying it by -1 or 1 it doesnt run :/ 

The guy already has a reference to the boat he's standing on, and thus knows the boat's position, velocity, orientation (even matrices or quaternions can be used). 

The problem I'm facing, is the fact that I don't know how to make some monsters appear harder than others. Since nothing has a level, and characters can only get stronger by acquiring better items, it's difficult for me to "warn" players that a monster is difficult for them. Fortunately, the whole world is designed by hand and we know which areas should be more difficult than others. So this means, I as developer knows which monsters are stronger than others. But new players won't! I don't want them to get frustrated by walking into the wrong monsters reserved for higher players. So then, how can I make monsters appear more dangerous than others? Some things I thought of: 

I'm building a game using WebGL and Three.js, and so far I have a terrain with a guy walking on it. I simply cast a ray downwards to know the terrain height. How can I do this for other 3D objects, like the inside of a house? Is this possible by casting many rays in every direction of the player? If not, I would like to know how I can achieve the simplest collision detection possible for other meshes. Do you have to cast a ray to every triangle in every mesh nearby? 

We're creating an action MMO using Three.js (WebGL) with an arcadish feel, and implementing physics for it has been a pain in the butt. Our game has a terrain where the character will walk on, and in the future 3D objects (a house, a tree, etc) that will have collisions. In terms of complexity, the physics engine should be like World of Warcraft. We don't need friction, bouncing behaviour or anything more complex like joints, etc. Just gravity. I have managed to implement terrain physics so far by casting a ray downwards, but it does not take into account possible 3D objects. Note that these 3D objects need to have convex collisions, so our artists create a 3D house and the player can walk inside but can't walk through the walls. How do I implement proper collision detection with 3D objects like in World of Warcraft? Do I need an advanced physics engine? I read about Physijs which looks cool, but I fear that it may be overkill to implement that for our game. Also, how does WoW do it? Do they have a separate raycasting system for the terrain? Or do they treat the terrain like any other convex mesh? A screenshot of our game so far: