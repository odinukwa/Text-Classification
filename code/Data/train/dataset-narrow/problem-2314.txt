This was a fun question to think about. As described in the other answer and the comments below, there is a Turing reduction from the Halting problem to computing Kolmogorov complexity, but notably there is no such many-one reduction, at least for one definition of 'computing Kolmogorov complexity'. Let's formally define what we're talking about. Let $HALT$ denote the standard language of TM's that halt when given a description of themselves as input. Let $KO$ denote $\{ \langle x,k \rangle \mid x \text{ has Kolmogorov complexity exactly } k \}$. Assume that $HALT \le KO$ by some many-one reduction. Let $f: \{0,1\}^* \rightarrow \{0,1\}^*$ denote the function that this reduction computes. Consider the image of $HALT$ under $f$, which I will denote $f(HALT)$. Note $f(HALT)$ consists of strings of the form $\langle x,k\rangle$ where $x$ has Kolmogorov complexity exactly $k$. I claim that the $k$'s that occur in $f(HALT)$ are unbounded, as there are only a finite number of strings with Kolmogorov complexity exactly $k$, and $f(HALT)$ is infinite. Since $HALT$ is recursively enumerable (aka Turing-recognizable in some books) it follows that $f(HALT)$ is recursively enumerable. Combined with the fact that the $k$'s are unbounded, we can enumerate $f(HALT)$ until we find some $\langle x,k\rangle$ with $k$ as large as we want; i.e. there exists a TM $M$ that on input $k$ outputs some element $\langle x,k \rangle \in f(HALT)$. Write a new TM $M'$ that does the following: first, compute $|M'|$ using Kleene's recursion theorem. Query $M$ with input $|M'|+1$ to get $\langle x, |M'|+1\rangle \in f(HALT)$. Output $x$. Clearly the output $x$ of $M'$ is a string with Kolmogorov complexity at most $|M'|$ but $\langle x, |M'|+1\rangle \in f(HALT)$ which is a contradiction. I believe you can also substitute in the problem "Kolmogorov complexity exactly $k$" with "Kolmogorov complexity at least $k$" with minor changes. 

While admittedly I haven't done the analysis, and this is not strictly a decision problem, I am willing to wager the best known matrix multiplication algorithms (by Coppersmith, Winograd, Stothers, Williams, et al) have irrational exponent. This can be seen more clearly in the simple case of Strassen's algorithm, which has running time $O(n^{\log_2 7})$. And, this is not precisely what you asked, but Ryan Williams has shown that all algorithms that solve SAT in space $n^{o(1)}$ require time $n^{2 \cos(\pi/7) - o(1)}$, which is another interesting and unusual appearance of an irrational constant in TCS. 

Consider the problem $\text{MAX-LIN}(R)$ of maximizing the number of satisfied linear equations over some ring $R$, which is often NP-hard, for example in the case $R=\mathbb{Z}$ Take an instance of this problem, $Ax=b$ where $A$ is a $n\times m$ matrix. Let $k=m+1$. Construct a new linear system $\tilde{A}\tilde{x} = \tilde{b}$, where $\tilde{A}$ is a $kn \times (kn+m)$ matrix, $\tilde{x}$ is now a $(kn+m)$ dimensional vector, and $\tilde{b}$ is a $kn$ dimensional vector: $$\tilde{A} = \begin{bmatrix} A & I_n & & & \\ & I_n & -I_n & & \\ & & I_n & -I_n & \\ & & & \ddots &\ddots \\ & & & & I_n & -I_n \\ \end{bmatrix}, \tilde{b} = \begin{bmatrix} b \\ 0 \\ \vdots \\ 0 \end{bmatrix}$$ where $I_n$ is the $n \times n$ identity matrix. Note that this system is always satisfied by the vector $\tilde{x} = \begin{pmatrix} 0 & b & b & \cdots & b \end{pmatrix}^T$. In fact, the first $m$ entries of $\tilde{x}$ can be arbitrary, and there is some solution vector with that prefix. I now claim that $\delta$ fraction of equations of $Ax=b$ are satisfiable iff there exists a sparse solution of $\tilde{A}\tilde{x}=\tilde{b}$ which has at least $\delta nk$ zeros. This is because every satisfied row of $Ax=b$ yields $k$ potential zeros when $x$ is extended to $\tilde{x}$ Thus, if we find the sparsity of the sparsest solution to $\tilde{A}\tilde{x}=\tilde{b}$, we have also maximized $\delta$, by dividing the sparsity by $k$. Therefore, I believe your problem is NP-hard. 

The quoted claim from the book is true. It is not true that $Z_1$ must always commute with all stabilizers of $\lvert \psi \rangle$. For example, if $X_1X_2$ stabilizes $\lvert \psi \rangle$ (e.g., if $\lvert \psi \rangle$ was an EPR pair) then $Z_1$ does not commute with $X_1X_2$ and $Z_1$ is not a stabilizer of $\lvert \psi \rangle$. 

This paper was presented at FOCS 2015 and is published in those proceedings. As far as I am concerned, this means it was peer reviewed and found to be plausibly correct, within the limits of a conference review process. So I would not consider this problem open, unless a specific flaw is discovered or there is some additional evidence introduced that this paper is not correct. Of course, that is not the same as a journal review process, which can often take years (this paper is only from 7 months ago!) 

Actually, acceptance of nondeterministic Turing machines in time $t$ is $O(t \log t)$-time reducible to SAT (the construction is via oblivious simulation, see Arora-Barak), so typically any time a nondeterministic machine is appreciably faster than a deterministic one, we'll see at least some speedup with a SAT oracle. To be more concrete, primality testing comes to mind, as the best variant of the AKS algorithm appears to test primality of an $n$-bit number in time $O(n^6 \; \text{polylog}\; n)$. But if we go "old school", Pratt gave a nondeterministic TM to decide primality in time $O(n^3 \; \text{polylog}\; n)$. Acceptance of this machine can be reduced (deterministically) in $O(n^3 \; \text{polylog}\; n)$ time to a SAT instance. The 3SUM problem may be another example, as it seems like one can guess a solution and check it in subquadratic time, and then acceptance of such a machine can be reduced to SAT in subquadratic time. 

Computing VC dimension seems unlikely to be in polynomial time, but has a quasipolynomial time algorithm. Also, it seems hard to detect a planted clique of size $O(\log n)$ in a random graph, but one can be found in quasipolynomial time; though the nature of this promise problem is somewhat different than the others mentioned. 

Note that even a result along the lines of $\mathsf{DTime}(\tilde{O}(n^2)) \subseteq \mathsf{NTime}(n^{2-\epsilon})$ would violate NSETH as univariate polynomial identity testing (as defined in section 3.2) can be solved in $\tilde{O}(n^2)$ time deterministically, but there doesn't seem to be an obvious way to use nondeterminism to help prove identity. 

In a lecture by Madhu Sudan* he claimed there was some belief that there exists $s > 1/2$ such that $\text{PCP}_{1,s}[ \log n, 3] \subseteq \text{P}$, via semidefinite programming, prior to the proof of Håstad's three bit PCP theorem. Indeed SDP does show $\text{PCP}_{1,1/2}[ \log n, 3] = \text{P}$, giving a tight bound on the complexity of such PCPs. (*I found this lecture of Madhu published in "Computational Complexity Theory edited by Rudich/Wigderson") 

If this graph has an infinitely large connected component, by König's infinity lemma, it has an infinite simple path. The event that the graph has an infinite simple path is independent of each individual choice of edge orientation (and thus, every finite set of edge choices). Therefore it is a tail event and by Kolmogorov's zero-one law the probability is either zero or one. 

It is well known that expanders, and often the special case of bipartite expanders, have found many uses in derandomization, coding, etc. However, I am curious if there are any special properties of bipartite expanders that more general families of expanders don't have (or vice versa). In particular, are there any extreme differences, where bipartite and non-bipartite expanders differ greatly (especially in a combinatoric, algorithmic, or complexity-theoretic sense)? A priori, we might expect that bipartite and non-bipartite expanders would likely share many pseudorandom properties, and in fact are constructible from each other. So that would suggest a negative answer to this question. On the other hand, bipartite graphs in general have many special properties (eg. König's theorem) that have complexity-theoretic implications. So it's not unreasonable to think that differences between random bipartite and non-bipartite graphs may yield interesting differences between bipartite and non-bipartite expanders. This is sort of a vague, open ended question, since I'm not exactly sure what kind of answer I'd like, and I am open to any interpretation. However, an example of a 'non-answer' might be 'bipartiteness is distinguished by the smallest eigenvalue in the spectrum'; I'm more interested in specifically bipartite expanders rather than spectral properties of bipartite graphs as a whole. 

I do not know if such a thing could exist or not. But it is interesting (and perhaps timely) to note that such a "gap amplification" would likely imply a quasipolynomial time algorithm for graph isomorphism (different than the recently announced one) In this paper, an approximation algorithm is given for the "MAX-PGI" problem of maximizing matched pairs of edges/non-edges; if we reduce from GI to "Gap-MAX-PGI", then we can approximate to distinguish which side of the gap we are on. So, I think Dinur's proof of the PCP theorem is unlikely to be directly generalizable to such a "gap amplifier", given the hurdles that would have to be overcome. 

I think there is confusion here based on binary vs unary representation. The statement 'most strings are incompressible' means that the Kolmogorov complexity $K(n)$ is approximately $|n|$ (that is, approximately $\log_2 n$) for most $n$. Of course, every natural number $n < 2^k$ has a $k$-bit binary representation. It is only in the unary representation that every natural number $n$ has complexity approximately $n$. Now, you may find alternative representations, possibly exotic ones, such as your busy beaver example, which achieves the same bound as the binary representation (i.e., every number $n$ has a representation of size approximately $\log_2 n$) but these do not 'compress' numbers more than the binary representation does. 

Essentially, you are asking for a graph "separator" of a certain kind, and while this doesn't answer your question directly, your question is likely related to the notion of the rankwidth of a graph. You can find more information in this paper, this paper or especially this paper Note that the notion of rankwidth uses "rank over the finite field $\mathbb{F}_2$", which may or may not be the field you were asking about. 

The assumptions often used in crypto are a form of average-case complexity assumptions, such as hardness of factoring or discrete log in various groups. Many lattice problems used for strong hardness guarantees for lattice based cryptography are qualitatively somewhat different than the factoring/discrete log based cryptographic assumptions. The development of indistinguishability obfuscation has also introduced a number of novel average case hardness assumptions. Often times average case complexity is used in the study of data structures for upper bounds (eg., of hash tables), but there are also some useful lower bounds. For example, the worst case $\Omega(n \log n)$ lower bound on sorting can be generalized to the average case, and to randomized algorithms as well (eg., see these lecture notes) 

Gödel's incompleteness theorem can be thought of as a reduction from the Halting problem to the language $\langle \varphi \mid \varphi \text{ is a true sentence in number theory}\rangle$, and a careful analysis of the running time would show that it is indeed a polynomial time reduction. Not every such reduction is polynomial time, however. You can observe that a reduction from the Halting problem $\langle i \mid TM_i \text{ halts on input } i\rangle$ to the unary language $\langle 1^i \mid TM_i \text{ halts on input } i\rangle$ has exponential blowup in instance size. 

So, is it zero or one? It's not immediately clear, though we can make a guess, since by the "infinite monkeys with typewriters" theorem, this graph contain simple paths of arbitrarily large length with probability one. Of course, more is needed to rigorously prove that it actually has an infinite path with probability one.