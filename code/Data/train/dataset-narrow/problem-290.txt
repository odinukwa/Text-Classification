With a local ping, the ARP request times out, no ICMP echo request is actually sent. With a remote ping across one or more routers, the last router (failing local ARP) might return an ICMP error. 

This is more or less to be expected - alligator clips aren't Cat anything, so probably the link training gave up and the link fell back to Fast Ethernet (not standard but not uncommon). Another possibility is that there's a bad contact somewhere and one of the pairs didn't link, also causing a fallback to FE. If you can't replace the cable, use a splice box to reattach the ends. 

a) Two hosts in the same VLAN should be able to connect to each other - when more than a single switch is involved, this requires proper setup of the links (=VLAN trunks) between them. Communication between two VLANs needs to be routed (either with a dedicated router or a layer-3 switch). b) This needs to be set up on the router. Depending on its capabilities, this can be firewall style or (with a layer-3 switch) through ACL rules. 

Additionally, on your ESXi host with a standard vSwitch, you shouldn't be using an "all VLANs" port group. Add a port group to your vSwitch for each VLAN that you want to use. Connect a vNIC from each VM to the port group according to what VLAN you want it connected to. The "All VLANs" port group receives frames from all VLANs but frames sent out are not tagged, so they all go to the physical switches untagged (default) VLAN. I've only ever used it for packet capturing into a VM (together with promiscuous mode). 

This depends on the firewall you have in mind. Depending on the type and possibly its settings, there are several possibilities: 

This is what you see in Task Manager. You can get a more detailed view in Resource Monitor. Port aggregation/LAG will only be able to do so much. Since a single flow will always use the same port combination LAG can't increase that bandwidth. It only helps avoiding aggregation bottlenecks. To increase the bandwidth between two nodes you must increase the bandwidth or use some kind of multilink load balancing, depending on the software in use. 

You can't reconstruct missing packet elements from the checksum. It's for error detection, not correction. If just one byte/word/longword is missing it could be reconstructed, e.g. by just trying all possible values and recalculating the checksum. However, educational purposes, hacking challenges and such are off-topic here. 

ARP is required when an IP packet is forwarded over Ethernet. When the IP address is in the local subnet it'll be ARPed, the IP packet wrapped into an Ethernet frame addressed to the ARPed MAC address and sent out. When the IP address is not in the local subnet, another router is required (next hop), so the frame is addressed to the router's MAC address instead (which also requires ARP first). Of course, not every IP packet triggers an ARP request - ARP responses are cached for some time ('ARP aging'). 

The simple setup is to only use tagging on the trunk between switch and the Unifi gateway. Your default/production VLAN runs untagged while you tag the guest VLAN. This must be the same on the switch and the Unifi. On the WAP ports, just use the guest VLAN untagged. However, this puts your WAPs' management completely inside the guest network. If you want to avoid that, use the same VLAN trunks - production untagged, guest tagged - with the WAP ports (on both switch and WAP side) and associate the guest VLAN with the guest SSID. It seems that you've tried the latter setup but you reversed the tagging for the Unifi - if it's the same on the Unifi side it's fine but I wouldn't do it that way. I don't know your hardware, so I can't give any more specific advice, sorry. And I can't make too much sense of the screenshot either. If you think you've already got the setup you should provide a table with the settings. 

Think of each VLAN as a single switch (or switch group). VLANs work by logically partitioning a single physical infrastructure. Each port is logically connected to one of the VLANs = one of the imaginary switches. Only devices connected to the same VLAN or imaginary switch can talk to each other directly. Devices in different VLANs require a router to forward their traffic - the router is your point of control where you can permit or deny the communication. Instead of running a separate cable for each VLAN between two switches, you use a VLAN trunk port: on the wire, each frame is tagged with its VLAN ID. The VLAN ID tells the other switch where the frame belongs. (One of the VLANs - the "native" one - can remain untagged but both switches need to agree on that). Edit: there are several goals when separating traffic into VLANs: 

VXLAN is L2 bridging over IP/UDP, so in short: no, it won't save you from a broadcast storm. There are a few things you can do to avoid broadcast storms from happening: 

The link pulses are always sent on the transmit pair for 10BASE-T/100BASE-TX even on a 1000BASE-T port. This creates a problem only when two ports with the same pinout - MDI vs MDI-X - are connected to each other, but the practically standard Auto MDI-X algorithm (more or less) alternates the transmit and receive pairs, so eventually the pulses will find the right path and the link can be brought up. 1000BASE-T also needs to figure out which pairs are connected to each other (straight cable, two-pair crossover cable, four-pair crossover cable). This is done in the physical coding sublayer (PCS). 

The specs on your link are just the amendments. You can get the complete standard at IEEE 802.org. As far as I can see, power management from Clause 6 applies to all PHY types. 

A switch not supporting 802.1Q tags should drop tagged frames. However, many simple switches don't comply to 802.1Q at all and they forward tagged frames just like untagged ones - for the most part compromising whatever intent the VLAN partitioning had. A simple switch can simply overlook the TPID marking the Q tag and regard it as frame payload, just like the Ethertype field that it preceeds. The effect is that tagged frames are switched just like untagged frames. Since the switch is likely not to have the destination MAC address stored in SAT the frame is also likely to be broadcast to all ports. You should never configure a VLAN trunk to a switch not supporting it. 

Trying to separate the trunked VLANs from inside the guest won't work as the port group with VLAN 4095 will forward all frames without tag. 

While there already excellent answers to this, I'd like to add: no, speed is not necessarily affected by distance and yes, very often speed is affected by distance are both true. Why is that? Strongly simplified, the longer the distance, the more "hops" are involved on the way through the Internet. The maximum bandwidth is determined by the slowest hop and concurring traffic. With increasing distance and a somewhat random distribution of hop speeds, the probability for getting slower overall speeds is increasing. Additionally, physics gets in the way and increasing latency may also slow down the link. But this is not to be taken for granted. Technology allows us to build a planet-encompassing connection of nearly any desired bandwidth. However, bandwidth and distance are enemies and both dramatically increase the cost of the connection, again making it less likely to exist just for the connection you might need right now. Of course, this is oversimplified but in reality, this situation is what you very often find. And then again you don't when there's a surprisingly fast connection or a distribution proxy just around the corner - but when everything's instant we rarely think about the speed of the Internet... 

iperf can help you generate flows of a certain bandwidth. You can then check if your network behaves as designed and examine your equipment for signs of problems: packet drops due to exceeding aggregate bandwidth, overrunning buffers, CPU overload, significant rates of checksum errors, and so on. A simulated network might behave somewhat differently from a real one. The simulation is limited for real-time or high-frequency effects and the simulated individual device might not act exactly like the real thing. For instance, simulated bad links behave statistically and rather unlike a real-world problem. Trying to understand the behavior based on the derived CWND parameter isn't easy. You should first run the simulation with an error-free link and check how congestion control works without interference. With random link errors, each frame drop is sensed as congestion, reducing the CWND - in conjunction with real congestion this can behave pretty eratically. 

RFC 791 is 36 years old and this option has never been adopted. Please mark this question as answered or it'll keep popping up. 

Point-2-point mode is the opposite of arbitrated-loop mode (AL). You usually do not want AL if there's a switch. Set all ports to P2P at all times unless you really do need AL mode (when you chain multiple devices on a single port). In AL mode, ports pass on traffic to other ports behind them in the loop. At any time, there can only two ports active in a loop. 

There may be several differences which may be important to you - or not. As with any purchase, you should know what your requirements are, what you'd like in addition to that, and what you're willing to spend. 

As long as all MACs can be stored in the switches and there's enough space in your subnets, no. However, only your hoster can answer that for sure. 

Easiest approach: use another subnet that's not within your production network (e.g. 10.0.4.0/24). Second easiest approach: split 10.0.0.0/22 into (at least) 10.0.0.0/23, 10.0.2.0/24 and 10.0.3.0/24. Another approach is an L3 ACL on your switches - if they support this. You can allow some source IPs to connect to 10.0.3.0/24 within the same subnet while denying all others. NAT doesn't help you - it works across a router and as long as your clients believe the destination is within the same subnet they won't use a router. You'd need the router to answer ARP requests on behalf of the destination (seemingly in the same subnet) - this is called proxy ARP. Both NAT and proxy ARP are messy and to be avoided. 

Using load-balancing trunks, the hardware needs to keep the flows in order - out-of-order reception in high bandwidth flows usually causes a high performance penalty. So basically, load-balancing works on flows and not on a packet-by-packet basis. Traceroute uses its own "flow" (ICMP oder some UDP port) which may or may not follow the same path as the flow you're analyzing, so it might show you a completely different route. 

In the original 100BASE-TX, nothing is transmitted in the IPG period. Energy-efficient Ethernet adds low-power idle (LPI) mode which sends idle symbols generated by the PCS sublayer. 

(Actually had to look up VLSM, CIDR is probably a more common term for the real world...) I don't think you've got that right. You can use any available IP address from the subnet for any device. It makes sense to have a common scheme, so you don't mix up things and simply "know" how your network is laid out. Additionally, IP addresses aren't assigned to links, they are assigned to interfaces - this is not always the same. Think of a layer-3 switch with half of its ports assigned to one subnet (VLAN) and the other half to the another. It requires two IP addresses that are assigned to its two VLAN interfaces. Also, many routers support switched port groups which are much the same as VLAN interfaces. 

Private IPv4 addresses allow you to run a network without applying for public IP addresses at your regional registry. Since IPv4 addresses have run out it's the only way to set up a new network or expand an existing one. Private IPv6 addresses allow you to design your network in such a way that some entirely local services simply can't communicate with the outside world. 

Since you route your VLANs on the SG300, the Fortigate can't ever see the client's MAC address. All it can see is the SG300's MAC address on VLAN 1 (which you've probably permitted so everyone gets through). MAC addresses are only meaningful within their layer 2 segment/VLAN, they simply cease to exist outside. (When a MAC frame is passed to a router, the router strips the IP packet from the frame and when forwarding it encapsulates the packet in a new frame with its own MAC as source.) I wouldn't use MAC-based authentication. Using reserved DHCP addresses on the DHCP server maps the MAC addresses to specific 'static' IP addresses. These you can use on the Fortigate. To prevent a client to use a fake IP address you can use DHCP snooping and MAC binding in the SG300 (not sure if the SG300 supports this though). If you do need to do this based on clients' MAC addresses you'll need to extend the VLANs up to the Fortigate. This however produces the problem that the LAN clients would need to use the Fortigate as default gateway towards the Internet but the SG300 as gateway for the LAN subnets. Routing everything through the Fortigate would work but is probably not what you want. If you can't set up a static route for 192.168.0.0/16 on the clients pretty much your only bet is to rely on ICMP redirects (causing each Internet connection's first packet to be lost). Another option would be to use the Fortigate's single sign-on feature and have the client authenticate towards a Windows AD or such. Yet another option is to apply MAC-based filtering on the L3 switch but that's not a good design - you'd be splitting forwarding decisions between core switch and firewall.