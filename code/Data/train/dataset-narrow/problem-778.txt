There is nothing native in SQL Server that is going to track that level of information. Based on what version of SQL Server you are using there is SQL Server Audit (SQL Server 2008 or higher) that can track database level access, but it does require Enterprise Edition. You could also roll out your own method of logging using Profiler or Extended Events that just capture object access for a given database. As long as you are not trying to capture the query and all it should be pretty low overhead, but it would be based on how active your system is. 

Not knowing what all the steps of your job do, we cannot provide you a step-by-step instruction to deploy it. You can script out configured SQL Server agent jobs, which may be a starting point. I would suggest installing another instance on your local machine, unless you happen to have access to a test server. Then take note of everything you do to get your job up and running on that instance. If you can repeat it over and over again, then you have your deployment document completed. 

I had thought you could change the to a lower value which would indicate a small buffer size to capture events. However the lowest value you can set this to in SQL Server 2012 is , which the query I used does not meet that limit to cause it to immediately be dispatched. Only thing I could do was at most execute a query that would cause the buffer to be reached and the previous events captured to be dispatched: 

I don't know that you can really be objective about choosing a lesser version over a current version. It is more or less forced eventually. Hardware goes out of date and purchasing any new hardware may require using a more current version of Windows Operating System; which that in turn requires you to upgrade SQL Server. I actually had conference call over a client that is in this very boat now. As well your hand can be forced by Microsoft's release plan. Once a major version is released you will reach a point that you can no longer purchase the older version. Which is the case now with SQL Server 2012, you can't purchase a SQL Server 2008 R2 license. You may use that version but you will have to purchase under the SQL Server 2012 licensing model. SQL Server 2014 CTP2 was just released the other day so after a certain number of days/months after the RTM release you will not be able to purchase SQL Server 2012. The overall decision has to come from the business' money holders. Business meetings I have taken part in the one thing that is always considered when building a new system out for an application is licensing considerations (support maintenance annual cost, licensing upgrades, etc.). The pros and cons of licensing what version/edition should always be considered up front. I have been in environments where the business was feed the wrong information on what quantity/type of license to purchase, then when they were audited because of industry standards they got bitten pretty hard from it (or the scape goat got fired). It was ultimately their responsibility. The best thing I would suggest is looking at Software Assurance. Especially since in the two years covered SQL Server 2014 should be released. You may pay a good bit more now, but with the discount pricing you will save a considerable amount of money when you go ahead and purchase SQL Server 2014 licenses. Especially if Microsoft decides to change their licensing model again, although I have heard nothing that indicates they are going to. 

You will need to come up with an expression for your fill color of that cell or field you want to change. So an example: The basic setup is I just have 2 variables to enter a date and then a text box on the body of the report I will adjust the fill color based on the days between those two dates: 

The key is , this DMV is only going to return those XE sessions that are running. So you basically just look at the and that is when the session was started. You can verify this by looking at the session as the time returned should match up to when the instance was last started. An example is my SQL Server 2012 instance on my local machine is kept stopped most of the time until I need it. I just started it so you can see the times are pretty close: 

You can do this using PowerShell fairly quickly. If you mount the ISO or insert the media for the version of Window Server 2012 you are running, then use the following commands in an PowerShell prompt (elevated privileges required so open it "As administrator": 

This is just informational, testing showed it worked for me but I have not tested this on 2012 (only have SQL Server 2016 installed right now). Confirmed the below XE session will work on SQL Server 2012 as well. Test Scripts I came across this article by Pinal Dave which shows a VBScript that can replicate the occurrence of the calls. I changed this into a PowerShell script to just run against my local instance. Extended Event Microsoft is adding new events to Extended Events with each version (and in some cases SPs). The events you are interested in to capture the query causing the cursor will be: or . I tried including the but that one did not show anything in my testing. I added specific actions for each of these events, taking out the attempt to use the cursor_execute. Your XE session definition would look like this: 

Both of these modules are available in the PowerShell Gallery so from a machine with Internet access you can simply run the following command to install the latest version: 

SSIS 2014 is another beast though if you want to actually use the new features that come with it for management: SSISDB Catalog or Project Deployment (which requires the SSIDB Catalog). You would have to have a SQL Server 2014 database instance in order to configure all this. The only thing you would be able to do with this type of setup would be a file system deployment, anything else I think is going to require the database engine to be at the same major version. 

The wait types are associated with Extended Events from what I understand and can find. Considering that and your first sentence: 

A difference to note between SMO and SQLPS here is that SQLPS would not output the system databases by default, SMO will. If you look up blog post on PowerShell Profiles a common thing to do is add the assembly command to that so ever time you open your PowerShell command it is already available. I will then add functions that are basically commands I use often, and happen to have one for databases: 

For the most part (1) and (2) are done through stored procedure calls. I believe SSIS will be more efficient in handling this process. My end result is to determine if SSIS can do a better job and then the most efficient way of designing the package. Question(s) In cases where there are a large number of records would SSIS get better performance with the BULK INSERT task when (2) and (3) are the same database on the same instance? Or just change the procedure call in (2) to be a , taking out the need for (3)? In cases where (2) is a remote source (another SQL instance on the same network), does SSIS handle pulling data from a remote source more efficiently than doing it through the .NET SQLClient? I would not think there is a huge difference. As well, when (2) is a remote source that is rather large amount of data (8 million +)would it be better to have a package on the remote instance export the data; then move that file to the destination server and bulk load it? 

To give information on the performance counter side... The only performance counters I know of that might help would be the ODBC counters for disconnects. SQL Server has a counter for killed connections but those are connections killed by SQL Server, not the client. You would have to capture these at the client which you could use command to do this remotely. SimpleTalk has a good article about using this command. The comment suggestion would be the more human way of doing things. 

You can configure multiple listeners but what I think you want to do is just configure the other IP (for the 3rd replica) at the cluster level so that your AG resource can access it. If your cluster is configured for the multi-subnet then you should have the ability to add the IP for that 3rd replica to your current listener. If I recall you might have to create the role in the WSFC for your listener as a client access point. I know this is the required configuration when I have built AGs in Azure environments, but those may be special circumstances compared to dealing with all on-premise setups.