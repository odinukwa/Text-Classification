you can absolutely control what Jenkins pulls from your SCM w/the proper configurations - these should get you there. Also: I have polling disabled - you really don't want to use polling as it is expensive - configure a BitBucket PullRequest plugin to call your Jenkins job upon creation as you are doing and you shouldn't need to poll, although I don't know that particular plugin... this one is great: $URL$ 

if that is the error you're getting, it is clearly an issue with BitBucket Authentication as that is in the stack trace... the specific API call which is failing is displayed and you can see it is in the authentication process... as to why it is running successfully when invoked manually - it would have to do with a configuration upstream somewhere - check the format of your repo and make sure you use this pattern: $URL$ 

Service Level Agreements - our dev teams want/need results in minimal time, we all know that's not happening with either DAST or SAST tools without heavy configuration. Allowing teams to choose their own language and not even having static code support... leaving us with DAST if applicable or, ugh, pen tests, which in my view are essentially useless. We need to shift software security "left" - from point of inception, not wait until code is in production and hope we detect the vulnerabilities - I am sure someone will find them, most likely not the pen test team we are paying huge money for, however. Automation of static and dynamic tools, properly configured, driven off a threat model seem to be our only options to get ahead of the game. We all know "developer education" is a lost cause. How is your company/team solving this, assuming they even are or recognize it as a problem to address? 

I was under the impression DevSecOps was a mindset, not a team - if you have a Dev(Sec)Ops "team" you're doing it wrong... I'm trying to wrap my head around putting two "DevOps Engineers" together and calling them a "DevOps Team." We have development teams, SCM, Application Security and Systems Engineers all working in tandem for a rapid deployment/release model for pushing code and configuration/system changes through to a given end point - either staging or production This has nothing to do with any "devOps" engineers, as such. 

Unfortunately I had to disable the Groovy sandbox because I ran into so many situations where methods I wanted to use in my jobs did not appear available for whitelist on the script security page. Instead of adding a bunch of individual method calls to a whitelist or disabling the sandbox, you can also use a global shared library, since global shared libraries are automatically whitelisted in the sandbox. (The shared library approach worked well for me at first, but eventually I ran into situations where I did not feel that the code I was writing was appropriate for a shared library, so I just disabled the sandbox as it had never provided any benefit to me anyway. Just as a warning, disabling the sandbox is usually fine in single-tenancy situations, but not in multi-tenancy Jenkins instances.) As for your code, unfortunately doesn't appear to have any properties pointing to the actual URL of the SCM source (I can't confirm this as I don't use SCM polling on my Jenkins instance). Instead you could try something like this: 

This is a known bug. See JENKINS-42878 and JENKINS-41996. This bug has been resolved upstream, which means you should be able to fix the bug by upgrading the plugin to the latest version. 

According to the official GitHub Branch Source Plugin documentation, the plugin can automatically configure webhooks for you if you have your GitHub API token configured in Jenkins global settings: 

Or this example builds a job with parameters and also triggers the build asynchronously (parent job won't wait for child job to complete before moving on to the next step): 

You cannot "Build with Parameters" on the first build of a Pipeline job. This is a long-standing known bug with Pipelines. 

doesn't persist environment variables. Instead, you need to tell what steps to run with that environment by passing it a block. Here is what I think you want your code to look like: 

Yesterday you have build myimage:latest which had the ID (SHA) 365d8f7bf565. Your container instance ABC is running a task named MyTaskDefinition-1-containerName-someLongId. when you inspect that container, it's running the image "sha256:365d8f7bf565.........." Your other container instance DEF is running another task. It has a similar name (only the ID differ), but it's running the same image. You push a change to your repo. CodePipeline picks up that change, build and publish the image to ECR. That new Docker image is also myimage:latest, but its ID (SHA) is f7ec5e54ac96 Now you need to add a step to your pipeline to use Lambda functions and the AWS NodeJS SDK to do some calls to your cluster: 

For question #1) I think this could perhaps be better answered on SoftwareEngineering SE. Nonetheless, I'll risk an answer: for this kind of information (states) coming from that kind of architecture (distributed), I recommend event sourcing. It removes the complexity and many headaches that come with the nature of distributed systems if someone try to use traditional database paradigms. For question #2: both would work. To know what is better and cheaper we'll need to know more about your use case. 

As far as I know, it is not possible. The the offcial AWS Lambda documentation says it support CloudWatch Events, but no mention of CloudWatch Alarms (and CW Events != CW Alarms) What you are currently doing, sending the alarms on a SNS and using listening on a topic seems the way to go. In fact, CloudWatch Alarms only outputs to SNS so far. 

I would keep the ECS container instances (I'm talking about the Docker hosts - I don't like AWS terminology here) and the deployment as two separate things. Get your ECS stack up and running. You can manage it through CloudFormation and Auto-scaling groups, that's fine. Just think of your cluster as a platform where you will deploy to, not something you need to redeploy. Then, for CD, the easiest method by far is to update the service definition to use a new task definition and let ECS rolling update the containers for you. Every time it start a task, ECS will run docker pull image:tag even if it has the image locally to make sure it has the latest version of that image:tag. So the image tag you use really don't matter (there is no need to change the tag on every build). That means that you can build myimage:latest over and over in order to deploy it easily. What you need is a task definition where the image = myimage:latest. Create a service with that task definition and every time that ECS start a task (an instance of your service) it will be the most recent "myimage:latest" you have built. From there, you are missing only one piece in the puzzle, from CodeDeploy, you can call something, perhaps a lambda function, to create a new revision of your task definition and update your service and ECS will automatically create new tasks for that revision and remove the old tasks. An example: Let's assume you have created a service called MyService. That you have configured that service to run 2 tasks for the task definition MyTaskDefinition:1 (revision 1). In that task definition, you have one container definition which image is set to "myimage:latest". 

As a side note, I suspect you actually want to set to , otherwise your checkout step will not be able to find git and your deploy step will not be able to find scp. 

As you can see, the invocation of can get relatively complex. See the documentation linked above for more complete information. 

It's much easier to use scripted Pipelines to do this since you can use arbitrary Groovy, but you should still be able to do this with declarative Pipelines using the step. 

I know this isn't the solution you want to hear, but you're probably going to have to switch to scripted pipelines. Generally speaking, scripted pipelines are more flexible and powerful than declarative pipelines, whereas declarative pipelines are best used for simple, straightforward builds. Once you have some complexity in your build, such as these requirements you're describing here, scripted pipelines become not just superior but necessary. From the official Pipeline docs: 

If the system recently rebooted and your proxy server is giving 502/503s, it's most likely that the backend service failed to start. Using whatever tools are most appropriate for your OS/distro (e.g. , /, ///etc.), do the following things: 

I believe this may be a result of running Jenkins behind a proxy, which can cause legitimate requests to perhaps appear to Jenkins as cross-site requests. From the official wiki: 

Yes, this is pretty easy with Jenkinsfiles with no need for any third-party plugins or anything along those lines: use the built-in Pipeline build step. I use this to trigger builds of projects in a dependency chain, so that after one project builds successfully, other projects that depend on it will pull in the updated dependency and build against it. Here is what this looks like in a Jenkinsfile: 

where is a variable containing the name of the repository you wish to build. Things can get a little more complicated, such as if you're using folders or Multibranch Pipelines: 

A big part of DevOps is making it possible to release very often. That comes with automated build, automated testing, etc. You can say that to achieve its goals, DevOps need to use automation to be efficient. Here's how DevOps and automation are related. DevOps is not just automation, there's more to it. Conversely, automation is not exclusively used by "DevOps people". A lot of automation was taking place in IT before DevOps came around. 

Create a new task definition (which will be exactly the same as before). That will be MyTaskDefinition:2 Update your MyService to use MyTaskDefinition:2 (instead of 1) 

ECS will create new tasks. The container names will MyTaskDefinition-2-containerName-someLongId. When you inspect those containers, you'll see that they will be running "sha256:f7ec5e54ac96.......". Perhaps you'll have 2 tasks on the container instance ABC, perhaps they will be sprayed out (that depends on your service's configuration) After some time ECS will remove the old task MyTaskDefinition-1-containerName-someLongId from ABC and DEF. 

By looking at these items, how they are important to you and how they are implemented by the solution, you will be able to choose one of the secret management service out there. 

Proper management of an application's secrets has always been a challenge. New challenges came with the adoption of the cloud. There's a great OWASP presentation about the reality and challenges of storing secrets in the cloud. You might be surprised to hear that storing secrets into the source code is one of the solution (or "architecture") presented. That's because, right now, there is no perfect architecture or way of doing this. In the end, your secrets might be encrypted... but what is guarding the encryption key? "Turtles all the way down", they said. Every type of secret management has its strengths and weaknesses and the presentation already covers that. Instead, I'll try to go over some of the features you might be looking for in an secret (credential) management solution: