and you apply another hash algorithm to this already-hash then? Why? MongoDB's implementation, apart from the missing method descriptions, is questionable on its own: 

What's a ? A ? A ? ? ... see 2. : What is in which box? Oh, there's nothing in a box. It's . is a noun. 

Interfaces, as well es classes, are types â€“ see Java Language Specification (JLS), 4.3. Reference Types and Values: 

I'd make them and document them. 2) and being used before their declaration might confuse a reader of your code at first sight. 3) I'd separate the actual "workhorse" from the UI, i.e. make a separate class. 4) I'd also make a separate class. 

, , : I knew what these abbreviations mean at first sight, but the point is they describe the technical type of what they contain and not the use-case semantics of their content. I know stands for (probably) and has nothing to do with one of these elms, but... What are ? 

There is a lot more you could do to the rest of the code, but that is out of scope for this question. 

Unfortunately, you didn't specify your Python version. In 3.X there is the flag. Hence you could refactor this to You could also get access to (there are implementations for 2.7 on pip). This would allow dealing with paths in a pythonic way, because you can now do things like: rather then and have python deal with the os specific bits (symlinks, correct slashes, ...) 

This avoids duplicates for corners and edges and I could cache the results for even faster computation (though this is not very expensive to compute). Here is the full example as a gist: $URL$ 

further we can replace the strings and with a Boolean and stay in numpy for longer (down to 1.633 seconds): 

This run, which covers about 1/5th of the effect sizes and 1/10th of the sample sizes you are interested in, takes about 5 minutes to run on my laptop. Since it uses , I think scaling up to your full system size would take about 50 times this number, or about 4 hours. The bottlenecks here are still the t-tests, but also simply calling , a sign that we got rid of the assignment-by-element bottlenecks and reduced the t-test bottlneck at least somewhat. 

Then, instead of copying all of the existing data into a new array every time you go through the loop, just update the relevant positions of using NumPy slice notation. 

I had my own solution to PE #2 lying around and in case it's interesting or useful to you here it is. (It uses and is wrapped into a function.) 

I now average over 1000 runs for a single game for both versions (compared to 1000 different games in my original post), using the method posted in Update 4. The other answer is very efficient in cutting down on the constant overhead and rightfully points out that the number of calls (even if it's doing no modifications to the board) adds unnecessary bloat. Juvian also pointed out that I do have access to the current move, which inspired this idea. For each adjacent field I use floodfill to find the group of enemy stones (if any). While doing so, if I encounter a border which is free the group has liberties and I stop the floodfill. If I manage to fill the entire region without encountering an empty border field the group has no liberties and is thus captured. Another advantage of this approach is that it conforms with the rules (See this Boardgames SE question), because I remove all stones in the opposite color first. Here are the two relevant functions: 

Since you are working with binary data, you should tell NumPy that your is everywhere that you can. That will lower memory requirements and speed up certain operations. For example, in should become . The default NumPy is which is not what you want. The python convention for naming functions is i.e. all lowercase with underscores, not . So should be etc. The right approach for optimizing your currently too-slow function is to use line profiling. I really like the module. If you use IPython you can use it very easily as an inline magic function. Doing #3 will mean unpacking that formidable iterator comprehension you wrote! Instead of squeezing it all on one line, I'd define a generator function for the iterator, and try to be extremely explicit so that every line has only one function call, like this: 

Assuming is an okay thing to do you don't want to check after ing an element but rather before you insert it. It saves you the overhead of appending and popping visited nodes which can be quite substantial. Further, should be a (as stated in @Alex 's comment). It could also be a good idea to use an actual queue object, be that (for FIFO / LIFO) or a . The latter will slightly reduce performance (insert from O(1) to O(log(queue_size))), but offers a lot of added flexibility and easy scalability to graph search. Setting the priority to: is DFS, is BFS, (or ) is Dijkstra's search, is greedy search, is A*. I think that's a really cool property. 

A) This is not very useful output. I would rather return how many lines have been inserted into the database or nothing at all. The fact that something happened somewhere while this code executed is implied by the user calling the script. B) If the script fails, you should inform the user; however, it is probably better to not catch any exception and then continue. The block will be executed regardless of what happens in . You can omit the entire block. A setup is thought of as a "cleanup block" which will make sure that the finally is executed before any exception is escalated. 

I didn't know about the option for . Very cool to learn! I like your graphs; the only improvement would be to plot the points and the curve on the same graph (i.e. combine the top panel and mid panel of the graph). Scipy's uses nonlinear least squares regression. In addition to comparing to the "local" results, you might also compare the NLSR results to the results of doing linear-regression on log-transformed data. 

Why are your Python lists instead of NumPy arrays? If you're already using NumPy, you might as well use it wherever you can. You probably don't need the loop, do you? Can't you use NumPy array slicing and the matrix capabilities of to replace this loop? If you are going to loop, you don't need to do and then reference . You can do and then reference in your loop code, for example. Write some docstrings for your functions please! 

There is a steep gap after buildins.sum, i.e. you spend most time there. We can use instead (pushing it down to 3.457 seconds): 

Here is a faster version (around per batch). Its essentially refactored for readability and often in vectorized code, more readability / code beauty makes code run faster: 

Large Array There is multiple optimizations you could do, but only 1 that really makes sense here: Bin it. You don't need it. You pre-compute a lot of information that you reuse exactly once and that you can compute on-the-fly. There is no benefit in having this. In fact, you are making it worse by reading the once and then reading the array version of it, which is 40+ times bigger. Not cool :D The short version of it is that is wrapping python s which store 5-tupels worth 40 byte per entry. takes to represent in this format, whereas you can instead stick to a single character worth 1 byte and look-up the value as well as compute using the predecesor (which you know). This will save 40(!) times the disk/memory space (down to after optimization). Here is a version that uses , but saves only a character (worth 1 byte) instead of the tupel (40 byte): $URL$ I've also added as dependency and refactored your code (a lot) because I couldn't make heads and tails of it. Here is an even shorter version that no longer needs : $URL$ I also removed the timing comments, because that can be done more efficiently with or another profiler of your choice. In this scenario, I felt like the prints obstructed the code a lot; now it's easier to read. If a blinking cursor with no output irritates you, feel free to add more prints (at the cost of readability and a tiny bit of runtime).