can be quite useful. though what you find for "Use Cases" if you do a web search (the pictures) are more for general software. I would also put some credit to the Class diagram. this shows that you are able to show the relationship between all of your objects, and that you know the layout of your architecture. what it comes down to is that your feature set should be all planned out, and locked int (at-leased in a need/want setup) before modeling, and diagramming is even started. these should be all in your Brief/Treatment/Script (sometimes referred to as pitch, features document, and story). then from there you would do up your tech doc stuff that has your models, and diagrams. there are companies that use UML, but these are usually companies that have separate design and implementation teams. the companies that will create all of their documentation, and then give it to a team of code-monkeys to create an prototype/alpha. its said that if you can model your game accurately you should be able to give it to a completely different team and have them program it though this is more a pipe dream then an accuracy. 

the only reason that market share should matter is if your end goal is profit. many people who make games are in it for more then just profit which is the same distinction as a "job" and a "career". It should be your decision, and you decision alone of what platform to target based on what you want to do. not what has the higher market share. this is the same decision that sometimes triple-A title developers have to make, and because of this they have to leave out market share. you should focus on what you know, and not what has the largest market share. if you want to target multiple platforms then do it, but I don't think market share should make the decision for you. 

I am looking at building a real time strategy game (of at least the framework for one) in Unity, and was wondering what control structures and/or architecture I should focus on using. current expectations: I think that I will need a global controller/registry architecture, with sub controllers for the different players while considering the AI controller(s) to be player(s), and then registries for the different groups. how does my current design logic hold. additionally are there any specific resources that I should look through to achieve this goal? 

yes, no, maybe it depends on what information you absolutely need your nodes to have (the simplest node I can think of for a tower defense game is is a point, a bool occupied, and a bool reachable) 

this might actually be a combination of things that are going on with the game, and the player simultaneously, but for different reasons. 1: the player may be learning the game to the extent of being able to master the tools they are given in a First Person Shooter becoming more and more accurate with a gun that is designed to have issues, or learning a different strategy to complete a given situation. these are all bases for player improvement (which some of the other answers have stated, or alluded to. 2: it may be to do with the difficulty curve of the game (there are multiple, but I will only talk about specifics here). as a game progresses it is expected to present more, and more challenges to the player, and by nature the player is needed to gain more, and more skill to proceed (see 1), and by virtue the game can continue to increase the difficulty of the game itself. the most common of these curves are linear increasing, increasing step function, and (one that I dislike, but is still used) logarithmic. 3: it may also be that the tools that are given to the player directly modify the difficulty curve by bringing it more toward a linear constant, or a fractionally increasing linear. though it should be said that with these new tools can also greatly increase the difficulty because the player is expected to have more of an advantage otherwise (this is where we get the step function difficulty curve where the steps are increased every time the player earns a new tool) when all of these parts are used in tandem if one, or a couple are under-, or even over-expected then the game can easily become too easy or too difficult, or just seem that way. like in your example of Angry Birds. as the game progresses the player is presented with different bird types that have different abilities that should conform to the given puzzle. so it is expected that the game still has a difficulty curve, but because each puzzle is in isolation of the others they must be evaluated individually instead of on a curve, and by nature the difficulty of a given puzzle is independent, but the game overall should still conform to a curve. as a note that this answer only considers player skill, and never takes into account luck. 

If you could give these platforms a physics volume (not sure if this is exactly correct) that can detect the components of the collision vector looking for a positive z component (seeing as positive z is up in UDK by default) then allow that player to pass throw. On the falling through on you would have to be able to relay a message containing the command (or a bool), and the "player" to the volume, and then basically turn off collision for that player for 1-2 seconds. I am unsure on absolute implementation of these features. 

in order to develop a game via physical media for a console (XBox360, PS3, Wii) you would need to contact the respective company (Xbox360->Microsoft, PS3->Sony, Wii->nintendo), and request/purchase a dev-kit (this is not a small request/purchase, and some of these companies may request that you formally pitch your game) this dev-kit is in many cases a system that has some of the features either removed, modified, or added (in the case of addition this is for the ability to debug, and to easily get information from the system), and can also give rights to the user that are not given to a user of the actual system. in other cases the dev-kit is a software-library/emulator for testing the executable on. few if any console developer(s) give these dev-kits to anyone who asks, and it requires a non-disclosure agreement (for anyone to work on the project). if your more asking about language, and dev-environment that can be different from system to system, but is a fair question when you contact to request a dev-kit. as a side note: these dev-kits are usually per title, and need to be re-requested/re-purchased for each title. 

This is the whole concept behind micro-transactions (I will use real money here for something more tangible, but can be extended to imaginary currency/points/rep), and companies have made millions in terms of real money from it. there is still some discussion of what should be the limits of this, and sometimes the question of ethics comes up, but that aside. Yes you can require a fee for some actions in your game, but the following question needs to be observed. 

This distinction can be based on a lot of factors. How is your physics going to function? will it be based on a variable frame rate for smoothness to the frames, or will it be based on a fixed frame rate for accuracy of calculations. How complex will your collision system be, or how many objects might be colliding each frame? (this can be a major bottle neck for variable frame rate let alone bottle neck period) variable frame rate is the easiest (assuming that your keeping a clock to give to physics, and maybe collisions) in that you just have a loop with a defined break on exit command for a constant frame rate I have seen, and done it a few different ways. 

for the actual implementation unless your game uses either of the 2 points at the beginning you can just treat the loading of each level as a different method called by your constructor. for example 

As far as I have ever gleaned the Y = up/down, and Z = depth is based off of physics where gravity is always in the (-Y) direction, and then adding 3D means you don't want to change a fundamental, so it was made depth. On the Z = up/down method though that is a throw back to mathematicians. because X/Y was drawn on the paper that was flat on the table when the Z-axis was extended it was coming up out of the paper, and therefore up. though many of your engineers will also use this convention as well. in regards to the convention used by the given tool: Maya, and Unity have Y-up (probably designed by someone with a physics background). while 3DsMax, and Unreal have Z-up (probably designed by mathematicians/engineers). though it can also be said that these could also be just a split decision made one day because a consistent system had to be used. since this question focuses on a modelling tool, and is placed on a gamedevelopment Q&A site. you might want to look into what coordinate system you will be exporting to, and make sure that you conform to that. also realize that some system the axis system is hard set, and permanent, and others it can be modified (think it can be changed in Blender and Unreal, but might be mistaken) 

if person X is working on section Y of the project, and person A is also working on it then both peoples modifications have to be taken into considerations, and in many cases their work needs to be manually merged. then comes the question of time, and this directly relates to the number of people, but not always. there is a "fallacy" in computer science that I have seen multiple ways called the "1 man month", it basically means that one person cannot create a fully featured solution to a computer science project in one month. though this has also been the site of some debate, and statements of "I can do that", but the thought is that it takes more then one person (sometimes it takes people with specific talents) to get things accomplished. then questions like this can very easily be used to ask how "many other people do I need to do, or something like project X?" when the truth of the matter is this is not a question for others, but an honest self-reflective question for yourself. then have you done a SWAT analysis (especially S, and W) of yourself, and your possible team? yes it is possible to find how many people made these games, but that doesn't "explicitly" mean that you will be able to do it with the same number of people. 

I am not directly sure as to if there are any direct influences from Microsoft for anything beside the general game. they have the right to not allow a game to be released for their system by just a single word. As to the actual successfulness of any of these different options that will actually very from IP to IP, and could very well be dependent on the exact game. you could probably go and find the top sellers for physical media games, and downloaded games, and probably see that some game types sell better as physical media while others sell better as downloaded games. For a time it was sited that thousands of people were buying an Xbox360 just to play Bejeweled though this most likely will have changed. Though this might not be what you wanted to hear, but like many things in popular culture the success, or failure of a given IP, or game can be determined not on its features, development time, or means of release, but on its ability to be that "flavor of the month" granted some IP/games have more of a staying power they are still just the current "flavor of the month". 

there are 2 competing ideas in projects for number of "workers", and they both have applications to programming/development 

My game entities currently hold a quaternion for their orientation with the ability to return either a 3X3 full rotation matrix (based on that quaternion), or a full 4X4 transform matrix. though what I have come to find is that I am not able to convert from my matricies to matricies directly, so my next thought would be to force the conversion by hand. which of the following methods would work best/easiest/accurate? 

Spacial partitioning is a big subject with entire books devoted to it which makes a general form answer difficult, but I will try to address each one of the major types. I will talk about the collision resolution to talk about the agent resolution (an agent field of vision is essentially a collision test) Tree Based Partitioning(BSP, Quadtree, OctTree): I know that BSP would typically get its own section, but it acts similar enough to the others so it is here. for collisions these tend to have fast resolution at the leaves, but can have slow resolution when the object in question is across the root partition (though this is an edge case) it eliminate some of the benefits of the tree partitioning. when using such for AI applications these have the same benefits as the collisions, but are far more likely to experience the edge cases of crossing partitions mainly because agent field of view is a bigger radius then the collisions, and tree partitioning tends to lend itself more to objects that are equal, or smaller then the surrounding objects. though you could spend some time optimizing n (depth from root). If your planning to have a different AI controller for each leaf. this will require a great deal of messaging due to the high likelihood of the edge cases, and if your basing all messages on player/enemy-agent location then you will have to not only know what leaves are adjacent (which is counter intuitive to the vary structure to have a graph underneath a tree), or do the AI FOV tests from the player, but that means you would have to do back end checks for if you want mod dynamics, or group level behavior. Hierarchic Based Partitioning (BVH) You could lump these in with tree based, but they have a different methodology of construction (leaf to root instead of root to leaf), and a disadvantage (wrt AI) that is unique to them so I am breaking it off. these are vary fast for things that are spread out, and converge quickly know what is adjacent, and relatively easy to move things around, but can suffer from maybe having to be rebuilt every physics iteration. for AI this is a late resolution system because the system is designed to not really do anything until your at a leaf (typically only 2 objects), and doesn't care about distance from one to another until it is making its root for the next parent (as these are usually built from leaf to root), and then you don't actually know where the entity is wrt to the dimensions of the leaf. for this approach it is best if every agent had their own controller, but I would greatly discourage from using this approach for AI as its drawback is quite enormous for the purpose of AI unless you are going to run it twice with FOV data as apposed to collision data which apart from reusing existing code artifacts has little merit. Grid based for collisions (presuming that geometry accommodates) this approach tends to having a graph feel to it, and is designed specifically to alleviate the problems of a tree partitioning edge case (mainly because an object in more then one grid section means that a collision will happen. though these do have a draw back of being data intensive. where a tree based system would rarely have nothing in a node, and a BVH would never have nothing in a node. the grid system is essentially a 2-3 dimensional array of object arrays, and has a high likelihood that a majority of them will be empty. Not to lose objectivity, but I would greatly endorse this system for AI. even though it can have a large memory foot print for collisions it lends itself easily to FOV tests (and could even replace the FOV tests with an adjacency test (is there a player n nodes away then react). though this approach does disallow for a unified controller system in that you would either have to overlay a tree onto the grid which loses versatility if the tree has to great of an n. there are other spacial partitioning systems, but they do not come to mind if someone would wish to add them in an edit it is acceptable general recommendation (this can be taken as conjecture) a high suggestion if feasible would be to have a zone type system (areaX is a zone with its own stuff, and then adjacent areaY is a zone with its own stuff), and then inside each zone have a grid. these zones can be based on a secondary partitioning system. composition of systems is not unheard of, and is quite extensible, but just avoid redundancy of systems (systemX does all the work, but needs to cross reference systemY that needs to do the same extent of work). When the discussion gets to the point of AI controllers (one controller for many agents, or agent groups) the point of grids do not lend themselves to unified controllers, but what you can do is have a controller for a group of agents (this is where mobs can come in), and then when one agent in the group "locates" the player/enemy agent the entire group can react. though maybe a threat processing, or something [tangent] for some originality have the agent controller for the group do a threat calculation on the enemy, and then have tiers of responses. so you don't have the classic "playerX pulls the mob while the other players setup to ambush the mob"[/tangent]