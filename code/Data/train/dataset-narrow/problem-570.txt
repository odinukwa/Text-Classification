With mysqldump you can only safely use if all your tables are InnoDB, otherwise your backup is inconsistent. If you have the requirement for a hybrid backup, then you need the on all tables in the backup (default), which will be safe for all engines. It's also worth mentioning that the default options will make sure your backup is safe, you don't need to turn any special flag on. Note: If you do have a hybrid mix, perhaps look at xtrabackup. It will only be locking during the MyISAM phase of the backup. 

The minimal package was designed for use by the official docker images for MySQL. It cuts out some of the non-essential pieces of MySQL, but is otherwise the same product. 

As noted, will change the system tables to include any new columns required. MySQL 5.6 includes support for microseconds in and , and as such uses a different format on disk for storage. Conversion to the new format does not happen as part of , but will happen on or and in which case you will not be able to start MySQL 5.5 and use this data directory. 

There's really risks associated with both approaches: Option a) Index from the start, but not realize you have created a number of indexes which are never used. These add some overhead (most noticeably to queries that modify data, but also with optimization of SELECT statements trying to identify the best index). You will need to discipline yourself to identify indexes no longer being used and try and remove them (PostgreSQL can do this; unfortunately MySQL by comparison is very weak at this out of the box.) Option b) Don't add indexes until people start complaining, or your diagnostic tools trigger that certain queries are slow and could be improved. The risk that you introduce is that you don't have a big enough time window between when you notice you need the index, and when you have to add it. PostgreSQL does support building indexes , which does reduce some of the stress from this sudden-index-add-requirement, but there are some caveats noted in the manual. 

The data about connection aliases is stored in the Registry, so either a file or a script that updates registry would do. Updating the Registry can be done with or Powershell. The tricky parts are syntax and the fact that 32/64 bit registry keys are not the same. That is, 

"Most secure" is an ambiguous statement that needs more explanation. You need to think about what kind of attack vectors you are trying to mitigate. For example, what if a malicious user trys to brute-force your built-in account? It's going to be locked out. This creates a denial of service scenario, as normal users cannot receive a list of valid accounts either. If you were trying to mitigate a DoS scenario by using hard-to-guess logon names, you just shoot your own foot. Hard-coding a password in your application will make it insecure. First, it can be extracted from the application, no matter how you encrypt it. That's exactly the way Blu-Ray encryption was broken. Second, should you need to change the password, you need to ship new binaries to all the users which is somewhat a hassle. How about creating a SSIS package that publishes a list of valid logins on a network share? This moves some security configuration from the database to your AD group membership maintenance. 

It used to upset me how features were decided at MySQL... How was it decided that partitioning was a critical feature for 5.1, but backup totally missed the radar? There seemed to be a bunch of low hanging fruit (years old bugs) that were not being addressed, and I was always cynical that unless it could check off a box on a features grid, it would never be handled. There was a bit of talk, but no indication it was any better under Sun's management. However, now that Oracle is in control, several years old bugs are being addressed, performance has become a feature, and I actually find really compelling reasons to upgrade to 5.5 and 5.6. I feel awkward having to defend one of the world's biggest software companies, but they're really not getting enough praise. Instead everyone is making claims they are somehow screwing the project. Most of the projects they 'screwed' made no commercial sense to them... however they make a non trivial amount of money on OEM licenses and subscriptions/professional services for MySQL. 

I have a blog post explaining why this is here. The short version: The query cache causes scalability issues on multi-core machines. So it is now disabled by default. 

As how input the data, a loop in a cmd session works pretty well. Change the loop upper limit to the actual number of files instead of using . 

Are there any other probable causes for disabling the BPE than human error? There is a KB article about I/O errors that might cause loss of BPE, but the current patchlevel should include the fix, and there are no log entries about I/O errors anyway. The tempdb files have been autogrowing around the same time, but there was plenty of free space on the SSD. The server is up-to-date with OS (Windows Server 2012 R2) and Sql Server patches (SQL Server 2014 SP1-CU6 X64 Enterprise Edition). 

Develop the packages on development environment. Push those to the test and let production admins move packages into the production. 

Talk with your SAN administrator. That's the source that should be able to explain you with detailed information what kind of SAN you've got and what it is capable of. Have you got MPIO? What's the structure of your fabric? Sometimes it makes sense to use multiple LUNs for different files. Behind the scenes, there might be different types of storage available. A SAN with some SSD capacity might offer tiering. That is, the hottest data is elevated to SSD -backed part of the system whilst colder data is persisted on HDDs. Some models provide autotiering, in which the system decides what's hot and what's not. Some models require administrative action. HP EVAs provide VRAID levels 0, 1 and 5. Using those will spread a LUN on all the disks in an array. This increases reliability, but the cost with VRAID 5 is increased controller CPU usage. The SAN admin needs to balance increased storage costs against increased CPU usage. Aligning NTFS blocks with storage is dependent upon the SAN. If you are in addition using virtualization (Hyper-V, VMWare, whatever), that's additional complexity introducec. Your storage vendor is likely to offer white papers, best practices and consulting services about how to configure the storage for optimal performance. Network packet size is relevant - if you use iSCSI. For FibreChannel, IP settings are not relevant. 

Small starting clarification: the article you linked to on InnoDB text/blob storage is a little out of date with MySQL 5.5, and the barracuda row format. This article is more up to date. On to your question: In the schema you have, each row will be less than ~8K, so you can guarantee across both antelope and barracuda row formats that all data will be stored in-line - not requiring external/overflow pages. If you were to require overflow pages, they are never de-duplicated (which is what I would probably describe your 'pooling' mechanism as). Even worse than they are never de-duplicated, they are never shared... If you could have a record too big to fit inline (~8K limit), each text/blob that needs to be moved out will take a minimum of a 16K page to itself. 

You've got to put it in context - InnoDB only verifies the checksums when it reads a page from the block storage device, and updates it before flushing it back to the storage device. While in memory, the checksum is not maintained. For many years, an IO to a disk has taken something on the order of 5-10ms (1ms = 1/1000th of a second). Computing a checksum probably takes somewhere around 50us (1us = 1/1000000th of a second). I don't have the actual data what it is in InnoDB's case, but if you Google "Numbers everyone should know", you'll hopefully agree I'm correct within an order of magnitude. Enter an era now where we have things like Fusion-io flash devices, which on paper have a ~20-30us access time, and you can see that reevaluating the checksum makes sense. My general advice: Don't ruin your backwards compatibility with MySQL releases unless you really need it. Most people do not need it yet.