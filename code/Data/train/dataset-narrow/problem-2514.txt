Hilbert-style deduction for intuitionistic logic and SK combinators; Gentzen's natural deduction and the $\lambda$-calculus. 

Yes, in type theory second order variables do have a type, it may be called $Prop$ (the type of propositions) or $Set$ (the type of sets) depending on the context. In your case, I would write $P:\mathbb N\rightarrow Prop$. The nLab entry on type theory and the Wikipedia entry on the calculus of constructions contain a host of references which you may find interesting. Also, the lecture notes by Sørensen and Urzyczyn are an excellent starting place for learning about the Curry-Howard isomorphism, independently of type theory. An additional note: if you are interested in second order Peano arithmetic and Curry-Howard, you may also want to look into System F before type theory. System F, which corresponds to propositional second order, has an enormous expressive power (precisely related to second order Peano arithmetic) and data types representing inductive structures may be obtained by the following "trick": take the second order formula describing the desired induction principle and "erase" all first order information. In particular, from usual induction (the formula you consider), you get $\forall P.(P\Rightarrow (P\Rightarrow P)\Rightarrow P)$, whose normal forms are exactly the Church integers. See Girard, Lafont and Taylor's book Proofs and Types and Krivine's book Lambda-calculus, Types and Models for a formal justification of the above "trick". 

The answer is yes. It is an immediate consequence of the definition of translation used by Lafont in his paper introducing the interaction combinators. A Lafont translation $\Phi$ from an interaction net system to another is an arity-preserving map from the symbols (i.e. the atomic agents) of the first system to principal nets of the other. Basically, a principal net of arity $n$ is a "tree" of agents with some leaves connected to each other and with exactly $n$ free leaves. In particular, it has exactly one free principal port and $n$ free auxiliary ports, so it may be seen as a "macro-agent". See Lafont's paper for the exact definition. A translation $\Phi$ must also satisfy the following simulation property: for all symbols (i.e. agents) $\alpha,\beta$ of the source system, $$\alpha\bowtie\beta\to\nu\qquad\text{implies}\qquad\Phi(\alpha)\bowtie\Phi(\beta)\to^\ast\Phi(\nu)$$ where the notation $\alpha\bowtie\beta$ stands for an active pair, and $\Phi(\alpha)\bowtie\Phi(\beta)=\Phi(\alpha\bowtie\beta)$ for its translation. Now, let $M$ be the longest simulating reduction $\Phi(\alpha)\bowtie\Phi(\beta)\to^\ast\Phi(\nu)$ (such $M$ exists because the number of possible active pairs is finite). It is clear that, if $\mu\to^\ast\mu'$ in $n$ steps the source system, then $\Phi(\mu)\to^\ast\Phi(\mu')$ in at most $M\cdot n$ steps in the target system. This is stated as Proposition 4 in Lafont's paper. So the simulation is efficient according to the notion of efficiency given in the question. The interaction combinators are universal in the sense that every system of interaction nets may be translated in the interaction combinators, in the above sense. Hence the claim. 

I don't know what your "oracle" is, but without further information what you are asking is whether the following language is decidable: $L:=\{ (t,u)\in\Lambda\times\Lambda \mathrel{|} t \rightarrow^* u, u \textrm{ normal}\}$ (with $\Lambda$ being the set of $\lambda$-terms). This is obviously not the case: for every Turing machine $M$, there is a $\lambda$-term $t_M$ (effectively computable from the description of $M$) such that $t_M$ reduces to a fixed normal form $u$ if $M$ terminates on the empty string and has no normal form otherwise; therefore, if $L$ were decidable, we would be able to decide the halting problem for $M$ on empty input by asking whether $(t_M,u)\in L$. If your "oracle" gives more information, then of course the situation may very well be different. For instance, if the oracle also gives an upper bound to the number of reduction steps needed to reach the purported normal form, then it is obviously decidable whether the oracle's answer is correct. If you are actually asking about proof-carrying code (like D.W. suggests), please modify your question accordingly and I'll be happy to modify/remove my answer. 

Like Emil says, the answer is yes, because the length (in binary) of the input string is actually computable by a deterministic logtime Turing machine, so is a fortiori in $\mathsf{FO}$. You may find this stated as Lemma 13 of Buss's The Boolean formula value problem is in ALOGTIME. The idea, attributed to Dowd, is to use the query tape to do binary search (under the convention that the machine gets an "out of range" response if the query tape contains a binary number exceeding the length of the input). I cut-and-paste the proof for quick reference (the number $n$ referenced in the proof is the length of the input, i.e., the desired output; the "index tape" is what Emil and I called query tape): 

Let me insist on the viewpoint touched upon by cody's answer. As far a see it, the question of finding a smallest $\lambda$-term equivalent to another $\lambda$-term is not really interesting, even if it there were an algorithm computing it. In fact, most programs you write in the $\lambda$-calculus (or whatever calculus of the $\lambda$-cube) are already in normal form, or at least head normal form, so they are already at their "smallest" in the sense you describe. Besides, being "small" doesn't mean being more efficient as discussed in this question. So the issue you point out (that normalizing blows up the size) is a real problem only when you want to apply a function to an argument, and reduce to normal form to get the result. For instance, suppose you have a term $M$ computing a function $f$ on binary strings. Then you have $$M\,\overline{x}\to^{l(|x|)}\overline{f(x)}$$ where $l(|x|)$ is the number of reduction steps using leftmost-outermost reduction, which is guaranteed to find a normal form if it exists (in CoC, it always exists, but what I am saying applies to the untyped case as well). Now suppose, furthermore, that $l(n)=O(n^k)$ for some constant $k$. Can you conclude that $f$ is polynomial-time computable? It is very easy to construct examples of $\lambda$-terms whose size increases exponentially with (leftmost-outermost) reduction, i.e., in $\Theta(n)$ steps you get a term of size $\Theta(2^n)$. This may make us seriously doubtful in regard to a positive answer to the above question: it seems that the $\lambda$-calculus is able to perform an exponential amount of work in linear time. In other words, it seems that the $\lambda$-calculus is not a reasonable model of computation in terms of complexity. Although legitimate, the above doubt comes from a misguided assumption, namely that $\lambda$-terms are efficient representations of themselves. They are not! Less jokingly, $\lambda$-terms are very inefficient representations of the states that a machine executing them actually needs to go through. It turns out that there is a syntax, called $\lambda$-calculus with linear explicit substitutions and introduced by Beniamino Accattoli, which is very good at representing the phenomenon of sharing alluded to in cody's answer. In particular, this syntax may be used to provide extremely faithful term representations of abstract machines of all sorts (see Beniamino's ICFP 2014 paper "Distilling Abstract Machines", of which I am co-author. I apologize for self-promotion but it seems relevant here). This same syntax may be used to prove that, contrarily to the naive intuition, the answer to the above question is yes, indeed: the number of leftmost-outermost steps to normal form is a reasonable cost measure, even if the size explodes, because there is in fact another way of representing the same computation (using linear explicit substitutions) in which: 

The fact that he never explicitly says that poly-size permutation BP are equivalent to poly-size BP led me to assume that having an $\mathsf{L}$-complete problem in $\mathsf{PPBP}$ was not known to be enough to get $\mathsf{PPBP}=\mathsf{L}/\mathsf{poly}$ (e.g., lack of closure under reductions). 

Edit: Just for completeness, this is Barrington on what I call here $\mathsf{PPBP}$ (second paragraph of Sect. 8 of his paper "Bounded-Width Polynomial-Size Branching Programs Recognize Exactly Those Languages in $\mathsf{NC}^1$", Journal of Computer and System Sciences, 38(1):150-164, 1989): 

[The following is more an extended comment with pointers than a real answer.] If you were in France, a good answer would be combinatorial physics. I say "if you were in France" because, for reasons that escape me but that must be mostly historical, in France combinatorics is considered part of theoretical computer science :-) In the rest of the world, combinatorics is considered to be a branch of mathematics, so I guess it is more correct to say that combinatorial physics is about interactions between physics and discrete math, rather than CS. Anyway, in my lab (which is a CS lab) there's a research group which focuses on several aspects of combinatorics, in particular combinatorial physics. This is by no means the only example in France of a combinatorics group in a CS lab whose research overlaps with physics; another example off the top of my head is this one in Bordeaux. Some of the members of these groups are theoretical physicists. The "official" recognition of combinatorial physics as a research field of its own is very recent, as you may read in this blog post, which contains some pointers and basic info about it. Computer science is explicitly mentioned a couple of times, although maybe not exactly in the sense you would expect, but I am sure that my colleagues from those research group would be able to give you more precise answers. Maybe you can start checking out their web pages for additional info. 

Later edit: my answer was just a bit more than a cut-and-paste from my comment and I realize that something more should be said concerning the heart of the question which, as I understand it, is: would it be possible to develop the theory of $\mathsf{NP}$-completeness without Turing machines? I agree with Kaveh's comment: the answer is yes, but perhaps only restrospectively. That is, when it comes to complexity (counting time and space), Turing machines are unbeatable in simplicity, the cost model is self-evident for time and almost self-evident for space. In the $\lambda$-calculus, things are far less evident: time cost models as those mentioned by Andrej and given in Harper's book are from the mid-90s, space cost models are still almost non-existing (I am aware of essentially one work published in 2008). So, of course we can do everything using the purely functional perspective, but it is hard to imagine an alternative universe in which Hartmanis and Stearns define complexity classes using $\lambda$-terms and, 30 to 50 years later, people start adapting their work to Turing machines. Then, as Kaveh points out, there is the "social" aspect: people were convinced that $\mathsf{NP}$-completeness is important because Cook proved that a problem considered to be central in a widely studied field (theorem proving) is $\mathsf{NP}$-complete (or, in more modern terminology, using Karp reductions, $\mathsf{coNP}$-complete). Although the above shows that this may be done in the $\lambda$-calculus, maybe it would not be the most immediate thing to do (I have my reserves on this point but let's not make this post too long). Last but not least, it is worth observing that, even in my work mentioned above, when I show that HO CIRCUIT SAT may be reduced to CIRCUIT SAT, I do not explicitly show a $\lambda$-term computing the reduction and prove that it always normalizes in a polynomial number of leftmost reduction steps; I just show that there is an algorithm which, intuitively, may be implemented in polynomial time, just like any complexity theorist would not explicitly build a Turing machine and prove it polytime (which, let me say it, would be even crazier than writing down a $\lambda$-term, let alone check for mistakes). This phenomenon is pervasive in logic and computability theory, complexity theory just inherits it: formal systems and models of computation are often used only to know that one can formalize intuitions; after that, intuition alone is almost always enough (as long as used carefully). So reasoning about the difficulty of solving problems like SAT, TAUT, SUBSET SUM, GI etc., and thus developing the theory of $\mathsf{NP}$-completeness, may largely be done independently of the underlying computational model, as long as a reasonable cost model is found. The $\lambda$-calculus, Turing machines or Brainfuck programs, it doesn't really matter if you know that your intuitions are sound. Turing machines gave an immediate, workable answer, and people didn't (and still do not) feel the need to go further. 

Call $\mathsf{PPBP}$ the class of languages decided by poly-size families of permutation branching programs, which are layered branching programs (i.e., the ones defined here) whose transitions functions are permutations (without any restriction on the width). We know from Barrington's famous result and from the fact that arbitrary poly-size branching programs capture exactly logspace that $$\mathsf{NC}^1\subseteq\mathsf{PPBP}\subseteq\mathsf{L}/\mathsf{poly}.$$ In the closing section of his 1989 paper, Barrington briefly considers this question and observes that $\mathsf{PPBP}$ is known to contain $\mathsf{L}$-complete problems under $\mathsf{NC}^1$ reductions. This suggests that the first inclusion above is strict but fails to yield a characterization of $\mathsf{PPBP}$ in terms of a well-known class, because it is not known whether $\mathsf{PPBP}$ is closed under $\mathsf{NC}^1$ reductions (right?). Has any improvement on understanding the power of permutation branching programs been made since Barrington's work? 

I am not aware of any implementation of Lamping's algorithm directly in the interaction combinators. I do know that the presence of integer labels is a necessary feature of Lamping's algorithm, even for EAL-typable terms, because the labels reflect the nesting of so-called exponential boxes in proof nets, and Lamping's algorithm is essentially the execution of proof nets using the geometry of interaction, as first observed by Gonthier, Abadi and Lévy. So the question of implementing the algorithm in the interaction combinators boils down to representing exponential boxes in proof nets using the combinators. This is essentially what Mackie and Pinto did in their paper. Of course, Mackie and Pinto's encoding adresses all $\lambda$-terms, which use full linear logic boxes, whereas EAL-typable terms use elementary linear logic boxes, which are simpler (they are so-called functorial boxes). However, I do not believe that this simplification would have a notable impact on interaction combinator implementations. This is because boxes are a global feature (they identify arbitrarily big subnets to be duplicated/erased), whereas the interaction combinators (as any interaction net system) are completely local (reduction only modifies bounded subnets), so the challenge is to represent such global features locally. Now, global duplication/erasing in EAL is identical as in full linear logic, that is why I do not expect that an interaction combinator implementation of EAL would radically differ from the one proposed by Mackie and Pinto. 

You seem to be confusing several things here. First of all, like Alexis said in her answer, I don't see why you would need to accept/reject the principles of a given logical theory in order to study it and learn about it. The fact that your theory is intuitionistic doesn't mean that your meta-theory has to be! You may freely use proof by contradiction or the axiom of choice in order to prove results about the $\lambda$-calculus (people do that all the time). Second: you seem to be interested in the $\lambda$-calculus as a programming langage, which means you can safely ignore (at least on a first approach) its connections to intuitionistic logic. You may have heard about the Curry-Howard correspondence and the fact that the $\lambda$-calculus and type theory are deeply connected, which is great, but is not necessarily the preferred route from your point of view. Blurring the distinction between functional programming and proof theory is wonderful but, in your case, it seems to have generated more confusion than anything. Third: if the stochastic $\pi$-calculus is what you are really interested into, then perhaps you should first look into standard process calculi, starting from CCS (arguably the simplest) and the related machinery (bisimulations, etc.) and then moving on to the $\pi$-calculus. In fact, I think you may even skip the $\lambda$-calculus entirely; at any rate, there is no need to look into intuitionistic logic at all. (Personally, I know some experts of probabilistic concurrency who only have a superficial understanding of the $\lambda$-calculus). Fourth: if you really are into Curry-Howard, then be reassured that functional programming is not at odds with classical logic: proof by contradiction has a well-known correspondence in programming languages. Googling "computational content of classical logic" should get you started on that. But I wouldn't look into that unless you first make sure you got rid of the confusion you have between the $\lambda$-calculus as a programming language and its relationship with proof theory (that is, until you have understood what Curry-Howard is about), lest you get even more confused.