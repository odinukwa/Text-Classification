I keep most of my home directory's dot files under revision control, so that I can easily move changes between any of the five or so desktop machines and dozens of servers that I use. Unfortunately, my directory is a bit of a pain when it comes to this, because gconfd seems to really like making arbitrary whitespace changes and, worse yet, updating the attributes on entries that it hasn't changed. Has anybody any thoughts on good ways to deal with this? I would prefer never to have to commit whitespace changes or time changes when a value hasn't changed, so that I can easily track my diffs over time. 

Linux Journal has a reasonable amount of sysadmin-oriented coverage, though not as much as they used to. And occasionally they do a sysadmin feature issue. Linux Magazine had more, but they're now web-only. 

As others have mentioned, having a route doesn't necessarily mean you have connectivity. If that's what you're looking to test, offers the option to scan to see if a port is open: 

If you're running a clustered application, you've got lots of options beyond Ethernet, but you'll need to figure out what characteristics will best suit your application. Often you'll need to make a trade-off between low latency of communications and high bandwidth. In extreme situations, you may want to look at spending more money to use a smaller number of higher-powered nodes to reduce latency to memory-access rather network-access levels. And, of course, you should take a look at your application to see if there are ways of rewriting it to work better with the technologies out there. Wikipedia offers a handy list of network technologies and nominal bandwidths that you can use to start off your research. It gives nominal speed (the actual throughput you'll get will be lower) and doesn't discuss latency. Note that if you're not using the latest and greatest servers, you need first to look at what you've got available in terms of internal buses. You can certainly put a 10GigE card on a 64-bit 66 MHz PCI bus and run faster than with a GigE card, but you're not going to get anywhere near the network's nominal rate of 1 GB/sec or so because the bus can only do about 500 MB/sec. As far as whether you should "use a routing switch stop Ethernet clashes," if you're talking about using a switch instead of a hub, these days that's pretty much automatic. Hubs are darn hard to find, in fact. However, not all switches are created equal; one that might handle two hosts transferring at 100 Gbps may not handle six doing the same. 

As shown above, in multiport scan mode the exit code will be true (0) if any of the ports succeeded in connecting, or false otherwise. There are several different versions of ; the one used in the examples above is the package from Debian 9, which is a rewrite of the "traditional" netcat ( package). For these particular parameters and exit codes the traditional version is substantially similar. If you are having problems with netcat command line parameters and exit codes, check which version you're using; may give some insight. 

I'd like to avoid any discussion of either of the above points here. If you want to find out more about the glibc maintainers' policy, or if you don't understand the attacks to which you are opening yourself when you don't follow our security policy, post a separate question, e-mail me with its URL of it, and I will link to it from here. 

Hosts with a BIOS that works over the serial port, USB serial adapters and Paul Vixie's rtty (packaged as remote-tty in Ubuntu and Debian) logging continuously. The primary advantage of this system is that when a server spews a huge amount of information out to the console and then wedges or reboots, you have a complete log of what happened, as well as what anybody was typing on the console up to that point. 

I've found that is a useful program to get key codes when making rules for . Also, note that Alt_R is a modifer key; you will have to use the "remove" command to make it a non-modifier key before you can use a "keycode" or "keysym" command on it. 

I have an entry from an OpenSSH file; I'd like to generate an SSHFP resource record for this. I can use to generate the fingerprint with no difficulty: 

Barry Brown, in a comment on the question, provides a clue to a possible answer. The packaging system uses the program to start the server after the package is installed.[1] This program will run to determine the policy on starting that server. The package includes the script, which either runs with its parameters if present, and exits with that script's error code, or exits with 0 (success) otherwise. The interface is expected to offer is documented briefly in the manage, and much more extensively in . The next step, I suppose, is for me to test this. Things remaining to be answered: [1] What other parts of the system use ? [2] Does this actually work? 

is Linux-specific, but you can also use the command (available on any Unix) to check the speed and other characteristics of any tty. operates on its standard input, so will give you the information about that particular tty. Alternatively, if you're in a situation where you cannot set the standard input of , you can use the option. 

I currently examine only the real differences by using a diff program that ignores the mtime and whitespace changes: 

The solution is to use the adjtimex package to let your kernel know how much time really elapses during each kernel tick. If it's idea is different from reality, the system clock will run more quickly or more slowly. I quote from Making NTP Work on Hardware with Large Clock Drift: 

That still leaves me with a web server with password-based access control (I can see no way to have it validate client certificates) and who knows what remote vulnerabilities. Turning it off when I'm not using it (which is most of the time) seems like a reasonable solution; adding a crontab entry to shut it down every five or ten minutes would catch those cases where someone forgets to shut it down when he's done. The ssh daemon is a version of dropbear that appears to be fairly heavily modified. It reads usernames and plaintext passwords from (which is also used by the web server), logs in any valid name and password as the root user, and ignores the file. This last problem is annoying; it forces you to allow password logins and opens the possibility of backdoors depending on from where-all it gets its names and passwords. So that's the dilemma you face: how much do you really trust this modified ssh daemon installed on a system that was fairly obviously designed by security-na√Øve developers? Not much at all, given the number of broken bits of cruft I've seen in their shell scripts. There are unusual naming conventions (/etc/rc?.d/sshd is a symlink to /etc/init.d/ssh), huge amount of code that appear to be unused, and features in just the ssh startup script, such as the file and even the command are entirely broken. (Don't try using these; sshd won't restart and you'll be screwed unless you have an existing login. We rebooted the BMC and ended up having to reflash it.) The best option I can think of, if one's going to use the thing at all, is to start ssh on an alternate port using a cron job, so at least it's less likely to appear in a portscan. The final component is the IPMI network management ports; I can't see how to turn these off. 

I have subversion use this by running . I revert files that have no significant changes. However, this is a bit awkward, and doesn't deal well with files where only one or two items have changed, but a dozen others have new timestamps, as all of those changes are still committed. 

I've got an AMD Athlon XP-2500+ host (Shuttle MN31 motherboard, nForce 2 IGP + MCP-T chipset) running 32-bit Ubuntu 9.10 (i686 2.6.31-20-generic kernel). Unfortunately, it appears that the clock drift on it is so bad (it advances close to an extra second every minute) that ntpd can't keep the machine in sync. How do I deal with this so I can get ntpd working? 

You can use the exit code to do something (or not) based on whether you have demonstrated connectivity to that address and port: 

Splice a UPS into power cable in order to keep the machine running continuously. Insert a pair of Ethernet bridges between the computer and the network termination point that will bridge the traffic over a wireless network of sufficient range that the host will maintain network connectivity. Open the box and use a probe on the memory bus to grab interesting stuff. Use TEMPEST devices to probe what the host is doing. Use legal means (such as a court order) to force me to disclose the data Etc. Etc. 

This feature is not going to be added to glibc any time soon. It's been missing for more than five years now, and nobody is showing any concern about it; rather, they're saying they feel that adding the feature is too dangerous due to the "high security impact" of the change, or some such thing. We have a strict policy that you may not connect via ssh to company machines whose keys are not verified (i.e., we use the "StrictHostKeyChecking yes" ssh option). 

To do this properly, what you really want to do is collect the host public keys of the VMs as you create them and drop them into a file in format. You can then use the , pointing to that file, to ensure that you're connecting to the host you believe you should be connecting to. How you do this depends on how you're setting up the virtual machines, however, but reading it off the virtual filesystem, if possible, or even getting the host to print the contents of during configuration may do the trick. That said, this may not be worthwhile, depending on what sort of environment you're working in and who your anticipated adversaries are. Doing a simple "store on first connect" (via a scan or simply during the first "real" connection) as described in several other answers above may be considerably easier and still provide some modicum of security. However, if you do this I strongly suggest you change the user known hosts file () to a file specific for this particular test installation; this will avoid polluting your personal known hosts file with test information and make it easy to clean up the now useless public keys when you delete your VMs. 

If you're running a Unix-like operating system, the probe messages a boot time will often enumerate everything on the PCI bus, and give you an indication of how it is arranged. Linux systems have an command that will do the same. If you need more bandwidth on your bus, you may want to look into getting a Supermicro server with UIO slots. Using an AOC-UG-14 would let you keep at least one 4-port gigabit Ethernet card off of the PCI bus. 2U hosts can have two UIO slots, plus I believe three additional PCI slots, which might well allow you to build a machine with 12 GigE ports working at full performance. 

My current hack is to run ntpdate once a minute from root's crontab. This moves the time back by just under a second every minute. I'm not very happy with this solution. However, it does demonstrate the consistency of the drift: 

SSH won't read the local configuration if it's on an NFS-mounted filesystem. This is worth checking because all the permissions can be just fine and SSH (at least version 6.6) won't give you any indication of why it's not reading the user config. (It will, however, read it from an NFS volume if you use the option.)