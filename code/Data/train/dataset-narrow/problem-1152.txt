This way, there is no way you or your end-user can mess up with the inputs. I hope you find this useful and it encourages you to write better code. 

some assumption checking with the use of variable names that are closer to the problem write-up (, , ) or more descriptive, e.g., the use of for finding if a number is divisible by or vectorization (notice how one of your loops is gone), which should make your code faster The use of instead of is more robust in the case when is zero. 

Next, from a performance point of view, you are wasting a good amount of time and memory by creating and storing a new vector at each iteration. Instead, you could keep the same initial vector and only pass around start and end indices: 

to pre-allocate a vector of integers. Integers use less memory; you will also save time avoiding unnecessary conversions from integer to character. Second, is for regular expression matching. When you do , you are checking if contains an which is not the same as asking if is exactly . In your case, you want exact equality so having used in would have been more appropriate. Even better, there is the function. It is vectorized so you can avoid the loop and just do: 

when defining your function, you meant to name the first argument , not . That was a bug. and are the kind of arguments that could use an optional value so I made it so. And once an argument has an optional value, it is recommended to move it to the end of the argument list, hence . I renamed to for 1) it is more descriptive and more likely to suggest that this is the annealing's temperature variable, but mostly 2) R provides as a shortcut for , although you can overwrite it like you just did here. This is a horrible feature of the R language and you should avoid using both for or as your own variable. is probably a more appropriate tool for logging. I also transformed the code so it prints one row per iteration. I hope you'll agree the log is much easier to look at this way. Keeping track of the best state is an improvement over the "vanilla" version simulated annealing process which only reports the current state at the last iteration. If you want it that way, then you need to use three states: best, current, neighbor. Which I implemented here. In addition to keeping track of the current state and best state, it is recommended to keep track of their function values, so you do not have to make unnecessary function calls to re-compute them at each iteration. Like the matlab function you referred to, it is preferable to return a list so you can provide more outputs than just the best state. Always, it is important to comment your code to make it easier to understand and maintain. 

Developed and successfully tested on Mono/OSX As far as i can see, yes there are some points where performance can be gained, but i would be intrested, if this is the real bottleneck. As the others before i believe the huge performance gains can be made in the database update code. But I'm ready to be profen wrong and so I would be verry interested in your performance mesurements! Output Snippet: 

I think this should do what you expected to do. Enqueue all Numbers greater than 20 if no number is in the queue of the thread. Please leave a comment if you wanted to do something else, i would be glad giving you the right examples. 

Hope i could help, please contact me if you have questions about my snippets or if you are interssted in my decisions. I would enjoy learning from you and also would be glad helping you! 

i would add a comment which explaines detailed what this regex is suppose to do. So if there is an Problem with the Regex everybody can check if the regex is doing it's job or if there is a problem in the expression. Throw an exception in your constructor, so the errormessage can be cought. Now the error Message is displayed in the frontcode. 

This would make it reusable and readable for other developers, and it reduces comments ;-) Currently you have many of them 

Instead of writing all the names in , you could get them from the file names. This would be particularly useful if you had many more employees: 

Now about performance, since you mentioned it. Know that and are vectorized functions so unless you are handling many millions of rows or doing some high frequency trading, you should be fine :-) Minor speed improvements might be made by replacing the with in-place replacements (), I let you decide if this is more readable: 

Last, stay away from for writing your output to a file. It is a really old function; the fact you have to provide as an input tells me it was designed with on-screen printing in mind. Instead, you could use to be consistent with your using of at the beginning of your script: 

I think you can simplify your code quite a bit if you compute all the summary metrics once for all in a single function. This way, you also avoid repetitive calls to read_excel: 

In the event that one or more of the distances is zero, the weight is now infinite, which is a bit undesirable. To handle that situation, we modify the weights to 0 or 1 for all rows that contain infinite values: 

is applied directly to rather than . The output is a matrix where each column is a -long sub-sequence of . takes advantage of R's recycling rules to compute, for each item in each sub-sequence, the signed distance to the corresponding element of . converts to absolute (unsigned) distances. summarizes each column into a single value: the total distance from for that sub-sequence. picks the minimum total distance across all candidates. 

Why does the Methods and return null? Wouldn't it be better to throw an exception, that you can signal that something went terribly wrong? In my opinion returning null is always bad for developers who are using your code, becaus they don't know what went wrong and what to change. At your example you are expecting CallMethodB to return an Object. So if nobody throws an exception everything has just worked fine, use the return value, if it is null let the nullReferenceException occur and enjoy writing well code. Removing Null checks would increase your readability and the reusablility of your code! 

hm there are quite a lot of wich don't do anything at all... if there would be a massive exception you would just continue with what you are doing... 

Try assiging values first to a named variable and then concating it, so its sustainable in the future like: 

Last but not least: try using "'" for strings, so its more readable and you make less errors by escaping not escaping closing, whatever 

Remove empty try-catch blocks and replace it with propper checks If in the lower section is null you wouldn't set Selected Property of Row due to the thrown exception before. In my code i want my exceptions to be seen or recorded by the system, so I can fix it. You don't know what else has gone wrong in that Method. Throw speaking exceptions so any user can change his input to fullfill the requirements of the application or can create a new bugtracking issue with the propper information. Try using local Variables instead of calling Properties over and over again. Current you are using 5 times. If the Propertycall takes about 0.5sec you are currently burning 2sec :-) Try redusing it where possible. It also gets more readable. 

There are certainly more things that can be done. One thing that comes to mind is to use the package instead of data.frames since you have such a large data. But please let us know first how much faster this code is. Maybe it won't be worth the extra effort. 

It is recommended you avoid variable names like and since they are very basic functions from R. Or you run the risk of shadowing them. and are not integers so using is a bit unpredictable. I feel it is better to use like I did, and with control over the grid density. I was not able to test my code because you did not mention the package name for so it is possible it will need some adjustment. In the future, please make sure to give us everything we need to run your code. 

I think exposes the input data.frame so you don't have to write over and over. For example, can become . To avoid writing twice, you can use instead of This is less about coding but I would warn about making hasty from some of your summary metrics. One example is the way you computed the overtime. If one person hardly ever does overtime but stays two extra hours every time, he or she would score better than a person who does one hour of overtime every day of the year. You might want to replace the definition of by so that days without overtime are now accounted for when computing the mean.