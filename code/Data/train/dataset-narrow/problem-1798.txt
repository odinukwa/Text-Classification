Have 53 TCP and UDP ports open in your firewall. Have DNS server listening on the right IP address (either on ANY interface or in your case 192.168.1.70) 

If you add DNS server role to your Windows 2012 server (Server Manager -> Local Server -> vpravo menu Manage -> Add roles and features -> Server roles -> DNS Server) and do not configure it at all, it will behave as cache DNS server - i.e. will get all unknown DNS info from the default machine's DNS server (e.g. 8.8.8.8). The only two things you need to care about are: 

From what you wrote, everything seems OK. nslookup is a "low level" program in a sense that it does not use the libraries that are used by other programs in the system in order to do DNS resolution. nslookup creates and sends raw DNS packets on its own and it also receives and analyzes raw DNS replies. If you want to check your settings, use ping command on the hostname. It does not matter if you blocked ICMP or not, ping command does DNS resolution using standard libraries (that use HOSTS file), so you will see in its output, if the resolution was done as you wanted or not. DNS resolution and using HOSTS file is not related to ICMP firewall settings, so do not worry about your inability to ping that server. 

It is hard to guess, but my would be a redirection, more specifically HTTP -> HTTPS redirection. In order to be it this case, there would need to be redirect from HTTP to HTTPS on your server and you possibly do not see those in your logs because you might have them at different place. So, the scenario would be that the client for some reason (some form somewhere misses right scheme) POSTs to HTTP, gets redirect code and navigates with GET to HTTPS. If this is not the case, it could be different redirection (like non-www to www prefix or alike). You should be see those in the logs, but you might miss them for some reason (filtering somehow based on HTTP code?). But this is not as likely as HTTP->HTTPS redirection. So, is this it or can you prove that this is not the case? 

I have a broken Ubuntu 14.04 server. Everything is OK except for apt-get, which for some reason thinks that it repeatedly fails to update mysql server package. The mysql server is updated and works perfectly, so I do not want apt-get to touch it. But every time I do anything that includes apt-get update and apt-get install (including installing completely unrelated packages), it always tries to finish the installation of mysql server. What I am looking for is to find the source of this information that tells apt-get that mysql server needs its attention. I would like to manually edit that source of information and tell apt-get that this package is all OK and it should not care about it anymore. Is this possible? Please note that I am not very interested in actually making apt-get to finish the mysql server update. This is because mysql server runs in production there and everytime apt-get tries to "fix it", it kills it and corrupts the database. If it is not possible to change that apt-get status about a package, would it be possible to somehow tell apt-get not to care about mysql server at all (i.e. to somehow exclude mysql server package from apt-get completely). 

I am considering switching to a new hosting provider and I would like to know if it is possible to achieve database (MySQL 5.6) migration without a huge downtime (= time to copy tens of GB of DB files from one hosting to other hosting). So, is it possible to configure the current live MySQL DB as master and the new machine as slave in some mode that the master would not wait with new data inserts or updates for slave to confirm, and the slave would slowly (i.e. would not consume too many resources of master DB machine) try to sync itself, i.e. it will take up to a whole day, or maybe a couple of days (full speed file copy would take cca 4 hours) to fully sync. Meanwhile I would setup the web server and other services on the new machine and then just switch DNS and switch slave to single master mode and disconnect the old machine. I expect (and I am OK with that) to lose some data during the actual DNS switch (some clients with old DNS record would access the old server and these changes would not replicate to the new machine), but for most visitors, this window would be 15 minutes or so. So, is something like this possible and somehow easy to do? Alternative is cca 4 hours of downtime, copy all files to new server and just start it, but I am not very happy with such a long downtime. I do not mind restarting DB service/daemon couple of times during this process in order to switch it to new configuration. I do not want to do this migration using dumps, when I have to resync tables manually. 

With many hosting companies, it is common that they do not manage their IPs reputation. This means that you can buy a new server and get a dedicated IP address which has a bad reputation because the previous customer of the same hosting was sending spam or had an infected machine. Delisting procedure is specific to each blacklist. A good summary is provided in this blog post How to Get Removed from Blacklists. In short, it really depends on the blacklist owner if and when you are going to be removed after you (or your ISP/hosting) request removal. Some blacklists are not even free to remove instantly. With every new IP we obtain with a new server, we always go with a check immediately and setup blacklist monitoring. If there are problems, we try to ask for removals and if it is not possible, we ask for different IP address. This prevents later surprises. Moreover, some email providers (Microsoft's services like Hotmail, Outlook; Yahoo, AOL) are known to be very strict and actually require a perfect reputation history of the sender in order to deliver all the emails. It happens often with these services, that you try to send email to an account there and it is discarded silently. 

My hosting is IPv4 only. My question is whether it is possible to allow IPv6 only clients to access my web (running Window Server 2012 R2). Is this possible using technologies like 6to4 or Teredo or something different that I can just install on my server + create AAAA DNS record and it will work? Or do these technologies require configuration on both ends, so that it won't just work even if setup properly on server side? Note that I do not mind performance impact due to any kind of tunneling. Subquestion: And vice versa - is it possible for my server to access other servers via IPv6 after some kind of configuration? 

I don't understand how to setup a failover for my quite simple scenario. I am building a service gateway for API. What I want to have is two servers hosted in different datacenters. And I simply want the user to be able to access the service even if one of the servers is down. There is no issue with DB sync, I only care about availability of the service. How do I do that while preventing the user to implement any kind of failover logic on their end? I want the user to be given a single domain or a single IP address and be able to access the service all the time using this single end point. What I do not understand is how this can be achieved. I know I can setup a network node that will forward the requests to the first or second server, depending on which of those two is currently online. However, I fail to see how this setup solved HA problem as we just introduced a single point of failure to the system - the forwarding node. So, if this node goes down, the service is unavailable. Could you please explain how to implement this in the real world? Is it possible to achieve this with reasonable cost (i.e. not more than a cost of hosting of the servers themselves). Edit: It has been suggested that different datacenters requirement is costly. So, feel free to provide suggestions for 2 servers within 1 datacenter. Edit 2: Feel free to mention what is a reasonable cost for the that setup. 

I am not sure where I make mistake. I have two almost identical Windows Servers 2012 R2 installations - servers A and B. One server A, I have setup a shared folder. I have verified that I can connect to this share folder from my Windows 10 using UNC path \\IP\Name. I can see files a folders, read them ... However, if I want to do the same from server B, it always fails. When I try "net use \\IP" or "net use \\IP\Name" on server B, where IP is address of A, I get: 

Update 3: I have setup a similar machine locally in VMware. In my local setup, instead of /dev/vda* I've got /dev/sda* and the disk size is 20 GB instead of 80 GB and the new space that I want to add is 30 GB instead of 80 GB, otherwise it is the same. I can see in GParted the very same situation, it behaves exactly the same as the real server, the /dev/sda5 can't be resized. Here are my attempts with fdisk: 

What I need is to extend /dev/vda5 from 80 to 160 GB without losing data. I would like to be sure that I can't do it wrong (this is also why I did not do any experiments on my own). So if someone knows how to do step-by-step, so that it can't get wrong, I would be very grateful. It is possible for me to run another tool too, but I guess that would be much more difficult. Update 1: I have tried system-config-lvm, but I am in the same position, here is the pic: 

So this is why I guess the real server would also fail here. Note that I have used "u" command twice, because it was already in "sectors" mode. 

You already have A record that says "mx.websolutions.com.ar" is "198.50.148.166", this is required for OVH VPS. So nothing to do here. This needs to be propagated well, so that OVH servers can see it that way (but you already have this, so just saying ...). Log in to your OVH manager Navigate to Web -> Platforms (left sidebar, in the middle of the screen) and select your VPS (something like vps123456.ovh.net) At the bottom you have IP Addresses - click IP tab (the second one) In the right bottom corner, click on Manage IP You should see the table of IP addresses with third column being called "Reverse" or "PTR" or something like that. Click the "-" in this column on the row with your IP address. Then enter your host name "mx.websolutions.com.ar" and click OK sign. Wait until propagated well (e.g. use dns propagation checker to check that or just wait long enough). You are done :) 

More likely than a server vulnerability exploitation, this looks like spoofing source address. One of the methods to deal with this (but not entirely mitigate), is to use SPF records. There are currently no SPF records for proactech.com domain. This means that the target mail servers can not verify whether an incoming message comes from your mail server (legitimate) or some other (not legitimate). If you install SPF records, the target systems (that are sending you bounce messages) that check validity of SPF records (and there are many of them today) will reject any incoming messages from servers that are not allowed by these SPF records and they will not try to deliver such messages. This means no bounces to you. You can also consider installing DKIM, which is another feature that can help you mitigate a part of the problem. I do think SPF is checked more widely than SPF, so the first thing to do is SPF, but if it is possible, also install DKIM, just to make sure you have done the best you could. 

Short answer: Yes Long answer: It depends entirely on how many clients do you expect each service to be handling. If you have an SQL server that is used by an application to its limits, so that it hardly catching up with its tasks, you do not want the machine to do other non-trivial tasks. But I guess you would be aware of this if this was the case, so most likely, in your specific case, there will not be any problem to use it for all the services you have mention. DNS servers are quite efficient, so unless you are going to serve public requests for very famous domains, you should be just fine. SQL servers need most of the resources usually. It depends on applications that use them. From your list, it is SQL server that you have to be careful with. Mail servers are rarely demanding on resources, so again, unless you expect to be processing hundreds of thousands of emails daily, feel free ti include. DHCP server - no problems here either. 

After trying several different machines I have realized that my hosting is OVH and they block outgoing connections to ports 139 and 445 If this is also your case, use IPv6, they do not block it and it works. If you are having problems with new Cloud 2016 VPS - they do not have IPv6 at all, use $URL$ to get IPv6 connectivity. 

UDP does not have connections, they are just packets that on their own has no relation between each other. However, what you can do to simulate network failure is to configure a firewall rule that will enable / disable the traffic over UDP protocol. You can configure which ports will be affected as well as which hosts will be affected, so this is exactly what you want to do. If you are not sure how to add a firewall rule: Run "firewall.cpl" and click Advanced Settings and add your rule. Or visit e.g. this page with step by step instructions on how to add a rule: $URL$ 

Here I can see the /dev/sda2 (local virtual machine) even starts on the same sector as /dev/vda2 (real server). Same for /dev/sda5 and /dev/vda5. 

For local (without entry in global DNS) web, use HOSTS file entry to translate domain1.com and domain2.com to 192.168.1.9. 

I understand the question as follows: 1) You have bought a domain from Provider1. This is your domain registrar and you can manage your DNS record within their interface. 2) You have bought a website hosting from Provider2. This is a different company. 3) You want to connect your DNS record with your hosting so that if you type mysite.com into browser, you will see your pages loading. 4) You know IP address (let's assume it is 1.2.3.4) of the web hosting server with Provider2 and you have already created DNS A record that says mysite.com is 1.2.3.4. 5) It does not work. If this describes your situation well, then there are two things I can think of that can go wrong: A) You created the DNS record, but did not wait long enough for the record to be propagated world wide and the DNS server that you use for your address resolving, does not have this updated record yet. You can use DNS Propagation Checker to get information on how well is your DNS record propagated over the distributed network. You can also flush your local DNS cache to prevent your operating system local cache from giving you the old records. B) You have not inform Provider2 that your hosting program should accept requests for mysite.com. How to fix this depends entirely on your web hosting provider's interface. However, you can tell if this is the case if you put your address into the browser and different page than you expect (which is your web application page) is displayed to you. 

If two services are executed under the same account (whatever its name is) they have the same access to files on the disk. If you want to separate that, you are going to need to create new accounts. This is very common. For example, when I install FileZilla FTP Server on our Windows servers, I create new user for it. Similarly, when I install Apache web server, I create new user for it. Some software support it on its own, but with most third party software, you need to install it normally, then to stop its service and set it to run under the new user account you have created and start it again. This will provide you the separation you are looking for. It might seem that there is a lot of work to be done, but if you take your time and create your groups and their users smartly, it is not that bad.