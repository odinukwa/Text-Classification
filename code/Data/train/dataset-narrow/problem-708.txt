Full text search fits more into your scenario. A full text search uses inverted index - think of it as an index structure that stores words or number mapping to its location in database. There are good amount of changes in sql server 2012 for full text search. Check Full-Text Search (SQL Server) 

To enable verbose logging you must add two parameter values to the Run Agent step of the replication agent job for which you wish to review more detailed logging: 

Complementing to what @Chris suggested - You should use sql agent alert and choose to either email you or log to a local database e.g. dbautility or dbaadmin (whatever you choose the name). This script from Andy Mallon is a great resource. Also, you can use sp_whoisactive with parameter to show you details - I have mine set as this gist. You can even log that to a table. 

I would not rely on the scripts generated by SSMS as they are not 100% accurate. SSMS is not the right tool to generate changes for the database, though it has functionality to do it. Same functionality can be achieved using native or open source or third party tools . Native tools : 

You have to create a login on the prod server as when you restore the backup to PROD server, you are having an orphaned user. So steps are : 

The inbuild system SP are limited to what they can report or show. The best way is to create your own (use existing ones and build your own <-- make sure you give proper credit ! ) using DMVs. e.g. sp_who is way ancient vs sp_whoisactive is what you will install on your server to quickly findout whats going on with the server. Remove as it is deprecated. Instead you should use 

This is the default behavior to automatically resume mirroring when the mirror comes up (provided no errors encountered). It will be in suspended state if there is a REDO error. 

Yes but You will loose all the transactions that happened after the last good FULL backup since you dont have any transaction log backups to do a point-in-time restore. Best references : 

Transaction isolation level should be thought in terms of read operations. Isolation levels control how the read operations are protected from the other write operations. The database engine governs the locking behavior of all write operations, and you cannot change that behavior at the database level. From BOL : 

SSMS behind the scenes uses to populate the data in the Properties page . Note that the SSMS properties page does not give info about filegroup backup. It only gives info about full, diff or log backup. You can use this script to retrieve SQL Server database backup history and no backups details 

I have implemented T-Rep where I have used same server as publisher and distributor as the data that was needed to replicate was less and also, have implemented separate distribution database on separate server that does all the heavy lifting of publishing the data to subscribers where we had massive data to push down to subscribers. You have to consider factors like - 

In the import wizard, you can delete the rows first and if you have identity fields, then you can enable identity insert on as below 

You can look into approach like incremental load using SSIS from staging to PROD database. You can apply different techniques when loading the data as well. 

Looking at your RAM availablity for this particular server and you are running several databases ranging from 30GB to 5 GB, you definitely need more RAM on this server. You have not mentioned that this is a stand alone instance or this server is having more than one instance of sql server running. Your MAX Memory settings seems OK for a server having 8GB RAM. See these suggested best practice settings from Glenn Berry. I would highly recommend you to do a baseline of your environment using below PERFMON counters to get a good value of your memory configuration : 

You cannot get such metrics using T-SQL. You can check the replication status using T-SQL though. Depending of how large/big your publication database is (for small databases in same network, you should not even look at the time/size as it will be super fast), you can follow below steps to get a ROUGH estimate (ball park figure) of the size and time of snapshot to get generated and apply at the subscriber : Note: I put emphasis on Rough estimate as depending on what you are replicating e.g. store procedures, indexes, constraints, etc there will be additional files generated as well. 

We have recently implemented TDE along with AlwaysON in Production running SQL Server 2014. In our application, we noticed a slight (1-3%) increase in CPU utilization. Your environment is different, so do a thorough load testing with some realistic PROD datasize. Takeaways from embracing TDE : 

Also, you should monitor Wait Statistics on the server especially SOS_SCHEDULER_YIELD resulting in scheduler contention on Servers having multiple CPUs running concurrent Bulk load operations and competing for the same CPU Cycles. Refer to this excellent whitepaper The Data Loading Performance Guide which have everything that I mentioned with diagrams and examples. Also, to automate the sliding window technique - creating staging tables, loading data into it and then switching the partitions, you can fully automate it using SQL Server Partition Management -- it has command line option as well -- available at CodePlex. 

This is because any database you create with full recovery model is always in pseudo simple recovery mode until you take a full database backup and this is where a log backup chain can be establish successfully. You can easily check if a database is in pseudo simple recovery mode using ** --> check for field with value of . This means that the log chain has not been established. Paul Randal has a TSQL script and Edwin Sarmiento has a PowerShell script that will tell you if a database is in pseudo simple recovery or not. You can use the scripts from above links to first check if the database is in pseudo simple recovery and if the database is then execute a full backup else run diffs or log backups. 

I would suggest to use Native SQL Server client. SQL Server Native Client is one technology that you can use to access data in a SQL Server database. From : When to Use SQL Server Native Client 

You can use server side trace (different from using Profiler GUI that incurs more resources) during your testing or your business cycle and capture only stuff related to SP's. Then you can load that in a table or excel for further analysis. Second approach, is to use DMV sys.dm_exec_procedure_stats (with limitation that if sql server is restarted, then the data is flushed). You can even schedule a job to capture DMV data to a table to keep it persisted. 

If the table is large, then BCP is the best choice. Below script will bcp out the data in a flat file + you have to flexiblity of converting it to a stored procedure or schedule it using sql agent job as well. 

ExpressProfiler available at CodePlex Or You can install developer Edition and then use profiler to trace the sql statements. Use Trace Flag 4032 that will log all the sql from all clients to the errorlog. 

There is no easy way to STOP trace when certain no. of files are reached. Instead you can delete the older one and keep the no. of files in the limit that you defined using parameter. Refer BOL - sp_trace_create - You have to use = along with -- specifies 

No, SQL Server service accounts can be different. We have a 3 node cluster running AlwaysON and on all the servers SQL Server is running with a different account. e.g. If you have one server in NY and other in LD, then 

Since the secondary in a log-shipping configuration is either or , you cannot make changes to the database (i.e. create a USER) until a ROLE CHANGE happens (i.e. when you failover from primary to secondary). You can create a LOGIN on the secondary server. You can use this script - How to transfer logins and passwords between instances of SQL Server to script logins - both SQL and Windows. If you are using SQL Server 2014, then you can just create a ROLE and then grant that role and . This works on readonly databases in logshipping configuration as well. Note that above is not that elegant if you keep security in mind, but still is an alternative that can be considered. 

You have to read the manual to find out or you can do a stress test using SQLIO or SQLIOSim. Brent has a good article on : SQLIO Tutorial: How to Test Disk Performance To see if underlying storage is a problem, you can use . It will show you where the hot-spots are and you can ask your SAN admin to move them away. 

State 58 occurs when SQL Server is set to use Windows Authentication only, and a client attempts to log in using SQL Authentication. You have to Change Server Authentication Mode and restart sql server, if you/your software requires SQL Server authentication and your sql server is configured for Windows Authentication. 

This way, UserA is not able to see SchemaB's tables, but still can execute procs from SchemaB. Below will explain the permission hierarchy : 

Recycle error logs using with a SQL Agent job. If you need more than 99 days of log (since you mentioned in your comment - ), you can use PowerShell to move the files to a safe location. I would doubt that you would need error logs past 99 days ! Just make sure that you keep them in a manageable size, else you it would be difficult for log viewer to open very large files. 

Apart from what Shawan referenced, another option is to use DAC then issue below command (note that I am not using NO_WAIT) 

If high CPU utilization is a frequent symptom on your server due to FullText, then highly suggest you to look into Improve the Performance of Full-Text Indexes A good practice would be to baseline your server instance. 

Whenever you do large updates/inserts to you tables, highly recommend to update stats and reorg/rebuild indexes. That way query optimizer does not select or produce bad plans on wrong estimates. 

Giving an analogy with Excel is comparing apples and oranges. Why ? Excel is not a database as it lacks data integrity. Excel is a pretty nice spreadsheet application and might be a complement to database. SQL Server is a relational database system which allows you to store all your data and provides a mechanism to query it. The important part is "Relational" as data relationship is important along with data integrity (ACID properties). Basics : The data in the database is organized into logical components (tables, views, procs, triggers,etc) that is visible to user. At minimum, a database is also physically implemented as two (data & log file) or more (secondary data file) files on disk. 

I dont see anything wrong in your setup. To be fair, this is the correct way of setting up SSIS in a clustered environment. Read up SSIS and clustering: What you should do instead Also for the login failure, its worth to check the Windows Server 2008 R2's firewall rules to allow an inbound rule for either the msdtssrvr.exe executable or the DCOM port SSIS listens on. 

Note: Express edition of the same sql server version is supported. Edit: based on the comment from @Raidri Technically it is possible to have a witness with a higher version of sql server than the 2 partners, but it is highly recommend and supported that all servers have the same VERSION of sql server running - edition can be different. 

As a side note, its more important to test your restore strategy as a backup is ONLY GOOD if it can be restored without any issues. Enabling Instant File Initialization will considerably cut down the restore time. Be careful when you are striping your backups as there are chances that a stripe might get corrupted or might become missing (deleted) due to machine or human error :-) References : 

Restore-DbaDatabase does have as parameter. Suggest you to download the latest version of dbatools and try it. Alternatively, you can try ps_restoregene - which is powershell based script written by Paul brewer. (I have used it and its a life saver :-) ) 

You can use DMV (in 2005 and up) - to find the pages in the buffer pool. Also, there are Memory Manager surface area changes in SQL Server 2012. KB 2663912 : 

There are benefits to indexing foreign keys as they provide better join performance as described by SQLSkill's team here and here. 

Yes - if you are planning to keep all the 3 replicas in sync. No - if you are planning to upgrade with minimal downtime. Make sure to sync sql agent jobs, logins, etc since they are not automatically synced. 

UDP 1434 is used for Named SQL Server instances and SQL Browser service listens on this port for any incoming requests to a named sql server instance. The browser service will respond to the client with TCP port no. for the requested named instance. From BOL : 

Backup from PROD and restore it on DEV server is the best option. Make sure to enable Instant File initialization to cut down the restore time. Edit: 

If you installed SQL Server then you will be having "" - if mixed mode authentication is enabled. You can use "" account to create a login and map that login to a database. Alternatively, you can use "" (if you have enabled it as a part of post installation step). By default, has access to sql server 2008 instance. If you are part of group then you will have access. Last resort : Recover access to a SQL Server instance by Aaron Bertrand wherein he shows how to use to get into sql server.