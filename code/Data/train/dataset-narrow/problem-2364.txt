The logics are expressively the same, though past operators make LTL exponentially more succinct. You can start here, from which there are references. 

Does anyone know of a similar program anywhere? Are there suggestions for concrete/general topics which you think can and should be taught in addition/instead of the topics above, while keeping the program interesting as well as important and directly relevant (e.g. group theory is important and interesting, but not relevant enough to justify the time it will take) I would have been happy to introduce machine-learning in some form, as it is a really hot topic nowadays. Any ideas as to how machine learning can be presented without tools like measure-concentration theorems are welcome. 

This may be related to network formation games - games in which players try to find a path in a network, and collaborating along a path reduces the cost for both players (i.e. the cost is shared) This paper may be of help. 

This question should (and will) probably be migrated to cs.se. In the meantime, consider the computation tree of the depicted structure: in almost all paths, $p$ is seen only finitely often, making the premise of $GFp\to GFq$ false, so the formula is satisfied there. However, there is one path, namely $s_0^\omega$, in which $GFp$ does hold, but in this path $GFq$ does not hold. We conclude that there exists a path on which the formula doesn't hold, so it is not the case that it is satisfied on every path. Thus, the formula is not satisfied in this structure. 

Note that by "equivalent" we mean that they represent the same (perhaps partial) function $f:\Sigma^*\to \mathbb{N}$. Some side-notes: 

Take a look at this MFCS 2013 paper, which studies compositionality in automata. Perhaps it will help. 

In general, CTL model checking is P-complete. Since we think that $L\neq P$ (and moreover $NL\neq P$), it is unlikely that an algorithm with logarithmic space exists. It is also unlikely that a sub-polynomial space algorithm exists, for similar reasons of common belief. I don't know of exact space-optimizations for the problem, but in general - yes, you need to mark each state with a formula, so naively you need the size you suggest. It may be the case that you can reduce the formula by encoding it more succinctly, but it hasn't attracted attention in research. You can start from this survey for citations. 

Karp has an algorithm that does exactly that. You can read about it in his paper "A characterization of the minimum cycle mean in a digraph." There seem to be other algorithms proposed here which are perhaps easier to read. 

Clearly the union of NSAs can be taken without any blowup - just use the nondeterministic union of the initial states. As for determinization, you'll have a double-exponential blowup. Consider the language $L_k=(a+b)^*a(a+b)^k$. That is, the $k$-th before last letter is $a$. You can easily construct an NSA of size $O(\log k)$ for it, but any DSA would need to "remember" the last $k-1$ letters (the same argument that works for DFAs would work here). So a DSA would need $2^{k-1}$ states, which is a double exponential blowup. As for union of DSAs, this is more of a conjecture: consider the language $L_p=(a^p)^*$ for a prime number $p$. This can be recognized by a DSA with 2 states and $p-1$ written on one of the transitions. Now, consider the union $L_p\cup L_q$ for $p\neq q$. It seems to me that you'll need a lot of states (i.e. $p\cdot q$) in order to recognize this with a DSA. But I haven't thought this through completely. 

A set of numbers $S=\{x_1,...,x_n\}$ is said to be algebraically dependent if there exists a (multivariate) polynomial $p$ with coefficients in $\mathbb Q$ whose roots contain $x_1,...,x_n$ (or a subset thereof). 

Consider a language $L$ which is hard for some class $C$ (e.g. PSPACE-hard). Trivially, $L$ is also $D$-hard for every class $D\subseteq C$ under the same type of reduction (e.g. NP-hard). Is there a natural/interesting example of a problem that is known to be $C$ hard, but that the proof of $D$ hardness is significantly different? For example, $TQBF$ is PSPACE-hard, but proving $NP$-hardness is trivial (by reduction from $SAT$), but I wouldn't consider this example very interesting, as $TQBF$ is a generalization of $SAT$. I am looking for a problem whose natural formulation is e.g. PSPACE hard, but one can show NP-hardness in a different way. I'm not sure how interesting this question is, but I am curios to see such examples. 

It is known that adding bounded-error randomization to PSPACE doesn't add power. That is, BPPSAPCE=PSPACE. It is famously unknown whether P=BPP, but it is known that $BPP\subseteq \Sigma_2\cap \Pi_2$. Thus, it is possible (while conjectured to be false) that adding probability to P adds expressive power. My question is whether we know (or have evidence of) the border between P and PSPACE where adding randomization no longer adds power. Specifically, 

Note that by "equivalent", we actually need to interpret LTL over trees. Thus, we say that a CTL formula $\phi$ is equivalent to an LTL formula $\psi$, if $\phi$ is equivalent to the CTL* formula $A\psi$. Thus, we essentially compare LTL and CTL in the common grounds of CTL*. Given this, it's not hard to construct a procedure to check the equivalent. Simply check whether the formula $\phi \iff A\psi$ is a tautology in CTL*. This can be done in 2EXPTIME. However, since satisfiability of CTL is only EXPTIME complete, it might be possible to reduce this to EXPTIME (but I haven't given it much thought). 

I tend to think this is undecidable: Let $x$ be a computable irrational number. Consider a TM $M$. You can construct a function that runs $M$ on $\epsilon$, and in parallel computes $x$ with growing precision. If $M$ halts, it stops computing $x$, otherwise it continues. Deciding if this function computes a rational number is equivalent to the halting problem. 

Not exactly what you asked, but Scott Aaronson has a paper, nicely explained here about Turing machines with the ability to time travel, but with self-consistency requirements (i.e. you can't go back to change the past. You can observe the future, but it must be consistent with the present). 

As you can see, they are not topologically equivalent. Hence, the minimization problem is harder than the finite case, and in fact, it is NP-complete. 

In your question, the phrase "the TM" is not well defined. Let's assume you meant that the language is decidable in $O(n)$. If this is the case, the problem is undecidable. Here is a reduction from the halting problem. Given a TM $M$, construct the following enumerator: it outputs $0$, then, in iteration $i$, it runs $M$ on $\epsilon$ for $i$ steps, and prints $0^i$ afterwords, and then increases $i$ by $1$. If at any point $M$ halts, it outputs the strings $0^i$ for all $i\ge 0$, one by one. Now, even deciding whether there is a finite bound between words is equivalent to deciding if $M$ halts. Indeed, if $M$ halts, then its runtime is the bound on consecutive words. Otherwise, there is no bound. However, the language is always the same: $0^*$, which is decidable in Linear time. 

Another famous example of using game theory is in CS is synthesis: in synthesis we get a specification over inputs I and outputs O (e.g. in temporal logic, or as an automaton), and we want to automatically generate a system (i.e. a finite-state transducer), that guarantees that for every input sequence of the environment, the computation induced by the transducer satisfies the specification. As it turns out, synthesis can be formulated as a game between the environment and the system, where a winning strategy for the system corresponds to a transducer. A very important tool from game theory that is used in this context is Borel-determinancy, especially when we work over infinite computations. You can start reading about this in Moshe Vardi's survey. 

While this is somewhat opinion-based, I think the voting platform in our community is an excellent way to rank the beauty of proofs. 

Regarding your first question - safety properties are, in a way, the "easiest" properties to handle, with respect to problems such as model-checking and synthesis. The basic reason for this is that in the automata-theoretic approach to formal methods, reasoning about safety properties reduces to reasoning about finite traces, which is easier than the standard infinite-trace setting. See the work of Orna Kupferman here as a starting point. 

Finite Automata: DFA, NFA, determinization, Myhill-Nerode, etc. Turing Machines: computability (RE,R, mapping-reductions, undecidability results). Complexity classes: P, NP, PSPACE, karp-reductions, Savitch's theorem, Time/Space Hierarchy theorems. 

Now comes the question of what to do next (usually we have about 3 weeks left). Option 1: NL, coNL, logspace reductions and the Immerman Zzelepcs√©nyi theorem. Option 2: Randomized complexity (RP, BPP), but in a very low level, since probability is not a prerequisite for the course. Option 3: Communication complexity - describing a communication model with some very initial results, describing IP and trying to prove $IP=PSPACE$, but usually only getting up to $coNP\subseteq IP$. Option 4: Kolmogorov complexity. (we haven't tried this one yet). Other options are welcome. The question, to be as precise as possible, is as follows: Assuming that at least 50% of the undergrads are not interested in theory, and that most of them will not continue to grad school, what would be most fitting, so as to teach interesting material (i.e. less definitions, more theorems), while keeping it somewhat relevant to other disciplines in CS (or, heaven-forbids, the industry)? My personal answer: I think that NL is a good option - theoretically it is interesting since we have some impressive results (NL=coNL), and practically it is interesting since many exponential time algorithms can be composed with NL algorithms to produce PSPACE algorithms (e.g. NFA universality). On the other hand, one might argue that it is more important to get acquainted with randomized algorithms. 

A min-plus weighted automaton (WFA) is a nondeterministic automaton with a weight function that assigns each transition a weight in $\mathbb{N}$. The weights along a run are summed, and the value of a word is the value of the minimal accepting run of the automaton on it. In a beautiful paper, Kirsten and Lombardy show that deciding unambiguity and sequentiality (i.e. determinizability) for WFAs is decidable for polynomially ambiguous WFA (the general case has been open for years). Working on related problems, I am trying to tackle the following: 

I was offered to teach a novel TCS high school program, which requires constructing a curriculum. I would very much like to hear opinions and suggestions regarding this. First, does anyone know of high schools where a TCS program has been taught successfully (or unsuccessfully)? The idea is for a 3-year program (10th-12th grades, ages 16-18), about 8 weekly hours, for selected outstanding students, meaning that it can and should be demanding. Unlike the standard "computers" program, this program should not focus on programming, but rather on selected topics in CS, mostly in TCS. The topics we have in mind so far are, broadly: 

As we all know, satisfiability of Boolean circuits is NP-complete. I am wondering if there are any studies of circuits with infinite inputs? That is, suppose the input is from the set $\{0,1\}^\omega$ (countable sequences of $0,1$). Another model I am interested in is arithmetic circuits, specifically with the gates $\min\{x,y\},1-x$, and $\frac12 x+\frac12 y$, with inputs in $[0,1]^\omega$. The first observation is that if the circuits are finite with bounded fan-in, then this is equivalent to the model with finite inputs. So we must consider infinite circuits, or at least infinite fan-in. Clearly, the satisfiability problem in general will be undecidable, since we can encode the behavior of a TM with an infinite circuit. However, there are circuit classes for which the problem is interesting. For example, we can require our gates to represent the temporal operators of $LTL$ (where we have a finite depth circuit with infinite fan-in), which makes the satisfiability problem PSPACE complete Are there other known models with interesting results? 

For an NFA $A$ with $n$ states and a word $w$, we can associate an $n$-dimensional vector $v_w$ with entries in $\mathbb{N}\cup\{0\}$ denoting the number of copies of the NFA in each state after reading $w$. For standard NFAs, this vector doesn't have much meaning, only it's support does (e.g. for the subset construction). However, when considering certain cumulative properties of NFAs, this vector is meaningful (see example at the end of the post). It would make sense that in an NFA, the behavior of the possible reachable vectors will be fairly "regular". Or at least have some nice properties. 

The statement $\langle M,i\rangle\models \varphi$ for all $i\in \mathbb{N}$ is equivalent to $\langle M,0\rangle\models G\varphi$. Thus, you can check the latter. 

Unanimity and transitivity do no imply IIA. For example, consider the Borda-count voting mechanism. There is an example of the violation of IIA here. 

SPOILER ALERT: Since you ask this in TCS, I assume you want the answer and not hints. If you don't want the full answer, don't continue reading... One example of such automata is as follows. The first, $A_1$, consists of two states $q,s$, where $L(q)=a$ and $L(s)=\neg a$ ($L$ being the labeling function). $q$ has a transition to $q$ and to $s$, and $s$ has only a self loop. The second,$A_2$ consists of 4 states $q_1,...,q_4$ with the following transitions: $$q_1\to q_2\vee q_3$$ $$q_2\to q_2$$ $$q_3\to q_3\vee q_4$$ $$q_4\to q_4$$ And the labels are: $L(q_1)=L(q_2)=L(q_3)=a$ and $L(q_4)=\neg a$. It is easy to see that the traces of both automata are exactly $a^\omega \cup a^*\cdot a\cdot (\neg a)^\omega$, but path $q_1,q_2^\omega$ makes it so that $A_2\not\models \phi$, whereas $A_1\models \phi$. By the way, you can remove $q_3$ from $A_2$, but I find it clearer this way. 

Turning my comment to an answer: The problem you describe is known as Not All Equal SAT (NAE-SAT), but is phrased differently. A NAE assignment for a CNF-formula $\phi$ over variables is one where in each clause there is at least one false variable and one true variable. It is easy to see that an assignment is NAE iff its inverse is also NAE. Showing that NAE-SAT is NP-complete is a well-known exercise, and it can be easily solved by splitting it to two parts. First, given a 3-CNF formula, we can convert it to a 4-CNF formula by adding a variable $w$ and converting every clause of the form $(x\vee y\vee z)$ to $(x\vee y\vee z\vee w)$. It is easy to see that the original formula is satisfiable iff the resulting formula is in NAE-SAT. Then, standard techniques can be used to convert this formula back to 3-CNF, while maintaining the NAE property. 

In general, $\omega$-regular languages may not have a unique minimal DBW. For example, the language "infinitely many a's and infinitely many b's" has two 3-state DBWs (in the picture replace $\neg a$ by $b$): 

Basically, this covers the TCS part of the first two years of a B.Sc in CS. However, we must keep in mind that these students lack the mathematical foundation needed for most of this material. In particular, things like set theory, combinatorics, probability, and modular artihmetic are not taught in high school (unfortunately). To sum up, and to give precise questions: 

A good starting point for practical LTL examples is LILY, as well as the PROSYD project. They provide some examples for LTL formulas, both "toy examples" and real-life applications. I think the website for the Prosyd project is a bit dead. By the way, your interpretation of the formula $P\to \Diamond Q$ is not exactly correct. First of all, it is not a state-formula, even if you consider it as a CTL^* formula and not an LTL formula. It's evaluation is over a path, and a path satisfies it iff if P holds in the first state of the path, then eventually Q also holds.