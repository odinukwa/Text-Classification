This problem is NP-hard as 3DM (3-dimensional matching problem) reduces to it. Just pick M=N=3, Y to be the points of the underlying base set, and X to be the triples on them. 

I am not sure if these results are known. If you define the $t$-thick upper (or lower, does not matter) shadow of $A_k$ as the sets of one level higher (resp. lower) that contain (resp. are contained in) at least $t$ sets from $A_k$, then what you ask for is the $(k+1)/2$-thick upper shadow. As far as I know it is open to determine the size of the smallest $A_k$ whose $2$-thick shadow is empty. Unfortunately I cannot point you to a reference but I think I heard it from Katona. (And in case I am wrong, then I remember incorrectly...) 

If the polygon into which you want to pack is not necessarily convex, then I think the problem becomes NP-hard. Here is a very sketchy proof. The reduction is from some Planar-3-SAT type problem. To each variable you can have a 1.1 x 1 place, depending where in this area you place one square will determine whether your variable is true of false. Also, if you leave .1 area left/right, then you can move two other squares a little more inside, and also the ones behind them, eventually giving another .1 free space somewhere else that together now affect four squares and so on. After you have as many copies as the occurrences of the respective literal, you connect these tubes to the respective clause component and there again use some similar gadget to ensure that from the three ingoing tubes at least one has to have a .1 extra space. 

By the work of Klivans and van Melkebeek (which relativizes), if E = DTIME($2^{O(n)}$) does not have circuits with PP gates of size $2^{o(n)}$ then PH is in PP. The contrapositive says that if PH is not in PP then E has subexponential-size circuits with PP gates. That is consistent with the fact that an oracle proof of PH not in PP gives a relativized lower bound for PP. No reason to think it implies any upper bound for PP, or any strength for circuits without PP gates. 

The proof of Ladner's theorem doesn't use any special properties of P and NP and the same proof unchanged will show, assuming EXP<>PSPACE, there is a language L in EXP-PSPACE and not EXP-complete under either P-time or PSPACE-reductions. You need the full Landner look-back trick to keep L in EXP. 

$S^p_2$ and $PP$ are both known not to have $n^k$-circuits for any fixed k and there is no known containment between them. Details in my blog post. Update: As Rickey Demer points out, these results do not necessarily give a language with a lower bound for all $n$ in $S_2^p$. I think the $\Delta^p_3$ is probably the best known. Since $PP$ has complete sets you might be able to get a all $n$ bound but I don't have a full proof. 

No, for any NP-incomplete set A there is another set B strictly between A and SAT. These equivalence classes are known as polynomial-many-one degrees. You can embed any finite poset into the degrees below NP. In particular the degrees are not totally ordered or finitely branching. This all depends on what you mean by "interesting". There is a huge theory of the degree structure of the computable sets (see Soare's book for instance) and many of those questions have not been ported down to polynomial-time sets. For instance, can you have NP sets A and B whose join is equivalent to SAT and whose meet is equivalent to the empty set? 

Edit 5th of Jan: In fact the One Heap Game described below is a special case of the problem, i.e. when the numbers follow each other in a specific way such that the first group is bigger than the second group which is bigger than the third etc. and the numbers in each group are increasing. E.g. 8, 9, 4, 5, 6, 7, 2, 3, 1 is such a permutation. So I propose to solve this special case first. Disclaimer: I no longer claim that the below proof is correct, see e.g. the comment of Tsuyoshi which shows that deleting a number from a permutation will give a diagram not obtainable by deleting a square from the diagram of the permutation. I left the answer here to show that this approach does not work, plus since it contains another simple game. The game has a very simple other formulation thanks to Young Tableaux. I am sure that it can be analyzed from there as other games and it will yield a linear time algorithm. First define the following game on Young Diagrams: At each turn, if the current diagram is horizontal (all squares in one line), the current player loses and the other player wins; otherwise, the current player removes one of the bottom-right squares, and play passes to the other player. Now order the sequence of numbers into a Young Tableaux. The main claim is that the winner of the original game is the same as the winner as the diagram game starting with this shape. To see this, notice that whenever the players delete a number, the diagram of the new sequence can be achieved by deleting a bottom-right square of the diagram. Moreover, any such diagram can be achieved by deleting the number from the respective bottom-right square. These statements follow from standard Young Tableaux theory. Although this diagram game is simple enough, it is trivially equivalent to the following game, which seems more standard: One Heap Game: The players are given some heaps with some pebbles in each. At each turn, if their is only one heap left, the current player loses and the other player wins; otherwise, the current player removes a pebble from a heap, and play passes to the other player. If there is a simple solution to the heap game (and I strongly believe there is one) we also get a solution to the original game: Just put the sequence in a Young Tableaux, and transform its diagram into heaps. Unfortunately I do not see which heap positions are winning/how to determine the Spragueâ€“Grundy values. I checked a few cases by hand, and the following are the losing positions with at most 6 pebbles: one heap; (1,1,1); (2,2); (3,1,1); (2,1,1,1); (1,1,1,1,1); (4,2); (3,3); (2,2,2). Anyone can solve this game? Edit: Peter Shor can, see his answer! 

Even if you have a one-player game there is no computable equilibrium. Consider nature putting probability $1/2^i$ on program $i$. Any computable strategy will achieve some value strictly less than one or you could use it to solve the halting problem. But you can achieve any value less than one by the strategy that for some fixed sufficiently large $t$, simulates nature's program $j$ for $t$ steps and outputs the number of steps it takes program $j$ to halt if $j$ halts in $t$ steps, infinity otherwise. 

This problem came out of my recent blog post, suppose you are given a TSP tour, is it co-NP-complete to determine if it is a minimal one? More precisely is the following problem NP-complete: Instance: Given a complete graph G with edges weighted with positive integers and a simple cycle C that visits all the nodes of G. Question: Is there a simple cycle D that visits all the nodes of G such that the total weight of all the edges of D in G is strictly less than the total weight of all the edges of C in G? 

OptP-complete. Krentel showed that MAX-SAT, finding the lexicographically maximum satisfying assignment, is OptP-complete and the reduction above reduces Max-SAT to ILP. ILP sits in OptP pretty much by definition. Note that you need n calls to an NP-oracle to solve ILP via binary search, O(log n) isn't sufficient. There really isn't much of a connection to UP, though Mulmuley, Vazirani and Vazirani give an isolation lemma that gives an alternate proof of Valiant-Vazirani via a maximization problem. 

As far as I know, this is still open. A very recent paper that mentions these quantities and some bounds is Aaronson et al: Weak parity (see $URL$ You can also see chapter 14 of Jukna: Boolean funcions and the 1999 (still beats 1998!) survey by Buhrman and de Wolf. Another very recent paper about randomized decision tree complexity is Magniez et al: $URL$ Finally, a short summary I made for myself last month (without defs): R2<=R0<=D<=n D<=N0*N1<=C^2<=R0^2 s<=bs<=C<=s*bs<=bs^2 (new: [Gilmer-Saks-Srinivasan]: there is f s.t. bs^2(f)=O(C(f))) D<=N1*bs<=bs^3<=(3R2)^3 deg<=D<=bs*deg<=deg^3 (new: [Tal]: bs<=deg^2) D<=N1*deg C<=bs*deg^2<=deg^4 Sensitivity conjecture is that s is also polynomially related to other parameters. 

It is well-known that it is NP-complete to decide whether in a 2-CNF at least s clauses are satisfiable. It also follows from the reduction from 3-SAT-3 that we can suppose that every literal occurs in at most k clauses of the 2-CNF for some constant k. Can someone give me a good bound on k? Can we suppose that every variable occurs at most twice negated or at most twice unnegated? 

If I understand your question correctly, by path you mean that we build up a tree starting from s by always taking an edge adjacent to our current tree. This problem is NP-complete, the reduction is from SAT. The main part of the graph will consist of n cycles of length four attached to each other at vertices s=v0, v1, v2, .., vn. So from s we have two paths of length two to v1, from v1 two paths to v2 and so on. From vn there will be a path of length N+1 to t. We will have only enough weights to use one of each pair of paths and depending on which path we use, the value of the variable xi will be true or false. The weight in s is N+2n, where N is some big number. Each clause is represented by an additional vertex that is connected by a path of length N to the center vertex of the path that corresponds to its literals and it has value N+epsilon (I know we need integers, but we can multiply up and replace each edge by 1/epsilon edges), where 1/epsilon is the number of clauses. So we have to visit every clause-vertex to get to t.