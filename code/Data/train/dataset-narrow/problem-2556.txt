Catmull-Rom splines (a type of cubic hermite spline) can be quite useful, if you've got a set of points that you want to create a smooth path between (without defining any additional control points), such as camera paths For all the maths, see: $URL$ If you're using D3DX, there's some handy functions for dealing with them (D3DXVec3CatmullRom) 

If you are replaying recorded inputs, consider the implications of any moving/destructible/interactive objects in the world, which may have moved or changed state when the actions are replayed Also, replaying inputs will not work precisely if your game uses a variable timestep. You may want to consider a fixed-timestep game update (with interpolation for variable framerate rendering)? 

I like using virtual coordinates, but based around a common target resolution (preferably one of the highest resolutions that you expect the game to be run at. These days, a good choice may be 1920x1080. All artwork and screen mock-ups can be created at that resolution, and it makes it easy to measure positions/distances in pixels. If running at a different aspect ratio to the virtual coordinates, you can choose how to fit it to the screen (letterboxing, cropping the sides, or a bit of both) When coding, I find 'thinking in pixels' much easier than thinking in normalised coordinates! - I want the text to be '50 (virtual) pixels in height' rather than '0.0463 units high' 

If you haven't already read it, I'd recommend reading this, gives some ideas of how non-tile-based 2D can be done very effectively: $URL$ You could also take a look at the Aquaria source code, and see if its editor is adaptable to your needs (that used a mix of tiles and arbitrary object placement) I've been working on a non-tile-based editor myself (screenshots: $URL$ , $URL$ but it's still very much a work-in-progress. 

It's a while since I played Worms, but from what I remember - when the rope wraps around things, there's only one (straight) section of rope that's moving at any one time. The rest of the rope becomes static So there's very little actual physics involved. The active section can be modelled as a single stiff spring with a mass on the end The interesting bit will be the logic for splitting/joining inactive sections of the rope to/from the active section. I'd imagine there'd be 2 main operations: 'Split' - The rope has intersected something. Split it at the intersection into an inactive section and the new, shorter, active section 'Join' - The active rope has moved into a position where the nearest intersection no longer exists (this may just be a simple angle/dot product test?). Rejoin 2 sections, creating a new, longer, active section In a scene constructed from 2D polygons, all split points should be at a vertex on the collision mesh. Collision detection may simplify down to something along the lines of 'If the rope passes over a vertex on this update, split/join the rope at that vertex? 

What kind of game is it? Is it possible to keep the 2 simulations entirely in sync? If you start the 2 instances of the simulation in exactly the same state, and update with a fixed timestep, then they should remain synchronized. But when you do anything to a physics object, you send a message to all clients telling them what to do and on which frame. So if you were making something like 'Worms' or 'Angry Birds', and the player launched a projectile on frame 1000, you'd send a message saying 'on frame 1000+N' we're going to spawn a physics object with these parameters. Of course, this will add input lag. And you need some way to ensure that no player will get too far ahead to respond to messages on the correct frame. Maybe a 5-10Hz 'clock' message, telling all clients 'you may advance your simulation to frame N, but no further'. (I believe that this is how online RTS games work, where it would not be practical to send the positions and states of several hundred units every update, and where a fraction of a second's lag between giving an order and the unit executing it is acceptable) 

For a small indie developer, with limited funds/time (and maybe more of a focus on 'making something cool' than 'making something profitable'), trying to go cross-platform from the start could be counterproductive. It takes a lot of effort to engineer solid cross platform tools and tech (different graphics APIs, endianness, input devices, and more) - time that could be spent on the more creative side of game development. But you probably want to make sure you've got a great game that works really well on one platform before worrying too much about getting it onto as many platforms as possible! If the game is a flop, there's no point wasting time and effort making it a multi-platform flop, is there? If you're coding in C/C++, mostly from scratch, then as long as you keep the code fairly modular and make sensible decisions about data formats and middleware/libraries, then supporting other platforms later shouldn't be too painful. If third-party cross-platform tech/tools (e.g. Unity) is an option for your project, then it's certainly worth considering. The main 'problem platforms' for indies would seem to be Xbox360 Indie Games (C# only, limited network access, etc), and possibly Android (massive differences in device performance/screen size/input devices). If you're determined to support these, expect a more sizable porting job, or plan to focus on them exclusively. 

This is a trivial problem if you are able/willing to link strips with degenerate triangles - as most stripping algorithms do anyway. Each Nx1 row of squares is a very simple triangle strip. For each row, you want to start a new strip. Simply duplicate the last vertex of strip 1 and the first vertex of strip 2, and that will create a degenerate polygon linking the two strips (However, if as your question indicates, the vertices are not shared between the squares - different colours/UVs etc, then you don't want to use strips) 

Adding an answer myself - as I ended up using this: $URL$ - rather than attempting an implementation from scratch. So far it's doing the job quite nicely, and it was very easy to use (with C#) Wikipedia has links to a fair bit of information on the subject, once I started searching using the right terminology: $URL$ 

Small teams guaranteed. It's the number one way to keep game dev fun, and bring out the real passion and team spirit required to make great games. A fair employment contract that does not try to steal ideas/code I come up with outside of work, or contain any nasty non-compete clauses. When the pressure is on, weekends and holidays will be sacred. None of the 'no holidays between pre-alpha and submission' BS Guarantee of a decent spec development PC with two 24" monitors or better (surprising now much old hardware, particularly monitors, is still in use at big studios) Management that know the abilities of their staff well - their strengths/weaknesses/skills/specializations - and don't just treat them as 'Programming resource X' A place that supports multi-talented developers. Artists that can do design/scripting, Coders that do a bit of audio work, etc - rather than 'you're a coder, your input about the art style is not welcome' Understanding that 'you can't make a baby in 1 month by using 9 pregnant women' 

As pointed out in the other replies, multi-pass rendering (drawing a single mesh multiple times with different shaders/parameters), as suggested in other replies, is definitely still used, primarily for lighting and special effects D3DX Effect passes could be used for this kind of thing. But it could also be implemented with more than one shader/effect. The original intention of passes was to help with implementing complex shaders on lower-end (pre-shader-2.0) hardware, where the restrictions on the number of texture stages and shader instructions per pass were quite limiting. In the example of multi-pass lighting, are there any significant performance gains to be had by using passes instead of switching effects? 

It's just a buffer that controls which pixels can be modified when polygons are rendered. For each pixel, there's a corresponding stencil value, and pixels can be conditionally modified/ignored depending on these values At it's simplest, it can be used like a physical stencil - a mask that allows some pixels through, and stops other pixels being modified. It is very similar in behaviour to a z-buffer - like depth testing, stencil testing is a true/false test, and there are similar settings to control the stencil test (pass if greater/less/equal). But instead of writing a depth to it, it will usually have pre-defined values written to it, or be incremented/decremented when pixels are drawn, as used in stencil shadow algorithms.