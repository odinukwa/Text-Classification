Or would an index on only suffice? It's quite a large table so I don't want to spend time adding the index if it is unlikely to help. 

Try running on the slave to make sure it has got the you think it does. If not you can run and make sure it is set up in the file for when you restart the database. Also check the error logs as there may be additional info in there that can help. 

In other words, get the value for all entries per minute for the past hour. However, in some cases I don't have an entry for some minutes, but I still need to know that there were 0 results for that minute. Is there a way of achieving this in MySQL? so I might get something like: 

So I'm thinking that this means I am creating a lock called that will remain in place until either I release it, or 10 seconds has passed. If I then open another session (simulating a second application), and try to run it just returns a . No matter how long I leave it, the lock remains in place. I would presume the full process would be something like: 

values so that the two Databases don't generate overlapping primary keys. $URL$ After that on your Slave DB (B), simply run . Use those details to issue the statement on DB A. What you should find is that anything executed on A is then replicated to B and vice versa. However anything executed on A shouldn't be replicated back from B to A. And as such, the only queries written back to A will be those that are executed directly on B. Finally, you will want to set B to read_only to prevent anyone accidentally writing to it, until such time as you want them to. 

I've installed 2 instances of SQL Server 2008 R2 onto our local windows server. For the purposes of testing I've turned off the firewall. I'll get the firewall back up after I manage a successfull remote connection. The server isnt exposed anyway. TCP\IP is turned on for both instances. The default port is assigned to the Default instance and that one is working fine. I've assigned 4143 to the named instance but I'm still unable to connect remotely. I can connect remotely to the default instance just not the named instance. What step or steps am I missing? 

My Boss requires that we keep up to date scripts of all database objects in svn. This results in constantly trying to find the object in the current script and copy and pasting the changes. Is there an easy way to set sql server to script database objects and write them to a file on the drive? If not then I've built the following sql script as a test run for creating a tables file but I'm not sure how to capture the output string that sp_executesql is creating. 

My company is changing from a distributed Access Database model to using a centralized SQL Database. The datatables were designed such that all of the tables have a modified date. In discussion it was suggested that since we will be creating a trigger on each table to handle the modified date perhaps we should have the trigger also log some information to an audit table. Is this the best way to setup auditing so that we can track who is changing information or is there a better way? Links to articles on the subject are welcome. For the audit I'm looking at capturing the table name, column name, date modified, row id and the username of the person making the change. Is there any information I'm not thinking of that I should be capturing that might help me avoid future pit falls? 

This may be a daft question, but on the MySQL release notes, a lot of them are followed by BUG Reference numbers. But most of these BUGS don't exist when you search for them at bugs.mysql.com. example: Bug #13651665 Despite my best efforts I can't find out where to find these BUGS. Can anyone point me at the right location? 

I have recently set up some new MySQL Databases on a remote site. They are all 5.5.47, running on Debian Servers. They are set up as one Master with multiple slaves. The Master is itself a slave from our main site. But periodically replication on one of them (never the same one, and only one at a time) gets stuck. The servers at my main site which have been running for years, are fine. The config of the servers at the new site is identical to the main site. The servers (VM's) are the same as the main site. I can see the relay logs continuing to increase in size, but the Exec_Master_Log_Pos value just sits there. The error logs are of no use as I have due to our website generating hundreds of every second. Everything else continues to work fine, until I execute a command which just hangs. After that all other related queries (, etc. also just hang.) I've tried killing the connections / queries, but it makes no difference with each of them sitting there saying 'killed', but not completing. I've checked disk space, and that is always fine. I can log in to MySQL via the terminal and run basic commands (until I run ). I have compared everything I can think of to the other servers, but there is never any difference. If I try and shutdown the database (), it hangs at Finally I resort to killing the mysqld_safe process (), which forces it to restart, and goes into crash receovery. After that it seems to be fine. Is there anything else I can check to try and find out what is happening. 

I need to create an alert that will notify me when any query has been blocked for more than 60 seconds. For example if someone has a transaction open on a table and forgets to run a commit or a rollback. Is this possible to get from the system tables? 

There were also several queries with a status of running but none of these had been running for a significant amount of time. SQL Server threw no alerts during the time frame and nothing looked out of the ordinary in the logs. There were also no alerts for Blocking processes at this time. Finally the decision was made to fail over the SQL Server cluster. This cleared up the issue. I've exhausted the places I can think of to look to come up with an explanation for the outage. Has anyone experienced similar behavior? Is there something I should be checking that I haven't mentioned? 

To use the CustomApp credentials, the user adventure-works\tengiz0 executes the following statement. 

Car rental now stores the relationship between the client and the car that they rented and for each record stores the datein and dateout. If you dont want to script all of this out you can use the table designer to create the table by right clicking on tables and then choosing new table. You can use the database diagram to drag and drop columns in order to create your foreign key relationships by right clicking database diagrams and chosing New Database diagram. If you use this structure then You would leave the DateIn field as NULL untill the car was returned. Your query to find out which clients and cars have not been returned would be 

will fail as has been set as the default database. Whereas under Row Based Replication it should be fine as it looks at the database that is changed rather than the default. $URL$ However, with all DDL statements are replicated as Statements. $URL$ 

If I understand correctly, you are trying to copy the new Database (database4) onto a slave that already has 3 databases replicating (these are all on the same MySQL Database). The problem then is that replication will need to be paused whilst you do this. The process I would use would be: 1) MASTER - restart the master with new | remove all in order to start populating the binary log with database4's data 2) SLAVE - Check the slave Database's replication is up to date ( > ). If not wait till it is 3) MASTER - To stop new data entering the master 4) SLAVE - Check replication is fully caught up and no data is replicating ( and should be the same and not changing (in )) 5) SLAVE - to stop any data replicating into the database once you unlock the master shortly. 6) Run with option 7) Once MySQLDUMP has started running unlock the master Database In this way your systems can continue reading and writing to the master, hopefully keeping downtime to a minimum n.b. that MySQLDUMP may lock the database4 schema while it works depending on your system 8) Once MySQLDUMP has completed, import it into the slave Database 9) check the newly imported database4 looks correct 10) Restart the slave Database, adding to the my.cnf file as you go Once it comes back on, it should continue replicating from where it left off, but including database4. 

The server needed to be added to the LMHosts file so that SQL Server could resolve the path to the directory that the Transaction logs were being saved to. 

ok. It looks like you have 4 tables here with nothing to join them together. Perhaps the easiest solution at this point would be to create a mapping table called something like CarRental which would have the columns Carpoolid, cilentsid, dateinid, and dteoutid. I think the way I would go would be to drop the datein and dateout table and put them on a table called car rental. 

To revert back to the adventure-works\tengiz0 credentials, the user executes the following statement. 

SQL SERVER 2008 R2 When attempting to connect to the default instance of sqlserver on our local server from SSMS on my desktop I'm receiving the following error. 

I have several access databases that I'm copying over to the sql server, connecting to as a linked server, and then pulling data from each night. I need to be able to identify if the current access db the linked server is pointing too has a particular column. If not I'll need to create the column before copying the next access db over. Is it possible to check if an access column exists through a linked server connection? 

Our database Server is being hosted by another company. They provide a file level backup that occurs once per day. They also allow for Log Shipping. My company is taking advantage of their Logshipping option as a major part of their backup and recovery solution. I would like to have a better backup system that would allow us to restore data up to the point in time of failure. Typicly this would be full backkup model for the database and backups of the transaction logs as well as the full and incrimentals. However, the vendor has told me that providing us with transaction log backups would cause issues with the Log Shipping. Is there a backup strategy that will allow me to restore to the point of failure and also use logshipping? 

Am I missing something here. I'm looking at using to allow two applications to co-ordinate which data to wok on. From reading the manual it suggests that I need to apply a timeout to the command. e.g. 

Is there some trick to getting the Visual Explain feature to work in MySQL Workbench? I am running version 6.3.6 on Windows 7. I've tried simple queries with just one join. I've tried it with complex queries with 12 Joins. I've tried it with MySQL 5.5 and 5.7. But every time I just get I've looked on the Bugs for MySQL Workbench > Visual Explain, but there is no recent bugs, making me think it is something I am doing. But I can't see what. Does anyone have some suggestions? 

Do you use statement based or row based logging? If it is statement based then you most likely have set in your replication filters e.g. so that only queries where the database is are written to your binary log. e.g. 

In the end, I renamed the entry in , and then I was able to install it. Once I checked it was OK I then removed the entry in . So far it seems to be working fine, 

Following further testing it seems my problem wont be performance, but simply creating the table, as that many BLOB fields exceeds the maximum row size, and so I can't even create the table!! I got to about 47 fields before it gave up. 

I'm receiving the data 1558.39999999999 However, investigation of the data shows that all data points only go out to two decimal places. In this case it should be impossible to receive the number above. using another query: 

We are migrating our SSRS reports server database from SQL SERVER 2008 R2 to SQL SERVER 2014 and as I understand it this means all SSRS reports will receive a new id. Hence any SSIS packages that reference a report would break. Is there a way to identify all SSIS packages that make reference to SSRS reports? 

I'm not certain about the service broker que but it is possible to setup a user without a login. This user will not be able to authenticate but you can still assign the user rights. The examples below are from the microsoft article for createing users $URL$ D. Creating and using a user without a login The following example creates a database user CustomApp that does not map to a SQL Server login. The example then grants a user adventure-works\tengiz0 permission to impersonate the CustomApp user. 

Once these views had been created we could pull the column listing from sys.columns joined over to sys.views. 

In this case you dont need to update the records for people who havent returned a car. You only update the record to contain the date when they have returned the car. 

But as far as I can see the 'referenced table' is The 'referenced column' is , and is the so automatically has a index, right? I checked the documentation, and as far as I can see I meet all the criteria: 

I'm trying to install the Percona Audit_log plugin for my instance of MySQL. I ran it previously so I know it works ok with MySQL (I'm sure it says so in the documentation anyway). I have MySQL 5.5.47, so I downloaded the files for Percona server 5.5.47-37.7 and extracted the file. I put that file into my plugin directory on the server (debian), but when I try to install it I get: 

1) Any , , etc type Query executed on the Master will be written to the Binary log, causing the to increase Furthermore, if the Master is receiving updates from another Master (in a Master to Master setup), AND if you have enabled these will be written to the Binary Log as well. Each time you restart the service, the Binary Log will be flushed, incrementing it by 1. 2) On the Slave, Run , and make a note of the . Now check, does this file exist on the Master still? If it doesn't then you have a problem, and will need to rebuild the slave from a copy of the master (e.g. MYSQLDUMP) Assuming it does exist you should be able to just issue a command, and it will start catching up (hopefully) Next run again and check the and . Are they both then all is good. Look for the to give you an idea of how far behind it is. If either of them is look at the Error ( or ) to get an idea of what the problem is.