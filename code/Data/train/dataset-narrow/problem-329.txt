TCP is bidirectional. There are actually two halves of a pipe created between client and server; think of this as being a full-duplex operation in that both sides of the conversation can send and receive simultaneously. But before any real communication can take place, the client needs to initiate a connection to the server first with a TCP SYNchronize (flag) packet and the server is expected to respond with a TCP SYN toward the client with a piggybacked ACK, and finally the client ACKs the server TCP SYN. This is the TCP SYN-SYN/ACK-ACK 3-way handshake. Packets are then free to flow in either direction until the connection is torn down. 

In both cases, the onus is on the client to initiate the action. The size of the pool of addresses in the DHCP scope, the lease duration, and the churn of clients must be considered so that all addresses are not exhausted. Reservations should also be considered because those addresses will never be available for the general subnet population. In the event that the client is unable to reach the DHCP server to renew its lease, the client may end up obtaining a different lease from another DHCP server. The initial server that held the client lease will continue to do so until the lease expires. 

One way that won't be well-received is to provide a locked-down proxy inside your network and block all inside-out tcp/80 traffic except for that proxy. Your clients won't get web access unless they go through your proxy. If the outside proxy they're using is on some other port, you're probably covered already if you don't have the inside implicit any/any allowed rule. Squid comes to mind as one proxy you could use. Other considerations should go to ASA-X series firewalls with CX and possibly NBAR on your router. 

Your server is obviously reachable over the Internet without VPN as evident by you receiving a username/password prompt over SSH. I can only speculate that the "Access Denied" resulted from whatever authentication method is employed that checked your source IP address and refused to grant entry from a public IP. Had you been on VPN, assuming either split-tunnel or full-tunnel mode forced your access to that server through your company's internal network or back out through the Internet from a known location, the authentication would have permitted what was now seen as the source address belonging to your company, not where you sat [publically] on the Internet. 

tl;dr: the true client's source IP address is usually known via the IP packet delivered to the web server. However, in the case of source NAT (sNAT) or HTTP proxies between client and server, the true client IP will not be in the packet the server sees. The x-forwarded-for (XFF) header should contain the client's real IP when HTTP intermediaries are involved as the IP seen by the web server is the proxy's IP. With sNAT, true client IP is lost unless the device doing the sNAT creates/rewrites a HTTP header like XFF discussed earlier or another custom header to contain it. 

This Q. is really confirmation to what I already suspect. On a single physical interface with a carrier that uses two dot1q logical sub interfaces to handle DIA and L3VPN, I suspect any usage of DIA for data from branch offices (BOs) instead of backhauling renders QoS for voice (SIP and RTP) packets over L3VPN moot when it's needed. Although I can mark voice packets for QoS over VPN, DIA traffic competes with that without DSCP so the physical circuit can be saturated and priority not given to voice. And since the congestion is already at the doorstep, not much can be done. Are these assumptions true? Would it be better to just backhaul data over VPN so end-to-end QoS is unaffected as long as sufficient branch office bandwidth exists? BO DIA could still exist as a backup. What other viable and proven options exist to this classic problem? All BO sites are part of full mesh MPLS-VPN and were required to have DIA before voice came into picture. Hosted VoIP provider can tie into this VPN or use SIP trunks from HQ. Provider is recommending uncompressed codec that eats up 90Kbps over compressed one at 30Kbps. 

From a networking perspective, the app that requires access only from your reverse proxy should ideally be running on a system (internal subnet/vlan) not accessible from the Internet directly. In fact, my preference would be to have all the apps behind the load balancer so that there is no direct path to the servers. If the app is tied to the code base used for all apps, you might be able to duplicate all the apps on an internal system that effectively only runs the SSO site (since it only receives those requests from the reverse proxy) and somehow render the SSO-site on the directly accessible system useless. Another viable solution is to have an ACL on the site so that only the load-balancer can make requests to the app. A solution not viable from a security POV would be to have public and private subnets mixed on your web host for handling your two use-cases. 

From a Cat6K, RP crashinfo indicates parity error. Guidance seems to be to not do anything unless this happens more than once in 12-month period. At what point do you push Cisco for hardware or RAM replacement? 

In other words, residential broadband is off-limits. Business or enterprise grade Direct Internet Access (DIA) is the direction you need to seek out. Consider carrier ethernet services delivered over twisted-pair (*Base-T), coax (T3), or fiber (1000Base-X) that provide symmetrical bandwidth and better service level agreements (SLAs). 

You often hear the terms Subnet and VLAN used interchangeably. With the ubiquitous nature of IP these days, when are the two not considered roughly the same from a high-level, understanding that VLANs are L2 and Subnets are L3. In other words, are there any cases for having a VLAN without a Subnet, and still have IP (L3) communication? [Also ignoring that all networks are not subnets when considering classful networks which all are really just CIDR prefixes these days.] 

During the DHCP BOUND state where the client has already obtained an IP address from the server, no further communication will occur between client and server until either... 

Also took exceedingly long to failover from active SUP720-PFC3B to hot standby -- 18 minutes -- w/SSO. **From my research, it appears long failover time could be due to crashdumps, but I don't see coredumps configured. And without crashdumps, wouldn't root-cause be difficult if not impossible. Cisco's states the following for failover time. Without coredumps configured -- no type commands -- why would SSO take so long (18 min)? I was completely down during this period; even my HSRP VIPs that were active seemed to have stay alive on a dead SUP instead of moving to another Cat6K; need more log analysis to know fo sure. 

Only the interface's primary address is sent in the DHCPDiscover packet as the gateway IP address (giaddr) field of the DHCP packet. You could look into using subinterfaces that allow separate DHCP relay agents (ip helper-address). 

In an one-armed SLB configuration, SNAT is used to force return-traffic to pass through the SLB. This has one negative: simply that web logs cannot capture the true client IP unless passed in XFF (X-Forwarded-For) header and the web server is able to log. An alternative is to use PBR (policy based routing) to get the return-traffic back to the SLB, but I try to avoid PBR unless there's no other/better solution On the 6500E platform with SUP720/PFC3B -- and I know the particular IOS version can be a factor too -- does PBR add any latency over doing SNAT assuming PBR is all done in hardware? If PBR is done in hardware using only the commands supported by it today, is it possible upgrading IOS in the future could change PBR to be done in software/process-switched? Today, our load-balancers have most of the web server VLANs directly behind them -- default g/w pointing to SLB -- and other servers like SQL in non-SLB VLANs. However, this web-sql traffic transits the SLB. Our goal would be to avoid crossing the SLB and just keeping SQL traffic separate, and still retaining the true client in web logs. I'd prefer to not introduce troubleshooting complexity with PBR and possibly having this change from hardware to software processed in the future. Short of the XFF and SNAT mentioned earlier, is PBR the only option here and what's the best way to keep PBR tightly configured? 

A recent question from Craig Constantine pertained to IPv6, but many people are not on the leading edge with IPv6 yet and are still responsible for new or improved IPv4 deployments. I would like to validate my own enterprise IPv4 address space planning against any public documents or guidance given directly here. Addressing has some unique needs between the DC and Campus that would ideally be considered. I'm specifically looking to see what best practices exist for planning out private (RFC1918) IP space assignments for regions, cities, campus, buildings, floors, uplinks, WAN links, loopbacks, etc. Wired vs wireless. Internal networks vs. guest networks. *I know this on its own can be a bit of an open-ended question, so I'm looking for specific references or examples to proven and well-thought out plans in a similar way as to the IPv6 answers. Suggested CIDR blocks would be helpful as the space gets allocated. Aggregation for routing, of course, is desired, and so is the ability to have simplified ACLs. There's a trade-off in ACLs on with the desire to aggregate all employee subnets, for example, whether wired or wireless vs aggregating all wireless users regardless if they are employees, contractors, or guests. 

As @Brett said, StackWise cables are required. Depending on what your goal is for the stack, you may be fine just creating an port-channel (Etherchannel) using up to 8x100Mb (800Mb) or 8x1Gb (8Gb) between 3750 switches. If you have certain 3750 models with 10/100Mb ports and 1000Mb uplinks, you could channelize up to 4 ports to get 4Gb. 

Reference: Configuring FlexConnect in Cisco Wireless LAN Controller Configuration Guide, Release 7.2 

Is there a way to interrupt the execution of this command short of closing the session as Ctrl-^x doesn't have any effect? 

Network stack offloading provides a mechanism for the NIC hardware to handle the partial or full stack. Broadcasts are CPU-interrupt wasteful without offloading as the stack needs to process the packet to determine the destination IP is not its own. With offloading, this can be done without involving the CPU. 

Judging by your switch, I'd say you don't have the budget for a real ethernet tester like those from Fluke Networks. Your switch is Layer 2 (L2) only and doesn't support routing, so you'd need an external router (L3) to move packets between the VLANs. I would conjecture that your random network issues were caused by either bad cabling or mismatch on speed/duplex between the switch and your systems. You can look at using iperf configured on a server, and then have each of your client computers run a test from their respective ports to the server (one at a time), then look for interface error counters being incremented to help isolate any issues or misconfiguration.