(I would also write as , but I think the compiler will optimize that one anyway, just old habits from ASM times die hard). 

Hmmm... anyway, I really like what you wrote here: "I'm noticing that reading doesn't really help much as much as writing programs and running into issues and solving them." This is absolutely spot on. All this general babbling around usually makes little sense when hit by real world problem. Also refactor a lot. Not just the code, and implementations, but as learning is your goal, dive deep into finished project and go trough all the API, all the abstraction, and try to imagine something better, easier to use, easier to understand it's responsibilities, easier to read and get the idea and eventually easier to implement (although sometimes to get better API and abstraction the implementation can be more bloated, but the cost of bloat has to be clearly justified by the cleanliness of resulting API/abstraction). 

Source differences only, all the where in static code the 32 bit address part is enough, have to change to full 64 bit in PIE, i.e.: 

So there is a redundant database roundtrip in your code. After this statement you know everything that is going to find out again. So you may as well do it yourself: if the record exist: modify it and its details, if it doesn't: add it. To modify the existing records, use : 

All other pieces of code that wrap this part can be deemed redundant. As the ultimate (over) simplification you could even write this code directly in an MVC controller's action method. No added layers involved and the job is done. Useful layers? Anything added on top of this base line should be carefully considered. Additions should be useful, not restrictive. Your proposed architecture is restrictive because it is "vertical". You seem to have a column of abstractions for each entity: , (as ), with subclasses like . Then there is a class, maybe part of a similar column. This architecture has the same drawbacks as Data Access Object: it will lead to multiple isolated queries and repetitive code. Alternatives? This columns-per-entity setup defeats the purpose of an OR mapper like Entity Framework, which is to work with object graphs that map to a relational data model. When you need orders and their related customers you can get them in one LINQ query. Likewise, when you want to save orders and customers, you can add them to the context and do one call to save everything in one transaction. This has made me move to API-oriented architectures. I usually create services that live for the duration of one web request. Each service has a number of methods that execute some business case, like creating orders. For this, the service has one context instance that can pretty freely be used inside the service methods. This works best in combination with dependency injection (or Inversion of Control, IoC), but that's not a prerequisite. This is, very briefly, what it could look like: 

I would move lot more closer to the area where it's modified, so it can be easily seen with eye, where the whole block is, and span over fewer branching points (which is always error prone, to keep correct stack across some branching). You can actually surround just few instructions with , not having any branching at all. 

Peter Cordes did leave you several review comments in the original SO question, so I will post the code-only here which is sort of adjusted by his advices (and my small modifications). Commands to compile: 

The initial comment: not clear what is entering (deducting it's about byte ) and I would rather use "arguments" or "input" word. Not clear the description is about bits. Not all arguments are described (the code does use also address for ). Typos. Modified registers are incomplete too (again ). Etc.. 

I had only some limited quick look, just cherry-picking some things to comment on: Entropy level: I'm not expert on this topic, but I think using time stamp as additional entropy source every time you produce a number is not a very good idea. But I'm even afraid you use it as only source of entropy in some cases, which is definitely wrong. I was unable to quickly show what's wrong about it, as you have weird way of updating, masking the problem out in your example. But after you change this I'm afraid it will become obvious this needs rather some "seeding", and building up upon seed data. About : You do great deal of pushing all around into it, yet only pops from it, and only once. So after running this for a while (using it as output stream, without calling RNG) the buffer will grow a lot, eventually running out of memory. If this one is supposed to be a buffer of pre-generated random numbers, then the should generate new buffer value only when buffer is empty, and then it should pop value from buffer and return it. But I would do something different, I would change buffer into single number, used as seed. At any point of your current source, where you end with buffer.push, you would instead use old value of buffer as input for the transformation (in some way), storing result back to buffer. Then will do yet another transform over it, and return the value. But at this moment the timestamp-every-call will start affecting the statistics of random numbers a lot for particular date-time and RNG calling period. So I would use timestamp only for initial seeding, then the RNG would work as any common pseudo-random arithmetic RNG, with added twist of output stream being further source of entropy. About output stream as entropy source: well, you should check the common output stream byte values first, they are not "random" bytes. From the code it looks like you are aware of that, trying to build an unsigned value ORing 4 shifted values, but the result is only 20b wide for ASCII, and the values are overlapping, so the upper bits of ASCII (not varying much) will affect the lower bits of next character (I hope I did read the source correctly, didn't debug it, BTW for better readability you should put these transformations from string to unsigned into some function, so you can test it on it's own). I would probably take only 3 bits (or maybe just alternating 2+3, to avoid ASCII specific values definition to affect the entropy of such value too much) of each output character, and cumulate them in 32b buffer till it's full (the overlapping 1-2 bits kept for next value), then use it for transforming the seed buffer (so roughly every 10 output chars the seed will get additional entropy). This may still go quite wrong with UTF-8 or unicode16/32 output stream variants, just imagine somebody using it with UTF-8 Arabic texts, having every second byte something like or what's the actual prefix (too lazy to check). About : 

Note that this returns an empty string if no occurrences are found. I think that's more correct for a function that returns "everything until the nth occurrence of x". 

The trouble is that with extension methods it's too easy to 'add' methods to a very general type while the scope of these methods is more restricted than the scope of the type itself, even within one namespace. For example, I had extension methods on that I decided to ditch again later, when wisdom finally took over. This phenomenon also applies to your extension methods. They are defined on . Now I don't know how many classes you intend to implement, but who says they're all going to have ? This means that you'd have to confine the extension methods to contexts knowing about . This, in turn, may imply that you may as well replace the extension methods by instance methods in one specific context class. When create a method at all? That's another question. No matter if it's an extension method or an instance method. Is the task even worth creating a generally accessible method? I specifically frown upon this method. To me, this looks like something that should probably be a service method. Remember the single responsibility principle? A context shouldn't have any knowledge about any format. That's a (domain) service's responsibility. It may make the context with all its paraphernalia less applicable (or targeted) to other parts of the application or other assemblies. Or, worse, you may get tempted to enter a range of methods to meet other specifications. Alternatives Finally, there are other ways to deal with this 'soft delete' problem, i.e. the problem that records are deactivated rather than physically deleted, while the deactivated records shouldn't be displayed. Of course (and that justifies your [extension] method efforts) you don't want to add to each and every query. But extension or instance methods supplying a pre-filtered set aren't enough either! Any old time you apply an you'll be in trouble. 

Why does the function end when is not equal to ? That should be mentioned in description, that must be to make it work. 

I never did MIPS Assembly, so I decided to try on this simple one. I will comment on your code mostly from performance point of view (as smac89 covered simplicity/readability variant well). In your case I wouldn't be afraid so much of branching (and it's not trivial to lower amount of branches down), but about number of integer divisions () and also syscall outputting integers (hidden divisions). From the limited info I was able to found about real world MIPS architecture implementation it looks like for example PIC32 MIPS32 M4K Core does use about 1 cycle for 1 bit during divide operation, maybe with some early exit optimizations, so in worst case it's about ~32 cycles for 32b/32b divide. I tried to use MARS and it works OK, but I don't see any serious performance information except simple instruction counters, plus is not counted into the stats at all. So outputting integer is "for free", while in real world it would hurt so much that it would be probably better to keep just string representation of and increment it as string, avoiding binary integer (at least with my code it would work, as I don't do on it, so I don't need integer form of "number"). Anyway I didn't go that far, only reworked your loop to avoid divisions, and also to avoid pseudo instructions when possible, so the amount of real instructions generated is similar to the source code. 

You are close to a standard validation implementation of Entity Framework, which is using . It may be worth the effort to replace your validation by this readily available validation framework. The advantage of using is that it works together with validations applied by data annotations or fluent mappings. If, for example, you have ... 

is a materialized list (for example, ). After running , a new enumeration of will produce the same, modified, objects. is an enumerable that produces new objects on each execution. After running , a new enumeration of will produce new objects. The changed objects are out of scope and will soon be garbage collected. 

First, you can copy an object easily by getting it with and then -ing it to the context. Even child objects will be added: So, leaving the Id values for a moment, the core of the copying code could be nothing but: 

Your entities have a dependency to a object that's somehow available to them. If this is one instance you may experience technical impediments when reading entities and their nested entities in one statement. But that's not the most important thing. The most important objection is that these "active" navigation properties will always give rise to the n + 1 problem: for each item you pull from the database by query, you will trigger queries to get their related data. That will certainly affect performance and it depends on the amount of data whether that's serious. This effect is aggravated by the fact that the data aren't stored into the parent entities: each time a navigation property is accessed the query is executed. There are more things to consider when it comes to reproducing Entity-Framework's (EF) behavior regarding navigation properties. EF loads entities into a context, which implements Identity Map: i.e. each database record will be represented by exactly one C# object. The benefits of this are hard to reproduce: 

One more note about the rest of code: I don't like how you use plenty of additional temporary vectors. When you want to enjoy C++ performance boost, you have to be a bit more aware of data structure, as that's the major advantage of C++ over other high-level languages. Usually the sorting algorithms are implemented to either work above the initial container memory without any temporary, or when temporary is required, only single secondary vector of full size is created. Then internal calls pass the first/last iterators to point to the parts of the vector memory, which should be processed in the particular inner call. If you need temporary vector, one of full size should provide enough temporary space for the operation, being properly partitioned by first/last iterators. I'm sorry to not provide the example, but I believe you can find some merge sort implementations on the Internet, probably showing operation on 1-2 vector's only without the copying of content between internal calls. 

Well, the runtime of your code can be maybe improved a bit by cleaning up the current code a bit, but the main bottleneck is the inefficient algorithm, so I will not comment on your particular code and style, and I will focus on the algorithm only (if you still insist on code clean-up of current version, let me know in comments, I may try to rewrite few bits of it more to my style to show you a thing or two, but I think reviewing better algorithm would make more sense). Also I would focus on the search algorithm, not on the init. I'm afraid with huge word list even init can be very costly, and worth optimization, but the initial data may be preprocessed ahead, so you then read not only word list, but complete definition of graph with edges between them. You should have posted, if the init itself is important for you as well (can be worth of effort for application where input word list changes often, so graph has to be rebuilt often). Imagine the words as nodes of graph, with edges between words different only in single letter (obviously words of different length form a completely disconnected sub graph, but even with words of the same length the graph can have several disconnected sub-groups). If a starting word has a ladder to the ending one, both should belong to the same sub group of graph. So first optimization may be to store each sub group separately (for example: having for 4-letter words two or more graphs). Then in O(subgroup_size*letters) you can tell if starting word belongs to the group under scrutiny. (with global hash map of words containing index to subgroup and index within subgroup the O(...) can get even lower, depends on hash map search implementation, but the initialization will get longer). Now the ending word must belong to the same subgroup, otherwise the ladder path does not exist at all, so another search of word ( O(subgroup_size*letters) ) will tell you, if the solution does exist. And also you will have both nodes (starting and ending word). Now you should do a "path between nodes" search, I'm not sure if the shortest one is required, or any will do. For these situations something like A* path-finding algorithm can be used. I didn't check A* lately, so just from my head some idea about such algorithm, basically searching the graph from both ends, in a deep/wide way by word_distance: You have to create some and set . will be distance (number of nodes) from starting point. Also set and marks whether belongs to the starting node, or to the ending node. Put both indices in the deque. Now till the deque is not empty, pick the index out of it and it's color. For all it's neighbours: 

In short, this would mean that each step in a workflow would be represented by a service method. The UI just issues commands and reads results. It doesn't contain any business logic whatsoever. 

Now if this validation is violated, it will also throw a with the custom message in . Notice that the context responsible for saving the item is wrapped in the . This is not so by default. You must override the context's method to add the context to : 

... you would pull all records from the database before the actual join is made. By returning , this would turn into a SQL query containing a and (obviously) far less traffic. 

... EF will carry out the validation when is executed. If validation fails, a is thrown that contains a property showing the validation errors. All this happens without even implementing . If however you also implement this interface, you can add custom validations that blend seamlessly with the ones from data annotations/mappings. Here's how to do that, reducing it to the essentials: 

You obviously want to benefit from both strands of data reduction. As for the reduction in number of rows, there's no way to make Entity Framework join with local data other than lists of primitive values. Even then, joining is rather inefficient because EF has to convert the local list into a temporary SQL table (sort of), which requires a considerable amount of code. It's more efficient to use , which translates into an statement: 

one way is class holding the actual string, responsible for manipulation with it. other way is helper utility class providing only functions, not holding any string at all. 

(the exact value stored in is , encoded as 64 bit integer value) So you are just destroying precision bits of the original value, but the resulting value can still contain decimals with precision you don't expect. For some more information study how the floating point numbers are designed, maybe this may be of help: $URL$ 

I found another bug in your source: will be always false. Unrelated to your bug, I have read an advice somewhere to always use only "<", "<=", "==" and "!=" in comparisons. It felt strange for few weeks, but once you get used to it, it really makes easier to read sources, as you know the values should only increase from left to right, if the expression is true. So I would write your expression as: . 

Which would use getters to set up the exp bar, exp number display, level number display, set up correct colours based on those, and finally to start some effect when would be true (having that "effect" as an stand-alone app entity, capable to handle it's own life cycle, like some animation of fire works or sound player playing ding once). In case of some more complex level-up effect I would consider either making state of it part of original model, or having separate LevelUpEffectModel to hold state of effect, with it's own view and controller. Controller: Finally controller is the glue of view and model, but should not contain any biz-logic, or low-level view updating commands. So in this example it would do probably things like: 

What is this? This is either a copy/paste error or a major design flaw. How can a repository add itself to the it contains? And why the double(!) cast, why the ? "Smelly" is an understatement. Why is 's member internal? The repo is supposed to encapsulate a . What should other classes in the assembly do with it? If you need it to be internal, it's because of something you don't show, and which, again, would be a major design flaw. One method returns untracked entities? (), while and methods don't. That's confusing. It may be useful to have options for applying or not, but a consumer of a repository should not have to know which methods do and which don't. Either the method name should reveal it, or it should be parametrized. in its present form is a useless method. It returns ... 

Where's Commit? No, I didn't forget the method. The fact is, repositories shouldn't commit. Maybe this is surprising, but if you think about transaction management it becomes obvious. There may be business transactions in which several repositories are involved. When each repo has the potential to save all changes, it may be very hard to figure out which one is able to save at the right moment. That's the reason why generic repos always come with a Unit-of-Work pattern. This is all explained well enough in the link above. You can see this problem lurking in your code. At the end you have 

I would refrain from using as general purpose register. This is limiting you in using / subroutines, and you risk memory corruption caused by interrupt happening in your program context. I would also refrain of such heavy LUT tables usage, as the program will be more likely limited by the I/O operations speed, so that tiny amount of calculation will quite likely hide in the buffered I/O waits. Here is my version, avoiding those things mentioned above: 

And the other three too (modify target register "edi" to "rdi"). And the instructions into glibc themselves require extra ELF setting to make the linking dynamic ("abusing" a bit directive "with regard" and special keyword ): 

Some short note without really reading into the source. In MVC usually the Model is independent of View and Controller. So your looks like mixing together Model and View class, supplementing functionality of Controller too. Some general notes how I would split these: Model: 

Why name like ? Was it just for this review, or is it actual label? Use rather something more descriptive. 

I also modified the code to be PIC (position independent code). This is first time ever I tried that with assembly, so I'm not 100% sure I did+linked it correctly, but the code works, in debugger I see relative addressing, and stripped binary has only about 6kiB, so looks OK to me ... and now I tried to run it multiple times in debugger, and the code address is randomized, so the ASLR works too. And fixed some of your comments. And I test return value, so now the code upon invalid input will simply output the current sum, and the program can be terminated early by entering non-integer, or Ctrl+D.