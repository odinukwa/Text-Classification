According to this document from the MongoDB documentation, there are various data types in MongoDB, but again, How do I explicitly define data types for a MongoDB collection? 

Is there a good ratio for drive sizes for MongoDB? For example if you have a 8Gig drive for the data, then how big should my drive for the log be? How about the drive for the journal? Just a little more background I'm following this tutorial, which states: According to this MongoDB tutorial which explains how to manually deploy MongoDB on EC2, one of the steps states that you should have: "Individual PIOPS EBS volumes for data (1000 IOPS), journal (250 IOPS), and log (100 IOPS)." 

All: I'm trying to set up regularly-scheduled backups of our MariaDB cluster with mariabackup, and have set up an account for this purpose. The account is a member of group mysql. But when I run the backup as that user: 

I'm trying to optimize some queries in MariaDB, and I've found the ANALYZE FORMAT=JSON functionality to be extremely useful. However, in the case of some complex joins, I'm running into some examples where the time doesn't add up, or come close to it. A when-it-works example, in the case of one query, the query_block r_total_time_ms was about 239ms; the query itself involved 11 tables, and one of those 11 was taking up nearly 227ms, accounting for the large majority of the time spent in the query. There was an obvious index change to make, and making it took that element down to less than 1 ms, and total query time to just over 1 ms. But in another case, the query_block r_total_time_ms is a little over 163ms; the query involves 9 tables and/or subqueries, and the highest r_total_time_ms for any of the components is just over 15 ms. The total of all those components adds up to about 25 ms. So where is the rest of the time being spent? What's it doing for the other 140-ish ms? If there's a way to tell, I don't know what it is. Here's the ANALYZE output that I'm struggling with: 

According to this MongoDB tutorial which explains how to manually deploy MongoDB on EC2, one of the steps states that you should have: "Individual PIOPS EBS volumes for data (1000 IOPS), journal (250 IOPS), and log (100 IOPS)." Why do I need individual EBS volumes for journal, log, and data? Can I just combine these into one EBS volume? 

How do I explicitly define data types for a MongoDB collection? I understand that in Mongo if a collection doesn't exist it will create it when you insert the document, but I know the fields and data types of the collection before hand and I want to create it. I have created an example collection using: 

If there are special cases in the real data (e.g. some sets may be incomplete), a different approach may be required. 

The first half of the query just lists the current contents of the table. The second half appends the same rows but this time putting the column at the same position as in the first query and specifying an empty string in place of the original . The column names of the final resulting set are defined by the names that the first SELECT is returning. So, values of the second SELECT will be returned as in the output and the empty strings as – that is, for your example the output will look like this: 

I had a similar issue with an upgrade where I ended up with mixed libraries. Make sure you don't have dated library files still out there. I had to completely uninstall MySQL and reinstall it from scratch, and then it worked. 

I'm not certain why it's not showing up in the timings, but in this case, the time was being occupied by the index_merge step. After analyzing the issue further, I discovered that MariaDB isn't as good as other database platforms at recognizing and therefore ignoring bad/unhelpful indices (with very low selectivity). By removing several of these from the table in question, I was able to get it to skip those indices (and the index_merge altogether), and execution time went down from 160-ish ms to under 10 ms. 

In order for the transformed set to follow the order of , you could include those columns in the output and use them for sorting: 

So much for Test B. Add another IF EXISTS, use the above query as the EXISTS subquery and customise the action appropriately. In conclusion It does not matter much whether you are implementing a trigger or just writing a complex query – most often you will need to be able to think in sets to come up with an efficient solution. That is not easy, especially at first, and that is where splitting the problem into smaller parts helps immensely, especially when you are still learning. 

If I run with sudo -u mysql, the exact same command works fine. Is there a way to turn on extra debugging or verbosity so I can see WHICH file or directory it's having trouble accessing? MariaDB v10.2.11, CentOS 7 (x86_64) 

I was able to use the strace command to figure out what was going on. There were two problems. The first is that there was no group write permission on the output directory, so it failed to create the xtrabackup_backupfiles directory. The second is that there were two database directories in /var/lib/mysql that lacked group r-x permission. By fixing these two issues, I was able to get it to work. Still, it would be nice if the error message actually indicated what specifically it didn't have permission on, rather than simply reporting that it lacked permission for something. 

Note that the above will give you counts per sts_supplier_number across the entire interval specified. If you want counts per sts_supplier_number and day, add to the GROUP BY and SELECT: 

The following assumptions have been made (some of them possibly repeating parts of your description): 

In my tests, the above query returned the same results for 5.5 as the original did for 5.6 for your example. Although the two queries should logically give equivalent results, they are not exactly equivalent: the rewritten query explicitly changes the logical order of joins. Perhaps that prompted MySQL to choose a different path through the data. But whatever the reason for the different output, please keep in mind that there is no guarantee the behaviour will match for every scenario. I will repeat, you need to stop relying on the behaviour that is not documented, or, actually, documented to be undefined: