Concise code Finally, using the points above, it is possible to rewrite function in a much more concise and clear manner: 

is a bad name in is a bad name - size may be the size of the individual elements or the total number of bytes. , or even would be more clear. does not need an statement Sometimes you write: 

Use for length parameters When counting items or storing an amount of memory (i.e. cannot be less than zero), use . It is unsigned and is guaranteed to hold any array index. is limited to 231-1 = ~2 billion. General sorting code should be able to handle arrays that can fill a machine's RAM. The largest Amazon instance has 244GB of RAM, which is ~30 billion 64 bit s. Implement a generic sort If you are implementing sorting algorithms you should not need to know about the data types or how to compare them. The algorithm is the same if you are sorting , , or any other type of array. In C this is achieved by passing in: the array as a void pointer (), the number of elements, the size of the elements, and a function to do the comparisons. Comparison functions traditionally take two arguments (,) and return an which is if , if and if . Ideally the comparison function should take a third pointer in order to pass any parameters required for the comparison (e.g. string encoding) or local memory required to facilitate the comparison (e.g. to avoid malloc'ing for each comparison). Such comparison functions can be written for like so: 

Once you've implemented a sort function in this way, it can be used to sort any data type for which a comparison function can be written. Edit: Need to cast to in to do pointer de-referencing and arithmetic 

I much prefer the first style, as it avoids adding needless indentation. Imagine you had many conditions you had to check for - if each one added indentation the resulting code would be off-screen. Functions should not accept bad inputs In C there is the notion of defined and undefined behaviour. Functions will do the proper thing only for a defined set of inputs. For inputs outside of those permitted, behaviour is undefined. Your functions should not accept bad inputs. Instead you should use to ensure that the user has given inputs for which the function is defined. This meanns and should always succeed with reasonable inputs. Therefore there is no need for them to return success / failure. is not a useful general function This is more of a design niggle. Keep your interfaces simple. If the user of the API can easily iterate through the linked list, they can quickly implement this and many other functions themselves. Focus on making iteration and accessing elements intuitive to users of this API. Add a comment to Another minor point - etc. don't usually have any indentation, so it is hard to see where started. The problem grows as files get longer. I like to comment with where the conditional started: 

Use is just like but will initialise the memory to zero. You can use this to cut your down to just one line with exactly the same behaviour: 

Using fewer if/else conditionals results in simpler code that has fewer cases to work through when reading the code. Side note: personally I'm a big fan of two space indentation. 

If I understand correctly, you wish to maintain a list of places, and record only the shortest route to each place. This means that each time you need to find any duplicate entry, and choose which to keep. For this task, an unordered list is pretty much the worst choice you could use. Your algorithm is O(n2) (that is, O(n) for adding each of elements), and while that isn't important for 10 destinations, it's pretty critical for 3 million! Given that ordering is not critical here, a hash table is really the correct implementation to use. This will get you O(1) insert and lookup, and the added programming complexity and memory use is appropriate for that number of elements. If that's not possible somehow, then second best would be some kind of self-balancing tree. Finally, it makes no sense to count the length of a large list by iterating the elements. Just increment a counter every time you add an element. A reduction from O(n) to O(1). (In theory, if you add and destroy a lot of elements very frequently, but only query the size once in a blue moon, then my statement is untrue, but I doubt that's the case here.) As far as your existing implementation goes, it's a bad plan to create the new node and then not use it. Maybe in your implementation a garbage collector will sort it out, but otherwise it'll be a huge memory leak, not to mention wasted effort. 

Looking at the State Pattern on Wikipedia I'd say it's more normal to replace the entire function table at once, rather than write individual function pointers. To this end, I would do this: 

You can then delete and (but make sure you set your initial state in the watch constructor). Finally, and this is just advice for C code in general, I would consolidate all the functions that really form one module into one .c file, define the private types inside that, and only expose the public facing types, perhaps as abstract structs, in a corresponding header. In this case I would expect you to have , and that exports only the constructor, , the methods , , and (each of which I would rename according to the theme), and the destructor . You would also need to expose the abstract type , but not the internal definition. My header would look like: 

However, if you have a big program, with a lot of states, each requiring a non-trivial amount of code, it would make sense to have one .c file for each state. Even then though, I would endeavour to present only one abstract header to the external callers. 

If is a unchanging list that really is as short as you show then you should just hard-code the strings into the code (or use a macro, or declare them (make sure they're const pointers as well as pointers to const)). That way the compiler can optimise the calls away to almost nothing; short strings like you show might even be done via a numeric comparison (a four byte string is the same length as a number), but don't do it manually - let the compiler sort that out. The key point is that the compiler cannot optimize this to the maximum if it can't prove that is constant. If is unchanging, but much larger than shown, then you should use "perfect hashing". There is a tool called that, given a list of names, will generate C code to do the lookup in an optimal way. If can change at run-time and is small then you're probably just about optimal already. If can change at run-time, but can be very large then a hash table is the best option. Failing that a sorted, balanced tree would be better than a list.