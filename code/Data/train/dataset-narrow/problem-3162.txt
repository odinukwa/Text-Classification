I have a large dataset for the activities performed by multiple staff in a factory over a long period of time - 01/01/2017 - present. The activities performed by different staff are recorded at each point in time (since they interact with software). I have tabulated these to record the number of each activities performed by each operator for each day. My table looks something like this: 

Each line represents the activities performed by each operator each day they worked, and the number of units processed during each activity, along with a classifier for the shift and team that the operator was a member of (for simplicity, assume that this does not change over time). For brevity, I have omitted values from Shift B, but essentially, the team members of Shift B will (usually) work different days from Shift A, but the proportion of tasks performed will usually be similar to the corresponding Team on Shift A - Team A or Team B. The problem I want to solve is: I have the date, activity and units processed - as well as various other variables - for another operator, "GOofy". But I don't know which shift/team Mr GOofy works. So I am using the data for Mr Mouse and Mr Duck (obviously, in reality, scores of people) to see if I can try to train kNN to correctly guess the Shift and Team pattern for each Name, given the Date, Activity and Units Processed fields, among others. My thinking is: a) There is no particular value in keeping Team and Shift separate, so I should create a joined column which combines both B) If I create separate columns for "Soldering", "Welding" and the other activities, I can have the number of units processed for each day for each activity by date. Given that the kind of activity performed is (I hypothesise) a strong predictor of the shift/team combination, I should be able then to train to recognise shift/team based on both the date of that line (perhaps converted to a numeric date) and the relative values for each line of soldering, welding, etc. The problem is that, when extended to the test set, this will only give me predictors for each individual day. But I suspect that the days worked is also a significant predictor, so I would like to include this as well. But I'm not sure how to approach this. The two approaches I can think of are: Option 1: To use kNN to generate estimators for shift/team for each operator/day combination, with the x variables being the date, units soldered and units welded per day, and then calculate, for each operator, the proportion of times "Shift A, Team A", "Shift A, Team B", etc were assigned to that operator - so if DDuck is assigned "Shift A, Team A", on 90% of days, it seems most likely that DDuck is indeed "Shift A, Team A". Option 2: To somehow create a variable which represents all of the days worked for each operator - although I'm not sure how to do this - and thus create a set which contains one row for each operator. Are either of these approaches valid? Is there a widely-used alternative approach for this? Note that this is not a duplicate of previous questions relating to kNN and time-series data, since those were concerned with forecasting, whereas I am trying to analyse retrospective data. 

Well if you want to answer the question if a single segment reaches the same level and you ignore all other segments behaviors then this should be the required number (given that initial performance of the segments was the same). As a warning when you use to many segments this: $URL$ can happen. 

It depends a bit if the timestamps have any connection to each other (is t2 impacted by t1 as example). In general this looks like a classification problem and you can use for example sklearn. If you want to distinguish A and C and all other cases you would end up with a multi-class classification problem and not all algorithms support these. If not You can just transform the Label into target (A+B) /non_target (the rest). Three additional advice: 

If you are really paranoid you can add your input parameters a second time to the dataframe in the same way and compare the diff in values (should be 0). 

As a more general comment I think the excel file is not sustainable as you are already almost at its maximum ($URL$ 

Your problem looks to me more like a classification problem than a time series problem. My suggestion: Split the date into several sub-variables (year, month, day, week-of-day (maybe). Then just use this and the other values as input for a classification algorithm. Ideally you try several. I can recommend sklearn for this ($URL$ One advice: Depending on the classification algorithm you need to first normalize your data. I find the following blog useful for entry-level problems (with code examples-- if you want to approach this from a time-series perspective he also talks about this) and documentation $URL$ Hope that helps. 

At the end each distribution can be described by a function with parameters. Can be a Gaussian, polynomial etc. In principle you can choose functions that only have one free parameter and fit this one. Depending on your data you might be able to guess a function class that seems to fit the underlying distributions. You can then use the fit parameters as input for your data set. Example: Fit a Gaussian and use mean, normalization and sigma = 3 parameters for your model. 

If both frequency and shift (delta_t) are known you can use something like an abs( (sin(phi*t + delta_t)) to be used as probability density function PDF for background (periodically recurrent data). If you then have a data point with a low background probability you can select it. This has the caveat that it does not work if data is recorded at the same time but then I guess you have to check the content anyway. The sinus function might not be the optimal implementation but is more too help you visualize it. I would just use gaussians with an appropriate width and stack them for the points when you expect data. So your global PDF could be a stack of many small gaussians. If you do not know the initial shift you probably you have to fit it on data. 

What you call sum product is the same as a dot product of two vectors of equal length, $(w_{0j},w_{1j},\dots,w_{nj})$ and $(x_0,x_1,\dots,x_n)$. Based on your diagram, your difficulty is that you want to be able to define connections between neurons that are not in consecutive layers (in other words, the connections might skip layers). I assume that there are no directed edges (synapses) that would go in the opposite direction (from layer $n$ to layer $m$ for some $m<n$). In this setting, you have to forward propagate information to layer $n$ from input $X$ and layers $1,2,\ldots,n-1$. I don't know when and how often you want to 'update' your network topology. Do you want to change it during training?! (Otherwise you'd fix a partially connected NN and you wouldn't write update in your question.) For forward propagation in a fixed network topology, I would associate to neuron $j$ a vector of weights $(w_{ij})_{i\in I_j}$, where $I_j$ is the set of neurons that bring information to $j$ (those $i$ where there exists a directed edge from $i$ to $j$). Then you could either cherry-pick the neurons $i$ from the set of all neurons (by maintaining a list of indexes to find them in the vector of all neurons) and put them into a vector $x$, which is now as long as $(w_{ij})_{i\in I_j}$, and you can use dot product on the two vectors. (With for Python, would work.) You would need to do this separately for all $j$ in the given layer. As these are receiving information from differing numbers of inputs and neurons, they indeed cannot be arranged into a matrix/tensor, not even receiving neurons of the same layer. Or you could force all potential preceding neurons into one vector. Neuron $j$ of layer $n$ can only receive information from neurons $x=(<$input nodes$>$, $<$neurons of layer $1>$, $\ldots$, $<$neurons of layer $n-1>)$. This is a vector, and you can define a vector $w$ of equal length for $j$, which would indeed have many zeros, and $x$ and $w$ can be multiplied. For all neurons of layer $n$, you could stack these $w$ as row vectors on top of each other into a matrix/tensor of size (the number of neurons in layer $n$) times (the size of input $+$ the number of neurons in layer $1$ $+\ldots+$ the number of neurons in layer $n-1$) and use between this matrix and the $x$. How to do training (backpropagation) with such topologies is something you have to consider a bit. I suspect it will work without much adjustment compared to a fully connected neural network without layer skipping. In the second option, you would only need to zero out the weights which must be kept zero after each backpropagation update. This indeed carries overhead if you're not careful. But if you maintained a binary ($0$ or $1$) 'mask' matrix of which weights are live (which correspond to existing connections), then you would only ever update these weights in the backpropagation. Additionally, you may want to introduce a bias term $w_{-1j}$ (also known as intercept term, a constant offset) as if $x$ had an extra dimension that is kept constant $1$. After the aggregation with the sum product, you should also pass the result through a non-linear activation function before entering the value into the neuron in the next layer.