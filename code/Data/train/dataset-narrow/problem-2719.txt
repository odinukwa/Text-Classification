The choice to make depends on what your multiplayer architecture is for the game. There are two major architectures for multiplayer games, the first being client based, in which each client is responsible for its own decision making and updating, and the server simply distributes these updates to other players. The other is an authoritative server, and prediction based clients. In this architecture, the clients are basically fancy renderers, that are responsible for simply sending "intentions" to the server. The server is responsible for managing the global game state, and telling the clients what the current state is. In this case, the prediction code is simply used to help mitigate the affects of latency, and smooth gameplay. To answer your question about more smaller packets, or less larger packets, this would depend on your send/receive architecture, as well as whether or not your game can handle less frequent updates. Stalling an update until you have enough data to reach your desired packet size would lead to less frequent updates, and could make time sharing on the server less effective for asynchronous handling if the number of clients was large enough. This is something that is specific to the architecture of both client and server, but in general I would say "send em when you have em". 

This sounds like a pretty straightforward example of a need for data driven design. Using something such as XML to represent a manifest is not uncommon or even remotely "hard coded". Either way, your game will need to parse something for a list of levels and videos that are available to it, whether that means auto identifying files in a particular folder, or using XML to parse the list at run time. Neither of these ideas are uncommon, and it is simply up to you as to which you would prefer. Loading all the files in a folder can represent a larger risk than loading specific files listed in an xml/txt manifest. 

I have no source code to provide you, but I will point you in the correct direction. "Taking a Picture" is a simple task when rendering a game, you simply need to make a copy of the back buffer before it is swapped at the end of the render stage of your game loop. If you then want to blur it, you will need to filter your image using one of many blur functions and a convolution matrix. This is typically done as a post processing step in engines, and it involves rendering a quad the size of the screen to a texture, while sampling the original back buffer image as an input. A note here, this isn't a trivial thing unless you have sufficient experience with your rendering pipeline, and it would be far too much code to simply demonstrate the entire process. Here is a link to the theory behind a Gaussian filter, and how it can be used to produce a blurred/smoothed image in the general context of computer vision. $URL$ 

The choice of development technology is something you have to decide based on your goals. If you have never written a game before, then the last thing you need to worry about is any sort of middleware limitations, what you need is experience under your belt. Either way, the technology choice should be made based on the skillset of the development team, the designed feature set and aesthetic requirements of the game, as well as the target platform. Either of these choices will get you started and familiar with the technology no problem. This kind of question is pretty open ended, and can turn into a sort of "religious debate", so you should avoid these sorts of questions. 

You can't really put a number on how many shaders you should or should not have, as it is dependent on the limiting factors of your game, as well as the target platform. In practice, reducing the number of active shaders to be "only as many as you actually need" should be followed. Sometimes this means you have only a handful of shaders (10 or so) at once, and sometimes it means you have a few dozen. One way to help limit the amount of permutations that pop up in your game is to implement the "ubershader" technique, by which almost every shader is derived from a singular shader, and the differences and special behaviors are swapped out via a preprocessor. There are exceptions of course for special effects such as depth of field, ambient occlusion, and so forth. My experience with AAA games up to this point has shown that a couple dozen shaders active is not unreasonable. 

If you can write an n-body simulation yourself, then it will ultimately give you significantly more control over the accuracy of the simulation. Is the goal of your simulation performance, or accuracy? Box2D is designed to be a real time physics engine, so it is geared more towards high performance simulations, meaning it will make assumptions where necessary to provide the best performance without sacrificing too much precision. You will be able to make it work, but it simply depends on what your goals are. edit this is a characteristic that is true of all real time physics engines. I have found myself encountering this problem over and over when trying to use a physics engine for something that is a bit unorthodox or simply not what it was intended for. 

A better approach than straight up encrypting the data would be to pack the data in a compressed format that still allows efficient loading, and then use a check sum to verify the integrity of the data at load time. Any form of message digest (even rolling your own) should be significant enough. Also, be aware of what encryption seeks to accomplish, and who it keeps out. If your objective is to keep 100% of people from accessing your data, then you may want to reconsider not shipping that data with the game. The objective of this is to keep out the majority of people, but the people that really want access to this data will take the time to break your compression/encryption efforts, or simply access the data in memory when the program is handling it. 

Your game timing system should have its own internal clock that is started when the game begins (this can be setup by the server to force clients to be the same). Have you considered using this internal timer? It would be valid, and the same across all clients. 

The program is trying to convert a unicode wide character format into a standard ascii format. The code you are trying to convert is out of the available ASCII format range. $URL$ This is the code you are trying to convert, and ASCII only supports 128 different values, with extended ASCII supporting 256. edit you need to use functions that support unicode characters, instead of standard or wide ASCII characters. 

The less times you have to send texture data through the pipeline for rendering the better. A single larger texture set would be more efficient than 1,000 smaller ones of the same memory capacity. It is not uncommon for developers on limited platforms, or developers trying to push the limits of consoles (even today) to pack textures and limit the amount of texture set calls necessary. Packing a texture atlas is a relatively easily automated process, and the extra effort up front reduces the run time performance hits. 

You have multiple questions here, but your question of whether or not it is more efficient to have threaded asynchronous event handling or blocking message handling is likely going to lean in the direction of asynchronous handling. Unless you are encountering some very extreme locality of reference issues, which would honestly likely be encountered regardless of threaded or not. I would recommend you do not implement an asynchronous callback system, as your engine is likely going to see far better improvements from threading other intensive operations. Callback systems are extremely low overhead. To answer more your architectural question, I will explain a simple architecture I have seen in modern AAA game engines, and something I have written myself. Typically, the game engine framework will have an entire system dedicated to handling events, and this is often built on top of a generic messaging, or callback system. Events are triggered at specific points throughout the program flow, and are typically delivered immediately by the corresponding event/callback (unless you support time delay events). At that point, any entity, or system that implements a callback listening interface, and is subscribed to that event will receive the notification and potential payload. As a final note, your method names == scary. :) 

When designing an item system, or in reality any system requiring collections of whatever, you should begin by considering what type of functionality is shared by all objects in these collections. For instance, all items may need to be rendered to the screen, all items have a quantity, all items require collision detection, etc. So starting with this, begin creating base classes that contain the similar functionality between items, but allow for unique derivations for customized behavior. Here is an example, written in pseudo code. This first class represents a base class called Item, which would extend the abstract class renderable. Whenever extending from another class, always ensure you consider whether or not your class "Is A" or "Contains A". For instance, an item "Is A" renderable object, or does it "Contain A" renderable object. Depending on your architecture, this could be different. This item class implements basic functionality and variables that would be common to all types of items, such as a name, quantity, and the callback OnCollision that is triggered whenever something collides with it. 

In this situation, the particle emitter is responsible for spawning the effects by itself, but is not responsible for managing the individual particles. A separate system would perform any allocations, and behavior updates for the effects queued up. This decouples your effects from the object itself, and allows for a singular system to manage the resources associated with a potentially complex and expensive system. edit A final thought is that this isn't necessarily the "Best practice", as the implementation that is best for you is entirely dependent on your context specifics. Therefore, the reality is that there is no such thing as a universal best practice. Hopefully this helps. 

You would probably be better off having your artists produce variations on the default color set, and decide which one to use when the zombie is initially created. The implementation you are using now performs per texel checks to only change a specific color, and say your image is 100x100, that is 10,000 color checks per zombie, on top of the final draw calls. This is a ton of run time overhead just for changing a color. Instead, you could simply select a random texture when the zombie is initially created using a single call to a random function. 

These will each scale a vertex by half along each axis. The third example demonstrates a scaling of 2.0, on only the Y axis. Again, using row matrices. These are simply modifications of the identity matrices. EDIT I suspect the source of your problem is that you are performing scaling to the object in the incorrect coordinate space. Applying scaling to an object in world space will scale it relative to the world origin. You most likely want to scale it relative to the objects origin, which means you need to scale the object when operating on object coordinates. 

The concept of a surface in this situation is simply describing a texture. To understand this better, you should also understand the rendering process. When rendering anything using modern graphics API's, the end result is always going to be the same, a buffer (texture) of color data that is presented to the screen. How you get to that buffer can vary quite significantly, but the end goal is still the same. The rendering pipeline today is a complicated multi-stage system that involves at the simplest level per-vertex and per-pixel operations. When rendering a 2D image to the screen, you are essentially passing through a quad of a certain size, and uv/texture information for that quad. The graphics pipeline takes care of transforming the vertices of that quad into the appropriate coordinate system for your screen, and rasterize the texture you passed in to the pixels at that rectangles location on the screen. This pixel color data is all drawn to a texture, before finally being presented. To finally answer your question about how to create a surface that can represent a tile, you should consider the requirements of your surface. You need a way to represent its location on the screen, you also need a system for representing the size of the surface, and the texture information associated with it. Chances are that pyglet already has support for renderable sprites/surfaces/textures, and you simply need to wrap this functionality in such a way that it is easy to use in your game. A quick look up shows pyglet provides an easy method of rendering a grid of textures to the screen already, as well as support for per-texture render calls. $URL$ 

Note, I am clearly using some of my own classes in this situation to store the information in a format my system prefers. 

What you are referring to is known as a collide and slide algorithm. This is frequently used for player controllers, and cameras. The following links may be able to help you. $URL$ $URL$ 

The issue of input events versus input polling is a matter of fidelity in most situations, and indeed, the reality is that one is simply a layer of abstraction built on top of another. Using input API's to directly read memory from a particular device gives you the option to control precisely how often you are reading input from a particular device, and in situations where you are attempting to simulate an analog/continuous function (driving/flying for instance) this is quite important. On the other hand, events tend to simulate discrete actions, and they work better for on/off type behaviors. Many systems use combinations of the two, based on their needs. 

Within a 3D rendered scene, there are typically three main matrices used to transform an object from its own local space (object/model space) to a homogeneous space known as screen space. World 

Even though you are sending data using UDP, you will still need to add in your own form of reliability to handle situations like this. UDP just gives you the flexibility to do what you want, rather than deal with the reliable but less flexible format of TCP communication. Confirmation messages, or acknowledgement packets of a sort should be used when receipt of information is necessary, otherwise your client has no way of knowing if the data it sent needs to be resent. For instance, if you send critical information, and dont see a response within a set period of time confirming the receipt of that data, resend it. 

I have developed games using both the android sdk/andengine , as well as unity, and my personal preference is to go with the android sdk route. Unity is great, but seeing as this was my first trip into the mobile development world, I took this as a good excuse to learn the environment, and understand the constraints and pitfalls associated with it. Unity simplifies everything so much, making everything from debugging to deployment ten times easier, but I must say that from a personal perspective I don't feel like I got a darn thing out of it. If your goal is rapid prototyping, or you simply aren't interested in the challenges or opportunities to learn associated with the android platform, then you should go with unity hands down. Otherwise, I would recommend the SDK. 

Subtract the position of the ball from the origin of the planet, that will give you the directional vector that you want. You can calculate the magnitude of the force you need to apply using simple newtonian gravity. Newton Gravity Convert the direction into a unit vector, and multiply the magnitude of the force by the unit vector to create a force vector. 

I'm writing a simple geometry shader to create 3D "primitives" in place of a single point. I am performing all of the world-view-projection conversions within the geometry shader after creating the triangle strips to form the 3D primitive. Unfortunately, it seems to be creating the triangles in projection space, and giving me incorrect results. The following pictures demonstrate this problem. Any advice on how to work around this problem? 

I would consider the requirements of your multiplayer experience. For a quick two week prototype I put together a couple months ago, I was on the ropes about whether or not to support TCP/WiFi connectivity between devices, or simply go with bluetooth. I chose to go with bluetooth due to the reliability of it in comparison with the local network I was dealing with, and the simple data format I was sending (XML). I wrote the bluetooth connectivity using the native android SDK, and was able to get it up and running within a day or two. Additionally, consider whether or not you will be hosting the game externally, or requiring one of the devices to act as a host. If you plan on having more than a couple of devices connected at once, you may want to consider an external service (or at least extra device) dedicated to managing connections and processing requests. edit also, bluetooth has very limited physical range, thus that may eliminate it as an option immediately.