Configure the switch so it is not accessible from the public-facing network, and ideally from a specific management LAN connection. Then connect using a VPN - configure it to use certificate authentication in addition to your logon. If you absolutely cannot do this, configure the firewall between this switch and the internet to only accept management connections from your IP address. This isn't perfect security, but it limits visibility of the logon screen so will increase security. 

Of course psexec is no longer an external tool - SysInternals is now part of Microsoft (since 2006, I believe) From Mark Russinovitch: 

Under most VM platforms you can do something very close to what you describe. Have Win XP, Linux and Win7 as VMs. Treat the Win7 VM as a normal PC. Log in and out of it as you like and have it maximised on your screen. Not exactly what you have asked for, but it will look exactly like what you want. I have used VMWare and VirtualBox like this and the docs imply the others will work similarly. Same as all platforms you want to run multiple VMs on, go for large memory and fast CPU, more is better here. 

What does varnish do when me! is sick (or really if all backends in the director are sick, only in my case it's 1/1)? Does it go to vcl_error immediately, and trigger a restart? I want to know how it will handle max restarts. Say in this example, I only want to try twice before giving up. I always want try to get the page locally first, and then if that fails, try one of my peers. But, if I already know ahead of time that my local is sick, I still would like to be able to try 2 of my peers. Is there a way to set that up? 

The basic mmm setup is working - if I move the writer role to server5, that works too (server4 becomes readonly, server5 is now writable, and the output of mmm_control shows that the .201 writer role is now on server5). What I don't know is if there's some simple configuration that I've missed (my background is as a programmer, I learn the networking/sysadmin stuff on a need-to-know basis). Or perhaps the way mmm assigns floating ip's is incompatible with the way a tinc vpn works? (Our other system using mmm does not use a tinc vpn, so I can't compare it directly there). 

You should plan to use a variety of companies or rotate them. I tend to encourage people to use a panel of 4 or more, as each has their spacialisations and specific experience. You will never be secure, but you can get 'secure enough' based on the risk profile your company wishes to accept. Don't assume that because you are small that you are not a target - current organised crime structures sell on exploit methodologies from successful large organisation hacks downwards, and if you are on the Internet you are a target whether you like it or not. Various questions over on security.stackexchange.com have covered this question so it is worth having a look over there. 

802.1x works fine on a single vendor LAN (my experience has been with Cisco ones) - and in fact has less challenges from a management perspective than IPSec in an Enterprise environment. If you use Cisco for your LAN I'd probably suggest this as it is straightforward to implement. 

You could do something simple as a first check: go to one of the internet speed check websites - these let you determine upload and download speeds, and often the latency as well. You run it, and let the client run it - compare times. 

On several others, apt-get update + upgrade tells me there's nothing to do, although the version installed there is only 5.6.15. Why isn't it finding the most recent version? Up-to-date version from servers that did update: "Server version: 5.6.17-65.0-587.precise-log (Ubuntu)" Version from servers that are not updating: "Server version: 5.6.15-63.0-log Percona Server (GPL), Release 63.0" I have confirmed that the following lines are in /etc/apt/sources.list on all servers: 

I've got Percona DB 5.6 on several Ubuntu 12.04 servers. On a few of them, I've been able to successfully upgrade to the latest version (5.6.17) using 

So mmm thinks it's got the .201 ip assigned to direct to the .4 server, but when I ping .201, I get this: 

(percona-server-common-5.6 & percona-server-client-5.6 are identical to this too) From the servers that are not upgrading: 

3 times over the past 48 hours, we had about a 6X spike in traffic lasting a few hours. The server handled it each time, but just barely. This was almost all bad-bot traffic (or maybe failed DOS attempts). I need to set up some sort of wall to automatically block this while it's happening (not by manually going through the logs the next day). Of course, fail2ban comes up a lot in my searching, but I can't find any good examples or documentation to know if it fits for me. I need to implement a filter for apache that ignores most of the log depending on a regex for both the url requested, as well as the user-agent. And only then starts determining if an IP is hitting us too much. The problem is that I can't just use a simple threshold ban on ip addresses. Every legitimate page request is immediately followed by lots of other requests for supporting content (GET /images/...; GET /extensions/...; GET /skins/...), so just blocking anyone who made even 10 requests in 2 seconds would catch almost everyone. I need to filter these entries out of any calculations, and count only the top-level requests. But even if I get it to only look at top-level requests (so now maybe I ban on 20 requests in 10 minutes), then my problem will be that I could easily block crawlers that I'm happy to serve pages to (GoogleBot, Slurp, etc), so I also want it to skip those. Is Fail2Ban or any other product out there this robust? I can get the info I need rather quickly with a couple of grep -v statements, but is there an existing program that already does this? 

The the way TrueCrypt and similar full disk encryption applications work hides the encryption layer from the operating system/applications etc. There is a slight performance hit, as every disk access requires an encrypt or decrypt, but for a low load application it will just work. The slight caveat would be around unattended reboots - I am guessing you only use this server when you are on site, but if you needed to use it remotely, and a power cut had caused it to power down, you would need a physical presence to get it started up again. 

I have never seen any company use public IPs for their desktops or internal servers, and these days it is also very rare for externally facing servers (eg webservers) to have a public IP address - usually these are NATed behind load balancers, or ever more commonly, are virtual servers in a dynamic server pool, so don't even really exist. The NAT'ing may not be down to the level of all internal IP's to one external, usually there are ranges, however it is the overwhelming norm for NAT'ing to be used in one form or another. 

The fact you are using IIS is irrelevant - you just have a memory hungry config, so want a big chunk of RAM. Your best bet is to pop over to somewhere like crucial.com, and input your server type - it will then spit out various memory options which are compatible with your server and you can pick and choose your price point. The problem is that pricing varies dramatically so any single answer here will be dated far too rapidly for it to be useful. 

Is there any way to make KVM automatically restart any VMs that have been shut down due to power failure? Here is my scenario: I run a small VM tank, mostly with development VMs on it. I now have a VM that is set to autostart on system boot, which works. I have installed apcupsd on that VM, reading from the daemon on the host, and configured to shut down when battery reaches 75%. The host will shut down when the battery reaches 15%. My question is, if power returns during this window (i.e. the host stays up), can I restart the VM that was shut down? I know I could hard-code a call to 'virsh start [VM name]' but I am looking to start any VM flagged as 'autostart', somewhat like doing 'mount -a' to mount all defined filesystems. Is this possible? 

From the dpkg log, it seems like the init script is running hardware checks, failing to detect the iLO and determining it cannot run, thereby returning 1 to the calling command. Unfortunately, this means dpkg receives the exit code. Re-enabling the iLO controller means going into the BIOS and I am not able to do that. Instead, I tried adding an into the init script immediately before the standard statement, but this seems to have done nothing. It's interfering with other package upgrades so it really needs to be uninstalled. 

One of the very interesting points talked about by one of the Cisco network leads at the Qualys stand at RSA was that the major difference is one of scale. I'll have to update this post when I get home and can source my notes, but he basically said the problem is that now the number of IP addresses he is responsible for is over 1 nonillion. That's a 1 with 30 zeros after it. Scanning a host for ports 1024-65535 can take some time, but assuming 1 minute per host, 1 nonillion hosts would take 1900 sextillion years. So the real change in security scanning between IPv4 and IPv6 is around how you target hosts or subnets; no more blanket scanning of a range! 

It is a control that could have been added by the admins on that server - concurrent logins (except where this expected) are a simple flag to alert of possible malicious behaviour. However, it is not something we see that often, and very rarely at system level - this is usually an application based control - so I would be more inclined to think that somewhere along the line something has just got broken, whether this is a password expiry, account disabling for some other reason, incorrect keypairs being used, or even configuration settings being set up incorrectly when your friend did that. There are a lot of good reasons to avoid sharing accounts, and not just for the sysadmins - you might need to go through the history file on your friend's machine to see exactly what happened at his end. 

(and it had to work at some point, because they were all installed originally using apt-get) EDIT: From estibordo's suggestion, I'm adding in the output of 

First, grep is matching a text pattern where ^d specifically matches all lines starting with the d character. When you do ls -l, the lines start with drwx if they are a directory, -rwx if they are a file, lrwx if they are a link, etc (give-or-take the read/write/execute permissions). When you ls -1, it's listing just the file or directory name with no other info, so grep'ing ^d will get you only files and directories that start with a d. There are two ways to do what you're looking for: To list only directories with the ls command, you need "ls -d */". To get your desired result, you list all the directories on one line, then remove the trailing / character if you want: 

I've done my own testing, and it seems like it is an error when the director is unhealthy. Note I never did test this with more than one server in the first pool. When I set my target page.php to return a header 500 status automatically (only on the me! server) and watched the varnishlog, I saw the request to me! with X-Restarts = 0, and it returned a 500. Followed up with a request to one of the peers with X-Restarts = 1 that successfully gets page.php with a 200 status. When I set my probe test on me! to show me as unhealthy, and made the same request for page.php, the first (and only) entry in the log was the request to one of the peers with X-Restarts = 1. So it does behave as I would guess ... but what it really needs is a counter on the number of times it has actually tried to pass to a backend. It's a pretty big difference to know if the failure is from an actual attempt to retrieve the page vs no attempt being made. 

Security angle: The best assumption is that attackers could spoof any address, so you should blanket filter all the ones that should never come in through your perimeter. This would include the ones in James and Steve's answers, plus any others you can guarantee should never hit your outside interface. Don't just assume they would require a valid address so they can receive response packets - they may not need to, depending on the type of attack. 

Publishing configurations can help an attacker a little - in that it reduces the time they would usually spend in scanning/information gathering, but if you are a target then they would be carrying out these tasks anyway. Having directory or server names that indicate their function also speeds up an attack (eg FinanceServer01) so you are better off having a naming convention which doesn't give away free info like this. Realistically, if it makes your life easier to publish the config, then do so, but remove unnecessary info (passwords, certs, keys, hostnames) - focus your security efforts instead on making sure your patches are current, your config secures you against attack, and you monitor your most sensitive data (if appropriate) for intrusion. 

I have a laptop running Ubuntu 16.04.3 LTS graphical (so has Network-Manager et al installed). I think I've got KVM and QEMU installed correctly. When trying to set up a Debian VM from the netinstall ISO, it fails to get an address from DHCP. I need to be able to access the VM from outside my laptop so I can't use NAT. I've tried following instructions from: How do I configure bridged networking for VMs KVM-Guests can't get past bridge - no internet connection KVM guest is unable to access the internet But still no luck. The laptop is a Dell XPS 13 and has no onboard NIC. Instead, I have a TP-Link USB3.0 Gigabit ethernet adapter attached, which according to the spec page is an RTL8153 chipset. Ethernet is working fine on the host. Wifi is disabled. I have tried configuring the bridge through the Virt-Manager GUI, through brctl and defining it in /etc/network/interfaces. As best I can tell, the bridge is up and functional, but trying to ping outside the VM results in failure. At one point I was able to ping the host laptop's IP, but no further than that (I can't remember what I did to cause this and it's no longer the case, pinging anything on the same subnet results in the packets disappearing, pinging Google results in . I have stopped the ufw service and additionally flushed the iptables rules, each to no avail. I have Docker on the same machine, but I don't know if that makes any difference. Host machine: ifconfig: