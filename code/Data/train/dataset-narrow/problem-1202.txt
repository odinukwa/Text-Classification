I kinda thought that my implementation of the data type might be a bit dumb, hence the title. Feel free to rip the code apart! 

This is a to encoder that I wrote a little while ago. The only method that is really called is , which takes in a file, converts it to FLAC, and stores it in the file that is taken in as a parameter. I would prefer suggestions on how to improve the method, decrease run-time, or cut down on the length of the code. Any other suggestions are acceptable though. 

I've implemented this below. It seems to mimic quite well, even for all the edge cases I've been testing. ls.c: 

Some of your conditions only have one statement in them. This is completely optional, but I like to remove the braces and move the statement up to the same line as the condition. 

You've all heard of neural nets, no? One of the "hello world"s of neural nets is OCR with the MNIST dataset. My idea for speech recognition is to train the neural net with short labeled spectrograms instead of characters. Unfortunately I don't know of a database for doing this, so I have to create my own software for doing so. Any suggestions on how to improve it? Note: Ultimately this is meant for real-time speech recognition, but when tested I couldn't plot and write spectrograms to file quickly enough for this to happen (as it interferes with how often the CPU can sample audio from the microphone). I would be grateful for any solutions detailing how to improve performance in this area. 

This is a simple brute force algorithm I have in C. All the program does it print out every possible combination of the given for the given length. I would prefer suggestions on how to improve the algorithm, or decrease run-time. Any other suggestions are acceptable though. 

I find the space between the name and the asterisks a bit hard to read. You also don't include a space sometimes. You can choose to keep the space or not, but consistency is important. 

Right now, my implementation should run with \$ O \left( n\right)\$ time complexity. This would be unacceptable with the hundreds of thousands of commands my project could scale to. I am looking for reviews on scalability and optimization, and how well my Command structure and function pointer template would scale as well. 

I've made GUI's before, but it's been a few years and I know that the language has updated since then. Any suggestions for improvements? Perhaps ways to make it look more visually appealing? 

I've created a regular expression (regex) parsing library in C, and would like some feedback on it. Speed is really important to me, but any and all suggestions are acceptable. 

Disclaimer: I'm not sure if this code will be the solution for SPOJ. You don't check if the input number is an . 

Test run: As you can see, the accuracy is somewhat low. The runtime speeds are faster than the original Python program in the post above, but I feel could still be improved upon. 

The array is uninitialized before it is passed to , so once you iterate beyond the last token, the code is trying to run on uninitialized nonsense address values. Initialize to something and then check for that initialization value in the start/end fields during in the loop. 

For a basic sentiment analysis this is fine, but do note that it does have it's flaws. If you're looking to improve the accuracy of your algorithm, I'd recommend reading this research paper, which achieves a classification accuracy of 90% (higher than any other published results). Code: 

Now that I have generated training data, I need to classify each example with a label to train a TensorFlow neural net (first building a suitable dataset). To streamline the process, I wrote this little Python script to help me. Any suggestions for improvement? 

Algorithm Let's redo our processing a bit, shall we? Let's read the file line by line, parse the necessary data, and then process that data for optimal speed. You should only need two loops in this code, one to parse input and one to output data. 

If the user is inputting the text directly I don't believe text can be (I'm not completely sure on this), you can simplify your condition test down a bit using the method . 

This is the second project for my CS1 class, this time I'm actually getting it reviewed before I submit it 

I think it's a great project! But it could do with a few improvements: Neuron Type(1) Suppose we have a network of perceptrons that we'd like to use to learn to solve some problem. For example, the inputs to the network might be the raw pixel data from a scanned image of a signature. And we'd like the network to learn weights and biases so that the output from the network correctly classifies the digit. To see how learning might work, suppose we make a small change in some weight (or bias) in the network. What we'd like is for this small change in weight to cause only a small corresponding change in the output from the network. 

When run with some given input, it runs the method associated with that input. Since this is a scaled down version of my project, it can only run two commands. 

To streamline the setup, I created this Python script (despite me not knowing Python very well). It uses the standard Python library, and I would like to keep it that way. setup.py: 

Principal Components Analysis PCA can be used for data compression to speed up learning algorithms, and can also be used to visualize feature relations. Basically, in a situation where you have a WHOLE BUNCH of independent variables, PCA helps you figure out which ones matter the most and gets rid of the others (think of having centimeters and inches both as input features, we only need one to get the same information). Looking at the research paper you linked, it looks like there are only 10 features input into the neural net. But to me, it looks like we could get rid of 2, possibly 3 features! That's quite a bit for the few features we have. The functions \$ \sin \$ and \$ \cos \$ are related to each other, why do we need both to measure direction and curvature of the trajectory when we could use just one and get the same information into the neural network? One could also make the argument that the centripetal and tangential accelerations are related to each other, or that the velocity and curvature together rule out the need for the centripetal acceleration since \$ a_c = \frac{v^2}{r}\$. More analysis would be needed by the software to determine that thoroughly. Be warned, if not applied correctly PCA can reduce neural network accuracy. PCA is also not to be used to handle over-fitting (since overfitting usually occurs when many features are present). There is a nice GitHub repo here covering PCA using Torch. 

You can combine the attribute with either the or attribute, as in this implementation of the postfix increment operator () for instances: 

It looks pretty good to me. I can see that a lot of research has gone into this. There are a few things I would fix though. 

Removes the loop and compacts your code a lot, making it a lot more readable IMO. Also notice how easy it was for me to extend to capital letters. 

First we care about only unique dates, right? So lets grab indices for their groupings. I'm assuming this original data is stored in the matrix . 

For Khronos, I've had to develop these utility functions to help me deal with storing the files. However, they could also be used in a variety of applications. A description of what the three functions do are given in the header documentation comments. 

Now the Playground environment doesn't complain at me for using my much-loved common operator. I'll leave it up to you to implement the rest of them (since they aren't too hard to implement ). 

Suprisingly, there isn't much on the internet for doing this well, so I figured I would make a simple program for it. 

means you no longer have to write all over the place. That not only saves keystrokes, it also can make the code cleaner since it provides a smidgen more abstraction. There are some places I wouldn't use it in your code, but the s in your header file can use them. 

Now is the only value I used from this output, so you could ignore the other returns by putting in their place. Second, let's split out data up based on these groups. We can use the function to accomplish this nicely. If we pass in the function handle to it, it'll even find the max within these groups. 

This is the first program that I have written in my C++ saga that I actually think is useful. The description for this assignment is kinda long and mundane though: 

This is my first time seriously exploring the aspects of Java 8 development. Therefore, I would like reviews to be tailored as such, since I would like to know the best way for using it in the future. 

Final Program: A quick note about something a few people will want to point out: a portion of the C standard defines the string handling function arguments, unless specified otherwise, must have valid values. I try to mimic that here, therefore excluding the check. This also provides a slight boost in execution speed. 

I recently stumbled across this article on how to write a spelling corrector, and figured I'd try to have a go at it in C (mainly because the link at the end of the page for the C code is broken). Here is what I would like reviewed: 

Understandably there are parts to this code that I haven't included (some method calls, structure definitions, etc.). Posting all that here would make this question quite large and I would like the reviews to be more specific to certain pieces of code than very general and spread out over multiple files. 

Noisy, linear-ish data is fitted to both linear and polynomial functions. Although the polynomial function is a perfect fit, the linear version generalizes the data better. I don't know Lua very well, but by looking at your code I don't see any attempts to reduce over-fitting. A common approach to this is by implementing regularization. Since it's too hard of a topic to cover in-depth here, I'll leave you to understand it if you would like. It is quite simple to use once its concepts are understood, you can see from this Torch implementation here. Another way to reduce over-fitting is by introducing dropout. At each training stage, individual nodes are "dropped out" of the net so that a reduced network is left. Only the reduced network is trained on the data in that stage. The removed nodes are then reinserted into the network with their original weights. The nodes become somewhat more insensitive to the weights of the other nodes, and they learn how to decide more on their own. Dropout also significantly improves the speed of training while improving performance (important for deep learning)! 

I've just started a new class learning Java, and since it's been a long time since I've programmed in it I thought I'd put up my first project to get back in the swing of things. Here is my first assignment: 

Cost Function I don't see any use of a cost function in your code. I'm going to recommend you read this section in Neural Networks and Deep Learning to get a good reason why you should be using one. In short, the cost function returns a number representing how well the neural network performed to map training examples to correct output. The basic idea is that the more "wrong" our network is at achieving the desired results, the higher the cost and the more we'll want to adjust the weights and bias to achieve a lower cost. We try and minimize this cost using methods such as gradient descent. There are certain properties that you look for in a cost function, such as convexity (so gradient descent finds a global optima instead of getting stuck in a local optima). As the book suggests, I would lean towards using the cross-entropy cost function. The way we implement this in Torch is with . Torch seems to have implemented a bunch of these cost functions, and I encourage you to try different ones and see how they affect your neural net accuracy. 

So Apple already has an implementation for this, using . A bit easier to implement than what you have now . 

Well, I don't know much about PHP; but I know a little about security so that is what I am going to review. First I am going to review your encryption algorithm: AES-192. 

Your program fails when all of the members of an array are negative, it simply returns instead of the maximum negative number. 

You comment what the variable is, instead of giving it a more helpful name to begin with. It's good that you had the comment though, many people don't comment what obscure variables mean. 

So recently I made a large project of mine open source: Khronos. I will be dissecting parts of it so that I can have it reviewed more easily here and so that the project as a whole will be improved. The first part I want to have reviewed is the CMake file involved with kicking off the building process of the project. Please feel free to tear it apart. CMakeLists.txt: 

It would be good to note that this is a replacement for your block of code as it is right now. If you plan on printing the vowels in a variable amount of strings (perhaps input by the user), then you would want to make a method that would do this for you. In this function you would pass in the precompiled regex and the string to print. I wrote this up really quick in a text editor and didn't compile it, but here is a program that could handle multiple strings better: 

A few notes: (I implemented this in Octave, so there may be differences between my code and a proper Matlab implementation, but there shouldn't be). 

Gradient Checking For more complex models, gradient computation can be notoriously difficult to debug and get right. Sometimes a buggy implementation will manage to learn something that can look surprisingly reasonable (while performing less well than a correct implementation). Thus, even with a buggy implementation, it may not at all be apparent that anything is amiss. Therefore, you should numerically check the derivatives computed by your code to make sure that your implementation is correct. I found an implementation of gradient checking with Torch here. Be warned that this check is computationally expensive, so once you've verified that your implementation of backpropagation is correct you should turn off gradient checking. 

Here is my code implementing the above. Basic testing has been performed and it seems to work as intended: 

You don't have any statement, yet you declare that you are returning an . Let's return at the end of our program to indicate success. 

Things you could improve: There is a lot that could be improved in this code, so I doubt I will be able to mention them all. Preprocessor 

Not too much to say, looking for a more efficient way to implement this perhaps. Feel free to rip it apart!