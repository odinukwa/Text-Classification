I believe $tt$ with $t=(\lambda x. (\lambda y.1) (x x))$ will terminate using $L$ even if it has an infinite reduction. The first reduction step is: $L(tt)=L(t)t=L(\lambda x.(\lambda y.1) (x x))t=(\lambda x.L((\lambda y.1) (x x)))t=(\lambda x.1)t$. The first reduction step with $F_\infty$ is $F_\infty([(\lambda x.(\lambda y.1 (x x))) t]))=(\lambda y.1) (tt)$. 

One option is to use a BDD library, such as JavaBDD. All such libraries either have a function that counts solutions fast or, at least, they make it easy to write such a function. The disadvantage, however, is that constructing the BDD will be slow in many cases and may require much memory. In case your input is in CNF, a simple heuristic that speeds up the construction of the BDD is the following. First, build a small BDD for each clause and put them into a priority queue whose root is the smallest BDD. Second, pop two BDDs, compute AND between them and push the result to the priority queue. Here's the idea: Since computing AND between BDDs of size $m$ and $n$ takes $O(mn)$ in theory but $\sim m+n$ in practice, minimizing the runtime is the same as finding a Huffman code. 

Depth First Search. It is the basis of many other algorithms. It is also deceivingly simple: For example, if you replace the queue in a BFS implementation by a stack, do you get DFS? 

You are asking (at least) two different questions: (a) What parts of theory build on finite automata nowadays? (b) Why were finite automata developed in the first place? I think the best way to address the latter is to look at the old papers, such as: 

The question in the title (Is it NP-hard to find a small decision tree for a monotone boolean function?) remains unanswered. 

Related. According to Johnson et al. [2], in 1988 it was unknown whether minimal covers of hypergraphs are P-enumerable. The equivalent problem for graphs, when $\forall e:E\;(|e|=2)$, is known to be P-enumerable, since 1977 [3]. But, [2] explains why the method of [3] cannot be generalized to hypergraphs. The related decision problem of finding one minimal cover is clearly in P. The related counting problem is #P-complete for graphs [1]. I also found some sources [4, 5] which I find hard to read: one uses many concepts I'm not familiar with, and the other is long. For example, Theorem 1.1 in [4] seems to imply that there exists a quasi-polynomial algorithm; but, [5] has an extra condition (1.2, submodularity) that wouldn't hold for the covers problem. Moreover, [5] mentions an obstruction (Proposition 5.2) similar to the one alluded to by [2] (‘exercise for the reader’) for the methods of [3]. So, it seems to me that it was still unknown in 2002 whether hypergraph minimal covers are P-enumerable, although I'm not completely sure I interpret [4 and 5] correctly. 

A shortest supersequence $c_n$ of all permutations on $[n]$ has length $\Theta(n^2)$: see this question on Mathoverflow. What if we force $c_n$ to be short? How many permutations can it cover? Let's define $\#_n(s)$ to be the number of permutations on $[n]$ that are subsequences of $s$. Let $C$ denote an algorithm that reads an integer $n$ and produces a sequence of integers from $[n]$, and has a runtime bounded by $O(n\cdot{\rm polylog}(n))$. The function $f_C(n)=\#_n C(n)$ says how good algorithm $C$ is. Let $f = \sup_C f_C$, with functions ordered by their asymptotic behavior. What is the asymptotic behavior of $f$? Has this or a similar problem been studied? 

(Conversely, if there would be some unexpected connection, then that would be worth describing. But I very much doubt this is the case.) The main idea of symbolic execution is that, at an arbitrary point in execution, you can express the values of all variables as functions of the initial values. The main idea of abstract interpretation is that you can systematically explore all executions of a program by a series of over-approximations. (I can hear several AI enthusiasts groaning at the previous approximation.) Thus, at least in the original formulation, symbolic execution was not concerned with exploring all possible executions. You can see this even in the title: it includes the word ‘testing’. But here's more from Section 8: "For programs with infinite execution trees, the symbolic testing cannot be exhaustive and no absolute proof of correctness can be established." In contrast, abstract interpretation aims to explore all executions. To do so, it uses several ingredients, one of which is very similar to the main idea of symbolic execution. These ingredients are (1) abstract states, (2) joining and widening (hence, ‘lattice’ in the title). Abstract states. The concrete state of a program at a particular point in time is basically a snapshot of the memory content (including the program code itself and the program counter). This has a lot of detail, which is hard to track. When you analyze a particular property, you may want to ignore large parts of the concrete state. Or you may want to care only whether a particular variable is negative, zero, or positive, but not care about its exact value. In general, you want to consider an abstract version of the concrete state. For this to work out, you must have a commutativity property: If you take a concrete state, execute a statement, and then abstract the resulting state, you should obtain the same result as if you abstract the initial state, and then execute the same statement but on the abstract state. This commutativity diagram appears in both papers. This is the common idea. Again, abstract interpretation is more general, for it does not dictate how to abstract a state -- it just says there should be a way to do it. In contrast, symbolic execution says that you use (symbolic) expressions that mention the initial values. Joining and Widening. If program execution reaches a certain statement in two different ways, symbolic execution does not try to merge the two analyzes. That is why the quote above talks about execution trees, rather than dags. But, remember that abstract interpretation wants to cover all executions. Thus, it asks for a way to merge the analyses of two executions at the point where they have the same program counter. (The join could be very dumb ({a} join {b} = {a,b}) such that it amounts to what symbolic execution does.) In general, joining itself is not sufficient to guarantee that you'll eventually finish analyzing all executions. (In particular, the dumb join mentioned earlier won't work.) Consider a program with a loops: "n=input(); for i in range(n): dostuff()". How many times should you go around the loop and keep joining? No fixed answer works. Thus, something else is needed, and that is widening, which can be seen as a heuristic. Suppose you went around the loop 3 times and you learned that "i=0 or i=1 or i=2". Then you say: hmmm, ... let's widen, and you get "i>=0". Again abstract interpretation does not say how to do widening -- it just says what properties widening should have to work out. (Sorry for this long answer: I really didn't have time to make it shorter.) 

The traversal, deque, and split corollaries of the dynamic optimality conjecture for splay trees are examples of such gaps. Experiments back up the claim for linear time, but there is no known proof. 

Did anyone investigate precise statements of this kind? Searching for the name of the professor I found a small webpage and book (Chapter 4) that discuss this taxonomy. Sort of background: In case you wonder why are cycles useful at all in real hardware, here is a simple example. Connect two inverters in a cycle. (An inverter is a gate that computes the boolean function NOT.) This circuit has two stable equilibriums (and an unstable one). Absent any outside intervention, the circuit will simply stay in one of the two states. However, it is possible to force the circuit into one particular state by applying an external signal. The situation can be seen like this: While the cycle is connected to the outside signal "we read the input," and otherwise we simply "remember the last value we saw." So one loop helps us remember stuff. 

Programming is a good way to improve your understanding of various concepts, but it is also a dangerous time sink. A typical argument against programming is that it makes you spend time with unimportant details; a typical argument for programming is that it makes you realise that details you thought are unimportant are in fact important. Becoming good at programming mainly means becoming able to deal with the unimportant parts quickly. Becoming good takes a long time. As for the programming language to learn: "all of them" is my (tongue-in-cheek) answer. 

Exercise 118 proves that BINARY DIGITAL TOMOGRAPHY is NP-complete. The input of this problem consists of line and diagonal sums, all from $[2]=\{0,1\}$. 

Example. Consider the path graph $x \mathrel{-\!-} y \mathrel{-\!-} z$. The associated 2-DNF formula is $(x\land y)\lor(y\land z)$. This can be represented by the decision tree $$\textbf{if $x$ then (if $y$ then $\top$ else $\bot$) else (if $y$ then (if $z$ then $\top$ else $\bot$) else $\bot$)}$$ with 4 decision nodes, but also by the decision tree $$\textbf{if $y$ then (if $x$ then $\top$ else (if $z$ then $\top$ else $\bot$)) else $\bot$}$$ with 3 decision nodes. There is no equivalent decision tree with less than 3 decision nodes. In the first, non-minimal decision tree we encounter $x$ and $y$ by following the else branch always. In the second, minimal decision tree we encounter only $y$ by following the else branch always. The set $\{y\}$ is a minimum vertex cover for the graph we started with. 

What does this construction say about lower bounds? Not much. But it does say that if you find a solution that answers a query in $O(h(m,n))$ time after $O(g(m,n))$ time preprocessing, then there exists a representation for monotone boolean functions that takes $O(g(m,n))$ space and allows evaluation in $O(h(m,n))$ time. For example, BDDs have exponential $g$ and $h(m,n)=n$. The reference for ‘exponential $g$’ is 

Say that you have $n$ (comparable) elements in a red-black tree and you want to extract the $m$ elements that belong to $[a,b]$ into another red-black tree. 

The (fairly abstract) problem that both types and contracts attack is "How to ensure that programs have certain properties?". There is an inherent tension here between being able to express a wider class of properties and being able to check that a program has or not a property. Type systems usually ensure a very specific property (the program never crashes in certain ways) and have a type checking algorithm. On the other hand, contracts let you specify a very wide range of properties (say, the output of this program is a prime number) but do not come with a checking algorithm. Nevertheless, the fact that there is no contract checking algorithm (which always works) does not mean that there are no almost contract checking algorithms (which tend to work in practice). I would recommend you look at Spec# and the Jessie plugin of Frama-C. They both work by expressing "this program obeys this contract" as a statement in first-order logic via verification condition generation, and then asking an SMT solver to go try to find a proof. If the solver fails to find a proof, then either the program is wrong or, well, the solver failed to find a proof that exists. (Which is why this is an "almost" contract checking algorithm.) There are also tools based on symbolic execution, which means roughly that "this program obey this contract" is expressed as a bunch of propositions (in some logic). See, for example, jStar. Flanagan's work tries to take what's best from both worlds such that you can quickly check type-like properties and then labour for the rest. I am not really familiar with hybrid types, but I do remember the author saying that his motivation was to come up with a solution that requires fewer annotations (than his previous work on ESC/Java did). In a sense, however, there is some loose integration between types and contracts in ESC/Java (and Spec#) too: when checking contracts, the solver is told that type-checking succeeded so it can se that information. 

(This points to some related results. I initially thought that the related results are very related, but I can't fill the gaps quickly, so maybe they're not so related after all. Perhaps still helpful.) Exercise 118 in the (draft of) section 7.2.2.2 of The Art of Computer Programming looks at a very similar problem. In the solution, Knuth credits an article that in turn credits 

This problem is NP-complete, even for the special case $|P_k|\le 3$. I will give a reduction from Vertex Cover. I will refer to the sets $P_1,\ldots,P_k$ in the question as constraints: binary or ternary, depending on their cardinality. Let $(V',E',k)$ be an instance of Vertex Cover: Is there a subset $S$ of $k$ vertices from $V'$ such that $S$ covers (that is, intersects) all edges in $E'$? We add a distinguished vertex $\bullet$; that is, $V=V'\cup\{\bullet\}$. We add binary constraints for all pairs of vertices in $V'$: for each $\{i,j\}\subseteq V'$, we add the constraint $\{i,j\}$. We then add ternary constraints for each edge in $E'$: for each $\{i,j\}\in E'$, we add the constraint $\{i,j,\bullet\}$. We ask whether there is a graph with $\binom{|V'|}{2}+k$ edges that satisfies the above constraints. The answer (yes or no) is an answer to the Vertex Cover question. Why would that work? Because of the binary constraints, we know that edge $\{i,j\}$ is selected. So, the only task that remains is to pick between $\{i,\bullet\}$ and $\{j,\bullet\}$. That's exactly the task we have in the original Vertex Cover problem: Pick which endpoint of an edge we use to cover it. 

Descend from the root in time $O(\lg n)$ to the smallest element that is $\ge a$ (aka, $a$'s successor). Start from there an in-order traversal that build an array with the desired elements in $O(m)$ time. Build a binary search tree: The middle of the array gives the root and you recurse left and right. The distances from leaves to the root differ by at most one: Color the 'far' leaves red. (You do the coloring in the recursive procedure for constructing the tree.) This takes $O(m)$. 

Is it known or unknown whether hypergraph minimal covers are P-enumerable? I would be most happy with lower bounds. I'd also like to hear about conditional results, which assume some conjecture is true. Of course, I'd also want to know about closely related problems (such as independent sets and cliques). Motivation. I have a problem to which enumeration of minimal covers in hypergraphs can be reduced, and an algorithm that is exponential in the worst case and works OKish in practice. I wonder whether doing much better is possible; or are there good reasons I haven't found something better? (The problem arises in the context of static analysis of programs.) Background. A hypergraph is a pair $(V, E)$ of vertices $V$ and edges $E:(V\to2)\to2$, the latter being subsets of vertices. A cover $U$ is a subset of vertices that intersects all edges: $\forall e:E\;\exists u:U\;(u:e)$. A cover is minimal when no strict subset of it is a cover. Judging from the results of googling ‘P-enumerable’, the term is not too popular. I'm referring to the definition given by Valiant [1]: 

This problem is PSPACE-complete even in the case in which the edge weights obey the triangle inequality. See 

(Answer-in-progress, according to comments.) I will look at a special case, and then discuss how it relates to the general case. The special case is $m=1$ and $V(G)=\{0\}$ with no edge. The added vertices, in order, are $1,2,\ldots,n$, starting from $1$. Let $d_{i,n}$ be the degree of vertex $i$ divided by $2n$. So $\sum_{i=0}^n d_{i,n}=1$. Let $l_i$ be the length of the longest path from $i$ to $0$ that visits vertices in decreasing order. (Vertices added after $i$ do not affect decreasing paths starting from $i$, so there is no need for $l_{i,n}$.) Both $d_{i,n-1}$ and $l_i$ are random variables. The generating model for these variables is how you'd expect: Once we fixed their values for $n-1$, we pick a number $k_n$ from $\{0,\ldots,n-1\}$ according to the probabilities $d_{i,n-1}$, and compute $d_{i,n}$ and $l_n$ as if we added edge $nk_n$. We have that $l_n=1+l_{k_n}$, where $k_n$ is a random variable drawn from $\{0,\ldots,n-1\}$ according to the distribution given by $d_{k,n-1}$. In other words, $l_n=1+\sum_{i\lt n}[k_n=i]l_i$ and $\mathbb{E}[l_n]=1+\sum_{i\lt n}d_{i,n}\mathbb{E}[l_i]$. (The independence here is a bit tricky. In the comment on the post I said it does not hold, but I think it does. The trick is to think of this as a stratified generative model, such that the choice of $k_n$ is independent from $l_i$, but drawn from a certain distribution.) Let's assume, without proof for now, that $d_{i,n}$ depends on $i$ as $\Theta(i^c)$ for some constant $c$. Now, let's assume $\mathbb{E}[l_n]=O(f(n))$, and see what properties should $f(n)$ have. According to the recurrence on $\mathbb{E}[l_n]$, we should have that $$ \sum_{i=0}^{n-1} i^c f(i) \Big/ \sum_{i=0}^{n-1} i^c = O(f(n)) $$ In the continuous approximation, this is $$ \int_1^n x^c f(x) \,dx = O(n^{c+1}\cdot f(n)) $$ One function that has this property is $f(n)=\log n$. But, does $d_{i,n}$ grow like $i^c$ (for fixed $n$)? When $m=1$, we can write a recurrence on vertex degrees. The arc $ni$ occurs with probability $d_{i,n-1}$, so $$d_{i,n}=d_{i,n-1}\frac{2(n-1)d_{i,n-1}+1}{2n}+(1-d_{i,n-1})\frac{2(n-1)d_{i,n-1}}{2n}=d_{i,n-1}\Bigl(1-\frac{1}{2n}\Bigr)$$ The border conditions are $d_{n,n}=1/2n$ and $d_{0,1}=d_{1,1}=1$. Now apply linearity of expectation and approximate $\sum_k\log\Bigl(1-\frac{1}{2k}\Bigr)$ with an integral. Alternatively, note that $d_{i,n}/d_{i-1,n}=d_{i,i}/d_{i-1,i}=(i-1)/(i-1/2)$, so $d_{i,n}$ is roughly $\Gamma(n)/\Gamma(n+1/2)$. Both approaches lead to $\mathbb{E}[d_{i,n}]=\Theta(i^{-(1/2)})$. For $m=2$, you draw two variables $k_n$ and $k'_n$ from $\{0,\ldots,n-1\}$ according to $d_{i,n}$, and we keep just the maximum. This is like picking just one variable, $\max\{k_n,k'_n\}$, but from a different distribution. The question is if this distribution is still $\Theta(i^c)$ for some (other) $c$. Let $d^{(2)}_{i,n}$ be this distribution. We have, dropping the $n$ subscript, $d^{(2)}_i=2\sum_{j=0}^i d_i d_j + d_i^2$. So, $d^{(2)}_i=\Theta(1/i)$. In fact, $d^{(2m)}_i=2\sum_{j=0}^i d^{(m)}_i d^{(m)}_j + {d^{(m)}_i}^2$. Again based only on some quick-and-dirty calculations, I believe that for $m\gt 2$ we have $d^{(m)}_i=\Theta((\log i)^{cm}/i)$, which would seem to say that the $O(\log n)$ bound on $\mathbb{E}[l_n]$ doesn't work anymore. The only thing that matters about the seed graph is how many edges it has. I didn't look at how this affects the answer, but, again, it cannot increase the expected length.