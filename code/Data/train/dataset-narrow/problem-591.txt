You will design your data model, logical model, using these tools. After that you will export your physical model to different databases. Something like below. 

I would like to use schemas to separate database according to modules and usage patterns. I find that it makes it very easy to understand database tables therefore maintenance becomes easier. I had following schema types in my last sql server project. LT -- Lookup Tables 

According to comments. You can connect oracle using easy connect but hr (human resources) account does not exists. Therefore try to use 

I would like to find computed column list in oracle database using Oracle Data Dictionary Views. I would like to add more information. Suppose I have following computed/calculated column in database. 

This specific expert system will hold substances and patients. Every rule give an advice according to patient's attributes , which is stored in database. For example: 

You're under Ubuntu. You can use Debian wrappers. Try (you can change main for your cluster's name. To check if another PostgreSQL version is running, try . If it' won't start with pg_ctlcluster. Look at the logs. For Debian-based, default logging is in . 

The in IPv4 is for small network. You can translate it in for IPv6. Here's the quote from documentation : 

On psql, it's the default, but you can (un)set it with . So I suggest trying at the beginning of the script. From documentation: 

You weren't far from finding it. Here's the documentation you're looking for. Yes you can define a specific locale for chosen columns (from 9.1 version). 

Whenever something goes wrong, you have to look at the logs. You will find warnings, error, fatal, and panic messages. You can find where your logs are in your postgresql.conf file. Look for the setting, if it's on, you will find your server logs in the directory specified in the setting. If is set to off, look at the setting. If it's syslog you need to look at your syslog settings to find where your logs are. If it's stderr you might find something under where is the PID of your running PostgreSQL server. You might find this page of documentation usefull. 

I have a MySQL master server and slave became corrupt because of space issues on the master. Binary logs are potentially corrupt and I don't trust them. The databases are using MyISAM tables. I want to create a new slave, but I can't afford to take the master down or lock the tables for a mysqldump. Is there a way I can get a known place on the master to seed the slave without creating an outage? If not, what is the way to do this with the briefest outage? 

I'd like to set the default prompt on MariaDB across all our database servers for everyone. I assume this would be best done in my.cnf. I can set the prompt in a session, but when I try to add something like in my.cnf, MariaDB fails to start an complains about it. What is the proper way to do this? 

I'm planning an upgrade to MySQL where DATETIME, TIMESTAMP, TIME and YEAR are potentially a problem. I'd like to query the database to find all uses of these datatypes. How can I accomplish this? 

I would like to offer also INFORMATION_SCHEMA views. These are ANSI Standard and works cross database ,for databases which support them. 

SQL Server Management Objects SMO is your answer. You can use it to accomplish this task. Here is an example to generate Create Table Scripts. 

I would like to find given schema, table and column find that if this column is calculated/computed? Wrongly I thought that INDEXES view gives me this information. But following select returns no rows. This gives only functional indexes. 

For a big modules, we also separated them to more schemas. For example personel module consists of more then 5 modules. 

If you are using csv , you can not do this. But if you are willing to use other tools like Microsoft SQL Server Reporting Services or Crystal Reports you may do this. 

My backup is normal rman backup pieces not backup as copy. I am trying to rename nonexistent files. After this rename process , I will try to restore database from rman backup. But this backup is not piece by piece copy. 

I guess you can recreate a new cluster. That will create a fresh bunch of new sys views. And then you move (logically with pg_dumpall) your databases to that new cluster... 

First thing: look at the logs. You will find warnings, error, fatal, and panic messages. You can find where your logs are in your file. Look for the setting, if it's , you will find your server logs in the directory specified in the setting. If is set to , look at the setting. If it's you need to look at your syslog settings to find where your logs are. If it's you might find something under where is the PID of your running PostgreSQL server. You might find this page of documentation usefull. 

I don't know if my answer is accurate as we don't have much informations in your question, but perhaps you should consider one of this lead: 

Key preserved means that 1 key value goes to 1 table. Giving counter examples may help you understand this concept better. Example1: Your view contains aggregation. Suppose you have following view structure. 

I am trying to clone our production database in test virtual machine. Our production database works with ASM. I would like to use plain file system in test database. I created database, services, pfile etc. I gave production database control files to test database. Right now I am trying to rename datafiles in test database. I get following error. 

If your file is created but it is empty. You may still have permission issues . Try to use some file monitor program to see what SQL Server (Agent) is doing in your machine and in your remote machine. Process Monitor is a good utility for this. You can filter file operations and see what your package is doing. You should add this information to your question so that we can help you more. Also you may try to run your package with different credentials to see if your problem is really about permission issues. A handy utility about this is ShellRunAs. 

To answer @a_vlad, the environment hosts customer dbs for a SaaS. Here is how we dealt with it: Load occurs on some customer DBs around the clock. We ended up writing a script to detect usage, if no usage occurred during our lighter times, we did a mysql dump and import for that particular organization on the master, forcing a full sync to the slave for that database. We then ran this overnight for a month and were able to catch most of the organizations on that particular database master in a usage lull. 

I have a MySQL 5.6 server that feeds to 6 web servers and a slave read-only mysql 5.6 server. These are the only clients with the exception of a monitoring software. If any were failing to work, I'd expect my users to notify me immediately or get a report from my monitoring software, instead I am seeing performance issues under heavy load that I'd like to improve upon. All the web servers and the db servers are on the same subnet in a VMWare cluster with SAN storage behind. I'm not seeing any performance/latency/service-affecting issues on the hardware or storage networks on other VMs hosted on this infrastructure so I'm not seeing a reason to blame hardware. In looking into this, I've noticed high connection problems on both the mysql master and slave servers. Details below are from the master server, but look similar on both.