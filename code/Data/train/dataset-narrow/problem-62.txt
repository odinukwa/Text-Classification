I'm looking for an algorithm that can identify edges across which colour is changing sharply, rather than just finding changes in brightness. Is this just a matter of using a different colour space with existing edge detection algorithms, or is there a better approach? 

I have a partly formed idea which I'd like to work on, but first I wanted to run this past the experts to see if this is a pre-existing technique so I don't repeat work that has already been done. I've searched for "sampling solid angle" and "voronoi sphere sampling" but I can't see any sign of prior work. I'll describe my idea in case it goes by a name I can't think of. Example image 

This is all that is required for a correctly working approach, but there are a number of other things you might need to take into account if this approach performs too slowly. I recommend implementing the simple approach, and once it works correctly you can make gradual improvements if it is not sufficiently smooth and responsive (this may not be necessary unless you have a large number of rectangles or restrictive hardware/software). Determining whether a rectangle overlaps the selection rectangle As you point out, using the point in polygon algorithm is impractical for this purpose - each rectangle is made up of an infinite number of points. So we need a completely different approach. One way to check if a candidate rectangle overlaps the selection rectangle is to check for the following two cases: 

You want to know how to calculate the Probability Density of a path when using Next Event Estimation. There is evidence of some problem unrelated to this. 

This is a potentially confusing re-use of terminology. Ambient Occlusion is not in itself a post processing effect. Screen Space Ambient Occlusion is a post processing effect using the depth buffer to approximate the effects produced by Ambient Occlusion. Ambient Occlusion is a relatively expensive global method, while Screen Space Ambient Occlusion is the cheaper alternative for real time animation. Only the latter is considered post processing. 

You also mention that a pixmap can have pixel values that refer to colours stored elsewhere in the file. I have avoided this format as it is not necessary for understanding how a pixmap works. This is known as using a palette (a list of predefined colours so each pixel is represented by an index of a colour in the palette). This is necessary for formats that only allow a small number of distinct colours, but for full colour images there is no need for a palette - each pixel is defined as red, green and blue components without having to refer to anything else. 

It is not generally useful to try to optimise small parts of a program before you have profiled the program to see where the most benefit can be gained by optimisation. Make sure everything is correct and working first, and then profile to decide where to optimise (if optimisation turns out to be necessary). Mathematically, your approach is already correct for all lines. It will correctly identify all lines parallel to either axis, and it will not incorrectly identify any lines that are not parallel to an axis. However, for use in a practical setting, it's worth asking yourself about near-parallel cases and any odd exceptions. Consider all this before even thinking about optimisation, otherwise you may have to repeat all the optimisation later if something you have to change for correctness breaks your initial optimisation. One case to consider is when both the coordinates are identical. That is, the end points have the same x coordinate and the same y coordinate. This is a degenerate case that doesn't define a line (it could have any direction). Check your implementation with this case and make sure it gives the output that you want it to. Depending on your purpose, you may want to detect only exactly parallel lines, or you may want to detect lines that are sufficiently near to parallel. In some cases lines near to parallel may satisfy your purpose, and in other cases it may be essential to accept lines near to parallel, if for example there is the possibility of small inaccuracies in the coordinates. 

Similarly, if the edge is horizontal, check if its y position is between the y coordinates of the selection rectangle, and if one of the following holds then there is an intersection: 

That is, would using a tiny threshold and just terminating a path the moment it drops below that threshold give a more biased or less biased result? Given an arbitrarily large number of samples, would both approaches converge on an unbiased resulting image? I'm looking to understand the underlying reason for using the Russian Roulette approach. Is there a significant difference in speed or quality? 

Although you may be able to detect what hardware is available as a first approximation of a computer's capability, depending on this might not be useful since the same hardware may behave differently depending on the machine it is hosted in, and any other tasks that may be competing for it. Use the frame rate It looks like you are already measuring the frame rate, so you could simply use this value to decide which features to include. If you settle on a target frame rate, then you can order your features from most essential to most optional, and gradually add in less essential features for as long as the target frame rate is exceeded. You could also remove features in reverse order if the frame rate drops (in order to avoid poor frame rate if the available resources change). If you decide to do this, I recommend setting the target frame rate to a slightly different value for adding and removing features. Otherwise some machines near the border between two feature levels may end up skipping back and for between the two levels, adding and removing that feature endlessly. So set the trigger for removing a feature at a slightly lower frame rate than the trigger for adding it. You'll need to find a compromise between adding new features too quickly so that the frame rate suddenly drops further than you intended, and adding features too slowly so that there are several seconds of low quality animation before it settles on the appropriate level of features. You may be able to estimate that some features can be added 2 or 3 at a time if the frame rate is already very far above target. This will depend on the specific features involved and may take some trial and error on a variety of machines with different resources. If you prefer, you can show a blank background until the frame rate has settled, so the user does not see the feature level being adjusted. Alternatively you may be able to adjust the features sufficiently gradually that there will be no perceptible change in any given moment. Consider the window size On my laptop I get 4 frames per second consistently regardless of the window size - whether full screen or a thumbnail sized browser window. Since it appears that the particles move only away from the centre, and do not contribute later to the area they have left, it might be worth considering abandoning particles sooner when the window size is reduced. If this allows a higher frame rate when the window size is reduced, then the extra features will be automatically activated even if they were not possible at full screen. 

The first step in your existing code calculates the orientations of one line segment relative to each of the two end points of the other line segment, using the cross product. This allows testing whether the other line segment has one end point anticlockwise and the other end point clockwise from the first line segment, indicating that the line on which the first segment lies cuts the other segment. Rather than writing a new test, you can use these same orientations to test for line segments that overlap (including partial overlap). If both segments lie on the same line, then all four orientations calculated in your first step will be zero, because none of the end points are either clockwise or anticlockwise from the line, since they are on the line. Then it remains only to check whether the two segments on the same line overlap, by checking whether either of them has an end point between the end points of the other segment.