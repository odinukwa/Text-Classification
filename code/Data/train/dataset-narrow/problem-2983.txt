Formalization is important, I believe, at every step, concurrent with analogies, metaphors, and examples. Give them the formal definition. Use it frequently in teaching and in conversation. Make them write it on a study guide. Give them a question about it on a practice quiz. They will learn it in spite of themselves. One day their brains will go "aha", and the formal definition will coalesce with the informal representations you've been giving them. Last week a student asked me for help with her code. She was trying to add a constructor to a class (C#), but she wasn't naming it correctly. I asked her to tell me how to recognize a constructor. She answered with the definition I'd given her - "a constructor has the same name as the class". As soon as the words were out of her mouth, she realized what she'd done wrong. Up until that point, she'd memorized the definition, but she hadn't really considered what it meant. As I coaxed it out of her, however, her brain made the leap and she had understanding. That "formalization" wouldn't have been there if I hadn't pounded the definition, ever so subtly, in my daily lessons and other activities. 

I do study guides because some students may need to list the information just once more to get it. What if they hadn't had that opportunity? They may have missed it. And, let's face it, do a lot of students, especially those at the high school level, have the self-discipline to go over the material once more unless they have a compelling reason? Even a test may not be a compelling reason. But a study guide is something I rarely have students completely ignore. They will turn it in, maybe not with all the correct answers, but they will give it a reasonable attempt (let me say as an aside here that I don't always grade for correctness, sometimes just completeness). The students who don't need the study guide - who already have the material, or who have good study skills - will see it as a nuisance but will do it anyway without much effort. Those who can benefit from it are your real target. 

We have found that Red or Yellow in math and/or Red in literacy are accurate predictors of a student who will struggle in programming. Just looking at the data from last semester, when I taught programming I (VB.NET), the only C's and D's I had in the course were the students who had Red or Yellow math scores or Red literacy scores. Every semester when we go through our rosters (we are doing it right now for next fall), if we encounter a student who has signed up for a programming course who does not have a strong math or literacy foundation, we first approach their counselor, show them our prior semesters' data, and talk to them about the student's chances of success. The counselor will then talk to the student, and maybe the parents. Sometimes the student will choose to take something other than programming. Sometimes the student will want to take programming anyway, and that is fine. We just want the student (and parent(s)) to be aware that, if they want to be successful in programming, considering their history, they may have to work extra hard or get extra help. While this process we go through may smack of "profiling", our goal is to help every student be as successful as they can be. Note that the converse, a student who has all "Green" data, is not necessarily an indicator that they won't struggle. There are, obviously, other factors, many not quantifiable until you get to know the student: motivation, maturity, perserverence, and hard work. 

What skills should we strive to foster in our students that will make them good software developers in the future? They are in our classes to learn coding skills, but what else do they need? Collaboration skills? Time management? Tenacity? Curiosity? Persistence? Some skills are needful in any career path, and we cannot emphasize them all. On which should we concentrate? How can we do this efficiently and effectively? We are charged with educating the next generation. I'd like to make sure I do my students the service of not only making them good programmers, but also preparing them for the workplace, specifically as Computer Scientists, if that is what they desire. So, what makes a good programmer? 

Since I first considered posting this question, the situation played out in my classroom, and here's how I handled it. I had three students who had a history of "Lone-Rangerism" (last semester). I assigned the group project and warned the entire class that no one could go rogue. I observed each group frequently, circulating the room every 5-10 minutes, paying special attention to those groups who had a former Lone Ranger on their team, making sure that their project wasn't suddenly "done" from importing code the LR did at home. I also set a timer and made each team change "drivers" every 30 minutes so that the Lone Ranger couldn't take over and do all the work. So far, so good. 

Should CS students be keeping a portfolio, and if so, what should it look like? What would you, as a potential employer or college recruiter, like to see in/on a potential employee or student portfolio? Are there ways other than portfolios to showcase a student's work? Many high schools, mine included, are encouraging, if not requiring, students to build an online portfolio showcasing their achievements and growth through their high school career - and not just in the arts. Many of the students at my school have built web sites for themselves using free services such as Weebly and are adding pages and tabs for every year and every class. Each page or tab displays work completed for the class (sometimes but not always their best) - an essay, a math test they did well on, etc. - with their reflections about what they learned, what they could've done better, how they worked in groups, etc. What is the best platform for this showcase? Is Github good enough, or would you like to see something a little more formal, like a Weebly page (with embedded code or links to code)? 

I typically have the same students two semesters in a row, for programming I (VB.NET) and programming II (C#). In our early, impressionable time together, I stress to these students (high-schoolers) and show them by example (I write lots of code for them) the importance of writing clear, readable code, which is partly achieved by explicitly specifying types for all variables (at first I do not tell them there are other options) However, at some point, I have to reveal to my students that they can, indeed, declare a variable as an Object (i.e. ) and that it can hold anything; or, that they can declare a variable as var (i.e. ) and that the compiler will figure out what type it is. Some of them discover this on their own, of course. Then I inevitably have students who abandon the good habits they had formed and want to make everything an Object, or declare everything as var (note I realize this is not equivalent in the language, but students tend to abuse the usage in the same way). I am always torn about how insistent to be that they revert, because I know the use of var in C# is controversial in the industry. (See the SO discussion use of var in C# for an example). Plus, the more savvy students are hanging out in SO anyway, and they see some questions and answers that lack explicit typing and other good programming habits. My question is, since these students are still learning, and since it is my classroom after all, should I emphatically require that they always explicitly specify types unless absolutely necessary? (Of course, sometimes it is justifiable, preferred, and necessary NOT to). And, if I do require it, how can I explain the (in my opinion) sloppiness they sometimes see in online communities?