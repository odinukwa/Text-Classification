1) Hajos calculus for non-$k$-colorability. Using the Hajos construction, one defines a notion of $k$-constructible graph as follows: 

One other way to look at this, which brings in potentially all complexity classes above $\mathsf{E} = \mathsf{DTIME}(2^{O(n)})$, is to consider real numbers in their binary expansion. Any real number whose binary expansion doesn't end with $0^\infty$ or $1^\infty$ - i.e., which is not a dyadic rational - has a unique binary expansion. We can treat this binary expansion as an element of $\{0,1\}^{\mathbb{N}}$, which in turn we can view as a subset of $\mathbb{N}$, and therefore (under the standard identification of $\mathbb{N}$ with $\Sigma^*$ for $\Sigma$ a finite alphabet) a language. One can then ask about the complexity of this language. (Dyadic rationals correspond to languages which are only finitely different from $\emptyset$ or from $\Sigma^*$, so aren't all that interesting anyways...) Note that if a language $L$ has its characteristic function $\chi_L$ being real-time computable, then $L$ itself is in $\mathsf{E}$: given input $x$ of length $n$, suppose that $x$ is the $N$-th string in length-lexicographic order (that is, the string $x \in \Sigma^*$ corresponds to the integer $N \in \mathbb{N}$ under the standard identification). To decide whether $x \in L$, use the real-time machine to output the first $N$ bits of $\chi_L$ and read off the $N$-th bit. This takes $O(N)$ time; but $|x| = \log_{|\Sigma|} N$, so this is $O(|\Sigma|^{|x|}) = 2^{O(|x|)}$ time. (As far as I can tell the converse need not hold. Or at least, the naive proof that I was thinking of doesn't work. That is, suppose $L \in \mathsf{E}$. The naive way decide the first $N$ bits of $\chi_L$ takes $\approx N \cdot 2^{O(\log N)} = N^{1 + c}$ time for $c > 0$.) Using this identification, you can in principle use all complexity classes that aren't contained in $\mathsf{E}$ to try to understand the "complexity" of any non-real-time-computable transcendental numbers. However, I don't know how to relate complexity properties of the language $L$ to whether $\chi_L$ is algebraic or transcendental. Strikes me as a very interesting question. As pointed out by Emil Jerabek in the comments, using this identification, all algebraic numbers are in the linear-time version of the counting hierarchy $\mathsf{CH}$, hence also in $\mathsf{E}$. So this approach seems mainly useful for distinguishing the complexity of transcendental numbers from one another, rather than for distinguishing e.g. the complexity of real-time computable and algebraic numbers. 

Although not specifically aimed at (rooted) trees, I think the G-trie data structure might perform quite well in your setting. It is an adapation of the trie (for searching sets of strings) to graphs. 

Yes, people have looked at this and related groups, though not a whole lot as far as I can tell. For example: Morozov, A. S. Turing reducibility as algebraic embeddability. Siberian Math. J. 38 (1997), no. 2, 312–313. Let $G_d$ denote the group of permutations of $\mathbb{N}$ computable below the Turing degree $d$. Morozov shows that $d_1 \leq_{T} d_2$ if and only if $G_{d_1} \hookrightarrow G_{d_2}$. (Note that a permutation and its inverse always have the same Turing degree. This no longer holds if we restrict to primitive recursive or poly-time reductions.) Kent, C. F. Constructive analogues of the group of permutations of the natural numbers. Trans. Amer. Math. Soc. 104 (1962) 347–362. In fact, if I recall correctly, the primitive recursive permutations generate the group of all computable permutations. (If you restrict attention to the group of permutations $\pi$ such that both $\pi$ and $\pi^{-1}$ are primitive recursive, you get a smaller group.) Furthermore, every computable permutation can be written as a word of length six in the primitive recursive permutations and their inverses. I think the same result holds if you replace "primitive recursive" by "polynomial time." [I don't recall the reference just now, but I have a physical copy of the paper at home. I will post the reference when I return from traveling.] Slightly different but related: Combarro, E. F. Classification of subsets of natural numbers by computable permutations. Siberian Math. J. 45 (2004), no. 1, 125–135. The group of computable permutations is not finitely generated (Is that what you meant by "Are there generators to this group?" Every group has generators, for example, the entire group...). If it were, then there would be a c.e. set $I$ of indices such that the set $\{\varphi_i : i \in I\}$ was exactly the set of computable permutations (where $\varphi_i$ is the $i$-th computable function in some acceptable enumeration). It then takes a little argument to show that this cannot happen (start from the fact that the set of all indices of computable permutations is $\Pi^0_2$-complete). 

In order to not have to write things like "If every $\mathsf{FNP}$ (resp., $\mathsf{TFNP}$) function problem has a solution in $\mathsf{PF}$ (resp., $\mathsf{FP}$ according to above definition), then..." in this context one uses Definition 2 of $\mathsf{FP}$, which is: 

Brockett [1] studied a closely related idea, and showed how to construct dynamical systems that solve any linear programming problem in (I believe) the same manner you suggest, as well as dynamical systems to sort a list of numbers and to diagonalize a matrix. You may be able to use this to directly get the dynamics you need to compute the squaring function. (At some point I saw a cool video of the trajectory of a dynamical system for sorting, but I can't seem to find it...) I won't venture a guess as to whether such dynamical systems formulations could be used to prove something interesting in computability/complexity, but can offer some further references that may be relevant. In quantum computing, Nielsen, Dowling, Gu, and Doherty show that QC can be realized as (if I understand correctly) geodesic flow on a certain manifold - a particular example of the kind of dynamical system you're talking about. See [2] and references therein for a discussion of some complexity issues related to this. Finally, although I don't think it's exactly what you're talking about, it would probably also be worth checking out Bernard Chazelle's work on "influence systems" which are a type of dynamical system that is at least as powerful as Markov chains and Turing machines, but can exhibit all kinds of dynamic behavior (including chaos, etc). See [3] and references therein. [1] Roger W. Brockett, Dynamical Systems that Sort Lists, Diagonalize Matrices and Solve Linear Programming Problems, Proc. 27th IEEE Conf. Dec. and Control, Austin, TX, pp. 799-803, Dec. 1988. [2] Mark R. Dowling, Michael A. Nielsen. The geometry of quantum computation, arXiv:quant-ph/0701004, 2007. [3] B. Chazelle, Natural Algorithms and Influence Systems, Comm. ACM 55 (2012), 101-110. 

You might consider the algorithms that are used for generating Sudoku puzzles - presumably generalized to $n \times n$ - since (usually) Sudoku puzzles are supposed to have a unique solution. On the other hand, Sudoku puzzles are also usually guaranteed to have at least one solution... But finding that solution could still be a good benchmark for your solver. You might use a Sudoku-generator together with a reduction to SAT, or you might think about how to apply the techniques used in Sudoku generation to more directly generate Unique SAT instances. For the former, obviously your SAT instances will have some structure, but it's unclear to me whether it's more or less structure than e.g. planting a solution or using the witness isolation technique. Probably depends on your needs and your solver. The one reference I know of here is: Sudoku Puzzles Generating: from Easy to Evil. 

(1) In terms of structural complexity classes (as opposed to just upper bounds on deterministic time), for general Group Isomorphism, the known upper bounds are essentially the same as for Graph Isomorphism, namely $\mathsf{coAM} \cap \mathsf{SZK}$. However, Arvind and Toran showed that Solvable Group Isomorphism is in $\mathsf{NP} \cap \mathsf{coNP}$ under a relatively benign derandomization assumption (in particular, weaker than that currently needed to show Graph Isomorphism is in $\mathsf{coNP}$). Although this isn't general Group Isomorphism, as solvable groups are widely believed to contain the hardest cases of Group Isomorphism, this is "pretty close." As it is conjecture that $\mathsf{coAM} = \mathsf{coNP}$, it is also conjectured that Group Isomorphism is in $\mathsf{coNP}$. In the Cayley table model, many people believe that Group Isomorphism is even in $\mathsf{P}$. (2) Subgroup Isomorphism in the Cayley table model is unlikely to be $\mathsf{NP}$-complete, as it has a quasi-polynomial time algorithm. Namely, $H$ has at most $\log_2|H|$ generators; try all possible mappings of these generators into $G$ to see if any gives an injection. This takes time $|G|^{\log_2|H| + O(1)}$. (3) Every finite group has a generating set of size at most $\log_2|G|$ (simple exercise). For the rest of this part of the question, it really depends on how the group is presented. However, note that how the group is given as input - e.g. Cayley table, generating permutations, generating matrices, generators-and-relations, black-box - also has a significant effect on the complexity of the corresponding algorithms. It is known that there are $n^{\Theta(\log^2 n)}$ groups of order $\leq n$, so by counting, groups of order $\leq n$ in general need $\Theta(\log^3 n)$ bits to describe. It is an open question whether there is always a presentation with generators-and-relations of poly-logarithmic size. 

It's not really needed, so much as it is a matter of convention and utility. Of course, depending on your aims and your specific problem, it is completely reasonable to consider arithmetic circuits of polynomial size regardless of degree. This class is often denoted $\mathsf{VP}_{nb}$ (for "Non-degree-Bounded"), or sometimes "algebraic $\mathsf{P/poly}$ or $\mathsf{algP/poly}$. I was curious about this same question for a long time, so a while ago I spent some time digging. I found both a posteriori motivations, based on what we now know, and more historical, a priori motivations. I'm sure this list is incomplete, but here's what I found. A priori motivations: 

Typically the way individualization goes is this. You're trying to decide if two vertex-colored graphs $G$ and $H$ are isomorphic in a way that respects the colors (sends vertices of color $c$ in $G$ to those of the same color $c$ in $H$). You pick a vertex $v$ in $G$ and assign it a new color, say $c$, that has not been used before. This is called "individualization." Then for each vertex $w \in V(H)$ you will, in turn, try coloring $w$ with $c$ and see if there is an isomorphism $G \to H$ that respects this new coloring. (This incurs a multiplicative cost of $|V(H)|$, so you don't want to do this too often.) In other words, you are guessing the vertex $v$, and then trying to see which vertices of $H$ it can possibly map to. 

If your goal is the original permanent versus determinant conjecture, there is an earlier step in GCT, namely (as pointed out by chazisop) moving to the strong perm v det conjecture by considering the orbit closures. It is conceivable that the original permanent versus determinant conjecture is true but the strong version is false. However, this seems highly unlikely to me. Also, if this is the situation, then none of our current methods can even come close to resolving the perm v det conjecture, since they all currently work for the "strong"/"approximative"/"border-"/Zariski-closed version of whatever algebraic complexity statement they are proving. If your goal is not perm v det but Boolean $\mathsf{NP} \not\subseteq \mathsf{P/poly}$, there are additional claimed steps in GCT that have yet to be published. It is possible that one of these unpublished steps could fail as well, but obviously it is hard to comment on the details of mathematics one hasn't seen... [Potential failures of lower bounds in general, not specific to GCT.] GCT is currently aimed at nonuniform lower bounds; that is, even in the GCT approach to Boolean lower bounds, it is aimed at showing $\mathsf{NP} \not\subseteq \mathsf{P/poly}$. But of course, it is consistent with current theorems that $\mathsf{P} \neq \mathsf{NP}$ yet $\mathsf{NP} \subseteq \mathsf{P/poly}$. Of course, it's also technically possible that $\mathsf{P} = \mathsf{NP}$ and the perm v det conjecture is false! 

1) Here is a paper that studies your question in the case of finite languages $L$, and shows that if a finite language $L$ can be decided by an $n$-state DFA, then any permutation of $L$ can be decided by an $m$-state DFA for some $m \leq \frac13 (n^2 + n + 1)$: 

Lovasz and Vempala (FOCS 2003 special issue of J. Comp. System Sci.) use a variant of simulated annealing to get a better ($O^*(n^4)$) algorithm for computing the volume of a convex body. Obviously, they can prove something about the variant they use, in order to get the provable upper bound on their overall algorithm. 

Testing for constant border-rank can be done in polynomial-time, I'm pretty sure, if you're talking about tensors of fixed arity. More precisely, testing for border-rank $\leq r$ in $\mathbb{C}^{d_1} \otimes \dotsb \otimes \mathbb{C}^{d_k}$ can be done in something like $k(d_1 d_2 \dotsb d_k)^{2(r+1)}$ evaluations of $(r+1) \times (r+1)$ determinants plus some additional constant work (constant depending on $r$). Theorem 3.7.1.1 of Landsberg's tensor book ("Inheritance") says that the equations for the variety of tensors of border-rank $\leq r$ in $\mathbb{C}^{d_1} \otimes \mathbb{C}^{d_2} \otimes \dotsb \otimes \mathbb{C}^{d_k}$ are given by the equations for border-rank $r$ in $\mathbb{C}^r \otimes \mathbb{C}^r \otimes \dotsb \otimes \mathbb{C}^r$ together with all $(r+1) \times (r+1)$ minors of flattenings. Since $r = O(1)$, there are only finitely many equations of the former type. Border-rank 1 = rank 1, and more generally rank $\leq r$ implies border-rank $\leq r$. But border-rank 2 can have rank anywhere from $2$ to the arity $k$, and border-rank $3$ in arity 3 can have ranks 3, 4, or 5. Beyond that I don't know about testing for rank. 

I don't have a good answer, but in the spirit of complexity, I have some answers which suggest that a good answer may be hard to come by :). 

They are typically called AND-functions. (I'm not joking.) Indeed, this concept has been considered before, and that's what people call them. See, for example, the book by Kobler, Schoning, and Toran on Graph Iso, where they talk about AND- and OR-functions for GI. And, by the way, there is an OR-function for GI (ibid.). The question of an AND-function for graph automorphism is, I believe, still open :) (as stated in the book above). Based on your last paragraph, the type of reduction you are talking about can also be generalized to what are called "truth-table" or "tt" reductions. These are non-adaptive Turing reductions (the queries are fixed by the input, but cannot depend on the answer to previous queries). For example, the negation kind of reduction in your last paragraph is a 1-tt reduction (1=number of queries). 

If PIT over a finite field $F$ is in P, then there is a family of multilinear polynomials whose graph is decidable in $\mathsf{NE}$ but which does not have poly-size $F$-algebraic circuits (Carmosino-Impagliazzo-Kabanets-Kolokolova APPROX-RANDOM '15). (And a similar result holds over $\mathbb{Z}$.) This is an algebraic circuit lower bound on $\mathsf{NE} \subseteq \mathsf{NEXP}$. To get $\mathsf{P} = \mathsf{BPP}$ out of, e.g., Nisan-Wigderson (& Impagliazzo-Wigderson), one needs a Boolean (sub)exponential circuit lower bound on functions in (deterministic) $\mathsf{EXP}$. So, on the one hand, an algebraic circuit lower bound on $\mathsf{NEXP}$ is a lot closer to $\mathsf{P} = \mathsf{BPP}$ than we are today, but still seems pretty far in some absolute sense: algebraic -> Boolean*, super-poly lower bound -> exponential, and $\mathsf{NEXP}$ -> $\mathsf{EXP}$. (Of course, as discussed by Emil Jerabek in the comments, if one uses Impagliazzo-Kabanets to get PIT in $\mathsf{quasiP}$ by giving an exponential algebraic circuit lower bound, then the "super-poly -> exponential" gap goes away. But I took the question to mean "Suppose $PIT \in \mathsf{P}$ by any arbitrary method...") *Over a fixed finite field this is probably the easiest one to overcome. 

This is the decision version of what is sometimes called "Approximate Graph Isomorphism." While I won't say it's been studied a lot, it has been studied. See, for example: 

In the last decade algorithms have been used to increase the number (and quality, I think?) of kidney transplants through various kidney donor matching programs. I've been having trouble finding the latest news on this, but here are at least a few pointers: 

There are lots of overlaps between small world and scale-free, but I think much less so between those two and expanders. The terms "small world" and "scale-free" are often used informally, but formal definitions are often along the lines of: 

Valiant-Skyum-Berkowitz-Rackoff [SIAM J. Comput. 12(4):641-644, 1983] extends Hyafil’s result to yield circuits of the same depth as Hyafil, but whose size is polynomial in the original size and the degree. The more recent depth-reduction results (the chasms at depth 3 and 4) also involve the degree of the polynomial. As with VSBR, they become significantly less powerful for polynomials of large degree (and trivial for polynomials of really large degree). von zur Gathen’s “Feasible Arithmetic Computations: Valiant’s Hypothesis” [J. Symb. Comput. (1987) 4, 137-172] provides several useful reasons for bounding the degree. In particular, by bounding the degree in the definition of $\mathsf{VNP}$, $\mathsf{VNP}$ is closed under many natural operations that it would not otherwise be closed under. See esp. the two paragraphs at the top of p. 156 mentioning results of Kaltofen (1986) and Plaisted (1984). von zur Gathen, ibid., p. 7: "Restricting the degree is quite reasonable over infinite fields, e.g. over $\mathbb{Q}$, where the binary representation of the value of a polynomial like $x^{2^n}$ has exponential length even for small inputs. In a different setting–over varying finite fields–natural problems like the trace, testing for quadratic residuosity, or factoring polynomials, lead to polynomials of large degree, which can nevertheless be computed efficiently (yon zur Gathen & Seroussi, 1986)."