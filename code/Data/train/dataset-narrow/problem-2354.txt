You can take a look to the work of Lutz, Mayordomo, Hitchcock, Gu et al. on Effective dimension: ... In mathematics, effective dimension is a modification of Hausdorff dimension and other fractal dimensions which places it in a computability theory setting ... I found interesting (though I'm not an expert) E. Mayordomo's introductive video "Effective Fractal Dimension in Computational Complexity and Algorithmic Information Theory" (or the related paper). See also: John M. Hitchcock, Jack H. Lutz, Elvira Mayordomo, "The Fractal Geometry of Complexity Classes" 

** In some ways **, the minimal length matches the minimal length of an efficient Universal Turing machine $U$ that treats its input as a pair $\langle M, x \rangle$ in some fixed encoding (e.g. $1^{|M|}0Mx$), and simulates $M$ on input $x$. Indeed given a language $L \in \mathcal{C}$ decided by $M$ you can simply transform an input $x$ in $1^{|M|}0Mx$ and use $U$ to compute $M(x)$. In other words, whatever language you pick there is a linear time reduction that you can use in combination with the tiny $U$ to solve the problem. Or another way to see it is: given a problem, there is an equivalent problem in which the input representation is a little bit less efficient, but for which the minimal program that solves it is $U$. 

I don't know if there is a canonical description (scheduling notation: $1|?|?$) for it; but it seems that there is a quick reduction from Hamiltonian s-t path problem on a directed graph. Given a digraph $G= (V,E), |V| = n$ and the two vertices $s,t$; build a scheduling task with $n+2$ tasks $T_A,T_1,...,T_n,T_B$ in which $T_1,...,T_n$ correspond to the nodes of $V$ (two of them: $T_s, T_t$ correspond to $s,t$); set $d = n+2$ and set execution times: 

You can reduce the SEPARATED k-SUM problem to a (k+1)-SUM problem in the following way: Given $X_1,...,X_n$, let $b$ such that $2^b > \max( abs(X_1) \cup ... \cup \;abs(X_n))$, where $abs(X_i) = \{ |x| \mid x \in X_i \}$, and let $c$ such that $2^c > k 2^b$ For $i = 1,...,k$ build $Y_i = \{ 2^{c+ki} + 2^{b} + x_j \mid x_j \in X_i \}$; let $u = - \sum_{i=1}^k 2^{c+ki} -k2^b$ Build an equivalent (k+1)-SUM problem picking $X = \{ u \} \cup Y_1 \cup ... \cup Y_k$ Note that every $Y_i$ contains only positive elements. Informally we require a $k+1$ elements subset $C$ from $X$ whose elements sum to zero. We cannot build a solution only with the negative element $u$; so we must include in $C$ at least one element $y$ from one of the $Y_i$; but the $2^{c+ki}$ "component" of $y$ can be balanced only if $u$ is also included; but including $u$ implies that exactly one of the elements of each $Y_i$ is included (the $- \sum_{i=1}^k 2^{c+ki}$ component of $u$ allows to keep the separation between the elements of the original $X_i$). But we also have $\sum_{j=1}^k (2^b + x_j) = k2^b$ and this implies that the original $x_j$s (coming from distinct $X_i$s as seen above) sum to zero. 

In the simplest VRP formulation, all trucks (vehicles) have the same capacity and only one product is to be delivered to each point $P_i$. Other common constraints are: time constraints (or total length of each route), time windows, precedence relations between points. To summarize: the main difference between a TSP and VRP is that the salesman must return to the starting location after some points have been visited. For what regards "It seems relatively easy to model TSR in the form of VRP and likewise inversely."; the reduction from TSP to VRP is immediate, the opposite direction VRP $\leq_m^p$ TSP is surely more complex (and probably it requires other intermediate reductions). 

Yesterday I googled around to check the status of this problem and I found this new (2012) result: Dan Brumleve, Joel David Hamkins and Philipp Schlicht, The mate-in-n problem of infinite chess is decidable (2012) So the mate-in-n problem of infinite chess cannot be Turing complete. The decidability of infinite chess with no restrictions on the number of moves for a mate seems still open. 

Just another (perhaps simpler) reduction from Exact Cover by Three Sets (X3C). Given a set of $3q$ elements $X = \{ x_1,...,x_{3q}\}$ and a collection of 3 elements subsets $C = \{ C_1,...,C_m \}$, does $C$ contain an exact cover for $X$, i.e. a subcollection $C′\subseteq C$, $|C'| = q$, such that every element of $X$ occurs in exactly one member of $C′$? Reduction: pick $n$ such that $2^n > q$ and transform every subset $C_j = \{x_{i_1}, x_{i_2}, x_{i_3}\}$ into an integer: $$a_j = 2^{6qn} + 2^{2(i_1-1)n} + 2^{2(i_2-1)n} + 2^{2(i_3-1)n}$$ and set as target sum: $$b = q 2^{6qn} + 2^{2(3q-1)n} + \ldots + 2^{2n} + 2$$ $X$ has an exact cover if and only if there exist integers $y_1,...,y_{3q}$, $y_j \geq 0$ such that: $$a_1 y_1 + \ldots + a_{3q} y_{3q} = b\quad (1)$$ 

An extended comment: a recent paper by Demaine & al. proves that one tile is enough to simulate an arbitrary computation: Erik D. Demaine, Martin L. Demaine, Sándor P. Fekete, Matthew J. Patitz, Robert T. Schweller, Andrew Winslow, Damien Woods; One Tile to Rule Them All: Simulating Any Turing Machine, Tile Assembly System, or Tiling System with a Single Puzzle Piece (2012) but the tiling is not an exact tiling : "... The output one-tile system requires tiles to live on the same square or hexagonal lattice, allows tiles to rotate, and is nearly plane tiling in the sense that it leaves tiny gaps between the tiles. ..." 

A1) The problem remains NP-complete even for fixed $|\Sigma|=3$ A reduction from planar 1-3-SAT is the following; suppose $\Sigma = \{0,1,2\}$ 

EDIT As noted by usul, my previous answer is too broad, so these are some additional notes with personal ideas (so it is now more like an extended comment, than an answer): If the given grammar is context sensitive, the alphabet has size >= 2 and there are no limits in the number of transformations, then even the problem of deciding if the grammar generates the target string is undecidable. You can easily find a grammar that simulates a NTM; as pointed out by Jeffe Markov algorithms are Turing complete, so given a TM and a string w you can build a grammar and a source string that generate a target string iff TM halts on w. So finding the minimum is undecidable, too. If you put a limit in the number of transformations (polynomial), then the problem of deciding if the grammar generates the target string is PSPACE complete, and the problem of finding the minimum number of transformations is surely harder. If the number of transformations is fixed, I think that the the problem is NP complete (I've a fuzzy idea of a quick reduction from monotone NAE-3SAT) I leave the previous answer below. The problem of finding the smallest CFG grammar that generates a given string (also known as Minimum Grammar Compression or MGC) is NP-complete (J. Storer, "NP-completeness results concerning data compression", 1977). I think that the complexity of the problem when the alphabet is restricted to $\{0,1\}$ (2-MGC) is still unknown. If you switch to context sensitive grammars (LBAs) then you can look at resource-bounded Kolmogorov complexity. Unlike the unbouded Kolmogorov complexity, finding the smallest program that computes a given string is decidable, but we are obviously nearby intractability. There is a lot of reasearch on the subject (and many open problems); for example consider a binary string of length $2^n$ that represents the truth table of a boolean function $f$ and an integer $s$; the complexity of deciding if there is a boolen circuit of size at most $s$ that computes $f$ is unknown (probably not in $P$ but also unlikely to be NP-complete). Here it is a simple introduction and a very nice paper on the power of random strings. 

Just a piece of the story: The seminal 1963 paper of Hartmanis and Stearns, "On the Computational Complexity of Algorithms" introduced the definitions of quantified time and space complexity on the multitape Turing machine model and showed that given more time/space a TM can compute more things. 

I suggest you this survey/introduction paper (but perhaps you alredy read it): Unconventional computing: a short introduction by M. Oltean (2009). It is a little bit funny (see for example the "Price" column in the comparison table) ... however the references at the bottom can lead you to other relevant papers. I'm not an expert but searching papers on other subjects I sometimes found titles about the "DNA computing" model, so - if you classify Quantum Computing conventional computing :-) - I think it is one of the most studied model, and there are many results out there (see for example "A Robust DNA Computation Model that Captures PSPACE"). I'm curious to see other answers about other weird models/results. EDIT: I was missing a "must": Scott Aaronson's "NP-Complete Problems and Physical Reality" (2005). There is also a PowerPoint presentation ... but unfortunately no video (Scott's presentations are great, see for example a small easy introduction on (un)conventional??? quantum computing :-) 

Though point 2. is also related to the age of the players (or how much a player "want to think" while playing); e.g. simpler games like "game of the goose" (which is purely random) or the $O(n^2)$ "connect the dots" are funny for children. Oldest games like chess, checkers and go satisfy many of the (orthogonal) aspects underlined above, but each in a different way: e.g. chess has harder rules than checkers, but it is deeper from a tactical/strategical viewpoint. I'm not an expert of their history, but I'm sure that initially there were many variations of them, and their rules/settings have "slowly been tuned" to better satisfy the above aspects. For example, in order to shorten the duration of a chess game and enter the middle game faster, rules were changed (see history of chess or History of chess variants). Go rules in ancient times were always passed on by word of mouth, and were usually not clear; and even nowadays there are many variants (two main variations are about scoring, i.e. winning conditions) (see for example The History of Go rules). Even draughts has many national variants. As a further confirmation of point 1. and 2. you can examine how many addictive video games (most of them are single player puzzles) have been created in the last years and have become "classics": candy crush, sokoban, snake, minesweeper, atomix, tetris, portal, ... they have completely different rules and settings, but they share a common point: they are theoretically hard :-) From a theoretical point of view; a game is simply a path on a state graph (or state space) in which each node is a valid position and many of the above aspects are closely related to the structure of such a graph. We could write pages about such relation, but I think that a key concept is: 

The first part of the question leads to a coNP-hard problem; this is a reduction from UNSAT. Suppose that $\phi$ is a SAT formula with $n$ variables. Check if it is satisfied by $(1,1,...,1),(0,1,...1),(1,0,...,1),...(1,1,...,0)$ if yes, build a dum false instance of your problem. Otherwise build: $$\phi' =( \phi ) \lor (x_1 \land ... \land x_n)$$ Which is satisfiable and $w_1 = (1,...,1) \in Mod(\phi')$. Note that for all $w \neq w_1$ we have $w \in Mod(\phi') \Leftrightarrow w \in Mod(\phi)$ , if you pick $k = 1$, and $\alpha= 1$; then $\mathcal{I}$ must contain only one element and must be at Hamming distance one from the other elements of the model. But by construction the only $n$ models at Hamming distance 1 from $w_1$ $(0,1,...,1),(1,0,...,1)$ are not in $Mod(\phi) $and are not in $Mod(\phi')$; so your problem has a solution if and only if $\mathcal{I} = \{ w_1 \} = Mod(\phi' )$; if and only if the original $\phi$ is unsatisfiable. 

I tried the same approach followed by Ibarra to prove that a 2CA cannot decide $\{n^2\mid n \geq 1\}$, but it seems not the right way. Note: for simplicity a 2CA is equivalent to a program with one variable $c$ that initially contains the input and the following instruction set: 

The problem becomes NP-complete ... this is a "graphical" :-) reduction from 3-SAT ... it should be self-explanatory (... if not let me know). 

From the comments above: the Hamiltonian cycle problem remains NP-complete even in grid graphs with max degree 3 [1], but in these graphs every traversal of a node requires two edges and at most one edge remains unused, so a node cannot be traversed twice by an Eulerian path. So apparently there is an immediate reduction from the Hamiltonian cycle problem to your problem: given a grid graph with max degree 3 $G = (V,E)$, just ask for a trail of length $|V|$. But all three edges of the node at the end of the trail can be used; to avoid this situation you can pick the top-left node $u$ of the grid graph (which has degree two) and add two nodes: $V' = V \cup \{u',u''\}$ and a new edges $E = E \cup \{(u,u'), (u,u'')\}$ and ask for a trail of length $|V'| = |V|+2$: informally the added edge forces $u',u''$ to be the endpoints of the trail. [1] Christos H Papadimitriou, Umesh V Vazirani, On two geometric problems related to the travelling salesman problem, Journal of Algorithms, Volume 5, Issue 2, June 1984, Pages 231-246, ISSN 0196-6774 

I expand my comment: 1) a fan-in $k$ AND gate can be simulated by $k-1$ fan-in 2 AND gates (and the same applies to an OR gate); so if $I_i \geq 2$ is the fan-in of gate $g_i$ the following relation must hold: $$|C| + \sum_i (I_i - 2) \geq 3(n-1)$$ 2) if you allow arbitrary fan in then you can beat the $3(n-1)$ bound; for example consider the PARITY on 3 variables $(x_1,x_2,x_3)$; the following circuit computes it with only 5 arbitrary fan-in gates: 

Perhaps this is a possible weird reduction from 3SAT. The idea is to use the set $S$ with restricted degree to simulate a true/false assignment to the variables using their odd/even distance from the clauses that contain them. Given a 3CNF formula with $n$ variables; let $c$ be the maximum among the number of occurrences of the variables in the clauses, and let $k = c+2$. Build $G$ in the following way: 

Look at the " $U$s " in the first table of the paper "Small Turing Machines ...". For example, 2 states and 18 symbols are enough to build a Turing Machine that can execute an operating system (if you augment it with an adequate I/O mechanism :) ... If you look for small models closer to the Von Neumann architecture then take a look at Random-access stored-program machines From Wikipedia: ... The RASP is a random-access machine (RAM) model that, unlike the RAM, has its program in its "registers" together with its input.... The instruction set has only 3 opcodes: INC, DEC and JZ See also S.A. Cook and R.A. Reckhow, "Time Bounded Random Access Machines" (they use a larger ALGOL-like set of instructions). 

A possible reduction is from Exact Cover by Three Sets (X3C) (which is strongly NP-hard): Instance: a set $X = \{ x_1,x_2,...,x_{3n}\}$ and a family $F_i = \{ ( x_{i_1}, x_{i_2}, x_{i_3}) \}, i=1,...,m$ of 3-elements subsets of $X$ (triples); Question: Is there a subfamily $F'$ of $F$ such that every element in $X$ is contained in exactly one triple of $F'$. Reduction: given an instance of X3C, just pick a knapsack with $3n$ dimensions each one with maximum capacity $c_i = 1$; pick $n$ objects corresponding to the subsets $F_i$ with profit $1$ and assign weight $a_{ij} = 1$ if and only if $x_j$ is contained in set $F_i$. You can reach a total profit of $n$ if and only if the original X3C problem has a solution, i.e. you can fill the whole knapsack; the objects in the knapsack correspond to the subsets $F_i$ that form a valid exact cover of $X$. 

After clarifying the (unclear for me) meaning of "popular science" (thanks Sasho :-) I propose: Title: Winning Ways for Your Mathematical Plays (4 volumes) Authors: Elwyn R. Berlekamp, John H. Conway, Richard K. Guy Description: it can be considered a compendium of information on mathematical games (tons of games are analyzed: coin and paper-and-pencil games, Soma, Rubik's Cube, mechanical wire and string puzzles, sliding block puzzles, magic squares, Life). It is easy enough to please any fan of recreational mathematics or simply anyone who is interested in games and how to play them well; but I think that it has also been a source of inspiration for many deeper results in combinatorial game theory. Addendum It is not a book, but I think that the Martin Gardner's 'Mathematical Games and Recreations' column for Scientific American must be cited. Resource: The 'Mathematical Games and Recreations' column for Scientific American Author: Martin Gardner Description: for 25 of his 95 years, Martin Gardner wrote 'Mathematical Games and Recreations', a monthly column for Scientific American magazine. These columns have inspired hundreds of thousands of readers to delve more deeply into the large world of mathematics. He has also made significant contributions to magic, philosophy, debunking pseudoscience, and children's literature. Many Martin Gardner's books are collections of informative extracts from his Scientific American column (e.g. Fractal Music, Hypercards and More...: Mathematical Recreations from Scientific American Magazine, Wheels, Life and Other Mathematical Amusements, ecc. ecc.).