Running your mail server as rather than may cause some severs to classify the mail as spam. Almost incoming main I have seen using second level domain names in the HELO message are spam. Most claim to be high recognition domains like , , , or . These domains actually use sub-domains for their mail servers. Multi-domain certificates are available. Or you can use the same third level domain for everything. Providing services on the second level domain is problematic on a number of levels. It is common to have a web server at this level, but except for purpose driven domains like , it is also common for them to redirect to a sub-domain. 

Depending on the distribution you can configure this at startup by editing /etc/sysctl.conf or adding a file in /etc/sysctl.d. Normally forwarding is disabled by default, so you may have a line enabling forwarding. Some firewall builders will enable or disable forwarding depending on the configuration. 

This can be handled, but isn't handled out of the box. I have reviewed the Shorewall and Multiple Internet Connections documentation a couple of times, but haven't needed to implement it. As noted in that documentation, this is not a trivial setup. However, you implement Multi ISP configuration you will likely want to read over the documentation. There is a risk you will route traffic out a different interface than it arrives on. This can create interesting situations where some connections work, but others don't. Marking traffic so that it returns on the same interface it came in on is important. 

Use a header to allow the recipient to reply to the message. The file is used the following rewrite code, which should be at the start of the section of the configuration file. 

If you want to copy it, add an additional transport which writes the data where you want it. You have a choice of formats: mbox, Maildir, BSMTP, and other. Add this as a shadow transport to the appropriate transports. You may want to use a router to select a custom transport with the shadow transport defined. If you just want to capture the mail use a router to select an new or existing transport to save the output as above. Adding routers and transports may be easier to implement using a split configuration. This will be stable over upgrades. 

You could rsync / into another directory, which will give you a full backup of the production server. You will need enough space for the whole hierarchy. Also you will need to exclude things like /proc, /sys, and other such mount points. Use will exclude your data if it is on a mounted file system. Ideally for this kind if setup, I would identify the data and configuration directories for the applications being used with and cherry pick them. When planning a backup scenario, decide how much data you are willing to loose and plan your backups from there. Are you willing to loose log data? Backing up live databases with rsync is likely to cause problems. The approach I use there is to used the database tools to create a recoverable backup, and then copy that. Consider using to select the directories which need to be backed up. Use the option to see what will be backed up before your first run. 

Have you considered routing data. This script should return the broadcast address of the Internet interface: 

Just setup your mail server on the static address. Your dynamic address should have an MX pointing to this. There is no requirement that the MX be in the same domain tree as the MX. Your MX will need to be configured to know about the two domains. How they are handled will need to be configured, but it appears you are handling that already. When sending from your dynamic address relay thought the server on the static address, or use your ISP. Dynamic addresses won't have the necessary PTR record to establish trust. Also many dynamic addresses are listed in Spamhaus and other blacklists and will prevent you from sending e-mail. Some sites will refuse you mail if the PTR and A records don't refer to each other (rDNS validation). If the mail is to be delivered to the host with the dynamic address, relay it through a server on the static address. It should be setup queue mail and authenticate before delivering email. Basically, you will be configuring a backup mail server on the the static address. It will appear as the primary (and only) MX in DNS. 

Creating and deleting files is controlled by permissions on the directory. Modifying the file is controlled by permissions on the file. You may have a mask which is removing the write privilege from the file. 

It is also possible to use some GPS units as a time source. One of my time sources claims gps as its time source. You can start with the NTP Reference Clocks documentation if you need to use this approach. Use the command or to check the reliability of your time sources. You can add a hostname to query your peers, although they may be configured not to respond. You can use in debug mode to scan the local network for servers. However, you may find some rouge servers which are highly inaccurate. (One network scan I did found many srtatum 0 servers with clocks that were a day or more off the current date.) Look for a moderately low stratum (2 to 4) with an accurate time. Checking the peers of server at stratums above 3 may help you discover accessible time sources. 

It gets more complicated when you have multiple interfaces. In that case, you may need to add routes for non-local network blocks that are routed via routers on an interface other than the one with the default route. When you have IP addresses in multiple network blocks on the same interface, it is best to add them to the interface rather than the loopback interface. Normally when I work with servers that have addresses in multiple network blocks each network block is on a separate interface. Having secondary IP addresses on the loopback interface may resolve port conflicts where an application must be configured to respond to traffic on an interface. This can cause issues to other application using the same port on secondary IP addresses. 

You may want to verify your configuration with to see if you get any warnings. Check the file for related messages. If you have it enabled, the sever-info page is also helpful in diagnosing what is happening. EDIT: This is an extracts of my localized-error-pages configuration with several error documents omitted. This can likely be common for both sites as the content you need to modify should be in the /errors/include 

Many browsers will open up multiple connections to load resources like javascript. I see four of the requests are for java script. These connection may be closed quickly. 

From the Domain-based Message Authentication, Reporting, and Conformance (DMARC) RFC section 11.4 (DMARC Tag Registry): 

Changes to DNS should be relatively instantaneous on your authoritative servers. However, due to DNS cashing it will take a while for the changes to get out to clients. This will be more of a problem for frequent clients than occasional clients. You can work around this by pre-populating your data. The various answers already posted cover everything you need to worry about. 

If you implement BATV (Bounce Address Tag Verification), you can block them as they come in. Most of these messages are likely to userids which don't exist on your system, and should be refused on that basis. If you set and publish strong policies (SPF, DKIM, and DMARC), many servers will refuse the spam and you should see less of it in a few days. (Some of the servers sending this "backscatter" spam, may stop sending based on these policies.) 

Characters most likely to cause problems are ESC(27), SI(14), SO(15), and DC-3/X-OFF(19). Some terminals support CSI(155 = 128 + 27) as a short form for introducing ESCape sequences. Escape (ESC) introduces control sequences. Shift-In (SI) and shift-out (SO) can change character sets and other functionality. X-OFF (DC3) may stop the terminal from sending any data. Bell (8) may be noisy. You may want to filter non-formatting control-characters in the range under decimal 32. Most used formatting characters are TAB(9), LF(10), CR(13), and FF(12). BS(7) and VT(11) are less commonly used now. Control characters are arranged in groups by functionality which could make filtering easier. Existing tools already handle the problem fairly well. Consider aliasing one of them as cat. This can break command chains. You can always get the raw cat back by prefixing the command with a backslash. will fix the terminal if you end up in the wrong character set. 

From the timestamps it looks like you updated several programs built Dec-19th about 7:30. Modification timestamps should be the build timestamps. It depends on how they get moved into place. Some programs are linked to through /etc/alternatives, and the symbolic links will have the timestamp of the install.This could be an automatic security update. Check Check your file from then. It is likely compressed and rotated, but can be read with /var/log/aptitude.log`. Many packages have md5sums that can be used to verify that the files they contain haven't been modified. It is safest to run statically linked tools from a read-only media which contains the comparison checksums. However, if you don't think the md5 toolchain is compromised you can use the local files. Programs like usually require a switch to enable updating their database of checksums. You may want to run the program before running updates, and then again after the updates with the switch to capture the changed hash codes. 

ubuntu-minimal depend on python. Therefore you can count on python being installed on Ubuntu. Debian shows python-minimal tagged as system boot. Therefore you should be able to count on python on Debian as well. As noted by others, a minimal Debian installation does not include python. 

You can define variables in (Linux/UNIX) or (Windows). Define the variables in the appropriate manner for the O/S you are running on. For Linux/UNIX you will need to export the variables. You can also define them in the environment you start Tomcat from. You can also create an or file for application (local) changes. Read the existing or file for details. Periods and hyphens are not valid for environment variables. Traditionally, the names are transformed by upper-casing the name and changing periods and hyphens to underscores. That would give the the name . This would be defined with a line like: 

My first question I would ask is why you are announcing 2 prefixes. I am not sure how Windows built its stack, but I would expect it is looking for one route. The prefix should not be used for global (internet) routing. However, given the lifetimes, it appears to be the preferable network in terms of lifetime. Also it is closer to the desired /64 for a local routing block. Is there any reason for having a local identifier when the global identifier would work as well? The prefix is being advertised with the full /48 supposedly supplied by your ISP. Normally this would be broken down into /64 sub-nets with each router being assigned a sub-net. This would be good for 65536 routers in your organization. Try advertising a /64 subnet and see what happens. 

Having reviewed your assumptions do both. Use a CD/DVD based media to dump the current state. Primarily you will want to be able detemine how you were compromised. You may also want to attempt to recover user data not on your backup images. Yo Then rebuild the system from the latest backup media that is not contaminated. Verify this with checksums if possible. Alternatively, reinstall the software from installation media, and reconfigure. Reconfiguration should be automatic if you have been using Puppet or cfEngine to configure your server. Reload user data and scan for root kit components. Verify you have no setuid or setgid programs in the data directories. Determine and close off the method of access used to infect the system. Stage reactivation of the server allowing time to verify applications are running as expected. Carefully monitor for new infection attempts. This all assumes the infection is at root level. Web infections can be done by altering the code run by the web server. Allowing the web server write access to its code may make this more easily done. You may still want to treat this case as if the root account has been compromised. If root on one system has been compromised on one system, you may have more systems compromised. Carefully consider which systems can be accessed without a password from the infected system. 

Use separate UIDs. Having multiple users with the same UID make it impossible to tell who is who. Any reverse lookups from UID to logname become unreliable. One standard solution to your requirements is to install and use . sudo allows you to grant the ability to run programs as a different user to any users or user groups you wish. The file allows significant flexibility in who is permitted to do what. Actions performed using are usually logged. Some distributions lock root and use to allow users to perform actions which need to be done as root. It is possible and common to allow users to execute , or use the option to become another user. This reduces the audit trail somewhat, but tied with process accounting you can get a very good audit trail. Remember that anyone with root access can usually work around your audit trail. Don't give people root access unless you trust them. 

radvd (router advertising daemon) should be disabled on the DLink, at least on the interfaces facing the Cisco router. Alternatively, you could setup a static default route to the Cisco router on the DLink. This will make the route one hop longer, but still valid assuming the DLink will route back out the interface to the Cisco router. If the WAN port is the one connected to the Cisco router, the DLink router should not be advertising routing on that link. EDIT: You may be able to influence routing by setting and/or in the Cisco router's radvd configuration. EDIT2: The problem appears to be that the DLink router does not have a global IP address or route. Default route for routers is usually not discovered, so it may need to be set manually. Step for setting ipv6 router preference from CISCO documentation are: 

SPF shouldn't be causing a header to be added. Something else should be doing this. Look at your headers for some segment where there are lots of lines in a row which are indented (continuation lines). This will be your problem header. As you are using , your SPF record won't be that effective. You are better off coming up with a policy which wil enable you to end your spf record with '-all'. See my comments on Securing your Email Reputation with SPF. 

The simplest solution is to use your ISP's relay server. This should get you around many of the host checks. If you want to send directly you will need a static IP address. Get your DNS configured so that rDNS validatation passes. (Your IP provider will need to configure a PTR record for you.) If you have your own domain, configure an SPF record allowing your ISP's relay server to send mail for your domain. Using DKIM with 1024 or 2048 bit key, should help as well. If you configure SPF and DKIM, you can add DMARC to your configuration. This will enable you to get you a delivery report, and/or a failure report on mail to sent supporting servers. 

I would expect there are not a lot of tools as the parse rules are likely to be application specific. However, I work with a number of tools that do accept requests from email. Most poll a mailbox and parse the messages they find. For simple processing tools like allow parsing, filtering and transformation of messages. sas the ability to pass the message off to a program for processing. I use this to handle DMARC reports and load them into a database. I've also used it to parse, log and remail requests for delivery to a pager. In my case I use , but postfix should be able to do the same. 

Your server address may be listed as a dynamic address, which should never be sending email into the Internet directly. The standards provide of a layer of trust and require static addresses with correct rDNS configuration. Almost all the spam I get comes from dynamic addresses. You should setup your server to send outgoing emails via your ISPs SMTP server. You can use Gmail as your relay, but you will need to enable SMTP services on your Gmail account. Then you will need to configure Postfix to authenticate when connection to Gmail.