The major difference between MyISAM and InnoDB is in referential integrity and transactions. There are also other difference such as locking, rollbacks, and full-text searches. Referential Integrity Referential integrity ensures that relationships between tables remains consistent. More specifically, this means when a table (e.g. Listings) has a foreign key (e.g. Product ID) pointing to a different table (e.g. Products), when updates or deletes occur to the pointed-to table, these changes are cascaded to the linking table. In our example, if a product is renamed, the linking table’s foreign keys will also update; if a product is deleted from the ‘Products’ table, any listings which point to the deleted entry will also be deleted. Furthermore, any new listing must have that foreign key pointing to a valid, existing entry. InnoDB is a relational DBMS (RDBMS) and thus has referential integrity, while MyISAM does not. Transactions & Atomicity Data in a table is managed using Data Manipulation Language (DML) statements, such as SELECT, INSERT, UPDATE and DELETE. A transaction group two or more DML statements together into a single unit of work, so either the entire unit is applied, or none of it is. MyISAM do not support transactions whereas InnoDB does. If an operation is interrupted while using a MyISAM table, the operation is aborted immediately, and the rows (or even data within each row) that are affected remains affected, even if the operation did not go to completion. If an operation is interrupted while using an InnoDB table, because it using transactions, which has atomicity, any transaction which did not go to completion will not take effect, since no commit is made. Table-locking vs Row-locking When a query runs against a MyISAM table, the entire table in which it is querying will be locked. This means subsequent queries will only be executed after the current one is finished. If you are reading a large table, and/or there are frequent read and write operations, this can mean a huge backlog of queries. When a query runs against an InnoDB table, only the row(s) which are involved are locked, the rest of the table remains available for CRUD operations. This means queries can run simultaneously on the same table, provided they do not use the same row. This feature in InnoDB is known as concurrency. As great as concurrency is, there is a major drawback that applies to a select range of tables, in that there is an overhead in switching between kernel threads, and you should set a limit on the kernel threads to prevent the server coming to a halt. Transactions & Rollbacks When you run an operation in MyISAM, the changes are set; in InnoDB, those changes can be rolled back. The most common commands used to control transactions are COMMIT, ROLLBACK and SAVEPOINT. 1. COMMIT - you can write multiple DML operations, but the changes will only be saved when a COMMIT is made 2. ROLLBACK - you can discard any operations that have not yet been committed yet 3. SAVEPOINT - sets a point in the list of operations to which a ROLLBACK operation can rollback to Reliability MyISAM offers no data integrity - Hardware failures, unclean shutdowns and canceled operations can cause the data to become corrupt. This would require full repair or rebuilds of the indexes and tables. InnoDB, on the other hand, uses a transactional log, a double-write buffer and automatic checksumming and validation to prevent corruption. Before InnoDB makes any changes, it records the data before the transactions into a system tablespace file called ibdata1. If there is a crash, InnoDB would autorecover through the replay of those logs. FULLTEXT Indexing InnoDB does not support FULLTEXT indexing until MySQL version 5.6.4. As of the writing of this post, many shared hosting providers’ MySQL version is still below 5.6.4, which means FULLTEXT indexing is not supported for InnoDB tables. However, this is not a valid reason to use MyISAM. It’s best to change to a hosting provider that supports up-to-date versions of MySQL. Not that a MyISAM table that uses FULLTEXT indexing cannot be converted to an InnoDB table. Conclusion In conclusion, InnoDB should be your default storage engine of choice. Choose MyISAM or other data types when they serve a specific need. 

Multiple upstream Kapacitor servers are sending notifications to a load-balanced django app. If all the upstream servers are working correctly, the app will always receive duplicates of these notifications (since all the upstream notifiers should send the same notifications; it's just for redundancy). I want to be able to filter out these duplicates. However, since the python app is load-balanced, the only place we can check for these duplicates is in the database. This means I'm using this stored procedure to control application logic, just inserting the data with the hash into the database and ignoring duplicates is not an option (the application might do something like send someone an SMS message based on the contents of the alert, so we definitely don't want dupes) To do this, I'm hashing the messages, then invoking a stored procedure in the database that checks if a message received in the last 10 seconds had the same hash. I want to be 99% sure the stored procedure is safe against race conditions. Here's some SQL code that seems to work: 

Will this work as intended? DO I need to change the transaction isolation level? Is there a better way to do this in MySQL? Note I'm using MySQL 5.6 in one environment and Amazon RDS in another environment, so it should be as compatible as possible. 

This only seems to happen with ONE table (all other tables are fine). So we tried recreating the table, but the same problem persists. Any idea of what might be causing this issue? 

Log in with the user that has the User DSN entries that you with to convert to System DSN Open the Registry Editor and navigate to HKEY_LOCAL_CURRENT\SOFTWARE\Microsoft\ODBC\ Right-click ODBC.INI and select export to save it as a file on the desktop (or anywhere else you fancy) Open the .reg file with a text editor such as Notepad Replace the text HKEY_CURRENT_USER with HKEY_LOCAL_MACHINE. Save your changes Double click the .reg file and proceed to import it into the registry. 

I am trying to create a stored procedure that will allow us to duplicate values from the previous month into the current month -- BUT ONLY if there isn't a value for the current month already. 

Here is the answer. Even though the job was configured to run via a PROXY Account, the SQL Server Agent is still responsible for the job. I had a look and the SQL Server agent was configured to run under the Local System Account on that server. So what I did is to put the agent to run under the superuser admin account and it worked as expected. Now in this case the fact that the job no longer needs a proxy since the Server Agent itself is running under the ultimate account. However I appreciate that this is not the right way moving forward (even though this isn't my server and I hope I never get to touch it again!) I will be advising the customer to reconfigure SQL so every service runs under a dedicated domain account (i.e. created solely for this purpose), which is the way it should be! Now what I would love to understand is why the job would run as long as the proxy account used for scheduling the job was logged into the SQL server! 

CONTEXT: this isn't exactly a closure table. We need to have the full hierarchy in these other tables for quick access. For example, we need to be able to do joins on the complete set of parents (since stuff like permissions are inherited by sub-folders, so if a user has access to a parent, they have access to all subfolders). Therefore, the and (sorry about the naming conventions; I don't control that part) need to have a record of every item and every child of that item (transitively). Basically, we need to be able to check if a user tries to access a folder 5 levels deep what level of access that user has access to it, which can be granted at any level of the hierarchy. We also need to do some aggregations/sorting on stuff that joining the subfolders table would be helpful for (ie "sort on total number of items in this folder and all its subfolders"). The reason there are two tables is that we have one table for folders, and one for items. Folders and items have different ID spaces. Think of it like a filesystem with directories and files treated separately. A file ("watchlist") can't have any children, but a folder can have either folders or files as children. The code I posted above works for this. My concern is just with the concurrency and correctness in the face of multiple simultaneous clients. 

I have a table in my db that stored both successful and failed log-in attempts. I am creating a stored procedure that allow us to delete records which are older than X days old. So far so good, but I want to raise it a notch (or two) and allow us to specify whether to delete records on whether the [Success] column is true, false or both. I am having some issues with the concatenation of the script that needs to be executed, though. Here is what I did so far: 

As part of an ETL process, I need to copy a varchar field in table1 (staging table) which is meant to contain an integer value to a tinyint field in table2 (production table). However I am having some issues when trying to combine the following two business requirements: 

This immediately made me think that a ODBC driver mismatch might be the issue, where SSIS is looking for the 32-bit drivers. So here is what I did: 

(we ensure that Excel is connected to the deployed Tabular Model and not the user's workspace copy in Visual Studio) 

I have a date dimension table in which I need to add a new column in which I define the iteration of the day of the week within the month (2 for the second Mon/Tue/Wed/Thu/Fri/Sat/Sun etc). Is it possible to do this be making calculations solely on the date column of the table, which is of type 'date'? 

However, I'm very worried about the synchronization of all this and making sure we don't end up in a bad state if multiple queries are running concurrently. Because we have multiple nodes that could be accessing the database, concurrency at the application level is very tricky (we would need to use redis or something for locks, which I'd rather not do). I can use GET_LOCK and RELEASE_LOCK with a named lock, or I can use table locking. My fear with these methods is: what will happen if something goes wrong? The lock is held for the length of the session, right? We're using connection pooling (some services using Apache DBCP and others using Hikari), which reuses connections, and even without that, we might have transactions that do multiple operations. Since MySQL lacks any mechanism, I'm afraid we might get into some sort of deadlock situation. What's the best way to implement concurrency with this approach? Note that I only care about concurrency within the triggers/update process itself. It would be nice if other clients don't read an intermediate state, but it's not the end of the world. As long as it's eventually consistent, I can handle phantom/stale/whatever reads from clients that aren't doing updates. 

I'm trying to implement a hierarchy using closure tables maintained by triggers. I'm using MySQL 5.6. I know we should move out of the 90s and use a database that actually supports CTEs, but this is what we're stuck with for now. I've written this simple test database and procedures for now that seems to work: