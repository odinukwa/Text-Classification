You're right on track with using the context only from a single thread. You can only use an OpenGL context from one thread at a time, but you can do everything else in another thread. 

Since I get the idea that you have rolled your own custom game software, you might as well roll your own shader tool. If you show the GLSL compile errors you are halfway there. To bring the experience up to something realistically usable, integrate inotify into your shader loader, and trigger your engine to re-compile shaders when a change happens on disk. This will give you a truly What-You-See-Is-What-You-Get interface for developing GLSL code without wasting massive effort. You can then use any code editor and your own engine will provide live preview. (Works great with always-on-top or multi-monitor) EDIT: For windows you can use FindFirstChangeNotification 

And for good measure, here's the tool I wrote to generate those images. Using SDL and plain C, I called it "hbm2tnm.c" (Height Bump Map to Tangent Normal Map) 

Sampling the heightmap with a clamping mode produces an output like such: Or with a wrapping mode, produces what was shown in your comment: (Including the errors around the border) 

You've already got most of the setup. What you could do is just control the Campfire from the other collider inside the Collision method [untested code] : 

From my experience recently in doing a few 3D animations, I found it very simple to just split up the animation into 3 separate clips. That way I felt that it was quite intuitive and easy when creating transitions between each animation clip in each stage of the overall animation. You also have a great deal more control over the animation transitions using this method. If you split the animation up then just ensure that when you import the animations that you check the Loop animation check box in the Animations tab for the middle climbing animation clip and you should be good to go. You can then also use State Machine Behaviours to drive any additional actions like playing sounds or effects etc during each clip. I'm sure you could also perform some complex looping logic as you allude to, however that seems unnecessarily complicated and error prone in my opinion. 

$URL$ If you're using Aron Granberg's pathfinder, then are you perhaps using one of the smoothing modifiers? This would result in the unit trying to optimize the path which would probably prevent the unit from hitting each node as it steps through the path. Or is the problem that you have a consistent offset when the unit paths from node to node? 

One way to accomplish this would be to use an FBO (Frame Buffer Object) and multiple depth buffers and/or depth textures. A basic use case is shown on the Wiki at OpenGL.org. 

This answer will focus on statement #3 in the original post, and is meant to supplement ToddersLegrande's answer 

Ugly. But we have a closed form solution in time :) Before we can solve for the parameters you're interested in, we have to address one small ambiguity: The damped harmonic oscillator never stops, only decays. I will use a threshold where we consider motion "stopped", and solve for the peak which attains this amplitude. Now, from the solution above, I have obtained that the set of peaks are generated by: 

Basically the same as JasonD's answer, except using bitwise operations instead of absolute value function. This is assuming you have 16-bit short integers! 

One reasonable approach would be to use a loop to update your X and Y, and draw again repeatedly. This would involve computing delta time, and using it to animate your coordinates. Here's an example jsfiddle: 

The Pannini projection, for example, can capture wide fields of view in nice ways. (totally just my opinion) I think implementation details would be beyond the scope of this specific question. 

A great explanation of a well known voxel chunk system can be found in the minecraft wiki Regardless of how you want to store the data programmatically, the ability to generate smooth flowing infinite voxel terrain comes down to a smartly optimized neighbouring chunk loading system. "The exact number of generated chunks varies in single player mode, depending on view distance and movement. In multiplayer mode, a grid with a default inradius of 10 (for a total of 21x21 or 441) chunks is loaded around each player and sent to the player by default, although this can be configured to be between 3 and 15, usually only lowered with a poor connection home server. These chunks may have activity (mobs spawning, trees growing, water flowing, dropped items disappearing etc.), while the other world chunks are inactive, stored on your hard drive. Chunks will not save again if they were saved in the last 30 seconds." So effectively in a player driven game like minecraft you're only ever creating/loading a small number of chunks around your player at any time. It's quite tough to troubleshoot your slow chunk loading issue without more information or code examples etc. 

Wouldn't it be simpler to just use some integer state logic to drive the match comparisons? For example you could just keep track of each Tile's state and colour and do numerical comparisons instead of interrogating the actual texture of each gameObject? This has the added value of using a single Texture Atlas to store your tile textures and then just map to that Atlas as per the norm if a tile needs to change via a user mouse click. A quick comparison example for you to Ctrl-F5 (if you run it a few times you'll get a match) : 

Since you have an angle in the range of , you can make the range positive without rotating the angle by adding (360Â°). Now your angle is in the range of . You can adjust the range without rotating the angle by computing the modulus: . The resulting angle has the same direction, but is now in the range . 

I arrived at my assumptions because your offsetting code in the vertex shader seems to indicate that your variable is measured in pixels, not normalized: 

I didn't check thoroughly, but one major problem I see here is that you aren't following the OpenGL manual: This line of code is never valid: 

A less effective, but simpler, approach would be to use a fixed timestep. This can be achieved with a function like or . Be warned there are issues with these routes: might create a queue of frames to draw faster than they can be pushed. might leave you waiting too long for your next frame. With that said, here is another example jsfiddle 

You are using sampler 0 for every single texture, you should fix this call so that it looks more like: 

Long answer: (pre-calculus required) Define your jump function which is a simple integral over time: 

I know some people frown on link dumping, however I found this to be a very enlightening paper, and it obviously conveys way more than I could elaborate on : $URL$ 

I found it a little bit difficult to follow the entire thread of your question. However at the most basic level, in a simple FSM you could either just query the current state of your StateMachine (i.e. assuming its a singleton manager class etc : StateMachine.Instance.GetState ) and then do the necessary long-winded if or switch statement logic depending on which state is returned. Alternatively, for something a bit more loosely coupled and dynamic you could just have each relevant Class subscribe to a OnStateChanged event equivalent and react to specific states with callbacks. There isn't a right way to implement a FSM, however you can take a steer from one of the many online resources eg: $URL$ $URL$ ------ EDIT UPDATE ------ The idea is that if you're going to roll your own GameStateManager in the Unity engine, then each state would essentially have it's own methods such as Update etc. These methods would execute sequentially as per the norm. You could manage your state transitions with a State stack container. This way multiple states could be queued up and pushed into the stack, and then executed in order i.e. GameState-->MenuState-->ControlsMenuSubState etc. At the end of each frame you could then do some bookkeeping and check if it's OK to roll onto the next state i.e. pop the current state and then execute the next state object on the GameState stack. It does sound like you're overcomplicating things by coupling each class to each State of the game. The classes generally shouldn't know or care which state they're in as it's the State's job to call into other classes, not the other way around. Unity's normal Scene methodology is also suitable. You could just use Scenes to transition between major games states, and then use the Unity GUI for Overlay states such as Inventory or Menu states which need to run in the current state. All you would need is at least 1 object to maintain your meta game state between scene transitions. 

The "best" option is to try it yourself and see what's faster. I will put my money on option 1 being faster. You will only gain performance benefit this way if the pillar is incredibly expensive to draw, and you use effective culling. 

One way to circumvent the accumulation of rounding errors is to re-normalize your vector when you calculate . This might look like such: 

But in order to retain flexibility in situations where multiple handlers may need to observe the event, "Bubbling" can be applied so that all handlers get to see the event: 

Lazy loading! Add a method to SpriteComponent to let it store the name of the new sprite to load, then let the SpriteSystem load the actual data whenever it comes into play. To smooth out the loading laggies, preload. 

I have obtained an implicit solution, and although it looks like it could maybe be solved by the W function in closed form, we would then need to implement the W function in C++, so I have not investigated that. Instead, I have taken the approach of reformulating the problem as root-finding, and numerically approximating the soluiton using Newton's Method. This strategy has yielded the following fixed point iteration: 

A quick test, just grab the logo image from the SFML site and paste it into the working directory of your project (or just somewhere simple and explicitly state that in code i.e. "C:\test\img.png") 

When importing the animation there is a 'mirror animation' checkbox under the Animations Tab in the Inspector for that asset. If you check that box and rename the animation to "myanimation_mirror" or whatever then you should have 2 mirrored animations. 

Additionally, I've noticed that you're loading a new texture for each block. This kind of defeats the object of using a texture. With a texture you want to load it once into video memory and then point all of your sprites to that once instance to reduce draw calls and memory requirements etc (aka batching your draws). In 2D games using the concept of one large texture atlas is very common because it's so efficient. You could have a variety of block textures all tightly packed into one 'blockTypes' texture and then just use 'sprite.setTextureRect' to refer to different sections of that texture as mentioned above. I'd just throw a few texture atlases into a map so that you have a single texture dictionary to refer to in all of your block objects. 

Sounds like you are asking for a convex hull, this is sortof like "gift wrapping" all your vertices. (Otherwise, if the shape can be concave you cannot imply it by the vertices alone) Wikipedia has a good list of techniques here: $URL$ And google code even has an implementation (I haven't tested this): $URL$ 

Variance shadow mapping, plainly put, just suffers from these light bleeding issues. I personally prefer to implement ESM (check out page 257 of ShaderX6) as the memory pressure is half of the VSM map and the artifacts are much less abrasive to me: (The very beginning of the shadow is a bit too bright.) With this said, here is a (rather old) PDF full of great techniques to get you thinking. (or just to show you the algorithm if you don't have ShaderX6) $URL$ In my current engine, I have a hybrid which is basically ESM, but uses the 2-moment (or higher) shadow map to compute the variance and reduce the ESM artifacts at the places where the occluder is too close to the receiver. 

Which appears to be right on target, crossing 4 times to achieve a peak value of 0.01, after 5 seconds of simulated time. 

Using a 2D tile array for your world/level generation and representation will definitely simplify things. For example you could internally represent your world in a grid of tiles and take it from there : 

in each Update() call. targetPos can just be a gameObject in your scene indicating a position to the left, just outside of the visible screen space (at which point you can kill/recycle your pillar). If you need objects which have their own speed then alter or add to the 'speed' variable for each required gameObject. For example a projectile being shot by a trap towards the player from right to left might be moving at playerSpeed + bulletSpeed etc. On the topic of recycling objects : instead of instantiating a new gameObject for each obstacle such as pillars, especially in a tight loop or Update() function, instead investigate object pooling in Unity where you can just keep recycling from a pre-allocated list of gameObjects. --- EDIT forgot you're using rigidBody ---- After you instantiate each pillar with an initial velocity (moving towards the player from right to left) then it sounds like you could then use an InvokeRepeating or something similar to fire off an increase in speed of each subsequent pillar by just adding force to the current velocity : 

This time the Adjusted Jump Speed is being forced non-negative; If the player is already rising faster than they should be able to jump, they would attain a negative adjusted speed, which allows them to use the "jump" action as brakes. (to slow down to the intended jump speed instantly!) Note: I believe your contact X and Y are already normalized as a pair. I included explicit detail for completeness sake though. 

(although, I think maybe you wanted this one that accounts for gravity but can be used to calculate any possible jump) 

Which is our answer, notice that time is still unknown in this system. This means there are infinite trajectories that will land on the purple rectangle. You have to decide how long it should take. 

The simplest way to take advantage would be to do all the loading as you normally would, but send some kind of "event" back to your main thread to actually call the OpenGL upload with everything already prepared. 

The texture sampling function expects texture coordinates to be normalized into the [0 - 1] range. You can divide by the size of the DuDv map in pixels, to normalize your texture coordinate into the [0 - 1] scale. For the sake of efficiency, I prefer to evaluate on the CPU, and use multiplication instead of division in your shader.