You can't do this directly: the credential manager isn't actually designed to serve private/public key pairs but to hold passwords. You can, however design a workaround: get keepass 2 and the "Keeagent" extension. remove pageant since it will conflict with keeagent. Once both are installed and running, create a database and link it to your current user account. After that, create a new entry in keepass, add the private key file as attachment to that entry, use the private key password as the entry's password and set your 'nix username as user name. Then go to the KeeAgent tab of the entry and enable it to be used in agent. You're done. When you now connect to a system that uses agents (putty, mostly), you will be prompted for the keepass database password which is actually only the user account: just press enter and you'll be in. Be careful to keep a safe backup of the key, however, since you WILL lose access to it if you have to delete your windows user account. Of course, it would be much safer (and quite a bit more flexible) to secure the keepass database with a password and a key file. If you're willing to do so, you'll be able to use it for all your passwords needs (personally, after going down that road years ago, I can't imagine going back). 

IIS doesn't do anything special when generating a self-signed certificate so you can use and tool for that. For instance, you can use Powershell. This one-liner will create a self-signed certificate for the DNS name valid for 5 years, with no password and place it into the local machine certificate store (it requires elevation). 

After a recent incident with Outlook, I was wondering how I would most efficiently resolve the following problem: Assume a fairly typical small to medium sized AD infrastructure: several DCs, a number of internal servers and windows clients, several services using AD and LDAP for user authentication from within the DMZ (SMTP relay, VPN, Citrix, etc.) and several internal services all relying on AD for authentication (Exchange, SQL server, file and print servers, terminal services servers). You have full access to all systems but they are a bit too numerous (counting the clients) to check individually. Now assume that, for some unknown reason, one (or more) user account gets locked out due to password lockout policy every few minutes. 

Not in a generic manner. You can restrict the access to the database server to trusted users but trying to achieve perfect (or even descent) security using code obfuscation is a pointless waste of time and resources in most (if not all) cases. Edit: there is one thing that you can do to make it a tinny little bit harder to see exactly what is happening in you code is to write it as a CLR stored procedure. It's not going to slow someone competent very much but it'll make it harder to follow what's going on just using the SQL debugger. 

There are many tools available to help you track down issues like this. Start with the performance monitor which is provided with your OS. You can set it up to take periodic snapshot of pretty much any metric you can think of, including individual memory usage per process. In your case, that's probably the best tool for identifying rogue processes. Also process explorer, which you'll have to download, is a very good way if looking into all processes of your system. It will allow you explore your system state in a very detailed way. Finally, you can use process monitor, also a separate download, to watch a particular process activity in detail. 

Check the default document: in your screenshot, you're not specifying any PHP file, just a path. More detailed explanation: By default, no modern web server will just serve a directory listing when the user doesn't specify a document but just a path (e.g. $URL$ so they all have a parameter that specify what document in a folder should be considered the default one to serve if the URL isn't specific. In IIS 7.5 (running on Windows 2008R2), that list is, by default, in this order: default.htm default.asp index.htm index.html iisstart.htm default.aspx So either try to access to you main page explicitely $URL$ or add it to the list of default documents. 

Without knowledge of what hardware and software you're using, it's difficult to give you more precise answer. 

I also made sure that the other app is NOT bond on 0.0.0.0:443 but uses the specific IP address. Finally, I ran and got this: 

NSlookup is a DNS lookup tool. It can be used in interactive mode to query many different record types but, when used from the command line, it will either try to perform a standard forward-lookup of an IP based on the provided host name or a reverse lookup if the input is an IP address. So, if you enter a random IP address, here is what happens: 

Technically, you could write an update script that copies the new data from the production to the test system but not only is that going to be complex, you're also going to run into problems that are far from trivial to solve: 

You didn't look very far: Start the IIS manager MMC, select your folder and you'll see "IP address and domain restriction" in the middle pane, in the "IIS" section. Double-click on that and the then: 

Simply put: yes, it can. It's not as straightforward as that, though: you'll need to configure the environment before you can really use it, but it's not that complex. The simplest, really, is to get an Amazon WS account and try it for yourself: it'll cost a couple of dollars at most. 

This error is the one IIS throws if IP:Port it tries to bind to is taken and yet netstat clearly say it is available. What am I missing ? Edit: There are two events in the system event log when I attempt to start the service: 

For creating self-signed certs, you have plenty of options. The simplest one, if you're a windows shop, is to do it through IIS (see this: $URL$ You can also do it with OpenSSL (quite messy but works), with the makecert.exe tool that comes with the .NET SDK or with a number of similar tools (I use my own tool for this but, that's just me). For integrating a CA with AD, the simplest way is to install the certificate services role on a machine and configure it for AD integration (although in your case, it doesn't seem to be a necessity unless you want to use it for other things). Finally, you might want to create your own root that isn't integrated with AD. Unless you have to work with client certificate authentication, have many different servers (with different names) that you want to use in testing (and perhaps with automated testing) or if you want to be able to test some aspect of your application that uses special certificate properties or chaining, it's probably not worth the trouble. In your case, assuming I understood it correctly and all you want to do is test your web app with a certificate, all I would do is generated a self-signed cert (using whatever tool you like best) and then install that certificate in the correct store on your test machine (to avoid certificate warnings and errors) 

Get the memory dump or at least, the minidump. In your case, since the machine doesn't start, you can do it by mounting the system VHD from the host (it's usually located in the c:\windows\minidump or directly at the root of the C drive, but that can change) Save the dump on a machine that has the Windows Debugging Kit installed (see there). Run dumpchk.exe from the WDK with the parameter. That will tell you more precisely what happened and give you more indication about the probable cause of the bugcheck. 

SQL server 2008 has two modes of operation: one is high-safety mode in which the mirroring is synchronous: a transaction isn't commited until it has been written to the mirror. In that mode, the only data that you can lose if from the uncommited transaction. The second mode is high-performance. In that mode, the transaction is marked as comitted on the principal as soon as possible without waiting for the mirror. It will allow the system to continue to work even if the connection between principal and mirror is temporarily broken but, of course, you will lose all transaction that haven't been copied yet if you perform a manual failover. See this link for details: $URL$ 

You used the "NORECOVERY" flag which indicates to SQL server that you want to restore additional T-log backups. You should have used the "RECOVERY" flag instead (or nothing as this is the default). To recover, either recover the missing T-logs or, if you don't want to restore any more logs, issue the following statement: 

Simplest way to work around these kind of issues is to use a content delivery network (CDN). Just host your downloadable content with the CDN of your choice and let them handle the load. Otherwise, there are DDoS protection services that can protect your whole web site. 

Have you tried installing it in the recommended fashion for installing TS apps ? You need to either start the installer through the "install" buttong of the add/remove contraol panel applet or run the "change user /install" command-line first (and run "change user /execute" once you're done). 

If you want to use the event log instead, then you can use the built-in eventcreate command like this: 

You should have a feature named and another named To install the GUI shell from the powershell prompt, you can use: 

Intrusion incident analysis is never easy, in particular if you haven't followed standard procedure for recovery (take physical server off-line, grab a sector image of all file systems it has access to, rebuild machine completely from install media, restore data). Typically, you would review all the logs files fist, starting with the Apache logs. The most likely attack vector is, in your case, drupal but it's by no mean the only possible one so all logs should be checked (I mean ALL logs). Depending on the file system you're using, additional steps can be taken to identify what activity took place at the time of infection and figuring out both the attack vector used and what was done. Meanwhile, check all the software your machine is running and make sure it's all up to date. That includes all your drupal modules, themes, etc. I'd also check any custom code with a comb. Edit: I forgot to mention the fact that, in your case and since you apparently don't have the relevant expertise in house, you might want to consider contracting the incident to a security company that does forensic analysis: it might be a bit on the expensive side, but you'll get clear answers about what happened and how to prevent it. 

You can mix SAN certificates and wildcard certificates, thus creat a single certificate that can be used for all your domains. However, IMNSHO, The best way to handle this is really to assign a single IP per 2dn level domain and the use a SAN or wildcard cert for sub-domains and different hostnames. The main reason for this is that if you try to put all your certs through the same IP, you will run into trouble when you want to add or remove a domain or host because any change to the published list will require you to request a new certificate. This can end up being pretty expensive, quite a bit more than getting a handfull of IP addresses. Also, public CAs typically limit the number of SAN that you can include in a si^ngle cert.