The argument is the same, there are only $1 + 2 + 4 + ... + 2^{\delta n - 1}$ programs shorter than $\delta n$ so there are at least $2^n - (2^{\delta n} - 1)$ integers with $K(x) \geq \delta n$. 

Here is an attempt to prove that the problem without the reverse condition is NP-hard. The basic idea is that disjoint intervals in $S$ like this one: 

The Hamiltonian path problem on grid graphs with maximum degree 3 is NP-complete. The proof is in C. H. Papadimitriou and U. V. Vazirani, On two geometric problems related to the travelling salesman problem, Journal of Algorithms, Volume 5, Issue 2, June 1984, Pages 231–246 (Theorem 2) 

I'm not an expert, but perhaps some (not-so-natural?) examples can be directly derived using the technique of deterministically reducing BPP search problems to BPP decision problems, presented in: Oded Goldreich, In a World of P=BPP. Studies in Complexity and Cryptography 2011: 191-232 In particular see Theorem 3.5: (reducing search to decision): For every BPP-search problem $(R_{yes},R_{no})$, there exists a binary relation $R$ such that $R_{yes} \subseteq R \subseteq (\{0, 1\}^∗ \times \{0, 1\}^∗) \setminus R_{no}$ and solving the search problem of $R$ is deterministically reducible to some decisional problem in BPP, denoted $\Pi$. Furthermore, the time-complexity of the reduction is linear in the probabilistic time-complexity of finding solutions for $(R_{yes},R_{no})$, whereas the probabilistic time-complexity of $\Pi$ is the product of a quadratic polynomial and the probabilistic time-complexity of the decision procedure guaranteed for $(R_{yes},R_{no})$. The theorem can be extended to general construction problems, for example (see Corollary 3.9) consider the problem of finding a prime in a large enough interval : For any fixed $c > 7/12$, on input $N$, find a prime in the interval $[N, N + N^c]$ The randomized algorithm runs in expected polynomial time; no deterministic polynomial time algorithm is known; but if BPP=P such deterministic polynomial time algorithm must exist (because it can be reduced to a BPP-decision problem). 

No, this is not new; range searching with multilevel B-trees is completely standard. See, for example, the following surveys: 

MaxCut can be solved in polynomial time in $K_5$-minor-free graphs but is NP-hard in $K_6$-minor-free graphs (in particular, for apex graphs of planar graphs) [Barahona 1983]. See also this WG 2010 paper and slides by Marcin Kamiński. 

The solution is $T(n) = \Theta(\log n /\log\log n)$. (I'm assuming the $O(1)$ term in the recurrence is really $\Theta(1)$, since otherwise $T(n)$ has no lower bound.) As you and Tsuyoshi already observed, you can derive a lower bound by overestimating the denominator in the recursive argument. Consider the function $L_k(n)$ defined by the recurrence $$ L_k(n) = L_k\left(\frac{n}{\log k}\right) + \Theta(1). $$ The solution $L_k(n) = \Theta(\log n / \log \log k)$ follows from standard methods. An easy inductive argument implies that $T(n) \ge L_k(n)$ for any $k\ge n$. Thus, setting $k=n^2$ (for example) immediately gives us $T(n) = \Omega(\log n/\log\log n)$. For the upper bound, the symmetric trick is to under-estimate the denominator in the recursive argument. Consider the function $U_k(n)$ defined by the recurrence $$ U_k(n) = \begin{cases} U_k\left(\frac{n}{\log k}\right) + O(1) & \text{if } n \ge k,  \\ T(n) & \text{otherwise.}\\ \end{cases} $$ An easy inductive argument implies that $T(n) \le U_k(n)$ for any $k\le n$. Assuming inductively that $T(n)$ is a nondecreasing function of $n$, the solution $$ U_k(n) \le T(k) + O\left( \frac{\log(n/k)}{\log \log k} \right) $$ follows from standard methods. Setting $k=\sqrt{n}$ gives us the simpler(?) recurrence $$ T(n) \le T(\sqrt{n}) + O\left( \frac{\log n}{\log \log n} \right), $$ which is easy to solve by standard methods. I'll walk through that one, too. Multiply both sides by $\lg\lg n$: $$ T(n)\lg\lg n ~\le~ T(\sqrt{n})\lg\lg n + O(\log n) ~=~ T(\sqrt{n})(\lg\lg\sqrt{n} + 1) + O(\log n). $$ Setting $LT(n) = T(n)\lg\lg n$ gives us $$ LT(n) \le LT(\sqrt{n}) + T(\sqrt{n}) + O(\log n). $$ Assuming inductively that $T(n) \le 10^{10^{100}}\lg n$ for large enough $n$, the recurrence simplifies further to $LT(n) \le LT(\sqrt{n}) + O(\log n)$. This recurrence expands into a geometric series, implying the solution $LT(n) = O(\log n)$, which implies $T(n) = O(\log n / \log\log n)$. Hey look, all our inductive assumptions worked out! Short version: Logarithmic factors usually act like constants in recurrences, because they change so slowly. The details are often grungy, but straightforward with a little practice. (A glaring exception is the recurrence $T(n) = T(n/2) + \Theta(n/\log n)$, whose solution is $T(n) = \Theta(n\log\log n)$.) 

Note: if a plate can only open/close a single door, then you can add an auxiliary structure with (long) one way corridors that (de)activates the distinct state doors of each cell. 

This is a reduction from Clique to your problem . We start with an instance of Clique: a graph $G$ and an integer $k$, let $V = \{ v_1, v_2,...,v_n\}$. Clique remains NPC even under the constraint that $max(deg(v_i)) \leq 2(k-1)$ (proof sketch: if $max(deg(v_i) > 2(k-1)$ then add a $K_t$ where $t = 2(k-1) - max(deg(v_i))$ and connect it to all nodes of $G$ and ask for a clique of size $k' = k + t$ in the new graph). So we assume that in $G$, $max(deg(v_i)) \leq 2(k-1)$. For each node $v_i$ for which $deg(v_i) < 2(k-1)$ we create an "external" clique $C_i$ of size $2(k+1)+1$ (every node of $C_i$ clique has at least $2(k+1)$ neighbours). If $deg(v_i)$ is the degree of $v_i$, we connect $v_i$ to $2(k-1) - deg(v_i)$ nodes of $C_i$. In the resulting $G'$, each $v_i$ has degree $2(k-1)$; so $|A| \geq k$ because at least one vertex must be selected. It is clear that if one of the vertex of $C_i$ is included in $A$ then at least $2(k+1)/2 = k+1$ nodes must also be inserted in it. Note that if an original node has $deg(v_i) < k-1$ then at least one node of the linked $C_i$ must be included, leading to $|A| > k$. So we can build a set $A$ of minimum size $|A| = k$ if and only if $G$ contains a clique of size $k$. An example of the reduction in which we ask if the graph $G$ represented by the yellow nodes and bold edges contains a clique of size $k = 3$ (a triangle). 

Immediately and publicly admit the mistake. Explain steps 2 and 3. Give every student full credit for the problem. Yes, even if they submit nothing. Grade all submitted solutions normally, but award the resulting points as extra credit. In particular, give the usual partial credit for partial solutions. 

This is one is common to computational geometry, but endemic elsewhere: Algorithms for the real RAM can be transferred to the integer RAM (for integer restrictions of the problem) with no loss of efficiency. A canonical example is the claim “Gaussian elimination runs in $O(n^3)$ time.” In fact, careless elimination orders can produce integers with exponentially many bits. Even worse, but still unfortunately common: Algorithms for the real RAM with floor function can be transferred to the integer RAM with no loss of efficiency. In fact, a real-RAM+floor can solve any problem in PSPACE or in #P in a polynomial number of steps. 

No, the intuitive observation "There are about $\sqrt{n}$ prime factors to try" does not imply a lower bound on the complexity of factoring. There is absolutely no reason that a factoring algorithm must try every possible prime factor, or even that the algorithm's behavior should resemble "trying" different factors at all. Even though precisely the same intuitive argument can be applied to checking whether a number is prime, the AKS primality-testing algorithm runs in $\log^{O(1)} n$ time. 

Just an extended comment to include the picture: if the following (random) resistor network is valid then the max current flow 33.9mA is not on the shortest path from $s$ (+5V) to $t$ (GND). 

But there are many other puzzles/videogames that are directly inspired by the Hamiltonian circuit/path problem: Inertia, Pearl, Rolling Cube Puzzles, Slither,... ... and the "hardness" of HC makes them addictive: even small instances can be very hard to solve for our brain!!! 

$F$ needs only a limited look-ahead buffer (4 symbols) to make the rewrite and also to perform the $w+1$ operation; the internal states of $F$ embeds the internal states of $M$ so it can simulate the transition function $\sigma$; 

The problem is also knwon and heavily studied as Dynamic Vehicle Routing Problem (or On-line vehicle routing problem): It differs from the static counterpart because: 

From the comment above: if a problem seems hard enough, but you are not able to prove that it is NP-complete, a quick check is to count the number of strings of length $n$ in the language: if the set is sparse it is unlikely to be NPC, otherwise P=NP by Mahaney's theorem ... so it's better to direct efforts towards proving that it is in P :-) :-) An example is the problem of partitioning numbers into k-boxes (from Fortnow & Gasarch's blog, original source: Doctor Ecco's Cyberpuzzles): $\{ (n,k) \mid \text{ there exists a way to partition }$ $\{1,...,n\} \text{ into at most k boxes so that no box has } x,y,z \text{ with } x+y=z \}$ 

Chazelle, Liu, and Magen's paper Sublinear Geometric Algorithms (STOC 2003, SICOMP 2006) has several clever applications of the following random sampling trick. Variations of the same trick were previously used by Gärtner and Welzl [DCG 2001], who cite the first edition of CLR (1990). Suppose we are given a sorted circular linked list of numbers, stored in a contiguous block of memory. That is, we have two arrays $Key[1..n]$ and $Next[1..n]$, where 

For example, here is a recursive formulation of Borůvka's minimum spanning tree algorithm. I've previously defined $G / L$ as the graph obtained from $G$ by contracting all edges in the set $L$, and Flatten as a subroutine that removes loops and parallel edges. 

As the figure hopefully suggests, this algorithm breaks the input array into chunks of size $k/2$, and then applies bubblesort to the chunks, using the $k$-sorter in place of a compare-exchange operation. Correctness follows by observing that the network correctly sorts any array of 0s and 1s. As @VinayakPathak's comment suggests, the $O((n/k)^2)$ bound can be reduced by replacing bubblesort with a different sorting network. For example, Batcher's even-odd mergesort reduces the number of black-box calls to $O((n/k)\log^2(n/k)) = O(\sqrt{n}\log^2 n)$, and the AKS sorting network reduces it to $O((n/k)\log (n/k)) = O(\sqrt{n}\log n)$. This last algorithm matches Neal's non-oblivious algorithm up to (large!!) constant factors. 

The aim of the game is to choose a valid configuration for each cell (the type and the rotation cannot be changed) in such a way that no two green squares are adjacent (vertically or horizontally). The game is NP-complete (a quick reduction is from planar 3SAT). 

The Generators can simply insert into the MESSAGE table their requests (and optionally fill the SEQUENCES table): 

Answer converted from comment. Definition: 1-in-$k$ SAT is a $k$-SAT problem with the tighter condition that - given a truth assignment to the variables - each clause must contain exactly one true literal (and thus $k$-1 false literals). See for example 1-in-three SAT on Wikipedia The reduction from 1-in-$k$ SAT to $k$ SAT can be done easily. 

From the comment above: you can use the same oracle $A$ used in: Richard Beigel, Harry Buhrman, and Lance Fortnow. 1998. NP might not be as easy as detecting unique solutions. In Proceedings of the thirtieth annual ACM symposium on Theory of computing (STOC '98). for which $P^A= \oplus P^A \neq NP^A = EXP^A$ ($EXP^A=NP^A\subseteq PSPACE^A$ also holds) 

Knot triviality: Given a closed polygonal chain in 3-space, is it unknotted (ie, ambient-isotopic to a flat circle)? This is known to be in NP by deepish results in normal surface theory, but no poly-time algorithm or NP-hardness proof is known. 

The white king can capture at least $hn^2+4n$ opposing pieces—every piece in every hoard, plus four additional edge pieces per vertex—if and only if the graph $G$ is Hamiltonian. 

If the underlying surface is orientable, we can choose a global "clockwise" orientation, which means any embedding onto that surface has a representation where all edges in $G$ are positive. On the other hand, if the underlying surface is non-orientable, some edges must be negative. Any one-sided cycle must include an odd number of negative edges (and therefore at least one negative edge), because moving once around a one-sided cycle reverses your local orientation. That's what "one-sided" means. Still, it is possible to ensure that every edge in your favorite spanning tree is positive. The proof is straightforward induction over the tree $T$. 

Up to my knowledge the current "limits" have been settled in: Stefan Porschen, Tatjana Schmidt, Ewald Speckenmeyer, Andreas Wotzlaw: XSAT and NAE-SAT of linear CNF classes. Discrete Applied Mathematics 167: 1-14 (2014) See also Schmidt's Thesis: Computational Complexity of SAT, XSAT and NAE-SAT for linear and mixed Horn CNF formulas Theorem 29. XSAT remains NP-complete for $k$-$CNF^l_+$ and $k$-$CNF^l$, $k, l \geq 3$. (XSAT for $3$-$CNF^3$ is exactly 1-in-3-SAT where each variable appears exactly $l=3$ times) Note that the theorem also proves the NP-completeness of the stronger monotone case ($CNF_+$) 

UPDATE: the answer below is not correct, because I wrongly assumed that the Hamiltonian path is in an arbitrary graph, not in $K_n$. I leave it undeleted, perhaps I'll be able to fix it or it will give some hints for another answer. I think it's NP-complete. This is a very informal/quick reduction idea from 3SAT For every variable $x_i$ add a "variable gadget" with: