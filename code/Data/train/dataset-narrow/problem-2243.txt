I have a square plate of size 1x1, full of lots of skittles. I want to eat all of the skittles, but the only way I can get the skittles is through these two oracles: $f(x, y, r)$ tells me how many skittles are in the circle of radius $r$ centered about the point $(x,y)$ on my plate $q(x, y, r)$ gives me all of the skittles that are in the circle of radius $r$ centered about the point $(x,y)$ on my plate However, my plate is very big, and my oracles are very small. So the $r$ given to $f$ and $q$ must be less than or equal to a given value $R$. Oracles don't come free these days: I have to pay a cost of 1 each time I call $f$. Each time I call $q(x, y, r)$, I must pay a cost of $f(x, y, r)/P$: 1 for each $P$ skittles that my oracle brings to me (rounded up). The $P$ is an input to this problem. Then those skittles are eaten. There are $N$ skittles on my plate. What is a strategy that doesn't cost very much to eat all of my skittles, in terms of $N, R$, and $P$? I'm curious about two cases: 

I think your question is closely related to the set reconciliation problem, which is solved in this paper: $URL$ The problem of set reconciliation is to given two sets $A, B \subseteq [n]$ find $A \backslash B$ and $B \backslash A$ with as less communication as possible. If $B = [n]$, then you just need to find $\bar A$. Authors provide an algorithm with $O(k \log n)$ communication complexity. Basic idea of the algorithm is to find small prime number $p$ greater than $4n$ and compute next two polynomials $\chi_A(x) = \prod_{a\in A} (x - a)$ and $\chi_B(x) = \prod_{b \in B} (x - b)$ in $\mathbb{F}_p$ on $2 \cdot k$ different points. It can be easily shown that $$\frac{\chi_A}{\chi_B} = \frac{\chi_{A \cap B} \cdot \chi_{A \backslash B}}{\chi_{A \cap B} \cdot \chi_{B \backslash A}} = \frac{ \chi_{A \backslash B}}{ \chi_{B \backslash A}}.$$ If you compute these polynomials in non-zero points (for example, greater than $n$), then you obtain $2 \cdot k$ equations of the form $$ \chi_{A \backslash B}(x_i) \cdot b_i = \chi_{B \backslash A} \cdot a_i, $$ where $a_i$ and $b_i$ are corresponding values of $\chi_A$ and $\chi_B$ at $x_i$. System of $2k$ equations with $2k$ variables over field $\mathbb{F}_p$ can be easily solved. The last thing is to factorize polynomials. The authors provide easy algorithm for this case. Turning back to your first question $\chi_{\bar S}(x)$ can be expressed with your $s_i$'s for $i$ from $0$ to $k$. 

Given any undirected edge-weighted graph (with weights > 0) and some dimension d, is there a way to assign positions in $\mathbb{R}^d$ to those vertices such that all of the edges between them have euclidean distance equal to their weights? The resulting edges may be crossing, that is okay. I'm really interested in the decision problem of when it is or isn't possible but an efficient algorithm to do it when it is possible would also be nice. 

MA In this case, the prover simply sends it's proof $\pi$ to $V$, and then $V$ examines this message, generating random coins as desired, and then returns $V(x, \pi, r)$. A language $L$ is in the class $MA$ if has a protocol in this manner such that 

The blank symbol is a $0$ The tape alphabet is $\{0, 1\}$ The input to our turing machine is always nothing (the tape is always initialized to only containing $0$'s) There are only $n$ internal states, for some $n \in \mathbb{N}$. 

Are there any problems that are solvable in polynomial time only if P!=NP, and otherwise solvable in (say) $O(2^n)$ time? A simple example would be: If P!=NP, compute a primality test for a random n-bit number, otherwise, evaluate a random worst-case position in generalized chess of a nxn board with 2n pieces on each side. That seems kinda hacky though. Are there any more natural examples? 

The Eulerian cycle problem with "transition" costs $f$ is NP-hard by reduction from the Traveling Salesman Problem (TSP). Specifically, for any TSP instance given as a complete weighted graph on vertices $V = \{v_1,v_2,...,v_n\}$, encoded via the cost function $d : V \times V \rightarrow \cal{R}$, we can transform this into your problem in polynomial time as follows. First, create a graph with a single "anchor" vertex $x$. Then, for each vertex $v_i \in V$, create a (self-looping*) edge $e_i = (x,x)$ with cost 0 (you can envision these self-loops as the separate "petals" of a flower-like graph in two-dimensions anchored around $x$). Finally, create a transition function $f$ (as per your definition) such that $f(x, e_i, e_j) = d(v_i, v_j)$. All Eulerian cycles (with transition costs from $f$) in this case are thus in 1:1 correspondence with all Hamiltonian cycles (i.e., solutions) of the original TSP instance and have equivalent cost. So if you can find a minimum-cost Eulerian cycle with such transition costs, then you can solve TSP to optimality, completing the reduction. *Note that the self-looping edge encoding is not necessary, but it simplifies the description somewhat for the purposes of discussion above just to give the intuition (and your encoding seems to allow this). These self-loops can actually be broken up into separate "triangle" sub-graphs ($K_3$ gadgets), all anchored at the shared node $x$ whose edge transitions to other such gadgets are assigned costs accordingly from $d$ (but in a slightly-more-detailed manner). 

In the formal description of Deterministic Pushdown Automata, they allow $\epsilon$ moves, where the machine can pop or push symbols onto the stack without reading a symbol from the input. If these $\epsilon$ moves aren't allowed, and the stack can only be modified once after each symbol read, are the resulting automata equal to power to DPDAs? There may be something trivial I am missing with regards to using the powerset of $\Gamma$ as your new $\Gamma$, allowing you to "compress" $\epsilon$ moves into the equivalent automaton without them, similar to how you can compress $\epsilon$ moves in a DFA. Just it seems that such a conversion is not as trivial as for DFAs, and I'm not sure it's even possible. So are the two equivalent in power? I'm just asking because everyone seems to assume that DPDAs have $\epsilon$ moves and I'm wondering why that assumption exists, since it seems like a more complex model. 

Are there any NP complete problems with no infinite subset of instances $\Phi$ such that membership in $\Phi$ can be decided in polynomial time, and for all $x \in \Phi$, $x$ can be solved in polynomial time? (Assuming $P \neq NP$) 

I'm looking for a one-pass algorithm which computes parity of a permutation. I assume that an input permutation is given by stream $\pi[1], \pi[2], \cdots, \pi[n]$. The output should be the parity of the permutation. The question I'm interested in how much memory a deterministic algorithm should use. Is there any randomized algorithm for the problem? I know that computing number of inversions in one pass uses $\Theta(n)$ memory. The upper bound can be easily obtained with any BST. The lower bound is presented here: $URL$ Alas, the proof of the lower bound in the paper can not be extended to the parity case (or it's not so obvious to me). Also I know that computing parity in a little space with random access to a permutation can be done in $O(n \log n)$ time and $O(\log^2 n)$ memory by deterministic algorithm or in $O(n \log n)$ time and $O(\log n)$ memory by randomized one. See $URL$ The main idea is that the parity of a permutation can be computed by formula $sgn(\pi) = (-1)^{n - c}$, where $c$ is the number of cycles and $n$ is the size. The authors make the cycle decomposition of a permutation. So one can easily compute the number of cycles. Does anybody know an effective algorithm or lower bound on memory for computing parity in the streaming model? Randomized algorithms better than random coin are interesting to me too.