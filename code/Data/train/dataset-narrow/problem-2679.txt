If the sprite(s) are bigger than 32x32 pixels, the easiest (but not the most performant) way to solve the collision check is to handle them as groups of 32x32 pixel sprites. If you're using OpenGL to rotate your sprites, this technique is naturally out. Rasterizing the rotated sprite(s) and doing pixel-by-pixel checking is probably (but not necessarily) prohibitively slow. If you're going that route, no need to hassle with bits, as you'll have to wade through so much data in any case. 

Like others have mentioned, using threads adds cost. This is often more insidious than you'd expect, as you have to know a lot about the underlaying hardware to know what's actually going on. This is especially true when several threads access a lot of the same data. Threads work the best when they have little or no overlapping data. Cache lines make the "overlapping" harder to see - I'll trivialize, but let's say you have a cache that always reads 1kB of data. If your program accesses one byte, and it's not in the cache, the CPU actually has to fetch 1kB of data to the cache for you to get the one byte. Now, let's say that you have two threads that are plotting pixels in, what looks to you, in different places in memory. Let's, for the sake of this example, say the pixels take one byte each. If the pixels hit the same cache line, you're invalidating the cache all the time, and what in a single-threaded application took 1kB of data transfer per 1k of pixels plotted may end up taking 1kB per pixel plotted - ending up with 1MB of data transferred! 

You can do that with either fragment shaders or a grid of textures. With fragment shaders you get more precision. The basic idea is that you have some kind of transformation and then you recursively apply it to the same data - meaning you store the results of the last frame and then apply the same transformation to it again. As an example you might divide the screen to 24x24 quads, and then jitter the vertices a few pixels. Applying this transformation to the data will cause the pixels to flow a bit. Add a smoothing pass and voil√° - fluid fx. edit Here's a quick simulation of this done in photoshop; few frames with the "waves" filter applied and re-applied: $URL$ note that it's the exact same filter applied to the previous result, not new parameters applied to the first frame. edit why it appears so fast is due to this simplicity - it's just rendering the whole screen once, using the last frame as the source texture. edit Browsing through the presentation, yes, it does seem it's based on "real" fluid simulation, but the result is pretty much the same - rendering the whole screen, using the previous frame as source texture, offsetting using an offset texture which contains the motion vectors. Calculating said motion vectors is another matter, but can even be done offline. 

Finding all the steps between these is a matter of building a line-drawing algorithm from (x1),(y1) to (x1+xd),(y1+yd). 

Another way to slice would be to take horizontal or spans, but it's less likely that you end up with a small number of uniques. But if you do, the result is much better even with one iteration: 

You know those paper dolls with moving arms? The arms are attached to the doll using tacks or something similar. What you're looking for is basically the virtual counterpart to this. 

Whether you want to award everyone who has doled damage that is still valid, or only the killer and whoever has doled most damage (or second most) is up to you. 

There's nothing that stops you from doing any of the above in SDL. While SDL has some functions for blitting scaled versions, it's probably better to roll your own for your specific needs. This is relatively easy to do. As for the white flashes, I'd just keep a second copy of the textures that are white. 

For really, really, really simple GUIs, I recommend rolling your own IMGUI library. If all you need are buttons and sliders, it's dead simple. If you need anything more, I recommend looking at some other GUI libraries, though. 

"Game oriented virtual machines" have been around just about as long as there has been games. Zork, and other Infocom games, ran on Z-Machine. Whenever the company got the Z-Machine ported onto a new platform (say, c-64), they could easily release their whole portfolio on said platform. Later on, companies like Sierra or LucasArts came up with their own (AGI, SCI, SCUMM). Those were, however, extremely limited scope VMs for games (interactive fiction in case of infocom and graphic adventure in case of Sierra or LucasArts). So what's needed for a game anyway? Steve Wozniak was quoted to say that when he was designing the apple, (or possibly apple II?) he pondered what features a game needs - and the computer was never primarily a game platform. So looking for a VM that aims JUST games seems kind of funny, unless you're targeting some extremely specific game genre. As such, the most distributed VMs out there today that are used for games are, I guess, java vm and flash vm. 

Other answers have already covered the history aspect, e.g, how home gaming learning the wrong thing about the arcades. In modern games, you generally either give the player a challenge, or you're trying to tell a story. In the 'challenge' category, when you fail, you fail. In the 'story' category, you will want to let the player keep retrying, however badly he plays. Whenever you get to a situation where multiple lives might be applicable, you have to wonder why you're making them limited. If you're telling a story, you don't want to have limited lives.. and if you're not and the player is, basically, playing for a high score, something very few games aim for anymore, there are more entertaining ways to practically give the player "more lives". Such as limited amount of shields, plain hit points, etc. One game I played recently that actually does have limited "lives" is shatter, which is a breakwall game (but the best of that genre I've seen so far); you get a limited number of balls. Once you run out of those, the game does let you continue, but your score resets; so the concept is still out there. I haven't played a lot of shmups lately but I wouldn't be surprised if they still had limited lives. In the end, it all pretty much boils down to "which option is more fun". 

Well.. judging from the discussion, I'd say if the changes are frequent, the tree model wins; if changes are infrequent, the array model wins (it's ok to rebuild the array if it's rare).. In a real-world case some hybrid might be the optimal, leaving most of the hierarchy static while other parts are dynamic. I didn't post this as an answer before though, as someone might have actual experience on the matter, instead of just pondering on it on an algorithmic level. In any case, I'd look into this only after it's found to be an issue. 

Texture. The easiest method. Make a 2x2 texture with wrap uv, point sampling mode and fill a quad with that, repeating the texture several times. 64 separate 4 vertex quads (i.e, duplicated vertices, like @Krom mentioned) Use flat shading, where the color of the polygon is taken from the first (or last) vertex of the polygon. Tricky, and you either need old enough or new enough opengl to do it. 

..and so on, and so forth. So designing a turn structure that can handle the above abuse can be rather tricky. Add to that the numerous games with "whenever" cards (like in "chez geek") where the "whenever" cards can disrupt the normal flow by, for instance, cancelling whatever card was last played.. So basically I would start from designing a very flexible turn structure, design it so that it can be described as a script (as each game would need its own "master script" handling the basic game structure). Then, any card should be scriptable; most cards probably don't do anything strange, but others do. Cards can also have various attributes - whether they can be kept in hand, played "whenever", whether they can be stored as assets (like fluxx 'keepers', or various things in 'chez geek' like food)... I never actually started implementing any of this, so in practice you may find plenty of other challenges. The easiest way to start would be to start with whatever you know of the system you want to implement, and implement them in scriptable ways, setting as little in stone as possible, so when an expansion comes along, you won't need to revise the base system - much. =) 

Not sure how unity handles these things, but "truecolor" textures may be shipped as jpg images, for instance, in which case they will probably take less space (1:10 or better) in an apk than ETC compressed files (1:4 or 1:6) would. 

Second: choose edge direction based on edge length. Check whether / or \ is shorter and pick that - or the longer one. Test and see which looks better. The bad side about this approach is that it requires a little bit more work. Third: Implement algorithm to "turn edges". For each edge you find two triangles (on the both sides of the edge) which form a quadrilateral. The edge that splits said quad can be "turned" to form two different triangles. Note that the "turnable" edges include the original horizontal and vertical edges. Run several passes over the geometry to minimize the edge lengths. Fourth: Discard squares to begin with and while your source data may still be square-based, just sample it for the height values based on some sampling algorithm. Point sampling is fine if you first scale your source data way up. After discarding squares, things get more interesting; what kind of mesh to use? Hexagons? Subdivided polygons based on amount of noise within the polygons (so flat areas use less polys than bumpy ones)? Random data? You may also want to pick up the classic, "Texturing & Modelling, procedural approach" $URL$