The code samples on that site are erroneous. They have certain shell characters replaced with HTML entities. The quotes also seem to be in the wrong places. I wonder if the author ever looked at that page when writing it... Once we fix that, and then check to see if the first of the month is in two days rather than one... 

This occurs when the emergency shell is enabled. This debugging shell is spawned when dracut is unable to mount the root filesystem. Since the passwords are on the root filesystem, authentication isn't really possible at this early stage. Check the kernel command line for . This option should be set to or be absent, to disable the emergency shell. 

You almost certainly have set the wrong character set in your PuTTY settings. Verify the character set on the remote system by running the command: 

Keep in mind that if the server is compromised, the attacker can just remove that and then wait for hapless admins to connect with their agents. So it's kind of a ridiculous workaround. 

You cannot add a route whose gateway is an invalid IP address. If you try, you receive the error. (But you can add routes to invalid IP address ranges. This is to support bogon handling, blackholing, and various other oddball scenarios that you should not normally have to deal with.) To resolve this problem, renumber your network so that all hosts have valid IPv6 addresses. 

You're running in a VMware virtual machine, and the VM has memory ballooning enabled. Thus the hypervisor can dynamically "take away" memory from your VM and allow other VMs to use it (since your VM is not using it). With VMware, this shows up as unaccountable "used" memory. 

There is no on CentOS because that name is a Debian-ism. You will find logs relating to user authentication in . 

You're seeing this behavior because of summer time (daylight saving time). Because you are currently in summer time, where your clock is one hour ahead, when you ask for three months ago at just after midnight on the first of June, the time ends up being one hour "earlier" because it was not summer time three months ago. The GNU date documentation suggests to work around this by using 12:00 noon and the 15th of the month as starting points, when asking for relative days or months, respectively. For example: 

A firewalld zone can be specified either by interface or by source address, but you want to filter by destination address. You'll need a rich rule to handle this particular situation. Such a rich rule may look like: 

The addresses in an email message header serve different purposes than the envelope sender and recipient (which really aren't hidden per se, they just aren't part of the message). The envelope sender and recipient, which you never see in a message, are part of the SMTP protocol, and specify delivery instructions, that is, to which mailbox the mail server is expected to deliver the message, or where to return it in case of some failure. Neither address is required to have any relation to the semantic content of the message. These are explained in detail in RFC 5321 sections 4.1.1.2 and 4.1.1.3. Logically these are analogous to the addresses printed on the envelope of a piece of postal mail. The originator and destination addresses which appear in the message itself indicate semantic meanings, rather than explicit delivery instructions. These are explained in detail in RFC 5322 section 3.6.3 and RFC 6854 section 2.1 (which obsoletes RFC 5322 section 3.6.2). In brief, From: in the message indicates the mailbox of whoever wrote the message, Sender: indicates the entity which sent a message on behalf of someone else, and To: and Cc: indicate the intended recipient mailbox. The RFCs define other header fields you may be interested in, as well. Logically these are analogous to the addresses printed on the correspondence inside a piece of postal mail. Often, the envelope sender and recipient are the same as to the From: and To: addresses. But it is common for them to have no correspondence at all, for instance, in the case of mailing lists. 

The reason is that you explicitly asked for two IP addresses. First, you asked the host to configure a static IP address for the container, which is active as the container starts. Then you asked the container to request a second IP address with DHCP. You should remove those two lines from if you don't want the second IP address. 

You can't create subdomains of the EC2-provided hostname. You must use name-based virtual hosting with your own domain name. 

Of course, you only do this once, on first installation, to set up the initial data directory. You would not do it again unless you were creating a completely new installation or restoring from a disaster. 

You can certainly put up a NAT64 gateway on the customer premises. Tayga, for example, will run on a Raspberry Pi or similar small hardware, or even in a VM on an existing server. This will make the cameras accessible via IPv6, and thus available on mobile devices. Now, if the cameras require proprietary software to access them, and it only speaks IPv4, then all bets are off. As a long term matter, your customer should complain to the camera manufacturer about the lack of IPv6 support and his willingness to buy cameras from some other manufacturer in the future because of this. 

You can take your machine off the Internet, and that will stop the attacks. But it will also stop the mail coming in. I suggest you use fail2ban to ban these bots, rather than trying to do it manually yourself. Recent versions of fail2ban already contain postfix and dovecot jails, which are disabled by default, so all you need to do is enable them. For instance, in a file included from : 

One way to go about it would be to write a bucket policy to block the IP address ranges you're interested in. (IP address lists by country can be found all over the Internet; ask Google.) Another way is to make the entire bucket private, and generate pre-signed URLs for users after they agree to some click-through agreement that they won't export to $COUNTRY, etc. This is probably reasonable enough (many, many organizations do this) and the URLs are time-limited so they can't be easily shared. 

No, there's nothing you can do. Any email sent to your address is going to bounce, because the nameservers for the second-level domain are offline (and have been for over a week). I would suggest you register a real domain name with a reputable registrar this time around. 

What I found here is that the command to verify config was not actually changing from the root user to the toranon user before reading the configuration, so access to the directory was being denied, as systemd did not give the process CAP_DAC_OVERRIDE. You can see the user IDs were logged as . So to resolve this on my system, I decided to have systemd start Tor as toranon rather than starting as root and Tor changing its own uid/gid. 

Without knowing more about your setup, your theory sounds plausible. You will want to change your startup scripts to ensure that your command which sets the system date is complete before starts. 

Everyone needs to be able to read and write to . So these are not an issue. The kernel version is not really an issue either, provided you're actually installing updates, using Ksplice, etc. As for making outbound network connections, you can restrict this, as some web sites do not need to make such connections. But sometimes they do, for instance most web sites will need to connect to a database. You can manage this with SELinux booleans, such as: 

This doesn't show that Apache is running. It shows that is running under the user account. That is, of course, what the headings for the columns say: 

You only ped traffic coming in on . But the unwanted traffic is almost certainly coming in via a different interface. Remove that qualifier from the final rule, and better yet set the table's policy to . 

Your comments reveal files and directory structures which are commonly seen with rootkits. So it's a very high probability that your server has been compromised and taken over. You should begin remediation as soon as possible. 

So, haproxy is binding every local port from 32768 to 65535 inclusive. This is a problem because, by default, outgoing connections bind a local port within this range: 

Use the directive in , so that supervisord starts as root, does any necessary opening of files, and then drops privileges. 

You need to update your system. RHEL (and CentOS) switched from OpenSSL 1.0.0 to 1.0.1 during the 6.4-6.5 cycle in order to resolve a years-long issue. As a result any programs which use OpenSSL had to be rebuilt for 6.5. Since EPEL only tracks the latest point release, and its software is only guaranteed to run on the latest point release, you need to update to 6.5. A simple should take care of it. 

In order to do this, you would have to add tens of thousands of firewall rules, one for each netblock, where a country may have anywhere from one to several thousand netblocks associated with it. When a request comes in, it would have to be checked against every single rule, which takes very little time for a few dozen or maybe even a few hundred rules, but with as many rules as you would need to use, (1) every request will be slowed down significantly and (2) it will use a lot of CPU. The way to do this without a significant performance impact is by doing what you're already doing: blocking only those specific addresses which are being problematic. 

You don't need to do any of this. As HBruijn mentioned in a comment, the file already contains your credentials and MySQL's command line tools will use them automatically without you needing to do anything special. So just do: 

Your ciphers should be listed in order of preference. But you listed before . Try reversing their order in the list. You may also wish to reorder the entire list so that all the 256-bit ciphers appear before all the 128-bit ciphers. You also need to have set in your . 

If you look carefully at the disk symlinks in you will see that there are also links for each partition on the block devices. For instance: 

You need to activate a subscription entitlement for the machine before you will be able to install software from Red Hat Enterprise Linux repositories. If you believe the subscription for the machine is active, contact Red Hat for support. 

You may also wish to Disable Windows Error Reporting entirely. In addition to using Group Policy, you can disable Windows Error Reporting via Server Manager. 

Note that you can't do this with packages from incompatible distributions (e.g. you can't install a SuSE package on CentOS). 

If (and that's a very big if) I'm going to deploy a Mac OS X Server in production, installing all of Xcode just to get memcached doesn't make a whole lot of sense, if there's an easy way to just get the components I need. As a system administrator, I want only the components I need to deploy the application/service that the server is supposed to be running, and nothing else. All else is either an unnecessary waste of disk space or a potential security problem or both, and having unnecessary things on the server increases my workload. For a development machine, it's more or less fine, though, especially if you have to install a bunch of things to try several approaches to a problem. (Just clean up after your failed experiments...) All that said, I've never deployed Mac OS X Server into production for anything, and I don't expect to do so at any time in the foreseeable future. 

Such rules aren't necessary when doing 1-to-1 NAT, and don't actually do anything useful. Of the information you've given, this appears to be the most likely cause of the problem. Simply remove it. 

Anyway, you are not passing on the header, which is the most likely reason I can think of why your URLs are being mangled. Try setting that: 

Using compression, your CPU usage will be higher, but your bandwidth utilization will be lower. If you're paying for bandwidth by the gigabyte (and many of us do) then this will benefit you as well. @ChrisS makes good recommendations, but I'll expand on them a bit: 

Edit the unit file, to specify the dependency. The section contains an line which specifies what services/targets should be reached before this one. 

That looks like it might be an IPv6 address, though it's difficult to tell since you have mangled it. 

Linux already does some writeback caching. Look into pdflush and how it works. Unfortunately it takes some time to understand all the details, since it's quite complicated, but if you're wanting to tune it (e.g. for laptops) then that's the place to start. 

From your stack trace, we can see that the kernel hit a page fault and then tried to read some data from your squashfs, at which point it got hung for 120 seconds (or more). This suggests that something is wrong with the flash drive, DVD or whatever media from which you're booting the system. You were not at all specific about this, so you'll have to look at whichever device has a squashfs filesystem on it. 

You should be using the real IP module, so that the client's actual IP address is considered the remote IP address, rather than your load balancer's IP address. This way, you won't have to check X-Forwarded-For in your logs, nor in your application either. It is simple to enable it, just supply your load balancer IP address(es): 

Finally, some progress! But it still complains that I didn't use . Of course, it also warns me that I should try using the module and . Let's see if that works. 

Your LV name specified here seems to be , but typically this would have been created as . Notice the difference between the number one (incorrect) and the lowercase l (correct). You should be able to correct this in , and that ought to resolve that problem. 

The quick and easy fix is to fix your web application so that it stops serving URLs that need to be redirected. This will also improve your site's overall performance and SEO ranking. For instance, if you redirect to then all of the URLs served by your web application should start with .