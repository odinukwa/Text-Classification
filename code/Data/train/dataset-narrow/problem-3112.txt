I divide the whole range were the target variable changes (0 to 1) into 10 bins. Each bin is 0.1 wide. The amount of bins can be thought of as a hyper-parameter. The more bins the closer the classification problem to the corresponding regression problem. But too many bins is probably not good. 

I have an idea but I am not sure if it is correct. Please feel free to express whatever opinion or emotions you might have about the following solution. Classification and regression tasks are very similar. If done, for example, via neural networks, then a network for regression will differ from the corresponding network for classification only in activation function of the output neuron and the loss function. The idea is to bin the target variable for the regression task, make a classification on the binned labels, and then use to get the probability of the predicted values to be in a certain interval. The prediction probability for the initial regression task can be estimated based on the results of for the corresponding classification. This is how it can be done for the same toy problem as shown on the picture in the question. The task is to learn a 1-D gaussian function 

To make our life easier, let's omit optimization methods here (e.g. Learning Rate, Momentum) and focus on vanilla Backpropagation. As you know, backprop consists of computing the partial derivative with respect to each weight in order to penalize each weight for its role in the global output error; such that: \begin{equation} \frac{\partial E}{\partial W_{ij}} = e_{i}y_{j} \end{equation} With $E$ the global output error to minimize, $W$ the weight to update, $y$ the output value, and $e$ the local error. The local error $e$ is the unknown we want to compute! :) Using the chain rule, the gradient can be expressed as: \begin{equation} \frac{\partial E}{\partial W_{ij}} = \frac{\partial E}{\partial y_{i}} \frac{\partial y_{i}}{\partial x_{i}} \frac{\partial x_{i}}{\partial W_{ij}} \end{equation} With $x_{i}$ the input value to neuron $i$. First, the partial derivative with respect to $W_{ij}$ can be computed as follows: \begin{equation} \frac{\partial x_{i}}{\partial W_{ij}} = y_{j} \end{equation} Which is simply equal to the output value $y_{j}$! Secondly, the partial derivative with respect to $x_{i}$ is: \begin{equation} \frac{\partial y_{i}}{\partial x_{i}} = \frac{\partial \phi(x_i)}{\partial x_{i}} \end{equation} Which is simply $\frac{\partial \phi(x_i)}{\partial x_{i}}$, namely the derivative of the activation function (i.e. Sigmoid, Tanh, ReLU...). Thirdly, the partial derivative with respect to $y_{i}$ can be computed as follows: \begin{equation} \frac{\partial E}{\partial y_{i}} = \begin{cases} \begin{aligned} \frac{\partial}{\partial y_{i}} (T_i - y_i) \end{aligned} & \text{if $i \in$ output layer,} \\ \begin{aligned} \frac{\partial}{\partial y_{i}} \left(\sum\limits^{n}_{j=1}W_{ij}\frac{\partial E}{\partial y_{j}}\right) \end{aligned} & \text{otherwise;} \end{cases} \end{equation} With $T$ the target expected output (i.e. the label). The local error $e$ is computed differently depending on the layer position. For the output layer, the error is proportional to the difference between the predicted value (i.e. $y_{i}$) and the expected output (i.e. $T_{i}$). Otherwise, the error in hidden layers is proportional to the weighted sum of errors from connected layers. Fourthly, combining the partial derivatives allow the computation of the error at a given neuron $i$ such as: \begin{equation} \frac{\partial E}{\partial y_{i}} \frac{\partial y_{i}}{\partial x_{i}} = e_{i} = \begin{cases} \begin{aligned} \frac{\partial \phi(x_i)}{\partial x_{i}} (T_i - y_i) \end{aligned} & \text{if $i \in$ output layer,} \\ \begin{aligned} \frac{\partial \phi(x_i)}{\partial x_{i}} \left(\sum\limits^{n}_{j=1}W_{ij} e_{j}\right) \end{aligned} & \text{otherwise;} \end{cases} \end{equation} As you can see here, you need to recursively compute the local error $e$ all the way to the input layer, that's why it's called backprop! ;) I think that what you missed! If we now simplify: \begin{equation} \frac{\partial E}{\partial W_{ij}} = \frac{\partial E}{\partial y_{i}} \frac{\partial y_{i}}{\partial x_{i}} \frac{\partial x_{i}}{\partial W_{ij}} = e_{i}y_{j} \end{equation} We already know $y_{j}$, and we now know how to compute $e_{i}$ all the way to the input layer. So the weight can finally be updated from the gradient as follows: \begin{equation} W_{ij} = W_{ij} - \,e_{i}y_{j} \end{equation} Sources: 

Each row of the array contains probabilities of putting a test point to one of three classes. I estimate a regression's analogue of by taking the maximum of these three probabilities. 

This depends on the data in your minority classes. The data in each class can be considered as a sample of observations from some population. This sample may or may not represent well the whole population of instances from that class. If the sample represents the population well, then oversampling will introduce only a small error. However, if the sample does not represent the population well, then oversampling will produce data that have statistical properties different from those of the population. All estimates (like confidence intervals, prediction intervals) are calculated from the statistical properties of the sample (mean, variance, etc), the exact calculations being different for different distributions and learning algorithms. If statistical properties of your oversampled data are different from the statistical properties of their populations, you will get wrong estimates of the confidence and prediction intervals for your model. I will illustrate this with an example. Let's assume that you have 2-dimensional data (two features in each observaton) that belong to 2 classes. Data in each class are normally distributed with the standard deviation for each feature = 1. The population mean of the class 1 is (-2, 0). The population mean of the class 2 is (1, 0). I illustrate a large population, taking 500 points for each class. The classes can be separated by logistic regression line as follows: 

2) Recurrent Neural Networks, the LSTM and GRU architectures are particularly interesting for time series predictions. Resources: 

Here is a beginner tutorial to do just that with Tensorflow: $URL$ If you need extra data to train your model, take a look at the MNIST dataset: $URL$ 

You can try two different approaches: 1) Kalman filter, the method is battle-tested and has proven useful in many areas. Resources: 

The standard output should not show any error and print the name of the GPU. If so, you are ready to run Keras and Tensorflow in GPU mode. 

I would still stick with using a CNN for that specific application. Think about CNNs being used to detect various types of cancer in noisy images with an insane precision (Stanford, Google). This type of input is actually very similar to yours with cancer cells hiding in a cluster of healthy ones. And yet the models are performing as good as cancer experts in some cases. CNN have shown to work best when trained with a HUGE amount of data. If possible try to provide more training data with a decent class distribution (roughly the same number of positive and negative examples). Moreover, apart from tuning hyperparameters you could also experiment with different CNN architectures. You will fin plenty of inspiration in the litterature. 

This time x-component of the sample mean is OK, its y-component is a little overestimated, and the standard deviation is underestimated. The separating line is again incorrect. 

The regression line is almost exactly between the population means and is almost vertical because both ordinates of the population means are zero. If I take a couple of thousand points then it will be vertical. The code for this picture: 

Some approaches when there is a small amount of labeled data and a large amount of unlabeled data: Semi-supervised learning $URL$ - mixtures of supervised algorithms on labeled data and unsupervised algorithms on unlabeled data. One of them (label propagation) is even implemented in scikit-learn $URL$ Active learning $URL$ - algorithms that actively choose the data from which they learn, so they can achieve better performance using less labeled data. These two approaches are complementary. Therefore, there are combinations of active + semi-supervised learning algorithms. 

To do regression and predict future data points, you would need to build a training dataset consisting of a sequence of events. Let's say a value $x$ for every timestamp $t$. Your data seems to have 1 dimension, so both the network input layer and the output layer would consist of 1 unit. You would then train your model to predict $(x_{t+1})$ given $(x_{t})$. Let $M$ be our trained model and let's say you want to forecast a data point at time $k$ and you know the current value at time $t$. $M(x_{t}) = (x_{t+1})$ $t = t+1$ $M(x_{t}) = (x_{t+1})$ $...$ increment $t$ and keep predicting until $t+1 = k-1$ $M(x_{t+1}) = (x_{k})$ Put in pictures this corresponds to: 

Different loss functions are used for classification and regression. I also assign different loss weights which can be thought of as another hyper-parameter. 

Lateral connections exist so that the update of a neuron forces the neighboring neurons also to be updated but to a lesser degree. Think of each neuron that has n inputs as a vector, a point in an n-dimensional space. It's coordinates are the values of the weights on its inputs. When the network receives an input - also an n-dimensional vector, each neuron calculates the distance between its weights and the input vector. The neuron whose weights are the closest to the input is the winner, and is allowed to update its weights. It updates them by moving one step towards the input vector. The size of the step is equal to the learning rate. While it moves, it uses the lateral connections to pull its neighbors (or push some of them away, depending on their distance to the winner and on the form of the function that you use for the lateral connections). As a result, the neighbors also move but they move less than the winner. Only the winner and its neighbors are allowed to update their weights. All other neurons don't move. The neighbors are those who are closer to the winner than a certain radius. This radius is a hyper-parameter. This type of learning allows to chart the space of the input vectors. The result is the weights of the neurons are distributed more or less uniformly in the set of the input vectors. After training, each neuron can be thought of as a representative of some region of the input space. 

TensorFlow is a tool to write computation using data flow graphs; this being said, if you want your app to use a pre-trained model only, there is no requirements to use TensorFlow specifically. You could even use one of the ML library written in Javascript to import and run the pre-trained model. 

If you are looking for a way to compile code written for the Keras API to code only using the Tensorflow API, there is no ready-to-use solution for that. And I cannot see any good reason why someone would want to do that in the first place... You can simply look at the Keras backend source code for Tensorflow and rewrite your entire implementation. But once again I don't see any valid reason that would make this worth it. 

The x-component of the sample mean is overestimated (it should be = 1) and standard deviations are underestimated (they should be = 1). As a result, the line separating the classes is different from the true line on the previous picture, so a lot of new data will be classified incorrectly. Let's take a couple of more samples randomly from the same population. Again, the size of the minority class is 10, and I resample them using the same two methods. 

Intuitively, the probability is high where there are training data, and it decreases in the regions between the training data. The model becomes less sure about its predictions far from the training data. The maxima of the prediction probability are not exactly at the training points. This might be because there is no exact correspondence between the underlying classification and regression problems. They are related but they are not the same, and the relationship between them depends on the values of the hyper-parameters, and the learning algorithm. For example, if I change the loss weights,