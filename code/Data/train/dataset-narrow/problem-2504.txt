In quantum computation there is a fair amount of interest in the task of simulating quantum physics. One instance of this is the problem of simulating the evolution of a system under the action of some general Hamiltonian $H$, which will be given by $e^{-iHt}$. If $H$ is sparse, and the entries of $H$ are available via some blackbox function then there are efficient algorithms to simulate this evolution operator to within some constant distance $\epsilon$ in the trace norm. According to Berry, Ahokas, Cleve and Sanders, Commun. Math. Phys. 270, 359–371 (2007) 1-sparse Hamiltonians can be simulated efficiently using only 2 black box queries. However, the citations that go with this are to a masters thesis which does not appear to be online and to a STOC 03 paper on quantum random walks by Childs, Cleve, Deotto, Fahri, Gutmann and Spielman which seems to only deal with a specific subset of such Hamiltonians. I guess that this is in fact true for all 1-sparse Hamiltonians, as the paper seems to indicate, but there is obviously something I'm missing (which is probably in the unobtainable thesis). I would be very grateful if someone could tell me whether or not this is true in general, and if so explain how it can be done (or point to a paper which contains it). For what it's worth, I am specifically interested in the case of simulating diagonal Hamiltonians. 

The first task is trivial, since PP=PostBQP=MPostBQP[1] $\subseteq$ MPostBQP. The second task is is really the main question here, but is answerable by making a simple adaptation to the proof that PostBQP = PP, given in quant-ph/0412187 (see the Wikipedia page on PostBQP for an outline of the proof). The following is adapted from the Wikipedia proof sketch for PostBQP = PP. We can write out the circuit corresponding to any MPostBQP computation as a series of unitary gates and post-selections. Without loss of generality we can assume that once a qubit is post-selected, it is never again acted upon. Thus, the quantum state obtained at the end of the computation is given by $|\psi\rangle = \prod_i (P_i^1 \prod_j A^{ij}) |x\rangle$, where $P_i^1$ denotes the projector for qubit $i$ onto the $|1\rangle$ subspace and $A^{ij}$ are the matrices corresponding to elementary gates. Note that without loss of generality we can assume that all the entries in $A^{ij}$ are real at the expense of an additional qubit. Now, let $\{p_i\}$ be the set of qubits which are post-selected upon, and let $q$ be the output qubit. We define $\pi_0 = \sum_{w \in S_0} \psi_w^2$ and $\pi_1 = \sum_{w \in S_1} \psi_w^2$, where $S_0$ ($S_1$) is the set of computational basis states for which $p_i = 1 \forall i$ and $q=0$ ($q=1$). The definition of MPostBQP then ensures that either $\pi(1) \geq 2\pi(0)$ or $\pi_0 \geq 2\pi_1$. The idea is then to construct a PP machine to compare $\pi_0$ and $\pi_1$. Expressing $\psi_w$, the part of the final wavesfunction $\psi$ corresponding to a particular computational basis state $w$, as a sum over paths and replacing the indices $i$ and $j$ on $A^{ij}$ with a single index $k$ running from 1 to $G$, we obtain $\psi_w = \sum_{\alpha_1 ... \alpha_G} A^{G}_{w,\alpha_G} A^{G-1}_{\alpha_G,\alpha_{G-1}} ... A^{1}_{\alpha_2,\alpha_1} x_{\alpha_1}$. The idea, then, is to construct a PP machine which accepts with probability $\frac{1}{2}(1+C(\pi_1-\pi_0))$ for some $C>0$, since then $x \in L$ would imply that $\frac{1}{2}(1+\pi_1-\pi_0)> \frac{1}{2}$ and $\frac{1}{2}(1+\pi_1-\pi_0) < \frac{1}{2}$ if $x \notin L$. Now let $\alpha = \{\alpha_i\}$ and $F(A,w,\alpha,X) = A^{G}_{w,\alpha_G} A^{G-1}_{\alpha_G,\alpha_{G-1}} ... A^{1}_{\alpha_2,\alpha_1} x_{\alpha_1}$. Then $\pi_1 - \pi_0 = \sum_{w \in S_1} \sum{\alpha,\alpha'} F(A,w,\alpha,X)F(A,w,\alpha',X) - \sum_{w \in S_0} \sum{\alpha,\alpha'} F(A,w,\alpha,X)F(A,w,\alpha',X)$. Such a PP machine can then be defined as follows: 

You may want to follow Joel's link for a more detailed answer, but the current situation is that there have been a number of serious issues raised with the proof, and it is now deemed to be incorrect (and most likely irreparably so). There is currently a wiki keeping track of these issues here, thanks largely to Suresh as well as Terrence Tao. 

Perhaps I am misunderstanding this question. If you are asking whether you can implement the verifier circuit for a problem in QMA using a measurement based computation, where Merlin supplies the input layer, and Arthur supplies all further qubits in the resource state and entangles both sets of qubits before measurements commence, then the answer is trivially yes. This follows directly from the fact that any quantum circuit can be implemented as a measurement based computation whether you care about classical or quantum input. You'll notice that in most papers on measurement based computation input sites are generally identified separately from the other sites, and this is why (i.e. specifically to deal with the case of quantum input). 

For every variable $x_i$ in $\phi$, $\Phi$ has $n$ variables $y_{ij}$. For every set of indices $i$, $a$ and $b$ with $a\neq b$, $\Phi$ has a pair of clauses $y_{ia}∨￢y_{ib}∨￢y_{ib}$, and $y_{ib}∨￢y_{ia}∨￢y_{ia}$. I'll refer to these as comparison clauses since they ensure that $y_{ia} = y_{ib}$ if they are satisfied. For every clause in $\phi$ acting on variables $x_i$, $x_j$ and $x_k$, for every $a$ and $b$, $\Phi$ contains an equivalent clause, where $x_i$ is replaced by $y_{ia}$, $x_j$ is replaced by $y_{jb}$ and $x_k$ is replaced by $y_{k(a+b)}$ (here addition is done modulo $n$). I'll refer to these as inherited clauses. 

This may sound a very trivial thing, but I would recommend trying to take a break before you go to bed. Try to take a break from research and clear your head. It's very tempting to decide to take a few minutes to work on some pet problem in the comfort of your bed before you go to sleep, but in my experience it absolutely guarantees insomnia and leaves you totally unfit for proper thinking the next day. This is more of a do as I say not do as I do thing, because I find myself drawn to working late at night far too often, and I can say from experience that it is a practice best avoided. 

The ability to query oracles or external databases in superposition provides a provable separation between quantum computers and classical computers in terms of query complexity. There are a variety of communication tasks which see drastic reductions in communication cost which quantum communication is used. Quantum information processing allows for information theoretically secure protocols for a wider range of problems than are classically possible. Certainly QKD does not require a universal quantum computer to be implemented, but many protocols for other tasks do. Pre- and post-processing of large entangled quantum states allows you to violate the shot noise limit in metrology, resulting in more precise measurements. 

This isn't really a proper answer to your question, but is a bit too long for a comment. The quantity you are after will vary from graph to graph, and will depend on the initial site of the walker. The expected number of distinct intermediate nodes will depend strongly on clustering within the graph, and I would expect the expected number of distinct intermediate nodes to be correlated with the clustering coefficient. A cluster is basically a subset of vertices which share a large number of edges, so that each vertex is connected to a large fraction of the other vertices within the cluster. When a walker enters a cluster it is likely to stay in that region for a large number of hops, possibly revisiting each node many times. Indeed, using random walks in this way is one of the computational techniques used for identifying clusters in large graphs. Thus for a walker starting in a cluster, the expected number of distinct intermediate vertices will likely scale with the size of the cluster and the average probability of leaving the cluster. While the above applies to both weighted and unweighted graphs, lets take the maximally connected unweighted graph of $N$ vertices as an example. In this case, at each hop after the first, the walker has probability $\frac{1}{N}$ of returning to the initial vertex. Thus the expected number of hops to return to the initial site is $N+1$. Even if we connect some vertices in this graph to a vertex in some other graph (i.e. outside of this clique) the probability of each hop leaving the cluster before returning to the initial site can be very low. Thus we expect clustering to reduce the number of distinct intermediate vertices by confining the walker within the cluster. The average degree of vertices within the graph will also play an important role, though this is linked to the clustering. The reason for this is that when the walker jumps onto a vertex with degree 1, it must hop back to the previous vertex on the next hop. Even when the degree is 2, there is only one path which can be followed through the graph, although it can be traversed in either direction at each hop. On the other hand, for graphs with degree higher than 2, the number of paths can explode, making it extremely unlikely to return to the initial site even if the shortest path between then is small. Thus you would expect the number of distinct intermediate vertices to be high for graphs which both have an average degree substantially above 2, and also have no significant clustering, such as trees. Of course these comments no longer hold in the case of quantum random walks, but I guess you only care about the classical case. 

Never having worked or studied in Spain, I can not really help with local information. However, as I mentioned in the comments, the most obvious source for such funding in European universities (aside from internal university or departmental sources and local research councils) would be funding from the European Research Council. The ERC has many different kinds of grants, including training networks and personal grants, which can often be used to fund overseas students from. Additionally, the European Commission offers funding for postgraduates and postdocs via Marie Curie actions. Further, there is the China Scholarship Council which also offers support for students wishing to study abroad. Then there are the industry scholarships: Google, IBM, Microsoft, etc. If either of the students is female, then there are more options (see Google's Anita Borg scholarship, etc.). Lastly, many European countries have bilateral agreements with China or Chinese institutions which may be another potential source of funding. 

In quantum mechanics, the state of the system is given by a vector $v$ such that $v^\dagger v = 1$. For a closed system the evolution is unitary, and for a constant Hamiltonian (the total energy function for the system) is given by $U(t) = e^{-\frac{i H t}{\hbar}}$. Note that it is the Hamiltonian, rather than the time evolution operator that is Hermitian. So this is all well and good, and we have deterministic evolution of $v$, since $v(t) = e^{-\frac{i H t}{\hbar}} v(0)$. What brings randomness into the picture is the fact that when you measure a quantum system, you do not get to learn the entire state of the system (i.e. $v$). Instead, for the simplist kind of measurements (known as projective measurements) when you make a measurement on the system, you are effectively imposing an orthonormal basis on the system. For some a given orthonormal measurement basis $\{b_i\}$, the outcome of the measurement is $b_j$ randomly with probability $|b_j^\dagger v|^2$. After such an outcome, the state of the measured system is then $b_j$, and any further information about $v$ is lost. To give a concrete example, we can consider a qubit (a two-state quantum system) which is originally prepared in state $|0\rangle$ (this is just a notation used by physicists to denote vectors representing quantum states, in this case 0 is equivalent to the bit value 0). Next, we consider what happens when the qubit is exposed to a Hamiltonian $H=[0 ~-i; i ~~0]$ for time $t=\hbar \pi/4$. In this case, we have $v_{final} = e^{-\frac{i H t}{\hbar}} |0\rangle = \frac{1}{\sqrt{2}}\left(|0\rangle - |1\rangle\right)$. So, up to here the evolution has been entirely deterministic. Now, the question is what happens when we choose our measurement basis as $\{|0\rangle,|1\rangle\}$. In this case, we see that the result is either 0 or 1 random with equal probability (0.5). So the resuting bit is uniformly random. A photon passing through a beam splitter is undergoing a very similar process, though quantum optics are a little more time consuming to explain explicitly.