I'll first answer question (2). Let's solve the $(\max,+)$ product problem. The $(\min,+)$ product can be solved analogously by negating entries and adding $M$ to each entry to make all entries positive. Take $A$ and $B$ whose product $C$ we want to compute, and create matrices $A'$ and $B'$ where $A'[i,j]=(n+1)^{A[i,j]}$ and $B'[i,j]=(n+1)^{B[i,j]}$ for all $i,j$. Compute the product $C'$ of $A'$ with $B'$. This takes $O(Mn^\omega \log n)$ time since the bit representation of the integers in $A'$ and $B'$ has length $O(M\log n)$. Consider now $C'[i,j]=\sum_k A'[i,k]B'[k,j]=\sum_k (n+1)^{A[i,k]+B[k,j]}$. If $\max_k A[i,k]+B[k,j] = z$, then $C'[i,j]\geq (n+1)^z$, and if $\max_k A[i,k]+B[k,j]<z$, then $C'[i,j]\leq n\cdot (n+1)^{z-1} < (n+1)^z$. Thus, $C[i,j]$ is the largest power of $n+1$ that's at most $C'[i,j]$ and hence $C$ is easy to obtain from $C'$. With respect to question (1), in order to find for each $i,j$, the index $k$ that achieves the minimum (called the witness), one uses a method by Zwick (from Uri Zwick. 2002. All pairs shortest paths using bridging sets and rectangular matrix multiplication. J. ACM 49, 3 (May 2002), 289-317.) This method is based on ideas from an earlier paper by Alon, Galil, Margalit and Naor on finding witnesses for Boolean matrix multiplication. The basic idea is to first figure out a way to extract the witness $k$ for entry $i,j$ provided $k$ is a unique witness for the minimum. Then one uses a carefully chosen, polylogarithmic number of random samples of columns of $A$/rows of $B$ which ensures that $k$ is the unique witness for $i,j$ in one of the samples with high probability. To extract a unique witness, one only needs to do $\log n$ distance products. For each $l=1,\ldots,\log n$, let $K_l$ be the integers whose $l$th bit is $1$, and compute the distance product of $A$ and $B$, restricted to the columns of $A$/rows of $B$ with indices in $K_l$. Then if $k$ is unique such that $C[i,j]=A[i,k]+B[k,j]$, one can compute the the binary representation of $k$ by setting to $1$ only those bits $l$ for which the distance product for $K_l$ had $C[i,j]$ as its $i,j$ entry. 

Here are three in shortest paths research: $1$. Is there a linear time algorithm for single source shortest paths in directed graphs with nonnegative weights, at least in the word-RAM model of computation? Note that a linear time algorithm exists for undirected graphs (see Thorup's paper). Based on that, Hagerup has a runtime of $O(n+m\log w)$ for directed graphs with weights bounded by $2^w$. Is there a faster algorithm? $2$. Is there an $O(n^\omega$ polylog $n)$ algorithm for all pairs shortest paths in unweighted directed graphs? ($\omega<2.376$ is the exponent of matrix multiplication) The current best runtime is $O(n^{2.575})$ by Zwick, and for undirected graphs the problem can be solved in $O(n^\omega$ polylog $n)$. (Are the directed problems actually harder?) $3$. Is there an $O(n^{2.9})$ algorithm for all pairs shortest paths in $n$-node graphs with weights in {$0,\ldots,n$}? Or, is there a reduction from the general all pairs shortest paths problem to this restriction? 

Here's a problem that, as I recently realized, looks actually harder in undirected graphs than directed ones. Suppose you have a graph with positive and negative edge weights, and you are asked to detect a negative weight cycle. There is a scaling algorithm for this problem for directed graphs by Goldberg'93 (A. V. Goldberg. 1993. Scaling algorithms for the shortest paths problem. In SODA '93.) running in O($m\sqrt{n}\log C$) time where $m$ is the number of edges, $n$ the number of vertices and $C$ the largest absolute value of an edge weight. In contrast, the same problem in undirected graphs has much worse algorithms. To my knowledge, the best known is by Gabow'83 (H. N. Gabow. 1983. An efficient reduction technique for degree-constrained subgraph and bidirected network flow problems. In STOC '83. ) and runs in O(min($n^3, mn\log n$)) time. There's also an approach using T-joins which gives the same runtime, I don't remember where I saw it however. The negative cycle problem is crucial in the design of single source shortest paths (SSSP) algorithms and it is not surprising that the best running times for SSSP in directed and undirected graphs with arbitrary weights have the same runtimes-- O($m\sqrt{n}\log C$) and O(min($n^3, mn\log n$)) respectively. 

I am not completely sure if this is what you mean but there are a bunch of problems which don't seem like they are counting problems, however, the best ways that we know how to solve them is to count objects. One such problem is detecting whether a graph contains a triangle. The fastest known algorithm is to compute the trace of the cube of the adjacency matrix, which is 6 times the number of triangles in the (undirected) graph. This takes O($|V|^{2.376}$) time using the Coppersmith-Winograd matrix multiplication algorithm, and was first noticed by Itai and Rodeh in 1978. Similarly, the best way we know to detect a k-clique is to find the number of k-cliques, again via matrix multiplication. 

Here's what I know about the girth problem in undirected unweighted graphs. First of all, if the girth is even, you can determine it in $O(n^2)$ time- this is an old result of Itai and Rodeh (A. Itai and M. Rodeh. Finding a minimum circuit in a graph. SIAM J. Computing, 7(4):413–423, 1978.). The idea there is: for each vertex in the graph, start a BFS until the first cycle is closed (then stop and move on to the next vertex); return the shortest cycle found. If the girth is even the shortest cycle found will be the shortest cycle. In particular if your graph is bipartite this will always compute the girth. If the girth $g$ is odd, however, you'll find a cycle of length $g$ or $g+1$, so you may be off by $1$. Now, the real problem with odd girth is that inevitably your algorithm would have to be able to detect if the graph has a triangle. The best algorithms for that use matrix multiplication: $O($ min{$n^{2.38}, m^{1.41})$ time for graphs on $n$ nodes and $m$ edges. Itai and Rodeh also showed that any algorithm that can find a triangle in dense graphs can also compute the girth, so we have an $O(n^{2.38})$ time girth algorithm. However, the runtime for the girth in sparse graphs is not as good as that for finding triangles. The best we know in general is $O(mn)$. In particular, what seems to be the hardest is to find a $o(n^2)$ time algorithm for graphs with $m=O(n)$. If you happen to care about approximation algorithms, Liam Roditty and I have a recent paper in SODA'12 on that: Liam Roditty, V. Vassilevska Williams: Subquadratic time approximation algorithms for the girth. SODA 2012: 833-845. There we show that a $2$-approximation can be found in subquadratic time, and some other results concerning additive approximations and extensions. Generally speaking, because of a theorem of Bondy and Simonovits, when you have densish graphs, say on $n^{1+1/k}$ edges, they already contain short even cycles, say roughly $2k$. So the denser the graph is, the easier it is to find a good approximation to the girth. When the graph is very sparse, the girth can be essentially arbitrarily large. 

As far as I know, the problem is sometimes called "nondecreasing paths", and was studied since the 50s. See for instance this paper: G. J. Minty. A Variant on the Shortest-Route Problem, Operations Research, 6(6):882–883, 1958. The version of the problem which asks for the nondecreasing path from $s$ to $t$ with minimum last edge weight is typically referred to as "earliest arrivals" (since the last edge weight is the arrival time in the itinerary application). There's a lot of work in the literature focusing on this version.