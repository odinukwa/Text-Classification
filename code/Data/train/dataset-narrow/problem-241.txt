You have a routing problem. If the CR router does not have a route to tell it to send the traffic destined for the network to the outside interface, it just drops it. Traffic is only translated from the inside interface when it is going to an outside interface, but that traffic never makes it to the outside interface; the router doesn't know what to do with it, so it just drops it. This is expected behavior for a router. 

By definition, frames (what you have is a broadcast MAC address which goes on an ethernet frame, not an IP packet which uses a broadcast IP address) do not cross a layer-3 boundary. A router will strip off a layer-2 frame before forwarding the layer-3 packet encapsulated in the layer-2 frame. The router will create a new layer-2 frame with which to encapsulate the layer-3 packet for the next hop. Layer-2 broadcasts are not forwarded across a layer-3 boundary; neither are layer-3 broadcasts, except in special cases. MAC addresses are only significant on the layer-2 domain because they are only needed for the layer-2 frame. A router will have an ARP cache for each ethernet interface which it has, just as a PC would have an ARP cache for each ethernet interface which it has. Neither a PC nor a router is sure to have all the MAC addresses for every device in the layer-2 domain. Routers are only needed when a host needs to communicate with a host on a different layer-3 network. Any host can communicate with any other host on the same layer-2 network (there are some corner cases like Private VLANs where this may not be true) without going through a router. 

Ethernet (IEEE 802.3) has been dethroned, and Wi-Fi (IEEE 802.11) is now King of the LAN. There are more devices shipping with Wi-Fi than there are shipping with ethernet. 

By the way, routers that are actually routing shouldn't use the command because they are the gateways. Instead, they should use a default route. 

Having lived through the wired network wars, I have some personal perspective on this. I remember when ethernet interfaces were expensive. ($750 each, of course, the computer you wanted was $5000, and that was a lot of money 30 years ago). There were many different LAN interfaces/protocols used: G-NET, ARCNET (IEEE 802.4), token ring (IEEE 802.5), etc. Some were cheaper and some more expensive than ethernet, but basic ethernet was faster at 10 Mbps than the others, like token ring (4 Mbps) and ARCNET (4 Mbps), which were also expensive and saddled with patent royalties. Token ring and ARCNET had the advantage of no collisions, but the landscape changed with the introduction of ethernet switches. Also, ethernet was starting to be produced by companies other than 3Com (creating competition and lower prices), whereas token ring and ARCNET were still basically tied to single companies and expensive intellectual property royalties. Ethernet was pushed to 100 Mbps when token ring got to 16 Mbps, and Thomas-Conrad finally bumped ARCNET to 100 Mbps, but it was late to the party. Token ring and ARCNET were finally ported to UTP, which was cheaper and easier to use than the coax used by the original ethernet and ARCNET, or the proprietary cabling for token ring, but they were simply following ethernet. In the end, it really boiled down to lower prices, and the fact that ethernet could be mass produced by many different companies on single chips. 

Since you don't give any details, I will have to make some assumptions. First, I assume you mean that the wireless clients are having difficulties, and you assume that it is a particular client using a lot of bandwidth. Your assumption may be incorrect. You may be experiencing wireless interference. Always start troubleshooting at layer-1, which, in this case, is the airwaves. You need to get a hardware/software combination that can sniff the airwaves to see what is actually happening. Next, you can use the router/firewall's logging facility to look at the traffic to and from the Internet. If your problem is inbound, you can look to see if you are experiencing a DoS, or look at the destination addresses to see if one of the devices is streaming some sort of video or something. If the problem is outbound, you can look at the source addresses to see which device is sending an inordinate amount of traffic. 

You do not move octets from one fragment to another, nor do you add any padding. RFC 791, Internet Protocol has a complete description and example of fragmentation: 

You have not given us much to go on. My example will concentrate on ICMP echo requests and replies (ping), but it permits any other traffic types, and you will need to extrapolate for anything else. With standard access lists, you want to place those as close to the destination as possible in order to avoid in inadvertently blocking traffic that should be allowed. You cannot use standard access lists for specific types of traffic. With extended access lists, you want to place them as close to the traffic source as possible in order to avoid wasting router resources by routing traffic that is destined to be discarded. Extended access lists can be very granular in the traffic types, sources, and destinations. Access lists will be processed in order, and the processing will halt as soon as there is a match. Also, remember that access lists have an implicit at the end, so you must explicitly anything you want to allow. For example, let's block every VLAN, except VLAN 10, from sending ICMP echo requests to VLAN 20: 

It starts out with an empty token being circulated. The empty token has a priority, and a station must have an equal or higher priority to use the empty token. A host wanting to send something seizes the empty token. Then it sends a frame, and the frame header has an Access Control field with a token in it. The receiving host will change the token back to . When the frame circles all the way around to the host sending the frame, the sender will see that the token is , and it will remove the frame data and send the empty token back around. The token is part of the frame. It can be seen conceptually that the host holds the token, but the token is really part of the frame header for a data frame. 

This is the way I have seen it work successfully, albeit only used on layer-3 interfaces, and only in one direction or the other: 

If by adjacency, you mean a Full adjacency, then on a broadcast or NBMA medium, a router only achieves a Full adjacency with the DR and BDR (of course, the DR and BDR should have a Full adjacency with all the routers). The router will not get past the 2-Way state (bi-directional communication has been established) with any other routers. A Full adjacency means that two routers have exchanged LSAs, but a router on a broadcast or NBMA medium only exchanges LSAs with the DR and BDR, so it will not form a Full adjacency with any other routers on that medium. A broadcast medium implies that every router can see every other router on the medium. On NBMA, you need to be careful. You should set it up as a hub and spoke topology, and the DR should be at the hub so that all the other routers can see it (the DR and BDR must have access to all the other routers). You could also use something like subinterfaces configured as point-to-point links so that there is no DR or BDR. 

Switches only forward frames based MAC address. The secondary ASA takes over the MAC address of the failed ASA. Cisco has an explanation of the process. 

IPv6 can also have different extension headers. Based on the packet headers, you can discover the type of payload, and where the payload starts. Usually, but not always, the packet payload will be either TCP or UDP. TCP and UDP have their own headers. UDP header: 

First, if the three sites connect to the data center over WAN circuits with any appreciable latency, layer-2 connections are not a very good idea. Layer-2 must send all the broadcasts across the layer-2 links, and this can degrade performance and eat up expensive WAN bandwidth. Sending the VoIP over the layer-2 link will force it to compete with the broadcast and link-local traffic inherent in a layer-2 connection, so you may not always have 3 Mb for VoIP as you envision. The proper way to separate classes of traffic and guarantee bandwidth is with QoS. You are going to need a router on each end of the link if you use GRE. In that case, you should use layer-3 links. Doing this will allow you to use QoS to mark priority traffic and guarantee bandwidth for VoIP. You could also have a lower-priority class of traffic for things like backups and replication which would normally hog bandwidth, starving more immediate, normal user traffic. When the higher-priority classes are not using their bandwidth, the lower-priority class(es) can use that bandwidth. 

Cisco maintains a page with links to the password recovery procedures for a lot of devices: Password Recovery Procedures 

Assuming your Internet router has a default route, you could run a common routing protocol between the two routers and advertise the default route to your Cisco router, or you can statically configure a default route in your Cisco router: 

You can configure the WAP to be a client of the LWAP. The WAP would act as a wireless bridge. It will not be a point-to-point link, but the WAP will bridge the devices connected to its ethernet interface to the LWAP. Apparently, you can only configure this for one radio in the WAP. In the radio configuration, use the command. Cisco provides an example: 

Ethernet has its own checksum, and it has nothing to to with IP, TCP, or UDP. Neither TCP not IPv6 have anything to do with the UDP checksum. UDP on the source will create the checksum, and UDP on the destination will verify the checksum. I think you don't really understand the network stack layers. Layer-2 protocols, e.g. ethernet, Wi-Fi, etc., may use a checksum. In general, layer-2 protocols will drop any layer-2 frame with a bad checksum anywhere along the layer-2 path. For instance, a switch will discard an ethernet frame with a bad checksum. Layer-2 protocols don't care which layer-3 or layer-4 protocols are carried in their frames, nor are they aware of any layer-3 or layer-4 checksums. In layer-3, IPv4 has a header checksum that layer-3 devices, e.g. routers or hosts, will inspect to verify the integrity of the IPv4 header, discarding any layer-3 packets with a bad header checksum. IPv6 has done away with the IPv4 header checksum. Layer-3 protocols do not care which layer-2 protocol carries their layer-3 packets, nor which layer-4 protocols they carry. Neither are they aware of any layer-2 or layer-4 checksums. Layer-4 protocols, e.g. TCP, UDP, etc. may have a checksum. In IPv4, the UDP checksum was optional, but it is mandatory with IPv6. A layer-4 protocol will inspect it own checksum, and it will discard any datagrams with bad layer-4 checksums. Layer-4 protocols are unaware of any layer-2 or layer-3 checksums.