If you can add an ID column and fill it with a unique value for each record then you should be able to run a query like 

At my current place of employment someone made a decision to put IDs into a comma delimited column. I'm looking to break these out into a proper many to many relationship. However; it is not in the cards for the application that references this data to change right now. So I need to modify a view to still show the comma delimited column. What is the best way to setup the view so that it displays the comma delimited column? Is there a way to do it that doesn't involve leaving the original column? A stripped down version of the table definitions is as follows. 

The largest thing I look for when trying to optimize an ssis package is data sorts. Since these operations have to complete before the data stream can continue they can be very costly for performance. Without seeing or knowing much about the package its hard to give much more than general advice. 

This would remove the duplicates then you could delete the If you have enough duplication that you exceed SQLs limitation for the IN statment then You could insert the ID values for the IN statement into a temp table and run an exists against that. 

I've verified that the server is set for remote connections inside the instance - properties - connections. I've verified that TCP\IP and Named Pipes are enabled under Configuration Manager - sql server network configuration - protocols for MSSQLSERVER I've verified that the browser service is running and that the sql server service is running. I've verified that the 1433 port is opened in the windows firewall. 

I'm trying to do a copy database by scripting a backup and restore. I have the backup procedure working correctly but I keep getting the error 

Is there a way to capture the queries experiencing the SOS_Scheduler_Yield wait type as it is happening. My cpu is pegging out at night and I suspect its some xml processing that is causing it by chewing up all my processor cycles; however, the application design is such that what is coming back as having the highest worker time is a section of xml that should only be run one time per client. So I need to catch the individual offending query each night to make my case. 

Access returns an error looking for the parameter a.opromisedshipdate. Any idea how I can achieve this filter? In the real world query I'm doing this to provide aggregated order information (the inline view) next to non aggregated order information but I need the aggregated information to only go up to the date that is a part of the current order. Thanks in advance. 

I need to be able to pull say 50 percent of the output for each organizationid. So in this example I'd come back with 2-3 records. Which records doesnt matter as long as the correct percentage of the records is pulled. Any ideas on how to go about this? 

I'm trying to design a set of fact tables for a datamart that will work in an ssas cube for one of our clients. One of the challenges I'm facing is that there appears to be some disperencies between order item pricing and order pricing such that the summation of all of the order items does not equal the pricing of the order. This occurs because admins are aloud to go in after the fact and change an order price inorder to discount the customer. However no record of the discount exists. In this case would I want to create a fact table for the order and then a fact table for the order item? If so I'm assuming I would need to create a key for the fact tables to maintain the relationships. Is this an acceptable practice or will I run into problems with this type os solution when I go to build the cube. Any thoughts on a better way to model this would be appreciated. Thanks in advancce 

This appears to be related to some implicit conversions that are occurring in the background when exporting the report to xlsx. Numeric columns are being sent to excel as if they are text columns. One report responded to a change to the query using an Explicit cast to Numeric (Cast as opposed to convert to remove any commas or other formatting that might confuse the conversion). Several other reports did not respond to the Cast but returned correctly after using an expression conversion of VAL(). I still have several reports that are not responding to either. If anyone out there has a good explanation for this I'd love to hear it. 

I'm attempting to determine root cause for an issue that caused an outage for my company. Essentially the site connections to our database server were timing out after not receiving a response for 5 min. A check of perfmon counters showed that the database server was using about 10% of processor, memory was under utilized, and our hard disks were not being stressed. A check of long running queries using the following statement showed that there were a lot of queries queued up with a status of suspended the longest of which had been running for 50 minutes. 

We are working on migrating our SSRS from SQL Server 2008 to SQL Server 2014. After brining the reports over I have a set of reports that will execute just fine but when I try to perform a standard export to excel from the 2014 Server I get a message box saying: 

I found the issue but I'm not sure why its happening. To query the linked server I have to right click SSMS and select Run as Admin. Then I can query the access db. I dont know why this is the case as I'm remoted into the machine. I'm an administrator on the machine. I created the Linked Server to the Access Database which resides on the C:\Drive of the server. But this will at least allow me to hand run my code. Since this is my development server I think that will suffice at least for now. 

I was trying to connect to a secondary instance on the server. If I use the primary instance this appears to work. Is there a way to use the secondary instance? I have the secondary instance port open but it is not of course using 1433. 

I pulled the syntax straight from the invoke-sqlcmd get-help examples. Can anyone tell me what is wrong with this? Thanks, as per request this is running on windows Server 2008 R2 

I'm working on a sql query that needs to get a percentage of the records based on the value of a particular column. The percentage is given by the user. A stripped down version of the query is below 

If you have the option of moving the data into another database I would begin looking at using a star schema. Here is a website that might help you begin research $URL$ Star schemas are built specificly for the fast retrieval of large amounts of data and are very good at aggregating that data over time. Plus having the data seperated from your OLTP database means that there are not as many draw backs to adding indexes. What's more having your data layed out in a Star Schema sets you up to be for creating data cubes with SSAS in the future; although, you do not need a cube to interface with the data. 

I'm working on a query in Microsoft access and it does not appear to allow me to filter the inline view by a date that exists in the table outside of the inline view. A simplified version that exibits the problem is below 

So it turns out that the get-help invoke-sqlcmd -example shows the array variable as using 'dbname="MyDatabase"' as the syntax. However this gives the error above but if you swap the quote positions such that the variable uses "dbname='MyDatabase'" then the script works. 

I'm attempting to get a listing of the users and roles they are associated with on a remote server to be input into a database on the local server. But when I use the linked server sys.database_principals only shows me information for the login that the linked server is using. How do I get a listing of users and roles by database to a central db location? 

The short answer would be when you have no set based way to get the information or have exhausted all other options and rejected them based on their performance being worse. The reason for avoiding scalar sub queries is that they force SQL Server to perform the scalar query once per every row that is returned. There is almost always ways to get the information back using a set operation that will perform and scale better. 

When using RESTORE FILELISTONLY to restore a database using code the logical_name for the files is coming back as 423. However when I do a manual restore of the database the logical file name appears to be 3497. I'm running SQL Server 2008 R2. Has anyone run into anything like this before? How do I repair this? 

Is it possible to give a user or group rights to a snapshot without giving them rights to the database if the database and snapshot both reside on the same instance? 

However, I do not receive the same message when exporting to Excel from the 2008 server. I believe the problem is related to some Numeric fields that are coming back with a value of 0.0000000000000000000. Has something changed with the excel export function between these two versions? 

I'm trying to create a scalar function that will return a delimited list from some sql that would be passed in. Unfortuantly where I work the previous people responsible for the database thought it would be a good idea to put comma delimited id lists inside of some columns. This function is the first step for me to rectify the problem without breaking the developers UI. Can anyone tell me how to fix this error? My code is below. 

This did not occur near the time of the Snap recreation job. Several of the table data extracts (that point at the same snap) prior to this one worked fine. And the job appeared to recover for the next table data extract. I'd like to find out what caused this job to fail. Any help on places to look would be helpful as it doesn't appear that there is any reason for the snapshot to have been offline. 

I've setup my databases so that anytime a procedure is blocked for more than 45 seconds the database notifies the DBA email. Is it bad practice to setup a way to auto kill the process that is doing the blocking? I'm assuming yes; however, waiting until an off hours DBA can get to a computer and fix the change seams problematic as well. Is there a better way to handle the blocking processes? 

I have a sql server user that our application is connecting as. The user has been granted db_datareader and db_datawriter as well as Grant Execute on each stored procedure that it needs to use. These are the permissions I see when I veiw the usermapping on the Login and when I view the user under the database. Given these permissions I don't think the user should be able to alter a procedure; however, when my developer logs in as that user they are able to update the stored procedures. Am I wrong about what these permissions allow? Is there someplace I can look to find out about permissions that may not being showing up in the UI? Or do I need to explicitly deny alter on the stored procedures for that user? 

Would this achieve what you want? Technicly the inline view isnt necessary as you could repeat the case statement in the order by. 

We've been using a linked server to an access database for close to a year now with little issue. Now when I run a select query against the linked server the query sits there and never finishes. Killing the session results in the familiar transaction sitting in Rollback/Killed status until the service is restarted. 

Is there a way to clear out these select statements or perhaps run them such that they don't end up in the rollback/killed status? Has anyone else seen this sort of issue before? What did you do to get around it? 

The update should be updating the record with the NUll dtdeleted date and setting it to GETDATE() which appears to be throwing the error. 

However when I try to pull the sqlhandle out for use in sys.dm_exec_sql_text() I get an error "The handle that was passed to dm_exec_sql_text was invalid." Or no value is returned. If I pull the handle from the xml and put it into the query manually it returns just fine. What is the proper way to store a varbinary value that comes from a file so that I can pull the value out and use it with dm_exec_sql_text? 

I'm not sure what else to check. I'm using the correct servername. If I attempt to connect using IP address I get the following error. 

I'm writing an ssis package that imports a number of access databases nightly. Each database has the potential to have a slightly different schema. Since I'm creating the tables than doing a direct table insert using execute sql tasks inside of a for each loop container the schema differences cause errors. I've upped the max error count so that the package can take errors and continue running. This leaves me with some databases that have incomplete data which I would prefer to drop. I attempted to make an event handler that would drop the database; however, at the point that the event handler is called the database is still in use. Is there another way that I could drop the database if there is an error? 

SQL SERVER 2008 I have a mapping table that contains a deleted date column. Since the table uses a surrogate key as its unique identifier there is a uniqueness constraint on the table. This constraint contains each of the foreign key values and the deleted date. I have a process that runs each night and attmepts to modify this data based on an external data source. The process is attempting to update a record and set its deleted date to GETDATE(). There is currently a record in the mapping table witht he same foreign key values and a deleted date of 2011-12-17 00:17:22.157. The process is returning the following error Violation of UNIQUE KEY constraint 'UNQ_tsitemapping_fullcolumnlist'. Cannot insert duplicate key in object 'dbo.tSiteMapping'. The duplicate key value is (4, , 5, , 1394, 154, Dec 21 2011 6:59AM). Shouldnt the inclusion of the deleted date in the uniqueness constraint mean that this is a unique value? Why would I be getting a UNIQUE KEY constraint violation on this table? Any suggestions on how to fix this problem would be welcome. As Per GBN's comment below. Here is the table definition. 

I'm creating a script to automaticly copy from multiple access databases into sql server databases. My script currently creates a new sql database and creates all of the tables. It then trys to insert the data from an access database (using linked servers) table into the newly created sql database table. The problem is not all of the databases have all of the tables. In these cases it is ok for the sql server table to remain empty. However, the insert throws an error because the table does not exist in the linked server. Is there any way to tell sql server to ignore the table not found error so that it will continue on to the next insert statment? 

when I run the procedure to do the restore. Here is the procedure code. Can anyone spot what my error is? 

Ultimatly I'd like to combine these into a single products table and a many to many relationship ID ProductName ProductType where product type would be either 'product' or 'feature' ID productid featureid for the mapping table. Yes the view that is setup needs to be an updateable view. 

We have a SQL job that runs each night to perform a data extract and import function. The job performs against a snapshot and copies from several tables in a serial loop. Today the job reported the following error: 

The way we solved this was to use a template db to auto create views against the access linked tables. Each view was created as 

I'm attempting to setup log shipping between two differnet domains. When I attempt to connect to the secondary server instance the primary server fails to connect. If I turn off the windows firewall on the secondary server then I'm able to connect. I have opened up the following tcp ports on the secondary server windows firewall 1433, 1434, 137, 139, 445 I have opened up the following udp ports on the secondary server windows firewall 137, 138 Are there any other ports or firewall settings that I've missed? 

SQL Server 2014 I have an application that provides the xml for blocking reports. The xml contains a sqlhandle that I'm wanting to store in a separate database for later consumption. The sql handle is stored in the table using the following code 

We have an application user which has been given read write to the appropriate databases. This user has the ability to query the sys tables by default. I've also heard that there are times when this user needs to be able to obtain a listing of tables and columns that exist in the database. Are there any security risks to having the user have read access to the sys tables?