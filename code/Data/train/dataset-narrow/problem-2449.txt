You could have a look here EDIT I should have added that these are the lectures by Amitabha Bagchi at IIT Delhi 

Recently, I was going over an introduction to Holographic Algorithms. I came across some combinatorial objects called Pfaffians. I do not really know much about those at the moment and came across some surprising uses they can be put to. For instance, I came to know that they can be used to efficiently count the number of perfect matchings in planar graphs. Also, they can be used to count the number of possible tilings of a chessboard using 2*1 tiles. The tiling connection seemed very curious to me and I tried searching for more relevant materials on the web but in most places I merely found just one statement or two about the connection and nothing else. I just meant to ask if someone could suggest some reference to relevant literature as that would be really great and I am looking forward to study some related materials. 

Also, I would like to know what is the best known "approximation algorithm to minimize elimination ordering". By approximating the minimum elimination ordering, I mean a poly-time algorithm that outputs an elimination ordering which best approximates the minimum fill-in value. Thanks for your time Best Regards -Akash 

I was going through Les Valiant's seminal paper and I had a tough time with Proposition 4.3 on page 10 of the paper. I cannot see why is it the case that if there is a generator with certain values for $valG$ with a basis $\{(a_1,b_1) \ldots (a_r,b_r)\}$, then there exists some generator with same $valG$ values for any basis $\{(xa_1,yb_1) \ldots (xa_r,yb_r)\}$ ($1^{st} kind$) or $\{(xb_1,ya_1) \ldots (xb_r,ya_r) \}$ ($2^{nd} kind$) for any $x,y \in F$. Valiant points out the reason in preceding paragraph - namely the $1^{st}$ kind of transformation can be achieved by appending to every input or output node an edge of weight $1$. The $2^{nd}$ kind of transformation, Valiant says, can be achieved by appending to input or output nodes chains of length $2$ weighted by $x$ and $y$ respectively. I have not been really able to understand these statements. Maybe they are already clear, but still I cannot really see why the above construct helps achieve any realizable $valG$ values with one basis with the new basis which is one of the above types. Please help illuminate them to me. On a different note, are there some tensor free surveys for hologaphic algorithms available online. Most of them use tensors which, sadly, scare me :-( Best -Akash 

Recently while working on a problem, I had to go through some of the literature on nested dissection. I happen to have one (maybe two?) questions related to the same. First, I will define a few relevant terms. These terms come up when we study the process of Gaussian elimination graph theoretically. Say, we have got a matrix $M$. With this matrix, we associate a directed graph $G_M = (V,E)$ where we have $V = \{v_1, v_2, \ldots, v_n\}$ where $v_i$ corresponds to row i and variable i and $(v_i,v_j) \in E$ iff $M_{ij} \neq 0$ and $i \neq j$. The elimination process may create some new non-zero elements in locations in $M$ which contained zeroes to begin with; the edges corresponding to these elements are called fill-in. In graph-theoretic terms, removing a vertex $v$ calls for addition of the following set $S_v$ of edges. $S_v = \{(u,w) | (u,v) \in E, (v,w) \in E, (u,w) \not\in E\}$ In order to make the elimination process efficient, we can target minimizing fill-in. By a result of Yannakakis, we know that fill-in minimization is a NP-Complete problem. It is easy to see that the value of fill-in depends on the ordering of vertices which leads to definition of a related parameter. An elimination ordering is a bijection $\mathbf{\alpha \colon \{1,2,\ldots, n\} \to V}$ and $\mathbf{G_{\alpha} = (V,E, \alpha)}$ is an ordered graph. Basically, this represents the order in which the vertices will be picked for deletion in the corresponding directed graph representation. Corresponding to different orderings, we get different values of fill-ins. The ordering which minimizes the fill-in size is called the minimum elimination ordering. And again we (of course) have that computing the minimum elimination ordering is NP-Complete. My question 

Let $y_t = x_t^T$. Then, $y_{t+1} = y_t P^T$. Thus, $y$ (and therefore $x$) corresponds to the original Markov Chain run backward in time. Hope this gives some motivation towards the concept of dual chains. 

(Reduction from set disjointness) Suppose Alice and Bob are given sets $S, T \subseteq [n]$ with the guarantee that $|S\cap T| \leq 1$. Alice and Bob run the protocol for finding the common element of $S$ and $T$ assuming that their sets have a non-trivial intersection to decide a common element $X$. Now, they can communicate with each other to verify that $X$ is in fact common to both $S$ and $T$ with $O(\log n)$ bits. Therefore, any protocol for finding the common element of $S$ and $T$ must take $\Omega(n)$ bits of communication. 

I can think of two situations where a linked list based linear search with heuristics may be better than using a hash table: 1. For small lists the overhead associated with calculating the hash function may matter more than the improvement in complexity. 2. You need a large enough table to avoid collisions (number of buckets should be at least twice the number of entries). In applications where memory is an issue (e.g. embedded systems), this can be a significant factor. 

I think that Hensel Lifting is pretty nifty too, and it has many applications in algorithmic number theory and algebra. 

Analyzing any problem with a lot of symmetry is facilitated by using group theory. An example would be to find algorithms for things like rubic's cube. Although I do not know the details, I am sure that proving that God's number is 20 required some serious group theoretical pruning. In a different context, practical solvers for graph isomorphism problem like nauty use the automorphism group of the graph. 

I think that the entire area of data streaming and sub-linear algorithms is an effort in this direction. In data streaming, the focus is on solving the problems in o(n) and ideally O(polylog(n)) space whereas in sub-linear algorithms you try to get algorithms with o(n) running time. In both cases, one often needs to compromise with having randomized approximation algorithm. You can start with the material on this page and this. 

First of all, I think that you probably mean angular impulse and not torque. (You can look at impulse as the total effect of a torque applied over a short time.) If you neglect air drag etc., the motion of any rigid body (and in particular a coin or a cube) in the COM frame is very simple - it just rotates with a constant angular velocity. This makes this problem kind of trivial. Just rotate the body by an angle $\omega t$ about the axis of rotation and find the side "facing up" by whatever geometric definition you want (it was not very clear in your description of the problem). If you are defining your top face as the face intersecting the vertical line passing through origin, things are even simpler. Rotate the line by angle $-\omega t$ about axis of rotation and find the intersecting face. I would not say that this problem is a good model for the SMG problem because in SMG you have a point moving with constant speed on the surface whereas here the whole body will be rotating with a constant angular speed, which makes this problem so much simpler. 

This should really have been a comment, but for the lack of space I am posting this as an answer. Thanks for the answers and comments everyone. Recently, I came across another survey by Robin Thomas. You can find it here $URL$ Other than this, I would also add one statement about the tiling connection (which was pointed out to me by Prof Dana Randall). If you take the dual lattice, then 2x1 domino tiles are just edges. Therefore, a perfect tiling is precisely a perfect matching in the dual. Then, the theory of Pfaffians can be used to count perfect matchings in planar graphs. This means that you can just primarily focus on counting perfect matchings in the graph - the rest just follows trivially. 

How about the fact that computing permanent is #P-Complete but computing determinant - a way weirder operation happens to be in the class NC? This seems rather strange - it did not have to be that way (or maybe it did ;-) ) 

Recently, I started (independent) learning of the theory of metric embeddings from the Fall 2003 course offered at CMU . I had a very basic question from the very first lecture of this course which I would like to get more intuition about. On page, $5$, the notes say that this technique can be used in a straightforward way to give an $\alpha$ approximation algorithms for problems like TSP if (say) the following hold. (i) The metric embeds into a tree. (ii) The embedding has distortion at most $\alpha$ What I am not sure about is whether the solution generated by using the embedding is even valid - because for all I know, it could be that the TSP solution on the tree uses only from among those edges which were contracted. To be more precise, I feel more comfortable accepting that if we have got a mapping $f$ from the original space $(X,d)$ to the tree metric $(V, d')$ which expands all the pairwise distances, then I can use the TSP solution on this tree as an approximate solution to the TSP problem on the original metric with approximation factor same as the expansion of the mapping $f$. I am not sure about how approximation factor can be the same as (or even related to) the distortion of the mapping $f$. Thanks -Akash 

I am not sure if the following question falls within the scope of this site; if it does not, I will request the moderators to take appropriate action I have been going through Jin-Yi Cai's expository paper on Holographic algorithms. I had a question. Immediately after introducing Grassman-Plucker Identities for Pfaffians and the definitions for matchgates, recognizers and generators, Cai introduces signature tensor for matchgates. My question arises from the following statement. He states that a generator $\Gamma$ with $m$ output nodes is assigned a contravariant tensor $\mathbf{G} \in V_0^m$ of type $\binom {m} {0}$. I looked up contravariant tensors on wikipedia but did not find any reference to the type of contravariant tensors which Cai talks about. Maybe I am not searching properly, but I was unable to find a proper reference which defines what I am looking for. I would be glad if anyone could help me with this. Thanks -Akash 

The publication of Chiang and Tamassia's paper on dynamic algorithms in computational geometry included several algorithms used in solving dynamic computational geometry problems such as: 

I've only began my research into the Held-Karp conjecture and I was wondering about recent progress in proving the conjecture. The Held-Karp relaxation is conjectured to have an integrality gap of $\frac{4}{3}$ for symmetric TSP. There have been some recent advances in proving this conjecture. Among these include the 4/3 conjecture for metric TSP was proved for cubic and subcubic graphs by Boyd et. al. $URL$ Furthermore, for the class of graphs that are degree-3 bounded and are claw-free, the Held-Karp relaxation yields a 4/3 approximation ratio as proven by Momke et. al. : $URL$ Then, Qian et.al. ($URL$ proved that for a special case of graphs with all edges have cost $1$ or $2$, there exists a bound of 10/9. I would very much appreciate if anyone with more expertise in this research topic would point out other recent research advances in proving the Held-Karp conjecture. Links and/or titles to research papers would be very helpful. 

I'm looking for a data structure that can do the following geometric operation: Suppose there are a set of buckets $b_0, b_1..., b_n$ each of which contains some elements. Suppose I want to move all the elements in buckets $b_i$ where $i > k$ one bucket forward. So the elements in bucket $b_{k+1}$ would be moved to bucket $b_k$ and the elements in bucket $b_{k+2}$ would be moved to bucket $b_{k+1}$ and so on. The obvious way to move these elements is to go to each bucket and shift all the elements into the previous bucket. But is there a data structure that will allow me to move the buckets all at once? I used buckets in the description because it's easier to formulate the question in terms of buckets. But the data structure doesn't necessarily have to be buckets. All I need is a data structure that can allow me to move "chunks" of elements in one go (for example shifting consecutive the buckets $x$ number of buckets forward all at once) and then allow me to query the structure as normal (for example, allow me to query $b_{k}$ now with all the elements shifted. EDIT: I'm mainly interested in whether an already existing data structure that I'm not aware of does this. 

And others. What are some open problems in dynamic computational geometry currently that have good static algorithms but worse dynamic algorithms? I am especially interested in algorithms that use priority queues in the static solution. 

Is there a way to create a max flow graph such that it satisfies the condition that a flow either saturates an edge or completely avoids it. It can't have half its flow through one edge and half through another edge. Can this be formulated as a max flow problem with a polynomial time solution or is this problem hard?