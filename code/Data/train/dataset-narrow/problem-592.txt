Assuming you are talking about the column in , or some status field derived therefrom, you can create an invalid (or intentionally corrupt, if you prefer) index like so: 

(though as you hopefully got to see, canceling that expensive can save the database from a lot of unnecessary grinding if you're just going to anyway.) 

This behavior is controlled by the parameters max_standby_streaming_delay / max_standby_archive_delay. You can fiddle with these parameters in the RDS Parameter Group used by your Read Replica instance to allow more time for queries against your Read Replica to complete. 

Not sure why Teradata has that limitation, but should be fine in PostgreSQL even when other tables have foreign keys depending on that index. PostgreSQL has fairly sophisticated tracking of such dependencies -- for example, if you tried to do you would see a complaint like: 

Erwin's answer does a good job of answering the question as originally stated, however you added the comment: 

Here, Postgres knows that the index is bad and marks it as such in . There are countless other ways to create a corrupt index that Postgres won't immediately notice: Erwin's answer, mismatched glibc or other collation behavior between a primary and a standby, writing arbitrary bytes to the files behind those indexes, performing bogus updates to Postgres' catalog tables, and on and on. 

However whenever duplicate values are entered I run into Error 3910 or 3616, which means the transaction is un-committable. I think it's because insertion into customer table need to be rolled back and I know that I cannot rollback part of the transaction while keeping the remaining part (which is, unfortunately, the intended outcome). I found MERGE statement but it has too many restrictions (like WHEN MATCHED must be followed by UPDATE and DELETE). Please kindly provide any working solution. 

I'm very new to db development and currently working on my first production app. I learned that I would need a business logic layer (BLL) to authenticate and authorize users (for example John can only query the database while Andrew can insert new records). Does it mean the BLL would have to connect to the database with greatest privilege necessary, instead of least privilege needed for each user? In another way, the BLL need INSERT permission to provide service to Andrew, which is more than enough for John? Can we solve this potential flaw (except by securing BLL better, which I would of course do)? For example, implement authorization in database layer (as described here)? 

The SQL value null represents the absence of data, so when you pivot and a cell as no data a null will perforce be generated as the cell value. It is your responsibility as the programmer to coalesce the null to whatever domain value is appropriate for missing data, when that makes sense. 

Every user in the system will immediately start seeing the three default bookmarks, personal copies of which they can then edit as they see fit. 

t is not always accurate to the business requirements to unpivot the table as you propose. For example, in a tournament scheduling database the table for Game will always have two distinct FK's to Team, one labelled HomeTeam and the other labelled VisitingTeam. Unpivoting this eliminates the business requirement that a Game is always between exactly two teams. Another example is the case of a database for an online meeting scheduler, where each meeting typically has a single Host and any number of participants. It wold be appropriate to embed the Host FK to the Participant in the main meeting table, with all non-host participants listed in a detail table. If this were an appropriate model for your business requirements then all but one of your reference_n fields would be pivoted out to achieve proper normalization. So, in the absence of the relevant business requirements, we are left wondering whether it is appropriate from a business perspective to unpivot as described. However, let's assume unpivoting is accurate to the business requirements. Why are you worrying about performance so early in the design? If it actually turns out that once you have a few billion rows this one table is at the core of a key performance criteria, there are a dozen or more techniques for addressing that only one of which is the denormalization you inquire about. There is absolutely no possible way that you can determine at this early stage which of those performance enhancing techniques will be an appropriate solution. Meanwhile, if you continue to denormalize your design in this way you will vastly complicate the writing, reading, testing, and development time of the codebase using your application. Are you sure that cost is worthwhile for a very, very, early guess at performance needs? 

Canceling queries (or, equivalently, rolling back a transaction) in PostgreSQL doesn't have any database corruption hazards which you might have been spooked by in certain other databases (e.g. the terrifying warning at the bottom of this page). That's why non-superusers are, in recent versions, free to use and to kill their own queries running in other backends -- they are safe to use without fretting about database corruption. After all, PostgreSQL has to be prepared to deal with any process getting killed off e.g. SIGKILL from the OOM killer, server shutdown, etc. That's what the WAL log is for. You may have also seen that in PostgreSQL, it's possible to perform most DDL commands nested inside a (multi-statement) transaction, e.g. 

PostgreSQL reads its (index, heap, etc.) blocks either from shared_buffers, if they are available there, or from disk if not. Postgres does not need to read out of its WAL files other than for crash recovery (similarly, standby) purposes. 

Amazon's RDS only offers PostgreSQL versions 9.3.x, and it seems unlikely that they'll ever offer to host older versions of Postgres. So by jumping from a local 8.4 install directly to RDS, you would in effect be making two significant changes at once (jumping up several Postgres versions, as well as switching to managed hosting). That may be alright or not -- it all depends on what features you're using and depending on. You should do some reading on RDS's limitations (no external hot standby, limited extensions, no shell access to the database instance, etc.) and benefits (hopefully much less maintenance work) and decide whether it's right for you. Also, I suggest you walk through the steps of dumping and restoring your data into RDS and ensure your application works OK, as well as reading through the Postgres major-version release notes for 9.0, 9.1, 9.2, and 9.3, paying particular note to the incompatibilities listed to see if any of them would affect you. 

If the primary key is a surrogate (ie an IDENTITY valued INT) then you need to remove it from the field list of the insert (if possible) otherwise (if you need to retain the surrogate key values to support foreign keys) to bracket the insert with and . 

If you decide to keep a single entry for both sides of a transaction, then by definition you are engaging in single-entry bookkeeping. This may be the most appropriate solution for some simple applications, but be clear that you are losing all the functional and robustness advantages of double-entry bookkeeping, in exchange for a simpler design. Note that when viewed stand-alone Subledgers (though not their corresponding Journals) are often implemented as single-entry, since a control-account in the General Ledger captures the subledger total and the balancing side of the transactions are in the General Journal (GJ) and General Ledger (GL). You also appear to be confusing the distinct concepts of Ledger and Journal in traditional double-entry bookkeeping. The various Journals (of which there will be numerous specialized varieties for specific common transactions of the business in addition to the General Journal) is a chronological history of all transactions entered into the system. The General Ledger is an ordering by account of all transactions entered into the system, and the various subledgers are an ordering by subledger-code of all transactions entered into the corresponding Journal. Two examples of common Ledger and Journal combinations: 

For some reason we don't have existing ID systems for customers so UserID will be auto-generated at import-time. In my scenario, any of Facebook, Twitter or Phone number can uniquely identify a customer so I have unique index for each of them to enforce uniqueness constraint. I created a view to facilitate data import: 

A common case is that customer's Facebook (or other contact method) appears in multiple sales records. A trigger is created to handle such cases: 

I'm importing some paper-based records and they're in chronological (time) order, with following columns: 

There are more then twenty thousand records in the order db, which means the data flow task will be executed for more than twenty thousand times. The CRM db will be queried for more than twenty thousand times, too. It takes more than an hour to do these. Can I utilize some built-in features to speed up these (or do it in a "smart" way)? And, is an hour a long time, in the context of ETL and / or SSIS? 

So, 300k rows total doesn't seem like a huge amount, I wouldn't be overly worried unless you have a particular cause for concern (e.g. your UPDATE taking way too long, holding row locks for too long, etc). But two suggestions which may be helpful for your particular use-case: First, make sure that your UPDATE statement does not touch rows it does not need to. If you want to set all values of some_bool_column to false, do it like this: 

which will more-or-less double the size of the table, since the UPDATE has to keep old row versions around. You may want to read up a bit on how PostgreSQL implements MVCC and how vacuuming works, but to answer this question: 

However, this is really not what CHECK constraints are supposed to be used for, and it actually introduces a race condition if you have multiple transactions writing to example_table at the same time (can you see how?). Use the UNIQUE constraints that PostgreSQL provides. If your values are too large for the UNIQUE constraint's B-Tree index, create the UNIQUE constraint on an MD5() of the value. 

This has the additional advantage of being data-driven; in the case that your masking needs to be amended, only a data change is required instead of a code change. 

It's a Multi-Level Marketing system! Jeff Moden has written a a pair of articles here and here on efficient implementation of Hierarchical Reporting against a SQL Server database. There are a number of ways to store the hierarchical information but the two main ones are Adjacency List (each child has a parent foreign key) and Nested Sets (each parent stores details of its child hierarchy). Adjacency List is more intuitive and faster to update, while Nested Sets provides faster reporting. Jeff has explained this topic far better than I can, and developed efficient SQL Server algorithms for converting an large Adjacency List tree into a Nested Set representation, 

Note that the single clustered index on the view is identical to the (one and only) clustered index on the original table. However, several queries running against the Indexed View run slower (averaging about 3*, ranging up to about 6*, slower) than against the original table. Does anyone know why this could happen? Is it a possible bug in the Engine to not treat two identical clustered indices identically? My test data currently covers only two periods, one year apart. I initially thought it might be due to the columns of the view being nullable, but using isnull to coalesce them simply makes the queries so slow I can't even measure the performance. I am on SQL Server 2014: 

Supposedly it is possible to hook up Bucardo to RDS now that RDS Postgres supports the session replication role, but if you want a nightly snapshot I think you'll be much better off using RDS instance snapshots. 

I am wondering if anyone knows the history of why is the default transaction isolation level for PostgreSQL, SQL Server, Oracle, Vertica, DB2, Informix, and Sybase. MySQL uses default REPEATABLE READ, at least with InnoDB, as do SQLite and NuoDB (they call it "Consistent Read"). Again, I am not asking for what the differences are between different isolation levels, but rather for some explanation of why the default was chosen to be in so many SQL databases. My wild guesses are: small performance benefit, ease of implementation, some recommendation in the SQL standard itself, and/or "that's the way it's always been". The obvious downside of this choice is that tends to be quite counterintuitive for developers and can lead to subtle bugs. 

The space utilized by the table should go down if you run a or ; probably a alone will not be sufficient to immediately reclaim space. 

An SSIS package keeps failing for no reason. There are only three lookup transform components in the package (besides the source and output component), two running in partial cache mode and the other in full cache mode. Each lookup will need to find records among tens of millions of entries. When the full-cached component have cached around 10M records the data flow will fail. The only error message is "Data flow task failed" (no error code provided). At that time the server has 15% free memory, and SSIS uses up about 3GB. There is no warning about memory space during execution. Windows Server and SQL Server are 64 bit, but I'm not sure about Visual Studio BIDS. 

I need to associate customers' order with their "level" (Silver, Gold, etc.) when they placed the order: 

Execute SQL against Order db to extract the orders and put them in an object variable; Loop through each order using "foreach container", in which I put a data flow task that extract data from CRM db (both parameters come from step one), derive some columns and write the output to another table. 

A Non-Clustered Index on the child table by ParentID and TypeID will cover the subquery. An Indexed View on the subquery is possible also. 

None of these requirements for 1NF is violated by the design you propose. For instance a Junction Table created to normalize a many-to-many relationship will always have a composite Primary Key, with each component being also a Foreign Key into one of the joined tables. 

(My apologies for the SQL Server syntax - I don't have MySQL. Please treat as pseudo-code.) A scheme such as the following should work 

In practice relations frequently have multiple candidate keys, and these rules must apply to all of them in turn. Also, when Normalizing one must determine the minimal key(s) for each relation, and use those rather than any Super Key. Your lecturer didn't remove the fifth column altogether because the functional dependency in that column still exists, and must still be accounted for in the Normalization process. Update: The FD AD->C doesn't disappear by virtue of recognizing ADC as a subset of CDA; neither is it sensible to have two relations ADC and CDA both in the model as this is a redundancy of exactly the sort Normalization is designed to eliminate.