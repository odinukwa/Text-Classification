Mind that I am not asking "how to rewrite it more efficiently", but rather how do I find witht the explain plan what the most costly operation there. Meanwhile I am reading about it, but I'd appreciate some help. 

The good one. All I did here was taking the result of (seven records), and added an to the end of the big query. Same as described: 

Can I simply delete these trace files from my FS w/o consequence ? (I know, if they apeared one should probably look at them.. but won't happen and the database has no production use whatsoever. Going to have to happen another time.) What should be done to prevent it from appearing again? 

I am running a query in some big tables, and although it runs fine even tough is a lot of data, I'd like to understand what part of it weighs on the execution. Unfortunately I am not too good with explain plans so I call for help. Here is some data about these tables: 

Welcome to the world of Database Administration... and good luck. You're going to want to read up on as much Oracle documentation as you can, as well as other good technical sources (O'Reilly has always been good), and subscribe to lots of Oracle blogs. I'll answer your questions here, but you're really going to want to get a solid foundation in RMAN ( For 10gR2: $URL$ ). 1.Do you have to shutdown your Oracle DB when you want to make a copy/clone of it? Yes and no. It depends on if your database is in archivelog mode. If the database is archiving its logs, the backup can be done while your database is online, though you may notice some performance degradation during the backup, so it is still a good idea to schedule the backup during a non-critical time of day. If the database is not archiving the logs, then you must shutdown the database cleanly in order to make a copy of it (any other way will result in a corrupt/incomplete restore). 2.A good beginner example This is hard to do without knowing your environment. There are various RMAN commands that will happily clone a database on the same server, but when you get into moving a clone from one server to another, you have to go a different route. So without knowing your environment, I can't really tell you a good example. That said, essentially your goal is to do the following: - Get a good copy of all your datafiles - Get a good copy of all your archive logs - Get a good copy of your database parameters and control file - Create a new database with the settings from your old database (or reuse an existing database) - Copy over your datafiles and archive logs - Restore from your controlfile, and recover until there are no archives to process. RMAN does a lot of the work for you with some fairly simple commands, so I suggest learning how to use it effectively, but you can always do the hard work without it. (For a long time at a previous workplace, we did this with some shell scripts and such. Fun it was not, and was easy to screw up.) 3.Does a GUI exist for cloning an Oracle Database? I think the thing that comes closest would be Oracle Enterprise Manager (GRID). It offers several automated backup/restore options as well as cloning features. Keep in mind, however, that it uses RMAN under-the-hood, and you should never use a tool blindly without understanding what's going on underneath. Sooner or later, you'll need to delve down into the command line because the GUI won't do what you want it to do, and without a good understanding, you'll be stuck. 

(I mean, values hardcoded) Cost, cardinality, and bytes read drop dramatically and the query executes in a few minutes. Now, I have tried to isolate the "small query" in a clause, tried to use an join instead a sub query and nothing... the result is always the same. Why is it this way and how could I possibly prevent it from happening? Maybe worth mentioning that in both cases (fast and slow) the costly part of the query is a FTS on one of the big tables used in the join. Also, I am using Oracle 11gR2 [EDIT] These are the explain plans of the two example executions The bad one. Notice I didn't use , but rather a simple join adding to the clause. 

And that has a cardinality of a few billions, bytes read around 12gb and explodes my temp. However, if I execute the , which yields (always) 7 records, take these records and change the query to: 

By having the table CustomerOrders, you satisfy the ability to map common customer order data to common fields (simplifying reporting at the expense of making the import a little more painful since the fields must be mapped), and the CustomerOrderFields gives you the ability to have the custom fields per customer necessary for the un-mappable data. The custom fields are still reportable, but not as easily as your generics as they'll come to you in multiple rows (instead of multiple columns). There are some ways around all that depending on your report creator (e.g., pivoting the results). The only other option would be to do something like this (which, personally, I would avoid): 

Be really, really careful when mucking around in /etc/rc.d/; this is where your startup/shutdown programs live, so removing the wrong file will put you in to a world of hurt. (Unfortunately, I can't tell you which file is the one Oracle tends to use.) Second, Oracle's uninstall instructions always leave a lot to be desired, as does the actual process, which leaves just about everything hanging around on the file system even when it isn't necessary anymore. For removing Grid, IIRC (that is a big IF), I think you're in the clear -- pretty much exactly what I would have done. And, as to weblogic, same deal -- I'd have run the uninstall.sh and see what happens. I suppose you could nuke the entire directory at this point so that there'd be no chance of an old file coming back to bite you, so that'd be just about the only other thing I'd do. Good luck with the re-install... 

The query causing me the issue is too big, but the piece that seems to be the core is quite simple, I will try to go with that: The query has an structure like: 

(That would be in Oracle 10gR2) In short, I want to know how much (the total, over and below the HWM) space does Oracle have to keep inserting things. If my query is wrong, can someone provide one that does that? pd. I also have other messy queries summing the segment sizes of objects, but then again, I do not know how all this wraps together with fragmented space and HWM. An explanation here would be highly appreciated. 

The partition containing my Oracle 11g installation began to fill up with trace files and when I went looking for what are these I've found this disturbing post about how to disable the trace file generation. The two related questions I have are: 

Note that there's not really anything here that speaks to if the data is valid and/or accurate according to your business logic. This logic is anything you put into triggers, procedures, validation routines, etc., that you build yourself to try and make sure that everything going into the database is good. (It should be noted that Oracle's check constraints could be considered a form of business logic that is enforced like a unique or primary key constraint). The database will happily reject data that doesn't fit into the above criteria, assuming they are defined, but will also happily accept invalid or inaccurate data that isn't otherwise in the above criteria. If I have a field that contains people's names, the database can't make the determination if "John Smith" or "Jonh Smiht" is accurate (notice the typo). So while the database will say everything's good, you know from a visual inspection that it isn't. (This example, while trivial to do, is hard to do anything about. After all, how do you know his name isn't really spelled this way? I use it only as an example of any data coming into the system. A field expecting percentages could easily have 5% as 50% -- how can the database tell which is valid? It can't without you writing lots of complicated business logic, and even then -- at some point, how do you know it isn't 50%? Or that it isn't 5%? Or that it was supposed to be 25%, and the typist got really confused!) Use the database integrity mechanisms to your advantage, but don't assume that because there are no integrity errors that your data is good. It can still, easily, be bad and misleading. Further, don't assume that your business logic ensures good data either. Yes, you can prevent obvious errors (like, say, a field that shouldn't have values out of the range of 0 to 100), but once ranges are satisfied, at some point, you have to trust the user who is giving you the data. And at some point, the user will give it to you incorrectly. Poof, bad data, with perfectly valid database integrity. 

That always eludes me when calculating free space in my tablespaces. Will the following query consider fragmented free spaces of object below the HWM value for each TS? 

The Question is: I have an index containing the columns , and (that , which it even uses on the first part). Since there is no further joins, why would it be doing the FTS? 

I'd use a to generate a list of components a certain customer has and compare it to another list generated the same way somewhere else to detect inconsistencies. The problem is that sometimes a customer can have too many components and exceed the maximum output of . I was wondering if there could be a way to generate a hash from a group of ordered rows, in a way I could use to make the same validation. Sort of: