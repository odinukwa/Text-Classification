For terminal services, my gut feeling would be that deploying multiple virtual TS instances is your best bet, with TS load balancing. 

Filter out the informational alerts so that you're just seeing warnings and errors. Research each one in turn and attempt to resolve each one as you go. Google is a perfectly legitimate way of accomplishing this. If you're able to resolve an error so that it doesn't re-occur, great, case closed for that one. On to the next. If you can't resolve an error, try to determine whether it's benign or a genuine problem. If it's a genuine problem, escalate it. If it isn't, add it to your 'known error' records (or mental 'ignore this' pool) and move on to the next error. 

Unless you have a compelling reason to change your strategy (and I can't see anything in your post to suggest that you do - You're well within capacity. LTO2 is still widely available and used, throughput speed/window problems weren't mentioned so I assume not a problem), I recommend sticking with your current system. If a component has failed, replace it like-for-like. LTO 2 drives are still widely available. Tape backups are not a legacy concept. They're still 100% relevant today, and widely used in most medium and enterprise businesses. I hate to ask the obvious questions, but lets cover them off just in case: Has the tape drive been taking a cleaning tape regularly (every couple of weeks)? Has the server been rebooted/backup exec services been restarted? Have any Windows patches been applied recently? Have any other configuration changes been made to the server? Is the SCSI cable terminated properly? Have you tried swapping the SCSI cable for a replacement? I'm always very wary of using a component failure as the business driver to move to a 'new and improved' system. The quickest way of getting a successful backup is likely to be replacing the tape deck with another tape deck. 

without another element between you users and your website (a reverse proxy), you probably won't find a suitable solution. What we typically do is temporarily switch rules on our proxy to redirect to another web host with the maint page on it. 

Short answer is that I think you'll spend more time, effort and money on chasing this than you ever would save by implementing it. There are few products that can unify management of a disparate collection of technologies, and of the few that exist I can't think of any that are inexpensive or straightforwards to implement. They're typically the kinds of products that starry-eyed execs at large companies roll out under the assumption that it'll magically make IT simpler and allow them to lay off some techs. Given the constraints/circumstances you listed, IMO your best approach would be to focus on reducing/unifying your systems to cut down on variety. Some examples: 

Shame about the Linux requirement. This is exactly what Windows DFS does. Since 2003 R2, it does it on a block-level basis, too. 

This can be caused by faulty memory sticks, motherboard faults, and driver issues. Let us know the make & model of your hardware and we may be able to offer specific tools and methods for you to troubleshoot. First off I would verify your drivers are all in order. If your server is an HP, and you build it from the smartstart CD, the drivers should be kosher and can be (tentatively) ruled out. On the other hand if you downloaded and installed all the drivers manually, or are coasting on the default windows drivers, update them. Once you've run out of easy tests on the drivers, run a stress test on the RAM. Again, your vendor may provide tools for this (HP's are on the CDs that shipped with the server). Some vendors have a tester built into the BIOS menus. If both of these solutions come up blank then post up some more info about the hardware and build method and we can take it from there. 

Check if the VM shows up on the host itself, rather than the vcenter, by connecting directly to the host as root. You should also try deleting from here, if it's listed. If it's not listed, the issue is definitely on the vcenter. Double-check that your account has all the permissions necessary in vcenter, including ability to delete a VM and delete from the datastores. This error can crop up if you only have partial delete permissions. Also, disable all your client plugins in VI Client, restart the client, then try again. If that fails, see if you can delete from the web console on the host machine. 

Did you mention which virtual environment you're using here? Everyone's assuming VMWare so.... You should be able to achieve this with the VirtualCenter/vSphere Convertor plugin. It has options for scheduling and re-occuring conversion jobs, and you can specify both the source and the target as the same VirtualCenter or ESX host. You'll need to enable guest customization on your vCenter, and you can set up a scheduled task in vCenter to delete the Test VM a few hours before the conversion job is due to run. Edit: hmm, no delete vm option in ESX scheduled tasks. Bugger. Could look at doing this from the console with vmware-cmd. 

The event logs are a clearing-house for any messages or errors thrown by the OS, its components, and any software installed on the system. So we can't fully cover all it's potential contents because there's unlimited potential things it could contain and they all require individual treatment. One way to analyze event logs is: 

You must fully qualify the user accounts you are passing like DOMAIN\username or username@domainname Outside of that we need more info about the exact error message. A screenshot would be good. 

Regarding the disconnections, are you running ESXi or ESX? The logging on ESXi rolls over very quickly (especially messages) so you may not be able to go far back enough to see the disconnection information. If this is the case you can rectify it by configuring the host to log to an external syslog server. We've seen host disconnection issues for strange reasons recently, most notably that a checkpoint appliance between the host and vcenter was interfering with packet order (via it's 'Intelligent' IDS) and causing hosts to regularly drop to an unmanageable state until we restarted the management services. Are there any WAN links or firewalls between the hosts and vcenter? 

I'm a bit rusty on Exchange 2007 admin so forgive me if I'm a bit vague: This often happens if someone's mail account is set to forward all of their mail to a third party. Check each mail account for forwarding rules on the server and client. I believe it's also possible to delegate meeting room managers, who will receive meeting invites if the rooms they 'own' are booked. You may also want to check to see if a resource was booked and if so, whether anyone is setup to manage that resource. 

You need a valid system state backup of the domain controller in order to recover it. Quite how you get that could be any number of ways, including booting into safe mode, or bringing the server online using the original disks in replacement (but very similar) hardware. Or safe mode. Without a valid system state backup in your hand I believe you either have to recover the original server somehow, or start again from scratch and re-add all your machines to the new domain. 

Active Directory and DNS are tightly integrated. If you are running AD on this same server, and you've removed the DNS role from the server, you've probably stuffed AD quite badly. If you have another AD-integrated DNS server in your environment, try setting your server's DNS entries to point to that remote server for its DNS lookups. Once you've done that, AD should be able to come up properly. Once AD is up properly, you should be able to DCPROMO the server so that it's not a domain controller anymore, and once you've done that, you should be able to install a standalone DNS role without AD integration. 

First off the usual disclaimer: VMWare is a company, not a product. Name the product that you're referring to, because they vary in their operation quite drastically. The stats within the guest operating system are only what's visible to that OS. It has no visibility of the load that other VMs on the same host may be generating, so you're only seeing your slice of the pie. That said, in an uncontended (low-load) environment, what you see is probably quite close to what's available. But if overall host load or individual VM load is high you're almost certainly not seeing the complete picture from within the VM. The CPU ID that's reported is usually the actual CPU of the host machine, unless CPU masking is being used (not that likely). You can't tell how many sockets or cores are available on the host via the guest, however. 

James, why not configure the ESX hosts at the remote location so that their guests are in a DMZ, but the ESX service console etc are in a back-zone subnet that you can establish a VPN with? That way, your hosts are isolated from web connectivity (a good thing) but your guests can continue to operate front-facing. As for the remote site problem... you really need a site-to-site VPN link going on here, between your internal LAN and the remote (non-DMZ if possible) subnet. 

1. Performance In my experience, SAN storage and DAS storage have different characteristics which make performance hard to measure objectively, since workloads tend not to rely on just one metric (e.g. access time), but rather a variable blend of access time, throughput, read vs write, etc. It's a very complex picture. The main benefits of a SAN, IMO, are having your data available to several hosts simultaneously (allowing for clustering/high availability), and unifying the storage of your data allowing for easier management and maintenance. So long story short - I wouldn't sweat performance all that much for DAS. 2. SAN Availability & Cost You don't have to go with off-the-shelf discrete SAN solutions. Many folks are building their own since a collection of regular server parts can get you a fully functional SAN system. Here's one route to that: 

You can copy the output directly into your windows clipboard by 'piping' to 'clip' so your command would look like this: 

Does the server have a battery-backed cache for the storage controller and if so, is the battery missing, disconnected or failed? Dramatic differences in throughput like you describe have been seen in instances where the cache is missing, malfunctioning or disabled on a server, vs an identical server where the cache is operating correctly. On a brand new machine, there may be a period when you first power it on where the battery-backed cache is charging, and caching will be disabled until it's ready to go. This can be up to 24h after it's initially powered up. Also, during RAID rebuilds, caching is often disabled by the controller. Check the perfomance again once the rebuild is complete. 

The error is telling you that there's still DNS entries for your dead DC in the domain. Specifically, there's probably still an A record for DOMNAME.A.B that points to the IP of the dead DC. You need to step through the process for completely removing the dead DC from your domain (which is more involved that just turning it off). See here: $URL$ Once you've done that you can probably get through without the error. Note that your replacement DC should have a different name AND IP to the failed DC, ideally. 

This process depends on your SAN, ESX and Switch capabilities being able to support a full MPIO configuration, and being configured appropriately. Depending on your SAN model, this guide may be appropriate: $URL$ $URL$ After a bit more reading, some say ESX 3.5's software iSCSI initiator doesn't support MPIO, while ESX 4 does. We have MPIO implemented on ESX 3.5 over iSCSI with the Software initiator, for a Clariion unit... so YMMV. 

The question isn't clear enough yet. Is the user signing into the Terminal server when in the office AND when working remotely? Or just when working remotely? If the user only signs into terminal services remotely, then the solution is to apply a loopback policy applied to your terminal services OU. Greg's answer then contains the kind of policy settings you'll want to apply in that GPO. On the other hand, if your user signs into the Terminal server both remotely, and when in the office, and must do so with the same user account, you're in a whole world of hurt. I don't think there's a supported configuration for you if this is the case, without getting into nasty hacks. It may be worth looking at creating a site in AD for your VPN clients, then applying a policy to that site to restrict network browsing, but I don't think that'll apply if the user connects to a terminal server. Still, it's the only avenue I can see that might get you the right results. 

As already mentioned, your exchange install/uninstalls will probably be making changes to the Active Directory environment as well.... and AD doesn't play ball with snapshots. If you roll back a domain controller without carefully rolling back all other DCs at the same time, the domain will pretty much crumble. One possible approach may be: 

Deliver to internal users? No. This is primarily a feature of Google Mail and isn't part of the feature set of Exchange. It may be available via an add-on component but I'm not aware of one. As for delivering from Exchange users to GMail users, it should work fine with no configuration changes. 

Some folks see this as sloping-shoulders shrugging off responsibility, or are lulled into the notion that they must be able to answer any question authoritatively no matter the subject. Often as IT folks I think we get lulled into a sense that we are expected to answer authoritatively on any subject, and not just the one in which we're knowledgeable. So yeah... Learn and apply appropriate boundaries of responsibility to your role, and the non-IT people in your organisation will appreciate and respect your understanding of how IT fits into the business. You'll avoid a reputation of being a loose cannon, difficult to control, or arrogant. Not to mention protecting yourself against any ramifications that may arise down-the-line if the decision that was taken leads to problems. Oh and in conjunction with the above and as a seperate principle in its own right: Always establish an email trail of decisions so that they can later be traced back and proved.