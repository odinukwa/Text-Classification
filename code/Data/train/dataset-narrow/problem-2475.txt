The other side of the classical algorithms to estimate the volume of a convex polytope is linear programming. I don't know there has been any progress finding a quantum acceleration for that. It seems difficult to avoid a stage of linear programming in order to put the convex polytope in a favorable position for sampling. 

The question is usually taken to be moot, for the following reason. Grover's algorithm is a combinatorial search algorithm to find a solution to an arbitrary predicate. While, yes, $\Theta(\log N)$ is the quantum gate complexity in each stage of the black-box algorithm, the predicate needs to be computed too. The quantum gate complexity of that is $\Omega(\log N)$, because otherwise it wouldn't read the whole input and you could discard some of the input bits from the search. On the other hand, an interesting predicate could take a lot more time than that. Hence, the number of calls to the predicate is taken to be the standard coin, just as it is for the classical analogue of Grover's algorithm, namely random guessing. 

I am given a 3D model represented by its outside surface as a triangular mesh (hollow inside). The model is mostly 2-manifold, so that each triangle edge is shared by exactly 2 triangles. This, naturally, means that every triangle has exactly 3 neighbors (except at non-manifold bare edges, but we can ignore this case for now). The mesh is represented as an array of triangles. Assume that I know the indices of each triangle's neighbors. Is there an algorithm for reordering the triangles such that most triangles are very close to all 3 their neighbors in this 1D ordering? I suspect this is an NP complete problem, but I wonder if there are approximation algorithms. Here's what I found but all seem unsatisfactory: Space-filling Hilbert-like curves (e.g. for triangular grids). Even if I could generate such a curve for arbitrary topology (non-regular) meshes, these do not preserve or minimize overall locality: 

The gist of the question is, given that quantum probability is a source of true randomness, how does that effect the extended (or efficient, or polynomial-time) Church-Turing thesis? The answer is that, per conjecture, it doesn't affect it. People conjecture that BPP = P, i.e., that randomized algorithms can be derandomized with pseudo-random-number generators with polynomial overhead. Faith in PRNGs as a replacement for true randomness is one reason that people would believe the extended Church-Turing thesis if not for quantum computation. 

arXiv:quant-ph/0104137 - Quantum Walks on the Hypercube arXiv:quant-ph/0205083 - Quantum random walks hit exponentially faster arXiv:quant-ph/0301182 - Decoherence in Discrete quantum walks arXiv:quant-ph/0304204 - Controlling discrete quantum walks: coins and intitial states arXiv:quant-ph/0411065 - Quantum walk on a line with two entangled particles arXiv:quant-ph/0504042 - Entanglement in coined quantum walks on regular graphs arXiv:quant-ph/0609204 - Quantum speedup of classical mixing processes arXiv:0804.4259 - Speed-up via quantum sampling A random walk approach to quantum algorithms Discrete quantum walk for solving nonlinear equations over finite fields 

What is guaranteed, is that close points on the 1D curve will tend to be close in 2D space, but the converse is not true (i.e. close points in 2D space will not necessarily be close on the 1D curve) and that is what I want . Adjacency Matrix Bandwidth Reduction Another approach I considered was creating the adjacency matrix for the triangle neighborhood graph where each node in the graph is a triangle and there is an edge between each pair of neighboring triangles. The adjacency matrix is symmetric very sparse since each node has (at most) 3 neighbors. I'd like an algorithm to reorder the columns and rows of the matrix such that most of the sparse entries are as close to the diagonal as possible. This is called matrix bandwidth reduction, and is an NP-complete problem, but it has several well known algorithms such as the reverse Cuthillâ€“McKee algorithm (RCM). This algorithm and its variants are essentially variants of the breadth-first-search algorithm. However, IIUC, in my case the graph is mostly locally planar, so the algorithm will essentially generate a spiral of interleaved triangles from and around the start node. This spiral will cause each triangle to get farther and farther away from at least 1 but sometimes all 3 of its immediate neighbors by a distance that is proportional to the circumference of the spiral at that point. I prefer fewer long non-local hops to many shorter non-local hops. Am I missing anything? Is there another approach I could take? 

There are ways to see that either the answer is probably no, or that the question means more than one thing and has a negotiable answer. On the one hand, the PCP theorem says that many, but not all, NP-hard problems are still NP-hard to approximate. The standard belief is that Grover's search algorithm, which gives you a quadratic speedup but no more than that, is the best quantum algorithm for the hardest NP-hard problems. This leaves fairly little wiggle room to expect any quantum algorithm to have any special relation to approximation to NP-hard problems in general. Some NP-hard problems are easier to approximate than the ones amenable to the PCP theorem. However, the difficulty of approximation is then highly variable. Meanwhile Shor's algorithm does something very specific: It finds the period of a periodic function on the integers or on $\mathbb{Z}^n$. This problem is also in the complexity class SZK, for example. Maybe you could cook up an approximation problem to an NP-hard problem that lands you in SZK or period-finding, but I suspect that there aren't any known, natural examples of that. 

Here is a necessarily wrong proof of $P \neq NP$ as it relativizes, but I can't find the error : Le $U$ be a universal Turing machine, whose inputs are restricted to Turing machines accepting languages in P. Let $L = \mathcal{L}(U)$ the language accepted by $U$, hence the acceptation language restricted to P. 

If we look at DTIME hierarchy theorem, we've got a log due to the overhead in simulation of a deterministic Turing Machine by a universal machine : $DTIME(\frac{f}{\log f}) \subsetneq DTIME(f)$ We haven't this kind of overhead for NTIME of DSPACE. A basic justification comes from the details of the proof by considering the difference between simulators. My question is the following: without considering the detail of the proof of DTIME hierarchy theorem, is there a justification of this log or it could be just a consequence of the proof and it would be reasonable to imagine that if $f = o(g)$ then $DTIME(f) \subsetneq DTIME(g)$ In my opinion, considering that the simulation explanation is a good justification should be itself justified by proving that if we had a better result, then we could create a better simulation. 

I am trying to grok dependent types, and there's something that I find unclear. In C++, templates can have non-type (template) parameters. The values of these parameters have to be specified at compile time, and it is then - at compile time - that the value-dependant types are defined/created/generated/declared. It is not possible to generate a dependent-type with a run-time value. Beyond syntactic differences, how are languages with dependent types like e.g. Idris different from what C++ does (albeit with somewhat awkward and possibly convoluted syntax)? After all, the whole point of their strong type systems is also to catch type errors at compile time, so obviously any runtime behavior is already after all the compile time checks have succeeded. If I was to define the proverbial fixed-size list/vector type (where the list size is embedded in the type), then would return a (new) list of a new type with the new incremented size specified as part of the type. In C++, you would need to know the actual types, i.e. the size of the list, at compile time. There is no way to call on the result of the previous call, a runtime-determined number of times (as in a loop), because there is no (obvious) way to specify the type of the object to hold the previous result at runtime. Calling it recursively would cause a compile-time stack explosion. What does e.g. Idris do that is different? What extra power comes from dependent-types in languages that support them? Alternatively, what is C++ missing to be considered as a language that supports dependent-types? 

Assume $P \neq NP$ Let use the following notation ${}^ia$ for tetration (ie. ${}^ia = \underbrace{a^{a^{\cdot^{\cdot^{\cdot^{a}}}}}}_{i \mbox{ times}}$). |x| is the size of the instance x. Let L be a language, $L|_{f(i)\leq |x| < g(i)} := \{ x \in L \mbox{ | } \exists i \in \mathbb{N}\mbox{, } f(i) \leq |x| < g(i) \}$ What is the complexity of the following languages : $L_1 = SAT|_{{}^{2i}2 \leq |x| < {}^{2i+1}2}$ $L_2 = SAT|_{{}^{2i+1}2 \leq |x| < {}^{2i+2}2}$ As $L_1 \sqcup L_2 = SAT$, they can't be both in P under the assumption that $P \neq NP$. As there both have exponential holes, I don't think SAT can be reduced to one. Hence the intuition would be that they are both in NPI, but I can't find a proof or disproof. Two others languages are $L_3 = SAT|_{|x|={}^{2i+1}2}$ $L_4 = SAT|_{|x|={}^{2i}2}$ If one of both is in NPC, the other is in P because for each instance of one, it can't be transformed into an greater instance of the other because it is of exponential size, and smallers instances have a logarithmic size. Still by intuition, there is no reason why they would have a different complexity. What would their complexity be ? Ladner's proof of NPI problems under $P \neq NP$ assumption use languages like $L_1$ or $L_2$, but $L_1$ and $L_2$ aren't built by diagonalization. 

Roughly speaking, in Ruppert's Delaunay Triangulation refinement algorithm, so called encroached edges are split until no more encroached edges remain. The algorithm specifies splitting the edges at their midpoint (except in the case of small input angles where concentric circular shells are suggested. This question is unrelated to these cases.) In certain domains, given a segment, there are points on the segment that I would prefer to split on that are not necessarily the midpoints (unrelated to the concentric shell trick). These points are chosen based on some domain specific underlying data (considerations beyond the graph structure the algorithm is aware of). 

Another way to ask this is: Are there split points that are better (by some interesting measures) than the a-priori selected midpoints?