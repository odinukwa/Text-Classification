Wi-Fi is two-way, so if you had a WAP that could cover 10 km, the clients could still only use it within 100 meters (the IEEE 802.11 maximum distance) because the client radios will only work that far. Since the airwaves are a shared medium using CSMA-CA, you can't evenly divide the bandwidth among Wi-Fi clients for a first come, first served medium. I think you need to do some research about IEEE 802.11, how it works, and the laws surrounding the use of unlicensed radio, before you do anything else. This is a subject far too broad to be discussed here, and product or resource recommendations are specifically off-topic. 

First, I do not see why you have Area 1 and Area 2. Those two areas seem gratuitous. You could make those two links Area 0 links because they will only advertise the link addresses. Each OSPF router in an area has a full understanding of all the routes and routers within the area. Also, what are your intentions about the user LANs? Are they going to be in a separate area(s)? It seems that you really only need the single Area 0 unless you have other routers out on the user LANs. 

The security part comes from using VLANs. Users and devices on one VLAN cannot communicate with users and devices on another VLAN, except through a router. This gives you the opportunity to place restrictions (firewall, ACLs, etc.) on the VLAN-to-VLAN communication. VLAN tags are used on a trunk, where traffic from multiple VLANs travels, in order to tag the frames so that switches know which frames belongs to which VLAN. Most end-devices don't understand VLAN tags on frames, and tagging frames to an end-device will usually result in the frames being dropped. This part isn't really about security, except where it helps keep the traffic separate on trunks where there is traffic from multiple VLANs. 

Yes, there are ethernet loopbacks that connect the Tx and Rx pairs (more difficult on 1000BASE-T because it uses all four pairs for both Tx and Rx), and this may be configured at layer-1 or layer-2 on some ethernet interfaces. Ethernet devices usually detect a loopback, and some interfaces will display errors when keepalives are looped back. Also, you must remember that ethernet runs on different media, so you must have the correct type of loopback for the medium you are testing. 

To answer questions two and three (question one is for a home networking, consumer-grade device), DHCP for VLAN 2 is done on the switch, rather than the router, so the router doesn't know about them, either through DHCP or via layer-2. You could run DHCP for both VLANs on the router, then the router will know about devices on both VLANs, or you could run both VLANs on the router so that it can see all the devices via layer-2. 

What you really need to do is to get a wireless site survey completed. This will give you the required WAP quantity, placement, frequency, etc., and identify problems like radio shadows and outside interference. The survey can take into account the locations where you do testing (outside interference), and assign a particular frequency to use for the testing in a particular location. The survey is also three-dimensional. Randomly assigning frequencies to your WAPs is never, ever a good idea. 

The EtherTypes you mention ( and ) are registered. The EtherType of is registered, and it is used by Provider Bridging (IEEE 802.1AD) & Shortest Path Bridging (IEEE 802.1AQ). The EtherType of is registered, and it is used for VLAN-tagged (IEEE 802.1Q) frames with double tagging. 

You are experiencing an intermittent hardware failure. That would need to be fixed by Cisco, but you are more than four years beyond the last day of support for that switch model, so you are out of luck there. It is time to replace the switch. It may soon fail completely, and you will not be able to get it to run at all. 

Yes. There are "BX" standards, e.g. 100BASE-BX, which use different wavelengths for send and receive. The transmit wavelength on one end needs to be the receive wavelength on the other end. For example, Cisco has these transceivers: 

I think you are really asking about the difference between trunk interfaces and access interfaces. An access interface is an interface where you connect and end-device (PC, printer, etc.). Most end-devices do not understand tagged frames. The switch will only send frames for a particular VLAN through an access interface, and it assumes any frames received on the interface are for the VLAN configured on the interface. Trunk interfaces carry frames for multiple VLANs. In order for a device on the other end of the trunk link to separate the frames into the correct VLANs, you must tag the frames (possibly except frames for a single VLAN, which would be the native VLAN for that trunk). Some end-devices may be configured to understand tagged frames and use a trunk. This is done by creating virtual interfaces, one for each VLAN. 

VLAN tags are used to mark which ethernet frames belong to which VLAN on a trunk link, usually between switches. Setting an access port to VLAN 201 does not add VLAN tags to the frames because most end-devices do not understand VLAN tags in an ethernet frame. By setting a native VLAN on a trunk, you are saying that that particular VLAN will not have a VLAN tag. All you need to do to tag frames is to set the interface to trunk. For any VLAN which you want tagged, do not set that VLAN to native. Something like: 

First, the OSI model is just a model, and things in the real world do not necessarily match. In particular, OSes, do not implement the Session and Presentation layers separately from the Application layer. The network (Internet for the TCP/IP model) layer is connectionless. The two most-used transport protocols are TCP and UDP. TCP is connection-oriented, but UDP is connectionless. Since the OSI model is an ISO standard, the ISO/IEC wording is what you should go by. 

That depends. If it is done correctly, each flow would get a maximum of 1 Gbps, but with multiple flows, you will be able to use the full 2 Gbps. Some people, on some equipment, can, and will, configure round-robin balancing, but that leads to problems like out-of-order packet delivery, which can completely kill real-time applications, and it can actually degrade your performance to less than 1 Gbps per flow.. Correctly done, you use a hash algorithm to determine which flow gets which member interface. This will limit a single flow to a percentage (possibly 100% on a lightly used link) of a single link in the channel. This will average out to using the whole 2 Gbps of the channel with multiple flows. 

Yes, it will cause TCP to take longer to send something to your network, but it will be sending at a reduced rate (lower bandwidth), giving other inbound traffic a chance. It will actually be consuming less bandwidth, but more data usage over a longer period of time. Do not confuse bandwidth and data usage. Bandwidth is the maximum number of bits a link can handle per second, but data usage is how much data is actually sent or received over a period of time. They are very different terms, and many people confuse them. You can't really do much about connectionless (UDP or other) traffic clogging your inbound bandwidth, and a single host could practically monopolize the bandwidth inbound to your network. 

WIC (WAN Interface Card) slots are small slots that accept interfaces that are primarily used for WAN connections, e.g. T1. As I recall, there were some ethernet WICs that could be used in the 37xx routers, but the actual throughput is limited in the WIC slots compared to the NM slots. NM (Network Module) slots are larger than WIC slots, and have a higher throughput. The NM cards generally have more processing power than WICs, and can offer more LAN-type interfaces. The 37xx series of routers went EoL (End of Life) six years ago, so Cisco no longer supports them. You will need to use a newer, larger router if the 3725 doesn't meet your needs. That is why Cisco has different models; you can choose the model that best fits your needs. 

A static route such as this has a really low AD (default is 1, and lower is more preferred). You can add a second default route pointing to your backup next hop, but assign it a higher AD (for example ): 

A NetFlow collector can be the collector for many devices. The collector knows where each record comes from by the source address of the sender. How does a web server know which host to reply to when thousands or millions of hosts send it requests on the same port? It's the same thing. How the collected records are presented is up to the application you are using to view them. 

The default speed and duplex of a Cisco 29xx fast ethernet switch interface which was reset to default settings would be Auto. ARP frames are really no way to measure an interface speed. An ARP request receives an ARP reply. You cannot measure the interface speed from that. One problem could be that one side of the link is set to Auto, but the other side is set to a fixed speed and/or duplex. That will cause serious problems on the link, and it could look like your link speed is very slow. You will get a lot of interface errors and that will cause re-transmissions. See this Cisco table for the combinations which can cause duplex mismatches. 

A simple Internet search will turn up a lot of information on this subject. if you add to your search, you will get links to the RFCs. For instance, RFC 793, TRANSMISSION CONTROL PROTOCOL: 

You can send configuration commands to the syslog server with the command (Cisco IOS Configuration Fundamentals Command Reference): 

Your symptoms point to an overloaded power supply on the switch. PoE switches, especially low-end models, can usually only handle a few PoE devices. There should be some power commands in the switch to show you the power status, and allow you to enable/disable PoE on the ports. Per your comment, it was a power problem, and disabling PoE on the switch solved the problem. 

Switches don't get involved in layer-3 (e.g. IP). A switch is a transparent layer-2 device, so hosts connected to a switch will have no problem getting to a DHCP server on the same LAN. 

RIPv2 with the option will advertise the specific routes, not the aggregated prefix, unless you you use the interface command. The network statements in RIP are not specifically telling RIP what prefix(es) to advertise, they tell RIP which interfaces should participate in RIP, and RIP will get the specific prefix(es) from the interface(s) which fall into the network statement. This is true for most routing protocols on Cisco routers, and it is a source of confusion for many people. For instance: 

Having the NTP source based on the loopback is a good idea. If one link goes down, NTP can still be updated if the traffic can get to and from the server via a different path. The command will be used for commands on which you don't use the optional for any of the ntp peer ` commands. The command will be used for commands on which you don't use the optional for any of the ntp peer ` commands. 

The link will probably glitch when you do this, and if you make an error, you will likely send ports into . The real way to do this is to shut the ports down, build the port channel interface, add the ports to the channel, then bring up the ports. Also, understand that you will not increase the usable bandwidth for a single data flow. Each flow will only use one of the links in a port channel. 

The various optical ethernet standards use different wavelengths, light sources, and fiber diameter. Copper-based ethernet sources can change frequencies, and use, relatively, the same medium (Category-6A can run all the current ethernet standards which use UTP). A laser or LED would need to change the light source, so you just change the SFP/SFP+ module. SFP and SFP+ modules are specific to the standard which they support. For example, even among 1 Gb optics, there are multiple (a half dozen, or so), standards requiring different SFPs, toss in the different 10 Gb SFP+s (another half dozen, or so), and you have around a dozen different 1 and 10 Gb optical ethernet standards, most requiring a different transceiver. 

If you are going to configure multiple NTP servers with the same authentication keys, it will probably look something like this: NTP Server 1: 

This is expressly forbidden by the standards; you are not allowed to mix applications in the same eight-conductor sheath, even on different pairs, but you can mix applications on a 25-pair sheath, as long as the applications are electrically compatible. You would never get such mixed use to pass the required tests. You will create impedance mismatches and asynchronous echoes from splitting off the applications, and it would cause problem with the various measurements (e.g. frequency, insertion loss, NEXT, PSNEXT, FEXT, ELFEXT, PSELFEXT, return loss, propagation delay, delay skew, balance, longitudinal conversion transfer loss, etc.). POTS also uses a high voltage to indicate RING, and this would be detrimental to network equipment. Why, in a world of VoIP, would you want to remain with POTS? 

You are describing a problem called collision. There are different network media and protocols that are subject to collision, and the protocols must have a method to detect when that happens. Your question is really too broad to go into details, and those will vary with the medium and protocol, but I will give you some information. The original ethernet was on a shared medium (coax cable) where more than one host could send at the same time, and is uses CSMA/CD (Carrier Sense with Multiple Access using Collision Detection). A host needs to listen to the medium to see if it is free before sending, but that doesn't guarantee that there will be no collision because it takes a finite amount of time for a signal to cross the medium. The ethernet hosts will detect a collision and send a jamming signal, back off a random amount of time, and try to resend. (Switched ethernet has eliminated collisions for all practical purposes.) Wi-Fi also uses a shared medium, so it is subject to collisions, and it uses CSMA/CA (Carrier Sense with Multiple Access using Collision Avoidance), but that doesn't mean that it can entirely avoid collisions.