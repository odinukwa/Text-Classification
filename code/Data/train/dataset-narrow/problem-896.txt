Statistically insignificant errors You have another alternative too, which is to reduce any modulo bias to a statistically insignificant amount. You do this by using significantly bigger random numbers (bigger than 256). Combining multiple bytes for each output byte would accomplish this, for example, using 4 bytes. Using more bytes would further reduce any modulo bias: 

The bottom line is that power-of-2 sizes for hash tables are very, very convenient. It means we can do a very fast bitwise AND-operation, instead of an expensive Modulo operation. Sicne this is a common operation in computing, it is worth learning that it is there, and how to do it. In Java, there are language details to help, as well. So for example, if you want a table to have a size of about 50.... we convert that to a power of 2 as follows: 

Note, in the Java 8 example, I allow the sub collection to be any supported type that you can add the content to. So, for the above example, the input is an inaccessible list (no public default constructor), but the supplier gives you what you need. 

There are a number of things that could be improved here. You're doing the right thing with the pre-compiled regular expression/pattern, but, you have fallen victim to the little-known auto-format-muck-up-monster, and what I consider the magic-value-overcompensation issue: 

This is one way to do it, but the parsing could just as easily be done with a StringTokenizer (and some people prefer this method for a variety of reasons even though it is 'Discouraged' in the JavaDoc). I quite like the simpler process of using String.substring(...). With a simple token system (like a comma) it is easy: 

Java is an Object Oriented language... and I recognize that objects are not always the right solution to a problem.... The generally accepted "opposites" of object-orientation, though, are "procedural", and "functional". It is common (for example, in C) to write code as a collection of procedures, or (in haskell) to write it as functions. In almost no languages, though, is it common to have no procedures, no objects, and no functions... well, except shell scripts, I guess. Your program has no methods, no objects, no functions, except the main method. You need to break your code down in to parts that do logically isolated things, and then call those reusable chunks when needed. Function 1 The first function I would extract, is a start-of-game match-count: 

I should point out that your code does not conform to the specification in one specific way. An entry of negative values should fail to validate, but your code will happily assign it the grade . Additionally, I am uncertain about your top-of-range validation. You fail to validate the value 1.0 which I would expect to be graded as an . The specification is slightly obscure about that, but, I would expect 100% to be possible. Note, your 1-value test system of 0.85 is inadequate. You should read up on test strategies, especially on boundary conditions. Your tests should ensure the correct values for at least the following inputs: 

then you can monitor just a single channel, and can also correlate any results to a name in a better way, and also correlate an error better too. Concurrency The use of the channel is OK for concurrency, but for a job like this I would instead defer to having a more discrete mechanism. Have a channel that you push domain names on to from the CSV parser, and then have X number of concurrent go-routines reading from that. Closing the channel indicates no-more-data to process. Use wait-groups to monitor completion.... 

Now, suddenly, your code hangs and does not complete. When using synchronization it is almost always a bug to have a synchronization point on a public/leaked instance. Apart from that issue, the synchronization looks complete, but excessively scoped. You lock the whole data structure. Your instance is 'serialized', no matter how many threads you have, only one thread can be doing anything at any one time. There has to be a better way.... Alternate scheme If it was me, I would consider a combination of the AtomicReferenceArray an AtomicInteger, and a ReentrantLock. The system would look something like: 

Have you tried to benchmark your solution against a simpler non-parallel one? go-routines are really cheap, but that's relative to real threads. Your use of the go-routines at such a granular level, and the heavy use of the channel as a queue, are bound to be causing all sorts of memory contention. I suspect that if you just process the whole lot in a single routine, with a simple slice, that things will be a whole lot faster.... and simpler. So, turn in to a (a slice with capactiy for possibly everything), and then append flood-candidates to that. Your map should also possibly be a instead of . It makes the logic easier later... instead of: 

So, as an exercise, I took your code, and implemented both a state-machine and a Scanner implementation. I have used statemachines in the past to parse comma-separated value files, and the process was very fast... I figured it made sense here too. The Scanner is more complicated than I would have hoped, but you may find the implementation to be educational (I did). As for a review of your code.... I found it 'easier' to write it again myself, than to try to understand yours. In a sense, that says a lot. 

In general, I am impressed with the test coverage, the attention to detail, and the overall structure of the code. It is easy to follow, and understand. Having said that, there are a few places where it can be improved. processing You code uses directly to set up the help mechanisms, and also for the count parameter. You should consider driving a FlagSet directly. Your code: 

Now, in your function you would produce the ID by shifting the X, and the hash, by the modulo of the table size. Let's assume the table size is 32768 (a nice big value that should eliminate collisions, right)? 

I agree with Janos that, as you currently have it, the code will be improved by putting the static inner classes in regular abstract class files.... but, I would go further than that. Your code has the feel of being inverted. I would recommend you have two interfaces: 

A huge amount of you work is just plain work that has to be done.... (the joys of brute-forcing). MessageDigest On the other hand, this work is unnecessary: 

OK, that's some relatively simple stuff. Messing your code around using the above suggestions I get: 

In general, you should use one, and only one synchronization strategy in any class. You have synchronization, and are contemplating volatiles too. The best-practice mechanism for now in Java is using the classes from to manage locking, and memory synchronization. The benefit from there that will help you most, is the Condition concept, as well as the fine-grained management of locks. Your locking at the moment relies on a 'global' lock that all events use, thus if you have many collections of events running, each collection uses the same lock. Thus, if some other Events are happening in some other code block somewhere, we will still be notified or each of those 'remote' event completions, and our completions will notify their awaits.... Additionally, I did not like the way you manage the await-any concept. You literally scan the Events for changes, and check for one to complete. In essence, I dislike: 

While you were clear that the () method is final, and can't be overridden, you have not made the method final. This allows overriding classes to alter the way the events are handled by the queue. That's a bad thing. The should be final. Your abstract method looks fine, but I would synchronize the parameter name with the () method. Currently your parameter is but I would call it ... so it would be: 

In terms of the raw/basic functionality, what you have is fine. The transactional logic is good. Readability is the only concern I have, and would rewrite your code as (note, there are some spaces I added around some conditions): 

This would be a good opportunity to learn some performance features and limitations of the Java Virtual Machine, and the available libraries. I want to take your code, go through a staged progression of optimizations that will improve the way the code performs, and, while it will not change the runtime 'complexity' \$O(n^2)\$ of the insertion sort, it will improve the actual runtime. As Nick has suggested, your variable names are not very meaningful. He's suggested and . I can use those, they are good. So your code becomes: 

Trust... it's all about trust. Trust your is accurate (if it is not, you have other problems). Then, your code becomes a simple loop: 

Edit: Based on the benchmarks for my browser (Firefox), a decrementing while-loop is much faster than alternatives. I would use: 

So, that class declares an abstract method that the child classes will need to implement, and the abstract method will do the child-specific checks: 

Use references that are unique and not related to the name. I would consider using the attribute name 'id' because that has some advantages: 

(I have checked that using my ID number, and it's OK) Update Note I have been doing a little more reading on Luhn's algorithm because of @Molvalio's comment and also I remember doing it a couple of decades ago for other numbers (not ID numbers) and I remember the checking algorithm to be different to this implementation. I was right that checking the number is simpler than your code. See the algorithm here: Luhn's Algorithm Verification The point is that your code is computing a check-digit and comparing it with the existing digit, but you're missing the fact that the digit is designed to be incorporated in to the same calculations as the checksum, and a valid number has a resulting digit of 0. Additionally, the Luhn's algorithm is computed right-to-left. In your case, because the length of SA ID numbers is 13, you're OK (both left and right digits are odd) but you should implement the algorithm more closely.... So, the code can be simplified further: 

there's no generic type for the Multiton. This is expected. All it needs is the public method, and the generics for that method are determined by the call arguments.... which is point 2.... the generic type of the values are declared on the Creator (which is also the key). In other words, each key knows what the type of the value should be. This means that the generic type is 'recorded' at create time, rather than retrieve time. There's no need to pass a class in to the call since the class is actually part of the . I created 2 'helper' classes that are Creator instances. These classes and are simpler ways to actually create anonymous, or Java-8 based Creators. 

That function is doing too many things .... hmmm actually it's just got a useless outer loop. The "scan" loop is all you need. The will only terminate the loop when the connection is closed (the Reader returns an error - presumably , but any other error has the same consequence... is not readable). So, remove the outer loop, and, we know that the scanner will return an error too, so the condition at the end is not useful. This leaves: 

Just use a LinkedTransferQueue and deal with duplicates elsewhere (use the add and poll methods respectively). Just use a List with a simple and basic synchronization. 

Now, the bulk of the hard logging work is not even on the threads that are doing the real work. You also have a multi-threaded environment and thread-safe logging. If logging starts backing up, you throttle the application at 100 events in the queue. Basically, you have a better solution. 

That parser can identify lines that interest it. If the line can be parsed, it is fed back in to the parse method, and all following lines until the parse method returns true. A simple exception is also useful. Making it a makes this easy tp put in to streams at some point too: 

I am working on some multi-threaded code that requires a prime-number source. The following code keeps an array of primes in memory, extending it as needed. It works in the 'int' domain, being careful to avoid overflows, and to keep the memory for storing the data relatively small. it uses a state-based concurrency model... it keeps an immutable state that covers a range of primes (from 1..range). If a request is for some data that is outside that range, it will defer to a backup process which is single-threaded, where one thread extends the state. At any time, some other thread can query the state, and it is not blocked if the existing state covers its needs. The idea is that only one thread is working at a time on calculating primes, and any pre-calculated primes are reused by other threads. Additionally, during prime calculation, if one thread is calculating a really large extension, it regularly creates a new state, then 'breaks' out of the locked code, and allows any other waiting threads to use that new state if it is good enough.... The long-calculating thread will then start again on the next extension. PrimeReserveInt.java 

So, if the suggestions from your reviewer are consistent with the common-practice at your location, then, absolutely, do them. Even if they are not common practice, still do them. But, I have some comments to come after a small diversion..... 

I believe a simple split on newline and a hard-coded parse would be better than the regex solution.... especially if you can trust your input data will be valid. In essence, the grouping and iterative looping in the regex is probably the slow part. Of course, the for each loop is also very slow.... and probably is something you added afterwards? If it is in your actual code, that's almost certainly the problem. Let me explain the hard-parse with a code example: 

There's two things in there, firstly, the comment is a lie ;-) The code does nothing with 8 or 9 decimals... it rounds "half-up". The second issue is that the rounding is inaccurate if/when the is something like , which your code will round-up to 60. This is a problem, because it should round up to 0, and the minutes should be increased (and, worse, if the minutes is 59, you need to round up the degrees... for example, rounding the value 8°59'59.8" should be 9° 0' 0" seconds - but your code gives 8° 59' 60") Half-up rounding There's an easy trick for half-up rounding when dealing with integer-casting in programs, the trick is to add a half-unit to the source value before doing any calculations, and then truncating the result as an integer. For example, to half-up round a float value to an int, you do You can use this in your code quite nicely. I would also reverse the logic you have in your function... convert everything to seconds (half-up rounded in ) and then extract the values from that. Note that you can express the location in total seconds, total minutes, and total degrees, and then get the "remainder" (modulo) to get just the incremental part: 

Your regex is overly complicated, I must admit. The negative lookahead is going to do a lot of work to identify all the negative cases before even looking for (nearly) positive matches. I think the trick you are missing is the word-boundary anchor. Consider the following regex: