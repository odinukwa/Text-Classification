However, calculating some bounds on Ramsey numbers is not as difficult: $$ (1 + o(1)) \frac{\sqrt{2} s}{e} 2^{s/2} \leq R(s,s) \leq s^{-c \log s/\log \log s} 4^{s} $$ My question is: 

A particular model I am working with can only compute a function $f: \{0,1\}^n \rightarrow \{0,1\}$ iff $f(x_1,...,x_n)$ is a linear combination (over $\text{GF}(2)$) of the $x_i$'s or has at most a constant amount of non-linearity. What is the complexity class that most closely corresponds to my model? Non-linearity I am not sure if there is a standard definition so let $S,T \subseteq \{1,...,n\}$, and $x_S$ (or, $x_T$) mean the bitstring from only the bits of $x$ whose index is in $S$ (or, $T$). Then we can define a function as $k$-near linear as follows: 

For bitstring to boolean functions, people usually build binary decision diagrams instead of decision trees to represent functions compactly. If you want to find a small BDD and are willing to sacrifice correctness on a few inputs (as your question implies) then you might want to look into approximate BDDs as studied in the following two papers: Hinsberger, U., Kolla, R., and Kunjan, T. [1997] "Approximative Representation of boolean Functions by size controllable ROBDD's" Ravi, K., McMillan, K.L., Shiple, T.R., and Somenzi, F. [1998] "Approximation and decomposition of binary decision diagrams" I am not sure if there is work that generalizes this for $\mathbb{R}^d \supset \mathbb{D} \rightarrow \{0,1\}$ functions, but I would use those papers as a starting point and do a forward-reference search. 

Hopefully this is not too off-topic of an answer, since it looks at this question from the point of evolutionary game theory (EGT), instead of AGT. Game theory as originally formulated by von Neumann and Morgenstern was a static theory. Hence, many of the popular equilibria concepts (Nash, Correlated, etc) are inherently static. To talk about non-static equilibria, we have to introduce some sort of dynamics. AGT often does this by considering specific reasoning (algorithms) agents might use to arrive at their decisions. An alternative approach, and one embraced by EGT, is to consider the population dynamics of a large number of agents with very simple decision making. This usually creates non-linear dynamics in the population and places EGT as part of dynamic systems. Hence, you start to see all the crazy equilibria concepts of dynamic systems such as limit cycles or chaotic attractors pop-up as equilibrium concepts. These non-stationary equilibria are well studied in EGT, although often the analysis is purely from dynamic systems and not algorithmic. If you are interested in EGT, then a standard (and accessible) starting point is Hofbauer and Sigmund's 2003 survey "Evolutionary game dynamics" 

To make my life easier, I am going to make your definition of $A$s slightly more precise. By input-less I will think about algorithms that run on the all 0s input, and by output of $A$ I will take the decision problem approach: halt and return $D(A) \in \{0,1\}$. The $A$s (including those that don't halt) have some ordering which is easy (i.e. we have an algorithm $N$ running in $O(|A|)$ such that $N(A) = i$ if $A$ is the $i$th program in our ordering) to compute from their code. Now I will define a magical infinite string $d$ (over $\{0,1,\bot\}$). Let $A$ be the $i$th machine in our ordering, if $A$ halts then $d(i) = D(A)$ else $d(i) = \bot$. By $d(1, ..., k)$ I will mean the string $d$ truncated to the first $k$ bits. Fix a favorite universal machine $V$ and consider the following sequence of universal machines $U_k$: 

You don't need to keep track of all $3$ colours for your colouring, because we know how to two colour quickly. Let the colours be $\{0,1,2\}$. Have an oracle $f: \{0,1\}^{|V|} \rightarrow \{0,1\}$ that you interpret as selection a subset $C_0 \subseteq V$ that you will pretend is $0$-coloured. Your circuit then (1) in polynomial time checks if $V - C_0$ is two-colourable with $\{1,2\}$, and (2) in polynomial time checks if $C_0$ is an independent set. If both are true then it returns $1$, else $0$. Now you are searching over only $2^n$ database entries for a marked element and so have the runtime you wanted. 

Here is a sketch of an attempt at partial separation. I was trying to improve this over the past two weeks into a full answer, but haven't made much progress. Hopefully someone else knows how to extend it. Let \[f_{n,m}: \{0,1\}^n \times \{0,1\}^{{m \choose 2}} \rightarrow \{0,1\}\] So we have a total function on tuples. $f_{n,m}(x,y)$ returns $1$ if $x = 1^n$ and if $y$ interpreted as the edges of a graph has a clique or independent graph of size $n$. Otherwise, it returns $0$. Thus if $R_n$ is the $n$-th diagonal Ramsey number then for $m \geq R_n$ and all $y \in \{0,1\}^{{m \choose 2}}$ we have $f(1^n,y) = 1$. Thus, if we can compute $R_n$ on an input of $1^n$ then we don't have to read the bits of $y$ if $m$ is large enough, and the query complexity of the query-optimal algorithm drops to $n$. However, $R_n$ is harder to compute on an input of $1^n$ than it is to check if a graph given by edges $y$ has a clique of independent set of size $n$ on input $(1^n,y)$. Thus, a time-optimal algorithm can't afford to compute $R_n$. It could, instead use some approximation $\tilde{R}_n > R_n$. For $m < \tilde{R}_n$ a time-optimal algorithm will read at least some bits of $y$. Thus, for $R_n \leq m < \tilde{R}_n$ the query-optimal algorithm will use more time to make fewer queries than the time-optimal algorithm. This approach can be made slightly less hand-wavy (or generalized to other Ramsey-like problems) but I think even the more rigorous attempt doesn't fully answer the question. 

Are there problems where the best known time complexity algorithm has a different query complexity than the best known query complexity algorithm? In other words, can we perform more queries to make the between-query operations easier? Or is there an argument that shows that there is always a version of an asymptotically optimal query algorithm having an implementation with asymptotically best time-complexity? 

At the intersection of evolutionary biology and theoretical computer science there are two recent books. 

On input $A$, compute $i = N(A)$ Search $d(1,...,k)$ for index $i$ and output If $i > k$ then output $V(A)$ 

Since you asked about program correctness of real world programs like operating systems, you might be interested in the seL4 project (journal, pdf, conference). The NICTA team took a third-generation microkernel of 8700 lines of C and 600 lines of assembler implemented according to an abstract specification in Haskell. They provided a formal, machine-checked proof (in Isabelle/HOL) that the implementation strictly follows the specification. Thus proving that their program is bug-free. So just like the halting problem, although it can't be solved in general, it can be solved for some specific instances. In this case, although you can't prove that arbitrary C code is bug free, they could do it in the case of the seL4 microkernel. 

Unlike the other answers, this is more along the lines of "things we should worry about when saying something is 'provably secure'" as opposed to places where TCS has been used in security. Thus, it addresses the first question of security concerns when working with theory. As hackers say, theoretical results are often tangential to real-world security. This sort of argument has been made more theoretical, scientific, and precise by Alfred Menezes and Neal Koblitz in their series of 'Another Look' papers (warning: the site seems a little confrontational to me, but I think the basic idea of questioning assumptions is very important). They point out weaknesses in standard assumptions in cryptography, even in seminal papers. Some examples (quoting/paraphrasing a few points from their site): 

I am not 100% sure if this satisfies your condition for non-trivial, but here is a partial counter-example. Take a decision problem $P$ which has a uniform circuit-complexity that is $O(n^{1 - \epsilon})$. For each $n$ consider the $L'_n$ that accepts only those strings that are in $P$ and have length $n$. This $L'_n$ probably has exponential size (if you pick $P$ carefully), however this is a language that accepts based on finite prefix; thus needs to be modified to achieve condition (c). Define $L_n = (L'_n)^*$ (i.e map the initial state an accepting one, and map each accepting state to the initial state). Given an input $(n,x)$ build the circuit $C_n$ run it on $n$-bit chunks of $x$. 

The negative adversary method ($ADV^\pm$) is an SDP that characterizes quantum query complexity. It is a generalization of the widely used adversary method ($ADV$), and overcomes the two barriers that hindered the adversary method: 

I am not sure if this is what Blum was talking about, but it is easy to make an optimal algorithm up to a constant factor for almost any $NP \cap coNP$ problem. Here is an sketch for factoring in particular. Given a number we want to factor N. Is N prime? If so output 'PRIME' else: For $i = 1...\infty$ For $P = 1...i$ Run program P for i steps with input N If P outputs two integers (L,M) and $L \neq 1$ and $M \neq 1$ and $N = L*M$ then output $(L,M)$ 

If a function is $k$-linear on any input size (where $k$ is a constant) then I say the function has a constant amount of non-linearity. If this is not a standard definition, could you point me in the comments to a standard definition? Is my definition obviously equivalent to some other standard definition? Question 

A certificate for an input $x$ is a subset of bits $S \subseteq \{1,...,n\}$ such that for all inputs $y$, $(\forall i \in S \quad y_i = x_i) \rightarrow f(y) = f(x)$. Then $C_x(f)$ is the minimum size of a certificate for input $x$ and the certificate complexity $C(f) = \max_x C_x(f)$. Thus, certificate complexity can be seen as a form of query complexity for nondeterministic machines: guess the smallest certificate for $x$ and then verify with $C_x(f)$ many queries. This is used as an intermediate complexity measure when proving relationships between deterministic query complexity ($D(f)$) and quantum query complexity ($Q_2(f)$). Is it known, or believed that for a total functions $f$, $C(f) \leq Q_2(f)$? Are there any total functions $f$, where it is know that $C(f) \in o(Q_2(f))$ (or vice-versa)? And just for fun: does this question correspond in some formal way to the questions associated NP vs. BQP?