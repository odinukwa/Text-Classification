The traveling salesman problem is apparently accessible... at least where I am, this seems to be the most popular CS problem among non-CS folks by far. I also found the following illustration of Vertex Cover quite appealing, as introduced by my algorithms instructor: You have a road network and wish to ensure that if a car is stuck out of fuel, there is a gas station on at least one end of the road. As a city planner, you want to minimize costs by building the fewest number of gas stations possible. This is essentially the vertex cover problem, and I have found some success in pointing out that although you don't expect to find the optimal vertex cover in polynomial time, you can find something that is only a factor of two away in polynomial time, by simply picking up both endpoints of a maximum matching (well, that last detail might be omitted depending on how keen your audience is - especially since the MM algorithm isn't exactly a two-liner). As for an example of a 'jump in complexity' with a small change in the nature of the problem, I think the difference between checking 2-colorability and 3-colorability makes a good example. With all the publicity surrounding the four-color theorem, one might also point out that checking whether a map can be properly colored with only three colors instead of four is hard, even though we know that it can always be colored with four colors. A fair number of people find this quite startling. Another fairly natural situation is the deadlock recovery problem in operating systems. This is modeled by the NP-complete problem of feedback vertex set - the smallest number of vertices whose removal makes the graph acyclic - and I find this to be a remarkable example as well (and is explained further in that wikipedia article). 

Let $G$ be a simple graph on $n$ vertices $(n > 3)$ with no vertex of degree $n âˆ’ 1$. Suppose that for any two vertices of $G$, there is a unique vertex adjacent to both of them. It is an exercise from A Course in Combinatorics, van Lint and Wilson, to prove that such a graph is regular. My question, however, is whether graphs satisfying the given constraints even exist. While discussing the original exercise during a problem-solving session, someone asked if we could come up with an example of a graph where every pair of vertices have an unique common neighbor, and there are no global vertices. Neither were we able to come up with a concrete example or procedure for construction, nor did we establish a proof that no graph has these properties. Any suggestions? Note: as for proving that such a graph is regular, it turns out to be fairly straightforward, the rough idea is to pair off the neighbors of every pair of vertices using the unique-common-neighbor criteria to establish the fact that every pair of vertices have the same degree, and then a transitivity argument, with the help of the no-global-vertex constraint, gives us that the graph is regular. 

I realize that this might not directly answer your question (about references), but I would like to outline a possible approach for showing NP-hardness without the 2-connected condition. There are two things that are missing: one is a proof of the NP-hardness of the 'source problem', so to speak, and the other is that I'm reducing to a 'colored' version of H-cut that may or may not be useful. As for the first bottleneck, I believe I have a proof in my mind that I am being lazy about formalizing, so I hope I will get around to that soon. I've thought some about reducing the colored version to the one you present, however, with little luck so far. I am also very curious about your proof in the event that H is 2-connected, could you possibly supply some details? So the colored version is the following: each vertex in the graph is equipped with a list of colors from a palette P (a fixed, finite set). We are required to find a cut so that no partition induces a monochromatic copy of H, that is, there is no subset of |H| vertices that induces a copy of H, and the corresponding list of colors have a non-empty intersection. Here's a reduction from a restricted variant of d-SAT, where d is |H|. (Notice that this obviously wouldn't work when d = 2). The restricted variant of d-SAT is the following: 

I would like to document some partial progress - seemingly promising so far - towards a polynomial time algorithm. UPDATE: Added some details to account for a glitch pointed out by @David (thanks!). The approach is to reduce this to an instance of MIN-ONES EVEN-3 CSPs (MOEC), which happens to be a polynomial time solvable problem. The proof of the reduction is a bit fuzzy, but I am hopeful that it exists! An instance of MOEC is a family of $3$-sized subsets of an universe of variables, and an integer $k$. The question is whether there is a satisfying assignment of weight at most $k$, where an assignment is a function from the universe to $\{0,1\}$, the weight of an assignment is the number of variables that it assigns one, and an assignment is satisfying if, for every subset of variables $\{x,y,z\}$, the assignment (say $f$) has the property that: $f(x) + f(y) + f(z) = 0 (mod ~~2)$. You could visualize this as 3-SAT with a different notion of satisfiability - pick none or pick two. I'll be a bit lax about the instance of MOEC in that I will allow for, apart from the usual $3$-subsets, implications, disjunctions of length two, and the constraint $(x = 1)$. I believe these simple additions will keep the problem polynomial time. Let's say we're reducing the addition chain problem for the number $n$. The variable set for this reduction is the following: For every $1 \leq i \leq n$, the variable $N_i$. I will re-write the variable $N_n$ as $N$. For every pair $i,j$ such that $1 \leq i,j \leq k$, introduce variables $P_{ij}$ and $Q_{ij}$. Introduce the following subsets, for every $i,j,k$ such that $k = i+j$: $\{P_{ij}, Q_{ij}, N_k \}$ and the following implications: $P_{ij} \Rightarrow N_i$ and $P_{ij} \Rightarrow N_j$ and the following constraints: $(N_1 = 1), (N = 1)$. Finally, we need to add constraints that ensure that at least one of the $P$-variables are picked when a "corresponding" $N$-variable (forgive the abuse of notation) is assigned one. This can be done by adding the usual OR constraint over all $P_{ij}$ such that $i + j$ sum to the $N$-variable in question. We have to, however, find a way of re-encoding this in MOEC-framework. So let me outline a general way of saying, given a set of variables: $(X, l_1, l_2, \ldots, l_t)$, how the constraint "if an assignment is satisfying and sets $X$ to one, then exactly one of the $l_i$'s must be set to one by the assignment", can be encoded with the MOEC syntax. Note that this suffices for our requirements, we simply introduce the constraints: $(N_k, \{ P_{ij} ~|~ i + j = k \})$. The encoding is done as follows. Let $T_X$ be the rooted complete binary tree on $t$ leaves. Introduce a new variable $T_{di}$ for all $1 \leq d \leq \log t$ and $1 \leq i \leq {\cal L}(d)$, where ${\cal L}(d)$ denotes the number of nodes of $T_X$ at depth $d$. For every node $T_{di}$, if $p$ and $q$ be its children in the tree, introduce the EVEN-3 constraint: $\{T_{di},p,q\}$ This means that if a variable corresponding to a node is set to true, then exactly one of its children must be set to true as well. Now add the implications: $(X \Rightarrow T_{11})$ and $(d_{\log t,j}) \Rightarrow l_j$ (comma for clarity). This combination of EVEN-3 constraints and implications is equivalent to constraint that we wished to encode. Intuitively, what's happening is that the last two constraints trigger exactly the reactions required to build an addition chain. In particular, let us look at the $N_i$'s that are assigned one by a satisfying assignment - the claim is that they will form an addition chain for $N$: since the assignment is forced to set $N$ to one, there must be at least one $P_{ij}$ that was set to one, and the implications force $N_i$ and $N_j$ to be assigned one, and this goes all the way down (I am sure this can be formalized with induction, although I haven't worked out that level of detail yet). Note that a satsifying assignment that is optimal in the number of ones assigned will not set $P_{ij}$ true for two pairs $(r,s)$ and $(r',s')$, for the reason that the $P$-variables come with the additional baggage of the implications, and the $Q$-variables don't (they are there to ensure EVEN-3 satisfiability - on a clause where $N_i$ is true and $P_{ij}$ is not true, we still need to pick something to satisfy that clause, and for reasons that are easy to see, this cannot be one universal variable across clauses). So I believe an addition chain corresponds to a satisfying assignment and vice-versa. Let me describe one part of this somewhat formally: given an addition chain, we construct an assignment $f$ that is satisfying. To begin with, $f$ sets all $N_i$'s that feature in the chain to one, and the other $N_i$'s to zero. Further, if $k$ features in the addition chain, then for each $N_k$, let $i_k,j_k$ be the elements in the chain such that $i_k + j_k = j$. Then $f$ sets $P_{i_k j_k}$ to one (and $Q_{i_k j_k}$ to zero), and all $(i,j)$ such that $i \neq i_k$ and $j \neq j_k$ and $i+j = k$, $f$ sets $Q_{ij}$ to one (and $P_{ij}$ to zero). For all $k$ that don't feature in the addition chain, for all $i,j$ such that $i+j = k$, set all $Q_{ij}$ and $P_{ij}$ to zero (notice that consistency follows from the fact that two numbers add up in only one way). Every clause involving a $N_i$ in the chain is satisfied because either a P-variable or Q-variable corresponding to it was set to one (and notice that exactly one of them are set to one for any pair $(i,j)$). For every other clause, everything is set to zero. That the implications hold is easy to check. The part that is unclear is the following: because for every element $t$ chosen in the addition chain, the assignment incurs a weight of $t$ (because of all the $Q$-variables being set to one). So there is a possibility that a longer additional chain would correspond to a cheaper assignment, but I am quite sure this doesn't happen because of a proof along the following lines: consider an optimal addition chain and suppose there is a longer one that has a smaller-weight satisfying assignment corresponding to it. Clearly, the elements of the longer chain exclude at least one from the shorter one - let that element be $x$. I wish to say that the cost incurred with $x$ is incurred in the longer chain anyway, and the remaining compares favorably. However, I have to write this down carefully, and I might just be seeing things from post-midnight syndrome! 

(I have some idea about why this seemingly restricted version might be hard - a very closely related restriction is hard, and I can imagine a reduction from there, although I could be easily mistaken!) Given this problem, the reduction perhaps suggests itself. The graph has a vertex for every variable of the formula. For every clause C_i, induce a copy of H on the set of variables that participate in the clause, and add the color i to this set of vertices. This completes the construction. Any assignment naturally corresponds to a cut: L = set of all variables that were set to 0, R = set of all variables that are set to 1. The claim is that a satisfying assignment corresponds to a monochromatic-H-free cut. In other words, (L,R), when given by a satisfying assignment, would be such that neither L or R induce a monochromatic copy of H. If L has such a copy, then notice that the corresponding P-clause must have had all its variables set to 0, which contradicts the fact that the assignment was satisfying. Conversely, if R has such a copy, then the corresponding N-clause must have had all its variables set to 1, contradiction again. Conversely, consider any cut, and set the variables on one side to 1 and the other to 0 (notice that it doesn't matter which way you do it - given the kind of formula we're working with, an assignment and it's flipped version are equivalent as far as satisfiability goes). If a clause isn't satisfied by this assignment, then we can trace it back to a monochromatic copy of H on one of the sides, contradicting the monchromatic-H-freeness of the cut. The reason one has to indulge in the coloring is because copies of H can interfere to create spurious copies of H that don't correspond to clauses, in a direct reduction attempt. Indeed, it fails - badly - even when H is something as simple as a path. I've had no luck in getting rid of the colors, and I am not sure that I have made the problem any simpler. However, I do hope that - if correct - it might be a start. 

Let me try to give an explicit two-way reduction that should make the FPT/W-hardness in different situations clear (it's strongly recommended that you look up the excellent references in the other answers, as this is just something I worked out after reading your question, and I could have quite easily missed something). I'll work with the following problem: we are given a family of subsets of an universe, and the question is if there is a subfamily of mutually disjoint sets of size at least $k$. So here is a reduction from independent set: let the universe be the set of all pairs $(i,j)$, $i < j$. For every vertex, introduce the subfamily: $\{(u,v) ~|~ (u,v) \in E(G)\}$, with an appropriate ordering between $u$ and $v$. It's easy to see that a collection of independent vertices corresponds exactly to a mutually disjoint subcollection. Now, here is a reduction to independent set: introduce a vertex for every set, and add an edge between two sets iff they share an element in common. Again, a set of mutually disjoint sets in the family corresponds exactly to an independent set in this graph. This establishes, modulo details, that the problem in question is equivalent to the independent set problem, which is well-known to be $W[1]$-hard. On the other hand, if the graph has bounded maximum degree (let's say the $\Delta = O(1)$), then the problem is FPT by an easy branching strategy: note that any maximum independent set intersects non-trivially with $N[v]$, and one could branch if $|N[v]|$ is bounded. That's why your problem is W-hard in general, and FPT in the special case when the sizes of the sets in the given family are bounded.