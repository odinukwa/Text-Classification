Fingers crossed that this one doesn't get closed. I've tried to do something similar, but it hasn't come out well. Hoping that some others have suggestions. It looks like they're using some sort of overlay or whiteboarding software, and I assume a tablet or stylus. I can see a cursor where their pen is drawing. I've tried this, and it didn't go well. But, I think that's more a factor of my handwriting than of the idea. Enough years of typing being my main method of written communication has made my handwriting terrible. And it's even worse on a Wacom tablet. Same thing with some student created videos. They're just hard to read. I'd like to find whiteboard software that also allows typing. Haven't found one yet, although I haven't looked all that much either. A couple things that have worked... If I'm in a hurry, Powerpoint has enough animations built in that it's possible to do a fairly decent job. And, they can be exported to videos if you want to upload to YouTube. When I've had more time I've used Flash. It's deprecated now, but I still have an old copy on my computer. Takes longer, but gives me a little more freedom in what I build. Also can be exported to a video, which is especially important since browsers are starting to frown on Flash. Edit: Just played around with the pro version of Acrobat and it looks like it has a pen and text tool that might work for what I'm trying to do. Most of the time I'm just trying to annotate what's already typed out. Edit 2 - After "screen casting" was added This year I started capturing my screen as we work through problems and then uploading to YouTube for kids that missed the day or just want to go back for a refresher. I'm using a program called OBS. Works really well. A little Googling brought me to a Windows program called ZoomIt that will let me write and type over the screen as I'm demoing. Think I might bring my Wacom tablet to class tomorrow and give it a try. 

I use school colors and principal's name. If someone comes in tomorrow and says your principal is no longer Mr. Smith, it's now Ms. Jones then that change is made for every object (student) in the school. You don't have to go to each individual student and tell them that their principal has changed. It worked really well this year because we did get a new principal. 

Wish I had a good answer, but I can sympathize with your Scratch example. What I started doing was just giving up on the first day we did Scratch. I would show them the drawing tools before we did any coding. Spent about 5 minutes showing how to make sprites and backgrounds and then gave them the rest of the period to play, with the understanding that was the only day that they had to just play around and doodle. Day two, we start coding. Worked fairly well. It was at least better after I started doing this than before. I think the novelty of it wore off when they were allowed to goof off for a day. Haven't taught Scratch in a few years, but I noticed the same thing happening with Jeroo. Kids love painting the island with flowers and water. The last lab in the set is one where they get to build their own lab, and make their own island. I think having that to look forward to helps. 

Yikes, that doesn't sound like a fun way to grade. Sounds about like what I do with students that are competing in ACSL competitions. But that's only 6 or 7 students, 4 times a year. I can't imagine trying it with 100 students all year. Here's what I'm doing, and what I've done. Online Autograder This is what I'm doing now. Kids login to Canvas and it launches an LTI tool embedded in an assignment. They do their coding in Chrome and click the Test button when they're ready. They can keep testing until their happy with the grade. Grades get sent back to Canvas. I still have to transfer them to our actual gradebook. I can then go back and download the submissions if I want to look at them for style or tips. Generally I try and do this with everybody on at least one lab per lab set. What I've found is that students average about 11 submissions before they move on to the next lab. I only grade the last one, although I'll go back and look to see how they progressed. Downside to this is that it works well for smaller labs, but not as much with larger projects. I can break down large projects into pieces that they can check, but eventually there has to be a full project turned in. JUnit Tests Before I moved online I would write a JUnit test for every lab, and usually I'd write two. One that I would include with the starter code and one, more in depth, that I would use to test. Students could run the test code as many times as they wanted. Then, they'd submit their solutions and I'd run it against the other test code. Biggest downside is it was pretty time consuming to write unit tests for every lab. I've gotten pretty quick, but it's still a time suck. Walk around Not ideal, but I can pick up a lot about students' code by walking around the room and watching them code. I do this a lot with projects to get a feel for where the kids are on the project. By the time it's turned in I've already got a pretty good idea on what they've done. Doesn't scale well though. Biggest class I've ever had was 34 students. "Participation Grades" Sometimes I fall into this trap, especially with my second and third year students. I give them labs, they work on their labs, and I assume that they're done correctly if they've been working in class. Only saving grace on this one is that labs are worth very little and tests make up a majority of their averages. So even with gimmie grades on labs, they can still get hammered on the tests. Admittedly not a good solution, and one that I'm trying to work my way out of next year. Eyeball It Skim the code and see if you think it works. Same as the participation, this only really works with smaller assignments and when labs aren't worth all that much. 

Spaghetti code is often the result of not understanding the problem, although an attempt to treat variables as immutables when it is not appropriate would certainly contribute. Even experienced programmers will create spaghetti code if they don't understand the problem, or if the problem changes sufficiently over time. If you don't believe me, walk into any enterprise shop with custom processes and start reading code. 

As suggested, moved from comment to answer. A range is exactly that - a definition of a beginning and an end point. The 2.7 default behavior made it look as if it were a list, and confused the issue. To new programmers, there is no "change", it is simply how things are. Only those with prior expectations will be confused. My perspective is someone who has no practical experience in Python, but decades of OO programming experience. I would find the 2.7 implementation of range confusing because a list is not inherently a range, although a range could be implemented as a list with a length of two (beginning and end). 

In industry, the DEV environment is where developers are free to play and break anything (provided they fix it for those who follow). A typical enterprise shop will have a DEV, TEST/QA, and PROD environments, with developer access to DEV being nearly unlimited, but PROD being limited to end user support without significant from 5 layers of management and a pope. DEV will typically mirror prod closely enough for practical purposes, but be underpowered to reflect its lesser usage. 

This started as a comment, but got too long, and I realized I was moving well into answer land. Understand I'm not a teacher with a class full of kids, so this may be too esoteric of a way to look at the question. However I have worked with students at different times from different types of backgrounds. Those who were in classes where OO programming is taught first took longer to produce their first working application, but when there was a working application it was far in advance of what their peers in a functional programming first class are doing. I admit I learned functional programming first, then progressed to OO programming later, but that was because in 1975 there were not many OO languages available to a high school student using the school's teletype. Xerox had decided that Smalltalk was cute but had no commercial value, so the paradigm appeared dead. Start with the understanding that Object Oriented Programming is a way of analyzing and structuring problems, and is not tied to any language. You don't need an OO language to write OO programs. I have seen OO programs written in COBOL (not OO COBOL, which is neither OO nor COBOL). I built OO frameworks in K&R C, back when C++ was mostly an academic novelty. I have seen and built OO programs in BASIC (as in "10 let x=1", not the modern Visual BASIC which is a blending of BASIC and PASCAL). Teach the concepts of dealing with an entity. There is the entity, its attributes, and methods for it to interact with the outside world. In COBOL, you might embed the entity and attributes in a copybook, then the methods in nested programs (the lack of scope in COBOL sucks). In C, it might be a struct in a .h file and a function library. In OO languages, use the languages natural paradigm. Personify your objects. Use pronouns like "he" and "she". Teach to build the logic in the entity's method, and keep the methods very simple. Show that a complex method means that the solution is either housed at the wrong level or not clearly borken out. If they are taught this from the beginning, a lot of issues that require retraining can be avoided. 

As many of them will go on to become computer engineers as programmers. Computer engineering is all about logic circuits. You teach them at this level for the same reason you teach them programming. Besides, some problems are not solvable in real time by software alone. For a fun reason they might appreciate more directly, Redstone circuits in Minecraft are integrated circuit problems time scaled to the minecraft heartbeat. You could have them make the circuits in Minecraft. Have them build boobytraps for the last person through the door, or other problems that require complex logic. 

The LET notation was cumbersome, so most dialects of BASIC introduced the "implied let". If you started the statement with a variable, it was implicitly a "LET" statement. Algol, Pascal, and some other language of the day introduced the ":=" operator (read as "becomes equal to") to keep a distinction between assignment and comparison. 

which is nonsense, and they realize that, and get confused. When programming most languages use "=" as an assignment, where it should be read as "becomes equal to". Back when I started (in the 8 bit days before PC's), BASIC handled this by requiring the "LET" statement, so it read more like algebra, but the LET keyword was a cue that we were making an assignment. 

C and its descendents were created for brevity rather than easy reading. They distinguish assignment from comparison by having the most common operation require the fewest keystrokes. Once you started programming in C, you were already thinking like a programmer rather than like an algebra major.