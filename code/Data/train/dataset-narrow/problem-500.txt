(My apologies for the SQL Server syntax - I don't have MySQL. Please treat as pseudo-code.) A scheme such as the following should work 

Note how, despite the LEFT OUTER JOIN which one expects to ensure that all Person rows are returned, the placement of the condition in the WHERE clause instead of the JOIN clause coerces the join into an INNER JOIN; so that Ginny is dropped from the first result set. This is a specific example of how, more generally, the occurrence of a NULL value in a field being tested violates intuition. One loses the Excluded Middle, so that when a predicate A may be NULL it is no longer tautologically true that will give you all rows; all rows with a NULL value for A will be silently dropped. 

t is not always accurate to the business requirements to unpivot the table as you propose. For example, in a tournament scheduling database the table for Game will always have two distinct FK's to Team, one labelled HomeTeam and the other labelled VisitingTeam. Unpivoting this eliminates the business requirement that a Game is always between exactly two teams. Another example is the case of a database for an online meeting scheduler, where each meeting typically has a single Host and any number of participants. It wold be appropriate to embed the Host FK to the Participant in the main meeting table, with all non-host participants listed in a detail table. If this were an appropriate model for your business requirements then all but one of your reference_n fields would be pivoted out to achieve proper normalization. So, in the absence of the relevant business requirements, we are left wondering whether it is appropriate from a business perspective to unpivot as described. However, let's assume unpivoting is accurate to the business requirements. Why are you worrying about performance so early in the design? If it actually turns out that once you have a few billion rows this one table is at the core of a key performance criteria, there are a dozen or more techniques for addressing that only one of which is the denormalization you inquire about. There is absolutely no possible way that you can determine at this early stage which of those performance enhancing techniques will be an appropriate solution. Meanwhile, if you continue to denormalize your design in this way you will vastly complicate the writing, reading, testing, and development time of the codebase using your application. Are you sure that cost is worthwhile for a very, very, early guess at performance needs? 

Trick question! The answer is neither. Sure few_vals is a long string. So you can get good compression out of it. And you (might) get an index skip scan for the queries using (few_vals, lots_vals) that only have predicates on lots_vals. But I don't here, even though it performs markedly better than a full scan: 

By doing so, you'll make it much easier to answer questions such as "What are all the trains going to station X on 1 Oct?". It'll also makes "temporary gaps" when trains aren't running (e.g. Christmas day) possible to identify. A one-off train is now simply one with only one entry in SCHEDULE_DAYS. As the schedule can be different on weekends to weekdays, I think it's better to have separate rows for each day. This allows linking different schedules for every day of the week, should you ever need to do this. 

So it's unlikely to be worth indexing on its own. Queries on lots_vals return few rows (just 1 in this case). So this is definitely worth indexing. But what about the queries against both columns? Should you index: 

The design doesn't meet third normal form, but not just because of the city. The fields STREET, CITY are functionally dependant on each other (if you change the city, the street should probably change as well and vice-versa). You could also have the same street, city combination represented in different ways (Foo St, Foo; Foo Street, Foo; etc.). To normalise this you would create a new table ADDRESSES which has the street, city etc. in and link the customer to that via an address id. This would also allow you to list several addresses for a customer (via a link table) if this is what you require. This still leaves you to decide whether to extract the city into it's own table. To fully meet 3NF you should create a cities table, whether you need or want to depends on the answer to the following questions: 

so NOPL is another possible candidate key, CK2. However CK1 and CK2 have columns NOP in common, making them overlapping candidate keys. 

No, it's not acceptable to have circular foreign key references. Not only because it would be impossible to insert data without constantly dropping and recreating the constraint. but because it is a fundamentally flawed model of any and every domain I can think of. In your example I cannot think of any domain in which the relationship between Account and Contact is not N-N, requiring a junction table with FK references back to both Account and Contact. 

(Please forgive the SQL Server test case - the problem is common to all SQL implementations because that of common semantics mandated by the SQL Standard.) Even though you have used a LEFT OUTER JOIN, the semantics of SQL can convert this to an implied INNER JOIN if you improperly put constant-test conditions in a WHERE clause instead of the JOIN clause. The example below ilustrates this. Preliminaries to create test data: 

A Non-Clustered Index on the child table by ParentID and TypeID will cover the subquery. An Indexed View on the subquery is possible also. 

It's a Multi-Level Marketing system! Jeff Moden has written a a pair of articles here and here on efficient implementation of Hierarchical Reporting against a SQL Server database. There are a number of ways to store the hierarchical information but the two main ones are Adjacency List (each child has a parent foreign key) and Nested Sets (each parent stores details of its child hierarchy). Adjacency List is more intuitive and faster to update, while Nested Sets provides faster reporting. Jeff has explained this topic far better than I can, and developed efficient SQL Server algorithms for converting an large Adjacency List tree into a Nested Set representation, 

I believe the important difference is to inform developers which of the available unique keys should be used when applying foreign keys to a table. The important features of a primary key are: 

To help you fix this, if the query is static (doesn't change) and you've licensed the tuning pack, I'd advise looking at the SQL tuning advisor. With this you can create an SQL profile locking the query to a good plan. Hopefully the advisor will find the good plan for you automatically, but if not you may have to create it manually. Some links: Using the tuning advisor package: $URL$ Manually creating SQL profiles: $URL$ If you're not licensed for the tuning pack, then I think you're down to restructing your query, adding indexes and fiddling with hints. Finding out which changes will benefit will be a bit of trial-and-error; it's difficult to say exactly what you should do without access to the actual datasets. 

If you do this without ROWDEPENDENCIES they will come out with the same ORA_ROWSCN because the rows are on the same block: 

But there's no FK defined :( So the optimizer doesn't know this. And it needs to access both tables when executing the query: 

As Justin's said (and the links in his post prove), the cardinality rule is a myth. This aside, there's a good reason to use bitmap indexes on fact tables: separate bitmap indexes on can easily be combined by the optimizer to reduce the numbers of rows to access. This is very useful with fact tables with a large number of dimensions. While any single dimension may return a large percentage of the data, when combined with others this may fall dramatically. For example, you may have thousands of orders per day and thousands of customers (with hundreds of orders each), but a given customer is likely to only have 1-2 orders on any given day. This saves you having to create multi-column b-tree indexes. As (ignoring some skip-scan conditions), the leading column in an index must be referenced in the where clause to be used. So with three dimensions you need to create six multi-column b-tree indexes to ensure an index is available for every query your users may throw at you ( ind1: col1, col2, col3; ind2: col1, col3, col2; ind3: col2, col1, col3 etc.) With bitmaps, you just need three single column indexes and can leave the optimizer to decide whether it's beneficial to combine them or not. This example shows how the two single column bitmap indexes are combined, but the b-tree indexes aren't (note Oracle can convert b-tree indexes to bitmaps, but this is rare): 

Index width would be degraded significantly with your proposal. Just how do you propose to manage all those random 2-digit integers to enforce uniqueness. Have you thought of how much code would have to be written and maintained to implement this scheme. Won't typing all those key fields in for every join in the implementation be a joy. 

in your inner WHERE clauses is non SARG-able, so no index can be used. Change both occurrences as shown below, to make this term SARG-able: 

The Key - there must be a Primary key for every relation being normalized. The Whole Key - There must not be any functional dependencies of attributes on any proper subset of the Primary Key. And Nothing but The Key - There must not be any functional dependencies of attributes on non-key attributes. 

In EXCEL, from the Data ribbon, Get External Data tab, select From Other Data Sources -> From SQL Server. Follow the wizard to connect to your server and create a query. 

In practice relations frequently have multiple candidate keys, and these rules must apply to all of them in turn. Also, when Normalizing one must determine the minimal key(s) for each relation, and use those rather than any Super Key. Your lecturer didn't remove the fifth column altogether because the functional dependency in that column still exists, and must still be accounted for in the Normalization process. Update: The FD AD->C doesn't disappear by virtue of recognizing ADC as a subset of CDA; neither is it sensible to have two relations ADC and CDA both in the model as this is a redundancy of exactly the sort Normalization is designed to eliminate. 

Vincent makes some great points of the caveats of IOTs, but you can get some significant benefits from them as well. Personally I think that they are significantly underused in Oracle and should be considered much more widely - not just as possible solution to performance problems. As you have to recreate the table to convert between IOT and heap, this is a change which is unlikely to happen on an always up, heavily used database unless the performance problems are severe. Martin Widlake has a great series of posts about IOTs. There are some significant benefits you can get by using them: 

The check constraint on the MV will only be invoked when it is refreshed, so for this to work successfully you need to ensure that this is done on COMMIT. This will add to your commit time processing, so you'll need to bear in mind the following: 

This appears to be a straightforward connect by where you're getting the next person based on the prior manager. The only difference being you want to get the top-level (root) person listed for each row it applies to. This can easily be found using the function (docs), which will return you the value of the column listed at the root node in each hierarchy. This gives you a query like: 

If you're not already familiar with reading and understanding execution plans I'd spend some time learning these: your bound to run into performance issues at some point so knowing how to diagnose the problem correctly will become more important as it's harder to add new indexes or make schema changes when your row counts are larger. 

The theory is all fine and good, but it only starts to really make sense once you understand the practice. The Lawyer's version of the first three Normal Forms is: 

If the primary key is a surrogate (ie an IDENTITY valued INT) then you need to remove it from the field list of the insert (if possible) otherwise (if you need to retain the surrogate key values to support foreign keys) to bracket the insert with and . 

Note that the single clustered index on the view is identical to the (one and only) clustered index on the original table. However, several queries running against the Indexed View run slower (averaging about 3*, ranging up to about 6*, slower) than against the original table. Does anyone know why this could happen? Is it a possible bug in the Engine to not treat two identical clustered indices identically? My test data currently covers only two periods, one year apart. I initially thought it might be due to the columns of the view being nullable, but using isnull to coalesce them simply makes the queries so slow I can't even measure the performance. I am on SQL Server 2014: 

If you decide to keep a single entry for both sides of a transaction, then by definition you are engaging in single-entry bookkeeping. This may be the most appropriate solution for some simple applications, but be clear that you are losing all the functional and robustness advantages of double-entry bookkeeping, in exchange for a simpler design. Note that when viewed stand-alone Subledgers (though not their corresponding Journals) are often implemented as single-entry, since a control-account in the General Ledger captures the subledger total and the balancing side of the transactions are in the General Journal (GJ) and General Ledger (GL). You also appear to be confusing the distinct concepts of Ledger and Journal in traditional double-entry bookkeeping. The various Journals (of which there will be numerous specialized varieties for specific common transactions of the business in addition to the General Journal) is a chronological history of all transactions entered into the system. The General Ledger is an ordering by account of all transactions entered into the system, and the various subledgers are an ordering by subledger-code of all transactions entered into the corresponding Journal. Two examples of common Ledger and Journal combinations: 

Shared nothing typically refers to hardware, though it could also be used when describing an SOA architecture. From a hardware perspective, a "shared nothing" Oracle database simply means a machine using local disks, memory, etc. Oracle RAC (real application clusters) is a shared disk architecture, but not shared memory. Horizontal scaling is then achieved by adding more machines to the cluster. When talking in SOA terms, "shared nothing" means that each service has a corresponding database which is only accessed by that service. So the ACCOUNTS service accesses the ACCOUNTS_DB, ORDERS service the ORDERS_DB and so on. These databases could be shared nothing from a hardware perspective as well, or use RAC. Ensuring consistency of data and references which would normally be handled using foreign keys becomes a challenge in SOA shared nothing databases. Sharding typically refers to partitioning managed at the application level, rather than within the database. For example, you could partition accounts by email address and direct customers with address starting A-C to ACCOUNTS_DB01, D-F ACCOUNT_DB02 and so on. The shard mapping could be a simple range like this, a function on the input or a lookup database stating which database is stored in. The databases would be "hardware shared nothing" in this case as the idea is you use relatively cheap machines which are easily added and replaced. You could shard your databases at the application level and still have Oracle partitioning at the table level within the database itself. So you could shard your ORDERS database by customer, then partition the orders table by order date as well inside the database. The downside to both meanings of shared nothing comes if you frequently run queries that have to access several databases. In these cases your joins will be pushed into the application layer rather than the DB layer so are likely to be slower. Good governance is necessary to ensure this doesn't happen.