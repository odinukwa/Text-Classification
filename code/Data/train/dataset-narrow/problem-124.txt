I know this is an older question, hopefully you've solved it by now, but I wanted to toss in my two cents, for the benefit of future generations if nothing else. First of all, yes, ethernet and PoE specs mean you can do exactly what you're trying to do, and run two PoE cameras over a single Cat5e. First up, there are very, very, VERY few IP surveillance cameras that use gigabit ethernet; 99.99% of them are 10/100 Fast Ethernet only. The ones that do use GbE will be super high-end, super high-res, and super expensive. Second, very very few cameras use more than about 5-6 watts. Most IR cameras won't pull more than about 4W with the IR on; non-IR cameras will typically use 2W or less. To use a full 15W you'd be looking at something with massive IR range, heater, fan, and probably PTZ as well. The Axis outdoor cameras I use, with internal heater and fan to dissipate moisture, spec a maximum 12.1W draw. With all that in mind: 10/100 ethernet uses only two of the four pairs, and PoE "mode A", aka "endspan" runs power over that same pair. This means that if your switch and cameras both support Mode A or endspan power (which will include most except the very cheapest), you can run a camera over only two pairs. That leaves the other two pairs free for a second device - I've run a second camera that way, a IP video decoder, a wireless access point, a room temperature monitor... On the switch end, I'll often just strip the jacket back 2-3", terminate the orange and green pairs normally in one RJ45 plug (n that case, for T-568B, the plug would look like white/orange, orange, white/green, blank, blank, green, blank, blank), and then put the brown and blue pairs where the orange and green pairs would go in a second plug (I use brown for orange and blue for green, just to keep it simple to keep track of). The two can then plug into adjacent ports in the switch. If you prefer to split the two out into adjacent keystone jacks and use standard patch cords, you can do that too. On the other end, you can split the pairs out in a box and terminate into keystones, then run patch cords to the cameras... or bring it in behind one camera, put plugs on the ends and plug one into that camera, then run an extension to the other camera and put a keystone on it to connect to your home run. Of course, you can adjust the termination types to suit your purposes. In a pinch I've just used "beanie" connectors to splice the wires - at the end of the day, they're still just moving electricity. Now some PoE switches will do up to a full 15W per port, but for only half the ports, and more typically provide 7.5W per port... but again, with most cameras, that will be more than enough, and again, that's per port - you're plugging each camera into its own port here, so that's not a problem. Yes, this is all very "non-standard"... but it is certainly possible, easy to do, and so far it's worked very reliably for me when there have been no other options. 

Data transmission or reception happen through channels. Channel indicates the frequency range of operation. Typically its bandwidth will be +/- frequency range based on a operating frequency / center frequency. Here 2.4Ghz is the operating frequency / carrier frequency. The channel bandwidth for 802.11b is 22Mhz. This range is divided into 14 channels spaced 5 MHz apart. Channel contention shall occur if multiple AP operate in same channel. The higher the channel bandwidth, the higher the amount of data that can be sent and higher the cost. So, Wide bandwidth channel will enable more data transfer, but in turn raises the chances of interference with other channels. 802.11b supports a max of only 11 Mbps data rate. Theoretical throughput is the maximum channel capacity of system that is equivalent to the maximum possible amount of data that can be transmitted in the channel in ideal conditions. Presence of multiple channels provides choice of usage to avoid interference. Different countries have different policies in allowing the channel usage, number of users and power level within the operating frequency ranges. 

IMEI is provided by equipment manufacturer for the mobile. It is stored in EIR via the network operator while registration. IMSI is a combination of MCC(Mobile country code), MNC(Mobile Network code) , MSIN(Mobile subscriber Identification number) and is stored in SIM. There are several such identifiers based on the mode of operation to uniquely identify a user. GSM is a combination of TDMA/FDMA. Each BS is assigned one or more carrier frequencies which is then divided in time, using a TDMA scheme, into 8 time slots. The time slot usage is such that the mobile does not recieve and send it the same time. That is, the MS uses one time slot for transmission and one for reception. The BSS acts as a radio resource manager and allocates a traffic channel (a radio channel and a time slot) for every MS once authenticated and informed by MSC. Each MS operates only over the provided radio channel in the given time slot. In GSM, the RR protocol between the MS, BTS and BSC(BSS) does the routing of the data to the recipient and you can consider it to be similar to that of network layer(layer 3 of OSI). The routing of data is further coupled with SCCP for end to end addressing/routing in SS7. 

The real way this is done in Amazon is different from how you might imagine, as common solutions don't scale. They did a talk in 2013 about this at re:Invent, which you can watch on YouTube: $URL$ However, the more general answer is "IP addressing is a matter of perspective." More specifically, if your hosts never want to talk to the hosts of someone else who was allocated the same IP space, no one cares that you have the same IP addresses. If you do, and you want to talk to each other, then through the use of some mechanism like NAT, you will change the IP addresses of the the hosts in network A from the perspective of network B. 

The Controller doesn't do anything right away - it does not know this event has occurred. The initial decision to be made has to be made by the device that received the packet it can't match. It may decide (due to configuration) to send that packet to the Controller, but simple math indicates that this doesn't scale (the management interface is very slow compared to the aggregate front-panel throughput of the device) and so by default unmatched packets are dropped. If the device sends the packet to the Controller (or, more likely, just the first hundred bytes or so) then of course the Controller is free to do anything it likes with this data. 

Most of this doesn't matter, ethernet flow control has never been widely supported and most switch devices will respect frames, but not send them. That being said, your questions can be addressed fairly easily: 

Both "layer-3 switch" and "router" are essentially marketing terms - they have no definitive technical meaning. Chances are that a "layer-3 switch" has more front-panel ports for cheaper than a "router", with less support for protocols and table size, while both do all forwarding at line rate, but that's highly dependent on the specific hardware in question. 

The better approach for deploying AP is a complete site survey to determine the AP density , multipath propagation characteristics, interference, noise etc.. before setting up the AP. The first immediate checkpoint for the scenario in-hand should be checking of SNR, RSSI and operating frequency/co-channel interference. For optimal performance, placement of AP plays a key role. AP should be located centrally within areas requiring coverage. Ensure to avoid coverage holes with proper overlapping of APs coverage areas. The radio range and data rate are inversely proportional. That is, the nearer the user to the AP, the higher the data rate(Due to reduced path loss and high SNR). For effective radio range, also ensure to avoid buildings in-between. The type of antenna, its placement and antenna gain are crucial in deciding the maximum radio range and the coverage area. The range is directly proportional to antenna height, however if the height is beyond certain limit, interference can be more. An istropic antenna provides coverage area in the form a sphere. Dipole antenna provides coverage area in the form of doughnut. There are also various directional antennas. Beware that the omni-directional antenna can lead to hidden node problem incase of large cell size. Antenna with focused beam can be helpful. Multi-sector directional antenna can give high capacity, range. Determine if there are other active channels in your environment that introduce interference. Presence of other APs operating in the same frequency in the same radio coverage area can cause interference. The operating channel and channel separation can also play a role in connection speed / call drops. You may need to change the channel/separation accordingly to reduce interference incase if there are only 802.11 devices. However it might not solve the problem incase of presence of interference from other non-802.11 technology devices (Bluetooth/Cordless phones etc..). Also note that interference need not necessarily from another 802.11 devices, but also from other non-802.11 devices(Microwave oven, Cordless phones, Bluetooth devices...) that can cause secondary effects such that data rate gets reduced. The impact can be due to high output power and the time/frequency the signal is on. For example, Microwave ovens mostly operate in the same frequency band as 802.11b/g and hence are more likely to cause interference. It is better to keep away such devices(Microwave ovens,bluetooth, cordless phones etc...) from the coverage area or shield those devices to continue presence in the coverage area. There is a typical tradeoff between capacity and coverage. The higher power level can increase the range but if there are nearby APs, it can lead to interference. If the capacity is of importance, it is better to have the APs closer together. However if the APs are closely placed, the proper level should be set to low to reduce co-channel interference. So, ensure to keep optimal power levels. Above such points should be analyzed along with site survey and the collected data should be analyzed for optimal performance. From your observations of high PER, suggest that transmission channel is impacted due to high interference / multipath fading/channel noise. A proper site survey can be very helpful to you. 

Sniffing is different from analyzing - in general software like Wireshark relies on a different piece of software (or hardware) to deliver the actual packets to it, commonly in a format called "PCAP". Parsing is pretty simple - most protocols are documented - although it's extremely time consuming to develop parsers for every protocol you might see (particularly at L4 and above). Once a packet is parsed, analyses are done based on that data, which is well formed and not unlike analysis performed on any other kind of structured data. As to how those files get created, sometimes it is as simple as asking an OS to copy all the packets the host receives to a file in PCAP format, while other times it is an extremely complex operation performed in hardware to peek into and copy a light or electron stream on a physical wire. A common case is to use a span/mirror on a network device to copy all packets out to a port specifically for the purpose of online/offline analysis. 

Not exactly. You can still send pause frames, but your card won't respect ones sent by the switch (which you will likely never get anyhow). The driver probably doesn't send pause frames though, so any you send would have to be generated manually. Autonegotiation has no effect on flow control on full-duplex gigabit links Ethtool is responding with information from the NIC driver. It doesn't matter what the hardware supports if the driver doesn't support it, so what ethtool is telling you is important. No. Unless you're working at 100Mbit, autonegotiation in general isn't going to help you (unless you're working with repeaters or other rare half-duplex gear at gigabit). 

The ARP opcode could be expressed as a single bit ( or ). The argument could be made (and was, at the time) that 16-bits for both and was wasteful, and that should simply be the high bit of the field. Doing this would have restricted the available space for ethernet to 15-bits. 35 years ago this was a much more significant concern than it is today, and that is why the discussion is called out specifically in the RFC. 

TCP is a connection oriented protocol that uses stream socket. It is bound by IP address and port number at both the endpoints. In connection oriented protocol, a logical channel is established between the peers before exchanging data. So, if the IP address is changing, it has to tear down the existing connection and re-establish the connection which obviously is disruptive. It is possible that IP address can change during every restart provided the subscriber is configured for such a plan of either static IP address or Dynamic IP address. However, IP address change is not preferred while the connection is ON as it will be disruptive considering the fact that the higher level protocols like TCP will be shutdown. Such scenarios may happen when the mobile moves between different PDNs. To overcome this, 3GPP based networks use either GTP or Mobile IP. GTP(GPRS Tunneling Protocol) ensures that the data is tunneled such that the same IP address is retained. Mobile IP allows location independent routing of data with the use of CoA (Care of Address) which utilizes the PGW as home agent(HA) and the SGW as the foreign agent(FA). Here, a mobile specific CoA is provided to the HA by FA, so that packets can be forwarded to the correct destination of mobile location. 

Not sure of the type of handover you are talking here. In general, Inter-RAT handover of LTE to UMTS does not require any change in MAC layer as the PDCP layer takes care of the packet delivery. The handover procedure shall be similar to that of Intra-LTE mobility banked upon S1-based handover based procedures. SGW plays the role of anchor in case of handover with other 3GPP technologies like UMTS or GPRS. In case of mobility from S1 mode to Iu mode, as soon as the source eNB sends a handover required message to source MME, it will do a forward relocation request to Target SGSN. The target SGSN does the mapping of the EPS bearers to PDP contexts. It also maps the EPS bearer QoS to that of Rel99 QoS parameters and triggers a Relocation request message to Target RNC. The target RNC allocates the resources and returns the applicable parameters to the target SGSN in the message Relocation Request Acknowledge message. Based on the Forward relocation response from Tgt SGSN to MME, it can establish path for either an indirect forwarding or direct forwarding. Once the Handover complete is indicated by UE, If it is direct forwarding, source eNB will perform direct forwarding of DL data to Target RNC else if it is indirect forwarding, source eNB will forward the DL data to SGW and via Tgt SGSN to Target RNC. Seamless handover does not use a STATUS TRANSFER msg and hence it should be fine. However, incase of lossless handover, the PDCP status preservation shall not be present(context shall not be continued) as STATUS TRANSFER message was introduced in LTE and not supported in UMTS.