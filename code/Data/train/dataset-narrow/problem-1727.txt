I'm using ESXi 5.5 and vCenter 6.5 with vSphere Update Manager. I successfully staged about 20 updates (new host deploy) and set it to remediate. I know this can take a long time, but the percentages are static for many hours. Is there a way to check (via command line or otherwise) if it's actually hung or if it's doing anything? It would be nice to also get a more realistic idea about how much it's got to go, but that isn't essential, I mainly want to be sure that I can leave it be, and it's working properly on the patches, even if slowly. On Windows I can watch update-related files being accessed and update-related processes I/O counts, in task manager/perfmon, as they do their disk and process I/O, and on Linux or BSD I can use various well-known tools (but they aren't included in ESXi). What's the equivalent with command line or other tools, in vSphere? 

In ESXi 5.5, the host config has a number of similar sounding settings related to swapfiles and caches of various types. I understand the principles of write-back/write-through disk cache and swapping VM swap files to the host instead of their remote VMDKs, and I'm reading the docs, but it's still pretty confusing which of these is which, and how they inter-relate within ESXi. For information, my system has a single standalone host with 96GB RAM and three datastores - a local boot store, an iSCSI main store, and a 250 GB NVMe SSD for swap/cache use. A clear explanation of the differences and how they work together would be really useful right now :) 

I didn't get an answer here so I asked on VMware communities. The best answer I got was that there's a VMware "fling" called visualesxtop (on the VMware flings website, best found via Google in case URL changes), which produces graphical and tabular monitoring data for an esxi host. Works great! 

I understand that iSCSI doesn't 'know' about files, and that a file and its metadata which was in use wouldn't be guaranteed to be served correctly to a second 'interloper' read-only initiator if it was changed halfway through the request or something, but I'm thinking here about reading from old ZFS snapshots or when the main initiator isn't connected, or files known to be idle - situations where there may not be the usual risk of conflicting instructions and corruption, and for a small setup it would be helpful. 

I don't know powershell specifics for regex or to scan a file line by line, but assuming powershell regex is like all other regex, the actual pattern to match your string with, looks something like this (the 3rd regex below matches your examples): 

I manage a small network of windows clients and a BSD file server running Samba 4.6.x. We had some odd issues which led to the discovery that when users save files to the server, about 12% of the files as saved aren't faithful copies of the Windows original. (Tested by copying 2000 files of 1 - 5 MB and hashing Windows originals and BSD copies: about 245 differed). I tested a bunch of things: copying from multiple clients (same happened on all clients), server hardware checks (ECC fine, ZFS no errors), network data corruption (no issues end to end), directionality (copying client to server corrupted about 12%, server to client was faithful), consistency (copy same folder 3 times one after the other in a session and compare: in each copy, the corrupted files differed; one copy had no corruption), long path issues (no long filenames, paths, or odd chars in filenames). I also copied using SCP but got "server aborted connection" errors after a second or two, which might mean something or nothing, so I couldn't check if it was Samba-specific. SSH which I think SCP uses is rock solid so I'm not sure what to make of that. The NICs are good quality - Intel 1G + Chelsio 10G. Nobody else has logged in, the server is locked down and firewalled, and no system tweaking has gone on - it's pretty much FreeBSD 11 + Samba. I've always assumed (naively?) that file server issues were almost always down to access issues (config, permissions and authentication) and provided users can actually write files then, barring hardware faults, it "just works". So this random "file saves on server but saved version not same as original" has really got me foxed. Any suggestions what kind of issue could cause this, and how to troubleshoot it? 

How it works? If the old BROWSER functions on ports 137-139 are disabled, how does enumeration by a client of local shares work? Where do available servers and peers offering shares make themselves known? How do potential clients "know" which other local devices offer file or printer shares, and if a device starts to offer a newly created share, or starts to offer a share when it didn't previously, how do existing LAN devices discover this? What changes I have to make, so it'll work that way? On Windows 8.1/10, apart from the checkbox "Disable NetBIOS over TCP", what else do I have to do, to move my local SMB file shares off the old protocols, off ports 137-139, and onto port 445 or whatever the current practice is? 

I have an LSI 9211 HBA and an Intel 910 SSD. I updated the firmware on the HBA, using LSI's usual sas2flash utility. I removed all other LSI/HBA cards first. Unfortunately it now looks like the SSD also has the same controller internally, which I had no realistic way to know in advance, and now Intel's SSD toolkit won't recognise the SSD so I can't figure how to put it back as it was. Sas2flash -listall shows the SSD with P20 LSI bios. What do I do? 

What's the current state of play on this for a modern *nix file server with Windows 8.1/10 x64 clients, if NFS is also enabled on the clients? 

Create two VLANs, say 1 and 2, with any VLAN able to access sharing services on the sharing ports, but only VLAN 2 able to reach the admin IP/port Create two IPs on the one NIC, say 192.168.1.2 and 192.168.1.3, with only 192.168.1.3 able to reach the management login. Blocking the management access ports (80,443 etc) for VLAN != 2 and/or IP != 192.168.1.3. 

I'm migrating data from my old server to zfs on FreeBSD 10.x (I'm actually on FreeNAS 9.10.2-u1 but doing this activity in console so it's pure FreeBSD). My problem is that needs a new_device in the correct format or slice/partition information, which I don't know how to provide. Because of costs, I'm migrating the data in two stages - copying the data from my old mirror to a new zfs pool (without redundancy), then breaking the mirrors on the old server to move the mirror drives over and resilver on the new server, at all stages having 2 copies of the data. SMART stats are all good, ands all disks are "enterprise" type. Although not ideal, so far it's gone well. I've copied over the data, and connected the disks from the old server to the new server - where I'm now stuck on getting the correct args for . Current storage is as follows: identifies the disk devices and model numbers, giving: 

As the question says. There's a lot of threads around on NFS vs. Samba/SMB, but a lot of them are outdated or refer to old security models, or just give a one-line "use SMB with Windows". Both modern Windows clients and modern *nix file servers can handle both of NFS or SMB/Samba. Whichever protocol is chosen, one will be using a "native" protocol and the other won't. So in mixed environments (*nix server/Windows clients) it's not as simple as "for X use Y". So I'm interested in actual pros, cons and experience. The few threads I can find that cover modern incarnations of these protocols suggest as possible differences: 

I just came across this page ("Direct hosting of SMB over TCP/IP"). It's quite old, so I can't be sure if it's the standard these days. It refers to disabling NetBIOS over TCP and disabling WINS, which suggests that it's still not the standard or default way SMB works these days, at least in many smaller networks. Is this page still relevant, and if it is, how do I know whether it's a good idea? My network here is Win 8.1/10 talking SMB 3.x to FreeNAS 11 (Samba 4.5+) if it helps. Update: Based on comments below I've updated the question to reflect the point of confusion: If it's now standard to disable it, clearly none of the Win 8.1/10 PCs and Server 2016/Samba 4.5+ servers on my local network ever got the memo. (Nor did I.) It's all still running on ports 137-139 despite being 100% modern devices that should apparently be preferring a newer approach. I can imagine that when NetBIOS over TCP is disabled in a small local network without AD, the host announce/locate functions used to enumerate devices offering shares/printers migrates to DNS (or host file lookup), and the actual client-server traffic runs much as before only on a different port and more modern protocol. I can add specific hosts to my local DNS resolver and I'm running DHCPD locally, if that helps. I might run RADIUS in future but not at the moment. On reflection, I'm confused about server enumeration, and what I need to do, to move off the old approach (= changes needed to how I currently configure the clients/servers).