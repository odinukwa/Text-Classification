The google search indicates the UTM appears to be a firewall. While you could get say a cheap router/firewall put it on a shelf and if the UTM dies physially replace it, that seems a bad idea as that boxes are not functionally equivlant. This is a form of redundancy though a static kind, as mentioned in the comment. Net of this is that if you need the firewall function you need a duplicate physical box. MAYBE you can 'limp along' with a less expensive spare box while you wait for your replacement firewall but that is a business call. Lastly most people here will tell you that your ISP connection will fail far more often than your hardware and that is what you need to make redundant first. 

You also need to set up a PIM RP since you only have 1 routing device you do not need to support auto-rp or bsr ip pim rp-address rp-address [access-list] the access-list has the multicast IP range so access-list 10 239.192.0.0 0.0.255.255 would make the 4900m the RP for the private multicast address range 

Firstly, many internal software data structures have a constant overhead which does not depend on how many items are stored in the data structure; in other words, whether there is one peer or 32 peers, the overhead is the same. A better way to check the actual memory consumption per peer is to configure another peer, and measure the difference between the newly reported memory usage and 4568. Then configure a third and see if the consumption goes up exactly by that number. Secondly, the output of a "show" command only displays items of interest to the network operator. There may be many bytes which have to be stored per peer but not displayed in the "show" command output (for example, a data pointer to some other data structure in the memory, a pointer to the next peer, or whatever). Without reading the source code it is impossible to say. 

The 4507 supports module hot-swap, so there is no initialization needed: either the module is supported and it starts working, or it is declared as not supported. The syslog messages you are seeing appear to be a software or hardware glitch of some sort and you have to ask Cisco for support. If there is no other problem other than the syslog messages, I would suggest just ignoring them: they should go away when you reload or power cycle the switch some time in future. If the syslog messages are too bothersome, you can try this procedure to see if they stop: insert another module in slot 5 and remove it after a few minutes. Use a module that you know for sure is supported. 

If your problem is that you have two sites/business parters etc that have separate Internet ASes you can connect them together NOT through the Internet but over a VPN or private link. You have a couple of things to watch for if the address spaces are also advertised via the internet relate to administrative distance and prefix matching. BGP is preferred for many reasons, and you have to use it to talk over the internet. A little more on your use case assuming it is not entirely theoretical would help. At the end of the day there is no law that prevents you from using an IGP. But remember that any network vendor is in the business of selling you rope, what you do with the rope... 

Most products require you to configure MAC addresses in DHCP for imaging to, so a normal PC will not use DHCP addresses from the imaging server, this begs the question why have a PXE VLAN? I use one for servers but all production networks are tagged so we can rebuild the server without needing to change the switch, but I would suggest this setup is needlessly complex. Use 2 DHCP servers 1 to build and one for normal operations and have a small scope in the build DHCP server. 

(Last 4 bytes = Dest IP address not available from your post. Try the -x option to get tshark to print the entire frame in hex). The data preceding the IPv4 header is the SNAP header: 

If all your links are constantly running at maximum utilization during normal operation, you won't have much spare capacity when some unexpected event occurs. 

The formal/correct way to do this for both IPv4 and IPv6 is to use "service discovery". Apple's "Bonjour" system is an example. 

The supervisor engine maintains (in hardware) a table of 5-tuples: src-ip, dst-ip, src-port, dst-port, protocol (udp/tcp). The table has rows like this: 

In Cisco IOS, "NVRAM" is the name of the area where the startup-config resides. "flash:" (or on some Cisco platforms, "bootflash:") is the name of the area where user files reside. On a factory-fresh device, this area contains the Cisco IOS image, but it can be used to store any arbitrary files. Now: on most modern Cisco IOS devices, there is not necessarily a 1:1 relationship between these names ("NVRAM" and "flash") and the underlying hardware storage device(s) where the storage is implemented. See, for example, the data sheet for the Cisco 4500X switch here. Under the "CPU and Memory" section, you only see one entry for a 2GB "NVRAM". This actually refers to a single 2GB flash memory chip on the board which contains the storage for both the IOS NVRAM as well as the IOS "flash:" file system. IOS software partitions the single hardware flash storage device into logical "NVRAM" and "flash:" areas. If you run the IOS EXEC command "format flash:", that would wipe out the contents of the "flash:" partition but leave the NVRAM partition intact (i.e. leave the startup-config intact), although both partitions reside on the same physical device, at least in the case of the Cisco 4500X. So to answer the question: flash is the area where the user is allowed to store any arbitrary files, and is subject to operations like "format". This usage of flash must not interfere with the startup-config - after all, you don't want "wr mem" to fail because you've filled up the flash with your vacation photographs :-) - which is why it is a good idea to have the storage for startup-config reside on a separate partition which, for historical/traditional reasons is called NVRAM. 

Each VLAN creates its own broadcast domain in 1 or more physical switches. If you have a switch taken out of the box it tends to put all ports in vlan 1 so for say a 24 ports the broadcast domain includes all 24 ports. If you were to create a vlan 2 and configure half the ports to be members of vlan 2 you then have 2 broadcast domains each of 12 ports. if you create a vlan 3 and put half the ports that are still in vlan 1 in it you would end of with 3 broadcast domains 2 with 6 ports and 1 with 12. 

The idea if not use ECMP if HSRP is in use may be ok for SERVERS where ingress traffic may be higher than egress traffic, in a PC situation IN GENERAL ingress traffic from the WAN (responses) is higher than egress traffic (ingress). We like most people just set the ARP timers. you can mess with CAM timers BUT if you have say an MDF with the layer 3 switch and an IDF with 2 collection switches and say 5 access switches, it is a LOT easer to configure on the L3 SVI than doing all access switches. 

I agree, that looks contradictory. For the DSCP case it says "Ingress: default trust dscp, no policy needed" but for the CoS case it says "Ingress: apply policy-map trust-cos". You can ask Cisco to clarify their documentation, but rather than wait for a clarification, you can go ahead and implement an explicit input policy anyway. Configuring an explicitly defined policy is probably better than depending on some poorly documented implicit behaviour, and is also more portable across multiple devices/software releases. If you want to trust the incoming CoS, use a table-map that maps 1 to 1, 2 to 2 and so on. This is what the example in the documentation ("trust-cos" policy map) does. If you do not want to trust the incoming CoS, use a policy-map that sets the cos to 0 unconditionally. 

A TCP connection is considered to be "in force" as long as the software processes on either end keep the socket open. When the process(es) on one or both ends close the socket (either gracefully or the connection gets aborted for some reason), this translates, on the wire, to a TCP packet with the FIN or RST flag set. The NAT implementation on the NAT router looks for the FIN and RST flags, and when it sees a packet with these flags, it "closes the hole". After this point, the client has to initiate a new connection in order to "open a new hole". To summarize, as long as your client and server keep their sockets open, the NAT association stays alive. 

Assuming that all link speeds are the same, things become hop count. If you explicitly set a root bridge the switch 'across' from it in the ring will have the blocked port, it will be the port with the higher MAC address. There is no real difference in blocked port selection between rapid and 'classic' STP 

I will assume you are running IBGP, you never send a prefix you received via IBGP to an IBGP neighbor, also there would be split horizon (don't send a route back to the person who sent it to you). Since this box only has one neighbor and it is not originating any routes by itself, it will not send any routes, so the policy is implicit, but there. 

The only dynamic adjustment of MTU size is to avoid IP fragmentation. That is changing the TCP segment size, to match the smallest IP packet size. IP packets can be divided up by say multilink PPP but that only lasts for the single MLPPP hop. Bottom line no protocol ever changed sizes to reduce retransmissions it was said in the old days that you might want to manually adjust data sizes down when using bad links but we are talking at least 15 years ago. 

Assuming my understanding of your problem statement is correct, let's see what it would take to implement this. Let's say the queue on the egress interface looks like this at some instant: 

on Vlan10 (and in fact on all other Vlan interfaces as well). Only DHCP packets will go between Vlan10 and Vlan100, and all other L2 traffic remains isolated as expected. 

Every TCP packet has two port fields; one is the Source Port, and the other is the Destination Port. The youtube.com server is listening on Port 80. This means that any packet travelling to youtube.com from your computer has Dest Port = 80, Source Port = (ephemeral). Any packet travelling from youtube.com to your computer has Source Port = 80, Dest Port = (ephemeral). (ephemeral) is any number from 1025 to 65535. This number is fixed to some value in this range when the connection starts, and remains unchanged as long as the TCP session is in force. This is why you can start two youtube sessions simultaneously on your computer, and both will work without interfering with the other: the (ephemeral) number is different for the two sessions. 

You probably want to be polling the CAM/MAC tables, that would have the MAC address of any devices send any traffic through the switch. ARP is L3 CAM/ARP is L2 

IPv4 and IPv6 operate as 'ships in the night' as far as routing is concerned, so I see not benefit to separate VRFs with ipv4 in one and ipv6 in another. Also any dual stack hosts would need separate interfaces or separate tagged VLANs to operate dual stack. Now if you are concerned about RAM in the router VRF will not help that, for that concern route summarization or default routing would help there, and that applies to both IPv6 and ipv4 

Local(255.255.255.255) means that a router will not forward the packet (in some cases like DHCP the router will convert it to a unicast packet and forward it). Directed broadcast addresses have just the host part of the address as all 1s and routers will forward so if I have a subnet 10.10.10.0/24 I can ping from elsewhere in the network 10.10.10.255 and I would get an answer from all hosts. However there are a number of attack that exploit and you can configure your routers to not forward directed broadcasts.