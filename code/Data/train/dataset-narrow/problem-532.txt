If constraints exist on the trigger table, they are checked after the trigger execution and before the trigger execution. If the constraints are violated, the trigger actions are rolled back and the trigger is not fired. An trigger is executed only after the triggering SQL statement has executed successfully. This successful execution includes all referential cascade actions and constraint checks associated with the object updated or deleted. An trigger will not recursively fire an trigger on the same table. 

And you can script out the msdb procedure to see the code in the procedure, in case you want to include some of that in your own script. 

The whole point of an INDEX REBUILD is to make the processing of data more efficient. This means that when possible it reorganizes the data to reduce the number of pages (according to the fill factor and other limitations) used for that index (whether it is a PK, unique, or non-unique index)and to order the rows of data more efficiently within the used pages and extents. Therefore, it will reuse existing pages as the first choice. This should result in less storage being used. Of course if the indexes are modified, this could expand the amount of storage needed, depending on the modification. Using tempdb to rebuild indexes can be a performance boost, but is unlikely to dramatically affect the required storage. In this case you should definitely rebuild the indexes. Note that this will not reduce the physical size of the .mdf and .ndf files. It will free up space that can be used as tables in the database expand in size. 

Kendra Little has discussed some of the problems at: (Link corrected) SSMS 2016 Query Store Missing Index Details Error Document Frame Sqleditors She also has created a link to the Connect issue. You can go there a vote it up, if you wish. Also the Quick Rundown at the bottom includes comments on which behaviors you can expect. Since you are running SQL Server 2016, note: SQL Server 2016 Reset on database offline/restart. 

As you delete old backups the SQL Server will still have the OLD NAS path on the backups that went there. So it will progressively delete those files without any further action from you. I generally recommend against updating system tables. When we have to move files, we just move them and cope with an extra script to handle the moved files until they are purged. If you have a week or two on NEW NAS the likelihood of needing the older backups is small. 

In that same discussion Robert Davis (SQL Soldier) agreed that would resolve the problem for the moment. But he also pointed out that if you use the fully qualified domain name of the servers you are less likely to run into a name resolution error. UPDATE: When you reset the endpoints, it will take the database offline for the duration of the restart. However, it will not break the mirror. The mirroring will stop running when the endpoint is , but it will resume once the endpoint is again . The MSDN article: $URL$ suggests. 

My quick experiment showed that the code works as long as the nvarchar(max) value is 4000 characters or less. (Of course, all blanks with nothing on the end collapses to no characters and thus works just fine.) The 4001st character triggers the message. So you might examine your data for a SerializedValue that is longer than 4000 characters. EDIT: Yes, the conversion is to a . The problem is not the , but is the . For example: 

It is not normally recommended to do unless you are dealing with a severe space shortage. No, it is not necessary to restart SQL Server after a operation. A very busy database, which is certainly true of tempdb, can be shrunk, but not always easily. You may need to and make repeated efforts to shrink the file. Restarting the SQL Server will return (and files), to their defined start size. Likely you would not want to do that on an active server during times of heavy load. Your database's data and log files should be ideally defined to match the work you are doing on the server, with some extra buffer. Although puts an extra burden on your server and adds to fragmentation problems, you may decide to do so if needed to recover space without a restart. Usually though, this can be managed by doing log backups at a frequency that keeps the log files smaller than the space allocated. Also, adding more resources to the server would likewise reduce the occasions where shrinking files might be needed. 

You might find the diagrams and explanation found in the SQL Server 2008 R2 documentation useful. (Nothing has fundamentally changed recently on Full Text processing.) $URL$ Quoting from that explanation: "The query processor compiles and executes SQL queries. If a SQL query includes a full-text search query, the query is sent to the Full-Text Engine, both during compilation and during execution. The query result is matched against the full-text index." So you might view the Full Text search as a 'function' that returns its portion of the query from the Full Text Engine, then joins with any operators from the Database Engine that may also be part of the overall SQL Server query. 

This does not work, because there is no row to return, so there is no column to COALESCE. If this is what you need, then you will need to force a row to be included. E.g. 

So, your problem is with the catalog collation. As you change to contained, it is changing the database's catalog collation to Latin1_General_100_CI_AS_WS_KS_SC which is the source of your problem. Perhaps the comments on collation, particulary the CATALOG_DEFAULT may provide you some assistance: 

So, RSS enables Windows with better options for receiving data, but it does not seem to indicate that the SQL Server will behave in some better way. But, I cannot find any clear direction on this and most of the papers are about a decade old. 

There are ANSI Standard data types, but I believe that is an Oracle standard, not a part of ANSI. It appears from history that Oracle's was designed to overcome the limitations of their earlier implementation. Having said that, practically every SQL dialect has some unique datatype that is not accepted by all other SQL dialects. (I primarily work with MS SQL Server, but do at times need to absorb data from other systems.) Fortunately there are a number of online resources to help you in mapping one datatype to another as you move between the products of multiple vendors. Usually it is not too difficult. Note: it is not only strings (such as ) that can have conflicting definitions. 

You will need to set the SQLCMDINI variable in Windows. For example: C:\SET SQLCMDINI=c:\sqlscripts\init.sql The init.sql (or whatever you name it) would contain the initial script. 

Yes, it is possible to wind up with a poor plan. One common cause of this is called "parameter sniffing". This is usually helpful, but if the stored procedure can be called with parameters that cause widely varying result sets, then the procedure can be stuck on a 'poor plan' for many executions. (But it might have been a fine plan for the execution that caused the plan to be created.) Using DBCC FREEPROCCACHE is quite a heavy gun, since it frees up all the plans in the server, which means that each one has to recompile the next time it is used. If you need to force a recompile, you can use sp_recompile to do so for a particular procedure, table, etc. If a stored procedure is likely to be widely varying in results you might find it useful to offer the OPTION (OPTIMIZE FOR UNKNOWN) hint. This will still optimize for your database statistics, but it will not optimize for a particular parameter. Benjamin Nevarez posted a useful explanation at: $URL$ 

The sys.database_principals Fixed Database Roles are owned by (database principal_id = 1) and cannot have ownership changed. But other Database Roles can be created and assigned to an owning principal_id. 

Microsoft has documented their "Description of support for network database files in SQL Server" at: $URL$ Trace flag 1807 bypasses the check and allows you to configure SQL Server with network-based database files. However, this is not without risk and you can fairly easily wind up with a corrupt database if the device does not fully support what SQL Server needs to achieve consistency. If you want to use this approach in a manner that Microsoft will fully support, they have a set of standards describing what they support. Following is a quote from the link: Windows Hardware Quality Lab (WHQL) qualified devices Microsoft Windows servers and networked servers or NAS storage servers that are Windows Hardware Quality Lab (WHQL) certified automatically meet the data write ordering and write-through guarantees required to support a SQL Server storage device. Microsoft supports both application and storage-related issues in these configurations. Note To be supported by SQL Server, the NAS storage solution should also meet all the requirements that are listed on the following Microsoft website: $URL$ 

Since it was working in the A.M. and it is not working in the P.M., then it seems likely that something has changed. Possibilities: 

Since a decides how to interact with you, that may have several and also may place . And I would think that the customer could cancel the whenever he wanted to. Therefore, both you and your customer have reason to keep a complete trail of orders and fulfillments (whether or ). That means that you do potentially want an of some sort even for . Here are two ways to handle this, namely treat them as the same thing or as two different things. 

So you can see that 2569.19 MB is essentially the same as 2569.73 MB The other numbers in the bottom picture are showing you how that database is allocated: 

For what it is worth, we have done it both ways over the years and both ways have their issues. But more systems that were using embedded documents are now using a file share instead. 

Run "cliconfg.exe" from a Windows run dialog to determine that you did not check "Force protocol encryption". 

If your retention period for backups is 1 month or something relatively limited, I would suggest the following approach. 

Generally speaking, adding AD groups to database roles and granting the permissions to the roles gives you some separation of purpose. In that case you would use them as: 

So, you get to choose between (1) slower restores for STANDBY MODE and (2) having faster restores, with the penalty of losing the connection. 

We have inherited a corrupted database 'DBName', with no good backup available to us. The corruption apparently happened some months ago. We have tried a few thing: 

Likely many of the DTA recommendations are included in the missing indexes query. Whenever that works for you, then you have the scripts you need. Anything from the DTA that is not included in the DMV recommendation could be hand coded. 

If that is insufficient for your question: "What metadata is stored and how does Sql Server keep it in sync?" then I suggest reading books such as: Microsoft SQL Server 2008 Internals (Developer Reference) authored by Kalen Delaney, Paul Randal, Kimberly Tripp, Conor Cunningham, Adam Machanic, and Benjamin Nevarez. (All SQL Server powerhouses.) A link, in case you need one: $URL$ 

This does not necessary imply that every column needs an index, but you can try creating a few indexes on those columns and see how much that helps. Note: ypercube recommends a composite index in his comments on the question. 

SPID -2 is an orphaned distributed transaction. If you have a Unit of Work (UOW) for the SPID the you can KILL the UOW. You get this from: 

One thing to remember is that an does not have to be generated by the property. Using has challenges, since as soon as rows are moved from the standby server to the current server (using of course) with an value higher than the current identity value it becomes the new current identity value. Which can complicate matters between the two servers. For other issues see: $URL$ You might find a sequence generator with NOCACHE or some other mechanism to generate on each machine gives you more control. For example, you can set ID ranges that can last for a long time for each server. For example: 

Repeat if necessary, to get the file shrunk to a reasonable size. Then think if you really want a FULL recovery model. If so, set up regular log backups and the log file will remain in control. Do a new FULL backup and then the LOG backups should run just fine. 

There is no Run As proxy for T-SQL Job steps in SQL Server Agent. You could upvote this with the chance that one day it will be filled: $URL$ The current way to get a T-SQL command to run with a proxy is to run it as an Operating System Command which does support a proxy user (instead of T-SQL which does not) and run the task either using or to execute the code. 

A server has very many events happening every minute. Having an event that happens every 60 seconds is not automatically too frequent If the event runs quickly and affects a small amount of data, then there should be no particular worry. The bigger the impact of the event (CPU,I/O,memory,etc) the more cautious you need to be about scheduling. 

The first ALTER may not be necessary, but it helps prevent someone else getting in as the "single" user. 

I am not quite sure that I understand your question clearly, so please bear with me on the issue of Logins and Users. It appears to be, in your case, SQL Server logins and not Active Directory accounts, but they behave essentially the same within a server and database. Also, for what it is worth, it seems that some step or steps are missing from your question. No big deal overall. Login: (Server Level) You might create login Login1, which has a SID of and grant it some rights. These rights belong to the login. User: (Database Level) When you create User1 for Login1 the user inherits the same SID of . So, inside your database the server login Login1 is actually executed by the database user User1 so the User is accredited with the permission. Because, as you see, the two are really the same account. The name of the User is absolutely meaningless in terms of execution. It is the SID that matters. 

For MySQL in addition to the command, there is also a command. However, has limitations. If you you cannot remove one table by running . This is because will only remove rights as they are granted. That is, you could: