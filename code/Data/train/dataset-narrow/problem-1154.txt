This is a maintenance hassle waiting to happen, because every manager that I've ever worked with would ask at some point for another item to be added to this list. I would be to pull these items out of a table in the database (if the DB is normalized they should be in a separate table anyway). 

That way, you don't have to hard code the size of the arrays that you are using, and you don't have to do any work to keep the related pieces of the record in synch (think what would happen if one of the arrays got sorted and the rest didn't). Then, in your parser you can create objects for each record: 

Miscellania Remove your dead and unused variables in , in and in (which you inexplicably after never using - see Setting objects to ) jump out, but there might be others. As far as the design and function, I'll let others tackle that - but I will mention that if you're doing anything that I mentioned above to make the class more "generally usable" it's a code smell. For example, if you use and all over the place to make it "generic", you should really be looking at compositing and using interfaces instead. The performance penalties and potential for trading compile-time errors for run-time errors just isn't worth the hassle of having to debug and maintain it. 

...appears loop over the same set of cells repeatedly when their values aren't changing. I don't recommend this often, but you might be best served by a completely different strategy. If all of the values are unique, there isn't any reason to update column A until you are completely finished (or add your check-marks for that matter). This is the part that doesn't make much sense to me: 

If you don't (for example if you're only testing it once), you can simply omit the variable declaration and test the return value directly: 

isn't doing what you think it is here. It doesn't test whether a cell is empty - it tests whether the passed to it is equal to . 

What does is hold an object reference to avoid having to dereference it multiple times. If you only use it once, it's reduced to 2 extra lines of code and 1 extra indentation level. That said, the place where it is appropriate is with your , and it isn't used there. This is much better: 

Naming You should avoid underscores in member names, i.e. . This isn't a stylistic thing - the underscore has special meaning to the VBA compiler. Note how all of the events ( for example) follow an pattern? There's a reason for that, and it's baked into the language. If you get into the habit of using underscores in procedure names now, you'll find it much more difficult to manage when you start writing and implementing your own interfaces and raising your own events. Use PascalCase like everything else: . I'll throw out my personal distaste for Hungarian notation while I'm at it. The prefix in particular is meaningless if I can see that it's declared as an object instance and it has an otherwise meaningful name. If you haven't already read it, I'd highly recommend reading Making Wrong Code Look Wrong by Joel Spolsky. 

Third, turning off screen updating is your friend if you are going to be writing values to a lot of cells. Again, I don't know the use case here, but it is a good habit to get into especially because of... Finally, performance. There are some things that VBA does well, but in general the built in Excel functions are going to be much, much better regardless of your algorithm. I have yet to find a function that I can outperform Excel with if a native alternative exists. First among those functions are look-ups and sorting, which Excel does extremely well. I took the liberty of testing your code with the numbers 1 through 10,000 in D3:D10003, 5000 random numbers between 1 and 10000 in column A, and 3000 of the same in column B. Your code took about a minute and a half to execute (in my resource starved VM). The code below took 10 seconds: 

Forgive any syntax errors - my VB is rusty. If you can't change the calling convention and have to work with VB6 types, there are similar date handling functions for the VB6 Date type to extract the year, month, and day. The logic would be the same though. The code above can be stream-lined a bit, TargetMonth and ModeFrequency are declared mainly for the sake of clarity. One final note (and this is more something to be aware of as opposed to something I would change) is that the code is relying on how the language handles dates to enforce a business rule. In this case it is when the payment is due if the effective date has more days of the month than the due date. The original code (and the sample above) both assume that the due date reverts to the last day of the month (behavior of .AddMonths() and DateAdd()). Some companies assume the first of the next month. Some companies like the one I currently work for won't assign an issue date after the 28th. 

They're also a potential bug source because they are resolved at runtime for late bound objects (which is the same reason you take a performance hit). That means that if you have a typo in the name (i.e. ), it won't be caught by the compiler. It is also dependant on how the typelib is defined for the class. For example it's possible for some late bound objects to introduce errors by specifying the same variable name multiple times. Excel seems to be prone to this type of error: 

There are magic numbers everywhere. This makes it both confusing and non-obvious what cell and range indexes are referring to. I'd replace them with descriptive constants that make it obvious what is happening - this also makes your code much easier to maintain if the layout changes: 

You created implicit casts when you extracted the function. You have it declared as returning a , but you declare as and then return that with . Then when you call it here... 

AdvancedFilters method I would consider a method with 6 state flag variables to be a candidate for creating a new class to hold that state. It would be much cleaner (and more in line with SRP) to simply extract this functionality into a class that is responsible for Worksheet filtering. It could probably use a more descriptive name as well - if the only thing I knew about the method was its name, I'd be pretty surprised when it started deleting rows. More Miscellania I'm a bit up in the air about storing member variables in a user type - it seems like a bit of overkill. When they have the same names as properties and are assigned to a variable named , I'm not in the air any more. When your member variables are accessed in the properties, it looks like a stack overflow at first glance because implies (at least to me) an instance of the class: 

These are not conditional, so pull this step out and do it by itself. A fairly efficient way to do this is to build a lookup of "CUSIP" to row number from the EDM sheet with a , and then go through the SSB "CUSIP" column and see if they're in the lookup. While you're doing this, keep another hashset of "CUSIP"s that are unmatched, and then use them on the next pass. 

9 - You have another (less) subtle bug. If you use to have the user select the range to work with, you can't use the global or collections - they have to be qualified. The reason is that you yield control to the user, who is free to select a cell in a different Workbook than the one that was active when the macro started. 

Second, enumerations should only have one member for each distinct value. The only real point to using them in VBA is to make your code more readable (there's no strict type enforcement), and it isn't immediately clear when you see something like this... 

I see several issues with this. First is the naming. and both hide global Excel variable (although whether this is good or bad is debatable...). This otherwise valid code becomes a compile error "Expected Array" everywhere in the project that contains the enumeration. 

2. The range selection interface duplicates Excel functionality Note that this is more a matter of personal preference than anything, but if Excel already provides an interface to select a cell or range of cells, why duplicate that? I'd simply use the existing object when the macro starts. You're already prompting the user to confirm that the that they selected when prompted is the one they want to work on, so why not just skip that entire process and use the object instead? Errors @Zak already addressed the big issue with the error handling, so I'll nitpick a little instead. 1. Duplicated code Your error handlers in and are identical, and only display the error condition to the user. I'd recommend extracting that section to it's own Sub: 

Methods , and are the main methods for interacting with the display. Any item added to the container will be rendered. forces the display to repaint itself. If changes were made to any of the properties that alter how it is rendered on the Worksheet, it will apply those changes. As a side note, this should eventually include Z-ordering, but I'm still up in the air as to the implementation details (and Tetris doesn't need the functionality - maybe for some other game...). There's also room for improvement in the resize - I currently have the conversion between character width and pixels fixed, but it should really calculate it based on the display settings. is simply a factory method. I'm open to ideas as to how to make the "default constructor" private. :-P 

My rule of thumb is that Windows COM calls are generally expensive, and are best avoided if alternatives exist. This should be finishing on the order of seconds not minutes, and the majority of the processing time should be coming from simply opening the Word document. 

The first thing that jumps out is that you're testing with 6 times per cell. VBA's doesn't short-circuit like other languages, so you'll test every single one even if the first condition is true. You can use for short circuiting by checking conditions against . So, your condition... 

Header: The and enumerations are used as flags. values can't be combined, so they are a straight up . There's probably some room for criticism here... 

There are a couple places in your code where you've "de-optimized". I'm not sure which of these adds up to a hour of run-time, but these are the most egregious: 

Third (on a related note), you should use the explicitly when you're checking for it's members. This... 

This illustrates the second issue - you are not actually benchmarking the code itself, but the performance of each of the underlying compilers. Assuming that the syntax is analogous between the two languages doesn't mean that it compiles the same in the C# compiler as it does in the VB.NET compiler. In fact, the different warnings between the two compilers make this quite obvious. Remember, just because the IDE is the same doesn't mean it does the same thing when you compile it. A proper benchmark has to be compiled under the same conditions. This is essentially like comparing benchmarks between identical C code compiled with gcc and Visual Studio. I am curious how similar the compilers are though - try removing the return instruction (or adding one in the C# code), ignore the warnings, run the benchmarks again. EDIT: Finally had time to look at the IL, and the recursion doesn't have anything to do with the performance - both of them have exactly the same IL: 

If you get more than one cell in the , it will never return , because will be a containing an array of (empty) 's: 

Second - Get a reference to the Worksheet object at the start of the function instead of relying on calls to . Nothing will make the wheels come off of a long function faster than the user doing something that changes the active Workbook or Worksheet in the middle of your execution. 

...that (to paraphrase Joel Spolsky) makes merely misguided code look wrong. When I see the above line of code, the first thing that pops into my head is "that requires a ". Going back to the Hungarian notation briefly, your "object prefix" doesn't match the semantics of the assignment, and your property declarations make it possible to ignore the standard reference assignment semantics. It would be difficult to make that line of code look more misleading. 

OK, that's probably doing much better now. But what if there were a way to link multiple tables of data using common identifiers? Well, you're in luck - that sounds a lot like SQL, which is supported by Excel via ADODB. The first step boils down to this: 

Internal Functionality: Just a couple of helper functions to convert the enumeration values into the command line options: 

user2023861 covers a lot of good ground, so I just have a couple more things to add. First, instead of using parallel arrays, you might want to consider using a collection container like a List and filling it with objects. Each line appears to a distinct record with a set of properties, so I would make them a simple Class: 

I pulled this out of my code bucket and dusted it off earlier today in response to a post over on SO that made me cringe. This was originally written to highlight changes in Excel cells in real time via , so it is designed with an eye toward raw speed to avoid blocking the UI. Benchmarks on current hardware are running around 3 seconds to compare 2 1kb strings. I cleaned it up a bit to modernize the coding style, but I'm mainly looking for input on the algorithm used and suggestions for making the code a bit more understandable for somebody who isn't familiar with it. It basically works on byte arrays and tracks the current working position in each array with a set of index pointers for the "start" and "end" of each substring that it's working with. The algorithm is similar to a binary search. The entry point function finds the longest matching substring in the two byte arrays, excludes it, logs all the differences to the output, and then recursively calls itself on the slices of the arrays to the right and left of the match: 

Once you have an absolute Row and Column relative to the Worksheet, it makes your calculations a lot simpler. For example: you can test to see if the Row you returned if one that you care about, and then use that knowledge to directly address the other cells you care about without fumbling around with the Offset. 

3 - returns a , which is an . When you make tests of the return value, you are implicitly cast it to a , then comparing it to an (), which implicitly casts it back to an : 

I'll just focus on performance, because that's the fun part. You're correct to be worried about the string manipulations, so you should obviously try to minimize them. The other thing you should be worried about is the division and exponentiation used for bit-twiddling. If all you need to do is swap the byte order of an intrinsic type, you can do it using a CopyMemory API call, a struct, and simple assignments: 

OK, so at this point we have a hashset of "CUSIP" that are unmatched. That means we only need to test ones that didn't match. We also have a lookup of "CUSIP" to rows in the EDM sheet that we built on the first pass. So, go through the BB sheet and see if they're in the "unmatched" hashset. If they are, look up the row in your EDM lookup and test the other values. The rest is just moving data around. 

...then do a code review on the entire thing. Ask yourself, "In the context of the full Sub, what is the reason for every single line of code other than part above"? I'm guessing that in roughly 99.99% of cases, there won't be a good answer for all of them. 

I think the answer to you question mainly lies in the level of faith you have in your statement that "this particular application will likely not change or add functionality at any time." In my experience, its only a matter of time before somebody asks "wouldn't it be nice if..." or the business requirements that drive the application change. That said, it doesn't look like there is a lot of immediate gain in decoupling this much further at this point. There may be in the future, but if it does the job right now the addition effort in refactoring might be a little bit premature. I would ask yourself how many use cases there conceivably are at this point - if this is basically just a one-off office automation type project I'm guessing there aren't that many right now. That said, what has bitten me on projects like this in the past are "simple" changes that are easy to implement but require the source to be recompiled and redeployed. This makes the following code section leap out: