Continuous delivery and continuous deployment both take continuous integration one step further, by adding a 'deployment to production' step to the process. The difference between continuous delivery and deployment is that for delivery this step is done manually and for deployment is it automatic. 

Difference between Continuous Integration, Continuous Delivery and Continuous Deployment. Picture copied from codeproject.com Whether you do continuous delivery or continuous deployment is very much an implementation choice. If you do continuous deployment, changes in code will be deployed automatically after the acceptance tests are passed. This may or may not be desirable for your product. With continuous delivery, people can make a choice whether a particular code change is deployed or not (and possibly where exactly it is deployed). Since the difference between continuous delivery and deployment is small and many people are unaware of the exact difference, the two terms are sometimes used interchangeably. 

Recently the Amazon S3 had a major outage in the us-east-1 region. It looks like it was likely caused by a spelling error when running a maintenance playbook in Ansible or a similar tool. You can put a shell script wrapper around ansible-playbook to look like: 

This is a brilliant idea, also because of Daniel Kahneman who showed that if you split a single score into 5 weighed scores and add numerical criteria and bounds to those, you will significantly reduce bias. You could design not just the resume scoring, but the entire hiring process, with phone screens, onsite interviews, everything in this way. It would significantly reduce the inherent bias of the interviewers. We have actually started to do something similar for all hiring. Obviously, inside each area, your should add weight to what is important to the company for the position, but you are hiring a well-rounded engineer and you want someone who will propose major changes to how your organization operates, you are not simply hiring someone for specific skills to work in a limited area. Many people simply see this role as a higher paid Release and Build Engineer and if that is the case, that is what you should hire and advertise for. For a DevOps hire, I would suggest replacing the Lean with Learning. It is originally CAMS and even though some extend it to CALMS to include Lean, that is somewhat restricting as DevOps is based on so much more than just Lean. It is also Deming's ideas about Special and Common Cause Variation and System Thinking, Nash's Equilibrium (if each optimizes for themselves, the result could be suboptimal, compared to when everyone includes the interest of the group), Shewhart's Statistical Process Control, Goldratt's Theory of Constraints, Taleb's Anti-Fragility and so many more. This would also allow you to include participation in conferences in Learning and presentations at conferences or meetups as Sharing. In a position where you are not always a part of a team or your company might not be big enough to have your peers as your co-workers, it is even so much more important to establish and maintain out of workplace relationships and learning opportunities. We generally grouped those two under Culture. I would personally put under Culture the soft skills required to be effective in improving processes at your organization. CMMI, Kanban, Work in Progress limits, Agile practices, etc. JIRA seems more like Sharing tool and Git is more closely related to Automation. 

Or does blue/green mean, that exactly such considerations have to flow as well into the software design? 

Imagine you would run a bunch of services say based on the same Tomcat image. Would Docker optimize memory usage for identical memory segments and reuse these patterns? 

Eventually, using the setting for the client I have found the log outputs (apparently currently there are no debug level messages implemented as reported. 

These components have their bugs as well! Acceptable answer: at least one example of a GitHub project with working code going in this direction which is more than 6 months old but with updates within this timeframe (Maven or Gradle both ok). 

If the work of your team is sustainable, you will spend roughly the same amount of time on each of the four. If the unplanned work starts to creep up close to 50% of your time, it is a sign you are definitely understaffed. You should be able to hire to stay about one person ahead of the unplanned work reaching 25% of your time, otherwise, one person leaving will send your entire team into a tailspin you might never recover from. Overprovisioning of people and technology have same reasons and benefits. 

Adopt DevOps best practices and tools for increased effectiveness. Adopt DevOps culture and values for organizational transformation. 

The startup stage (under 150 engineers). Of course, the developers need to run their own software. Everyone does so in a startup. You might not even have operations team to begin with, but even if you do, it is small and the speed of progress is so fast that there is no way to pass the knowledge required to run it successfully on another team quickly enough for them to be successful. The medium sized business (over 150 engineers, but a single operations team). At this stage the churn in the company starts to be too high, the engineers who build software do not necessarily stick around also to run it. You don't know everyone anymore and it is hard to communicate effectively for everyone to be in operations. It would start to turn into chaos. At this stage you want to turn to the Google model, where every team has to operationalize their software, but not necessarily operate it. They will operate it at the start, but a big part of building software is to reduce the cost of operating it to a point, where the load is small enough that the operations team can sign on running it. Only then it is considered done. Large enterprise with multiple business units, (where each has its own operations team): At this stage you can turn back to the Amazon model, where every team essential develops and operates their own services. Each of the business units has to be small enough for everyone to know each others, so under about 150 engineers and you operate each essentially as a startup. Amazon has each AWS service operating more or less separately and it works for them. 

And got the same result; apparently 1G memory is insufficient even for simplest experiments. Increasing both master and workers memory to 4G and the problematic behaviour was not reproducible. However before the systems start computation the message still could appear but just once, seems it is printed in a waiting loop. 

Today, you could more or less setup a CI/CD toolchain by youself, even locally. Indeed I have seen teams doing it in an ITSM environment because the communication with management did not work. Nevertherless we know CI/CD is a very important, if not most important, company production line - it produces value, even if it is not seen so by ITSM to give it operations status and priority (in short, SLA for systems which should survive project time instead of setting them up in every project and department over and over). Let's ignore for simplicity network downloads. Question: what should be the execution speed of CI/CD relative to a setup on a local machine (if possible): 

Correct files or packages need to move to the server. Configuration and service states need to change. 

Of course I was notified at 2am and it took me until morning to get it up and running and everything configured and tuned up, but I'm afraid it is not going to be as good as before. It might take weeks before it is back to it's former glory. Now my uptime is gone, I don't have even measly three 9s and who knows what this will do to my reputation. Who is this Chaos Monkey and why did he do that to my server and why is he trying to ruin me? 

However many people on the Internet argue that this is incorrect because it violates REST/HTTP specifications; "embedding of API version into the URI would disrupt the concept of hypermedia as the engine of application state". Itâ€™s more appropriate to use the Accept header to request a particular version. For the latter people suggest to use a Vendor MIME type, for example something like Nevertheless, the reason why many API designers do include an API version in the url is because it's easy to implement and debug (clearly visible which version you are using). Side note: in our organization we recently decided to support both a versionless endpoint that always point to the latest stable version of our APIs, as well as an endpoint with a version specification. This allows users to choose if they want to commit to our latest API (which may require making changes when a newer version is released), or to connect to a fixed API version (which may become deprecated over time). 

Both Docker Registry and Docker Engine have API interfaces. I consider it should be possible to implement a Docker plugin for this integration to have images scanned for example as somebody pushes them. (side note - Docker registry is an image registry, not container registry). This scanner functionality is also possible through the commercial Docker Enterprise edition. $URL$ UPD here an example with clair/docker, looks quite simple $URL$ 

UPD. Strange enough, the very first image layer which always gets stuck before it downloads anything stucks rarely at "downloading... 987B". UPD2. Same behaviour with Docker EE client (Docker-Client/17.03.0-ee-1) UPD3. Filed this as a bug to the Moby project. 

Imagine you have resources for a job which has part 1 and part 2. Part 2 requires part 1, but both take considerable time. And, part 2 requires part 1 only at the end. Would you start them both in parallel and let part 2 somehow wait for part 1 getting ready? (chances are it 50/50 it will be ready by then) 

Well, there is no rename, it is a multi-step process, which involves renaming a bunch of entries inside the vmx file, using vmware-vdiskmanager to rename to vmdk and in general doing a bunch of potentially problematic actions if you don't know what you are doing. You could probably write a quick Perl script to do all that using this guide. Another option would be to clone it and delete the original, but it is resource intensive and does way too much work for what it is worth. The code below is untested: 

These roles are distinct from your 6 essential software development roles that traditionally compose the software engineering organization: 

Back in the Java world.. Maven and Gradle are quite advanced tools offering sophisticated configuration capabilities. For example, you might want to have a fast-fail build stage in your CI to find compilation errors but then be able to run an extensive series of acceptance tests, maybe not on every commit. How to model this in Maven and are there maybe already available resources? Requirements: 

In first place I look for default JIRA functionality e.g. without 3rd party plugins to simlify and improve the issue workflow. Examples: 

This has been a Docker bug caused by jumbo Ethernet frames while using VPN which has now been fixed. Thanks Docker team! $URL$