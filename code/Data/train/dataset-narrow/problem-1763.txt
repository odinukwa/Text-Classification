We have a Microsoft Exchange Server 2003 SP2 (v6.5.7638.1) for some user accounts. For one of them I've created the following Outlook 2010 rule to automatically delete mails from a certain origin: 

So I want mails from deleteme@example.com to mailbox@example.net to be deleted. For debugging purpose, I'm also forwarding matching emails to myself. Now the issue is that mails are being forwarded to myself (so the rule is working) but they are not being deleted. I've enabled maximum logging for rule actions at the Exchange level and I can see that the rule is triggered: 

Note that I've got another rule to delete emails with the same issue. Any idea why the emails are not being deleted? 

CloudFlare published a very informative blog post on how they're dealing with anycast. Only routing is involved. Each host is announcing a route via BGP and thus affecting the routing decision. When a host goes down, the route is not announced so the router takes the next available route. Critical processes are also monitored and routes are announced or not depending on the server load. 

I'm running a bunch of Windows Server 2008 R2 on a 64 bits hardware. I recently noticed that the service is going wild about memory consumption. The service on its own can consume about 4GB of the available memory and is continuously growing. I first took action to move in its own process to confirm that it was the cause of memory consumption. 

I'd like to use the capabilities of two Dell EqualLogic SAN and a VMWare vSphere 6 installation to implement a storage virtualization solution. Basically I'd like to put virtual SAN layer above my two physical SANs so that it can provide the same services as a usual SAN, this is for say, LUNs, iSCSI endpoint and more, NFS, CIFS shares, etc... The idea is that whatever happens to the physical layer, I can replace the defective device in a transparent manner or attach new devices to the virtual layer so that more space is available. On its end, the storage virtualization layer should make sure to replicate data for redundancy and use the capabilities of the physical devices for replication, snapshots and other. It seems that VMWare's Virtual Volumes is what I'm looking for but I don't seem to be able to create a Virtual Volume/VMDK (a.k.a LUN) and allow a physical host to connect it via iSCSI. Do you know any solution that could accomplish the requirements listed above? A bonus point would be to be able to use the resources from the VMWare infrastructure. 

is doing its job. has no idea of what is HTTP if your targeting the same port, only the first rule will match whatever happens to the request afterwards. The only way to achieve what you need is to setup a reverse proxy which will get all HTTP requests and redirect them to the correct HTTP server depending on the host name. 

All your tests have pointed out something that you should have figured out. When dealing with Netfilter/iptables, you cannot successfully build your rules without having the packet flow in mind. As you can see, a local process never go though the chain but only and . This is why your process is redirected when you place your rule in but not when you put it in . However, this rule is right for an external packet traversing your machine. 

Memory consuption was caused by one of our services monitoring the event logs. After having disabled this functionality everything was back to normal. 

So you don't have to check the state of your connection there as this table is checked only for connections. Let's talk about your problem OpenVZ is a "virtualization" technology based on namespaces. Basically, your virtual machine is a simple folder in which a Linux system tree has been set up and contained to give you the illusion of being in a truly independent system. The originality of this virtualization method is that all containers are running one and only one Linux kernel instance, the host's one. Now you have a problem because as you don't run your own kernel instance, you don't have full control and this explains a lot of things. 

I'm facing a strange problem with Windows Server 2003 and its DHCP server. Here is my scope and its related options. 

The best option for me would be to put a network tap between the switches. You can however put a Linux box with 2 interfaces and set it up as a bridge. 

So the rule is triggered but I can't see why the mail is not being deleted. All I can see is that the message is being delivered (what I don't want). 

Your Apache HTTPd server is running in prefork mode what means that a single control process is responsible for launching child processes which listen for connections and serve them when they arrive. Those are the many processes you can see. Then in your Apache HTTPd configuration file, you may find a directive instructing the server to run as the user. Since the user can have other uses on the system, this is not always desirable to use it as well to serve Web pages. It is better to create a dedicated user for this purpose. 

Running this code on my WSUS server I will get no update that are not applicable (count equals 0). However, in the WSUS Console Administration, I do see some updates that are not needed. How can I know if an update is really needed by a computer target and calculate the Needed Count value as shown in the WSUS Administration Console? 

On Windows Server 2008 R2 I'm trying to use the Remote Desktop Connection tool. As usual, I put the IP address of the remote host and click on connect. However, this time, the tool stays on "Initiating connection" and then fails with the following error: 

Compiling OpenSSL will not help you much. Your Apache is still linked with the old OpenSSL. You can verify this using the command. You should recompile Apache or for it to be linked to your new OpenSSL. 

Note however that you will need a wildcard SSL certificate for it to be valid whatever the targeted domain name is. 

No you cannot, each DNS server has its own setting to refresh their cache and you can add to this local DNS caches stored on the computer. You only have to wait. 

The strangest is that if I start a Wireshark capture on the host, there is no RDP packet going out. So the application is not even trying a network connection. Any idea? 

Your Postfix is listening only on the Loopback interface (). Edit the file and update the parameters with your public IP address. 

There was on access list on the switch for this specific port (TCP 3389) plus the Wireshark had a global filter on port 3389. 

You just have to add your domain names in the directive's list an configure each DNS zone to resolve as your Web server. 

X.509 certificates don't rely on the IP address but on the domain name. As long as your domain name can be found as common name or alternative name, you are fine. There was a time when having multiple SSL virtual hosts behind one IP address was not possible but now most of the Web ecosystem supports server name identification. 

You can log off a user using the task manager however, you need administrator access for that. The easiest way to do that is to open a console as Administrator and then run . From there, in the "User tab, you will have the ability to log off users. 

Deploying a Linux system can be as simple as mounting all the disks under the correct mount point, extracting a tarball with the system files and installing the boot loader. I know it works since I did it multiple times. However when it comes to deployment of a bare-metal system, things aren't that simple. Unless I missed something we're only left with Kickstart and the like. Installation instructions are repeated over and over while an image could just be extracted. The container echo system brought multiple filesystem image builders. I'm looking for such tool for bare-metal where I could prepare my system image and deploy it. And I'm not talking about the disk image that I can get from CloneZilla but something more approaching the work done by the Open Container Initiative. Having a container image I can therefore choose to deploy on bare-metal on directly as a container. Any idea of existing tools to accomplish this task? 

The directive accepts many parameters to configure how the connection is handled with the backend server. Among those parameters, you may be interested by: 

You just need to copy your existing public key to all hosts you want to connect to. Just use to setup your public key into the remote host. 

Then you set up Nginx to match on a regex server name from which you can serve a different folder depending on the user name. 

As you can see, option number is missing from the list. This is a custom string option I added by I had the same problem with option 44: WINS Servers, not showing in the list. I rebooted the server and checked any option but I can't tell why this is happening.