It may be perfectly valid to combine role 1 with one or both of the other roles, as long as role 1 isn't compromised in any way. Sometimes that's a thin line, but generally the Single Responsibility Principe is a good touchstone. I can be short about combining role 1 and 3. This may be valid in simple CRUD functions, although I don't like the dependency on Json.Net in a data layer class. And who says that in each use case the same properties should be ignored? It's generally preferred to use dedicated DTOs for client traffic. The DDD role is tougher to judge. Let me focus on your example. The method... 

As a loose definition, repositories are supposed to expose the database tables as collection-like interfaces to the application code. So it's expected for them to have , , and methods. But what's the use of a method like ? Remember that consumers of the repo only see the outside. They'll wonder "am I going to insert a context? And into what?" This is bad, but the really bad thing is that the method has vastly unexpected side effects: it replaces the context's by . How can consumers even begin to expect that to happen? Together with the first point above I don't understand anything of these methods receiving as a parameter. No composability. OK, now if the above points wouldn't exist, you'd be left with a pretty regular repository. The only problem would then be that you can't use it to compose queries efficiently, because the "get" methods return , not . Take this example: 

Side note: Dapper's Multi Mapping Feature won't alleviate the first two points because it also creates separate object instances for "equal" entities. So all in all, I wouldn't do this. I would get the data separately and perform some sort of "relationship fixup" manually. 

tl;dr Together with the points mentioned in the other answer, very much is very wrong. Back to the drawing board. Or back to some generic repository implementation from the internet. They're all essentially identical. 

Leaky as an old roof :) An abstraction is leaky if you need to know details about the concrete implementation in order to work with it properly. Leakiness of an interface may reveal itself in various ways, for example: - 

These s generate a very wide query (as you show), because all fields of as many as six tables are queried. Often, when tackling performance troubles, people focus on reducing the number of rows that are fetched by a query, but reducing the number of queried fields can be at least as beneficial. This is especially true for ORMs, where materializing entity objects can take a significant amount of time. So it would make a lot of difference if you'd project to the view models, and in the LINQ query as , i.e. not after . This would narrow down the query to only the fields required to populate these models. However, you don't do this, obviously because this function call is not supported in a LINQ-to-Enties query. Then, of course, you also query too many records. In the end, you only need data from one and one , but because of the s you fetch all seasons and all episodes of a show from the database. The Solution I think you can both reduce the number of queried rows and fields if you start the query at the bottom. If a user watched an episode, they obviously also watched its season and its show. So if you get the latest episode directly, you don't have to worry about getting watched seasons and shows any more. You don't need this function, because you start by getting the latest episode. Further, you can get required data by accessing parent navigation properties. Like this (only showing the essentials): 

I think this library is a gem. One more thing: I my opinion, repositories, if you decide to use them, should be generic repositories. That means, for each entity class they do exactly the same thing. Your method doesn't belong in a repository, rather in a service (that uses repositories). 

Where's the DDD going here? For the first option the code always needs to know that must have loaded and there may not be a single source of players: they may get loaded from the but also in and navigation properties. The second option is even worse: the caller is made responsible for 's proper state. In DDD you'd use a class that is guaranteed to have all data it requires to execute its methods properly. Objects of this class will be created solely by a factory that ensures their integrity. It's always safe to call their methods (Tell, don't ask). So, to summarize, it may be possible to equip EF classes for executing business logic. It mainly depends on the extend to which it can be guaranteed that the data layer produces entities in the proper state. 

That's one query for each . So you end up having 1 + 1 + n queries. No doubt, it's better to turn these into one. For example: 

Note that doesn't return but . This opens the opportunity to compose a LINQ statement involving multiple repositories and still translate the whole statement into one SQL statement. For example, if you need an occasional (because there is no navigation property), it would look like: 

The problem here is that you'd actually want to include subtypes. If had a collection of s, you could have done 

As you see, the property of an entry in EF's change tracker is used to build a clone, which is always a shallow clone of mapped properties. Of course, you can't apply this method inside an entity class, because it requires a context to which the entity object is attached. But is that bad? I'd say no, because this clone method has a very specific purpose which is tied to an EF environment. To me it would break the persistence ignorance principle if a class would require knowledge of the data layer implementation for which it clones itself. 

After revisiting this, I finally arrived at the best solution I could find after benchmarking a couple of alternatives: 

Of course this includes all members, active or not. And (grief), s can't be filtered. Fortunately, there are better solutions for this. The most viable one, in my opinion, is EntityFramework.DynamicFilters, by which you can define filters that will be applied any time a type is queried, also in s. A very technical, but more complete, solution is the one proposed by the EF team's product owner himself, the code and explanation of which is available here. More complete, because it also redirects deletes to setting a delete flag instead of physical deletes. Another, pretty elegant, solution, also redirecting deletes, is here. But it uses inheritance, so it may not play nice with other inheritance schemes. 

if it's very hard (or impossible) to implement the interface with another technology stack than the one for which it was designed. Or if it perfectly exposes major features of one implementation, but would make powerful features of other implementations inaccessible. Or if it enforces a work flow that perfectly fits one implementation but forces other implementations to bend their own preferred work flow. Or If it doesn't tell the whole story, if an implementation has added core features. 

The DTOs serve as an abstraction layer between UI and service, so the UI can change without implications for the service layer and vise versa. Service layer: 

As you see, it expects a that implements . This is an interface in the namespace. So you run from one implementation challenge into the other. I don't think there will be any provider implementing that interface, other than those created for Entity Framework. And it can be mocked for the purpose of unit tests in an EF environment, as in the link you shared. Now what? Does this mean you should revert to the original plan and jump through hoops to return correctly? I don't think so. For one, is leaky as well. But I may have answered your question in a stricter sense than you expected. Maybe you never intended to craft a completely different implementation. Maybe you only contemplated the implications of exposing in a unit test setting. If so, , or even is good enough. 

So what you do is the only way to get the with s and s. There are some improvements to be made though: 

When testing this with 107 integers, the statement took approx. 70% of the time. But is a highly efficient method, so all in all this is the winner. 

No it isn't. When the choice for Entity Framework has been made (which is good), the simplest repository is the one EF provides out of the box: the . In this case, . Any layer on top of that can be useful, but shouldn't be applied just because it seems such a good idea to implement the repository pattern. It's already there! You emphasize that the application is to be simple, so I wouldn't stack layer upon layer prematurely. The base line The only thing you really need to persist s is the part (slightly rewritten): 

(Note that this changes your model data type.) 2. Use a projection These queries return complete entities. But in the end, you only display one field (let's ignore the fact that in reality you probably do more). So you may as well get that field only. Reducing the number of fields in a query can considerably improve performance, especially when records are wide and many joins are involved. I often see people focus on reducing the number of records, but reducing the number of fields is equally important. In your reduced example, it's enough to get only the names from the database: 

That would leave you with the two queries and a return statement. But there's more. As you say, if you use , you get all data, including deleted items. It's because of this annoying inability of EF to filter s why such elaborate workarounds are necessary. But there is a third-party library that makes this a lot easier: EntityFramework.DynamicFilters. This library offers a simple API to define global filters that can be switched on and off. In you case it could look like: 

Extension methods So far, the challenges only just applied to implementing the interface specification itself. The real bummer are extension methods. If you've got an , it seems reasonable to expect that you can apply extension methods from or the vast class. After all, extend and is in the same namespace. But let's look at the source code of just an arbitrary method, 

It's not necessary to set the return string all the time. You can first look for occurrences of with an incrementing parameter of the function. Only after no (new) occurrences are found, or when the required max number of occurrences are found is it time to set the return string: 

This is generally considered to be a bad idea. has deferred execution, which means that in your example, can be forced to enumerate any desired number of times. As a consequence, it depends on the implementation behind the whether any changes applied by will still be visible after your methods have run. There are two possibilities: 

If returns you'll see that the s and s (all s) will be fetched into memory by two queries. Also, the is executed in memory, not translated into SQL. With , the whole statement is translated into SQL, making it far more efficient. (Assuming, of course, that both repos receive the same context instance). Finally There's always much discussion about the use of generic repo/UoW on top of EF's / that implement the same patterns. I wouldn't use them just because it's a "good pattern". In most cases they're only a thin wrapper around the EF objects. Maybe you have to reevaluate this. 

is an . If you join it with , i.e. without , Entity Framework will throw an exception about primitive values, which is an obscure way of telling you that it can't translate into SQL. So join in memory, i.e. with . But now all data from will be pulled into memory, which has two adverse effects: neither the reduction in numbers of records by joining with nor the reduction in width of the result set by selecting only a restricted number of properties can be translated back to the SQL query. 

... will always try to find an existing record in the database in order to determine whether should be marked as or as . But you already fetch the existing record by the statement: 

It can't be any shorter. It's basically a thin wrapper around a . But I do have a remark about the design. IMO you shouldn't return from and , but . There reason is that by returning you can compose queries comprising multiple repositories that will result in one expression tree and, hence, one SQL query. (I'm assuming that all repositories in a unit of work will receive the same instance.) With your current code, if you'd join two repository results, like this ... 

As you see, for the details I use a ( which serves as an outer join) to determine the existing and the new details. The existing ones are modified, the new ones are added. 

Whether or not you should set up a UoW/Repository layer on top of the UoW/Repository implementations that EF offers out of the box (/) is a question I consider beyond the scope of this review. You'll find many many opinions about this on the internet. But a couple of things are definitely wrong. Repository's internals 

is so leaky, I wouldn't even call it an abstraction. Let's look at what you encounter if you want to implement for, say, NHibernate. 

This achieves the desired data reduction. But now you haven't got objects yet. Can't be done by this query, because they also contain data from . This final step can only be achieved by joining the result in memory with : 

... assuming that simply s the entity to the context. Now EF will see and as new objects and (try to) insert them on . So how to assign the and values? You could do that in a very generic way that will solve this for any you add, not only copied ones, even removing the need of this constructor. It's by overriding in your subclass: 

You may have noticed another big advantage, compared to your approach: the method returns meaningful information rather than just a boolean. I'm not even sure how you would supply feedback from your method. As you see, this is close enough to consider refactoring your own architecture, but also different enough to make this more than a trivial operation. It's more at the ground level, while your validation is in an abstraction layer. Another difference is that the EF validation is holistic: it validates an entire object graph, while your validation validates individual entities. Both have their pros and cons. With EF's validation it's harder to get validation errors for one specific entity, with your validation it's hard to validate a mixed collection of objects. 

If one entity is modified, the changes are reflected wherever the entity is referenced. Also, changes are unambiguous: there are no "equal" entities around having old values. (You're probably getting read-only data, so this may not affect you). Ability to perform operations that are based on referential equality. For example, in your case, grouping s by will produce groups having 1 item, because the language object aren't equal (sure, can be evaded by using , but still, it's a gotcha). EF can perform relationship fixup when it loads entities: loading Resources and Languages separately into one context will auto-populate the navigation properties. Your code won't ever do that. 

... is hardly ever an economical way to do querying. It fetches a complete entity from the database of which subsequently all but one property is discarded. Or, when is a lazy loaded collection, everything is discarded. In general a better way is... 

A property bag that communicates data back and forth between the database and object-oriented code. That's obviously it's primary role. A DDD class that encapsulates business logic, i.e. data and methods working on them (the OO principle). A DTO class that communicates between some client (UI or B2B) and the business logic. 

As I explain here, the EF model is primarily a data layer. Its classes may be suited for other roles, but their primary responsibility should always be: smooth data access. Your question is about combining three possible roles an EF model class could play: 

The second part is OK. Getting the most recent item from a collection always requires some ordering that defines "most recent". Note that using the improved form, EF will translate this into one query, because isn't materialized yet. It is an expression tree1 that can be merged with the second expression. If you want, you can create one statement in LINQ as well: 

One file vs. many partials My first comment is about the class itself. I would prefer keeping it together. If for any reason you want to make some consistent change in the extensions it's very hard to do that when they're scattered all over the place. When to use extension methods This is the main question: should I do this? My opinion: no. At least not to that extent. When extension methods were unleashed in c# 3.0, the whole developer community (including me) went on a razzle with them and started creating extensions for just about anything. A bit like the days when text processors with more than one font entered the market. Suddenly we saw club bulletins appear that looked like (and violated) this: