As far as I understand it you have 2 connections to transit providers and 1 connection to a peering point, in this situation I assume that you are using BGP to peer with your transit providers and with an IXP router. The way BGP works is others can only reach the destinations you advertise to them. So for example you have a /24 and you will advertise this to your transit providers so hosts on the internet can reach you through you transit peers and you would also advertise your /24 to the peering point so that hosts connected to the peering point can reach you directly without going over the internet (as this would be seen as the best path). For BGP sessions you would normally be filtering what you advertise to your peers and what they advertise to you (if you have downstream peers) with a prefix list for example. Generally you wont filter inbound from the peering exchange as the exchange will only send you routes of people connected on the exchange. This is similar to your transit providers except they will generally send you the full global routing table (all destinations on the internet). In this situation you would add a prefix list matching an ACL in the outbound direction on the BGP session connected to the peering point to only advertise your /24 prefix this will allow hosts on the peering exchange to reach only IP's in your /24 via your router (which is what you want). If someone advertises a default route to you and you accept it, you wont be taking their traffic and sending it to the internet. In this situation you would see a route to the internet via them because your router will see a route to 0.0.0.0/0 (the internet) through them because they advertised it to you. The only time hosts connected to the peering exchange will see the internet via you is if you advertise a default route on to the exchange yourself. The only other time you may be used as a “transit AS” is if you have customers that are downstream peers with you and they ask that you advertise their IP space to the IXP so they can reach the exchange through you. 

I feel that I've done everything I can here with the USB stick. Is there specific software that I need to use to prepare a USB stick for the boot loader? I've tried diskpart and also Rufus, but it just seems to be the boot loader that doesn't like anything I've tried. Please adivse. Thanks. 

Recently, I've been working on two spare switches which I need to stack at some point, but before I did that I needed the clear the config on both switches. Unfortunately, I made the mistake of typing erase flash: instead of nvram: and it's obviously caused me a problem. Not a massive issue though as I could just load the IOS image of the other switch as they're both 2960x switches. I've taken a USB drive and partitioned it to 2GB and formatted it as FAT16. When loading the USB onto the working switch, it accepts it without issues and allows me to copy the IOS image to usbflash0: and when doing a dir usbflash0:, it shows me the IOS image so I know it's all ready to go. When I console into the switch that does not have an IOS image, it takes me to the boot loader which is expected. However, it's at this point that usbflash0: is not recognised, and displays the following: 

I've tried to find an explanation online that just simply tells me how inverse ARP is configured, and I can't seem to find a straight answer for it. Let's use the below diagram as an example. 

I have a full mesh core network running OSPF. I use OSPF down to the "L3 Agg switches". Now I want to restrict traffic between some of the networks at our site, but how is this done when there is multiple routes to every network? Behind every "L3 Agg switch" there is a cluster that in some cases need to be isolated from the rest of the network. 

Now we want to renumber the hosts with private IP-adresses (one net per cluster) and use OSPF internally, to reach the internet we still use a default route to some central university router. One important thing is that we still need to have some hosts with public IPs reachable from the internet (a few login nodes per cluster and some other services). 

Most high end network equipment (switches and routers) can act as a NTP-server for hosts in the network, but I cant find any information on how stable these are. Does anyone have any information or insight? Edit: So, my actual question is: Are switches and routers usable as ntp servers in a network? Or should we go for specific hardware? 

My first question has to do with the links between Core and aggregation. I could use MC-LAG (Dell VLT), Stacking or just OSPF everywhere. 

First of all 802.11g is 2.4Ghz only and 802.11a is 5GHz only. If you don't have a dual band client (a+g) it can only connect to g OR a depending on what band your client supports. 802.11n can do both 2.4GHz (gn) and 5GHz (an) depending on your AP. A 2.4GHz 802.11n (gn) device can always behave as a 802.11g device because the n only means bigger channel width (40MHz) and up to four spatial streams. But it can revert back to using just one spatial stream if there is a 802.11g client. The same is true for a 5GHz 802.11n (an) device, it can also revert back to fewer streams if needed. Please have a look at: $URL$ 

I know that 90 is the administrative distance, but the metric of 30720 seems high going over fast ethernet to only one hop. Could any light be shed on why this is so high in comparison to OSPF for example? I understand that this is probably a simple case of apples and oranges being two separate routing protocols, but I'm interested to know how this is calculated. 

Is there something wrong with my config that's causing this? EDIT: On both interfaces from the core and the access stack, there is a stationary amber light which usually indicates STP has suspended the port to avoid a loop. Port Channel 1 (Access Stack) 

I'm looking for an understanding of how the metrics are structured within EIGRP, this includes the routing table, and also the topology table. I'm sure I'm not the only one that finds the concepts of EIGRP a tad tricky to grasp. My small network has been created and I've enabled an AS of 1 on both connections for an EIGRP neighbouring relationship. This is the output from both the routing table and the topology table: 

I've recently been studying the fundamentals on IPv6, but there are some things that I don't quite understand about how the addressing is structured. I know that link local addresses start with FE80, unique local addresses start with FC00 and global unicast addresses start with 2001 for example. Also from what I've seen, most addresses use the /64, sometimes accompanied by EUI-64. What I don't understand is the slash notation ranges with some of the address types. For example: Global Unicast 2000::/3 Link Local FE80::/10 Unique Local FC00::/7 With the above three address types for example, could someone please explain to me what the slash notations indicate? I can't seem to find a proper explanation for this anywhere. For the Global Unicast address for example, I've mostly seen 2001:0000 etc etc addresses. Does the notation mean the most I can go up to is 2003 as it's a /3?The same with the Link Local and Unique Local. The slash notations just don't make sense to me, and the books just don't seem to bring any logic to the table. I'm more than likely way off with my assumptions here, so some clarity would be good. I'd really like to understand this, rather than just assigning 2001:0000 etc etc Global Unicast addresses, without truly understanding why I'm doing it. Thanks in advance. 

In classful networks the class is determined by the leading four bits in the ip-address. B-networks start with 10 (binary). So, in fact 190.28.0.0 is a Class B network. $URL$ When it comes to CIDR you can say nothing about the size of a network from just 190.28.0.0. But 190.28.0.0/16 tells me there is 16 bits in the network part of the address and the remaining 16 are host bits. Since ip-address calculations are performed in binary, to find a netmask that will divide a /16 into 8 subnets you do the calculation 2^x = 8 (looking for how many digits you need in a binary number to have 8 combinations) which is 3. So, a /16 can be divided into 8 /19. 

If you divide your network into eight /19 you have 32-19 bits remaining for hosts. To find the number of hosts you calculate 2^(32-19) = 8192. But remember that the first and the last address are reserved for network and broadcast-addresses. That gives you 8190 usable IP-addresses. To find the ranges you set the host part of the address to all zeros to find the network address (first address) and to all ones to find the broadcast address (last address) Edit (Working example) The ip 190.28.0.0 is 10111110.00011100.00000000.00000000 in binary. Let say i choose the subnet 010 to get a /19 network. This gives me the network address 10111110.00011100.01000000.00000000 which translates to 190.28.64.0. To find the broadcast address of the same network we set all remaining bits to 1: 10111110.00011100.01011111.11111111 which translates to 190.28.95.255 You can then do the same calculations for all eight subnets i mentioned above. 

With a hub all ports are in a single collision domain meaning that all frames are visible on all ports and their connected devices. In a switch every port is its own collision domain so frames sent on one port cannot collide with frames sent on another port. Full duplex is negotiated between the end host and the switch port this allows the use of all send and receive channels/wires on the cable and forming the single collision domain (between the switchport and the end host). The difference between hubs and switches is that a switch builds a mac address table (learns the mac addresses of the connected end systems) and will only broadcast frames when a mac address is not already known in the mac address table. When a mac address is learned on a port only frames destined for that particular mac address (end host) will continue to be forwarded on that port. A hub will not build a mac address table and will always forward all frames on all connected ports. 

The only way to determine what is happening exactly is to get a packet capture of the traffic so you can see what the router is actually doing. Most modern routers will de prioritise icmp traffic in favour of forwarding actual traffic if they are under load. As others have pointed out this particular router is a fairly low level device so this could be the case. I have seen this exact issue with a (fairly powerful) router reporting packet loss when testing with MTR when in fact no loss existed. 

As you can see, I've configured this as an MP frame relay all in the subnet. Now I could quite easily link all of these together by creating static maps. That's not the issue. What I'd really like to know is what configuration needs to take place in order for inverse ARP to work between the routers? My guess would be to place routes on the frame relay switch from one DLCI to an outgoing interface, but how does the frame relay switch know where the DLCI is coming from? Does it need to still be mapped somewhere else, so there's communication between the routers and frame relay switch? Otherwise it just seems like a free for all. Any help would be appreciated, as I'd really like clarity on this. Thanks, 

As these switches are not related to eachother from a previous stack, how I do remove the switch provisioning for each switch? If I were to attempt to remove the setting, it comes to back to say that it can't be done whilst the switch is present. The first switch appears to be a master, with the other switch being the slave. Is there a config file that stores the settings for this? I've cleared the startup-configuration but this still remains. Would I have to connect them both with stacking cables to create a stack first before I can deactivate the setting? These switches will be used individually in the future, so this is why I want the stack removed altogether. Please advise. Thanks. 

Ok, lets try again. It seems Im having problem asking the right questions so lets take it from the beginning. I work at a HPC center at a university. We have a number of small (<300 nodes) clusters and a few storage systems. To our site we get a statically routed /22 network. Today we have the whole /22 in a single broadcast domain and we have decided to redesign and renumber the network for better scalability and performance. To do this we have bought two new L3 switches (Dell s6000-on) to use as our backbone. Connected to these we will have the aggregation switches of the individual clusters (which are HP 5400) and it will look something like this: 

On every vlan I have two ip ranges (for historical reasons). To PXE boot machines on these vlans I use ip helper/dhcp relay to relay requests onto the vlan where the dhcp server sits. But the dhcp server only handles DHCP requests for one of the ip ranges (the one used as source address in the relayed dhcp message). How could I tell my dhcp server så accept dhcp requests for multiple subnets from one specific IP? 

The machines on private IP-adresses still need internet, so I want to NAT them out. But our new core switches doesn't support NAT (as far as I know) so we are setting up a NAT-router on the side. Is there some smart way in OSPF to redirect traffic from privates IPs to the nat-router? Or should I use PBR? Do you have any solution for the public IPs? They are sort of scattered throughout the datacenter so there is not a single access point for these machines. It would be very helpful to have a large vlan with a /24 or so that spanned the whole network, see question 1. But maybe the best way is to just split up the network into smaller ones and route them with OSPF as needed. Some of you say its a bad idea to have both public and private IPs in the same OSPF area. If this is so, what do you think we should do instead?