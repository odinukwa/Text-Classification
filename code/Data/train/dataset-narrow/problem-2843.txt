This is obviously a terribly contrived and simplified example since I don't know what your game object model is; it does however illustrate making the dependency on the event scheduler explicit and shows some potential for further encapsulation (you wouldn't necessarily need to pass the responders the scheduler if they communicated through to a higher level collision response system at the same conceptual level as the factory that dealt with the nuts and bolts of raising events via the scheduler. This would isolate each individual responder implementation from the implementation details of the event dispatch system, such as which specific event to raise on collision, which may be ideal for your system -- or not). 

The ideal way to do this would involve OpenGL and D3D sharing the texture memory on the GPU. But there is unfortunately no practical way to do that (as far as I am aware). Thus, you're going to have to shuffle the texture data around on the CPU. The process is fairly straightforward though. Once your render-to-texture has completed in OpenGL, map the texture to the CPU (via or something fancier), which gives you access to the pixel data of the texture. With that mapped information you can use and/or to create a D3D texture using the same pixel data. If you're going to do this repeatedly you'll want to make sure you create both textures with the appropriate flags to suggest dynamic updates to the API. 

A data structure is a tool, like any other. That means it has places where it is appropriate and places where it is not, and a map is no different. If it fulfills the need of your program, makes logical sense in the use case and contributes to the improved readability of your code, then use a map. If that use case ever becomes a performance concern (which you'll know through regular profiling of your game), address that concern then. You've provided no references or citations to the assertions that maps have no place in game development, but if you had I suspect those claims would be easy to dismiss as overgeneralized hand-wavy FUD. 

To solve this problem, I'd recommend you build a paging or streaming system. This will allow you to dynamically load and unload resources as they are needed, keeping only what is necessary for the current area of your game on the GPU (instead of trying to keep everything there all the time). If you have single resources (such as textures) that are overly large, you'll have to consider ways to break them up or reorganize them so you don't have single, monolithic, gigabyte textures floating around. As to the background, or why you get this error: means that the graphics device is being asked to utilize more resources in a single frame than will fit in video memory. Using for a resource means that that resource will be placed, based on the set of usage criteria you specify when creating the resource, in the most-appropriate memory pool. This is usually video RAM. The API will not manage anything in the default pool like it would with the pool (if the device is lost, you must release and re-create default-pool resources), if that is what you are wondering about. The error you are getting means that your resources can't all fit. Keep in mind that 

When writing a game in C# that uses plain-old Windows Forms and some graphics API wrapper like SlimDX or OpenTK, how should the main game loop be structured? A canonical Windows Forms application has an entry point that looks like 

What you're looking for is something along the lines of "painterly rendering" or "cel shading," probably. Both of these are subsets of the space of non-photorealistic rendering techniques. The majority of the information on these rendering techniques can be found in academic papers or books. There doesn't appear to be a wealth of Max plugins that provide NPR effects: 

Now you have two mask textures (the last two images). You can destroy your original sprite and create two new ones. Both use the same base texture, but they also have a mask texture assigned. In the shader, you sample the base texture for the red, green and blue components of the output but you sample the mask texture for the alpha value (in the above examples, you'd use the red component of the mask texture as the final alpha component, and you wouldn't actually want the background of the mask to be grey - I did that only to make it distinct from the site's background). As you continue to cut a sprite again and again, you should combine the new masks with the old. This will provide you with a basic implementation. It's relatively simple to implement, and has the advantage of allowing fairly arbitrary cuts in your sprites. However, it's disadvantage is that it requires a lot of per-pixel operations on texture data (flood fills and inverts), which can become a bottleneck as the number of cuttable sprites increases. You can alleviate the problem by using lower resolution textures for the masks, to some degree. 

Yes, the simplest way to do this is to animate the texture coordinates of the relevant geometry over time. You could either: 

Max (and most other modellers) also have rendering support, so they can render your scenes out to images -- you don't need to capture the screen to get your models into an image. The process of creating sprites from a model is essentially invoking the modeller's renderer with the desired settings (for lighting, anti-aliasing, and what have you) repeatedly at every desired camera angle. The settings you have to select really will depend on the desired effect you want in your sprite images -- you'll have to experiment. Most serious modelling tools have scripting support, so you can create scripts to automatically render the scene from all the desired camera angles and possibly even stitch the resulting images together in a sprite sheet. Here's one of many available scripts for Max, for example. Since Max is quite expensive and you don't currently own it, you probably don't want to drop the cash on it. You can use Blender, which is free and has Python scripting support that should allow you to build an automated workflow for your sprite rendering. Just make sure the assets you purchase are loadable by Blender -- try to get a sample file from the author first and make sure everything works well (this is a good idea even if you don't use Blender, note).