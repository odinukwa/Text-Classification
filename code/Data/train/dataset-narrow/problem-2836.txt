The short answer is yes. The long answer is that the specifics of how to do it massively depends on how you handle drawing your characters. If you use skeletal animations (like when using spine), then you can easily exchange bits of your character by just replacing the texture of it. (Since in skeletal animation systems your character is separated into parts anyway). You can do the same thing when you use sprite sheets too, but it is slightly more complicated. You already had the right general idea in your post. You split the animation up into the parts that you want to combine and you need to remember a draw order for all those parts for each animation. But then you can draw each frame of an animation easily by just combining the parts together. The drawback is that you need to make a full set of animations for each part, since every hat for example has to move the same in every animation, otherwise some combinations will just look weird. tl;dr: It is definitely possible and it is much easier if you use skeletal animation. 

Fourth there is also something to be said about the effectiveness of lists, especially in a garbage collected environment, but that varies a lot depending on implementation details. Fifth You can handle your collision phase differently if you don't care if objects intersect for a few frames, by just letting them gardually push each other out by applying force. It looks like you are trying to guarantee zero intersect, which you are currently not doing. (An object can be moved out of the first collision and then back into it when resolving the second collision) As a last sidenote I think that simulating n-body attraction is just always going to be a performance nightmare, so in some way you don't really need to worry about this rest, since that's what will most definitely ruin your performance. (Although space partitioning can also aleviate that a bit since you can only check with objects that are close enough to matter) I probably didn't notice everything but I think that's the jist of it. 

this is actually the meat of your question (I know you didn't say gambling, but in essence you are "put down amountX for the chance to win amountY" is gambling) this falls back in a circular fashion to the previous section where if the currency is easy to obtain then players will be more likely to wager more. though at the same time players will also see it like they would putting money down on a game of High card draw or Black-Jack. The higher the anti the higher the likely-hood of better players, and the statement "to rich for my blood" comes to mind. for this reason I would advocate for a tiered wager system(tier1 costs x, tier2 cost Y, tier3 costs z... || x < y < z < ...) this will allow for your in game economy to feel more open, and also give players a sense that "if I go to a low wager match then I will see weaker opponents, and a high tier match will have strong opponents" this also gives the player the chance to try the system out by possibly entering at the lowest tier to get a feel for how the system works. then the "better" players will gravitate toward the higher tiers, though your more casual players will gravitate toward your lower tiers, and the middle tiers will only ever be used for the high tier player to recoup losses, and get back into the high tiers, or the low tier players to seek a challenge, and improve their skills. In conclusion: you can't really set hard and fast numbers for what is to much, and what is just right its the same as balancing how much damage a weapon does with respect to how much damage a shield can take, or how many points eliminating a given enemy type is worth. Though when you throw in perception it does make things interesting (low to one person can be high to another). It will come down to how easy the player perceives earning currency in your system is. if they see that after every "story event" they earn 1,000,000 currency, but for most other "events" they earn 20 currency then you can put higher prices on things, but if there are only say 10 of those "story events" in the game, and the player hasn't seen one in a while they might tighten up the purse strings a little. In short the key word is balancing. aside: If your going to have a wager system on a section of the game have a defined rule set that you state up front (winning/losing, scoring, and objectives) even separately (or mandatory the first time they enter the section, but still reachable later) otherwise a new player might feel cheated if they lose the first time, and if it is at the beginning of each match an experienced player might get bored having to sit through it every time. 

You can do any interpolation or tweening or whatever that you want there. As a sidenote, in almost all cases converting away from radians seems like a bad idea. If your question was specifically about how to figure out which way to rotate. 

XNA has a Vector3.Forward, transform that with your cameras viewmatrix and if necessary set your y component to zero and normalize. Generally if this gives you trouble you should refresh your basic understanding of linear algebra. 

Have a currentRotation and a desiredRotation you will also want some helper function to give you the shortest angle distance, so let's just call that angleDist or whatever. (You want that because sometimes going clockwise is shorter or vice versa). Then all you need is to interpolate between them somehow. 

Does it change the state of your game world? It's logic code. Does it display the state of the game world? It's rendering code. 

There is no one size fits all answer to this, as is so often the case. Generally though, if you can precompute it, do it. If your robot doesn't change all the time, so for example you build it and it stays the same the whole time, then what's the point of calculating all of its parts every frame. But if it does change all the time then obviously you can't get away with making all of it one big object. You are probably aware that there are tons of things that become computationally more expensive the more objects you have, for example collision detection. So you have an interest to keep the number of game objects low(-ish). When it comes to rendering, ideally you would want to have a VBO and IBO for your whole robot, so you can push it over to the GPU once and then just reference it forever. If instead you split your robot up into bits you will have to make a draw call for each of the bits. While the amount of drawing that your GPU ends up doing will be the same, the amount of work for your CPU to translate all of those instructions for the GPU will be much higher. So in most cases treating it as one big object would be better. However there are cases where the other treatment might work better as well. Computing everything you need to treat your robot as one object is relatively computationally intensive and memory heavy. (Compared to just keeping everything as a collection of blocks) So if you are in a garbage collected environment and want to minimize your memory footprint, if each time a block is changed you have to recalculate the big object it could cause a garbage collection every time and make your game lag for a frame. 

I am trying to design the algorithm for my level generation which is a rule driven system. I have created all the rules for the system. I have taken care to insure that all rooms make sense in a grid type setup. for example: these rooms could make this configuration The logic flow code that I have so far 

there are also general forums that are not specific to platform/engine/framework, but at some point that question may come up especially if your posting a job opening. 

though I would have to mention that if you want a fixed frame rate have some debug write displaying the frame rate to make sure that your not getting to low of a rate. (then start optimizing), and realistically test your game on more then just one system even if you have min requirements. 

Why would you do this? I see no value besides having something that you can physically see in the editor, and when it comes time to run the game you wont be doing anything with these cudes as cubes, so why have them in the first place if your just going to take away their collision, and rendering. All you have left is a transform which you could have right away by having empty gameObjects. the easiest way to do nodes in Unity is to create empty gameObjects(mainly for the position), and then give them a script for all the variables you need, and then put all those nodes onto their own layer. EDIT (In response to request for more detail in comment): 

My best guess is that you have some rounding errors. You aren't actually showing the movement code for the bullets so it's really hard to tell. Edit: Looking at the code, it should(tm) work. It definitely works fine to do things like this in the games I've written with XNA. The thing that bothers me is that your game doesn't seem to be running at all when you set FixedTimeStep to true, so something really weird must be going on somewhere. Could it be that you didn't separate Update and Draw logic properly? Edit2: The TargetElapsedTime is set to 16.666 seconds instead of milliseconds, so that's most likely causing the issues. 

To me it looks very much like your issue here is that you are mixing world and viewspace or something similiar. Now your GBuffer normals look like they might be in viewspace in that picture, but the code in your geometry pass definitely doesn't transform them from world to view space. If they are in world space then your NBT matrix is basically oriented incorrectly by exactly the rotation of your view matrix, so your kernel will end up being rotated into or out of the wall depending on where you are looking. And that would give you exactly the result you are seeing. Hope this helps. (Minor sidenote: you are only interested in offset.xy, so after projecting you can just use the two rather than offset.xyz) 

your right to a point. when I say the word grid most people think about drawing boxes, and having all of those boxes be uniform dimensions, but when we go to put things in those boxes all we really care about is a point in space (usually the center for 3D, but for 2D sprites top left) so if we take away the boxes, and instead only keep those points in space we still have a grid, we just don't have boxes. You can still use all your favorite pathfinding algorithms with points/nodes that you did with a grid, and more. Calculate the distance between them, and apply a weight to that distance (dijoksra, and A*), Allow the agent to consider multiply nodes at once (fuzzy logic), track the players movements through a set grid pattern, and then give a weight to a set of rules that correspond, and then have the agent chose a response based on the highest weight (exert systems). A grid is just a visual representation that the player may never see (unless you actually want to draw those boxes on the screen, in 2D ok, but if your in a 3D perspective that can get confusing quickly especially if the camera can rotate). 

yes, and no. yes its the same in terms of physics, and rendering, but no in terms of the engines book-keeping. every fixedUpdate (especially in non-release mode) the system takes all components that a object has, and the same for its children, and puts them to be calculated, and then if any of those are not active throws it away. so its still trying to do stuff with the inactive components its just not that much. if you multiply this enough times it can amount to maybe an extra half second per frame, but that's probably up there. 

Based on my experience.. Neither. The reason for this, is that when learning game development I find it alot better to be looking at the back end of the code, and learn from the ground up. I started back in the day with Game Maker, and while some people may disregard that, it allowed me to learn how programming languages work, and gave me a simple look at OOP. About a year ago, I started to learn C#, and soon after started to mess around with XNA. The great thing about XNA is that is managed code, and takes out most of the really hard stuff, but at the same time, you can develop games really quickly without having to learn how engines like UDK and Unity work. From what I hear Unity and UDK are mostly 3D, and personally that is not a good place to start for a new game developer. With XNA you have SpriteBatch and the Content Pipeline, which makes drawing sprites to the screen really simple. You have the Draw and Update method, which are handled by the backend of XNA to keep timing values, and the rest can be designed by you. Once you understand how DirectX works on a very simple level, you could try looking at using Unity or UDK. But, by then, I think you would find it gives you much more control to use a framework, and much more enjoyable too. 

I have done a fair amount of play-testing, and those surveys tend to ask general what do you think of the game, and then go into specific details about specific things they are probably concerned about. if your concerned about what people think of the physics in a platformer then don't ask "how would you rate the physics" ask "what did you think of how the character jumped/fell" you can use scale values, but the data needs to be usable. if you just ask about physics, or graphics it is likely that Sallies Mom doesn't know what your talking about, or what it affects, and even if your giving a scale question then put something for "didn't notice" "don't know" some times if some one doesn't notice something as odd they will just think it is normal, and wont even register it. then by asking specific questions like "what do you think about X" if you get a high density of complaints then it is something you might want to take a serious look at. though remember that art is primarily for the artist, and then for the customer. 

No. from an application standpoint think of an empty gameObject as a modifier that is modifying something, or nothing. I can create an empty gameObject, and then move it around the world/scene, and then I can rotate it, and scale it, but if it doesn't have any children nothing happens, but the changes are recorded. then if I take, and create a sphere, and make it a child of that empty gameObject then that child will take on those modifications, and have its own values stored with respect to its parent, but in essence of physical logic that empty gameObject is nothing (no size, shape, or anything), but it does have a transform, and can receive components. 

this should also clear previous touch since List is a reference type. The second thing is that there is no space partitioning so your collision check currently runs in O(n^2) as best case runtime. The third thing is that it's weird that you calculate the atan2 of the vector between the two objects to get theta and then you only use theta to get the vector back. 

I can't see anything fundamentally wrong with the shader, but here are a few things I find commonly done wrong with deferred shading that you might be doing. 1: Drawing full screen lights. The beauty of deferred shading is that you can pack your lights into geometry so that you only need to consider a part of the screen when drawing them (Like a cube with 2 times the radius as size). If instead you draw a full screen quad for every light, that will have a serious performance impact. 2: Render target depth. You are moving a lot of data around in deferred shading, so you have an interest in making the footprint of that as small as possible. If you can reduce the number or size of your render targets that can have a pretty big performance impact. 3: Rendering one light at a time rather than batching them. (Edit: You can have a static vertexbuffer and indexbuffer containing vertices for the max number of lights you want to ever render and then just patch the position and color of the lights that are active) And lastly, you can always look at the assembly of your shader and see how many cycles it will take, so that gives you an easy way to see your own performance and compare. GPU Gems has 2 or 3 great articles on deferred shading and the performance and other issues that come with it. 

you could just do a key binding (that is not normally used in your game) that modifies the game state, and then in some section of your screen print out specific information about what is going on. Keep in mind that I have not worked with the debug layer, but I have done this with output. remember that somethings are easier to see what is going on numerically (seeing that valueX is changing/not changing in this way), and other are easier to debug visually (it looks like that model is interpenetrating the wall) the biggest thing is figuring out is what information is really needed for you to know that everything is working or not. When I have done this in the past (was designing debug for keyboard) I mapped AI states/positions to one button, another button showing bounding volumes, another button outputting positions, and bounding data, and a final button that displayed every collision that was not purely Y (at one point I had things falling through the world, and had to just revers the bool check, but that a different story) 

UML is not one thing it is a collection of things some of them have value others not so much. the older style Use Cases (at least what we call use cases) that state 

I am working on a game that will be a 3D-shooter (camera trailing player), and want to impose some architecture on the game being that a is composed of where each room can hold (the player, enemies, pickups, projectiles), , walls/floor, and (more on these in a little) my first concern/iteration is to get a single room functional, and then link rooms together in a later iteration(this is so that rooms to render are dynamically chosen to accelerate render times on larger level). my direct question for this iteration is what would be an optimal data structure for holding my for the room? keeping in mind that whatever structure I use needs to be searchable, removable(single/group of items), sortable(this can be given up if needed), growable, and possibly be able to take pointers to the . this structure would probably also be used for my doors. my initial thought was to use linked list though removing items from linked lists can be a chore, and if not done right can just create a memory black-hole. I keep bouncing back, and forth on putting walls/floor into the same structure as the as it would be mostly efficient for collision detection (i think), but I know it can cause a graphics nightmare (more things being rendered means longer it takes), so maybe keeping walls separate, and create a separate list of walls to be rendered vs collisions. the next part would be linking the rooms together by doors(see picture bellow where the joint between each room is a ) where my first though was adjacency list. I understand that the has an adjacency list that it uses though I don't feel that it would work in my situation as just rooms , and / don't work within a so would it be worth while to build a custom adjacency list (might need to see an implementation as I keep getting lost on connecting adjacent things that should be connected)