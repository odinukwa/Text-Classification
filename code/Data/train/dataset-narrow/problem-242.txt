Radio waves travel at the speed of light of the medium (atmosphere walls, vacuum, etc.), and electricity travels through copper at about 2/3 of the speed of light in a vacuum. That is really peripheral to how fast data is transferred in a network. For example, you could transfer data at 100 Mbps, 1 Gbps, etc. through copper, fiber, or radio. There is a lot more involved in how fast you can transfer data, and it is a subject far too large to be discussed here. 

DTP doesn't actually use a VLAN because it is a local-link protocol that does not go beyond the endpoints of the links. The frames used by DTP are not tagged, so many people say that it uses the native VLAN, but if the native VLAN is used by other switch interfaces, the DTP frames will not be forwarded to those interfaces the way other frames in the native VLAN can be. The current Cisco best practice is to not use a native VLAN or VLAN 1. The link-local frames for things like DTP, CDP, etc. will still reach the other end of the link and work. 

If you mean switch interface aggregation (LAG, etherchannel, etc.), then you need to understand that you will get the same results in performance per flow. If you are testing a single flow, then you should get the same results. It is only in aggregate with multiple flow where you will see increased throughput. You really don't want a single flow spread across multiple connections because you will increase lost and out-of-order packet delivery. That can completely kill real-time traffic like VoIP, and it causes problems with TCP because it must reorder packets that are received out of order. Your aggregation has a hashing algorithm that determines which flow gets which link in the aggregation, but all the traffic for a single flow will use the same link. An example is that the algorithm will hash based on the source and destination MAC and IP addresses. That means all traffic with the same source and destination MAC and IP addresses will use the same link of the aggregation. 

You can't compare times between packets (like ICMP) that only get as high as layer-3 to datagrams (like HTTP) that must endure processing all the way up to layer 7. The difference is going to depend on the hosts on each end. The host processing is going to add a large, unpredictable overhead. You have no way of knowing the capabilities of the hosts, the applications that the hosts are using, and the host load. Such a comparison is not valid since it will vary greatly based on the endpoints themselves which has nothing at all to do with the network. Edit: Certainly, network latency plays a part, and a change in latency affects the total time, but what you get from a PING can't really be used in the calculation. The TCP nature of HTTP/HTTPS will vary the amount of data that can be transferred in a window. TCP, with its reliability algorithms, will multiply the latency, but it is not a constant multiple, varying during a transfer. The nature of the layers higher than layer-3 will multiply the latency in ways that you can't completely predict, but you may be able to average them over a period of time if the data transferred is identically sized every time. 

Your DHCP server can serve addresses for both LANs, but the configuration of the server is off-topic here. If you want Laptop 0 on Network B to get an address from the DHCP server on Network A, you need to put in a helper address on the router interface for Network B: 

A transparent bridge, e.g. ethernet switch, has no effect on ARP. A translating bridge, e.g. ethernet/token ring bridge, may change a MAC address between canonical and non-canonical or have some other effect, based on what it is bridging. 

Think of your networks/subnets as a binary tree. Adding a bit the the mask length simply halves the number of host addresses for the network. In the diagram below, it doesn't matter where you start on the binary tree above the host address (, , etc.), following down the binary tree will get you to the same final address: 

If you are using prefixes and networks, then the answer is no, the bits need to be contiguous. There are cases where a wildcard mask (inverse of mask) can be used, e.g. Cisco ACLs, and those can be any bit pattern. For instance, you could block traffic from all the odd numbered hosts on a network. This seems to still be taught, but I have not seen it used very often (although I have seen it) in the real world. 

NAT stands for Network Address Translation, and it translates addresses, not protocols. Some layer-4 protocols (TCP and UDP) have addresses called ports, which coincidentally use the same set of address numbers, but the addresses (ports) are per protocol; TCP port is not the same port as UDP port . NAT can translate either or both the source and destination IP addresses, and, in some NAT versions, some layer-4 protocol addressing. If NAT translates a UDP datagram source port to UDP port , that has nothing to do with TCP, and any TCP segment source port , which could be simultaneously translated to TCP port . 

Regardless of a routeâ€™s metric or administrative distance, OSPF will choose routes in the following order: 

The metrics of different routing protocols are not compatible, and you need to assign a metric when redistributing from one to the other. Use metrics which make sense for you network design so that the path chosen by your routers will be your preferred path. Remember that lower metrics are preferred over higher metrics. You can run into problems with mutual redistribution where routes get redistributed back and forth between your routing protocols. A way to avoid this problem is to use route tags. Then you can deny routes that have been redistributed from one protocol to another, and back again. Cisco has documents regarding this, and you can search for them. For example, Redistributing Routing Protocols: 

When you go to a web site that reports your public address, it only sees the ISP public address since the private addresses assigned to your router cannot be routed on the public Internet. That public address is not on your router, it is on an ISP router. All your traffic gets translated on your router between two private address blocks, and it gets translated again on the ISP router from private to public addresses. That double NAT may cause problems for you, depending on what you try to do. 

When I see a problem such as you describe, it is almost always a duplex mismatch. Look at the statistics on your switch interfaces. If you see a lot of collisions (should not exist on a full-duplex switch interface) and/or FCS, then you have a duplex mismatch. A duplex mismatch usually occurs when on side of a link is set to auto-negotiate, but the other side of the link is set to a fixed speed. When this is the case, the side set to auto-negotiate cannot negotiate. It will detect the fixed speed, and it will default to the duplex for the speed (half duplex for 10 or 100 Mbps). Cisco has a document, Troubleshooting Cisco Catalyst Switches to NIC Compatibility Issues, that describes this, that includes a table that tells you what happens at various settings. 

Edit: Based on you comment, this is for voice (POTS) cabling. There is no distance limitation or test suite for POTS cabling, which is usually Category-3 cabling. Remember that the telco uses Category-3 copper cabling to get from the CO to your site, usually several miles away. The current best practice is to install all UTP cabling in a data category. That way the cable plant can be used for both voice and data. Trying to install and maintain two separate cable plants is expensive and confusing. 

You also need to follow the ANSI/TIA/EIA Commercial Building Pathways and Spaces, along with the various laws, rules, and ordinances required by your AHJ. The least is usually the NFPA 70, the National Electric Code (NEC), but your AHJ may have more stringent requirements. Failing to do this can get you fined and have your building red-tagged for occupation until the problems are corrected. There is also the threat of criminal prosecution in the case of something like a fire where anyone is injured or killed. 

ICMP echo requests or replies could be blocked anywhere in the path, including at the endpoint itself. There are many circumstances or reasons this may be the case. 

I think your questions can be answered by looking at the RFCs. RFC 1918, Address Allocation for Private Internets defines private IP addressing. You can make up your own addressing from any of the private IP address ranges defined in Section 3: 

I'm not sure why you would need to do what you are proposing since traffic from each set of users can be routed to the server with a single IP address, regardless of what addressing range it uses. That is really the whole point of IP addressing and routing, and everyone in this large corporate network can use a single IP address to get to the server. There are a few ways to do this. For instance, many servers can use 802.1Q trunking to use multiple VLANs. You would configure the subnets on your router and the VLANs on your switch, and then trunk the VLANs to the server. 

Manually configuring an IP address on a device doesn't require the device to check for address conflicts. It is only if the device configures its own IP address (DHCP, etc.) that it should check for address conflicts. You are not going to see a gratuitous ARP if you manually configure a device since the device has no way to change its (or request a new) address if it discovers a conflict. The purpose of the RFC is so that a device, configuring its own IP address, can detect if it needs to change the IP address it got. It can do that for things like DHCP, but it has no way to do that if you manually configure the address. In other words, the device has to trust that you, the human, know what you are doing, but it needs to verify that any address it comes up with on its own is not already in use.