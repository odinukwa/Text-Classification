You may have to put a static route for 8.8.8.8 over ISP1 to make it always exit out that path. Obviously if you really use 8.8.8.8 choose another IP because otherwise you won't have reachability to it if ISP1 goes down. 

This command is supposed to be run on trunk ports towards non bridging devices, such as a server with multiple VLANs or a router. This command should not be run on trunks towards switches because the port will bypass the listening and learning phase which could potentially create a bridging loop. If you have an interface configured like this: 

You should see which mode the port is running in. You need to use ENI or NNI to support CDP on the interface. 

It seems that the 6500 generates MPLS labels for every route if BGP is run in VRF. The fact that your IPv4 and MPLS TCAM usage is almost identical seems to indicate this as well. Can you try this command: 

R1 is sending full updates towards R2. This is the final update before shutting down Lo0 which has the IP 1.1.1.1. 

Then you would telnet to ports 2001-2004 to connect to the switches. If you want to support this remotely then you could port forward on the ATT router for these ports or simply forward SSH only to your server and then connect to switches from there. If you want to be more secure there's always the possibility of doing some sort of VPN to the server as well. There's also the option of getting a 2500 and using it as an access server. 

This is from the configuration guide for IOS 15.2T. The feature is called RA guard. Basically you create a policy and define if the port that this will applied to leads to a host or to a router. Then you can be more specific and match on hop limit, managed-config-flag and match on an ACL with a range where the trusted sources should come from. You can also make the port trusted and not do any further checks. In some ways this is very similar to DHCP snooping. The basic steps are: 

That makes it easy to run inter vendor labs and you can connect them through the VM network which makes it simple to setup. I have a lab like this now and it's hosted by a friend so a VPN in to a box he setup (virtual) which is my GW. Then I can configure vSphere and anything I like and run it on the server. If you have a powerful laptop which 8GB RAM or more you can run a lot of stuff directly on your laptop. Most of these things are RAM heavy but not that heavy for the CPU. 

But if it's received over a trunk it shouldn't be routed in the first place and even if it was the jumbo MTU should still apply. 

Then we configure so that hosts matching will get NATed to . It is important to configure add-route here or to add a static route because when doing NAT, NAT takes place before routing in the order of operations. That means that R3 must have a route for 10.1.1.21. R3 now has the following NAT table: 

Higher end devices supports something called microflow policing but it's not available on the ISR G2 as far as I know. 

Then you need to have a L3 interface between the switches. Are you running L2 links today with SVI or do you have "real" L3 interaces? If you are using SVI it would be: 

Most often Cisco devices can only receive PAUSE frames. They can't send them. If you are running storage over your network I can understand why you would be looking at implementing it and some server/storage vendors even recommend you to do so. Note however that PAUSE frames is a very blunt tool as it can pause all traffic meaning you can't differentiate between packets. That means your high priority packets will be treated the same as low priority packets. If you run a separate storage network then it's no issue and you can safely enable it. There is a standard 802.1Qbb that enables to send PAUSE frames per class so not all the traffic gets paused. This article describes how 802.3x works and the implications of running it like adding delay to RTT for TCP packets and such. 

You can have multiple DHCP servers serving a VLAN. The client will use OFFER that comes in first if receiving multiple. ISC has support for DHCP redundancy while Microsoft was a bit lacking in this department. They have recommended split scopes in the past but it's not really a good solution. You can have multiple subnets per VLAN. On a Cisco device you would use: 

Source: For 10-Gigabit Ethernet there is a BER recommendation of 10^-13 to acheive the same number of errors per day as for Gigabit Ethernet. Source: Some other sources say 10^-12 for 10GE. If you set it to both 10^-12 for both GE and 10GE that would probably be a good number. 

Trunk port is Cisco terminology and Cisco is one of the few vendors implementing Per VLAN Spanning Tree + (PVST+) which is the equivalent to 802.1D but with one spanning tree instance per VLAN. There is also Rapid Per VLAN Spanning Tree + (RPVST+) which is the equivalent of 802.1w but per VLAN. The plus means that STP is running over 802.1Q trunks as opposed to ISL. On an access port, only one VLAN is allowed, hence only one instance of spanning tree will be running on the port and the Bridge Protocol Data Units (BPDUs) will be sent untagged. Normally access ports will connect to end devices and the port would be configured as an edge port to bypass listening and learning state and to not generate any Topology Change Notification (TCN) on link up/down. You could run an access port between switches as well but that is generally a waste because you will want to have several VLANs between the switches. So far everything is the same but Cisco runs PVST+/RPVST+ and other vendors run STP/RSTP. On a trunk port (Cisco terminology) several VLANs will generally be allowed to traverse the trunk. On Cisco devices, every VLAN will in its own instance and different VLANs can be forwarding on blocking on the same physical port. On other vendors there will only be one instance running, even though several VLANs are traversing the trunk. This means that all VLANs most follow the same topology. It's not possible to any form of load sharing/traffic engineering. Cisco devices will allow a different number of instances depending on what platform it is. Some will allow 32 instances, some 64 and some 128 and so on. There is also the option of running Multiple Spanning Treee (MST) which does not do per VLAN Spanning Tree. Instead it groups VLANs together into instances which is more effective. The advantage of PVST+/RPVST+ is that you can send VLANs on different paths and do traffic engineering. Also a change in one VLAN will not affect the others. The drawback is that it's less scalable if you have a lot of VLANs. The reverse is true for STP/RSTP, it scales better but it does not offer load sharing and changes sourcing from one VLAN can affect the others. 

I'm not sure what limitation you are referring to? It seems it only supports mode on but that seems to be consistent for 5508 as well. 

Then the local device generates an ICMP Echo (Type 8, code 0) which is sent outbound. The device then waits to receive an ICMP Echo Reply (Type 0, code 0). If the packets TTL expires before reaching its destination, then an ICMP Time Exceeded (Type 11, code 0) packet is sent to the originator of the ICMP Echo. When using Traceroute and the ICMP packet reaches the final destination, normally a ICMP Port Unreachable (Type 3, code 3) will be sent back towards the source. If a device in the forwarding path does not know how to route towards the destination it will send an ICMP Net Unreachable (Type 3, code 0). This is true no matter what kind of packet was sent from the beginning, ICMP or not. Note that many administrators filter ICMP (often on lacking knowledge) so that ICMP packets may not be received back. 

Why was only downstream affected and not upstream? Are these real collisions? Since cable has separate transmit and receive pairs. 

Then you would have to do the same for traffic going from the inside to the outside of course. Regarding your last question it only really makes sense to either translate the source or the destination of the packet. What you are suggesting sounds like some kind of policy routing. You can use inside and outside NAT to do everything you need. 

For some reason there is a bridging loop, STP is disabled or someone applied a filter in the wrong place or such. PC A wants to communicate with PC B. It first ARPs for the MAC of PC B, the destination is a broadcast with MAC ffff.ffff.ffff. So the frame goes to both SW1 and SW3. The SRC MAC is PC A. SW1 then floods the frame towards SW3 and SW3 will flood the frame coming from SW2 to SW1. SW1 and SW3 learned the MAC of PC A when the first frame came in. When the second one comes in from the opposite direction it has to relearn it. Because these events occur so fast and repeatedly you will see log messages complaining about MAC flapping. Something like "MAC FLAP 0000.0000.0001 is flapping between Gi0/24 and Gi0/23". This is a good sign that you have a loop. What you could do then is to try to trace this MAC. Try looking in the ARP cache of a device in the same subnet and see what IP this device has. So with the MAC you could try to trace it with sh mac-address-table or with the IP maybe you have a list with all IPs and where they are connected. If the host gets a IP address from a DHCP server you could also try there to find where the host is coming from. If you have option 82 enabled that would be a great help. Other signs are that the CLI will be very sluggish. CPU load will be very high. Switches do almost everything in ASICs so if a switch has a CPU load over 50% it's probably not good. You should implement SNMP monitoring and watch for high CPU load. Also look for the MAC flap messages. If the switches have a loop the LEDs will probably be blinking like crazy. Things you could do to protect against loops: 

If you are moving these IP addresses from the global table then there will be a disruption because when you move it to a VRF all your routing state will be cleared because at that point the VRF is empty. Then you need to configure your IGP: 

Weighted Fair Queueing (WFQ) is as the name implies a queueing algorithm. Queueing is used when there is congestion on an interface. This is usually detected through that the Transmit Ring (TX-Ring) is full. This means that the interface is busy sending packets. Queuing does not take place unless there is congestion on the interface. In some cases the size of the TX-ring can be manipulated. A small TX-ring gives the software queue more power as to which packets get sent out first but it's not very effective. A too large TX-ring would make the software queue almost useless and lead to higher latency and jitter for important packets. The default queueing algorithm is usually First In First Out (FIFO). This means that packets are delivered in exactly the order as they arrive on the input of the interface. This is not usually desirable because some packets should be prioritized. It is quite common that a customer buys a service from an Internet Service Provider (ISP) at subrate. That is, the customer buys a 50 Mbit/s service but the physical interface is running at 100 Mbit/s. In this case there will be no congestion but the ISP will be limiting the amount of traffic from the customer. To introduce artificial congestion in these cases a shaper can be applied. So now that there is congestion a queueing algorithm can be applied. Note that queueing algorithms don't provide any extra bandwidth, they just let us decide which packets are more important to us. WFQ is an algorithm that takes several parameters and makes a decision based on that. The algorithm is quite complex and uses weight (IP Precedence), packet size and scheduling time as parameters. There is a very detailed explanation from INE here. WFQ is a good choice if one does not want to fiddle too much with queueing as it provides adequate bandwidth to small size flows like SSH, Telnet, voice and that means that a file transfer won't steal all the bandwidth. Weighted Random Early Detection (WRED) is a congestion avoidance mechanism. WRED measures the size of the queues depending on the Precedence value and starts dropping packets when the queue is between the minimum threshold and the maximum threshold. Configuration will decide that 1 in every N packets are dropped. WRED helps to prevent TCP synchronization and TCP starvation. When TCP loses packets it will go into slow start and if all TCP sessions lose packets at the same time they could become synchronized which provides a graph like this: 

Yes, it is possible. You are doing something wrong, most likely tagging frames on the router but the trunk has VLAN 1 as native. 

NAT works at layer 3 because it is modifying the IP header. If you use PAT you could argue that it is working at layer 4 as well because it MIGHT change the source port of the packet in case it is not unique. 

I like to keep the subinterface IDs matching the VLAN number although it is not required. Use a configuration like: 

If you have PCs at both ends then you could run xjperf, Qcheck from Ixia or other tools. You might get different results depending on if you use UDP or TCP and the number of sessions. For a distance over 100 miles you are looking at a minimum RTT of 1.6 ms at the speed of light in fibre/copper. So your RTT should be very low, maybe only a couple of ms. Say that you have a RTT of 6 ms. With default window size options on Windows you might only get around 85 Mbps of throughput. You would need a window size of at least 768 kbyte to send a gig worth of traffic. You can use Throughput Calculator TCP to do your own calculations. Ixia has more highend tools but they cost money which the above tools do not. 

Note that R4 has configured with an IP and turned off to emulate a host. Debugging of ICMP on R1 is enabled and debugging of ip nat on R3 is also enabled. 

If the unmanaged switches do not support RSTP, they should forward the BPDUs as any other L2 multicast and simply flood them out the VLAN. If they do, things will work fine since the managed switches will receive the BPDUs. The unmanagad switches would basically be transparent to the managed switches from a STP perspective. Worst case the switches would consume the BPDUs but not act on them and create a bridging loop. I've never seen this myself but heard of such stories from others. 

And reports back all interfaces running in half duplex. This would only work for switches. For routers you would need something like: 

This policy is more granular for the realtime applications like video, streaming and signaling for these protocols. Finally this is the 12 class model. 

I wouldn't say that it is best practice to create a SVI. However I don't think there will be much of an issue if you do create it. For example Catalyst 3750 supports 1000 SVIs which you will not be likely to hit. 

Not sure this is a question that can get a really good answer but it's important to know the preference order of OSPF: 

OSPF is a link state protocol that uses multicast. It sends Link State Advertisements (LSAs) that are flooded. Every router builds a tree by running SPF where the router itself is the root of the tree. In OSPF we have transit networks and stub networks. Transit networks are networks that are used for transit to reach networks while stub networks are the endpoints or leaves as you described it. If we are in the same area then the router LSA (type-1) is examined to find the destination. Here is a router-LSA to reach the network of R1 which has a RID of 1.1.1.1. 

What this does is to translate from 130.130.130.130 to 10.0.0.1, 10.0.0.2 and 10.0.0.3 in a rotary fashion. So for every incoming request to the inside global IP of 130.130.130.130 it will be translated to a different inside local address in a round robin fashion. IP nat outside source static translates between outside global and outside local IP. One common use case would be if you have overlapping subnets. Like if you are doing a merger and both companies use the same IP subnets. So say that both company A and company B are using 10.0.0.0/24 for something. So you are working for company A and you want to translate all 10.0.0.0/24 on the outside to 192.168.0.0/24. 

So the redundant supervisor is only partially initialized. This means there will be a disruption when the supervisor fails over. SSO on the other hand is fully initialized. 

EIGRP is a distance vector routing protocol. It has some advanced features but at the end of the day it's still distance vector. While you may have multiple routes in the RIB only the best one gets advertised to your neighbors. EIGRP only advertises routes that are in the RIB as EIGRP. When you add the static route, it has better AD than the EIGRP route so EIGRP stops advertising the route. You could of course redistribute the static into EIGRP if you want to.