I have a Windows 2003 print server that I need to retire, but I need to migrate the print queues off of it first onto another Win2k3 server. I have found some information on migrating, but it all seems to have to do with duplicating the print queue settings. I want to figure out the most transparent way to deploy the new print queues to my clients. Right now, the clients all have their print queues configured manually. I don't really care too much about removing the old queues, though I wouldn't say no to doing that. I just want to automatically add the new queues. It seemed to me that a GPO would be the way to go, but I've never set one up before. (I'm a Unix admin forced into dealing with Windows.) Every piece of documentation I've seen about print queue GPOs seems to reference things that simply don't exist. Print Management Step-by-Step Guide refers to a "Print Management" option that might be in Adminstrative Tools or might be an MMC plugin. It exists in neither place on my print server. The print server role was activated ages ago, and there's no "Update this role" option as referenced in that document. I tried activating it on a different server, and it didn't appear there, either. (That document also says: "Installing Print Management is accomplished by adding or updating the print server role. Note that the computer on which Print Management is installed does not need to be a print server." Of course, you can't add the print server role without sharing a locally-attached printer, so I'm not sure how that statement isn't oxymoronic.) I also found Microsoft referencing a program called PushPrinterConnections.exe, but I can't find anywhere that that program exists. Basically, after two or three total failures in Microsoft documentation, I've given up and am asking in hopes that someone else actually knows how to do it. 

This would seem to point fingers at LDAP connections being blocked somewhere. (And 0x51 == 81, which was the error from from yesterday's update.) I could swear I tested this using weeks ago, but now I'm thinking that I may have assumed that its clearing of the screen was telling me that it was waiting and not that it had connected. I'm tracking down LDAP connectivity problems now. This update may become an answer. 

Outlook 2007 under Windows XP connecting to Exchange 2003 SP2: when started, it flips back and forth between "Connecting to Exchange Server" and "Disconnected" three or four times, then gives up and stays disconnected. I tried deleting the ost file (which was nearly 2GB), turning Cached mode on and off, recreating the account inside the Mail control panel, changing the account to use HTTP, and probably some other things. None of it seemed to make any difference, until … After fiddling with it for a while, I got this absurd error message dialog at startup, and it exits after I click OK: 

the kr/s numbers were wildly inconsistent, but those are representative numbers. while ing from (to /dev/null): 

No, you can't run on a different port than port 80 without specifying the port in the URL. But why can't you just set your web server to provide the first site when the Host: header matches "*.example.com" and the second site when it matches "*.domain2.com"? (Someone might even be able to tell you how to do that if you tell us what web server you're using.) 

I have a NetBackup 6.0MP7 installation running on Windows Server 2003. It functions as the only Master Server and Media Server. I swap a full set of tapes in and out every week, but leave a set of tapes with their Volume Pool set to "Scratch" in all the time. The weekly tape sets then get rotated back in after a period of time. Largely, this works fine. I seldom actually need the scratch tapes, but every once in a while, a backup will run over what I have dedicated to the task. However, one week's set of tapes consistently gets declined in favor of the scratch pool. The backup policies are the same for every week, they all have "Policy Volume Pool" set to "NetBackup", and all of the tapes for every week (beside the scratch tapes) have had their pools assigned as "NetBackup", definitely including the week that always gets ignored. That said, it doesn't ignore all of the NetBackup pool tapes for that week. It does usually write to two or three of them, but it writes to like 20 of the scratch tapes. (I haven't thought to look to see if it's always the same two or three tapes.) And this problem never seems to occur for any other week. It doesn't load the tapes and then reject them; it never seems to try to use them at all. They are not flagged as frozen. They are all active and unassigned when I swap them in. The tapes are in a Quantum PX510 tape library. The NetBackup server is attached to the library/robot via fibrechannel going through an HP-branded Brocade switch. I'm not an expert on NetBackup at all. I don't really even know where to look. Any advice on logs to look at or logging to enable or really anything at all would be appreciated. I'll keep an eye on the question and update it if anyone needs any more info to help. 

The poorly-named Console is a replacement terminal for cmd.exe (or powershell.exe or, really, any other cli shell). It's still running cmd.exe on the inside, so there are still problems with things like its confusing command history, but window resizing, selection, etc. all work much better. It also supports tabs, support for saving multiple configurations (so you can easily start different shells and different options, like startup directory and appearance settings), PageUp does something useful (I reconfigured mine to Shift-PgUp), etc. 

Packets from those computers will be tagged with their own MAC address regardless of an intervening switch. Both of your devices are GigE, so there should be no need for a crossover cable. (Auto-MDIX is built into the GigE spec.) The only thing I can think of is that maybe your computers are sending jumbo packets and the router doesn't understand them? (I'm not even 100% sure that makes sense.) 

Sometime over the Thanksgiving holiday, my Netbackup installation decided that it no longer liked the tapes in my library. It had worked fine a week ago with no changes that I can think of, besides moving the new week's set of tapes into the NetBackup pool. (I had previously moved them to an unused pool so that they wouldn't be written to until Friday.) Now when I try to perform a backup, it immediately errors out with error code 96: "EMM status: No media is available unable to allocate new media for backup, storage unit has none available". If I try to label a tape, I immediately get error 98: "error requesting media (tpreq)". However, catalog backups work fine. (That is a different pool, though.) The tapes show up in the output of with the correct pool and other information. I have tried moving tapes into the Scratch pool and seeing if it would pull them into the NetBackup pool. I have verified that my policies are referencing the NetBackup pool. I have tried setting policies to a different pool and then setting them back. I've tried moving both tapes and a policy to a different pool. I've rebooted the Netbackup server and the tape library. None of it makes any difference. I don't honestly know where to look next. If someone can suggest logs that I can look at or enable, I'd appreciate it. It's Netbackup 6.0MP7 under Windows Server 2003. 

I don't know that it has this feature, but it's possible that you can get it from NUT. Their HCL says that HP provided them protocol docs for the R1500 G2, so there is some reasonable expectation that it might be there. It also apparently uses the same protocol as Eaton UPSes, which might imply that they are rebranded Eatons, and Eaton sponsors the project to some extent. 

The MFI controller completely failed yesterday. I'm guessing this slowness was just an early symptom of that impending hardware failure. 

I am installing a Sun Grid Engine environment and I have a scheduler limit that I can't quite figure out how to implement. My users will create array jobs that have hundreds of sub-tasks. I would like to be able to limit those jobs to only running a set number of tasks at the same time, independent of other jobs. Like I might have one array job that I want to run 20 tasks at a time, and another I want to run 50 tasks at a time, and yet another that I'm fine running without limit. It seems like this ought to be doable, but I can't figure it out. There's a configuration option, but that appears to apply globally to all array jobs. I can't see any way to use consumable resources, as I'd need a "complex attribute" that is per-job, and that feature doesn't seem to exist. It didn't look like resource quotas would work, but now I'm not so sure of that. It says "A resource quota set defines a maximum resource quota for a particular job request", but it's unclear if an array job's sub-tasks' resource requests will be aggregated for the purposes of the resource quota. I'm going to play with this, but hopefully someone already knows outright. 

The shell you're running on the FreeBSD machine probably doesn't support that control sequence. Without knowing what shell you're running on either end, though, it's hard to say for sure. 

It sounds to me like IIS is expecting a "Host:" header from the client that it's not getting. Is the URL you're using a hostname or just the IP address? 

That said, I'm not sure that the "GB" suffix does what you're intending. I think it just does raw math on the root number it follows, not figure out how to get that many gigabytes from the block size you've given. I would do something like this: 

I have a set of eight HP ProCurve 2910al-48G Ethernet switches at my datacenter that are set up in a star topology with no physical loops. I want to partially mesh the switches for redundancy and manage the loops with a spanning-tree protocol. However, our connection to the datacenter is provided by two uplinks, each to a Cisco 3750. The datacenter's switches are handling the redundant connection using PVST spanning-tree, which is a Cisco-proprietary spanning-tree implementation that my HP switches do not support. It appears that my switches are not participating in the datacenter's spanning-tree domain, but are blindly passing the BPDUs between the two switchports on my side, which enables the datacenter's switches to recognize the loop and put one of the uplinks into the Blocking state. This is somewhat supposition, but I can confirm that, while my switches say that both of the uplink ports are forwarding, only one is passing any real quantity of data. (I am assuming that I cannot get the datacenter to move away from PVST. I don't know that I'd want them to make that significant of a change anyway.) The datacenter has also sent me this output from their switches (which I have expurgated of any identifiable info): 

As I recall, Firefox on MacOS won't open .url files, right? And Web Location Converter is an application that should convert .url files to .webloc files, which I think Firefox will open. It says that it isn't 100% under Snow Leopard, but the only thing broken is the other direction, so you should be okay. Here's an AppleScript droplet that would work to simply open the files if Firefox hadn't broken its AppleScript support at some point. Either way, one you get them opened in Firefox, it should be trivial to then bookmark the lot of them. Alternately, .url files are pretty simplistic. You could throw some text processing at them to convert them into a simple html file pretty readily: 

Note the capital X. This sets the executable bit on directories and files that already have any of the execute bit already set. Note that you can only use capital X with '+', not '=' or '-'. 

I've put some throttling in place, and it's not likely to affect performance of the web site, but I'd really like to find some sort of root cause. If I can't find anything out here, I am going to start directly asking the users that I can identify, but I'd rather deal with it internally if at all possible. The web servers I'm gathering these logs from are behind F5 load balancers. The logs are from Apache, and the logs do show different timestamps, so it's not a logging error. Plus, we can see some side effects of the multiple requests in database server logs and so forth. It's possible that users are scraping data, but it seems unlikely. I'm hoping to find a technical explanation first. If I can't find one, I'll move to looking for a social explanation. 

First, your conclusion that there are two processes is wrong. There's one and one in your output. Next, you say that the quoted file is in your root crontab. What you quoted says that it's in . So, is that the contents of or ? Those are two distinct things. If it's both, well, then you're telling it to run those things in one place and then in another place, so twice. You probably want to remove it all from root's crontab. 

I switched to TrendMicro OfficeScan recently, and I'm reasonably pleased with it. (Though I also switched from Symantec, so I would have been pleased with a kick in the teeth.) I do not believe that they charge for virus definition updates (you can download their pattern file for free, so I assume it's free for the software, too), it's client-server based, and they do have clients for 2k through Vista and '08, (Windows 7 isn't listed, but I would be surprised if it wasn't supported). I believe that it might also have the possibility of uninstalling SAV during installation, possibly even during remote installation. (I couldn't do it because the stupid Symantec firewall had been enabled and I had to touch each machine anyway.) 

However, this assumes that your terminal is VT100-compliant, which, while a good bet, is not a certainty.‡ The more correct way to do it is to rely on your terminfo settings and run this command: 

netmask supports automatically figuring out minimal sets of subnets for a particular IP range, which I find to be handy. For example: 

You probably want to consider using , as KPWINC says, but to answer your question directly, you want to use 's "skip" option. If your first command, as stated, is: 

I have an ISO image on my VMware ESX 3.5 host that I would like to mount in a guest OS. I cannot figure out how to do this. I can easily mount an ISO image with the VMware Infrastructure Client's "Connect CD/DVD" button (that also allows you to mount the local workstation's CD drives), but that button only allows you to reference files from the point of view of the client workstation, which means I'd be accessing that image over the network, which I don't want to do, and I want it to be independent of VIC because it constantly crashes. Update: I see now that if I edit the guest OS's settings where the CD drive itself is defined, I can mount a datastore-located ISO from there. Isn't there some way I can log into the host OS and mount/present the image to a guest OS without having to interact with a GUI? Update 2: I must be an idiot today. I've tried the vmware-cmd utility and I can't get it to work. 

I think the most important thing is to leave a note. From your story, it sounds like the user deduced that her computer had been messed with by IT, rather than having been informed. Chances are that a note that said something like "I'm sorry, but we were forced to log you off of your computer in order to perform some required maintenance. Please contact us if we created any problems. Signed, IT" would have at least ameliorated the situation. And don't email it; leave it on a PostIt stuck in the middle of the monitor. You need to inform them that something has changed before they notice that something has changed. Of course, the best thing is to not need console access at all. This question is about when you do need access, but you should make sure your admins have as many tools and as much knowledge as possible about remote administration to avoid needing console access. That said, I have a technical note. Administrators not being able to dismiss a locked screen without logging the user out is one of the worst GUI decisions that Microsoft made with Windows. When you do need console access to click one button, you always have to weigh the unknown impact of shutting down all of the user's running programs against what you need to accomplish. Fortunately, someone created a way to get around this, called RemoteUnlock. The source code and binary is long missing from the site, so I uploaded an archive I had to Launchpad: RemoteUnlock on Launchpad.