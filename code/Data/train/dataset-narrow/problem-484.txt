and using command. In both cases it takes more then 19 hours. Is there a way to optimize the clustered index rebuild operation? 

I have never used with precision. So, I went back to the source of this format - Alter Non-Temporal Table to be System-Versioned Temporal Table. The only difference with the script I have been using was the date time function. I used as I do not need to be so precised with ( for example) and in the example it is . So, I have changed it. I have create a script which is dropping a database if exists, restoring a database from backup and then executing my code in a loop (as I said I get the error sometimes and it was very hard to reproduce it). I have run a the script a lot of times and I was getting different number of fails (sometimes 70%, sometimes 50%, sometimes below): 

Is there a way to search by text in packages using statement (or other language)? I want to check if certain table is used in any package as I am going to drop it - if the table is used I need to edit the package. Could you advice? 

I have many large tables that are populating with data constantly. The information is rarely or never read and I want to move them out of the database. So, the idea is to: 

I am going to test the both variants of course but before doing that I am wondering is there another option or any issues in the above ones? 

Basically, the index is created for 20 minutes, so I need a way to guarantee user experience is not blocked. The alternative is to have separate window for maintenance in which the database to be in single user mode. 

I am testing feature and once the operation of encrypting column is done I have a file with hundreds objects failed to be refresh by the procedure. Should I investigate these errors and perform the refreshing by myself? What are the risks of not doing this? 

@a_vlad has your answer... create a new table with the same structure without keys and autoincrement (it is faster to manage indexes in batch than one row at a time). Then insert into the new table select * from the old. After population, any indexes (including the pk) can be applied and add autoincrementation advanced to the next value you want to generate. 

It seems the most important thing is matching time out with the time in. The query below shows one way this can be accomplished. The approach below attributes time worked to when the individual "clocked" in... there is no attempt to attribute the time to the day in which it occurred (there are other questions on this site that address that need). 

Unfortunately, MySQL's regular expression function return true, false or null depending if the expression exists or not. The trick in effecting the desired behavior is to determine which substring begins with the character you care about, has the correct length, and is followed by a number. A series of substring_index functions are used to extract the string... 

The following is an untested attempt at distilling the problem into its basic components then unions the results together. The last query (with the correlated subquery) can be turned into a join if the introduction of orders does not cause a Cartesian product. I can not test with what is provided to see if this is a valid assumption. 

You can either recreate your table or use "optimize table" command to rebuild your table. Highly recommend making a backup just in case. $URL$ $URL$ 

What is the fastest way to determine if an IP is contained within a CIDR block? At the moment, whenever I store a CIDR address I also create two columns for starting and ending ip addresses. The starting and ending ip addresses are indexed. If I want to see which network contains an address then I look which seems less than desirable. It occurs to me I can store the right shifted number and could match similarly shifted IP address (660510 in the case of @cidr)... 

I want to either compressed them or move them to cheaper(slow) storage. Because of the tables structure (there are columns) I was not able to apply or achieved good results using row, page, column store or column store archive compressions. So, I have decided to move them to cheaper storage. I guess I have to options here, but let me know if I am wrong about something: 

I am testing how one of our stored procedure is working on vs editions. I have created two virtual machines and install a () and restore a database on each instance. Then I have generated some test data (large volume but the same on each database) and started testing if there is an execution time difference. I have been told that there should be better performance on the edition when a large volume of data is used because there is NUMA Aware Large Page Memory and Buffer Array Allocation. So far, there is no such difference and the execution time is almost the same (a or second difference). I cannot say I understand completely what is and how it works, but I guess the hardware is on as the following query returns me and : 

I want to see the size of a spacial index. I am usually using one of the following code blocks to get the indexes sizes of a given table, but none of them is working for a spatial index. 

I have found the following queries to detect the CPU usage by database, but they are showing different results: 

I am wondering if I am using the hint, the table will be blocked for inserts. In the documentation is said that: 

The above query tells that the issue is with one of my database (almost 96%). And the query below tells that the issue is with the master and the distribution databases (about 90%): 

Try rewriting the query in different ways to see how the execution plan and times change. Changing the order in which tables are accessed, using set operators, indexing, etc... can make a huge difference. The two approaches suggested below are using the MINUS set operator and using NOT EXISTS instead of NOT IN. In both cases, the queries are driven by the SHU_STUD_TERM_SUM_DIV table. This will reduce the number of rows joined to NAME_MASTER. The MINUS set operator works by filtering the results of the first query with he results of the second. This allows the MySQL tables to be joined directly. The NOT EXISTS will behave like the NOT IN (each row will query the MySQL tables) but does have the potential of comparing a smaller set of values (only those that directly match NM.ID_NUM). Using MINUS: 

In order to benefit from this in an indexed manner, I would need to know the subnet mask (the number of bits to shift). Otherwise, I'll either be systematically comparing bit shifts (i.e., blindly shift for each possible netmask (from 0 to 24 bits)). I have other sources to optimize, but optimizing the IP2Locationâ„¢ LITE IP-ASN Database found at $URL$ would be a proof of concept. The table... 

This is an ugly solution that may introduce other issues. It is offered as a means to eliminate the lock you are experiencing. Auto_increment is preferable to managing numbers in this manner. The number could be managed in its own table incremented as needed. This table could be locked at no detriment to the main table. When write locked, other sessions are prevented from using the table, the locking session can then increment the number (and store it in a variable - something meaningful like @next_position) then releasing the lock immediately after the update. The number is then used in your main query - no join, simply "LQ.initialPosition = @next_position". You may still have contention on the position number table - but these locks shouldn't be held too long - only during the incrementation to ensure only one process increments the number at a time. The locking scheme could be eliminated, but this would require knowing the current number first which would then be tested in the update's where clause to eliminate race conditions with other sessions. A loop will be necessary to try again if the update doesn't work (another session made the update first). This complicates the use of the table but reduces the potential for trouble.