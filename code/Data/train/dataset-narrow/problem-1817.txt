The technology you're looking for is called NAT64. Note that this will generally run on a router upstream of your IPv4-only service, rather than on the server itself. What to use to implement NAT64, and where in your network to put it, is going to depend on your existing network architecture and the services that need to be accessed using it. Speaking of those services, if at all possible, they should be made IPv6-capable, or replaced. 

You replaced the wrong EPEL repo (for CentOS 7) with the correct repo (for CentOS 6) but the system still is trying to download EPEL packages for 7. In this case yum still has cached metadata from the EPEL repo from the last run with the wrong repo. To resolve the problem, clear the cached metadata. 

When testing via IPv4, I can reach your site and get the correct certificate. On IPv6, I reach a completely different site whose SSL certificate claims to be corvuise.me and which serves the Forbidden error you noted. To resolve the problem, correct your DNS AAAA record so that it has the correct IPv6 address of your server (or remove it, if your server doesn't yet have IPv6). 

To resolve the problem, check your shell startup scripts (e.g. , ) and the system shell startup scripts (e.g. those in the directory) to see where the environment variable is being set, and make the desired changes. 

You have an invalid repository named which is preventing yum from working. Disable or remove the repository (most likely from directory) and then try again. 

In general you need to set up a VPN connection between Windows Azure and your company network. Microsoft has extensive documentation on how to set this up as well as a VPN compatibility list which you can consult. After setting up the VPN, you can also (optionally) run a replica domain controller in Azure, which is especially useful if you plan to run a lot of VMs. Once your VPN is set up, you can just join the VM to your domain. 

Wow, a tough one. This seems to indicate that 0x31120303 is a bus reset due to one of your devices being under heavy load. It also says you don't need to worry about it. (Haha, yeah right.) This indicates that these log messages are happening because one of your devices is taking too long to respond to commands. This says the same thing, and also indicates it occurs under heavy load. While this isn't a complete answer, it hopefully will point you in a useful direction. 

Don't install the packages manually. You had to explicitly ignore a bunch of warnings telling you to not do what you just did or things would break, and that's why it isn't working. To fix the problem, follow the instructions to add dotdeb.org to your apt sources, and then use to install the desired packages. 

You can't really do this easily, and it's unlikely that you really want to. If you could do this, it would require a query to your web application for every single incoming request, in addition to serving the request itself, thus approximately doubling the load on your server. This could probably be done with some clever embedded Lua code, but I think you probably don't want to overload your server. Better to just redirect everything and then let the destination (your new forum) serve a 404 if necessary. This doesn't really have any SEO impact, because the original links were 404s already. But it provides a better user experience, since incoming traffic to dead links will at least see the new forum rather than a plain white nginx 404 page. 

VMware has released a patch which fixes the issue. After updating ESX 4, you must update VMware Tools in the virtual machine as well. 

At the moment, I'm not aware of any method for manually causing the system to switch to a new temporary address. However, you can tune the time period in which a temporary address is used and cause the system to create them more frequently. From the kernel documentation: 

You have configured Postfix on your web server to believe that it handles all incoming mail for your domain, by setting . With this set, Postfix will always attempt to deliver mail for the named domain locally. This is apparently not what you want. Instead, you should simply remove this setting, which will cause Postfix to use the system hostname instead (which should not be set to the naked domain name) and thus deliver mail for the domain according to its MX records. 

The only obvious problem I see in your configuration is . This is unlikely to provide better performance than . Beyond that, I also don't recommend compiling any of these components (kernel, libvirt, QEMU) yourself unless you already have a deep understanding of them. Better to use a well-tested and known working package from a Linux distribution which has optimized it for performance and stability. RHEL/CentOS and Fedora work fine. I can't vouch for any other distribution. 

Your processes are using up more RAM than you physically have available, thus something has to get swapped. (It's also interesting that in the screenshot showing this, you cut off the top, and that you restarted Apache before taking the second screenshot. What are you hiding?) You need to reduce the system's memory usage dramatically, most likely by reducing the number of simultaneous processes, or get more RAM. That said, the host should be rate limiting this sort of thing already, which is not too difficult; perhaps they just don't know how? When you decide to get more RAM (you will), get a new host as well. 

Don't set default gateways for interfaces which don't connect to the Internet. Remove the default gateways that are defined for those interfaces. That is, delete the line from the and files. You do not need to worry about the route metric at all. 

You specifically asked for it to be forwarded to a URL containing the IP address. If that's not what you want, undo it. 

You will need to set up ClassicLink to allow your classic EC2 instance to communicate with your new instance in the VPC. This has two steps: 

I suspect that your problem is that you've set . By default, the MySQL/MariaDB user database contains only entries that allow access from . But if you skip name resolution, then MySQL doesn't translate your connection from to , and thus can't match your connection to any host that's allowed to connect. Remove and try again. If you really want to keep this option, you'll need to create MySQL users who can connect from (and if you still use IPv4) while is disabled, and then re-enable it. 

Not long ago I went looking for Icinga RPM packages, and could not find a repository (that looked reputable) containing them, so I went to build them myself. Fortunately and contain their own spec files which you can use as a starting point: 

As you said, your siteurl and home in your WP options are wrong. You just need to fix them. Since you put CloudFlare in front of your site and enabled the HTTPS option, your URL actually begins with https:. But the WordPress URL has http:. Change them to https:. 

You're not seeing the web browser's IP address from because the connections are coming from CloudFlare. This is how CloudFlare works. To see the IP addresses you need to look at your nginx logs. 

Since CentOS 6.6, SELinux policies that applied to Apache are now also applied to nginx and php-fpm in the same way. Thus you need to use the right SELinux boolean to allow the web server to send mail. 

Deleting any file in which referenced VZ repositories. Getting a clean copy of the latest RPM and installing that over the existing one: 

Fix the reverse DNS entry (PTR record) and possibly the forward entry (A and AAAA records) for the host in question. 

The usual solution is to stick the destination site in a frame. But keep in mind that anyone with half a clue can figure out what the site actually is. 

The latest release of NetworkManager (0.9.4) is supposed to have added support for VLANs. Whether it's yet in your distribution of choice is another question, though. 

Or you can use a virtual PC console instead of a virtual serial port, but you may need to reconfigure the virtual machine to do that. 

I'm not sure you read Apache's docs on mod_autoindex closely enough, as it does reveal two ways to set descriptions. Probably not your fault; they are kind of buried... First, you can use to set individual descriptions for files or groups of files by partial match. Second, you can set and Apache will use the of each HTML document as its . This is CPU and disk intensive though. Descriptions given by take precedence. 

In this very common model, developers write their code on the development machines, push code changes to the staging machine for testing, and finally the tested changes go into production. To keep gremlins to a minimum, we generally want the servers to be configured as close to identically as possible. So, you can ssh into each system and install the same software (and the same updates) on each machine, but in production, you may have more than one server (e.g. for load balancing). You may find your app gets popular and you have to scale out to hundreds or thousands of servers. Wouldn't it be nice to be the next Twitter and make millions of dollars?... (oh wait.) But you can't ssh into every one of them anymore to apply your updates if you have several thousand servers, or even a few dozen. This is where configuration management systems like Puppet and Chef come in. These help you by applying identical configurations to a large number of machines at once (see their respective sites for further details). Once you get beyond the point of needing more than one server, it helps a lot to have a system to keep them all in sync and updated with exactly the software you expect in exactly the configuration you expect. 

The idea to write wrappers was eventually abandoned as unworkable, and nearly all Linux distributions have switched to iproute2 since then. 

No, you can't access VMs directly from the ESXi console. You can get the web address of its web client, which is how you'll need to manage your virtual machines, if you don't already have a vSphere client installed on your computer. 

I'm assuming a Red Hat-based system, since you didn't specify (and it may be important): The quick fix would be to edit and set . This will cause all your RAID arrays to be checked sequentially. As for the algorithm, is just a shell script, and you can easily read it to see what it's doing. 

The relevant section of RFC 2616 makes for interesting reading if you're wanting to control caching. 

Your site may be blocked because its IP address was flagged by various online services as containing malware. When I tried to access the site, for instance, Malwarebytes came up and stopped it from being loaded. Google doesn't have your site flagged for malware, though. Looking at my Malwarebytes logs, it specifically matched on the IP address. That makes me think that your site is on shared web hosting, and likely some other site on that same IP address is distributing malware. 

To resolve your problem, you simply need to tune the php-fpm pool correctly. You have a large number of idle servers but it's spawning more, which indicates to me that one of or or both are set too high. Try reducing them. 

Your machine does not have an active Red Hat subscription. Assign an active subscription to the machine and then try again. 

If you specify for the in question, then Apache will not generate a directory listing. However, if someone guesses the filename they could still access it if the operating system allows the web server to access the file. 

Because of the use of I would not recommend using nginx on Windows in production due to the performance issues it will cause. For a development box it would be fine, though. 

You're actually receiving mail with ssmtp? That's a strange configuration. Anyway... So ssmtp reads a file (which may or may not exist, and which your distribution's copy may look for elsewhere, so check the man page!). If you put something like these in the mail.rc then it will forward your mail: 

No. The tar "file" exists only in the pipeline; it's not written to disk in the intermediate stage, but only at the destination when you extracted it. 

It appears PHP has run out of memory processing the uploaded file. You will need to increase the parameter. Further information on upload tuning can be found at the PHP web site. 

This looks perfectly normal to me. Most video (and even audio!) players request small chunks of the file at a time, and then request more later, as the user actually plays the video. 206 is only sent when the user-agent specifically requests a specific range of the file, rather than the entire file. 

You built PhantomJS on a much newer system than the one you're trying to deploy it on. Rebuild it on a system matching the deployment system. 

SMTP server software such as sendmail, postfix and exim is designed to handle large quantities of mail, try again in case of temporary problems, etc. Your script isn't, and shouldn't be, smart enough to manage all the intricacies of SMTP. If it is your server, then you'll need to look at the server logs that it's generated to find out why it rejected the mail. If you're using a third party server, you'll need to contact the third party to find out what's going on with the mail server. 

OpenShift runs every file in the directories on the relevant schedule. Thus, we see that first is being executed by bash and throwing a syntax error. Then immediately afterward is being executed. To resolve the problem, get rid of and add this to the first line of : 

All three of those records, if looked up, return either NOERROR with no records or NXDOMAIN. Since three records didn't return anything, you exceeded the void lookup limit of 2, and the SPF record fails.