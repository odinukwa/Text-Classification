} To go back to your code, you should be able to simplify it in the following way. The loop is gone, otherwise, if you have other contraints that you didn't mention, you can always add it back. It works by tracking which pointer id is used for which control (move/shoot) when DOWN is triggered and reseting them on UP. Since you don't use gestures, you can restrict your switch() to DOWN, UP, MOVE and OUTSIDE. 

A user keeps a game on his mobile phone on average 20 days. So for the most part, adding ads is not going to be noticed much after launch. However, it is going to affect your biggest fan the most, which is the segment you don't really want to piss off. There are ways to mitigate the effect however. #1 is to only show ads to people who downloaded the game after version X, so old player won't see any ads. Also, do not show ads to players who purchased something (so no ads in premium games and no ads to a user who dropped $5 on virtual goods). I have retroactively added ads into a popular game. The effect was some bad reviews, but for the most part people expect ads - as long as they are not over the top annoying. The rating didn't really drop when I added the ads. Maybe 0.1 points, but that's it. Also you can let the users know that you need the money to make another game... lots of people are quite understanding of the plea of the indie developer. 

Changing the working directory worked for me recently: Go to -> -> . Then click on the left hand panel and then finally enter the path of the files under . All of your paths are then relative to the path you entered. 

Using a dummy 1x1 texture with the color (128, 128, 255) - this will lose Phong interpolation. Switching shader programs for normal mapped and non-normal mapped surfaces - I get the feeling that I'd end up duplicating a lot of code this way, especially when I start implementing specular maps, parallax displacement maps, etc. 

You may want to double check the string manipulation code, although I highly recommend where possible with since you won't be using it in a very performance sensitive area. I've also used which is better because you don't have to pick their max length before compiling the code (amongst other things). Don't forget to include and at the top of each file if you use them as follows: 

The object you instanciate, does it have some scripts attached to it? The instanciated object doesn't run its awake()/start() until the next chance it gets and not when you call Instanciate(). In the following code 

To stay motivated, keep telling yourself that you are making a game, not a game engine -- well, unless that's your thing. And that's cool, game engines are great, but they too often get in the way of making games. To illustrate my point, I can tell you how things often go: at first you create a few sprites, move them on the screen with your proto-framework and you are thrilled! You can see your progress and it is going well; you can show your friends. Then, once you have played with your concept a bit you realize that you need to make your framework (or game engine) more flexible. Or that you should re-factor some class that are not following the latest patterns. And from there, you embark on a spiral of death: you stop working on a game and you start working on a game engine. And game engines are not nearly as fun to make. You can spend hours refactoring and have nothing to show for it - in the game. And then, you lose interest. So, remember: make games, not game engines. Only refactor when you need to. Don't be too flexible - just the bare minimum.* *: of course refactoring and flexibility are important. But not as important as actually having a finished game. 

As far as I can tell, the main part of the calculation seems correct compared to things I've found online: 

The tangents are correct even over the seams. I am using the following piece of code to compute my tangents: 

I have noticed that the tangent vectors that I am calculating are not always facing the correct direction. The tangents on the left and right of the mesh both face the same direction. Here is a screenshot showing this: 

I am updating one of my shaders to a version of OpenGL/GLSL that doesn't automatically provide (for educational purposes; I'm not ripping out working code for the sake of it). Therefore, I need to compute my own normal matrix on the CPU and pass it in. I understand that a separate normal matrix is used to avoid issues with non-uniform scaling affecting the direction of normals. However, I've noticed that in my code I never perform any scaling let alone a non-uniform one. So, I'm tempted to use the upper left 3x3 sub-matrix for transforming my normals and calling it a day (perhaps normalising them to allow for uniform scaling). My program assumes that every mesh it loads is already at the correct size, with no scaling required. Will I soon run into something that requires scaling (uniform or otherwise), or is there another reason for using a separate normal matrix that I haven't realised? 

Solved Thanks to everyone who helped me with the issue. There were a few factors in play. First, there was the scale. What I did to figure this one is create an empty scene and put 2 cubes in there. I varied the size and position of the cubes (from 68x35 to 0.65x0.35 for size and the position by factors or 10 as well) and attached a script to move them, with variation in speed by factors or 10 as well. So all else being equal (same size on the screen and time to cross it), the size of the objects elected a different response to collision: big object got interpenetration, small ones none. I am not familiar enough with Unity to explain the cause of that, but it is reproductible. A possible second factor was the shape of my colliders and how it may be possible that they screwed up the ejecting part. The colliders I had were not overlapping, so I simplified them to 2 boxes in the shape of a cross. Finally I was setting the position of the objects manually in FixedUpdate and that caused some problems with interpenetration at lower scale (at higher scale, it didn't appear to matter). I changed that to work with the body velocity and it helped. 

I am trying to implement Exponential Shadow Maps and I've got it almost working. The part I am stuck on is the "optional" separable Gaussian blur of the depth map to give soft-looking shadows. I am using an OpenGL Framebuffer Object attached to a temporary depth map, and I am trying to use a screen quad (two triangles) with the original depth map as an input texture. Then, I am doing the same for the second stage of the blur, with the input and output reversed. Unfortunately, this results in a depth buffer filled with 1.0 which suggests to me that nothing is being drawn. In this example code I've found, they are using a color and depth attachment in order to draw to a screen quad with a blur shader. (unfortunately the only OpenGL example I could find) I want to know if this is necessary or that they are only attaching and blurring the color buffer because they are storing their depth values in it. In other words, I would like to know if it is actually possible to only use a depth buffer Framebuffer Object attachment in this scenario. 

i'm developing a android project for school and i'm currently using libgdx for rendering. It performs quite well, but it lacks a 3d physics library. So i searched and found that Bullet physics engine was ported to android through NDK (c++). Did anyone try to connect this two libs together? I've never used a physics engine/library before (i've mainly developed 2d games so i've made one my self) and wanted to ask if any one had any previous experiences with implementing bullet and libgdx? To be more precise i need to simulate a jump and implement physics like: wind/drag, friction, lift, gravity; during the jump. Does bullet calculate the gravity and other forces by it self (if so can i implement other forces easily?) or can i control which element gets updated (mainly re transformed) and when? How does collision detection work (is there some kind of collision world/collection)? Can i handle collision detection on my own or does bullet take care of this as well? Thanks for the reply's! 

I'm in a bit of crunch time and I find myself spending way too much time tinkering with an algo, so I would like some help. In the game I am working on, there are some old-style, pixelated minigames. One of the minigame is a spaceship in a cavern. The caverns curves and narrows down over time until the ship crashes in a wall. I want them to be generated at random during runtime. I'm having a problem creating the walls of the cavern and narrowing them while keeping a smooth curve on them. For the narrowing, I keep track of it with a variable that decreases over time, but how about the curving and how to keep it natural? I've though of a keeping a target point that goes up and down randomly and have the wall try to reach for it, therefore smoothing the randomized number but it is not working great. Any ideas/algo? 

To find the normal, you can use the cross product of three of the points in the polygon. Create two vectors from those three points and find the cross product of those. To find the intersection of the ray with the polygon, you will first need to ensure it intersects with the plane of the polygon. To do this, you will need to do some algebraic manipulation of the equation of the plane as seen here. Your ray should be defined as R0 + tV = P, where R0 is the origin of the ray, V is the direction of the ray, P is an arbitrary point on the ray and t is an arbitrary parameter. The plane has the equation P . N + d = 0, where P is an arbitrary point on the plane, N is the normal of the plane (calculated earlier) and d is the vector offset from the origin. We want to substitute the ray equation into the plane equation (replacing P) to get: (P0 + tV) . N + d = 0 and find the value of t: t = -(P0 . N + d) / (V . N) then you substitute that value of t back into your ray equation to get the value of P: R0 + tV = P. Finally, you want to go around each adjacent pair of points in the polygon checking that P is inside the polygon, which is done by checking that P is to the same side of each line made by the points. When the instructions say to check that the point "to the left of every edge", imagine that you rotating the polygon and testing the edge that is the right-most. That might help you understand why we test that the point is always on the left of the edge.