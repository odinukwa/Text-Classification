Do you realize that using pre-built technologies is (1) essentially inevitable (you'll be using a pre-built runtime on a pre-built OS for example) and (2) orthogonal to the issue of which language you use? It's fine to build things yourself for learning purposes, but don't let "not invented here" syndrome get you in its claws. Once it has you, it's hard to get out, and it's very easy for a new programmer to get snatched up. Resist the temptation, you will be a better developer for it in the long run. So all that ancillary stuff being said, to answer your real question: It doesn't matter which language you pick. My personal recommendation for people who want to get into game development and don't already know any programming languages is C# or Python. If you already know a language, use that language (it sounds like this is where you fit; if you know some C# already, I'd say continue using that). If you really can't decide, flip a coin. Between C++ and Objective C I'd say go with C++, since I think the available tools are more mature (especially on the Windows platform -- Xcode is decent if you are on a Mac, but it's no Visual Studio). A good programmer will know many languages and, similarly, the more languages a programmer knows the easier it is for her to pick up more. So you should never be focused on trying to predict the motion of the industry so as to study the "right" language. Instead, pick something, learn it, make some games, and move on to new languages as the time comes. You will never be wasting your time doing so. 

Not easily. Shaders aren't really designed for that. You can do various things to make the GPU do general purpose computation and read the results back on the CPU, and various GPGPU ("general purpose GPU") libraries and tools exist to wrap and abstract all that complexity, such as OpenCL. However, in this particular case it's unlikely to be that useful for you. 

It's often better to prefer composition to inheritance. In this specific case, I would strongly advise against using inheritance to arrive at a solution. What you are trying to do is take a sprite, which is naturally a rendering entity, and inject into it some methods and data for handling responsibilities outside its domain -- namely what sounds like AI and pathfinding. This is violating the single responsibility principle. A far superior solution would be to have some kind of object (for things dealing with AI and scheduling, such objects are often called "actors") that contains a pointer or reference to a sprite and manipulates that sprite as-needed based on its own logic. This sounds more similar to your second, "controller" type approach. However I would also advise, along the same lines, against creating a subclass of this controller type for each classification of actor (player, enemy, bullet). The behavior of those different types of controllers tend to differ in data, not in code, so there's little reason to create a complex inheritance hierarchy where no hierarchy is required at all. The differences between a player and a bullet are probably all things that can be altered by altering properties of the controller or sprite -- the image used, its bounded, and perhaps the name of the script that controls motion behavior. 

I wouldn't bother sanity checking or asserting against the size of individual assets. I would have a report or something that could tell me the total size of my final asset bundle, and if that exceeded something I was comfortable with I might look into using a more aggressive compression routine or something, but that would be an entirely manual check unless I was working on a platform with very strict hardware limitations (and thus I had very strict memory budgets). Regardless this would be something done at asset compile time, and would be optional, otherwise one might restrict the ability for end-users to mod one's game, which is usually a negative. Remember that exceeding the predefined bounds of your asset volume may have just meant you mis-estimated your asset volume in your initial planning, not that anything has, per se, gone "wrong." I also wouldn't worry too much about this because of most of the time compressing the data "well enough" or not is largely out of our hands -- sure, we can elect to use data formats that compress better under certain algorithms, but we shouldn't be doing that at the cost of quality of the in-game asset as a general rule, and unless we're writing our own compression there's only so far we can get things compressed. Unless I've misunderstood you, I sort of feel like this issue is overly hand-wringy. 

(Ray's tutorial uses 3D positions and also provides color information, which I'm excluding for brevity.) Store this data into the appropriate buffers using (assuming you've previously created both buffers): 

is, underneath the hood, a . Not only is it not possible to use the to directly supply an input to (et cetera), but it is a phenomenally bad way to store vertex data in general because of the extremely poor cache locality of the data If you were to use instead, you could pass the address of the first element of the vector to functions like easily. 

is an extension, unless you are using OpenGL 3 or above (I think). You probably want to use a library like GLEW to load it. See OpenGL Extensions for more information about extensions in OpenGL. Many things that were extensions in 2.x were promoted to the core API in versions 3 and 4, but unless you upgrade to those versions, you'll have to use an extension loading library (or do it yourself, which is not really that fun or worthwhile). 

Indices exist to reduce the memory footprint required to represent a 3D model, much in the same way that color palettes can be used to reduce the memory footprint of a 2D image. Indexing allows you to avoid repeating a full definition of a vertex if you have to duplicate that vertex's data, as you usually need to do for a complex model. Modern 3D APIs render using triangles; each face of a cube requires two triangles: 

JMonkeyEngine does not natively support as of this writing. Your best bet is going to be to wrangle your models into a format it does support, such as or . If you don't need the animations, I'd go with . Even though it may not be "favored," it sounds like it will work, and that's more important. You could also import the Max file into Blender and then save it, since the engine's asset pipeline supports . It appears that as of the beginning of January, support for importing was added, but it's unclear whether this was only a community-build set of scripts or if it will eventually make it into the real product. 

I'm going to gamble on the fact that you really want to know how to achieve a similar effect, and not specifically how Minecraft does it, which wouldn't be an on-topic question. 

In your title also mention "at random times," which sounds to me like you also want the ball to change direction randomly every so often. If this is true, one way to accomplish this is to have a timer that counts down, and when it reaches zero you re-generate above. Once you re-generate , reset the timer to a random value in the desired range (say, 2 to 4 to make the ball change direction every 2 to 4 seconds, or whatever). 

These aren't fundamentally different operations, really, although the type of data collected by each operation is pretty significant. The type of data collected by the first technique is generally reusable across many programs, whereas the second type of data tends to be more program/game specific (experience may not even exist in a particular game, for example). You have the right terminology for this kind of technology -- "profiling," "tracing," "user monitoring" and such are all appropriate terms. The technology itself is fairly straightforward to implement as well. The most basic approach just involves instrumenting code by calling a function that collects the desired data. You can then write that data to a log file or (most usefully) send it to a database for later querying and report generation. Code coverage, which you mention at one point, is a little more complex and difficult to get right (especially in more dynamic languages). It is more akin to the first technique, that is examining the state of your code rather than how users use your program. 

Since you are passing your custom bloom effect to within your function, you are executing that positive branch, so all passes of your technique are applied both times you call within , yielding incorrect results because those passes are not all meant to be applied to each texture. By switching to multiple techniques (as you have), you work around that behavior since each technique only has a single pass. You could also solve the problem by passing for the effect within your method. 

There is no simple solution I am aware of, you'll have to transition your resources to another pool type. I haven't ever really noticed the input latency issues you're describing, so I would venture to guess that they might be caused by a bug elsewhere in your code. Can you verify that it's a D3D-related issue (maybe it's a driver/card problem?) Or at least provide a more in-depth description of the problem? My hunch is that it's not worth the effort to transition to D3D9Ex just for that method. 

A series of pre-defined sprites, per base, is a reasonable and simple approach. A more dynamic approach that reflects the damage to each base on a per-pixel can be accomplished via a mask. The mask is a simple bit map corresponding to the base sprite. 0 for an invisible pixel, 1 for a visible one. Initially the mask would look like a blacked-out version of the base. For example, with crude ASCII art: 

There's a ton of links if you ask Google about it, but most of them are things that seem relatively unheard of. I have used one of the top results, Love, for a little while and found it pretty quick to get up and running with. It uses Lua. There's also Torque 2D, which I've heard decent things about (it is non-free, which I know you mentioned, but it is also relatively cheap, so...). cocos2d is quite popular for the iPhone. You also have the option of using Unity or Ogre or Irrlicht or any of the other available 3D game/graphics engines to simulate a 2D space, but that may involve more extra work than you want. 

The Xbox system pretty clearly does not provide a mechanism to track or display the progress of achievements (although some games may do this themselves via their own internal technology). I don't know of any official public statement anywhere that indicates that Microsoft intended this to be the design of the system, but given that it is a thing that hasn't changed since the achievement system was introduced I think it's fairly safe to assume that it is a design decision. 

There are some basic techniques you can use to reduce log spam. You can implement a runtime-configurable log verbosity filter. This allows you to reject the display of log messages below are certain filter level (for example, allowing you to display only errors, hiding debug and warning classes of message). You can obviously make this filter apply both (and/or independently) to the visual display of the log messages during the game and the saved logs on the disk. Since you are already tracking the verbosity level of each message, this should be relatively simple. You can implement message throttling. This involves defining, where the message is logged, a value indicating how often the log message appears. For example,