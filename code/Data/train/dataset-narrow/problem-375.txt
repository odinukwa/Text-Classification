You've got a few different questions in here. Q: Is it really a good practice to run Profiler on a production system? Generally, you want to avoid doing it, but there can be situations where it's the most efficient way to solve a problem. For example, if you've got a SQL Server 2005 box, and every query comes in with OPTION RECOMPILE so it doesn't stick around in the plan cache, and you need to troubleshoot a particular sequence of queries, then Profiler can be your best bet. You also mentioned dynamic queries - depending on how the dynamic queries are built, Profiler might indeed be the only way to capture the problem. Some monitoring programs are even configured to automatically run a trace whenever the server comes under heavy load so that they can help diagnose the problem. Q: If the server dies under load, how should we troubleshoot it? You'll probably need to be more specific about what "dies" means. If it stops accepting any query requests, I'd start by checking the error logs, not by running Profiler. Q: After running traces for 2 weeks, we haven't solved the problem. Are we using a good approach? If you haven't solved it after two weeks, that would be no. 

There's a ton of dynamic management views (DMVs) you can use to get the data, but the easiest way is to use Adam Machanic's sp_WhoIsActive stored proc. Here's a video on how to use it: $URL$ And you can download it from here: $URL$ The output includes columns for the database name, CPU cycles used, query duration, and more. 

I've seen this happen a lot when folks only have one set of network cables connecting their servers - meaning, a pair of 1Gb Ethernet cables in each node, at best, and they're using those for both regular networking as well as iSCSI storage connectivity. (The fact that you're using Equallogic is a clue - I've seen a lot of those with 1Gb implementations.) If you have any networking problems at all: 

That means if you have a nonclustered index on CustomerID, some CustomerID values might produce a plan with a nonclustered index seek followed by a key lookup, whereas other parameters will do a clustered index scan across the Widgets table. There are a few ways you could fix this scenario, and I'm going to list them in a generally safest-to-most-risky way: Use OPTION (RECOMPILE) on the query. This does require a code change to add the line to the query, but then every execution of this query should get the most appropriate plan. The risk is higher CPU use for plan execution (although that generally won't matter in a single-table, single-predicate query like this where the plan will be ultra simple to generate). Cache every variety of the plan. You noted passing the query in as a string will get each parameter to cache its own individual plan. While that will work today, it does bloat the plan cache (taking up more of SQL Server's memory). The risk here is that someone will turn on Forced Parameterization, a database-level option that will parameterize all of your queries whether they're sent in as strings or not, and suddenly you're back to troubleshooting this issue again. The rest of these are valid solutions, but not for your single-table, single-predicate query. I'm only listing them here for posterity and clarity: Use the OPTIMIZE FOR UNKNOWN query hint, or as we like to call it, optimize for mediocre. Requires a query change, and gives you a generally-good-enough plan. This will avoid random changes of the query plan due to parameter sniffing, but the risk is that it still won't be the most performant plan. Use the OPTIMIZE FOR query hint with a specific CustomerID. This also requires a code change, and you would optimize the query for one of your larger customers. This will get a query plan that's great for big customers, and not-so-good for small customers. Small customer performance will go down, but the big customers won't cripple the system. The risk is that your customer distribution will change, and this will no longer be the right plan for the app as a whole. Use a query plan guide. You can get exactly the query plan you want, and then pin the plan guide to memory. Here's the Books Online section on plan guides. I'm not usually a big fan of this because if your indexes change, the query plan won't take advantage of the new indexes. If your query changes, the plan guide will no longer be in effect. Suddenly the system might perform terribly, and people will have forgotten that a plan guide was helping before. Use a stored procedure with manual logic. Have branches that call different stored procedures, one for large customers and one for small customers. This is only used for much larger, more complex queries that can have variations between minutes and hours (or not completing at all). 

The gotcha with sharding is that the application has to know which shard to query. Generally, this is done by sharding on something like client. I'll adapt one of my old blog posts to use as my answer. When you’re building an application for lots of clients, there’s two common ways to design the database(s): 

I hesitate to even say that last one, because the 32-bit issue is so bad, and it's really hard on the older versions of SQL Server. If you were on a current one, you could go through the plan cache and sort queries by memory grant, find the biggest grant recipients, and tune those. Not an option on this old antique, though. 

Brent here - the guy in the hairy chest wig in the video. Much like that hairy chest wig, I don't use those tools much anymore. The video is still up just for comic relief sake. Over time, I wanted better tools, so with the help of my coworkers, I built 'em and open sourced 'em. Here's the Github repo for the First Responder Kit, which contains: 

There's two parts to this question: Where should the data be persisted permanently? Let's hold off on that part until we answer the second one, which is much more important: Where should the clients query to check for vulnerabilities? A caching layer. Your clients should never hit the underlying data store first. There's not a need for atomic transactions here, and your queries would be fine dealing with data that's a few seconds, a few minutes, or perhaps even a few hours old. For that caching layer, you can use things like Redis, Memcached, Elasticache, or whatever in-memory store is available at your chosen cloud provider. Your app should check the cache first, and if the required listing isn't in cache, query it from the database, and then populate it into the cache along with an expiration date. This logic should be built into your app, not into the data persistence layer or the caching layer. Now, back to that first question: where should the data be persisted permanently? Once you design the app to check the cache layer first, you can see why the persistence layer isn't quite as important of a decision. It's easy to scale a caching layer to thousands (or hundreds of thousands) of concurrent connections. The answer: use the database you're already comfortable with, and start getting comfortable with a caching layer. 

In my experience, the most common corruption issues are connectivity problems, followed by storage processor/controller firmware bugs, followed by filter drivers (I see less only because they were so unreliable that most folks have uninstalled them), finally followed by drive corruption. After all, in modern storage, the RAID controllers are pretty good about catching problems with a single failing drive. 

It sounds like you ran it with @GetAllDatabases = 1, and an error occurred. For example, you may have more than 50 databases on your system, or it may have encountered a dynamic SQL problem. When you're troubleshooting why a query doesn't produce the results you expected, head on over to the Messages tab in SSMS. 

This will give you a rough idea of how far behind each replica gets. If performance doesn't meet your goals, then you can drill into more granular measurements. Keep in mind that network latency & bandwidth isn't the only issue that can affect replica latency. There's also log file write latency and redo thread throughput on the replicas. Starting at the high level of just checking synchronization lag will tell you whether or not there's a problem at all first, and then you might be able to just avoid drilling down into details altogether - especially since you wrote that this is a DR-only setup, not for HA.