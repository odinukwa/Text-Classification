the answer is that it doesn't matter. The optimizer is automatically going to do an internal transformation from the SQL 92 syntax to the older syntax anyway. If you have performance problems, it is highly unlikely that they are related to your choice of join syntax (though when Oracle first added support for SQL 92 join syntax, there were bugs relating to its ability to transform the SQL into the older style). 

Presumably, you have a development and test instance of this database running on similar hardware with a similar data volume and the same database components installed, correct? And, presumably, you will be upgrading these lower environments (and testing that whatever applications use this database still function correctly), correct? Assuming that is the case, I'd time how long it took to upgrade the development database and use that as your estimate of the time required to upgrade the other instances. There are, obviously, a number of factors that determine how long the actual upgrade will take. My guess is that the downtime would likely only need to be an hour or two but you're much better off using the actual time required to upgrade dev. 

The only way for a trigger on a table to prevent an operation from completing is to throw an error. It is, as you have stated, a huge hack, but you could 

You would need to use analytic functions to get that result. I'm not completely sure that I understand exactly what results you're looking for, but something like this would appear to be what you're looking for. 

for example, would tell Oracle that the current session is 8 hours before GMT (currently the Pacific time zone), if the data is stored in a column, you'd need something like 

It's not obvious to me whether you modified the text of the error message to remove a directory from the error-- normally, the error will tell you a specific directory that you need to grant access to. If your intention is to allow the Java stored procedure to execute arbitrary shell scripts (this would be very dangerous-- the commands would run as the Oracle operating system user so they would have the ability to bypass any security measures in the database), you should be able to do something like 

That means that I probably got a bit unlucky and I had just a bit more data than would fit in 79 extents totaling 64 MB so I had to allocate an 80th extent that was 8 MB in size, for a total of 72 MB. We can use the dbms_space package to get more details about how much space is being used. When we do that, we see that we're actually only using 66.22 MB of the 72 MB that have been allocated. So our actual estimation error is really only ~10% 

Can you explain exactly what problem you are concerned with? People have come up with lots of different definitions of "fragmentation" some of which are impossible, some of which are possible but don't create any problems, and a few of which might be worth thinking about. If you delete at random 1 out of every 2 rows in a table, that will generally mean that you'll have lots of half-empty blocks in the table. That space will be reused by subsequent inserts into the table, though, so it is generally not create any problems unless you are stating that you are permanently reducing the size of the table (i.e. it will never again grow past 5 GB in size) or you have queries that rely on doing full table scans of the table that you want to tune. Depending on the Oracle version, you can probably do a on the table to reduce the size of the segment in that case. 

If we can declare , , and as , you can create a composite index on that can be used instead of doing the full table scan. Here is a sqlfiddle showing that approach. Note that I applied a hint to force the index to be used since there isn't enough data in the example for a full scan of the index to be less expensive than a full scan of the table. The index full scan path would probably be more efficient in the scaled up example assuming each location has data for many more than the past 26 weeks. That's probably not going to be an order of magnitude improvement, though, unless the table is substantially larger than the index. 

Most blocks, of course, are subject to transactional modification so they would have transaction information. 

In a relational database, there is no such thing as a "natural order". If you care about the order of your results, you have one and only one option-- specify an clause. Without looking at the query plan, I would guess that your table is the driving table of a nested loop join which happens to return all the rows first. It would be perfectly valid, though, for the order of results to change if the optimizer decides to use a different plan, if the underlying data changes, if you add and remove rows over time, etc. If you care about the order, specify an clause. Adding an does not necessarily force the database to do any more work. It is entirely possible that it simply causes the database to choose a query plan that returns data in the order you want as a side effect. 

is a function that returns a . Oracle SQL, however, does not support the data type so you cannot directly the result of the function just like you couldn't a function you write that returns a . 

Why would you want to have an auto_increment column that is not the primary key? If you want a column to be an auto_increment, by definition, you are not storing meaningful data in that column. The only case where storing non-meaningful information makes sense is the special case that you want to have a synthetic primary key. In that case, the lack of information is a benefit because there is no risk that someone will ever come along in the future and want to change the data because some attribute of some entity changed. Having multiple auto_increment columns in the same table seems even odder. The two columns would have the same data-- they're being generated by the same algorithm and being populated at the same time after all. I suppose you could come up with an implementation where it is possible for them to be slightly out of sync if there were enough concurrent sessions. But I can't imagine how that would ever be useful in an application. 

Our estimate of the average row length was spot on (note that, in reality, you won't be nearly this close-- your estimate of variable column sizes will not be nearly so accurate) 

WE8DEC is the old DEC MCS character set which stood for Digital Equipment Corporation Multinational Character Set. The WE8 prefix identifies this as a Western European 8-bit character set. 

Sure-- there is even a chapter in the Upgrade Guide on using DataPump to move the data from the old database to the new database. 

SQL Developer the client application is free of charge. Of course, the Oracle database would need to be licensed in a way that allowed you to connect with any tool. PL/SQL Developer is a completely different tool produced by a different company that you would need to license. Define "secure". Assuming a default database install, using any tool to connect to the database is secure in the sense that, say, the password isn't sent in clear text over the network. But all the data is, by default, sent in clear text unless you configure Advanced Security. But there are many, many ways that a database could be relatively secure or relatively insecure because there are many, many ways to set up security and many types of things that people may want to prevent. 

Unfortunately, you can't (unless something has changed in 12c that I'm not aware of). You'll have to recreate the table with and move all the data from the old table to the new one. Of course, you could use the package to do this redefinition online. But under the covers, you'd still be creating a new table with enabled, copying the data over, dropping the old table and renaming the new one. It would just involve potentially less downtime (at a cost to how long it takes and how much DBA time is required). 

Additionally, you'll want to make sure that your initialization parameter is set to something greater than 0 to ensure that jobs will actually run. 

Of course, in your actual system, I'm guessing that there is a role that you would grant privileges to and that role would be granted to . 

It is possible, though quite complicated, to write a pipelined table function that returns a variable structure. Your pipeline table function could take the two arguments and use the Oracle Data Cartridge interface and the magic of the AnyDataSet type to return a dynamic structure at runtime. You can then use that in subsequent SQL statements as if it was a table, i.e. 

This isn't saying that there is a memory leak in the Instant Client. It is saying that using the Instant Client involves adding a few kb of physical memory and a bit more virtual memory to your application's memory footprint. That's normally not something that would impact performance. If you are running in an environment where a few kb of space is an issue (for example, you're building an application that is supposed to run 10's of thousands of copies of itself on a single server), then you might be better off with a full client install. Of course, the full client will undoubtedly load more than a few kb of shared libraries into memory, they just won't count as part of your application's footprint. 

In Oracle, one way to enforce this sort of constraint in a declarative fashion would be to create a materialized view that is set to refresh fast on commit whose query identifies all the invalid rows (i.e. rows that have no match in ). You can then create a trivial constraint on that materialized view that would be violated if there are any rows in the materialized view. This has the benefit of minimizing the amount of data that you have to duplicate in the materialized view. It can cause problems, however, since the constraint is only enforced at the point that you're committing the transaction-- many applications aren't written to expect that a commit operation might fail-- and because the constraint violation can be somewhat hard to associate with a particular row or a particular table. 

should show you that there are two LOB segments associated with the table. You can then query to get the size of those segments 

Presumably, there is more than 1 row in . Given that, how do you know which particular row(s) in you want to read the from for each row in . I'll assume that there is some sort of key in and that would allow you to determine which row to read. Assuming that is the case 

In general, procedures should not commit. Those sorts of transaction control decisions should be left to higher-level code that knows when a logical transaction is actually complete. If you commit inside of a stored procedure, you are limiting its reusability because a caller that wants the changes the procedure makes to be part of a larger transaction cannot simply call the procedure directly. If you call a procedure interactively, you will have to explicitly commit or rollback the transaction because Oracle has no idea if you intend the procedure call to be a logical transaction or if you intend to compose a larger transaction involving multiple procedure calls. If you use , assumes that a job is a logical transaction and commits at the end of the job assuming it was successful ( does the same thing). Functions should not manipulate data in the first place. A function that manipulates data cannot be called from a SQL statement (barring the corner case where the function itself is declared to use an autonomous transaction which is almost never appropriate). The whole point of having both functions and procedures is that functions can be embedded in SQL statements and can be more freely granted to users because they do not change any data. 

There are a few different approaches depending on the details of your batch process and why you're trying to view the uncommitted changes. 1) Oracle Workspace Manager is a tool that was originally designed to allow people developing Spatial applications to have the equivalent of extremely long-running transactions (i.e. transactions that may require multiple days or weeks of humans figuring out where to run a pipeline in one transaction). Your batch process could create a new workspace (which is logically like creating a new transaction), make whatever changes it would like in that workspace while committing whenever it wanted. In a separate session, you wouldn't see any of the committed changes until you entered the batch process's workspace. When the batch process finished, it could merge it's workspace back into the live workspace which is the equivalent of committing a transaction. 2) The DBMS_XA package can be used to allow you to "hand off" a transaction from one session to another and to allow one session to connect to a transaction started by another session. This is a pretty obscure package to be using, but there was a nice example of using it in the PL/SQL Challenge (you may need a free account to access it) recently. 3) If you're just trying to see the status of the batch process rather than seeing the actual data, the batch process can write logging information using autonomous transactions that you could then query from another session. Or you could use the DBMS_APPLICATION_INFO package to have your application update various attributes in V$SESSION and/or V$SESSION_LONGOPS so that you could monitor the status of the load from another session. 

To the best of my knowledge, there is no limit. Of course, it is exceptionally rare that you would have more than one listener for a database. I've seem people run two listeners just in case one listener fails but I've never heard of anyone wanting to run more than two. If you really wanted to, though, nothing stops you from running a dozen listeners on a dozen different ports or on a dozen different machines. But since the listener is virtually never the bottleneck and the listener virtually never fails, that sort of redundancy is rarely helpful. 

The only real downside is that there are a number of configuration options that you can put in a TNS alias that you can't use when you use the easy connect syntax. Easy connect is designed to simplify the syntax for simple connections. In order to do that, though, it loses the ability to create more complex TNS aliases that do things like load balancing/ failover or that request a dedicated server session. If you don't need any of that, there is no downside to using the simpler syntax. As soon as an organization has one use case that uses something that the easy connect syntax doesn't support, though, it either has to support a hybrid configuration where some things use easy connect and others use TNS aliases or it has to use TNS aliases everywhere. Supporting hybrid configurations or changing how connections are handled can be somewhat painful depending on your perspective. It's relatively easy for the Oracle client to handle a bunch of different naming conventions. It's much more difficult for an organization to support. It's relatively easy for organizations to come up with ways of distributing a single, shared tnsnames.ora file to everyone or to stand up a central LDAP server to host the organization's TNS information. If some applications use easy connect syntax and some organizations use TNS aliases, that can be problematic when an organization wants to do things like consolidate databases or move databases from one host to another. If an organization wants to add load balancing support, it can be problematic when some applications fail over automatically and some don't. Someone has to track which applications are which, admins have to treat applications differently rather than being able to count on organization conventions that are adhered to across the board. None of this is impossible, of course. But consistency across the environment makes DBAs and admins much more productive and allows teams to support many more applications/ databases/ whatever with any given level of staffing. 

If the SQL is more readable and understandable if you use joins, then use joins unless you have a strong reason to do otherwise. Likewise, if the SQL is more readable and understandable using subqueries, use subqueries unless you have a strong reason to do otherwise. Different queries are more easily expressed using one construct or the other, it's not a one size fits all situation. I would only consider using the less readable option if you find that the more readable option is not efficient enough. SQL Server, like most relational databases, can frequently transform a statement that uses subqueries into one that uses joins. So there is frequently no difference in the query plans. 

If you don't want a user to create a database link, don't grant them the or privileges. My guess is that you've granted the developers a role that you didn't realize had that privilege-- the role in at least some versions of Oracle includes . I think that's been removed in more recent versions but I'd need to validate that. This is one of the many reasons that using the predefined roles and is highly discouraged in a production environment-- the privileges associated with them are generally much more expansive than you want (or than the name implies) and they tend to change over time. You're much better off creating your own roles, granting those roles whatever privileges your users actually need, and granting those custom roles to your users. As for the underlying issue of user queries bogging down a data warehouse, I would tend to expect that you want to use Resource Manager on the data warehouse to limit the resources that lower-priority users get when there is contention for resources. You might be able to get away with a lighter weight solution based on profiles as well to put a hard cap on the amount of resources any single query can consume before it is killed. Resource Manager, though, is a much more robust set of tools to prioritize requests.