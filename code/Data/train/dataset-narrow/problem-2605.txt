Sounds like you are indeed talking about parallax scrolling. (it's not c# or XNA, but the skills are transferable) You can read up on some simple scrolling backgrounds in an sdl tutorial actually $URL$ (one of my all time favorite tutorials) Then you can make multiple layers, and move them relative to the camera's position. 

With my AI, I simply check if there's a platform below and int the direction of its travel (not using a tilesystem, just a groovy collision system). If there is not- or if it hits a solid block, it gets a confused look and turns around. This way you can have dynamic maps and still have a working(term used loosely) AI. 

Instead of delaying a set number of frames, why not only update frame if the time elapsed since the last update is xx? (for instance 100 ms) You're animations will look great- and won't depend on your framerate. In other words: have a class variable to store the update time, and when your update function rolls around, if (the current time - previous update time > desired frame time) increment frame() 

Forenote: My engine uses a collision detection class that checks collisions with all objects real time, only when an object moves, and only in the grid squares it currently occupies. My Solution: When I ran against problems like this in my 2d platformer, I did something like the following : -(engine detects possible collisions, quickly) -(game informs engine to check exact collisions for particular object)[returns vector of object*] -(object looks at depth of penetration, as well as previous position relative to other object's previous position, to determine which side to slide out of) -(object moves, and averages it's velocity with object's velocity (if the object is moving)) 

The important step here is when you have a bottom collision you add the other object's velocity to your position. This allows you to move about freely on their platform and have your own physics unaffected by it's (you may want to, instead, change your axis velocity to theirs and add their other axis's position to the object in question) 

There is not ideal way of doing it, this is a common problem with meshes. To solve this there, are two different approaches: Considering that you have a vertex that has to be used with two different textures coordinates here is how you can approach the problem: 1:Duplicate the vertex and assign to each one the different texture coordinates. As a result you will have two vertices with exactly the same position but two different texture coordinates. How you store the vertex data is not really relevant at this point (interleaved or not). There is no way i know right now (someone correct me if i'm wrong) to be able to represent an indexed vertex buffer in order to share vertex position and different texture coordinates. 2:Separate the geometry in multiple parts and draw it with two (or multiple) draw calls but this has a couple of drawbacks. First need to create extra code to be able to share the vertex position, second you need to make multiple draw calls and this hurts performance especially on mobile devices. I think the first approach is the industry standard because in the end the extra memory used is not much of a problem. One way to overcome the memory usage is to use streaming and it's much easier to use that (not to mention that you can significantly increase the amount of geometry) instead of the second approach in which adds a lot of code complexity. 

Here is an approach to get the direction regardless of the how many directions you have and how many space dimensions: 

So basically you want to know if any line , , , or intersects your polygon The naive way to do this is to define the polygon with a a set of segments you can use line-line intersection to test this: 

Here is a simple solution: Instead of calling everywhere , replace that with a function what has the following code: 

To simplify the problem i think you want to check if any point ,, is visible from the players's perspective and in this case you don't have to take a reference point you can just do , 'BD' and . You would basically have to do this for each polygon in your scene which is not that efficient in the end (if you have a big scene). The best approach is to use spacial partitioning like a BSP tree (best for your case) but this is not that trivial to implement. If you scene is small or relatively small you can use the approach described above and you can even improve this by adding a 2d Grid to store references to polygons that you want to test. 

Assuming you have your , and as demonstrated in your screenshots, here's how to get a relative vector representing this hypotenuse: 

It's possible to "embed" software to appear as though it's not getting installed along with the primary package, but it's sneaky and wrong. It's also possible to request that users install additional programs in addition to the one they're currently installing. This isn't "embedding" per se, but rather is a request for the user to install an additional program. The mechanism for requesting this differs by platform. On non-AppStore-like environments, the two software companies can make a deal where one agrees to include the other's installer along with their own. In a modern consumer computing environment (such as the AppStore for Mac and iOS and the new Marketplace in Windows 8) this kind of application behavior won't get approved. You need to present some sort of request to the user indicating that you'd like them to download this other piece of software. The "request" part is important. The AppStore and Windows Marketplace are enforcing this because installing software without a user's permission is a characteristic of malware. It's like somebody bringing an uninvited guest into your home without your consent. Sure, there's enough people doing it where it's not uncommon, but we all find that guy to be really irritating. 

Unity's on collision event gives you a Collision object that gives you some information about the collision that happened (including a list of ContactPoints with hit normals). But what you don't get is surface normals for the collider that you hit. Here's a screenshot to illustrate. The red line is from and the blue line is from . 

There's a lot of different directions you could go with this. What kind of game are you making, and what does type Mob represent? It sounds like you need to separate your concerns more. 

Choose a language based on what you are personally interested in using. especially since this is a single-person project. You could write the whole thing in C++ and be fine. You could also write the whole thing in C#. You could also use something like Corona or Love2D and write the whole thing in Lua. A common pattern is to write low-level and speed-critical game code in C++, and wrap this up into a higher level API with a scripting language. Lua is a common choice because it has a lightweight runtime and flexible syntax. The reason that an integrated scripting language is more time/effort-efficient is because you don't have to spend the time recompiling your game engine. In fact, you could feasibly load game scripts while the game is still running, constantly tweaking them as they game runs. C# with Mono has made headway as a scripting language thanks to Unity. C# will generally have faster execution time overall since it's JIT-compiled, but these things always depend on the use case. Since C#/.NET/Mono is so fast, it's also common for people to just write their whole game in C# using frameworks and libraries like XNA, MonoGame, or OpenTK. You can also use a language that targets .NET IL code and write a lot of game logic in a non-C# language such as IronPython, IronRuby, F#, or Boo. If you go the route of C#/.NET, it's often viewed that a scripting language integration is not necessary. C# on its own is very expressive, and you could always use a more dynamic language like IronPython to write higher level game logic. You can also consider Java (as your "native" language, it's not very good for embedding). The same principle of targetting the VM from C# (C# vs IronPython vs F#, etc.) works with Java (except you're looking at Scala and Clojure). C# Advantages 

How It Works First, you need to find the object with the nearest wall- in a tile system this is a simple check for the tile with the nearest center. When I did this I sorted my objects from closest to farthest. Next, you run this routine on it: 

Hahah, this is a pretty common problem, here's what I do-> Step 1: collision detection: Be sure you're separating your map into sections or using quadtrees to speed up grouping, Step 2: basic collision resolution, my preferred method works great for moving platforms, I always preform this check 

Now I won't end up using this, it's for the initial networking testing phase. I'll probably end up using dead reckoning. However I have a couple questions: 1: I am using TCP for all my networking. However it jumps and skips if you drop any packets at all, so I'd like to switch to UDP and have a numbering mechanism to make sure all packets arrive. Is there a preferred Networking Schema for game communication? 2: For critical things like object hits with bullets Should I implement a second port for these important events, or just use the same UDP proto? 3: (Side Question) How should I regulate my framerate with the networked game? I don't want to have an unnecessary Sleep in each frame... 

The way I currently have my systems set up, events spawned by objects trigger scenes, as you stated you can have player triggers cause scene changes, and you can certainly use a state machine. You can make your own animation scene protocol, so it doesn't have to be hard coded. You also have the option of playing actual movie files if you so desire, but generally they're quite large. I think you're definitely on the right page, since this is your program- you can go about it any way you desire. Creating functionality for things like this is intriguing and fulfilling. I've never seen any real documentation on this subject so I'd be interested to see anyone else's take. 

There's a little more to game audio than just playing back and fading in/out sound files. XACT is primarily useful when you're working with a sound designer who either has no coding experience, or no desire to work in code. Omnion's answer covers the essentials: 

Are you using a lot of memory on textures already? If you make all your texture rect sizes uniform (rects being the slice of the texture that represents a single frame of animation) and draw them all on the same size quad, are you drawing a lot of transparent pixels to the point where it's taking too long to render a frame? (more problematic on mobiles) Are your art assets already in one format or the other? Is it easy for whoever is creating your art to do one way versus the other? 

Freeplane is an awesome fork of Freemind, but you may also like VUE. For me, the best tools for game design have always been a pencil and graph paper. Then Google Docs or a wiki to disseminate information throughout the team. Google Groups is useful as well. 

Also, slightly unrelated, but when the game is paused, keep a timer and if there's no user input after 3-5 seconds or something please fade down the music and other continuously playing sound effects. Update Adding Trevor's comment in the answer because it's important: 

Source: $URL$ [EDIT] The debug function can also be useful in a limited context. [EDIT EDIT] The love-console library was apparently built on an older version of LÖVE, but at least it's a starting point for building your own prompt. If you're not specifically looking to work with Lua and a game-centric SDL-based framework, another fun one to try out is ruby-processing. It wraps JRuby, making it more convenient to access the Processing library, and has a mode where it will watch a sketch and recompile it every time you save the file. There's also a "live coding" mode but I haven't gotten it to work for me. [EDIT x 3] Also look at PyProcessing. It has the advantage of having to not bundle JRuby, and can be imported into a standard python interpreter (provided you have all the dependency modules installed, which is Pyglet (which requires PyObjC on OS X). 

This method stores the first value in the integer part (by multiplying by 1000) of the float, and the second value in the fractional part. Using the magic number allows you reliably to store values from up to and for texture coordinates this is more than enough. For a 2028 texture there is almost no precision loss using this method compared to the classic approach. The computing cost if the unpacking is unnoticeable. 

Changing to should solve the problem in this case but it's not a general rule. Here is why: Some math facts first, for matrix multiplication ; also So when you take a tutorial or code and you see in code and you want to do the same in the shader you have to think how and will end up in the shader code (transposed or not transposed). If it will end up transposed then you need to do to achieve the same result, otherwise A * B. If a matrix ends up transposed or not is dependent on the rendering Api and the matrix library you used. When you sent the matrix to the shader the api will copy a series of floats and interpret that as a matrix, but it doesn't know if the first 4 floats represent a column or a row in the matrix. 

Setting the position before you destroy an to 'infinity' will handle all the appropriate collisions calls. 

interleaved: if is easier to understand and to manage memory wise and code wise. Instead of having 4 buffer you have just one and that's it. separate: there is no practical advantage in sharing resources, managing 3d stuff is difficult as it is and by having the separate streams shared would only create a nightmare. You might gain some memory by doing that but it's not worth it. on performance there might be a difference , at least on some Android GPU i know that you will have different results. 

The application is usually tested on the targeted platform with the worst case scenarios and you will always be prepared for the platform you are targeted. Ideally the application should never crash, but other than optimization for specific devices, there are little choices when you face low memory warning. The best practice is to have preallocated pools and the game uses from the very beginning all the needed memory. If your game has a maximum of 100 units than have a pool for 100 units and that's it. If 100 units exceeds the mem requirements for one targeted device then you can optimize the unit to use less memory or change the design to a maximum of 90 unit. There should be no case where you can build unlimited things , there should always be a limit. It would be very bad for a sandbox game to use for each instance because you can never predict the mem usage and a crash is a lot worst than a limitation. Also the the game design should always have in mind the lowest targeted devices because if you base your design with "unlimited" things in it then it will be a lot harder to solve the memory problems or change the design later on. 

There's one major principle you need to understand when it comes to game audio which is obvious in hindsight, but not everyone gets on their first approach: 

The trick to this is really just finding a way to balance the amount of data parsing and hard-coded behavior. I'm sure that a teleporter is not the only type of behavior you'd like to add to your tile. Ideally you'll be able to add new behaviors quickly, and have an obvious way for describing them in a data format. You didn't provide a lot of details on your tile class, so I'm gonna make some crap up. Let's assume you have some sort of base class, which has some basic variables like position and group. I'm assuming s are things that are generally dynamic in your game. Things like static scenery wouldn't fall under this category. is just something I tacked on to illustrate the effect of checking for just the player, all NPCs, etc. 

You're probably at the stage where you'll get the most information by looking at various tutorial postings for specific engines online. There's also a decent enough number of open source games you can check out. One interesting thing to study might be the Monocle Engine. 

The state management system can be a FSM pattern, or a simple enum and switch statement. Its purpose is to point the current Viewer/Renderer reference to the appropriate one from the collection based on the sprite's state I'm not familiar with Processing, so I can't much on the details of the Viewer/Renderer interface/abstract class and the static image vs sprite sheet implementations. Check out Brandon Furtwangler's blog, it's C# and XNA, but he shows off his really solid architecture for managing sprites. His animation system is also really cool, and although it uses lambdas, you may be able to achieve similar effects with anonymous methods in Java with only slightly more verbosity. 

First things first: If you're targeting XBLIG and Windows desktop, you're using XACT, right? Just making sure. Unless you have a compelling reason not to, you should be using XACT. It's got warts, but it solves too many problems for it not be used. That is, unless you're looking to also compile with MonoGame or deploy to Windows Phone. Then it's not so useful.