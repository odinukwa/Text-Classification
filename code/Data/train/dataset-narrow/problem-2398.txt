Note that one of the issues in doing that, besides taking the minimum of $n$ identically distributed random variables (the influences), is that these random variables are not independent... although I do expect their correlation to decay "pretty fast" with $n$. (For what it's worth, I have computed explicitly the first few $I_n(1/2)$'s up to $n=4$, and have run simulations to estimate the following ones, up to $n=20$ or so. Not sure how helpful this could be, but I can include that once I am back to my office.) 

(I am mostly interested in the first) I apologize if this is obvious, or follows easily from the proofs of the lower bounds for Gap-Hamming of Woodruff or Jayram-Kumar-Sivakumar; or the more recent ones for two-way communication. As far as I could tell, these proofs move the problem to the continuous, Gaussian setting, and it was unclear to me how to get the continuous version of the variants above. 

By Chernoff bounds one can also show that each $\operatorname{Inf}_i[f]$ has good concentration, so that by a union bound we get (if I did not mess up too badly) $$ \frac{1}{2} - O\left(\sqrt{\frac{n}{2^n}}\right) \leq I_n\left(\frac{1}{2}\right) \leq \frac{1}{2} $$ but this is most likely loose on the lower bound (due to the union bound) and definitely on the upper bound. (I am in particular looking for an upper bound strictly less than the trivial $\frac{1}{2}$). 

This is Corollary 3.22 of Analysis of Boolean Functions, by Ryan O'Donnell (2014). You may want to consult the proof in the book, or look directly at the online version (which has a different numbering: this corresponds to Corollary 22 there). Note that you can obtain a version of the book following this link. 

[LSW15] A Faster Cutting Plane Method and its Implications for Combinatorial and Convex Optimization, Yin Tat Lee, Aaron Sidford, Sam Chiu-wai Wong. FOCS'15. $URL$ [BCELR16] Tolerant Junta Testing and the Connection to Submodular Optimization and Function Isomorphism. Eric Blais, ClÃ©ment L. Canonne, Talya Eden, Amit Levi, Dana Ron. arXiv, 2016. $URL$ 

[1] Tolerant Versus Intolerant Testing for Boolean Properties, Eldar Fischer and Lance Fortnow. Theory of Computing, 2006. $URL$ 

(The next question, but which is subordinate to the first, is whether one can also get good concentration bounds around this expectation.) 

Sorry for unearthing this post -- it is quite old, but I figured having it answered may not be that bad an idea. First, it looks like you performed your Chernoff bound with some slightly odd setting of parameters. Note that to perform your suggested "testing by learning" approach, it is sufficient to learn the distribution in total variation distance (or $\ell_1$, if you prefer, which is the same up to a factor 2) to distance $\frac{\varepsilon}{2}$. (before checking "offline" if there is any distribution $p'$ having the property $\mathcal{P}_n$ which itself is at distance at most $\frac{\varepsilon}{2}$ from your learnt hypothesis $\hat{p}$). This would naively lead to an $O\big(\frac{n\log n}{\varepsilon^2}\big)$ sample complexity upper bound for this approach; however, it is known (and "folklore") that learning an arbitrary distribution over a domain of size $n$ up to distance $\varepsilon$ (in total variation distance) can be done with only $O(\frac{n}{\varepsilon^2})$ samples (and this is tight). So the baseline should actually be $O(\frac{n}{\varepsilon^2})$, which is already linear in $n$. Now, one can ask the next question -- are there "natural" properties for which testing (say, for constant $\varepsilon$) requires a linear dependence in the domain size $n$? The answer is (as far as I know) "not quite, but close." Namely, following a significant line of work on estimating properties of distributions (or equivalently, tolerant property testing), the results of Valiant and Valiant imply (STOCS'11, FOCS'11, and some others) that the rather contrived property "being $1/10$-close to uniform" has sample complexity $\Theta_\varepsilon(\frac{n}{\log n})$. (Note that it's a bit "cheating," in the sense that the property is simply a way to take a tolerant testing question and relabel it as testing of an ad hoc property). If that is not entirely sufficient to quench your thirst, one can also show that for the (natural?) property of "being a $k$-histogram" (is the distribution piecewise constant on a set of $k$ unknown intervals?), setting $k=n/10$ for instance also results in an $\Omega(\frac{n}{\log n})$ lower bound (it's in a paper of mine from 2016; the lower bound follows from a rather simple reduction to the Valiants' result). Now, whether you consider "being an $\frac{n}{100}$-histogram" to be a natural property is up to you. 

What you seem to be looking for can be captured under the field of distribution testing, a subfield of Property Testing initiated in TCS by the work(s) of Batu, Fortnow, Rubinfeld, Smith, and White in 2000. Most of the works in this field answers questions of the following sort: 

Conjecture 1. For any two monotone Boolean functions $f,g\colon \{-1,1\}^n \to \{-1,1\}$, one must have $W^{(0)}[fg]+W^{(1)}[fg]+W^{(2)}[fg] > 0$. Actually, I'd be actually inclined to believe the following stronger statement: Conjecture 2. For any two monotone Boolean functions $f,g\colon \{-1,1\}^n \to \{-1,1\}$, one must have $W^{(0)}[fg]+W^{(1)}[fg]+W^{(2)}[fg] \geq \frac{1}{\operatorname{poly}(n)}$. Side note: this would have implications about weak learning of the class of "2-monotone" functions, which are exactly those functions obtained as parity or anti-parity of $2$ monotone functions. (See e.g. [BCOST15].) But more importantly, this is a very simple-looking question, that has been nagging at me for way too long. 

Disclaimer: I know very (very) little about deep nets, besides what an introductory course on machine learning would teach on neural networks, and skimming some paper abstracts and introductions. If I understood correctly the concept, an autoencoder is a specific case of neural networks with as many input nodes than output nodes (say $d$), whose goal is to approximate the identity function $$ \operatorname{id}\colon \mathbb{R}^d \to \mathbb{R}^d\,. $$ The trick is that this net can be broken into two parts, "encoder" and "decoder" of the form $\Phi\colon \mathbb{R}^d \to \mathbb{R}^k$ and $\Psi\colon \mathbb{R}^k \to \mathbb{R}^d$, such that $k\ll d$. Therefore, there has to be something non-trivial going on for $\Psi\circ \Phi$ to approximate the identity, given the restricted width of the middle layers. This struck me as begging the question: 

In the proof of the positive result in [2] you are referring to, namely Theorem 2, the argument goes as follows. For every possible concept $L_i$ of the hypothesis class $\mathcal{H} = \{L_1,\dots, L_N\}$, let $p_i$ to be the distance (probability of disagreement) with the true concept $L^\ast$. Then, under a classification noise $\eta$, we have that the probability $p_i$ that a labeled example $\langle x,y\rangle$ disagrees with $L^\ast$ is exactly $$ p_i = d_i(1-\eta) + (1-d_i)\eta = \eta+d_i(1-2\eta) \tag{$\dagger$} $$ where $d_i = \Pr[x\in L_i\triangle L^\ast]$ is the probability to hit the region where $L_i$ and $L^\ast$ disagree. In particular, for any "bad" concept $L_i$ which is $\varepsilon$-far from $L^\ast$, we have $p_i \geq \eta+\varepsilon(1-2\eta)$, while for $L_i=L^\ast$ we have $p_i = \eta$. The argument then goes by applying concentration bounds and a union bound over the (at most $N$) bad concepts to see how many examples are enough to ensure that, w.h.p., choosing the concept consistent with the maximum number of examples taken rules out all bad concepts. (In particular, the "gap" on expectation for $m$ examples between a bad concept and the true concept is at least $\varepsilon(1-2\eta)m$ by the above.) Now, what changes under malicious noise? (Or, even, under the milder assumption that the adversary can, with probability $\eta$, decide to flip or not the label of a sample, instead of flipping it automatically as in the classification noise) Put it simply, $(\dagger)$ is no longer true. For instance, the adversary could focus on a specific bad ($\varepsilon$-far) hypothesis, say $L_{i^\ast}$, and decide to only flip the label of a given example $x$ if that example falls into the region of disagreement $L_{i^\ast}\triangle L^\ast$ (and not if it doesn't). In that case, one gets $$ p_{i^\ast} = d_{i^\ast}(1-\eta) + (1-d_i)\cdot 0 = d_{i^\ast}(1-\eta) \geq \varepsilon(1-\eta) $$ instead of the previous expression. That is a huge drag for the analysis, and essentially kills it: now, in this possible scenario (which may not happen, but is a valid scenario) to have any hope of separating $L^\ast$ from this bad concept $L_{i^\ast}$ by looking at the disagreements, we need to separate the expected $\eta m$ (for $L^\ast$) from the expected $\varepsilon(1-\eta) m$ (for the bad concept $L_{i^\ast}$)... and to have any hope of doing so, we need $$ \varepsilon(1-\eta) > \eta $$ or equivalently $\eta < \frac{\varepsilon}{1+\varepsilon}$. Note that this is by no means a formal proof of the negative result of [1], more a hand-wavy way to see that things are consistent. 

Opening and doing a quick search in the (classic) Computational Complexity book of Arora and Barak (online draft here), there are 19 occurrences of the word "philosophical", including such subsections as 

The Discrete Analysis Journal, which works as a peer-reviewed overlay for arXiv, includes among its topics "theoretical computer science" (and, for instance, computational complexity. From their website: 

Proof. Consider the empirical distribution $\tilde{p}$ obtained by drawing $m$ independent samples $s_1,\dots,s_m$ from the underlying distribution $p\in\Delta([n])$: \begin{equation}\label{def:empirical} \tilde{p}(i) = \frac{1}{m} \sum_{j=1}^m \mathbb{1}_{\{s_j=i\}}, \qquad i\in [n] \end{equation} 

As it turns out, the one-sided error case (public coin) was addressed in [KK16], which shows the communication complexity is then $\tilde{\Theta}\!\left(\frac{(t-g)^2}{t+g}\right)$ (the upper and lower bound are off only by a $\log(t-g)$ factor). (so, for $\mathsf{GHD}_{n,2\sqrt{n},\sqrt{n}}$, the one-sided public-coin communication complexity is $\tilde{\Theta}\!\left(\sqrt{n}\right)$.) [KK16] One-sided error communication complexity of Gap Hamming Distance, Egor Klenin and Alexander Kozachinsky. ECCC TR16-173, 2016. 

[1] $L_p$ Testing. Berman, Raskhodnikova, and Yaroslavtsev, STOC'14. [2] Testing $k$-Monotonicity. Canonne, Grigorescu, Guo, Kumar, and Wimmer, ITCS'17. 

For instance, ${\sf EQ}_n$ is $\Theta(\sqrt{n})$ for SMP private-coin, and $O(\log {n})$ for one-way private-coin; but in the public-coin setting, it is $O(1)$ for both. On the other end of the spectrum, ${\sf DISJ}_n$ is $\Theta({n})$ for both models, and so is ${\sf GAPHAMMING}_n$. (As a side note, one can derive a separation between one-way "imperfectly-shared"-coin communication complexity and SMP "imperfectly-shared"-coin communication from the work of Bavarian et al. [2] on communication with correlated random bits, from their ${\sf GAPIP}_n$ problem, but this separation does not hold for perfectly shared randomness (public coins)). [1] Randomized simultaneous messages: solution of a problem of Yao in communication complexity, L. Babai. 1997. $URL$ [2] On the Role of Shared Randomness in Simultaneous Communication, M. Bavarian, D. Gavinsky, T. Ito, 2014. $URL$