This says, take all our current partial solutions, for each partial one, generate a list of more complete ones. Then, flatmap those to an extended list, and collect them. Now, that logic needs to be embedded in a left-fold operation, and you're right, one does not exist in Java. So, I built one. A left-fold takes two inputs, and returns a result of the same type as the first. To make it work I need to keep a 'state' in order to 'accumulate' values in to. Here's my implementation: 

IntOps Some small helper functions used for some common operations on Int primitives, are here. I expect this to grow over time. 

If the file is larger than your memory, you will have to re-position the byte-buffer occasionally. I recommend using a emopry-mapped size of about 4MB plus the size of the search-string. That way you can search the 4MB window, and then start the next window at the next 4mb boundary. Once you get in to it, it will make sense. This system will be fast because you will never have to copy the file's data in to Java. Everything will actually happen in the native side of things. There is a lot to read to make it work. I would start with a tutorial.... 

To save having the complicated exceptions on the method I recommend adding the first value to the pool in the constructor, and making the constructor throw the complicated exceptions.... then the method will be simpler to use .... Note the following in these examples: 

Then, in your existing code you can create a single instance of this, and just call it when you need a new name: 

The concurrency looks complete to me in the sense that I cannot see any places it can fail, or block significantly. The static and make sense. The itself is technically correct in the sense that it returns the right results, without logic problems. There is no need for the double-check locking though. It saves nothing, and solves nothing, other than creating two separate lock points. Additionally, methods should not return concrete-types when interface-types would be available. Your method (and Future should be of type and not Your code pulls the from the , and locks on that. There are only two places where you use (one in the , the other in the ). Neither of them need a sub-lock of the , they can both operate on the itself. Your code would be simpler, and slightly faster, as simply: 

It's not complete BS. Your use-case is somewhat surprising, and your disregard for using a Map is also surprising, but given those, you're left with little option other than a completely custom implementation.... but, let's look at the issues you currently have... People need to do a round-trip query-before-inserting operation - they need to call before setting a new value. People can't use all the methods available to them. For example, they can't call: 

So, there is no need to specify at all, or, if you do, you should do it consistently. The (or ) on all of your tables are defaulted to , but the columns are still nullable. CreateDate will never be null, and should be created as . I am suspicious of the column on . Columns like that are typically a small domain (only a few values, with many repetitions). That should be normalized out in to a table, and the column replaced with a . This will potentially improve the performance and maintainability of the system. Of course, if your type has many different values with few repetitions, the normalization won't make sense. Similarly, I am sispicious of the column on . This is a value related to the application that does not make clear sense based on what you have presented. I can only guess what it will be used for, but, since the rest of the schema is clear, it stands out as being ... 'obtuse'. Fnally, I expect that you are missing some indexes. Postgres will index the primary and foreign key columns, but I suspect indices on , , and would be good (and consider making things like mod and card names unique....). 

What the above code does, is keep the most recently added-to node at the top of the stack. Then, if the node can still be added to, it fills it. If the node is now full, it goes back up the tree, looking for the next insertion point, which may nto exist on this level. If it does not then it goes all the way down the left edge and starts a new level.... This means that, for many inserts (half of them?), the performance is \$O(1)\$ and for the worst case, when you have just completed a level of the tree, and you have to start over again at the left, it requires one walk up the right edge, and back down the left edge, in an \$O(\log{n})\$ operation. So, this brings the process from a \$O(n)\$ operation with \$O(\log{n})\$ space complexity, to a worst-case \$O(\log{n})\$ operation with \$O(\log{n})\$ space as well. 

why throw an exception for an empty array? Why not return null? you have not followed the instructions correctly... it is impossible for a 0, 1, or 2 element array to actually have a peak, since there is no or to compare against. Additionally, there is no peak in cases like , since the 2's are not peaks, and the three's are at the edges. your first if conditions are and , and those are just messy.... your should have a recursion-terminating condition and not spread it around in the method. I am a pragmatist about OOP in Java... Objects are great, I agree, but there is no reason to have an instance for this code. A static method passing the input array in would be fine....: 

Next up, I am concerned that you have two tee processes both writing to the same "full" file. The one that starts second will overwrite what the first one started with, but I suspect that they will subsequently "merge" the results. It would be better to start a clean file, and then have both tee processes append to the existing file. I messed around with your function, and came up with: 

The above changes do not change the logic of your program at all, just the techniques used at the various points. Your implementation would still be 'textbook'. In terms of performance, though, your limit is the number of times you create, copy, and discard arrays of data. There is a variant of the Merge Sort that uses just two arrays, the input array, and a 'temp' array that is the same size. The algorithm repeatedly merges small chunks of data from one array, to the other, then swaps them, and merges the now larger chunks back to the first, and keeps doing that until the data is sorted. Using that algorithm means there is no additional array copying, etc. It is much faster, but the implementation would look very different to yours. Still I would recommend you try it. There are examples on Wikipedia 

That saves using the and combination, so you save a process, but the code is a bit more complicated. 

Your code is a reasonably neat use of recursion to solve the problem, and recursion is a good solution to this problem. I prefer it for people to make it obvious that a function is used recursively to prepare myself for what to expect, I tend to use "recursive" in the name. You don't show how you set up the recursive method, though, and in general it's poor form to embed print statements inside functions that do other things too (single responsibility principle: $URL$ A better solution would be to return a collection of results that you can print in a separate place. What really bothers me, though, is two things: 

You know, it's not too bad, but I dislike the magic numbers you have added in place. The mask as is a problem. is not a standard size, so why have you set it as 32 bits? I think you are missing a simple trick here. You are setting the mask high, and decreasing till it's done, when instead, you should start at the low order bits, and increase until there's nothing left to do.... by using a bit-shift (and the mask which is int-size safe. You have forced the values to be unsigned, so you may do it really easily: 

End-of-data frame of reference What I mean by frame-of-reference, is that your common reference point between the input string, and the output array, is the last character, and the last member of the array. You should line up your reference points, and work out from there. In this case, it means working backwards. The next thing that you have as a frame of reference, is your input value. You use this value to drive the calculation of the output array size, and also to drive the iteration in the loop. In this case, what it means is that you should be using the input chars to drive the loop, not the size / 2. Putting this together, consider a loop that iterates from the last char, to the first char, and then populates the last byte, to the first byte. We can then do math from the end of the input/output arrays based on the loop. Bitwise manipulations There are some bitwise manipulation tricks you can do here that help: 

Yuck ... you should be able to handle an empty list more gracefully than that. Creating a special instance perhaps. Random Access I like that you differentiate between RandomAccess and other lists. This is a good thing. public indexProperty() By exposing this, and the indexElement, you are allowing people to completely mess up your data. They can change the indexProperty, and not the elementProperty, and now you have corruption. Co-Modification Your method is not reliable. A followed by a will result in a regular Iterator throwing a ConcurrentModificationException, but, your code does not. To implement fail-fast co-modification behaviour, you need access to internals of the List that are not public. next, current & previous This is a broken concept.... I don't like it. You have access to three methods that may, or may not, all return the same value.... a single-element list will have all three produce the same results. I would expect that you have to move the cursor before you can access the content. Additionally, there is no way to easily loop through this structure.... How would I visit each member exactly once? 

Your code can be drastically simplified, and there are significant bugs too. First, the bugs. SQLInjection is a serious bug because it allows a malicious attacker to compromise your system. Vogel612 has already emphatically pointed that out. On the other hand, SQLInjection is simply a way to exploit a bug in your code in an intentionally malicious way... The bug has to be there first... and, in this case, your bug is that you do not 'sanitize' or 'escape' the values you concatenate in to the String query. Now, why is that bad? Well, I work with a person who's name is . You cannot save that name using your system. It fails to execute. A malicious person could use that fact to craft a name which does more damage than just fail..... A second item of interest, is that you are not running a query, you are performing an insert. Calling it 'query' is not helpful. Finally, when you do not mention a column as part of an insert statement, it gets the value null. So, you are inserting null values in to the and columns when the params are not set right. There is no need for the conditional columns if you can just insert null values explicitly. Now, all of these issues can be easily solved using parametrized statements. Vogel612 has already strongly recommended them, to solve the injection, but they will also solve the complexity of the code.... Consider a PDO solution: 

Problems like this are often "academic" in nature (although the principles can be applied to other problem-spaces too). In this instance, I believe that the challenge is to use the correct form of "modulo" and integer-division type arithmetic and to have a "simple" conversion function for each target element. Your initial output array creation looks good: 

Note that the results from the above code may, or may not include the terminating period. If the match is in the last sentence of a text, and that text ends with a period, then the period may be returned as part of the result. If there is a match in the middle of the text, then the period will not be included. 

The above script will convert newlines to null characters in the input list, then copy the files to the server. You can add the argument to xargs to do 10 files are a time, or whatever works for you. I like the -t argument as well which echos the xarg command to stderr before it runs it. The above will copy only one stream at a time, but, it will do the files in bulk operations, and you will likely be limited by your network bandwidth, not the parallelism of your copies. EDIT: If you want to run the scp's in parallel, you can add the ()argument to xargs, which will run as many as scp's in parallel for you. So, for example, if you have hundreds of files, you can scp them in 5 parallel streams, 5 files at a time, with: 

Note how all the characters have valid values, except Z. Now, there's a trick with that... which is as ugly as anything, but it works really well.... - subtract an integral 10'th of the value from itself. What does this mean? Well, it means that your function can be (for valid input):