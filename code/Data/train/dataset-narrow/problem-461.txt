Looks like the JDBC 11g NAT+RAC issue. JDBC Connections Using SCAN Fail With ORA-12516/ORA-12520 (Doc ID 1555793.1) 

This would have had the same result as your recover command, without throwing an error. You can also specify and . 30 because: 

In the above statement, typing in lowercase or in uppercase makes no difference, it is case insensitive. Just because you named your PL/SQL parameter (in uppercase), does not mean the database will use it when you type (in uppercase) in the above. Even if the in has unique values, the above returns all* rows from the table, because the column precedes the parameter, and always* equals (*except for ). You could just simply use a different name for your parameter, for example I usually use the prefix for them, so your parameter could be changed to : 

1158 is the default port for Enterprise Manager Database Console, not the database listener, and you can not log in there using SQL*Net or JDBC. The default port for the database listener is 1521, try connecting using that port. You can check the listener port by: 

Redo logs can be mirrored, your query does not take into account that. Controlfiles are also part of the database. 

Then name of the synonym is . You are trying to drop the object (view) here, called: . And that view is owned by SYS, not SYSTEM. Where you see , the synonyms points to a non-existent object. Replace the object or drop the synonym. 

I could not find any official reference to this, but by experimenting, I found that a JSON record value that is longer than 32K triggers this error. Maybe this will be fixed in a future release, like this similar bug, that is said to be fixed in 12.2 (this bug is about having JSON identifies longer than 64 bytes, not this error): Creating a JSON Index Fails with DRG-50850 (Doc ID 2110588.1) Until then, I would try to use shorter records, or open a Service Request. And the experiment: 

There is no such thing enabled by default in the database. or views are not guaranteed to contain all your SQL statements all the time. The amount of memory to store SQL statements in views is limited, and views contain only sampled data. Furthermore, they do not store information about constraint violation errors. If you want to find the SQLs causing unique constraint violation errors, you can create a trigger that catches the errors and logs information, for example: 

The same can be specified in the standby database. RMAN Configurations at a Standby Where Backups Are Not Performed 

If you disable the constraint this way, the index remains usable, and there will be no need to rebuild it when re-enabling the constraint. 

What makes you think you need to rewrite it? SQL Tuning is more than just trying to rewrite your query. If you do not understand what happens behind the scenes, then how will you rewrite your query? The estimated cardinality in step 10 and 21 is 1. Still the database decides to scan the whole table. Twice. Is the above estimation correct? Would those steps really return just 1 or a few rows? If you run this query (with actual values), will this return 1 or hundreds, thousands, millions? 

Oracle database supports Java and external C calls. They can be used as wrappers to call programs written in other languages such as Python. Publishing External Procedures 

This means you set instead of . When you use , the contains , and the actual actions performed by that session are stored in the column as characters. For example the value means there was a select on the object, as each character represents the following actions in order: 

When the O7_DICTIONARY_ACCESSIBILITY parameter is set to false, users with SELECT ANY TABLE privilege can not access tables such as SYS.USER$, unless they have direct privileges to them. 

For , you need Enterprise Edition with the Diagnostic Pack. If you have that licensed, you can enable collection of historical data with: 

Or you can import the table directly from database1 to database2 through a database link. Using Network Link Import to Move Data 

With proper types, everything works expected, the index can be used. It is not a matter of single quotes, but a matter of using proper datatypes, so 2) is better. 

Oracle 12c provides the procedure . EXPAND_SQL_TEXT Procedure If you have a query, it can expand its text to involve th base tables and its columns. Example: 

Then view the audit records in . This gives you and . Using , you can find the SQL in , and in , the (= in ) and columns tell you where that statement came from. 

all the new data end up in the same database block (not necessarily a table, a common example is a PK index on an ID column, where the ID values come from a sequence) changes are not committed immediately (or quick enough), so locks will be held for a long time, and all the 50 sessions will hold the locks at the same time 

So unless you pass the column as , the result will be , and that is not good enough, because that means data loss during conversion. works with or , so to simply put it, you need to convert everything to , then convert the result back to . Below is an example: 

Start the old application, and log in. Find your session in the database (let's say: sid=12, serial#=3456), and enable SQL tracing for that session, for example: 

The above connection string should work with the addition of . Seems like your SQL Developer connection is configured differently. Alternatively, you can define the connection type as , and use the below custom JDBC url: 

queries directly from the dictionary table and nothing else. also queries , but joins some other tables and views as well, for example . This view does not contain all the objects from , so this join eliminates some rows from related to the missing objects. For example on my database: 

Where variables starting with are bind variables, so that is where you bind your actual values. And this is really bad practice: 

This can be done in a few minutes with storage snapshots/cloning. If you can't do that, just go for RMAN duplicate. Both method can be scripted and scheduled to run automatically. 

Where 1234 is the desired clustering factor. The lowest valid value of the clustering factor is the number of the table blocks. The highest valid value of the clustering factor is the number of the table rows. But this does not mean you can not set it lower or higher. This setting will be lost on the next index statistics collection. You can use the above to change other statistics as well that have effect on the cost: () or (). 

In order to grant the privilege, your user needs the privilege , or the system privilege. Otherwise you have insufficient privileges. $URL$ 

Changing this setting requires a database restart to take effect. For FGA you can specify a different audit trail, for example: , that way you can leave on . If you use FGA, you do not even need to use , just create the policy you need. 

Of course it can be done, the question is, do you really want this? Scheduler jobs can raise events (put in a queue). You can capture (dequeue) those events using Advanced Queueing. For example: Monitoring Job State with Events Raised by the Scheduler How To Use DBMS_SCHEDULER To Publish Events For Oracle Advanced Queueing (Doc ID 871718.1) Once you have the events and details, you need to write them to syslog. You can do this by using external procedures, for example: write to syslog from pl/sql Or, you could keep it nice and simple, and use the built-in e-mail notification support for Scheduler, for example: 

Yes, there is a difference, and the issue is that the estimated selectivity (thus cardinality) will be different in the 2 cases. For a simple example, lets say the year column has years in it from 2000 (low_value) to 2014 (high_value), so there are 15 distinct values (num_distinct), they are evenly distributed, 1000 rows for each, 15000 rows (num_rows) in total in your table. In the first case, where year < 2010 (limit = 2010), the estimated selectivity will be: 

SID identifies the instance, not the user. Use for SID - based on your output. This is not a solution, it is a cheap dirty hack: 

You can use the above to check the actual usernames when logged in (or if your client does not support ). Your trigger in its current form does not work with the first user above, and does work with the second user above. 

A NOMOUNT instance stays in BLOCKED status with dynamic registration. You need to use static registration to connect a NOMOUNT instance remotely. Add the below to and restart the listener: 

This is described in the note: How to Clean up The information in EM Backup Report (Doc ID 430601.1) Edit , find the procedure , change the default value 60 as needed: 

Let's say no is less than . Because of condition, the outer query returns 0 rows. Why would the database scan the without any filtering, just to find out after it in an instant that it was all for nothing, because the outer query returns nothing. 

If you created the table with the above statement as user , then that table belongs to the schema, not . If you want to create tables in other schemas, add the schema specifier to the create statement, for example: 

The above note suggests upgrading the JDBC driver to 12c. Whenever you connect through SCAN, your connection is redirected. Previous versions of the Oracle JDBC driver can not handle that properly. If you download the latest SQL Developer, that comes with the 12.1.0.2 JDBC driver. Another solution that I prefer is to use OCI with an Oracle Client instead of JDBC (this makes possible to cancel long-running queries in SQL Developer). After installing the Oracle Client, you can configure this in Tools / Preferences / Database / Advanced. 

But we do not care about courses. The below lists which student is taught by which professor(s). is unique, and 1 course is taught by 1 professor, so the same (student_id, professor_id) values appear multiple times, if the student attended multiple courses taught by the same professor. 

The tutorial you linked uses the multitenant architecture with pluggable databases. I quickly read through the tutorial, and it does not cover this topic, but pluggable databases do not open automatically with the root container, unless specified otherwise. My guess is that you tried to connect the pluggable database. Run the below: 

Then manually upgrade the database to 12.2: Example of Manual Upgrade of Windows Non-CDB Oracle Database 11.2.0.3 

This is quite typical on 11.2 because of a feature called "cardinality feedback". Check the execution plan of the slow runs, and if you see "cardinality feedback" in the Notes section of the execution plan, try setting the below parameter: , and run your tests again. Some bugs related to this: Bug 12557401 - Suboptimal plan on 2nd execution caused by cardinality feedback (Doc ID 12557401.8) Bug 16837274 - Cardinality feedback produces poor subsequent plan (Doc ID 16837274.8) Bug 8608703 - SubOptimal Execution Plan created by Cardinality Feedback (Doc ID 8608703.8) Bug 8521689 - SubOptimal execution plan on second execution of GROUP BY query (Doc ID 8521689.8) 

Then upgrade the database to the new release. Instructions can be found at: Manually Upgrading a Non-CDB Oracle Database Note that the above documentation is for version 12.1. Direct upgrade from 11.2.0.2 to 12.2 is not supported, you need an extra upgrade step to 11.2.0.3 or 11.2.0.4 or 12.1 before upgrading to 12.2. 

Having a physical standby in read-only open mode while applying redo requires the Active Data Guard option. 

Yes, it is possible, as stated in the 11.1 documentation: Supported Releases for Downgrading Oracle mentions 10.2.0, because ideally you need not to set anything more specific (more digits). This is explained in: How To Change The COMPATIBLE Parameter And What Is The Significance? (Doc ID 733987.1) 

Columns referenced by a foreign key constraint should have a PK or unique constraint in the referenced table. This is not true for , , . To be honest, those FK constraints are unnecessary, remove them, and keep the FK constraint on . Also: 

Another possibility is that you need to install the Microsoft C++ 2010 Redistributable manually: $URL$ 

a) Use an OS that is certified for installing and running Oracle Database (Ubuntu is not amongst them). Native or virtual machine, your choice. or b) here is an unofficial guide for installing Oracle 11.2 on Ubuntu Linux $URL$ I have never tried myself, but several people succeeded installing Oracle 11.2 on Ubuntu with the help of this. 

The listener listens on the default port: 1521. You are trying to log in using port 8080. Instead of this: 

The problem is, the above can not be done with a type. types have only fields, and can not have member functions. Furthermore: Record Comparisons 

The above drops the index, so when you enable the constraint, the index will be rebuilt. The below preserves the index: 

Because that is nothing more, than an extra row in a specific table (), we can insert anything in there. And the required script was not run. 

And here comes , the variable that was meant to make your life easier, but it is also a great feature to play a prank on someone who does not know about it. Even if you connect , SQL*Plus will try to open a remote connection because of it: 

This is a restriction of direct path load, not staging tables. Direct Path Loads, Integrity Constraints, and Triggers Triggers fire during conventional path loads. 

Above statement produced just a tiny amount of redo. But there are other aspects: the required locks and invalidation of related PL/SQL objects. 

Do not ever rely on implicit type conversion, especially not in cases where it depends on NLS settings. 

The database does not care about the IP addresses. Grid Infrastructure does. The method to change the IP addresses can be found in detail in the below MOS notes: How to Modify Public Network Information including VIP in Oracle Clusterware (Doc ID 276434.1) How to Modify Private Network Information in Oracle Clusterware (Doc ID 283684.1) 

The message indicates that no archivelog exists with this sequence in the current incarnation. Failover starts a new incarnation, and log sequences start from 1 again. Let's say your database is at sequence 10 now, and the log sequence was 159 before the failover. V$ARCHIVED_LOG at this point still contains entries about previous incarnation, so the above query will return 159 because it doesn't consider the start of a new incarnation (resetlogs). For these kind of queries always check resetlogs_change# or resetlogs_time, e.g: 

That is the typical error message you get on Windows without properly setting up the environment. While the steps in the manual may work flawlessly on Linux/UNIX, on Windows you need extra steps. On Windows, you need to create a service with , start it (if it was not started), and after that you can use . The bare minimum is: 

For the output: Your trigger runs in an autonomous transaction. When you select val from , your original update is still not finished (commited), you will see the old value. Fixing your trigger for : 

The above documentations refers to OUI (Oracle Universal Installer), not DBCA. Saving response files in DBCA is available starting with version 12.2. See the below example (Save Response File in bottom right corner): 

A - Makes no sense. is unique, the query retrieves at most 1 row based on an equality filter, this should be a dead simple . B - I don't think so. is unique, the number of distinct values equals to the number of rows. With huge gaps in a unique column, a height balanced histogram can still provide extra information for better estimates for a full/range scan, but this is an index unique scan. C - Maybe, but very unlikely in a real scenario. The above query should return its result after a few block reads and gets (lets say, <10, index height + 1 table access). Instead, it took 453 disk reads and 797 gets. Maybe the query read the whole table instead of an index unique scan. In that case, decreasing MBRC would increase the cost of a FTS maybe up to the point, where the index scan becomes favored. Still, in a real scenario, with proper statistics, I doubt this would happen. D - Maybe, but again, unlikely in a real scenario. "Decreasing" the index may reduce the cost of it. The clustering factor and number of leaf blocks do not affect the cost of an index unique scan. This leaves us with the index height, and yes, that may decrease, which means the cost decreases as well, but this difference is so small, I find it difficult to believe the database would choose a FTS with 453 reads over an index unique scan with an index that has a much lower BLEVEL (typically between 0..3, it is rare to have indexes with higher BLEVEL). E - Makes no sense. Same as A.