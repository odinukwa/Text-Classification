If were truly of type , it would be automatically converted by the compiler to , thus calling the correct overloaded operator(std::ostream&, int). However, since is of type , the compiler does not find that conversion (it stops looking after the conversion to ). Make sure to document this (sometimes surprising!) behavior appropriately! Thinking ahead... If you allow custom getters as well, you might find cases where both getter and setter only refer to another variable (other than ). It might be worth to consider making a special case for those. If I had to implement something like that, I would probably start with something like this: 

As you can see, most y-values have either 0 or 2 corresponding x-values. The exceptions are (1, 4), (14, 9) and (26, 23) corresponding to (, ), (, ) and (, ) - for this selection of , and . Why that? There are multiple reasons: 

Compilation flags Please specify for which sets of compilation flags this code is expected to work (it will break if compiled with defined, as described below, and I'm not 100% sure on 64 bit support). Bugs / string handling If compiled with defined (e.g. by a compiler flag), a lot of stuff will break: 

Suggestion If targeting C++17 or later, consider providing a partial specialization for : access paths only require a (read only), while non- access paths should be locked with (write access). Also, for convenience, a member function to explicitly acquire a reference would help. See this talk by Andrei Alexandrescu for more information on that topic. 

Design It's simplicity of usage is great. However, you have no way of enforcing that it will be used at all possible call sites (where appropriate).Another possibility that comes to mind would be to use the State pattern to provide access to the OpenGL functions in form of a member, with 2 states: One that records the OpenGL calls and one that simply forwards them. The call to then switches state from recording to forwarding, executing the recorded calls.Though also not foolproof, but which is harder to forget: "I have to use OpenGL calls in a lambda passed to this function." or "I have to use this member to get access to the OpenGL functions (as they aren't provided directly by default anyways)."? Example (rough outline, as I currently have no Qt install at hand): 

On the other hand, if the requirement is that the consumer has to run on its own thread, why fuse it with its own queue? If there is only one queue, you could run multiple consumers on it to share the workload if needed and/or producers by themselves don't have to decide which consumer to call! 

Further reading I suggest you look for learning material about , and , as those will simplify memory management quite a lot (if used correctly). 

This line is not correct. An iterator over a vector might still be a random access iterator, but it very likely won't be of the same iterator type as the iterators passed in (e.g. iterators over a or a custom container). If insisting on proper static typing, this could be remedied as follows: 

Correctness Every returned by might be dangling. This can happen if the gets destroyed while there are still pointing to contained objects. This is a result of the not owning the pointer. If you can guarantee that there won't be any pointing into the when the is destroyed, this problem easily disappears. If this can't be guaranteed, there are two options: 

With the current implementations of and you risk getting stack overflows in case of very deep branches (around \$2^{16}\$ or \$2^{17}\$ on 64-bit or 32-bit windows with default stack size of 1 MiB, different values for different OSes), even with the potential fixes from @vnp and @LokiAstari. Not only that, but you would probably need them for future additions anyways (e.g. a Constant-Folding optimization pass is easy to implement with a post-order traversal). I might implement something along these lines: 

Algorithm allocates a new buffer of scratch memory for each recursive call. This means sorting an array has to use \$O(n \log n)\$ allocations total, with \$2 * n\$ peak memory usage. This is double the amount of memory usually required, and if s runtime complexity is worse than \$O(1)\$, the whole operation will perform worse than \$O(n \log n)\$. Also, every call to unnecessarily copies all of the elements of the previous buffer into the new ones. These copies can be completely skipped with appropriate management of the already existing buffers. The operation isn't stable, though it can trivially be made so by changing to . Stability is usually a major factor for choosing merge sort! Implementation 

Note This could maybe be enhanced by strategic use of atomics. However, that would require more knowledge about the members and usages of than I could gather/guess from the code given. 

For patterns as simple as these, I'd probably not bother to encode them in any special format. Just an array of lines is fine (unless you're programming under heavy memory constraints). These patterns can be set statically, loaded from somewhere or even generated dynamically. Choose what fits your circumstances best! E.g. loading from a file could allow for different patterns, allowing for customization. 

There are some nearly unique bidirectional mappings when is a multiple of and and are coprime and must be greater than 0 or lower than -26 - this is because how the modulo operator works and how you handle negative y-values. They would be unique if you reduced the number of possible input values to 26, e.g. by moving the values for to down to to . However, those mappings are basically linear (the contribution of gets "removed" by the modulo 26). For , this would be a cesar cipher. 

Design problems is a queue fused with a single consumer, so there will never be more than one consumer for the queue!. If the consumer is not required to run on its own thread, the implementation could be simplified to: 

Naming Many variable have very non-descriptive names. These could be improved for better readability (what tells you more: or ?). 

Absolutely. In it's current form, it does far too much stuff and (at least in my opinion) is not really flexible enough. Every time you try to add something (e.g. other card patterns, loading patterns from a file, change the card border, ...) the function will just get more and more bloated. Actually, I'd implement it in a class . This way, you can transfer state (e.g. card patterns) between calls in a nicely, encapsulated way. Also, I'd split the functionality into multiple member functions, so it's easier to reason about them. 

Depends on whether your class already contains a vtable pointer or not. If it does, there will be no additional memory requirements per instance (just another entry in the vtable, which is shared by all instances). If it doesn't, each class will need an additional vtable pointer (that will be automatically inserted by the compiler to make virtual dispatch work). Also, a vtable will be generated, but those are one per class. However, since you are already using (and that includes possibly deleting) instances of derived classes via pointer to base class, the base classes destructor (in this case ) should already be marked so the derived classes destructor gets called correctly when deleting the . This means each class should already have a vtable anyways - so no additional per-instance overhead. 

Contention There is only one , and every thread is permanently in contention for that same lock for every small partial operation. Thus, all the threads are permanently in contention over that lock, and at most one thread at a time is actually doing any work. A single threaded implementation should be faster - it has to do the same work, but doesn't have to fight over lock control. So, how can this be fixed? 1) Separate independent data per thread In the usage example, elements of are split between threads so that no two threads are accessing the same elements. So, accesses to elements of don't need a lock - if this convention is followed strictly. If this is possible, locks aren't needed for those parts! 2) Finer granularity locks Right now, taking the lock stops every thread from doing any work at all. Even with the improvement of option 1, only one thread at a time can access elements from . This can be improved by introducing locks at a finer granularity: 

Boundary checks You never verify if is actually a valid position in the list. checks You never check if any call to returns a . Without one kind of check, your code will very likely try to dereference a if is greater than the number of elements in the list. Wrong condition sets to , and if unequal to , executes the branch, deleting a wrong node from the list (it's only the right node if ). You probably meant to write . Memory leak At the begin of the function, you allocate a new node. This node will never be deleted (it either crashes because of nullptr dereference, or another node pointer gets assigned to before gets deleted. Unnecessary nesting The check inside the loop isn't necessary: Just run the loop until ( will then be true after the loop ends). 

I won't repeat any of the excellent points @Loki Astari already mentioned. Asymmetric Interface The current implementation only allows for custom setters, but not for custom getters. This might be fine for trivial implementations of those, but will hinder reusability in more demanding cases. Unnecessary encapsulation breakage There's no need for a definition in the macro. Unnecessary convention introduction The implementation requires that each setter function is and a class method. Both requirements might be too restricting for all use cases. Naming I get it, naming is hard. might be borderline acceptable, but (as those from C#) or might be more fitting. Also, just looking at the name, what should do? Get a "setter"? Declare a "setter/getter" object? would be a far better fit IMHO, better conveying its intended purpose. User defined conversion problems If has its own user defined conversion operator, you might get into problems when "chaining" conversions. Example: 

Introducing your own smart pointer type that checks the for validity every time it's dereferenced, as the standard smart pointers (, and ) are not designed for this task. (Ab-)using the returned to keep the section alive. This can be done in the lamda init capture of the custom deleter. 

Algorithm The encoding algorithm is fundamentally flawed (it cannot be reversed unambiguously in the general case). For an example, I have plotted the values for : 

MSVC still does produce some extra instructions (for the 's and the lambdas constructors and destructors), but those are never actually called. The final count for of MSVC would be 19 instructions (only 3 more than GCC because it does some stack pointer management, though that could probably be turned off with the right compiler switch). Link to godbolt with fixed macro (MSVC) 

So, time to explore the scary depths of template metaprogramming (well, scary for me, anyways). This library basically provides 2 different lists, a list of types and a list of sizes. Both lists support: 

usage Normally, a is used to express "I own this". So a signature like says "Call me, and you become the new owner of whatever I return". Is this necessary in this case? No! After all, the caller just wants to access the existing object, and not acquire a new one. So, how can this be expressed? There are two variants: 

Correctness can be destructed while another thread is performing an operation on it, because the destructor or its caller don't have to acquire a lock to do so. Technically destroying a mutex while it is locked already is undefined behavior, but it gets worse if another thread happens to modify the now invalid object. Same reasoning for the move constructor: The object from which will be moved could still be modified concurrently by another thread, so locking would be required. Also, rule of 3/5 violation: There's a custom move constructor (and there will hopefully be a corrected destructor), so copy constructor, move assignment operator and copy assignment operator should also be provided (currently, they copy without locking neither nor the other object). Also, should be marked , otherwise a can't be accessed. Other nitpicks 

TL;DR: MSVC does some extra stuff and really doesn't like the call to . To elaborate: The functions in the original examples only takes 16 instruction (GCC) or 23 (+8 inside ) instructions (MSVC) respectively. GCC inlined everything it could, proved that and don't change (so they are basically constant), elided the branch and variable allocations, and just calls directly before exiting. MSVC, however, only inlines the destructor of into and the constructor of into . MSVC seems unable to inline the call to or to prove that and don't actually change values (so it has to create them on the stack and generate instructions/calls for them). But this can be improved! Changing the macro so it doesn't call suddenly allows MSVC to come to the same conclusions as GCC and remove the checks and thus the stack allocations.