The article isn't well worded but here's what I think it's saying Beginning scenario - DatabaseA is in an AG and is currently primary on Server1 and can run on Server2. DatabaseB can only run on Server1 T1 - Transaction begins T2 - Row inserted into DatabaseA (log not yet sent to Server2 though) T3 - Row inserted into DatabaseB T4 - Transaction commit called T5 - DatabaseB commits transaction (since the two DBs commit individually) T6 - DatabaseA fails over before log is sent Since the log was never sent DatabaseA wouldn't have the row but DatabaseB would. If synchronous mode is being used that can't happen because the commit can't be called until the log from the row is sent. However, it may be possible for the commit on DatabaseB to happen and DatabaseA to fail over before the commit happens there. This may lead to a rollback in DatabaseA instead of a commit. I can't say with certainly that you can get into the same situation with synchronous mode but if you can that's how it would likely happen. 

Windows 2008R2 with firewall disabled for testing (not that it changed anything). Listener.log doesn't show anything of worry. Just evidence of me restarting the listener many times. I am aware that I could configure a static listener with but I would like to understand why this is not working. This is the 4th time around that I have been doing this and I have not run into this problem yet. I am basically stuck since I am not sure where else I should be looking. 

Really new to Oracle and being a DBA in general. I am trying to set up a development environment so that I can play an learn oracle better. Enterprise Mananger failed to configure itself when I first created the database using the Database Configuration Assistant. No biggie. Just need to user emca.exe I had some issues with the Listener but those might have just been me being impatient in waiting for the service to register or the service not running. Right now my issue is this from the emca log: 

If the master database is corrupt you have two options. Hopefully you have a backup and can restore it. This link describes the steps: $URL$ Alternatively, if you don't have a backup available you can reinstall SQL and then restore any backups that you do have. You'll have to reconfigure security, sp_configure settings, and possibly other things if you go this route. 

For a repeatable process you can use Powershell to script objects. The following link has more detail but essentially you load the SMO objects, loop through the objects in the database, and call the Script function. $URL$ 

The only way to restore a single file group is to run in all the logs so it's up to date with the rest of the files. This would of course run in the bad data modification you're trying to prevent but it's necessary to ensure consistency throughout the database. You'll need to restore it to another location and move the data over. $URL$ 

This should be what you're looking for. If not can you update the question with an example of the expected output? Thanks. If you haven't used CTEs before note that the statement before the CTE needs to be terminated with a semicolon. 

For testing I have been trying to install Oracle 11g on a test system with a single database several times with the aid of snapshots. This most recent iteration I have been having issues getting the database to register with the listener. I am to understand that PMON, as long as the database is running, will attempt to register itself at regular intervals with a listener that is running locally on the same machine using port 1521. I have such a listener running but the service is not registered it seems. 

That tells me that the database registered itself dynamically correctly. prodbkp is my SID. This might be a case issue since I named the DB "PRODbkp" but everything else seems to be fine since I can connect with just fine. Case should not be an issue with service names as per docs.oracle.com tsnnames.ora 

That was difficult to figure out on my own. Research for the general error "Access Denied" in this context led to many different avenues but none that address my specific problem. Most stemmed from not using Reporting Configuration Manager to set up the service account. I did in my case and was able to verify the actions it took were done correctly. RsExec role, URLReservations using new account etc. I ran into a thread that said... 

This is happening because the server is responding but the mirroring endpoint is down. The partner and witness get a response from the OS that the port that the endpoint is on is closed and immediately starts failover. The timeout applies to when no response is received from the host as opposed to, "the port you're looking for isn't listening anymore," response. To get around this you'll either need to suspend the mirroring session as Max suggested or, if you're also concerned about unplanned cluster failovers, disable automatic failover as swasheck suggested and manually fail the mirror over when needed. 

The error is happening because the error being thrown part of a recompile error due to deferred name resolution. Looking at SQL BOL those aren't trapped when they happen at the same level as the try...catch. However, if it's happening at a different level, either as dynamic SQL or a SP call, then it will get caught and rolled back. Using Profiler you can see that the "alter table foo add x dog" statement recompiles before executing and then errors and bypasses the catch block. 

Which also looks OK. Most of the solutions point to SERVICE_NAME mismatches. However I don't appear to have one. v$parameter output 

According to post here and on SO it should just be an issue with the service name. Problem is it looks right to me. Listener.ora 

So it would seem the issue was not the service name specifically but that the request was going to the IPv6 address which was not set up in any of the required files. Looking at listener.log ( which for me was located D:\app\Administrator\diag\tnslsnr\dvp-oracle\listener\trace\listener.log) I found these entries associated to my connnection attempts. 

That gap you see above prodkbp is in the output as well. Not sure if that matters either. My production server has that anomaly as well so I can't imagine that has anything to do with it. Basically everything looks right but something is still wrong. I cannot install Enterprise Manager Environment 

Which made sense since I had changed the account that was being used. I simply deleted encrypted content to address that since it was a new SSRS instance anyway. The second error was the one that took me for a loop 

You can put the users in the db_ddladmin, db_datawriter, and db_datareader roles. This would prevent them from modifying permissions on the DB but either the db_securityadmin or db_accessadmin roles could be granted as appropriate keeping in mind that it's possible for db_securityadmin to be used for privilege escalation but db_accessadmin may not meet your needs. As always, test the setup before deploying it to production to make sure it restricts what you want it to while allowing what you want it to. If the goal is to prevent DB growth make sure autogrow is disabled on these databases. 

This is going to be one of those things you need to try for yourself to find what works best. Replication can be tricky so while there may not be a direct monetary cost there will be administrative overhead maintaining it. To expand on Log Shipping, you don't need to restore the logs every 15-30 minutes. If you choose, you can do it every four hours or once a day. A solution similar to this that I've implemented is doing a weekly full backup and restore to a reporting DB (which can take a while and happens on the weekend). During the week differential backups are taken and those are restored to the reporting database nightly. Users need to get booted before the restore but since the reporting DB is a business hours application there isn't an issue with that. Data is a day old which shouldn't be a problem based on your requirements. To use database mirroring for this you would need to purchase Enterprise to be able to use snapshots if you're not already running Enterprise. It also wouldn't keep the data 100% up to date since the snapshot needs to be dropped (meaning all users need to be out) and then recreated to get the new data. However, this would be less time than either log restores or the method I explained above. If upgrading to SQL 2012 is an option it's possible to set up a read-only secondary that will be kept up to date with the primary database. I only mention this because it's likely to be the smoothest solution. 

The important portion was . Since I would never need to support IPv6 I removed it from the network adapter and restarted the server to ensure all services were updated accordingly. While it might not be the ideal solution I was able to recreate the EM dbcontrol successfully after that change. 

I can connect to the db using and running shows the DB in question. So between that tnsping and I know the listener is at least running. does not appear to have an effect either. Not that it should matter since I should just have to wait a minute for it to work on its own. I then went looking for any PMON related logs. It should have been in the trace folder ($ORACLE_BASE/diag/rdbms/database_name/SID/trace/SID_pmon_PID.trc) with other trc files but it was not there. I then used the following query to verify where it should be 

I was having an issue getting SQL Server Reporting Services 2008R2 SP3 working under a domain service account on Windows Server 2008R2. It started with this What am I missing for my SSRS Service account local server permissions? and I have progressed from there some. I have a domain account setup as the service account for SSRS and the service is running. However on the /ReportServer and /Reports pages I am getting page cannot be displayed on my local server. Looking at the logs under "C:\Program Files\Microsoft SQL Server\MSRS10_50.MSSQLSERVER\Reporting Services\LogFiles" I saw two errors 

If you wrap the statements in dynamic SQL the error isn't returned to Profiler and the transaction is rolled back 

Right click on the database, go to Tasks and then Generate Scripts. That will give you the option to script it as one file or one file per object. You can also look into SQL Source Control from Red Gate. I haven't used it but I've heard good things from those that have and it does link with SVN. 

Document the details of how to reproduce the bug and submit it on connect.microsoft.com. I checked and couldn't see anything out there already that would be related to this. 

You can create a temp table and use it inside the dynamic SQL. I didn't go based off your code but this shows the concept: 

My reading of Books Online made me think that what you're doing is right since AdminSapr is in the db_owner role but in testing I had to do something like the above to get this to work. 

You could deny access to each individual view. The downside here is that any new views would allow alter unless you had a mechanism to deny permission such as a DDL trigger. Alternatively, you can revoke the alter command at the schema or DB level (this may require removing a DB role) and then grant access individually to tables via some mechanism. Another option would be to create a DDL trigger on all alter events. That trigger would check to see if the object being altered is a view via EVENTDATA and if it is make sure the logged in individual is someone with access either by a list of names or using sys.login_token to check for a domain group. If they're not then an error can be raised. 

As part of the troubleshooting I was doing to try and address the issue I ran Process Monitor while I was trying to start the service. I tracked as event that also had a result of "Access Denied" which was the service trying to read files inside the directory where reporting services was installed an running from. In my case it was: "C:\Program Files\Microsoft SQL Server\MSRS10_50.MSSQLSERVER\Reporting Services" I check the security of the folder and the service account I was using had no rights to the folder. That is why giving it local admin rights fixed it because that group did have access. I gave my service account Modify access to the folder and its contents. After that I was able to start the service. 

Much to my surprise that actually fixed the issue. My problem is that the documentation for account permissions on the SSRS account do not mention this permission is required. They only state that "Log On As A Service" is required. All my other SSRS environments, which I inherited, use a domain admin as the service account so I have nothing to compare to. I am trying to get away from that setup. Is this just a flaw in MS documentation or did I cover up the problem (XY)? I do not understand how "Bypass Traverse Checking" fixed "ERROR: Failed to initialize listener" 

Trace flag 834 can allow the maximum amount of memory to be allocated at startup for x64 machines. The following blog has more detail but here are the basics: Enterprise Edition needs to be installed 8GB of RAM or more needs to be present Lock Pages in Memory needs to be on. $URL$ Read the full article as there are caveats and warning spread throughout as this can lead to a much longer startup time (or failed starts). A big one being that it needs to allocate a contiguous chunk of memory and I'm not sure how that will work on VMWare. Also, if the physical memory in the host is 128GB I would reduce max server memory some more to make sure there's enough space left for VMWare to do it's thing. 

You can output the query results to file by pressing Ctrl+Shift+F if you're looking at one-off query. If you're looking for something you can automate you can wrap the query in Powershell or another scripting language and have that write the file.