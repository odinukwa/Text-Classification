You only ask about performance, but I want to point out anyway that there is a small error in the definition of : you used instead of . Now, let me get to the performance part. The thing making your code slow is that accesses to worksheets are expensive. Accordingly, they should be reduced to a minimum. Currently, you access each cell individually. A better approach is to load all on the same sheet in one go. You can do this by assigning the property, or better the property ( causes problems with fields formatted as dates.), of the used range to a variable. After that, the variable contains a two-dimensional array consisting of the values in the range. By comparing the values in corresponding arrays, you only need to access each sheet once to load the data and then for each time you find an error, in order to change the color. 

Finally, you could keep track of the row into which you pasted last. Then you could avoid querying Excel for the last row each and every time you copy rows. Now, I would like to add some general stylistic comments: 

It is a very good practice to give variables meaningful names. This helps the next reader of your code a lot trying to understand what the code is doing. In your case, it would make most comments unnecessary. E.g. you could use instead of and instead of . Moreover, If you load the columns into variant arrays, you can call the array for row 9 and that for column 12 . You should avoid to use the active sheet implicitely. You are referring to it with your calls to . This can lead to very hard to detect errors. Instead you could explicitly use it by writing or enclosing everything in a block and then using . Personally, I think the first alternative is better since the period can be overlooked or forgotten easily. You should also avoid to use default properties, like the property of the range object returned by . Using default properties does not only hurt the readability, it can also lead to obscure errors. Instead, you should use the property directly, or better when you are reading the data, especially when querying cells formatted as currency. These get crippled by . (Again, see this blog post.) Always declare your variables. Otherwise, they are implicitly Variant. In your code, and are not declared. To ensure that you always declare variables, you can add . Then you get a compiler error for undeclared variables. This has the added advantage that you cannot inadvertedly introduce a new variable by a typo. (Such bugs are very hard to find.) Get into the habit not to use underscores in method names unless there is a syntactic reason for it. This would be the case when writing an event handler or implementing an interface. The problem with underscores surfaces when using classes in VBA. You actually cannot implement a method of an interface if it contains an underscore. (This is a bug of the VBE.) 

Alternative Approaches Finally, I would like to present a completely different approach to your problem: to use the SQL support for Excel via ADODB. How to use it, can be found in this Microsoft article. Using it the output you seem to want could be produced with a SQL statement similar to the following. 

Although this question is slightly off-topic I will give you a run down of your code. I will start with some bugs in your code, then make some general remarks about the coding style, explain what is probably causing your code to miss duplicates and, finally, propose an approach that removes all duplicates in one go. Bugs The bugs I referred to above are that you frequently refer to cells on the instead to those on because you have omitted the dot in front. Style Now, let me say something about the coding style. 

Correctness First of all, I have some concerns whether your code actually does what you want it to do. Let me explain why I think this. 

You should indent your code properly. In your code the start and end of if blocks and loops do not match up, which makes it very hard to read. One of the best practices to improve readability of your code is to use meaningful names. E.g. does not tell you at all what it is. (It containing 'row' I would expect it to be a , but actually it is a . (I hope you declared it above the code you posted.)) As far as I can see it might better be called sometime like . If anybody else ever reads this again, or you in a few months, he will be grateful for the added readability. This is not a major concern here, but try to follow the single responsibility principle, which basically tells you that a unit of code should do one and only one thing. E.g. the first for loop could be its own sub called . In the With block variable you make an implicit reference to the . It is good practice to make that explicit. Generally, you should avoid implicit references and default members, because they hinder readability and hide subtle bugs. 

Let's start with your actual question, i.e. with reducing the loops. If you look closely, you can see that in 'Filter SSB CUSIPs' your second inner loop is independent of the surrounding loop. More precisely, nothing in the loop with parameter depends on . Accordingly, you can execute the loop for after that for . This would also result in the intended search order. Similarly, you can reduce loops in the other parts by extracting independent inner loops. Actually, you can get rid of many explicite loops by using the method. This returns the first match for a value in the range it is invoked on. If there is no match, it returns . A further way to improve the speed of the code would be not to use and but to read the values in the rows into a two dimensional array (best using ) and write them out from that array again. (See this blog post.) 

In your inner Do While Loop you delete the next row, but still increment . This means that you are skipping more and more rows. I think your intention was to always look at the next row, i.e. at . In the inner loop you do not check whether you are still in the same cluster. So, you will end up aggregating over different clusters if the addresses match. The inner loop does not depend on the middle loop. Since you delete rows, your outer loop will run past the last remaining row. 

For more help with the coding style you might want to have a look at Rubberduck. (Full disclosure, I am a contributer.) Potential Cause of Problems Now to what I think might be the problem with your code. When you are deleting rows, all rows below get shifted up. This makes you skip consecutive rows that should have been deleted. To solve this, always remove rows bottom to top. Alternative Approaches The approach I want to propose is to sort first by filename (Key1) and then by version (Key2). All you have to do then is to go from bottom to top and remove every row where the row below it has the same filename in the filename column. Because you sorted by version as the second key, only the highest version survives. Alternatively, you could use a , which requires a reference to VBScript, to store the highest version seen so far in a first pass over your data. (Use to see whether you have seen the filename before. If not, save the revision with the filename as key. If yes, compare the current revision for the filename to that in the dictionary and save it if it is higher.) In a second pass, from bottom to top, remove every row where the version is not the one in the dictionary. The second approach is faster for large data sets since you do not have to sort. However, if you want to sort the filenames anyway, as your example suggests, there is no real performance advantage. 

Looking at your code again, I see that it is actually not doing what you intend to do. The problem is that in 'Filter SSB CUSIPs' in the elseif the condition is just the opposite of that in the if statement. Thus, the else branch is dead code. Finally, if your tables are very big, you might consider to do a merge join instead of the two outer loops in 'Filter SSB CUSIPs'. More precisely, it might be good to load the first column of , and the tables and into arrays, sort these by identifier using your favorite n*log(n) sorting algorithm, and then step through them in order. 

After having a short look at your code, I get the impression that your database accesses in a double loop are the cause of the long execution time. First of all, it is generally much faster to pull all necessary data from a database in one go into memory and to assign the specific points of data to their correct place later. Moreover, to make optimal use of the database engine, you have to be cautious with conditions. Casting on a database column inside a condition, generally eliminates the possibility to use an index for fast access. Thus, most likely you will get a full table scan. Accordingly, you might want to think about how to change your date condition to eliminate the cast. The next thing I observe is that you close and reopen the database connection in the loop. Establishung connections is rather expensive. So, you should open it once, reuse it and then close it at the end of your procedure. Talking about the connection, you seem to execute all queries twice. There is no need to first open a record set and then execute the query again throwing the result away. You can simply set the result to the record set without opening it. Now, let me give some more remarks nit concerning performance. Your code could really benefit from proper indentation. With it how deep your queries are in the loops would be immediately apparent. Another thing that might be good for anybody maintaining the code would be to split it into several procedures and functions clearly separating the different jobs performed in this large procedure. With good names, this can help readibility a long way. There are probably a few more things but I will leave it at this. 

It is rather hard to understand what your code is doing because you heavily rely on default members, in particular on the default member of a , namely . It is not always clear what you are actually comparing. Your code could benefit from splitting it into logical pieces. Basically, everywhere where you have a caption comment you could extract the code following the caption into its own aptly named Sub and just call it. Another example is that you could extract a sub that handles copying the rows. This would remove quite some code duplication. In 'Remove lines with no identifiers' you can avoid the nested if blocks by using to combine the conditions. It is a good practice to use longer more expressive names for variables in favor of short unexpressive ones. This makes the code much easier to read for people without intimate knowledge of the code. 

Accessing a worksheet in Excel VBA is expensive. You should load as much as possible into the memory at once. To achieve this you can load an entire range into a two dimentional Variant array by assigning the property of the range to a variant variable, or better the property. (See this blog post for some reason to use .) You can write the array back to a range by assigning to the property of the range. If you go down this road, you will have to employ some collection to save the rows to delete for later. (When you remove the rows, you should do it from the bottom to the top as this guarantees that the row numbers of the remaining rows are preserved.) Your middle loop is redundant. This is the case because the loop body does not depend on the index variable . I think what you actually wanted to do is determine whether and only do one loop. (I already set and to 1 in accordance with my first comment from above.) You can save some redundant itterations by decrementing by 1 whenever you delete a row.