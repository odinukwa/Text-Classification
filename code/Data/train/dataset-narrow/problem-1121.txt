I was trying to create a function to delete the node at index from its current position and insert it after node at index from a . These container is logically a circular container of nodes, that is there's no actual first or last node, i.e. after comes . I really need this function not to have bugs and to be as performant as possible, so I'm asking here your help to a further check and for eventual suggestions to improve its performance. So, this is the function: 

I implemented a function to shift an element after another in a logical circular array. Shifting in this case simply means moving element at position to in front of element at position . Of course I can't simply swap the elements at position and , because I would alter the positions of two elements in this circular array. Here's the code I came up with: 

Now, this pseudocode is really easy and intuitive to understand, and I implemented very fast my "contains cycle" function using my adjacency list representation of a graph that I had implemented some time ago. Note that checking if is an edge in an adjacency matrix representation of a graph is a constant time operation, but not in an adjacency list, where the complexity of that operation is linear in the size of the adjacency list. Thus, with an adjacency matrix representation of a graph, the above algorithm runs roughly in O(n3) time, since iterating through the edges requires O(|V|2) and through the vertices O(|V|) times. On the other hand, using an adjacency list representation, the time complexity of the "contains cycle" algorithm is even worse, as far as I have understood, unless we can iterate through the edges in linear time with respect to the number of edges. We could do this, if we keep track of a list of all edges in the graph while constructing the graph, but I would like to avoid this, and try to find an alternative solution. The following is my implementation using Python 3: 

For the timeout detection, you could simplify your logic, by making use of the . Thanks to this, your timers are not needed anymore. Your monitor would then look like this: 

But as-is, the never finish, because the input channel is never closed. So we need to modify the computation functions to close the channel after the for loop. 

I would recommend Don't repeat yourself As you can see, the two branches of your are very similar. Instead you could do a 

This code code should work (I can't test it), but the way the "address" is managed could be more elegant (for example to manage in case of multiple listeners). Here is a proposition, where each listener is in charge of forwarding the frames to a particular address, via a given connection. The main loop is in charge of maintaining a slice of all those listeners and forward every frame to all of them (without blocking). With this code, we see clearly, that only 2 connections are used (monitor and session), which might not be the best idea (I don't know how they behave when concurrent goroutines write data at the same time). To fix this, you should simply adapt the main loop. 

Find the dictionary for the criteria you want to use (if you have multiple criteria). Pick a number from >0, <=(last value in the list) Find the block number: The index of the last entry in the list which is < the number you picked. Seek to that block - seek(blocksize*index), discard the first line (partial word). subtract the lookup for this block from the number you picked While the counter>0, Read through the file; decrease the counter for each match When your counter hits 0, the last line you read was the one you want. 

This way, you only have to read the index, plus (on average) half a block. Bigger blocks = smaller index, but more for the final search. Smaller blocks = bigger index, but you have less data to search through sequentially. Make sure the word list hasn't been changed since you made the index. 

index["6+"] = [0,0,3,4,7,9]. They are a running total, so will always increase. This means the first two blocks don't have any matches, the second has 3, the third has 1 more, and so forth. There are 9 matches in the entire file. I pick a random number from 1-9 (inclusive). I pick 8 (i.e the 8th word). The last entry < than my pick (8) is index["6+"][4] (which is 7). The number I want is somewhere in block 4. I seek to (blocksize*4), and read one (partial) line, which is really part of the previous block. The number of words I've already skipped is index["6+"][4], (which is 7). I subtract that from my picked random number, leaving 1. I read the file, counting down for each match. The match that makes my counter go to 0 (the first one in this case) is the one I want. 

Using the tips of the justforfunc #16 video, you could make your tests using a table ( = testing table) and then iterate on it ( = test case). Your test could then look like this: 

The key is the microserie and the value is the number of series done by the user. For microseries without any result, you will need a default value (0 here: . With a similar technique you can have the total number of microseries. 

I think that a recursion is quite elegant here (to know about the performance, you would need to do some benchmarks). Regarding your code, I would suggest some minor changes to make it more readable: 

go-torch beein able to generate a FlameGraph ($URL$ Here is a video introducing profiling in go: $URL$ 

"callback pattern" shouldn't be frowned upon (they are used in "first-class functions" for instance: $URL$ $URL$ However regarding your code, I don't think that it looks like idiomatic go code. 

Events Instead of adding 3 (permanent) , you could just keep the first one: and when this is triggered, add the 2 other events and on the document (it will also enalbe the user to move quickly) The event should then simply remove the 2 event listeners (you will need to keep a trace of the ). You can then get rid off the variable. The could be moved inside the constructor. moveCursor In the method instead of moving only if the new position is completely in the area, you could separately check the X and Y coordinates (It will then be easier to move near the edges). Naming I don't find the name to be very expressive... maybe is a better name? 

I implemented a invert-range operation in a (logical) circular vector. A circular vector is a vector without a logical starting and ending object, or, equivalently, the successive element of the element at the last index of the vector is the element at index 0 (similarly for the previous element). I'm not 100% sure it's correct. If it's correct, any suggestions to improve it (especially in terms of performance)? 

I have a graph represented as an adjacency list. I need to find a triangle in this graph. A triangle is a triple of vertices , and , such that , and are edges of the graph. The graph does not necessarily needs to be undirected. I found the following pseudocode for solving the problem: 

I have implemented a "infix-to-postfix" function that takes as input a list representing the parsed expression, resulted from applying a certain regular expression to an expression, and I would like to have your opinion regarding its correctness and efficiency. Good suggestions are of course more than well-accepted! For making you able also to test directly my algorithm, I decided to include also the regular expression and other important details. 

Please, don't tell me anything about the docstrings, because I actually removed them from my code to make it clearer. In general, I prefer efficiency to clarity, so I am not so interested in list or generator comprehensions if they don't make the code more efficient. Anyway, you could also suggest them, if you feel that they would turn the code more "pythonic". 

A minor refactoring might be to put the statement out of the loop. It makes a real uses of the and remove an indentation block. 

A buffered channel is just a way to allow goroutines to be more independent when they are producing/consuming a channel. 

edit regarding the performance I don't see simple changes which could drastically improve the speed. There are some minor changes (from looking at the source of ): 

But joining paths like this is not very pythonic (and might cause problems on windows). Instead, is what you are looking for. About the arguments You can take inspiration of the os.path.join even further and change the order of your arguments (and completely remove the branching): 

I find your variable naming quite good (but it took me time to really understand the goal or your code). Code simplification I consider that should only contain the results of the user (or better: its assessments): 

Readability To ease the readability (and testability) of your code, I would recommend you to split it in multiple functions communicating via multiple channels. For instance, for the client: 

vnp and Peter Taylors suggestions are very good. One could go a step further and make nice methods on the type: , and for instance: 

2 more options to consider. I suspect these aren't relevant here (though nothing in your post rules it out), but they are worth keeping in mind. Put your data in a database, have all the work done for you. Databases are REALLY GOOD at what they do. If you think a database has too much overhead, consider sqlite - tiny footprint, all the advantages of a database, and if you want to move to a different database later, it's easy. If you're always looking for 7 letter words, extract those into a file. Then all the words you don't want, don't have to be processed. Optionally, you can make your target file fixed length records (at least the size of the longest word!). For example, if your longest word is 23 bytes, pad all your words out to 23 bytes with spaces. Adding a new line (optional) would increase this to 24 characters. Then, if your file is 2,400 bytes long, you know you have 100 records; pick a number from 0 to 99, seek to that position * 24, and read your word. Don't forget to trim(), and beware of the difference between letters and bytes in multi-byte encoding! 

In your main, you "iterate over generators to create values for each key". You could actually create a "base" generator for this! It would be an array generator (10 elements, 0 nullPercentage) of objects (being the objects that you generate). Using @ferada's answer leads also to much less code (I also renamed to ). It uses embedding (one could further optimize, by using the as base - instead of ). There was a typo on the function : it should be and not (because returns between 0 and 99 included). Here is what I come up with: 

I think having a at the very end is also nice to quickly check the type of result returned by the function. 

The method could also be faster if it didn't use . For instance, it could use the last 7 bits (from 0 to 127) of (or multiply the probability by 10 and use the last 10 bits - from 0 to 1023). But there is probably a bigger optimization regarding the generation + insertion in the database. Currently the data is generated and inserted into the database sequentially. You could do it concurrently with a channel and two goroutines: