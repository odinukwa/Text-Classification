Another thing that is often done in games with this sort of feature (especially with music rather than color) is to change the background over time. That is, when the color changes significantly you interpolate to the new color at a fixed rate over time rather than taking it only from the player position. This can be added to the above process as a final step of computation, if you want it. 

The addition and subtraction of π (a half-turn) combined with modulus puts the difference-between-angles in the range −π…+π, which is the “smallest amount to match” property. Note that if you are implementing, for example, a turret, then this might be undesirable as it makes it harder to strafe a particular arc as the player needs to make sure not to lead too much. The joint should follow the motions of the stick. That is, if the user quickly makes multiple revolutions of the stick, the joint will follow and make multiple revolutions even if the user's movement is long over. To implement this, the logic is the same as above except that instead of using the joint's current actual angle, we use the joint's target angle (which can be simply a variable/field in your program, unrelated to the physics engine) as the state input. 

is a point which is at step along the straight line between and . This is just like linear interpolation in disguise. was divided by so that the last loop iteration, where , hits the end point exactly. 

This is a general algorithm for 2D rectangular chunks and a 2D rectangular camera view. It sounds like in your case your chunks are larger than the camera, so you always have at at most four chunks visible; this could simplify things, but I recommend using this algorithm which avoids having any special cases until you're more confident in how to tweak things. Note that this algorithm does not care how the camera is moving, or when it crosses a boundary. It only makes sure that the current frame is drawn correctly, regardless of what happened before. (I suspect trying to make use of the previous position/movement is part of your original problem.) This also means that it can handle arbitrary movement like teleporting or respawning. 

Any time there is no movement in progress, check the movement keys' state and start another movement if one is down. (If you only have key events, then remember the last one seen for a movement key.) This is sort of like "ignoring input", but note that it will not ignore a key which was pressed before movement finished but is still down when it does finish. Any time a movement key is pressed, remember its direction. Any time there is no movement in progress, use the single recorded keypress to start a new movement. 

If you want to get a cube map texture starting with that image on disk, then just extend your texture loader to slice up that image into individual cube map faces! 

Since you ask about bad practices: you have massively repetitive code and magic numbers. Take out that recurring 8 and use local variables to hold relevant values: 

As user Fabinout already commented: “Splitting the object in two … The upper part is behind the character, and the lower part is between the player and the character.” If you are making a rigidly tile-based game (the shown paths are the only two possible paths near the wall), this is likely a fine way to do it. Note that for this to work, the distance between the upper and lower paths must be at least as much as the height of the character. A disadvantage of this method is that it only helps with cases like this particular one; it's not a general strategy for stacking sprites. Draw all sprites — both the player and the scenery — from top to bottom in order of their “ground level” positions (base of the wall, player's feet). This will automatically cause the wall to be shown on the correct side, and is a common strategy for “isometric” and “2D RPG” styled games. Another advantage of this is that it generally looks good even if objects pass through each other — e.g. characters that don't block others' movement; walking through a field of tall grass. Disadvantages are that you need to efficiently determine the drawing order (e.g. either sort your sprites, or have an 2D array of tiles which know what sprites are in them) and that it gets complicated when you have objects which are not all visually rooted on the same ground level. Have a “front layer” and “back layer” where your character occupies one or the other (and the wall is drawn after back but before front). Depending on how you approach the wall, the character gets switched to the front or back layer by trigger zones. This is how Sonic the Hedgehog games handle things like loop-the-loops. The advantage is that you can have essentially two independent 2D planes to build your level elements on. However, this is more appropriate for a game where vertical motion is jumping up, whereas from the shape of your graphics, your game appears to be one where vertical on-screen motion is moving front/back on the ground, and there are far more than two different positions in that dimension. 

More general advice: Remember that your rendering executes on two processors: CPU and GPU. When your frame rate is insufficient, then one or the other is the limiting resource — your program is either CPU-bound or GPU-bound (assuming it isn't swapping or having scheduling problems). If your program is running at 100% CPU (and doesn't have an unbounded other task to complete), then your CPU is doing too much work. You should try to simplify its task (e.g. do less culling) in exchange for having the GPU do more. I strongly suspect this is your problem, given your description. On the other hand, if the GPU is the limit (sadly, there aren't usually convenient 0%-100% load monitors) then you should think about how to send it less data, or require it to fill fewer pixels. 

It also looks like your collision logic depends on the ball being just at the edge (its center being within but outside the brick itself) to determine collision direction. This could miss collisions. It would be more robust to, once you've decided a collision has occurred (the two outermost s as they are), write logic which decides which direction the collision was and always gives one answer under all circumstances (never "both horizontal and vertical" and never "neither", which are both possible with your current logic). 

If you are really working with single-pixel tubes with tight corners and want to produce a single-pixel glow as your example suggests, then your problem more closely resembles a tile-based graphics problem — choosing transition tiles — and you should approach it that way. 

(Expanding on my older comment...) From observation while playing the game, I believe that Minecraft's lighting works in the following way: 

Perform the translation in your vertex shader. You must either have a parallel array which contains the translations for each vertex, or store the translations in a texture which you lookup in using some attribute of each particle. (Note: Answering as if for WebGL; I have no actual GL ES experience.) 

You don't show how you adjust the scale, so this is speculation. If you scale an object relative to the camera (or its initial position) as center point, there will be no visual change but speed of motion will necessarily be slower relative to the scale of the object, so your results are to be expected. To strengthen the impression of size, add other things which provide a scale to compare to, such as: 

You are looping through the enemies effectively from right to left. Every time the leftmost enemy hits the left side, it changes the movement direction, then moves according to the changed direction whereas the previous ones did not. To fix this, defer the change until the end of the frame. There are many ways to do this; one is to have a second variable which stores the movement direction for the next frame, which you copy to the current direction variable at the beginning or end of each frame. Another way would be to have a queue of deferred events which are dispatched after the enemies are looped through; this might be useful if you have many pieces of state that need treatment like this. 

However, a more typical solution, on reviewing what I know of platformer physics, is to make the player a more highly rounded shape, and leave the terrain alone. In particular, consider making the player's shape a capsule (stretched-in-the-middle circle (2D)/sphere (3D)) — then your collision normals will naturally be nearly vertical, eliminating any catching problem. You say you're using a collision algorithm specifically for OBBs, but you should still be able to, after finding an OBB-OBB collision, use a further test against a shape which is entirely within the OBB. 

[Moved from comment on request and expanded.] I don't know what the actual problem is, so here's some advice on troubleshooting lighting. Are you sure the light position is such that the specular reflection should actually be visible on that (apparently) flat square? Most ‘shiny’ objects are curved and so have greater opportunities to have a visible specular ‘hot spot’. I suggest instead testing with a sphere or other highly curved geometry to more completely display the effects of your lighting. 

You have six vertices (correctly) but only four texture coordinate pairs, so the last two are undefined. You must specify matching texture coordinates for each vertex, including the repeated ones. 

For each attached neighbor, a linear spring force based on the difference between this block's displacement and its neighbor's displacement. A gravitational force, scaled by the total mass of this block and every interior block directly above (opposite to gravity) this block (e.g. count how many solid voxels a ray cast upward traverses before hitting an upper surface; apply a 'cone' correction if you're feeling fancy). 

Your 'elasticity' should be removing energy from the system so that it settles down. The first thing that comes to mind given that that isn't working, and that you mention measuring in pixels, is: make sure that your velocity is floating-point, not an integer. If that isn't the problem, then the first thing I would do to debug is calculate the energy (ignoring mass) of the ball: . If your units are right and your simulation is good, this should slowly decrease with each bounce. If it doesn't, then the bounce is a problem. If it increases continuously while not bouncing, then your basic simulation step is wrong. 

If none of the above is what you meant, then I recommend clarifying your question. Even the roughest of actual prototype graphics or even freehand sketches of what you're trying to achieve would help greatly. 

Vertices: Every triangle you submit to OpenGL must be checked against the view frustum. If you send geometry which is out of view, it still must be transformed (by your vertex shader) to find out that it is out of view. The more vertices in your scene, the more useful it is to cull vertices in your code before sending them to the GPU. If this is a bottleneck for you, then (since you are using a tiled scene) you should break up your scene into chunks of several tiles, each of which is a separate VBO, and skip ing them if they are outside the view frustum. You asked: “is there any point in submitting the vertices for an object that may not be visible?” You should only do so if you find it is more expensive to do a test for whether they are visible than it is for the GPU to do so, or if they are (usefully) bundled together in a VBO that it would be inefficient to be adjusting all the time for new visibility. Faces: You should remove the redundant faces that face toward each other; OpenGL doesn't know you're not going to be doing transparency in your shader, for example, and will fully process all of them. Keeping these redundant faces will waste both vertex and fragment processing capacity. is only relevant to removing the back-sides of triangles; it does nothing for obscured front sides and still requires the vertices to be checked, but it does allow skipping the fragment stage for that face. Fragments: After the GPU has decided a triangle needs to be drawn, every pixel (fragment) in it needs to be processed individually (for texturing and other effects). At this point, the best you can do is order your data so that nearer-to-the-camera geometry is rendered first (e.g. render the mud before the rock), allowing the depth buffer test to skip full fragment processing. It is worth noting that one of the easiest ways to bog down a GPU (due to insufficient fill rate) is to have many large triangles covering large areas of the screen; this could happen, for example, if the player zooms in on a complex multi-layered tile and you're either doing transparency or unnecessarily rendering obscured layers. 

Note that the rear box of the front car (whichever one that is) is behind the front box of the rear car, so the contact points generated will be facing the wrong way. On the other hand, if you make them out of two intersecting boxes, then there are no such inward faces: 

Don't copy all the data; just collect the visible chunks and render each one. It sounds like you considered this: 

Looks to me like a lack of a depth buffer, so that the cylinders are being drawn on top of each other in the order you supply them, rather than according to their depth on screen. I don't know XNA so I can't advise you as to specific programming, but make sure that when you create/request your context (?) you request that it has a depth buffer. 

is the key ingredient you didn't have: it points perpendicular to the line between the start and end points, and is what we use to displace the points according to the sine function. (Linear algebra side note: If you combine and as the columns of a matrix, then that matrix is the transformation matrix of a rotation matching the orientation of the line!) 

What you aren't showing is how the cubes' falling translation is applied. From your description of the effects, it is occurring after the rotation; so you are either translating in or updating the etc. coordinates. The "graphics" fix to your problem is to apply the falling motion before your . However, this would be setting yourself up for bigger problems. You are eventually going to want to collide your cubes against the rest of the objects in the playfield so as to know when to stop them and remove rows etc. Just rotating in the rendering isn't sufficient to handle that. Therefore, you are going to want to compute the rotation yourself, not delegate it to OpenGL. My recommendation would be to actually change the configuration of the cubes — that is, change , , and according to the rotation. Since you are only doing 90° rotations, this is especially simple. This means your collision tests do not have to think about rotations. (If this does not seem to be an appropriate answer, then please update your question with details of how you are animating the falling.) 

Generally, you should not “cull” physics updates in your game with respect to the screen, except perhaps to a very limited extent — things not moving when they are off-screen is now seen as archaic. What you need to do instead is make the updates more efficient. You state that you have tile-based liquids. I assume they are flowing around by checking their neighbor tiles and converting those into liquid tiles, or other similar local rules. Here is a technique for optimizing such updates which saves time when most of your liquids are stationary, but the environment will sometimes change to allow it to flow. 

(Note that these are not actual forces, because this model does not include velocity. If I'm not confused, this should basically work as if the system is extremely damped.) 

Then the overall algorithm is that you apply the first function for each system, and feed the results into the second function, and that's your background color. Different functions produce different effects; the reason I've specified the above design is because it allows you to experiment with the specific results without needing to design new algorithms, just simple arithmetic. 

The difference between what you have and a normal maze is simply that it has non-adjacent connections vertically. I think that what you should be looking at are graph-based maze generation algorithms. You simply need to have a larger set of "adjacent rooms" or "possible walls" than an ordinary 2D maze does, in that every vertically aligned pair of floor-grid-cells which does not already have an intervening lift is adjacent. You could model this as a graph where adding definite lift edges incidentally deletes other possible lift edges; some algorithms might be confused by this, but not others.