We know that Maximum Independent Set (MIS) is hard to approximate within a factor of $n^{1-\epsilon}$ for any $\epsilon > 0$ unless P = NP. What are some special classes of graphs for which better approximation algorithms are known? What are the graphs for which polynomial-time algorithms are known? I know for perfect graphs this is known, but are there other interesting classes of graphs? 

Suppose we are given two graphs $G$ and $H$, where $H$ is a subgraph of $G$. What is the maximum number $k$ such that if any $k$ edges are removed from $G$, $H$ still remains a subgraph of $G$? What about the same question when edges are replaced by vertices? A generalization is to consider weights on edges/vertices and ask for maximum weight edges/vertices. I want both a bound as well as an algorithm. This problem is NP-hard as subgraph isomorphism is a special case of it. Any papers on this problem will be helpful. 

Can any tree on $n$ nodes be decomposed into a set of $O(\log n)$ caterpillars? If not, what is the maximum number of caterpillars required? Are there efficient algorithms for finding the decomposition? Any papers on this topic will be highly appreciated. 

The divide and conquer algorithm by Michael Shamos to solve the planar Closest pair of points problem in $O(n \log n)$ time. Not only is this optimal in the algebraic decision tree model of computation, it also illustrates the power of recursive thinking in a non-trivial setting. 

It is $W[1]$-hard even when $G$ has maximum degree $3$, but $FPT$ if $G$ has constant treewidth (all the above examples have constant treewidth). See the paper Everything you always wanted to know about the parameterized complexity of Subgraph Isomorphism (but were afraid to ask) by Marx and Pilipczuk. Indeed, it follows from an earlier paper of Marx: Can You Beat Treewidth? Theory of Computing 6(1): 85-112 (2010) that a $f(k)n^{o(k/\log k)}$ time algorithm would violate the ETH. Here $n$ is the number of vertices in $H$ and $k$ is the number of vertices in $G$. This holds even when $G$ has max degree $3$ (but the degree of $H$ is unbounded). 

Start from the partition problem and let $a_i' = a_i * 100n^2 + 2*i + 1$. Also add in new elements $b_1', \ldots b_n'$ with $b_i' = 2i+1$. All variables are odd and distinct. For the forward direction, suppose there is a partition of $\{a_1, \ldots a_n\}$ into two sets $L$ and $R$ such that $\sum_{a_i \in L} a_i = \sum_{a_i \in R} a_i$. Set $L' = \{a_i' : a_i \in L\} \cup \{b_i' : a_i \notin L\}$ and $R' = \{a_i' : a_i \in R\} \cup \{b_i' : a_i \notin R\}$. This is a partition with the same sum in $L'$ and $R'$ For the reverse direction, suppose there is a partition of $a_1',\ldots, a_n', b_1', \ldots b_n'$ into $L'$ and $R'$. Set $L = \{a_i : a_i' \in L'\}$ and $R = \{a_i : a_i' \in R'\}$. It is easy to verify that the sum in $L$ and $R$ is the same - since otherwise the sum of $\sum_{a_i' \in L'} a_i'$ and $\sum_{a_i' \in R'} a_i'$ differ by at least $100n^2$ and the $b_i'$s can't compensate for this. 

Suppose, we are given a graph $G = (V,E,d)$, where $V$ is the set of vertices, $E$ is the set of edges, and $d$ is a distance function $d: E \mapsto \mathbb{R^+}$. Let $S$ be the set of source vertices and $EX$ be the set of exit vertices in $G$. Further, we are given the integers $k, \gamma$ and $\delta$. A $(k, \gamma, \delta)$-hub is a set of vertices $H \subseteq V \setminus (S \cup EX)$ such that: 

In the paper Randomized Primal-Dual analysis of RANKING for Online Bipartite Matching, while proving that the RANKING algorithm is $\left(1 - \frac{1}{e}\right)$-competitive, the authors show that the dual is feasible in expectation (see Lemma 3 on page 5). My question is: 

Please list here all the books on Online Algorithms that you may know. If there are any books freely available on the web, that will be great. 

The Perron–Frobenius Theorem states the following. Let $A = (a_{ij})$ be an $n \times n$ irreducible, non-negative matrix ($a_{ij} \geq 0, \forall i,j: 1\leq i,j \leq n$). Then the following statements are true. 

This problem is closely related to the graph coloring problem. The problem is to color the vertices of a $k$-colorable graph with as few colors as possible. The following vector program is a relaxation of the graph coloring problem. $$minimize \qquad \alpha \qquad \qquad \\ subject \ to \quad v_i \cdot v_j \le \alpha \quad \; \; \, \forall (i,j) \in E \\ \qquad \quad \ v_i \cdot v_i = 1 \quad \quad \forall i \in V \\ \qquad \qquad \quad \ v_i \in \mathbb{R}^n \quad \forall i \in V$$ The claim is that $-\frac{1}{k-1}$ is the minimum possible value of $\alpha$. 

There is a nice trick to reduce $\geq k$ cycle to finding a cycle of length exactly $t$, for $t \leq 2k$ (I first heard of this trick from Daniel Marx). The key observasjon is that contracting an edge of $G$ may not increase the length of the longest cycle in G, and may only decrease the length by a factor at most two. Thus we can search for cycles of length exactly $t$ for $k \leq t \leq 2k$. If no cycle is found, contract an edge and repeat. This shoukd be quite a bit faster than the treewidth based algorithms, I believe, especially if you use the sieving methods for finding t-cycles (paths). There are very efficient implementations for $k$-path by Bjorklund et al: Fast Witness Extraction Using a Decision Oracle, with Andreas Björklund and Petteri Kaski Proc. 22th Annual European Symposium on Algorithms (ESA 2014), LNCS 8737, 2014, pp. 149-160. This should be adaptable to your problem. 

For question $1$: any bidimensional parameter has this property on general graphs. A parameter $s(G)$ is bidimensional if the value of $s(G) \geq s(H)$ for every minor $H$ of $G$, and if $s$ is ``large'' on grids. In applications to PTASes, sub exponential algorithms and kernels on minor-free classes of graphs, "large" means that there exists a constant $c$, such that the value of $s$ on a $t$ times $t$ grid is at least $ct^2$. This is what you most likely will find if you do a google search for ``bidimensionality'' However, for your question it is sufficient that $s$ grows to infinity on $t$ times $t$ grids as $t$ grows to infinity. This is because any graph with large enough treewidth will contain a large enough grid minor. So, to conclude, if s: 

The Unsplittable Flow Problem (UFP) remains NP-hard on a path. Indeed, UFP is NP-hard even on a single edge, as it is equivalent to the Knapsack problem. 

But the theorem does not say how fast the sequence of vectors $A^k x^{\langle 0\rangle}$ will converge. Are there any known results on the rate of convergence? What are some good, polynomial-time algorithms to compute this limiting vector? 

It is one thing to show that the expected value of the objective function is something. But if feasibility constraints are satisfied in expectation, there is no guarantee that it will be satisfied on a given run. Moreover, there are many such constraints. So what is the guarantee that ALL of them will be satisfied on a given run? 

Networks, Crowds, and Markets: Reasoning About a Highly Connected World by David Easley and Jon Kleinberg. $URL$ 

I am interested to know the structure of random graphs generated by the preferential attachment model with degree bounds. Specifically, when a vertex is chosen with a probability proportional to its degree, the edge is added if and only if the degree of the vertex does not exceed some upper bound. What will be the vertex degree distribution of such a graph? What will be the size of the largest (giant) component, diameter and the average path length? Any reference will be highly appreciated. 

Expanded from my comment: It would be very surprising if some problem where the graph is the only input (i,e no lists / weights, etc) is W[1]-hard when parameterized by Vertex Cover, because instances with a vertex cover of size $k$ can be encoded with $2^k \log n$ bits, so a reduction from $k$-Clique to the problem would have to compress $n^2$ bits to $2^k \log n$ bits in FPT time. I would speculate that it is possible to use the incompressibility result of Dell and van Melkebeek for the Clique problem (in essence that no polynomial time procedure can reduce the input to $n^{2-\epsilon}$ bits) to prove that a polynomial time reduction showing W[1] hardness parameterized by Vertex Cover of any parameterized language where the graph is the only input would imply $coNP \subseteq NP/poly$. 

If you could perfectly generate mod $3$ OR solve SAT (or any other NP-complete problem, for that matter) then $NP = coNP$. In particular, consider the perfect generator / solver when given a SAT formula $\phi$. Let $\ell(n)$ be the maximum number of random bits drawn by the generator on inputs of size $n$. Since the generator runs in polynomial time, $\ell(n)$ is polynomial. Since $2^{\ell(n)}$ is not divisible by $3$ there must be some sequence of at most $\ell(n)$ coin tosses that will make the generator output a (correct) answer for $\phi$. Thus, if $\phi$ is unsatisfiable, there is a set of coin tosses that make the generator say that $\phi$ is unsatisfiable. If $\phi$ is satisfiable then the generator will never wrongly claim that $\phi$ is unsatisfiable, no matter what the coins are. Thus, we have shown that the language $UNSAT$ of unsatisfiable formulas is in $NP$, implying $NP = coNP$. 

Foundations of Data Science by John Hopcroft and Ravindran Kannan. It's an amazing book on Algorithms for Big Data Analytics. They call it the 21st century algorithms. 

Intuitively, a hub is a small set of vertices such that for any source vertex, there is a short path to some exit through an intermediate hub vertex. An optimization problem is: given $\gamma$ and $\delta$, find the minimum $k$ such that there exists a $(k, \gamma, \delta)$-hub (or show that none exists). This problem is likely to be NP-hard, but I could not find a reduction from an existing NP-hard problem. Is there any known hardness result or approximation algorithm for this problem? 

Can we multiply two arbitrary $n$-bit numbers in $O(n)$ time? There is a trivial lower bound of $\Omega(n)$, but no better lower bound is known. The asymptotically fastest algorithm was given by Schönhage–Strassen, which runs in $\Theta(n \log n \log \log n)$ time. They also conjectured a lower bound of $\Omega(n \log n)$. A recent algorithm by Martin Fürer runs in $\Theta(n \log n \; 2^{O(\log^{\star} n)})$ time, where $\log^{\star} n$ is the iterated logarithm of $n$. Even an algorithm with running time of $\Theta(n \log n)$ will be a big breakthrough. 

Suppose, we are given a set of $k$ unit vectors $v_1,\ldots,v_k$ in $\mathbb{R}^n$. Consider all possible dot products among distinct vectors $v_i \cdot v_j$, where $i \ne j$. Let, $$\alpha = \max_{1 \le i <j \le k} \{v_i \cdot v_j\}.$$ What is the minimum possible value of $\alpha$? 

What you call a non-reducible vertex cover is commonly known as a minimal vertex cover. So, what you are looking for is a minimal vertex cover of maximum cardinality, i.e a maximum minimal vertex cover. I'm not aware of any literature on this problem per se, however the equivalent Independent Dominating Set problem is quite well studied. An independent dominating set in a graph $G$ is an independent set $I$ such that every vertex not in $I$ has a neighbor in $I$. In the Independent Dominating Set problem input is a graph $G$ and the task is to find a smallest possible independent dominating set. This problem is known to be NP-complete. The two problems are equivalent because a set $S$ is a minimal vertex cover if and only if $V(G) \setminus S$ is an independent dominating set. 

Let $A$ be any language not in $L$, such that $A$ has density $2^{o(n)}$, and define $$B = \{s \circ 1 | s \in \{0,1\}^*\} \cup \{s \circ 0 | s \in A\}.$$ Here $\circ$ is concatenation. The language $B$ has density $\Omega(2^n)$, which is superpolynomial in $2^{o(n)}$. On the other hand, $A$ and $B$ log-space reduce to each other ($A$ to $B$ by concatenating $0$, and $B$ to $A$ by reducing all strings ending in $1$ to the smallest yes instance of A, and removing the last bit from all strings ending in $0$). Hence $B \notin L$ as well. 

The multicut problem is the following. Given a graph $G=(V,E)$ with edge costs $c_e$ for edge $e$ and a set of $k$ terminal pairs $\{(s_1,t_1),\ldots,(s_k,t_k)\}$, the objective is to find a set of edges $F \subseteq E$ of minimum cost, such that in the graph $H=(V,E \setminus F)$, no terminal pair $s_i,t_i$ are in the same connected component. In other words, deleting the edges in $F$ will remove all paths between any terminal pair $s_i,t_i$. This problem is NP-hard. For general graphs, an $O(\log k)$-approximation is known. For trees, a 2-approximation is known. It is also known to be APX-hard. Is there any other results known for special classes of graphs? I am particularly interested in the following graphs, but other classes of graphs will also be informative. 

The multi-terminal cut problem (which is also known as the multiway cut problem) has many important applications. In the more general setting, each edge $e$ has a cost $c_e \ge 0$. The goal is to remove a minimum cost set of edges such that in the resulting graph there is no path between any two vertices in $T$. Here is an application in distributed computing. Each vertex represents an object, and an edge $e$ of cost $c_e$ between them represents the cost of communication between the objects. The objects have to be partitioned to reside on $k$ different machines, with special object $s_i$ residing on the $i^{th}$ machine. The goal is to partition the objects residing on the $k$ machines in such a way that the communication cost between the machines is minimized. 

Then s has the s-treeewidth property. See the recent parameterized complexity book ( $URL$ ) in the treewidth chapter for more info. 

There are good reasons to expect that there is no polynomial time reduction that takes as input a graph $G$ and outputs a graph $\hat{G}$ such that $\omega(\hat{G})$ depends only on $\gamma(G)$. In particular the Clique problem is complete for $W[1]$ while Dominating Set is complete for $W[2]$, see the Wikipedia page for Parameterized Complexity. A reduction from Dominating Set to Clique where the size of the clique only depends on the size of the dominating set would imply that $W[2] = W[1]$, which is considered unlikely. On the other hand it is not too hard to make a reduction where $\omega(\hat{G})$ depends only on $\gamma(G)$ and $|V(G)|$. For every edge $uv \in G$ make two vertices $[u,v]$ and $[v,u]$ in $\hat{G}$. For two vertices $[u_1,v_1]$ and $[u_2,v_2]$ of $\hat{G}$ we put an edge between them if $u_1 \neq u_2$, $u_1 \neq v_2$ and $u_2 \neq v_1$. We claim that $\omega(\hat{G}) = |V(G)| - \gamma(G)$. The intuition is that the vertex $[u,v]$ is interpreted as ``$u$ is dominated by $v$''. Then each vertex of $G$ not in the dominating set should choose exactly one vertex in the dominating set to dominate it. Someone who has chosen to be dominated may then not be a dominator. Consider a dominating set $S$ in $G$. We make a set $\hat{S}$ as follows: for each vertex $u \notin S$, pick an arbitrary neighbor $v \in S$ of $u$ and add $[u,v]$ to $\hat{S}$. Clearly $\hat{S}$ is a clique of size $|V(G)| - |S|$. On the other hand consider a clique $\hat{S}$ in $\hat{G}$. Let $S$ be the set of vertices $u$ in $V(G)$ such that there does not exist a $v \in V(G)$ such that $[u,v] \in \hat{S}$. Observe now that $|S| \geq |V(G)| - |\hat{S}|$, since each element of $\hat{S}$ rules out at most one vertex of $G$. Consider a vertex $u \notin S$. There must be some vertex $v \in V(G)$ such that $[u,v] \in \hat{S}$. We know that $uv \in E(G)$, it remains to show that $v \in S$. Suppose not, then there must be some $v' \in V(G)$ such that $[v,v'] \in \hat{S}$. But $[u,v]$ and $[v,v']$ are non-adjacent in $\hat{G}$, contradicting that $\hat{S}$ is a clique. So $S$ is a dominating set.