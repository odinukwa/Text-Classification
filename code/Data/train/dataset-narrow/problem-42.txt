Image 1: Constraint solver in action, red constraints are fixed while blue ones are free to change. There are several ways how the solver might work, it could be a numeric nonlinear based on gradient descent. Or it can be fully algebraic. Usually its a gradient descent solver as this is easier to implement, and possibly faster. 

No, most likely these kinds of displays do not exist, at the time of writing this post. Although the negative is hard to prove. And in this case i don't have deep enough understanding of the lore. Reason for me saying this is that usable displays need some serious miniaturization. The miniaturization process is quite expensive and requires some serious investment. There should be quite massive patent trail if this was indeed true. So we should look in patent databases for this trail. Second, having such tech probably will not yield full color space, at least initially. Because the filter can only filter out colors that the back light can generate. Most probably therefore this is some kind of projector technology at first. Also filters probably have a practical limit to how much they can be tuned. Third, if/when such tech is available it must recuperate the development cost by selling enough units to overcome the capital investment. There is a likelihood that this is one of those things that can not be produced without the miniaturization step like digital cameras. So keep a lookout for a killer application for this tech. Some major downsides of this kind of tech is the fact that you filter out light. This means it eats up part of the energy input. This leads to a heat dissipation problem, which for perfect narrow band filters is actually pretty huge part of the emitted light. Lot of energy goes wasted, and needs to be engineered around. 

Image 1: Starting point. The geometry in this case is a BÃ©zier curve although if somebody has solutions for any functions or higher order curves would be fine. So in essence im open to conics and NURBS also. 

The inverse coordinate is not entirely trivial in all cases. But basically, for a basic triangle mesh with nothing exotic and has non overlapping UV's, you need something like this: 

How to accelerate the triangle finding. You can do a a sweeping search in O(log(n)) time. You can also use a a bsp tree to do much the same. This would produce a O(m*log(n)) algorithm where m is number of samples and n triangles. Sounds good. Wait, we can do better! What if instead of baking each pixel in order we bake each triangle in order. Then you dont have to go find the triangle. Finding the points in a triangle should be trivial. So you get something more akin to a theoretical O(m) algorithm. Which should be both conceptually easier and at least theoretically faster as you eliminate step 1. Also in the second case you can forego barycentric calculation if you so wish and use an alternate formulation if you wish. 

Yes, this is essentially the same problem that occours in paralax mapping. What you basically have is a colored height field. That needs to be rendered from a second view. There are several ways in which you can approach this. You could cheat and just shift pixels by their depth and ignore occlusion. Or you could just render a textured height map as if every pixel would be opaque. Or you could use any of the available paralax mapping methods to eliminate occlusion. How well this works depends on the. A scene multiple transparent surfaces wouldnt work very well without some deep map. 

When you have a curve you can adjust the knots so that they lie on top of each other. This is essentially a bit like having several control points on top of each other, except there's only one point. This is sometimes known as multiplicity or duplicity. When you have as many knots on top of each other as you have degrees in the curve smoothness, you end up with a cusp, also known as as sharp corner. Once you have a sharp corner you can just go and delete the points on the opposite side as they no longer affect points no the other side of the corner. 

Image 1: Flying very close to a sphere looking slightly sideways. Notice how we suddenly puncture the surface form inside. So to recap when the sphere is very close so it exits the picture in wide image it can be a parabola or hyperbola. But the shape will just exit the frame to do so. 

Image 1: Blend between 3 curves, not closed but same principle applies. Open curves are easier as they clearly define the boundary conditions. (software used is Creo because that's what I had open) You usually want the first edge be from a surface edge because otherwise you will lose the tangency info. But nothing prevents you from using a natural tangent direction, you just lose control. Also you need to pay attention to how you intend the curves to connect (what point connects to what point). Personally I prefer drawing the hull or using some of the network based tools. This way allow you to specify control curves in 2 directions, thus giving control of what to connect where and how it should work mid run. 

The ratio is with a quick and dirty visual measurement $665:501$ which is approximately $5:4$. You can measure it by taking the ratio of the vanishing angles $\alpha/\beta$ (see picture 1) because we are so close to the center. 

Introduction It depends on how you create the map! Consider the following and let it sink in for a while before you go forward: 

When the lines of the square do not exit the polygon. You now have a piece with a hole or the entire polygon is contained and theres no hole and no piece. When the lines exit 2 times you have one fragment* when the lines exit 4 times you have two fragments* when the exits are 6 times you have three fragments* when the exits are 8 times you have four fragments * 

Ideal mirrors are just that, ideal. The question if or not it has color never comes to play, its ideal it reflects everything. Like division by zero it is undefined. However, that does not mean you could not multiply your result by one its still the same result. The problem is that we have succesfully mixed the concepts of intensity and color together. We simply assume in RGB that color is 3 independent intensities. Which is not at all true, its quite an simplification of how reality works. There really is such thing as a highly intense dark orange that RGB can not account for. So as such its hard to tell since we are conflating two independent things as one. But yes probably some energy being removed for reason unknown in that code. 

Image 5: 2 different basis functions, a bezier like and a uniform segment parametrisation, spread to 0-1 range. And now we have mostly described the answer to question 1. The range is not defined you can stretch the basis functions as you see fit. And finally the knot vector simply produces the parameter ranges for the basis functions. Theres still one more thing that governs the shape of the curve and that is the weight vector. But that another story to be told elsewhere. 

These rely on a transformation from global coordinates to path local coordinates, where the local axes are along and out (or more often u and v). In essence this all works on a principle similar to how offset works. 

Image 1: This is what I get when i plot squares at $(x, z)$ with direction $(x_{dir}, z_{dir})$ Mathematica source for image 

Well you can render at higher resolution and sample down thhis is called FSAA and should just work without much change to render code. FSAA has the benefit of not having a conflation problem whereas smoothing does. 

Image 2: A proof of concept of unwound spiral with the mesh method. Note i scaled the unwound spirals length to make it fit the site requirements better. From initial test in my 3D app of choice seems that a dense enough triangular mesh works fine. 

FBX is a pretty common interchange format for 3D animation software. The format is originally made for a software called filmbox which handled motion capture data (since renamed to Motion Builder). Currently the format is owned by Autodesk who make and maintain a sdk for the format. The Bone structures and mesh bindings are pretty basic functions within 3D modellimg and animation applications. Possible applications are (in alphabetic order): 

One can do curved drawing with hardware. There is a method described in GPU Gems 3 that describes how to do this. User @yuriks actually comments this. I have actually made a quick a dirty demo for you to take a look at. 

No, something has to emit this info. You take the derivate (the gfx card does this for you) of the surface varying to determine how far the step would take you in your pixel. if its over the edge then you antialias. 

Image 2: Animation with interpolation of knot form [0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2] to [0, 0, 0, 0, 0.34, 1, 1.66, 2, 2, 2, 2] and back. If you do proper point insertion then the curve does not change. Just talking about what multiplicity is. Alternatively to changing parametrization you can just add points on top of each other. This is equivalent although slight misuse of resources, but useful in surface modeling. Having many control points on top could also be useful for the uniform nature of the knot distribution. 

In a 2D case it reduces to the same calculation. Anyway for 3D we have quaternions that are multidimensional imaginary numbers with one real and 3 imaginary components. Quaternions have a property that makes rotation composing a linear interpolation operation by summing 2 weighted quaternions. This neatly solves certain problems with space rotations. But at the cost of understandability. 

Image 2: And now you can offset the shape. But you need to recheck that there is no intersection left after this. Now the topology is somewhat stable across levels of slices so you can use that to your benefit. Just follow the 3D surface. Or you could do the offset in 3D on the polygons so you do not need this info. Also if you just need the winding for knowing which way to offset rule you can derive it from the 3d model itself, each vertex has a normal so project the normal for one triangle in each loop with your slicing algorithm per loop. That then gives you the direction of loops outside which is inside for nearly free. You wouldn't get the tree but then again you might not need it. 

You project your data on a sphere, it may be that this process was already done for you. And then you project it back to a cylinder 

Image 1: Image without ambient light (left) looks like it was shot in space. Image with ambient (right) looks more natural, although possibly a bit flat if overused. The real problem is that ambient light does not really exist. Even if youd argue that its useful model, it certainly is not uniform. Its just a quick fix. Therefore all kinds of tricks, like ambient occlusion, have been proposed to enhance the quality of ambient light. 

This is more like a long comment to @SimonF's answer that I'm trying to make somewhat self contained. All cuts of cone are possible, hyperbola, parabola and ovals. This is easy to test by drawing images in a 3D engine by a extremely wide angle camera. Rotate the camera to say in 30 degree angle so the object is not in the middle of your focus. Then gradually move the camera closer to the sphere. 

* This rational in this case means that a NURBS curve does not have to be a polynomial, as you cant describe a circle with polynomials. ** One can define other types of points. 

Some software like Maya, solve this by using a polar (or actually cartesian that turns polar at a distance) much in the same way as you grid centered on the camera position. This setup adds more detail where it counts most Then they rely on the shaders normal processing at further ranges. There is room for improvemenet offcourse. You cold modify this approach a bit, and have any other shape that increases the mesh density towards the camera. The benefit of this is you can stretch the effect up to the horizon without worrying about the seam. The trick to not get the displacenent jumbled up in this case is that you gradually reduce the displacement as you move further away. You then just use normal modification in the pixel shader as you get further. This is easier to filter than having to filter an accurate shiluette edge. Also if you can see that far away then your vawes are likely sufficiently flat anyway. 

If your wall geometry is vector graphics you can simply extrude the segment away from the light position. This means 2 triangles per draw call, all the extrusion offsets can can be handled in the vertex shader. 

I am trying to figure out how to convert a flat representation of a curve into the silhouette of a surface of revolution in a isometric projection. In essence in want the planar cut of the surface edge to be converted to the silhouette.