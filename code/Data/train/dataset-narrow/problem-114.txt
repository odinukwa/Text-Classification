Elderly equipment was limited (device port or trunk port, never the twain shall meet.) More recent (by which I do not mean new) equipment is less limited, and can have ports that have both untagged and tagged traffic (from different VLANs) on them. I have 3com (so you know they are not new) switches from both of these flavors, and the older ones are on the shelf. Under the "modern" scheme ports have several settings that govern how they behave - incoming untagged traffic can be assigned to a VLAN, while incoming tagged traffic is left on the VLAN it's on; or incoming untagged traffic can be discarded (which is more similar to an older trunk port setup.) Traffic tagged with a VLAN that's not assigned to the port is dropped in any case. Outgoing traffic from one VLAN can be untagged as it exits the port - any others need to be tagged, or all can be tagged (similar to an older trunk port). While it is uncommon for most end-users to use (or understand) the functionality, "end-user" computers can in fact handle VLAN tagging, and it's folly to assume they cannot (don't expose something to end users in the belief they can't touch it.) I have a 2006 MacBook laptop that's been happily connected to VLAN1 (untagged) and VLAN4 (Tagged) for several months now, since I wanted it to be accessible from both networks. It's easy enough to find the same ability in Windows (I just haven't really used it there.) Most "enterprise" WiFi will (or can) assign a SSID to a VLAN. Fancier/newer implementations will (or can) assign a VLAN when a user signs into the RADIUS server (so two users on the same SSID could be assigned to different VLANs depending on their sign-in credentials.) Whether or not you make use of dynamic VLANs, using a RADIUS server (WPA2 enterprise) makes it much harder for "students" to get access to the "faculty" network, and also lets you know which faculty to have a little chat with if they do, since each user has a unique password, rather than "anyone who knows TheSecret123FacultyPa55w0rd can get on the faculty network." In a normal install, you assign wired end-use ports to one VLAN and untag them (the old-fashioned approach.) APs get ports tagged with the VLANs that the SSIDs are assigned to, or that are the various dynamic VLANs users will be assigned to. Trunks between switches are tagged. 

Turn access point transmit power down. If the client can't hear the "wrong" access point, it will connect to the right one. If it hears both and is prone to making bad choices (as many clients are) you get the problem you have. If clients can hear the wrong access point when they are near the "right" one, the wrong one (probably both) is (are) turned up too high. Most people seem to gravitate to a "more power is better" approach to WiFi, which is pretty much the opposite of the truth. Lower power APs, closer to the clients (which may mean more APs) work better in nearly all cases... ...And run wired network to both APs - "Wireless Range Extender" is a performance-limiting mode that should be avoided. Good wireless is done with a lot of wire and fiber providing network to APs. 

In the case of partial wiring damage, half duplex can be the difference between a slower connection and NO connection (until the damage is repaired.) That can be a BIG difference. 

With LX optics, you can connect two units with a short patch cord and expect them to work fine. With ZX optics, you will need an attenuator if you are not connected to a long section of fiber. If the optical receiver is expecting a signal that has passed through 40-70Km of fiber, it can be overloaded by one that's passed through 5m of patch cord instead. Looking at Cisco's specs, and remembering that every 3dB is double/half the power, we see that a receiver twice as sensitive is coupled to a more powerful laser (almost 4 times as powerful at maximum): This page includes information about power out and power in for Cisco SFPs Note (under fiber loss budgets) that the maximum power out of a ZX is 5 dBm (min 0 dBm), and the maximum power in is -3 dBm - while the maximum power out of an LH/LX is -3 dbm (min -9.5 dBm), and the maximum power in is also -3dbm. That means a ZX with a low-loss link will overload its receiver, while an LX will not and cannot. The minimum receive power is -20 dBm LX, -23 dBm ZX. Thus, the total loss budget for a ZX is between 23 & 28 dBm, and for an LX it's between 10.5 & 17 dBm. 

Your question is vague, to say the least. I run a small campus single-mode fiber optic network without any "media converters" (so-called.) I do have switches with both copper and SFP ports, and those do convert from one transport to the other, generally at far more attractive prices and with better performance than most "media converters." Whether done by a "converter" or a switch, conversion allows the data to flow to devices with different interface types, or through a medium that has better performance (such as length between nodes) that's between two devices with the same interface type. I can't run 4000 feet of copper between two computers, but I can run 100 feet of copper to a switch connected to 3850 feet of fiber connected to another switch connected to 50 feet of copper connected to the other computer; And when a thunderstorm comes along, I'm very happy not to have copper between them. 

Electrically speaking, encoding schemes are important to keep the line balanced - even if the data changes state often enough to clock and be distinguishable from a dead line, if it has an uneven number of 1's/0's the receiver develops an unbalanced offset voltage. Encoding ensures both that there are no long strings of 1's or 0's, and that the total number is effectively balanced over time. 

Depends on the LAN. In mine, there is a huge, noticeable difference, because the LAN extends across multiple buildings scattered over 1/2 mile, and served by different power lines. When it was copper it did not cover as many buildings, because copper would not reach, and burnt out ports were a common result of thunderstorms. With fiber, thunderstorms cause no problems to the network at all, and even on the wimpiest (singlemode) SFPs link length is 10 kilometers, so nothing anywhere on campus is out of reach, no matter how convoluted the run. If your LAN is not hampered by 100 meter length limits and is within one building, there will be virtually no noticeable difference. 

A: your scope (or probe, or whatever you have between the probe and the wire) isn't fast enough. B: you are not running a differential probe. Ethernet signals are differential - the 60 (or elsewhere 50) Hz picked up from electrical supply wiring is picked up by both wires equally and rejected at the receiver, which only looks at the difference in the signals. If you don't do the same, you can't see the signals (it's a scale problem - they are there, but hard to see.) Also, if you can see the 60 Hz wave, you can't see the 100-250MHz-class signals at the same time on nearly all scopes, as the time domain is vastly different - so even if your scope is fast enough, your display window isn't. If your scope and probes are fast enough, try sampling both wires in one pair and subtracting (the crude approach to a differential signal.) 

Fiber is not so expensive unless you are getting fleeced. Indeed, it can be cheaper than copper cabling. It's also the right solution to long runs. Given the installation costs, it's likewise foolish to install 5e rather than 6A at this date and into the future for copper. The cost of the cable is a tiny fraction of the cost to get it installed correctly. With 6A your inter-switch links can run at 10Gb, even if your drops are only running at 1Gb. But your inter-switch links should really be fiber. If you are stuck with a penny-wise, pound-foolish corporate mindset, drop in a switch every 100 meters or less. Throughput from [everything on a switch] is going to be limited by what the switch uplink speed is, to the extent that more than one thing on a switch wants to pass data up or down the uplink. Commenting on topology without some sort of sketch of the building and knowledge of what other PWPF limitations on common sense are in effect is shooting in the dark. Post diagram and switch model: Is it more or less than 100 meters of cable between each of the 3 switches? Is it more or less than 100 meters of cable from each device to the switch it connects to? "The far end of the building" is not a factor here, unless there's a cable you are trying to run from this switch to that end. If more than 100 meters, you need fiber to make the link. If less, copper is an option, but fiber is a superior option. If you limit yourself to that particular switch model, 4 fibers (2 links, aggregated) from each remote switch to the switch at the router is all you're going to be able to manage. Use 12 fiber cable anyway, it's not much more expensive if you shop well. A different switch at the router might offer you 8 SFPs and aggregating 4 links to the other switches, but changing all three to a switch model that supports SFP+ would be 2.5 times better than that... Of course, if you don't actually have things like local file servers and this is all connected to a 50, 100 or 500 Mb (or even 1Gb) internet uplink, and nearly all network traffic is from or to the internet, not between local devices (or not with large data between local devices) this may not be a bottleneck in practice, as the internet connection will be the limiting factor. When looking to optimize a network I tend to try and eliminate bottlenecks on the assumption that if not now, at some point someone might hang a fileserver or database server off the network and it would be nice if the network worked well with that, but with a low-budget approach that may not be a current concern for your application - in which case a single gigabit link would be OK, though a dual aggregated link will offer minor protection from a cable disconnect. Connecting the distal switches with a normally STP blocked path will again offer minimal protection against one of them becoming disconnected, though in this layout a cable cut would be likely to take out both such links at once so the benefit is probably minor. If cost is such a concern and your blue lines are fairly accurate, smaller switches might save quite a bit of money. Going a bit further into why we push fiber: at 10 Gb, fiber transceivers are much more power-efficient than copper transceivers. Fiber is effectively immune to electrical noise, while copper is subject to it; the design of copper systems is intended to reduce such noise pickup, but that can be thrown off by pulling a cable too hard, bending it too tightly, or many other fiddly installation details. Fiber, particularly single-mode fiber, is effectively unlimited (itself) in terms of bandwidth; upgrades merely involve plugging in the newer, faster transceiver on each end, rather than replacing fibers in walls and ceilings. And, as mentioned, fiber is the only way to get past the 100m limit at full speed and without intermediate devices. But in your case, you seem to have missed that the "100m limit" applies to "cables between devices" not "overall size of the building" - when you get to a switch and go out another port, you start counting again at 0m from the switch port.