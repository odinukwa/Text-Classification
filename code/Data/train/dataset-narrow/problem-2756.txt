I'd say it's a "UV-mapped triangle" or "UV-mapped quad". Or simply a "polygon with UV coordinates". I guess it's also fine to just call it the same as the geometry.. eg. UVs of a triangle, quad or polygon. There are some names that are introduced in UV mapping, such as "patches", "shells" or "islands", which are all names for a group of connected UV coordinates though. A polygon doesn't get a new name once it has been UV mapped, it just gets some additional UV coordinates. So it really isn't a "UV Tile".. generally you just talk about UVs (the "vertices") and "shells" or "islands" (connected UVs). If you select a polygon within UV editing, you just select and modify a bunch of UVs... 

Then you can use ImageMagick to convert this image to a sprite with magenta background using the following command: 

Where is the loaded texture atlas. "fontName" references the font-sheet inside the atlas. The parameter is the loaded font data (file sometimes has extension). 

However, this type of ranged-based spawning won't provide much variation. Another approach would be based on probabilities (or weights). Something like: 

Since you're most likely never going to find out the properties of each cubic-meter of the real world, you'll need some way to generate that data that is uncertain based on assumptions. So if you have that figured out, there's no need to calculate and store all that data, but you can rather generate it on the fly. First and foremost you can discard all the voxels within the earth, because these will only have to be calculated if somebody actually digs a hole, eg. the voxels become visible. For the surface of the earth, I'd probably take an image as starting-point for my calculations. Maybe some sort of temperature- and humidity-map will allow you to calculate the type of blocks to apply. Eg. Water, sand (desert), grass, snow etc. Since the image probably won't have one pixel of information for every square-meter of the earths surface, you would have to mix this with some noise to generate a bit of variation on the surface. If you always use the same random-seeds, your result should be deterministic nevertheless. In addition, an elevation-map would be useful, so that you can determine the height of the surface features. That way you can add mountains etc. So this boils down to a data-volume of some 2D images that contain information about the earth surface. For everything on the inside, you would revert to a pure procedural approach, where you render different types of blocks, depending on the distance from the earth-center. But as said above, these have to be calculated only, when somebody digs a hole. To make changes persistent, I would only save modifications to the world. So if somebody digs a hole, I would store information about which voxels have been removed, as I should be able to render the surrounding voxels procedurally. As for the rendering: You will need some sophisticated level-of-detail and culling algorithms to make this work. It's silly to render all the surface voxels, when the camera is at a zoom level that shows the whole world. At this level, the voxels should be much bigger, maybe even a simple textured sphere would be enough. I guess the most tricky thing would be to have a solid generator that allows you to calculate voxel properties, even for different "resolutions", so that you can use it to generate different levels of detail. 

You need to learn about UV mapping. For that you'll have to provide UV coordinates with your vertex data. This introduction to stage3D also covers how to use textures and specify UV coordinates (at about 2/3 of the page). To map a portion of a sprite-sheet to a quad, you have to calculate the UV coordinates for that portion. Imagine your texture is and you wish to map a sprite with the dimensions of , located at to a quad. Since the texture width and height always maps to , you calculate the coordinates as follows: 

The most flexible approach is to use the graphics object of the , or class and paint your lines dynamically. Then (as you suggested), apply a Glow effect to this display object. With the graphics object, you can paint many lines in a single (or ), so it's a good idea to do that and have the filter applied to the Sprite, so that all lines will get the same filter effect. If you're drawing lines over a huge area, you should know that the glow filter is limited to certain size. From the docs: 

After countless tests (and some coding) I was able to find two valid approaches to the problem. Both aren't optimal solutions, but apparently there is none (exporting a simulation from Blender to Unity simply doesn't work). Approach 1: Export as obj sequence and swap meshes in Unity Pretty straight-forward. Exporting a simulation using the exporter generates a separate file for every frame of the animation (if the "Animation" option has been toggled in the export options). Drag all these files into your Unity project (eg. into ). Then write a simple script to swap the mesh of the GameObject at runtime. Pros: 

If your argument against an array is "The world will be huge", then it's not about the data-structure, but rather about memory constraints. If your world is so large, that it doesn't fit into memory with a 2D array, then it won't fit into any other data-structure. Instead you would have to implement a (file-)format, that allows loading chunks (or sectors) of the world. Then you simply load/unload the needed chunks into a data-structure. There's nothing wrong with a 2D array. As for rendering: I assume you have some sort of camera/viewport. Then you simply render all tiles that are currently in the viewport. 

Simple, you're calling in your loop. That means, your animation will restart every frame, resulting in a still image. The second parameter to the play function is a flag whether or not the animation should be forced to restart (see docs). So either call: 

While this functionality isn't available in Unity, a basic implementation of such a timeline shouldn't be too hard to do. Here's how I would go about that: 

OGRE is an abstraction layer on top of some popular graphic APIs, including OpenGL. Since the underlying API is exchangeable, you'll gain portability (same code will run on Direct3D and OpenGL ES with no or only minor changes). On top of that, OGRE adds quite a lot of features that are useful in the daily life of graphics programming. A scene-graph, scene-managers, mesh- and animation loaders, material scripts, shaders etc. Here's an extensive list of features. Implementing all these features alone means a ton of work. If you're interested in writing a graphics engine, then OGRE is not for you, since OGRE is a graphics-engine. If you want to write a game and need a robust 3D engine with lots of features, then you're definitely going to have an easier time with using OGRE instead of writing OpenGL calls. 

Is a static variable? If that's the case it is very likely that has changed when gets called (because was modified during playing of the sound). You should probably use another method to build that identifier... 

The simplest way would be to make your paddles origin at the center of the circle. Then you just need to calculate the angle and you're done (your paddle origin, or center position should be at the circle center and the paddle itself should be to the right of the circle as starting position). Something like this: 

If your color was red, you would then color the note (all the black parts) with the same red. What you would need in addition, is a grayscale image with the shading of the note. Then combine the shading with the flat color by using blend-modes like Multiply and/or Screen. Another, probably simpler approach would be to just have a grayscale image where you would multiply each color component with your selected color. So if you have a gray value of , and a red color , that would result in for the given pixel. Update: Here's an example image to illustrate what I mean with the blend-modes: 

There's no disadvantage I'm aware of when using squared length to compare distances. Think about it like that: You're just skipping the which doesn't give you any additional accuracy. If you don't need the actual Euclidean distance, then you can safely leave the out. Of course the squared length scales quite differently than the Euclidean distance and is therefore a bad candidate for things like pathfinding heuristics. 

The way I read it, the last four parameters are output parameters. So you basically pass in 4 variables of the requested type and after the function has finished, these are populated with the data you need. What you do is something along these lines: 

Comparison Here's a video that shows both types of animation in effect. The used scripts (both written in C#) can be found here: 

Render the sprite to a bitmap (using BitmapData.draw) and perform vectorization on the alpha-channel. If the resulting shape is concave, triangulate it. Use the as3swf library to parse an existing SWF file in flash. You can extract shape-information from there. Your main problem here is going to be: Finding the shape(s) that form the outline of your object. Convert this shape into convex polygons. 

I don't know what software you use to develop that game. If you're using FlashDevelop or FlashBuilder, you can profile/debug your game and look for memory-leaks and errors. 

You can set a custom class for your particle-system instead of the standard-particle. Use the property (here's an example of how to use it). In that custom class you can then write code that handles the user-interaction etc. 

What would be the best approach to tackle this problem? Optimally, the solution should be generic, eg. work with arbitrary 4x4 matrix blocks on an arbitrarily sized and populated board. 

The solution to your problem is actually quite simple. Instead of calculating the ratio, you calculate the possible movement-distances for camera and background and interpolate them. For the background this is going to be: (results in 100) For the camera it's . Assuming that the camera x-coordinate is at the left, your background position would be: (assuming goes from to ) Update: If you want to stick with the (which is probably more intuitive) you can calculate it like this: 

In case of the zeroes and ones, you have to split with , but in case of the tile-numbers this doesn't work as it would create an array entry for and when the value should be . But luckily you have a delimiter which you can use. So instead of 

I think you have a flaw in your architecture there. The Player should not be a subclass of (or any cocos2d node class for that matter). The is only the visual representation of your player-character, therefore your Player class should have a as member (or property as it's called in Objective-C). This makes your architecture much more flexible. You could implement a component-based architecture, where your node is part of a "VisualComponent", or you could have an inheritance-based architecture where you inherit from a "GameEntity" base-class etc. But inheriting from is a bad idea and will definitely hurt you in the long run. Update: As requested in the comments, here's a short guide how you could refactor your code using a Player class that inherits from and implements a GameEntity Protocol. For a more complete documentation of protocols, read the Objective-C docs. Protocols are much like interfaces known from other programming-languages. A very simple protocol could look like this: 

Using RGB values by generating a random value for each component might not only create colors that are similar to the background, you can also end up with very similar colors for the balls. I'd probably choose a less random approach and create colors that are guaranteed to be different instead. You could create a color for each ~32 degrees in the hue range and alternate the brightness or saturation (use HSV color-model instead of RGB). So something like this: 

A common problem with using radians is that they start to the right. Look at this picture (from Wikipedia): 

I think it depends on how you're planning to render your graphics. Do you want to include animations? A playing board with a pseudo-3d-view? A top-down view is probably easiest and could be done using DOM and/or Canvas. Since DOM is supported in all major Browsers and jQuery offers a nice toolset (including animations) for DOM manipulation, I'd probably pick DOM over Canvas. Since this is a multiplayer game, you'll have to think about where to put the game logic. The best approach (which also prevents cheating) would be to keep all the game-logic on the server-side (programmed in PHP) and only have rendering logic and user-input in the clients. I don't know about any PHP framework that has a focus on game-development. I'd probably pick a multi-purpose framework like Zend, Cake, Sapphire or Symfony. This will let you focus on the implementation of the game-logic while it will already provide tools for data-persistence or handling of AJAX-request (which you'll probably use for communication). 

You can select edge-loops by holding Alt and klicking on an edge. This works both in vertex- and edge-editing mode. To display the numbers you see in the video, press N. This will bring up the transform panel in your 3D view. In that panel there's a section called Mesh display where you can tick Edge length. The scaling is explained in the video. Hit S this will cause blender to change into scale-mode. Then you can constrain the scale mode to the X-axis by hitting X. This also works for and and also in "reverse". So if you would like to scale and you would use Shift + X. He also holds down Ctrl during scaling, so that scales snap to fractions of 1/10th (eg. , , etc.) 

Tetris-Tiles are stored as a 4x4 boolean matrix. Each rotation step has it's own matrix, the representation of the T-Block would look like this: 

It sounds like you want to increase the mass of the ball. Play around with the parameters of the Rigidbody-component in Unity. Increase the mass, set "drag" to zero etc. Maybe you'll also have to tweak your level a bit for it to work (if your ramp is really steep, then there's probably no way the ball will jump over that.. or you could cheat and apply a force whenever the ball hits the bottom of the ramp). 

Somebody who wants to cheat would have to set health and healthComplement correctly, otherwise the game would crash. I think it's kinda pointless to try to prevent stuff like this. People have successfully created hacks/cheats for much more complex stuff and it just needlessly obfuscates your code or makes your game perform worse. 

Just recalculate your building-options at a bigger interval than your game-loop? You could just as well recalculate every 500, or even every 1000ms. The user won't care/notice if the building-options refresh with a slight delay. All in all, this sounds a bit like premature optimization. I highly doubt you're going to have so many options to calculate that you'll be running into performance problems even if you update every 50ms. 

If you'd like to learn Objective-C, I suggest you have a look at cocos2d. It's an open-source 2d engine (written in Objective-C) that allows you to write games for iOS or Mac OS using XCode. It's not as easy to create games with as with a package like Unity, but there are lots of tutorials (and even books) for cocos2d to be found. A good place to start with lots of tutorials is Ray Wenderlichs site. 

If your movement should look a lot like your graph, you could make use of a bounce easing equation like this one (source): 

I'd suggest using a ZIP file. It's an ubiquitous format and you'll find ready-made libraries that allow you to load files from within a ZIP file. A quick Google search even revealed a zip loader for sfml. 

When working with floating point values it's usually not a good idea to use the comparison operator, as even slight inaccuracies will result in inequality. That's why a comparison of floats usually incorporates some sort of "epsilon".. a margin of error. Example: 

If you have any other bodies that will interact with your body attached to the rope or even the rope itself during your game (eg. a collision mid-swing), then it will be a really hard task to find the forces necessary to restore the swinging motion after collisions have been resolved. And if you can ensure that there will be no interaction with other dynamic bodies, why use a physics-engine for the swinging animation in the first place? You could just as well make a looping animation? If I had to build this with Box2D, I'd probably add a "Revolute Joint" at the top of the rope and enable its motor. Then use the motor to apply a rotational force to the rope. My first try would be a sine force, or just enable the motor in specific intervals/impulses. But you would have to experiment with the setup to see which values work best.