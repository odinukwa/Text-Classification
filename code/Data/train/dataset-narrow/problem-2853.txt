OpenGL is needed on Mobile phones, OSX and every console other than the X-Box (well the other console use their own thing thats a stripped down OpenGL similar to OpenGL ES since ES 2.0 wasn't out back then). So you will definitely need it in the games industry. You will probably also need DirectX. Having said that I think most game devs now program using premade off the shelf engines and don't worry about the graphics API (other than possibly things like shaders). I don't know much DirectX (being a Linux user myself) but I can't see learning 1 really causing you problems learning the other. They should bother share similar underlying concepts. The main thing would be the coordinate system. For an indie game developer it can depend. Indie games are niche products. Having support for other platforms such as OSX can give you a large number of extra sales as the number of game available on the platform is fairly limited and there more likely wanting to boost support for their platforms. You can also throw in Linux support for little extra and get some good PR (the main hassle is building for a whole bunch of different targets). Mobile phones are also something to look at as they all use OpenGL ES. Porting to WebGL is also another possibility with things like Google's Nativeclient and emscripten (Compiles code to JavaScript) or just redoing it in JavaScript (or even using JavaScript across the board the desktop, web and mobile). 

I know you've already accepted Zhen's answer but I'd like to put another out there just in case it helps anyone else. To reiterate the problem, the OP wants the ability to keep the rendering code separate from the logic and data. My solution is to use a different class all together to render the component, which is separate from the and the logic class. There first needs to be a interface that has a function and the class uses the visitor pattern to retrieve all instances, given the list of s and renders those objects that have a instance. This way, Renderer doesn't need to know of each every object-type out there and it's still the responsibility of each object-type to inform it's via the function. Or alternatively, you could create a class that visits all GameObjects and based on individual condition they can choose to add/not-to-add their renderable to the visitor. Either way, the main gist is that the calls are all outside of the object itself and reside in a class that knows intimate details of the object itself, instead of that being part of . DISCLAIMER: I hand-wrote these classes in the editor so there's a good chance that I've missed something in code, but hopefully, you'll get the idea. To show a (partial) example: interface 

Then when you render, just run though the list. I have used references above but they could be smart pointers, raw pointers, object handles and so on. EDIT: 

It isn't really possible to have an 'infinite' space. You need some way to index the positions, so if you used an int then the maximum size would be MAX_INT. You can use bigger index data types. Maybe a long or even something more esoteric like a long long long long. There are some ways to have numbers that can grow arbitrarily but they will add performance/memory overhead. At the end of the day you will still be bound by the memory of the system. Do avoid floats/doubles at they loose precision the further away from 0.0 you go. Look at the Minecraft end of the world videos. So it's probablly better to use a 'fixed' sized world and just make it very very very big. With a fixed sized world you could use a GPS system. You can also make the world 'wrap' around so it's like a sphere. Having said that I wouldn't give the player raw coordinates to have to deal with. You are just making them remember stuff and giving them extra work. Place names seem hard to implement in a procedural system. Seems like they would come out too uniform (ie you would be naming square regions rather then points of interest). It seems like having a 'waypoint' would be the way to go. Combine A map, compass markers, plus a list of waypoints that the player can turn on/off and possibly a 'pillar of light' at the position' so it can be seen on the horizon (that only makes sense for 3D games) and a fined grained marker at the point on the ground. Also let them set their own waypoint. As a simple version would just have a direction (an angle, or arrow that points there) and distance to target. The problem with that is the player sometimes has to go around the long way to avoid obstacles rather than straight in the direction. You can also use the waypoint system for 'points of interest' within a range like Skyrim does for dungeons. 

I know that the image is getting loaded because the logs says so The log says that it managed to add the camera as slave to the viewer 

Create a camera Set the view matrix of the camera to identity so that there are no view transforms made to the children Set the projection matrix of the camera to be of an orthogonal matrix with width and height equal to 1 Set resize policy on projection matrix to be fixed Set render order to be (I previously had this as and that didn't work. I still have to dig into why). Create a textured quad with width and height of 1 unit Add the textured quad to an instance of and add that geode to the camera Extract the first window from the camera. Set the graphics-context and viewport of the camera Add the camera to the scene and you have a background image 

Firstly OpenGL 1.1 stuff like Display Lists will still work in a new context provided you have the compatibility profile (which is generally the case). The only problem is if you expect to port to OpenGL ES, one of the console specific graphic library (they are generally stripped down OpenGL similar to OpenGL ES) or even WebGL (which would require quite a bit of reworking anyway). Personally I would recommend using vertex/fragment shaders and VBO's. They have been around for quite a long time now and offer great performance improvements. You could probably even provide a simple fall back if you wrap the functions in a class. You may also be able to emulate things like Vertex Array Objects. 

I was unable to find a good working code for this simple thing. Luckily I got this working. I hope this helps someone else who's trying to do the same. P.S.: If you want to displace the background image on the screen, think of doing that in relative values; [0, 1]. So if you want the background image to be on the top-right of the screen, create the like so: 

I'm trying my hand at using OpenSceneGraph for graphics in my game. I'm having a hard time trying to figure out how to get a background image up. The relevant piece of code that I have can be found in this gist. Does anyone here have an idea of what I'm doing wrong/missing? BTW: 

This advice isn't really specific to rendering but should help come up with a system that keeps things largely separate. Firstly try and keep the 'GameObject' data separate from the position information. It's worth noting that simple XYZ positional information might not be so simple. If you are using a physics engine then you position data could be stored within in the 3rd party engine. You would either need to synchronize between them (which would involve a lot of pointless memory copying) or query the information directly from the engine. But not all objects need physics, some will be fixed in place so a simple set of floats works fine there. Some might even be attached to other objects, so their position is actually an offset of another position. In an advanced setup you might have position stored only on the GPU the only time it would be needed computer side is for scripting, storage and network replication. So you will likely have several possible choices for your positional data. Here it makes sense to use inheritance. Rather than an object owning it's position, instead that object should itself be owned by a indexing data structure. For example a 'Level' might have an Octree, or maybe a physics engine 'scene'. When you want to render (or setup a rendering scene), you query your special structure for objects that are visible to the camera. This also helps give good memory management. This way an object that isn't actually in an area doesn't even have a position which makes sense rather than returning 0.0 coords or the coords that it had when it was last in an area. If you no longer keep the coordinates in the object, instead of object.getX() you would end up having level.getX(object). The problem with that is looking up the object in the level will likely be a slow operation since it will have to look through all it's objects and match the one your querying. To avoid that I would probably create a special 'link' class. One that binds between a level and an object. I call it a "Location". This would contain the xyz coordinates as well as the handle to the level and a handle to the object. This link class would be stored in the spacial structure/level and the object would have a weak reference to it (if the level/location is destroyed the objects refrence needs to be updated to null. It might also be worth having the Location class actually 'own' the object, that way if a level is deleted, so is the special index structure, the locations it contains and its Objects. 

Having done both courses, Bachelors in Information Technology (more like SE) and Masters in Computer Games Technology, I find the difference in curriculum is profound. Just like what Ken had mentioned, SE covered topics that were close to designing software and how the systems worked, while CGT was geared more towards SE for Games. If you're looking for a career in games, CGT would be the way to go as you get to learn (in a concentrated manner) the stuff required for games. It would also give you a better chance at getting a job in the games industry. I say better because it's not necessarily the degree that decides if you get the job or not. But when it comes to game development basics, you'd already be well-versed at how things fit together in game, while a SE student will have to go through the extra learning curve and learn graphics/AI/physics for games on his/her own to prove their worth to game companies. I should warn you about the downside though. As good as the game industry sounds, it doesn't always provide a lucrative career. For those who've settled themselves in a well-paid job in games industry, two words, WELL DONE! You're living the dream! But it's not an easy task. You've to work your mind off to prove your worth before they even consider to keep you in the company. And typically, you'd first end up working in a start-up (or self-found) game company, which doesn't provide you any form of job security and with basic salary. Trying for a big-shot company usually ends up with them telling you that you don't have enough experience. Not only that, if you do manage to get through to a big-shot company, they usually don't pay you as much as what you'd earn as a Software Engineer. With that warning, if it's your dream to be working for a game company, GO FOR IT! But beware of what is to come and be prepared for it. In the end, when all your hardwork pays off, it's the sweetest achievement of your life. If however, you're not sure if you'd like a lifelong career in games industry but still like to dabble on the idea of working with one, I would suggest first taking up an SE Bachelors degree, try to get internship in a games company based on your degree and progress your career from there. Failing to find any, you could go for Masters in CGT and try for a game company after that. If all fails, you'd still be able to get into software companies based on your Bachelors degree and the fact that you've got a Masters degree related to CS (they don't usually care if it's CGT or not) as long as you can prove your worth. 

In OpenGL 4.0 there are uniform subroutines. These allow you to define functions that can be swapped out at runtime with very little overhead. So you can make 1 function for each pass. Also 1 function for each shader type. There's a tutorial here. For older OpenGL versions your best bet is to either have a bunch of different shaders and swap between them. Otherwise you can add together values that you multiply by a uniform that is either 0.0 or 1.0 to turn it on or off. Otherwise conditional if statements can be used but OpenGL will execute all possible outcomes every execution/pass so make sure they aren't too heavy. 

Another possibility in addition to the boundingbox/sphere techniques given above is to use an occlusion query. Basically how it works is you render a low quality version (unshaded, untextured, possibly just a bounding box itself) and you check to see if there where any fragments actually written. If there where you go ahead and render the full mesh otherwise you can toss out the mesh. The advantage to this is that if you have a mesh behind an object but still in your fov then it wont get rendered. Of course in order for that to be really effective you need depth-last sorting of your objects (except the transparent ones which are depth-first unless your using some kind of order independent transparency). Transparency ordering is vastly helped by decent spacial data structures. OpenGL has dedicated occlusion query api functions. I'm not sure about XNA/Direct3D. In addition to that if you have your meshes stored in a decent spacial data structure (ie BSPs or Octrees) you will probably find that there are quick ways to throw out entire chunks of areas. For example the regions behind your camera can be pruned. In an Octree you could render the entire cube region as just a cube in an occlusion query and see if that entire region needs to be processed at all which would let you skip even bothering to check bounding boxes. Finally be careful that very large meshes or ones that cross boundaries don't get cut. You could find that you need to calculate the bounding box of the region itself as being bigger than the actual region if you have a large mesh that's half off the region. A simple hack would be to just add the largest bounding box to the regions size. So basically you can combine all of the above into the following steps: 

I was able to solve my issue. The second revision of my gist has the solution. In a nutshell, this was what I did: 

If I were you, I would question myself about 'What do I enjoy doing for a game?'. Do you want to be a graphics programmer or a game programmer? Do you enjoy fixing those odd pixel in the screen that doesn't fit with the rest of the screen or do you enjoy building the game and don't want to be really bothered by the graphics implementation? If you're more into graphics, learn a high-level graphics API first, like Ogre3D, Irrlicht, Horde3D, etc. Once you grasp high-level concepts, take your time and dive into details. If you're looking to game development, learn to use game engines like Unity3D, Unreal3D, etc. They've done the hardwork of getting the engine implementation right and you can concentrate on the building the game itself. 

Giant imposing list aside, just about all of that is all insanely fun to learn, you programming will likely improve heaps as a result and much of it is useful in other areas or programming. Obviously a lot of that can be cut down depending on what you are trying to accomplish. You will probably want to split up all that stuff into small projects. Much of it might not be 3D at all (like the networking and data structures). And lots of it isn't specific to 3D games either (networking, scripting , etc...). One big problem with learning 3D is you need to make it interactive a lot more in order to understand it and have anything useful. Having a scripting engine for example can be great since you can just spawn in stuff at runtime, it break you out of just having a 3D rotating mesh on the screen and actually having something that looks like a game. Once you have the script engine maybe you can just store your levels as scripts rather than trying to invent your own data structures. Dumping in a physics engine will give you collision detection which is much harder in 3D than in 2D as well as all the cool physics interactions you will get. Choose a more inefficient scripting langauge that will let you introspect object properties. Perhaps you could start off learning the api by porting your 2D game to it as a bunch of 2d squares. Then maybe you can look at trying to 3Difiy parts of it. Use a 3d mesh for the main character, then other ones, then 3Dify the tiles and background. Even that is kind of heavy since you need to learn things like animation and probably shading. Another idea is a massive cutback on stuff. Some is obvious extras like multithreading. But maybe you shouldn't bother with any kind of lighting, shadows or texturing. Choose an art style that works with everything being flat like a cartoon (although actual cell/toon shaders also require learning different lighting algorithms). It would also save on making a whole bunch of textures and your models could probably have lower polygons counts. Or wireframe (although that might actually be more work since OpenGL core profile doesn't support actual wire-frame rendering any more, you either have to draw a bunch of lines which means either several redraws of your meshes or having different line based geometry layouts rather than the traditional triangle ones for your meshes or use a special wireframe shader. On the flip side using a premade game engine allows you to skip much of the stuff in that list and you can concentrate on making an actual game and it's content. Just place an object as X,Y,Z and let the engine figure it all out. Of course you will be restricted by what you can do to what the engine supports or what you can make it support.