I guess I'll take the counterpoint here and argue against using static values. In this case, all of the hex regions you're talking about are (a) easy to compute - you don't need to use BFS or anything so complicated; you should be able to iterate over all of the hexes in any of them with straightforward doubly-nested loops; and (b) not something you'll need to compute 'on-the-fly' very often. At worst you should only need to compute them once per turn, and if multiple systems do want the cells touched by an effect then you can easily cache the values off into a 'reachableCells' array or something similar; regardless, the computation is so easy that it should be effectively free to do in terms of per-frame costs. So what do you get for that? Flexibility. It's easy to say right now that these values will never change, but games have a knack for surprising you; even if it's more likely than not that these regions won't change, you give up essentially nothing by building that flexibility in, and there's a good chance that future-you will thank you down the road. What's more, even if those are the final regions you use, well-written loops for iterating over the regions will be substantially easier to understand and debug than any sort of fixed-tiles array will. I just really don't see any meaningful gain for going with hard-coded data compared to the benefits of going the other way. 

For the first test you shouldn't really (directly) need any quaternions; you have your AI's heading as a vector (and if you don't, you can quickly derive it from their orientation quaternion by transforming one of the axes), and so as you note your cone-of-vision test is just comparing the dot product of the normalized heading vector for your AI with the normalized vector-to-player. While you would still need a distance check, the best way to perform that cull for most AI entities might be 'up-front' and implicit: use your spatial partitioning scheme to avoid ever doing the checks in the first place for AIs that are far enough from the player! In other words, rather than iterating over all AI Entities in the world for the field-of-vision tests, iterate over just a list of the entities that are in cells close enough to the player that you know the distance-based culling has some chance of passing. Most importantly: both of these culling operations are fast enough already that it simply doesn't matter what order you do them in; you could do them both for every AI and it still shouldn't have any measurable impact on your performance. From that perspective, this smacks strongly of premature optimization. I really wouldn't worry about which cull will be more efficient/more effective at this point; unless you have literally thousands of AIs performing this check every frame, it Just Won't Matter. 

Actually, it turns out that you can't have it 'both ways': if your intention is to not have any sense of 'absolute orientation' on the sphere (that is, if the players aren't always e.g. facing towards the poles), then you'll need to have a notion of player orientation. This is because, contrary to what intuition might suggest, movement on the sphere is not exactly like movement on a plane, not even locally (quite); the intrinsic curvature of the sphere means that players can take actions that will rotate themselves! For the most extreme example of what I'm talking about, imagine that the player starts at a point on the equator (for convenience we'll imagine a clock face mapped onto the equator from above, and put the player at 6 o'clock), facing 'up' - that is, towards the North Pole. Suppose the player walks all the way to the North Pole; then they'll be facing directly towards the 12 o'clock point. Now, let the player move directly to their right, from the North Pole back to the equator; they'll wind up at the 3 o'clock point - but because their facing doesn't change when they move right (the idea is that their facing doesn't change no matter how they move), they'll still be facing the 12 o'clock point - they're now facing along the equator! Now, let them move 'backwards' back to their starting (6 o'clock) point; then they'll still be facing along the equator, so they'll be facing towards the 3 o'clock point - just moving along the sphere without ever changing their 'personal' orientation has caused them to rotate from facing towards the north pole to facing along the equator! In a sense, this is an elaboration of the old 'a hunter moves a mile south, a mile west and then a mile north' joke - but here we're taking advantage of the curvature of the sphere to effect a change of direction. Note that the same effect still happens even on much smaller scales; this is the most extreme version of it, but even just short 'one foot north, one foot east, one foot south, one foot west' rectangles won't leave the player facing precisely the way they were before - this is an expression of the fact that the sphere has nontrivial curvature. Fortunately, quaternions do (as you noted yourself) handle this situation; since a quaternion represents an arbitrary rotation, it effectively represents an arbitrary 'point plus orientation' on the sphere: imagine starting with a 'triaxis' at the origin and giving it some arbitrary rotation, then moving one unit in whichever direction the rotated axes' Z-axis points; a little thought will convince you that this brings you to a point on the unit sphere with some 'orientation' (i.e., some arrangement of the X and Y axes of your triaxis), and that you can get to every point+orientation on the unit sphere this way (just assign your Z axis to point along the line from the origin through your point on the sphere, then transport your triaxes back to the origin along that line). What's more, since multiplication of quaternions corresponds to composition of rotations, each of the operations you describe can be represented by multiplying your 'current orientation' by an appropriately-chosen quaternion: specifically, since the (unit) quaternion (qx,qy,qz,qw) means 'rotate about the (qx,qy,qz) axis by arccos(qw)', then (depending on your specific choice of coordinate system, and letting c_a be cos(alpha) and s_a be sin(alpha)) two of the three quaternions M_x = (s_a, 0, 0, c_a), M_y = (0, s_a, 0, c_a), and M_z = (0, 0, s_a, c_a) will represent 'rotate (i.e. move) in the direction I'm currently facing by alpha' and 'rotate in a direction orthogonal to the one I'm currently facing by alpha'. (The third of those quaternions will represent 'rotate my character about his own axis') This means that every tick you'll figure out which key has been pressed and then, e.g., say if the player has pressed up, or if the player pressed right (or possibly something like if the player pressed left, where M_yinv is the 'inverse' of the M_y quaternion, representing a rotation the other way). Note that you have to be careful which 'side' you apply the rotation on, whether to premultiply or postmultiply; to be frank, it may be easiest to solve that with trial-and-error, trying both multiplications and seeing which works. Going from your updated quaternion to a point on the sphere (and to an orientation of your character) is relatively straightforward, too: by the correspondence of the last paragraph, all you have to do is use your quaternion on the basis vectors (1,0,0), (0,1,0) and (0,0,1) of your frame via 'rotate vector by quaternion' operation v &rightarrow; qvq-1 (where the multiplications here are quaternion multiplies and we identify the vector v=(x,y,z) with the 'degenerate quaternion' (x,y,z,0)). For instance, the position on the unit sphere is gotten by just transforming the z vector: pos = (qx, qy, qz, qw) * (0, 0, 1, 0) * (-qx, -qy, -qz, qw) = (qx, qy, qz, qw) * (qy, -qx, qw, qz) = (2(qy*qw+qz*qx), 2(qz*qy-qw*qx), (qz^2+qw^2)-(qx^2+qy^2), 0), so would be the coordinates of the 'transformed' user on the unit sphere (and to get the coordinates on an arbitrary sphere, of course, you'd just multiply those by the sphere's radius); similar calculations work for the other axes, to define e.g. the user's facing direction. 

Another straightforward approach is by using your own low-frequency noise to draw (or define) a figure in polar coordinates. Suppose you want a blob centered at the origin, of average radius 1; this can easily be scaled and translated to other positions and sizes. Imagine with the simple equation r=1 — this would define a circle of radius one at the origin. To add a little variation to it, you can change the radius sinusoidally - add a term of the form w1*sin(θ+θ1), where w1 and θ1 are constants I'll get back to in a bit. One sin term won't make a whole lot of difference, but having several different sines of different frequencies will start to add exactly the sort of 'soft' variation I suspect you're after. The overall form would be along the lines of r=1+w1*sin(θ+θ1)+w2*sin(2θ+θ2)+w3*sin(3θ+θ3)+w4*sin(4θ+θ4)+w5*sin(5θ+θ5) - or more terms if you want, of course. So how do we pick the values for wi and θi? Well, the θs should just be picked randomly from (0,2π) - in other words, each 'wave' on the surface's shape should start at a different point around the shape. As for the w's, there are several different choices. Choosing wi at random from (0, w) (for some fixed w that represents the 'overall variation' to give the shape; I might start with w=0.25 but experiment with w=0.1) for every i will lead to so-called white noise, where all the frequencies have equal weight — this will be by far the 'blobbiest', with wide variations at all frequencies. Choosing wi at random from (0, w*(1/i)) — in other words, dividing each random weight by i — gives pink noise, where the weight trails off, but slowly. This is also known as 1/f noise, and it's the most famous 'fractal' noise. Finally, choosing the weights randomly from (0, w*(1/i^2)) (in other words, dividing each random weight by i^2) gives brownian noise - this is the 'softest' of the three, with the least variation from a circle - it'll generally be an oval-ish shape. Here are examples of the three, using a 'total weight' of w=0.25, and using the same set of random values for the wi and θi pulled from random.org: "White Noise" blob: 

To flesh out Nick's answer a bit: the core concept behind the DDA algorithm (which works just as well in three dimensions) is that for each axis of your grid you keep track of the next 'crossing point' for that axis in terms of your line parameter; each step of the algorithm consists of finding which axis has the next crossing point (which is a simple compare in two dimensions), taking the appropriate step, and updating the next-crossing values for each axis. 

Above and beyond the answers in the question Tetrad points to in comments, there's also Racing The Beam, which takes a look at the coding and culture of the 2600 - it's by no means a perfect book, but it's well worth a look. 

My first instinct is that you've got a mistaken assumption hiding in the sentence 'Basically, a lot of game components (instantiated inside of Game) will have to gain access to the Journal functionality.' Why will a lot of game components need access to the journal? The way you've laid it out, journal entries should only be coming from your 'story manager' or equivalent; information the player learns about NPCs can come from this, information they learn about objects can come from this, etc. At worst, it feels like you should hang the journal methods off of your core Player class somewhere and be making calls along the lines of (which will then call to the journal class behind the scenes, of course). Regardless, the upshot is that 'lots of game components' needing access to this fairly specialized entity is a good sign of a design error somewhere else in the chain. 

Based on the discussion in comments, I would say that the question you're asking is several steps removed from the question you should be asking at this stage of your project. The first and foremost question is, "What do I want my player experience of the dungeon to be like?" Do you want the player in near-constant combat, with a sense that they are never actually safe? Or Do you want them to have brief bursts of excitement and action with pauses for recovery in between in order to heighten the next encounter? After you've ironed out the player experience you want, then you can start asking the next question: "How can I design a dungeon to support the player experience that I'm after?" But be careful here — dungeon design is much more than just the layout of the individual units. It also includes issues like encounter density (does every 'room' have something in it? Does every room have a monster in it? What about monsters roaming the corridors?), features (what is my 'special' room set? Should every level have one? What about entire special levels?), global geography (is there just one stairway up and one stairway down per level, or do levels have separate exits to the aforementioned special levels? What about exits that traverse multiple levels? What about traps that might drop the player several levels? Do I have secret doors? What about secret stairs?), and so on. Once you understand what your dungeon is trying to provide from a game design perspective and how its structure supports that design, then you can start to worry about how your code works to build the sort of dungeon structure that you're after — but worrying about the code before you really have a good grasp on your design is putting the cart before the horse here. 

Finding connectivity in a general graph is usually done with floodfill-style algorithms (i.e., breadth- or depth- first search and variants thereof) anyway, so I don't think that abstracting out the process in the way you're describing is actually any great help. Instead I would maintain the core data structure in a grid; there are very standard approaches for storing hex grids (which is what the bubble grid amounts to - imagine 'inflating' the bubbles until the gaps between them fill in) in rectangular 2d arrays that are directly applicable here. (And I can fill in more details on the specific grid structure here if you need them, certainly.) The one small 'catch' is that you probably want to initialize your flood fill/search structure by adding all nodes adjacent to the top or walls to your 'to be processed' queue; this is likely to be quicker and more straightforward than flood-filling from each of the connected bubbles in turn. Regardless of how you do it, though, the connectivity pass should be so fast (you're iterating over probably not more than 100 items!) that doing anything too complex with it smacks of premature optimization; this just shouldn't be a huge part of your frame time. 

First of all, notice that unlike the position update, this one isn't corrected at all for different tick values, so changing your dt (i.e., your ticksPerSecond value) will change how quickly acceleration changes the velocity. But even correcting for that (for instance, doing something like ) isn't really the right thing to do; that would be equivalent to saying V=1/(T0-A*t) for some value of T0, which is physically incorrect. Instead, you want to do something roughly equivalent to what you've done for position: