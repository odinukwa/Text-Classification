But that would throw error messages in all the applications, and potentially stopping new customers from registering. Therefore, I am looking for this auto-converting rule/trigger which will handle any updates or inserts into this table. Is it possible to do this at all, so it won't come back and bite me later? 

Needless to say, it is impossible to get fluent in the naming of our database objects. Also, because we are very agile with releasing new updates (uptime is not much of a concern so fast is better than correct at first attempt), we keep adding more objects with wrong naming. Postgres will help me out in some cases, but it will not fix references to a table inside a stored procedure and the same goes for any references from our any application, or configuration script. What I am after is that if I write a stored procedure then the stored procedure will use the following while running: 

I think it is incredibly tedious to administer user rights in Postgres. If I for example want to give editing access to an updatable view, then I need to ensure that the user has the right accesses to, the database, the schema, the underlying table, the sequences used (for inserts), all the columns. So often something goes wrong, also due to my lack of understanding. However, I don't really see any need to have a deep understanding of this. I can imagine a tool where I could just grant access to the view and the tool would somehow cascade (is that the right expression) the user rights to all needed objects. I understand that this could get difficult to do if giving access to, say, a pl/pgsql function, which touches 100s of objects under various conditions, but for basic objects like views, tables, etc. this should really save me a lot of time. Please tell me if this question should have been in the softwarerecs StackExchange, I felt that this was the right place, since it is so specific to postgres and, I believe, of general interest. 

That sounds way more flexible. I do lose my relational integrity, but I don't know if that's such a big issue. Just to sum it up: in the end, the user has to select a product from which a record in any of the applicable tables will get created for him/her and thus grants the user privilege to that functionality. 

That just feels wrong and will have me change the database table every time we add a new product type. Something I did think about is something like this: 

This was a mistake. CREATE TABLE ... LIKE does not copy foreign keys, so our new users table lacked all foreign keys. We then did basically the same trick: 

I've got a table and a table . The table obviously contains pages the user wants easy access too. But, there's a new requirement now: every user gets 3 unmutable bookmarks. One of the bookmarks (be it an unmutable one or a user-specific one) is marked as homepage. Always. I'm thinking about 2 solutions, but I'm not sure which one to choose: 1) Add those 3 records for every user and use triggers or application logic to enter those 3 records automatically when a new user is created. 2) Keep those 3 'records' out of the database altogether and fix it in the application (on the 'bookmarks' page). This solution has a great disadvantage: by default, one of the 3 unmutable bookmarks is selected as the user's homepage. The user can change their homepage to one of the other 2 unmutable bookmarks, or a bookmark of their own. I would have no place to store this data, or I would have to insert the 3 unmutables in case the user makes a change. But that sounds hackish. What would you do? Is inserting 3 records for all users a design flaw? 

Now I would like to utilize the test view or any other view in a GUI which simply presents an editable table. This is possible with the recently introduced automatically updatable views. I want the table to contain drop-downs containing all possible values every time there is a column with constrains on it, like the column with a foreign key in this case. How can this be achieved? I know that I could utilize enums and I do that today, but on Amazon RDS they are unreasonably hard to modify. I had an idea of (ab)using the "EXPLAIN SELECT" query for each column and check which table and column is being queried. 

What this achieves is that I could now modify the new "matches" table and for example add a column or rows, which do not need to get presented in the "reconciliations" view (by adding a where clause to filter them out). I am on Postgres 9.5 so the view is automatically updatable. Initial tests shows that there are no immediate problems with this, so I am asking this question to know what kind of problems I should be looking for. Performance is not a big issue. 

There's a bunch more but I'm trying to keep it straight-forward here. The problem I'm facing is that there's no overarching object called Product. A table in which we set the prices, the invoicing interval and what not. Functionalities X to Z are now granted to the user by an admin who just adds a record to those respective tables. That's gonna change; a user will be able to just select a product, pay and use it right away. How do I setup this table flexibly? How do I refer to those individual tables? An option I do not want is this: 

Whenever we apply changes to the database, we first run it on the copy database and then on the production database. But something has gone very wrong earlier this week. We applied this script: 

I'm working on a large application, with tons of tables and a huge codebase. It's a system in which people have rights to use functionality X and/or functionality Y and/or functionality Z. 

... the query plans on both databases look completely different. Both tables have around 2 million records, and on the production database it joins on all those 2 million records, on the copy database it just takes 1 row as it should do. At that point we realised that setting FOREIGN_KEY_CHECKS to 0 while inserting may have been (yet another) mistake, so we ran this script on both databases: 

We are creating SAAS where we will at most have 50.000 customers. We are considering creating a user in the Postgres database for each customer. We will map each user that logs into our service to a user in the database in order to be very sure that they only have access to their own data. We also want to implement an audit trail directly in the database by this solutions, which utilizes triggers. If each customer has its own database user, then it would be very easy to see who did what, even if two customers would share the same data. Will we be running into some unexpected problems because we have 50.000 users in our database? Performance-wise or administration-wise. Maybe connection pooling would be more difficult, but I do not really know whether we would need it. 

I am considering a model where I use PostgreSQL COPY to copy data from a file into a table. I was wondering what kind of performance to expect on high-end hardware. An interval in MB/s would be nice so I can start estimating. If you just know the answer on other databases, I would be interested to compare.