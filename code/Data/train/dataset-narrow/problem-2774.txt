First of all I don't understand why there's H and H'. Isn't the halfway vector unique for both layers? It says that just p,r and F vary from layer to layer. But the fragment is the same, so I don't understand how to compute H'; I also don't understand, for how it may seem banal, what does [F D] mean. Is that just a plain multiplication? I don't understand why it uses the bracket square syntax; To compute D' should I replace p with p' and r with r' ? 

I want one like this !! Maybe I am using wrong values of phi and other values? Or there's something wrong in the formula? 

light{Specular | Diffuse | Ambient} : 0xffffff (converted to a rgba vector of course); materialAmbient: 0x543807 ; materialDiffuse: 0xc6901d; materialSpecular: 0xfdefce; materialShininess: 27.8974. 

And I believe it's correct. Now since I need to draw it with a variable number of points, I'm trying to apply the explicit definition: 

I checked many times the formulas and the implementation, and it seems like I've done all correctly. What's the problem? 

The parameters metalness, smoothness and transparency are uniforms. I try to vary them, but I cannot get something similar to this result: 

Which seems very strange to me, I've seen other images of Ashkhmin-Shirley implementations on the web, and they aren't similar. This is an example: 

Runs just in Objective-C and not in Swift. Does anyone know how to convert it to a SCNMaterial, or alternatively to use another way to apply a bump map in a SCNMaterial? 

All the tutorials that I've found online speak about using Metal alone, without any other supporting library. But I don't understand if it's possible to create a SceneKit game and then use a Metal layer just to make some optimizations. 

I'm trying to implement the Schlick shading model in the fragment shader. I took the formulas from Karsten Schwenk's "a survey of shading models for real-time rendering": 

Which I believe is incorrect. I guess I'm not applying correctly the explicit definition, but I don't know where's the mistake, I would like to know what I'm doing wrong. 

I am writing an article on WebGL and three.js, I'm trying to search all the built-in variables available in the vertex and fragment shader. I've found many sites mentioning some, for example: Vertex Shader 

But there is no property for the bump map. The only way that comes to my mind is to use a MDLMaterial but I see no way to convert the material back to a SCNMaterial. The method: 

I already checked and it seems like all the uniforms and varying are passed in the right way, I pass P and N from the vertex shader. The variables are: 

I'm trying to draw an Earth, as I've found the textures in this site: $URL$ I loaded the diffuse, specular and bump maps: 

The plist file was invalid because I renamed the image, so that the name contained in the plist file wasn't the true one. So I just made the spritesheet again with zwoptex and now everything works fine. 

But I get a result similar to a lambertian surface or Oren-Nayar model, where the specular component is absent: 

But I know there are more, I just can't find a resource that mentions all the built-in variables. Also, some of these variables are passed by three.js classes, I need to distinguish the built-in variables from the ones which are created by the class. Does someone have a list? 

But, alas I'm not sure what parameters I need to use for left, top, right and bottom when iterating across the scene, viewport or screen. Can anyone assist me? Edit: I found this example (unfortunately D3D) of someone doing something similar. The author seems to be just multiplying _11 and _22 by the width (scale up) and then modifying _31 and _32 according to the current tile position - iterating through the whole grid. I did try this but I got a black screen of doom. 

advice I had as a UI designer/developer a very long time ago is to design/develop in black and white, add colour only for emphasis. I've seen so many bits of software over the years that were destroyed by a theme, skin or graphics that the developer probably thought was a good idea at the time, but that looked pretty awful to anyone with a small amount of aesthetic judgement. The other tip I would give is to make sure all of your bitmap assets are scaled correctly, with filtering and/or use anti-aliasing. The final rule is to design "sets", so that all of your assets have a similar aesthetic. If you apply those 3 it's hard to go wrong :). (Another quick tip: If you're going to use gradient fills, make them as subtle as possible). 

The keyword you're looking for is "easing". There are lots of different easing functions that behave and look different but all of them interpolate some variable from A to B given a time T. If your ship is at A and you want it to decelerate until it hits B, you can give it a velocity by, for example, applying this function: 

Shimmering I understand shimmering in textures is caused by sub-pixel accuracy aliasing against the regular grid of pixels on the screen when drawn. I have a good example of it here, whereby I'm attempting to scroll/pan a 2d texture by modifying the texture coordinates rather than by moving some actual geometry. The texture is "wrapped" and my idea was to fill in the bit falling off the left (or right), filling it in on the other side, to effect a single scrolling/panning surface of (almost) infinite size. Unfortunately with random noise on the texture, when I'm zoomed all the way out the shimmering is kind-of horrific. When I zoom in a bit it seems OK, which is kind-of confusing to me. But anyway, is there a filter of some kind I can put into my shader to prevent this shimmering? I'm at something of a loss here. (To complicate matters my texture is actually just L16 luminance and I'm palettising it in the shader - the L16 is sampled with LINEAR, the palette texture is POINT, though I'm pretty sure this makes little difference to the shimmering). Please note that with the video, YouTube has done its absolute best to remove any detail from it, meaning it's difficult to see the shimmer under the encoding artifacts. 

I thought there might be something screwy with my texture coordinates too, so I hard coded them to be 0.0, 0.0 on the left and 2.0, 2.0 bottom right. I expected x 2 repeat but got a similar result to the screenshot, with the texture top left and then what looks like clamp across the rest of the image. What mistake have I made here? (Note that the screenshot isn't the 0.0, 0.0 -> 2.0, 2.0 experiment I did, it's the general case I get as I'm panning my image around).