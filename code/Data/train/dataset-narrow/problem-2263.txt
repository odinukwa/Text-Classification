I'm interested in why natural numbers are so beloved by the authors of books on programming languages theory and type theory (e.g. J. Mitchell, Foundations for programming languages and B. Pierce, Types and Programming Languages). Description of the simply-typed lambda-calculus and in particular PCF programming language are usually based on Nat's and Bool's. For the people using and teaching general-purpose industrial PL's it is great deal more natural to treat integers instead of naturals. Can you mention some good reasons why PL theorist prefer nat's? Besides that it is a little less complicated. Are there any fundamental reasons or is it just an honour the tradition? UPD For all those comments about “fundamentality” of naturals: I'm a quite aware about all those cool things, but I'd rather prefer to see an example when it is really vital to have those properties in type theory of PL's theory. E.g. widely mentioned induction. When we have any sort of logic (which simply typed LC is), like basic first-order logic, we do really use induction — but induction on derivation tree (which we also have in lambda). My question basically comes from people from industry, who wants to gain some fundamental theory of programming languages. They used to have integers in their programs and without concrete arguments and applications to the theory being studied (type theory in our case) why to study languages with only nat's, they feel quite disappointed. 

I'm not sure if I correctly understood your question, but if you're looking for a programming language based on a kind of string rewriting system, you probably would be intersted in Refal, which is based on Markov algorithm formalism (a Turing-comlete formalism which is also a grammar-like string rewriting system). 

Sorry if I'm mistaken with the place to ask the question (maybe I should go to stackoverflow.com/mathoverflow.net?). I wonder if there is a proof that when evaluating extended Euclidean algorithm the Bézout's coefficients (that is s and t in identity as + bt = gcd(a, b)) will not exceed some reasonable values (depending on a, b, I guess). In particular implementation on some general-purpose programming language I'm interested in overflow correctness of the program. To be precise I can mention that I use Victor Shoup's description of the algorithm (4.2 in his book “A Computational Introduction to Number Theory and Algebra” freely available from his homepage). 

Where can I get the photo of “Introduction to automata theory, languages and computation” by Hopcroft and Ullman '79 (first edition) cover in order to be able to read all the phrases placed on the cover? Obviously the ones that gave me Google.Images (from Wikipedia, Amazon and others) do not allow this. Solved: $URL$ 

There is an interesting Springer volume on applications of Gröbner bases in coding and cryptography: 

Personally I'm doing my research in the algorithms for computing ideals of error locator polynomials (quite well-known concept in coding theory, especially syndrome decoding). In the case of codes from algeraic geometry error locators ideal is usually an ideal of polynomial from several variables — that's the place, where Gröbner Bases play central role. In the abovementioned volume most interesting part for me is the S. Sakata's description of BMS-algorithm and a survey of its applications for decoding algebraic geometry codes. 

First, I believe your implementation is not polymorphic. Second, and more important, even if there is no injection from $\mathbb{Z}\to\mathbb{B}$ to $\mathbb{Z}$, there is one from the elements of $\mathbb{Z}\to\mathbb{B}$ that your program constructs in some finite time. (If you give up polymorphism but not state, then there is a way to find a counterexample to any potential implementation. I learned this from Paulo Oliva, but I don't know how yet.) 

This is not an answer, but too long for a comment. I'm trying to explain why the question, as posed, may be hard to understand. There are two ways to define computational complexity for a device X. The first and most natural way is intrinsic. One needs to say how the device X uses the input, so that we may later look at how the size n of the input affects the run time of the device. One also needs to say what counts as an operation (or step). Then we simply let the device run on the input and count operations. The second is extrinsic. We define computational complexity for another device Y and then we program Y to act as a simulator for X. Since there may be multiple ways for Y to simulate X, we need to add that we are supposed to use the best one. Let me say the same with other words: We say that X takes $O(f(n))$ time on an input of size n if there exists a simulator of X implemented on machine Y that takes $f(n)$ time. For example, an intrinsic definition for NFA says that it takes n steps to process a string of length n; an extrinsic definition that uses a RAM machine as device Y says that the best known upper bound is probably what David Eppstein answered. (Otherwise it would be strange that (1) the best practical implementation pointed in the other answer does not use the better alternative and (2) no one here indicated a better alternative.) Note also that strictly speaking your device X is the regular expression, but since the NFA has the same size it is safe to take it as being the device X you are looking at. Now, when you use the second kind of definition it makes little sense to ask how restricting the features of device X affects the running time. It does however make sense to ask how restricting the features of device Y affects the running time. Obviously, allowing more powerful machines Y might allow us to simulate X faster. So, if we assume one of the most powerful machines that could be implemented (this rules out nondeterministic machines, for example) and come up with a lower bound $\Omega(f(n))$, then we know that no less powerful machine could do better. So, in a sense, the best answer you could hope for is a proof in something like the cell probe model that simulating an NFA needs a certain amount of time. (Note that if you take into account the conversion NFA to DFA you need time to write down the big DFA, so memory isn't the only issue there.) 

No discussion of a non-standard presentation of remarkable ideas would be complete without mentioning the work of Jean-Yves Girard. Unique is probably the best word to describe it (without being diplomatic or sarcastic). From, the paper Linear Logic. 

The meaning of simpler in your question is unclear. Kripke structures have a labelling function on states. LTSes have labels on transitions, which can be viewed as a labelling function on transitions. Why is one simpler than the other? In the context of your question, using acronyms like "ACTL" is ambiguous because the "A" could mean all paths or action-based. The difference, in my opinion, between Kripke structures and LTSes is based on modelling convenience and not simplicity. There is a lot of work comparing and contrasting the two. Here are a few starting points for chasing down related work. 

I do not know of good tutorial material, but there are papers that are sufficiently elementary for a grad student (like me). The first might be what you are looking for (emphasis is mine). 

Your question itself is not naive but the type of answer you ask for is. It is rare for any line of work or intellectual enquiry to have an elevator pitch explanation. Not all would agree with your characterizations of mathematics and physics because they ignore the depth and nuances of those fields. Theoretical computer scientists are concerned with studying and applying computation. The computational perspective is a deep and all encompassing one so the study of computation is also deep and has a bearing on many other areas of study. Every single process, whether arising in nature or synthetic, manipulates information. They compute. As in mathematics, there are different languages and types of structures involved in computation, as in physics, there are fundamental laws about computation that we are trying to discover, as in chemistry, fundamental elements of computation can be classified. Theoretical computer science is broad and robust enough to be amenable to any perspective you bring to it. Some of the questions studied are: 

The Lattice of Flow Diagrams, Dana Scott, Programming Research Group report 03, Oxford University, 1969. Flow diagram = Control flow graph. Another viewpoint is of imperative programs as generators of possibly infinite transition systems. The transition systems will form a coalgebra. Introduction to Coalgebra. Towards Mathematics of States and Observation, Bart Jacobs. Artem's comment and Neel's answer provide further possibilities. There are many answers to this question depending on what you mean by imperative program and what properties are of interest. Do you care only about syntactic objects or some underlying semantic notion? Even if you only care about, say, control flow graphs, there is a difference between arbitrary flow graphs and those generated by standard structured programming constructs (the latter are reducible). These properties in turn affect the mathematical structure of the space involved. 

It's not clear to me how to reduce this to your problem. One observation that might help is that the output of your problem also depends only on the sums, not on the exact positioning of the queens. (See Theorem 2.4 in [Rivin, A Dynamic Programming Solution to the n-Queens Problem, 1992], although perhaps this is easy to see.) Knuth proves that BINARY DIGITAL TOMOGRAPHY is NP-complete by a reduction from the BINARY CONTINGENCY PROBLEM. This is a very similar problem, except in 3 dimensions, and without diagonals. 

Given is a dag. You want to label each node by how many nodes are reachable from it. $O(V(V+E))$ is a trivial upper bound; $\Omega(V+E)$ is a lower bound (I think). Is there a better algorithm? Is there reason to believe the lower bound can be improved (related: what exactly is known about lower bounds for transitive closure)? Motivation: I had to do this a couple of times while representing fol formulas as dags. Edit: Please note that simply doing $c_x=1+\sum_{x\to y}c_y$ counts paths, not reachable nodes. (I added this because apparently many people thought this simple solution would work by the votes I saw on a now-deleted answer.) In fact, this problem appears precisely when you want to do something interesting with 'shared' parts, nodes reachable by more than one path. Also, I say dag, because if they are solved, then solving digraphs is easy. 

There are several algorithms for estimating cardinality. This problem seems to be important enough in practice. For example, Redis, which describes itself as a ‘data structure server’, supports it. I suspect students would find this a good motivation. The algorithm that Redis uses, HyperLogLog, may be too difficult to analyze in an undergrad course. But, there are some alternative algorithms that seem good for an undergrad course. One is to use the minimum value of all hash values seen. Another is to keep the maximum $k$ such that $2^k$ divides at least one of the hash values. The HyperLogLog paper is a good starting point for even more alternatives: 

This works in $O(m+\lg n)$. Compare with "traverse the tree and insert in the result", which takes $O(n+m\lg m)$. Update, in response to the request for $o(m)$ auxiliary space: I believe you need $\Omega(\lg m)$ auxiliary space to build an almost complete binary tree given that you are told the size in advance and then you receive the elements in-order one-by-one. Draw the complete final tree and imagine you received the first $k$ elements. These elements are separated from the others by a vertical line that cuts some edges. Since the left extremities of those edges need to be connected later, you need to remember them. In the worst case the vertical line cuts a zig-zag with $\lg m$ edges. I didn't work out the details, so I'm not sure how the extra bookkeeping affects the running time. Second update: JeffE's comment below says how to do it with $O(1)$ auxiliary space and within the same time bounds. (For mutable trees, at least.) That means that my waving hands argument above about $\Omega(\lg m)$ space is wrong.