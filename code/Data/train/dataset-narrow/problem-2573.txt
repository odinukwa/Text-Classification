Choose 4 (real) numbers at random in the range [1..10] - these will be the frequencies of your sine waves. I 'rolled the dice' at random.org and got: f0 = 1.75, f1 = 2.96, f2 = 6.23, and f3 = 8.07. There's nothing magical about the number 4 (you can use more, but using any fewer will start to make the individual sine waves more obvious) or the range 1 to 10 here (it'ss just a way of making sure that your highest and lowest frequencies aren't too far apart). It might make sense to choose one frequency in the range [1..2] and the rest in the range [2..10] just so that you have a known 'dominant' sinusoid. For each of these four (or however many) frequencies fi, choose an amplitude ai somewhere in the range between -C/fi and C/fi for some constant C. The value you choose here controls the overall amplitude of your wave - for convenience's sake, I picked C = 1. Then I needed random numbers in the range [-1/1.75 (= -0.571) .. 1/1.75 (=0.571)], and similarly in the ranges [-0.338 .. 0.338], [-0.161 .. 0.161], and [-0.124 .. 0.124]. Rolling the dice four times again, I got a0 = -0.143, a1 = -0.180, a2 = -0.012, and a3 = 0.088 . (Note that this probably isn't quite the best way to do this step - since the maximum possible value of the function is the sum of amplitudes abs(a0) + abs(a1) + abs(a2) + abs(a3), it might make more sense to divide each of your four ai values by this sum once you've generated them, and then multiply each one by C so that you can be sure the precise maximum the function can attain is C.) Pick four 'offsets' oi, each in the range [0..2Ï€] (0..6.28) - these will tweak the starting points of your waves so that they don't all begin at 0. I got o0 = 1.73, o1 = 4.98, o2 = 3.17, and o3 = 4.63 . 'Plot' the function f(x) = a0 sin(f0 ( k x + o0)) + a1 sin(f0 ( k x + o1)) + a2 sin(f0 ( k x + o0)) + a3 sin(f0 ( k x + o0)) - here k is another constant, one that controls the horizontal 'stretch' of your functions. You'll have to figure out what this is for your own application; for convenience I just picked k = 1, and so my overall function is f(x) = -0.143 sin(1.75 (x + 1.73)) - 0.180 sin(2.96 (x+4.98)) - 0.012 sin(6.23 (x+3.17)) + 0.088 sin(8.07 (x+4.63)). 

I love to work with Vectors this way so whether you use this or not, I hope you learned something from it. I have created a very basic program for you that does what you want. Get it from github: $URL$ The readme shows how to make it work. 

Now all you need is to sync the project with the gradle files. In Android Studio I would go . If you do not use Android Studio and cannot find this just search google how to sync with gradle for your IDE. 

We all know that each game has elements from another game but when does one cross the line of copyright? I have a view particular questions about this since this "line" is very vague. 

I also have a each character separately in and . To make clear to what I need this is a complete it needs to be accompanied by a single image that holds all the images of each character. 

Just log the pointers to see the output and set accordingly. But why do you need the active touch? Coding the movement straight into the listeners is no problem. Or better to make two extra methods for walking and jumping. I cannot look into the rest of your code but something like this should work. The listeners only trigger when there are actual touches so do not bother setting up a boolean for that. 

The math depends on how everything is set up but is very simple. For example it makes a difference if the center of the screen is the camera location, the top left or bottom left. You should end up with something like this: 

Now this is not much different then your method, only mine stores if the tile can be walked upon too. Your walls should probably never be walked upon and floors should so why bother changing to my method? Scalability is the answer. What if you decide that you want to add objects to your map? If you have say 10 objects like tables, chairs, pillars, etc then for each int that represents a floor you need 10 more of those. Where I just add another int for the objects texture or perhaps the object itself if it has more properties like a tile. Yes you could add another array to represent your objects and draw that over your tiles. But then you decide that object a can damage the player in a certain state. Now you need to make another array or a extra int to refer too. Where I change the behavior of a object in it's class. This is why you use a object oriented language anyway. 

I'm working on a website for asynchronous two-player games (mostly board games); as part of the site's development I'm hoping to use it to playtest new games I design. The good news is that this offers a much larger pool of playtesters; the bad news is that they'll be remote, so I have no easy way of gauging reactions or of directly watching them play. Obviously I can get a lot of useful information just by extracting metric data (e.g. How many moves games take, who wins more often, average margins of victory, etc.), but I'm wondering how much I can go beyond this too: 

Another serious con to having Vec3 inherit from Vec2 or, arguably, to having both inherit from a single Vector class: your code will be doing a lot of operations on vectors, often in time-critical situations, and it's very much in your best interests to make sure that all of those operations are as fast as they can be - much more so than it is for many other objects that aren't quite so universal or low-level. While a good compiler will do its best to flatten out any inheritance overhead, you're still relying more on the compiler there than you'd like to; instead, I would build them as structs with as little overhead as possible and possibly even try and make most of the functions that use them (with the exception of things like operator+ which can't really be helped) be globals rather than methods on the struct. Early optimization is generally recommended against, and with excellent reason, but in a circumstance like this where you can be sure that vector operations will almost certainly be a substantial chunk of your runtime, it's worth a bit of effort up front to design for efficiency. 

The set of pixels on the heightmap for this second version can be anything from a straight subsampled grid (i.e., find and , similarly for and , and consider all pixels with and ) to an 'overlapping samples' approach where you look at every heightmap-pixel within a circle centered around wherever (vx, vy) maps to on the heightmap; you could even subsample your heightmap and interpolate between heightmap pixels for finer detail. One major caveat with this whole approach is that fractal terrain isn't really very 'terrain-aware' - it knows height, but it doesn't know anything about features : it doesn't really know what a river is or the effect it has on the surrounding geography; it can't distinguish easily between 'old' and 'new' geography; etc. If you want truly realistic terrain then you should consider some of the more simulationist approaches - but these tend to directly conflict with the kind of terrain modifications that the linked video shows, so if realism is your goal then it may be worth rethinking the voxel approach entirely. 

We can still use this vector for our rotation since nothing has changed there. If we a origin of and a target of the previous direction vector would have been . what we just did is shrank the length of it to 1 by maintaining it's rotation. If we do this to all our vector movement we have a equal starting magnitude of 1. Now let's make a velocity vector. At this time I have to warn you about how LibGDX deal with vectors. A vector is passed by reference by default and it's methods will work on the method itself. So if you do Then not only both velocity and direction have been scaled by 100, velocity is just a reference of direction. If there is something strange going on 99% of the time it's because of this. It gave me headaches when I started out with LibGDX. But luckely, we can just copy the vector. 

Sorry yesterday I was a wreck :) but I just found a solution for you. Simply build up the button yourself... lol, I cannot believe I didn't think of that yesterday? 

Now we can use the direction vector to move your arrow towards the mouse. But remember when I said a vector is a magnitude as well? Currently that angled vector stretches has the same length as the distance between the two other vectors we got direction from. So if we add to it would be instantly be on top of the mouse pointer. We can deal with this by normalizing the direction and make the total magnitude of it . 

I understand there are not much lawyers here, but how could anyone create a game these days that does not cross the lines of copyright. Like the Mechwarrior example, there are plenty of games nowadays even movies that use this concept. For what it matters Mechwarrior could have ripped the idea from the Gundam anime series. With so many titles coming out each week including the indies it is next to impossible not to infringe into someone copyright. 

As for many things within game programming you only calculate what you need to calculate and discard the rest. For collision detection on a tilebased game it is as simple as just checking the tile you or any entity wants to move too, if that tile has a blocking flag you disallow moving to that location. It is likewise for the tiles you see on screen, only those that you visually see will get calculated and rendered the others will be discarded. You would not load the gameover screen until it is needed right? Same goes for NPC's, if they do not need to move outside the screen then do not calculate that, if you do want some variation off screen you just calculate a couple of tiles outside the screen. The same rules apply for modern (FPS) games, you put many parts of a level inside invisible blocks, if you cannot see that block from your current location and angle you do not render it. Only if the player is within a block you need collision detection on the objects within that same block, first you check the collision with a simple cube or sphere around the player and if something hits that boundary you go check for mesh/object collision which is very expensive. 

Here's another approach to procedural generation that hasn't been explicitly mentioned yet: spline skinning. You can use a version of Hermite Splines (which provide a curve interpolating positions and tangents) to define the curves: when it's time to generate a new segment, just choose a position (roughly in the direction of the previous segment, as bcrist says) and a direction (roughly in the same direction - e.g., within some well-defined cone of the previous direction), then use the new position+direction and your previous position+direction to build a new 'spine' for your cave. Once you have this backbone, you can skin it with a cylindrical construction: determine the positions and tangents of (for instance) 10 points along the curve, use those positions/tangents to find an orthogonal 'frame', and then use these frames to build cylindrical segments. One small caution with this is that the cave can't curve too much, or else you may run into self-intersection issues. EDIT: Here's a rough pseudocode breakdown of the algorithm: 

A variant on lorancou's approach: for each puzzle type, keep an array of (shuffled) puzzle numbers; then every time you hit a puzzle of that type, get the next number off the list. for instance, let's say you have Sudoku, Picross and Kenken puzzles, each with puzzles #1..6. You'd create three shuffled arrays of the numbers 1..6, one for each puzzle type: 

Likewise, you can do similar tests for the other three regions using the appropriate lines from inner to outer corner. These tests may look complicated, but they're pretty straightforward and they have a lot of advantages: they'll work no matter where your inner box is (as long as the box is entirely contained inside your screen), whatever the dimensions of your screen and inner box are, and they don't involve anything more complicated than a few multiplies - they can even be done in purely integer math if need be. 

It's unlikely there would be any problems with conflating the definitions and treating points as vectors â€” but be a little careful, because some APIs have a 'Point' class that you might need to use (for representing, e.g., vertices of polygons) and if you define your own class you'll want to be able to port them back and forth. What I would do, though, is treat them equivalently in your code; if you do use vector and point interchangeably, then there's no reason that your declaration for the Line() function should be talking about 'startingVector' and 'endingVector'. I would strongly encourage going back to 

i just did the tutorial on Hardware Instancing from this source: $URL$ Somewhere between 900.000 and 1.000.000 draw calls for the cube i get this error "XNA Framework HiDef profile supports a maximum VertexBuffer size of 67108863." while still running smoothly on 900k. That is slightly less then 100x100x100 which are a exactly a million. Now i have seen voxel engines with very "tiny" voxels, you easily get to 1.000.000 cubes in view with rough terrain and a decent far plane. Obviously i can optimize a lot in the geometry buffer method, like rendering only visible faces of a cube or using larger faces covering multiple cubes if the area is flat. But is a vertex buffer of roughly 67mb the max i can work with or can i create multiple? 

Perhaps you can go with only 4 points if you do not have tiny gaps in your level. For bottom you only have to check the bottom middle and for right only the right center. It all comes down to fine tuning this to your own liking. But these are the basics. You have to do the same for the top and the left, just wrap them in a statement like . 

I'll assume you are talking about a 2D game or at least a 2D UI. Well, if you think you need to create graphics for 1920x1080 then you should go for it. If you setup a viewport properly libgdx does all the scaling for you. Personally I have my viewport represent a 1280 x 720 area. You won't see any difference on phones, I barely even notice the difference on descent sized tablets. But I'm not a great 2D artist, lol. Anyway this saves a ton of work so keep that in mind. So what you basically do is create graphics that fit your viewport or camera size. If you are setting the screen size to 1920 x 1080 I guess you should always create your 2D art for that size. For 3D it's different, higher resolution will give you crispier edges on your models. Here I would use a high resolution camera for rendering the 3D and a lower resolution viewport to overlay the UI, again unless you want your 2D to look really crisp on bigger screens.