(Security) zones are what you define by your firewall rules. Usually you map the subnets and VLANs you've created to these. Depending on your security requirements, a zone can consist of more than one subnet/VLAN - you might prefer routing subnets within a single zone through L3 switches instead of your firewall. 

Not sure what you tested. You need to aware that any single flow will only use one of the port combinations each way. Port aggregation allows you to increase the throughput for multiple flows, not for a single flow. How flows are distributed to the potential egress ports depends on the device. Most use either source/destination MAC addresses, source/destination IP addresses, or source/destination IP addresses and port numbers (SA/DA MAC, IP or IP/port). It's completely normal to have one direction of a flow to use a different port combination than the other. 

miss a network mask. Accordingly, the default route back to RTR3 is chosen and the packet loops. Edit:The config marked "One of the level 2 routers" lacks routes to the above subnets. The config marked "The Level 2 A Router config" has them included. 

The network path is "found" anyway by the first data or handshake packets. PMTUD requires just one round trip for each hop where MTU is lower than the currently discovered value. Note that this is per connection as opposed to overhead per packet with fragmentation. A later reduction of MTU again just requires one round trip. An increase in MTU is probed and detected on a regular basis using the data stream. 

VLAN trunks don't automatically forward all VLANs. Each VLAN must be activated on a trunk. One VLAN may be untagged (native), all others must be tagged. The trunk has to be set up in the same way on both sides. 

SYN received very small delay (local stack overhead) SYN/ACK sent longer delay (RTT + remote stack overhead) final ACK is received, socket is open very small delay (remote stack & application overhead) GET is received 

Since you can ping PC-1 from the physical PC (PH) but not vice versa, the most logical explanation is that PH doesn't reply to echo requests (firewall, filtering, ...). Edit after your added PH's routing table: On PH, you need to add a route -> . Otherwise the default gateway is used, leading somewhere completely else... 

This depends largely on your switch. E.g. on HP Provision switches, the monitored ports ingress and egress traffic is copied to the mirror port. When you monitor both port A and port B, you get A->B or vice versa flows twice on the mirror port with some devices and just once on others. I'm not sure about broadcasts, but you're likely to get a copy from each monitored port. Since forwarding is only done with ingress frames, a frame exiting the mirror port will not be multiplied. Usually you just monitor the traffic on a single port in both directions and that's not a problem. When using a passive tap, the tap is a one-way connection (or rather two such connections), so nothing will ever flow back. The problem with aggregating multiple taps through a switch is that the switch won't have a destination port for pretty much any frame, so all frames are likely to be flooded to all switch ports (mimicking a repeater hub). learns all tapped MAC addresses as belonging to one of the tapping ports - this may cause frequent situation were a frame received on on tapping port is forwarded out (to nowhere) the other tapping port. You won't get a complete capture. Also, you must not connect that switch back to the monitored network - this would create a bridge loop, causing a broadcast storm and SAT instability. Cutting the transmit side (for dual-simplex connections like 10BASE-T, 100BASE-TX, 1000BASE-SX, ...) might not work. Using auto negotation requires both sides to see each other which won't work. You'd need to force speed and duplex on the port so the connection just relies on the carrier. This may not work with modern NICs (as very often you can't really deactivate autoneg, just limit it to a single speed and duplex mode). 

NVR as in network video recorder? Do not connect it directly to the public IP network as most devices are insecure. The easy - and unsafe - method is to configure your router with port forwarding to pass requests to the private IP address of the NVR. This is unsafe, as all security issues of the device on that port could be exploited from the Internet and your network might be compromised that way. The safe method to do this is to create VPN access to the network and secure access that way. In order to find your network, you'll need a static IP address or some kind of dynamic DNS service that gets updated when the IP address changes. 

Working with network shares, the #1 bottleneck is usually the server, not the network. For 20 users simultaneously moving .4 Gbit/s, the server would have to cope with 8 Gbit/s which is quite a load. In contrast, using a fairly cheap NAS with four large HDDs would work well for a single user, OK for two users, but it would totally cave in with 10 or even more heavy users: only four spindles can't handle the required I/Os - you'd need a larger count of HDDs or (much better) SSDs. For more than general advice you'll need to detail your environment: 

If you map two paths to a single range the information about the path is lost and is hard/impossible to recover. A relatively easy approach for this is to use two distinct IP ranges for the internal network. Each load balancer maps incoming connections to on of the ranges. Replies source from the IP address the request was sent to and are routed back to the corresponding firewall and load balancer. If you need hosts serving requests from both load balancers you simply give them IP addresses from both ranges. 

It does happen. We've had the luck to get a few dark fiber pairs spliced off when a larger trunk was laid down along a major road just three years ago. In fact, one of our locations doesn't have any local servers any more. It's just some 2 km and you can't see a difference between a local and a remote server. 

Different latencies are no problem but they do add up. When multiple, parallel flows behave the same as fewer flows this rules out general latency/TCP windowing problems. The BDP of 82,500 bytes indicates an LFN though, TCP requires tweaking with few flows. My bet is on channel interference. Each link by itself performs fine but both in conjunction don't. Both channels' bands are different and shouldn't interact but they still might. Check 

Other protocols may be different, but Ethernet transmits most signficant octet/byte first and within each byte least significant bit first. So, a 16-bit value is transmitted 8-9-10-11-12-13-14-15 - 0-1-2-3-4-5-6-7. Check IEEE 802.3 Clauses 3.1.1, 3.2.6, and 3.3. (This is for purely serial Ethernet - depending on the physical layer, up to eight bits may be transferred simultaneously. Additionally, the bit order goes only for the unencoded layer 1.) IPv4 also uses most significant octet first, check RFC 791. However, numbering in IETF RFCs is in order of transmission with the bit order in reverse to Ethernet: Bit 0 = most significant bit = transmitted first (where not otherwise defined). 

For the devices using Gateway1 as default gateway, you need to add a static route with the VPN pool subnet pointing to Gateway2. Alternatively, you can add that route to Gateway1. (Or better yet - as Ron suggested - set up dynamic routing.) As it is, they're using the default gateway which is (apparently) routing the packets out to the Internet. Instead the packets need to go back into the tunnel. 

vSwitches use static VM/MAC-to-port distribution, do not put redundant ports in trunk mode on the physical switch. With this logic you can have complete control over frame distribution/load balancing which wouldn't be possible with trunking and you can use redundant uplink switches without STP blocking ports. Use the vSwitches to map VLAN IDs to port groups: 

A WoL magic packet needs to contain the magic (FF:FF:FF:FF:FF:FF followed by 16 times the destination's MAC address) anywhere within its payload. It doesn't matter if you send it in an (unpractical) bare Ethernet frame or as (most often used) a UDP datagram to any port in an IP packet (to any IP address) - as long as you make it reach the destination port. Even VLAN tags don't matter, the destination port just has permit them out. The frame's destination MAC address doesn't matter either. Usually, your switches will have forgotten the associated port anyway. So, you send the frame as a broadcast at all times. When you need to cross a router you can either use directed subnet broadcasting (if the router allows) or you need to configure a static ARP address on the router's egress interface with e.g. 172.16.39.254 -> FF:FF:FF:FF:FF:FF, sending any IP packet to that address as an Ethernet broadcast. You need to figure out what kind of frames make it out of the destination port. If these are from the default VLAN only this is your only choice. Your downgraded port should work with WoL packets over VOIP as well - if you don't want to use that you may want to add another VLAN, especially for WoL. 

The layer 2 approach: Use static ARP entries mapped to the device you currently want to talk to. If they're behind a router, you need to configure the static ARP on the router. The (simple) layer 3 approach: Put every device behind its own router. Configure your local route to use the router in front of the device you currently want to talk to. The layer 3 with NAT approach: Put every device behind its own router. On the router, configure destination NAT / port forwarding / virtual IP to forward the required port (e.g. 80) to the device behind it. Talk to the router instead and you've got the device behind it. This allows you to talk to several devices at the same time. Realizing the last approach with a single router will regularly fail due to port forwarding relying on (simple) routing when you need to force the route through a specific interface. If you find a router able to do that, it's what you need. Additionally, you'll need to use an ingress IP pool or several ports on a single IP to separate port forwarding. Probably it's much cheaper to use a bunch of simple SOHO routers. 

$URL$ EDIT after @user1016274's very reasonable comments: Using a switch (the FGT-200E) with only gigabit ports as core may severely limit the overall throughput of your network. Even aggregating multiple GbE ports won't enable you to run multi-gigabit flows across the switch. You should look into options using the FGT as controller only and connecting the faster switches directly. 

Q1) A host should send ACKs as soon as possible = on a per-packet basis. However, as the text mentions it's not in violation against RFCs to only send one ACK at the end of the window. Q2) The sender sounds out the whole window and only when the window is finished the ACKs arrive and a new window is scheduled. This is in contrast to the normal, sliding mode of the send window. This burst is usually only seen at the very start of a transmission where TCP parameters have to align themselves. The 'ACK only at end of window' prevents this alignment. Pretty obviously, this ACK scheme destroys the purpose of the sliding window scheme. Essentially, it limits the throughput to one window per RTT. It's quite like a receive/send window of 1 with a packet the size of the window. 

Both variants are passive. If you need a lab simulation to check whether the device works in all possible scenarios you'd have to expand variant 2 so that you generate your own FLP bursts. 

You're talking about 10GBASE-T - most other 10G flavors use straight 64b/66b. Two consecutive PAM-16 levels (on each lane) represent one two-dimensional symbol. Not all possible 256 symbols are used, but they are selected from 128 maximally spaced combinations (DSQ128). Of these 7 "raw" information bits, 3 are uncoded data, 4 are used for low-density parity check (LDPC). Check Clause 55.1.3 for details. PS: since you're new here, please don't forget to mark the question answered when it is. 

SOCKS(5) is a universal proxy protocol allowing a client to run various protocols across a proxy. This is in contrast to an application level proxy such as an HTTP proxy. Using a SOCKS proxy with a VPN client enables the user to connect a VPN even if he is behind a (SOCKS) proxy. It doesn' t make the VPN connection any better, it just enables more users to actually use it. 

In addition to Ron's anwer, some PoE switches support proprietary, pre-standard PoE modes that weren't as thoroughly designed as 802.3af/at. When active, sending power to a device not supporting it gets more likely. 

An IP address isn't assigned to a router. The router has interfaces and that's where the IP addresses are assigned to. In the diagram, let's assume router 1 has assigned to its downfacing interface. Accordingly, routers 2-5 would have an IP address from the same subnet assigned to each upfacing interface. Let's assume these are , , , and . Effectively, you can use any network address that's not being used anywhere else in your network, including the bottom subnets. Now you can connect one of your four subnets to each routers downfacing interface: , , , and .