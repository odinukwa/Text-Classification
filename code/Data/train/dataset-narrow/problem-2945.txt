Since programming languages are made for humans to easily learn and write in, it is like writing a book. We choose alphabets of the language and write meaningful segments that perform tasks whether it is to loop over an array or read some files. 

Let's start with the term "Loop Invariance". It is a property of a loop that is true before and after each iteration, thus in-variant, non-changing. So then, what is the purpose of the loop invariance in proving algorithm correctness? That is, it is a predicate about what the loop is supposed to do. Thus with proof by induction on this predicate shows the correctness of this algorithm. I know this is still very theory heavy so let's break this down even more. A simple insertion sort. The purpose of insertion sort is to sort an array. Therefore the loop invariance would be that after each i-th iteration, the array is sorted up to the i-th element. The magic here is that instead of looking at the nested for i, j, loops of the algorithm you are choosing the loop invariance that contributes to the goal of the algorithm. To answer (1). There is no sure guarenteed way to choose the correct loop invariance unless you are very experienced in algorithm correctness through countless examples. The best approach is to choose the segment of code that is actually doing what the algorithm is trying to do. Such as the example above, sorted up to the i-th element. (2). I believe this has to do with the proof itself, rather than understanding the loop invariance. Structurally, to prove that the algorithm is correct, you would have to use proof by induction (either simple, or complete) to pove the loop-invariance and the fact that the algorithm actually terminates. Usually proof of termination is a 1 liner, such as when i > array.length, loop will terminate. 

A set of instructions written in human readable language (at least to developers) that is executed to perform a task or goal. 

High level: Just like any language that exists in the world today, it has it's own alphabet, syntax and grammar that is for communication. Technical: First off I just want to note that some languages are interpreted while some are compiled, as for their differences I believe it's off-topic. The idea is that your "code" is tokenized based on the language's alphabet and syntax and formatted into a parsing tree. The parsing tree is then translated into some intermediate code. Lastly the compiler translates the intermediate code into source code or machine code that can be executed by the CPU. 

You're grading attention to wording details, and not comprehension of the material. Grading attention to wording would be appropriate if you were teaching reading comprehension, but it isn't specifically relevant to teaching computer science. 

You could point out that a file has an owning user and an owning group. Since “owner” appears twice, specifying for “owner” would be ambiguous. That's weak because the owning group doesn't really have any special privileges on the file, unlike the owning user: the owning user can change the file's permissions and other metadata, but the owning group only has the privileges granted by the file's permissions. I think the best approach is to pair up user and group so that people remember them together. There's user and group: and . There are basic file permissions for one user and for one group. ACL entries can apply to either a user or a group. The command has two columns for ownership, one with the user and one with the group. Beware that sometimes the naming is not consistent. On the system there's a user database () and a group database (). The command takes both a user and a group, but there's also a separate command and so is often used for the user only, which tends to reinforce the association between “user” and “owner”, so avoid mentioning that if you're trying to dispel the association between “user” and “owner”. 

Flowcharts are a useful tool to understand programs that perform moderately complex sequences of interactions. They aren't always a good way to describe an algorithm, but they are a good way to describe the behavior of a system that reacts to external events in different ways depending on its state, with a non-linear control flow. Note that by flowchart, I'm not referring to a specific formalism — at this level of detail, I might as well call it a state diagram (although a proper state diagram requires a more precise understanding of what the different system states are before you can draw it). Flowcharts have their place in an imperative programming course, but only at a fairly advanced stage, after the students are familiar with basic control structures such as conditionals, loops and subroutines. They're a visual aid to understand complex control or data flow, in the same way that decision diagrams are a visual aid for complex series of conditionals. The only good reason I can think of to introduce flowcharts early on is if the students started with a style of visual programming that resembles flowcharts. Otherwise, teach while loops first. Goto is an instruction that's hard to really understand. (If you think it's just a jump, you don't understand goto.) It's perfectly fine to teach imperative programming without goto, if you're doing it at any level that's higher than assembly (in which case what you'd teach is jumps). Goto is very rarely useful in the real world and is rarely used. Its place in a basic or intermediate imperative programming course is as an incidental mention, as something that exists, that you mention for the students' interest but isn't part of the curriculum and won't be on the exam. I work in industry. I write software for embedded systems in C. Think I should be insisting on the importance of goto? Wrong. In my world, is almost exclusively used for one thing: a forward-only goto, a generalization of that allows breaking to the end of any block. The single common idiomatic use of is to jump to a common cleanup code before returning from a function in C: 

I've always admired the Swiss' education system of teaching kids where they rarely have examinations, but rather through constructive assignments and homeworks to teach students. At a conference I've attended, I heard a quick introduction on gamification of education and I am trying this out with some students. Here is what I proposed: Assesments (excluding exams and final project, due to curriculum and school board constraints) have unlimited re-tests, limited to once a week. 0.5 credit is awarded for 50%+ and 1.0 credit is awarded for 80%+ At the end of the term, their number of credit earned is divded by total number of credits for a "term work" grade worth x% of their final mark The goal here is for students to not worry about a 50, 60, 70, 80, 90 or 100, but rather track their progress through completion of content. I believe the unlimited retries gives incentive for students who are falling behind to realize early and catch up immediately, rather than later. This is to avoid the mentality of giving up because it is "too late" or "wait for next test". To some degree, I believe in the innate competitive nature of CS students transferred from love for gaming I believe this method (with modification to suit your needs) meets what you are looking for. Accurate enough to give a % mark because you track progression. Although I foresee multiple 100% with this method Does not disturb students because they are well aware of their progress, and know they can make improvements rather than blankly stare at an unfortunate poor test 1 Quick and low effort - I just use an excel macro and export to show my class after each week their progress 

Ultimately it comes down to if the work can be done alone? The purpose of group work should not be so that everyone has less work to do, but rather if the original work could not be done within the given span by a single person. In the workforce, you're most likely to be working in a team and contribute to iterative releasts (Agile Methodologies). If your expectation is that because you're in a group, you don't have to work as hard compared to working alone, then you are set to fail. My suggestion would be to design a project such that bi-weekly or monthly iterations are presented, building up towards the final product. Incorporate Agile Methodologies into this as it is very useful in the workforce and teaches team management / tracking. Groups should be no bigger than 3-4, otherwise it is too big to be efficient. The number of hours required for the project should be big enough that everyone is kept busy. Of course some will do more than others, however one person should not be able to do the entire project. If this is too heavy for your course, then I'd suggest stick with single person projects as there is no merit to group work. 

Given your description of the tests, in this situation, I think you should change the way you word your tests. 

What's your students' reaction here? If it's “ah, I see, I hadn't understood/remembered that part of the lecture”, you're doing it right. If it's “ah, I see, I hadn't understood the question that way”, you're doing it wrong. 

I don't see how that follows. (After all, random grade assignment would get a good spread.) I think your students would be somewhat justified to consider your grading unfair, since it isn't based on knowledge or comprehension of the material. Yes, attention to detail is a useful thing, but trick questions, not so much. You are also heavily penalizing students to whom your course is in a foreign language, and possibly students with reading disabilities. The former may or may not be acceptable; the latter, if it is the case, isn't. 

Many coding standards for embedded programming forbid using goto for anything else. In languages that have a better clean-up mechanism, such as try/finally or C++ destructors, goto is useless. Understanding goto is a secondary skill for programmers, part of understanding how a program's code relates to the way the machine executes the program. A good programmer understands goto, but a decent programmer understands how to program without goto. The primary skill for a programmer is understanding how a program works, not understanding how a machine works. (There are exceptions, obviously — I write OS code, doing things like memory management and context switching and accessing peripherals, and that obviously requires a precise understanding of how the machine works. But that's a highly specialized field.) The real difficulty with goto is, as I mentioned before, that it isn't just a jump. It's a jump to a different context. The invariants that hold at the location of the jump may not hold at the target location. A goto introduces a non-local connection between two points in a program that makes it hard to figure out how the program state evolves and what invariants hold. Paul Powell's statement that “GOTO (…) is easy to understand” is just wrong. What's easy to understand is how a machine executes a goto statement. But the most important part, understanding how a program that uses goto works, is difficult. The statement that “it can be used to explain what loops and other items of structured programming actually are” also completely misses the point. Goto can explain how structured programming items are implemented on a processor. It explains an implementation, not the concept. Goto is an advanced step after structured imperative programming, not a step before. Using goto to encode flowcharts is also very misguided. With goto, “we can code directly from a flow chart” — this is true: goto makes it easier to write a program from a flowchart without understanding how the program works, without figuring out the structure in the flow of events. But when you do that, you end up with a write-only program. Sure, you've been able to write it, but you won't be able to explain its behavior when a parameter that isn't reflected in the flowchart turns out to be important, or to modify it in a way that isn't easy to draw on the chart. Write-only programming is the mark of a mediocre programmer, capable only to fumble in the dark until they somehow manage to pass the tests. Goto has its place when you teach how a machine executes code. It's what's happening under the hood. It has little to no place in teaching how to program, and Dijkstra would be quite right to complain about its use in this context. 

The real question is this: do you want to teach your students what is actually going on, or teach them which magic buttons to press in an IDE? Of course for professional programming work nobody would NOT use the most functional IDE they could find for the task they were doing. But if you throw a complete beginner into the deep end of a tool like MS Visual studio, they are unlikely to have any idea what is going on, and the only way they can create a working project without wasting a lot of time is be following a "magic recipe" provided for them. Personally I don't consider that to be a university-level learning experience. Of course they shouldn't be forced to use a command line "for ever," but IMO they should certainly be required to use it until they understand the relationship between classes or modules with physical files (including any required naming conventions,) how to get the individual parts connected together into a complete application, etc. Those are transferrable skills, as is the more basic one of being able to use a command line at all. The details of using a particular IDE are not transferrable, unless you understand what they actually DO. The command-line-level skills are also what you need to figure out for yourself why a "new improved" IDE isn't doing what you want when you first migrate to it! Related to this, also start early teaching them how to use a version control system in a simple way from the command line - not to mention "make!" Actually, using vi (or vim) or emacs plus command line commands can be an efficient way of working without an IDE, since the command line commands you need often are only one key-press away! In a real working environment, there is nothing more confusing than sitting down at someone else's workstation where they have configured an IDE in a completely different way from your own - that's the time when just firing up "vi" in a command window can be the quickest to get "real work" done! 

I don't think this is really a CS problem - though of course some individuals do get "addicted" to computing. The root of the problem is that these students don't know how to study - and ironically, it's quite likely that the education system they are progressing through has never even tried to teach them that basic skill. But you don't have time to teach them that, and teach the contents of your CS course as well. Students who have found everything "easy" since the start of their education are often the worst sufferers - eventually they hit the brick wall where just listening to the teacher and "getting it" with no effort doesn't work any more, and then they are completely lost. The best solution would be to try to get a general "how to study" course into the curriculum for every student - or at the least, start your course by giving them some guidelines (including notes to refer back to!) on the study strategies that work, and those that don't. But you can only lead the horse to the water - as somebody once said, "Homo sapiens has a fundamental design defect: most members of the species can learn, but none of them can be taught." 

In SCRUM, during the end of each sprint, there is a Sprint Retrospective and Spring Review. Important artifacts from the two should be extracted into this report, as it reflects the "developed work". I'm not sure the scope of what you require from your students for documenting the work, is it for the whole internship, or just one cycle? In any case, because Agile is done incrementally, they can just write one template per sprint they've completed. 

I've found a lot of success giving real world (often times very silly) examples of boolean algebra to give them a more intuitive understanding in addition to the pure algebraic laws. An example would be "If it rains tomorrow, I will bring an umbrella so I will stay dry". This is a simple A -> B: If it rains tomorrow then I will bring an umbrella, I will stay dry (T -> T = T) If it rains tomorrow then I will not bring an umbrella, I will not stay dry (T -> F = F) If it does not rain tomorrow then I will bring an umbrella, I will stay dry (F -> T = T) If it does not rain tomorrow then I will not bring an umbrella, I will stay dry (F -> F = T) Using DeMorgan's we know A -> B = !A V B. We can say A = it will rain tomorrow, B = bringing an umbrella and whether you stay dry or not is the equivalent of the resulting truth table value. You can incorporate students in coming up with these silly examples, and having them figure out how the narrative would look like to reflect the truth table values. In addition, pairs can come up with scenarios and test each other's knowledge. (This was during 2nd year University too! So it's never too old to get silly) Lastly as a remark, I did not see you mention some Laws of Boolean Algebra such as Associative, Commutative, Idempotent, Identity, and Distributive. I think it's worth while to introduce these laws during lesson 1 or 2 because solving boolean algebra down the road is built off of these fundamentals. 

I can tell you are very intelligent as this is something only someone who truly understands algorithms and proof of correctness can say. It is actually very difficult for younger students to see this as they are tunnel-visioned by the actual loops in the code instead of the bigger picture. Instead, I think what you are trying to convey is to look for "what part of the code is doing what the algorithm is meant to do"