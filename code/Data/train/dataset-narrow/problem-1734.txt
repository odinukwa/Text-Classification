An easy way to see all your databases (and what web application they belong to) is to go to Central Admin -> Operations -> Perform a Backup. This will give you a tree view of your farm with all of the databases listed. 

This is due to the export-clixml/import-clixml. It actually changes the type of each file object from System.IO.FileSystemInfo to Deserialized.System.IO.FileInfo. Have your second ls command export-clixml to a temporary file, then import and compare against that and it should fix the problem. 

You need to change the rule to use regular expressions instead of wildcards. This is because the R:1 is a regexp backreference. Also - you probably want your pattern to be (.*) for it to be R:1 (most likely it will be R:0 without the parens - R:0 is the backreference for "the entire match") Check out $URL$ for lots of info on the user friendly URL portion of URL Rewrite. 

The utility has a switch that checks for issues with your ACLs. The two things it checks are that the ACL is in "canonical form" and that the ACL length is consistent with the ACE count. I'm assuming the "canonical form" check would catch your problem. It won't automatically repair as far as I know, but you might be able to do some scripting to save the broken filenames off to a file, then re-run icacls against them to repair. icacls ships with 2003SP2+ by the way. icacls reference 

I don't think there is a way to do what you want. The closest available way that I can think of would be to remove the content source, wait for a few crawls to happen, then re-add the content source. The reason you need to wait for a few crawls to happen is that the search index doesn't get cleared of the data for the removed content source right away. During subsequent crawls the data is removed from the index. (You should be able to see errors in the crawl logs that the data was removed) 

The Trace Log section "Path" box will tell you where your logs are located. This screen will also allow you to increase the logging level if the default levels don't show you any useful messages. 

This isn't built into IIS, but there is a module you can install that will perform this functionality. It is called ARR helper, but it will work for any proxy in front of IIS: $URL$ 

The easiest way is to get a tool like SharePoint Manager. Go into the site you are looking at, and find the WebTemplateId property. You can then match it up to a list of known template types. There is another way to do it, but it is much more manual (and ugly) so I won't outline it here. As far as a page template goes - this only works on pages within a Publishing site (in the Pages library...) but you should be able to look at the ContentType field in the Properties for a page in SPM. If you are looking at a pages library, you can even just add Content Type to the view directly within SharePoint and get the same information. 

There is no way to apply a template (.STP) to an existing site. There isn't even an easy way (as far as I know) to apply a separate site definition template (the "site template" you choose on initial site setup) to an existing site. Even if you could do either, removing the existing site content would probably not be part of the process. The closest thing I can think of that would accomplish what you want would be to create a new SharePoint Feature that contains the lists/etc. that you want, and enable that on the sites. You can even staple the Feature to specific site definition templates so that any site created with that template always has the Feature enabled. I don't think you can have a Feature delete existing lists on a site though. 

Here are 2 blog posts that walk you through the database attach upgrade procedure: $URL$ $URL$ Also, check out this chart from Microsoft to see all of the available upgrade options. 

It looks like the ReportServer virtual directory is being processed by SharePoint still. You need to set it up as an exclusion in SharePoint. To do this, switch to the SharePoint 12 hive (C:\Program Files\Common Files\Microsoft Shared\Web Server Extensions\12\bin) and run the command: 

Another option is to train users a little differently. For some reason users typically see as some egregious miscarriage of justice, but if they can use their email address that is fine. In AD, users have what is called a UPN (user principal name) - which is typically @domain.com - which typically matches their email address. Luckily enough, you can use the UPN to login to an NTLM authenticated website. So - assuming the default UPN for your users is the same as your email domain, you can tell users to login with and it will work, and possibly be less of a headache for you. 

I don't believe Performance Monitor counters are available through SNMP out of the box. There are some add-ons available that will add that functionality though. A paid version: SNMP Informant and a free one: SNMP Tools 

What about something simple like setting up a perfmon blackbox and zipping/emailng the log files out once a day? You could then analyze the data in perfmon or Excel/etc. on your local system. It would take a little scripting to stop/email/restart the logging once a day, but it would be fairly simple. 

Close all instances of Reporting Services Configuration Manager or SQL Server Management Studio. Open a command prompt. Register the Reporting Services WMI provider. In the command prompt, run the following command: Run the WMI Tester again to see whether you can now connect to the namespace for the Reporting Services WMI provider and continue with the debugging process. 

You can set the application pool for the web app to recycle when it reaches a certain memory size. Check out the help file for IIS manager to decide whether you need to set it for Virtual or Private memory. You'll most likely want to set the Private Memory setting (typically used for memory leaks) - the recommendation in the help is 60% of your systems physical memory. 

Go into Windows Explorer Select "File Types" Find the PDF file type Click the Advanced Button Uncheck "confirm open after download" Click OK on the screens 

I don't think this is possible out of the box (because the selectable fields are only W3C fields, no access to the NCSA date format for example). You would probably need to write your own logging module to accomplish this. How "real time" do you need the logs? You can flush the log buffer manually using the command: perhaps you can schedule that to run every 10 seconds or something, giving you near-real time access to the logs, without having to do a bunch of programming work? 

I'm assuming you mean the RSAT tools, which have Hyper-V manager in them? If so they are not a feature in Win7, so the method you list wouldn't work. Instead, RSAT is listed as a hotfix, so the easiest way to check from Powershell would be to check if the hotfix associated with RSAT is installed. The hotfix ID is KB958830, so you can query hotfixes from WMI with the command: 

In order for this to work though, you will need to enable the OLE Automation feature in Surface Area Configuration for Features on your SQL instance. I pulled this code from here: $URL$ 

Which will change the app pool for the web site specified by to be whatever is specified in - this app pool must already exist. Writing a wrapper around this in your favorite language should be pretty trivial if you are already talking about using C# to do this. Also, if you aren't familiar with it, adsutil.vbs typically exists in 

Check out the built in (but undocumented I think?) stored procedures and . They should get you all the information you are looking for - just not quite as pretty as activity monitor. Example usage: 

Look at the ASP properties for your site. Under "Debugging Properties" there are 2 settings that are relevant to your situation: 

Unfortunately, it isn't possible to load the IIS provider as the same thing on both 2008 and 2008R2. On 2008 the IIS provider is provided as only a snapin, and on 2008R2 it is provided as only a module. With a little bit of coding, you can actually determine which to use, and dynamically load the module or snapin in your script, depending on which is necessary. I took this code from $URL$ when I was having a similar problem. 

The view contains all the logins with access to the instance. You can filter by type and to get just Windows logins and Windows groups. You can use the the T-SQL commands , and to manage logins without using the GUI. There are similar commands available for database users. $URL$ $URL$ $URL$ 

No - the Time_ConnectionIdle event really is benign. If your application takes too long to respond, it will show up in your normal HTTP log as a 500 error. 

Agree with Jim B and Chris S that it is in use, and that is (usually) a good thing on servers. If however you wanted to pursue the "what exactly is using the disk" question, then ProcMon with a filter on PATH should get you the information you need. 

Use the "net user" command - for example "net user USERNAME" will display a list with all sorts of info, including password last set and password expiration. 

IIS can't directly import PEM files. Instead you need to convert it to an IIS compatible format, and import that. OpenSSL will let you do this conversion. The command line would be something like: 

The Web Services object in Performance Monitor has counters for number of current connections (and some others that might be useful - current anonymous users, current nonanonymous users, anonymous users/sec, etc.). You could setup the counters, then pull the data from each server into Excel to combine and analyze. 

You can add a new (DateTime typed) field to your CSV in-line using the value from Hire Date to seed it, and then use that for your sorting. You can still print the standard Hire Date though. This should work for you: 

The function is just the default prompt supplied by Powershell. If you put a new function into your profile, it will overwrite the existing one - but if you remove the custom definition in your profile, the previous function will be used again. Edit your profile with: 

In general, you are going to need the stsadm migrateuser command. I think for the mysites, you are also going to need to update the owner of the site using the stsadm siteowner command. The mysites could get weird depending on how you have them setup. If the sites are just /personal/username, (and the username is the same from AD to LDAP) then you should be OK. If they are /personal/domain_username (or the username changes from AD to LDAP) then you may also need to actually change the url of each users mysite. This would get messy because there is no built in command to do it - the only option would be to backup each site and restore to a new site collection with the new username. PS - I've never done this, I'm just theorizing based on available commands in SharePoint... 

This is more of a stackoverflow answer, but the following code at the top of your page should do it. This has to be before any HTML is sent to the user or it won't work.