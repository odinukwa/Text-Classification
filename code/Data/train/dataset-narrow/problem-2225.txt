Question: Does anyone recognise this problem? For example, is this a well-known NP-hard problem? I am mainly interested in positive results — efficient algorithms for exact solutions or good approximations. Algorithms that are exponential in anything (the number of patterns, the length of a pattern, the number of wildcards in a pattern) are too slow for my purposes. 

At least as hard as $k$-colouring an arbitrary graph $G = (V,E)$. For each edge $e = \{u,v\}$ you have a subset $X_e = \{ u, v, x(e,3), x(e,4), \dotsc, x(e,k) \}$; here each $x(e,j)$ is a dummy element that is not present in any other subset. If you can $k$-colour $G$, you can easily find a colouring of the set system (just colour the dummy elements greedily), and vice versa. 

This is a TCS site, not a general computer science site, so I will only give the TCS answer. In TCS, the following things are more or less equal: 

We can also study the question from a bit more practical perspective. Unfortunately, vertex covers as such do not have that many direct uses, but for the sake of argument, let us consider these two (somewhat contrived) applications: 

Motivation: We encountered a closely related problem recently when we were doing this work. Very briefly, our goal is to simplify a machine-generated case analysis by merging similar cases. 

Setting: patterns with "don't care" symbols, binary alphabet. For example, pattern $x = 001?$ represents the set $L(x) = \{0010, 0011\}$. We are given a set $P$ of disjoint patterns: $L(x) \cap L(y) = \emptyset$ for all $x, y \in P$, $x \ne y$. The task is to find the smallest possible set of disjoint patterns $Q$ such that $P$ and $Q$ represent the same set of strings: $$\bigcup_{x \in P} L(x) = \bigcup_{y \in Q} L(y).$$ 

An extremely simple (but not optimal) solution is to just pick an appropriate set of 32-bit labels like 

In the first step, you only perform $n/b$ write operations, but each of them hits a new memory page and you pay the penalty. In the second step, you perform $n$ write and read operations, but they are now cheap, as we do not have any page faults or memory management overhead. A typical page size is 4 kilobytes, so if you estimate $b \approx 1000$, you should get reasonable ballpark figures. 

Parameters: $k$, $K$, $n$ are given, and then $N$ is chosen to be sufficiently large. Terminology: an $m$-subset is a subset of size $m$. 

Hence if we can solve the question "is a given $p$ automorphism of some $G \in S$", we can also solve the question "is a given string $y$ in $L$". Moreover, if we can do the former in, say, polynomial time in $|p|$, we can do the latter in polynomial time in $|y|$ as well. Now you can just let $L$ be your favourite NP-hard problem. Or the halting problem... 

Now "$x > 0$" is an invariant. It certainly holds initially and after each iteration. However, it is not an inductive invariant: merely knowing that $x > 0$ before an iteration is not sufficient to guarantee that $x > 0$ after the iteration. After all, if $x > 0$ is all that we know, then we might have $x = 0.1$ before an iteration and thus $x < 0$ after the iteration. On the other hand, something like "$x > 1$" is an invariant and also an inductive invariant. It is easy to check that if $x > 1$ before an iteration, then also $x > 1$ after the iteration. 

Now even if your compression algorithm squeezes the useful information into << 1 bits per pixel, you will still have as much as 3 bits per pixel of incompressible noise. And the uncompressed version is 8 bits per pixel. So the compression ratio will be in the ballpark of 1:2, no matter what you do. 

An extended version of my comment: Let $p = n+1$ be a prime number. Then we can construct an $n \times n$ square from the multiplication table of integers modulo $p$. For example, if $p = 5$, we have 

In what follows I will interpret unmatched nodes (nodes not incident to any edge in $M$) as stars with 0 edges. Hence a feasible solution partitions the set of nodes into node-disjoint stars. Now if the number of such stars is $k$, then the number of edges in $M$ is exactly $n-k$: there are $n-k$ leaf nodes that are connected to a star center. Therefore maximising the number of edges in $M$ is equivalent to minimising then number of stars. Now it is straightforward to see that we have a solution with $k$ such stars iff we have a dominating set of size $k$: 

Don't have multiple web sites for the conference. If there are many possible URLs, make sure that all of them redirect to the same place. Don't try to maintain multiple sites by manually copying information from one place to another. This may sound ridiculous – why would anyone set up multiple web sites with different content – but for some reason it seems to be happening all the time. There is the "official" web site with a cool domain name and a fancy layout, but it is too difficult to update it; then another web site is set up, and soon nobody knows which site to check for the latest information. People don't need fancy web sites; they want to find information. 

There is a $k$-colouring. The ratio of the number of vertices to the maximum size of an independent set is at least $k^{\log(k)/25}$. 

Consider a 3-regular graph $G = (V,E)$. If there is an edge colouring of $G$ with 3 colours, then you have a partition of $E$ in 3 disjoint perfect matchings. In particular, you can find 2 disjoint perfect matchings. Conversely, if you can find two disjoint perfect matchings $M_1$ and $M_2$, you can also find a third disjoint perfect matching $M_3 = E \setminus (M_1 \cup M_2)$. The partition $\{M_1, M_2, M_3\}$ of $E$ is an edge colouring of $G$ with 3 colours. Deciding if a 3-regular graph has an edge colouring with 3 colours is NP-hard (Holyer 1981). Hence it is also NP-hard to decide if there are two disjoint perfect matchings (i.e., to decide if the minimum number of shared edges is 0). 

There is no such thing as "too long for a review". Sure, senior researchers write one-line reviews, but that does not mean that a four-page review is too long for a conference paper. If you write a long review, of course anyone will immediately guess that this is written by a junior researcher, but I do not see any reason to avoid it. 

You use it to advertise yourself and your identity. You hope that little by little, people learn to recognise your name and know what kind of work you do. Other researchers will use the information to find more information about you and your work. If they find a relevant paper written by you, they might want to find your home page and see if you have done more recent research on the same topic. Or they might want to contact you and ask more about your work. Various organisations will use it to construct bibliography databases (DBLP, ACM Portal, MathSciNet, etc.) and to come up with all kinds of statistics (how many papers were published by university X). The editors of the bibliography databases typically want to figure out which papers are written by the same person (far from trivial, as the names are not unique). 

Detect if there are any missing events. Count the exact number of missing events. If the number of missing events is at most $k$, find out what are the missing events. 

(And if a journal is so questionable that you would be embarrassed if your name was somehow associated with it, let's skip it entirely.) 

How to decide when you have enough research results to write a journal paper: As soon as you have matching upper and lower bounds. 

(Outside TCS, "distributed computing" can mean anything: SETI@home, grids, clusters, clouds, HPC, Internet, web services, P2P, IPC, you name it.) 

Now if we get back to the original question: isn't it enough to just find a one-way separator, to break the strong connectivity? So isn't the original problem in P? 

Of course all of this has exactly nothing to do with TCS research, but I think it is good to keep in mind what really limits the compression of real-world digitised data. Advances in the design of fancier compression algorithms and raw CPU power is not going to help; if you want to save all the noise losslessly, you cannot do much better than 1:2. 

Note that $M_1(u)$ and $M_2(u)$ can be extended by adding the edge $(v,u)$, where $v$ is the parent of $u$. All of these values are trivial to compute for a leaf node. Once you have computed these values for all subtrees of a node $v$, you can compute them for $v$; let $C$ consist of the children of $v$: 

Definitions Let $\epsilon > 0$ and let $d$, $r$, and $g$ be positive integers (with $g > 2r+1$). Let $G = (V,E)$ be a simple, $d$-regular, undirected, finite graph with girth at least $g$. Let $\le$ be a total order on $V$. For each $v \in V$, let $V_v \subseteq V$ consist of the nodes that are within distance $r$ from $v$ in $G$ (the shortest path from $v$ to any $u \in V_v$ has at most $r$ edges), and let $G_v$ be the subgraph of $G$ induced by $V_v$. Recall that we assumed that $G$ has a high girth; hence $G_v$ is a tree. Let $\le_v$ be the restriction of $\le$ to $V_v$. We say that an edge $\{u,v\} \in E$ is good if $(G_u,\le_u)$ and $(G_v,\le_v)$ are isomorphic. That is, there is a bijection $f\colon V_u \to V_v$ that preserves adjacencies ( $\{x,y\} \in E$ iff $\{f(x),f(y)\} \in E$ ) and order ($x \le y$ iff $f(x) \le f(y)$). Otherwise an edge is bad. We say that $(G,\le)$ is $\epsilon$-good if there are at least $(1-\epsilon)|E|$ good edges. Question Let $d = 4$. Does there exist an $\epsilon$-good pair $(G,\le)$ for any $\epsilon > 0$ and any $r$ and $g$ (with $r \ll g$)? Remarks: 

Assume that we are given $k$ such stars. Then we can find a dominating set of size $k$: simply take the centers of the stars (in a star with 1 edge you can pick a node arbitrarily). Assume that we are given a dominating set $D$ with $|D| = k$. Then we can simply connect each node in $V \setminus D$ to one node in $D$. These edges form a family of $k$ stars. 

By writing a long, thorough, honest, but polite review. It helps if you address the paper, not the authors. Make it as non-personal as possible. Say how the paper should be revised, not what the authors should do. Say that Theorem 3 is wrong, not that the authors are wrong. 

On the conference web site, post simple but detailed instructions for getting from the airport to the conference hotel by public transportation. Don't give dozens of options – just one or two routes that are straightforward and easy to follow. Tell what kind of tickets to buy, from where, how, and how much it should cost. Make sure that the information that you post is actually up-to-date and valid, especially if the conference takes place in summer. (It might be a good idea to have a look at a Lonely Planet guide book to get a good idea of what information is useful for someone who is visiting the town for the first time.) 

Let $x$ be a newly allocated array with $n$ words, and let $b$ be the size of the memory page (in words). Very roughly, the following operations (executed in this order) are equally expensive: 

There is now a jump function for SFMT (a fast Mersenne Twister implementation). This allows me to initialise 1000 MTs so that there is no cycle overlap. And SFMT should be faster than MTGP. Almost perfect for my purposes. 

Now let $p$ be a permutation of $\{1,2,...,3n\}$. Assume that $p$ is an automorphism of some graph in $S$. That is, $p$ is an automorphism of $G_y$ for some $y \in L$. Let $i \in \{1,2,...,n\}$. Let us consider the following two cases: 

That is, we would like to round the rational numbers to integers so that we minimise the sum of errors in pairwise distances. For each pair $i, j$ we would like to have the rounded distance $y_j-y_i$ as close as possible to the true distance $x_j-x_i$. 

What we have now should be a fairly good example of what happens when you study a featureless part of a scanned black & white photo, for example, clear sky. In principle, there should be exactly nothing to see. However, with a larger magnification, it actually looks like this: 

Now Ramsey's theorem (the hypergraph version) says that no matter how we choose $f$, there is a monochromatic $n$-subset $B'$ of $B$: all $K$-subsets of $B'$ have the same colour. I would like to go one step further and find a monochromatic $n$-subset $A'$ of $A$: if $B' \subset B$ consists of all $k$-subsets of $A'$, then all $K$-subsets of $B'$ have the same colour.