Then, the way AnimatedEnviroment draws himself, It's not the same as Enviroment, cause he's an animation., every AnimatedEnviroment Object will draw an animation, cause you will override the Draw function in Enviroment. Then a candle object will be: 

So a Floor block, Its just floor, and does not need to be animated, you will only need to place it somewhere, and give him a look, (asuming you are making a 2D game), that, would be just drawing a sprite and... done. Then a floor, a wall, a door should be allright just extending of Enviroment: 

When you make a list, you are making an Enviroment one, and you are adding Enviroment, you don't really care what kind of Enviroment, you just know that they are going to be placed. I think that a game is complex enough for not-to-be organized with code, so, this is how I would do it. Sorry if I extend it too much or If I gave you bad practices, but at least is a point of view; Im curious of what kind of platform you are aiming for, if your objective are smartphones I would start from here and then see what I can do to ease method calls or drawing, for example, floor's, don't necessary need to be a lot of block's, but just a large sprite with a certain pattern that cover's all the screen, different would be the case with other Enviroments that could be smaller. A solution could be just store in a list where the HazardousEnviroments Are placed, so you just ask if any adventurer I'ts on any of them, and if possible, limit the amount of those according to your adventurer's level, should help you save the amount of check's. Hugs. 

You need to create variables that determine the position of your image, make your render function use those variables as the position, and change those variables when you want to move your object. Here's how you can do it: 

It is generally assumed that the mass does not matter and they bounce up to the same height. This is because the coefficient of restitution, which lets you calculate the velocity change after the collision, does not depend on mass. The velocity right after the collision determines the height that the ball will move up to, independent of the mass (just like how mass does not affect free fall duration). So, for games, it's safe to assume that they will end up at the same height. However, in real life, it can be hard to make the two have the same contact properties and balls with different masses may end up bouncing to slightly different heights. This paper can provide further insight. 

Try placing this code in FixedUpdate() instead of Update(). Physics motions happen in FixedUpdate() and Update() is synched with draw calls. The two don't always happen at the same frequency. Most of the time this is the cause of the jittery motion. So, if you are going to affect the motion of a physically-simulated object, you need to do it in FixedUpdate(). Now, why does it happen only when you do the normalization? Probably it's because the extra processing time required by Normalize() causes the Update calls to lag more behind FixedUpdate. The fact that it acts differently in different computers also supports this idea. How much out-of-sync Update and FixedUpdate get depends a lot on the available CPU cycles, which tends to be nondeterministic. 

Different It's the case, in wich, you have like a candle or spike kind of Enviroment. Those need to be animated, so, you need more like an "Animated Enviroment". Every thing that's going to be animated, in your world, should have an animation., then you can force any object who's gonna be animated, to actually do it., when you say that many different object's could share a behavior, then, they implement an interface. 

Ah yeah. Fire Emblem, a great game indeed. If you take a really close look to the critic attack of Lyn you will actually got it. The first slash is going from down-right to up-left. That will be the first slashing image starting from the left of the sheet combined with the second. So, we can say that the second slashing image is a continuation of the first one, and that makes a single large blow. That's why the end of the line in the first image is fat headed, so the second image can be placed parcially on top of it. Same thing happens with the third and fourth images, (from up-rigth to down-left), they both are a single great blow. After the enemy get's hitted, she then returns to his place, and that's the last slashing image. Reasons for making a first blow in two images could be a couple, I think. One of them is to make the eye believe that the blow really last a while so, it gives an impression that Lyn traveled a long trail around the enemy in pretty high speed. She is really fast, so she cannot be seen! D: The other reason is that the width and eight of every image that represents the blows were not enough, so they had to make it in two pieces, probably, because some systems work better in power of 2 images, say 64x64, if you take a look to the second and fourth images, that are the continuations, they have the same width and height, and the fourth one Its like is not finished, but it doesn't matter, because, where is placed on the screen, it make's it look like it continues. And about the spikes, I'm not an artist, but I think it resembles where the end of the sword is pointing, notice that, spikes are when she draws the sword from the cover, and at the end of the blow, when she hit's, giving some impression of colition or friction. And the middle clean part is where the sword takes more speed. 

As for the mesh/skeleton export. You can do using the simple Wavefront (.obj) exporter. This file is readable by most physic/3d engines. Or the Blender to FBX exporter :) I am not exactly sure how does the action import work in the engines you noted. But many game engines have their own systems when it comes logic mechanics. UnityScript, HeroScript, UnrealScript and so on. You might have to export just the rigs, meshes, skelets and animations seperately. To set it up one by one inside the other engine using the internal game engine language. 

I could make it a long answer but it would be a waste of time to write it, taking into consideration the fact that unity has made a great tutorial covering every step. 

There are plenty roles in Gamedev. business, each role splits at least into a dozen, if you want to work at some company as a game developer here are some roles you can pick: 

I posted the overall stuff you might need to know to find yourself around the game creation process. There are more engines as the Tourque 2d, more software to use like the Allegorythmic Substance creator for smart textures, or the 2d Illustrator. But I hardly believe that anyone would be able to master everything at once, so check out what suits you most and then go deeper into the rabbits hole. Whether it is the gamedesign, story/code writing or art design - You have to choose 

Dokkat, from my experience I can tell that Unity 3d Mecanim animation has a sophisticated system for all sorts of animations, with the Mecanim tools the ammount of code you MUST write is limited, but the sky's the limit. You have plenty options to choose from. $URL$ I have to note that it will only be usefull to use Unity animation, if you are going to use Unity as your native environment. You can't export those animations into Maya/Max etc. Edition of the Magic Sword colour can be done using the V4 in the Color class $URL$ Function "operator Color Colors can be implicitly converted to and from Vector4." 

1) Since speed is a concern, you may want to take a look at approximate nearest neighbor algorithms. I've used ANN in the past and it performed very well for around 12 dimensions. It lets you adjust desired precision so that you can have a trade off between speed and precision and find what works best. 2) Since your visual occlusion is a black-box one (I'm assuming unpredictable moving obstacles), I'm not sure if you have much of a choice other than doing occlusion tests on the points that the NN algorithm returned. 3) I don't believe ANN supports points changing, but I'm not sure since I didn't need that. It seems Cgal and Pastel support dynamic sets, but in terms of insertion/removal of points. Perhaps the papers here would also provide some insight. I don't know if you need this advice, but I found that reusing libraries for such problems almost always is a better idea. There are so many pitfalls one can fall into while implementing the details. Good luck! 

1) Yes your observations are correct. 2) The standard global XYZ coordinate system makes sense when you think in terms of a first person shooter, when you are looking through the eyes of a character in the scene with a blank(identity) transformation matrix. Like it would when you draw a coordinate system on a piece of paper, X points to right and Y points upwards. According to the right hand rule (x->thumb, y->index finger, z->middle finger), Z points towards you. 3) It wouldn't be wrong, but it would be a diversion from standards. There are three problems that I can think of at the moment: (a) Let's say one day you want to use a physics library that uses the standard coordinate frame. If you did not follow the standard, now you have to think about the transformation that takes you from your world to the physics world. Can get annoying when you want to fix a bug. (b) When you want to share code with someone, or bring someone over to help with development, they have to get used to your convention. (c) When using standard 3D models, you always have to have a transformation above them to prevent them from looking sideways. Now to add to question 2, it is sooo useful to think of X, Y, and Z as not just three letters, but as right, up and backwards. Every character in the scene has a local coordinate system attached to them, and in their local coordinate frames X is always right, Y is up and Z is backwards. Once you have this, now you can make sense of vectors that you print out, or write your algorithms in a way that makes sense. Let's say you have two characters A and B, and you want to do something if one of them is facing the other. You can simply find B's location in A's coordinate frame (Ta^-1 * p_b), look at the vector you get and see if Z(backwards) is negative and X(right) and Y(up) are small, because that vector tells you how much backwards, right and up B is with respect to A.