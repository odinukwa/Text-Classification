There are several things to address here: Naming Conventions: only fields, method parameters, and local variables should be camelCase, everything else should be PascalCase. This doesn't make your programs run better, but it does make you a more likable programmer in the workplace. Being able to produce code that is consistent with your co-workers will help you stay employeed. No one likes a rogue programmer. Validate all external input: in your application the external input is coming from the info provide by the user of your program. It could be a text box in a windows application or data provided to a web service that you have written. In all cases you need to validate the input before processing so that you can provide the user with an appropriate message. In your case there are places where valid values cannot be less than zero. Check for that and alert the user of their mistake. Here is an example that verifies the pay rate and ensures that it is at least the minimum pay rate. 

Keeping it local is good. However for clarity you may want to assign the lambda expression to a Func or Action variable, and then do your threading code. This would help in making the threading code easier to understand on sight without mixing in the details of the actual code that is being threaded. In other languages it is not uncommon to declare the method to be threaded inside of the method that is calling it (javascript, ada, f#, etc.). 

A user of your code that tries to assign 1.0m to the property is not expecting that value to magically change to 8.25m. If you refer back to the example for the property you will see that I am not defaulting a negative value to zero. I am throwing an exception. It is the user's responsibility to provide your class with valid values. In order to facilitate this you should be documenting your code. The example property should clearly document that it will throw an exception if someone tries to assign a negative value to that property. Conclusion The items explained above should be carried beyond this program and taken into consideration for all programs that you write. They will make you a better programmer in the long run if you adopt them now. There are also a few other things in your code that are incorrect. Those are simply bugs in your code 

You don't need to keep all of Pascal's triangle. In fact you need only keep one row. Below is a C routine that I use, I hope it explains the idea. 

You could save some computation by first transforming your collection of universities to have the coordinates, spherical polars, that are used in the distance calculation; at present if you have n universities you will do these conversions n squared times. Along the same lines you could change the distance formula you use by expanding cos(theta1-theta2); then your formula for 'cos' would involve only sines and cosines of phi1,theta1,phi2,theta2. So if you were to store these in the transformed table, the calculation of distance would involve a few multiplies and adds to compute 'cos', and then an acos call. 

The point being that if you ever change the type of list you don't have to change the sizeof. Another small point is that it would, I would say, be more idiomatic to use a for loop rather than a while in run_euler_problem(). 

Of course this is just the transpose of the lower factor. We want to find a cholesky factor of the inverse of 

It may seem that no progress has been made -- we have to do m factorisation and multiply up the results -- but in fact Z can be computed simply, and so can the products. We note, by Woodbury, that 

I hesitate to write this as it's not about the code obove but about a different algorithm. However I think, for small enough m (eg a quarter of n -- here A is nxn and B is mxm), that this is faster. The below is in terms of upper cholesky factors, ie an upper triangular matrix U so that 

A standard trick to reduce the error accumulation in vnp's code is to notice that the real part of base will be close to 1; we can use the multiple angle formula to compute base-1 (with base as in vnp's post) more accurately as 

Add to method printout of current \$k\$. For me output was unclear without it and I couldn't compare the output with "golden" table. I would rename to cause doesn't give any additional information. Strings in constructors may be changed to it'll simplify i18n of such strings in the future Use for arrays filling instead of circles or even remove zeroing at all as Java Spec guarantees arrays zeroing after initialization. Extract this initialization into a separate method (remember of SRP) Make parameters' checks in and consistent (or even remove it from at all as it's impl) Split into some separate methods with SRP and appropriate names. E.g. for me is unclear how works now. Remember empty lines in a method code is the sign of breaking SRP and is like "code smell" in the most cases 

I would go totally in a different direction. Look, what if you need to rotate not but 'LinkedList' or even unknown implementation? So the better approach is to use decorator pattern: 

UPDATE I also suggest not to do any premature optimization till it'll be a real problem and you can confirm it with a profile. See When to optimize paragraph. 

I personally don't like classes which encapsulate internally only algorithms but not really needed data (the sign of such classes are or suffixes). It's actually, sign of procedural programming but not OOP. So, 

I would create class with name and implement for it interface make the class immutable and don't use any internal cached strings. Only link to the source string and offset as the constructor parameters if you need to do new rotation from some implementation (, your , etc.) just create a new instance as a decorator with appropriate source and new offset. remove static method from the class body and add some unit tests instead in a separate file. as a bonus have thread-safety implementation as your class is immutable :) 

Conceptually your works incorrectly. You shouldn't put current into if your finally returns because it's only attempt to request your server for the request execution. You shouldn't count it. You should keep in the map only successfully processed attempts. Also I would reuse exist Google Guava com.google.common.util.concurrent.RateLimiter implementation. 

Though this more computation, it will have less rounding error. Unless hardware rules it out you should consider computing base as doubles, and accumulating the complex exponentials in doubles; you can use one variable W say with 

then stored W in tab[i] -- hence converting it to float. Again more computation but less accumulation of error. 

This lends itself very well to being implemented as a fold. In the particular case of chebychev polynomials (and other orthogonal families) it is even better to use their recurrence relation. Not only does this avoid the (sometimes unpleasant) calculation of the coefficients, but will also compute the first n polynomials in a single order n loop. For chebychev polynomials T the recurrence is 

An implementation, that I believe works, is below. The matrices are in column order. The ws parameter is workspace, 4*C doubles (though only C doubles are used in the second routine). Note that v is assumed to have dimension C, while really U is CxC, but could be stored in a RxC array. If you are using square matrices set R to be C. The function mat_ut_vec( R, C, U, v, w); computes U*v (for upper triangular U) in w. 

Depending on how big the maximum test case can be, and how many test cases you are to get, it might be quicker to fill out a table of the answers for all possible cases. Then the test cases can be answered by just indexing into the table. One way to fill out the table would be to first set the entries to 0 for all powers, and then to fill in the rest according to how far thay are from the nearest power. Unfortunately I don't know java but in case it is of interest here is a C program that on my machine fills in (and prints) the table for the first million numbers in 70 milliseconds, while the fist 100 million numbers takes 7 seconds. 

A better, (faster, more accurate) way to evaluate polynomials, given the coefficients, is to use horner's rule, eg