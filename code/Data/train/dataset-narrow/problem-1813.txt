This should be moved to unix.se ... but to do this is fairly easy. I run my own DNS servers so I buy a domain, set its DNS servers to ns1.mydomain and ns2.mydomain, and run a few shell scripts on my primary and secondary servers to set up zone files, an apache vhost, and mail service. If you don't feel like duct taping your own solution together like I did, there are service management consoles that you can use that would do all of this, and allow creation of sub-management, etc for resellers and so on. If this is of interest to you, I'd recommend looking at ISPConfig - $URL$ 

The error tells you - you have no A records for your name servers. This means you are probably hosting your own primary and secondary name servers, so you'll need glue records as well. 

Clients connect to for Submission (w/ TLS/SSL) and pop3 and/or imap (both with tls/ssl). Works great. 

And then let the SMTP protocol worry about getting mail there (that is what MX records are for) and let their folk worry about having a SSL cert. Now, if that provider DOESN'T have a cert for eSMTP, etc. then.... I'd find a new provider. Or self host. 

I'm assuming appropriate info in named.conf (or named.conf.local) that says you are a master server for your domain. Check the zone file with Assuming that all checks out as OK, check the serial numbers for each domain's zone file info. Now, what you use for a serial doesn't really matter - AS LONG AS it is numeric and always increments when you make changes/updates to the zone file. Looks like you are using a unix time stamp which works fine, I like YYYMMDDVV format where VV is 01 to 99 for the revision that day. Figure if I mess up 99 times in a day, it is time to quit... Serials are important because when your DNS server sends out notifies OR is queried by a slave server/secondary server for your domain, the serial is examined. If the value isn't larger than the serial that secondary server has cached, it won't update its store of data - it figures it hasn't changed since there isn't a new serial. 

First issue is did something change on your end ? No longer listening on your LAN address and only on localhost, etc. New firewall policy being pushed down by domain controller/etc? Then you would be looking at addressing. Does yourcomputername.company.com still resolve to the address your computer actually has? Does it resolve that way on other computers? IE, things could be great BUT that name is resolving to the wrong address... Errors would be "can't find server named ..." or "dns resolution" if the name isn't look-up-able at all and you'd need to check what address it does resolve to separately... Last check is routing. Many sub-netted networks do not allow packets to travel between "client" subnets, only from client to "server" subnets and then out to the world. Can someone on the same subnet connect to you? Can you connect to others on other subnets? Routing issues typically give a different error message (no route to host) 

Now, on his server in his or he needs to add an entry to service that domian, and allow your name servers to get domain transfers when he updates/sends notifications, replacing the addresses wtih the ip addresses of ns1.example.com and ns2.example.com 

Now is an authorative name server, and create more hosts in its own zone, or it should be able to be a primary nameserver for some other zone. 

If you want to serve multiple domains, you can still do so at least for modern browsers that understand SNI/etc. First, obtain separate letsencrypt certs for each domain. If you have multple hostnames (ie, both and ) they can share, as long as the actual domain is the same. 

Yes, a ssh tunnel will do this for you. Assume remote service is listening on and you want to be able to access it at your , and your username on the remote machine is and the remote machine's hostname is 

This is "tunnel traffic from port 3456 on my localhost to port 80 on whatever remotehost resolves as www.example.com". You could then point a browser to $URL$ and see the content of www.example.com HTH 

Think of the serial as a version number. You (re)start bind, it checks the version number on its data cache vs. version number in config (the serial). If the version is the same, why bother re-processing everything, and why waste network bandwidth telling secondary servers that you have zone(s) to transfer... Always update your serial. Only rule is that it must go up. Using a unix time stamp is good, or a format like YYYYMMDDNN where NN is a revision number for that day (do you need to change it more than 99 times a day?). The problem, as you have discovered, is remembering to update the serial when you edit the file. Use some template files, data files, and shell scripting to create a "build" process where you'd make your edits to the data, then tell it to regenerate the zone file(s) part of which would include putting out a new serial, or even go to a (way overkill) web based front end with a "service provider" control panel like ISPConfig where the data will all be in a sql database and the ispconfig software will create the zone file(s) automagically. 

This says "connect as remoteuser to remotehost via ssh, and tunnel traffic from my port 4321 on localhost (no ip specified on local side) to port 2345 on whatever remotehost resolves as localhost (localhost is specified) " Another example, forwarding through to some website on port 80 - 

I've migrated from a Wheezy based postfix+courier+mysql to a Stretch based one (postfix+mysql+dovecot) with slightly updated config plus a few new options on a fresh install. The key for my migration was that the users are all virtual (via mysql tables) and all mail was stored in /home/vmail/domain/user/[various maildirs] New system has similar structure for maildirs, just under /var/vmail/domain/user instead of /home/vmail... Only "trick" to it was copying the files and making sure correct ownership and other permissions were applied on the new location. 

As said, you can use almost anything. Some choices make things harder down the road (like mail), so before you go installing all sorts of services and things that read the hostname and write it into the default config you want to set something sensible that tells you what machine you are on or what the purpose of the machine is. My personal practice is to use what VPS number it is (I have 3 or 4 going at any one time so vps01 or vps03) or if it is a VM in virtualbox on my own machine I'll use its purpose (dns-experiment or whatever). For mail servers (I use postfix+dovecot w/ mysql on Debian) I never use the host-name-part of the fqdn that will be used as the mailname (/etc/mailname and in postfix's myhostname in main.cf). And of course, don't forget to update /etc/hosts ! 

Change the IPs and device names to match what you really have. To change which device is the default gateway, simply move the comment from one gateway statement to the other and restart networking. ONLY LEAVE ONE GATEWAY STATEMENT UN-COMMENTED!! 

Change the cron scheduled time, even remove apache from logrotated and set it up manually if needed. Stop the apache service, pause for a few seconds to let apache really finish shutting down, rename the log file, restart apache. Since you only renamed the log file it stays in same directory and happens "instantly". Once your service is back up, then move/compress/whatever the logfile to where it needs to be. If it gets really bad, my inner BOFH says to point the logs to /dev/null and don't worry about rotating them... 

You are setting it inside the loop, so it will keep prompting you for it. I would have two loops - one to prompt for the server name and keep prompting until a valid value is provided, and then one to do option A or B or Quit. For pure programming questions like this, you may be better off asking on stackexchange 

1) a few ways. Assuming that the active site config(s) are under /etc/apache2/sites-enabled you could go there and for the directive. Or use which will display a summary of the running config. 2) No, not possible, because Apache serves up different content based on the hostname used to address the server. You could have some directory somewhere aliased in or symbolically linked to both DocumentRoots so $URL$ and $URL$ could serve the same content from the same directory, much like many/most hosting providers do with phpMyAdmin and other control-panel-like scripts. 

On the client you'll need enough OS to boot, load libraries, manage the local video/keyboard/mouse, and run a X server. On the remote headless box, do your regular install of whatever you want and configure the greeter on it (gdm, kdm, mdm, xdm are the typical choices, depending on desktop environment, etc) to allow querying via the XDMCP protocol. Once that is done, on your local client start the X server and tell it to query the greeter on the remote host. Apps run from remote host, user interaction takes place on local client. You could even run a full OS on your local machine, and when you need something from the remote you could use to nest a second X server inside your current one, query the remote host, and run the 2nd desktop as an application, much like VNC works. 

It looks like you are trying to host the entirety of your DNS on your own machine with one IP address, referencing your own domain as the DNS server. You can't get there from here. First, you need 2 DNS servers that resolve to different IPs. If you want to name your dns server(s) ns1.example.com and ns2.example.com then you need to set up what is known as "glue records" with your registrar. This will allow ns1.example.com and ns2.example.com to be the only dns servers for the example.com domain. Once you have your glue records set, remove the forwarders from the /etc/bind/named.conf.options - you shouldn't need it unless you have clients querying your servers directly. 

Still applies. Have headers been sent, but waiting on data transmission to start? Waiting on headers? Half the data has been sent but there is a temporary transmission pause? Anyway, reports as "sleeping", didn't want to deal with writing more code and experimenting for the others. Perhaps some method of relating voluntary context switches to elapsed time would work? With , and a simple script - 

Changed to a new IP address, or do you now have 2 IPs and gateways? Changing your IP - Your current configuration is for DHCP... if you've been given a new IP for your VPS just re-requesting a DHCP lease should do it - . Take that line out it isn't doing any good. You now have 2 IP addresses - OK, so assuming you have been given static IP settings (IP, netmask, gateway) for TWO IP addresses/gateways it depends on what device your second IP is attached to/associated wtih. It may be eth1, or it could be an alias to eth0 - eth0:1 (linode does this). You want your file to look something like this - the actual device identifier may be different for you - check it with 

IIRC when I had this issue it was the option. Don't set it to as that may prevent communicating with non-SSL'd SMTP servers (who knows why those are still out there?) Here's my working config - 

Basically, after each Host statement, you can use pretty much any option that would be valid in the system-level ssh_config Then simply ssh to whatever tag for the host you have to do is - 

Apache by default uses a different host config file for the default ssl server. And I don't see any reference to SSL in the snippets of your config that you posted.... So.. it is probably falling back to whatever default host is defined and is pointing at the wrong DocumentRoot. Run -S to see what names/aliases, addresses, and ports are in play as it is currently running. It will also tell you what config file defines it and what line the definition starts on. 

Depends on what level RAID you want to do, and of course that depends on what you want to do with the RAID :) Also don't forget that with Linux you can do software raid, no hardware support needed. What is nice about this is that the raid drives can be moved to another machine and be brought back up quick and easy. Minimum of 2 drives for both RAID-0 and RAID-1. Minimum of 3 for RAID-5, 4 for RAID-10. Of course, you can always add more... if that is of interest, you may want to look into LVM and RAID+LVM.... RAID-0 stripes the data across both disks, which can help speed things up for doing work like video capture. Since both disks are evenly used for data, if you loose a disk the -0 in the name tells you how much data you'll be able to get back. RAID-1 mirrors the disk, keeping the 2 drives in synch. If you have a failure of one disk, you can recover. If you have a hot spare defined (a 3rd disk) you may not even notice when it fails. RAID-5 writes pairs of bits of data across 2 disks and writes a parity bit of the 2 bits it just wrote to a 3rd disk. And of course it shuffles which disk gets which bit. Loose one disk, you can recover. Again, if you have a hot spare defined (4th disk) you may not even notice. RAID-10 is really RAID-1+0. Start by setting up 2 identical RAID-1 systems (4 drives), and then make a RAID-0 volume out of them. As long as one drive in each RAID-1 array is good, you can recover from a failure, and you get the speed boost of RAID-0. For seamless fail over you'll need a spare drive for each RAID-1 set up (2 more drives, 6 total).