Okay, you've gotten really great answers here, but I'll illuminate why I love VMware & it's brethren. 

Exposing a SQL server to the Internet at large? Eh, I wouldn't do it if I'm storing Credit Card or Personally identifiable information. 

have you verified your results with a tool like wget? Are you using ISA as a proxy, or a transparent proxy? Sometimes clients have issues if proxy auto-detection is set up in IE. If you turn this off, or hard configure it to use your ISA proxy, then things get a lot better. I had this same problem at startup at one of my clients, but not quite as reliable or prevalent as you seem to have it. 

I have a 6TB RaidZ ZFS array configured on my nv129 based OpenSolaris filer, and I want to upgrade to FreeNAS as painlessly as possible. I remember betas had warnings that they did not support existing ZFS pools - has this changed? I can't seem to find any official statement that this is possible, and I'd rather not risk my array if possible. I have backups, so I could start from scratch, I suppose, but I'd rather not. Thoughts? 

your SQL server doesn't know how to route to the gateway device (not likely if you can browse the web from it). Your virtual server on the firewall is a proxying device for web traffic, and doesn't understand your SQL traffic. You want "port-forwarding" 

Today there are multiple levels of backup, nearline and offsite. Nearline is where you back up to disk. Here you can keep multiple backup sets of highly important data near, while a copy gets made from the backup servers disks to tape and then the tape gets sent offsite. This has several benefits: 

A hub takes a message from one port and broadcasts it to all the other ports. A switch takes that same message, and through internal tables and knowledge of who is listening at the other ports, only sends it to the ports that need it. This results in less utilization on the part of the rest of the hosts, and results in higher total aggregate throughput. About.com - Network switch About.com - Network hub 

www.opengoo.org is a project striving to recreate much of the Google Docs experience (including mail integration). I'm not sure about the importing of XLS documents. I haven't quite made it that deep into the demo. 

That said, you should treat your backup servers disks with the same sort of redundancy you treat your database server. Say your database server fails at noon, you can rollback to the backup servers ondisk copy from last night and do your restore, where you tapes might already be a $250 emergency return from your offsite vendor. You should put RAID on every server you run, IMHO, and not that non RAID RAID-0 crap. :-) 

Cost: XEN and Hyper-V are likely going to be cheaper products in the short run. Storage compatibility: You really want a decent SAN to drive your storage. Tools: VMware is king here. VirtualCenter, Lab Manager, LifeCycle Manager, Backup Assistants. Citrix/Xen is only just starting to build tools of this functionality (although the VMware tools CAN be horribly buggy at times). 

backup to disk is usually faster You have an effectively unlimited # of disk devices, where backing up to tape is usually constrained in the number of heads you have to write at a time. 

it allows me to enforce the memory and practice of what I've just done. it documents what I just did so I can revisit it. It gives me artifacts I can use to show prospective employers I know what I'm doing, that I can communicate about what I'm doing, and that I have excellent writing skills. 

My boss tells an amusing anecdote about one of my coworkers, a Chinese man with a thick accent. Smart guy, but hard to understand on the phone sometimes (I'm an expert in Engrish). So one day he gets a tech-support call from an Indian guy, and is having a hard time getting the guys name and problem description. After about 5 minutes of listening to the Chinese guy on the phone, my boss, native English speaker, offers to help. He gets on the phone "Can I help you?" to which the poor Indian goes, "Oh thank God!" 

What virtualization platform are you using? VMware's Lab Manager product is working wonders at my workplace for setting up test-clusters and customer environments. 

JBoss has maturity, whereas Glassfish is striving to be THE reference J2EE stack. A year from now, there'll be almost no difference to your production deployments. 

Absolutely no problem. You probably won't be able to get the full capacity of the drives due to different geometry, but you'll be just fine with those three drives. 

Having run numerous virtualization farms, both for big business and personal use, I'm of one singular camp. VMware. The VMware tools support is currently unparalleled, between Lab Manager, LifeCycle manager, etc. Citrix XenServer is coming up, but it has 10 years of makeup work to do to catch up with the mature VMware products. And as a general rule I've found that even though you start at a dozen or so, you need to plan for 50. Once you start virtualizing, you never stop. At the moment, though the Citrix offerings are promising, VMware is your best choice for the near future. If you're willing to live with the growing pains Citrix offers (immature tools support), I don't think you could lose with either open. And both have Free-as-in-beer versions you can try-before-you-buy. 

I keep track of my notes with a combination of pNotes portable, and Evernote. If I ever need to REMEMBER something that I've just worked on, I write an article about what I did, what problem I solved, and how I did it, almost as if I was publishing it (even if I never do). 

A buddy was experimenting with some weird extents-based MD+LVM on Linux, and Linux apparently has a hard 63 partition limit on any disk. I'm not sure if that's filesystems per extended partition, or what. I'd like to think that in today's day and age, it's relatively irrelevant. 

Over a gigabit ethernet connection, you're only going to get a maximum of 120MB/sec. And that's best-case, you'll probably top out at 100, and that's even if the Drobo can keep up with that (though I've heard it can). I've used iSCSI from an EMC Celerra over the same transport - it did relatively well for 10 or so low-usage hosts, 1 SQL server doing maybe 250-500tps and a Clearcase server doing probably triple that. 

Utilization - in a room full of servers, of which maybe a dozen are doing anything near 50% utilization, I can instead consolidate those servers onto one or two single larger servers and have room to growth. Capacity planning - becomes less of a concern as you can buy with resources to grow, and $5000 worth of a server gives you lots of flexibility in deploying new services Real-estate - I'm running a 200 machine test lab on three ESX servers (2xquad core). That's 197 servers that aren't sucking 1-300 watts of power sitting idle 90% of the time, and wasting disk, memory and CPU. Flexible deployment - I need 15 Windows servers for a new project. With tools like lab manager, I can have this in an instant. Simplified upgrades - I want to test an upgrade to a product. I can simply clone the entire machine, put it on it's own network, and run an upgrade test without impacting the existing service. Backup - I can take snapshots of the entire machine's running state. No more need for special backup clients that can't lock files. (not entirely true for application state, however). Mananagement - I can remote manage every single on the machines from one unified tool. Cost-center/utilization billing - there are tools coming on the market now where you can bill by utilization, and help tailor your budgets to ensure groups aren't spending more than their fair share. Disaster recovery - if your big ESX server crashes, it CAN transition the workload to a backup server designated to recover for it. Sometimes without the VM even knowing it crashed. 

I remember a fight with Digital Equipment way back in the day trying to get the Alpha NT linker to work to link Pro/Engineer on NT 3.5. This particular release of Pro/E broke the 32MB executable limit (wow, remember when that was a big deal)? Needless to say, I tell myself today that DEC's refusal to fix that problem for three months contributed to the ultimate demise of AlphaNT, since we'd already shipped Intel and MIPS versions, and Pro/E was THE NT app of the day. Yes, I'm delusional, I'll admit it, but those were good times. 32MB of RAM and 1GB hard drives. 

In datacenter-grade equipment, you're looking at at least $1000/core currently, with large memories. Which is a pretty damn good price, IMHO. But the problem is that of capitalization. A lot of that is underutilized, even using tools like Surgient or VMware/LabManager. So you move to the cloud on-demand. Have a huge process that needs to run for 3 days at the end of every month? Deploy it to the cloud. $10. Versus $10,000 for having a server sitting around doing nothing for 25-28 days a month losing money. The time-value of money is what drives people to the Cloud. It may cost more in the long run, but can you get more for the dollar you have now, versus the dollar you MIGHT have then?