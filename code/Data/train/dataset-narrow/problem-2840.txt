If you don't/can't have one part of the code magically "know" about some data, then it will need to be passed in somehow. However that doesn't mean it must necessarily by passed only through arguments. In your example case, could you not have some kind of "AssetManager" which would load and store the assets, and then the ScreenManager would only need to be given a reference to that (probably at creation)? In that sense you're passing the references to the assets wrapped up in another object, and you can pass that once, at initialisation, rather than pass it down to the leaf function when it's required. Now IMHO that AssetManager, being the kind of thing you only want one of, might as well be a singleton. Provided you understand the pitfalls, and code specifically to avoid them (assume that singleton will be accessed simultaneously from multiple threads and stab yourself with a fork any time you do something that needs to block), then knock yourself out. 

Are you actually setting the identity matrix at any point? What other matrix ops are happening, and in what order? 

I would limit the amount you are doing at runtime. Precompute as much as possible - a PVS is a fairly standard techique for static geometry, and depending on your environment perhaps portals would work (these fairly easily cope with moving objects too). 

Your target platform should be whatever the people you want to play your game, own. There's no point targeting high-end PCs if you're making a game for the kinds of people that are happy with their ancient P4 running W2K. 

If you want to go crazy, you could take a grid of samples around your test-point, do an edge-detection algorithm to identify the surface (i.e. any point part of the terrain with a neighbour which isn't, or vice-versa, is a surface point), and then find the best-fit line through those points to use as an approximation to the surface. Might be overkill though :) 

Yes, C++ is the language used most often (though some people do still use C). There are numerous reasons for this. Sheer momentum is one - it's simply the language that has been used for years, a lot of tech already exists and people are comfortable with it, so changing is not going to happen overnight. Then there is the issue of control. Game developers are control freaks, and we like to know everything that is going on in our code. C++ gives us that control, C# and Java (to pick on the two alternatives you mention) take control away. In many ways that might be a good thing, but game coders don't like it :) Finally there's the simple practical issue that the SDKs for various platforms are very C++ centric. Using another language inevitably involves writing wrappers, cross-compiling down to VMs, and possibly (in the case of some console development) it's not allowed by the platform holder (they really don't like people doing JIT compiling, for a start). 

The existing answers give a lot of information. I also gave a talk a couple of years back on how the terrain system in PhyreEngine works. It's PS3 oriented, but actually fairly similar to the Halo Wars technique in many ways - we also have full 3D displacement, and indeed can handle "bridges" (i.e. complex topologies). This is available here: $URL$ 

Surely if you're using indices, you're not repeating verts? You could also look at instancing, where you have a set of primitives being repeatedly drawn with a set of matrices being sent at lower frequency (i.e. a single call could draw 20 lines, repeated with 15 different matrices). edit: It occurs to me that you might be worried about the duplication of indices rather than verts. I wouldn't worry about that - that's kind of the point of indices. They allow verts to be reused without being retransformed by the GPU. 

Various scripting languages, both text-based (ones with simple syntax - LUA for example - can be more accessible for a non-programmer), and graphical (Unreal, for example, is very GUI oriented). Alternatively I've seen people just expose tweakable stuff through an editable text file (sometimes a CSV formatted file usable in Excel), if you expose the right stuff you can give designers fairly powerful abilities to change the game, without them having to actually alter the logic. Basically the tools I've seen being used are: 

Binary search wont help if you have thin bits of scenery and fast moving projectiles - you might miss them. I think your best option is to sweep a line across the front of the projectile along the path it takes, pixel at a time. You could do a bounding check first on the whole volume to avoid doing it every step. 

I note an answer has already been accepted, but it's generally useful for clipping to have the view frustum transformed into a unit cube. 

I think I agree that normalised co-ordinates don't really map well to UI stuff. What I typically do for 2D layouts, is basically your "virtual" co-ordinate space, but I pick a space which maps 1:1 with my prefered target resolution (1280x720, for example). It's not fixed, but it's intuitive to deal with and I know that in 90% of cases it'll look just right. Obviously it's important not to get complacent, and to actually check different resolutions often. For crispness when remapping resolutions, I'd borrow some tips from font-rendering, and provide hinting information. So make sure that things which need to be continuous are tagged in some way, while also performing rounding to exact pixels where crisp alignment is necessary. Perhaps also consider making things more relative. So rather than everything being "position object 1 at absolute X,Y", you could specify "position bottom left of object 2 at some offset from bottom right of object 1". It's easier then to rescale and/or move things about, without losing important relationships. 

HDR isn't always necessary. A lot of the time you can get away with compressing your output values in the pixel shader. Essentially you're just doing the tone-mapping in a single pass, so you have HDR rendering without a wide pixel buffer. This makes it trickier to know what values you should use for the tone-mapping, and certainly makes it tough to do a localised effect. However if you use feedback from the previous frame, you can adjust the values over time, and that can actually aid the visual effect as it looks like an eye adjusting to the brightness changes over time. Doesn't work well with anything multi-pass, including alpha-blending, unless you special case those (if you're using alpha-to-coverage, it's not too bad, though you'll be linearly blending values which have been non-linearly mapped into RGB space). 

You're right about having the camera applied first and then the object transform, because this allows the usage of pushing and popping matrix states between objects. Aside from that there is no "correct" order, other than a basic assumption that the transforms will be applied in the reverse order to which you call the matrix functions. So if for example you do: 

If you want to understand how a traditional software rendering pipeline works (and things haven't changed that much even with the introduction of programmable hardware pipelines), one book I'd definitely recommend would be Jim Blinn's: A Trip Down The Graphics Pipeline. Unlike some of the other suggestions, it's not particularly comprehensive, but it is very readable and I think if you're just getting started with 3D, it's a good introduction. And it's written by Jim Blinn, who is one of the founding fathers of computer graphics, and thus is written from the perspective of someone who actually invented/discovered these techniques.