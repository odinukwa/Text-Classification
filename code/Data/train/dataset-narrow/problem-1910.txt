Connecting passive extenders in series is a very bad idea. In USB 2.0, the length of cable is limited by signal degradation along differential twisted-pair cable. USB 2.0 does not have any sophistication of USB 3.0 as signal pre-emphasis and adaptive equalization of receivers during link training, and relies on plain quality of transmission line between link partners. The quality of line deteriorates due (a) frequency-dependent losses (attenuation of high-frequency edges), and (b) inter-symbol interference coming from multiple reflections from line imperfections. Even a uniform twisted differential line has certain degree of imperfections, so the end-of line accumulates significant jitter, and receivers fail to decode the data stream and recover embedded clock. Now, consider how USB connectors are made. First, the pair of mated connectors (receptacle-plug) has quite different geometry, and impedance matching is not always good. Then, the connectors are not designed for automated assembly. The cable must be cut, wire spread out to fit connector spacing, and then soldered by hand. Most of the cable assemblies inside the connectors moldings are horrible from impedance matching standpoint. So when you connect a single extender, you introduce four (4!) bad segments (cable split1 -> receptacle - > plug -> cable split2 into the transmission link. As result, horrible reflections are coming in all directions along the line, and signal deteriorates beyond acceptable. This is why USB specifications explicitly disallows any passive extenders. If you put more extenders, things will go really bad. The above considerations apply for cables with two junctions, at host side, and device side. Active extenders usually use "captive cable", which is soldered directly at device end, and thus eliminates at least a pair of connector elements and one cable split, so captive cables can do a bit better in terms of signal integrity, and can have longer functional cables. In short, making a USB cable out of several mechanically interchangeable segments is a really bad idea. 

It sounds like mean that your PC doesn't have an old 32-bit PCI slot, and has only modern PCIe. Yet typical PS/2 port adapters are only made in PCI-32 format. Then your solution is to get a PCIe-to-PCI adapter, like the StarTech card 

This bridge operates under control of 32-bit ARM™ Cortex-M3™ processor. As one can see, the bridge supports both USB 3.0 and USB 2.0 interfaces, which are running through the same USB 3.0 connector. Therefore there are some differences how the bridge can handle attach/de-attach-shutdown sequencing. The issue is that due to essentially half-duplex interface of USB 2.0 and lack of deferred out-of-order completion of bus transactions, USB 2.0 link can implement only the legacy Mass Storage Class Bulk-Only Transport (BOT) specifications. The USB 3.0 bus protocol has enabled the USB Attached SCSI (UAS) specifications, which allow much wider functionality of SATA drives. I am pretty sure your system loads a UAS driver over USB 3.0 link, and resorts to BOT functionality if the enclosure is attached over USB 2.0 link. Different drivers (or driver modes) produce slightly different behavior after the "eject" operation. However, I am pretty sure the firmware in the USB-SATA bridge chips makes certain that after receiving the "eject" command everything is flushed and parked accordingly, otherwise the enclosure developers would go out of business pretty quickly. Therefore if a system says "it is safe", then do disconnect the drive with confidence. 

The female-Type-A legacy cable to male Type-C is a legal cable assembly, per spec. I think it is a misprint in the question. However, adapting the new Type-C device plug to legacy Type-A host port is indeed a challenge, and it is not addressed by specifications. Although there are Type-A receptacle to Type-C plug adapter dongles (as referenced in the question), they cannot provide one of main benefit of Type-C connector, the universal polarity of it. The other problem is that the simple passive dongle will provide always-on VBUS, which is against Type-C mode of operation. Other than that, they should work if nicely implemented, you just would need to flip the Type-C connection in 50% cases to get USB 3 speeds, and the USB2 should always work. The right way to connect a Type-C flash drive to a legacy Type-A host port is to use a proper hub, with legacy type (A or B) of connector upstream, and full-blown Type-C receptacles on downstream ports. Recently Genesys Logic announced such hub controller chip, GL3523S, as well as others like Microchip and Cypress, but at this time it is difficult to find any OEM products with these chips yet, only development boards are available. If you should find a finished OEM product of this kind, please post. 

So, if you have a desktop PC or laptop connected to AC outlet, each USB port MUST supply 500 or 900 mA of current. Note the language, "at least". So it could be more, unless an OPTIONAL overcurrent functionality is supported in hardware. For example, a common desktop PC in sleep mode derives the VBUS power from +5VSB rail of its PSU, which at least is capable to deliver 2 A of current. Or more, which is specified in particular PSU. For example, if a Raspberry Pi3 gadget gets its power from AC-DC adapter from a wall AC power, it must supply at least 500 mA per each (of 4) ports. Unfortunately, it fails to do so, and therefore is not USB-compliant. However, if a USB host is a skinny battery-powered device (such as MP3 player or smartphone), this can be declared by manufacturer as "low-power host", and the USB port can be limited by design to deliver 100/150 mA only. This limit is very inconvenient to customers, and is rarely enforced. If a USB system (host or hub) is declared as normal host, the ports are tested to USB-IF test specifications using specialized USB port testers. The tester either applies a load equal to 5 units and checks if the voltage drop doesn't exceed specifications (5% or 10% margin), or applies a step-wise increasing load and determines at which point the (optional) overcurrent circuit trips over. Under household conditions the port capability can be checked by applying a big 10 Ohm (or 5.5 Ohm if USB 3.x) resistor to a stripped-off cable. Or using a dedicated variable load found on e-Bay. The requirements for power delivery from a normal USB port should not be confused with requirements for USB DEVICES: USB devices should NOT take more than one unit of load until host completes the device enumeration. USB hosts must keep track of consumed power declared by attached devices. During enumeration a host reads mandatory power requirements of the device within its descriptor, and if the host believes that its power capabilities are maxed out, it can refuse the connection. 

If the 12V was shorted into the ground pin, the ground trace can be fried/evaporated. It should be visible, and maybe repairable. If VBUS was hit by 12V, all depends whether the laptop has individual high-side power control switches, fuses, or not. If the switch was fried, it can be replaced. It looks like your case is a lucky one, since other ports still work. To determine if the VBUS is ok, you need simply check if the questionable port has 5V power. If not, the switch is fried, which might be repairable. If data lines were exposed to a prolonged 12V DC, then it is very likely that the data interface is damaged beyond repair. However, there could be a chance that external ESD protective diodes went broke, and shorted data lines either to ground or to 5V/3.3V rail. I've seen such cases. In this case the port might signal some sort of broken connection, and should be visible by USBview.exe utility. Again, checking if data lines are shorted using a DMM will help. Still, the chances to fix this particular USB port in your laptop are slim, and it requires certain experience and skills. 

If the "waiting channel" is in "read_descriptor" state, it means that the USB channel went into heavy recovery after a fairly serious hardware problem, because the "descriptor stage" occurs only on port reset, and port reset happens only when an unrecoverable transaction error occurs. The fact that it works under Windows only means that the OS software likely engages some different hardware configuration and controller/PHY parameters. I strongly suspect that the Link Power Management (LPM) is at fault here. The Linux distribution likely enables all bells and whistles and latest and greatest, while Windows might use so-called Intel-devised "filter driver" to fix some controller deficiencies. The LPM states U1 and U2 occur on hardware level, so they are likely invisible from software side. To determine if the link goes back and forth into LPM states, you would need a super-speed USB protocol analyzer, Ellisys 280 or Teledyne LeCroy Advisor T3, or some other tool that detect LPM states on Super-Speed link, like this much less expensive tool. 

Every USB device, by requirement of the standard, must have two basic parameters, Vendor Identifier (VID), and Product Identifier (PID). These identifiers are transmitted by every USB device during enumeration stage, in "get descriptor" command. The VID and PID are embedded into device hardware, and thus are OS-independent. In addition to the generic USB class of a device, their purpose is to let OS load proper driver if the device has proprietary functions specific for this vendor. VIDs are assigned to every manufacturer registered with USB organisation. The USB.ORG has a list of unique VIDs assigned to manufacturers. The PID is an additional identifier of a device, it describes different device types and model versions within the manufacturer's line of product. So yes, two keyboards from the same store shelf will report exactly the same VID and PID. These should not be confused with identification of instances of drivers ("handles") that are internally assigned by OS to every connected USB device and can vary depending on the order how devices were plugged in and discovered. 

This behavior is very possible when the two ports have different "charging signatures", while the two connected devices have different cohesion to charging signatures. 

The native wireless USB hubs have died from natural causes several years ago. An alternative would be the "USB over TCP-IP" projects, check this one. 

The adapter in Link1 is designed to work on HOST side, converting Thunderbolt3- Type-C to Thunderbolt and Thunderbolt2 devices. The adapter does not support any purely-USB3 devices. Type-C connector does not necessarily mean USB 3.1 functionality. More, you seem to plan to use the adapter on device side, which won't work at all. In short, sorry, you will have no functionality from this setup at all. 

The graphics can be transmitted over USB 3.0 standard and then converted into a video standard (typically VGA or Display Port) by a dedicated USB video-class device, notably made by DisplayLink company. The converter chip can be in a separate dongle, or built directly into a monitor. In this case it will be designated as "USB Monitor". The Type-C port pins can be switched (re-used) as a native Display Port if (a) host is designed so, and (b) the peripheral video device accepts this mode and signals over CC1/CC2 wires to turn the port into so-called ALTERNATIVE MODE. This mode is quite flexible. It can support full-featured USB 3.0 connection AND 2-lane DP. Or it could be full featured DP connection (since the Type-C port has four high-speed differential lines) without USB 3.0 and miaintain only USB2.0. To have this ALTERNATIVE MODE, the host must have a sophisticated data switch/multiplexer, and a circuitry to detect "alternative mode" signature from compatible displays.