After looking at the trailer in your link, they are indeed hand-drawn sprites. The animation seems smooth, so I wouldn't be surprised if they used some sort of skeletal 2D animation. This style involves drawing the movable parts of the character separately, so limbs, head, etc are separate sprites and they are posed and rotated accordingly to create keyframes, and tween the animation by code. The other method as you mentioned, would be to make 3D models and export their animations individually for use in a 2D medium. If you are familiar with 3D modeling, this approach can be a lot quicker. You'd make your keyframes and tween them as usual but you will be able to export the entire animation as a sequence of images ready to be used in your game. Ultimately, it depends on the aesthetic you want to achieve. Skeletal animation isn't suited for complex deformations. 

The & is also used as a reference operator. It returns the address of the variable it's referencing too. If you had a function that took the pointer directly as a parameter, then the function will be working directly with the pointer (useful for pointer arithmetic). Pointer pointers to resources are quite common in the D3D APIs. You usually don't want to access them directly as it's not of any benefit. 

Whether you want to use immediate mode or VBOs, it depends on the complexity of the scene. I've seen some examples where tangent/normal lines are drawn using immediate mode. There is nothing wrong with using VBOs for debugging. However, keep in mind that, generally speaking, batching will give you performance benefits no matter which approach you use, so always look to use it whenever possible. You can still benefit a lot from batching in immediate mode (maybe even more), because it will greatly reduce the number of state changes. If batched properly, you will only ever need one GlBegin() and GlEnd(), and all similar data is tightly grouped together. The only difference is that you'll be batching state calls instead of vertex data. 

Every bubble that isn't floating must have some path going back to a top bubble (are we assuming the side walls aren't "glue"?). Apply a flood fill algorithm for every bubble found in the top row. Doing this for every top bubble is essential because it'll work flawlessly in any case, in particular if there are several columns of bubbles hanging from the top but not touching each other. Flag all "filled" bubbles for each iteration of the algorithm, and skip any already filled bubbles in the top row to save time. When all top bubbles are filled, drop the bubbles that haven't been flagged. 

There's not much you can do unless you apply some sort of physical constraint model in Maya. I haven't used Maya in a long time, so I can't say exactly how you can do these sorts of physics for rigid objects in Maya. The best safeguard is to properly rig and animate your characters. Animators and modelers are going to be smarter than computers, so they should be animating them in a way so that their meshes do not intersect from any reasonable angle of view. If you require some procedural animations, a bounding-box collision system like the one Byte56 explained will help. These boxes can be controlled based on the bone movements of the character's skeleton. 

particleData and visibleParticles are of the same length, defined by maxParticles. Initially, populate visibleParticles with pointers to all of particlesData just to avoid null data. visibleParticles will be partially overwritten in each frame anyways. After updating the position of each particle, cull every vertex in particleData, and keep two numbers to increment. The first is visibleCount which will be reset to zero each frame before culling begins. A second number is inside the loop to increment by one for each vertex. For every vertex that is in view, assign a pointer to particleData.at(i) to visibleParticles.at(visibleCount), then increment visibleCount by 1. Here's a trimmed down example of how a culling procedure might look for rearranging visible particles: 

Don't do your portfolio based on how you perceive the "standard" to be. You should work on projects that interest you. If you like game mechanics, go ahead and make a bunch of games. If you like creating interesting AI, maybe make a demo for an RTS-like setup. As an example, I have a growing interest in graphics programming, and putting more time into learning rendering concepts and applying them in my engine. (Consequentially, my game project has been temporarily put on the shelf.) When you work mostly on things you like, it really brings out the "you" in the portfolio. On the other hand, having at least one completed game shows that you can pull through the "uninteresting" parts of making a game. It's good to have some degree of flexibility to break into less familiar territory, but don't force yourself into it extensively. You can tell good portfolios from the level of enthusiasm and interest put into the work, and projects based on your areas of interest are naturally gonna get the most polish. So whatever your area of interest is in, you will eventually have to focus towards that area of programming for a job. 

if the slope is going up. Determine if the slope is upwards or downards by the sign of the slope ratio. 

The btVector3 class should let you move the object sideways by changing the first or third (X and Z) parameters. The tutorial assumes that you understand vector math. Also, when you set 0 in all btVector3's, that makes the sphere intersect the plane halfway through, because they are both in the origin. This means a collision is already happening during initialization. That's probably why the sphere object is jumping up, because it has responded to the collision. Setting up rigid bodies with a finite mass in a way that they're alrady intersect each other during initialization can have unexpected results in their movement. Usually, the only rigid bodies that can overlap without moving are the ones with "infinite" mass, and these are usually for static scenery objects. 

Update all the particles' positions Cull the non-visible particles Assign pointers to visible particles to the beginning of a vector Copy vertex data referenced by the pointers to the vertex buffer Draw vertex buffer with no. of visible particles as no. of vertices 

The realism of graphics and physics adds to the immersion of the game, but physics and graphics do not have to be held to a realistic standard. Fun is not directly associated with realism. Part of what makes a game fun is giving the player a good sense of empowerment. This requires a balanced set of physics rules to be able to do a lot of cool stuff as if it's second nature. High-profile games are usually held to the standard of summer action Hollywood movies, and from a technical standpoint this actually isn't too bad. Those movies are pretty liberal with physics and visual effects and filled with over-the-top action sequences that only the hardcore engineers and physics geeks will have trouble accepting. You just need enough realism to that degree to satisfy the average gamer, and they'll be pulled into the game's world. On the other hand, glitches are a sure way to remove you from the immersion and remind you that you're still just playing a game. Only sim-type games try to make the exception and aim for a true-to-life feel. Case in point, sports and racing games for the serious fans. 

There's mainstays like Quake 3 or if you want something a bit simpler (and in 2D) look at the indie game Gish. They both use OpenGL and are cross-platform too. Gish is a little on the messy side, though. 

I'm building a voxel world generator with XNA where the voxels are rendered as polygonal cubes. The world is divided into 1024 chunks of 32x32x256 cubes each (as 32 chunks by 32 chunks), and each chunk has its own index and vertex buffer. Since each chunk is different, vertex buffer size is determined on runtime. To prevent massive stalling on opening the program, only one chunk is re-built per frame until all chunks are built. Occasionally the program crashes with an "insufficient memory" related error that is caused by the line that creates the vertex buffer. Here is how I set them up: 

For heading-to-nearest diagonal conversion, reduce both X and Y proportionally so the larger value is exactly 1 or -1. Set 

Materials made for a 3D modeling program won't translate directly into the materials used in your game. You would have to construct a content pipeline for your Blender or 3DS assets, or use one that's pre-made, and then you have to tell the hardware how to use the data extracted in these assets to display the graphics. That is what shaders are responsible for. Your program cannot guess exactly how these files are supposed to be used. Shaders are especially useful in applying screen-space effects, which do not take in regard the geometry in the scene, at least not discreetly. Even if you use BasicEffect in XNA, you are using some sort of shader, just a pre-built one. Unlike DirectX 9, XNA does not have a fixed function pipeline. So even diffuse texturing is a very simple use of a shader. There are ways to minimize shader use, by using the 3D modeling software to bake the effects to your models as textures, such as ambient occlusion. But these tricks do not work well for dynamic scenes. 

This might seem unfavorable to some but I tend to keep my resources local to the GameState that needs them, and each GameState has a ResourcePool of sorts. This is a nice way to keep level assets separate since I don't really need menu backgrounds Your Resources class would be better served as a structure, and the GameState will be responsible for Load and Unload. Some of resource management in XNA is partly determined by how you import your content in the first place. Many people bind textures and effects to their models in the content processing phase of the build- leaving them to only manage meshes and the rest is already referenced within. You seem to take the more classic "mix and combine" approach for more flexibility, so you need an approach that black-boxes the underlying work and cut the code you have to write in the long run. I haven't used FlatRedBall, but from what I can tell from the short description written here, it sounds like the Lazy Loading pattern. This is a concept worth looking into if you want to make your life easier with managing many resources. 

You're right on track that linear algebra and more complex math usually involves 3D graphics and 3D space. But there's still more math that can be done within 2D games. Physics math can get pretty hardcore, and it gets more complex if you consider soft body physics and B-spline dynamics (and still in 2D, keep in mind) Try building or dissecting a physics library that will cover collision handling and response for common 2D shapes. Linear algebra is pretty useful for calculating trajectory vectors for collisions. The dot product is quite related to the unit circle used in trigonometry. Yet, the complexity of rigid body physics increases exponentially when applying it in 3D. 3D graphics gives you a greater understanding of matrix calculations, quaternions, linear algebra, and some applied calculus. The first thing you'll probably pick up on is using matrices to move and manipulate objects in 3D space.