When the player is attempting to walk to the top-left, and run the collision resolution with blocks A then B, this is what happens: 

One more thing; I read this somewhere (but I don't remember now) that the first level in Super Mario Bros has an excellent example of preparing the player in advance for obstacles. Consider this section: 

Since moving to the top works, we'll do that. Note also that this is a method that only works when everything is AABB - all your walls are horizontal/vertical and so on. In the general case, such as when you have diagonal walls, you will need to work out which way the walls go, in order to "slide along" them. 

I'm guessing that and traverse the quad tree from root to leaf, and that's why you are concerned about its performance? (By the way, rule of thumb is never perform any optimisations unless you've asked "have I measured a real performance problem" and can answer in the affirmative.) In games, the vast majority of movement would be continuous, that is, your entities will be moving from one leaf node to a neighbour. You would have a tree with linked leaves, so even if the leaves share a very distant ancestor, you only need to follow the local links instead of all the way up the tree. 

Don't assume the pixel format that gives you. Check its value; chances are it isn't ARGB8888 like you expected. Instead, if you want that pixel format specifically, then use on the loaded surface. Pass in your spritesheet surface's pixel format to guarantee that the two match. 

Minimax works fine for simultaneous move games; the only modification required is that instead of enumerating an opponent's counter-moves to each possible move, you build a payoff matrix based on what you and your opponent play at the same time. Recall that in minimax, at each node you enumerate your (or your opponent's) possible moves, evaluate your opponent's (or your) counter-moves to get the best one corresponding to each of your moves, and then pick the move that maximises your payoff. That is, you may have this: 

I'm putting together a ECS for my game with another two main components: an event bus for communication and a Lua interpreter to load scripts. Now, the parent element is a framework/game object with references to all this three components. My question is, what is the best communication pattern: drill the interpreter and any other orchestration objects down to every system or centralize all those calls in a subscriptor for the eventbus, and make everything from there. Example: // Plan A 

is not accepting the context parameter that I am giving him, which is a "this" reference to the main class. Main class extends from Cocos2dxActivity but I don't have any other that extends from Application. Any suggestions on fixing it or how to improve the architecture? EDIT: I am trying a new solution. Make the bridge class into an Application child, is called from Main object, initializes OpenFeint when created and it can call the OpenFeint functions instead of needing an additional class. The problem is I still get the error. 

I'm implementing engine tools for my hex board game and this one is becoming messy. I want to get a list of all the positions that a cone of size N would have, given "caster" origin X,Y and origin in X0, Y0 taking direction into account. So far I have been able to get a size one cone using a "simple pattern" approach, but it doesn't translate well for N-sized cones. This is the original cone 

The problem was the library naming, as the standard Android project has the library names as "cocos2d" (my project had cocos2dx) and "cocosdenshion" (case sensitive into "CocosDenshion") 

If I have a texture with known metrics (pixel size, byte type) and a GL surface to render to of a know density and measures, and I want to draw a quad composed of two triangles that correspond to the size of the texture in proportion to the size of the surface. For that I need to recalculate the needed quad's vertexes. Can someone explain me the math involved in this process? Example: I have a screen/surface of 800x600 and a texture of 100x20 that I want to position in (20, 20). How do I calculate the vertex of the quad needed for it. My shaders are simple v 

What you could do is either use an array of the critical points, and then use an enum for the index that you retrieve based on this. Alternatively, you could use else-if statements chained together. I feel that an enum would be the best final data structure (containing miss, dodge, parry, hit, critical hit) as it can allow you to have stronger typing in the end. 

I am working on a top-down space shooter, and I have come to the point where I need some input on a mechanic. I have implemented enough that I can make this choice; either way will not change the code in any major fashion. Which would be a more interesting feature: Having planets being among the 2d objects that the ships interact with (crashing into, being able to have batteries that fire from them); or should they be background objects, maybe still having effects on the battle, but less of a direct influence. Practical differences: Would the planets have gravity (first yes, second maybe not)? Would they take up space (first yes, second no)? Any other differences that might affect the differences, please let me know. 

The closest thing I've found to doing this is , but that only takes either a string or a type and I'd assume it just finds the relavant script and instantiates a clean copy of it. That could work for what I want to do as I could just fill in the relevant information, but that would be tiresome and there should be an easier way to do this. 

What you need to do is two things: One, the ball has to have a rigidbody2d attached (the walls don't) and then create a PhysicsMaterial2d and experiment with the two values (I think you want friction: 0, bounciness: 1). 

The problem, as you can see, is that if you want to keep the same layout of the graph, you'll get some really curvy edges in the dual graph. Also, you'll often end up with a multigraph - a graph where some vertices have multiple edges between them. It is guaranteed to be planar though, so that's something. To use your example, we can produce the dual graph in the following steps: Step 1: For each face in the original graph, create a vertex 

Furthermore, diagrams are great for communicating and documenting your design, either to non-technical people or people who are new to your project - and remember, in 6-months time you are practically new to the project too! How you use UML should be driven from these considerations. Diagramming for your own sake? Use whatever notation you are most comfortable with. Collaborating with other developers? Try to include the details of API calls, message types, directions of dependencies. Discussing architecture? Black boxes and simple connections will suffice. No-one uses the full set of UML features anyway, plus it is very useful as a set of standardised notation that many people understand - whereas my napkin doodles may be incomprehensible to you and vice versa. As for myself, I use diagrams all the time - simple notepad drawings for personal projects, simple UML diagrams at work. This UML diagram is what I'd consider too complex, and one that I'd never make because the cost of producing and maintaining it outweighs its benefit, but of course YMMV. 

But since you deal with first, you "listen to" it (go left), and by the time you get to and attempt to move left, you get stopped dead. Notice that if you had done this in the reverse order ( then ) it would have worked, which explains why this bug appears only if you're moving up and not down. Solution I think there may be many ways to solve this, but one simple method is this: 

The problem was in the Android manifest. My main class inheriting from Application was not added as the main application class in the description. Once added, the app called a new object and the OnCreate method where I could initialize OpenFeint. As OpenFeint is open you can now statically call the OpenFeint functions to open the different views. 

I am trying to create a generic C++ bridge to use OpenFeint with Cocos2d-x, which is supposed to be just "add and run" but I am finding problems. OpenFeint is very exquisite when initializing, it requires a Context parameter that MUST be the main Application, in the onCreate method, never the constructor. Also, the main Apps name must be edited into the manifest. I am trying to fix this. So far I have tried to create a new Application that calls my Application to test if just the type is needed, but you do really need the main Android application. I also tried using a handler for a static initialization but I found pretty much the same problem. Has anybody been able to do it? This is my working-but-not-as-intended code snippet 

I am trying to implement OpenFeint for Android in my cocos2d-x project. My approach so far has been creating a button that calls a static java method in class Bridge using jnihelper functions (jnihelper only accepts statics). Bridge has one singleton attribute of type OFAndroid, that is the class dynamically calling the Openfeint Api methods, and every method in the bridge just forwards it to the OFAndroid object. What I am trying to do now is to initialize the openfeint libraries in the main java class that is the one calling the static C++ libraries. My problem right now is that the initializing function 

For FPS cameras, there is no technical reason why the pitch needs to be smaller than +/- 90 degrees; the reasons for limiting it are purely gameplay-related, and it's obvious if you've encountered it. When you are looking straight up or down, attempting to look left or right will not move your reticle with respect to the game world, instead you simply rotate on the spot. This makes it difficult to track moving targets that are directly above or below you, amongst other issues. Some games impose a pitch limit to address this issue, but most games avoid this issue altogether using smarter level design, and I think you should do this too. Try to avoid situations that would require your player to look far up or down, such as: 

If you're starting with a tileset with regular dimensions and layout (as in your example), and your goal is to create tile maps in Tiled, there is no need to use third-party tools. Tiled supports these natively and easily. There are a few tutorials on using Tiled like this one, but it's very simple: 

If you absolutely need to control whether the player can see something or not, possibly for multiplayer anti-cheat or if it's key to your game mechanics, then completely obscure them. This way no amount of gamma correction will make them visible. Not the best example, but in Closure, areas not being lit are in complete darkness: 

There is no need to filter in this scheme; you might have a rendering system that draws all the "drawn" components, and a physics system that moves all the "moved" components. 

Note that even with this heuristic, you can get stuck in loops eventually. It is up to you to decide what to do in this situation: 

A similar thing happens no matter which tile I use. More information: I tried placing a cube on where the hex is, supposedly. Its transform is very different. So what it appears to be is that the tile is being placed in the wrong place, not the cube. Further experimentation shows that the cube is appearing at exactly half the hex's apparent transform (I added a multiplier of 2 to the cube's position and it appeared in the right spot). I still have no idea why. 

I've just switched over to MonoGame from XNA. Since MonoGame is supposed to have the same API (implying that any copied code should work as usual), I've run into a strange issue- input doesn't seem to be handled through MonoGame. When I tried to fix any missing "using" directives in that class, it automatically added which implies that there's no MonoGame equivalent. Googling the issue had no success- all the tutorials I found for MonoGame said to use XNA's input. Is there a MonoGame equivalent for handling input, or do I just need to use XNA for that? 

What you could do is do like the old computers did when solving board game: Have the computer play through the game many times (> a couple thousand, not so hard to do if you remove player input). Each time it gets to a decision, choose randomly, but have it mark that it made that decision. Then have it analyze based on the other games where that same exact decision was made, and compare the results of those to the ones where the opposite choice was made. 

I have a procedurally generated tile that is a part of a turn-based hex tile game. When I try to have the tile instantiate a prefab that is the placeholder for a unit, I used the tile's transform.position as the position part of GameObject.Instantiate(Object, Location, Rotation). Unfortunately, this is the result: 

To make bodies immovable is an arcade physics thing. For P2 it's . "Kinematic" in P2 means, generate collision events, but don't be affected by physics itself like gravity and collisions. To selectively collide P2 handles this problem using collision groups. Basically if you want one group to collide with another, but none of the bodies in the same group to collide with each other, you put them in separate groups and specify that the two groups collide with each other. Pay close attention to the example and documentation because it's not trivial to set up. To handle collision events Collision event callbacks are still there but they are set up differently; see the example given in the last part. Instead of explicitly requesting a collide/overlap, P2 will be doing all its stuff all the time, and if you gave it a callback during setup it will call it as collisions occur. As for overlap, P2 doesn't support it directly, but there is an equivalent solution known as the "Postbroadphase Callback". Basically this is a callback where P2 collects all potential collisions and then asks you - via the callback - whether to allow those collisions to resolve or be ignored. You return false in the callback to tell P2 not to perform collision resolution, but the fact that the callback was called in the first place means that those two bodies have overlapped, so this is where you put your overlap handling code. 

Start with Northerly directions only, i.e. the player is only moving up the screen Gradually add in East/West directions Finally, add a few Southerly directions 

When doing complex projects like games, you often can't make all the features you want, because you're running out of time/money or because they didn't turn out to be as good as you expected. This is known as feature creep. But there's a flip side to this; you will also find features that you didn't think you needed, but as the project takes shape their need becomes apparent. This is why people build prototypes - so they can learn what works and what doesn't, so they can cut features that don't work, but also so they can find new features that would be awesome. If you're not doing either of those things you're not learning, you're doing it wrong. This is basically the sentiment expressed in a talk called Advanced Prototyping, by Chris Hecker and Chaim Gingold, which includes many examples from their work on Spore, where they were often surprised by what worked and what didn't, going as far as redesigning whole systems based on prototype feedback. Another example is the design process for Left 4 Dead; at first the game only had basic zombies, but from playtesting with experienced players, the designers found that the players stuck together effectively and the game was too easy, so they added special zombies to break the team apart and keep the game exciting. Of course, this doesn't mean you should build your game without any prior design at all. You should make sure that the core of your game is fun before proceeding, because that's often the hardest part of making a game.