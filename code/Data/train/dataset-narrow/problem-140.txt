I am answering under the presumption that you are asking about the equipment and not a managed service (i.e. you are paying someone else to manage the network for you). There are many reasons why managed network equipment is much better than unmanaged equipment. This borders on being a question that is too broad, but in summary with unmanaged equipment you have no visibility or control. Here are a couple of basic questions you can answer on a managed network equipment that cannot be answered with unmanaged equipment. Knowing the answers to these questions can allow you to address problems within the network. 

Anything you choose to do will increase attenuation and potentially shorten the distance you can run PoE. There is no best practice answer to this as the best practice is to re-run the cable. Since you can't (or aren't willing to do this) then I would do one of two things, although I would still highly recommend running a new cable (you can use the old cable to pull the new cable through walls, etc). 

This would depend on the particular switch's behavior. Different switches will behave differently (based on vendor/model and configuration). However you should expect these to be dropped because broadcast is not a valid source. Switches look at both the source and destination addresses. Destination for delivery and source for learning. They will also look at both for other features as well. 

Yes, this is most certainly a major factor. A 802.11n 3x3:3 dual band adapter and access point will have far better throughput than an 802.11n 1x1:1 single band adapter. In this specific example, you may be looking at over six times the throughput (factoring in the spatial streams, guard interval and bonded channels in 5GHz only). 

I will start by noting that there isn't a single probe response in this capture. This leads me to believe that there is some sort of problem with how this capture was obtained. As such, there is no way to determine if the Microchip device has responded with a probe response or not. However, we can assume that a probe response has been sent and recevied at some point because it appears your iPhone6 has joined the IBSS. Take a look at the beacon frames at 19.85 seconds into the capture. You now see both the Microchip and the iPhone6 sending beacon frames for "Anova 1" with the same BSSID. Since they have synchronized the BSSID, this would indicate they have both become part of the same IBSS. 

Sticking to the options you provide, I personally would follow #1 on your list, but I would not use common ST. I would rather use RST (or MST if you need to load balance VLANs across links) as it allows for must fast/smoother transition when a link comes up or goes down. This addresses both the concerns you have for this approach: 

The SSID is only part of the information used between an AP and a station, and many software clients will aggregate or simplify the networks they find into one entry in the wireless networks. However with most enterprise wireless solutions, each AP will have a separate BSSID (looks like a MAC address) that is associated with a logical interface on the physical interface. With some software clients (Intel used to do this, but I haven't used it in a while so not sure if they still do), you will see each unique AP/BSSID listed in the wireless network list, so you end up with multiple entries with the same SSID. You can also use a software tool like InSSIDer to view the individual devices broadcasting the same SSID. You are correct in that they share the same "collision domain" and resources, however there are many reasons to do so. For instance, you may want to provide different security mechanisms such as WPA2-Enterprise for your employees and an "Open" network with a captive portal for guests. You could do this with two different sets of APs, each doing one or the other. However in the 2.4GHz space, you really only have three channels to work with in your channel plan, so unless you only need one AP for each, you are going to have channel overlap and still be sharing the "collision domain" (and this also complicates the channel planning significantly, but that's another discussion). Better to do so with multiple logical interfaces on one device as this means less devices, a lower cost (both capital and operational), and a simpler network to manage. Now there is a caveat, and that is with each additional BSSID/SSID on a physical device, the more you do lower the efficiency of the RF use, mainly because you are creating additional management traffic in the air. While dated, you can find a good explanation on this effect in this document, if you are interested. 

In re-reading your question, I realized you noted you did not seem to have the force command available. In your case, I will still recommend removing the command and have your interface look like so: 

Managed switches are in simple terms switches that can be "managed." Managed means that they can provide information/statistics about their operation and usually that they can be configured. While the vast majority of managed switches can be configured for IP (and this includes all the more capable devices with full feature sets), there are some that can be managed strictly over L2 with proprietary management software but this limits them severely in terms of what advantages they have over a non-managed switch. A L3 switch is a switch that can perform some or all the functions of a router in addition to being a switch. This then begs the question, what is the difference between a L3 switch and a router? Technically speaking, a L3 switch is a router. Or put another way, a device which performs L3 functions is a router (this is also why they can call consumer gateway devices "routers"), and a L3 switch performs L3 functions. So why the distinction? People will point out many things sometimes, but you can always find exceptions to those (whether it is based on features, performance, etc). In my mind it really comes down to one thing. L3 switches are designed first and foremost to perform L2 functions. Even if they have a full L3 feature set and high L3 performance, the primary motivation behind their design and engineering is L2. Routers are first and foremost designed to perform L3 functions. Even if they have L2 modules or functionality, the primary motivation behind their design and engineering is L3. So when it comes to pushing new capabilities, features and/or performance, the focus is often on their primary layer of operation first. An example of this was the Cisco 6500 L3 switch and the 7600 router. While they were both basically the same platform and could use much of the same hardware/modules, the focus was different. 

The other answer deals well with how the outbound traffic from your device decides which network connection to use. However it seems your question is asking more about how data inbound to your phone (such as push notifications) decides which network to use. There are a number of ways this is done, but if it is truly a service that works on both WiFi and cellular, then odds are it periodically "phones home" or establishes and maintains a connection to a server. When the device/app is checking in or "phoning home," it can collect any messages that are stored for it. In this case, it works much like email and all return traffic from the server will go back to whichever IP address was used to send the request. Another option is that the device/app creates a connection to the server and keeps it open so that the server can use it to immediately push the notification to the client whenever it receives one. If your device connects/disconnects, the device/app will re-establish the connection to the server. Again, since the device/app will originate this traffic, all return traffic will go to the source IP whether that is on your WiFi network or your cellular network.