Inter-data-node latency is much much lower. So data shipping does not have such impact on performance. And all the tables (except some absolute corner cases) are sharded between data nodes. For any data fetch data nodes must find which node holds active part of the required row. This latency still cannot be ignored. One can find that for the best possible performance Dolphin Interconnect is suggested. But: 

But with such amount of memory I would go with ASMM (SGA_TARGET) and huge pages. Especially if you will have many clients connected. Overhead to manage 48GB of 4kB pages will be quite big. 

Of course I forgot something. :) People will add more advantages in comments. While listing advantages I am not considering scenario when you have to preserve data between restarts. Database Concepts about Temporary Tables 

ORACLE_SID can be parsed from /etc/oratab file. ORACLE_HOSTNAME maybe from HOSTNAME environment variable. 

CREATE LOGFILE GROUP and CREATE TABLESPACE accept only bytes as unit. $URL$ With MB converted to bytes logfile group was created successfully for me. 

Similar concept in Oracle is called Index-Organized Tables (IOT). Difference with PostgreSQL CLUSTER is that in PostgreSQL CLUSTER command reorganizes table once and later table still grows as it wants to. In Oracle IOT keeps its structure as ordered by index. Unlike Phil I'm seeing IOTs now and then. The most often they are used when you need to retrieve many (think hundreds) rows by index. 

Also with such amount of memory you really really should use Huge Pages. Of course that means no more AMM and back to ASMM. But especially if you have many connections to Oracle the difference can be really big. You can read about configuring Huge Pages e.g. here: $URL$ 

This instruction is for Oracle Linux. And you are using Red Hat Enterprise Linux. Even though Oracle Linux is compiled from RHEL sources but they have separate base repositories. You will have to resolve dependencies manually. I tried to download preinstall RPM and install it with yum but it requires RPM which is not available on RHEL. Even if I am not the fan of what Oracle does with RHEL but for Oracle databases I switched from RHEL to Oracle Linux. Less resistance this way. Oracle ASM kernel modules are not available for RHEL and Flash Cache feature is available only on Oracle Linux. 

~50 million ~1kB records is ~50GB of data even not counting headers and possible indexes. And you have 3 machines with 8GB of RAM each. That means that Data node could use somewhere up to ~6GB of RAM. All the data records in MySQL Cluster has to be stored on two nodes. So in your Cluster you can store (3*6GB)/2=9GB of data. Actual amount is even less because of data records headers, possible indexes, other metadata. So to store 50GB of data in Cluster you have to use MySQL Cluster Disk Data Tables. And by the way with the default Cluster setting of you cannot have 3 Data nodes. Documentation says that . You have either to use 2 Data nodes and dedicate third server for SQL node or change to 1 and loose high availability. 

If your ASM diskgroup uses some storage device with several disks then you should be able to improve performance by copying several datafiles in parallel. 

Yes you can do that. There's nothing dynamically changeable here in normal circumstances. All the files here are not touched except in case you apply some patch. Files specific to the particular database resides in: 

Fuse-zip is available from RPMforge so one does not have to compile himself. Of course I would not use this for production database but just for restore - why not? 

With ALTER tables on NDB we noticed the funny thing. You can work with the data if you run the queries on the different SQL node from the one which is running actual ALTER TABLE command. Maybe not all the possible variants of ALTER TABLE but enough for our purposes. So we were doing the following on one SQL node: 

In such way you can add several extents adjusting their sizes. After you'll check that corrupt blocks now longer belong to free space you can fill the table: 

When renaming datafile you have to move it to the new place first. command does not move file. It just changes file record in control file. But destination file has to exist. Renaming and Relocating Datafiles 

Then edit processes in cleanup some mess made by strings start Oracle with pfile and recreate spfile: 

First 2500*50kB ~= 128MB. Then if you will check CREATE TABLESPACE syntax default INITIAL_SIZE for the datafile is 128MB! So if you want to store more data you can either specify INITIAL_SIZE you need while creating tablespace or you can ALTER TABLESPACE ADD DATAFILE. By specifying in CREATE TABLE statement you stated that you want on disk table not in memory. With such tables shows nothing meaningful for that table. If you want "classic" NDB table which is stored in memory just skip modifiers and then will show you how much memory is used for the data and indexes. 

Now if you look into your output you can notice that only backupsets with archivelogs has tag FIRST. Backupset containing backup of datafiles has autogenerated tag TAG20150515T105436. 

Also I am guessing that you are running database on disks with write caching enabled. Or RAID controller with write cache enabled and no batteries or flash to preserve unwritten data. Do not do that if you value your data! Quite probably you will get some corruptions in case of crash reboot e.g. in case of power loss. 

"Too many active scans" error means that at a given moment there are too many queries running which are scanning the tables while trying to get answers. Scanning means for example range scan queries (WHERE val > 20). And if I remember right scan also means fetch queries if index is not has. 

Apparently you dropped the object already. Now to calm you down - corrupted blocks now most probably are in free space and do no harm. They just annoy you during backups. To check that: 

Take backup of NDB tables structure with mysqldump. Make NDB backup. Restore mysqldump backup on the new cluster. Restore NDB data using ndb_restore (on both datanodes). Rebuild indexes (command has to run just on one datanode). 

We were using the second method on 9i to compress export online. And I do not recall problems with this approach. We ran two sessions from the shell script: 

Browse My Oracle Support for the possible causes. For example quick search revealed a bug about your Oracle internal SQL. Workaround for it is: 

As far as I know - it is impossible. Oracle is very strict about ACID. In general to reduce size of redo logs you can use: 

MEMORY_TARGET needs /dev/shm filesystem with required size. By default /dev/shm size is half of the system memory. So you have to change line in from: 

For that you should configure SQL*Plus output. Documentation what can be done and how to do that is here. In your case it is: 

It will find all the objects which consume some space in given tablespace and sorts the output by used space. TEMP objects are always related to user session. So you need to query another view: 

You can. From backup (rman) perspective there is no difference between LOGGING and NOLOGGING tables. What you cannot do is restore through NOLOGGING operation. That means that if recover procedure will encounter such operation in archive log it is currently applying table will be marked as INVALID. 

This means that you have to include Oracle instant client libraries into the database used by Linux dynamic linker when it has to resolve run time bindings. Instructions tells you to create new .conf file in /etc/ld.so.conf.d/ directory with the Oracle instant client libraries directory. And then you have to run with root permissions so that it will create new database with the Oracle instant client libraries included. Example from one of our servers: 

Also I assume this is development machine because in production MySQL Cluster with has little sense. 

I believe your DBA told you to use temporary tablespace for temporary data? If so using temporary tables have the following advantages: 

If large_data_table is really big (tens GB and more) then 1% or something like that may be needed. And do not believe that in dba_tables sample_size=num_rows. For big tables actual auto sample size is much much lower. I had the SR with Oracle about that. They found actual sample percentage only from session trace file. It was ~0.004% for 170GB table. 

You already got two answers about one database - multiple schemas approach. I will try to add some arguments when several databases may be better. If your applications are very different it may be better to have separate databases for them. Then you will be able: 

What does alert log says at that moment? From my experience - in almost all of the cases when Oracle's takes very long time (10+ minutes) or does not finish in reasonable time running DBMS_JOBS jobs are the problem. Don't know if DBMS_SCHEDULER jobs would also inflict such behaviour. So the best thing before reboot is to disable jobs and kill running jobs. No problems with shutdown then. 

When you no longer need the data you can drop the tablespace and delete datafiles. This is basically the only way to release space back from Oracle to the operating system. When doing backups you can exclude tablespace from backup. E.g. if it contains non essential or easily recreatable data. When doing restore you can skip tablespace. E.g. if you need only specific table or you need to start as soon as possible you can skip index tablespaces and rebuild indexes online. Tablespace per user can be useful. Then when user is no longer needed you drop the user then drop tablespace and have disk space back. Also if user suddenly starts to generate lots of data only his tasks will break when tablespace becomes full. Other users will be unaffected. Data blocks corruption usually is contained within tablespace. In such cases only one tablespace is affected. You can store tablespaces (datafiles) on different types of disks. So you can manually manage which data goes on SSD and which on SATA. In really rare cases you may need different block size for the tablespace. 

For Oracle client you can use Installation using Response Files. Your C# program can generate response file and run installer with particular command line options. 

Performance will be very similar. GHz difference is not essential because e.g. E5-2690 has 3.8GHz Max Turbo Frequency vs 3.5GHz on E5-2643. You can find full comparision here: $URL$ The big thing may be licensing. If you are using Standard Edition or Standard Edition One per CPU licensing they are licensed per socket. So in case you buy second E5-2643 you will also have to buy one more Oracle license. Of course that it not the case with the Enterprise Edition. If licensing is also not an issue then you still have two decide between two choices: 

It is possible to restore backup on a different cluster. Did that many times myself. Just backup and restore procedures are not so simple in the case of NDB. 

Pushdown basically means that some part of the job is "pushed down" to data nodes. So performance gain is because: 

If you have split exactly in half brain situation MySQL Cluster resolves it designating one node as master. If you look into ndb_mgm output below you will notice asterisk at the end of node 10 line. It marks master. It means that if your cluster will be split in two equal parts the half which contains master will continue running. Nodes from the other half will be shut down.