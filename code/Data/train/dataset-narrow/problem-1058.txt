is redundant you can just do You will run into false positives for any property set on such as or (for instance consider ) is not a sufficent as it will miss any falsey value (NaN, null, false, 0, "", etc). You should use either the operation or This can be done considerably faster (and more accurately) by iterating the array instead of the properties on (lets you get around a call) 

I've made some validators of my own and this is my personal preference for structuring validators and it allows us to due away with that weird variable. I've also fixed a bunch of your linting errors - there were a lot of them so I didn't really comment on them. In the future run your code through jshint before posting it :) One last thought. There doesn't seem much of a reason for you to be writing this code as a class as its most likely a singleton and you're not writing the code on the prototype. I've resturctured your code to be a more conventional singleton rather than a class Here's the start of a counter proposal... Theres likely bugs but the code is a great deal simpler and uses less hackery than your original approach. 

The way I would do this with the current iteration of (1.6) would be through reduce. Note use if you want to favour items to the left 

However, in you can use which would be more intuitive. will be available in underscore 2.0 if they accept my pull request 

Alright I'm going to focus on some potential errors with your function. The first obvious issue is you're relying on being set. This isn't always the case - for instance consider any class declared . Now if you run . Furthermore, many frameworks provide some class extension/constructs such as which would invalidate that check. Further issues may present themselves with code minification. Out of curiosity, I decided to plug your code into the underscore js test suite to see how it would do. I couldn't implement as it accepts multiple types as objects. It passes all the tests but the ones for understandably. I excluded the tests as I couldn't get them working on gists or jsbin but they pass as well. Not bad :)! 

Customer and Item classes Well, to start with, isn't used and I don't see how it could ever be. So that should just go away. Your naming style is off for C#; you should be using PascalCase instead of camelCase for public methods (eg., AddItem). and don't add much value; they're OK as-is, and are actually a reasonable encapsulation - but they're kind of overkill here. (as an aside, your class doesn't include , but I inferred it from your ). This comment could really be directed to the whole structure, actually - since you really just need a to solve the problem. Not to say the structure can't be useful, but I would consider it overkill unless there's some future plans being made here. Program class Your class sets a private member, but never uses it outside of ; it's odd to have a class instantiate itself like this. In this case, you can just use the as a local. will take an object and call on it for you; no reason to use the format overload. 

From there, any further optimizations would be heavily dependent on your data and would need some example data of the correct relative sizes to profile and test. 

Ok - now we've got most of the pieces, we just need to put the actual program logic together. Let's move on to the method: 

So, I'd suggest it'd end up looking something like (it's been awhile since I've written straight ADO.NET, so there may be some minor issues here): 

Note the weak typing of using - if these classes are used somewhere else, implementing as an explicit interface would probably be preferable. You could do generics, but that makes the chaining harder. 

Your unit tests for now only need to be concerned with the results of - which verifies the was constructed properly (an important bit to test, since it's weakly typed). You can dress it up with generics, extension methods, builder patterns, etc. - but that's the basic pattern. 

Pretty straightforward here. We could've written this more succinctly, probably even in a (really big) one liner, but this strikes a reasonable balance with clarity, I think. So, now we just have to put those two together... 

Before even addressing the actual question, have you actually proven that database queries are harming your responsiveness? Since the queries are to local storage it's possible that they are fast enough to not require using asynchrony, particularly if they are simple queries or the database is small. Next, I notice you've assumed that the database itself is not threadsafe, i.e. that you must only allow access from one thread at a time. Are you sure that's actually true? Many (most?) database handle concurrency themselves, so you may be adding an unnecessary layer of synchronization. I looked around a bit, but could not find anything specifically documenting concurrent access to isolated storage databases. I would start by researching that, or possibly asking a question on StackOverflow. If the database does allow concurrent access then you just need to worry about update conflicts, which you could hopefully avoid in a single-user phone application. What I'm getting at here is that multi-threading and locking is hard. Don't do it unless you're sure you have a good reason to do it. If you really must to multi-threading, then the C# keyword is a good place to start. Unfortunately, your example probably will not work properly because each instance will have it's own lock object - so if you create more than one instance they could conflict with each other. You "Current Variant" actually gets this more right, because your is a static variable, so there is only a single instance of it across the system. However, as I understand it lets you use Linq statements against the database, which will not know anything about your lock and hence will not be synchronized. I think you'd have to create a separate application layer to wrap the and expose just the certain operations that your application needs. This is generally called the "Repository Pattern". Inside the repository you could create a single lock object, wrap a around all accesses to a , and use inside each of the repository methods to make them asynchronous. 

One more note: you probably want to add your custom selectors near the top of your code (and definitely outside of your keyup event handler!) in case you want to use your selector somewhere else in your code. Now some nitpicks Your Javascript near the end becomes difficult to read because the formatting of your handler. Try pasting your code through an automatic formatter and notice how much easier it will be to follow (eg $URL$ 

To answer the actual question OP seems to be posing -- the pattern is fine I wouldn't change it but I would expose whatever you want to expose explicitly into a namespace using this format (window or whatever namespace): 

On the first pass the code was pretty easy to follow but are all those global variable intended? Globals I noticed in my look through... May be more. 

The first thing that really jumped out at me is your method is using synchronous http requests (looks accidental as you're using a callback anyway, see msdn for why this should be avoided etc). Instead of you probably want Making async requests will allow the first notable improvement I would make is to make loading async. I'm going to use the native promises -- feel free to adapt 

Alright first thing the order that an engine enumerates object properties is not guaranteed!!! Its pretty consistent but there are engine bugs and you shouldn't rely on the behaviour. That said, this is how I would write your . You can use to create the ranges list but again - order isn't gaurenteed. You could sort it I suppose? 

I see a bug for a property case as . You should check if it's not null or an object :) Another less important? bug is you can't use the key on any of your objects. You can get around this by using Only obvious optimization I see is to move the check after the check. is a relatively expensive function so you will probably see some gains off that. I expect this should be even faster than doing which is known to be faster than your loop... I assume you're polyfilling trim for older browsers right? 

Once you have the of the integer portion, you can use the format specifier to get the correct number of decimals, which would clean up the string building part. 

If you're familiar with inheritance, hopefully you can see how you could add that functionality into a 'PersistentInventory' subclass. Hopefully, you can see by splitting the functionality out cohesively both readability and maintainability. Think through adding the following functionality in v2 of your app with the various designs: 

I think a plugin architecture would be a little overkill unless you're interested in versioning or deploying the sub-modules separately. You haven't shown the sub-modules (the actual solvers) but I'd probably define an interface for them and then use a instead of the statement. Really, it's pretty minor, but I see a couple of advantages of the : 

This is basically a pipe and filter pattern - where you construct some number of filters into a chain and just pass the outputs to the next filter. If you control all instances, then the simple thing is to abstract out to an interface: 

Now that we can see that we're looping over all the rows for each , we can change to traversing once and pick up any along the way. This effectively flips the order of iteration (I'm assuming there's more rows than query strings). To get rid of the nested loops altogether, we'll switch to using to find any matches. We'll also drop the check on each iteration for a single call at the end. That should keep us from iterating multiple times. 

That's not going to do a whole lot for performance (basically get rid of a rows iteration), but everything else I see is really context specific that may end up with worse performance assuming your data looks like I expect it does (< 10 , < 50 and thousands of rows). A couple of additional thoughts you can try, though, depending on your data: 

For file IO, the way you're currently doing it (saving after each add/remove) you could add it as part of : 

Well thats how we would want to write it anyway... But alas, we live in tough times where people still try to support Chrome 33 and Firefox 26 (poor souls). I'll let you fellows in on the way some popular libraries write their functions I suppose. Actually, I recently improved underscore's uniq function so you may notice its faster than you expect. Lodash's method is even faster in some cases Anyway, heres the fastest way I know how to make a set, there was some discussion in doing it this way in underscore... It similar to what lodash does (here's a discussion on implementations $URL$ 

I'm biased here, but as a past Mootools developer I keep comparing your function with Class.refactor. Personally I would prefer you add a reference to the original function on - maybe as some property or let the user handle storing the original. I'm not a fan of adding a global for the original function. A question, why do you not pass to your constructors? If you're wrapping some classes this seems like it may make usuage less intuitive. Update (still at work and can't look into removing the approach yet but I think I found a great change... You can rewrite the extremely confusing like this (unit tests passing): 

Some key things to notice - see that its checking backwards, that will improve speed for near sorted collections. You can use instead of the while loop -- thats the difference between the and implementations. You can write the while loop as below if ya prefer 

Don't have time to do a full review but you probably want to reorganize your and loading. This will allow the browser to download the stylesheets concurrently while downloading+executing your scripts. Also you probably want to load before as knockout will delegate to the more robust method where applicable. In the press release for they claim you won't have to load jQuery first. Also note, there's no advantage to loading in head afaik as it won't actually apply the templates () until the content ready event. Also you probably want to point to a single version of jQuery to prevent something going awry between jQuery (quite unlikely I guess but worth considering).. 

I'm not sure if you're interested in better algorithms, but if so here are some. In this particular implementation, I would consider changing how you handle substrings. You're currently doing a lot of string concatenation, which can be slow as a new object is allocated each time. Since you're just tracking substrings anyway, you could instead store the source string, start index and length of each match. That would save you potentially quite a bit of memory, and run faster as well. If you're really attached to having separate string objects, at the very least figure out the extent of the match and then do a single to extract it, rather than building up the substring one character at a time. 

Since your data is already sorted you definitely don't need to use a dictionary. You can just accumulate and then whenever the or rolls over you write them all out. That wouldn't be a huge change from what you've got. But honestly, what you've got is a bit confusing because you're trying to do several things at once. Namely: 

That last function isn't really a thing of beauty either - it's got kind of a lot going on. But it's definitely better. I also added a statement around your , which is just a handy way of making sure that it gets d properly. By the way, I put up a DotNetFiddle of the whole thing. It doesn't work because I don't have a database to use, but it might be easier to read there. 

I think it looks like good, clear, general purpose code. I don't see any really significant changes to make, but there might be some minor improvements available. First, allocating default size collections and letting them grow naturally may not work well for large collections. IIRC they start at 10 elements, and then double each time they top out. But each doubling requires a reallocation and a copy, which can add up when you're adding thousands of items. You should initialize them with the proper size if you know what it is. If you can take a decent guess, even that will help: starting at (for example) 200 elements instead of 10 will save you a lot of allocations. But avoid calling on your input objects since that could cause them to be enumerated an extra time, depending on the underlying implementation. Second, if you commonly have no insertions in and no deletions in , you could add some code to skip the final enumeration of . As you're enumerating , keep a count of how many items were found in . If the number you end up with is equal to then you know there are no insertions, because you already matched all the items in that collection. As always with performance tweaking, profile it before and after any changes.