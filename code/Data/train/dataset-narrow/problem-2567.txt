A good reference for this kind of lists is GitHub's gitignore templates. The Unity-specific list is here. And if you feel that something is missing, make a pull request! 

That says everything. Store your objects location by-pixel or using floats in your level file. Now if you need a grid layout for something else (for instance pathfinding), you'll have to use some kind of approximation. E.g. consider a square occupied if there's at least one object inside. Or if some kind of object is inside. You could also forget completely the idea of using a discrete grid, and go for another technique, e.g. waypoints or a navmesh for pathfinding. 

Additionally, to perfect the illusion, you have some animated sprites for the dolphin splashes, and a trail that seems to be a textured quad strip. 

Gamasutra is always a good online resource for in-depth articles on this kind of topic. One article that seems to particularly match your request is the following: 

If you're really serious about all this, yes, this is probably a good idea to seek for proper legal advice. IANAL, as they say. 

To avoid this problem I would maintain a simple of all the active buffs, update them and recompute the stats each frame. This is what a single buff/debuff could look like, with an array of size : 

No. People are working low-level on game engines all the time. Otherwise you'd never get new versions of Unity or the Unreal Engine with all those fancy features. 

There's already a good answer about integers, but I feel like floating-points shouldn't be eliminated. In his answer, Byte56 took the option to go for the maximum orbit of Pluto, probably taken from this excel sheet, so I'll stick to that. That places the solar system boundaries at: 7,376,000,000 km = 7.376x10^9 km = 7.376x10^14 cm ≈ 7.4x10^14 cm The Double-Precision floating-point format offers a maximum precision of 15 significant decimals. So you're lucky: if your origin is at the Sun's center and you use a position around Pluto, you can represent all centimeters, e.g. in C++: 

This isn't a research engine thingy, and it might not be very practical, but you could probably roll out a Starcraft mod. It's the classic RTS so it could be a very good starting point for your experiments. 

As Nathan Reed and teodron exposed, the recipe for rotating a vector v by a unit-length quaternion q is: 1) Create a pure quaternion p out of v. This simply means adding a fourth coordinate of 0: 

To subdivide your quad in sub-quads, you create sub-quads inside it. There are several ways of doing this, so there is not such thing as the subdivide function. Things get messy if you want to handle the most general case, i.e. a quad that is not necessarily a perfect square. Your illustration does not really tell us what you want. There is a whole lot of different kinds of quads (and this is only for "proper" quads, lying on a plane). So I'm giving you one solution for gentle quads that are not too weird (so, convex quads), but don't expect it to work in every case. You can create line segments that start and end at regular intervals on each of your original quad's edges, and use these as edges for your new quads. E.g. with : 

Yes it's possible, no you don't need any natural talent. Knowledge comes mostly from practice, in 3D just as in 2D. 

The key point was that level editing was done straight in the game engine: any change in layout or look could be tested in-game straight away. 

I'm developing a free-to-play game on Android and iOS and Facebook. I see that Unicoins can be purchased in many ways, a lot more that I'll ever be able to implement myself (Paypal, Bitcoins, Gold, Reddit karma! I mean: wow!). Is there a way I can accept them as micro-payments and then turn them back into real money? 

I don't see any obvious issue in the code you've provided. One thing that could go wrong is the order of the indices for some faces, which would lead to normals pointing backward on them (as Joseph Mansfield hinted in comments). Check your index buffer: are you building up all faces in the same order, either clockwise or anti-clockwise? If not then what you see is perfectly normal. The order of the vertices matter, it defines in which direction the face is oriented. 

I'll mostly compile what others said in comments. It's definitely possible to make a 2D game using 3D rendering, it's actually what most games do nowadays. So, to answer your questions: Do you think I have to use JavaMonkeyEngine? You can use jMonkeyEngine, but you could use any 3D engine for that matter Do I have to handle a "z-fixed" camera or set-up OpenGL to render in 2D mode? I'd say you've got 3 options: 

In bold: the IDs mentioned in CardCaps.pdf (provided with the DirectX SDK), that add up with what Direct3D returns on actual hardware. 

It's hard to tell exactly what's being asked here but I'll try to give the best answer I can. There are a few misconceptions going around in comments and answers so I'll try to clarify all this, to the best of my knowledge. 

That would be better for latency, but yes, you lose the handiness of JSON. A middle ground solution: 

I wouldn't call this a problem. The 'fix' already exists, lots of game allow you to change the FOV on-the-fly, for instance try typing this in HL2's console: 

It's a fair approach, I've seen not-so-simple games using it. However, as your target is high quality, I advise you to support all aspect ratios properly. You don't want your players annoyed because you're using only a percentage of their pixels. So you've got two options: 

You could use OpenGL to use compressed/palletized textures (see this thread for tips) -as others pointed out in comments. 

Indeed, the default (horizontal) field of view of first-person shooters (e.g. 75° in HL2) is notably smaller than the 'natural' FOV (around 95°). It might be close to a single eye FOV, but to me this is more or less a coincidence. 

If you've not gone too far on the rendering side yet, one simple solution would be to use an actual 3D renderer. This way you don't have to reinvent the wheel and implement the parallax yourself, you can simply throw a classic perspective projection, a camera, and you're good to go. The last time I checked, three.js seemed to be a quite compelling option but I'm sure there are plenty of other libs that might suit your needs. Going this way will also probably require a WebGL-enabled browser for proper performance, which might or might not be an option depending on what your final goal is (do you want the largest audience possible or are you just experimenting?). 

If you're talking about a whole build process, including binarizing data, creating installation script, etc., then no that's usually not something that's done from an IDE. It's usually managed by some continuous integration software, or just a bunch of custom scripts, run automatically overnight for big projects. I won't go into folder structure, as there is no standard for that, just follow your instinct on what you feel is best. Just make sure you have a clear distinction between source code/assets and generated stuff, this helps keeping version control clean. What a build process does usually is as follows: 

You don't have to wrap everything though, just wrap what you need when you need it, iteratively. You won't need everything in the library interface, so that's the best way to limit the code size. I'd say that creating this kind of "glue code" is roughly the same amount of work than rewriting the libs, but it brings much more benefits: 

You need to check one by one the parameters you provide to this function, especially in this case you need to check that the present parameters you provide are correct (see the C++ doc for those, it's providing lots of details). In your case, as it's failing on one specific machine, you're probably asking for stuff that isn't supported by its hardware, e.g. a D3D feature level too high for the graphics chip. It sometimes help to check the samples provided by Microsoft to check what parameters they're passing, and see the differences that could cause the issue. 

Here you can see that as long the duration of stays reasonably small compared to the message rate (it's already very exaggerated here), the game will still have plenty of time to update its frames. So this explains why such a game loop structure doesn't prevent a game to run normally. But the solution CoderScott proposed in his answer makes this execution flow much more explicit, so in my opinion it should be preferred. 

Everything in your game should use delta times from one of the clock: graphics effects run on the GFX clock, AI & animation runs on the Gameplay clock, creatures affected by a slowdown spell run on a temporary Slowdown spell clock, etc. Then various things affect different parts of your hierarchy: a slowdown spell creates and affects a custom clock, while a bullet time will affect the whole 3D clock hierarchy. 

Most of the time, no. Endianess is usually abstracted away in the high level modules of a game engine, and you don't have to worry about it on a daily basis. If it isn't abstracted, then the engine has a serious issue and should be fixed, because this isn't the kind of details you should be worrying about when making a game. However if you're working on some low-level parts of a C/C++ multi-platform engine, you might have to deal with it. All three current-gen consoles use a PowerPC architecture, which is big-endian, whereas the x86 architecture used on PC is little-endian. So if you're working on some code that reads raw bytes from somewhere to put them in data structures (binary serialization, networking...), yes you will have to deal with it. For instance, in C/C++, it's common to see this kind of byte swapping in action (not tested, welcoming corrections): 

This is discussed regularly in the Game Programming Gems. That's probably one of the best resource you can find, here's a quick selection of articles: 

Color LUTs are also used for HDR tone mapping in (relatively) modern graphics engines. If your engine supports that, then it might be quite easy to plug those LUTs directly in your post-process chain. 

It'll do what you think it does. If you check the class source code, you'll see that they're doing exactly what you suggest, plus they're normalizing the result: 

This is known as 3D picking, and usually involves some kind of raycast from a point in screen space (the cursor position) in the camera's forward vector direction. For some Ogre tutorials, check those links: 

Sounds like you could try out Minimax to "mix" your decisions. There was a talk at last year's Game AI Conf by the programmers behind Green Corp, and that's what they used to build their AI. It took them a lot of time to get it right, but they have a decent result. 

EDIT I'm not sure that will be necessary (this is simply an artistic choice) but if you want the fog amount to change directly with the player's moves, you'll have to generate this fog matrix using directly distances from the player. E.g. if you want a simple fog circle, that's what you could do for one tile at (i,j) in your fog matrix: 

The rational is simple: the goal of a component-based architecture is to allow for modularity. If you reference everything explicitely you'll soon introduce direct dependencies between your components: removing them, adding new ones of replacing some will become a much more cumbersome task. 

This will seem to distort the perspective on a regular screen. To keep a natural-looking perspective with a high FOV, you simply have to use a display that covers your entire vision (stereoscopic or not). There are plenty of solutions: 

Some hints, code snippets, tutorials, links? It all depends on which option you choose, I'm sure you'll find resources by yourself. Still, have a look at Wikipedia for an explanation of orthographic projections, and here for their configuration in jMonkeyEngine. What about the HUD? It's just the same as in a 3D game, rendered in screen-space after all the rest with your favorite lib. 

I'd say 2: as you state, solution 1 would generate too much traffic. There's a chance it works in the beginnings, but then when you'll add other things to send you might have to reduce the input updates frequency and thus you game reactivity. As a rule of thumb, sending deltas instead of complete states is most of the time The Right Thing to do. You're right in telling that: 

Here you're basically giving away licenses for free. This can be to gain some attention for a "pro version" with extended features that is released under a commercial license (i.e. costs money). It can also be that the license is granted against a royalty share on commercialized games. Examples: Unity, UDK, GameMaker. Other options Now if you want to try out some alternatives to the software-as-a-product strategy, you have plenty of options. Those might fit more with open source software, but once again, not necessarily. Freemium, Donationware, Pay what you want Those are all variants of the traditional fixed price model. Licenses will be free or almost free, and you'll be try to get a variable amount of money from generous donators, or from micro-transactions (e.g. plugins app store?) This isn't something commonly used in games middleware, but maybe that's a model to try. Example: Humble Indie Bundle. Crowd funding 

Reverse engineering a particular system's hardware architecture and emulating it is apparently legal in most (if not all) jurisdictions. Otherwise you wouldn't find emulators for game consoles so easily. See the link provided by Derfder in comment for details on how this is considered by the US courts. This is for the hardware side of things. But as you said yourself, the software running on those systems is most of the time proprietary. It's thus perfectly illegal to distribute ROMs for emulators without the owner's consent. If the owner doesn't care, then it's abandonware and you're in a grey area. Probably most of the ZX Spectrum games can be considered abandonware today, but I wouldn't be too confident either. That's why most emulators creators never ever distribute ROMs.