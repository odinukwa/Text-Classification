So if I have both 'better' and 'good' within the range of INFO START and INFO END I will display the 'better' instead of 'good'. And 'best' for being the highest if 'best' is there. MY_TABLE 

Heres its output (i used dbms_output for testing so far but i will insert it to a table later on if i can get the right rate) 

I want to format my string in my select statement but I cant seem to find the syntax for this pattern. I have a column of card_num with 16 digits and i want to have a dash(-) after the first four digits. Original card_num: 1234567891234567 Desired output: 1234-567891234567 I think regex can do this but cant find elsewhere the right code for this pattern. Any idea how to do this? Thanks. 

idk how to ask the right question about this, but here, given I have this my_table. I need to display just one rate between every INFO START and INFO END and NULL if I dont have any. 

so far i can get the range of INFO START and INFO END where i should find the names and rates. my code; 

I want to connect table 2's number 1 entry(AC_ACCOUNT) to table 1's number 2 entry(AC_MGR) as what you can see in my desired output. I used rownum as a technique just to have a connection between my two tables. I think I misunderstood left outer join here, please kindly enlighten me how to achieve my desired output. 

I've already search the net about this but it can't solve my problem. I have two tables one with 10 rows and other with 9 rows table 1 

so any idea how to display the rates? i think i can use rank() here for my rates but im not that familiar how to use it with this case. do you have any suggestion or tips how to do it? rank() or any style that can solve this. thanks! hope you understand my english. Here's my fiddle: Using db-fiddle.com 

I'm researching and investigating about all possible ways to create a master data database for my portfolio of applications. To give you a quick overview, an example will come in handy: I want to create a Users database that several different applications will use. Instead of creating user tables in each application I need to centralize in one point all these users data and their permissions, for each application. All this applications have MS SQL server as rdbms, so the Replication engine with a single publisher and several subscribers is an option. However, I would like to know if there are other alternatives, and what's more important, if any of these alternatives could be platform independent (for example, a master DB designed in MySQL with two slaves which could be Oracle and MS SQLServer). Thanks for your help!! 

Although the elapsed time is not that much, this query is executed around a thousand times every ten minutes, so having more than 30k logical reads doesn't seem quite optimal to me. However, the main index in this table is designed in a way that a query like that can take full advantage from it. The table MainTable contains this: 

It's obvious that the improve comes because data is pre-calculated and pre-stored, hence reducing the amount of data, just before joining. Does anybody have a better idea? Thanks!! EDIT: Actual query plans added (first and second query respectively). You'll see they are almost identical, and I've checked the CPU costs in them and didn't see anything weird... 

Additionally, fields and are foreign key referencing two other tables. Referenced columns are IDs in their respective tables. What do you think? Is there room for some optimization? 

Sorry for the late response, I've been quite busy. I tried reordering the columns in the index by adding a new non-clustered index with the following fields and order: 

I have been reading up on innodb as a storage engine, mainly because I have recently moved to AWS and they do not recommend myISAM which my databases current run on (and have for about 10 years) So moving to a new engine is a little bit of a scary operation. I am apprehensive about the move, as it has been on myISAM for so long without issue, but if it gives me peace of mind long term, then it is better for the DB. I have read the whitepapers on InnoDB and it seems fairly straight forward, The one thing that I want to clear in my mind is the innodb_flush_log_at_trx_commit option By default this is set to 1, however from my reading this causes additional overheads, if the data was credit card transactions or something like that, I can understand its needs to be there, but it seems when dealing with non life changing data, that innodb_flush_log_at_trx_commit=2 is a better option. What I want to know is, this does not affect the time that the query is actually committed does it? It only affects its recovery ? I just want to make sure that when I do an insert or update that the query will run right at the time of processing and not 1 second later, no matter what the flush_log is set to. My understanding is that in the case of a crash , setting to 1 will allow it to recover all queries run on the server, where as setting it to 2 may lose the last second or two of data when trying to recover from the crash, is this correct? Also, if there is slow periods of updates/inserts (ie, not much happening on the server) does setting it to 2 add additional overheads on the server, or is it a case of the benefits of applying innodb_flush_log_at_trx_commit=2 to the database when the database is busy outweighs any additional overhead caused during slow times?