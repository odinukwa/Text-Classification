If you call whitin the same area code you don't need to dial it, so you can dial NXX-xxxx (7 digits) If you call to another area code you need to dial it, so you have to dial NPA-NXX-xxxx (10 digits). If you need to call to a foreign country you have to use the international prefix: 011 (for example: 011 + country code + number). In addition there are special numbering of 3 and 4 digits as: 

The first 7 bytes are the same: . The last byte called the Start of Frame byte is slightly different: . The preamble is not officially counted as part of the Ethernet frame. The frame begins immediately after the Start of Frame, without a gap. As the preamble is a fixed and known pattern, it is used by the receiver to "lock-in" the clock and from then it can easily understand the incoming frame. 

If station A needs to transmit, it tries to detect the presence of a carrier signal from another node before attempting it. If there is no carrier then it starts to transmit and this transmission starts to propagate. It means that while the first bit reach the farthest point of the media, station A is still transmitting. Let's suppose that station B needs to transmit, it detects a carrier in the media and then waits for the transmission in progress to end before initiating its own transmission. The propagation delay is not the same for each media (air, coaxial cable, UTP, fiber optic, etc.). That's why there is a distance limit for each media. To be sure that whenever a station needs to use the media every other station is aware of the state of it. Exceeding the recommended distance limit will cause late collisions: A type of collision that happens further than is allowed. It will decrease the throughput of the communication link because the data error will go up to the upper layers. 

ASIC can be thought of as a kind of chip. It is normally built in order to do something in hardware that otherwise would be done is software. So Cisco can build an ASIC for anything it wants. Depending on the model of the switch there is 1 or many ASICs. TCAM is a memory design since it is usually found on the chassis systems it is implemented as 1 of many asics. TCAM is used for particular lookup functions like routing (CEF) or ACLS, so if an ASIC does not need to do that kind of lookup it works separately from TCAM. On the other hand ASICs that handle QoS marking work hand in glove with TCAM. The presentation below on cisco live discusses some of the design tradeoffs, and a good place to look to get an understanding of what goes into switch design BRKARC-3466 - Exploring the engineering behind the making of a switch (2013 Orlando) it contains lists of the asics and a lot of general switch design information 

I cannot speak for anyone else but I do a TOR 8 to 16 port 'terminal server' that is connected to a management Ethernet, we do not try to use the structured cable to bring them to a central set of terminal servers. We then test as part of the turn up. We also home run the cables, as it is less likely that someone will disconnect one in error and you don't know that the cabling is wrong till you really need it. Unless you have on site people you really trust, I would not try to save $$s on this. 

IPv4 and IPv6 operate as 'ships in the night' as far as routing is concerned, so I see not benefit to separate VRFs with ipv4 in one and ipv6 in another. Also any dual stack hosts would need separate interfaces or separate tagged VLANs to operate dual stack. Now if you are concerned about RAM in the router VRF will not help that, for that concern route summarization or default routing would help there, and that applies to both IPv6 and ipv4 

For example, in 1988 IBM asked for a range of IP addresses and the assigned range was . It is a Class A range, so it went from to (a range of 16777214 hosts). (source: wikipedia) It's very likely that IBM never uses 16 millions of public addresses, so it becomes a waste of public addressses that can be used by other companies. Then, in 1993 the Internet Engineering Task Force published RFC 1518 and RFC 1519. These RFCs defined a new concept called Classless Inter Domain Routing. The most important thing of those RFCs is that obsoletes the Classful Network where ranges where associated with classes with fixed netmasks. So, from 1993 a range as becomes and it can be segmented in multiple networks. For example in 2 networks of more than 8 million hosts each one: 

Suppose you put in the end of a 1 Kilometer cable. If you measure the voltage in the other end you get, for example . There was an attenuation of the original voltage. If the cable was longer, for example, 5 kilometers then the voltage on the far side could be very low. For data signal this is key because if the original signal is strongly atternuated it could be gibberish for the equipment. 

RIP is an Interior Gateway Protocol, it means that it was designed to operate within a single autonomous system (AS). RIP version 2 was developed as a fix of deficiencies on RIPv1 mainly in the ability of supporting CIDR. To maintain backward compatibility, the original hop count limit of 15 remained, it means that if a router receives a RIP message indicating a subnet 16 hops farther, that information will be dismissed and the consequence will be that the routing table in that router won't show every destination available. 

The administrator of a private PBX has a group of internal extensions with their own numeration. For example [300-399 accounting], [400-499 sales], [800-899 management], etc. To determine easily if an user is dialing to another extension or to an outside number a group of rules can be set in this way: 

The idea if not use ECMP if HSRP is in use may be ok for SERVERS where ingress traffic may be higher than egress traffic, in a PC situation IN GENERAL ingress traffic from the WAN (responses) is higher than egress traffic (ingress). We like most people just set the ARP timers. you can mess with CAM timers BUT if you have say an MDF with the layer 3 switch and an IDF with 2 collection switches and say 5 access switches, it is a LOT easer to configure on the L3 SVI than doing all access switches. 

Local(255.255.255.255) means that a router will not forward the packet (in some cases like DHCP the router will convert it to a unicast packet and forward it). Directed broadcast addresses have just the host part of the address as all 1s and routers will forward so if I have a subnet 10.10.10.0/24 I can ping from elsewhere in the network 10.10.10.255 and I would get an answer from all hosts. However there are a number of attack that exploit and you can configure your routers to not forward directed broadcasts. 

The logic seems to be if there is not contention I will get the data at line rate (32ms) 150 users woudl consume 150*40000*8 = 49,152,000 which is 50 % of 10 meg. If the link is contended and hence policed to 50 meg it will take twice as long as only 50% of the BW is usable 

The google search indicates the UTM appears to be a firewall. While you could get say a cheap router/firewall put it on a shelf and if the UTM dies physially replace it, that seems a bad idea as that boxes are not functionally equivlant. This is a form of redundancy though a static kind, as mentioned in the comment. Net of this is that if you need the firewall function you need a duplicate physical box. MAYBE you can 'limp along' with a less expensive spare box while you wait for your replacement firewall but that is a business call. Lastly most people here will tell you that your ISP connection will fail far more often than your hardware and that is what you need to make redundant first. 

A little trick: In this case, the 4 bits for host part, means that you will have 16 address on each subnet. Then divide , if the division is exact without decimals then is a network address and can't be used. 

Before 1993 the internet used classful networks, it meant that the full IPv4 scope was divide like this: 

Circuit switching networks as X.25 or Frame Relay use a mechanism that opens a virtual channel from transmitter to receiver before the data transmission begins. For example: If using Frame Relay you want to communicate from London to Paris, your communication device has to send a signal to its next Frame Relay switch indicating that you want to open a channel to Paris, and that switch sends the same signal to the following switch and so on until the signal gets to Paris switch. Now that the channel is stablished the communication begins. Each frame from London to Paris goes through the designated channel and when the communication ends the switches close the channel. Packet switching networks as TCP/IP don't open a predefined channel before sending the first frame of communication. In the same example using London and Paris, your device sends the first frame and the next switch will have to decide what is the best next hop for that frame and every network device will do the same until the frame gets to Paris. For each frame the switch decides the best next hop so sometimes the frames will go through one path and sometimes through another depending of traffic, congestion, availability, etc. Packet Switching networks are more flexible than Circuit switching networks because there is not a designated path from start to end. 

It will keep doing that until TTL=32 and port=33465 When each one of those UDP datagrams goes through a router the TTL value is decremented and if it reaches zero, then the router returns an ICMP Time Exceeded Message, also known as ICMP Type 11. My PC receives a lot of ICMP Time Exceeded Messages. Checking the source IP adddresses of the ICMP message, my PC learns the IP's of the devices that are between itself and . But it doesn't know the order. To know it, checks inside the ICMP message because it contains the header of the original UDP datagram. The gives the position of that device in the route to . Keep in mind that Windows imnplementation of uses ICMP instead of UDP, that is used by Unix, Linux, BSD, etc. 

You also need to set up a PIM RP since you only have 1 routing device you do not need to support auto-rp or bsr ip pim rp-address rp-address [access-list] the access-list has the multicast IP range so access-list 10 239.192.0.0 0.0.255.255 would make the 4900m the RP for the private multicast address range 

The only dynamic adjustment of MTU size is to avoid IP fragmentation. That is changing the TCP segment size, to match the smallest IP packet size. IP packets can be divided up by say multilink PPP but that only lasts for the single MLPPP hop. Bottom line no protocol ever changed sizes to reduce retransmissions it was said in the old days that you might want to manually adjust data sizes down when using bad links but we are talking at least 15 years ago. 

FETs are not required to connect 2Ks, they are far cheaper than SFPs and for some odd reason (to me) you can only order them when you order 2ks. As Ricky said you are going to see a non standard Ethernet encapsulation but that is a matter of does wireshark support it. Cisco will be happy to take the extra $$s for SFP+ 

Assuming that all link speeds are the same, things become hop count. If you explicitly set a root bridge the switch 'across' from it in the ring will have the blocked port, it will be the port with the higher MAC address. There is no real difference in blocked port selection between rapid and 'classic' STP 

If your problem is that you have two sites/business parters etc that have separate Internet ASes you can connect them together NOT through the Internet but over a VPN or private link. You have a couple of things to watch for if the address spaces are also advertised via the internet relate to administrative distance and prefix matching. BGP is preferred for many reasons, and you have to use it to talk over the internet. A little more on your use case assuming it is not entirely theoretical would help. At the end of the day there is no law that prevents you from using an IGP. But remember that any network vendor is in the business of selling you rope, what you do with the rope... 

IP is a layer 3 protocol. It doesn't know anything about the physical media, it means that IP can travel through any media (for example: fiber optic, copper cable, air, etc). IP relies on a layer below (layer 2) that manages the access to the media. In the case of ethernet each device is connected to a common media (copper cable) and then the device has to identify itself to let know the others it is there, and that identification is the MAC address. Each device has a MAC address that is used by the layer 2 protocol to access the common copper cable and move frames from one device to the other. It seems to be enough to have communication, however layer 2 protocols doesn't scale well if you have hundreds of devices. Then it is needed a layer 3 protocol as IP. 

So, each time the PC needs to communicate to the server, it will send the IP packet to the default gateway MAC address. If the switch is a layer 2 switch it will check the destination MAC address and redirect the packet to the port where that MAC resides. If the switch is a layer 3 switch it can check the MAC but also the destination IP address and take the decision to route the packet directly to the server. 

Let's make each chunk of 25000 bits long, giving us a total of 800 chunks. Let's suppose the media has a propagation delay of 10 milliseconds. Start-Stop protocol: Protocols using a start-stop technique send each chunk and stops until an acknowledge returns, in that case and supossing zero errors, to send each chunk of 2500 bits takes 20 milliseconds and give us a bandwith use of 125 Kbps. In that fashion it will take 16 seconds to transmit the file. Sliding Window protocol: A sliding window technique allows to send chunks one after another and receive acknowledgments in an asynchronous way. Ssupposing a window of 10 then the sender put 10 chunks on the media. It takes 100 milliseconds and before sending the next one, the acknowledge for the first chunk must have arrived. If everything is right and there are zero errors, it will be 110 milliseconds for 25000 bits giving us a use of 227 Kbps ( more efficient that the first case). It will take 8,8 seconds to send the file. A bigger chunk (5000 bits) can give us 455 Kbps and a transfer time of 4,4 seconds. All this supossing zero errors. The bandwith is a limit but the data transfer is a result of the protocol used, the propagation delay and the errors in the media.