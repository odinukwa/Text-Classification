The running time is asymptotically the same for the usual algorithms,since $G'$ has at most $|E|+|V|$ edges and $|V|$ nodes and $|E|$ is almost always the dominating term of the runtime. This can be ignored however to always have the same running time (see below). Correctness lies on the correctness of the original algorithm, as well as the fact that by subdividing we minimize according to the quantity $ |P_{2}| + |P_{1} \cap P_{2}| $, as desired. Finally, note that most algorithms may work with weights from $\mathbb{N}$ with no additional cost, so instead of subdividing one may simply double the weight of the edges along the shortest path. This method is more general and shows that the algorithm works equally well on weighted variants of the problem. Note that it is not necessary for the shortest path to be part of the optimal solution. See the comments for a discussion on this and thus why my proposed algorithm does not guarantee optimality. 

Since the problem with solving the halting problem is knowing when the machine is going to stop, by running the machine in a spacetime that is different from ours can allow you to solve it. From my sources when I was writing a report on models that can efficiently solved $NP$ , theoretical physicists believe that those conditions are satisfied near the edge of black holes. To do this you must have the computing machine very near the black hole but not into its event horizon (so it doesn't get pulled in). Then you dive in the black hole and you can review the whole infinite timeline of your machine in finite time. This probably means that you get pulled in the black hole, so I guess it's not going to be implemented and tested even if we could reach a black hole. This is all informal, you start reading a more theoretical physics approach from the wikipedia article on the Malament-Hogarth_spacetime. A helpful citation is also the article Does general relativity allow an observer to view an eternity in a finite time? 

"you can't compute it with 1 processor, but can compute with 2." This is not possible, assuming that both processors are TMs or a less powerful model. From wikipedia , for multi-tape machines : 

After thinking about the first part of my question, I realised that any gain we have by increasing the head size is nullified by the time needed to perform every step. So if we use a head of logarithmic size, we will need logarithmic time steps. This argument can be made clear if one tries to simulate the two TMs with a universal TM. The "speed-up lemma" that I mentioned before can bypass this difficulty, since it achieves only constant improvement, therefore it can be simulated by a universal TM with each step being executed in O(1) time. Equivalently, one can use a larger alphabet (which still is constant as required by the model). Using an alphabet whose size depends on the input size would result in non-uniformity. 

Extending on Hsien-Chih Chang's comment, every NEXP-hard probleme cannot be in NP, thus by definition cannot be verified in polynomial time. One could use the nondeterministic time hierarchy theorem to see that NP is strictly contained in NEXP. Therefore, we can be certain that given any NEXP-hard problem,it is not in NP or we would be led in a contradiction. 

There are two approaches when considering this question: historical that pertains to how concepts were discovered and technical which explains why certain concepts were adopted and others abandoned or even forgotten. Historically, the Turing Machine is perhaps the most intuitive model of several developed trying to answer the Entscheidungsproblem. This is intimately related to the great effort in the first decades of the 20th century to completely axiomatize mathematics. The hope was that once you have proven a small set of axioms to be correct (which would require substantial effort), you could then use a systematic method to derive a proof for the logical statement you were interested in. Even if someone considered finite automata in this context, they would be quickly dismissed since they fail to compute even simple functions. Technically, the statement that all computers are finite automata is false. A finite automaton has constant memory that cannot be altered depending on the size of the input. There is no limitation, either in mathematics or in reality, that prevented from providing additional tape, hard disks, RAM or other forms of memory, once the memory in the machine was being used. I believe this was often employed in the early days of computing, when even simple calculations could fill the memory, whereas now for most problems and with the modern infrastructure that allows for far more efficient memory management, this is most of the time not an issue. 

All deterministic classes are (almost trivially) closed under complement: Given a deterministic TM $M$ for a language $L$, one obtains a deterministic TM for its complement by simply running $M$ and then "flipping" the answer. The machine runs in the same time and space asymptotically. By applying the same proof to the complement class, it follows that $L=co-L$. The same obviously holds for all classes where the result can be safely "flipped", e.g. $ZPP$. Nondeterministic classes obviously fail this requirement. 

Let $P_{1}$, $P_{2}$ be two paths in a undirected unweighted graph $G=(V,E)$. We want to minimize the following quantity: $ C = min_{P_{1},P_{2} \; paths \; in \; G} \{ |P_{1}| + |P_{2}| + |P_{1} \cap P_{2}| \}$. Also suppose $L$ is the length of the shortest path in $G$, i.e. $L = min_{P \; path \; in \; G} \{ |P| \}$ Clearly, $2L \leq C \leq 3L$, since even if there is no overlap, the second shortest path cannot have length less than $L$ and in the worst case, we can pick two times the same path, which maximizes overlap. This simple algorithm should solve your problem: 

Consider the language $A=\{0^{k}1^{k}|k\geq0\}$ . On Sipser's book "Introduction to the Theory of Computation" an algorithm with running time $O(n\log n)$ is given, on single-tape TM. We also know that the set of languages that run in time $o(n\log n)$ is exactly the set of regular languages. Since $A$ is not a regular language, we can be sure that this is a strict lower bound, on a single-tape TM. Therefore, if $f(x) = n\log n$ and $g(x) = o(f(x))$ , the existence of this language allows us to say that $DTIME(g(x)) \subset DTIME(f(x))$ . Therefore: By using the padding argument, couldn't we argue that for any time function $h(x) = \Omega(n\log n) $ the same result applies, i.e. that if $g(x) = o(h(x))$ then $DTIME(g(x)) \subset DTIME(h(x))$ 

The above lower bounds should hold for the bit complexity of the problem. Once again, if you restrict your attention to $\mathbb{NP}$-complete problems, I am not aware of such lower bounds. 

I found the following helpful for understanding papers, especially when they are highly specialized or from a different subfield: Read the introduction very carefully. That is where the main idea is explained, while the rest of the paper proves it. One word can change the meaning of a whole sentence, especially when special vocabulary is used or if, unfortunately, a word has a completely different meaning in another subfield. Therefore it is a good idea to stop whenever you feel that you do not fully understand a sentence and look up the words , as you would do if you were learning a new (human) language. Making notes next to words or even better making a small "dictionary" helps a lot. Also, it's better to spend some time on the preliminaries, building on the foundations used, especially if you want to work on this paper rather than just understand the result. Make sure you have every necessary tool before reading the proof. As for the proof, I do not have much advice other than reading it very carefully and make sure you understand every step in the way. It is also a good idea to make a small list of the things that have been proven before the main proof, so that you can see what result is used where, and to have a quick index to look it up if you don't remember it exactly. The same goes for additional lemmas... if you feel you cannot follow the explanation of a lemma , it's best to read the main proof again. 

The classic result I know of is due to Paul, Pippenger, Szemeredi and Trotter (1983) and separates deterministic from non-deterministic linear time. Then, there is the more recent result by Fortnow,Lipton, van Melkebeek and Viglas (2004) that was already mentioned. The uniqueness of this result is that it is a time-space tradeoff result, bounding space as well as time. However, I am also aware of a result due to Santhanam (2001) that proves a lower bound of $\omega (n \sqrt{ \log ^{*} n} ) $. This result is slightly stronger for time contraints than the above, but does not provide any guarantees for space. Given the above as well as my knowledge of the field, I would say that proving that there is a $\mathbb{NP}$-complete problem that cannot be solved in $O(n^{2})$ deterministic time would be quite a big step. As far as I know, such a result is considered highly nontrivial and likely to require new lower bound techniques. Note: My wording of the problem in the last paragraph is different than in your question. I could be nit-picky (and perhaps not of much help) and tell you that trivially there is an infinite number of problems in $\mathbb{P}$ and thus in $\mathbb{NP}$ that cannot be solved in $O(n^{2})$ deterministic time, by the deterministic time hierarchy theorem. 

Calculate the shortest path using your favourite algorithm. Subdivide all edges on the shortest path. Run your algorithm again on the new graph $G'$ and obtain a second path. Output the path from 1 and 3 as output, taking care to replace any subdivided edge in it with the original edge. 

In extension to what you mention to your question, one classic example is using the fact that integers cannot be sorted using comparisons faster than $O(n \log n)$ in order to prove the non-existence of superstructures. Furthermore, it is not unusual to use information theory arguments (e.g. Kolmogorov complexity) in order to prove lower bounds for data structures. 

If we choose to study the human brain itself rather than how humans use their brain to solve problems,I don't believe this is an issue of complexity, but rather of computability. Since every TM needs a transition function, a human can imitate the TM's steps, therefore, the human brain is Turing-complete. In the reverse direction, can TMs compute everything humans do? The short answer is we don't know. Assuming that the Church-Turing thesis is true, whether the answer will change or not depends on your view of the world (philosophical, spiritual , religious and other). In that case, we can safely say that the human brain itself as part of the material world, can be simulated by a Turing machine. The rest is up to debate and , at least in my opinion, not related to TCS. One could argue that if $P \neq NP$ all problems in $NP-P$ would dwarf a lifetime. But we are talking about the power of the brain itself. The transition table and the work tape could be passed on from generation to generation until the answer is solved.Even if we require that problems solvable by humans do not exceed the lifetime of a single person, does $10^{10^{100}}n$ , which is just linear , seem like doable? I think not. One can argue that there is a TM that does the same in just $n$ using the speed-up theorem, but that would require storing $2 \log 10^{10^{100}}$ times more information in every step of the sped up algorithm. Of course, a specific lower bound would be needed to ensure a faster algorithm (constants included) does not exist. So, if you would like to precisely calculate what problems the human brain, given the constraints of actual life, like distractions, attention span, etc. you should have an upper bound on the number of steps done in total, an upper bound on the number of steps done consecutively (even the most devoted researcher must sleep and eat), a limitation on the space (not just in the tape, but also in any "internal" registers), a simulation of how memory acts because unlike TMs , we can forget something we write in our "work tape" or the exact state, and of course, determine the relation between machine time steps and time in seconds or "human brain steps". Perhaps other issues would pop-up as you would go. In an ironic twist, perhaps one or more of this problem cannot be solved by the human brain, at least efficiently.