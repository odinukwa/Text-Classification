To improve the sampling to a usable level, one can sample the luminance of the EM over the whole sphere. It is relatively easily implemented and the results are quite good. However, the sampling strategy is still ignoring the hemispherical visibility information and the cosine factor (and also the BSDF), resulting in high noise on the surfaces which are not directly lit by high-intensity areas of the EM: 

Papers I have found a few papers on the topic, but have not read them yet. Is any of these worth reading and implementing in a forward uni-directional path tracer, or is there something even better? 

Yes, computation of global illumination is usually done in a stochastic way and as such it relies on randomly generated numbers. Typically pseudo random generators are employed, which generate deterministic sequences, and usually have so called "seed" parameter. The seed basically says where to start in the sequence, which in turn affects the noise pattern of your rendered image. If you can use the same seed for each run, there is a high chance of getting identical results. The question is whether the software that you use allows you to do that. In the rendering settings, I would suggest looking for for words like seed, random or deterministic. Edit: Since you said you use Vray, it seems to me that using "Deterministic Monte Carlo" engine should be the way to go. 

This is not a full answer, I would just like to share the knowledge I obtained by studying two of the papers mentioned in the question: Steerable Importance Sampling and Practical Product Importance Sampling for Direct Illumination. Steerable Importance Sampling In this paper they propose a method for sampling the product of the clamped cosine component and environment map lighting: $$ L_{EM}\left(\omega_{i}\right)\left(\omega_{i}\cdot n\right)^+ $$ They make use of the fact that a piece-wise linear approximation of the product function can be relatively well expressed and partially pre-computed using the first nine spherical harmonic bases. They build this approximation on top of an adaptively triangulated EM and use it as an importance function for sampling. They pre-compute and store approximation coefficients for each triangle vertex and also coefficients for computation of approximation integral over the triangle for each triangle. These coefficients are called vertex and triangle weights. Then they make use of the fact that is it possible to easily compute coefficients for an integral over a set of triangles just by summing the individual triangle weights without incorporating additional spherical harmonic bases. This allows them to build a balanced binary tree over the triangles where each node contains coefficients for computing approximation integral over the node's sub-tree triangles. The sampling procedure consists of selecting a triangle and sampling its area: 

If you have a deterministic mapping function which transforms uniformly distributed samples into the desired PDF (cosine shaped in your case), just feed it directly with stratified uniformly distributed samples. The mapping will keep the strata separated. Usually one sample per stratum is used and the number of strata is set according to the total amount of needed samples per one Monte Carlo estimation. More samples per stratum will somehow work too, you just need to make sure that each stratum gets the same amount of samples not to break uniformity of the (input) distribution. Keep in mind, however, that using more samples per stratum will degrade the per-sample performance of the Monte Carlo estimator due to sample clustering which usually happen for simple non-stratified random sampling. 

I will not answer your questions directly, but will try to change your mindset a bit. I hope got your intentions reasonably well... The usual way the path tracing is implemented is that the reflection integral is split into direct and indirect illumination and they are estimated separately. The direct illumination can be estimated using more sampling strategies which are combined together using the multi-sample multiple importance sampling method by Veach. Typically, there is just BSDF sampling and light sampling used, but you can also add things like light portals sampling and other more sophisticated stuff. I guess this is where you are headed. The indirect illumination is usually estimated by just one sampling strategy (typically BSDF sampling) because you want to avoid exponential growth of recursive paths count. That's the reason why path tracing has poor performance for indirect illumination reflected/refracted through glossy/specular materials. A nice thing about the split integral is that you can share samples between the direct and indirect integral. If you have two integrals over the same domain and have a sampling strategy that can be used for both, then you can generate a sample to estimate the first integral and then use the same sample for the second integral as well. There is no problem with correlated samples here because we have two separate computations. In practice you generate a BSDF sample with some PDF, shoot a ray in that direction and use the intersection point to estimate both direct and indirect integral separately. 

PS: I guess that for indirect illumination estimator you could possibly use the one-sample multiple importance sampling method by Veach to incorporate the light portals and other sampling strategies, but I have some doubts about the efficiency of the resulting estimator, especially when reusing the samples for the direct illumination integral. 

Frankly, your implementation doesn't make much sense. It basically iterates x coordinate through variable and increments variable at each step. Since the doesn't cross the 0 boundary, it generates the diagonal points you can see on your picture. You also compute and update the variable somehow, but don't use it anywhere. 

Assuming that you are familiar with the concept of BSDFs, the usual way of modelling rough dielectric surfaces (i.e. glass, water, plastics) is to use microfacet-based models like Microfacet Models for Refraction through Rough Surfaces. To make it work efficiently in a path tracer you will need a good sampling strategy, like Importance Sampling Microfacet-Based BSDFs using the Distribution of Visible Normals. Also keep in mind, that the mentioned BSDF model tends to get darker as you increase roughness because it neglects the light which gets inter-reflected among micro-facets. This can be compensated, but it's not a trivial thing to do. 

The procedure should generate relatively good samples at the cost of heavy pre-computation – they show that roughly 100–200 BRDF samples are needed for BRDF approximation to achieve the best sampling performance. This may make it suitable for purely direct illumination computations, where one generates many samples per shading point, but is most probably too expensive for global illumination algorithms (e.g. uni- or bi-directional path tracers), where you usually generate only a few samples per shading point. 

It's not that hard. If you have just planar or angular light sources, you can think of them as one light source split into multiple chunks and the only thing to deal with is how to sample this multi-light and how to compute the PDF of the resulting samples. Picking probability First, you need to setup the picking probability $P(l)$ for each light source $l$. The picking probabilities can be any non-negative numbers, you just have to make sure that are always non-zero if the contributions of the respective lights are non-zero. However, the closer the probabilities are to the actual (relative) light contribution, the better the overall performance of your Monte Carlo estimator will be. Contribution estimates may be: 

TL;DR Yes, you can do it like that, you just have to divide the result by the probability of choosing the direction. Full Answer The topic of sampling in path tracers allowing materials with both reflection and refraction is actually a little bit more complex. Let's start with some background first. If you allow BSDFs - not just BRDFs - in your path tracer, you have to integrate over the whole sphere instead of just the positive hemisphere. Monte Carlo samples can be generated by various strategies: for the direct illumination you can use BSDF and light sampling, for the indirect illumination the only meaningful strategy usually is the BSDF sampling. The sampling strategies themselves usually contain the decision about which hemisphere to sample (e.g. whether reflection or refraction is computed). In the simplest version, the light sampling usually doesn't take care much about reflection or refraction. It samples the light sources or the environment map (if present) with respect to the light properties. You can improve sampling of environment maps by picking just the hemisphere in which the material has non-zero contribution, but the rest of the material properties is usually ignored. Note that for and ideally smooth Fresnel material the light sampling doesn't work. For BSDF sampling, the situation is much more interesting. The case you described deals with an ideal Fresnel surface, where there are only two contributing directions (since Fresnel BSDF is in fact just a sum of two delta functions). You can easily split the integral into a sum of two parts - one reflection and one for refraction. Since, as you mentioned, we don’t want to go in both directions in a path tracer, we have to pick one. This means that we want to estimate the sum of numbers by picking just one of them. This can be done by discrete Monte Carlo estimation: pick one of the addends randomly and divide it by the probability of it being picked. In an ideal case you want to have the sampling probability proportional the the addends, but since we don't know their values (we wouldn't have to estimate the sum if we knew them), we just estimate them by neglecting some of the factors. In this case, we ignore the incoming light amount and use just the Fresnel reflectance/transmittance as our estimates. The BSDF sampling routine for the case of smooth Fresnel surface is, therefore, to pick one of the directions randomly with probability proportional to the the Fresnel reflectance and, at some point, divide the result for that direction by probability of picking the direction. The estimator will look like: $$ \frac {L_{i}\left(\omega_{i}\right)F\left(\theta_{i}\right)} {P\left(\omega_{i}\right)} = \frac {L_{i}\left(\omega_{i}\right)F\left(\theta_{i}\right)} {F\left(\theta_{i}\right)} = L_{i}\left(\omega_{i}\right) $$ Where $\omega_{i}=\left( \phi_{i}, \theta_{i} \right)$ is the chosen incident light direction, $L_{i}\left(\omega_{i}\right)$ is the amount of incident radiance, $F\left(\theta_{i}\right)$ is either the Fresnel reflectance for the reflection case or 1 - Fresnel reflectance for the refraction case, $P\left(\omega_{i}\right)$ is the discrete probability of picking the direction and is equal to $F\left(\theta_{i}\right)$. In case of more sophisticated BSDF models like those based on microfacet theory, the sampling is slightly more complex, but the idea of splitting the whole integral into a finite sum of sub-integrals and using discrete Monte Carlo afterwards can usually be applied too. 

Using independent settings for each colour channel is like using settings dependent on wavelength when doing spectral rendering. So the question could be re-formulated as: 

To me, this looks like a promising technique, but the classical question with papers is how it will behave in the real life. On the one hand, there may be pathological cases when the EM is hard to approximate with triangulated piece-wise linear function, which can lead to an enormous amount of triangles and/or to poor sample quality. On the other hand, it can instantly provide a relatively good approximation of the whole EM contribution, which can be useful when sampling multiple light sources. Practical Product Importance Sampling for Direct Illumination In this paper they propose a method for sampling the product of environment map lighting and cosine-weighted surface reflectance: $$ L_{EM}\left(\omega_{i}\right)f_{r}\left(\omega_{i},\omega_{o},n\right)\left(\omega_{i}\cdot n\right)^+ $$ The only pre-processing in this method is computation of a hierarchical representation of the EM (either mipmap or wavelet based). The rest is done on the fly during the sampling. The sampling procedure: