They both check that the post exists first and then creates or destroys the like record containing the post id and user id and redirects to the post with a message depending on the outcome. In the Like model I prevent duplicate likes with: However the methods feel quite bloated... is there a better way to handle this? 

I have the following snippet of code that redirects a user to a specific page on successful login to the application. 

It feels a little old now (not sure how old the code is) but wondered if certain things could be improved and if there was any parts that were considered 'bad code'. Some observations of my own: 

I have the following code in PHP that appends a file path with a timestamp of when it was last modified: 

I have the following code that allows easy creation, pulling, and deletion of Tickets in a CakePHP application. 

We don't really care whether the create was successful or not and either redirect the user to the post (the page where the method is called) or return some js if done via AJAX (usually). The js partial looks like: 

However if I pass back 1000+ records then the JavaScript struggles and it takes a few seconds to do it and causes the browser to lock up. Any ideas on how to improve this code? It seems to be the line where I append the rows to the page: 

I have the following two methods which handle the liking and unliking of posts in my Rails application: 

The idea is that if a query string named 'next' exists and has a valid hostname that matches the actual sever hostname then send the user to that location otherwise send them to the default location. It should also handle really bad formatted urls by the parse_url method returning false. Can anyone see any issues with the above code? Or offer improvements? Thanks EDIT The next parameter can be added manually for example on a login link, but is also created automatically on the redirect when a user tries to access a protected action. The reason for adding the is because the session also contains the app url, so if your app is on a subdirectory e.g. and you try and access you will get redirected to the login form with which will then send you off to: adding /myapp twice! Doing the full url instead STOPS this from ever happening and doing the parse url prevents a malicious user from creating a login link with their own url as the return. 

However I didn't like that it expects the AJAX request to request JS and then having a partial render inside a jQuery method that then makes an assumption about existing to render it inside. So effectively the response is also handling how it should be used. My alternative approach was: 

This way we just return the partial or redirect depending on if the request was via AJAX. The former seems to be the standard Rails approach (according to most docs) but I find the latter far cleaner as it means I can handle how the response is handled as it just returns HTML rather than having the actual handling of the response being returned with the response. Is there a better way to handle AJAX responses? Or reasons why my approach would be considered bad practice? Of course using the first approach means using Rails UJS and my own uses custom JS to make the request and handle the response. 

P.S. I would also welcome feedback on the general level of the code, style, legibility, etc., as it is my first R package and I don't have any previous experience with such. 

Fails to list all the tuples, since at least one of the tuples does not exist in . I'm not sure if there's a nice and general workaround for this, but I found that simply removing the last two lines of the above and substituting 

The gene annotation is gone, and each of the annotations now gets its own row with identical information (except the field). The script below works and does its job, yielding equivalent results to the previous Python script, but it is slower. A very small file containing only a hundred variants took around 30 seconds (1 second with Python), a normal-sized file up to 5 minutes (5-20 seconds with Python), and I gave up on a very large file after an hour (5 minutes with Python). So, how could I optimise my script? Am I doing it in a very slow manner? I didn't think that I could use , as I need to go from a single line into many, and thus went for a loop. But maybe I can? Or maybe there's something else? Any ideas are greatly appreciated! 

The wonderful code provided by Gordon (above) does wonders, but I just found out that it doesn't work when the lists compared contain cases where one of the lists have zero unique entries. In such cases, the code snippet 

I previously published an article on a new method for analysing RNA-seq data as part of my PhD studies, and I'm now working on making this into an R package. I don't come from a programming background, so this is quite challenging and, thankfully, both fun as well as rewarding. There was a part of my code that was written in Python, since that particular part would be slow in R, but now I have to convert that part into R as well, in order for it to go into the R package. I have successfully done this conversion, but it is, as I guessed, horribly slow. I'm hoping this is only because of the way I did it, and that there is room for optimisation; hence, my question here. In essence, the script takes a VCF file (containing data on mutations from one or more samples), performs some filtering on data quality criteria and extracts the relevant information to another file. This is done to save time, as the resulting file is going to be analysed up to several hundreds of times (depending on the study) by other downstream scripts. This is an example record in the VCF file (long; scrolling needed): 

There is thus several levels of per mutation, because a single mutation might effect several genes and transcripts. The goal is to separate all fields by , keep those mutations with the highest predicted effect on protein function (going in descending order from , , and ) and output them together with the data for the specific mutation. I need to go from this ... 

... does the trick. Just in case anybody happens to stumble upon this thread, the solution should now be more complete! 

The main issue is the (mutation annotation) field in the 8th (extremely large) column. I can relatively easy get the following format, using the package: