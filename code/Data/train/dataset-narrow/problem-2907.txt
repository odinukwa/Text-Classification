If you wanted to do more interesting things, however, such as thicker rendering of lines or saner interaction with the depth buffer, you would probably want to construct a more complex data structure that understands what the edges of a quad are, and whether those edges are interior edges (like , above) or exterior edges (the ones you want to render). You can then render these edges using any existing "thick line" rendering technique suitable for your graphics API (which itself often involves rendering the "lines" as oriented quads-formed-by-triangles, but in this case you'd be working one level of abstraction above that). Hardware feature edge detection is a topic you'd probably want to look into if the latter options sounds appealing. 

A mesh should consist of what it needs to consist of. Certain modelling operations are made significantly easier to implement, or provide better visual results, when the mesh is represented as quads. Your linked article does a decent job of provided a brief survey, and also touches on the edge-loop benefits which are useful even in simple modelling. However, modern graphics cards only work with triangles, so at some point the mesh data must be converted to triangles. Consequently, a reasonable rule of thumb is model using quads (particularly if your art pipeline is going to be making extensive use of algorithms that are better-suited to quads), and convert to triangles after the stage in the pipeline where the modelling is done, for example during the export/bake process that turns meshes into the optimal engine format. If you're not doing anything in your art pipeline that benefits from quads, and you prefer triangle modelling for some reason, that's fine too. 

(The above images are a subset of this image from Wikipedia). As you can see above, an isometric projection has angles that measure 120 degree between any pair of axes. If you look at the tile containing the flagpole in your image 

Only a lawyer would be able to definitively answer this for you based on your specific project and its needs. You should ask a lawyer, especially since you've already had prior legal contact with Atari concerning this project. 

The "technique" is here is so simple that it almost doesn't deserve to be called as such: you just record the data from game systems you think are relevant. How you record that data (to a database, to files, whatever) is too broad to discuss here (and the techniques and patterns are not particularly game-development specific in any case, making them better suited for discussion on SO), as is the question of which systems are relevant. There are no clever automatic techniques to answer those questions; that would be quite the feat of artificial intelligence. The thing you want to make sure of with a game where there is a server component is that the server should do all the logging it can. Nothing you get from the client can be trusted, and especially if you're going to be using this data to tailor changes to the game you don't want players to be able to tamper with it. The client should only record and transmit statistics that the server wouldn't normally have access too. For example of you want to record UI click heat maps, that's probably only feasible on the client. 

In general, it will be better for you to take an approach that doesn't senseless create complex inheritance hierarchies. It does not sound, from the limited information you've provided, that barren versus gaseous versus normal (et cetera) planets different so significantly that they warrant their own unique types. It sounds like these are all properties of a single class. Consequently, you should go with your second approach and create a single class that can be configured by way of its properties (which you can load, as you noted, from XML or some other data store). Because there is no need for unique types per planet type, this approach will be much more maintainable if only by virtue of having fewer types and thus less code to maintain. 

Originally, dedicated graphics processing hardware had a fixed, hardwired set of functions. It would take input geometry, do very specific things to it to transform and rasterize it, and then blast the results to the screen. Over time, this functionality became parameterized and eventually programmable. "Shaders" became the term used for the programs that ran on the GPU, since they controlled the transformation and shading of geometry. As GPU hardware evolved, more and more of it has become programmable, so now the bulk of the kinds of shaders one can write only contribute indirectly to the actual shading of anything on screen (I'm referring to things like geometry and hull shaders here). With that came the generalization of the GPU as a device for doing large-scale highly-concurrent stream-based processing, such that while the intent of a GPU and of shaders is generally to implement some kind of fancy graphical effect, they can also be used to perform certain kinds of general-purpose computations (particularly those that are suited to being computed in parallel). This is often referred to as general purpose GPU programming, or "GPGPU." However, the GPU is still highly specialized and can't do a lot of the things a CPU could do. It has limited connectivity to the rest of the hardware in a system, as well, so you can't really write "regular" programs (with console output or mouse input, et cetera) entirely on the GPU. You can perform calculations on the GPU that aren't intended to be interpreted as renders, but it isn't a standalone CPU in its own right. 

You can do this with the API. As described in the documentation for recovering score data, you want to use the leaderboard object to represent a query to the Game Center service for leaderboard information, specifically setting the range to to return only the top score. This code would look something like this: 

Note that some APIs provide deltas directly to their mouse-move APIs, so you may be able to use those metrics instead, which can simplify your logic. It's also useful in practice to store a copy of the original position of the drag shape; for example if you want to easily support cancellation of the drag, or show a "shadow" as the user drags the object, leaving the original untouched until the drag completes, or to avoid floating-point error accumulation in some cases. You may want to consider augmenting the above bare-bones approach accordingly. In that case you can actually do away with the per-frame delta computation and store the original drag origin point once (not updating it in the move handler), and instead compute the total delta from the original origin to the current point during the move handler and use that as the translation value for the ghosted drag shape.