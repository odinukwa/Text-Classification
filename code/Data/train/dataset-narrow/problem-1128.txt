There is no need for , just put the (inverted) check into the loop condition (this will then also enable you to process empty lists). You can write your outer loop as a simpler (semantically equivalent) for loop: 

I don't think there is anything wrong with your general approach (or at least I don't have a better suggestion). On an implementation level I've a few suggestions 

First of all, as DarthGizka mentioned, your code is mostly easy to read and understand and except for the memory leak I mentioned in the comments I don't see any errors. I can't really contribute on the general question, of how effective skiplists are or what would be the best algorithm to determine the height of each node, however, I think there are still a few things that can be improved in your current implementation: General Interface I believe this is more of a proof-of-concept, but on if you go on with it, you should probably strive to make a interface more similar to STL-like associative containers. Meaning in particular: providing iterators, template the class on the member (and key type), providing the typical typedefs and functions (e.g. ) etc. As mentioned by others, this would also make it easier to compare it to other data structures. Making a nested class Skip_Node is an implementation detail that should not be visible outside of the class, so you can just make it an nested class of . Const correctness and static member functions You have a few member functions that should be specified const (, ) or even static (, ). Structure It seems that you assume, that you will never add an item to the container with the same key as the key. If that is the case, you should probably document and assert that. However, this also means, that there is no need to treat the node in a special way. More to the point: The main reason for using dedicated and nodes is so that your member functions don't have to care about empty lists, or whether a new node is the first or last node in the list. If you embrace this concept, then you can e.g. make a one liner that simply returns the size of the vector. Also, insert and erase seem a little long to me and share a nontrivial amount of code, so you might want to refactor the common functionality in a separate function. Finally, seems to be a pretty heavy member for the list nodes (due to the size overhead and the additional memory allocation). If the maximum level is a compiletime constant, you could try e.g. a member array instead (possibly using multiple different node classes of different sizes, as suggested by DarthGizka). Dead Code With the above in mind and when you carefully think, about what invariants hold at each line of code, you might see, that there is a lot of test that always evaluate to true or false and code that never gets executed. Comments Nice to see a thoroughly commented code. Personally I would write the function documentation at the point of declaration (in the class definition) and I also try to avoid to write comments basically repeat the code the code. After reviewing and refactoring your code, I ended up with the following (some of the changes are just personal style): 

Since many of the transgressions have already been described well in other answers [1] [2] , I'll resort to just enumerating the ones that immediately strike me: 

Now, one option is to use conditional indexing to modify . Since it's a 3 channel image (represented as 3 dimensional array), and our mask is only 1 channel (represented as 2 dimensional array) there are two possibilities: 

As Austin Hastings correctly pointed out, the trick is to use vectorized operations provided by numpy: 

Here I would expect to see at least a function which performs a single merge pass using given sub-sequence length, along with the main sort function which iterates the passes. Using would seem a legitimate approach -- if not, then I'm sure the implementation has already been discussed sufficiently, so there's no need to get into that. I think a decent implementation of a single merge pass could look something like 

This lacks some details, but we can assume it's text, with average 10 characters per number. At least one character being a separator, that gives us average 9 digits per number, so it seems quite safe to assume they're in range of a 32bit integer. So far so good, although your input code could have some better error handling and provide meaningful error messages when the input fails to meet your expectations. However I think you're being overly pessimistic with having to merge files -- as mentioned in another answer, 100 million 32bit integers take ~380 MiB, so it shouldn't be much of an issue fitting this along with a temporary buffer in the address space on much of current hardware. That being the case, I'd keep things simple, and stick with a 3 step process -- input, sorting, output. As such, I would expect to see at the least 3 functions, one for each of those steps. 

To perform this iteratively, we take the bottom-up approach. We can conceptually treat our vector of integers as a sequence of sorted sub-sequences (initially of length 1, and with the possibility of the last sub-sequence being shorter than the rest). We perform a number of merge passes, merging pairs of adjacent sub-sequences: 

Using STL algorithms If you want to advance an iterator by a certain number, you can use std::advance instead of a loop: 

I know, there are a few implementations of immutable strings out there, but my focus seems to be a little different. My goal was to have a type that provided value semantics, but didn't incur the cost of dynamic memory allocation when constructed from a string literal which is already guaranteed to exist during the whole program runtime. After refactoring, I ended up with two classes: 

Padding I just want to point out that aside from the false sharing between and , which is avoided via padding, any thread calling push or pop will access both variables anyway and afterwards you still have false sharing between the actual nodes. Performance This code contains a lot of micro optimizations, which might or might not be worth the effort if the code gets reused in different contexts (its definitively not worth for handling a worker pool). However, I'd suggest, to write at least few small benchmarks to ensure that those optimizations are in fact improving and not hurting performance. Also I want to repeat my warning from the comments that for some reason, VS2013 (and also 2015RT) seems to be unable to implement in a lock-free manner, in which case the whole structure is probably much slower than a normal stack with a mutex. 

The only thing you share among the codes is just define it as an atomic (). Even Better: Don't share anything: Let each task use it's own hit counter and sum them up at the end (easiest way to do this would be to use std::async). Create and seed a separate random number engine for each thread 

Upon construction, no actual nodes are created, but only properly aligned memory is reserved, on which you later call the assignment operator. I believe (although I'm not sure) this is OK if T is a POD, but if not, then (move) assigning values to them is definitively not allowed, because custom move assignment operators usually assume that points to a valid, initialized object. So in general, I see two possibilities: 

I would add rvalue reference support with moving of temporaries. seems to be too low precidence to be practical - you end up having to everything (as demonstrated above). % at least binds tightly. I do like . Better than my . Forwarding from the operator to the function lets you forget the function behind the operator entirely: -- very Haskell. N ary infix operators that defer application of allow to run as efficiently as possible. But doing that cleanly might be hard. Not sure what is intended to do above. For an interesting test case, implement (where that lambda is a placeholder for a functor) Block some copy and move ctors to prevent persistance, and friend the approriate operators. As noted, I allowed arbitrary binary operators (chosen when you ) to bracket the named operator: the precidence of the resulting named operator exactly matches the bracketing operators. So has precidence of and has precidence of . Of the 3 first use cases (lin alg, container append, then) for two of them the named operators where variants of existing operators, and matching their precidence seemed useful. 

I would get rid of the if-else statement in operator() of Rule, and replace it with a stored functor, or move the from operator() of Rule into StartsWith and make all of your checkers have the same signature. Suppose we go with moving into StartsWith. Then stores a , which you produce once at construction (possibly through a big if-else block, but you only run that block once). Then operator() on just calls that check on the input parameter. If I was to go further, I'd work on rule-factories. A rule-factory is a function that takes a MyVariant and produces a . Then register a rule factory for each enum entry. And now your class itself goes away -- a is just any that takes a and returns true or false. The end syntax looks like: