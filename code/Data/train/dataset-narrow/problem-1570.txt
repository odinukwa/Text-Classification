You can use the format to add the additional IP addresses. Just be sure to add the appropriate netmask to each network. You can route additional networks on each interface as shown. 

Verisign has a very large customer base and has been around for a long time. Omitting it would cause problems for a large percentage sites. This would be a problem for users, and consequently would cause them to change to different tool. Most tools allow you to check the trust chain so you can verify what your experience would be like if Verisign was not in the CA bundle. I sometime clean the bundle of CAs that I am unlikely to trust, but always keep Verisign. Some tools such a VPNs allow users to specify their own trusted authorities. With a private CA this can greatly simplify trust relationships. 

You can use the existing key to sign for both domains. The trick is to sign the email using the correct signer. I extract the domain from the sender address and sign as that domain. It is perfectly acceptable to have multiple active public keys with different selectors. During key replacement you will want the old and new keys active. Keys should be replaced periodically. If you are acting as a relay server and are signing, they need to generate the key they use. Whoever is maintaining the DNS for the signing domain will need add the public key for the selector used to sign the messages. It is safest to generate the key on the signing server. That will eliminate the need to have the private key anywhere else. The public key is public and will be published, so there is no need to secure it. Many large organizations fail to publish their public keys. I commend you for your efforts to get it right. 

Normally, this would be run by cron or as a service depending on how the package for your system configures it. Modern versions use to collect the historical data to files. Older versions ran to do the same. Check the pages starting with . Also there should be documentation in . can be used to collect and display current data even if the historical data is not available. Check to see if there are any files in , If there are then data is being collected. 

Check to see if 'sudo getent shadow' is working for ldap entries. Check that you can get an authenticated connection using ldap-search from ldap-utils using your /etc/ldap.conf connection data. Depending on your configuration you will also have to configure ssl values in /etc/ldap.conf. 

I would leave StrictModes enabled. It is intended to make it difficult for someone else to replace a users' AuthorizedKeys file. You may have secured this user, but all the other users are vulnerable. There are a variety of tools that can be uses to reestablish a sane configuration if it gets broken. I have been using . is a popular alternative. Even if the user changes their settings, the tool will reset the configuration back to a sane state. If desired it can alert that the change was required. From your requirements, it would appear you are securing an account for a service. Normally, these accounts wouldn't have a password and not a normal user's account. This kind of requirement for a normal user's account would raise my security hackles. As a user, I wouldn't accept this kind of restriction on my account. As an adminstrator, I would be concerned that the account is being used for purposes with two different security profiles. 

If you want both functions I believe you will need to use in at least one router, or combine both functionalities into a single router. 

See my rant on Running an Email Server for more things to check. You also appear to have an excess number of MX records for your domain. 

Try enabling java garbage collection logging. This will give you a good idea of how fast the application is using memory, and how well it can be recovered. You may find some tuning of Java memory parameters will resolve the problem. The Sun documentation includes some good memory tuning documentation. Check the documentation for Tomcat on some typical Java memory settings. 

Analog can handle this. With the appropriate logfile format you should be able to get reports by browser, O/S, user, and time reports. I am not sure it is updated for the latest browsers and platforms. But it does allow for recoding data, so you should be able to get the results you need. 

Unless you enable reporting or use addresses matching the policy domain, neither nor should do anything. See the RFC section 7.1 for details. You should have at least a working address while configuring . It will allow you to verify that your DMARC configuration is working as expected. The address is the address to which aggregate reports are sent by domains that have received mail claiming to be from your domain. I've only received reports from Gmail, Yahoo and Microsoft. The report is in XML contained in a zip file. I process the reports with a script that loads the data into a database for review. Reports are sent periodically by the receiving domain only if you have sent them mail within the report period. Most smaller domains do not support DMARC, but the major domains do. Correctly configuring SPF, DKIM an DMARC will improve the credibility of your mail server. Baring other issues, your email should avoid the spam folder. The address is the address to which you want forensic data sent when messages that do not comply with your policy are received. I've received one report of this type. These records may help you determine whether your domain is being spoofed or if you have a configuration issue. I find the reports are sufficient for my needs. None of the above domains have sent me a forensic report. 

The folder only needs 700 permission. All access should be done as the apache user (www-data on ubuntu). To ensure the appche sets 755 permisions on directories ensure it is run with 'umask 022'. It is important that the directory be owned writable by the web-server user. It is more secure to have only the uploads directory writable by apache. However, it means you will need to update themes, plugins, and languages by another mechanism. The Ubuntu package uses /var/www/wp-uploads as the uploads directory. 

To find the name server for a DNS server will query the DNS server for . This will return the nameserver information provided to your registrar. You must provide the IP addresses to the registrar when the servers are within your domain. To find the DNS servers the DNS server will contact one of the root domain servers. When the DNS server starts it will use a file to do an initial lookup of the root servers. 

Normally, there only is one default route. On a multi-homed device set the default route on the interface that routes to the Internet. In include a setting only for that interface. Other interfaces may need additional routes if they have access to routes that aren't local. Try to limit the number of these routes. It looks like you are trying to do split path routing. Leave off both the and specifications in the configuration and used the commands to configure the routing. You should need only a few lines per interface such as: 

Behavior is what I would expect if you had a mix of old and new nameservers specified at your registrar. Nameservers usually rotate on each request. Try checking what the root servers respond with. On Linux, will show the data for yourdomain.com. The number in the response lines is the time (in seconds) the response will be considered valid by DNS servers your users may be using. Expect changes to take this long to propagate fully. It can be weeks. Unfortunately, your most frequent users are most likely to get old data. This time is controlled by your nameserver configuration. Changes need to be planned at least one cache period in advance. The cache period should be reduced prior to the change, and increased afterwards. It can be increased afterwards, once you are sure the change is correct, 

Then allow access by service and/or network addresses. You can block by names returned by DNS record look-ups as well as by addresses ranges. The following allows access from the local network only, but blocks the router from access. 

You can add the email notification to accept rules as well. If you don't want the notifications, you can remove them. If your service does not log accesses, you can use a similar rule to log access by sending a message to the log daemon. 

It may be an ARP issue. See the Shorewall One-to-one Nat notes. I tend to prefer a firewall builder tool like Shorewall for things like this. 

It is likely a client issue. Do you have any anonymous access (shares, printers, etc.) on the server? Connecting via the IP address looks like a different server to the client. The Windows client will only allow use of one set of credentials to access a server. Drive mounts which can be accessed anonymously can be a problem. It your passwords aren't synchronized with the server, you may get anonymous mounts, then you can't get mount any secured drives until you log out, disconnect the anonymous mounts, or use a different server id for the secured drives. 

Add an alias for the address that should be delivered to the Exchange server with the domain of that server. This would go in . The alias should be something like: 

I expect you want to fake a bounce message on the old domain. I use Exim and their is a control to do this. You will also want a clear bounce message that indicates that the email was accepted for delivery, but future messages should be sent to the new address. Exim also allows for custom bounce messages in the aliases file. This can be used to specify the new address. Postfix or exchange may have similar functionality. EDIT: Exim documentation is quite good. See the specification chapter 40 (Access Control Lists) and Chapter 11 (String Expansions) for details related to your issue. You could try an entry in the recipient ACL something like this: 

records should not return records. Point your to the dynamic name and things should work. DNS tends to be cached so you may loose mail when your IP changes. Also use your ISPs relay server to send mail if your want reliable outbound delivery. EDIT: To fix the outbound addess: You should be authenticating to GMAIL to forward the email. Try using the GMAIL address in a header, and the desired address in the header. Alternatively, add a header with the desired reply address. Send yourself a message, and check the headers. The SMTP RFCs describe the headers which should be easy to understand. 

Mirroring data will have some impact, but that impact may already exit. Writing the log files incurs a performance penalty to ensure database integrity and recoverability. Hot backups populated from log files have been used for a long time. There will be a small load to transfer the file to the remote site. Depending on the log file size and count you might get some blocking under high load. There will be latency on the updates. This may be significant depending on when the and how the the log data is copied. In case of disaster you will likely loose data from the latency period. 

It appears you mail is being delivered over IPv6 which you have not included in your SPF configuration. A some options are available: 

You may want to look at the Shorewall documentation to see what can be done with iptables. I use it to build a firewall on all my Linux instances (including OpenWRT). It has well documented sample (default/base) configurations for servers with 1, 2 or 3 interfaces. The Linux Documentation Project also has documentation. 

The domain name extracted from a message's RFC5322 From field is the primary identifier in the DMARC mechanism. This will cause the DKIM validation for DMARC to fail as the document was not signed by coinbase.com. Either sign it as your domain or remove the DKIM validation from your DMARC record.