I have a pretty large table (~114 million rows) containing OS MasterMap data. This is freshly loaded data in a new table. When trying to set the primary key, I get this error: 

Turned out to be a minor corruption of the SQL backup file. After re-running the entire process again, the restore worked fine with no errors. You would think that Postgres would have in-built checking to ensure integrity of exported data! 

Somehow, I have ended up with an exactly duplicated row. Every field is the same in these two rows. I want to delete one row, but keep the other. As there is no way to distinguish between the two, how can this be done? I would like to do this as quickly and simply as possible. Creating temporary tables etc. is not really an option as it would take too long on a dataset of this size. Creating a new unique ID column would be quicker I guess, but also probably take some time. After a bit of research, I have learned that all records in postgres have a hidden unique id, the ctid. Can I use this to delete one of the duplicate rows? 

This works fine when runs sequentially. But when I run multiple instances of my application (concurrency), I see that some messages are processed twice or thrice. Here's what happens: 

They are designed to be separate, so please no advice on merging them. Now the logic is to find all messages that are not sent yet, and send them. Basically a simple clause in a single-threaded scenario would do the trick: 

But this database is used by many concurrent threads, therefore it's possible for a message to be taken by more than one thread, hence be sent twice or even more. If they were a single table, I could use statement to select unsent messages in a single transaction. What options do I have though to make selection transactional, so that a message won't be sent twice? 

I have a table on Azure SQL Database that I would like to have replicated/mirrored to our on-premise SQL Server So the on-prem SQL Server would have a copy of table from Azure that is always up-to-date, available for read-only queries Is there a technology for this ? The reason I need this is because I need to join this Azure table to some tables on-premise (on 300K + rows) in a query, and linked server is not working for me very well, despite all the tricks and workarounds I have tried Regards, 

but in case of sp_spaceused (without any parameters) - can not insert output, since it produces 2 result sets. I know 2016 has nice parameter @oneresultset = 1, but is there any way you can insert 2 or more output result sets into #temp in SQL 2014 or lower ? Is there any tricks ? 

Last night all of our systems failed and connections to the database kept dropping. We watched the log today and found out that this was the message: 

I'm stuck at setting transaction isolation level. Here's my scenario that happens in the application: 

And one hundred times it worked. Now I'm stuck. I've done all the steps, and client can't connect to the engine. It simply times out. Here's what I've done: 

Of course the overall design and query is much more complex and more details are in action in selecting next new word for a given learner. Now, imagine that words list contains 100K words, and a learner has already learnt more than 5K words. Using the given query, this gets slower and slower and slower by more learners learning more words. Is there a better design for these types of business requirements? How to design for scale in this case? 

I have a non-sysadmin user which must be provided with an ability to view "server audit logs" Tried to grant below permissions to this login / user: 

I even tried to significantly scale up Azure SQL DB (from 20 DTU to 800 DTU), but the speed of query (100 rows update) went from 18 sec to 8 sec which is still not acceptable What am I missing ? Is there any workarounds in this situation ? Regards, 

Found out that all our Azure SQL Databases (pricing tiers S1-S2) have high number of connections/sessions from SA 

It is making it very hard to capture the "root cause" error message (example 911) instead of that generic 3013 message Is there any way to suppress message 3013 so SQL Server does not throw it anymore ? 

Now that I've made sure that SAN is up and running, and permission are OK, how can I tell SQL Server to continue recovering? Since this database is very large, I don't want to interrupt the course of recovering and start from the beginning. And also, any backup would take hours to complete. 

This of course results in tremendous problems, because I'm working on a text-processing application and data comes almost from everywhere and I need to normalize text before processing it. If I know the reason of difference, I might find a solution to handle it. Thank you. 

I don't know why, but during steps 1 to 4, other instances can still perform read queries. This is not desired. I want to exclusively prevent anything, even read queries from being executed on messages table during step 1 to 4. How can I do that? What am I missing in my design? The goal is to make sure that while a message is queued for processing, no other instance would process it again. 

I have a production SQL server and a linked server (Azure SQL Database) I join two tables to do update 

Tried to exclude MyDB from availability group, set compatibility level to 130, and include back to AG But since database in NORECOVERY mode, it does not allow me to set compatibility level If I restore database with recovery, I can set compatibility level to 130, but can't return database in norecovery mode, and can't add back to AG What do you suggest on above ? I need to keep primary SQL server replica as 2012 for now, and I need to make async replica (SQL server 2016) to be available for read-only access 

How string comparison works in SQL Server Why comparison doesn't behave the same on one machine, and one platform, but different environments These 4 characters represent one human-understandable character. Why they are so abundant in Unicode character map? 

Learner can declare that he/she knows a given word Learner can memorize the given word (to be managed by the application later) Learner can choose to ignore the given word, so that it won't be given to him/her later Admin can ignore a word in general, so that it won't be given to any learner A list of words exist in database, as the reference Next word to be given to the student, should be new to him/her 

In SQL Server, is there an ability to limit allowed single query duration for certain logins (users) ? I would like to limit some logins so they won't be able to run queries more than 30 seconds. For a second set of logins, I would allow max query execution time of 60 seconds, and so on Regards, 

replica-01 and 02 are in on-premise data center replica-03 is on Azure VM (03 is synchronizing, no problems here) When I try to use replica-03 as reporting read-only server, running "use MyDB" statement shows the following 

The update of 100 rows takes about 18 seconds! 1000 or more rows take much more time I made sure below is true: