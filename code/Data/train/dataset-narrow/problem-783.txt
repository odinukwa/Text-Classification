I'm currently doing some work on monitoring SQL Server performance. I've found the following script[1] which calculates 'Page Lookups Percentage' - the suggestion being that a "good" value is something less than 100. 

Perhaps the easiest way is to just do a insert...select, re-referencing at the same time by using set identity_insert on and adding a fixed value to the existing identity to ensure no conflict between the data sets ? Something like this: 

EDIT #2 I just completed a backup using the GUI database backup in case my script was wrong somehow - This gave the same result of a damaged backup. -- This only started happening last night. The only significant change that I am aware of is that I changed the 'auto-shrink' option of the database (it was originally set to true). Is anybody aware of a problem in this area with SQL Server 2012 (specifically I'm on version 11.0.3128)? It could just be coincidence or related to something else entirely but that seems the most likely cause at the moment. In addition does anybody have any advice on what to do in such a situation? The database is functioning fine (as far as I can determine), but I don't care to be without backups for very long...! 

When using the autotrace, query A had a cost increase of 30% and Query B of nearly 40%. Obviously, I should be using query b in both cases, but I don't understand what causes them to differ. 

I work on a relatively small development team that works with an Oracle (11g) database. It's recently been requested that all the developers be given the role so that we can utilize SQL Tuning Advisor when developing complex queries. Some have raised concerns that this may have significant performance and/or security implications, but I have not been able to find concrete answers to what these implications are. If this role were to be given to the various members of my team, what are the major pitfalls we should be watching out for? I've included the tag for Oracle 12c as well, since we'll be upgrading to that in the near future. If there's a significant difference between the two, I'd appreciate it if it was at least pointed out. 

It sounds like your database administrator has set the value to . Change this value to , and do a restart. The restart will take a long time as normal, but the following reboots should be much faster. If this device is really a "blackbox" to you, I doubt you can change this yourself. I'd contact your DBA. See the documentation for more details. 

I have attached a screenshot showing the Date of Birth attribute. The Date of Death attribute is identical other than looking at the Date of Death Key field. 

If you only need to know that a row is distinct, and don't need the actual contents of col3, then perhaps returning the hash of col3 would speed up the query? You could even perhaps pre-compute the hash using a calculated column so that you aren't computing the hash on the fly. If you do need the contents of col3, but have a lot of duplicates of col1+col2+col3, then it still may be beneficial to work with the hash to remove duplicates as a sub-query, then only return the col3 contents for the distinct rows. 

I have a database that seems to be functioning fine with no apparent errors except that any full backup taken is broken - attempting a restore fails with an error "RESTORE detected an error on page (18469:-1767164485)" DBCC CheckDB on the database completes without errors. EDIT #1 The backup is created with the following command: 

leave them with the data warehouse database put them on the server that will have Reporting Services installed on it create another server specifically to host those two databases. 

In a current report, I'm trying to track the migration of a person from department n, to n+1, or to n+k. My data is split into a row per term (university data). An example: 

I'm trying to figure out how many times in my database a particular grouping has occurred. I have two relevant tables. 

No, they're not the same. Though I think they're equivalent to what your original query wanted. In an oracle database is an acceptable (if less ideal) way to write a left join. Likewise, denotes a right join. Your original join contains the set: 

This block mixes left and inner join notation. When you mix any form of an outer join and an inner join, it becomes an inner join. If you change the block to 

My team uses Oracle 11 and SQL Developer. I've been relying heavily on explain plans lately to try and determine the most efficient way to solve various problems. Recently, a coworker pointed out that explain plan is not always accurate to what actually happens in the database, and that an autotrace is a better indication since the query is actually run against the data. Testing a query, I've gotten the following results 

Some of the mystery is solved - The reason that some sites could connect and some couldn't is that there was an additional connection string stored in the machine.config file that two of the sites were using. The site that worked when a port number was specified did not use this connection string, so worked. The other sites didn't work when port number was specified because I hadn't added the port number to this connection string in machine.config. Adding the port number to that connection string as well as the ones stored in web.config allowed all the sites to work. Additionally, the reason that iisreset had an effect is that once IIS knows the port number that SQL is using, it seems to 'remember' the port number, and so it no longer has to rely on using port 1434. Once I did an iisreset it 'forgot' what port number was used, so had to make a request on port 1434, which for some reason doesn't work. So my question has gone from a very confusing 'works sometimes' situation to a basic 'cannot communicate on port 1434' situation. 

This isn't a big deal for such a small query, but most of them return many fields (often 20+) and I'm not a fan of so many case statements for obvious reasons. Because of how Reporting Services work, I can't do a general replacement either, it must be done on each and every field. Is there a more efficient method where I could replace every value in the row with 'Confidential' in a single case statement, or at least something more elegant? Edit: To clarify, that there isn't just this one field in the select. I only wrote one for the example, but in production, some reports are looking at displaying a huge amount of columns. I'm trying to avoid making two comparisons on every column for reports that could return rather large sets of data. 

I'm analyzing a database of login records for a university and I'm trying to write a query that will give me an idea as to how many users are using the labs for short bursts, verse a more extended stay. I have the query below query, which tells me how many times each user has used a lab for less than or equal to 10 minutes. What I want is a result that tells me this and their total number of logins. 

I have a table that has a full text index defined on it. Change tracking is set to 'Automatic' but I can see that 'Table Full-Text Pending Changes' is set to '58429', and recently added rows (for the last few days) in the table are not being picked up. The index is enabled. I don't understand how Change Tracking can be 'Automatic' but the index is not updated ? 

If you've tried everything else then perhaps it would be possible (making sure you have a good backup first!) to detach the database, rename the log file (so SQL Server cannot find it) and then re-attach the database. I believe this will force SQL Server to create a new log file. Whether it will also stop thinking that the database is replicated I have no idea, but it seems at least possible. 

I have a stored procedure that performs database backups. Because I'm looking at Availability Groups within SQL Server 2012 I want to utilise the *sys.fn_hadr_backup_is_preferred_replica* function within that script to test whether the script should produce the backup. If the script is run manually instead of as part of a scheduled SQL Agent job, or if the SQL Agent job is executed manually rather than via a schedule, then I want the job to fail with an error message to allow the user to see that the backup has not succeeded due to not being on the preferred replica. If the job is run on a schedule then I obviously don't want it to fail as it would be producing errors and sending out alerts all day long on the server that is not the preferred replica. The only bit that I don't know how to do is to check whether the job is being executed by a schedule or manually. Is this possible? Failing that, is there any other way that I can alert a user that the script hasn't produced a backup, whilst not causing the scheduled task to fail and produce an alert? 

I'm working with Microsoft Reporting Services 2008. In our database, we have a small group of confidential students that need to be taken into account for several queries. If they are a confidential student, the database needs to essentially return nothing. Currently, we do something along the lines of: 

I work on a team that has an SSRS setup with roughly ~1300 (and growing) canned reports. As one can imagine, this has presented problems when a breaking change is introduced to a table. Finding all the reports that may touch a table/field is error prone at best. I'm trying to programmatically build a dependency model. Getting the schema for and how views/tables relate is fairly trivial. What I'm struggling with is how to get a resolved list of fields from a given query. I can pull the query from the RDL files, but interpreting those files is far less so. Queries can contain aliases for fields and tables alike, plus there are problems such as . I'm trying to avoid a regexp hack, and I really don't want to write a SQL interpreter... My initial thought was to loop through the RDL files and parse the explain plan output. While technically possible, this doesn't give me a complete list of resolved fields. Is there any method in which I can use to get the DB analyse a given query and return a list of ? I don't mind having to do some text processing to pull out the results if necessary. 

You need to avoid casting your backup size to varchar or you will not be able to sum the values. If you need to then you can do that conversion afterwards. Other than that it is just a matter of wrapping the whole lot up as a subquery, grouping the results by database name, and doing the sum (You may be able to do it other ways but that seemed the least amount of re-working for me). 

Do note though that BufferWithTolerance has a tolerance value (in my example 0.9) that is essentially a trade-off value between speed and accuracy. If you want exact results this probably isn't the method for you. I also seem to recall that STIntersects is an imprecise method but I can't find any reference to back that up at the moment so maybe I am mistaken about that. 

I've seen suggestions to set the "Use 32 bit runtime" option, but this had no effect. I've seen suggestions to set something similar in BIDS, but I didn't use BIDS to generate this package. I've seen options to use the 32-bit version of DTExec but I don't think the 32-bit version is installed on the server. SQL Agent Job definition: 

If you have a bunch of random fields I would set that up as an . The table would include a reference key to the original account, a field that specifies what type of attribute it is, and the value of the attribute. Alternatively, you could have them each in a series of tables. If each country has a different style zip code, for example, a zip code table might not be a bad idea. Just make sure you have a field. 

to get the distinct program names, but I'm interesting in how often particular groups of applications are used in a given session. So essentially, how often are these three applications grouped together. Is there a way that can get me results in the form of 

The duplicated a's in the first group and b's in the second group are due to other rows in the data (I'm okay with this, but removing that would be a bonus). My main problem is I need that final a to be treated as a different group; so basically showing the first each time a cluster appears.