Can't you just do a planar projection of a regular tiling texture onto your tiles and just have hard edges where your tile types switch? So on your hexes that are "grass" just map their UVs in "map space" to a repeating grass texture. 

You can use those just fine. Your problem set is small enough I'm sure that you don't need to precompute anything. Just run A* every move and you'll have your paths computed given whatever the state of the board is. 

If you're making a game specifically for the iPad, I'd shy away from HTML5. You'll get much better performance using a native app. As an example, here's Bejeweled in HTML5. Try running this in your ipad browser: $URL$ As far as engines to use, I'd look at either Cocos2d or Unity. Both will get a lot of the heavy lifting out of the way and let you hopefully concentrate on making the game itself. 

Console versions typically have fewer cheats because it is harder to ensure stability when the players can go in and do debug stuff. Because the platform holders don't want to be known as "unstable", they can fail you if your game crashes for any reason. There is no central authority for PC games, so cheats don't carry as bad of a side effect. Also the PC market is filled with "tinkerers" who tend to understand what "unsupported" really means. 

Well tweening in the general case is just parametric movement (specifically, defining a function f(x) where x can be 0..1 for position/rotation/scale/whatever) with a modifier on the parametric value you pass in. The modifier also has the range 0..1. If you plot the algorithm on a graph you'll get something that starts at 0, ends at 1, and the slope of the curve defines the velocity at that point in time. If you want the math for the easing functions themselves, check this out: $URL$ 

Generally speaking you should use POT textures so you get the benefits of texture compression. For example, a PVR compressed texture at 128x64 @ 4bpp is going to be smaller in video memory than an uncompressed 72x36. Calculating UVs is pretty simple. Just plug in pixel values over the size (in pixels) of the source image. So if you were to just expand the image you made to the next largest POT, the upper left bit of the second icon would be at ( 36/128, 0/64 ). And so on. 

Well if you can think like a programmer and have learned to problem solve then great. Maybe you'll have an understanding of what makes a good end-user UI. Database knowledge might be a good foundation for... something... The rest of it (other than probably the web communication layer) you can throw away. Real time game programming is almost totally different than application programming. Maybe there might be a little bit of convergence when you start throwing multiplayer and server communication in the mix, but it's a significantly harder problem than just a local-only game. 

Use GameCenter unless you need some of the features beyond "high score list" that OpenFeint currently provides. 

Either way, what you're asking is more than possible. Here's an example of somebody completely replacing Unity's binary scene file format with a text representation: $URL$ What you probably want to do is more likely just take advantage of their editor scripting tools. For example, look at ScriptableWizard. You can take that base code and then do something like load an XML file and spawn a bunch of prefabs, or whatever. Pretty much the vast majority of things you see in the editor is scriptable. You can attach components, move/rotate/scale things, spawn prefabs, edit materials, all sorts of things. 

This is a completely different effect. At its most basic level you can get by with just tightening the FOV and upping the motion blur. 

I haven't used XNA, but when I've used sprite sheets in the past, part of the meta data associated with that sprite sheet is the number of frames on it. Usually if that number is '0' I just compute it to be the width * height, but if it's non-zero I use that and assume that the last sprites are blank. 

Which, according to a few sources I found, seems to not support shaders. You need a new graphics card. 

This is usually done by scaling down the time. So 1 second in real time is like a 1/4 second in game time. On top of this there are appropriate sound effects, etc. 

Well a solution would be to convert your beats to a time stamp. So a note that occurs on beat X in a song that's Y BPM would need to be hit at time (seconds) Z. From there it's pretty simple to figure out when you need to start doing things. If you're doing your standard Guitar Hero/DDR style "highway" for notes, and going from the start of the highway to the bar that signifies when you need to hit the beat takes constant time W, then you need to spawn your note object in the world at time Z - W. 

It depends on the style of game and the "perspective" you're going for, really. For the sake of argument I'm assuming your game is a pure side view instead of top down or faked perspective (think castle crashers or final fight). Generally I would think you wouldn't want anything to collide. In a pure 2d game you aren't really going to be able to pull off what you might need self collision for anyway, like the body landing on it's side, or legs getting twisted up. Now you could do that with a 3G game played in 2d, but I'm guessing that's not the point. 

Is the crux of your problem. You have to think about game programming in a fundamentally different way than other things. Yes, your character is moving one square at a time (and only in one direction, which is a separate bug), but you're not doing it over time. There are many ways of solving this, but thinking about it in a threaded sense is the wrong way to do it. In a very basic sense, you need to simulate all of your entities for a frame, draw that frame, then continue to update. That frame is usually somewhere in the range of 1/60th to 1/30th of a second. So if you want your guy to move at X pixels a second, for one "tick" or "frame", you move him that frame's portion. Usually game frameworks have some kind of "game loop" setup where the actual time it took to draw the frame is passed down as a "delta time" value that you use instead of hard coding a frame time. So in a rough sense, you would have to have an update() method on your guy that represents a single frame's worth of movement, and you do that movement and only that movement. The "while" loop is contained elsewhere (as a trivial case, your "repaint" loop is what you could use). Just look for documentation on "game loops" and that should point you in a better direction. 

This data is hardly standardized. On top of that, most companies aren't completely open with what they're working on. Just because company X shipped a certain kind of game in the past, doesn't mean they're working on that kind of game now or in the future. I mean for some companies it's pretty obvious, but for others not so much. So I doubt you'll find such a site. Personally I'd much rather find a place that has a corporate culture I'm interested in than one that's working on some predetermined type of game. 

Are you trying to play arbitrary files or are you making a game and your source music is in a NSF file? If it's the latter (for example a lot of shipped emulated games do this) then it would probably be easiest to just save out the wave from your sound file using some other software (like winamp) and play that. 

If players tinker and ruin the fun I would say that's their problem. For tinkerers half the fun is seeing what breaks. It's like getting worried that players would use a god mode cheat code and being worried that the player isn't challenged. I wouldn't do anything more than putting those config files in a zip file (which you should probably do anyway for loading times) and making sure your code can handle corrupted data gracefully. 

The common answer you'll get is "with components". There are lots of questions with that phrase in them that you can search through. In particular, here's a good article that has been linked to several times that's worth a read: $URL$ 

Unless what you're wanting to do falls under copyright, trademarks, or patents, you're free to do whatever. Generally speaking, mechanics aren't protected. Names are. Art is (and that includes things like music and level design). You can make a "clone" in the sense that it's a very similar game, but you can't call your Tetris clone "Tris" and not expect some lawyers to get involved. Likewise I wouldn't make a pacman clone with the same board layout and look of the characters. But you could probably do something with nearly identical mechanics and a different skin. 

It's certainly viable, although a lot of game programmers haven't really gotten on board with the idea yet, or have a good understanding of how to test complicated systems. I admit myself that I rarely use it, except for non-gameplay-related systems that are easy to test. Expect to use a lot of mock objects. Because of how tied together a lot of systems are, it's hard to test individual components of that. Plus a lot of things can't be thoroughly tested. How do you test-drive, say, a particle system? How do you test that your animation system is working correctly? A lot of things are visual in nature, and aren't obvious (at least to me) as to how to do proper testing. There are, however, a lot of things that aren't necessarily unit tests in the traditional sense of the word, but that exists as "tests" for specific features. Things like test levels for AI navigation are pretty common, but aren't necessarily the easiest things to automate. There are certain aspects of games that can (and probably should) have unit tests written for them. Any kind of generic "file reading" system should be tested. Maybe have some tests for initialization of hardware things (3d surfaces, etc). Maybe have some mock servers and test your client/server interaction code. Things like that. 

If you're looking for something "sourceable", try looking through the GDC Vault archives. You have access to slides from talks. Doing a search for "camera" lead to some results that might be useful. $URL$ 

One common thing to do is that if your current elapsed time is greater than your total calculated time, just clamp it (so your t is 1). That way you'll calculate your end position to be the actual end position you want to be at. All that being said, your particular examples aren't terribly suited for lerping. For rotating a turret you probably just want to apply a constant rotational velocity while the user has a button held down. Likewise for acceleration. Generally speaking lerping is only really useful for things that you know take a fixed amount of time and aren't dependent on continuous user input. 

If you weren't going to just center the sprite animation in a frame large enough to handle the data, you'd have to have additional meta data for the "anchor" of the sprite, so that you're drawing the sprite at the right location. Obviously this is a lot of wasted space. Fortunately, any half decent texture packing tool will atlas all of those images and give you the appropriate offset for you to use. 

It looks like any regular 3D model. The only thing that's "2.5D" about it is the fixed camera and play space. 

A very basic one is the Pythagorean theorem. Also known as the distance formula. a^2+b^2=c^2 $URL$ where and are the edges of a right triangle and is the hypotenuse. This means that in order to find the length of a vector, you do this: distance = sqrt( a^2 + b^2 ) $URL$ Another note of interest is that if you're just comparing distances, you don't have to take the square root (which can be relatively costly). That's why most frameworks have a "distance squared" or "length squared" function for their vectors. 

Perhaps your "walls" should be made of 4 planes, each of which has the appropriate horizontal or vertical tags.