For performance reasons, in Merge Sorts, it is common to have just one temporary array for the data, and then you use positions and lengths to work inside the relevant parts of the data. The above is hard to describe without a code exammple, so the following will have to do.... a typical merge sort algorithm has a recursive method that looks something like: 

Algorithm In your answer you suggest you can merge two loops and save time that way. You are right, but you can take it even further... you can merge all three loops. In addition, you can incorporate some memoization and dynamic programming to make the algorithm more efficient. In your code, you read all the data in to memory, and then scan each row against all the rows that follow it. You can reverse that logic, and scan each row against all the rows from before it. Consider storing the number of topics each member is proficient in, in an array, and then using that to short-circuit impossible circumstances. By merging the three arrays I halved the execution time on HackerRank to about 0.45 seconds. I am surprised that the system you use makes such a difference (4X down to 0.12 is impressive), but by merging the suggestions above (and code below), you should be able to get another loop out of the system. Note, using a BitArray will reduce the memory usage a lot, so it may be that which is making the difference.... Note that these are not changing the time complexity of the solutions, just the number of iterations through the data. Even I am falling victim to the overloaded Main method, but here's the code I suggest: 

Note that the special-case for 0 is built in to the recursive method too. This reduces the code requirement in the handler as well. The next logical step is to take the user-input and put it in a separate method, leaving something like: 

Having a loop to check each version of the URL could become a problem if there end up being a lot of URL's. There many be a better way to do it using a hash, or some other means of persisting data, and retrieving the most recently used version. Still, even with your loop code, there's a way to do it in a simpler fashion, using a helper method to check for a duplicate URL is a start..... 

but that is overkill, and unnecessary. Edit: In your comments you raised the issue of having multiple different-length values. I would recommend that you create a constant for the longest one (whether you use the String-constant or some other generator method), and then do a on that to get the shorter constants... alternatively, I would consider a helper function as useful for this problem.... 

Now, that first is doing the String-concatenation before the LOGGER can decide whether debug is enabled, or not. This means that you are doing the String-concatenation even when debug is not enabled. If the LOGGER supported a 'formatted' debug method, it could be called like: 

Also, there's no reason to have an 'else' clause to that . The continue breaks the code block scope, so the else is redundant. More completely, the following: 

What's wrong with that (apart from the 3 constant)? ^^^^ Having figured out all the loops you are going through, I struggled to understand the advantage that RxJava is giving you, especially when Java has already got the "right tool" in the toolbox. Let me explain, the concept says: Submit a bunch of jobs to the service, and the service will tell you when they complete. It has a method to add jobs to the service, and a method which will wait until the next-completed task, and return it. Creating a Thread Factory that matches the names you have in RxJava quickly, I have this code: 

every 10 seconds (or so) you create a bunch of threads. each thread tries to connect to a server:port combination. if the connect fails, you remove the server 

This is a typical implementation of a recursive DFS. I see no issues with the implementation other than the static implementation. Typically, you would do it like: 

So, I looked at the problem spec, expecting to see a 3-word description o the title of the problem, and not much else, followed by 'Looking for optimizations, and confirmation that compelxity is O(n log(n) ). Fortunately, I was disappointed ;-) Your description is improved over previous questions, and I can actually follow it without having to google-search for references and hints. It would have been improved slightly if you had spelled out carefully that diagonally touching values combine to form an island... but this is a nit-pick. Then, I did the normal-for-me task of thinking 'How would I solve this', and I thought for a moment, and decided I would: 

the size of your file is limited to the size of your memory ... unless you have lots of memory, but the file is >2GB at which point you can't create a larger array of bytes. 

Now, there are ways to improve that performance still, for example, lots of println statements could be grouped in to just one print... 

Your code, and whole question is based on the assumption that methods should have a single return statement. This 'prejudice' is not significant in Java (there are other languages where it makes sense). In terms of code-style, it is common in Java, and best-practice too, to have multiple exit points from methods, including multiple return statements (The other exit path being thrown exceptions). In addition, your question asks how to improve the recursive method. If I was asked to review this code in a real review, I would say: "Don't solve this problem with recursion!". Problems with recursion: 

Once they are in that Map, it would be easy to locate, and find things. If you need to use reflection, I would still use a Map-like structure, but would only use it to locate the class definitions, and then still have the interface that each class uses. Only create instances that implement the interface. That way you can just use a system like (excluding exceptions)...: 

I took the liberty of throwing this in to an SQLFiddle here If I play with the query, and run the screened and approved queries on the data that I chose, I see you have a condition which may or may not be a bug. If you consider my data, where I have multiple accountId values per application, then, your subquery: 

General As example code, there is a fair amount to comment on. For an eclipse plugin, I would at least expect you to select-all and Ctrl-Shift-F .... 

This optimistic approach simplifies the call structure significantly.... (and eliminates the isValid() method). Food for thought. Finally, I don't like calling your method .... it's not a depth-first-search.... since that applies to a tree. The 'cells' in the 'landscape' are not linked in a tree structure, as one cell could be a neighbour to many other cells. A better name would be , or even just . 

By doing things this way we have separated the model the view, and the controller. This is a primitive form of abstraction that is used in many GUI applications too. In essence, though, it is just a system for placing single functional components in single functions. Having multiple functions in a single method leads to maintenance problems. The question then becomes a problem of how to display things. Your display system has four functional issues: 

Doing the same for and will reduce six calls to just three. Additionally, I would consider wrapping the entire replace function in a call, that matches any of the patterns you are searching for, so you only need to do the full replacement call stack on values that actually require it. A large matches for all replaced values will, depending on how often values are actually required to be replaced, save time. 

The tools in the package provide very convenient access to complicated structures that can save a lot of development time. The tools all come with a caveat though - their behaviour when accessed by multiple threads concurrently is deterministic, but not necessarily intuitive. In your code you use: 

You have a physical table that has been established for the purpose of managing calendar dates. This is great, but with just a little more work it can be extended to do so much more. Consider adding a column "DayType", with values like: 0 -> Normal 1 -> Weekend 2 -> Holiday You could add this easily... right? Then, you can maintain it with: 

your code assumes that the guess will be the same length as the base word. If the guess is shorter, you will get exceptions thrown. is stored as an instance field, but it should be declared instead when it is used.... it should be: 

That query will duplicate the count of approved users if there are multiple applications for the same accountId. In the SQLFiddle I have, it returns a count of 4 for only 2 distinct approvaluserjoin records. It is likely that in your data it is not possible to get that condition though... right? Regardless. I believe the more logical representation of your query is as follows (which I have in this SQLFiddle here 

A Better way. The actual processing for this is simpler if we do some clever backward-forward logic. I spent some time 'doing it differently'... The trick is that you want to extract a function that does it for a single iteration.... so, let's start with the outer function (so it makes sense): 

The method name is way too long... that's an AppleScript name! The arguments in a Java method count as part of the signature, so, your method is really calling it ... it is quite sufficient to call it ... Then, the parameters are Nodes, so there is no need to call them and , and would be fine. Alright, so, now we have the method: 

Conclusion In this particular case, I am not certain that the streaming API from Java8 is the right solution. You are creating much more uncertainty than needs to happen. The right solution to this is a LinkedHashSet data structure. Your Java7 equivalent is a better solution, but change the HashSet to a LinkedHashSet, and then your results are going to be deterministic. The code is simpler, more maintainable, and the parallel benefits of your stream are not possible anyway, so the added overheads of creating intermediate maps, running complicated filters, and other processes are just painful.... Just because it can be done with a stream does not mean that is the better solution. 

leave the code as is, and assume it does something good, or, at least does nothing bad benchmark the code yourself, and confirm the benefits and then fix it, or move on (satisfy your curiosity) speak with the programmer who added the code, and see if there is something you are missing. 

I don't believe it gets the best results all the time. Specifically, what if the integer is negative, then the one array will have negative values, and the from that array will be wrong. your solution suffers from an off-by-one problem in the event that floating-point operaions are slightly less than accurate (which is typical). For example, you may compute the max of one dataset to be 100.0000, and the other to be 33.33334. When you do the division, the result will be 2.999999 which, when you re-calculate the factor, will truncate the wrong way in the int conversion. You need to round, and not truncate. 

There are a couple of suggestions I have here. The first is a major performance one... you have the code: 

Your code looks remarkably similar to the actual awt code used in Polygon to get the boundingBox...., start with extreme min/max values, and then go from there. I often find that the choice to use min()/max() functions instead of conditions is also fastest, so I agree with your code there. What has me somewhat concerned, is the use of: