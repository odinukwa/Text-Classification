From David Johnson, a discrepancy in theoretical vs. experimental approximation ratios: The Traveling Salesman Problem: A Case Study in Local Optimization, D. S. Johnson and L. A. McGeoch. In this paper they give experimental evidence of asymptotics (since the experiments run up to size N=10,000,000!) that defy the theoretical asymptotics: Jon Bentley's "Greedy" or "Multi-Fragment" algorithm (worst-case approximation ratio at least logN/loglogN) beats Nearest Insertion and Double MST, both of which have worst-case approximation ratios of 2. 

In a similar vein as the above, if every polynomial-time decidable equivalence relation has a polynomial-time complete invariant (function $f$ such that $f(x) = f(y)$ iff $x \sim y$), then any $NP$ problem whose witnesses have lots of symmetries reduces to the hidden subgroup problem for the automorphism group of its witnesses. Admittedly, the hypothesis here is rather unlikely to hold, but it does give some connection between symmetry and quantum complexity. 

There is a polynomial p such that (x,y) in R implies |y| is at most p(|x|). There is a poly(|x|)-time algorithm A such that, for all inputs x, if there is a y such that (x,y) is in R, then (x,A(x)) is in R, and if there is no such y, then A(x) rejects. For any poly(|x|)-time algorithm B, there are infinitely many pairs (x,w) such that B(x,w) differs from R(x,w) (here I am using R to denote its own characteristic function). 

I would say there is no "one best/most appropriate route" to becoming a theoretical computer scientist, so it is more a matter of your personal tastes, and even what part of theoretical computer science you are most interested in, which you may not even know yet. I know of great TCS researchers who started out in pure math, and great TCS researchers who started out in CS or (even!) EE. (And by the way, to the commenters: I know plenty of good TCS researchers who more or less abhor programming, and I also know plenty who are not only great programmers, but great software engineers.) Whatever route you take, if you think you are really interested in TCS then you should immerse yourself in it, especially to try to find out which parts of it you are really interested in. Introductory classes on algorithms (many of which are purely theoretical and involve no programming, if you so desire) or the theory of computation are good places to start, and beyond that it is a matter of reading, asking professors for references and pointers, sitting in on introductory TCS grad classes if you have the opportunity, etc. From that point of view, your particular degree doesn't matter so much (unless e.g. if you do a mathematics degree your university would perversely prevent you from taking a course on algorithms or theory of computation). However, it also sounds like it is still so early in your potential research career that it would be healthy to question why you are interested in TCS (even asking this question can lead you on a path to discovering exactly what parts of TCS you are really interested in, and give you better motivation for your future work), and to expose yourself to plenty of other topics to see if your true interests end up being elsewhere. 

(Even in the context of Graph Isomorphism, I could see someone, perhaps informally, referring to a $2^{\sqrt{n}}$ lower bound as "exponential", since it would be understood that there is a $2^{O(\sqrt{n \log n})}$ upper bound so essentially no stronger exponential lower bound could be hoped for...) 

As pointed out by @Marzio De Biasi, the problem you are asking about is $\mathsf{coNP}$-complete, by a direct reduction from TAUTOLOGY: given a boolean formula $\varphi$, is $\varphi$ equivalent to the constant 1 circuit? It is easily seen to be in $\mathsf{coNP}$. (Given that Marzio really answered the question, I suggest anyone thinking of upvoting this answer flip a coin and if it lands heads then go vote for one of Marzio's other answers.) Let me also clarify: the problem you are asking about is more typically called Circuit Equivalence. Circuit Isomorphism is the problem: given two circuits $C_1, C_2$ on $n$ inputs, is there a permutation $\pi \in S_n$ such that $C_1(\vec{x})$ and $C_2(\pi(\vec{x}))$ are equivalent? Circuit Isomorphism has a status similar to that of Graph Isomorphism, but one level higher in $\mathsf{PH}$: it is $\mathsf{coNP}$-hard (by the same reduction above), not known to be in $\mathsf{coNP}$, in $\mathsf{\Sigma_2 P}$, but not $\mathsf{\Sigma_2 P}$-complete unless $\mathsf{PH} = \mathsf{\Sigma_3 P}$. 

(Historical note: it is not too surprising that not many natural problems are known to be in $\mathsf{S_2^p}$ but not known to be in its subclasses $\mathsf{MA}$ or $\mathsf{P^{NP}}$. If you check the original papers of Russell--Sundaram and Canetti (independently), it seems as though the definition of $\mathsf{S_2^p}$ was made more or less specifically to capture their improved arguments placing $\mathsf{BPP}$ in $\mathsf{PH}$, rather than to capture some set of of natural problems.) 

As already pointed out by Emil Jeřábek in the comments, this is Hilbert's Tenth Problem over the rationals, whose computability is a notorious open question. In this case, note that the Boolean formula $f$ is satisfiable iff $t(f)$ has an integer zero: a satisfying assignment, when treated as 0s and 1s, gives an integer zero, and conversely, given an integer zero $\vec{\alpha}$, taking it mod 2 gives a satisfying Boolean assignment (this follows from the form of the translation $t(\bullet)$). Now, given a rational solution to $t(f)=0$, if all of the denominators involved are odd, then we may still take it mod 2 to get a Boolean solution, so we have 

What interesting differences are there between theory and practice of security and cryptography? Most interesting will of course be examples that suggest new avenues for theoretical research based on practical experience :). Answers might include (but are not limited to): 

This problem is NP-hard. Although it may be possible to find some canonical form for string isomorphism, say, in quasi-poly time, without upsetting our current guesses as to how the complexity world looks, finding the lexicographically least isomorphic string is NP-hard. This is precisely the content of Proposition 3.1 here. In fact, they show it remains NP-hard even when $G$ is an elementary abelian 2-group (=every nontrivial element of $G$ has order 2). 

First, (as has now been edited into the question statement) a positive answer to your question would immediately improve the state of the art in worst-case bounds for graph isomorphism. For a $O(\sqrt{n})-\mathsf{PTIME}$ algorithm yields a $2^{O(\sqrt{n})}$-time deterministic algorithm, but the current best known for GI is only $2^{O(\sqrt{n \log n})}$ Second, it is not even immediately clear to me whether or not the current best algorithm is in fact a $O(\sqrt{n \log n})-\mathsf{PTIME}$ algorithm, although the first part of it clearly is, in some sense. The algorithm first guesses a set of vertices of size $\sqrt{n/\log n}$ to individualize (Zemlyachenko's trick - see here for an exposition in English), which can be done by guessing $\sqrt{n \log n}$ bits nondeterministically. However, after guessing those and individualizing (in deterministic poly time), it applies the best-known bounded-degree isomorphism test, which takes time $n^{O(d /\log d)}$ (Theorem 9.1 of this paper), and applies it in the case of $d=O(\sqrt{n \log n})$. I'd have to think carefully about whether the latter algorithm could be turned into a $O(\sqrt{n \log n})-\mathsf{PTIME}$ algorithm (seems like an interesting question...) 

Although the previous answers are fairly comprehensive, let me just add that there are notions of time-bounded Kolmogorov complexity which can apply in your situation. For example, $K^t(x)$ is the length of the shortest program that produces $x$ within time $t(|x|)$. So, for example, a pseudorandom number generator that takes time $n^3$ could still produce numbers with high $K^t$ for $t(n)=n^2$, even though the numbers it produces will all have usual Kolmogorov complexity bounded by a single constant. Look up "Resource-bounded Kolmogorov complexity" or see Li and Vitanyi chapter 7 for more details. 

For your first question: yes, it is NP-complete. The complete graph is the Cayley graph of any group, if you take the entire group (say, except the identity, but that would just add a self-loop at every vertex) as the generating set. Then CLIQUE is a particular instance of your problem. A more interesting question might be to restrict Cayley subgraph isomorphism to Cayley graphs where only a minimal, or say $O(\log|G|)$-sized, generating set is used. For your second question, the answer is also yes, because not only is Code Equivalence similar to Graph Isomorphism, but GI reduces to Code Equivalence. Essentially the same reduction (due to Petrank and Roth) gives a reduction from Subgraph Isomorphism to Subcode Equivalence. 

If what you're looking for is a proof that is neither a) reduction from a known complete problem, nor b) straightforward diagonalization (which your various comments indicate you are), then as far as I know you are out of luck. All of the proofs that I am aware of that aren't by reduction - including those in the other excellent answers given here by Aaronson and Kjos-Hanssen - proceed by straightforward diagonalization. And all of those diagonalizations are essentially the same proof. Some of them are slight variants on the proof that yield slightly stronger/weaker statements, but the proofs themselves are typically just very slight variations. (And all of these proofs are essentially the same as Cantor's original proof about cardinalities, which is the same as the proofs of Godel and Chaitin incompleteness, which are the all just theorem-versions of Russell's paradox... So much so that at one point I wondered if one could formalize in some sort of reverse-mathematics kind of way a theorem which said that there was essentially only one such proof.) It may be worth pointing out, however, that there are proofs of other statements - typically of a different flavor - that are diagonalizations that are really, truly, provably different than diagonalization used to prove e.g. undecidability of the halting problem. 

Yes. First, since it took me a minute to figure this out myself, let me formalize the difference between your question and $\mathsf{AlmostP}$; it's the order of quantifiers. $\mathsf{AlmostP} := \{L : Pr_R(L \in \mathsf{P}^R) = 1\}$, and the result you allude to is $\forall L\, L \in \mathsf{BPP} \iff Pr_R(L \in \mathsf{P}^R) = 1$. If I've understood correctly, you are asking if $Pr_R(\forall L\, L \in \mathsf{P}^R \cap \mathsf{COMP} \iff L \in \mathsf{BPP}) = Pr_R(\mathsf{P}^R \cap \mathsf{COMP} = \mathsf{BPP}) = 1$. Consider $p := 1-Pr_R(\mathsf{P}^R\cap \mathsf{COMP} = \mathsf{BPP}) = Pr_R(\exists L \in \mathsf{P}^R \cap \mathsf{COMP} \backslash \mathsf{BPP})$. By the union bound, the $p$ is upper-bounded by $\sum_{L \in \mathsf{COMP}} Pr_R(L \in \mathsf{P}^R \backslash \mathsf{BPP})$. (Note that the latter sum is countable.) Now, by the 0-1 law - which applies since all the relevant statements do not change if we change $R$ finitely much - each individual probability in this sum is either 0 or 1. If the answer to your question is no, then $p=1$, so there must be some $L \in \mathsf{COMP}$ such that $Pr_R(L \in \mathsf{P}^R \backslash \mathsf{BPP}) = 1$. But this contradicts the fact that $\mathsf{AlmostP} = \mathsf{BPP}$. Update Oct 10, 2014: As pointed out in the comment by Emil Jeřábek, the same argument applies to $\mathsf{AM}$ vs. $\mathsf{NP}^R$, since we also know that $\mathsf{AlmostNP} = \mathsf{AM}$. He also points out that we didn't use anything about $\mathsf{COMP}$ other than that it is a countable class that contains $\mathsf{BPP}$ (resp., $\mathsf{AM}$). So the "interesting conclusion" in the OQ actually applies to any countable class of languages $\mathcal{C}$ that contains $\mathsf{AM}$: if $\mathsf{P} = \mathsf{NP}$, the "only" languages that witness the oracle separation $\mathsf{P}^R \neq \mathsf{NP}^R$ are outside of $\mathcal{C}$. But the latter statement feels somewhat misleading to me (it makes it sound like, for any $L_0$ we could consider $\mathcal{C} = \mathsf{AM} \cup \{L_0\}$, and thereby "show" that no $L_0$ realizes $\mathsf{NP}^R \neq \mathsf{P}^R$, contradicting the well-known theorem). Rather, writing it out symbolically, we've shown: If $\mathsf{P} = \mathsf{NP}$, then $\forall \text{countable } \mathcal{C} \supseteq \mathsf{AM}\, Pr_R(\mathsf{NP}^R \neq \mathsf{P}^R \text{ and } \mathsf{NP}^R \cap \mathcal{C} = \mathsf{P}^R \cap \mathcal{C}) = 1$. Note that, crucially, probability 1 is not the same thing as all $R$, and which full-measure set of $R$ satisfy the argument to $Pr_R$ can depend on $\mathcal{C}$. So if we try to alter $\mathcal{C}$ to $\mathcal{C} \cup \{L_0\}$, it at most removes a measure 0 set of $R$ that satisfy this statement. 

Here is a thorny difficulty that nullifies many naive attempts at proofs of lower bounds. It's not a theorem per se, but it's a salient example. Many attempts at lower bounds try to define some sort of "complexity function." These complexity functions often have the property that if a circuit C is composed of two circuits F and G and one additional gate, then the complexity of C is at least the complexity of F and G. But this phenomenon is strongly violated by our usual notion of complexity, as the following argument (which I think is due to Razborov) shows. By a counting argument (originally due to Shannon, I believe) almost all functions require circuits of size $\Omega(2^{n}/n)$ to compute. Let R be a random function, which is therefore highly likely to be hard to compute. Let S=1-R. S is necessarily as hard as R to compute. But S+R=1, a constant function, which is as trivial to compute as possible. 

The $\mathsf{MA}$-style algorithm guesses the circuit $C$, and then verifies the two conditions using polynomial identity testing, which is in $\mathsf{coRP}$ by Schwarz-Zippell-DeMillo-Lipton. Note that, without the restriction of poly-size, Hilbert's Nullstellensatz guarantees that there is no solution if and only if there is some circuit $C$ satisfying the above two conditions. (On the other hand, assuming $\mathsf{NP} \not\subseteq \mathsf{coMA}$, there are systems of equations coming from algebrizations of 3SAT for which the above poly-size promise is violated.) (This is the basis of an algebraic proof system from recent joint work with Toniann Pitassi, but for the purposes of this answer similar ideas go back to an earlier paper of Pitassi's as well as her 1998 ICM talk, and to the so-called Nullstellensatz and Polynomial Calculus proof systems.) 

Yes, one can define $BP\Delta_i^P$. Indeed, for any class $\mathcal{C}$ one can define $\mathsf{BP} \cdot \mathcal{C}$ as $L \in \mathsf{BP} \cdot \mathcal{C}$ iff there is a language $L' \in \mathcal{C}$ such that 

In most "standard" proof systems, the formula $\varphi$ being proved is usually part of the proof itself by definition of the proof system, in which case for all $\varphi$, $K(\varphi) \leq K(\text{proof}) + O(1)$ (the extra constant is for the part of the program which says, basically, "extract the last line of the proof" - anyways, additive $O(1)$ errors are the best one can hope for in Kolmogorov complexity). Even in a proof system where all that is required is that the formula $\varphi$ appear somewhere amongst the lines of the proof $\pi$, one can still get $K(\varphi) \leq K(\pi) + O(\log|\pi|)$, where here the extra $\log|\pi|$ bits are used to describe the index $i$ of the line of the proof that corresponds to $\varphi$. In the much more general Cook-Reckhow style of proof system (or its computable analog) - that is, a polynomial-time computable function $f$ (resp., just a computable function $f$) whose range is exactly the set of true sentences of your theory - again, $K(\varphi) \leq K(\text{proof}) + O(1)$, where here the $O(1)$ extra bits describe the function $f$. (Note that the trick of hard-coding certain tautologies into your proof system, pointed out by Kaveh, is handled by this latter case, as the hard-coded tautologies must be encoded directly into $f$, so they contribute to/are handled by the $O(1)$.)