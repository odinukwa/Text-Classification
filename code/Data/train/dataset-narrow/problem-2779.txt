There are plenty of tools for making images. I'm not looking for one of those; I have many tools for creating an image. I've got tools for compressing images, generating mipmaps, and even for poking at their basic data format. My issue is with texture assembly. DDS files support cubemaps, array textures, and even cubemap arrays. But I don't know of a tool that can pack a series of images into a cubemap or the like. What tools are available for doing this kind of thing? 

is part of the VAO's state (unlike ). So you need to do it while your VAO is still bound to the context, not after. 

Your guidance system is built on the assumption that accelerating directly towards the target will eventually cause the objects to collide. Since that assumption is false, the guidance AI based on that assumption is likewise unsuccessful. So stop accelerating directly towards the target. Add some logic to detect if the target's position is somewhat perpendicular to the direction of the missile's motion. If so, then the missile needs to accelerate towards the target, but also slow down its forward motion. So rather than going directly towards the target, it biases the direction of its acceleration so that the current speed in its direction of motion is slowed down. Also, you'll need a trigger to make sure that you're not going too slow. So add some threshold speed such that, if you're below that threshold, you stop doing the biasing. One last thing: no guidance system will be perfect. The reason missiles can intercept targets in real life is that targets move much slower than the missiles themselves, and the targets are not particularly nimble (relatively speaking). If your missiles are not going to be many times faster than the targets they chase, then they will miss a lot. 

Then you need to make a judgment call: do you want your game to be easy to write, or do you want it to be good? Yes, making a real in-game tutorial is a pain. But that pain is the difference between forgettable games and the ones people actually want to play. 

See how they both start out the same way? . The important part is what is different about them. And since I'd covered the offsetting in Tutorial 3, I didn't feel that it was necessary to bring it up again in Tutorial 4. However, I did add a clarification that points out that the offset is the same as previous offset values. 

Finite lives are a form of resource management for the player. If you notice, most games that have a finite count of lives tend to be very binary about being alive or dead. Maybe the player gets a couple of HP, but if you get hit more than 3 times or so, you lose a life. And there will generally be a healthy supply of "insta-death" lurking around, whether it is pits, spikes, etc. Because of that, lives function as resources in the same way that healing potions do in RPGs. The more you have, the more likely you are to be able to progress further. You don't have to push as hard, since you have more lives to try again. This is also why RPGs, even historically, almost never used multiple lives. There was no point, since they already had plenty of resource management. One of the reasons why finite lives is going out of fashion for games these days is that running out of lives generally isn't fun for most players. While the tension created by having low lives is nice, if you ever actually run out, the game becomes a lot less fun. You lose a lot of progress. One of the other reasons why finite lives aren't used often is because game developers tend to allow you to save anywhere. Or at least, at reasonably-space designated locations. Because of that, the only progress you can lose is back to the last save point. So, unless save points are significantly different from checkpoints, there's really no purpose to it. And if they are significantly different, players may not like that very much. So the only way to make finite lives worthwhile is to punish the player significantly more for running out of lives than for simply losing a life. 

At the same time, if you have a vector, it's not a bad idea to want to be able to normalize it in-place. For that, you use a member function, which is your indication that you're modifying the object, not simply returning a new one. So your member should be non-const, but your free function version should take its argument by . 

There are many things you could learn from. Here's my thinking on each, from the perspective of someone new to OpenGL. OpenGL Examples There is plenty of example code out there that you can read. G-truc's examples are pretty extensive and cover a lot of advanced features. However, if you are a beginner, learning from examples is a terrible way to learn. Reading code that you don't really understand will not teach you why it works. Indeed, the text on the above linked page specifically and rightly states that the examples are not for beginners. Learning from bare source code, unless it is heavily commented (at which point it's a tutorial) is not an easy thing. Attempting to do so encourages cargo cult-style programming and copy-and-paste coding. It is very easy to convince yourself that you understand how something works when all you're really doing is just copying code from one place to another. You may be able to mix and match things, but true understanding is difficult to achieve without proper instructional material. OpenGL Books There are a fair number of actual purchasable books for OpenGL development. I'll cover my thoughts on the two biggest here. OpenGL Redbook This one is somewhat problematic from a purely practical standpoint. See, the 7th edition covers GL 3.0 and 3.1. Which is rather old. There have been a lot of useful features added to OpenGL since then, features which change how you would write things. And not all of them are hardware features. The 8th edition is coming "soon", and will cover 4.1. There's no word on whether it covers old fixed-function stuff. I'd say this book is OK. The biggest problem with it is the organization of information. It's more like a comprehensive reference manual than a book made for learning. Here's what I mean. One of the most important things that one should do when teaching is to not overload the student with unimportant information. But the Redbook does exactly that. When introducing material, it introduces a lot of material. Much of it superfluous to the task at hand. What you talk about and when you talk about it are crucial to making your book a good learning resource. The Redbook never holds back information until a more appropriate time. When it talks about how to draw triangles and primitives, it talks about everything about drawing them, all at once. It covers every option, every function, every parameter, etc. That's just not a good organization of information. OpenGL Superbible The fifth edition of this book covers only core GL 3.x, so no fixed-function. However, the general organization of the book is more or less identical to the organization of the fourth edition version. This seems impossible since the 4th edition used fixed-function and didn't introduce shaders until much later. The way this was accomplished is my #1 complaint about the book. Essentially, the author built a library that implements a form of fixed-function OpenGL. It wraps VAOs, buffer objects, shaders, and various other things, so that he can get to drawing objects, matrix math, and textures without having to talk about things like how the GL pipeline works in detail. By hiding all of these details, it makes the material easier to digest. But you will often see people walking away from the Superbible without knowing how to actually function without the library. They don't really understand how shaders connect to buffer objects, how data flows up the pipeline, etc. It is a serviceable book, moreso than the Redbook. If all else fails, it will do the job. But I think it could be better. Also, according to some reviewers, it seems to miss out on certain useful information, like packing attribute data using normalized values and such. OpenGL Online Materials There are many online materials that one could learn from. NeHe's Tutorials NeHe's tutorials, as others have stated, are extremely out of date. They focus on fixed-function OpenGL. It is often stated that it is easy to learn fixed-function GL, which is true. But that doesn't make it a good idea. Understanding how the fixed-function pipeline truly works is hard. I would go so far as to say that it's harder than learning shaders. Once you get it, shaders are simple. Understanding the intricacies of texture environment stuff, combiners and whatnot, is very tricky and requires frequent visits to reference docs to make sure everything is set up right. Even if you understand everything correctly, it's easy to make a small mistake that causes everything to break. The difference is that you can make fixed-function work without understanding it. This encourages cargo cult programming. It makes it possible to get something on the screen without really knowing what one is doing. Over on the OpenGL.org forums, we see questions constantly about minutiae surrounding fixed-function, from people not knowing how gluLookAt works, to difficulties with lighting, to people trying to get some particular effect to work with the texture environment. So no, I do not think NeHe is a good way to learn OpenGL. The above commentary can be used for any non-shader based tutorial, like Swiftless, Lighthouse, and so forth. Wikibook's OpenGL Programming The Wikibook OpenGL Programming is probably the modern equivalent to NeHe. It covers GL version 2.1, because they want to keep it relevant to mobile platforms. If that's important to you, then by all means look here. The other issue with NeHe, and thus this Wikibook, is the large focus on source code. The text to code ratio is very small; there is a lot of code, but the text doesn't really explain how it all works. As an example, look at the bottom of Tutorial 2. It introduces blending. It doesn't say how blending works. It doesn't say what actually means or does. It just says, "Here's some code that makes things transparent." That's not the best learning environment. Incomplete Tutorials Swiftless has a set of OpenGL 4.x tutorials. Durian Software also has some shader-based OpenGL tutorials. And there's the "OpenGLBook.com" tutorials. The thing these all have in common are... that they're incomplete and abandoned. They all got about 4-5 tutorials in, and then were dropped. None of them reached texturing, lighting, or anything like that. Well, Durian did hit texturing but not lighting. Much can be gleemed from them, but there is much that is missing as well. Shameless Self-Promotion Reviewing my own Modern 3D Graphics tutorials would be a horrible conflict of interest. So instead, I'll hold forth at length about the organization behind them and why I think they're good. Oh and yes, I am working on Tutorial 17. The project's not dead. The first three chapters are really about learning how the OpenGL pipeline works. The Superbible failed because it tried to hide details. Instead, I attempt to explain those details really, really well. Repeatedly. The introduction explains the pipeline in plain text. The first tutorial explains it with code accompaniment. And the second tutorial visits it even more. From there, I naturally move on to positioning objects. This introduces uniforms, but I didn't want to jam uniforms and perspective projection in at the same time. So I separated the two concepts. After projection, depth buffering seemed a reasonable next step, followed by how transforms and matrices work. After that, cameras. Rotation with quaternions was a late addition, but I feel that it was an important thing to talk about for the budding graphics programmer. The lighting tutorials again build one on the other. Diffuse, then per-fragment lighting, then specular. Dynamic range was an interesting choice. Most introductory material tries to stay away from that, but I embrace it. You're not a graphics programmer these days if you think light intensity always is on the range [0, 1]. And you're not a graphics programmer these days if you don't know how to maintain a linear color pipeline. The final one in lighting, on imposters, was a weird one. I try to design tutorials that solve problems rather than just show some OpenGL functions, particularly as the book goes on. So much of my tutorial design comes from finding ways to talk about certain topics while still making them real issues and not obvious, "we're learning X now." Geometry shaders are a hard one, because they don't really solve very many problems. Imposters represented a problem that GS's were actually useful for solving. Also, it allowed me to talk about other less used things like and changing a fragment's depth. And it really shows the power of shaders: you can make a flat square become a sphere. The texturing tutorials are also interesting. One of the reasons I put off talking about diffuse color textures until the third one was to hold off on talking about sRGB textures for a while. This way, I could talk about the basic issues around textures (loading data, putting them in shaders, filtering, clamping, etc) without having to deal with linear issues. So then I could spend a whole tutorial on just that topic. That allowed me to really, really emphasize how important maintaining a linear color pipeline is. It's one of my pet-peeves.