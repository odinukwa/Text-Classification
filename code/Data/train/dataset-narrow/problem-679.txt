If what you say is true (no unusal transactions), then I say this is typically caused by Segment(Compression) Advisor going rogue. Compression Advisor still Generates Redo Log on 11.2.0.2 (Doc ID 1324598.1) Huge Redo Generation by Compression Advisor (Doc ID 1969765.1) Sometimes it copies your tables to check if you could reclaim space by reorganizing them, in the maintenance window (nights, weekends). This may generate a high amount of redo and archivelogs depending on the size of the table. This is the reason I always disable the maintenance task for it (also because I find it useless, and I can run my own diagnosis whenever I need to): 

Notice how the column is named automatically. This is an column, that you need to convert to be able to compare it with your regular types, for example or Now using this, a cursor could be coded like this: 

SQL*Plus starting with version 12.2 supports printing the output in CSV format. You can add the below in your script: 

This will not work at all, unless you meant the transportable tablespace method and you intend to restore user tablespaces, and you create the new database using different binaries without the unnecessary options. Sure, you can do this with TTS. Or export/import. These methods require downtime. Or you could just remove options from the existing database. It all depends on the components you want to remove if you need downtime for this. Some components you can remove at binary level (which requires a database shutdown) using starting with version 11.2 (which is the lowest currently supported version): Chopt Tool For example, do disable Partitioning, shutdown the database, then: 

You mentioned system copy. Whenever you change the ipaddress or hostname, DBConsole goes haywire, and even the official solution is to recreate it as described in: How to configure Dbconsole After the Ipaddress or hostname of the Machine has Been Changed or if the hostname ipaddress is going to be changed? (Doc ID 1333938.1) The usual steps to do this: 

Something like this. The below lists everything: which student took which course taught by which professor. 

The typecodes of built-in types are hidden in the dictionary views, but you can query the dictionary directly and find the type based on the OID: 

Ok, I sacrificed one of my 10.2 sandbox databases for a good cause, and upgraded it to 11.2. As I suspected, the above DDL optimization does not work with compatible parameter still set to '10.2.*'. After increasing compatible parameter, it works as intended: 

If the last query returns nothing, backup (Windows) or (Linux, Unix). To make it a simple as possible, you can simply copy these files after the database was shut down. An online backup requires ARCHIVELOG mode configured and using user-managed backup from SQL*Plus combined with OS commands, or RMAN. 

(By default here you should see and , and to be honest, I can not remember a single case where the database had different values - except the one I have just created in my sandbox.) Given the above, you will get the same execution plan as in your question. You can restart the instance, or set and at session or system (instance) level to the same values, it will not 'fix' the execution plan. To modify the above setting, it is technically possible (but do not ever do this in a real database) to update these values manually (re-running the dictionary scripts will not update this): 

That is possible. Not really needed. You can just simply transfer the database to the new server, and run the PSU postinstall script there, that takes like 1 minute. Depends on some factors: 

To answer your original question in title: Starting with 12c, one can easily limit both SGA and PGA. SGA could be limited in earlier releases also by or other parameters from which the database calculated . The problematic part was usually the PGA, with no simple limit value just some workarounds, but that can be now easily limited by using the parameter. 

The column was added to a few dictionary tables, including , in version 12.2. The EM templates are for version 12.1.0.2. The download page clearly states that the template should be used with 12.1.0.2. $URL$ 

Fix this and try duplicating again. Or just skip the UNTIL clause and let log shipping take care of the archivelogs. 

Then log in to EM Express using port 5501. PDB Tablespace is Not Showing in CDB 12c EM Express page (Doc ID 2278612.1) 

This is absolutely normal when you try to perform a complete recovery from a hot backup, because that is how hot backups work, you will never have the latest changes in your backups. Your backup includes archivelogs up to sequence 29. The next changes were in log sequence 30, but log sequence 30 became the current redo log at the time your backup was finished, so you do not have any backup of that. This is not a problem, this is how a hot backups work, you will never have backups of the latest log sequence. Obviously, the next hot backup will back up that, but by the end of that backup, another sequence becomes the latest sequence. If you simply try , RMAN tries to recover the database to the most current state, and it does not know where to stop (except when you have not only the archivelogs, but the redo logfiles also). Your last log sequence in the backup is 29, RMAN will complain about the next one, because it does not know where to stop. If you want to avoid the above error, you can explicitly specify RMAN where to stop (perform a point-in-time recovery). For example: 

Ok, so I had some time to waste, and this is just for the "fun" or "interesting" factor. It's nowhere near that I would use in a real scenario, I have played with it in my lab environment on x86-64 Linux platform, with a few 10g, 11g and 12c databases. At least you can do this even if the database is shut down. When you do a controlfile dump with: 

If there is a big difference, gather statistics. Is there any correlation between the columns and ? If there is, did you gather extended statistics on them, so the database can estimate cardinality more accurately? If both the statistics and the above estimation are good enough, then why isn't there an index on the (and BASLIK) column that the database could use to access the required rows effectively? If both the statistics and the above estimation are good enough, then why does the database decide to use parallel query at all? Did you force it or set it at table level? In the section: 

That is not how you load a field. returns a locator, and data is not stored in the database, but in files outside of but accessible to the database. The above command would not even succeed if BLOBCOL is really of type, you would get the below error: 

You can then search support.oracle.com using this information. This looks like Bug 9577499 ORA-7445 [kkqtutlSetViewCols] when query fails to rewrite. The suggested workaround is: This disables that feature at session level, another alternative would be disabling it only for your SQL statement that throws this error with a hint: 

Java inside the database is optional. If it is not installed, why waste memory on it? Since 11.2.0.4, it is possible to "disable" it if patch 20681008 is installed, with the below parameter: