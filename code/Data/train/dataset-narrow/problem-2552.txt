Forget about tessellation and compute shaders. You simply want to maintain a system copy of the terrain and send it (or parts of it) to the GPU every frame. Yes it's slow, but it ain't that slow :) The trick is to make the section your updating small enough to not bog down the computer. So you don't want to be updating a terrain 1000x1000 tiles. Use chunks of terrain, I use 16x16 tile chunks with 4 tri's per tile, indexed. I can update a terrain chunk in real time no problems. I was going to suggest a dynamic vertex buffer, but you don't even need that.. here's the code i use to update geometry, just use the default resource usage : 

I agree mostly with Asher, XNA is ... was a good language to learn on and C# is very intuitive and far easier to work with than C++. C# and Java are incredibly similar, so you'll feel something familiar there. What you know in C++ can be applied to C#, you just have to forget about all the annoying and confusing stuff :) But if you are going to learn a framework, just start learning SlimDX, I've recently given up on XNA because well... it's based upon DX9, an aging framework, and it looks like XNA has reached the end of the road. It cannot run DX10/11 under the hood, and that's what you want to be using. That is current technology. Using SlimDX is incredibly similar to using XNA but it is far more powerful and you know you are learning current technology. 

Qt, SFML, GLFW, SDL, GLUT. All do Windowing and Input. I've got more in depth descriptions and links here. Qt is the only one that handles some of the OpenGL API itself (as opposed to just making the OpenGL context), but I'm not sure I would want to use it over native OpenGL and afaik it's only some things like shaders (and maybe a simple scene graph). Qt is also fairly heavy if you just want a basic game as it's a whole Widget toolkit. As for directly interacting with OpenGL API there's not too much. You will probably want an extension loader like GLEW. Also some support libraries that don't directly interface with OpenGL like GLM for matrix functions, assimp for mesh loading, and stuff like texture loading. Other than that there are some C++ bindings that wrap the older raw C OpenGL API. I know of 2. OOGL gives full object orientated bindings. However there are problems with OOP and OpenGL. One example is you can often set things like buffer attributes for your entire scene then just draw all the meshes with the same settings. With OOP it's not possible to do that and so you take an efficacy hit. There are also problems with side effects, for example some commands require things to be binded so a seemly simple command to change a shader property could change your active shader, Direct State Access, glProgramUniform (as opposed to glUniform*) and similar functions could help avoid that to some degree but in the real world you will likely need fallbacks for older systems and they are probably still less efficient than doing things in bulk. There's also issues surrounding multiple OpenGL contexts. The other library doesn't bother with OOP but just takes the C api and adds things like proper C++ types for type safety. Not sure it's worth the dependency though. I think OGLplus works that way (but I'm not %100 sure). Realistically you would be better off targeting higher functionality and just using raw OpenGL under the hood. Instead of dealing with raw shaders/programs, deal with materials. And instead of directly calling the OpenGL API in the objects its probably better to put things into some kind of a render pipe (like a command list, but you can do things like sort meshes by material and draw them in one go). I haven't seen any libraries that just do that. Otherwise you can go the next level and start looking at an engine and avoid directly deraling with OpenGL at all. For example Gameplay 3D 

I can't find a way to simply set a uint to a shader constant variable. But the following is a workaround : 

If anyone knows how to set a uint to the shader that would be useful. Though now that I know the 'unpacking' works ok, I'll be passing in the blendweights via a Texture2D. 

Can I recommend getting 2d shadows working first, even if it's just for the level that your avatar is currently on. It will be easier to start looking at the code that way and get it working. I have implemented shadows in 2d tile maps in a couple of ways. One shadowcasting method which I found described by Eric Lippert at Microsoft works quite well. And the other way, which I did myself first time i looked at this kind of thing was to orthogonally sweep the visible tiles and tile-edges and generate edges (and maybe corners iirc) describing the scene in the lowest number of edges. You can then cull hidden edges and form any custom shadowing features such as recessed shadows if you want to show a little bit of wall. Then create your shadow geometry (projective shadow casting ?) and render it over the top. But if I try to take that idea to 3d, it just becomes easier to do it in 3d. While the method described by Eric Lippert could presumably be converted to 3d. But I think you'll find that doing it in 3d is expensive. Perhaps take a look at the source code for Brogue as well. It may have a more efficient implementation for 2d visibility/shadow casting. Good luck. 

First off do you need to actually 'remove' them? Another alternative would be to set a flag on them to 'dead' or 'disabled' or something, anything that sees that (such as your rendering function) will just skip over them. If that is a good idea or not will depend on the usage of your program. If you have a limited number of guys spawned at the start of the level then it works fairly well. It can also make things like reloading saves much faster (you just unset the disabled flag and reset their other attribues). But it does have some runtime costs as you will still be looping over all the dead guys (although you would be doing the full load at the beginning anyway). If you are continuously spawning and killing of waves of bad guys then that's not a great solution. In that case you need a data structure that is quick to insert and delete. An array is not a good choice as the entire memory must be copied each time. You want a linked list instead. Linked lists have a little bit of overhead compared to an array as each item points to the next one, it's also harder to access a specific element in the array as you have to iterate over each one, but generally it's good enough to not worry about for real world applications. You could always combine the LinkedList with a Array you use for indexing. Games often try and reduce the allocation of memory at runtime as much as possible. Games are generally fairly predictable. You know there will be a finite number of bad guys, the only unknowns are plays input (maybe there is a way for the player to cause bad guys to spawn), in that case they will guess a fairly good maximum and add a saftey factor and provide a fallback runtime way to increase the size (or just put some limits in place since otherwise the player could spawn so much they run out of memory). You can create new guys at runtime using what is called a Pool. Basically they allocate the guys in advance and pull out a new one when it's needeed. 

It probably depends on what it's for and what your employee is telling you to do (if you get to that stage). If this is just for yourself, don't bother with Autocad, just use Max, it's so much more fun. Max and Maya are great tools for 3d visualization, I've seen some wicked home interiors made with these packages. You can model everything in Max for visualization, but if you need technical specs then Autocad might be the way to go. Listen to what anyone says about Autocad, because I don't know it much, I've studied Max and to a lesser degree Maya. So an autocad user might have some things to consider. 

imagine the +'s as the vertices of your mesh. Simply randomize the height of the corner verts (A,B,C,D), then average the mid-verts between these, with a little randomness as well. Keep doing this foreach mid-vert until all your verts are positioned in the z direction. You'll end up with a fairly natural looking terrain. There are all sorts of ways in which you can modify your height algorithm, using various noise and smoothing methods. There's not really any math behind generating a simple terrain mesh. Not until you look at more complex methods, when you're after more interesting results. But you have to be comfortable with generating height maps first. 

To compute the camera size you will only need to scale it down from your maximum camera size if the map is smaller than that size. When scaling, you need to select the smallest dimension of your map, vertically or horizontally, and work out the >1 ratio of width:height or height:width. You want to do this because you always want the graphics to fill the scene-view and the larger of the two dimensions to reach off-screen. Working that out and using it to scale your map will assure that your scene-view is always full. You also want to do a separate bounds check, as Cong Xu mentioned, so your camera follows your character, except the camera's position is bound within a camera safe region. That region will be 1/2 camera width and half camera height in from the edges. Notice that this will need to be recomputed for each map as the camera size will change. 

The manpage for gluLookAt might be of use. That is deprecated now days in OpenGL itself, but glm has an implementation. Then you just use that plus basic trigonometry for working out the X/Y coordinates of the camera. 

It depends if you want to produce finished games or just learn. If you actually want to make a game, making your own game engine from scratch just isn't feasible in any real timeframe unless you have an very narrow, simplified game and even then your still looking at quite a while. Making a 3D game engine from scratch is a huge undertaking. They have heaps of stuff and most of it is complex. Here is a bunch of stuff that a 'game' might contain: 

Then when you render, just run though the list. I have used references above but they could be smart pointers, raw pointers, object handles and so on. EDIT: 

Do you actually need the 3D geometry or just the shape? You can make a 'fake' sphere using a single quad. Just put a circle on it and shade it correctly. This has the advantage that it will have exactly the resolution required regardless of the distance to the camera or resolution. There's a tutorial here. 

You might need to bind your vertex attribute id's to your shader, look at glGetAttribLocation. In your 4.0.0 version you have the layout statement telling it what will be in what id's. The program needs to know that "in_Position" is for attribute 0. It's possible that your implementation will default to using the first attribute as vertex coordinates and the 2nd as color. But it might not either. I'm not sure what the standards say about the default states, it might be up to the implementation or vary depending on what version your context is. Here's the code I use to get a log of the shaders/programs. 

But this doesn't behave as expected. The geometry is a dark red, when it should be white. What the turtle is going on here. 

Isn't it as simple as rendering your gun geometry (or 2d HUD style gun) near the camera and narrow the field of view. 

Well, this is both funny and painful because of how much time I spent trying to resolve this issue. The corruption might have been a clue. I loaded up the program tonight and the issue is non-existent now. It turned out to be a driver issue, because I have just installed the AMD Catalyst 11.10 Preview driver and haven't touched the re-sizing code. That makes sense. :) 

Can I just suggest that you absolutely forget about biomes if you can't make and use height-maps yet. Step by step is the way to go. 

you just have to provide the vertex data, which you've edited during the frame. Maybe even read about dynamic buffers, they might give you even better performance, but I don't know about that yet. edit : Just to clarify, this is SlimDX (DX11) code, so it should translate easily to straight DX11 code. edit2 : And just to answer one of your questions above, you can also have flat geometry and use the vertex shader to shape your terrain, but you still need to get the height data in to your shader. So you can avoid sending new geometry in, but then you have to send a height map in. So you are still updating gfx resources. Which is faster depends upon your vertex and height map formats.. importantly, their data sizes. In my case, the terrain only has Position & Normal, so it's not too large. My UV's are derived from position. And I think by updating the vertex buffer itself, then it's done, and you've got your vertex heights precalculated, rather than having to sample from a heightmap, which does have a cost.