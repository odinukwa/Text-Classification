I am attempting to get Galera replication working between two nodes. I am finding these errors in my innobackup.backup.log file: 

The seconds_behind_master always let me know if I was behind on one of my servers. I am not using galera and am not sure how to verify if everything is up to date. I have come across this article "Monitoring Cluster Status" I realize I can use this command to see how many nodes are in the cluster: 

I wiped out mysql.(Deleted all mariadb packages) Becuase the tablespace was corrupted. I have reinstalled all mariadb packages. I found I was only replicating the zabbix database so I deleted all files in I set this setting as it was . I started mysql. Now I am waiting however long it takes to replicate 3.1TB from my donor node to the joiner. 

This failed to, so I started thinking IO was not at fault. I played around with this command and found this one to complete: 

I have been using mysql master:master replication and was always able to check the status of replication using this command: 

What I have done: I have restarted mysql on the JOINERNODE to apply some database settings including increasing the back_log and query_cache_size settings. What I am seeing: When I start mysql on the JOINERNODE, I see socat launch and listen on port 4444 then stop about 1-2 seconds later. Joiner MYSQL logs: 

I have been working on tuning a mysql database for zabbix for quite some time now. We do not actually have a DBA to assist with this. We have a Zabbix server running 16k values per second. Our database is MariaDB 5.5.38 running galera replication with only two nodes. I will be happy to provide any information needed to assist in tuning. The issues we are seeing is our zabbix graphs are delayed and our dbsyncers are maxed out. According the the Zabbix performance tuning book and zabbix support personnel our database is not able to keep up with the amount of data being sent its way. We have 512GB of RAM on the server, in RAID 10 with SSD's, and 32 Cores at 2.59GHz. The mariadb, zabbix, and apache services are all running on this server. What can I do to increase the performance of this server. It does not seem like the OS is being over utilized based on iostat, vmstat and other OS performance checking tools. Thanks in advance. 

I am not sure where to do from here, I have googled a bit and didn't find anything that seemed like it could help me in my particular instance. Any advice will be most appreciated. 

BUT, I am starting the service using command so I want to know what all options are used by default when we start the service using ? ESP, is --log-error used? 

I want to run two MySQL instances on the same machine. The reason behind this is, I will be needing two databases with entirely different configurations. The specifics of the configuration of the both the DB are as follows, Fault tolerant, high-intensity IOPS, RAID 10. Highly available, Low-intensity IOPS, RAID 1. This two instance will have separate HA policies. Currently, I am only installing once and running the first instance using systemdctl whereas I am running the second instance manually using separate cnf files. So now, how can I install and run two separate instances of MySQL on same machine? DO I need to create separate instances of the MySQL-server binaries for both instances? And do I need to install MySQL-server RPM for a second time into an alternate folder? If yes, then how? I also want to understand the implication of using the single binary for running two instances. Does it affect the other instance in any way during recovery process or any other db intensive task? My mysql version would be 5.6.34 I have gone through this link($URL$ for installation of multiple instances on single machine but this support is enabled from 5.7.7 version whereas I am using 5.6.34. 

My mariadb configuration in my.cnf is not getting loaded for and . I have checked other configurations params are loaded. 

So, I want to know do we have any default location where these logs are getting generated, if the path cannot be read from config files. Update: After some investigation, I found this information, Reference: $URL$ 

I do not understand why I am getting this issue because that table was initially present. Could it be a chance that fs corruption has eated up this file and corrupted it's .frm or .myi file? What does the error mean, warning : Duplicate key for record at 10536347 against record at 10523110 

I am also observing the same issues, I would suggest to please check the permissions to the mentioned path of my.cnf and the path mentioned by my.cnf. 

Activating the Error Log The error log is active by default. The log-error=filename option determines where the output will be written. If no file name is specified, the log will be written to host-name.err. If no absolute path is specified, the file will be written to the data directory (determined by the value of the datadir system variable). On Unix systems, if the --log-error option is not used, the errors are written to stderr (usually, the command line). On Windows, if the --console option is specified, and --log-error is not used, the errors are written to the console. If --log-error is present, --console is ignored. So now I understand that due to some reason the configuration log_error in my.cnf is not considered. So as per the suggestion, on Unix system, if --log-error is not used, logs are redirected to stdout. 

I then queried the TEST database with the Windows login DOMAIN\USER. Because the DOMAIN\USER is also memmber of DOMAIN\GROUP the user is allowed to SELECT from all tables in the TEST database. You are writing that the DOMAIN\USER is unable to select any data. Correct? Do you have any orphaned users on the database level? Follow these steps to check. 

Reference: Creating and Modifying PRIMARY KEY Constraints (Technet) Solution You will have to drop the existing constraints (FK and PK) and/or indexes to create the solution you are aiming for. This can be observed by reading the following articles: 

Advanced SSMS Connection Properties window In the Network section of the Connection Properties change the Network Protocol to TCP/IP. Advanced SSMS Connection Properties window recommendations Your connection window should look like this: 

This will create a new value (ID). You would have to store this value in your program code to use when assigning players to the table. 

Additional information in response to comment: Transaction Log backup was performed with the option TRUNCATE_ONLY - when this happens, is there any way to know this by T-SQL query Backing Up Transaction Log With Truncate_only In previous versions of SQL Server prior to SQL Server 2008 you could use the following statement: 

SQL Server will then use this policy if the option is checked. A technical overview of the account lockout policy can be found here: Reference: Account Lockout Policy Technical Overview (MSDN) Reference: Account lockout threshold (MSDN) Locked out SQL Login Here is what happens after a SQL Login has been locked out after the set amount of incorrect logins (15 in my case as domain policy). You can see the is set. This can be unset to unblock the account. 

References: - Statistics (Microsoft Docs) - SQL Server Statistics: Explained (Microsoft Developer Blogs) The document then goes on to explain the algorithms for SQL Server 2014 and older: 

Size column in sys.master_files There is a delay in the size reported in sys.master_files according to the MSDN article sys.master_files (Transact-SQL) 

Reference: The Ascending Key Problem In Fact Tables â€“Part Two: Stat Job! Situation at hand However, your situation does not look like you want to deceive the query optimizer, but to just recreate the system generated statistics on your migrated table. Now because you have modified a large amount of data, by deleting the records you no longer require, you are possibly invalidating the value that you retrieved from the original table. Solutions Option 1 Instead of trying to fill the system generated statistics with "fake" values that don't seem to work, why not just create new statistics for the columns that have had automatic statistics created for them? You would just take your individual statements and instead of using the system generated name, replace it with a user defined name: