If I understood well you want to delegate the DNS from your registar to your own DNS server. So yes it is possible you just have to tell your registar to point to it. You will need to add an NS record and a A record to point to your server and server's IP address And so you'll will be the authoritative DNS server for your zone. It should look like this: registar: example.com. IN NS ns1.example.com. example.com. IN NS ns2.example.com. ns1.example.com. IN A 0.0.0.0 ;; ip of ns server is needed because it's the only way for everbody ns2.example.com. IN A 0.0.0.0 ;; to know where you are You: example.com. IN SOA ( ;;; soa blargh!! As it means Start Of Authority you are the one ) example.com. IN NS ns1.example.com. example.com. IN NS ns2.example.com. a.ramdom.host.example.com. IN A 0.0.0.0 ;; ip of a random host 

First what would you install apt instead of having yum? And second you'll need to find a source to had to yum so it can install apt, but because the two programs (apt and yum) are doing the same job but on different platform I don't think you will find one. So I think you'll need to build apt from source (see on Source Forge). 

When you add an IP address to a specific interface (let it be by DHCP or manually with ifconfig), linux kernel will add this IP's subnet's route as being on that specific interface. This is because logically you are part of the subnet. Possible issues would be: 

auditd is a good utility to know what have been done to every file. It might not be what you need tough. 

Yes it's possible to do so put a htaccess in the file you want to moderate the access. Put the same text as in the configuration file. Make sure that your conf files will read .htaccess. 

You can install a RAID volume utility that will do the mirroring during runtime, but to get there you'll need to copy the entire disk (not only files but the whole disk in raw like with dd command in unix). 

So I would check if your receiving end has any delay to fetch mail or that the server that receives the mail did not put in a long anti-spam check. I would pull out the logs from your mail server at that moment to see what happened wrong. If the header is right you should look at 2015-09-08 03:19 -0600 (your servers local time). 

I am using Windows Server 2012 R2, and after it reboots I absolutely need to connect to it in local or else it will not allow any connections (RDP, shared folders). What is the option (local or group policy) to allow connection without needing one to connect to it in person. 

An apple's airport express can do do the job as well as any other wireless router. You'll need to configure the router in a browser type: 192.168.1.1 or 192.168.0.1 and follow what you need to. 

It's not not secure from people sniffing the network. Just think about it when user need to connect there javascript hashes their password and send them to the server. The server compares it to the database. A sniffer would only have to sniff the password and send it to the server so this is as secure as clear text password. As others said I recommend SSL/TLS tunnels to be establish to connect to your server. 

I want to place a VPN beetween home and school because I do not trust the network down there. If I configure the VPN server with NAT-T (nat-traversal) and configure my router to foward UDP 20 -> UDP 500 && UDP 21 -> 4500 (I also configure the client to use UDP 20 for IKE and 21 for NAT-t) will the configuration works? And is IKE mandatory in order to ipsec to function? 

Context switch are normal. A process is assigned to an quanta of time, if it finish (or it paused caused by the need of ressources) what it have to do it can let the processor go. That said to count how many context switch are done (it becomes a stackoverflow.com answers) it would take the internal kernel schedule() command to write into the processes tables. A there is no such thing if you program your own kernel you'll be able to see but it's quite difficult. 

your php app will be the bottleneck with all 3 choices. I have setup multi-billion hit sites fine with apache. 

$URL$ Depending on which window manager you are using, you can either to to Applications --> Add/Remove Software Or from a shell type "system-config-packages". If you get "command not found", then you would first have to run yum install system-config-packages 

in the httpd.conf file, if you have your CustomLog set to "combined" (which includes %I and %O for in/out sizes) then it tells you the size of each request. to get all in/out, run: 

Here is a writeup of the capacity service. Essentially it keeps track of things like data growth over time, transactions per second growth, etc. It then tries to come up with a trend: $URL$ Sadly this is more of a "for management" metric though and usually does not mean anything. It just takes one new app/script/etc added into the environment to make all the trends invalid. At least that has been my experience. 

this seems like a silly question... "I need to use a database, but I refuse to use a database..." use one or don't. not really sure why you hate databases.. then are really simple, stable, and work with every language. You could go for something like hadoop and hive/pig, but that is WAY more then you are looking for and far more complicated the mysql. You need to give more info as to: 1) what you are trying to do 2) the data set sizes involved 3) the usage patterns that this will be hit with 

Add this to your java_opts: "-XX:+UseConcMarkSweepGC" This is a multi threaded GC that works much better under high load. 

So this appeared to be a kernel bug in 64bit Centos 5.4 AND 64bit Fedora 14. After I installed Centos 5.5, then problem went away. Sorry I dont have a better answer for everyone... 

If you have mail setup, you use mailx to send out email from a script... my-backup-script.sh | mailx -s "results from backups" myemail@myhost.com echo "just a test" | mailx -s "please ignore this" myemail@myhost.com cat << EOF | mailx -s "more tests" myemail@myhost.com this is a long test of email in a shell script EOF 

openvpn works great for this situation. You just generate a cert for each user (with the provided shell scripts). You can either do pem certs that don't need a passwd to connect, or require a passwd). if it is just 10 people, then a radius server is way overblown. Any modern machine would suffice. EDIT: not 100% sure how they could change their passwd on their own. 

you would just have a rolling 7 day window of configs routerx.1, routerx.2, .. routerx.7 Above is a very simplified example, but this is mostly what I do. I actually have a "config-backup.sh" and a "config-restore.sh". Each script takes the params of a filename filled with the device names and the second parameter is the date in "YYYYMMDD". If it is a backup, it appends the date to the config filename. If it is a restore, it tells to devices to load "$HOST.$DATE". I run the backups out of cron. With this I can very easily restore anything just with SSH from my phone. 

Short Version: Is replication from 5.5 master to a 5.1 slave possible? Long Version: We did a large scale upgrade from 5.0 to 5.5. It was a long process if dumping the 400gb dbs and importing them into 5.5. 5.5 replication seems to be completely broken. The masters consistently hang, the slaves keep dis/reconnecting and leaving stale binlog_dump connections (visible from show processlist). The master hangs on shutdown until I have to kill when shutdown "gives up" after an hour. Lastly it gets this type error daily "110423 13:55:48 [ERROR] Slave SQL: Could not execute Delete_rows event on table prod.site_iplist; Can't find record in 'site_iplist', Error_code: 1032; handler error HA_ERR_KEY_NOT_FOUND; the event's master log mysql-bin.000385, end_log_pos 65644796, Error_code: 1032" which is a bug that is will be fixed in 5.5.12. This has been very disappointing, as our 5.0 setup ran fine for 3 years. Anyhow, I am looking to move to 5.1.56 (which has at least 56 updates to a stable product). The problem is that all my databases are 5.5 now. Is it possible to have a 5.5 master and a 5.1 slave? The migration process being to import the db into 5.1 and then enable replication, fail everyone over to 5.1 once it is synced up, and then downgrade all the other 5.5 servers while everyone is on the 5.1 db. Will 5.5 master --> 5.1 slave work at all? If so, will it work with the current MIXED mode replication? Would I have to change that to be statement only? Thanks! 

No I checked at the man page of netstat and there is no way of knowing the time of an established connection using netstat. And I don't think it is stored anywhere because connection are so dynamic. 

For some reason those cmdlet are availible using the 64 bit version of powershell. It is shown as Windows PowerShell in the menu, without the trailling (x86). If it is not shown in the applications menu just search for it. You should then have access to the cmdlet for deduplication. 

As shown in the email and assuming all relay actually appended a Received: field. The mail was properly received by your bluehost server on 03:19:55 -0600 within seconds of being sent. As shown by line: 

Normally it will be an unsigned 32 bit (on 32-bit system) so 2^32 = 4294967296. So the range is 0-4294967295. 

It seems to be an client problem why it's declining the address. Is it well configured to use a DHCP address. Try runing dhclient manually. 

I accidently create a "\" file into my linux how to revert it. I tried rm \ (as it's the escaping character it didn't work), rm '\' and rm \\ nothing worked. 

If you run bash yo can edit /etc/profile and /etc/bashrc. They are analog to the user ~/.profile and ~/.bashrc. So put all your common vars in /etc and user more specifc in ~/. 

What I find strange is it that client's routing tables are pointing to nowhere (0.0.0.0). It is ok for local networks but for 10.2.10.1 that passes trough a tunnel it might be a problem. 

Try to see documentation about iptables there should be some config about caping bandwith. But on the other end you should try to configure iptables to ban bad IPs so it will clear the problem and also you will be able to report IPs and time of the attack to authorities. 

In grub legacy it uses exclusively menu.lst. In grub2 grub.cfg which you should never modify by your self. If I recall correctly there are commands called grub2-install and update-grub2 on debian that will configure grub.cfg. 

I am trying to follow this procedure to add a registry key to all my domains computer. The thing is that I don't see anything under: 

It seems that the return path for the packets is not known. To be sure you would need to check intermediate routes, I'll get to that in the end. When you ping 10.10.3.50 from the 10.10.2.0/24 host it is forwarded your default gateway (lets assume 10.10.2.1), then itself checks its own routing table and sees the route for 10.10.3.0/24 via 10.10.1.5. A ICMP redirect can normally be ignored since its purpose is only to shorten hops needed and router load. But it is sent because its seems that the next hop is on the same physical net as the request cames from. But what you should check is wheter or not the 10.10.3.0/24 router as a route for the source subnet 10.10.2.0/24. 

The problem with well constructed rootkit is that they modify your system's command; like ps and top to not show the processes of the rootkit and ls to not show files of the rootkit. So what you'll need to do is to get these command possibly from source or in binairies form. (Be sure to be well signed). But the trick of a root kit (I've seen it) is that they maybe corrupted your compiler too. So when the compiler knows he is compiling ls or ps or any command he infectet them as well. When I saw this problem I said fine lets recompile gcc, but no what I need to have to compile gcc...the infecte gcc....so when he knows he is compiling itself he infect it so it can infect the command. You will say that this come big and difficult to detect, yes but rare are the root kit that are so bulletproof I just gave youthe worse case. Seriously, if you are sure that there is a root kit in your server, reinstall it! 

I not sure to what you want to install both apache version on your server. It is like you want the brand new model of car and the old one too. There is no reason you can not install it but there will be a problem if they try to serve on the same port (80) as on will block the other. But if you configure them on different port it will work. Again I don't know why you want to do this.