Educated guess: The on AS5500 that IMO should not be there. Edge-Type ports are for the edge: PCs, printers, servers etc. Never another bridge/switch. I suspect that it has some influence on how the switches treat untagged traffic. Since VLAN1 is often being used as the default ("native") VLAN, frames from VLAN1 are usually sent without tags. What if one switch tags them, but the other doesn't, or expects them to be tagged, and drops incoming untagged frames, or maps untagged frames to another VLAN? There might also be a difference in default behaviour w/regards to tagged/untagged frames of the two different switch models - you'll have to consult documentation to find out. 

As long as you go down the VLAN/SVI path with that switching module, AND as long as you can get along with the restrictions they impose, you can use them for most purposes of routing. A few things that don't work well (or at all) with the VLAN/Switchport/SVI combination, in no particular order: 

Is there an actual difference between a CRC error and a FCS error? After reading a lot, they seem like the same thing, but most switches and readings refer to them as separate entities. Is there an overlap of these counters on a switch interface? 

I am trying to grasp the idea of how a switch communicates. Does a layer 2 switch require the entire stack to do it's job, same for layer 3? If a switch can support SNMP which sits on top of UDP, it must have a full stack? I believe most switches have some type of network operating system if any at all, so it is hard to understand what a switch actually entails. 

If UDP and/or TCP send packets via IP to an Internet Protocol Address, how can a layer-2 switch forward these? Is this possible or do you need a layer-3 switch? 

That is a must-have when running PPPoE, each IP packet on interface FastEthernet4 will get an additional PPPoE header of 8 bytes, so you want to reduce MTU for interface dialer 0. 

The ppp ipcp route default from the dialer0 interface will install a route with administrative distance 1, overriding the above one while the PPPoE session is up. 6. LAN interface, DNS and DHCP The 881 has an integrated 4-port switch which you need to treat as such. You cannot assign IP adresses to its individual interfaces, but you need a VLAN and an SVI ("interface vlan") to go along with it. In this case, we'll use 192.168.10.0 and VLAN10 as internal network. Adapt accordingly to fit your network situation. 

If an Ethernet link is up on my end, does it necessarily mean the computer on the other end is alive and I can talk to him? Or does it mean that my PHY is just ready to send data onto the medium? I know there are various ways to check "link state" and that there are operational vs administrative states of an interface. 

I am trying to understand the purpose of a VLAN aware NIC on a server or work station? I was under the impression a switch does most of the work when it comes to VLANs. Is this another way of filtering traffic? Or does the NIC receive the traffic regardless? 

What are the trade-offs/major differences of Ethernet Flow Control vs Quality of Service? How to know when to choose one over the other? They seem to both be a solution for congestion. The obvious downfall of flow control seems to be, that it can congest the switch itself. There are no priorities assigned to traffic, therefore the switch buffers can fill in a hurry. 

NVI NAT's already been brought up by Aaron D. Here's a the relevant config bits of a working example. It's been done on a CISCO881 with IOS 15.4(3)M6a 

These tests should help to establish if VLAN1's broadcast domain is actually "going throgh" across both switches. My suspicion is that it is not. I spotted a difference in your config: AS5500: 

Disclaimer: I am not suggesting to add any form of redistribution of internal routing information to an eBGP peering to an ISP. Please make sure that you know exactly what you are doing (and why), if you consider doing this. To answer your concerns about the eBGP peers not being directly connected: In that case, the stability of the adjacency is your concern, not BGP route dampening. There's ways to tune or help BGP a bit to allow for faster detection of connectivity issues between peers: $URL$ $URL$ , Section "BGP Fast Peering Session Deactivation" The best option might be to talk to your ISP and ask them if BFD based BGP peering is available, or (big style) what kind of redundancy options they have on offer. 

I am looking for a common MIB that supports checking of crc errors, does this depend on hardware vendor and a custom MIB like CISCO? 

If a layer 2 managed switch supports management functions and entails a "management plan" it must require an OS. If it is a typical network operating system, *nix based, does is have a full file system? Would I be able to write an application and run it on the cpu of the switch? 

I have a network with roughly 50 machines all on one LAN, consisting of Linux, Windows, and server machines. I have an untangled u150 firewall/router. I have the ability to add an additional WAN & LAN port to get more bandwidth. What is the best way for all machines internally to stay on the same LAN, yet gain the additional bandwidth? Part I am struggling with. If I assign the LAN ports 10.20.30.1 & and 10.20.30.2, everything will work I believe, but I manually have to then set the default gateway on machines to one or the other. Is this true, or am I not thinking about this correctly? 

proxy-arp is a networking black witch I will personally burn at the stake whenever I come across her. Her magic is only needed in dark corner cases - leave it disabled, unless you really, really, need it. However, ip unreachables are a blessing when it comes to reduced-MTU links as in your case. They make sure that the router can inform a host to send smaller packets - especially for UDP applications; TCP is taken care of by ip tcp adjust-mss. Unfortunately, not all hosts will respect or understand these "packet too big" messages, but that's their problem. ip verify unicast reverse-path is good best practice, it prevents ip source address spoofing, by allowing only those source address ranges (incoming) on an interface for which a route exits in the reverse direction through that same interface. That makes it harder for your internal systems to be part of a bot army working with spoofed source adresses. 

Do standard NICs that support IPv6 have the ability to perform MLD? Essentially I understand MLD, but am struggling to find if it needs to be configured or if it is enabled by default on a host. Just want to understand how a host sends a Multicast Listener Report. Does it happen automatically when a Multicast Listener query is sent by the router/switch? 

As a UDP segment traverses down the stack, each layer adds a header. What occurs for this to happen? Does the kernel do a bunch stuff then add the header? I am particularly interested in the transition from the network to data-link layer on an Ethernet system. Is ARP performed and then the cache searched in order to provide the next hope information? 

To me, this looks perfectly normal. I don't think that these captures are identical. Looking at the TCP headers of the the first frame (TCP SYN), you can see that - although all other properties are identical - the sequence numbers are different. EDIT: Oh.. there is also MSS clamping going on - ASA rewrites the MSS field from 1460 to 1380, on both the SYN segment from the initiator and the SYN-ACK segment from the responder. I think this is ASA's TCP sequence number randomization at work. EDIT: And the ASA performs some TCP MSS manipulation, too. Other than that, I would sincerely hope that all other properties of the frame/packet are unchanged when it is incoming through one of the port channel's subifs and exiting through the other (give or take NAT rewriting things a bit here and there, but NAT is quite obviously not in use here). 

How does the /sys/class/net/ethx/carrier field get set? I am trying to understand this field as it determines if a network cable is plugged in, but I am curious how it knows. This is specifically in regards to 10Gbase-KR and 1Gbase-KX. I have a little knowledge in regards to CMSA/CD, but that is only for half duplex and NPL - pulses are for auto negotiation. Is something going across the medium when no traffic is being sent? I believe it may have to do with IDLE symbols, but I do not fully understand them. 

If I want to send an IPv6 UDP multicast message, how does L3 to L2 address resolution occur? I think I understand ARP and how this same idea applies to unicast, but I am struggling to grasp the idea of how it works for multicast. I am aware of MLD and NDP, but not sure how they come into play with my question. 

Caution: NVI NAT can be VERY taxing on the CPU of low-end routers like the 800 series. Where my old 881 used to be able to deliver 50-60Mbit/s with classic NAT, switching over to NVI caused the throughput to drop to 20-30Mbit/s and would have the CPU glowing red when under load. That was also the case when the to-be-hairpinned translation was not actually in use, just with traffic matching the normal "interface ... overload" outbound NAT rule. 

8. other clever bits to have There's some clever config bits here and there, and I'll comment them here 

Hint: If anyhow possible, stay away from the "1" numbers for dialer pools and dialer lists, even more so when access list numbers come into play ("access list 1 permit ...") on top of that. It makes the configuration confusing to read, especially to the novice. I have no clue why Cisco's examples and documentation stick to that numbering style. By all means, do prefer named items (e.g. in ACLs) or pick "random" numbers that can easily be matched by a human reader, even when they're dozens or hundreds of lines away from each other in a config file.