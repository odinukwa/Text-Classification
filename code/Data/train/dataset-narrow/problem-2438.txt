The graph isomorphism problem is in NP but not known to be in P or NP-complete. A generalization, the subgraph isomorphism problem, is NP-complete since asking if some subgraph of the input graph with $n$ vertices is isomorphic to a cycle of length $n$ is the Hamiltonian cycle problem. 

In the anti-ferromagnetic region of the Ising model, the computation complexity of approximating counting depends on the Gibbs measure over infinite $d$-regular trees. The Gibbs measure on these infinite $d$-regular trees undergoes a phase transition on a line called the uniqueness threshold. On one side of the threshold, the Ising model is hard to approximate. On the other side of the threshold, the Ising model is easy to approximate. The complexity of the Ising model along the uniqueness threshold is currently an open problem, but the conjecture is that it is tractable. The most recent result in this line of work is by Sly an Sun. See their references for other related works. 

This is not an answer, just a long comment. First, you say that you are unsure if this problem in in #P. It depends on how you define your input, which can either be the $n$-by-$n$ graph or just $n$. I would say that it is more natural to take the graph as input, in which case, an NP machine can guess $n^2$ bits (which is a polynomial, linear even, in the size of the input) and can check in polynomial time, linear even, if all your constraints are satisfied. If the input is just $n$, then $n^2$ is exponentially larger than the input size $\log(n)$, so we can't say your problem is in #P, but it is in the counting class related to NEXP (in the same way that #P is the counting class related to NP). Second, this input issue also affects what types of hardness we can expect to prove. If the input is the grid graph, then you have at most one input for each input length. Such problems are said to be sparse (which means there is at most a polynomial number of inputs for each input length) and are not expected to be hard by (a generalization of) Mahaney's theorem. But if you pick $n$ to be your input so that set of instances is no longer sparse, then your output is exponentially larger than your input. What I am trying to say here is that the typical notions of hardness don't apply very well to your problem. Third, I can say something about the possibility of this problem being tractable. My research is in counting problems defined by local constraints, which we formally define as Holant problems. The difference between Holant problems and your problem is that we don't put such tight restrictions on the inputs graphs. We allow restrictions like planar, bipartie, and prescribed degree (such at $k$-regular or at most degree $k$), none of which defines a sparse set of graphs. The best I can do to cast your problem as a Holant problem is as follows. For omitted definitions, see the preliminary section in a recent paper of mine. In the Holant framework, edges take values from a finite domain and vertices impose constraints on the values assigned to its incident edges. To (partially) model your problem, we consider the Boolean domain $\{0,1\}$. As a first attempt to capture your problem, think of an $n$-by-$n$ grid graph as the input. To associate a bit with each vertex $v$, we add an edge $e_v$ incident $v$ and to a new vertex $u_v$. To communicate this bit value to the neighboring internal vertices, we duplicate all the edges between internal vertices (i.e. vertices not on the boundary) in the original $n$-by-$n$ grid graph. The vertices on the boundary have no constraint, which is represented by the signature $[1,1]$ tensored with itself twice for the corner vertices and three times for the vertices on the sides. The remaining interior vertices pick an edge in each direction and require these four edges and the other edge added above (with its associated bit) to take the same value. Then we impose your constraint by comparing this value with the four values assigned to the remaining four edges (one edge in each direction). Of course, between each pair of internal vertices, they have to agree on which edge each uses to communicate their bit value. One way to decide this, in a planar embedding of this graph, is that each vertex should use the edge that is encountered first in a clockwise traversal of its incident edges. The paper of mine that I linked to above is a dichotomy for Holant problems that use symmetric signatures (which means that the output is invariant under any permutation of the input). Unfortunately, the constraint that I used to capture your problem at internal vertices is not symmetric and it is still an open problem to prove the generalization of that dichotomy for general (i.e. not necessarily symmetric) signatures. Worse yet, we currently do not even know how to decide if this Holant problem is easy or hard according to what we conjecture the dichotomy to be. Furthermore, we can impose restrictions on the input graphs like being planar and bipartite that are satisfied by your grid graph, the hope being that this Holant problem may become tractable under these restrictions. However, a dichotomy for such Holant problems is years, maybe even a decade away. In closing, let me emphasize that this Holant problem that I have described is "more difficult" than your problem (when the input is the grid graph). The input to this (planar, bipartite) Holant problem can only use the complicated arity 9 constraint (that was assigned to the internal vertices) and the (unconstraining) unary constraint $[1,1]$ but the graph is not restricted to grid graphs. Formally speaking, your problem (when the input is the grid graph) reduces to this Holant problem. So, if this Holant problem were easy, then your problem (when the input is the grid graph) is easy too, but if this Holant problem is hard, then I want to say that your problem is hard, but I don't know how to do so (as I discussed above). 

To supplement the answer from @RJK, as of yesterday, there is a new "state of the art." Sly and Sun show 

I used a Gröbner basis to help find a short proof of a new dichotomy theorem for #CSP problems over 3-regular graphs with a single binary constraint function that has complex weights (arXiv version). There is natural equivalence relation over the set of constraint functions, namely, $f \sim g$ if $\#\operatorname{CSP}(f) = \#\operatorname{CSP}(g)$ for all possible instance graphs. For 3-regular graphs, there are fewer equivalence classes than would otherwise exist over all possible graphs. Since a dichotomy theorem only needs to prove the complexity of one constrain function in each equivalence class, this leads to a shorter proof. The Gröbner basis is used to convert from the initial four variables needed to define a binary function to six "symmetrized variables" that are invariant in each equivalence class (see section D of the paper linked above). However, the Gröbner basis is not mentioned in the paper since its only purpose was the automated transformation from the initial four variables to the six symmetrized variables in various polynomials (which was preformed by Mathematica's GroebnerBasis). 

This conjecture implies that the complexity of their algorithm is $O(k^{2/3} \log^{2/3} k)$. I addition to just "feeling" that this conjecture should be true, I have "checked it" for 19 (small) pairs of $k$ and $\ell$ with $k \le 8$ and $\ell \le 6$ in the sense that I computed the spectra for those small graphs, conjectured a pattern for the relevant eigenvalues based on those spectra, and then (easily) showed that the above conjecture is true. Does anyone know how to prove this conjecture? 

Let $X$ denote a (decision) problem in NP and let #$X$ denote its counting version. Under what conditions is it known that "X is NP-complete" $\implies$ "#X is #P-complete"? Of course the existence of a parsimonious reduction is one such condition, but this is obvious and the only such condition of which I am aware. The ultimate goal would be to show that no condition is needed. Formally speaking, one should start with the counting problem #$X$ defined by a function $f : \{0,1\}^* \to \mathbb{N}$ and then define the decision problem $X$ on an input string $s$ as $f(s) \ne 0$? 

I agree with the arguments for shorter variable names on the math.se question, but I disagree that "the pros of shorter names seem to apply more to TCS than those of longer names". In particular, I don't think the best argument there (which follows) applies here. 

I think you can use fully homomorphic encryption to solve this problem. Encrypt the program and data using a fully homomorphic encryption scheme, send it to the system to be processed, and retrieve the result. Let the correct output be the string $s$. Since you say that you might not be able to tell if $s$ is the correct output, I would have the program concatenate a prefix which you can verify. Something like: 

For the purposes of counting dichotomy theorems, the two relevant classes of decision problems are $\text{P}$ and $\text{P}^{\#\text{P}}$. 

This is not in NP, but comparison-based sorting. The $\Omega(n \log n)$ lower bound is information theoretic. 

For an example of the second type of edge, consider $k = \ell = 3$. Then the vertices $(1, 2, 3)$ and $(1, 3, 2)$ would be connected by such an edge. For given natural numbers $k$, and $\ell$, let $G(k, \ell)$ denote this graph with parameters $k$ and $\ell$. The analysis in the paper shows that the absolute spectral gap of $G(k, \ell)$ is $\Omega(\frac{1}{\ell \log \ell})$. I think the analysis of this absolute spectral gap can be improved to $\Omega(\frac{1}{\ell})$. 

If the system made a mistake (or tried to cheat by not executing your program exactly), I am sure you could prove that with high probability (under standard complexity-theoretic assumptions), the decrypted output would not begin with 

The eigenvalues of the m-by-n rectangle graph can be used to obtain an expression for the number of perfect matchings in such graphs. See the Wikipedia article on domino tilings. 

the Hamming distance between them is 1 or the Hamming distance between them is 2 and, after swapping the elements (in one of the vertices) in the two locations in which they differ, the Hamming distance between them is 0 (i.e., they are the same vertex). 

This argument works when the definition is generic, like "n is a number", but not when the definition is quite specific, like "BPP is the class of languages for which there exists a probabilistic Turing machine that runs in polynomial time and outputs 1 with probability greater than 2/3 for all inputs in the language and outputs 1 with probability less than 1/3 for all inputs not in the language". Sure, if I am dealing with a situation where I DO want to forget the complexity class, then I will use a single letter variable name, like using $\mathcal{C}^L$ to define the relativization of $\mathcal{C}$ with oracle language $L$. But as long as you are working with BPP specifically, I think that it is helpful that the name reminds you that you are working with Polynomial-time Probabilistic (Turing) machines with Bounded error (as opposed to the class of languages that without Bounded error, PP, and the class of languages that is also not based on Probabilistic Turing machines, P). When we use BPP, we really do want to remember what the variable represents. If this were not the case, then I would not expect everyone to use BPP to denote the above class of languages. 

Another example of $\varphi$ in the base is an algorithm by Andreas Björklund and Thore Husfeldt to compute the parity of the number of directed Hamiltonian cycles, which runs in time $O(\varphi^n)$. $URL$ 

Scott Aaronson just reported that the Complexity Zoo is down because the graduate student that was hosting it has graduated. To get the Complexity Zoo working again, we need someone to host and a copy of the site. 

Given a $k$-colorable graph $G$ and vertices $u$ and $v$ of $G$, what is the complexity of deciding if every $k$-coloring of $G$ must assign the same color to both $u$ and $v$? It does not seem obvious to me how to use the above problem as an oracle to construct a coloring, so it is conceivable that this problem is efficiently decidable. On the other hand, minor variants of NP-hard problems, such as this one, typically remain NP-hard. But most of all, I do not know what problem is a good choice to reduce from. Any thoughts? 

Xi Chen published a survey as a guest column for SIGACT News in late 2011. It discusses the results and techniques leading up to and including his papers with Jin-Yi Cai and Pinyan Lu on dichotomies for counting graph homomorphisms defined by an undirected target graph with complex weights (arXiv) and nonnegatively-weighted #CSPs (arXiv). At about the same time, Cai and Chen published a dichotomy for complex-weighted #CSPs (arXiv), which Cai discussed in a guest post on the Godel's Lost Letter and P=NP blog. 

Another framework of counting problems comes from computing the Tutte polynomial of a graph. In this framework, any two complex numbers defines a counting problem. The book Matroid Applications devotes chapter 6 to The Tutte Polynomial and Its Applications. The previous link is to a scan of that chapter from the website of James Oxley, one of the coauthors. Last semester, he taught a course based on that chapter. Another good reference on this topic is this survey-like paper by Welsh. 

Normally an unweighted #CSP problem is defined by a set of relations $\Gamma$ and the input to the problem #CSP($\Gamma$) is a formula $\Phi$. If $\Gamma$ only contains relations of arity at most 1, then every possible input $\Phi$ correspondes to a graph with disjoint star graphs, which is planar. Furhtermore, if $\Gamma$ contains a relation of arity 2 or more, then it is easy to construt instantces that are not planar. (Think of the variables as the vertices of a graph and binary constraints as edges between these variables vertices. Higher arity contains also work. In this way, any graph can be constructed, as least as a subgraph of another graph.) In constrast, you are ignoring $\Gamma$ and directly asking about which $\Phi$ lead to planar graphs. However, each $\Phi$ defines a (unique) graph. There is no uncertianity as you suggest in this paragraph: 

For simplicity, let's restrict ourselves to $k$-regular graphs. The first part of your update is correct. Changing notation slightly from what you have introduced, let me define $n_e$ (resp. $n_o$) to be the number even (resp. odd) edge-induced subgraphs of a given graph $G$. For the (arity $k$) signature $f = [1, -1, -1, \dotsc, -1]$, the Holant problem Holant($f$) does indeed correspond to the problem "Given a graph, compute $n_e - n_o$." To see this, fix a subset of edges $E'$ (i.e. the subset of edges assigned 1) and consider a vertex $v$. If none of the incident edges of $v$ are in $E'$, then $v$ is not in the edge-induced subgraph defined by $E'$ and the constraint at $v$ contributes a factor of 1 to the weight of $E'$. Otherwise, some incident edge of $v$ is in $E'$, then $v$ is in the edge-induced subgraph defined by $E'$ and the constraint at $v$ contributes a $-1$ to the weight of $E'$. Summing over the weights of all subsets of the edges gives $n_e - n_o$. Since $n_e + n_o = 2^{|E(G)|}$, we could solve for $n_e$ and $n_o$ if we could knew $n_e - n_o$. The second part of your update is incorrect. The $k$-ary signature $f = [1, -1, -1, \dotsc, -1]$ is not affine for $k \ge 3$. For a (rather explicit) list of the affine signatures, see page 7 of this paper. For $k \ge 3$, this signature defines a #P-hard Holant problem. To determine the complexity of this problem, notice that $f$ has the tensor rank 2 decomposition $f = 2 [1, 0]^{\otimes k} - [1,1]^{\otimes k}$. Let $\omega_{2k}$ be a $2k$th primitive root of unity. Then $f = [\sqrt[k]{2}, 0]^{\otimes k} + [\omega_{2k},\omega_{2k}]^{\otimes k}$. Under a holographic transformation by the inverse of $M = \begin{bmatrix} \sqrt[k]{2} & \omega_{2k} \\ 0 & \omega_{2k} \end{bmatrix}$, we have the bipartite Holant problem $\operatorname{Holant}([\sqrt[k]{4}, \omega_{2k} \sqrt[k]{2}, 2 \omega_{2k}^2] | =_k)$. This problem is #P-hard by Theorem 22 in this paper, even when also restricting to planar graphs. For $k \le 2$, $f$ is actually affine, so the problem is tractable, but it is also tractable for a much simpler reason as well. Any Holant problem using only constraints of arity at most 2 is tractable using matrix product and trace.