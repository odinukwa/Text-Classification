In here on page $13$ proposition $1$ it says 'If $CIRCUIT$ $SAT$ on $n$ inputs and $m$ gates is in $2^{n^{o(1)}}poly(m)$ time, then $EXP\not\subseteq P/poly$'. 

I found an answer to original query of whether positive decomposition rank and $0/1$ decomposition rank over reals have large gap that holds for partial matrices. Theorem 1.1 in $URL$ says the gap can be at least subexponential. 

We have $EXP\not\subseteq P/poly\implies BPP\subseteq io-DTIME(2^{n^\epsilon})$ at every $\epsilon>0$. This is essentially $DTIME(2^{O(n)})\not\subseteq P/poly\implies BPP\subseteq io-DTIME(2^{n^\epsilon})$ at every $\epsilon>0$. Is there any consequence of a stronger derandomization? Let $a(n)$ be any time constructible superpolynomial. 

A new paper came out claiming quasi-polynomial algorithm for Discrete Logarithm. $URL$ If correct, does it mean we no longer have an exponential separation in complexity of a classical algorithm and its quantum version for the discrete logarithm problem? Does this have any implication for quantum complexity theory? 

We suspect following relation: $$TC^0\subsetneq NC^1\subsetneq L\subsetneq NL\subsetneq AC^1\subsetneq NC^2\subsetneq P\subsetneq NP\subsetneq PH\subsetneq PSPACE$$ in Turing/boolean circuit complexity model. What are analogous complexity classes in BSS model and Valiant's arithmetic complexity model? What are known relations and implications among complexity classes in these models? What surprise would counter intuitive results such as $P=NP$ have on these hierachies and vice versa? 

Let $x_1,x_2,\dots x_n$ be literals. Let $P(x_1,x_2,\dots,x_n)$ be the parity function. What is the smallest degree of $f(x_1,x_2,\dots,x_n)\in \mathbb R[x_1,x_2,\dots,x_n]$ that represents $P(x_1,x_2,\dots,x_n)$ (where represents means $f(x_1,x_2,\dots,x_n)$ and $P(x_1,x_2,\dots,x_n)$ agree on $x_i\in\{0,1\}$)? What is the smallest degree of $r(x_1,x_2,\dots,x_n)\in \mathbb R(x_1,x_2,\dots,x_n)$ (sum of degrees of numerator and denominator) that represents $P(x_1,x_2,\dots,x_n)$ (where represents means $R(x_1,x_2,\dots,x_n)$ and $P(x_1,x_2,\dots,x_n)$ agree on $x_i\in\{0,1\}$)? Note that $f(x_1,x_2,\dots,x_n)$ and the numerator and denominator of $r(x_1,x_2,\dots,x_n)$ can be multilinear since $x_i^t=x_i$ on $\{0,1\}$. 

$\mathsf{P/Poly}$ captures those problems that could be solved in polynomial time given some precomputed polynomial number of constants. Is there an analogous complexity class in randomized world such as $\mathsf{ZPP/Poly}$, $\mathsf{RP/Poly}$, $\mathsf{coRP/Poly}$, $\mathsf{BPP/Poly}$ etc.? Or is there an intuitive reason why all such bounded error algorithms be removed of randomness to bring to $\mathsf{P/Poly}$? 

If $P\neq BPP$ then can $BPP^{\oplus P}\subseteq \oplus P$ hold? If $P\neq BPP$ and $BPP^{\oplus P}\not\subseteq \oplus P$ then can $NP\subseteq \oplus P$ hold (equivalently VV not directly derandomized by showing $P=BPP$ but just that $NP\subseteq \oplus P$ holds by a stronger argument yet $P\neq BPP$ and $BPP^{\oplus P}\not\subseteq \oplus P$)? 

We have $m$ list of integers $L_1,\dots,L_m$ and each list $L_i$ contains $n$ distinct integers $L_i(1),\dots,L_i(n)$. You are given two integers $a$ and $b$ with $b<a$ and we know $n=O(2^{(\log b)^\alpha})$ and $m=O({(\log b)^\beta})$ for $0<\alpha,\beta<1<\alpha+\beta$. I want to check to see if I can pick one integer from each list to check if product mod $b$ is $a\bmod b$. Is there a faster than $n^m$ brute force way to search for this? Is this NP hard (Andrew below sort of gives a pseudo polynomial algorithm)? 

(2) Is it $\mathsf{NP}$-complete to decide if there is a valid (valid here means vanishing) $0/1$ assignment with exactly $n$ of assignments to be $1$ (without regard to partition)? has a trivial reduction as shown by Michael Wehar. 

We know that $PH$ is in $P^{PP}$ or in $P^{\#P}$ and we do not know if $PH$ is in $PP$. We know $AWPP$ and $APP$ are weakening of $PP$ where $AWPP$ is in $APP$ is in $PP$. (1) Is it possible if $PH$ is in $P^{AWPP}$ or $P^{APP}$ or is there any consequences if $PH$ is in $P^{AWPP}$ or $P^{APP}$? Would it make it more plausible $PH$ is in $PP$? (2) Is there an analog of decision version of $\#P$ which is $PP$ for clases $AWPP$ or $APP$? 

What have been some of techniques (like discrepancy, arithmetic combinatorics) that have been introduced to shed light on Log-rank conjecture which roughly states that deterministic communication complexity of a communication problem roughly depends on some fixed power of rank of communication matrix of problem under study? 

We know that there are many families of matrices over $\Bbb F_q$, $\Bbb R$ etc are rigid. See $URL$ Do we know there are many families of rigid REAL matrices with alphabet $\{0,1\}$ or $\{-1,+1\}$ (note not same as $\Bbb F_2$)? 

Let $f:\{0,1\}^n\rightarrow \{0,1\}$ be a Boolean function. Let $[n]=\{1,2,\dots,n\}$. If $i\in[n]$, let $\Bbb 1_i$ be length $n$ vector with all $0$s except $1$ at $i$th position. If $B\subseteq [n]$, then $\Bbb 1_B$ be the length $n$ vector with $1$s only in positions marked by $B$. If $i\in[n]$ and $x\in\{0,1\}^n$, let $x^i=x\oplus\Bbb 1_i$ where $\oplus$ is $XOR$ operation. If $B\subseteq [n]$ and $x\in\{0,1\}^n$, let $x^{B}=x\oplus\Bbb 1_B$ where $\oplus$ is $XOR$ operation. Sensitivity of $f$ at input $x$ is $$S_x(f) = |\{i:f(x)\neq f(x^i)\}|$$ Sensitivity of $f$ is $$S(f)=\max_xS_x(f)$$ Block Sensitivity of $f$ at input $x$, $BS_x(f)$ is maximum $r$ such that there is a set of disjoint subsets $\{B_i\}_{i=1}^r$($\forall i\neq j$, $B_i\cap B_j=\emptyset$) such that $$\forall j\mbox{, }f(x)\neq f(x^{B_j})$$ Block Sensitivity of $f$ is $$BS(f)=\max_xBS_x(f)$$ Given $f$ in $n$-variables, would it be reasonable to ask the complexity class of deciding $S(f)>c$ and $BS(f)>c$ for a fixed $c>0$? I understand that describing a Boolean function takes $2^n$ bits fully. Does computing $BS(f)$ also take $O(2^{n+\epsilon})$ time as in answers below? 

Given a graph $G$, it is known independence number $\alpha(G)$ and Lovasz theta $\vartheta(G)$ satisfy the inequality, $\alpha(G^{\boxtimes n}) \leq \vartheta(G)^{n}$. If $\alpha(G^{\boxtimes n}) < \vartheta(G)^{n}$, under plausible complexity theory conjectures, is it possible to have any other polynomial time computable function $\psi(G)$ that works for all graphs $G$ (or special family of graphs) and that produces numbers satisfying the inequality $\alpha(G^{\boxtimes n}) \leq \psi(G)^{n} \leq \psi(G^{\boxtimes n}) \leq \vartheta(G)^{n}$? 

Let $\alpha(C_{n}^{\boxtimes k})$ be independence number of $k$-fold strong product of an $n$-vertex cycle graph $C_{n}$. $\forall n > 6$, is $\alpha(C_{n}^{\boxtimes (k+r)})^{\frac{1}{k+r}} \geq \alpha(C_{n}^{\boxtimes k})^{\frac{1}{k}}$ for infinitely many positive integer pairs $(k,r)$? 

The answer here (Generalized Ladner's Theorem) says for many natural settings Ladner's theorem applies. For many interesting problems such as those equivalent to finding parity of number of perfect matchings in bipartite graphs we have that finding parity is easy and such as those equivalent to finding number of perfect matchings in bipartite graphs we have that finding number is easy. Is there a general theory of such $\oplus P$-easy classes and such $PP$-easy classes? Can we have an infinite hierarchy between such $\oplus P$-easy classes and $\oplus P$-complete problems and between such $PP$-easy classes and $PP$-complete problem? Are there candidate problems? One motivation is on whether $BQP$ which is in $AWPP$ lies in such a $LadnerPP$ hierarchy? If so there should be a natural way to look at $BQP$ hard and easy and intermediate problems as well. 

Is there an interpretation of MAXCUT using eigenvalues of the graph that yields constant factor approximation to MAXCUT? Can the estimates provide sharp lower bound to MAXCUT? 

Is there a higher version of $ETH$ (Exponential Time Hypothesis) that is applicable to the $EXP$ versus $NEXP$ problem for $NEXP$ complete problems that come from succinct version of $NP$ complete problems? 

The motivation comes from possibility of counting $\#$ of perfect matchings in planar graphs in linear time? 

Given an arbitrary graph $G$, could there be a polynomial time algorithm to tell if it has a larger size clique $(\omega(G))$ or larger independence number$(\alpha(G))$? 

We know that an NP complete problem with a parsimonious reduction but a many one reduction is candidate problem for NP complete problem not being #P hard. 

Is it $\#P$ complete to find number of integer points in such polytopes? Is it $NP$ complete to decide existence of integer points in such polytopes? 

Consider a $(c^a,(c+d)^a,1)$-regular directed hypergraph $\mathcal{H}(a)$ on $n^a$ vertices with fixed $n\geq c+d+1$, fixed $c\geq 2$, fixed $d\geq 0$ and variable parameter $a\geq 1$ (meaning every vertex $i_1$ has only $1$ outgoing hyperedge $\{i_1\rightarrow i_2,i_3,i_4,\dots,i_{c^a}\}\in\mathcal{E}(\mathcal{H}(a))$ which has $c^a$ vertices and every vertex is on $(c+d)^a$ hyperedges). Consider the NP-complete HYPERGRAPH-MAXDICUT problem of given an integer $t$ and a hypergraph $\mathcal{H}(a)$ with above parameters, one has to decide if there is a subset $S \subset \mathcal{V}(\mathcal{H}(a))$ such that $$|\{\mathcal{I}=\{i_1\rightarrow i_2,i_3,i_4,\dots,i_{c^a}\}\in\mathcal{E}(\mathcal{H}(a))\mid i_1\in S \text{ and } \mathcal{I}\setminus i_1\cap S=\emptyset\}|\geq t$$ Can there be a $c^{a^{\beta}}$ approximation algorithm to HYPERGRAPH-MAXDICUT where $\beta\in(0,1)$? For which classes of $\mathcal{H}(a)$ could we have such approximation? If $n$ is variable how does the factor depend on both $a$ and $n$? 

Natural proofs paper shows 'if there is a natural property not possessed by any function in P/poly then there is no $2^{n^\epsilon}$-hard PRG'. Is it easy to see the converse 'if there is no $2^{n^\epsilon}$-hard PRG then there is a natural property not possessed by any function in P/poly'. The reason I seek is following. Even if SAT and $\#$SAT have $2^{O(2^{\sqrt{\log n}})}$ randomized algorithms then P is not NP is still possible. However in this case there is no $2^{n^\epsilon}$-hard PRG at any $\epsilon>0$. Then in this situation would it be possible to prove NP is not in P/poly by a natural proof? 

Best example is in area considered currently best candidates for OWFs where it seems every popular OWF that is cooked up surprisingly has a randomized sub-exponential algorithm while there exists no deterministic sub-exponential algorithm (take integer factorization for instance). In fact, in many cases, there probably is efficient algorithm given some advice strings (cryptoanalysis). 

It is well known LLL algorithm provides a fully polynomial algorithm to factor a reducible primitive polynomial over $\mathbb{Z}[x]$. Say one only seeks to identify whether a given polynomial over $\mathbb{Z}[x]$ is reducible, then what are the best ways known to solve this? If reducible, the algorithm should correctly say yes and if not, it should say no. 

In $URL$ a statement is added which reads "Oddly enough we would usually prefer a probabilistic over the deterministic method to find primes. Otherwise the adversary can use the same deterministic procedure and factor your number as easily as you put it together". As I understand, this seems to state polynomial time deterministic prime finding implies integer factorization can be done in polynomial time. Am I right? How to see this? Is there analogous statement to factorization in $\Bbb Z[x]$? Is there an analogous statement to discrete logarithms? 

Coding theory is an useful topic in theoretical computer science. There are known examples of problems coming from coding theory which turn out to be NP complete. My questions are the following: $(1)$ Are there natural good examples of coding theory problems that lie in different levels of the polynomial hierarchy above NP and are complete for those levels? $(2)$ Are there natural good examples of coding theory problems that are PSPACE complete? (Note that a coding theory approach is used to show IP=PSPACE in $URL$ 

What are the consequences of $MP=PP^{\oplus P}$? What are the consequences of $MP\subseteq P/Poly^{\oplus P}$? What are the consequences of $PP=PP^{\oplus P}$? Does it give $\oplus P\subseteq PP$?