Alternatively, and I think more easily, you can just use the object reference directly in the ACL statement: 

Each layer of the OSI model serves a unique purpose with the end goal of host to host communication. Layer 1 is responsible for moving bits (s and s) across a network. Layer 2 is responsible for communication within networks. L2 uses addressing known as MAC addresses for this purpose. A MAC address is essentially the address of a particular NIC. Layer 3 is responsible for communication between networks. L3 uses addressing known as IP addresses for this purpose. Fundamentally, your question is not "what is the purpose of Routers", but "what is the purpose of networks", if you understand why the Internet is divided up into multiple networks, then you will understand why you need a device that facilitates communication between those networks (aka, the router). Consider your mailing address. It will look something like this: 

Subneting is the process of breaking up IP address networks into smaller networks. It is typically used in the context of an ISP providing a company a /16 (for example), which is 65536~ IP Addresses, and that company breaking up those 65k IP addresses into smaller groups for more efficient deployment in their network. Segmentation is the concept of breaking up one larger network into multiple smaller network. It is often associated with VLANs, but doesn't require them. BUT, each new network does require its own IP address range, and therefore also involves the process of Subneting described above. Segregation can probably mean different things to different shops, but I've always taken it to mean the concept of placing servers/hosts with different security requirements in different network "zones" so you can apply security policies to traffic flowing to and in between them. For example, traffic flowing to your web server will be filtered differently than traffic flowing to your database server. As such, it is wise to put your web server in a different network than your database server, and also ideally separate those networks with some sort of Firewall or security device. Segregation will involve creating different/isolated networks, which might involve Segmentation, which will therefore also involve Subnetting. 

From there, you can see that packets 8,9,10 have a TTL of 1. And packets 11,12,13 have a TTL of 2. And so on and so forth. 

And to answer your last question. Whether HostE gets its address from DHCP or not, the process flow would appear as above if HostE did not have an entry in its ARP Cache for Router2's MAC address. IF, Router2 was the DHCP Server (which it doesn't have to be). And Router2 just assigned HostE its address. Then theoretically, HostE would know Router2's MAC address. But ARP entries don't last forward, particularly on clients. For example, my Windows 7 laptop keeps ARP entries for only 34.5 seconds (see below). So even if Router2 was the DHCP server, and gave HostE its IP address, sooner or later HostE's ARP cache would time out, and it would have to run the broadcast ARP request all over again, just like if HostE had always only had a static IP assigned. 

No, definitely not. An IP address must be unique and it must fit into the subnet you're in. Your router's external IP address is issued by your ISP (usually temporarily). It is to this IP address that all your requests need to be translated to and the answers back from (source NAT). This external IP address has been issued - in a large block - to your ISP by your regional Internet authority. It is unique world-wide (unless your ISP also uses NAT) and required to send back data to you. 

You need to keep in mind that today's major protocols - TCP/IP for layers 3 &4 and Ethernet for layers 1 & 2 - were developed separately. They both solve the tasks in their respective layers in different ways. When Ethernet was initially developed, TCP/IP wasn't ready and it would take 15 years for it to gain general acceptance. How do you built hardware for a protocol that isn't finished? The guys developing TCP/IP built on whatever they had on hand. For Ethernet's incompatible addressing scheme a translation had to developed - ARP (which by the way is replaced by the more efficient NDP for IPv6). Additionally, when Ethernet was young there where many, competing L3 networks out there - IPX, NetBIOS, Apple/Ethertalk, ... Actually, the separate addressing mechanisms give a network designer additional degrees of freedom - he can map multiple IP addresses to a single MAC or vice versa, use virtual IP addressing, invent new ways to do things (like anycast) or similar. All this wouldn't be possible with a strict end-to-end addressing scheme. Pure effiency on the link level is just one side of the medal. For overall effiency, you'd have to also count what you can do and how easily you can do it. Throw in scalability and cost effectiveness and take a look at the whole thing. If Ethernet wouldn't work so well with IP, one of the alternatives would've made the ubiquitous network standard today. 

You might want to plan ahead for a potential network expansion in the main office. I'd use 192.168.16.0/24, 192.168.17.0/24, ... for the remote networks. I'd use IPsec VPN. PPTP doesn't encrypt. 

TTL is checked on ingress packets and decreased when forwarding (=routing) packets. Accordingly, sending out a packet with TTL=1 will enable it to reach a local destination but it will not be routed. TTL is a layer 3 (IP) scheme, switches don't decrement it (unless they are routing). The Ethernet frame has no TTL value whatsoever and the IP TTL isn't changed while switching inside a L2 segment. 

While these terms are still used sometimes, the actual interfaces are long obsolete. AUI is the 10 Mbit/s interface between the MAC (within the NIC) and the external transceiver PHY for e.g. 10BASE5 or 10BASE-T). A MAU is an external transceiver connecting to the AUI, e.g. the extremely obsolete vampire tap for 10BASE5 or a pocket transceiver for 10BASE-T. This is the exact precursor of more current GBIC, SFP, XFP, SFP+, CFP, ... pluggable modules. The successors of AUI still exist as MII (Fast Ethernet), GMII (gigabit), XGMII, XAUI (10G), ... and their variants. As with AUI, these interfaces are optional and may not physically exist in a given device. Sometimes "AUI" is still used when people refer to a visible transceiver interface like you very commonly see inside an SFP slot. (edit: removed the references for S/GMII and XGMII since SFP/+ use a lower level interface.) 

IP is unable to deliver a packet to the correct service/application. And TCP/UDP is unable to deliver a packet from one end of the internet to the other. Both TCP and IP work together to enable them both to achieve the "end-goal" of Internet communication. Data that needs to get from one host to another is generated by the upper layers of the OSI model. This data is passed down to L4 which will add the information necessary to deliver the data from service to service, like a TCP header with a Source and Destination Port. The Data and the L4 header is now referred to as a segment. Then the Segment will be passed to L3 which will add the information necessary to deliver the segment from end to end, like an IP header with a Source an Destination IP address. The L3 header and the segment can now be referred to as a Packet. This process is known as Encapsulation and De-encapsulation (or sometimes decapsulation). Here is an animation of how it works: 

The problem is you have no access-lists applied. Access-lists are applied to an interface using the command, which I did not find in your configuration. Without an access-list, traffic trying to pass through your ASA is filtered purely based upon your security levels. Which means traffic from a higher security level interface is allowed to pass to a lower security level interface, but not the other way around. Currently, you have two interfaces: 

If you open a connection to a web server and download a webpage using the GET method, and that webserver supports connection keepalive. Subsequent requests to that web server, including the POST method, might simply re-use the already existing TCP connection. Therefore, that particular POST would not require a new 3-way handshake, since the data would be transferred in an already existing TCP connection. Connection Keepalive, however, does not have an infinite duration. So if after downloading the webpage, you waited a while before sending your POST, the original TCP connection may have already closed, and in this case, your browser would have to open a new TCP connection to POST your data, which would obviously require starting with the 3-way handshake. Since many browsers and webservers use different timers for how long they want their "connection keepalive" feature to keep connections alive, I wouldn't be able to give you reliable numbers as to how long it typically asks. 

To add to Ryan Foley's and iTom's great answers, I just wanted to mention a quick note from a non malicious or compromised host perspective. In TCP, any packet that didn't make it through must be re-transmitted. If I, as the sender, decide to ignore the Congestion indication from the Receiver, and continue to send traffic as fast as I can, I am only shooting myself in the foot because sooner or later the Receiver is going to request re-transmission and I'm going to have to do twice the work to send the same number of packets. This is why you don't typically see senders ignoring congestion indications, because its beneficial to both parties (sender and receiver) to obey the congestion control rules and slow down their transmission. (Again, this is only relevant in a non-malicious scenario -- see the other answers for the proper response to this happening under dubious circumstances) Another way of looking at it: If you're trying to fill a teacup with water using a fire-hose, its going to take considerably more effort and time then if you simply used a regular faucet. 

TCP is told which port to connect to by the application opening the socket. The application needs to know. Commonly, the application just uses a 'well-known port' - like TCP port 80 for HTTP. Otherwise the application has to be configured or instructed to use another port. Rarely, it just guesses and tries various ports. 

Think of a half-duplex connection as a single channel that you can turn around between packets. Then think of a full-duplex connection as two unidirectional channels that can be used simultaneously. Physically, all modern twisted-pair or fiber Ethernet connections have two channels, one for sending, one for receiving (most prominent in 10BASE-T, 100BASE-TX and fiber). With half duplex they may not be used at the same time while with full duplex they may. 

You track the current IP address and put it somewhere you can find on the Internet. The easiest way is to use a dynamic DNS service where you just access the DNS name which is always kept updated to the current IP address. On your Internet firewall you need to open ports to be forwarded to the PC or - preferrably - VPN access. You use a broker on the Internet that both the PC to access and the access client connect to. The broker ties both connections together and you can exchange data. The above mentioned Teamviewer is of this kind, there are many others around. 

A host indicates the largest TCP segment size (local MTU - (IP overhead + TCP overhead)) it can receive by the MSS. The MTU is the largest IP packet the underlying L2 transport can send/receive. Usually, they are directly related. The receive window is another TCP connection parameter not directly related to MSS or MTU. It's rather about path throughput and latency. Likely there are slower hops in the path than either receiver or sender can see. They must not be overrun. Often both receiver and sender have fast local connections (at least 100 Mbit/s) while they are connected over much slower Internet connections (say 10 Mbit/s). 

A router removes the frame around an incoming IP packet and encapsulates the packet with a new frame (depending on the layer 2 protocol) when passing it on. The MAC tables of the switch are populated by ARP: 

A simple router is stateless, ie. it just looks at the current packet and decides where it should go. A NAT router translates the source IP address, the destination IP address (aka port forwarding), or both. Usually, it also translates the according port number (PAT). In order to translate the addresses/ports back for the reverse direction, it needs to be remember what connections it is currently translating. 

These messages are a part of what is known as Dead Peer Detection, or DPD. DPD sends periodic keep alive messages (known as "R-U-THERE" messages) to the opposing peer. Upon reception of such a message, the other peer will respond with a keep alive acknowledgement (known as "R-U-THERE-ACK"). This informs the original peer that full, two way connectivity between the peers is working just fine. The operation of DPD is described in more detail in RFC 3706. For what its worth, your log messages are backwards. The bottom message is the oldest, and the top message is the newest. That said, DPD on the ASA is sent only when no active traffic is detected. Because if traffic is detecting going both directions, that intrinsically confirms the tunnel is up, so no additional verification is necessary. The ASA only starts sending DPD keep alives, if no traffic has been seen recently. So in the end, you've shown us the debug of a fully working tunnel. Nothing in what you posted indicated a problem. So if a Problem does exist, you'll have to provide much more debugs and context, maybe even sample configurations. I would also suggest the output of and show . 

You've asked a great question. The question seems very simple, but in fact the answer is somewhat more complex. I'll do my best to answer it in a succinct manner. Also, since you mentioned ISAKMP, I am going to assume you are interested in IKEv1. Things change a little for IKEv2 (well, a lot), but I did want to mention the answer below only correlates to IKEv1. Phase 1 can be accomplished in two different mods: Main Mode and Aggressive Mode. In either mode, the first message is sent by the Initiator, and the second message is sent by the Responder. Both of these messages include what is known in the cryptography world as a Nonce. A Nonce is simply a randomly generated number to use in key generation. (the term Nonce comes from _N_umber used _Once_). So, after message 1 and message 2, both sides know each other's Nonces. The Nonce's are combined with the Pre-Shared-Key to create a Seed value for generating secret keys. The relative part of the IKE RFC is here: 

Unfortunately, no, you are incorrect. Ron makes a good point, you didn't provide a subnet mask, so if we were to assume the classful mask, the 10.x.x.x address would have a 255.0.0.0 mask, which would actually put the two hosts on the same network. If that is the case, they would have no problem communicating. However, given the nature of your question, I imagine you intended for each of these hosts to use a smaller mask -- we'll go ahead and use 255.255.255.0, which puts both hosts in two different subnets. That being said, the heart of what you are missing lies in forgetting about ARP (Address Resolution Protocol). Specifically, in whom HostA decides to ARP for. Let me explain...