Be aware - I posted this before index definitions were posted Insert in the order of the PK to keep fragmentation down 

Pretty sure this is the same query Not sure if it is faster but I doubt is is slower The query optimizer has a better chance of filtering early 

You said join and I don't think this can be done with an inner join Top 1 is non deterministic without an order by Typically you want to let the query optimizer do its job It will use statistics and other logic to build an efficient plan I think this is how I would write it The way to test is to look at the query plans 

A unique constraint on TEACHER_ID, STUDENT_ID would prevent duplicate STUDENT_ID for a teacher. In fact you could just make the the PK and drop ID. This is TSQL so it may be wrong for mysql 

Please post the query to populate #localTempTable If you use that table for other stuff then flopping stuff around may not be and option 

The FK would still need to check with the empty table to see if the key was used on a delete operation. But this would be a quick check and never deny if the table is empty. 

I cannot know why they are not present. The purpose of a FK constraint is to enforce the FK is present. Without the constraint you could have many without a one. 

Just how are you going to define a M:N relationship without a bridge table? If F is a PK of T1 and T2 then you don't even have a many let alone a many to many if you join on F. Join on a common field G (not a PK or unique) is still not the same If records T2 rows 5, 6, 7 all have value 'match me' for G you cannot form a relationship to 5 and 7 using that common field G Common field is commonality and not an explicit relationship 

I am not positive on if this would reduce page splits but I would put date last if that has the most changes. Have a fill factor of less than 100%. Even 90% or 80% will slow down fragmentation significantly. Have a maintenance plan to reorganize / rebuild the index. A non-clustered index will use more room but it would make for more efficient maintenance. You can place a unique constraint on a non-clustered index. 

You will need to fashion this into an update. You don't supply the table. Basically create a table with the valid bit values and use a cross join. 

go with case insensitive collation full DATETIME will get rid of some overhead if that is a char field then that is a problem and you should fix the data 

If recordID is your PK and it is not fragmenting then you should flop and make recordID the clustered index. With IX_AmtoteAccountActivity as a non clustered index give it a fill factor of less then 100%. This will also speed up inserts. Since it is a big table don't go crazy bet even 90% will slow down fragmentation. And just schedule a rebuild of that index every night. 

all that join does is make sure it is in Profile but you are not reporting anything from profile and how is that not ? 

StudentTeams is a bad name as in plural. With that design a student can be on 0 or 1 team. If multiple students are on the same team (TeamName) repeats. Two student could be on the same team but someone could enter TeamName incorrectly so you would not know. I would either 

All you need is bar code to file I would just store bar code and file path in XML. When you load the application you read the XML into a dictionary. Use a dictionary lookup get the file name and then just read the file from disk. You you can use any database that will store a binary (they all do). This is just a simple table. It is kind of a pain to read and write binary. It is is easier to read files from disk and makes backup and restore easier. P.S. I write document management software for a living 

If an AcctNo had Code both 1 and 2 then this would be non-deterministic If you need one (actually 2) to win then 

you really need a composite PK of bigint? you have ID that is not an Identity it appears you have an index on a bit it is not clear to me what you are trying to accomplish I've been noticing that some queries are slow to respond I hope your queries are not inserting 500000 rows in a table Now responding to the indexes posted Those indexes are just crazy That is a level of indexing I would expect on static table An index has overhead to add, delete, and update and you are adding 500,000 rows I think you are lucky to be getting 500,000 in 14 seconds Add Disable / Enable to all but the PK Do not disable the PK And try a composite PK of Int, Int clustered 

Before you vote this down look at the question before the major edits This is valid (and good) answer to the original stated question What you have is just messed up Why use a merge for an update only? Why use a CTE when it is the whole table 

I don't think so. You pick one way or the other to reduce fragmentation. If you compare query plans with one index sort both ways the cost is split 50 50. 

It is strange to me that it is not using and index scan as [SOW_Number] is part of the PK. According to a comment an index scan would be reported as a table scan since it is a clustered index. Could add an index on [SOW_Number] as suggest by Max (+1). Putting [SOW_Number] first in the PK might help but doing that to table with 83,423,460 rows is not something I would jump into. 

Typically user would have the fk user: ID (pk) Name StatusID (fk referencing status.ID) status: ID (pk) Name A user has a status - not a status has a user