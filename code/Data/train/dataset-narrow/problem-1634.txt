Are there any ntpd messages in /var/log/messages? As I was dealing with my EC2 NTP issues I noticed that NTP didn't like being too far out of sync and wanted a manual update. Perhaps you're too far out for it to decide it will update for you. 

I've recently been moving our instances to EBS instances (CentOS) and still have a bit of confusion on what's happening when I "stop" and instance. I have some of my services with runlevels 345 on but when I start a stopped instance the services don't start. What's actually happening when I issue a stop command to the instance, and how do I get my services to start automatically when I start the instance up again? 

For what you're doing, you're probably fine running on regular hardware. But it's always worth learning about things. As mentioned, server hardware is really designed for reliability. You get things like ECC RAM, dual or quad CPU sockets, redundant power supplies and fans, RAID for your hard drives among other things. You can also generally build "bigger" boxes than you can with "standard" hardware which is beneficial for maintenance (fewer boxes) and solutions like Virtualization (pretends to be more boxes). Google doesn't do that sort of thing and takes the approach I think you'd be comfortable with, use cheaper hardware and replace it when it fails. Google's redundancy and scaling is horizontally (more boxes). The advantage here is it's cheaper to buy at the cost of complexity of overall architecture. Applications need to be designed differently and how the overall system functions can get more complicated. You need to add load balancers and such which may or may not be possible. Assuming downtime isn't a huge concern of yours, I'd say stick with the low cost hardware, backup things properly and replace stuff if/when you need to. 

Basically: every newly started process will get C2 N4 , so when you want to have the IO reduced to as low as possible, either go on idle only (C3) or C2 N7. 

As you already have written it seems you actually have a fallen or soon to fall SSD. Having an SQL Database and a nearly full SSD can result in fast "degrading" quality of the ssd. Best for something like this to at least have some values for anticipation is checking the SMART Values of the ssd. Some of the important values are "Wear-Leveling Count" and "uncorrectable error count" Depending on your SSD you can theoretically get a lot of (10000 or even more) repeated writes on one cell, but this might even happen fast than you think when all the data is still used and garbage collection can only recycle some of the cells. Sure enough the controller of the SSD usually takes care of that, but only during the last 1-2 years the controller did get significantly better. Basically summit: SSD broke. Advise: split OS + application on at least 2 seperate disks/SSD, get some raid to prevent downtime, and never forget backups. 

See Apache 2 Manual for the meaning of the different format signs % or Apache 2 Manual ErrorlogFormat Directive for having the error log in a specific format since apache 2.4 aswell. in short : Define the output format in your main config file and the output file for example per vhost in the VirtualHost Directive. You can define the config file for all your sites in the main file aswell, if you want to. something like would be needed to add (in case its not there yet): 

You could also do this using virtual hosts and setup Apache as a reverse proxy. This is how I have it setup where I work. 

I'm working on getting some servers running in the EC2 environment and I'm noticing some errors with ntpd trying to sync (using CentOS). I was reading on this site and the impression I get is that I don't need to run ntpd since EC2 is Xen and the host takes care of the time for the virtual servers. $URL$ Is this accurate or do I need to figure out how to get around the error I'm having? cap_set_proc() failed to drop root privileges It looks like it involves building a new kernel and other stuff I'd rather not do if I don't have to. 

Create or edit the vhosts.conf in your apache conf.d (or equivalent depending on OS). Use the NameVirtualHost directive to handle the DNS names. 

For an internal network, if you don't want to pay for the wildcard cert (or dedicated cert for the server), simply create a self signed certificate. Since it's your company, it shouldn't be too much of an issue for the users to accept the certificate. And depending on how your network works (and your admin friendliness), you might even be able to push it to the users so they won't be bothered. If you're dealing with any sort of sensitive information, you should be doing it over HTTPS. 

You might want to increase your shared memory settings when starting tomcat. this can be a temp folder issue (think of no space, no permissions, as Scott did write) Additionally it is possible that this is just too much ram you use: Increase your Xmx and Xms values and you might want to update your heap settings aswell. Ceck the SF search for "OOM tomcat" and you will find the rest of the things you need to learn. 

if its not a copy past error that your "proxy access" is via https then i suggest you check your vhost configuration for SSL. for all i know you need your mod_proxy setup in both your normal *:80 and *:443 Virtualhost Directive. so either your Virtualhost Directive does not have the entry or you should show us the *:443 Entry to try to help you more specifically. 

This can have a few different reasons. For example it might be possible that the interface was created after Wireshark was started. In that case you should reload the interface list inside of Wireshark. To check that the wanted interface/Subinterface is listed check in the "Capture Options" that the interface you want to use has the IPs you want to listen on. Additionally this might be a permission error that the Wireshark user is not allowed to read the interface. 

I'm wanting SNI on my CentOS 5.5 dev server and since it looks like I'm out of luck with the current repo versions of openssl and apache, before I go compiling custom RPMs I thought I'd see if I could get it working with gnutls. Anyone know how to do this? According to yum, gnutls is already installed but I don't see it in my apache modules directory. 

Checkout the documentation for ProxyPass and ProxyPassReverse. If you just do a name based virtual host for both then you could add something like this to your virtual host definition (or replace localhost for your IP if your box will be hosting apache): 

We've had a server (CentOS) running in EC2 for a few months. It had been going pretty smoothly until today when we got an alarm that the server was unavailable (HTTP service couldn't be reached). So I tried SSHing into the box but that timed out as well. I logged into the EC2 console and it said the instance was running and there wasn't anything in the system log. One odd thing I noticed is that even though we have an Elastic IP attached to it (which shows in the Elastic IP management area), the instance detail is not showing that there is an EIP associated with the instance. I looked through the message log and the last thing I see around the time we got our alert was the dhclient renewed the lease. I'm guessing there may have been some sort of issue with the networking. How might I check if that was the problem, or if there were any other issues that may have caused our instance to stop responding? 

The Real Problem I Need to Solve: How can I programmatically translate, convert, or update the content of these log files so that they only show what is actually visible to the user after processing the log file through command with enabled in PuTTY session logging? For the record, I have spent more than a few hours researching and testing possible solutions. Things I have tried which have not worked suitably (or at all): 

Background: I have a Windows 7 workstation and use PuTTY for SSH connectivity to Linux servers with session logging enabled. I previously used the option but that has the benefit of no escape characters but the drawback of making commands I've typed unsearchable if I used to autocomplete or because I corrected a typo (or 3) as I was typing the command. NOTE: I have installed for additional command-line tool support (i.e. , , etc.). Recently, I had to go back and find some commands to set the record straight with a coworker about something that happened on a server and the inability to see the final commands I issued is problematic and makes it more difficult to search the logs as well as being much more difficult to readily demonstrate what actually happened for my coworker. Example #1: This is an actual PuTTY log file of the 'pwd' command initially misspelled as 'pdw' and then corrected to 'pwd' with enabled when viewed with or in . NOTE: There is no difference between and in this case because there are no codes and only printable output was captured. 

Before the change this was set to . This did not help either. Smart Values of the HDDs/SDDs are OK, nothing too obvious. Note that the UDMA Value seems to be 33 now only. On boot of the server this were the sata link speed values: 

You could use a service script yourself (good) or include it in the mysql script (temp. workarround, ugly, wont work after updates.) something like /etc/init.d/mysql should exist. then you would search for and before mysql is actually started you would add your part of the script. (might differ a bit with newer versions though) on one of my hosts this would look like it: 

if md5sum check is enough for you you might want to try following plugin: nagios-exchange check_file_md5 From the manual: 

No obvious change in the situation. $URL$ $URL$ Others suggest sata cable or even an incompatibility between board + drives. However as i seem to either have the issue on one drive and this populates to all 4, or having the issue directly on all 4 devices i am unable to pinpoint the issue further. As this is a production server putting this server down for maintenance (aka bios/kernel param changes) is possible, but i like to prevent that if possible. According to the hoster this might be power management related: $URL$ $URL$ 

For the two sites on the same box, it depends on how they're setup. If they're on different ports, define the ports, if they're paths, then you'll need to add the path on the end of the ProxyPass and ProxyPassReverse entries: 

We've been moving servers to EC2 lately and I ran into an issue recently involving locales. We use a script to build an AMI from scratch that is largely based on a simplified RightScale script. However, we recently worked on an international project and I discovered that the locale was not set during the scripted install (issuing locale at the command line results in posix). It appear there is no i18n file by default. However, checking a development server that I installed locally (via GUI) the i18n file exists. What package(s) do I need to install and which program can I run (command line) to configure this during the scripted install? We're running the current version of CentOS. (5.4) 

A reboot will keep it's settings. If you bring up a new instance then you'll need some way to manage the IP's. A startup script is probably the way to go. Pull the instance metadata and update a config file (perhaps in S3) or DNS entry. You can also use an elastic IP and configure a cname which will resolve to the internal address within the EC2 environment. To do this, assign an elastic IP and note the public DNS string (there's a pattern but it's good to check) and create the cname record with it. The advantage with elastic IP cnames is you don't have to wait for DNS propagation. 

For having that setting stored without letting the user read the whole mysql config you can change the settings of the ~/.my.cnf file see Option Files for details In your case you would add socket=/tmp/mysql.sock to this file. 

That should let iptables start again and remove the error in munin. However if you used firewalld before the restart this possible could relate in further issues so really make sure you find out/know which one you do use! 

Manufacturer: Product Name: Version: SATA controller: 2x SSD, 2x hdd each drive can do Sata Rev3 (6.0Gb/s) 

We have a 4 core CPU production system which does a lot of cronjobs , having constant proc queue and an usual load of ~1.5. During night time we do some IO intensive stuff with postgres. We generate a graph showing the load/memory usage (rrd-updates.sh) This "fails" sometimes on high IO load situations. It is happening nearly every night, but not on every high IO situation. My "normal" solution would be to nice and ionice the postgres stuff and increase the prio of the graph generation. However this still fails. The graph generation is semi-thread-proof with flock. I do log the execution times and for the graph generation it is up to 5 min during high IO load, seemingly resulting in a missing graph for up to 4 min. The timeframe is exactly matching with the postgres activity (this sometimes happens during the day aswell, though not that often) Ionicing up to realtime prio (C1 N6 graph_cron vs C2 N3 postgres), nicing way above the postgres (-5 graph_cron vs 10 postgres) did not solve the issue. Assuming the data is not collected, the additional issue is the ionice/nice somehow still not working. Even with 90% IOwait and a load of 100 i was still able to use the data generation command free without more than maybe 5 sec delay (on testing at least). Sadly i have not been able to reproduce this exactly in testing (having only a virtualized dev system) Versions: Kernel Debian Squeeze rrdtool Hardware: SAS 15K RPM HDD with LVM in hardware RAID1 mount options: ext3 with rw,errors=remount-ro Scheduler: CFQ crontab: