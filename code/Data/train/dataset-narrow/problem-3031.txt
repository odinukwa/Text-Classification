Kernels are considered valid if they are positive-definite, so we must have $$ \sum_{i=1}^n \sum_{j=1}^n c_i c_j K(x_i, x_j) \ge 0 $$ for all $n \in \mathbb{N}$ and $c_1, \dots, c_n \in \mathbb{R}$ and (in your case) all $x^1, \dots, x^n \in \mathbb{R}^2.$ Letting $n=1$ and $c_1 = 1$ and $x^1 = (0, 1)$ shows that $K$ is not positive-definite, since $$ K\big((0,1), (0,1)\big) = 0\times 0 - 1\times 1 = -1. $$ The problem with your approach is that you define $\Phi$ on $\mathbb{C}$ but write $K$ as the dot product for real-valued vectors. The feature map argument for positive definite vectors only works if the product is an inner product on $\Phi$'s codomain. The dot product for real-valued vectors is not an inner product on $\mathbb{C}^2$ (because $i\cdot i = -1 < 0$). You would have to use the generalized dot product $x \cdot y = \sum_i x_i \overline{y_i}$, or another inner product on $\mathbb{C}^2$. 

I think instead of building something from scratch, you should utilize the domain knowledge of experts. One example: Turn Wikipedia's topic portals (e.g., the medicine portal) into a family tree. 

This will be very fast, unless $m$ is so large that does not fit into memory. In this case, I would follow your approach and use a for-loop: 

Interesting question! Maybe the pretrained models in Keras can help. Either by means of transfer learning, so that you might have to label only a small number of images by hand to retrain the higher layers. Or by using them for feature extraction and see if a certain keyword appears frequently for watermarked images. Or just upload the pictures some place that does not allow watermarks and see if they get flagged ;-) 

Expected value and standard deviation are 'independent' in the sense that knowing one gives you no additional information about the other. Therefore it is more accurate and much simpler to train two separate networks - one for the expected value and one for the standard deviation. This also has the advantage that you need to be explicit about what you mean by 'standard deviation of a (heteroscedastic) time series'. 

Let me try to answer your questions point by point. Perhaps you already solved your problem, but your questions are interesting and so perhaps other people can benefit from this discussion. 

Is there a standard way to deal with this? ------------ EDIT: -------------- On Github, I found this: $URL$ This suggests that if a centroid becomes an "orphan", it should be assigned to the point that is the furthest from its centroid. This seems like a sound method, is there any paper or theory supporting this? 

you need to deal with class imbalance if/because it makes your model better (on unseen data). "Better" is something that you have to define yourself. It could be accuracy, it could be a cost, it could be the true positive rate etc. 

You can do that by using binning. If you want to use K-Means for categorical data, you can use hamming distance instead of Euclidean distance. 

As explained above, every learning exercise will highly depend on the architecture and hyperparameter used, even the initialization of your weights, whether you use pre-training or not, and of course, your data. Again, I think that the shortest the time series, the more competitive regular NNs could be. But again, this is merely intuition-based and hasn't been checked thoroughly. - Can the NN behavior be understood better than the RNN behavior? It all depends on what you mean by understanding. RNN have more weights than NN so ultimately, there will be more things to analyze and eventually understand. But, with more data also comes more information, so perhaps there is more information to be gained from an RNN than a simple NN, even if it's a deep one. Plus, sometimes, based on the initialization of the weights and other parameters, the interpretation of the model could vary, even if it's trained on the same data. 

Suppose I use a linear Support Vector Machine with slack variables on a dataset that is linearly separable. Could it happen that the Support Vector Machine reports a solution that does not perfectly separate the classes? As an illustration: Is the situation in the picture possible for a Support Vector Machine with slack variables? Although there is a "better" boundary that allows perfect classification, the Support Vector Machine goes for a sub-optimal solution that misclassifies two samples. 

My question: Why does my algorithm break down when I use it on the differenced time series? What is a good way to deal with drifts in time series? Here is the full code for my model: 

1. Download a comprehensive list of English words. (I avoid calling it a 'dictionary' to avoid mix ups with the Python type of the same name). I found one here. Remove all words that contain non-alphabetic characters (including hyphenated words ... maybe not optimal). 

You mention that files may have different file types. Be careful when converting between types: Make sure for instance that separators and quote characters are treated correctly. 

See if one of the answers in this discussion is helpful. In my case, the error was caused by a : The dataframe's index started at 1, but contained a 0, so pandas silently inserted a row full of NaNs... 

No, you should only tune one hyperparameter at a time. If you change two hyperparameters and the performance increases, how do you know which of the two parameters is responsible? If you have the time, do a full grid search on the dropout rate and the training data size. 

Memory corruption seems to be an issue that is important enough for companies to buy expensive ECC memory for their clusters. The Wikipedia article on ECC memory lists some causes for memory corruption, including (to my surprise and delight) cosmic rays and ingenious hackers. 

I am implementing K-Means from scratch and that exercise raised a question. To update my centroids, for each centroid, I have to find the points for which that centroid is the closest. In some cases, especially when the number of centroids is high and the number of instances is low (i.e. k=20 and 100 instances), I find centroids for which no point has them as their closest centroid. In other words, they become "orphans" as no instances are allocated to them. 

Clustering is definitely something that can help. As you describe, the issue is that you can see that not all instances "behave" the same way. So if you can cluster them into groups that do behave more similarly, you would probably improve. Any clustering technique would work in theory. Although, techniques like K-means for instance do favour clusters of even-size, and so if your problem isn't necessarily "balanced", I would be cautious. What you could also do to improve your clustering is to look at which features are more discriminative (perhaps look at the information gain) and use a weighted distance to favour these features. Another way I feel could help you is if you used meta learning/stacking. By that I mean that you could use decision trees to split your data in a supervised way (as opposed to clustering), and at the leaves, use a more elaborate regressor than majority voting. 

As far as I understand, it is a simple autoencoder, meaning that all it does is trying to map the input into another space, so no fancy training, just some plain feed-forward and backprop. This is why it's rather fast to train. If you want to use pre-trained embeddings, you can do it that way 

As always, "is A better than B" always depends on what you consider better? Is it accuracy, is it speed etc. The dumb but correct answer to your question is: "try both and see which one is better". Performance of techniques is always to some extent dependent on the data. What you need to remember with word vectors, is that they are learned based on a certain context. If the context that was used by Google's model is similar to yours, you might be better off using their model. But if it's different, you might run into some problems. Just imagine the following case. You have 4 words: King, Man, Queen, Woman. Which pairs of two words would you create? Depending on the context, you could make a case for several 

Let me outline an algorithm that deals with both challenges. The prediction accuracy is not very good; but maybe you see a way how it can be improved. And at least it predicts something, right? 1. Simulating samples To be able to test the algorithm, I wrote functions that generate samples and labels. Generating samples: Each sample contains between 3 and 10 points. The number of points is random, drawn from a uniform distribution. Each point is of the form . The coordinates are again random, drawn from a normal distribution. 

3. Create the dictionary of hashed words. The dictionary maps each tuple to the set of corresponding words. 

(You can also see that 2. and 3. are true directly from the definition of $d(x,y)^2$). Looks fine so far. But: 

Each sample (read: each row in your table/matrix) can be seen as the realization of an $m$-dimensional random variable $X_{i}$, where $m$ is the number of features (read: number of columns in your table/matrix). Independence means that the random variables $X_i, i = 1, \dots, n,$ that generate your samples are independent. StatsSorceress explains the intuition behind independence wonderfully. A different way of looking at it is: 'Does knowing sample $X_i$ give me additional information about another sample $X_j$?' One case where this is true (and the samples are not independent) is for time series. If your samples are stock prices, and you know that the stock price one second ago was USD 100, then you can be fairly sure that the stock price right now is also going to be close to USD 100. 

From your comments, it sounds like you are trying to predict the next value of a series $X_1, X_2, \dots,$ where each $X_i$ is $(1000,2)$-dimensional. How about this: To predict $X_i$, you feed in the tensor $(X_{i-k}, X_{i-(k+1)}, \dots, X_{i-1})$, which has dimensions $(1000, 2, k)$. You apply convolution with stride $1$ and appropriate padding to the first and the second dimension: this does not change dimensions. And you apply pooling to the third dimension only (for example, set $k=8$ and use three pooling layers with window size $2\times 2$). 

Yes, it will affect the performance of Naive Bayes. It is called Naive because it assumes an independence between the features, which in practice is rarely the case. However, it's shown to be fairly robust to this and to be able to perform well on real-world problems. So having correlation will go against the Naive assumption. However, correlation is not necessarily a bad or a good thing for the performance of your model. Correlation between features in Naive Bayes simply means that if one feature "says" it's class A, then the other feature(s) will often say the same. Therefore, if your correlated features happen to be good predictors, your model will actually benefit from it, if they happen to be bad predictors, your model will be worse off. 

This is not an issue. Here, what you'll want to see, is if for instance, for each vector with label x, there is a vector with label y close to it. To do that, you could use the Earth Mover's Distance which gives you a single score when you are trying to see how far two "groups of things" are. 

I would personally take a look at collaborative filtering as this will take into account the information of the user itself, but also the information of similar users. If let's say, my best friend and I have the same taste in books, knowing his taste can help you guess mine! I'd recommend watching the Andrew Ng lectures on Coursera about recommender systems. KNN might seem like a natural choice if you don't know about recommender systems (I have been there!) but please, make sure to read about them before you decide to use KNN. 

Due to the curse of dimensionality, less features usually mean high improvement in terms of speed. If speed is not an issue, perhaps don't remove these features right away (see next point)