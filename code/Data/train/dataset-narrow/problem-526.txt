EDIT 2: The output of in order to remove extra information based on read and write: $URL$ Another result which reached around 1000: $URL$ 

When I edit my.cnf in MySQL 5.0 in filemanager and add the following settings, I get logged out automatically from Kloxo and when I remove these line and restart server everything is ok then: 

We have about 15GB of free memory that does not use! On peak we reach 400 OPS, and 500 connections per seconds. Is there anything I could do to improve the performance? 

An easy php based web application to produce very realistic data to populate your table. Its online site has limitation, but if you download the source code and install it on your PC then you can generate every kind of data that you want. It supports csv,sql,html,etc file formats. 

I have used to generate SSL certification. All the private key, chain and certificate is generated by `let's encrypt. Now to use it in I first merged and into a file called : 

As option separates table files instead of putting all data and indexes of DBs into one ibdata file, is using this option improve speed of alter table? I have a table of 40M rows and when I alter a specific table it takes about 5 to 6 hours. Does this solution help? Is there other ways around to improve alter table speed on heavy tables? 

A few notes about both of them. If a server crashes and you can't repair it what should you do? Set up a new server from scratch? In both physical and virtual environments it's gonna take a lot of time. When the database server is a VM should you recover it from a VM backup? This operation can last multiple hours for bigger machines. Or maybe one should keep a clean virtual machine with database software installed and in case of disaster: - restore databases on the clean VM - change the IP address and start using the new database server Any ideas? Or maybe you can submit some useful links or refer any books? 

You can use snapshot replication (it allows you to update the table every 5-10 minutes). If you would like instant changes, go for transactional replication. Note that you cannot publish a replication on SQL Server Express, you need at least Standard edition. 

I created a user in SQL Server 2012 database and revoked all permissions given by the public role. Then i granted exec permission on a stored procedure. The user can execute the procedure but cannot get the data it returns. The procedure is in a schema1 and the tables from which it selects are in schema2. If I add the user to db_datareader role it can read all data from all the tables in the database. I tried WITH EXECUTE AS OWNER but it didn't work. How can I grant only the access to the given procedure and nothing else? 

The "standard" only returns records that match in both tables. To return records that only exist in the left or right table you need to use an . This can be a or a depending on whether you want to retrieve all the records from the left or right table; by convention LEFT is more frequently used. $URL$ $URL$ In the above you are selecting from as the first table, and then doing one inner and then several LEFT outer joins on the other tables. So you are only going to get results from tbl_rooms, that is the LEFT table, that is how it works. You need to either move to using RIGHT outer joins on the other tables, or, and I recommend as probably less complicated to conceptualize, to start with the table on the top/LEFT that you want to get all the results from. So you need to start with at the top and then do your left joins down to at the end, reverse the existing order. You'll then get all the results from the table you start with, and only the results that match from the table you are LEFT outer joining on. EDIT: Something like this should give you properties with a room count: 

CONCAT will return NULL if any of the inputs are NULL. This suggests that your is returning NULL in at least one iteration. CONCAT_WS will skip NULLs. Try using that instead and see what it gives you. Note the first argument is the desired separator, so if you want to duplicate CONCAT() but with NULL skipping just set that to an empty string, This should help you debug the problem. Alternately you can also use on your if you want to set a default in cases where the result might be NULL. If you use COALESCE to set a default empty string you shouldn't get NULL back from the subsequent CONCAT. Presuming the is in Thai script, you may very well have collation/character set issues, which could be why it is returning null in the first place, your comparison may be failing. Check that all the columns you are comparing have the same character set/collation. @Rick James is also entirely right that looping in SQL should be avoided, and likely is not necessary in the first place. So ideally rewrite the whole thing without the loop. But the above hopefully will help you get to the bottom of where the problem is. 

I am designing a data warehouse using Azure Databases (not Azure Data Warehouse though), I have 2 databases: the main data warehouse and a staging database. As in a traditional ETL process, the raw data is stored in the staging, then transformed and finally loaded to the data warehouse/data marts. Since it is Azure SQL, cross database queries don't work and the only workaround I know is using external data sources and external tables, which is pretty problematic. Can you recommend the best solution to access both databases at the same time? My ideal solution would be cross database queries like in SQL Server on premise. 

For production instances it is recommended to create separate partitions for the following elements of SQL Server: 

I have found a query that is a major performance issue in my environment. I looked at the actual execution plan for this query and found out the main problem is the remote scan (98%). Its remote because SQL Server is accessing its system objects (DMVs). If you look at the estimated number of rows it says 33, but the actual number of rows is over 16 000. If it was a regular table query I would look at the statistics for the columns but in this case I don't know what I can do. 

There are multiple backup options (eg. WITH COPY_ONLY). I don't think however that you should list any other than full/diff/log as "other kinds of backups".