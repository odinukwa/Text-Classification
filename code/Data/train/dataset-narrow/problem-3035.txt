I would try to set a multilabel classification algorithm and make the output standard by adding zeros. So if your data is like this: <1, 1>, <2, [1, 1]>, <3, [2, 1]>, <4, [1, 2, 1, 1]>, <5, [1, 1, 1, 2, 2, 1]>. The maximum number of output is 6. So you could transform your data into something like: <1, [1,0,0,0,0,0]>, <2, [1, 1,0,0,0,0]>, <3, [2, 1,0,0,0,0]>, <4, [1, 2, 1, 1,0,0]>, <5, [1, 1, 1, 2, 2, 1]> Another option that occurs to me is to add the limit dynamically. Let say you have your training and test set. You can search for the biggest length and create an algorithm that adds the zeros to both datasets. Then let's say a new data you want to predict has a bigger length, then you'll need to recompute all training and test with for this new prediction. You can even check how extending the limit affects your model. 

First of all I think that what you're trying to do is very difficult. A research paper success depends not only of the words but the math, the time when it was published, the journal, etc. You have many features you should take into account. I would try deep learning. For input, I would add all the features above and perhaps more. As the output I would use the number of citations or maybe something more sophisticated like a custom function of popularity. It's not the same to be published in Nature than in other journals. 

I think mxnet is one of the best options if you code in R. They have an R wrapper but the core is in C++. They have several examples in the web. One of them is the character recognition with MNIST database. They have support for multi-gpus and also for Spark. 

I don't think theano have spark support yet, however there are at least 2 deep learning libraries that are good with that. The first one is mxnet, they have support for spark, R, python and C++. Another option is deeplearning4j, made in Java with direct access to Spark. 

The model I would use is the one that minimizes the accumulated quadratic error. Both models you are using, linear and quadratic, looks good. You can compute which one has the lowest error. If you want to use an advanced method you can use RANSAC. It is an iterative method for regression that assumes that there are outliers and remove them from the optimization. So your model should be more accurate that just using the first approach I told you. 

You might want to take a look at mxnet. It is a distributed library for deep learning. It supports C++, python, scala and R. There are many examples with R. Here you have an example of LSTM in R with this library. 

I think there might be a problem in the way you are stating the problem. You say that you test data doesn't have two fields, but that can not be correct. You have to take all your data and split it into 2 groups, the training set and the test set. In a proportion of 80%-20% or 70%-30%. Then you train your algorithm with the data in the training set, and test the accuracy of the model with the data in the test set. The accuracy you get is the probability that your model is correct. Or said in another way, the next time you use your model to predict a sale, the accuracy is the probability that your prediction is real 

This is the typical value function of Reinforcement Learning. The discount factor evaluates the importance of the accumulated future events in your current value. The smaller the number, the less important are the future events in the current action. Usually this number is selected heuristically. I usually select 0.9. If I don't want any discount then I would select 1. 

I am building a model that is trying to predict the 5 year sales production of a salesperson in every zip code in the United States. I have only 7 years of data. This task is one piece of a larger model whose purpose is to determine the most optimal location (as determined by the zip code) to place a new salesperson. My firm has approximately 20,000 sales people located in 10,000 zip codes. These 20,000 salespeople have customers in 35,000 different zip codes. I have historic sales information and zip code demographics. My problem is I am trying to determine the “home zip code” to place a salesperson. Only 10,000 of the 43,000 zip codes are the “home zip code” to a salesperson. My company faces different constraints in every state, so our representation is not uniform, but we are in most states. I can build a machine learning model to predict the production of the salesperson in the 10,000 “home zips”, but how should I approach the other 33,000 zip codes. I’ve thought about building a similarity index of the zip codes based on demographics, sales history and regulatory constraints and building a unique model for each these groupings, but this seems like I’m adding a lot of uncertainty with the clustering/similarity grouping not to mention smaller data sets for learning. My data is based on an annual contracts, i.e., the customer signs a one-year agreement on an annual basis. Any ideas how to best approach this problem would be appreciated 

Each time an ad is served to a given person they may have any combination of the above. For Example, on October 1, person p _1 may be servered with an ad with the following attributes: 

All other variables would have zero contribution for this purchase. Suppose there was 1 purchase for vector_2. I would get contributions of 

so person p_1 was served an ad on oct 5 on mobile, with digital_ctr_B on web_A. There is a cumulative effect to advertising, so this exposure takes the form of 

meaning that they have now been served an ad on desktop and mobile, and seen digital_ctr_B twice, once on web_A and once on web_B. Again, count all the purchases they make before they receive their next ad exposure. Since this is sensitive the time between exposures I thought about modeling the problem as the average purchases per day between exposures. For example if person p_1 made a purchase on oct 2 and oct 3, then we would have y= 2(purcahses)/4(days)=.5 Could I get the coefficients for each variable and then for each purchase divide each unique coefficient-variable product by the sum of the coefficient-variable product for that exposure. Suppose the coefficients for the variables are 

This equates to person_1 being served an add on desktop with digital_ctr_B on web_B. Count the number of purchases that this person makes before getting another ad ( they may only get one ad). If they do not purchase before they receive another ad they receive a 0. For example, 4 days later they receive another ad of the form 

I’m working on a problem that is analyzing purchases at a store and determining the effect from advertising. There are many advertising variables, but to keep things simple, assume there are three types of media: 

web_A= (1*(.037))/ (1*.041 + 1*(.0352) + 2*.047+ 1*.037 + 1*.081) web_B= (1*(.081))/ (1*.041 + 1*(.0352) + 2*.047+ 1*.037 + 1*.081) All other variables would have zero contribution for the purchase. A could make this a binary outcome, “purchased” or “not purchased” and use logistic regression, but I thought this approach would give a more granular view. Is this a sound approach? 

A good library for machine learning with GPUs is mxnet. The package is mostly deep learning though, so if you are looking for specific machine learning algorithms you might not find them there. However they have a good set of deep learning algorithms. 

A good way to measure the difference between two probabilistic distributions is Kullbak-Liebler. You have to take into account that the distribution has integrate to one. Also you have to take into account that it's not a distance because it's not symmetric. KL(A,B) not equal to KL(B,A) 

Can somebody answer that? It would be good if the answer comes with evidences or some research paper. I'm not asking for opinions 

Yes, they can connect natively. You can manage data and then put it all in different services like it is showed next. As you can see you can use SQL database, blob storate and also PowerBI. 

SVM can be used for classification (distinguishing between several groups or classes) and regression (obtaining a mathematical model to predict something). They can be applied to both linear and non linear problems. Until 2006 they were the best general purpose algorithm for machine learning. I was trying to find a paper that compared many implementations of the most known algorithms: svm, neural nets, trees, etc. I couldn't find it sorry (you will have to believe me, bad thing). In the paper the algorithm that got the best performance was svm, with the library libsvm. In 2006 Hinton came up with deep learning and neural nets. He improved the current state of the art by at least 30%, which is a huge advancement. However deep learning only get good performance for huge training sets. If you have a small training set I would suggest to use svm. Furthermore you can find here a useful infographic about when to use different machine learning algorithms by scikit-learn. However, to the best of my knowledge there is no agreement among the scientific community about if a problem has X,Y and Z features then it's better to use svm. I would suggest to try different methods. Also, please don't forget that svm or neural nets is just a method to compute a model. It is very important as well the features you use. 

Microsoft announced a couple of weeks ago virtual machines in Azure with GPUs. They use K-80 NVIDIA cards. The biggest machine has 4 GPUs and 224 GB of ram. Good to play with deep learning :-) 

Just to add some more resources. Recently there was a paper studying the differences between several packages of neural networks and deep neural networks. Here you can find the information. It looks that Torch and TensorFlow are the winners. Note: not all of them are in python. However, I posted it to open the discussion. 

I would suggest Recurrent Neural Nets. They are good for time series, however they need a huge dataset to get good performance. Here you can find an implementation in torch. 

The main difference between supervised and unsupervised learning is the following: In supervised learning you have a set of labelled data, meaning that you have the values of the inputs and the outputs. What you try to achieve with machine learning is to find the true relationship between them, what we usually call the model in math. There are many different algorithms in machine learning that allow you to obtain a model of the data. The objective that you seek, and how you can use machine learning, is to predict the output given a new input, once you know the model. In unsupervised learning you don't have the data labelled. You can say that you have the inputs but not the outputs. And the objective is to find some kind of pattern in your data. You can find groups or clusters that you think that belong to the same group or output. Here you also have to obtain a model. And again, the objective you seek is to be able to predict the output given a new input. Finally, going back to your question, if you don't have labels you can not use supervised learning, you have to use unsupervised learning.