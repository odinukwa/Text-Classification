Only render what is on-screen and can be seen by the player. Which with the iDevice screens won't be that much at all. Your'll probably need to add a simple offset of + 1 to this, as otherwise the player can see the edge tiles being drawn on-screen. Only render tiles that contain items, you don't want unnecessary draw calls rendering blank tiles. 

Well i got it going now :). It seems that i can have other elements using the "Type=Blah" definition, i didn't know that but it's good to know. The Animated_Tiles all needed to be "Items" of the List, i feel stupid :/ make so much sense now that the Elements in the "Animated_Tiles" Element would be required to have the title of Item. But it works great now :D. Thanks you guys for your answers though. 

Yes, that should be fine for your needs. Simple all you are doing would be some form of parallax scrolling methods alongside your basic tile-map with X amount of layers. Unlikely to cause you any issues on its own. Really it will depend on what else you have going on, usually things like physics, any other render intensive calls and how many enemies you will have in your game. Like eBusiness said, testing is key to your performance, in regards you should every now and again when you've implemented something new look at "stress testing". How many of X can i have along with X & X before i start losing performance? Really quite simple things, so shouldn't be too hard. As for simple optimization, remember to: 

Step 1: Load your color and alpha images into two different OpenGL textures. Step 2: Use glActiveTexture to switch to between and bind both color and alpha to GL_TEXTURE0 and GL_TEXTURE1. Step 3: In your fragment shader, define texture samplers for color and alpha, and use the right one to get the right channels in your shader. Step 4: Set "color" and "alpha" uniform variables using glUniform1i to 0 and 1, for textures 0 and 1. This will let you pick different memory layouts for color and alpha, and should still save memory over a standard 32-bit, while providing perfect alpha gradients. 

Since you have an angle in the range of , you can make the range positive without rotating the angle by adding (360Â°). Now your angle is in the range of . You can adjust the range without rotating the angle by computing the modulus: . The resulting angle has the same direction, but is now in the range . 

I arrived at my assumptions because your offsetting code in the vertex shader seems to indicate that your variable is measured in pixels, not normalized: 

Can that be done? Or is it only the "Asset" element that can have the Type definition? Currently this is what my new data layout looks like: $URL$ But currently, it seems to start reading it but i get this error by the first "Tile" Element. So the only difference i see between his & my layouts are that he has the Asset containing the List definition whereas i have "Animated_Tiles". So i'm unsure can any element can have the "Type=Blah" definition? 

So i'm not quite sure exactly what "glow textures" are. For my implementation of a "lightning" effect, according to the comments on the article; $URL$ They guy uses "glow textures". To achieve the really cool effects on his beams. I'm trying to-do the same thing, except that i'm not 100% sure what a glow texture is, currently the texture i'm using produces this output *I'm also using a simple shader to adjust the color value the lightning is rendered at; $URL$ Which isn't very good, it has the shape of the lightning but it doesn't have the sorta "flare" of it. This is a screenshot of my current texture that i'm using: $URL$ So essentially what i'd like to ask is mainly what is a glow texture? And perhaps to see an example of one would be really appreicated. Edit: Taking the advice of kaoD, i'm now rendering the using Additive Blending, I've also got the Max Blending working, yet, still the bolt's do not produce the required effect that i'd like. Here's another video of them in action with the current code; $URL$ And here's specifically how i'm rendering them; 

There is no canonical "correct way" to approximate general functions. Sorry. With that said, the very source you linked to has suggested the Lafortune representation. This representation has been described as "...compact and works well for hardware rendering..." in chapter 18 of GPU Gems. Implementation details appear to be out of scope for this question. 

Which conveniently brings the n-th peak into the relationship. Since you've specified both the decay time, and the number of crossings, we can derive a relationship between the two constants we are trying to compute: 

I didn't check thoroughly, but one major problem I see here is that you aren't following the OpenGL manual: This line of code is never valid: 

Sounds like you are asking for a convex hull, this is sortof like "gift wrapping" all your vertices. (Otherwise, if the shape can be concave you cannot imply it by the vertices alone) Wikipedia has a good list of techniques here: $URL$ And google code even has an implementation (I haven't tested this): $URL$ 

Color keying: Check if the alpha or color is equal to a magic cutout value. Alpha partitions: Obtain separate specular and transparency values using line equations. 

So using my copy of ATL, and just making a quick test tiled map, this code worked fine. Using base64. Should look like; $URL$ Result; $URL$ Map: $URL$ & my test sheet; $URL$ For clarity & any future reference ATL is a bit outdated, doesn't support polygons/polylines that are available in Tiled. It does however support older versions of LOVE. Whereas the atlernative; STI requires LOVE 0.9.1 but does provide updated support (Link) 

Here's a rather basic but great starting point to drawing textured quads in OpenGL, from this function starting point I have 7 other functions that provide slightly different functionality, to drawing with tinted colours, to drawing items with different alpha values and then we have rotation, clipping etc. etc. But this should help get you started :). Edit: Updated Code; 

Any help with this would be greatly appreciated. P.s - The base layer of tiles is rendering correctly just in case anyone was wondering, i just kept the entire base layer at tileID 0. *the plain grass tile you see in my output :) 

Image is a basic structure holding the texture data (GLuint) and then two integers to hold width & height. 

The "best" option is to try it yourself and see what's faster. I will put my money on option 1 being faster. You will only gain performance benefit this way if the pillar is incredibly expensive to draw, and you use effective culling. 

One way to accomplish this would be to use an FBO (Frame Buffer Object) and multiple depth buffers and/or depth textures. A basic use case is shown on the Wiki at OpenGL.org. 

But in order to retain flexibility in situations where multiple handlers may need to observe the event, "Bubbling" can be applied so that all handlers get to see the event: 

Which appears to be right on target, crossing 4 times to achieve a peak value of 0.01, after 5 seconds of simulated time. 

A less effective, but simpler, approach would be to use a fixed timestep. This can be achieved with a function like or . Be warned there are issues with these routes: might create a queue of frames to draw faster than they can be pushed. might leave you waiting too long for your next frame. With that said, here is another example jsfiddle 

I should mention that im not looking for any sort of rotational movement, just smooth diagonal and directional movement. However, i'm at a lose on how i can achieve that... So any help greatly appreciated :)! Edit: Smooth Transitioning between movements is what i'm looking for. Right now, the units sometimes (not sure how to describe but they "stutter" along), looks like they are shaking when moving. As to what i tried before, i had the position being updated directly in the If statements, that didn't give me any stuttering but did not seem like a good approach so i changed to the one above. 

I have my units that i move around my map with path finding. The units can move in 8 directions, currently i have the units moving around the map with a extremely basic check against the unit's current position vs. the next target destination in an array of Vector2s (the path). However, the movement is rather jagged and not very fluid. Current code (I know its not very good, i did this just to test out the pathfinding really); 

Long answer: (pre-calculus required) Define your jump function which is a simple integral over time: 

It looked logarithmic to me so I went ahead and fitted the natural logarithm to your points, then plotted to verify (and adjust coefficients). 

Which is our answer, notice that time is still unknown in this system. This means there are infinite trajectories that will land on the purple rectangle. You have to decide how long it should take. 

You're right on track with using the context only from a single thread. You can only use an OpenGL context from one thread at a time, but you can do everything else in another thread. 

You are using sampler 0 for every single texture, you should fix this call so that it looks more like: 

Lazy loading! Add a method to SpriteComponent to let it store the name of the new sprite to load, then let the SpriteSystem load the actual data whenever it comes into play. To smooth out the loading laggies, preload. 

Since I get the idea that you have rolled your own custom game software, you might as well roll your own shader tool. If you show the GLSL compile errors you are halfway there. To bring the experience up to something realistically usable, integrate inotify into your shader loader, and trigger your engine to re-compile shaders when a change happens on disk. This will give you a truly What-You-See-Is-What-You-Get interface for developing GLSL code without wasting massive effort. You can then use any code editor and your own engine will provide live preview. (Works great with always-on-top or multi-monitor) EDIT: For windows you can use FindFirstChangeNotification 

Edit: So i'm going to rephrase the question a bit, seeing as now i think know how i'm going to read this data. Looking at this example as my guide: $URL$ This is pretty much what i'm currently doing, and to be clear and show you guys: $URL$ that's how i'm loading my data. So looking at that guys example from his post, he has a similar layout, his "Enemies" can equal my element "Animated_Tiles" and then his "Items" could be equal to my "Tile" objects, at least if you compare my data to his they look extremely similar, and yes i did update the Data as Richard Marskell - Drackir suggested, But i'm wondering if i can have "Type" definitions like the guy has in his example, to show what i mean: 

There you see target is then a pointer to an enemy address, the cEnemy (currentEnemy). What my desired effect would be to have my Projectile store the enemy that I pass into it which then until it hits that enemy, the targeted enemy will forever stay focused on the enemy passed in when the projectile was first created. Again any help greatly appreciated! For reference Enemies = Class Name. enemies = vector array of active Enemies. cEnemy = (Pointer to Enemies Object)/Enemies* cEnemy. 

The fix is simple, integrate position in the middle of integrating velocity. (As in, add half of the force, update, then add the other half.) Here is a more in-depth explanation: $URL$ 

This answer will focus on statement #3 in the original post, and is meant to supplement ToddersLegrande's answer 

Sampling the heightmap with a clamping mode produces an output like such: Or with a wrapping mode, produces what was shown in your comment: (Including the errors around the border) 

One reasonable approach would be to use a loop to update your X and Y, and draw again repeatedly. This would involve computing delta time, and using it to animate your coordinates. Here's an example jsfiddle: 

Variance shadow mapping, plainly put, just suffers from these light bleeding issues. I personally prefer to implement ESM (check out page 257 of ShaderX6) as the memory pressure is half of the VSM map and the artifacts are much less abrasive to me: (The very beginning of the shadow is a bit too bright.) With this said, here is a (rather old) PDF full of great techniques to get you thinking. (or just to show you the algorithm if you don't have ShaderX6) $URL$ In my current engine, I have a hybrid which is basically ESM, but uses the 2-moment (or higher) shadow map to compute the variance and reduce the ESM artifacts at the places where the occluder is too close to the receiver. 

Is so much more clear and leaves no room for interpretation, i can easily see that this code will come into play when the character is facing right. So i'd say yes, there's nothing wrong with using a 'state machine' even in this most basic of ways. It just keeps things clean and nice to read. P.s - I don't think there's a difference between using enums & bools, i mean they both do exactly the same job, i suppose the only difference with boolean's is that like you have done, there's more work involved in making sure the "facingLeft" bool would have to be set to false & vice versa in the opposite movement functions. Its all about personal preference really. 

The SDL2 version is currently not slated to replace the Linux, Mac & GL solutions but when i asked the Dev he replied with "I hope so." I also asked him about shader versions; 

well i'm just wondering on the best way to go about create some form of "Lightning" effect to be used in a game, so for example: -In my game, i would like to have this effect in the menus and in-game in some form of random weather system perhaps. Just wondering on the methods available? I did read this blog post: $URL$ And took a-look at the Lightning sample thats around. I like the method placed in the blog post, just really a bit unsure on how to create the vertices from the lightning segments. I would be great if someone could explain that seconded sub-heading (Adding glow) a bit more to me :). But like i said, i'm really want to know if there's any other ways i could accomplish this?