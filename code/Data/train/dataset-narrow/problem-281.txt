The first thing you need to understand is that VLANs are an Ethernet concept. The switch doesn't care too much what kind of higher level traffic is flowing over them. The second thing you need to understand is that switches have very limited IP functionality. Many only support IP for management purposes, those that do support IP routing usuaully only have very basic routing functionality. The third thing you need to understand is that overlapping IP blocks are a massive pain in the arse. If you can eliminate them you should do so. 

It's a little more complex than that. The hub has to have circuitry to decode the wire-level encoding of incoming data and encode outgoing data in the correct wire-level encoding. This includes handling special cases like preambles and idle ports. The core logic of the hub waits for incoming data to be detected by one of the receivers. If it detects incoming data on a port then it sends that data out of all the other ports (but not out of the port it came from). If it detects incoming data on more than one port at a time then it outputs a jam signal to ensure the collision is seen throughout the collision domain. 

On a wired bus signal losses are fairly small and so it is fairly easy to detect collisions. IIRC coax ethernet does it by looking at the DC level on the line but it would be equally possible to do it by comparing the signal on the bus to the signal you are trying to transmit. That just doesn't work for radio. Signal loss between transmitter and receiver is massive, tens of DB at least. In the face of the strong outgoing signal it is impractical to detect the incoming signal which is operating in the same frequency spectrum and is massively weaker. This basically rules out collision detection as an approach for wireless systems. P.S. Twisted pair and fiber Ethenet uses seperate data channels for each direction, so there are no collisions on the wire. A "collision" is detected simply by detecting activity on both channels at once. 

TCP has congestion control algorithms. If all hosts are using the same congestion control settings then after a while things should balance out so that all the TCP connections get roughly the same share of the bandwidth. Bittorrent uses lots of TCP connections for the same download job, so it will grab a much greater share of the bandwidth on a congested link. 

TCP is a bit smarter than that, when it starts a new connection it will send packets relatively slowly. If all of them are delivered successfully it will increase the data rate, if loss is detected it will reduce the data rate. The result is after sending data for a while TCP will settle at a speeed that uses most of the bandwdith available between the two hosts while keeping packet loss low. 

IPv4 and IPv6 are fundamentally quite similar. The basic principles of NAT work equally well (or equally badly depending on your point of view) for both. IPv6 NAT (especially one to many NAT) while possible is strongly discouraged. The IETF has not published any specifications for one to many IPv6 NAT and the one to one stuff (known as network prefix translation) has only been published as an "Experimental" RFC. As far as I can tell pfsense only supports prefix translation ( $URL$ ) and not one to many NAT. Linux on the other hand supports both prefix translation and one to many NAT. I don't think prefix translation is going to help you, so unless you are prepared to move away from pfsense I don't think NAT will solve your problem. 

Assuming you want to run gigabit or 10 gigabit speeds, multimode tends to reach it's limit at a few hundred meters. Exactly what "few" means depends on the precise type of fiber you have and whether you want to run gigabit or 10 gigabit. Getting those distances at 10 gigabit over old fiber will require more expensive LX4 or LRM transcivers. Singlemode can go much further. As I understand it 100km is about the limit for a single segment without intermediate amplifiaction. 

Probablly not honestly, at least as a tourist. Mobile networks and public wifi tend to involve being behind a NAT you don't control anyway. 

Assign two subnets to the network with 77 users. If we assign it a /26 and a /27 we cover it's users while leaving a /26 free for further subdivision. Downside is that some formerly local traffic will end up going via the router and local firewalls may make incorrect assumptions about what is on the local network. Use proxy arp on the subnet with 77 users. We can then assign smaller subnets which overlap with unused parts of that subnet and proxy arp will pick up the traffic. Again local firewalls may make incorrect assumptions about what is on the local network. Proxy arp can also magnify the problems experienced in the event of a misconfiguration. 

The big question is are we talking twisted pair or Fiber? With twisted pair nearly everything supports autonegotiation and unless your equipment is very old autonegotiation works just fine. Occasionally you may find a crossover cable is needed. Be aware that mixing autonegotiation with manually set full duplex is likely to lead to a duplex mismatch. You should only use manual speed/duplex if you have problems with autonegotiation and if you do use it you should use it on both ends of the link. Fiber on the other hand is a mess of diffent incompatible standards. 1Gbps fiber standards are not compatible with 100Mbps fiber standards. Most 1Gbps fiber gear uses pluggable transcievers and it may be possible to get a 100Mbps transceiver that is compatible with your 1Gbps switch and is compatible with the fiber standard used by your 100Mbps device. Alternatively if the gigabit switch also has twisted pair ports it may be possible to use a media converter to go from 100 Mbps fiber to 100 Mbps twisted pair. 

The second thing to do is to get the guests off your main network onto another VLAN/SSID. This will free up address space and allow you to place firewall rules between the guest network and the main network. 

Assuming you are using static routes I suspect the most likely explanation is that you made a typo when setting up the route. 

It's efficient when you are transferring bulk data using a connection orientated transport protocol on a network that reliably supplies packet too big notification. Unfortunately that doesn't always match up with the real world. 

Wifi uses different techniques as direct collision detection is not feasible in the wireless environment. 

The reason you struggle to find a straight answer is because it depends on multiple factors including 

To forward a packet a host or router looks up the destination IP address in it's routing table. Routes can either point to just an interface or to an interface and a next-hop IP address. If the route specifies a next hop IP address then it will be used, otherwise the destination address will be used as the next hop IP address. What happens next depends on the L2 encapsulation in use on the outgoing interface. If it is Ethernet or similar then the IP address will be mapped to a MAC address using the ARP table and if needed an arp lookup. If the interface is a true point to point then the next hop IP address is likely to be ignored. Normally the only routes without a next hop specified are those for directly connected networks (usually created implicitly as part of configuring the interface address). 

Given that AT&T and Verizon are both teir 1 ISPs it will almost certainly pass over a private peering link between them. That link may well not be especially local though (you can often get hints as to the geographic route from the hostnames in traceroute). 

Resources for a tenant may be spread out through the datacenter due to gradual growth over time or a desire not to "put all your eggs in one basket". Running long dedicated cables for each client gets expensive. Resources are likely to be reallocated over time. Physical re-patching when resources are reallocated gets expensive and time consuming. One VM host may host VMs for many different clients. Fitting a seperate NIC to the VM host for each client would get prohibitively expensive. There is a certain minimum cost for a router or switch. Having switches with only a handful of ports used gets expensive. 

An AS isn't limited to one datacenter. Large ISPs have globe-spanning networks, so they can move traffic arround the world while keeping it in-network. Therefore from the point of view of the rest of the internet their network can be treated as a single network. Cogent are a transit free network, so to provide their customers with access to the internet* they will need to announce all their customers to all the other transit free networks that they peer with (and likely to most of the other networks they peer with though sometimes peering politics lead to only a subset of customer prefixes being announced) and similarly provide routes for outgoing traffic to all those peers. Of course with many/most of their peers they will be interconnected in multiple locations. They will likely use some mechanisms (such as nearest-exit routing for outgoing traffic and/or multi-exit discriminators for incoming traffic and/or artificially extending the "AS path") to try and prevent traffic taking stupid routes (sending traffic across the atlantic twice is generally considered a way to annoy customers and waste money). * Well most of it. They have an ongoing peering spat with HE and HE consider themselves to be an "IPv6 teir 1" and refuse to buy IPv6 transit. So there is no IPv6 connectivity between HE and cogent. 

If C sends packets as fast as he can both links will be filled, but only half the packets will reach H, the other half will be dropped by the router. On the other hand if C runs a protocol like TCP then his TCP/IP stack will estimate the availble bandwidth for the full path and the data rate through the two links will be very similar. 

Drops are normally caused by buffers filling up. If data comes in destined for a port faster than it can be sent out of that port then some of it is going to have to be dropped. In general most bulk transfer protocols will increase the data rate until they start seeing packet drops then back off slightly. So it is absoloutely normal that some packets are dropped somewhere in your network. Where the drops happen will depend on the topology of your network. If the ASA is doing routing between local subnets then the line from the switch to the ASA is likely one of the most congested on your network, so it is where you would expect to see drops. If the ASA is only doing routing to/from the outside world then it would be more unusual to see drops on the line feeding the ASA unless your internet connection is as fast as your LAN. Total packets dropped is a fairly meaningless metric, what you really need to know is the proportion. 

Someone mentioned anycast in a comment on the question. Anycast is possible with both approaches but you have more flexibility with the "one network" approach since the smallest route you can advertise on the internet is generally a /24 while within your own network you can route individual IPs or even route based on information other than the destination IP. 

A 10BASE-T link uses one pair for each direction. It was nessacery to connect the transmitter on each end to the receiver on the other. One approach would be to cross every plug to plug cable and every socket to socket cable/adapter resulting in always having an odd number of crosses between any two endpoints. This approach is the one generally taken by fiber communications standard. However it has a couple of significant downsides.