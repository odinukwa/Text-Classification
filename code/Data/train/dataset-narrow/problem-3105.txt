Like @SeanOwen pointed out its called . spark.mllibâ€™s FP-growth implementation takes it as a hyper-parameter under . It is the minimum support for an itemset to be identified as frequent, e.g : if an item appears 4 out of 5 transactions, it has a support of 4/5=0.8. Usage: 

Now all we have to do is a simple group by and perform a collect_list aggregation on the first dataframe : 

EDIT: To avoid confusion for some concerning PCA and Dimension Reduction, I add the following details : PCA will allow you compute the principal components of your vector model, so the information are not lost but "synthesized". Unfortunately there is no other imaginable way to display 39 dimensions on a 2/3 dimension screen. If you wish to analyze correlations between your 39 features, maybe you should consider another visualization technique. I would recommend a scatter plot matrix in this case. 

If you want to understand how spark internals work, I suggest that you watch the presentation made by Databricks about the topics 

You are actually creating and Frequent Pattern model without generating candidates. So actually you'll need to generate afterwards if you need to use them with : 

You can also set a threshold where you can drop a recommendation at a certain limit of your prediction level. E.g. Let's say an user alpha has the following recommendations with a threshold of 0.7 

Like I said in the comment, you'll need to perform dimension reduction, otherwise you'll not be able to visualize the $\mathbb{R}^n$ vector space and this is why : Visualization of high-dimensional data sets is one of the traditional applications of dimensionality reduction methods such as PCA (Principal components analysis). In high-dimensional data, such as experimental data where each dimension corresponds to a different measured variable, dependencies between different dimensions often restrict the data points to a manifold whose dimensionality is much lower than the dimensionality of the data space. Many methods are designed for manifold learning, that is, to find and unfold the lower-dimensional manifold. There has been a research boom in manifold learning since 2000, and there now exist many methods that are known to unfold at least certain kinds of manifolds successfully. One of the most used methods for dimension reduction is called PCA or Principal component analysis. PCA is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components. You can read more on this topics here. So once you reduce your high dimensional space into a ${\mathbb{R}^3}$ or ${\mathbb{R}^2}$ space you will able to project it using your adequate visualization method. References : 

$URL$ This is the time-stamped video of "deconvolution". I can understand normal convolution but not so much with upsampling convolution. In the video he explained that you plop down the filter and use each individual scalar as the weight to apply to each value in the filter. I am having a hard time understanding how he got an output shape of 4x4? Is there a special formula for calculating the output for "upconvolution"? I am also confused on the padding and how it affects upconvolution? My crappy paint image 

I have implemented a vanilla GAN which gave good results very fast but it had a lot of mode collapse issue, because of this I learned about WGAN which suppose to fix this, in fact they claim they have never encountered mode collapse problem which is great. My main issue is how slow WGAN takes to converge to good results. With a vanilla GAN by epoch 10 I was getting good looking generations, with WGAN I am still seeing noise images on epoch 50! Besides bumping up the learning rate is there anything else I can do? The network is a modified smaller DCGAN that has 1 less output layer than the original. So instead of the extra 1024 output layer mine stops at 512. I knew WGAN was going to be slow from all the research I have done but I didn't except to be this slow. Can some one point me to the right direction on how to better optimize WGAN's speed? I have googled around but most results are just vague comment chains or agreements that there is a speed problem with no further leads on what you should do next to counter this issue. 

Most of the advanced deep learning models like VGG, ResNet etc. require square images as input, usually with a pixel size of 224x224. Is there a reason why the input has to be of equal shape, or can I build a convnet model with say 100x200 as well if I want to do face recognition for example (and I have portrait images) ? Is there increased benefit with a larger pixel size, say 512x512 ? 

I built a prediction model and predicted on new data. I now want to specify a value of my confidence in this predicted value, e.g. ranging from 0 to 1. Three methods come to my mind 

So far there are many interesting applications for deep learning in computer vision or natural language processing. How is it in other more traditional fields? For example, I have traditional socio-demographic variables plus maybe a lot of lab measurements and want to predict a certain disease. Would this be a deep learning application if I have lots of observations? How would I construct a network here, I think all the fancy layers (convolutional etc.) are not really necessary?! Just make it deep? On my specific data set, I tried some common machine learning algorithms like random forests, gbm etc with mixed results regarding accuracy. I have limited deep learning experience with image recognition. 

I'm dealing with a regression prediction challenge where the evaluation metric is (pearson) correlation. However, I have the impression that this metric is kind of arbitrary. While I can keep the RMSE stable the correlation can have great variety. Could someone please explain this metric and how to optimise for it? 

So far I have read 2 papers on GANs and it seems like they are unsupervised networks that only uses supervision for the discriminator. If I want to translate an image from a picture to line art all I need to do is to prepare my ground truth "the unmodified picture" and the corresponding line art correct? Do I have to pre-classify any facial feature for the generator to learn the corresponding line art or is that what Conditional GANs are for? I am trying to brainstorm my own project but the data preprocessing stage is a little hazy. 

OP here: $URL$ This has helped me understand how deconvolutional layer or transposed convolution works! Note to self don't google deconvolution or upconvolution google transposed convolution instead. Update 2: $URL$ It turns out "deconvolution" is just convolution but with different arithmetics. You can take the transpose or add enough padding so that 1) You can upsample instead of downsampling. 2) Keep the previously linked relation, what I mean is you need to make sure each upsampled filter still contains a symbolic link with the smaller input. 

The 3 questions in the second images are, how is x, y-axis represented and in the our case? In the original paper instead of using fixed histogram bins, the author uses smaller "signatures" instead, I visualize them as tiny boxes that make up a single histogram bin. How are signatures represented in our particular case? 

I tried this with some sample images. My vector x is of shape (100, 3, 224, 224) for 100 observations, 3 for RGB and 224x224 pixel size. the reshapes this for the VGG model (it expects a different order). However, the output shape of is (100, 512, 7, 7). What is this shape? I want to use the features as input for a logistic regression. So I need a shape like (100, n): one row for each observation and the features in the columns. How do I reshape the output to this dimension? Say I now want to build my own simple Convnet: 

Built 100 models on bootstrapped data, predict 100 times on each new observation, then calculate confidence intervals. Smaller intervals mean higher confidence. High computational effort. use oob predictions of a random forest from every tree Bayesian methods can give confidence intervals through the posterior 

This model expects grayscale images as input, hence the shape. What kind of layer do I have to add to get features of this model (something I can input in a logistic regression or random forest). Thanks 

In the kaggle forums I found an example model where someone was using XGBRegressor for a binary (0/1) classification problem (sorry, cannot find the link any more). This was for a competition where output is measured by AUC, so only ranks mattered. I then tried this for a different problem with my data and also found a slight improvement using the Regressor instead of the Classifier. Some of my predictions where negative, but it would be no problem to shift them to the [0,1] interval. So is using regression for binary classification a common approach, and what are the pros and cons?