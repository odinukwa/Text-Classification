You have not given us the network device models and configurations, so we cannot give you the specific configurations. Also, I would not use a VLAN between the LAN and WAN routers. You should probably configure the interface on the layer-3 switch as a routed interface, rather than a switched interface. 

I don't know of any command to send an arbitrary message to the syslog server. Cisco has documents describing the logging facility, e.g. System Message Logging. 

Also, the Panasonic model is a SIP phone, and I see no mention of SIP in the specifications of the Gigaset model. 

You need to look at whether it's applied inbound or outbound (you didn't specify), and the source and destination on each line. It's also important on which interface (you didn't specify) you apply the ACL. You need to think it through and select the correct interface, correct direction, and the correct source and destination for what you want to do. A better explanation would help us to help you. 

There are a few problems with your premise. First, connecting switch ports to switch ports will either end up disabling the switch ports or causing a spanning-tree loop. Switches send BPDUs to determine the switch topology. Properly configured switches will have the access ports set to and . This configuration will disable the ports in order to prevent spanning-tree loops. As suggested by @generalnetworkerror, bad cabling or duplex mismatch are good places to investigate. Be sure to clear the counters, test the switch with some sort of traffic generator(s) on the original cabling, then look at the individual interface counters. It is also very possible that you have one of the counterfeit Cisco products that are far more pervasive than anyone wants to believe. It doesn't matter that you bought this switch as new from a reputable Cisco dealer since these fakes have found their way far deeper into the distribution pipeline than anyone will admit. The counterfeiters have done a very good job at copying all the telltales, including the chip stamps and holograms. Many counterfeit devices are out in production networks, running things just fine, but some cause these sorts of problems until they are sent back to Cisco for warranty work, where they are discovered as fakes. 

You can change the network(s), values, and actions to fit your particular situation. You have not provided enough information in your question to give you a good example. Remember that things that have both source and destination addresses, like extended ACLs, should be applied as close to the source as possible in order to avoid unnecessarily routing traffic that is destined to be dropped, which will waste router resources. 

I'm not sure I really understand the question, but I think you are confused. Why would routers have better signal reception that WAPs? A router with Wi-Fi capability merely has a WAP added to it. WAPs may be placed where you wouldn't place a router (e.g., in the ceiling in the middles of a room), moving the WAP closer to the clients. Multiple WAPs can all be on the same LAN, allowing roaming without reauthentication. 

You may be able to do something with an EEM script to fail an interface on the now Active secondary unit when the now Standby primary unit comes back up, and then restore the failed interface after the unit returns to Standby. This is a real kludge because this is not the design for Active/Standby. 

Jumbo frames are actually end-to-end, but frames only exist on a single layer-2 LAN because routers strip off the frame before forwarding the packet (frame payload). As I explained before, frames are not routed. Frames (layer-2) may be bridged (switched) on a LAN, but they do not survive crossing a router (layer-3). At layer-2, if a jumbo frame hits an interface of a bridge or host that cannot use jumbo frames, the frame is dropped as damaged or giant. Evey interface through which jumbo frames pass must recognize the jumbo frames. The problem with that is that there is no standard for jumbo frames. Each vendor has its own way to do that, and even within a vendor, different devices may use different jumbo frame sizes. There are switches that can use one size for some interfaces, but other sizes for other interfaces. You must carefully plan the LAN to use jumbo frames, and your hosts must recognize them, too. 

Except for frames in the native VLAN, when a switch puts a frame on a trunk, it inserts a VLAN tag into the frame. The TCI is 16 bits, which increases the maximum frame size from 1518 bytes to 1522 bytes. The first four bits basically serve the purpose of layer-2 QoS. Three bits are for the priority, and one bit is for indicating whether or not the frame is eligible to be dropped if there is congestion, although in extreme congestion, it can be dropped, anyway. The last 12 bits of the TCI are the VLAN ID. This gives 4096 different VLAN numbers (0 to 4095), the first and last of which are reserved for special purposes. A switch, receiving a tagged frame will look at the TCI before stripping it out of the frame and sending it to an access switch port which is configured for the VLAN contained in the VLAN ID of the TCI. It strips the tag out of the frame on access ports because hosts generally don't know what to do with a tagged frame. If a host supports tagged frames, the switch port to the host can be configured as a trunk port instead of an access port. A VLAN numbering policy is up to the network designer. Typically, VLAN 1 is used for the native VLAN (untagged frames on trunks) because it is the default VLAN for most switches. Using VLAN 1, or even having a native VLAN at all, can open you up to some layer-2 attacks and security risks, but depending on the vendor, switch model, or software version, some switches must use VLAN 1 and/or a native VLAN. Cisco switches will not let you remove VLAN 1, but with modern IOS, you can restrict any VLAN, including VLAN 1, from a trunk, and you don't need to have a native VLAN configured for a trunk. 

When an application wants to send data to an application in another host, it requests a connection (use of a particular port) with a layer-4 protocol, such as TCP or UDP. The layer-4 protocol divides the data into datagrams called segments, and it applies the segment headers, including layer-4 source and destination addresses, such as TCP or UDP ports, to the segments. The layer-4 segments are sent to layer-3 where packet headers, including the layer-3 source and destination addresses, such as IP addresses, are applied. The layer-3 packets are sent to layer-2 where frame headers, including the layer-2 source and destination addresses, such as MAC addresses, are applied. In order to get the destination layer-2 address, layer-2 must resolve the layer-3 destination address into a layer-2 address. This is where ARP (Address Resolution Protocol) may come into play. Layer-2 first checks its ARP cache for the resolution. If it doesn't find it there, it will send an ARP request for the destination host to reply with its layer-2 address. If the layer-3 address is on a different layer-3 network, it will use the layer-2 address of the layer-3 gateway. Layer-2 will then pass the frames on to the layer-1 hardware for serialization, and to put the resulting bits on the wire. When the receiving host (or gateway) gets the bits, it deserializes them, and de-encapsulates the frames, packets, and segments, passing the resulting data up to the receiving application. Note: ARP is only needed for sending, not receiving since all the addressing is already included in the received data. If the receiver is a gateway (router), it will de-encapsulate the frames since they are only useful for the local LAN. The router will then inspect the layer-3 headers for the destination layer-3 addresses, and look in its routing table to see if it has next hops for the packets. If the router has no next hop for a packet, it will discard the packet, otherwise it will switch that packet to the next interface and repeat the process of encapsulating the packet into a frame for the new LAN to the next hop. The new frame will then be serialized into bits for the next link. Some routers only have hardware queues, and some have user-definable queues which may be sized according to the type of traffic. There may be priority queues which get served first. Packets may be randomly dropped in order to prevent queues from filling up, or they may just drop any packets when the queue is full. Discussion beyond what I have described may be either device-specific, or too broad for this site. 

TCP doesn't know. The router(s) in between will fragment IPv4 packets as necessary. The TCP segments are the payload of the IPv4 packets. RFC 791, INTERNET PROTOCOL details the fragmentation process, and what the end-device needs to do to defragment the packets upon receipt. The IPv4 header has fields to facilitate the fragmentation/defragmentation process. 

You need to use the command after you change a router ID. Alternatively, you could just restart the router, but that seems extreme. 

You need software to read the syslog which can give you only the level 6 messages in which you are interested. 

The IMEI is below layer-3 (IP) or layer-4 (TCP) so it will not be transmitted beyond the carrier network to the public Internet. 

My two cents, based on experience: I would actually have a routed link between the firewall and the layer-3 switch, rather than a VLAN, and run a routing protocol between all the layer-3 devices. Static routes just don't scale. Configure the switch interfaces as layer-3 interfaces, and address them as point-to-point interfaces with or networks. You are using networks on the SVI for the VLANs, but you can run into some problems with delayed detection of link problems using SVIs, and you don't have that if you address on the physical interfaces. For the 4507, instead of: 

A router also knows which interface a host is connected on. Remember that at layer-2, another router is just a host on a network. The router knows nothing more about another router than it does a host. Also, only an ARP request is broadcast. ARP also specifies that a host create an ARP table, and ARP may simply find the layer-2 address in the ARP table without using broadcast. 

Remember that the OSI model is just a model, and nothing in the real world actually adheres to it. I believe what this is trying to get across to you is that the application in one host is peering with the application in the other host. Also, the transport protocol in one host is peering with the transport protocol in the other host, the network protocol in one host is peering with the network protocol in the other host, and the data-link protocol in one host is peering with the data-link protocol in the other host*. The data that one application sends to the other application ends up in the destination application unchanged. Yes, as the data moves down the network stack in the sending host, it gets headers from the various network layers attached to it, but as it travels up the network stack in the destination host, those headers are stripped off, leaving the original data from the source unchanged. Each network layer in the source host adds a header for the corresponding network layer in the destination host, and the corresponding network layer in the destination host will strip off the header, leaving the PDU for the next layer unchanged form the source. 

A broadcast, like ARP, will interrupt every host on a LAN, and require each and every host on the LAN to process the request to see whether or not the ARP is for the host. Multicasts are selective broadcasts, and only the hosts subscribing to the multicast group will receive the multicast. This method will only affect one or a few hosts on a LAN instead of all the hosts on the LAN. 

TCP is a reliable transport protocol, and it will request missing segments to be resent. The segments get sent, get lost or corrupted, and resent. This causes more data to be sent. 

As applied, your ACL is denying any IP traffic destined to into Area 3. From what you described, I thought you wanted to deny traffic leaving Area 3, not entering it. The and keywords on the command are from the perspective of the router, not the network or area, so the that you use means anything outbound on the Area 3 interface (into Area 3). You are probably trying to overthink the wildcard mask, which seems to be incorrect based on your question. It will not deny traffic to hosts in any other area. You probably just want something like , meaning you will deny traffic to any host in the address range. It doesn't affect hosts in Area 3 from sending traffic to any host in Area 3. You can't do that from the router because the hosts in Area 3 are connected to a switch, and the traffic will pass directly from host to host, not through the router. You probably want something like this: 

You can't use or on the same network because it counts router hops. It uses the IP TTL that is decremented by routers, but devices on the same network communicate directly, not through a router, so the TTL will never be decremented, and a router will not generate an ICMP message telling or that the TTL timed out. 

Alternatively, and I think more cleanly, you should be able to run OSPF across your VPNs, but assign those links higher costs than OSPF across the MPLS cloud. That would let OSPF dynamically change the routes to the lowest cost path that is up. 

Home routers (consumer-grade devices) are off-topic here. Business-grade routers will have an address for each interface (whether physical or logical) used, and they will route between any of them. With VLANs you will be creating logical interfaces for each VLAN, and each VLAN will need a router address for the VLAN it serves, and those addresses are the gateways for the VLANs they serve. 

CDP is not sent per subinterface. CDP is sent to a specific, link-only, multicast address that is sent either on the physical interface, or only one subinterface. Cisco has a document, Behavior of Cisco Discovery Protocol between Routers and Switches, that describes the behavior 

You will get Native VLAN Mismatch errors. The two VLANs will now be one layer-2 domain instead of two, and this may be a problem, or not, depending on how the rest of the network is configured and connected. If the ports have DTP enabled, and at least one side is Desirable, a trunk will form. If you have BPDU guard enabled on either port, it will be errdisabled. 

I think you may be looking at the Return Loss, and the higher the Return Loss, the better the cable. You don't want the power reflected back to the source, so a 100% Return Loss would be ideal. 

As Ron Trunk pointed out, bridging VLANs can be problematic in the results. Cisco offers SPAN for network monitoring. You can mirror the traffic from on or more interfaces or VLANs to an interface to which you connect your monitoring equipment. There is also RSPAN that lets you transport the the mirrored traffic across layer-2 to a different switch, and ERSPAN (for select equipment) that will encapsulate the mirrored traffic so that it can cross layer-3. Understanding SPAN,RSPAN,and ERSPAN 

The nibble can't be converted to because that's what converts to. Before you ask why doesn't convert to , it's because converts to . The nibbles are converted from a dictionary, and the dictionary specifies that converts to . Encoding and decoding by a dictionary is fast and easy, which is appealing when designing communications systems. 

I'm not sure I completely understand your question (the document does have a combination of path redundancy and daisy-chain), but I can explain the problem with daisy-chains. Normally, you want path redundancy. That is why the Internet was developed in the first place. It allowed traffic to automatically be routed in a different direction in case of damage (being funded by the DoD, nuclear war). Path redundancy eliminates single-points-of-failure (SPoFs). When you daisy-chain paths, you introduce SPoFs. If one link or device in the daisy-chain fails, then the two resulting parts of the daisy-chain are isolated. This can be a problem, and the daisy-chain is depicted in Figure 5 of the document to which you link: 

A pause frame can be MAC-to-MAC which is host-to-host through a switch. It can also be sent to a special multicast address which a switch will not forward, but the switch itself may or may not participate in ethernet flow control. The use of ethernet flow control is implementation specific, and not widely or consistently supported. The way it works, or doesn't, on your network is going to be dependent on your network equipment and the software on those devices, and the specific hosts and OSes of the end devices. 

If this is a large Wi-Fi deployment, you probably want to look at a system based on a wireless controller and LWAPs. The only real experience I have with such a combination is with Cisco. Cisco has a large product line of controllers, LWAPs, and WAPs. Fortunately, the Cisco devices seem to perform well. There are occasional updates which we thoroughly test if the added features interest us. The wireless controller-based system allows the LWAP updates to be fairly painless since the LWAPs get their software and configurations from the controller. Using Local mode means that both the management and data traffic are tunneled back to the controller, which can be remote from the LWAP. This has both advantages and disadvantages. The newer Cisco switches (3850, 45xx Supervisor 8, etc.) provide some wireless controller functionality built in to the switch to allow data traffic to be dropped locally. This mode allows for seamless roaming between LWAPs, regardless of subnet/VLAN, without re-authentication. You could also use FlexConnect mode which only uses a tunnel back to the wireless controller for management traffic, but it will drop data traffic locally. Cisco called this a kludge, because roaming can only happen on the same subnet/VLAN with re-authentication. The switches with built-in controller functions can do something similar to this, on Local mode, without the kludge of FlexConnect mode.