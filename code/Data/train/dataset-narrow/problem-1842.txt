However, if I run I get which is correct. Can anyone explain why there's a difference in version numbers? And how to get them all showing the correct 7.30.0? Does anyone have any tutorials / advice / any help at all on the proper way of upgrading everything cURL related to a later version. The topic seems to be incredibly lacking online, not sure why :/ Thanks Edit - Following one of the comments, here's some additional info: gives gives gives gives gives 

After doing all that I ran expecting to see the new version installed. cURL had updated to 7.30.0 as expected, but libcurl hadn't: 

We have a MySQL database server running on an Dell PowerEdge R720 (PERC H710 Mini RAID controller) ( (Ubuntu 12.04). We're considering upgrading the 2 x 146GB 15k SAS drives to Samsung 840 Pro SSDs. The Dell ones are just far too expensive! (nearly 2k per drive), and with us putting them in RAID 10, we can just have spare drives standing by for if any fail? Does anyone have an identical setup, and are we likely to get problems with this configuration? I've read reports online of the Dell RAID controller deciding it doesn't like the drives and marking them as offline randomly, but then other reports of people running 100+ of these in RAID and having no problems at all. Should we just avoid this entirely for a pretty critical database server? 

We have a Dell PowerEdge R720XD server and want to setup iDRAC, but this is a production server so we need to do it without a reboot if possible. We just need to set the IP address on the iDRAC but the servers do not have a front LCD panel so we cannot use this. The iDRAC will currently have the default 192.168.0.120 IP address but we are not on this IP range so cannot use this. We need to change it to 192.168.5.x. I've seen mentioned, but before I start messing around installing this on Ubuntu, is this what we need? and will we be able to set the IP address on the DRAC with this? Thanks Edit - The dedicated iDRAC port seems to be completely disabled until you enable the enterprise license, so I think we need to used a shared NIC for now. We don't know any way of enabling enterprise without first gaining access to it via the web GUI. The server is in production with bonded network interfaces, so we can't change the server IP to 192.168.0.x while we do this, or we might as well reboot into the BIOS and do it. 

I previously had cURL 7.22.0 on Ubuntu 12.04 Server.. but I now need to upgrade to cURL 7.30.0. I've done the following to compile this version for Ubuntu: 

I usually use MySQL Workbench to do the import but I wanted to use the parameter and I don't think does this. What's wrong with this syntax? I also tried: 

I've called Dell twice to try and clarify this basic (or so I thought) question, but I've had two different answers so far. We have a Dell R710, and a Dell R720. Does DRAC come installed by default on either? Dell said it comes build into the motherboard on the R720 but the second time I rang, they said we didn't have it. Can anyone tell me if DRAC comes as standard on the R720? I'm aware we'll need a license as well, I'm just interested in the physical capability on the server. I've never used DRAC before and know next to nothing about it, so apologies if this seems blindingly simple. Thanks 

All the commands etc work as expected but we need to be able to access the OpenManage web interface, however, it isn't starting up for some reason. 

Turns out this was down to the domain being different on the NAS and the server! on the ReadyNAS came back blank, and on the Ubuntu server came back . I changed it with: and updated: to Rebooted with: and it all started working as expected (think I possibly remounted the share as well, but not 100%)! 

A few days ago we were getting errors when trying to access files on the large RAID 5 partition. We rebooted the server and got a message about . We've had this before, and just needed to use Dell's RAID configuration utility to on the RAID. Last time this worked, but this time, it started doing a disk check then we got this: 

When it failed after 5 minutes or so with the error in my post, the memory immediately freed up again: 

How do I find out what these are actually doing? Can I see a list of files being accessed by each PID, or any more info? We're on . I tried but it's not giving me much useful info about what's actually going on. Edit - Additional stuff tried based on comments/answers: Doing on each of the PIDs shows the following: 

From fixya.com Connect to the console port via hyperterminal or similar. Then, at the command prompt... (hit enter twice!) 

Which "previous question" would that be? I assume when you connect your 3G device, it automatically overrides your default gateway, which you can check by using the command line and typing: 

You can create a specific "Taskpad" mmc for them to use, like here: $URL$ Basically its a customized version of MMC, that is locked to using certain controls, like, creating users, creating computers etc. Depending on the delegation settings/permissions, determines what they can do from there. 

The graphic (below) shows the fault I am seeing in VMWare Infrastructure Client, the drive0 light is also flashing. Not sure why, the other drive lights are green. Can't see any errors in the logs and VM's are running sweet. I got up super-early and rebooted it this morning (production box, so I'm paranoid). It came up and all the status lights went green.. but I get into the office and its back on red.. Is there anything I can do to troubleshoot this? I think reinstalling ESX might fix it, haven't tried that yet. Main points: 

This has a lot of topical information: $URL$ It seems due to the way IIS uses processes, its a bit hard to tell which "site" is actually using the resources (as they are matched to a process, not a thread within a process), unless you match the log entries with perf logs.. and that could be a bit of a ***.. annoyance. Depends on your process pool settings I suppose.. you might be able to use "Process Explorer from Sysinternals" to determine which site is using which process, or processes etc, it handily provides graphs of individual process usage, and its free. (I like being able to pause threads within a process.. damn handy that!) $URL$ 

We had a problem like this on our PowerVault server, solution: monitor the interface for 24 hrs till we found what was causing it.. it turns out it was a remote backup job in Backup Exec, flooding the interface.. added a second NIC, set that for BEX, problem solved! Your problem is probably something else, you might just have to stop and start the netlogon service.. I don't know. Any information you can give on the actual problem would help us to help you though. btw, yes, you can login through a command line, however, it uses the same kerberos/ntlm auth as windows, so you won't be able to achieve what you may think you can. If there is a problem with the server, this still won't work. (and you need to drop ALL the connections to the server first, not just a single shared drive like below) eg: 

If you have configured it for IMAP, you will have to specify which folders get synchronised, so its possible you have folders that are not visible.. HTTPS is the best for Outlook. If you are comfortable (have the bandwidth) to download your entire mailbox again, simply delete your profile (control panel -> mail -> profiles) and start outlook again, it will revert to virgin outlook, and you will have to configure it, however, when you get to the "Exchange Server Settings" part, type in the ACTUAL internal dns name of the server, select the cached mode again, enter your username and then press More Settings. 

Depends, do you want an externally hosted certificate? (Free from here: $URL$ How to use: $URL$ Or an internally created one? Free: $URL$ Once you have OWA using HTTPS, you can start using RPC over HTTPS. (If you have turned it on in Exchange of course, your question seemed to be about the certificate) 

I just installed it on my ubuntu-server box, it needs exim4 to be able to send messages, which is dead easy to configure. 

Possible? I'd basically like to mirror all email from the hosted server internally, so users can access it via IMAP. Allowing me to back it up! (Hosting company organized by consultant who manages it through a third/fourth/fifth??? party, gah) And filter spam/virii/etc.. Is there a way for users to log into my server, which then logs into remote server and downloads email to itself, then delivers via IMAP to them? Or am I overthinking/confusing/breaking something here? What would happen if I sent an email to myself? Would it go out to the hosting company and then back in? Ideally only certain users would need to be on the hosted server, could I set it so that internal email gets delivered locally, but certain users get delivered to hosted server? Its 1630 on Friday, so maybe my brain is fried. I'll probably think of a hundred things wrong with this by Monday, but I want a second opinion. Just thought of something, I can set a forwarder for all the users who are ONLY EVER INTERNAL, and get their messages forwarded to my server.. hmmm.. that could work! I'll have a play and see what happens to a few test users. EDIT: Nope, either DNS is fubar, or the remote server won't send email back to the server that sent it.. would probably create a loop anyway. Bad idea.. :-(