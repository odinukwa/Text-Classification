Could be. Then again it could also be an application trying to log on under credentials where the password has been changed or expired. You should look closer at the events and establish: - What kind of logon is occuring? See if it's RDP, or some other kind of access - What account names are being attempted (If it's random account names you don't recognize, or running through A-Z of names, then definitely an attack) Outside of that, verify that RDP to your server is accessible publically. If so, do you really need that? If your virtual server is within your organisation, lock down your public firewall to prevent this (or ask the admin in charge of the firewall to do so). If it's out in the cloud, the provider should provide interfaces for controlling network access (virtual firewalls). You have a pretty major security problem if you have servers available on the net that are not sitting behind a proper firewall. The boxes should be available exclusively on only the ports that are needed for operation, so a basic web serving box should only have firewall rules outbound for ports 80, and 443 if SSL is served. Security should never be approached from the other direction (start all-permissive, then lock down only specific items). Likewise, moving to a non-standard port gives only a very minor increase in security. 

You will need a separate network segment for your iSCSI traffic. Don't run data and disk traffic on the same network, and preferably run dedicated switches for the Storage Area Network. Whatever you do, never mix the two types of traffic on the same physical ports. 2 ESXi servers would be a good choice for reliability reasons. You can install ESXi onto an SD card on the host and boot from that, then run all of your disks out of the box you're configuring as a storage appliance. 

Yuri, this seems like the most relevant information I can supply: $URL$ Basically, if you're hosted out of the US, you can structure your system so that you're protected under the DMCA safe harbour provisions. Depending on the hosting provider you go with, some will flip out and cancel small accounts if they get complaints about copyright materials. You can mitigate this by going with a larger provider and talking with them beforehand about handling DMCA requests. You'll also need to provide a clear 'report copyright content' path for visitors to report DMCA violations to you. This will reduce the number of users jumping up the chain and talking to your provider. 

What you're looking for here is not an SLA, as an SLA is typically for ongoing support of a service, rather than an exceptional change to that service (as you're describing). You may want to read up on the RFP process as it's used in IT consultancy/service procurement just as much as any other field: $URL$ As well as surrounding information on the responding parties that allows you to make informed decisions about whether they're a suitably capable and professional organisation, you should also get details in the RFPs about the proposed approach to the work to be performed. All of this together should provide enough of a basis for you to select the best provider and method to meet your needs. 

Is there a firewall between your machine and the ESX host in question? Remote console uses an additional port (902 TCP) which may be getting blocked somewhere along the line. 

I'm not familiar with a method of splitting a single guest disk across several datastores. However, your engineer may be referring to either: 

What's the file system in use on the LUN? I ask because as far as I remember, you can't resize a VMFS volume. So if you're using VMFS and hosting VMs on this space, your best bet is to migrate your data to another LUN, then destroy and re-provision the LUN across the extra disks. Edit: To clarify - Adding additional capacity to a LUN is feasible with extents, but not recommended practice (direct advice from VMWare support/techs). This was accurate as of 12 months ago. 

You may wish to configure Event Log Forwarding to a central server with lots of spare disk space. **Even more interesting things happen if you pick 'Rotate after x events'. In that case, an attacker can do whatever they like to the server then just spam the event log to flush records of their actions and clear their tracks.* 

First off, check your media converters and network links, and run a comparison when using them vs when connected directly at 1Gbps to the server over a short CAT6 cable. Is there a difference? If there is, you need to improve the network. For example, run cat6 directly without the media converters, or run fiber for the entire run length. Chances are though, your network is set up that way for a reason and you might not be able to change it. Outside of that, check your raw ping times between the server and clients, it should be 1-5ms on LAN and should traverse as few devices and networks as possible. MS RDP is a lightweight in terms of features, and remote desktops really REALLY aren't suited to intensive graphics at high resolutions. If this is a major problem for you, you should be looking into Citrix ICA with speedscreen enabled. You should see significant refresh rate improvements with that vs RDP. Here's a comparison: $URL$ 

Unless I'm missing something here this is a dangerous setup. A single disk failure in the second array will lose your entire data set. This is a very likely scenario when you're talking about arrays with at least 10 disks each. Amazon and Google have their own dedicated storage technologies that's specifically written to work well with their hardware loadouts (lots of cheap disparate units). Specifically, their software detects failures in a storage block and continuously ensures that each item is stored in at least x additional locations. When a storage device fails, all its contents are immediately having a new duplicate added to some other storage pool. Unless you're rolling similar custom software for your storage tier, you can't use them as a basis for comparison. Regarding vendors - It's true that you can potentially do without an array from one of the big enterprise players here - Netapp/EMC or similar. Their storage is designed for things like running lots of concurrent VMs directly from them. However you're talking about dumb NAS serving up flat files... much simpler use case and the overheads and randomness of your IO is way down. You're still going to want to consider RAID 6 at the very least, though. What's your backup strategy? 

You can work around this using the quick-switch keys to change the input language. By default this is LEFT ALT + SHIFT. 

There's a 'block policy inheritence' setting sitting between the parent and child DCs (it's set on the AD object for the child domain). You can untick it and policies will start cascading down. To prevent blocking of a GPO, select 'enforce' on it. 

Is your proxy server transparent or explicitly defined on the clients? Are your programs definitely routing through the proxy (can you see blocked traffic in ISA monitor?) It may be the case that your apps are not hitting the proxy and are trying to jump directly through the network gateway. 

Agent-less backup for the majority of VMs. Backups are taken by snapshotting a VM, backing up the static disk that generates, then releasing the snapshot. If software within the VM is OK with snapshots, then it'll be OK with agentless backup via this method. VSS-aware apps like Exchange and SQL are, I believe, OK with snapshots... so you don't need agents unless you want granular (item-level) recovery of stuff like individual emails and table rows. SAN-based backups can be really fast. Especially if you're pushing that data at quiet times. We're making out all SP interfaces on our iSCSI SAN when backups are running overnight. Change-Block tracking makes incremental/differential backup of a whole VM possible, fast, and very small. 

Disk throughput and latency are not often an issue on file servers serving up mapped-drive data (documents & images). It's fairly easy to scale a file server's disks up to accommodate more concurrent users (by adding disks to an array, using junction points to add additional arrays, splitting shares), and scale them out across multiple file servers (with DFS, junctions and a few other tricks). Usually you hit a limit in network congestion or latency before you hit a serious problem with disk throughput and latency. However, there are much faster use-cases for enterprise storage which are already around and have been in use for many years now. These are iSCSI and Fiber-attached Storage Arrays, and are capable of serving data for much faster usage than is needed for simple file servers. Typically, they are used to concurrently serve data on a dedicated storage network to multiple servers concurrently. Those servers could be fulfilling nearly any function, such as email, file & print, web, database or application hosting. The impact that SSDs are having on these systems is increased availability of automated Tiered Storage capabilities, even in relatively low-end storage appliances. Administrators will usually purchase a few SSDs and add them as the highest storage tier, effectively utilizing them as a large cache.