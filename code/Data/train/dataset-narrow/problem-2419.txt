There are no polynomial-time $\alpha$-approximation algorithms for TSP where $\alpha$ is a constant unless $\mathsf{P} = \mathsf{NP}$. However, for metric TSP there are approximation algorithms, e.g. Christofides algorithm. A simpler 2-approximation is obtained by taking an MST. 

Note that the notion of nondeterminism in the sense of "there exists + verifier" existed in computability theory long before complexity theory, e.g. Kleene's normal form, arithmetical hierarchy. Other models of computation like Post canonical systems (known at least since 1943) and grammars are also nondeterministic. I think one can even push the notion to the time of Hilbert's epsilon calculus and choice operators. 

Church encoding is an encoding of natural numbers by lambda terms, it is not an arithmetization of a language (the correct terminology is arithmetization not Godelization). For arithmetization of a language we need some way of representing natural numbers in a language, but that is independent of the arithmetization of the language itself. But really the more important question is why would one want to arithmetize a language? Godel does it to be able to talk about the language itself in arithmetic and perform computation over the language. If you think about it what we really want is to talk about computation of functions over the syntactic expressions of a language, and we arithmetize because arithmetic can only talk about numbers. It is just a way of representing language expressions as numbers so we can talk about computation over them, the same way we encode language, numbers, graphs, etc. as binary strings when we deal with computers. Arithmetization was ingenious at the time of Godel, but now it is kind of trivial (in a sense) for a computer programmer. We can encode a formal language as numbers and perform computation over it, sure. Finally, if you can arithmetize language in a system, you can arithmetize langauge in any system extending it. The syntactic constructions that one is interested do not change from say PA to Godel's T to Girard's F. 

Is there any plausible complexity/crypto hypothesis that rules out the possibility that polynomial size circuits have subexponential-size (i.e. $2^{O(n^\epsilon)}$ with $\epsilon<1$) bounded-depth ($d = O(1)$) circuits? We know that every function computable by a $\mathsf{NC^1}$ circuit can be computed by a size $2^{O(n^\epsilon)}$ depth $d$ circuit (using AND, OR, and NOT gates, unbounded fan-in) (for every $0 <\epsilon$ there is a $d$ and $d$ can be taken to be $O(1/\epsilon)$). The question is: 

In circuit complexity we have one circuit for each input size. The size of the output is determined solely by the size of the input. So it seems to me that taken in its strict sense there are functions computable in $\mathsf{P}$ over $\{0,1\}^*$ which are not computable in $\mathsf{P/poly}$. This is partly caused by using $\{0,1,b\}$ in the Turing machine model while in circuit model we only have $\{0,1\}$. Is there a nice standard way to deal with this issue that would work well for small complexity classes (e.g. it shouldn't change the complexity of computing AND of inputs too much, so encoding/decoding inputs/outputs is not a good solution)? Is there a simple modification of Turing machine model or circuit model which would make them correspond without this issue? 

Also any $\mathsf{AC^0_{bf}}$ circuit of size $S$ can be turned into a formula of size at most $k^dS$ and therefore has a $\mathsf{AC^0_{bf}}$ formula of size $k^{2d+1}n$ so any function of superlinear $\mathsf{AC^0}$ formula complexity will not be in $\mathsf{AC^0_{bf}}$. 

If P=NP, every polytime computable 1-1 function $f$ has a polytime computable inverse: $\{(x,y) \mid \exists z\ |yz| \leq poly(|x|) \land f(yz)=x \}$ is NP. We can find a $y$ such that $f(y)=x$ by starting with the empty string as$y$ and greedily adding the following bits using this NP oracle. 

Each time we execute $y = y^{|y|}$ we square the size of $y$. After $n$ executions we will have a $y$ which is $x^{2^n}$ and has size $n2^n$, obviously not a polynomial in the size of the input. Let's assume that we only consider quantified formulas with $k(n)$ quantifier alternations (where $n$ is the total size of the quantified formula). Assume that $A$ runs in time $p$ (e.g. linear time which is not ruled out so far), and have maybe a more efficient $Cook$ algorithm outputting a smaller circuit of size $l(t)$ in place of $t^2$, then we get an algorithm for ExtCircuitSat that runs in time $(l\mathop{o}p)^{O(k)}(n)$. Even in the case that both $l$ and $p$ were linear (but with total coefficient $a\geq 2$) we would get an algorithm which runs in time $\Omega(n2^{k(n)})$ and if $k(n) = \Theta(n)$ it would be $\Omega(n2^n)$ similar to the brute-force algorithm (and even this was based on assuming Cook-Levin can be performed on algorithms resulting circuits of linear size in the running time of the algorithm). 

For the first case it uses a simulation, and it seems that one can get rid of the $\lg$ factor if the simulations can be done more efficiently. For the second case, the paper directly gives a language for the separation and doesn't use simulation at all. This uses particular properties of single-tape TMs with sub-quadratic running-time. 

Motivation: Sometimes we want to turn instances of other NP problems into SAT instances so we can run SAT solvers on them. In place of writing a reduction program for each NP problem we can use an implementation of Cook-Levin plus the code of a verifier for the NP problem. 

Assume that we have an unbounded fan-in circuit family of depth $d(n)$ and size $s(n)$. What is the smallest depth (in terms of $d(n)$ and $n$ and $s(n)$) bounded fan-in circuit family of size $poly(s)$ for it? In particular what is the largest depth $d(n)$ for which we know polynomial size unbounded fan-in circuit families of depth $d(n)$ are in $\mathsf{NC^1}$? 

I am assuming that we are talking about bounded fan-in circuits. If a language can be decided by a deterministic Turing machine in time $t_n$ and space $s_n$, then it can be computed by a circuit of size $O(t_n\log s_n)$. The depth can be reduced to $d_n = l_n \log t_n = O(l^2_n)$ where $l_n = \max (s_n,\log n)$. In the non-uniform circuit case and non-uniform TMs (NU-TM) (when the space used by a TM includes the log of space used on the oracle tape containing the advice), if the language has circuits of size $c_n = \Omega(n)$, then it can be decided by an NU-TM where time $t_n = O(c^2_n)$ and space $s_n = O(c_n)$. Similarly for depth $d_n = \Omega(\log n)$, we get an NU-TM with time $t_n = O(n2^{d_n})$ and space $s_n = O(d_n)$. Form these results we get: