It's not a recommended configuration to have a external root CA sign your RADIUS server's certificate. 

We have a lot stuff available to try an address this problem. A pretty beefy virtualization environment (Cisco UCS, vSphere and NetApp), SCCM, Microsoft Azure, Office 365 (hopefully soon) and just about any Microsoft technology out there we should already be licensed for. Maybe you guys can see something that I missed. 

You can't accomplish your goals with your current setup. Presumably some device is doing the NAT-RDR / Port Forwarding to required to redirect traffic from your external IP address through your NAT device to your server at 192.168.1.101. Your RFC1918 network doesn't know anything about the Internet and conversely the Internet doesn't know anything about your RFC1918 network. Consequently, your link on 192.168.1.101 doesn't have a route to find your other server at 192.168.1.102 once you are outside your network. When you connect to 192.168.1.101 from the outside you're really just connecting with your external IP address and your NAT device does the magic to translate that through to 192.168.1.101 so when you click on the link to 192.168.1.102 your client has no idea where that machine is or how to get there. You will need to either use a separate external address and separate NAT-RDR rule for your server at 192.168.1.102 or use a separate port on the same NAT-RDR and then update your link on 192.168.1.101 appropriately. 

The default configuration on most distros is going to be pretty secure. It's up to you to make it otherwise. ;) So before implementing custom htaccess rules, enabling symlink support, adding new modules, etc be sure to ask yourself how that change relates to security. Research that particular directive in the context of security via google and apache.org. The default configuration of Apache, though secure, may have modules and features you do not require. So you may wish to disable unnecessary modules, cgi support, ssi support, directory browsing, etc. There are a slew of articles available search for "hardening linux" and start with ones that don't include mod_security or re-compiling. I recommend testing each change as you make it so as to know which ones break your site. Also, often more important that securing Apache itself is securing the content Apache serves. Read about proper site permissions and the configuration files related to the languages used (php.ini). Sorry it's hard to be more specific without a more specific question. I obviously don't want to duplicate Google search results. 

Can anyone confirm that when doing an online P2V using SCVMM located on another network segment than the source computer and the virtual host that no imaging traffic (or any bandwidth intensive) traffic is sent between the SCVMM server and either the source computer or the virtual host? What happens to the physical host if I cancel the P2V process? Will it fail safe (i.e., will the source machine be effected)? 

The workstation does not show a gateway, manually setting the gateway through to my server ip (192.168.1.21) must trick it into thinking there is internet as it says there is but I cannot ping anything. Your workstation can route fine to your server because they're on the same subnet. Your workstation needs to know the route out - this is presumably your router (which is different from your Windows 2008 R2 server, correct?). Unless you have specifically configured your server to route for your 192.168.1.0/XX network, telling your workstation that it is the default gateway will not accomplish what you want. What is the default gateway set to for your server? Set your workstation to use that as the default gateway instead of your server (192.168.1.21). If you specifically want your server to do the routing then you need to establish the appropriate static routes on you server (and possibly a whole mess of other things depending on how your outbound connection is setup). 

I'm coming from munin and a CPU graph contains data for system, user, nice, etc ALL on one graph. I just installed ganglia and setup the basic monitoring. It appears that each type of cpu data is a separate graph! WTF is this and can I change the defaults to combine these into a single per host? That is my question, how do I combine cpu data into a single graph. Also, can I change the layout to something closer to munin's day-week side-by-side layout? I'm trying to be impartial and give ganglia a chance. ;) 

I would like to have ephemeral ec2 instances push logs to a central flat-file store for archiving and manual perusing, as well has have that data pushed to elastic search. Is there a single agent that can tail local log files and both push them to a central flat-file store as well as push them to elastic search? 

There is no real way you can mitigate a DDOS from the host that is getting attacked. By the time the traffic has reached your host it has already passed through your local network stack and consumed local resources. No amount of hackery or gyrations can change this. You need to work with your upstream provider to prevent the traffic from reaching your machine in the first place. If they don't provide that service you can likely purchase it from them or you can find a provider that does. 

We have been playing around with SCCM's Application Catalog and have come across an interesting quirk. My manager has directed me to implement the catalog so that software that falls somewhere between the "one-off install" and "needed by the entire workgroup" points on the spectrum of how many people need it should be published to the Application Catalog. Our help desk technicians can use the App Catalog to deploy these kinds of software to select users that need it as the situation warrants. We practice account separation, for example, our help desk rockstar Emmet Brickowski has two Active Directory user accounts. His regular unprivileged account, he should be using for all his regular work and when a UAC prompt rears its ugly head he has an privileged account () that is a member of BUILTIN\Administrators on all our workstations. When Joe User calls the help desk, Emmet remotes in or physically goes to help the user (our culture is big on face-to-face customer time), logs into the App Catalog with his privileged and sees a plethora of software that he can install in a standardized method for our user. Except when Emmet presses the Install button he gets this: 

The files are not re-installed though. What needs to be done to get yum to reinstall the files? UPDATE: Did an strace on the yum install and it appears that the file "/etc/pam.d/system-auth-ac" is opened by the rpm install but not written to. Looking further it appears that the file is generated once the authconfig binary is executed. So now the problem is no longer RPM related. I need to figure out what the default command to authconfig looks like for RH5.6 so I can get a normal system-auth-ac file. 

In the iptables output make sure there are not any rules rejecting connections before the accept rule. Also, try verifying it's accessible from another computer on the same network before trying outside the network (through the router). 

As warner mentioned (that's becoming familiar), zone transfers are othen denied for security reasons. If the name servers aren't something you have access to you can attempt to discover the most common subdomains of a given domain using one of the popular DNS bruteforce scripts. They work by performing DNS requests against a local nameserver using a user supplied dictionary list. Dictionary lists exist solely for this purpose. 

This is a bare-metal install of Windows 7 on this server and it's not running in a hypervisor? If so your issue is likely related to the use of a operating system that is not supported and thus not certificated as compatible for your hardware. If you review the Installation Guide you'll find that the codes are related to keyboards. My guess is that the USB implementation in Windows 7 is not working with the server's BIOS implementation leading the act of an USB device being unplugged to be interpreted as a keyboard IO controller error which in turns causes Windows 7 to crash. But this is just an educated guess. IBM could probably tell you more or they would if you were using a supported operating system. 

You can't set the EAP authentication mechanism to EAP. EAP is just an authentication framework - hence the Extensible Authentication Protocol. You need to pick a protocol for EAP to use. You mentioned certificates so I'm assuming you're implementing EAP-TLS. You probably want to change: 

Run the above on the server and it should list which services are running and which ports they are "bound" to. If 80 is not listed then you need to troubleshoot the apache startup. 

So I need to install the original /etc/pam.d/system-auth-ac file from the authconfig RPM. I attempted to do so by "reinstalling" the authconfig package/rpm like so: 

From the check_http man page: -k, --header=STRING Any other tags to be sent in http header. Use multiple times for additional headers $URL$ 

Try: ServerTokens ProductOnly Probably goes without..but you will need to reload for changes to take effect. 

Reboot and look for a RAID BIOS/config option (F7, etc) key will depend on RAID controller. Within the RAID BIOS you can most likely re-configure the virtal disk to be a single disk instead of two mirrored disks. This will clear the way to reformating the second drive within windows disk management interface as drive d. The specifics are dependent on the RAID controller, see their sites support section for limitations. Backup first! 

If your dom0 is smoking wreckage this gets substantially harder. I don't think you can boot a LiveCD and scrape the VMs off the disks - at the very least we need to know what kind of storage you are using. You could try doing something like re-installing XenServer while leaving the VMs intact (How to Reinstall XenServer and Preserve Virtual Machines on a Local Disk). 

This is a bit of a WAG but have you tried recompiling the iSCSI MOF files? I've come across similar behavior where NetApp's SnapDrive can't enumerate all the of the iSCSI drives on a particular server. This blog pointed me at this KB2001997. Try comparing the results of the following WMI query on this server to another known good one: 

Darkstat is a very simple but powerful network traffic monitoring program that displays information about network traffic moving over an interface via HTTP. It will do 90% of what you need with none of the hassle of using a more feature rich but complicated solution like Naigos.