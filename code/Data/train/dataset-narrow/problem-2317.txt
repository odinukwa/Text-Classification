(also asked here, no replies) A $(d,\lambda)$-quantum expander is a distribution $\nu$ over the unitary group $\mathcal{U}(d)$ with the property that: a) $|\mathrm{supp} \ \nu| =d$, b) $\Vert \mathbb{E}_{U \sim \nu} U \otimes U^{\dagger} - \mathbb{E}_{U \sim \mu_H} U \otimes U^{\dagger}\Vert_{\infty} \leq \lambda$, where $\mu_H$ is the Haar measure. If instead of distributions over unitaries we consider distributions over permutation matrices, it's not difficult to see that we recover the usual definition of a $d$-regular expander graph. For more background, see e.g.: Efficient Quantum Tensor Product Expanders and k-designs by Harrow and Low. My question is - do quantum expanders admit any kind of geometric interpretation similar to classical expanders (where spectral gap $\sim$ isoperimetry/expansion of the underlying graph)? I don't define "geometric realization" formally, but conceptually, one could hope that purely spectral criterion can be translated to some geometric picture (which, in the classical case, is the source of mathematical richness enjoyed by expanders; mathematical structure of quantum expanders seem to be much more limited). 

Let $\mathcal{B} = \{B_1, \dots, B_k\}$ be a set of Mutually Unbiased Bases (MUB) in $\mathbb{C}^n$, i.e. each $B_i$ is an orthonormal basis and for $v \in B_i, w \in B_j, i \neq j $ we have $|\langle v\vert w\rangle| = \frac{1}{\sqrt{n}}$. We are interested in discriminating between arbitrary vectors from $\mathcal{B}$. Is the optimal (worst case or average with uniform prior) POVM measurement identified explicitly anywhere in the literature (e.g. using Holevo criterion), at least for some specific constructions of MUBs? 

It is well known that some major complexity classes, like P or NP, admit a full logical characterization (e.g NP = existential 2nd order logic by Fagin's theorem). On the other hand, one can also define complexity classes in communication complexity (where P = problems solvable with poly(logN) communication etc. - see Complexity classes in communication complexity theory for more). My question is - are any descriptive complexity characterizations known for communication complexity classes (or do any such results from standard complexity classes transfer to communication setting easily)? 

We say that a Turing Machine $M$ is mortal if $M$ halts for every starting configuration (in particular, the tape content and initial state can be arbitrary). Is every recursive language recognized by a mortal Turing Machine? (i.e. if there is a TM that accepts $L$, there is also mortal TM that accepts $L$) 

Arxiv is not very useful for computational complexity, although certain subfields such as quantum computing do use it. On the whole, there is no quality control at all, and many of the papers listed as belonging to computational complexity are either incorrect, or only marginally related to the field. ECCC (Electronic Colloquium on Computational Complexity) reports are usually much more germane, and mostly by experts in the area. There are only a few each week, and cover a wide variety of topics. So I recommend looking at new ECCC reports, at least glancing at abstracts, and perhaps reading more if they look interesting. Another resource you can use is Oded Goldreich's list of ``Papers I find interesting'' or something like that, off his homepage. He gives a summary and discussion of stuff he likes. The additions are irregular, and seem to average one or two a month. You are also welcome to come to talks at IAS any time. I could add you to the mailing list if you are not already on it.... Russell Impagliazzo 

It sounds like this class would be exactly MA. The witness could be the results of pre-processing (which is of polynomial size). The probabilistic verification procedure would then be to simulate the protocol, including the multiple provers (who are polynomial-time given the results of pre-processing). Russell Impagliazzo 

This result can be proved using a simple counting argument. Consider a random function applied to the first $k$ bits of the input. This function almost certainly has circuit complexity $(1+o(1))(2^k/k)$ by Riordan and Shannon's counting argument, and matching upper bounds. Thus, picking $k$ so that $2g(n) < 2^k/k < f(n)/2$ we can distinguish size $g(n)$ from size $f(n)$. Note that the functions in question won't necessarily even be computable, but we can put them in the exponential time hierarchy by standard techniques (as long as we can compute the right value of $k$). We of course cannot prove any bound greater than $2^n/n$, because that is the worst-case circuit complexity of any function. Natural proofs do not apply for this type of argument, because the property in question is ``not having a small circuit'', which is not easily computable from the truth table of the function (presumably). It is not clear how low in complexity classes this type of counting can go. Is there any reason why we can't use a counting argument to prove lower bounds for $NE$? Not that I know of. 

Suppose I have an exponentially large graph $G$ ($|G|=2^n$) supplied with an efficient (of size $poly(n)$) randomized circuit $C_G$ implementing the random walk on $G$ - that is, $C_G$ takes a vertex index $i$ and outputs a random neighbor of $i$. Has this type of graph specification been studied and is it more powerful that the standard succinct representation, where $G$ is given as an efficient circuit that given $i,j$ outputs whether $(i,j)$ is an edge in $G$? I could imagine that being able to perform a random walk could help e.g. in detecting triangles in a dense graph (e.g. by choosing a random starting vertex and performing a random walk of length $3$; on the other hand, deciding triangle-freeness in the usual succinct model in NP-hard) 

(this is not specific to TCS conferences, but would work for better conferences in general) A nice idea I saw in a mathematical conference for young researchers is asking every participant to write a short "research statement" - in case of junior participants who don't yet have much results, a description of interests would be OK. Then, some time before the conference, the statements are published on the webpage. A working example of this: $URL$ (conference in geometric group theory) I think this would be especially helpful for junior participants suffering from the "I don't know anyone here" problem, but also the other way, since even students aren't anonymous mass anymore. Of course, this is rather feasible for smaller conferences/workshops, not 400-people events, but still I think it's worth implementing. 

Given a finite set of quantum gates $\mathcal{G} = \{G_1, \dots, G_n\}$, is it decidable (in computation theoretic sense) whether $\mathcal{G}$ is a universal gate set? On one hand, "almost all" gate sets are universal, on the other, non-universal gate sets are still not well understood (in particular, of course, it is not known whether every non-universal gate set is classically simulatable), so I imagine giving an explicit algorithm for checking universality could be nontrivial. 

I'm interested in examples of problems where a theorem which seemingly has nothing to do with quantum mechanics/information (e.g. states something about purely classical objects) can nevertheless be proved using quantum tools. A survey Quantum Proofs for Classical Theorems (A. Drucker, R. Wolf) gives a nice list of such problems, but surely there are many more. Particularly interesting would be examples where a quantum proof is not only possible, but also "more illuminating", in analogy with real and complex analysis, where putting a real problem in the complex setting often makes it more natural (e.g. geometry is simpler since $\mathbb{C}$ is algebraically closed etc.); in other words, classical problems for which quantum world is their "natural habitat". (I'm not defining "quantumness" here in any precise sense and one could argue that all such arguments eventually boil down to linear algebra; well, one can also translate any argument using complex numbers to use only pairs of reals - but so what?)