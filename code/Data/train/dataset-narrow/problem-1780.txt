Before you go changing your SSL config, it might be worth understanding exactly what the vulnerability is here. When 3DES was introduced, there was a requirement that it was interoperable with legacy single-DES systems. The idea behind 3DES is that you can multiply the security by performing multiple DES operations with different keys. In order to provide compatibility, they used an EDE construction: 3 DES operations in sequence - Encrypt, Decrypt, Encrypt - or EDE for short. It turns out that a DES decrypt operation is basically interchangeable with an encrypt operation in terms of security, so this works quite well. When you use three independent keys for each operation (known as keying option 1) you essentially have a 168-bit key. If you want to go back to old single-DES mode, you use a different keying option (3) which has all three subkeys set to the same value, i.e. k1 = k2 = k3, so that two of the operations cancel out and only a single DES operation actually matters. There's also another keying option which has two of the keys with the same value but one different, producing a 112-bit key, but this isn't really used in reality and (somewhat confusingly) is completely unrelated to why you're seeing 3DES reported as 112-bit. To make things even more confusing, you'll sometimes hear people talk about 64-bit DES or 192-bit 3DES. These are, from a cryptographic perspective, identical to 56-bit DES or 168-bit 3DES. DES specifies a key padding system whereby 8 padding bits can be added to a 56-bit key to produce a 64-bit padded key. This was for use in some old systems and it's not really important, but the 8 bits can be ignored and only 56 bits are actually key material. In 192-bit 3DES the same thing happens, where each 56-bit subkey is padded with 8 padding bits, but again the real cryptographic key is only 168 bits long. Now, what's the 112-bit thing all about? 3DES suffers from a problem called a meet-in-the-middle attack. The approach is as follows: 

We have a 3rd party application that runs on an IIS web server, during the day as people use it, it seems to take up more and more memory until the server is very close to the memory limit and we get nagios alerts. Here is a graph of a few hours this morning, IIS was restarted at 11:40, some of this ramp up will be due to people starting work but I suspect not all of it, the spike at 11:20 is of perticular concern. 

Basically No. This is a potentially dangerous misunderstanding, not sure how you came to have it. Perhaps you should try asking a broader question about what your trying to achieve. Also read the wikipedia article on NAT. 

For UK/Some European data centres data hop have good summaries containing some info that is not readily available elsewhere although obviously biased toward the ability to cable/put in transit hops. 

I'm trying to get a TDM400P card with FXO module to connect to our PSTN line. The card is correctly detected by Linux: 

I recently noticed that my ISP doesn't like routing native SCTP traffic over the Internet, unless it's tunnelled through UDP. A bit of a pain, but I solved the issue by using tunelling. This issue got me thinking - other than TCP and UDP, which transport layer protocols are (generally) allowed to be routed properly across the Internet, over IPv4? Is the "normal" policy to allow all forms of IPv4 traffic, regardless of the protocol? 

I'm in the middle of doing some testing on a mobile device, and want to test it from the network. The mobile device will only connect to networks via WiFi, and doesn't support ad-hoc mode, so I've set up an old WiFi router as an AP, which is connected via ethernet to a port on my laptop. The router operates under 192.168.0.0/24. My laptop is also connected to our normal network via another ethernet port. This network operates under 10.0.2.0/24, and provides internet connectivity. My laptop is running a VM which has two NICs, each bridged onto the two respective physical NICs. The 10.0.2.0 network is reachable via eth0, and the 192.168.0.0 network is reachable via eth1. The problem I'm having is that all connectivity drops as soon as I run . I've tried changing routing tables and adapter metrics, but have had no luck. Here's the output from : 

I have two machines both running CentOS linux, one is public facing machine with a real ip address (foo). The other is at a client's site behind a very restrictive firewall and with no real ip and no possibility of natting or opening an port to it (bar). I can ssh from bar to foo, however obviously not the other way round. Ideally I would like to be able to ssh from foo to bar so I am able to send file, work remotely, etc. Would really appreciate any help or advice on how best to get this working, have seen various tutorials on the internet which suggest it should be possible to setup a VPN connection over ssh but can't quite seem to figure it out. Jona 

We run a cluster of openvz servers and are looking for a way to automatically graph the content of user_beancounters for all ves. We currently have a fairly rudimentary cron which alerts us when limits are hit but we could like a graphing solution to show us history. Obviously we could roll our own using some fancy bash/php/perl and rrdtool but we're wondering if there are any existing solutions before we go down this path. We current run a cacti/snmp based graphing infrastructure. 

What you're looking for is a combination of penetration testing and code security review. There are a lot of companies and freelance individuals who will do a pentest for you, for a price. Depending on what you're trying to secure (webapp, payment gateway, physical box, hosted VM, entire network, etc) there may be certain regulations which need to be followed. You'll also have to liase with your hosting provider, since they don't like random people sniffing around in their network. A code security review, on the other hand, requires in-depth knowledge of your codebase and security concepts, so most companies hire a security developer (or contract one in) for this kind of role. They'll need to get comfortable with your entire application and network, then do a detailed analysis of any potential security issues within the code or infrastructure. 

I'm getting really slow queries in MS SQL Server 2008 R2 on my dev machine. This problem has been plaguing me for about a month. Other developers don't have the same problem, but we all run the same code. It seems to be that any query that includes a takes >20s, some taking up to a minute. Inserts and updates are fast. The total database size is about 30MB, so it's hardly huge. During the laggy queries, the CPU usage stays flat, the IO rates stay low, and the pagefault delta stays low too. I've not tweaked any performance settings in the db config - it's all stock from the setup. The software that connects to the SQL server is running on the same machine as it. I've tried multiple dev database copies, and customer databases that are known to be fine, all to no avail. Any ideas what might be causing this? 

We're deploying a wireless networking using Windows Server 2008 NAC as a RADIUS server. When Windows XP or 7 clients connect they initally fail to connect. In order to enable the client to connect we have to add the network manually and un-check the "Validate server certificate" as shown in the screenshot below. Does anyone know of a way to avoid having to do this? We are perfectly willing to buy a certificate from Verisign, Thwarte, etc if it will help but have tried our Comodo wildcard SSL certificate which hasn't fixed it. These machines belong to the end users so we can't easily control settings with group policy or registry hacks. 

I'm guessing I've missed a configuration step somewhere but no idea where, any help greatly appreciated. 

Does anyone know how to get asterisk to execute this command or some action that we could hook into when a phone call is incoming to specific extensions? 

You could try the racreset command, this may be available from your OS if you have the OMSA packages installed or you may have to ssh directly the DRAC (assuming it will let you do that). This will reset the DRAC (taking it offline briefly). See - $URL$ 

This is a time/space tradeoff that allows you to reduce the number of computations from 2168 down to 2112 with a space cost of 256 64-bit blocks (512 petabytes). Now, for some bizarre reason, all security tools seem to report 3DES-EDE as 112-bit without actually qualifying why. 3DES-EDE does not have a 112-bit key length, nor does it really even have a 112-bit effective key length unless you specify that your attacker has 512PiB of lightning-fast storage available alongside their massive array of DES-cracking ASICs. The practice of reporting it as 112-bit appears to have started with the "sslscan" tool, and has been copied by various other tools since then, leading to all sorts of confusion and misconceptions (I even saw this incorrectly marked in a security exam!) This isn't to say you shouldn't disable 3DES - it's an old algorithm now and there are problems with it, so it's probably worth moving away from it. It's just worth knowing why. If you want to do so, add and to your list of disabled algorithms. These names are defined in the cryptographic providers documentation, in case you want to disable any others.