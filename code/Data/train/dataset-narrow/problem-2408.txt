(Edit: Joshua Grochow pointed out that a positive answer to this question would imply an algorithm for GI that has better asymptotic runtime bounds than are currently known. I would therefore be happy to relax the bound, allowing $o(\sqrt{n}\log n)$ nondeterministic moves.) 

What you perhaps mean is minimization over all Datalog programs made up only of the terms that occur in the original program, such as the $A(x) \leftarrow D(x).$ example you provided above. This is a restricted form of Datalog containment, since one only wants to check containment between syntactically closely related Datalog programs. It is not obvious to me whether this restriction makes the problem decidable or not, although there may be some related work, perhaps in the rewriting systems or finite automata communities. Restricting the problem somewhat, one can try to find an equivalent minimal non-recursive Datalog program. Unfortunately checking for equivalence between a recursive and a non-recursive Datalog program requires time that is triply exponential in the size of the programs, and checking whether the recursive program is contained in the non-recursive one requires doubly exponential time. Moreover, these algorithms require constructing exponential-sized tree automata, so are probably not feasible for actual implementation. 

You linked to two papers, both with conjectures. I presume you mean Grohe's 2007 conjecture. This question was answered in 2008: 

One simple "bad" input that needs to be considered for worst-case analysis of this problem is as follows. Let $c=(\sqrt{17}-1)/2 \approx 1.56$. There are three objects of size $c$, $1$, and $1$. There are two bins of size $2$ and $c$. Initially $a=1$. Some heuristics will place the largest object into the big bin, necessitating $a$ increasing from 1 to at least $(c+1)/2 = 2/c > 1.2807$. An optimal packing leaves $a=1$, placing the two small objects into the big bin and the big object into the smaller bin, with no waste. Hence such heuristics will have a worst-case actual-to-optimal ratio of more than 1.2807. Notwithstanding this worst-case analysis, a heuristic like the one described in the edited question is likely to work well for practical examples, even if its worst-case performance is at least 28% worse than optimal. Similar heuristics are often used in practice, sometimes with adjustments like "instead of the general criterion, prefer a bin that is only a tiny bit larger than the object to be placed, if one such exists". Most implemented heuristics I'm familiar with are a big mess of such case analysis, but work extremely well in practice. However, it is often quite hard to come up with badly behaved inputs for such complex algorithms, and it is even harder to prove that they are the worst possible. 

proposes logic VO, variable-order logic. This allows quantification over orders over the variables. VO is quite powerful and can express some non-computable queries. (As pointed out by Arthur Milchior below, it actually captures the whole of the analytical hierarchy.) The authors show that the fragment of VO obtained by allowing only bounded universal quantification over the order variables exactly expresses all c.e. queries. VO allows the order variables to range over the natural numbers, so bounding the order variables is clearly a natural condition to impose. 

(this table appears on the page indicated as 247 in the draft). In a more recent manuscript (arXiv:1411.0650), Jian Ding, Allan Sly and Nike Sun showed that for all sufficiently large $k$, there is in fact a single threshold $r_k = 2^k\ln 2 - (1+\ln 2)/2 + o(1)$, and the error term $o(1)$ in this expression goes to zero as $k$ tends to infinity. 

A classic problem in probability theory is to express the probability of an event in terms of more specific events. In the simplest case, one can say $P[A \cup B] = P[A] + P[B] - P[A \cap B]$. Let's write $AB$ for the event $A \cap B$. There are then some ways to bound $P[\cup A_i]$, without assuming independence of the finitely many events $A_i$. Bonferroni gave the upper bound $$P[\cup A_i] \le \sum P[A_i]$$ (this is sometimes also attributed to Boole), and Kounias refined this to $$P[\cup A_i] \le \sum_i P[A_i] - \max_j \sum_{i \ne j} P[A_i A_j].$$ The dependence structure of the events can be thought of as a weighted hypergraph with vertices $A_i$, with the weight of an edge representing the probability of the event associated with the intersection of the vertices in the edge. An inclusion-exclusion style argument considers larger and larger subsets of events together. These yield the Bonferroni bounds. These bounds use all weights for edges up to some size $k$. If the dependence structure is "nice enough", then the Lovász Local Lemma can be used to bound the probability away from the extreme values 0 and 1. In contrast to the Bonferroni approach, the LLL uses quite coarse information about the dependence structure. Now suppose relatively few weights in the dependence structure are non-zero. Further, suppose that there are many events that are pairwise independent yet are not independent (and more generally, it is quite possible that a set of $k$ events is not mutually independent but is $r$-wise independent for every $r < k$). 

This is an extended comment to complement Ryan's answer, which deals with the thresholds where the number of clauses becomes large enough that the instance is almost surely unsatisfiable. One can also compute the much larger thresholds where the number of clauses forces unsatisfiability when it exceeds a function of $n$. Note that some technical issues need to be addressed. If repeated clauses are counted in $m$, then $m$ can be made as large as desired without changing $n$. This would destroy most relationships between $m$ and $n$. So assume that $m$ is the number of distinct clauses. We need to decide on another detail, whether instances are encoded so that order of literals within a clause or order of clauses within an instance matter. Suppose this is not important, so two instances are regarded as equivalent if they contain the same clauses, and two clauses are equivalent if they contain the same literals. With these assumptions we can now bound the number of distinct clauses that can be expressed with $n$ variables. Each clause can have each variable occurring positively or negatively, or not at all, and then $m\le 3^n$. First consider SAT without a restriction on $k$. What is the largest $m$ such that the instance is satisfiable? Without loss of generality we can suppose that the all-zero assignment is a solution. There are then $3^n-2^n$ different clauses consistent with this solution, each containing at least one negated literal. Hence $m\le 3^n-2^n$ for any satisfiable instance. The instance consisting of all clauses that each contain at least one negated literal has this many clauses, and is satisfied by the all-zero assignment. Further, by the pigeonhole principle any instance with at least $3^n-2^n+1$ clauses is unsatisfiable. This yields $2^{3^n-2^n}$ different subsets of such clauses, each representing a distinct instance which is satisfied by some assignment. In comparison, the total number of different instances is $2^{3^n}$. Now modifying the above for instances in which each clause has at most $k$ literals, there are $\sum_{i=0}^k \binom{n}{i}2^i$ distinct such clauses, and $\sum_{i=0}^k \binom{n}{i}$ clauses in which there are no negative literals, so $m\le \sum_{i=0}^k \binom{n}{i}(2^i - 1)$ for satisfiable instances, and any larger $m$ is unsatisfiable. There are then $2^{\sum_{i=0}^k \binom{n}{i}(2^i - 1)}$ instances satisfied by any particular assignment, out of the total of $2^{\sum_{i=0}^k \binom{n}{i}2^i}$ $k$-SAT instances. 

An instance of CLIQUE$_p$ contains a proportion $p$ out of all possible edges. Clearly CLIQUE$_p$ is easy for some values of $p$. CLIQUE$_0$ contains only completely disconnected graphs, and CLIQUE$_1$ contains complete graphs. In either case, CLIQUE$_p$ can be decided in linear time. On the other hand, for values of $p$ close to $1/2$, CLIQUE$_p$ is NP-hard by a reduction from CLIQUE itself: essentially, it is enough to take the disjoint union with the Turán graph $T(t,s-1)$. My question: