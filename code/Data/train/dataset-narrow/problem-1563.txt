This configuration should work. But why should you be satisfied with humming, when you can scream with nginx! You should consider adding the following directives for 'improved performance' Here is a comprehensive Nginx.conf, you can pick and chose directives, and see which work for you. Most should work, as this configuration is for serving static html files. You might want to put the server block and its directives in you default.conf and the nginx directives in nginx.conf separately as this is both into one nginx.conf unlike your present configuration above: 

I am setting up a vpn service for 3000 users in AWS. The solution is built up on Linux and AWS. The design of the solution is: 

Broadly there are two views to handling more requests, and serving faster. One view is to write extremely efficient code. The other view is to be have extremely efficient serving (server). You can try for best of both, but it is tough to achieve. Most of the sites are located somewhere between these two extremes. For both these approaches I can recommend switching over to nginx completely, if not for only serving your static files, as nginx outperforms apache in both these respects by an order of magnitude. nginx is non blocking server and doesn't have the overhead of php for serving non php files unlike apache. New programmers and hobbyists tend to end up developing with pre-made frameworks, and platforms. These codes are not optimum as they are intended to serve a large audience. This group of people takes the view of optimizing their serving (servers) as they can not leave their framework and hence can not fully optimize their code. In this approach, in context of nginx on linux you can tune your server to squeeze the maximum performance you can from it: 

I already have 2 domain controllers running Windows Server 2012 R2. This network doesn't have any file servers or SANs. It hardly needs any. But, I have one small need for a shared file folder and I would prefer it to be redundant. So I could set up 2 dedicated servers just for this purpose, but that seems like such a waste for one file folder share that will have just a couple files. Instead, can I just use my 2 domain controllers? I would want to install a failover cluster for file sharing on them. 

Let me answer my own question... I disabled "Require Server Name Indication" and suddenly everything worked. This is weird because SNI was enabled on all servers in the farm for the same site but for one of them, unchecking it made it all work. My theory is this: Even with shared config, SSL binding information doesn't really transfer from one server to the other, from the IP to the certificate. As many of you know, you still have to manually go to the other server and select the certificate. So that was a clue about how the setups could be different. I actually believe the setups were the same visually but somewhere under the hood something was different for one binding somehow. Anyway, I spent hours on this issue and nowhere did I read anything about "Require Server Name Indication" being related to a 502 error. So I wanted to share with the internet community so that future people will know to look at that setting if they are stuck with a 502 error when using SSL. Maybe there is a way to keep it enabled, since it was working on the rest of my farm, but at the very least you'll know in what area you might need to be looking to solve your 502 error. Of course, remember that the first cause of 502 errors in my opinion is not having the certificate installed on all servers when not using SSL offloading but that was not my issue, and mine was unique in that just one server in a farm was misbehaving with SSL enabled. I hope this helps someone else. 

You would want to optimize your tcp stack that comes on your os. Increase the number of open file descriptors. You might want to place your www directory on a ramdisk. You would want to increase worker connections and processes in nginx and the number of workers if you decide to use nginx. You would probably want to set up caching to compensate for badly written code. You are currently using APC which is an object cache, you might want to set up page caching using APC too, which will again offer improvements by an order of magnitude. You might want to memcache your database queries which should provide space to database bottlenecks. Use larger buffers in your web and database server. 

I have spent the day reading the documentation at Nginx - $URL$ and the documentation at Apache - $URL$ but it has only culminated into horror and despair. I seek your help :) 

I am trying to serve static HTML with server side PHP processing with Nginx. I have no experience with Apache. I would like to migrate the following re-writes from Apache's .htaccess to Nginx. What would be the corresponding rewrites for a server or location block in Nginx's default.conf? 

I have a configuration with ARR on a front-end server and an IIS (8) web farm behind it. SSL is enabled with the same certificate on the ARR server and the IIS web farm servers and I am not using SSL offloading. The servers are using Shared Config so the setup is theoretically identical. Interestingly, when the ARR round robin configuration hits ONE of the servers, it returns a "502 - Web server received an invalid response while acting as a gateway or proxy server." error. Another server returns the page fine with SSL working. If I point my browser to the "bad" server directly, without ARR, it works fine in HTTPS / SSL mode. I checked the configurations and found nothing different between the servers and even enabled Failed Request Tracing on the ARR server, which wasn't that helpful but I saw a different 502.3 error within the log. Why would I get a 502 error of any kind, especially on just one server in the farm when they are configured identically with shared config and certificates are on all servers? 

My questions is: Am I missing something critical in the design I have presented in the above diagram? 

The other group, generally experienced programmers who write their own code from ground up, or can manage to do so at a later point in time, try to write super efficient code, and be minimalistic in their 'design' efforts to server lean http responses which performs optimally on any stack. I have no tips to offer here but merely to suggest to follow best practices from authorities in the respective domain. Though, I can tell you Facebook's story in this regard. Facebook's is an iconic tale of progress from server optimization to code optimization. Originally built on PHP with apache, they soon ran into performance issues, at which point in time they started optimizing their servers heavily. The OS, PHP stack everything was optimized. Soon they had to start using memcache, which was quite recent from my memory. But no sooner they started experiencing service disruptions again. At which point, since they could'nt optimize PHP itself any further, they actually compiled it into machine code! Which is the end of line as far as improvements are concerned. Now they can only add more servers. Unless they switch their language. Which will also stop yielding benefits at a point. So these are the two options ahead of you. Choose wisely! Finally I can add that you should follow the handy set of rules and guidelines at Yahoo Yslow and Google Pagespeed for improving performance. Minify your JS, HTML, PHP, CSS, and place at top and bottom accordingly. Use a CDN. Design lighter pages etc. Best of luck!