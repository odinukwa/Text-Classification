You need to setup an SSH gatekeeper. This allows openssh to permit multifactor authentication. Here's a great link: $URL$ Essentially, you use the ForceCommand directive to run a script when the user logs in. That script then prompts the user for the password. I'm currently looking for a method to verify a given password against the system password, but I'm coming up (understandably) blank. If the user account is stored in an LDAP directory, you could attempt to bind to the directory using those credentials, but the problem is going to be that the program running will be running as the user, not as root. I don't know the security implications of writing the compiled code and setting it SUID. Hopefully someone will give you a better answer. but since I've typed this much, are you in an ultra-secure site? Because that's really the only reason for this. Normal public keys with passphrases should be more than adequate for 99% of cases out there. 

I hate to ask questions that don't really address the original request, but are you sure there's no way around keeping it in your office? Servers really weren't meant to be "quiet" or for use in habited areas. If the machine must be in your office, is there a reason it has to be rackable? Could it be a desktop on a rack shelf? There's got to be a better solution that won't drive you crazy. 

I would suggest that as soon as databases start taking up enough of your time that you can't get your work done, you might consider it. Try to get a DBA with a multi-discipline background, so that they have something to do besides sit around and wait on the DB to break. 

It's important to know that if you want people to be able access a directory, the execute bit must be set on all of the parent directories for that particular user. For instance: 

Cron isn't really good at what you're trying to do. Have you considered writing a script that acts as a daemon that basically sleeps 15 minutes, executes the command, then loops? 

(where volgroup and logicalvolume is the actual path to whatever is mounted on /) It'll say it's doing a live resize since the volume is mounted, and voila, running df -h should show that you have free space. 

It's self promotion, so sorry about that, but I thought I'd let you know about the podcast that Brandon Burton and I just launched, called SysAdministrivia $URL$ It'll be on iTunes shortly, but until it is, please download it and check it out! 

I have various services configured to authenticate against Active Directory. It would be very helpful if they all logged authentication failures, but they don't. This makes debugging even a simple "incorrect password" error very frustrating. Is it possible to watch in realtime (or later) authentication attempts against AD? The AD is Windows Server 2003. 

DNS. Make sure that your reverse DNS is working properly. You can verify this by typing "ping -n www.google.com". Immediate responses. 

It doesn't look like it. Freshmeat doesn't show any projects with ndmp in their names or description: ($URL$ and Bacula has been talking about supporting it since 2007 with nothing to show. Sorry about your (and my) luck. A FOSS implementation of NDMP would be a big win for the enterprise community. BTW, for anyone looking for more information on NDMP, the site of choice is $URL$ 

I would use PHP (since you already know it) and write a script to query your application from a remote machine. It shouldn't be too hard to write the script to log in and navigate around, especially since you wrote the target application. Write your script to test latency and other variables, and make sure to watch the resource utilization on the application server. 

If you have no intention of replacing the drive, why go through the effort of changing the RAID level, even if your controller supports it? RAID1 doesn't involve parity, so there's no computational overhead. If you know it's failed and you don't care, just leave it. 

If this doesn't work and the previous steps all did, check the firewall again, and check the firewall on the remote systems. 

Which strikes me as a little weird. What I suppose MAY be happening is that somewhere in the cacti stream, it's interpreting # as being a comment and stripping everything after, but I'm not sure. I was hoping someone could tell me that this was a known documented behavior, or that I could change it in a setting that I wasn't aware of. The alternative answer is to change the delimiter from # to something else, but I've got over a thousand lit switchports on an old college infrastructure, and I'm not sure what else might be relying on them. 

GFS2 was until 5.3 a "technology preview", even though the documentation for RHCS gave specific instructions for it. I can't speak to it in 5.3 because I gave up on it. I have heard good things about Lustre and OCFS. I have also gathered from listening to a lot of people that (if you have the disk space available) DRBD is an excellent way to go. Unfortunately, I'm yet to try it. 

If you can boot in from the CD again, you should be able to mount the root filesystem on the eeepc to /mnt/root or whatever, then chroot over to it. That should let you recover whatever you need. 

1 - probably, though not recommended 2 - odd caching behavior, insecure, no support anywhere 3 - no idea There is essentially a ready-made solution for this in memcached: $URL$ 

The next line is the segfault message. On my CentOS 5.3 machine (rpm version 4.4.2.3), my rpm immediately does this: 

I just spoke to some people who frequent the NJ Sysadmins List ($URL$ who work in schools (K-12 typically) and run benchmarks on the time it takes them to connect to the network and load their remote desktops from a centralized server. What they did was load a cart with 30 laptops into the room, and power them all on simultaneously. The metrics they were looking for were "time to bind" to the AD server, and "time to full desktop". They charted the minimum time and the maximum time for varying loads (30 laptops and 60 laptops). I don't think that kind of testing scales up, but in their rooms, they rarely get more than 30 laptops at once. Are you gathering metrics right now? It might be possible to extrapolate on those, and carefully change variables to determine what causes performance increases and what doesn't. 

I got it! Unbeknownst to me, ScreenOS has the ability to pipe the output from any command to a tftp server! The usage is: 

How about a Cisco 1841? It's got two built in FastEthernet ports, and it supports WICs so you can practice configuring whatever else, if you want to buy the cards. It retails for $1,400, but RouterMall has a refurb on sale for $525, and they might knock off that extra $25 if you ask nicely. 

Do you mean single sign-on or merely authentication? Authentication is probably pretty easy. Just point twiki to the OU that you keep your users in, if it's like every other LDAP authentication scheme out there. Single sign-on is much more complex, and I have no idea. Here's a HOWTO that might help: $URL$ 

The "$USER1$" is a Nagios macro that points to the /usr/local/nagios/libexec directory. You can edit the "resources.cfg" to see what else is available, and even add macros. Anyway, now that we've got the command in there, we've got to set up a service to take advantage of it. Save the commands.cfg and edit "services.cfg". Notice that everything is in the format: 

I'm taking a look at buying some new servers (small infrastructure, 2 racks, etc), and although I like a lot of the features in blades, I'm looking at the price point for Silicon Mechanics' 4-node machines. $URL$ It's a bit like a mini-blade enclosure, but has no shared resources, except for the redundant power supplies. A single point of management would be great, but for the low price point here, I'm possibly willing to give that up, if the server quality is adequate. Basically, have you used these machines? Any problems? Anything you like? 

So the answer to your question is "yes", but it would take a lot of work. A better response would be to fix the problem of your getting so many emails. Here's my question: Are you getting a bunch of emails because a bunch of things go down, or because one thing goes down, and everything else alerts because that one thing is broken? If you give us more information about the situation, I'm pretty sure we can come up with a better way to arrange your configuration so that you only get the notifications you need to take care of the problem. 

will recreate the directory tree of ./ in which html files are found, and build the same under /target/base/directory 

I might be going out on a limb here, but I don't think that raw performance is the most important metric when it comes to technologies like this. I think that usability and interface is important, as well as tools to support a reliable infrastructure. It seems to me that Xen has a far more robust set of existing applications that support it than does KVM. That might not be the case, as I have no evidence to back it up. Whatever you go with, decide what the best solution is for you, and look at the entire package, not just the raw performance. 

I can't find a lot of documentation on it, but it appears to be the vmware host/guest filesystem $URL$ 

I've been learning more about IPv6, and am getting to the point where I'm going to be implementing an IPv6 lab to test various technologies that our company relies on, so that I can re-engineer them now, if necessary, for a future IPv6 switchover. My plan is that in a year and a half, we're able to run fully IPv6 inside the network, and that we'll be running dual-stacks for client access. I've decided a year and a half so that I have 6 full months of testing and planning, and run the "hot" side of our infrastructure as IPv6 for 6 months while the "warm" side is IPv4, and after 6 months, convert the "warm" to IPv6. That will give me a testing, go live, and fall back point. I'm interested to hear how other people are solving this problem, and what your roll-out plan looks like. Edit @Evan: My business reason is foresight. Eventually it's going to be necessary to have IPv6 if you want new network blocks. Eventually, my clients will be on IPv6. Eventually, everyone is going to be on IPv6. I want to convert before we're forced to convert, and I want to be able to do it on my terms, rather than under pressure from some regulatory agency. Edit 2 Gerald Combs makes a great point. Emerging markets are not going to be able to get IPv4 blocks in the volume that they'd need, so at a point in the near future, and far sooner than established infrastructures, they're going to be using IPv6 regularly. Anyone with international clients or in a market that shows growth potential in the world economy may want to step it up. 

Alright. Obviously, passive mode needs to be disabled. I've read the man page a few times and I understand that I need to use -P to specify "active" mode, however from the documentation it seems like this will open a port on the client (my) machine for the data to stream to. Since it's behind a firewall, this won't work. This tells me that I misunderstand something, because the CLI client works in active mode. Help me serverfault-kenobi, you're my only hope. 

Is there a reason you want to run it in a virtual machine and not run it natively? There are still lots of distributions that run natively on PPC, so don't feel like you've GOT to run it in a VM. If you are tied to the idea of a VM, know that it's probably going to be ugly. Most of the virtualization platforms for PPC Macs aren't virtulization engines so much as emulation engines. Since there's no Intel-compatible hardware layer, they've got to completely pretend, which leads to incredibly slow performance. The only one that MAY offer some performance that I know of may be QEMU. There's a Linux-on-PPC forum Good luck. If you can't get native virtualization and you don't want to run native linux, then I think having a production server running on an emulated platform would be a bad idea. Since you asked. 

I can't afford VMware infrastructure to do all the cool things, but I also don't have the money to buy a physical server for each and every machine I need, so I've been implementing some non-core machines with VMware Server. I'm interested in hearing about what other people do with this, and if it's a long-term viable solution, or if I'm just postponing the inevitable migration to ESXi 

Your best bet will probably be to find or create an MSI, and then use the GPO to distribute it. Here's a link documenting how to create an MSI: $URL$ 

Would it be possible to configure the networking of the ESXi machine to create static routes matching those IP addresses or blocks, and route them to localhost? That would effectively eliminate the chance of traffic passing back to those hosts. 

It should work, but you'll only be able to run 32bit OSes (at least if it's the same as VMware Server, VirtualBox, etc etc) 

Just curious, but is your queue > 2GB in size? I'm wondering if it's running into a filesystem size limit or a hard limit for postfix. I know that Apache dies when it hits 2GB on the log file (or at least it did at one point) 

and update with the results? My initial guess is that PHP isn't installed. Assuming you don't see something like: 

It sounds like we're in a similar boat, in terms of infrastructure size and complexity. Essentially, I've got a SAN that handles my production data, then I've got a backup server with a pretty decently sized locally attached storage that is attached to a tape library (LTO-3 which is 400GB uncompressed / tape) Essentially, I do data-level backups. Since I'm running Linux, I do rsyncs to get the data from the SAN-attached-machine to the backup machine, then I write the data to tape. I'm fortunate that I've got enough local storage on the backup server that I can keep a copy locally, then just rsync the differences, but if you can't set that up, lots of backup solutions use the idea of a spooling directory to locally store the data while it's being written to tape. Because of the way that tape writes, it's a very bad idea to stream from network to tape directly, such as a windows file share or NFS share. That completely kills the tape write speed AND it kills the lifetime of your tape drive. So use a local disk to spool the data onto. The backup solution I use is called Amanda, which is pretty esoteric in its configuration, but has a commercial version available (for $100/server being backed up) which has a web based configuration, and you can also get extensions to plug directly into various databases. EDIT Since you mentioned not having tapes, I would recommend a poor man's virtual tape library (VTL), i.e. external USB drives. Amanda, at least, can address files as if they were a VTL, and I'm sure other software packages can as well. Really, though, hard drives have a defined lifetime. If your company is spending enough money to buy a SAN, you should work on them to get a tape changer. They're actually not as expensive as they used to be, particularly if you don't buy on the bleeding edge.