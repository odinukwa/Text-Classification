The values you'd get from with (that you were previously passing to ) are the same values you have previously used to define the OpenGL viewport size using glViewport. If, as noted in the referenced documentation, you've never called yourself, the width and height of the viewport are the dimensions of the (client area) of the window (and the X and Y values are both zero). You can therefore use the bounds of the client area of your window in the computation of your pick ray where glUnProject would have used the values. 

Purely through memory layout. You give D3D a pointer to a chunk of memory which you claim to be organized in a certain fashion (for example, via your cbuffer definition). It's up to you to ensure that organization is actually true. 

Most of the time, those are not encrypted data files. There's a difference between encryption and a custom file format. Most games tend to use the latter, not the former. Encryption is concerned with protecting data in such a way that only certain people can read it; a custom file format is generally only about storing a particular collection of data in the most-efficient or otherwise most-useful form for the program that will consume the data. Encryption is relatively pointless for most game data that will be directly read client-side, on the user's computer. The user's computer must perforce decrypt the data to use it, at which point somebody could intercept the data in-memory without much more effort than it took to read the data on disk, so all that extra effort and potential extra file size that went in to "protecting" the data is lost. The games that do use encryption somewhere (in a network protocol or a server back end, or even the few that do make use of it somewhere on a client side) will generally use an established encryption protocol of some flavor (and not rely on security through obscurity). Reinventing your own is a very bad idea, because it's surprisingly easy to create something that looks secure but is open to one of the many vulnerabilities or attack vectors that have been developed over the years. It's a fascinating subject if you're into that sort of thing, and you might consider taking a few classes on the subject. 

Per that comment, one is now expected to use the method from the class, passing an enumeration value to specify the desired triangulation algorithm (as you noted, the value you want to use for a Bayazit implementation is ). 

AI in games is about the modeling of behavior more than anything else. Interfaces that implement AI on a per-entity basis (entity system or not) are typically called "agents" or "actors," and typically contain code or data to control behavior of an individual creature/person/NPC/object/et cetera in the game. With that in mind, a common way to put AI into a component-based entity system is to have (or or , et cetera) which are associated with entities. Such a component implements an entire class of behavior for an entity and generally you don't attach multiple (although you could). For example, you might have an component or an component. In many games, "AI" typically just means executing behavior scripts, so often you won't even see dedicated AI systems or components since such behavior is normally just handled by more general scripting components that allow designers to attach arbitrary Lua (or whatnot) scripts to entities. I would not recommend an approach where you implement individual actions an entity can take as components and shove a bunch of them on to an entity, as that is too fine-grained and doesn't afford you the ability to easily order the actions without enforcing an overly-rigid update order on your entity component system. It also makes branching decisions difficult, and implies you're going to do a lot of adding and removing of components at runtime which isn't always very common (and thus not always very efficient). As always, the specifics of what goes into an "AI component" are going to depend heavily on your game itself: what it needs from AI, how your AI works in absence of the component system (the component system, remember, is a high-level object composition system and something like AI, rendering, physics should all be usable without also requiring the use of the component system; keeping that in mind will help you design better systems that work in isolation and help avoid the design paralysis that so often comes with building component systems for some reason). 

Joysticks and alternative input devices tend to vary wildly in how they expose their inputs through to the drivers, so it isn't always the case that an analog Z axis will correspond to triggers (for example, if the controller's triggers don't have analog input values, they may just be additional buttons). The API you use to access the joysticks may do some of the work for you and attempt to homogenize the data from the controller, but this depends heavily on the API and isn't always done properly, unfortunately. It sounds like you're on a Windows platform. XInput only supports Xbox-like controllers, the "next best thing" is probably DirectInput, even though it's a bit long in the tooth and COM-like. 

Copyright and intellectual property law varies from country-to-country. You're talking about anime, which means the source IP probably falls under Japanese copyright law. I am even less familiar with Japanese law than US law, but in the US, it is not sufficient to "give credit" to avoid infringing copyright -- you need to obtain the permission of the copyright holder. Even though you may see others disclaiming that "no infringement was intended," that is not a firm ward against litigation. It's possible that some things you want to use (such as the names of characters) do not fall under IP protection rights (or would be permissible under fair use), but others (such as character designs or images, or the proper name of the anime itself) may be subject to copyright, trademark or other equivalent IP protection. You'll really want a lawyer to help you untangle that mess. Either find yourself a lawyer, or choose a different tack for your development plans that do not involve the potential legal ramifications of IP infringement. 

Be warned that the transition into 3D graphics from 2D is much more difficult than the transition into 2D graphics initially. It is much more important to understand the fundamental mathematics involved in 3D graphics, lest you end up breaking your code in ways that won't seem to obvious. I would recommend you familiarize yourself with basic linear algebra, matrices and vectors. If you have the resources, purchasing the books "A Geometry Toolbox" and/or "Fundamentals of Computer Graphics, 3rd Ed," would be great. That said, it sounds like the crux of your specific question has to do with loading 3D models. You won't really be able to adapt your existing texture loading function for that purpose (although you will still find texture loading useful when you want to apply textures to your models). Blender can indeed export a variety of formats -- there is no such thing as the "best" choice here, as all options have pros and cons. Some, however, have more of one or the other. Starting out, I would recommend you try to parse and load the .obj file format. It's very straightforward, and you should be able to find a variety of example code and tutorials online to help you load it if you get stuck. There's also the .smd file format, which is only slightly more complex and supports animation. If you prefer to avoid writing the loaders yourself, you can use a 3rd party library like the Open Asset Importer Library. 

I think you're conflating render and logic updates. The delta returned by the object is an elapsed time value that probably should only be used for render updates, but the state an object is in is more of a game logic issue, and you generally want these things handled on different timers. This is because if you pause your game logic (by stopping the game logic timer, so all delta times for logic are zero), you may still want some aspects of your rendering (such as, perhaps, HUD animations) to continue. So first I would recommend you divorce your graphics and logic timers. Then, I would recommend pushing the delta time through to every object that needs it as a parameter. You can still your delta time by calling , but do it only once at the top-most update function, and push the resulting delta down through every game or render object's own update methods. This helps decouple them from the global instance, allowing you to do better global control of timing-related effects (like slowing everything down, or pausing things as described above). I'd also recommend moving the update of the elapsed time into an actual method, and not doing it in . It makes very little sense that setting the state would also advance the object's simulation time, and it means you can't call more than once in an update interval without artificially pushing the clock for that object forward. 

In your case, I'd model both the block and the block type as objects. The Cube object should be very lightweight, because you're likely going to have a lot of those instantiated to represent your world. To start with, the Cube object can contain only a pointer to a CubeType (or an appropriately-sized integer that refers to a cube type, if you are even more space-conscious). The CubeType object itself is where you'd store all the properties of particular types (such as dirt). This allows you to avoid the overhead of duplicating the repeated properties (all dirt blocks being the same color, after all) into every single block. I see no reason to use inheritance at all for the problem scenario you have described.