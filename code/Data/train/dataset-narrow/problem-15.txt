Manually create the server initially, then keep changing its content (mutating) each time a change is required. "Bake" an image for a server based on a recipe, usually in an automated way (not manually). Then create servers from that image. And repeat this process on every change. 

I created such a tool, it is called AWS Inventory and eventually, it will cover all available resources in your account. While it is still a work in progress, should be very easy to add the items you might be missing just by adding the API name to a list. The tool is just a single HTML file that uses to query all the different and APIs of CORS-enabled services. The project is MIT license and open source at $URL$ 

Terraform supports adding an additional file with variables during invocation. documentation: $URL$ We are using that feature to provide a file on each invocation of Terraform. We also use a script to wrap the command so that its invocation is consistent, and all team members avoid having to make the same mistakes. The wrapper synchronizes with S3 before an execution, and pushes back to S3 at the end. I also hear of people doing the same thing with state stored in Consul, even adding a kind of semaphore in consul to prevent two people from starting Terraform at the same time. When you avoid setting a default value in a file, it forces the user to input the value. It can be either entered manually or using the command option like described above. Not setting a default on your secrets is a good way to enforce changes that require a change in secrets. The file is a symbolic link to one of the files with secrets which are not stored in version control. We have several, one per environment, like so , , , etc... An even better practice would be to generate these secrets files during the wrapper script based on data in Vault or some other way to share secrets. Since currently when the format of secrets changes, or secrets themselves, we need to communicate it to the team outside the version control channel - and this doesn't always work well, to be honest. But secrets do change infrequently. 

The two terms are very different. Let us start with , which literally means "no mutations" or "no changes". In the DevOps sense, it means that once you created an artifact, be that a container image, or a VM image, or maybe a package from compiled code - you declare that you will never ever change it. Often if any changes are required, you declare that a new version of "thing" will be created instead. The term means that when changes are applied multiple times, the state is mutated (changed) just once. First, it already assumes that there are going to be changes applied which means that you cannot have something both immutable and have idempotent actions done to it (no actions are done to it by contract). In the use of configuration management tools, is used in some cases when applying the same change multiple times. Like adding the line that says to the file, you don't really need multiple such lines and if one already exists it is safe to not try to append again. Also is a term used to describe actions that attempt to change things, while is used to describe nouns (objects) that are set against changes done to them. 

The best explanation can be found (as always) on Martin Fowler's bliki article on Immutable Servers. A server, be it hardware or a virtual server in the cloud, usually has an operating system and application running on it. Often application, and components of the operating system, require configuration and require changes to be applied. For example security patches, deployment of new versions of the application and configuration changes. When you consider that any change is a mutation on the state of the server, the term starts to make more sense. It means that no mutations are allowed on such a server. It is often the case, when people are involved in changing the state of the server - be it a deployment of a version, or configuration change, or a security path. The result is a server that is no longer working as expected. For example, the application might not run now because of misconfiguration, etc. This is why a practice for creating immutable servers is established. With immutable servers, an image of a server is created with all the configuration, patches, application versions bundled in. Then that server image can be used to create servers in various environments. The first environment where such an image is used, would be an environment where the image can be tested to work. Any abnormalities are detected, and only then such an image can be promoted to a production environment to replace the servers there with the new version (which is known to work well). Once the process of creating the images and promoting the images is automated, you get a very failure-proof process that involves very little human effort and very low chance to introduce failure into your service. Often immutable servers don't even include any way to "enter" them, such as for example the ssh server is missing. In this case it is also often the case that all the metrology of a server (metrics, logs) is shipped to systems outside such as a metrics database or log aggregation service. With containers (see: Docker) there is also a process to create images, and then spawn these into running containers. These are quite often replaced by new containers based on updated images, and are never mutated. Meaning that no human enters into the container to "fix something" by introducing a change. 

There is definite value in automating manual tasks and placing systems under configuration management that is done using code, not using paper and human intervention. One huge benefit is the reduction in the amount of rework. You can consider any problem caused by a human mistake in repeating the same sequence a case of rework. As well as any bug that needs to be fixed more than once. Rework is costly, and there has been some research done to quantify its cost. You can read about it in this whitepaper - $URL$ The same whitepaper also quantifies the cost of failure for services/systems, and the slowness to resolve failure. All of which are greatly reduced by having a robust automated process that prevents human mistakes from ending up in production systems. The topic of automating manual tasks has been also investigated in the State of DevOps Report that has been issued every year since 2013. Most of these are available at $URL$ as well (with the exception of 2013). In every report it was mentioned as the biggest driver for excellence in high-performing organizations of all sizes. There are plenty of reasons and explanations that can be used as proof for your case. 

Netflix have presented their method of dealing with the problem of resource sprawl. They created the Janitor Monkey which is responsible to clean-up resources when it is apparent that those are not being used. To track the created resources in Amazon AWS, generate an audit log, and allow to search through time (and history) they also created Edda. Edda allows to store and search through your AWS resources. There is some mention that Janitor Monkey might be integrated with Edda, but they have not published much information about these since. Today with AWS CloudTrail and AWS Config Rules it is possible to achieve similar results without third-party software. When Edda and Janitor Monkey were announced (2012-2013) both of these services were not yet ready to solve these kinds of problems. With CloudTrail and Config, the tracking of resources is already in place. All to do is write a script that will decide what to do with these by going over the list from time to time. 

With these typical reactions, any executive launching a minor improvement effort is rarely greeted with enthusiasm. Managers find themselves in fierce competition with other functional areas over resources needed to execute their improvements, so no wonder the command to improve intensifies cross-functional battles! Even when a manager completes his part of an improvement project, he then meets other functional areas and other organizations (suppliers, contractors, etc...) that did not do their job. This diminishes or totally negates the results. This cross-functional tension is not limited to improvement efforts. It is in the very heart of day-to-day decision making and the judgment of management effectiveness across an organization. Here is one real-life example: