I might be missing something obvious but I can't find references about the complexity of counting matchings (not perfect matchings) in bipartite graphs. Here is the formal problem: 

For now take $L := (0|1)^* (\# (00'|11')^*)^* \# (0' | 1')^*$. Observe how, past the first $\#$, we must enumerate alternatively an unprimed and a primed letter. So, on the un-dashed triangle of intervals, our observation above still stands: even though it seems like these intervals have more space to the right of the first $\#$, only one position out of two can be used. The same claim holds for the dashed intervals. Now, $L$ further enforces that, when we enumerate an unprimed letter, the primed letter that follows must be the same. So it is easy to see that the possible words are exactly: $u \# (\tilde{u} \bowtie \tilde{u}') \# u'$ for $u \in \{0, 1\}^k$. Now, to show the claim, we simply repeat this construction $m$ times. Here's an example for $k=3$ and $m=2$, using now the real definition of $L'$ above the statement of the claim: 

Further, such a partition can be computed in PTIME. I have posted our current proof online. It's very rough and essentially not proofread because we have no use for the result for now, but I still thought it was tidier to add an answer to this CStheory question with our current progress. Don't hesitate to get in touch with me if you're interested in the result but can't make sense of the proof. 

I am interested about the minimal size (number of gates) of a family of circuits (with negation) over a complete Boolean basis (with fanin 2) that computes some explicit Boolean function. (In other words, I want results that apply for a specific function, not diagonalization, counting, or non-constructive arguments). I call $n$ the number of inputs. Section 1.5.2 of Boolean Function Complexity by Stasys Jukna (2011) says that the best such lower bound currently known is in $5n - \text{o}(n)$, from Iwama and Morizumi in 2002. This is very surprising, because, as Shannon proved in 1949 by a counting argument, most Boolean functions require exponential-size circuits. Is the $5n - \text{o}(n)$ result still the best known? Is there any reason why proving a super-linear lower bound on the circuit size of an explicit function seems out of reach? In particular, do we know that solving this would close long-standing open problems in complexity theory as well? 

A (finite) poset $P = (X, <)$, or partially ordered set, is a (finite) set $X$ equipped with a transitive antisymmetric relation $<$; it can be equivalently seen as a DAG $G = (X, E)$ that is transitive (whenever $(x, y) \in E$ and $(y, z) \in E$ then $(x, z) \in E$). An automorphism of $P$ is a bijection $f$ from $X$ to $X$ such that $x < y$ iff $f(x) < f(y)$, in other words, both $f$ and $f^{-1}$ are order-preserving. The automorphism is fixed-point-free if there is no $x$ such that $f(x) = x$. Of course, the identity is always an automorphism (which is not fixed-point-free); other automorphisms are said to be non-trivial. Both automorphisms and fixed-point-free automorphisms are well-studied natural notions for posets; intuitively, posets that have non-trivial (fixed-point-free) automorphisms have a certain symmetry. Is anything known about the complexity of determining if a poset has a non-trivial automorphism, or fixed-point-free automorphism? Or the complexity of counting the number of automorphisms, or fixed-point-free automorphisms? For DAGs that are not transitive, determining if a DAG has a non-trivial automorphism is in NP and its complexity is unknown, like that of graph isomorphism (source). So, while the problem for transitive DAGs is still in NP, it should not be realistic to prove hardness as that would imply hardness of that open problem; but maybe the graph being transitive makes the problem easier (solvable in polynomial time)? For other natural counting problems about posets, the problems of antichain counting (antichains are subsets of elements that are all pairwise incomparable), or of linear extension counting (linear extensions are the way to extend the partial order to a total order by adding more comparability relations), are all #P-complete to compute. (source and source). Is it also hard to count automorphisms, then? 

(Observe that there is some sort of duality in the following sense: given $C$, I can easily decide if an input word $w$ is in $L$ by evaluating the circuit, but it is NP-hard in general to find some word in $L$ by finding an assignment such that the output is true. Given $C'$ it is likewise NP-hard to decide if some input word $w$ is in $L$ because I have to see if an assignment yields $w$ as output, but it is easy to find some word in $L$ by evaluating the circuit on any arbitrary input.) 

The problem is NP-hard for $k=3$ already. Indeed, testing if a graph is tripartite (i.e., there exists a partition $V_1 \sqcup V_2 \sqcup V_3$ of its vertex set $V$ such that each edge is between two different subsets) is cleary NP-hard, as it is exactly equivalent to $3$-coloring. Now, I reduce the problem of the question to that problem. Given a graph $G$, construct the 3-uniform hypergraph $H$ by adding to each edge $e = \{v_1, v_2\}$ a fresh vertex $v_e$. I claim that $H$ is tripartite iff $G$ is. Indeed, a tripartition of $H$ clearly gives a tripartition of $G$. Conversely, given a tripartition of $G$, we can construct a tripartition of $H$ by assigning each fresh vertex $v_e$ to the one available class of the partition. The reduction is obviously PTIME. 

A polytree is a directed acyclic graph which does not have any undirected cycles, i.e., it is a tree when we replace each directed edge by its undirected counterpart. Given a polytree $T$ and a node $n \in T$, the set of reachable leaves $L(n)$ of $n$ is the set of nodes $n' \in T$ that have no child in $n'$ and such that $n'$ is reachable from $n$. I would like intuitively to know an efficient algorithm to preprocess a polytree to be able to answer queries where I am given an arbitrary $n \in T$ and I must enumerate the contents of $L(n)$. Specifically, a preprocessing algorithm takes as input the polytree $T$ and computes some data structure $D$ in some amount of time. An enumeration algorithm takes as input $T$, $D$, the query node $n \in T$, and the previous state $S_{i-1}$ of the enumeration (initially $S_0$ is empty), and outputs the $i$-th element $n' \in L(n)$ and a next state $S_i$ (with a special value used to signal termination of the enumeration). The enumeration, when called successively, must output exactly the elements of $L(n)$ in some arbitrary order, without outputting the same element multiple times. What are the most efficient algorithms for this problem, in terms of preprocessing time and enumeration time? Specifically, I am looking for a linear-time preprocessing and for constant-delay enumeration, i.e., the preprocessing should take time $O(|T|)$ and, for any query node $n \in T$, each enumeration step should take $O(1)$ time. If this is known to be impossible, I am also interested in a lower bound. [Note that we can just precompute the answer for all nodes with quadratic preprocessing time, or compute each answer on the fly with linear-time enumeration for each answer (to traverse the relevant part of $T$), hence my focus on linear-preprocessing and constant-delay.] [Further note that, if $T$ is a directed tree, we can achieve what I request by precomputing in linear time, for each node, its first and last reachable leaf in pre-order traversal, and for each leaf, its next leaf in post-order traversal. Then we can do constant-delay enumeration by jumping to the first reachable leaf of the vertex, and go through the leaves in order until we reach the last reachable leaf of the vertex. But the extension to polytrees does not seem straightforward.] 

Obviously this problem is in NP, by guessing a bijection $f$ and checking membership to $L$ in PTIME. My question: Is there a regular language $L$ such that the letter scheduling problem for $L$ is NP-hard? Some initial observations: 

OK, I think I found something relevant: this paper mentions a "T-occurrence problem" in section III (p. 2) which is exactly our problem (where $T$ is what we called $k$), hidden behind some domain-specific jargon. The ScanCount algorithm that they propose is the naive approach I suggested in my question. The MergeOpt algorithm is a generalization of the binary search trick. Their main proposal (DivideSkip) is a combination of this binary search trick and a different trick (MergeSkip) to skip multiple values. It even seems that experimentally the clever approaches are much better than the naive approaches (look at the "No filters" column in page 8, the filters are heuristics for their domain-specific stuff). This can be combined with David Eppstein's trick to make multiple binary searches in $S_2$ more efficient, and with the idea of using interpolation search instead of binary search (an idea from this other paper from the same field). 

In pseudocode, reformulating the second point to substract $q$ multiple times instead of finding $M$, we get the following very simple algorithm: 

The International Conference on Database Theory (ICDT) publishes its proceedings in the LIPIcs series. It is essentially the European-based database theory conference, with PODS (not open-access) being the American-based one. There is a more detailed list of open-access venues in data management research and other neighboring areas on this page. (Disclaimer: I was involved in setting up the page.) 

An edge cover is a subset of edges of a graph such that every vertex of the graph is adjacent to at least one edge of the cover. The following two papers say that counting edge covers is #P-complete: A Simple FPTAS for Counting Edge Covers and Generating Edge Covers of Path Graphs. However, unless I missed something, they do not provide a reference for this claim, or a proof. (Reference 3 of the first paper seemed promising, but I didn't find what I wanted there either.) Where can I find a reference or proof of the fact that counting the number of edge covers of a graph is #P-complete? 

It is clear that this correctly enumerates $S(N(n))$, and that it is constant delay because at each step we enumerate something So now let's turn to the proof of claim 1. To do this, we will proceed bottom-up as I pointed out above, further maintaining the following invariant: for any node $n$ of $P$, $N(n)$ is never a small internal node, so it is either a large internal node or a leaf. In other words, small internal nodes will only be used as an intermediate tool in the construction, but no node of $P$ directly points to such a node in the result of the indexing. The base case is for a leaf $n$ of $P$, where we set $N(n)$ to be a fresh leaf node of the infix tree whose contents are $\{n\}$. The inductive case is for an internal node $n$ of $P$ with children $n_1$ and $n_2$, for which $N_1 := N(n_1)$ and $N_2 := N(n_2)$ have already been prepared (and are not small internal nodes). We set $N(n)$ as follows depending on the types of $N_1$ and $N_2$. Note that, by design, in the nodes that we add, we will be pointing to $N_1$ and $N_2$ (and also to their children in some cases), but that's fine provided that we don't modify them. 

I am given as input a DAG $G$ of $n$ vertices where each vertex $x$ is additionally labeled with some $S(x) \subseteq \{1, \ldots, n\}$. A topological sort of $G$ is a bijection $f$ from the vertices of $G$ to $\{1, \ldots, n\}$ such that for all $x$, $y$, if there is a path from $x$ to $y$ in $G$ then $f(x) \leq f(y)$. I wish to decide whether there exists a topological sort of $G$ such that for all $x$, $f(x) \in S(x)$. What is the complexity of this decision problem? [Notes: Clearly this is in NP. If you look at the graph of allowed vertex/position pairs, with undirected edges between pairings that conflict because they violate the order, you get a graph of disjoint cliques where you want to pick at most one pair per clique, at most one pair per position and at most one pair per vertex -- it seems related to 3-dimensional matching but I can't see if it is still hard with the additional structure of this specific problem.] 

This is clearly in constant time, and one can verify that the semantics is correct, i.e., $S(N)$ is the set of reachable leaves, with no dupes: this is obvious for leaves and proved in the inductive case from the contents of $N_1$, $N_2$ and their children. This concludes the proof of claim 2 and the proof of the overall scheme. 

The additional constraint amounts to saying that the input DAG has width $\leq k$, i.e., there is no antichain of size $k+1$. In this case, if $k$ is a constant, the decision version of the constrained topological sorting problem is in NL by Prop C.2 of $URL$ which amounts to a PTIME dynamic programming algorithm. Reconstructing a matching topological sort as part of the dynamic programming algorithm will also be in PTIME 

Consider a family $(f_n)_{1 \leq n}$ of Boolean functions, where $f_n$ is a function on $n$ variables. Consider for every $n$ the smallest Boolean formula $F_n$ describing $f_n$, and the smallest Boolean circuit $C_n$ describing $f_n$. Say we have $|F_n| = \Omega(g(|C_n|))$ for a certain function $g$. What is the fastest-growing $g$ for which this is known to be possible, and the slowest-growing $g$ for which it is known to be impossible? (From the comments, it seems like there is still a gap here, but I'm trying to understand which one.) This is the "simple" version of my question. What I am interested in is a multi-output, probabilistic (=weighted), variant of the problem, defined as follows. It is clear how to extend circuits to be multi-output, and I define a $k$-output formula to be just a $k$-tuple of formulas on the same inputs. I say that the input variables have a certain probability of being true (written in binary and accounted for in the circuit or formula size), each independently from the others, and I look at the probability distribution on the tuple of outputs (forgetting which input is yielding which output, just looking at the distribution on values), given this product distribution on the inputs, in the circuit and formula context. Here again the circuits are certainly more concise than formulae, but how much? Are there some distributions that can be exponentially more concise to represent with circuits, intuitively because of sub-expression reuse? To give an example for this more elaborate version, consider the following distribution on $n$ outputs: 

Fix a finite group $G$. I am interested in the following decision problem: the input is some elements of $G$ with a partial order on them, and the question is whether there is a permutation of the elements that satisfies the order and is such that the composition of the elements in that order yields the group's neutral element $e$. Formally, the $G$-test problem is as follows, where the group $G$ is fixed: 

An antichain of a poset $(P, <)$ is a subset of pairwise incomparable elements, namely, a subset $A \subseteq P$ such that there are no $x, y \in A$ with $x < y$. By a result of Provan and Ball, it is known that it is #P-hard, given a poset, to compute its number of antichains. My question is whether this hardness result is known to extend to restricted classes of posets. More specifically, I am interested in posets which are distributive lattices. Is it #P-hard to count antichains in distributive lattices? Of course, one could also ask for which classes of posets is hardness, or tractability, known to hold. Has there been any work on this since Provan and Ball? 

Thanks to this observation, to check clauses, we will define our regular language $L$ to be the intersection of two languages. The first language enforces that the sub-word on even positions is a word in $L'$, i.e., if we ignore the annotations then the word must be in $L'$, so we can just use the construction of the claim and add some annotations. The second language $L''$ will check that the clauses are satisfied. To do this, we will add three letters in our alphabet, to be used as annotations: $+$, $-$, and $\epsilon$. At clause $1 \leq i \leq m$, we add unit intervals to annotate by $+$ the positions in the $i$-th repetition of $u$ corresponding to variables occurring positively in clause $i$, and annotate by~$-$ the positions corresponding to negatively occurring variables. We annotate everything else by~$\epsilon$. It is now clear that $L''$ can check that the guessed valuation satisfies the formula, by verifying that, between each pair of consecutive $\#$ symbols that contain an occurrence of $u$ (i.e., one pair out of two), there is some literal that satisfies the clause, i.e., there must be one occurrence of the subword $+1$ or of the subword $-0$. This concludes the reduction from CNF-SAT and shows NP-hardness of the letter scheduling problem for the language $L$.