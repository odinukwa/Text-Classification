This table has an column on it. I expected that when I selected the values from the table by this monotonically increasing primary key, I would see the timestamps in the same order, too. The timestamps might not be sequential, because there might have been other updates, but they would at least be in order. However, what I am seeing is different. The inserts are interleaving by primary key, but the timestamps are sequential by thread. 

We have a process that generates an inventory report. On the client side, the process splits of a configurable number of worker threads to build a chunk of data for the report that corresponds to one store out of many (potentially thousands, typically dozens). Each worker thread calls a web service that executes a stored procedure. The database process for processing each chunk gathers a bunch of data into a #Temporary table. At the end of each processing chunk, the data is written to a permanent table in tempdb. Finally, at the end of the process, one thread on the client side requests all the data from the permanent tempdb table. The more users that run this report, the slower it gets. I analyzed the activity in the database. At one point, I saw 35 separate requests all blocked at one point in the process. All these SPIDs had on the order of 50 ms waits of type on resource . One SPID has this resource, and all the others are blocking. I did not find anything about this wait resource on a web search. The table in tempdb that we are using does have an column. Are these SPIDs waiting for the IDENTITY column? What methods could we use to reduce or eliminate the blocking? The server is part of a cluster. The server is running 64-bit SQL Server 2012 Standard Edition SP1 on 64-bit Windows 2008 R2 Enterprise. The server has 64 GB RAM and 48 processors, but the database can only use 16 because it is the standard edition. (Note that I'm not thrilled by the design of using a permanent table in tempdb to hold all this data. Changing that would be an interesting technical and political challenge, but I'm open to suggestions.) UPDATE 4/23/2013 We've opened a support case with Microsoft. I'll keep this question updated as we learn more. UPDATE 5/10/2013 The SQL Server support engineer agreed that the waits were caused by the IDENTITY column. Removing the IDENTITY eliminated the waits. We could not duplicate the issue on SQL 2008 R2; it occurred only on SQL 2012. 

The second thread is running identical code, except that it is doing from the function to insert its thread ID. First, a word about the function. This uses a series of cross-joined common table expressions with a ROW_NUMBER() to return a lot of numbers in sequence very quickly. I learned this trick from an article by Itzik Ben-Gan, so credit goes to him for it. I don't think the implementation of the function matters, but I will include it anyway: 

My question is: 1) Why is the timestamp not always increasing with concurrent inserts? Bonus points if you can answer this question: 2) Why are the concurrent inserts overlapping the primary key instead of all being inserted at once? Each insert is running its own implicit transaction, so I expected the primary keys to be in order for a single thread's insert. I did not expect the primary keys to be interleaved. I don't know enough about replication to answer this one: 3) Do having timestamps out of order cause a problem with replication? In the above example, what if thread 2 commits its data first? When thread 1 completes, its timestamps are all lower than the records inserted by thread 2. I peeked at the executing requests and verified they are not running parallel, so I don't think parallelism is the problem. Note that this query was running in the default (READ COMMITTED) isolation level. If I increase the isolation level to SERIALIZABLE, I still get timestamps in reverse order when threads change. I am testing this on SQL Server 2008 R2. To check the timestamp orders, I was doing a , and I was also using the following queries: 

I am not familiar enough with extended events to know if they would work better-- event pairing, maybe? 

If I change 'use tempdb' to 'use master', the results are the expected 10 databases for each query. Why would sys.databases return different results when run as the user dbo from the tempdb database? And why does it return all databases with as the dbo user? More information - If I run this script in SQL Server Management Studio without including the at the bottom, my list of databases shrinks to the same two that this query returns from sys.databases. 

I wanted to share my experience with trace flag 4199. I just finished diagnosing a performance issue on a customer system running SQL Server 2012 SP3. The customer was moving a reporting database away from their production OLTP server onto a new server. The customer's goal was to remove competition for resources with the OLTP queries. Unfortunately, the customer said the new reporting server was very slow. A sample query run on the OLTP system completed in 1.6 seconds. The query plan did an index seek on a ~200 million row table that was part of a view. On the new server, the same query completed in 10 minutes 44 seconds. It performed an index scan on the same ~200 million row table. The reporting server data was a copy of the OLTP data, so it did not appear to be a difference in the data. I was stumped until I recalled that our software (which runs their OLTP system) enabled some trace flags on startup. One of them, 4199, I recalled was a query optimizer fix. I tested enabling trace flag 4199 on the customer's new reporting server, and the reporting query completed in 0.6 seconds. (Wow!) I disabled the trace flag, and the query was back to completing in 10 min 44 sec. Enabled the flag: back to 0.6 seconds. Apparently, enabling the trace flag enabled the optimizer to use an index seek into the view on the 200 million row table. In this case, the query optimizations enabled by trace flag 4199 made an enormous difference. Your experiences may vary. However, based on this experience, it definitely seems worth enabling to me. 

I found the problem. My login had a different default database than the database. When I changed my default database to , the error went away, and I was able to Watch Live Data on the extended event sessions. To change the default database, in SSMS, I expanded the server, Security, Logins. I right-clicked on my user credentials. On the Login Properties page for my user, I changed "Default database" to . The error went away when I closed and reopened the connection in the SSMS Object Explorer. 

I have tried this with my own custom event sessions. I can't watch the live data on them, either. I can query the system_health ring buffer target data from . Why can't I watch live data for any extended events session? (Note that this is also a Microsoft Connect item closed as Not Reproducible.) 

During work hours, take a look at sys.dm_exec_requests and see what the column says. This will tell you what the requests are waiting for. Right before working hours, you could run and then look at sys.dm_os_wait_stats to see the accumulated stats during the day. Do you have indexes defined on any of these tables? If not, then table scans might be clogging your I/O system, and locks might be causing some blocking. If people are running SQL Profiler traces during work hours, those could be slowing down the entire system. You could detect those by quering sys.traces. Running a careful profiler trace yourself might reveal some interesting facts about this query. Try capturing a Showplan XML Statistics Profile event when it runs. Maybe the query processor is choosing a very bad query plan. Maybe the plan is generating intermediate tables that have a ridiculous number of records, or maybe there is a bad nested loop that would work better with an index or with a merge join. Since this is an external server, another possibility is that you are simply overwhelming network bandwidth during working hours. You mentioned in a comment that there was a lot of data coming back. Adding some filters in the query might help-- if that is an acceptable solution for your application. 

These queries were optimized and ran exactly as I expected-- get the #Keys NULL value first and seek to Order_Details_Taxes. They are the last queries in the query plan linked. Why do the queries in which I used a @Table variable perform index and table scans on this large table, when I am joining using from a table that has a single NULL value to a table with only NULLs in this key value? I assume the answer is statistics and/or cardinality limitations of @Table variables, but the resulting query plan was non-intuitive to me. is on for this table and my SQL session. 

We have a SQL Agent job that is configured to run as user "dbo". This job gets a list of databases defined in sys.databases that match a naming scheme. The job then performs some dynamic SQL to cleanup some old transaction tables. The job starts against tempdb. The agent job runs fine on my own development database (SQL Server 2008 R2 Standard Edition 10.50.2500.0). The job correctly gets the list of databases. However, on a customer system (SQL Server 2008 R2 Standard Edition 64-bit 10.50.1600.1), the job does not find any matching databases despite them existing. On the customer system, a simple run against tempdb in a query window returns all 10 databases in the system. Using the profiler, I saw SQL Agent call when running this job. I duplicated the issue using the following SQL: 

So far I have not been able to capture the query plan used at the time of the deadlock, and the normal ways I try to retrieve the query plan are not returning anything(sys.dm_exec_query_plan and sys.dm_exec_text_query_plan both return NULL). UPDATE 2013-08-29 The customer installed SQL Server 2005 SP 4, but they are still seeing this deadlock. I will pursue removing the deprecated (NOLOCK) on the tables being modified and see if this fixes the deadlocks. 

I have a question about this query plan. We have a table in a test environment, Order_Details_Taxes, that has 11,225,799 rows. This table has a column, OrdTax_PLTax_LoadDtl_Key, which is NULL on every single row. This test environment is configured in such a way that this column will always be NULL. There is an index on this column. I ran some queries against this table using a NULL value for a column. A NULL INNER JOIN will never yield any results. 

As pointed out by sp_BlitzErik (thank you!), the problem here was the sampling rate was too low for the billion row transaction table. The more rows sampled by the statistics update, the more accurate the estimate, but the longer it takes for SQL Server to generate the statistics. There is a tradeoff between database maintenance time and statistics accuracy. A simple `update statistics MyTable' was sampling 0.13% of the rows. This generated a very poor estimate for the "EQ_ROWS" column that was usually hundreds of times worse than the actual row counts. For example, some EQ_ROWS estimates were over 60,000 when the actual counts were about 150. On the other hand, the default stats update completed in 25 seconds-- pretty fast for a billion rows. A full scan generated perfect EQ_ROWS statistics. However, the full scan required about 5 hours to complete. That would not be acceptable for the customer's database maintenance window. Below is the chart of samples vs. accuracy. We're going to recommend the customer adjusts the sample size manually for the largest tables in the system. I expect we'll go with a sample size of about 10%. The Avg Stat Diff column is calculated as ABS(EQ_ROWS - ActualRowCount). 

If you were profiling at the statement level to understand the performance of the function, then the profiler would have had severely affected the process of the system. SQL Server applies the function to every row. If you have 60,000 rows, then you will have 60,000 invocations to run through. That is a lot of profiling data. Our application uses functions heavily. We have learned through experience to exclude functions from profiler traces. Any time we profile functions, the performance of the entire system slows to a crawl.