That is too bad as it sounds like the cause of this issue is the embedded card authentication program. Keep on the vendor, maybe they will actually fix their software. 

A less common but still useful deployment is when you have application servers located in a DMZ that need read access to your internal Active Directory services. There's a few different security models but one involves extending your forest into the DMZ by placing an RODC there. See: Active Directory Domain Services in the Perimeter Network 

My Mac clients RDC to a Windows 2008R2, each client has their own USB printer....each rep wants their own printer. For the love of $DIETY, do not allow this to happen on your watch. Here's why. In our environment we have between 350 and 400 workstations. We have about 220 devices that have printing functionality. About 90 of the these devices are tried and true business line HP LaserJets (recommended and supported to a degree by IT). The rest are a complete menagerie of different models, make and quality. A lot of these devices are COTS all-in-one "Costco-special" devices. A lot of of them are entry level SOHO printers and MFDs. A lot of them are a wide variety of copiers. Largely people have pretty much been able to get what they want. These devices (and this kind of setup - which it sounds like you're leaning toward) is incredibly resource consuming to manage. One just because of the sheer variety and two because locally attached COTS devices suck. For the amount of time (read as: money) staff has put in trying to cajoling these devices to work we could of easily replaced most of them with a more appropriate business line product. 

If you're using a real WAP it should support SNMP. If you couple that with a monitoring system (e.g., Nagios, OpenNMS, etc.) you should be able to get detailed information about your WAP including things like client association/de-association, when a new DHCP lease is given out, and when it just fails completely. If you're not using a real WAP (and you probably should) something like SmokePing will at least get you some connectivity information. Be warned though, just because your WAP responds to ICMP doesn't mean it's functioning correctly for clients. If your laptop is multi-homed you could just setup SmokePing on it. This is the cheap and easy answer... but really SNMP is probably the way to go here. 

This method uses your Linux distro's init scripts to restart the process. These scripts are run at boot time to start apache. 

Your goal should be to find another job and leave without anything breaking. If something does break (and it probably will) be prepared to walk out. This means you should be extremely careful regarding CYA procedures. You need to assume that no on at the company has your back - make sure you're not in a position where you need to rely on someone's support. While you're looking for a new job setup a environment to practice and learn with and do your best to familiarize yourself with the current infrastructure. And for what it's worth... my degree is in Philosophy. You can succeed in this field if you want to, but not at this company. Good luck. 

It sounds like you are trying to solve the symptom and not the problem. I would suggest that a time sever hierarchy in your organization would be the appropriate and professional approach and that the effort it would take to either implement a monitoring system (which you will want eventually) or hack together some kind of script with cywgin to check to make sure your remote Linux/UNIX host/s are using the correct time would be better spent on implementing a true solution. 

Finally you should confirm that your Domain Controllers have the correct time source. See Ben Armstrong's excellent blog post for more details. 

Since your client has the rather silly requirement you cannot use your laptop or USB to download the required installation files just temporarily turn off Enhanced Security Settings, restart Internet Explorer, download the files and then turn ESC back on. 

Maybe. You can create new Virtual Machine from existing Checkpoints by Exporting a VM from a Checkpoint (I believe this merges the differencing disk and the parent disk so you don't save any time). Checkpoints should really just be reserved for temporary point in time restores: 

Now the shared object files are a little different. I like to use a combination of and . Let's say I'm interested in the object files linked against : 

The real issue is administrative: People expect SSH to be at 22, MSSQL to be at 1433 and so on. Moving these around is one more layer of complexity and required documentation. It's very annoying to sit down at a network and have to use nmap just to figure out where things have been moved. The additions to security are ephemeral at best and the downsides are not insignificant. Don't do it. Fix the real problem. 

I would greatly appreciate more information about how these namespaces are used by SCCM and exactly how this fixed the issue if anyone has more detailed information. 

It is a terrible idea to have your SQL server directly exposed to unwashed multitudes of the Internet. Instead you want to invest it what's called a "3-Tier" architecture. 

I'm working at an organization that has a small to medium sized network (~500 users) and about a dozen /24 subnets (and a handful of smaller ones behind NAT). We use a variety monitoring software that allows us to keep tabs on remote parts of the network and respond to problems proactively. 

VLAN tagging is supported in Linux using the 802.1Q module. NIC bonding is supported in Linux using the bonding module. Every major distribution should include a kernel new enough that it supports these features. 

My experience is mostly with Citrix's XenServer but the differences between their implementation and just building your own Xen host should be negligible. 

As for what that performance penalty will look like in the real world it's really dependent on your application and implementation. It might increase the time by a factor four which only works out to an extra 4/10ths of a second, or it might be four seconds. Testing is important here. It looks like at this point NIST (SP800-131A) only considers RSA and DSA 2048 key-sizes to be acceptable after 2011-2014 and they must have at least 112 bits of security strength. See the section in SP800-131A on Digital Certificates for more information. In my opinion it all boils down to this: your safety margin is "small" with 512-bit keys, "not bad" with 1024-bit keys, and "pretty good" with 2048-bit keys. Do a bit of threat analysis and decide how fat your organization's safety margin needs to be, what kind of data you are protecting and what you stand to lose if the cryptosystem protecting it is broken. Make sure to consider existing policy, and any legal requirements you need to comply with. 

You can connect your virtual machine's COM port to named pipes but apparently not to actual serial ports. Apparently this is primarily a debugging feature. You can provide access for a virtual machine to a serial port using a COM port re-director such as KernelPro's USB over Ethernet. Additionally the software and drivers for the licensing key need to support being installed on Window Server and in our case on Server Core if you want the licensing key to be installed on the host server. I ended up installing the licensing key and software on a workstation and then using it as that site's "licensing server". This adds about ten different things that can now break this software. A software-based licensing key would of saved me much trouble and I suspect be a more reliable solution. 

Did you clone the effected virtual machines from an existing image or from each other? I'm inclined to think that if you did, they might have duplicate SIDs since it only effects Domain Accounts and not Local Accounts (I'm assuming you have tested with multiple accounts of both types to make sure it is not tied to those accounts specifically). Give PsGetSID a try: 

If I look through the ruleengine.log (which is presumably the log file that the higher level SMS_RULE_ENGINE log within SCCM gets generated from) and coordinate the Package ID for the relevant Deployment Packages that the Automatic Deployment Rules are supposed to place these updates in I find the following: 

Unlikely but a spectrum analyzer could tell your for sure. There may be other devices in the 2.4GHz band that are effecting your clients. 

It means exactly that. RSync creates a list of all the files that have changed since the last time it was run using a "quick check" algorithm (by default) that looks for files that have changed in size or in last-modified time (rsync(1)). This warning is reporting that files or directories in the file list no longer exist at the time rsync tried to copy them to your destination. The files that have changed are most likely temporary files but if you wanted to verify this you can configure rsnapshot to pass rysnc the option to build the file list, wait an appropriate amount of time, run it again and compare the two to see what files have "disappeared". 

It has been a while since I worked in the network administration side of things but here is what I think about this: