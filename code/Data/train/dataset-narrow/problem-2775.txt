What are differences between them ? Are both ways correct ? For the standard shadow mapping with software pcf a shadow test will depend on the linear depth format. What about variance shadow mapping ? I implemented omnidirectional shadow mapping for points light using a non-linear depth and hardware pcf. In that case a shadow test looks like this: 

Unfortunately it doesn't remove light bleeding. Did I do something wrong ? Maybe I should calculate two different minVariance based on the positive and negative exponents ? Edit1: Calculating minVariance this way: 

The code doesn't work properly and I don't know how to explain that. What is wrong ? I found other solution which works perfectly, but it require extra integer texture in the gbuffer: 

You're calculating the up vector (and also the rest of them) from a matrix unrelated to the matrix, in which you have stored the new rotation. Usually, what I do is multiply an old rotation matrix by the new rotation matrix, and then calculate the up vector from the outcome matrix. Hope this helps. 

In a fragment shader calculate the distance between the current vertex and the light position and check if it's deeper then the depth information read from earlier rendered shadow map. I know how to do it with a 2D Texture, but I have no idea how should I use cubemap texture here. I have read that texture lookups into cubemaps are performed by a normal vector instead of a UV coordinate. What vector should I use? Just a normalized vector pointing to the current vertex? For now, my code for this part looks like this (not working yet): 

I'm writing code in XNA 4.0, and part of my game entails drawing a textured grid of cubes. It is working, but the problem is the memory usage is growing way too rapidly. Each cube has 8 points, and each point is a VertexPositionTexture. A 16x9 grid takes 50MB memory, and that is just the grid and lines, no textures or anything else. Doubling the grid to 32x18 makes the memory jump to 150MB....I don't understand what is taking up so much room. I draw the grid using DrawUserIndexedPrimitives. The cubes can move around and be different sizes so I can't consolidate them to one set of vertices. What is the proper way to render a few thousand vertices without using so much memory? These are all the members for my Cube class so far: 

In my fragment shader I have passed an uniform int variable, which indicates what type of light is in usage right now. The problem is that if-else branching does not work correctly - the fragment shader performs instructions in every statement block. 

Could you give me some hints or examples (preferably in WebGL code) how I should build it? UPDATE: I figured out that view matrices are superfluous in the case of program rendering the scene with shadows. One can read the adequate texel from the shadow cubemap by using one of those vectors: or (right now I don't know which is the correct one, because both gives a not complete shadowing result - the first one mirrors the shadow and doesn't display anything from the -Y light cubemap face while the second one displays the bottom face correctly, but it does right only that: >>>img here<<<) 

but I have no idea how to do that for the first format of linear depth. Is it possible ? Edit 2: For non-linear depth I used glPolygonOffset to fix shadow acne. For linear depth and distance to the light some offset should be add in the shader. I'm trying to implement standard shadow mapping without pcf using a linear depth (-viewSpace.z * linearDepthConstant + offset) but following shadow test doesn't produce correct results: 

I can use subroutines to reduce overhead during switching shaders. I also found the following article . Do you have any other ideas how to optimize above rendering ? 

I found a interesting technique - Exponential Variance Shadow Mapping which should provides better light bleeding fix. Here is saving depth for that technique: 

In the case when equals 1, unless I comment out the content of the second block, it assigns an another value to . Also while equals 1, when I remove the second 'if' block and change to like in the sample code below, nothing happens (which means that really equals 1). 

Finally, by trial and error, I managed to get this thing working. The problem was that the cubemap texture is mirrored, so I had to scale the regular projection matrix by (1, -1, 1) in order to un-flip it. Also, the right vector to read the cubemap is . Now everything seems to be working nice! 

While coding my WebGL app I've encountered an interesting phenomena: On my first PC (with GPU Radeon HD 5850), BrowserLeaks (link) tells me that in my browser - Google Chrome Version 36.0.1985.143m the Max Vertex Uniform Vectors value equals 1024 - which is true, when I try to create inside the shader an attribute array bigger than 1024, the browser throws an error: , which f.e. in my case let's me draw about 85 simple cubes in a single draw call. Meanwhile on my other PC (with GPU Intel X3100) with Opera-Next Version 12.15 installed, where BrowserLeaks shows a value 4096 next to the Max Vertex Uniform Vectors field, I can init an array of size 250 000 and even bigger, I can draw 20 000 cubes in a single draw call and everything works fine (except a very low framerate). So now my question is: Why those numbers varies so much, why in the second case the upper limit value does not seem to be valid? How would I find the true upper limit value (and read it inside my WebGL app at the runtime)? EDIT: Ok, I've found out how to get this parameter inside a WebGL app: , but the question now is how would I adapt it to shaders... 

I use Reinhard tone mapping. I calculate an average luminance and max luminance in screen space. Based on those parameters I get an eye adaptation, for example when a camera is moved from a bright outdoor area to the dark room. How an eye adaptation process is achieved in Uncharted 2 tone mapping ? In my engine I render results of the shading to the floating point texture. I assume that I don’t need hardcoded exposure adjustment (texColor *= 16) and exposure bias = 2.0f. Or maybe I should interpret those parameters based on the average luminance ? What about “w” parameter ? Can I assign to “w” a maximum luminance from the screen space ? 

In SDL, lets say I'm rendering text to a surface. Then I blit it with the scene's main surface to form a composite image to flip. I get the text surface into a class-level member called 'messageSurface': 

I'm trying to get a basic shader to work in XNA. I pass in a bool value called "TextureEnabled" to indicate whether or not it should expect some UV texture coordinates. But regardless of what I pass, it is always expecting the UV value, and it throws and InvalidOperationException -"TextureCoordinate0 is missing": 

If I just hard-code output.UV = float2(1, 0) instead of output.UV = input.UV, it does not throw an exception, so I know that has to be the problem. Its almost like the TextureEnabled variable isn't getting set up (or not evaluated), even though I can see SetValue(false) being called in the debugger. What am I doing wrong? Here's the relevant source files, if needed: $URL$ 

UPDATE2: Finally, by trial and error, I managed to get this thing working. The problem was that the cubemap texture is mirrored, so I had to scale the regular projection matrix by (1, -1, 1) in order to un-flip it. Also, the right vector to read cubemap is . Now everything seems to be working nice! 

First of all I must say, that I have read a lot of posts describing an usage of cubemaps, but I'm still confused about how to use them. My goal is to achieve a simple omni-directional (point) light type shading in my WebGL application. I know that there is a lot more techniques (like using Two-Hemispheres or Camera Space Shadow Mapping) which are way more efficient, but for an educational purpose cubemaps are my primary goal. Till now, I have adapted a simple shadow mapping which works with spotlights (with one exception: I don't know how to cut off the glitchy part beyond the reach of a single shadow map texture): >>>glitchy shadow mapping<<< So for now, this is how I understand the usage of cubemaps in shadow mapping: