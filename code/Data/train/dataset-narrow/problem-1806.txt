in the below examples is the IPv6 address from the 2002: prefix reserved for legacy addresses, which can be found with "ipv6calc --ipv4_to_6to4addr ". radvd will do router advertisements on LAN side, telling all IPv6-capable hosts how to configure their IPv6 addresses. A typical radvd.conf may look like this: 

As suggested by Mike Renfro above, idmap_rid is the central component. Below is a list of shell commands that get a box up and running, given a fresh RHEL5.5 box: client_packages: 

The second row is standard in most modern Linux distros. In the first row, I'm pretending that my localhost is our Subversion repository, so that I can then tunnel that traffic to my workplace network. The URL $URL$ will actually resolve to $URL$ but still contain the HTTP host header Host: repo.company.com. Does that sound like it addresses your need? 

Generally speaking, a web server's user should not have write access to anything, particularly not if it is running dynamic systems like PHP. Apache achieves privilege separation by having the sensitive bits operate from a master process running as root, which the children can send log events to and get configuration from. The children run as unpriviliged users that should only read stuff. 

I am replacing an old Linux file server serving NFS and CIFS. For the new server (still serving CIFS and NFS), I would like to have software that automatically and efficiently maintains old revisions of files in parallel trees, so that they can be accessed by users without special tools. I am looking for software that is akin to Time Machine or Flyback, but works well on a server. The dataset is some 10000 files weighing maybe 60 GB. Changes are relatively few, usually less than 100 files changes daily. Using LVM snapshots will not cut it, as the old revisions must reside on a separate set of disks from the live data. Edit: To clarify: keeping old revisions is non-vital addition to the solution, so any suggestion will have to stay in the range of some hundred euros. 

Basically its a long story but somehow I've managed to find myself in charge of deploying servers across a multiple-site enterprise despite a) primarily dealing with routing and switching equipment 99% of the time, b) having very little experience in using Windows Server, and c) my boss being totally aware of this and basically saying 'better get learning'! Obviously not ideal! My only previous experience with servers has been deploying Windows Server 2008 R2 for a business with a single physical location. The server had DNS, DHCP and AD DS all installed on a single server machine - as straight forward as a LAN can get. My problem is that I have no idea as to how to scale or deploy AD DS from a single physical location to multiple physical locations. The customer has the following requirements (probably very basic to an experienced individual): 

I've eperienced something similiar before myself. To fix this I first assigned each network adapter an IP address from the DHCP scope which they belonged to (and also pointed each adapter towards the correct DNS server). After these settings were applied I then went back in and reset the network adapter to automatically receieve an IP address (and DNS address) via DHCP and that worked for me. Sounds strange I know but it did work for me. 

That the users for each physical location can be administered locally. That any user from the business (from any branch of the business) can use a machine in any other branch (if given rights). 

Apologies if this is a stupid question but my only previous experience with SAN technology is using a SAN virtualisation tool (StarWind iSCSI SAN Free). This tool comes with a management interface that allows for iSCSI targets to be configured on the simulated SAN that can then be accessed. My question is basically: How is physical SAN device managed? Is an operating system required to be installed on the SAN device and then managed via software? Or can it be managed remotely via an application with no OS on the device? Thanks for any help. 

My ASA 5510 has the following configuration for an interface. My Ubuntu box (2.6.35) connected to this network will correctly autoconf an IPv6 address, but it will not set a default route. 

The problem with this approach is that content will be different all the time, which will (ultimately) provoke rebuilding of zone files on each puppet config poll. Is there some way I can insert a timestamp without it being included in the data that is compared against previous state? 

It is the tradition of serverfault not to unduly question the preconditions, but I have to ask: is it not possible for you to either 1) mount the remote filesystem via SMB, or 2) use fuse/sshfs instead? (I assume here that the sending machine is a Linux box as you are using bash and ssh.) To actually answer your question, I think your problem is simple. Consider: 

If you have any control over the running applications, why not have them log to syslog and have syslog output to the serial terminal? Having said that, asking screen to start all the applications in separate sessions using e.g. the at or exec commands is an interesting idea. However, there are two concerns: 

You may want to consider switching the guest over to using bridged networking instead. This means the guest will request it's own address from your NAT:ing modem. If you can tell your modem to assign a specific IP, you can then make sure your server gets a persistent address that the modem can forward too. This of course still requires firewalls to be properly configured or turned off. 

Download kernel from Debian repo: linux-image-3.0.0-2-686-pae_3.0.0-5_i386.deb Force the kernel: Manually generate a ramdisk: Create /boot/grub/menu.lst entry for the new kernel manually. Note that you need to set root=/dev/xvda1 as the generated ramdisk will not contain the label. 

From your description it sounds like the kernel actually believes something explicitly unmounted filesystem from /var. I have not known Linux to "forget" that it had a mount in recent years. My suspicion falls on some cronjob/script unmounting the partition or dbus or someone confusing it for a USB device that has been removed. If this was hardware failure, the kernel will insist that the partition is mounted and generate error messages on access. 

One tool that you can try is sshfs (you can use this from the command line without needing a GUI). You do not need to do any setup on the server side. Connecting from the client is as simple as: 

I recommend reading the revision number from a file rather than reading from an environment variable. There isn't an easy way to ensure that your current environment is the same a the environment that Apache is running under. Also this ensures that the revision number in the php code survives reboots, etc. You should set Subversion to ignore the svn-revision file so you aren't checking it in. 

Basically you need to include all directories in the search, then add all files to the list, the exclude all other files. The option is handy to use as it excludes any directory that doesn't have a file. 

You need to include all of the parent directories down to the desired directory before using the exclude rule. For instance, I use the following in a backup script: 

So after many days working on this, I was able to demonstrate that BtrFS does use TRIM. I was unable to successfully have TRIM work on the server that we will be deploying these SSDs to. However, when testing using the same drive plugged into a laptop, the tests succeed. Hardware used for all of this testing: 

When you do a reverse lookup of your IP address, does the name that is returned resolve back to your IP when looked up as a forward address? For example: 

Rsync can be confusing about selective copies like this. I use the following to do the task that you're asking for: 

After many failed attempts at verifying BtrFS on the server, I decided to try this same test using an old laptop (remove the RAID card layer). The initial attempts of this test using both Ext4 and BtrFS on the laptop fail (data not TRIM'd). I then upgraded the SSD drive firmware from version 0001 (as shipped out of the box) to version 0009. The tests were repeated with Ext4 and BtrFS and both filesystems successfully TRIM'd the data. To ensure the TRIM command had time to run, I did a before performing validation. One thing to note if you're attempting this same test: SSDs have erase blocks that they operate on (I don't know the size of the Crucial m4 erase blocks). When the file system sends the TRIM command to the drive, the drive will only erase a complete block; if the TRIM command is specified for a portion of a block, that block will not be TRIM'd due to the remaining valid data within the erase block. So to demonstrate what I'm talking about (output of the script above). This is with the test file on the SSD. Periods are sectors that only contain zeros. Pluses have one or more non-zero bytes. Test file on drive: