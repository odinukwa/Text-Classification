MX, CNAME, PTR, and NS records point to hostnames. A records point to IP addresses. Putting an IP address in an NS record is a pretty common DNS misconfiguration. One reason is that you might have NS records pointing to servers outside of your domain for someone doing secondary DNS for you. That remote domain might change the IP address of the server (but leave the hostname alone). 

Brocade with their VDX line of ethernet switching gear uses it. But the thing to keep in mind is that different vendors implement TRILL in different ways and they don't necessarily interoperate. The standard is so loose that two vendor versions can claim to be standards compliant but be completely incompatible. 

You can configure a Palo Alto Networks firewall to fail over to the other ISP. You need to set up two sets of NATs -- one for one ISP and one for the other -- or set two DMZs, one for one ISP and one for the other (or overlay two subnets on one interface). It will use both for inbound and will fail over to the second for outbound when one fails. You can start reading here. 

It will work. You will get more loss at the splice than if you were splicing like fiber but you can do it. You can even mix the fiber types in longer runs. Reference: Mixing of G655 and G652 Fibers in a Network 

Since you say you see no capabilities, there is no "route refresh" capability being advertised so there is no choice but to reset the BGP session in order to effect the change in routing policy. References: 

I can't figure out why you are running two instances of OSPF on the the 2900's. This looks way more complicated than it needs to be. You can run OSPF in passive mode on the firewall and distribute a default route from the 2900's. You put a static route on the 2900's for your /24 pointed at your firewall outside IP. Since this is active/standby, if the firewall fails over, the IP address moves with the active firewall. There really is no need to announce anything from the firewall, it is just listening for a default. If you are announcing a default, there is really no need for HSRP either, that can go away. The firewall will just send the traffic to where it hears the default. It might well load balance to both 2900's, though. Seems you are making it a lot more complicated than it needs to be. There is only ONE firewall address in this configuration so a static route will work just fine. Even so, there is no need for more than one OSPF instance and the only thing you are using that for is to handle the case where a router dies. Then the firewall uses the remaining path where it hears the remaining default route. 

It is to prevent routing loops due to bad practice or configuration errors. Example: Jackweasel.COM is single-homed to some transit provider Victim.NET who has assigned them a private ASN, say 65000. Someone at Jackweasel.COM decides to initiate a peering session with Clueless.ORG who has a public ASN, and has agreed to peer with Jackweasel using the private ASN that Jackweasel has (it would surprise you how many people would not notice off that bat that they are setting up a peering session with someone who is using a private ASN and might also peer with someone else). Now Jackweasel announces routes learned from Clueles to Victim. Victim will now keep that full path in its route announcements to prevent a loop just like it does with regular BGP announcements using public ASNs. Basically it is a matter of "someone is multihomed with a private ASN so I now have to treat the path the same as I do with public ASNs to prevent routing loops in other networks". It also might break connectivity to the announced routes for everyone else on the planet using that same private ASN. You might also be surprised at how many people accept routes with their own ASN because their network is not fully meshed. They have a colo in Virginia and one in California and they are each announcing a different /24 using the same ASN so they allow announcements carrying their own ASN to be installed so the two colos can talk to each other. But it also helps protect the Jackweasel who did this because they now see THEIR own private ASN in route announcements from Clueless (and who knows how many other peers they might have set up that way) that they sent to Victim. 

Sniffing: The details for capturing frames vary based on the system, with different affects on that system. If you're working on an embedded system, you can offload a frame buffer, transform it into PCAP and load it into Wireshark for analysis. If you're working on a server or laptop, Wireshark can interface directly with NICs to capture frames. In most cases this is fine, but under heavy network traffic load frames can be lost. In those cases an logic analyzer or other separate hardware can capture all of the frames in internal buffers for offload later. If you're working on a server, laptop, etc. you can be pretty sure that copies are made for all frames that Wireshark sees. Generally that's fine, but can impact performance for applications that require high bandwidth. Here is a good overview of the subject: Practical Packet Analysis, 2nd ed, Chris Sanders, 2011 If you want to dig deeper, then you need to dig into the OS, into drivers or into the software or firmware of an embedded system. In that case, you'll have to be looking for something specific. 

You were closer than you think to getting it working. In fact the problem may have simply been that flow control wasn't enabled on the switch. The ethtool source code (rev 3.18) and a register interface for a part I'm familiar with, reveal an explanation for the behavior you observed. The 802.3x standard defines flow-control, but I haven't looked there in a while. Flow Control (MAC Pause) is enabled during Auto-Negotiation with 2 bits in one of the exchanged pages. It has effect only if duplex is enabled. It's also handled at the MAC layer and can be handled in hardware. So, it's possible your driver doesn't get involved at all except for setting the register bits used for Auto-Negotiation. I haven't seen a driver that actively handles MAC layer Pause frames, but then I've only worked with a few. You started with: ethtool -A eth0 tx on rx on Then, you need to make sure auto-negotiation is enabled and restart it. ethtool -A eth0 autoneg on ethtool -r eth0 

The short answer is that the Data Field (2112 bytes) overlays the combination of the Optional Header (64 bytes) and Payload (2048 bytes). They are not separate fields. The use of the Optional Header and meaning of the bytes within it are dependent on the FC-4 layer protocol (usually FCP or SCSI) and the revision of the specs used. It's not clear what your interest is, but if you're concerned about max frame length, take into account the other fields. For end-point internal buffering, add the Frame Header (24 bytes) for a total of 2136. In the context of a fabric, you'll also need to account for SOF(4 bytes), CRC (4 bytes) and EOF (4 bytes) for a total of 2148 bytes. For more detail, try this slightly dated but good reference: Fibre Channel: A Comprehensive Introduction, Robert Kembel 

That's a pretty broad question and there's not enough space here to completely answer it. So, let's look at this from a high level with some direction on how to do your own investigating from there. Ethernet Frame Analysis: Wireshark works by decoding a buffer of Ethernet Frames and showing them in its display. Basically the format seen is what is delivered above the MAC layer, or Ethernet frames. That's handy because the underlying hardware does not matter: copper, fiber, wireless. Wireshark can read frames in or write them out to storage as files in PCAP format. If you capture some packets using Wireshark and store them in a file, you can go back to it later and pick it apart. 

All data bits flow at exactly the same speed down the wire (the speed of light in the medium of travel). So a bit of data travelling 1000 miles down a 10 meg circuit arrives at the other end at exactly the same time as a bit travelling down a 100Gig connection. The difference is the RATE at which the signal can transition state between 1 and 0. The faster you can transition the state of the signal, the faster you can send the next bit. So -- basically there is no such thing as "speed" because it all operates at the same speed (the speed of light), what differs is the RATE of data bits you can send. That is the "bandwidth". The faster I am able to flip the state of the signal from 1 to 0 and back again, the more data I can send in a given amount of time. Imagine two signalmen using old time semaphore flags. One signals quickly, one signals slowly. The actual light reaching your eye is arriving at the same speed in both cases but one can send a lot more data in a given time than the other. That signalman has more bandwidth and can send more data in a given period of time. The data doesn't travel faster, but that one can pack more data into a given slice of time. 

As long as you are fully meshed and the you can backhaul your own traffic arriving at one site but destined to the other, sure, it will work. So if your peering session drops with either ISP, your more specific will be withdrawn (you HOPE!) and the traffic will flow to the aggregate route on the other ISP and you can then backhaul the traffic to the other site. The most frustrating problem I see is network providers that advertise unreachable routes. Either through some screwup internally or whatever, they announce a route to their peers that they can not actually reach inside their network. There isn't much of a workaround for those cases. As for the F5 handing reply traffic back via the interface on which it was received, most load balancers can do that. I don't specifically know if the F5 will but I know Citrix Netscaler will and A10 will so it seems to be a rather standard feature. 

The default gateway of each PC needs to be the same as the subnet router port IP in its network. So the subnet router port in the first network would have the address 10.0.0.1 and the PC would have 10.0.0.2 and the default gateway would point to 10.0.0.1. This tells the PC "when I have a packet that must go to a destination that is not on my own network, send it to 10.0.0.1, and that device will know what to do with it". The "default gateway" is really just a route to 0.0.0.0/0 which means "the rest of the IP address space that I don't have a more specific route for". In fact, you can eliminate the routes on the subnet routers, too, and just give them a default gateway to the central router. So instead of having a route to 20/8 and 30/8 on the subnet routers, you could just put a route to 0.0.0.0/0 pointing to 192.168.1.2 on the first router, 192.168.2.2 on the second one, and 192.168.3.2 on the third. The only router that needs to know explicitly how to reach any of the 10.x.x.x routes is the central router at the top of your diagram. All of the rest can just have default routes.