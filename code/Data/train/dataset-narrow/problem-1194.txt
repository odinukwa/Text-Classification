These four lines also look buggy because is an array and yet it's being compared to an element with and . 

And then a simple loop over numbers from to can test whether the sum exists and if not can add it to a running total. 

I find a confusing name to use here. I also note that this gives a if : if you want to require that callers check this before calling, then you should document it. similarly. 

You may notice that this eliminates . It's not necessary to store it, provided that you refactor the listener to handle the event which is passed to it. And, in fact, you can also refactor it to be an anonymous function. 

Finally, a note on magic numbers. If I asked you to modify this to solve 16 x 16 Sudokus, how much would you need to change? How about 12 x 12 Sudokus, with the blocks being 3 x 4? 

Two things here: firstly, since the sorted values are only needed in one branch of the it makes more sense to push the sort into that branch. Secondly, 

is wrong. The worst case scenario is that one thread is in the method, about to acquire the lock, and while it's in that state every single object gets freed. That's a deadlock: given the example use case, the loop is blocked unless there's another thread which can make a parallel call to followed by . Moreover, expanding the scope of the lock in and isn't sufficient: the scope of the lock in is also too narrow. 

Looking past the syntactic sugar, that's six public methods (three getters and three setters). How many of them should really be public? I think that at minimum the setters should all be private, and I see no good reason to expose at all or to allow an external class to get and then mutate it. I would prefer to publicly expose just the equivalent (see below...) of 

Yakym's proposed code change was buggy (although it's now fixed), but the point about avoiding creating new lists is a good one. An alternative way of fixing Yakym's code which takes into account the goal of avoiding list creation and is further adapted to correspond to my point about using indices as arguments to is 

then good IDEs would be able to offer you better auto-completion. This applies to most of the method definitions, and I've just taken that one as an example because it was the first. 

If the polyline is made up of great circle arcs (i.e. "straight" lines) then this isn't true (unless , because the equator is the only line of constant latitude which is a great circle). An extreme example to make the point: consider a great circle arc from 10N 90W to 10N 90E. Both endpoints are near the equator, but the line between them passes through the North Pole. I'm surprised that QGis doesn't have libraries which take care of this for you, but if you really have to do it yourself then it's easier to work with the embedding into 3D Euclidean geometry. To first order we model the Earth as a sphere, so a great circle is the intersection of a sphere with a plane through the centre, and a line of constant latitude is the intersection of a sphere with a normal through a pole. The intersection of two planes is a line (although note the special case that the planes don't intersect), and the intersection of a line with a sphere is 0, 1, or 2 points, (although obvious they might not be in the right range for the great circle arc). Ignoring issues of numerical analysis, if the endpoints are \$p_1 = (\theta_1, \phi_1) = (x_1, y_1, z_1)\$ (respectively in spherical and Euclidean coordinates), and \$p_2\$ similarly, the plane of their great circle is the locus \$q \cdot (p_1 \times p_2) = 0\$. The plane through latitude \$\lambda\$ is \$q \cdot (0, 0, 1) = \sin \lambda \$. If we take the route of saying that \$q = (\lambda, \mu) = (\cos \mu \cos \lambda, \sin \mu \cos\lambda, \sin\lambda)\$ and let \$p_1 \times p_2 = (x_N, y_N, z_N)\$ then we have \$x_N \cos \mu + y_N \sin \mu = - z_N \tan\lambda\$, which can be solved for \$\mu\$. Then to check whether the resulting values (plural!) are in the great circle arc we calculate the midpoint \$m = \frac{p_1 + p_2}{2}\$ (we don't even need to normalise) and verify that \$q \cdot m \ge p_1 \cdot m\$. 

(and similarly for the four-element case). It's fairly standard knowledge that polynomials evaluation can be optimised for speed using Horner's method. I'll also pull out that multiplication by : 

There are a couple of inconsistencies which you could tidy up. You're toggling classes to show/hide the div but using show/hide directly on the triggers. You're using chaining in one onClick but not in the other. And you're using the class to reference the accordion contents in one case, but the element name in the other. 

You said to ignore the init, but it really looks to me as though the meaning of this class is unclear. Should it be split into a class and a class? 

However, that's not the final word. Na√Øve string search is asymptotically inferior to techniques such as Knuth-Morris-Pratt string search. You probably shouldn't roll your own KMP routine, but you could use to get the benefit. So a better implementation would be a loop around . 

What's wrong with an empty array? Typically a collection has a no-args constructor which initialises it to empty. 

is inadvertently reimplementing (and probably not as well) a standard primitive. You should use instead. The code 

Further optimisation is possible by just avoiding local duplicates, and in that case you can switch back to using a list for the accumulator: 

I agree with the other existing answer (by R Sahu) that is not a great option here, but I disagree on the best option. In my opinion, since the only use of is to compute powers of ten, it would be best to simply compute an array of powers of ten from to the largest one you'll actually need, which is the length of the input plus or minus one. I would also consider whether would make more readable. 

That recurses down the tree to find a node, and then returns enough information to recurse down the tree again looking for the same node. That's a clear sign that refactoring is necessary. Special cases 

Buggy. removes one instance of the object, but you're making no attempt to ensure it's the right one. If I register two methods on the same object, this could remove the wrong instance of the object, which would then make objects and methods not line up correctly. In fact, it's even worse than that: if I register a method on one object and then remove it on another, or register one method on an object and then remove a different one, I'll end up with and not even being the same size. Also, why would you want to call again unless the method hasn't been registered? If the method has been registered, you've already resolved it; if it hasn't, you don't need to resolve it except to check for typos. The best way to store the resolved methods is probably : that allows you to iterate through the entry set in the method and to efficiently implement . 

If the supplied username is such that is not a no-op, the check for an existing user and the insertion of the user use different usernames. This is an important bug. Quite how important depends on things you haven't shown us, in particular on the database schema. Given the current mix of database access techniques, you should ditch the one which requires you to escape things yourself (dangerous, because it's easy to forget when you change the code) and use prepared statements for everything. 

That depends on the regex engines, which might do more or fewer optimisations themselves, but basically you want to reduce backtracking. The obvious way you can reduce backtracking for a set of literal strings such as the opcodes is to turn them into a tree. E.g. instead of 

Why are these in a global scope? It's a good habit to always create your own scope so that you don't have unwanted clashes between scripts which use the same names. 

This is quite a big first project, so I'm definitely going to leave some points for other people to raise. I've only looked at about half of the code. 

Primes I don't entirely agree with Janos' comment on the initial size of the array, although I do agree that it should expand. The point of the parameter is as a hint for the initial capacity, not as a hard limit beyond which performance may suffer. That said, what's going on with ? 

Perhaps the problem is at a higher level. Extrapolating from the information available, you seem to be making a photo management system with the ability to edit EXIF metadata. The key question I have is: does it make sense for there to be two instances with the same path but different EXIF data? I wonder whether you might not be better off using some kind of lightweight pattern to ensure that at any one time there is at most one instance per path. That aside... 

I'm also unconvinced by the general structure. Why should your program have to take care of mapping file types to executors? That's functionality that's built into the operating system. If the registry is correctly configured then the method should just be 

Looks like is left over from a refactor and is now completely unused. Why append to a string? Other methods in the same class use , which is a better way to do it. In this case, with a known fixed length, there's a good argument for too. 

Check the spelling. What's the second skip condition about? I don't see that in the algorithm description, and it seems to reduce the ability to discriminate between multiple candidate ellipses. Why the inconsistent use of for two conditions and then a massive nested block for the third? It would seem more consistent to write 

Firstly, I'm surprised to see . Does that mean that two audits can have the same version? If so, that looks like another source of bugs. Secondly, is this really the best way to do that test? I'm not saying that I know a better one, but I would sincerely hope that there is one. 

If you're worried about complexity, you might want to consider whether you can flatten your tree into a canonical (wlog) prefix-order string and use an advanced string matching algorithm. 

On the basis of KISS and YAGNI you should start by using C#'s Sort. If profiling shows it to be worth optimising, you can consider more complicated approaches. But I doubt that it's worth maintaining a balanced tree. If you need to go beyond a simple sort, it probably makes more sense to pick a buffer size (I imagine that something on the order of 2n/3 makes sense, but I haven't worked through the calculations in detail) and use a binary heap of size : 

Why do you need quarters? The only thing that I can think of is that the constructor takes rather than the more conventional . 

Is there any reason for hard-coding as the type of the key and value rather than making them generic? 

I generally recommend favouring over . For many collections just calls , but for some it is much more efficient, so it's a good habit to always use . 

(As an aside, I don't think that is a great name. English doesn't inflect adjectives, and it's not a standard "nouning". Now that the name is no longer used, I'd refactor renaming it to ). 

? You should remove that kind of comment when you implement the method. It certainly shouldn't still be around by the time you reach code review. 

Readability Layout The is indented as far as the columns to select, and the is off screen unless I scroll horizontally. Styles vary, but if your style guide suggests hiding clauses as important as and then I'd look for a different one. I personally prefer to indent both at the same level as , and to put each from the clause on a separate line indented once. There's also some inconsistent whitespace around commas and parentheses. Comments You seem to have changed comment style at some point, because there's one line 

Wrong question. It's not a matter of re-ordering the iteration: it's a matter of iterating over something much smaller. You're looking for \$s\$ such that \$(s+t) \mid st(s+1)(t+1)\$. But \$s(s+1) = (s+t)(s+1-t) + (t-1)t\$, so that's equivalent to looking for \$s\$ such that \$(s+t) \mid (t-1)t^2(t+1)\$. It's pretty easy to factor \$(t-1)t^2(t+1)\$, since it's already partly factored. To make it really efficient you can use a sieve (which you already need for the primality test anyway). I adapted some code I wrote previously to enumerate factors given a prime factorisation, and was able to run with in about 1.4 seconds. Online demo. The bottleneck (about 55% for ) was the sieve generation, and that would be a serious memory problem for . Since we use it for factorisation up to , and only for primality testing beyond that, I changed the sieve to only run up to and to case split. This gave a 70% speedup (presumably beating the obvious limit of 55% by improving the cache locality), down to just over 30 seconds for . Online demo. Then there are small speedups available by pushing the range tests on into the generator and not pushing onto the heap values of which are too large. I did think that there would be a speedup by observing that when you increment you can reuse the factorisations of and , but that actually doesn't seem to work. My fastest version takes 20 seconds to go up to : 

I hope someone more qualified than me can give you feedback on the JavaScript style and the use of promises. What stands out to me is the method, for two reasons: 

Having made it explicit what the difference is, we can address the biggest problem: correctness. To correctly sum a list of floating point numbers, you should start with the smallest ones, not the largest ones. But since we now have a simple expression for as a function of , we can invert it to find the first value of for which the term is less than the desired error, using a . 

I know nothing about Processing, but this looked suspicious to me, so I went looking for the maths functions in question. I presume it's e.g. 

IMO this is excessively complicated. Unless you're reusing and in contexts which require or , why not make them return ? And then you can push in the case split for the type to use, exposing a single method and leaving the responsibility in the method where it really belongs. 

Why and not ? Well, ok, personally I'd split out and cases, but the point is that these look like exception conditions rather than "no solution" conditions. Why ? Would it not make more sense to require that the board size be exactly 9 x 9? 

Scope This code reads as though it was written by someone whose preferred language is C (pre-99). Variables should be declared when they're needed, not at the start of the method. The only case in which it's usually necessary to declare a variable without also initialising it is immediately before an or when each branch will initialise it. So, for example, in the variables , , don't need to be outside the loop. (In fact, only one of and needs to exist at all, because they're just aliases; similarly and ). The variable in is never read: your IDE is probably giving you a warning about that. 

This should be about as efficient as your code, but has the great advantage that can be memoised. Converting to frequency representation is quite simple, and in fact you could refactor this to produce output directly in frequency representation. 

But secondly, by only using 6 bits per byte you're throwing away 25% of the entropy which the system just produced for you. On busy servers, cryptographic-grade entropy is a valuable resource and you should only request as much as you need.