I would run your original query at midnight to get them all If you must try to rank all, maybe you can try something like this: 

Running this query now will give you all of 2015. Running this query next year will give you all of 2016. NOTES gives you the first day of last year gives you the last day of last year The reason I use 

You will see the IDs reordered and the AUTO_INCREMENT of the table at Then, you can get rid of the old table 

Don't worry about putting 106G inside ibdata1. MySQL was running with innodb_file_per_table=0 before MySQL 5.5. It can still handle it. Give it a Try !!! 

This problem looks weird. It reminds me of a post I wrote 7 years ago : Problem with MySQL subquery Sometimes, values in subquery results may disappear intermittently while processing. This problem was usually associated with non-SELECT queries involving subqueries. This looks like something even worse. You should file a bug report on this one. 

You may want to consider setting the database's default character for new tables going forward using ALTER DATABASE. Here is an example using MySQL 5.5.12 for Windows: 

Doing could make the temp table in and not in place like Please remember that tmpdir is mapped somewhere. That's where space may give out. 

If you have triggers and can live without it for the duration of the load, drop the trigger, do the , and recreate the trigger. CAVEAT: Make sure you are using the latest version of MySQL 5.6 (at least 5.6.23) to avoid foreign key issues with . Please note that I did not mention using third party tools. This is just straight up MySQL. GIVE IT A TRY !!! 

This will erase all relay logs in the Slave, starting with a fresh one. It should start retrieving binlog events from the Master. If it fails again, then on the Master may be corrupt. In that event, you would have to set up replication from scratch by doing this: 

The command TRUNCATE TABLE is DDL. That would entail doing a full table lock regardless of storage engine. If other DB Connections are waiting to access the table, you can be sure there are MUTEXs. For the sake of example, let's say the table you are truncating is . You can get around the MUTEX problem (as manifested by ) Instead of doing this: 

Stop replication on the 2 slave servers with STOP SLAVE. Run on all three servers Run on the Master Run on the Slave Stop MySQL on all 3 servers with . Make the changes in the file on the master server. Start MySQL on the master again to get the live database back online ASAP with . Make the changes in the my.cnf file in both the slave servers. Start MySQL again on both slave servers with . 

When you have this unique phenomenon, mysqld has encountered an undocumented error (Don't laugh, I have seen this). SCENARIO #2 Something else to keep in mind (not necessarily for monitoring) Give this scenario 

You have to make sure your connector software's character set/collation settings match the database it is connecting to. If the REPLACE ran on the DB Server, the REPLACE is a case-sensitive match. I could easily see a collation shift in the eyes of IIS or Moodle messing up a server-side string replace. You may want to substitute this with doing a client side replace using PHP's str_replace 

My Perspective InnoDB can handle 1024 current transactions but there are only 128 rollback segments. If there are other transactions going on, you got a New York City traffic jam on your hands. With all the InnoDB Internals to manage through your bulk insert, seeing NULL in the processlist should not be a surprise. You should look at four(4) things to make sure they are up-to-date: 

When crosschecking for mutual friendship, it could incur a little expense because the userid may be retrieved from the table when traversing the index. Perhaps you could index as follows: 

Give it a Try !!! CAVEAT : Please note that the results come from your actual data in SQLFiddle. I simply loaded the data into a test database and ran my code against it. 

OK, Big Deal. The PROCESS Privilege lets you see the Process List. How does that help? You can quickly detect a mysqldump in progress when you run and see a pattern like this in the Info field: 

would probably nail this problem right on the head. The stack trace's first response was right : Please read the MySQL Documentation on Using a Stack Trace. UPDATE 2015-07-06 10:47 EST Earlier you commented on the definition of the table 

You can also run the script on demand to repair any slave. You can also run this script against a live master since all user tables are InnoDB and you perform the mysqldump as a single transaction. Thus, a slave is loaded with a point-in-time snapshot. 

My initial guess would be that when the mysqldump file was being created, the option single-transaction was not used. According to MySQL Documentation on single-transaction 

This will handle host address that have a colon separating hostname and port number I hope everybody is not logging in as root 

Here is the crontab I ran every 20 minutes (less 10 seconds) keeping the last 144 copies (which is 48 hours of profiling) 

Here is something enlightening about the whay MySQL does error handling. The book MySQL Stored Procedure Programming has a whole chapter on this subject. On your particular problem, you need what's on pages 132,133 under the subheading Handler Conditions. It states on page 132 that there are three ways to define an error: 

This worked for me when ta_table was MyISAM. It just kept running using InnoDB. This may be the sticking point. 

This should work even faster because the first three(3) lines will empty out the table immediately. Then, whatever rows have lastactivity >= 1342709401 from the old table is brought over. The old table is then dropped. 

If you get any of 16, you have to enable for the old style authentication to work. PASSWORDS FROM CLIENT In some cases, using mysql libraries that came from old yum installs of MySQL, PHP, Perl or Apache may have pre-MySQL4.1 user authentication code. Please upgrade such libraries. 

You should provide the EXPLAIN plan for a query. Since the data is identical, it may not be necessary. There are a couple of things that may be different YOUR PROCESSOR I looked up the Intel Core 2 Quad Q9400 @ 2.66GHz (TEST) and the the Intel Xeon E5530 @ 2.40GHz (PROD) and found a difference. 

Within the query itself, trying separating the COUNT(*) from the retrieval by rewriting the query like this: 

My previous employer had MySQL Administrators and Data Administrators (DA). While a MySQL Administrator was just another term for an operational DBA whose specialty was MySQL and performed the grunt work of making sure MySQL was up and running and just cared about data throughput, the DA was responsible for checking the cohesiveness and integrity of datasets from a logical standpoint. For all intents and purposes, the terms Data Administrator and Data Analyst could be used interchanegably as the DA. Historically, a Data Analyst may have specific duties in terms of laying out ER Diagrams, Data Flow Charts, and things like these. The term Data Administrator may be somewhat newer and thus less defined. The role of the DA differentiates itself from DBAs, who may be playing the role of both operational DBA and DA. 

It all depends on how the Stored Procedure was created In the table (physical home of Stored Procedures), there is am ENUM column called defined as . If a Stored Procedure was defined as and the calling user has the EXECUTE privilege, then all grants are proxied and the calling user can run everything in the Stored Procedure. Nevertheless, you will be able to run it. If a Stored Procedure was defined as , then the calling user needs to have all necessary grants before the calling user can run everything in the Stored Procedure. If you are in database A running as myuser@'%', then needs to have the EXECUTE privilege to even call Stored Procedures. In your case, if you are in database A running as myuser@'%', then myuser@'%' needs the database-level grants to database B defined. SUGGESTION: Move the Stored Procedure to database B, give the user the EXECUTE privilege and run running . 

Seems like a lot of work, eh ??? Try the pt-online-schema-change first. UPDATE 2012-08-22 11:56 EDT I am not sure what would happen, but please hear me out on this suggestion: Try executing a repair on an empty file. How do you do that? Take my idea from my first suggestion and augment to swap the new and old . 

STEP 02 Run . If the file exists, rename it with Then, copy your into STEP 03 See if you have a previous mysql setup 

This solution can be done with mysqldump but with a bit of a risk For the sake of this example, suppose you have the following: 

I also recommend reading the file when you download and install it. Perhaps the file will give you some guidance on getting proper documentation. 

This is how MySQL 4.x did this and it used to severely aggrevate me. In fact, there was a formula I computed on how many such index maneuvers were needed 

For the table with UniqueKey and timeStamp, to see if the exists within the last 5 minutes, simply run this 

You could play some games with , the physical home of all Stored Procedures and Stored Functions. First, here are the databases on my PC 

Here is a fourth alternative requiring some project management decisions: Instead of storing you should store . The stands for seconds since Jan 1, 1970. Then, your formula would be simpler 

This why you should experiment with join_buffer_size. HOW TO EXPERIMENT TO join_buffer_size You can change the join_buffer_size one MB at a time. Then, run the and time it. STEP 01 : Set an initial size of 0 and initial runtime of 48 hours (172800 seconds) 

Notice that my PC has 19.019 MB of data and 7.134 MB. mysqldump will only dump the 19.019 MB of data. The indexes are not exported. If phpmyadmin uses mysqldump, then I only have one possible explanation. mysqldump uses the option --opt by default. Here is is what --opt does 

it shows that doing would greatly improve retrieval for MyISAM tables by physically ordering rows. In contrast, doing would have no effect on InnoDB tables because data is always ordered by RowID within the clustered key. MORAL OF THE STORY When it comes to InnoDB, do not worry about randomness of data. No matter what machinations you perform on tables indexes, the clustered key has the final say on access. Whatever order you load the data, gen_clust_index will abide by it. No questions asked. 

Whatever number comes back for is the size you use. Please look up my posts about how to create Dedicated MyISAM Key Caches. I would not worry too much about this since the INSERTs and UPDATEs seems so rare. 

This will perform a full index scan rather than a full table scan because all three columns are in the index. That's a lot less baggage to walk around with for temp table generation because you are scanning just 3 columns in a smaller resource (the index) as opposed to 6 columns as from a bigger resource (the table) as well as not sticking url and bodytext (which are probably VARCHAR(300) and TEXT fields) into the mix just for the sake of gathering keys. Next, make the SELECT sid query into an inline table and connect them back to the news table using only the fetched keys. EXAMPLE : Suppose your LIMIT variables are 200,10. This means you want to move to the 201st row of the news table and get 10 keys from that point. This means that no matter which page you are on, you want to collect 10 keys at a time, and only 10 keys at a time. Here is the new and improved query: 

This will cause everything that has been uncommitted to be committed on shutdown. Then, it flushes the binlogs to disk. On the Slaves, run this 

This may sound twisted but here it goes.... DON'T USE If you login as root and you do the following: 

then any database with any name can have a proper authentication setup. You can still run these two lines anytime. UPDATE 2012-02-24 15:20 EDT To openly demonstrate the danger of having anonymous users in , I would like to create a user that has only the usage privilege. I will be using MySQL 5.5.12 on my Desktop First, look at the mysql.db