I don't know for certain, but I suspect the answer is "you can't" for the reasons given in their reply to a user requesting OpenGL support. Just in case that URL changes/disappears, I'll quote the relevant bits below; 

This is definitely outside my realm of knowledge and would probably be better asked on the Raspberry Pi camera forum where the firmware devs might pick it up. Still, I'll try and answer as best I can given what I've read in the past: 

The H.264 encoder on the Pi outputs an H.264 NAL stream which lacks all sorts of information including (rather importantly) the framerate, without which one cannot calculate the video length. This is why you can, for example, record a video with raspivid at 1fps but if you play it back in VLC it'll play back at 24fps because that's what VLC defaults to in the absence of such information. This is why it's generally necessary to use some tool to wrap the output up in something more useful like an MP4 container (which will contain things like framerate). The easiest method for doing this at the moment (on a Pi) is to use MP4Box: 

If depth perception is required, that means running the two cameras simultaneously. That's not possible with the multiplexer which only permits recording from a single camera at a given moment. Stereoscopic capture simply isn't possible with a regular Pi. It is possible with the compute module which has two CSI connectors (and as much computing power as a Pi 3 since the launch of the CM3 (linked). Stereo capture/recording is supported in the firmware on this particular platform, however unless you use the IO development kit, the general assumption with the compute module is that you'll build your own interface board for it. 

It's pretty obvious from the above that the JPEG compression and decompression is redundant. We could get rid of that step by capturing with the unencoded format straight off: 

If you're trying to shoot absolutely consistent pictures the one thing you can't do is re-initialize the camera between each shot. The reason is that the camera firmware provides no means of setting the camera's gains; all it provides is the ability to fix them at their current values (or let them float according to the results of the AGC process). So, I'd recommend doing as the recipe suggests and set up the camera, then capture several images without re-initializing it. The recipe demonstrates one method of doing that with the method, but you could simply use instead, and even do that within your function. For example: 

Let's start by looking at the camera modules themselves. The v1 camera module is capable of 2x2 and 4x4 binning (see the camera modes table); I've heard there's an 8x8 binning mode as well but the firmware devs weren't able to get it working. This is why the v1 module can achieve full field of view (FoV) in most modes. The v2 camera module by comparison, unfortunately, is only capable of 2x2 binning which explains why many of its modes have a partial FoV (I think the v2 module can also do line skipping, but I don't think that's used by the Pi's camera firmware). However, this isn't the whole story. This is only the beginning of the image processing pipeline. In other words, this is just what the sensor itself passes to the ISP block in the GPU which handles the rest of the processing, including any resizing. Whilst the camera has several discrete modes (listed in that table), it can effectively work in any resolution up to the listed maximum. If you read a bit further on from those tables in the documentation, you'll find a description of the heuristic used to select the sensor mode according to the requested resolution and frame-rate. Provided you either wind up in, or force the use of, a full-frame sensor mode you'll be capturing from all pixels on the sensor anyway. As for concerns about CPU usage: don't worry. The CPU isn't used for any part of the camera's imaging pipeline, it's almost entirely GPU based (except for that first binning step which is done by the sensor ISP). The only time the CPU gets involved is when it receives the final output and has to do something with it. If you're looking for minimal CPU usage, this is a major plus of the camera module compared to USB webcams which, because the USB bus is polled by the CPU, use significant CPU time (USB3 uses interrupts instead of polling but we're talking about Pis here which only have USB2, and besides: most USB webcams don't use USB3 at the time of writing). Onto your specific requirements. You want: 

You should see MediaTomb appear as a source pretty quickly on any DLNA clients on your network (Internet radios, PS3s, XBMC installations, BubbleUPNP on Android, etc. etc.) but it might take a few minutes for media to appear under the source. MediaTomb has to index stuff before it makes it available for streaming, hence the delay. 

User runs in the interpreter The interpreter imports picamera picamera imports mimetypes mimetypes imports urllib urllib attempts to import socket At this point the interpreter finds in the current directory and imports it instead of the "official" in the Python distribution Something in attempts to execute to create a new socket, but the that got imported doesn't have a callable named "socket" and the script crashes 

Firstly determine whether the issue is software (your code) or hardware (the camera module itself). After a clean boot, use the demo / commands to test the camera module. If doesn't fire up the camera almost immediately, something's wrong with the hardware end of things (I'll assume below the issue is hardware). There's two common(ish) hardware issues: 

I'd suggest giving the new gpiozero library a try. It's intended to simplify GPIO programming and sits atop the RPi.GPIO library you're currently using. Rather than concentrating on pins, it's focus is on representing the devices attached to pins which tends to make reasoning about the program a bit easier. Here's several different ways of connecting the operation of your relay with your button using gpiozero. First a straight-forward declarative method: 

That suggests to me that it's very likely it's doing lens-shading correction for you. It's notable that library is tuned for the v2 Raspberry Pi camera module, which is exactly what you're using (otherwise I'd expect any lens shading to be slightly wrong - would be interesting to see its output with a v1 module!). 

The morale of the story is "don't named your files after top level modules in the standard library (at least when you want to use those same modules). Admittedly this may be tricky, given the extensive nature of Python's standard library! 

The usual way to use the camera from C/C++ is to use libmmal (this is the library used by and ). The source is part of the userland repository, specifically look under in there and you'll find all the headers. For examples of MMAL use, have a look at the and source code, which you can find under in the same repository. Whether this will compile under Visual Studio I don't know (from goobering's link it looks like it's using GCC, so there's a chance). 

By far the most efficient way of doing this is using a splitter on the camera's preview port, then connecting that to a couple of renderers. Sadly, the picamera library doesn't support this "out of the box" (it connects a splitter on the video port to support recording at multiple resolutions, or capturing while recording, but it doesn't support multiple previews because that's a fairly niche requirement; see camera hardware for more info on the camera's ports). However, it's quite easy to arrange by using the layer which picamera is built upon (that link goes to the latest version of the docs which includes a long introduction to , but also has a few currently unreleased features - luckily we don't need the unreleased bits for this). Basically we're going to build an MMAL pipeline that looks like this: 

This is fairly easy to accomplish with the picamera API, specifically the record_sequence method. I won't tackle the cloud upload bit as that'll bloat this example horribly, but it's pretty easy to add Google Drive integration (they've got plenty of docs on using Python to interface to Google Drive), and I'll point out where you'd want to add this. Firstly, some assumptions given this is for a security camera: 

There's a few bits I need to add to the documentation for picamera 1.9 - the first is that while the camera can output frames at full resolution (2592x1944) at 15fps, it can't do so with the H.264 encoder which tops out somewhere around 1920x1080. It might be possible in MJPEG but there's other issues which currently prevent that (although it's looking likely there'll be a workaround in picamera 1.9 for that). If the video quality doesn't have to be that good, then I'd recommend using a mode like 1280x720 (720p in HD terms). Despite being a lower resolution, this will actually wind up using the full width of the sensor; specifically at 30fps it'll use the 1296x730 mode which uses 2592x1460 pixels of the sensor with 2x2 binning to produce the image (this is something else I ought to add to the documentation!) 

Nothing wrong at all with goldilocks answer above, but here's an additional one that deals specifically with the picamera API. You can use a custom output to perform such a split (as many ways as you like) and send the output to a variety of destinations. In your case, if you wanted to record to a file and a socket you could do something like this: