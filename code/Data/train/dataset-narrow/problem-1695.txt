I have been using EveryDNS.NET for several years with positive results. While a free service they do accept donations to help keep everything running along. 

Not terribly familiar with the SSL Headers concept although the article looks interesting... You should be able to add a second IP address to the existing cluster (don't need an additional cluster). Then you can configure IIS with the additional IP address and assign a new certificate to the new IP address. 

Why would I want to use RAR instead of GZIP? Well one thing GZIP doesn't have is the ability to automatically include a date stamp on the file name. So with this info here is an example of how I will be backing up the MySQL database information: 

This design wouldn't require a change to your server deployment, rather just adding a certificate to each site along with a url rewrite rule on your main site. And, don't forget to add the redirect url for remapping from http to https: 

I would try and trace back (tracert) one of the IP addresses to the provider, look up an abuse contact email/number for the provider, and report the IP address. If the user is on a public network you're pretty much at a dead end, but if it's a company or residence then you might be able to request an inquiry into the IP Address ownership. 

While I am a little confused about this statement: Or is there a ... way ... to filter out ... RTMP to 80, but still allow RTMPT to 80 (where all four hostnames are identical)? I would think that you could also try and create an IPSec filter to block certain traffic to/from specific hosts and allow certain traffic to/from specific hosts... 

Don't forget about your network interface needs. You might want to have at least two interfaces (our four for load balance/redundancy) so that you can have the Host communicating through a different interface than the VM's. You could also consider dedicated interfaces for certain VM's to avoid network bottlenecks for things like SQL and Exchange... 

Good idea to have a better understanding of the different types of Hyper-V networking. John Howard has an excellent article that spells out most everything you need to know about the various networking options. Also, I posted an article that talks about enabling routing without having to build a VM Router... Lastly, remember that Windows 2008 has an embedded firewall that is pretty restrictive by default. You may need to modify the firewall rules to allow your VM's to talk to the Hyper-V Host. 

The App_Data Folder To improve the security of the data used by your ASP.NET application, a new subfolder named App_Data has been added for ASP.NET applications. Files stored in the App_Data folder are not returned in response to direct HTTP requests, which makes the App_Data folder the recommended location for data stored with your application, including .mdf (SQL Server Express Edition), .mdb (Microsoft Access), or XML files. Note that when using the App_Data folder to store your application data, the identity of your application has read and write permissions to the App_Data folder. What's new in ASP.NET Data Access 

How about Microsoft's URLScan? You could include the restricted files in the [DenyUrlSequences] section of the UrlScan configuration file... If you upgrade to IIS 7.0 on Windows 2008 you can use the built-in Request Filtering option and specifically restrict/hide the files/folders you don't want accessed. 

While Microsoft does not support or recommend using a NLB solution in front of Active Directory there does indeed appear to be some options for authenticating non-Microsoft AD aware applications. 

I couldn't get the verification to work (anywhere else than in my workstation computer), but in the end I moved on and everything worked just fine, so maybe it wasn't that important. 

I accidentally started backing up much more than was expected so I filled all volumes. I now fixed the issue of what is being backed up and what isn't; but how do I get backing up again? I cannot create more volumes and I'd rather not destroy volumes. What should I do? 

I couldn't found why this was happening but I solved it by using WP Super Cache; which greatly increased the performance of my Wordpress. 

The /dev/xconsole error happens even if I disable TLS and everything seems to be fine. Not sure if I should read anything into it. Maybe there's another log file to inspect that I'm missing? Searching I found this bug report: $URL$ From that, it seams that rsyslog tls is just broken on Ubuntu and that's the end of it. No workaround, no fixes coming, nothing. Am I reading it right? Is there any workaround or any other way to move forward? 

I have around between 3 and 8 upstart jobs in various Ubuntu boxes that I wish to easily start, stop or restart all together. It seems that upstart would make it easy to do that, but I'm not sure how. Should I use dependencies to make a single dummy job that depends on all the others? One of my requirements is that I wish to still be able to stop some without them restarting because others are started. How should I go about doing this? 

and I get logged in without being asked for a password because I already copied my public key. Due to forwarding, I should be able to ssh to pupeno@b1 from b1 and it should work, without asking me for a password, but it doesn't. It asks me for a password. What am I missing? This is the verbose output of the second ssh: 

Are there any guides, howtos, books, etc about installing and maintaining a publicly-accessible Windows Server 2008 (with IIS and SQL server) for programmers (that want to deploy their own apps)? 

If I manually run service mount_public_uploads start, it mounts just fine. Maybe it's trying to mount before glusterfs is ready? 

I've configured some sites on IIS pointing to E:\WebApps and subfolders. In basic settings when I click the Test Settings... button (connection as the application user) I get the error: 

I am really curious. Mac OS X as a server sounds like a very expensive solution that is not much better than the free one provided by free software. I understand paying extra for a nice UI and an Apple logo on your desktop computer or laptop (I did it). But a Apple logo gathering dust in a dark room somewhere with no monitor attached, doesn't make much sense for me. But then either Apple is producing the server at a cost, or some people know something that I don't and choose Apple servers. If that's your case, why are you doing it? Enlighten me. 

Is there a way to require a resource so that it's executed first, but if it's not present, just drop the current resource all together? 

For off-site backups we are running a Bacula SD on another location and the internet connection to it, although quite good for what you can normally get at an office, is not as good as a single ethernet cable. It's slow (100Mb/s) and not very stable. One of the backups seem to take around 16hs or more to finish. The chances of the connection being lost over that long period of time is quite big. So far in a week I never got a single backup to finish and this is the problem: Bacula seems to start from scratch every time. Can anyone confirm this? It also seems not to be re-using the volumes, so I already run out of space having 95% of my volumes used by useless pieces of a backup. Does it mean Bacula cannot work on this conditions or is there something I'm missing about Bacula's configuration? Anything else I should try before giving up Bacula? 

App Pool crashes are usually because the AppPool Identity isn't a member of the IIS_WPG local security group... Additionally, the AppPool identity must have read access to the web content that is being displayed... 

A service account running with the credentials of a domain account that has recently changed the account password will run into a problem only during a restart of that service. Since the server hasn't been updated with the new password your service will not be able to authenticate the service account credentials until you update the service properties with the correct password. That being said, it is recommended that you use the SERVER\NETWORK SERVICE account for services that require domain level access. The NETWORK SERVICE account is actually an alias account linking to the DOMAIN\SERVERNAME directory object in Active Directory. ex. ServerA\NETWORK SERVICE --> DOMAIN\ServerA Imagine your server running the service is ServerA and the resource your service needs access to is ServerB. By configuring the service to use the ServerA\NETWORK SERVICE account will actually be running with the DOMAIN\ServerA account. This has an added benefit of the automated computer password change mechanism that takes place (by default) every 30 days, transparent to you or your service. Also, if you need to grant permissions for your service to communicate to the resource server (ServerB) in the same forest you can simply edit the access permissions on the ServerB to grant access permissions to the DOMAIN\ServerA account (remember it is the actual account for the ServerA\NETWORK SERVICE account) and then all requests to the resource on ServerB will be performed using the credentials of the DOMAIN\ServerA account. All that being said, the Managed Service Accounts in Windows 2008 (thanks for pointing that out Oskar) looks to be an even better way to handle service account needs! 

This might be possible if you configure the IIS 6 server as a proxy server. Managed Fusion has a URL Rewriter that can do transparent proxy that should be able to have the IIS server pull all requests from your LAMP server. In the discussion forum of the URL Rewriter project is an article that talks about doing something similar to your request; this article is about Apache on a localhost but shouldn't be much different for a remote Apache Server). EDIT: Keep in mind that using IIS as a proxy to a LAMP (or any other server) is incredibly wastful... You should work with the ISA Admins to redirect the web publishing to the actual target server. 

Hyper-V synthetic interfaces are bound to the hypervisor, and the Hyper-V product has most everything (if not all) you will find on other platforms. Lastly, I would suspect that all vendors are going to end up offering the base Hypervisor for free and the profit will come from management and add-ons. Enterprise virtualization decisions really need to be made with product comparisons and considerations of the product road-map. 

What version of IIS? For IIS 7 you can use AppCmd.exe. For IIS 6 you will likely have to use WMI/VBScript as I believe the configuration is stored in the IIS Metabase. Please update your post with what version of IIS you are working with. 

Socket Pooling continues from IIS 5.0 to the current Windows versions. Try disabling the socket pooling and see if you can get your web site working. I ran into this problem and wrote a blog post about it titled Separating IP:PORT Bindings on Windows. 

One suggestion (not an immediate fix unfortunately) would be to reconfigure your SSHD to listen on port 443. Then your client software will appear to any proxy and/or firewalls as HTTPS traffic instead of SSH traffic. If you are forced to go through a proxy server than you can use an SSH client like WinSCP that supports connecting through a proxy server... I wrote up an article about this topic that some might find useful... 

and it did create /var/lib/bacula/bacula.sql, but when I run the job it gets deleted. Any ideas what's going on? The whole output looks like this: 

but when cron runs, it somehow tries to connect to the public IPs of the machine, which fails, because they are not bound by postfix: 

How do I set all volumes into Append mode in a Bacula server so it starts backing up from scratch? I have 70 volumes which are file volumes and due to a mistake it backed up too much and run out of space. I want to have everything reset to initial, like if the volumes were just created, so I could run a full backup and take it from there. I'd like to start backing them up in alphabetical order so I know that Volume-02 comes after Volume-01 chronologically. Any ideas how to do that? 

I've checked that my IIS is running as NETWORK SERVICE so I've given read, read and execute and list folders contents access to not only E:\WebApps but also to E:. But I still get the error. This machine is not part of a domain. Any ideas what am I missing? I've tried putting a web.config in E:\WebApps, and restarting IIS and the site in particular, but it made no difference. 

Apache ignores the file names, you have to define the IP addresses in the Virtual Host definitions. For example, for my web site pupeno.com I have: 

That works fine. On the nodes where I include that class, firewalling is enabled. Then I have another class, for enabling OpenSSH: 

In that case I ended up nuking the database and rebuilding it, without changing anything in the configuration and it worked. I'm not sure what happened. Since then I've had the same issue several times and it was solved by restarting directors and storages. 

Any ideas what's going on and/or how to fix it? As an alternative that I'm not too thrill about, I tried having an upstart job mounting those volumes. I added noauto to my fstab glusterfs entries so that they wouldn't be automatically mounted at boot item and created an upstart job with these content: 

Is there any book you'd recommend to learn how to administrate a public-facing (IIS7, SQL Server 2008) Windows Server (2008 in this case)? I've searched for books in this matter and I've found "Windows Server 2008 Undercover", "Windows Server 2008 Unleashed", etc, which from the table of contents seems to be centered around the Windows server in a local network that is working as the PDC, or Active Directory server, or serving files, or some other tasks for local clients. The last of which I don't have any. I haven't used Windows in ages (not even in the client), so even basic things are puzzling for me at the moment. 

I enabled SSL by following this guide: $URL$ except that I have the keys and cert in both gluster and glusterfs files as the guide seemed to use one at the beginning and the other one afterwards: 

How can it be 11G? What's going on? Just rounding up? but then why does it fail to fit on the other machine? 

It was a PHP error. Enabling display of PHP errors showed that and the reason why I didn't saw it when I was running the script manually is because I was running it as root and the error was lack of permission to write temporary data in a directory. 

Rails and Django are development frameworks, to be able to serve requests from a web browser, they need a web server that will execute the code. I'm not sure about Node.js, but I would expect they are similar. Rails and Django are not web servers by themselves, but they use a small web server during development to makes things easier. That's how you can run, for example: