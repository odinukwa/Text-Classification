Also I would check all my matrix multiplication, it should be in reverse order to how would you do it with Assimp matrices. 

If you are using ENet you could make the server send an update packet for example 5 times a second, and use a non-blocking function to process it in your client. A non-blocking function just checks if any packet has received, does not wait for one to arrive in case one hasn't already. In ENet you can use 

As stated by Iva Kuckir You are passing an invalid spot direction. The direction [0,0,0] is no direction, you need to set it to some other value. For example[1,0,0] in which case your spotlight is facing the positive X axis. This is basically because you cant normalize a zero-vector. 

Based on my experience, you should go on with your VBO per class solution. I don't know whats your target platform, but any computer should be able to handle a couple thousand VBOs without problem, especially as you are talking about a 2D game, which is less likely to have many vertices. It depends on the usage and target platform tough. But as a general rule, never optimize something that you haven't profiled to be a bottleneck, avoid premature optimization. 

Any decent OpenGL math library should have a function called . It does exactly what you want with the exception that it produces a matrix and not a quaternion. This problem can be solved by converting the matrix back to a quaternion. In case you aren't already using a math library, I recommend checking glm which basically tries to provide everything that GLSL has, just in C++. 

Your problem and a possible solution is supplied by chipgw. But there is an alternate solution, which is an importer flag, which will pre-transform everything for you. So you can simply add this flag to your importer: . But note that this has a huge negative: It drops all animations.(Although the node tree is kept) 

When using index buffers, you are indexing into all of the buffers at the same time. That means that if you have a point which can have multiple texture coordinates(If there is a seam at that point) or normals(for example if faceted) then you need to duplicate the given points vertex coordinates with all possible combinations. 

The simplest solution to this would be simply buffering the vertices into a VBO like you normally do, then rendering them as instead of or . This will give you a cloud of dots, that you can rotate the usual way with your vertex shader. If you want nicely sized circles, you should use a geometry shader to create a camera-facing impostor/billboard from each vertex and process those using a fragment shader, you could event texture these. While technically you could do the same with the built-in approach, it is not supported properly by drivers in my experience, so you have to resort to your own geometry shader. 

I have an Entity Component system and I want to have a Component that would add the given object to the physics simulation. My problem arises because the Bullet API requires me to add each object before doing the simulation. How should I proceed to create a System(System in entity component terms) that wraps the Bullet Physics API to do simulation while the components are getting added and removed? Edit: This is how my Entity component system looks like. 

I have implemented this(using the RTP) in a simple(but quite tedious) way. I took a list of all neighbors for the current cell, and with a lot of statements I drew the tile as 4 smaller/quarter tiles. For me this method lead to some barely visible errors, but they can be resolved by testing for some edge-cases and correcting accordingly. If you look at the source images and the resulting image in the RPG maker, you should be able to do this(perhaps with some trial-and-error) with statements, identifying what the current case is for the given quarter tile and drawing accordingly. This method can be further improved and made less tedious with bitmasks(as mentioned by jzx). 

A TFLOPS is short for Terra(Billion) Floating Point Operations Per Second It simply means how many floating point operations(Such as adding, multiplication, division) can a processing device do in a second. Threads are simply paths of execution, the more threads a process has, the more processor cores can it use, so in a multi-core environment it is faster. Both of these are general concepts that apply to both processors and GPUs. GPUs usually have much more cores(in the hundreds) so parallelism(use of many threads) is very important to achieve high performance there. There is no direct relationship between the two, but usually the more threads means more processing power, as there is a limit how much transistors and thus flops can we pack into a single core. 

As with every "Will it be fast enough" question, the proper answer is: Profile it. Below is my speculation on your case. I have no experience with CPU emulation, I will base my performance guesses on the performance of Lua, which is said to be the fastest scripting language. 

Make the client request the time remaining from the server that handles giving out the token. Then count down from that using the local clock. Also I believe that you could synchronize your servers much better than that and this wouldn't be a problem as long as your app can handle the disagreeing servers. And also probably you shouldn't let a user push a button to get a token until he can actually get it, so just request that from the server too. 

I believe what you are looking for is called Deferred Rendering. It is a rendering technique that scales extremely well with a lot of lights, so well that it can used for dynamic indirect illumination. That means 1000s of lights on the screen. It is basically a technique in which you first render all your geometry data(position, normal, depth) into an intermediate pixel buffer(called the G-Buffer). Then in a second pass you render a light shape along with its parameters. The shader of this second pass takes the information from the G-Buffer, applies light calculation, then blends it into the final image. You can find implementation details here 

In response to your edit: If you want to keep your original model, and you are willing to sacrifice performance(though that will depend on the implementation), you could do it in 2 passes. The first pass will only enumerate cameras into the system, and the second pass renders all objects from all viewports. 

Here you are reading outside of bounds. The second row should also be 0 - 3. Consider making it a simple function.(assimp mat4 to glm mat4). 

There might be multiple problems with your code. In your fragment shader you mix in a color which is transparent, this causes the end result to be partially transparent too. For this you could do the following: 

Should a game/engine clean up after itself(close windows, shut down renderers, close files, free memory) when its closed? The OS should do that anyway, and usually in a faster way. I guess most developers don't really care as they need proper cleanup for everything anyways(With dynamic asset-loading, and changing maps, etc.), but won't ensure that everything gets cleaned perfectly. But is there any positive to cleaning up vs not cleaning up or the reverse? I am using C++. What about game consoles? Do they all clean up after themselves?