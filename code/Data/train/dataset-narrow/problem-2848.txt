Say now you want to find out how to transform directly a point Qb into a point Qa (notices that the b and a following the letter stand for the frame that vector/point is expressed in - Q is the same physical point, but it is seen from different places with different measurements). You do the same and express Qb in the world frame as Q and then take this Q and express it as Qa: 

It's very probable that Erin Cato subtly justified the use of the Symplectic Euler over RK4 or another higher order integrator. The author has lots of slides and/or material (e.g. $URL$ related to the inner workings of the Box2D engine. The main reasons for why RK4 is not really needed when writing this kind of a Physics Engine are: 

The Commandos series of games and its similar western counterpart, Desperados, use a mix of 2D and 3D elements to achieve a very pleasing and immersive atmosphere. Apart from the concept that alone made the series a best-seller, the graphics eye-candy was also a much appreciated asset of that game. I was very curious on what was the technique used to model and adorn the realistic terrains in those titles? Below are some screenshots that could be relevant as a reference for whomever has a candidate answer: 

I don't think that the claim is categorically true, as one only rarely "moves" the world coordinates in a game, but actually changes the coordinates of the virtual camera. What the concept of camera actually does, is transform the finite viewing frustum -- that is a truncated pyramid with 8 corner points (or defined by intersection of 6 planes) to a unit cube, which represents the clip space in the final stages of openGL rendering pipeline. In that sense the world is not moved, but one only calculates world coordinates in the coordinate system of the clip space. 

Then the matrix that transforms the cube to that shape is the inverse transform of the matrix == M^-1, as the forward matrix represents the transform from a viewing frustum to clip space (==unit cube). (Also we know that the frustum doesn't have to be symmetric, so there is quite a lot of degrees of freedom left...) 

In this way color values between 0 and 0.5 are reserved for normal color values; and 0.5 - 1.0 are reserved for "modulated" values, where 0.5..1.0 maps to any range selected by the user. Only the color resolution is truncated from 256 values per pixel to 128 values. Probably one can use builtin functions like max(color-0.5f,0.0f) to remove the ifs completely (trading them to multiplications by zero or one...). 

Regarding your Mip selection, I am using a custom texture atlas shader. In my case, the following snippet is accurate enough. You do have to provide it your own texture size.. i.e. you need to know the width X height parameters of the texture you want to "mip". In my case, these are just defines.. If you use dds textures, direct x compatible, they should already have mip levels embedded. 

I've seen the comment of Byte56, but the links there don't provide the exact answer, or aren't graphically detailed for this specific task, so if it's an answer the user wants, why not let him have one. Here goes. 

Well, let's try it in 3D: Assume the dynamics equation: r(t) = r0 + v0 * t + 0.5*g* t^2 where r is the position vector, v0 is the initial launch velocity and g is the gravitational constant acceleration vector (0,0,-9.8) . Now let's analyze the length functional: L(t) = Integral(0,t, ||r'(t)|| dt) . This means that the total curve length from its beginning (t=0) till this t time instance is L(t). In this formula, ||r'(t)|| is the norm of the time derivative of the position function r(t). We know that the norm is actually the square root of the dot product of its argument vector: ||r'(t)|| = sqrt(dot(r'(t),r'(t)) hence you can analyze this amount: r'(t) = v0 + g * t and therefore dot(r'(t),r'(t)) = v0ov0 + 2*v0og*t + gog*t^2 where is the dot product operator (some write it as an angular bracket < a , b >, others use a dot which I tried to imitate here with this ). This dot product, in your case, is a quadratic function of with nothing more than scalar coefficients in the name of those dot products. Hence, if you can compute a primitive for this sqrt(dot(r'(t),r'(t))=sqrt(at^2 + bt + c) where a=gog, b=2v0og, c=v0ov0 you're on the right path. Call this primitive F(t), then L(t) = F(t) - F(0). If you want to know what t0 instance corresponds to a length on your path of d0 units, then just compute the inverse of L(t) by, what else, computing the inverse function of F(t). as I am in a hurry, I can't compute the primitive, nor its inverse for you, but if you can't either, do it numerically (numerical integration and then numerical equation solving via Newton's method). Later edit: Use the Wolfram Alpha to find the integral, then perhaps solve numerically for its inverse.. or again Wolfra Alpha 

BTW, if you are only clipping single points, then a more efficient method is to calculate [x,y,z,1] * clip_matrix -> [X,Y,Z,W] and to check that |X|<|W|, |Y|<|W|,|Z|<|W|. I'm justifying using 'makePlane' approach because I cull axis aligned bounding boxes and have something more in the makePlane routine that makes the frustumCulling function to choose a single corner of the boundingbox per clipping plane. 

Let's assume that you have a sprite sheet with defined order of sprites C,B,A The following methods allow you to draw the sprites in any order using z-buffer. 

A cube has 6 faces and CUBE_MAP texture combines 6 individual sheets in a single texture. The texture coordinates are 3D and the face is selected by the dominant coordinate: if |x| > |y| && |x| > |z| then either 'left' or 'right' face is used. if |y| is the dominant coordinate, then top or bottom sheet is selected. 

The simple example is for rotating in xy-plane (up = z). In order to circle around the object (at origin) at distance R, you use To rotate camera instead, the equations are ; Position = x,y,0;` It's basically vector math, where the vector origin and target change place. 

If your two quaternions are and , they represent the same rotation if either of these two conditions hold: 

The problem: A player entity wishes to throw a ball from a known position with a known initial velocity. The surrounding environment contains physical objects that can alter the trajectory of the ball. How can this trajectory be as accurately as possible be rendered? One solution: perform small steps and simulate throwing the ball. During each small step, a raycast is performed against the world to find potential colliding bodies. In case a collision is reported, it must be handled accordingly. The intermediate positions of the ball will then be saved in an array and the trajectory should be described by the succession of these points. While this solution works (it is tested and doesn't fail almost never :) ), are there any workarounds or possible optimizations that can be done to avoid performing the raycast queries too often? It would be nice if there were such a thing as a parabolic caster instead of a linear ray caster. Do you know of any existing solution that is better of the one I just described (that either avoids those many raycasts or performs a more clever kind of query to reduce the number of intermediate steps and replace the actual line segments with parabola segments)?