The Code To provide useful feedback I assume you'll need the Code. In the following you'll find the Fragment Shader code. The variable GradientsTexture contains $G$ and 

THE LONG VERSION Basically my problem deals with texture access in OpenGL's Fragment Shader. First I'll describe the background of the problem and what I want to accomplish. Afterwards I'll explain the point at which my problem arises. And finally I'll present a few lines of code followed by my actual question. If you're not interested in the details you can skip directly to the problem. But maybe the detailed explanation is useful for others. 

Figure 2: The Offset-Texture which transforms the coordinates from a point of each instance in the Gradient-Texture to the coordinates of the raw depth image in the Gradient-Texture. When I do the computation stated in equation (2) I obtain the Base-Coordinates $x_D$, as I called them. They are shown in the image below. 

causes unexpected results as shown in figure 4. Thanks in advance and sorry for the long explanation. Cheers, Christian Bloch. 

THE SHORT VERSION In my fragment shader I'm reading (using texelFetch) multiple times the same texel from a texture (created by another fragment shader) and write it to the output render buffer. After a few read operations on the texel a fault occurs. The texture and my rendered image have a size of (n*256) x (m*192) pixel/texel. In the first instance (texel [0,...,255]x[0,...,191]) the texture contains a human. Here is the minimal code of the fragment shader which should copy the human: 

The Question And finally my question: Does anyone knows where these artefacts come from? As you saw in the figures above, the steps before give corret results. Only the access to the Gradient-Texture with 

Figure 3: The Base-Position $x_D$ of the raw depth image for each instance. And now when I access the values of the Gradient-Texture with the computed Base-Coordinates $$D_c = G(x_D,y_D)$$ I get a fault. The result is shown in Figure 4 below. I would expect each instance to show it's assigned raw depth $D_c$. But as you see there are black artefacts. Afterwards I would have to compute the gradient image $\nabla D_c$ but I stopped here since there is obviously a fault. 

Here's my understanding so far: No suffix -- e.g. . This function is a part of the core profile. The wiki page tells me that this was added to the core profile starting from version 1.5. ARB -- e.g. . This function is part of the standardized extension. The spec of this extension clearly declares in the "New Procedures and Functions" section. The "Dependencies" section tells me that I can potentially access this from a 1.4+ context, if the hardware supports the extension. EXT -- These are vendor-specific extensions and functions that only some vendors may support. Vertex buffer object doesn't seem to have an EXT extension in the registry. 

I thought I had formed a general understanding of how OpenGL naming conventions and extensions worked, until I stumbled upon a case that confused me. 

Here's where my understanding breaks down: , as the wiki shows, was added to the core in 3.0. Now I want to access the frame buffer features at a lower core profile version than 3.0. So I want to use it as an extension. The spec registry tells me that there are two available extensions - ARB and EXT. Question 1 -- If an ARB extension exists, why does an EXT extension exist? Wouldn't you always choose the standardized one over the vendor-specific one? A look at the ARB spec in the "New procedures and functions" section tells me that the extension defines the function. No ARB suffix this time. GLEW doesn't have a function prototype for at all. Weird. The EXT spec does however have a function in the new functions section, and GLEW also has. Question 2 -- Why no ARB suffix if there's an EXT suffix? How does this work for ARB, given that the names of the ARB function and the core function are the same? Question 3 -- I ultimately want Framebuffer features from a 1.4 profile. Which extension and which function-set should I use so that I get maximum hardware compatibility coverage? 

The Problem To compute the sum in equation (1) i need to add the gradient to each $\frac{\partial D_c}{\partial q_k}$. Therefore I need to access $D_c$ in each instance, compute the derivative and add it to the instance $\frac{\partial D_c}{\partial q_k}$. This is done in a Fragment Shader which has as input the figure 1 (as GL_TEXTURE_RECTANGLE). Since each instance $i$ does not know where to find the raw depth image ($D_c$) in the texture, an additional input with the x- and y-offset from the current pixel/texel position to the according pixel/texel position of the raw depth image is provided: Let's call it $O_x$ and $O_y$. So to get the coordinates of the raw depth image $D_c$ in the Gradient-Texture $G$, we do: $$ x_D = x + O_x(x,y)\;\, \;\;\;\;\;\;\;\; \\ y_D = y + O_y(x,y)\;, \;\;\; (2)$$ where $x$, $y$ are the current pixel coordinates (gl_fragCoord) in the Fragment Shader and $x_D$ is the x-coordinate of the raw depth image $D_c$ assigned to the Gradient-Texture at $(x,y)$. The Offset-Texture $O_x$ is shown in the image below. 

Figure 4: Raw depth $D_c$ extracted from the Gradient-Texture $G$ using the computed Base-Coordinates 

The Background Basically I want to compute the partial derivatives of a rendered depth image according to equation (15) in this paper Wei, Xiaolin, Peizhao Zhang, and Jinxiang Chai. "Accurate realtime full-body motion capture using a single depth camera." ACM Transactions on Graphics (TOG) 31.6 (2012): 188. Derivatives In this paper there are two important derivatives which has to be computed: 1. The Parameter Gradient The change of depth value $D$ with respect to a parameter $q_k$ which moves the skeleton: $$ \frac{\partial D_c}{\partial \vec{q}} = \left[\frac{\partial D_c}{\partial q_1},\; ...,\; \frac{\partial D_c}{\partial q_k},\;...\right] $$ But since I'm using multiple cameras, I've different depth images of the same model. In the example here two cameras are used ($c=1,2$) and therefore we have $D_1$ and $D_2$. This gradients can be seen in the image below. I'll refer to this image as Gradient-Texture $G$. Here we see multiple instances of the same model. The first instance (0) in the upper left corner is in contrast to the other instances not a derivative but the raw depth value $D_1$. The second instance is the depth change with respect to a rotation of the whole model around the x-axis (which is parameter $q_1$)($q_7$ is the angle of the upper leg). After all $\frac{\partial D_1}{\partial q_k}$ are computed we proceed with $c=2$ and see $D_2$ and so on. 

I would like implement physically based rendering, following this tutorial I was able to find a list of light sources ordered by lumens, but I have no idea how to use it in the calculations. 

According to your comment, your goal is to avoid drawing the invisible faces. There is no reason to find the closest 3 sides of the cube and draw them, because it is possible that only one or tho sides are visible. Finding the exact distance from a polygon in 3D space is computationally expensive. Instead of doing it, I would like to suggest a better method: Use face normals. A normal is a vector, which is perpendicular to a given surface at a given point. If you calculate the normal vector (and the points of the polygon) in world space, you can decide using a simple dot product, if the polygon is facing towards the camera: 

You don't need to render to texture to achieve an effect like this. Use stencil buffer. The visibility polygon can be drawn using , if you start from the middle: 

Clear the stencil buffer (and enable stencil test) Set the stencil function to always pass, and to replace the current value in the buffer to a greater than zero number (for example one) Draw the visible part as a . If you have multiple characters/lights, draw the visibility polygon for each. 

Now the stencil buffer contains 1 at visible locations and 0 where the character can't see. Once you have a stencil buffer like this, you can control which objects you want to draw using glStencilFunc. Do not write to the stencil buffer, just use the stencil test to discard fragments which are visible/invisible. If you want to draw a background which is visible everywhere, use . For objects which are only displayed in the visible area use and . Similarly you can draw something (for example a dark quad) just in the invisible parts of the scene with and . If it is not clear, how to use stencil buffers, check out this tutorial