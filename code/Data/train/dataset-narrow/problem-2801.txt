A little more digging reveals that is dispatched based on the underlying rendering API (D3D or OpenGL), and all it does is used the computed rectangle above to set the scissor test rectangle. It does not do anything related to transforming coordinate systems; it just means that anything rendered to the window that falls within that rectangle will be rendered, and anything outside of that rectangle will be discarded. That's generally the meaning of "clip" in graphics terms. 

Your best (and probably only sane) option to consult with your company's legal department or, if your company does not have a legal department, talk to a lawyer outside the company. As others have said, just use temporary assets. It's safer, it should be trivial to do, and it's not like you need to impress anybody if it's for internal use only anyhow. It will also help make sure you remember to get the assets replaced with the final ones. 

The algorithm involves considering all mesh faces "unvisited," picking an initial face with the fewest neighbors, and trying to grow a triangle strip from that face. At each step, if there are adjacent faces, the algorithm runs a number of lookahead simulations to see how adding a face would impact the vertex cache (basically, if it would overflow the size of the cache). If possible it tries to grow the strip until it optimally fits in the vertex cache. If it would overflow or if there are no more adjacent faces, the algorithm restarts, choosing a new face. When possible new faces are chosen such that their vertices are already in the cache. The second part of the algorithm involve perturbing the ordering of the face sequence and measuring the change in cost; the best perturbation for the vertex cache cost is chosen. The related function can perform other, more explicit optimizations to the mesh. is very similar to calling with the flag, which uses a vertex cache size assumption that works better on older hardware. 

If your game has a gross revenue of $3001 in one quarter, you have to pay Epic 5% of the $1. If your game has a gross revenue of $0 the next quarter, you don't owe Epic anything for that quarter. The royalties are all based around a quarterly model. You have to consider each game separately, not in total. If you have two games that move $3000 in a quarter, you don't owe any royalties. If you have two games that move $3001 in a quarter, you owe 5% of the extra $1 twice (one for each game). It is also important to note that Epic considers in-app purchase revenue and ad revenue part of the gross revenue for royalty-computation purposes, so it's not only the initial sales of your game that factor in. 

The names of sports teams names are usually trademarks of their owning corporation or entity, as are the logos. You cannot use them as teams in your games without permission. This is a legal matter; you should contact your lawyer for definitive advice. 

In general you can use to almost-globally enable or disable exceptions. You can also set up more complex exception exclusions via . You cannot, however, prevent SlimDX from throwing exceptions of a constructor (by design). This is because that's the only way to signal failure of a construction aside from constructing an object in a zombie state (which is ugly). The static method should be usable for constructing your device without throwing (if you disable exceptions). If this doesn't work, please file a bug on the SlimDX issue tracker. You are correct that it's generally preferable to avoid relying on exceptions for flow control (that is, it's better to be able to ask if something will fail than to have to try it and wait for it to fail, although this is not always possible). SlimDX should support this and if not, it's a bug. As an aside, you probably have "break on throw" enabled in Visual Studio via the Debug -> Exceptions menu. You can configure how VS reacts to exceptions from that window -- unchecking everything will prevent the debugger from triggering a breakpoint when an exception is raised. 

When you render, you use both the mask and the real sprite and you skip drawing any pixels of the sprite where the mask is 0. In the old days we'd do this with bitwise magic prior to blitting the sprite; on modern platforms you'd probably accomplish this by multiplying the mask's color with the sprite's color. Whenever a base takes a hit, you update the mask by: 

you're likely to update components of differing types frequently (poor code locality of reference, essentially) this system doesn't lend itself well to concurrent updates because you aren't in a position to identify data dependencies and thus split out the updates into local groups of unrelated objects. 

The answer is that it depends. Hiring practices, needs, and wants are different in every studio and even vary over time. Often they vary wildly. It may be a benefit, or it may even be disadvantage. But, that said, generally your resume, which includes your degree, is only going to get you in the door for the part of the interview where you actually talk to a human. Once you get to talk to a human, what you can actually do is far more important than what the papers say you can. 

This is the first step towards a real-time loop. In this basic form, however, will block if there are no events. There are also some events you will miss (mouse movement events) unless you configure the console input handle accordingly. For many purposes, the blocking nature of the function is acceptable, but if it isn't, you can have a full real-time loop by using a wait function, supplying the console input handle ( above) to the function. The wait function will block until input is available or until the specified timeout occurs. You can use, for example, with a very low timeout and check the return value, which indicates if the wait timed out or if the event was signalled. If the former, you process a frame of game updates without player input and wait again (if the latter, you process the player's input). This method avoids the complexity of threads (although it does involve the complexity of events, which are thread synchronization primitives, so it's not totally trivial), but doesn't require you to set up a full-blown message pump and window (and thus lets you stay in an otherwise pure "text-based" environment you are presumably already familiar with). 

Direct3D10 and Direct3D11 are very similar in terms of their API design, but 10 is a significant break from D3D9. No matter what you do you're going to have quite a bit of work ahead of you, because not only does the API surface change drastically, so to do many of the fundamental basics become more involved. The best way to protect yourself against such a migration is to try to isolate your D3D9 code as much as possible: minimize the number of places you touch the actual D3D9 API itself, and expose higher-level concepts than D3D does from your own rendering API. By this I mean, if your rendering API is basically a 1:1 mapping to the underlying D3D types... so you expose vertex buffers, index buffers, shaders, textures, et cetera... then you will have a harder time dealing with D3D10's notion of a shader input layout, which you now have to expose and weave through all your code. If you exposed a higher level "drawable" object that encapsulated most of those concepts within it, you may not need to touch as much code. Fortunately for you, Microsoft has documented several of the high-profile concerns that will occur when migrating between D3D9 and D3D10. I suggest you peruse that document, and the follow-up for D3D11 which is less intense but still useful. 

The way you have phrased your question implies to me that you intend to break up each subcomponent of the game and farm that out to an individual outsourcing entity (somebody gets the graphics, somebody gets the physics, somebody else gets the audio, et cetera). That seems fraught with peril -- you will need to spend an inordinate amount of time making extremely clear, detailed requirement and design specifications to give to each outsourcing entity in order to have a prayer of integrating everything without doing significant reworking on your own -- thus wasting money and probably defeating the purpose of outsourcing anyhow. It's more feasible to essentially pay a single somebody to develop the entire game. You can find outsourcing companies via Google, unfortunately I don't know of a reputable directory of such companies. You might have some luck at the Help Wanted forum on GDNet, although I wouldn't hold my breath. You may be able to handle outsourcing every component individually if you do them one at a time, and you write the core game yourself (basically providing a design and hooks for a rendering API, and having somebody else fill it out, et cetera). I feel like you're vastly underestimating the amount of iteration and clean up that is going to go into outsourcing code development, and when you add that to the cost (because you'll get what you pay for) I'd be willing to bet that outsourcing that much of the game's development is not financially viable for indie game development. If you were a large studio, perhaps the overhead would be amortized a bit. 

Create a an array of that structure and use your entity index to refer to that. Don't fall into the (unfortunately extremely common) trap of thinking that building a component-based entity system means breaking down everything into the smallest thing possible. You want to break things down into the smallest component such that a single component is still a useful thing on it's own. 

The actual online application form asks for various other things an established company should have, as well as information about your development history and published titles, six-month product development plan, et cetera. 

No, it isn't a bad idea. In fact, this kind of technique -- determining which (usually rectangular) regions of the screen were "dirty" and only redrawing those -- used to be standard practice for rendering to the screen before the modern era of 3D graphics, hardware acceleration via powerful dedicated GPUs, and so on. There isn't any need to waste computational power re-drawing parts of the frame that have not changed. Now, in modern times this technique is of less obvious utility. Many games have so much changing from frame-to-frame (especially in 3D) that it might be worth redrawing everything all the time, even if the modern render pipeline was not specifically designed to function that way. If you are using a technology that doesn't or can't take advantage of hardware acceleration, then it's probably a good idea, especially for a 2D game without much changing between frames. In short, it's unlikely to be a bad thing, at worst it will not likely have any noticeable impact on your performance. At best it will help quite a bit, especially if your rendering involves literally setting individual pixels each frame (it's a bit beyond the scope of your question, but if possible you should use whatever higher-level rendering primitives are available in your toolchain, such as "DrawRect" or "DrawImage" if they exist rather than manually flipping each pixel in turn). 

Per the documentation, was added with Portal 2. It sounds like your version of the SDK and toolset is too old to have it, and there is no alternative that I am aware of (the releated is also only available in Portal 2). 

DXUT was primarily used to drive DirectX samples, and really that's about all it was good for -- it was itself always shipped in the samples directory of the SDK. Modern (that is, for Windows 8) samples seem to directly include "DirectXApp" classes that drive the basic equivalent functionality that DXUT provided. I don't believe DXUT itself has survived the transition because I don't see it in the samples directory linked off of the second page you provided. But that's fine, since it wasn't really worth using for production applications. EDIT: However, as of September 2013, as Chuck notes above, a standalone updated to DXUT can be obtained. 

You're taking the wrong approach with a static UI class. The usual way to "bounce" from a static callback to an instance function is to store something capable of making the jump in a place that is accessible from the static callback. Most APIs, like GLFW and native Win32, that require these sorts of static callbacks provide a way to make the association above. GLFW windows have a pointer-sized block of storage that you can assign to: the user pointer. You can get or set this user pointer as needed. A very common pattern is to have some kind of class that has methods like "HandleKeyPress(Key key)" or whatnot. When you program starts, you create the object and do all your GLFW initialization, then stuff the pointer into the user data storage: