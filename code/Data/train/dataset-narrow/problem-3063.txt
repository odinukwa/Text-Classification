Welcome to the site! The course you are taking sounds like a good start; but I am not sure if it will be enough to land you a job as a Data Engineer (depending on your other qualifications, of course). If you are willing to invest more time, here is a great text on how to learn Data Science in one hundred hours. 

Triangle inequality: Do we have $d(x,z)^2 \le d(x,y)^2 + d(y, z)^2$ for all $x, y, z \in \mathbb{R}^n$? No. Pick an arbitrary $x \in \mathbb{R}^n \setminus \{0\}$ and set $y = 2x$ and $z=3x$. Then $$ d(x,z)^2 = \sum_{i=1}^n (x_i - 3x_i)^2 = 4 \sum_{i=1}^n x_i^2 $$ and $$d(x,y)^2 + d(y,z)^2 = \sum_{i=1}^n x_i^2 + \sum_{i=1}^n x_i^2 = 2 \sum_{i=1}^n x_i^2. $$ Since $4\sum_{i=1}^n x_i^2 > 2 \sum_{i=1}^n x_i^2$, we have found a counterexample that shows that the triangle inequality does not hold. 

One of the most fundamental assumptions in machine learning is that the training data is 'similar' to the test data. Training makes no sense otherwise. So the question is: How similar are reviews of, say, movies and stocks? Maybe somewhat, but not too much. Your movie-trained algorithm would certainly be able to deal with statements like 'This company is awesome' or 'Warning, do not buy this stock'. But what about 'The stock price will explode/implode' or 'Concerning this stock, I am bearish/bullish'? The words explode, implode, bearish and bullish have probably never been expressions of sentiment in movie reviews. 

Your data format is not the default data format. , and by default expect inputs of the form . Your input is of the form . So your algorithm tries to apply convolution, pooling and upsampling to the and dimension, not to the and dimension, as intended. Fortunately, the fix is easy: Add the option to all convolution, pooling and upsampling layers. (Or change your data format). 

The Perceptron's output $f$ is $$ f(\overline\theta \cdot \overline{x}) = \begin{cases} 1 &\text{ if } \overline{\theta }\cdot \overline{x} > 0 \\ 0 &\text{ if } \overline{\theta }\cdot \overline{x} \le 0\end{cases} $$ Here, $\overline{x} = (1, x_1, \dots, x_n)$ where $(x_1, \dots, x_n)$ is the input vector. You can see that the output only depends on the sign of the product $\overline{\theta }\cdot \overline{x}.$ Therefore the output will not change if we multiply $\overline\theta \cdot \overline{x}$ with a positive constant: $$ f(\overline\theta \cdot \overline{x}) = f(c\times \overline\theta \cdot \overline{x}) \qquad \text{ for all } c > 0. $$ In particular, we may choose $c = 1/\lVert \overline\theta \rVert.$ So we get $ f(\overline{\theta }\cdot \overline{x}) = f(\tilde\theta\cdot \overline{x}), $ where $\tilde\theta = \overline\theta / \lVert \overline\theta \rVert$ is the normalized vector. Conclude that there is no loss of generality in assuming $\lVert \overline\theta \rVert = 1.$ 

No, it is perfectly possible to train on multiple categories. What you need, though, is an exhaustive list of these categories (in supervised learning, that is). Suppose you are trying to associate sentences with topics, and you have a list of possible topics . It sounds like your data look something like this: 

Please note that the following is my personal opinion; I still hope that you find it useful. If you cannot properly explain a concept on paper, then it should not be part of your PhD thesis. It is possible to implement Deep Learning algorithms without any conceptual knowledge. While this may be (somewhat) acceptable in the industry, it will get you into trouble in academia. I have no doubt that your algorithms are well-programmed and solve many issues that are challenging from a programmer's perspective. But that is not what the reviewers of your thesis are interested in. They are also not interested in the prediction accuracy of your algorithm. As scientists, they want to know why something happens; and to my knowledge, Deep Learning algorithms have almost nothing to offer in this respect. And this is where 'middle age' linear regression has its strengths (by the way: if you want to make enemies in academia, tell people that the method they have been using all their life is too old to be useful). Yes, linear regression is not an exciting methods, and it has a lot of weaknesses. But it is extremely well understood. Most importantly, there are tons of books and papers about the connection between assumptions and valid interpretations: we know under which assumptions and in which sense the linear regression estimator is optimal; we know which assumptions lead to which kind of confidence intervals for the estimator; we know about robustness with respect to model misspecification; etc. As long as you cannot answer these questions convincingly and on paper (in what sense is my result optimal? How confident can I be about my result? How robust is my model?), you should not use Deep Learning in research as an alternative to classical statistical methods. 

Please also keep in mind that the derivative for a finite set of points $X(t_1), X(t_2), ..., X(t_n)$ does not exist. There are infinitely many functions that pass through all points (and almost all of them are not differentiable). In other words: You have to make additional assumptions on the function that you are looking for. With the methods above, you make these assumptions explicitly, which I think is better than burying them deep inside a machine learning algorithm. 

This is just a wild guess, but I was wondering whether your custom distance function is indeed a distance function. In particular, your problem might occur because your distance function $d(x, y)$ does not separate observations: This is the case if there exist two observations $x_1$ and $x_2$ that are distinct, $x_1 \neq x_2$, but have zero distance, $d(x_1, d_2) = 0$. Then $x_1$ and $x_2 $ would necessarily be put into the same cluster by your algorithm. If this happens for many observations in your test set, then you will observe large clusters. You might be able to check on paper that your function satisfies the four axioms of a distance function (see the Wikipedia article above); if that is not possible, you could at least check it by looping over your test set. 

I want to do one-step-ahead predictions for time series with LSTM. To understand the algorithm, I built myself a toy example: A simple autocorrelated process. 

Generating labels: As a toy example, let us assume that the rule for choosing a point is: Always pick the point that is closest to , where 'closest' should be understood in terms of the Euclidean norm. 

But even then, your claim is not always correct. Here is a counterexample. It has no practical value, but perhaps it is a good illustration. Suppose $\mathbf{X}$ is $(N \times 1)$-dimensional and write $\mathbf{X}_i = X_i.$ To illustrate the point, suppose further that $Y_i = X_i$. Now consider the following model $f$, given a test value $X_j$ and a training set $\tilde{\mathbf{X}}$: If $X_j$ is in the test set $\tilde{\mathbf{X}}$, predict $Y_j = X_j.$ Otherwise, predict $Y_j = 42.$ If I evaluate $L(Y, f(\mathbf{X}))$, I get a perfect fit and therefore zero loss because all $Y_i = X_i$ are in the test set $\mathbf{X}.$ If I evaluate $L(Y_j, f(\mathbf{X}_{-j}))$, I generally get a nonzero loss, because my model always predicts $42$. 

Non-negativity: $d(x,y)^2 \ge 0$. This one is obvious. Identity of indiscernibles: $d(x,y)^2 = 0$ if and only if $x=y.$ This is true because $d$ is a metric, and $d(x,y)^2 = 0$ if and only if $d(x,y) = 0$. Symmetry: $d(x,y)^2 = d(y,x)^2$. This is again true because $d$ is a metric and therefore $d(x,y) = d(y,x).$ 

Let $x, y \in \mathbb{R}^n$. The Euclidean distance $d$ is defined as $$ d(x,y) = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}. $$ The squared Euclidean distance is therefore $$ d(x,y)^2 = \sum_{i=1}^n (x_i - y_i)^2. $$