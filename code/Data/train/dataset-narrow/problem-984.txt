V8 specific Watch out when using . Some of these code challenge sites are still running on older versions of V8 and let used to add a big overhead especially inside loops. Careful with indexing indexing. Some JS engines are not as efficient as others when it comes to array indexing and property referencing. For example V8 will be slower when you reference an array elements using multiple indexes 

By breaking the problem into smaller parts you reduce the overall complexity and make it easier to read and maintain. 

Links filter, map, filter can be chained. Also is a bit noisy you can use to do the same. So now the function looks like 

But that said there is nothing wrong with how you do it, either way is good. Unless you have a regular main loop as part of an ongoing animation then you do it from there. 

Precision testing is flawed... ...because precision function is flawed. JavaScript uses FLOATING point numbers, but you are treating them like fixed point numbers. Consider (Small value is ) JavaScript will happily return the correct value I think you are trying to fix problems like which JavaScript will calculate to be which has an error of 2e-48 Both examples your code will round to zero, and the test will pass even if it is completely stuffing up the operators eg is which is in fact out by 16 orders of magnitude. You are better of providing the test function with the JavaScript calculated value. Don't test with the known result but rather the calculated result and remove the calls to . Euler's constant Looking at the code it it seams to me that values entered as exponents will be incorrectly evaluated (maybe throw) eg will not work. Though I am not sure, I have not run your code? Triming Javascript has a trim function so there is no need for Thus 

Yes, as far as I can tell. The best way to make sure is to run the code and test all parts of it. The way of OOP 

Week start Day and Month week starts in The start of the week can be different for different people. To simplify the code you can set the start of the week (week day 0) to any day. 

The trick is the second default parameter needs to set the first argument to 0 and assign the second argument to the first. The only way to do that is to use an expression . The order lets you effectively swap the variables without the need of a interim value. Another example is a gaussian random where the random values are distributed around the mean. A third parameter is needed to define the distribution curve 

Bad code. There are some that will not agree, this is an opinion on good coding practice for JavaScript. The code in question 

Algorithm UPDATE seams I miss read the question. The order of the elements must be maintained. I will leave in this second half of my answer in case anyone is interested. This is an example of a packing problem. Find the max items to fit a finite space. Your algorithm assumes that the items to pack are ordered from smallest to highest and thus fails to find better solutions if there are smaller items further in the list. To fix you need to sort the elements array. This is expensive so to reduce the overhead you can first get the total size of all the items and if they all fit return the element count avoiding the need to sort. Then if the items width is to large start at the largest and remove until the you get a length that can fit. Improved algorithm The following solution will find a better count. However I have not come up with a proof that it works for all cases and I feel that there may be some cases that it may fail, though can not come up with an example (proof false by contradiction). There is also some ambiguity. Are items with 0 or negative width valid. I have let 0 width items in, but negative items are out, yet could also be valid as they are used to increase the packing size? 

Now we have almost everything. There is still a chance of the two numbers being misinformed (eg "0.0.0" or second number as "0+10") but we can use the function (is Not a Number) to vet these Vet again 

The test is of 1,000,000 shuffles each starting with the same array. As you can see the first item has a good random distribution with the difference between the highest and lowest position of 1.06%. But all others had terrible bias. If it were gambling this level of bias would bankrupt a tote in a few dozen shuffles. Look at the center one , it is 27% less likely to be in its starting position than in the position one down, and approx > 50% chance of being in position b,c,d. To improve. Using the algorithm you have can get better results by just shuffling the array more than once. This of course increases processing time. If we look at the distribution range between the lowest position count and the highest for each item, we can see that the number of shuffles make a big difference. Just by shuffling twice reduces the distribution of the last 8 items from the 27% to < 2%, but compared to the first item the distribution is still not even across all items. Shuffling 8 times brings all to under 1% distribution, but the problem remains that the first item will alway have a distribution that is lower than all the other items. Remove select bias You can instead randomly select both items for the swap each time and shuffle the array 4 times. This reduces the distribution of all items to around 1% for 1,000,000 shuffles. 

Constants, holidays, and dates Convert the holidays to start of holiday's day, so you dont have to convert it each time you check the value. The example uses LOCALE to convert the date string to the correct format "World" or "US". 

The merge function Inside the while loop of the merge function you are doing too much. Each 2 values that need to be compared have the overhead of two if statements. They are true only when the loop is ready to exit. The loop should only deal with the comparison of two values and after the loop you can clean up by adding the remaining array content to the result. Improving the merge Remove the unneeded if statements and put them after the loop. 

Or you could have jumper return a promise on the first pass which resolves with the answer. I am not too sure if this fits the FP paradigm. 

You create an array with then overwrite it by assigning it the reference to You should just declare and not assign it an array that is not used and immediately dereferenced. Also I am unsure what your intention is here. Do you expect there to be a second copy of that is sorted? 

Some notes (*) Called Object/s because in Javascript there are no "classes" only Objects. The class token is just a way of defining an object. (*1) Note that in some cases to such as conditional and loop statements (where you use conditional operators) it is better to define befor the statement variables that require operations. 

In terms of memory use GC impact, and CPU use the following can do the same in ~70% the time and much less memory. 

Foreknowledge of result length This type of problem has a short cut because you can know the size of the resulting array by just inspecting the first and last items. You can then use the calculated result length as an exit condition. In the best result you only have to inspect the first and last value and exit without iteration if there are no missing values. The worst you will have to count over all the values in between the first and last. The resulting algorithm is very efficient 

Functions If you write many functions with just a few minor differences its a good sign that you can write one function and pass the differences as arguments. Each function has just two differences, and abstractly just one "The choice" 

If you want to improve the performances there are a few things you can do. Testing The first thing is that you can run tests and see how code style and logic can effect performance. Javascript testing is a little tricky. You can not just run the functions. You need to make sure you are not being tricked by the optimiser I have added a basic Javascript performance tester to the bottom to highlight the following points. Slow iterators The Array iteration functions such as are generally slower than writing a standard , or loop. The reason is because functions incur a lot of additional overhead each time they are call. They need their own memory, special structures to hold the current scope, and closure values. All this is added to the JavaScript heap and called the function's "context". On top of that the actual function has to do some checks to make sure that the arguments you pass are correct and can be used. This all adds to the time to run the function. For of loops are faster Using a loop avoids all that overhead and for this example is about 60% faster (on Chrome)