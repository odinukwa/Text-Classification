Not sure which type you are referring to as the "event doesn't happen" can take different forms, it can be either conditional or unconditional. Examples: 

You might be also interested in nxlog as it provides a wealth of features such as rfc5424 syslog format, TLS/SSL, filtering, rewrite, etc. (note: I'm affiliated with the project). 

AFAIK rsyslog doesn't support wildcards in filenames. nxlog does. In addition it can parse apache logs and can send it to elasticsearch over http. You might want to take a look at it. (Disclaimer: I'm affiliated with the project.) 

You should investigate further why logstash is not closing the connections properly (e.g. check the logs). Perhaps you have some network gear/proxy firewall between the two that terminates the TCP session? 

There is an example in the manual: Example 6.9. Parsing URL request parameters in Apache access logs 

You need to tell the compiler/linker where to find the zlib library. This is usually done with if it is autotools based. 

Probably you should send the message without the hostname (foo) and in rfc3164 format (not rfc5424 as the above) to get it parsed. 

Can you try removing from your ? It will be still running as . Afair there was a bug with this in the CE. 

The cause of the syntax error is that your brackets are not correctly paired. It should be like this: 

I think the issue is that exec_async() should not receive the arguments concatenated to the command, i.e. you need this instead: 

The message in the event is rendered by the EvtFormatMessage function. As far as I remember there was a limit of around 32k characters for this so this shouldn't be causing the truncation. This works via a format string that is identified by the event id and a set of values that are stored with the event. The piece is such. The EVENTDATA_DESCRIPTOR structure that is used to write this value can also store larger data. My bet is that the event provider has an internal limit (5120) for this. The reason behind this is probably due to the limitation noted in the documentation: 

This is a bug in the module of the NXLog Community Edition. We have already fixed this in the EE and the fix will be available in the next CE release also. 

If you do you'll see a list of the resources that are causing the 404s.. There might also be package information in . You might need to remove (as in ) those packages that are causing the 404s. Be careful not to remove those that are working. Then if you cd into you will notice . In my case I just ran and that removed all the broken packages (after verifying the contents of , of course). You can run , , and in sequence afterwards and you should come out clean. If you are in doubt about the naming convention for the packages in the list file, you can always do . 

I resolved the flurry of opening and closing sessions on problem by commenting out the and settings on from 

Background: I added OTP token authentication to my web server. I modified the file with the command. Problem: I have a local Jenkins instance connecting to the web server for doing deployments; Jenkins can't enter token info or respond to phone calls (although who knows, I bet there's even a plugin for that!). Possible solution: use the command parameter to force the token script on all keys, except for the key being used by jenkins. Question: How less secure than the global sshd_config approach the authorized_keys approach is? Would you consider it an acceptable trade-off? Is there a better solution (that allows Jenkins to do slave deployments, whilst keeping everyone else locked down with token auth?). I've tried both approaches and both work like a charm. The second approach I find more practical in terms of deployments, but it raises some sort of internal red flags for me. I don't know if I'm chasing ghosts (with the red flags). Discuss! 

In other words, I temporarily disabled the PAM module while I figure out with it's vendor the correct settings. 

So this is related to sshd, however, since this is so specific to a token-auth vendor (whose name I am not disclosing for privacy), I think this might be better solved by the vendor. 

While tailing I noticed that there where multiple entries being entered (instantly) by the minute for user "foo". I personally had only one connection open as user "root_bar" while tailing the (log sample below). As you can see, there is no IP information for this incoming SSH connections. What is the best way to trace the IP address for incoming SSH connections? 

If you are after the first case and need an open source tool, there is a Pairwithwindow rule in SEC and an Absence rule in nxlog.(Note that I'm affiliated with the latter). The second type is simpler and both tools can handle that too afaik. 

Your event has 12 values and if they used equal limits for each then it comes down to around 5kb. Perhaps you could file a bug report with Microsoft. 

Yes, but localhost (which is normally 127.0.0.1) is not accessible from the outside so you need to make it listen on an address that is accessible. Your im_tcp input instance needs this: 

I think SEC can do this, but it needs to be monitoring it in real time. I can also recommend you nxlog (disclaimer: I'm affiliated) for checking such situations. This example could be tweaked to fit your needs. On the other hand writing such a script in perl wouldn't be that complex, but you need to take a few things into account in order to not generate false positives or miss an alert, and once more rules need to be added, you can easily find yourself stuck with development. 

Take a look at nxlog. It can ship your eventlogs securely, there is TLS/SSL and HTTPs support. You could also format your logs in JSON and entirely skip the syslog format. I think these features will help integrate better with loggly. (Disclaimer: I'm affiliated with the project.) 

You should check for any errors. To me it looks like the line is incorrect as there should be a linebreak after each . 

I can't say if it is a bug or is intended to work this way. The file can be monitored even if it isn't opened. Calling stat(2) and checking mtime/size will give hints whether there is any change since the last read. At least this is how nxlog works and avoids running out of file descriptors if you need to monitor a lot more than 28. 

It's a little unclear whether there is a " character in your input or not. Try setting QuoteChar to something other than the double-quote. 

If you are shipping it as plain syslog (i.e. using in ) then the value of $SourceName (=) will be in the message in the part what RFC3164 calls :