did the trick on all machines I tried. And while starting the other nodes, it is also a good idea not use the "systemd way" systemd mechanism has a timeout, and if your sync with the other nodes takes a bit longer, systemd spits out an error, but mysql keeps running and does what it is supposed to do. It's not a bad thing, but it's kind of confusing. So for now I recommend, starting the other nodes also "by hand" 

I have a server landscape, running mysql 5.7 on debian 8 in some GTID based replication configuration. All is high load servers and 200+GB databases. Now I got some new servers. I like to run that new servers on debian 9 and the recommended mariadb 10.2.X expanding it later to a MariaDB Galera Cluster. I've read some, how to migrate from mysql to mariadb, but anyhow none of them seems to fit for me. Different GTID handling and innodb format between mysql and mariadb does scare me a bit. After all I have to run some tests. So, my idea is: on one of the masters (mysql 5.7), -flush tables with read lock -make a snapshot (LVM) of the database partition -show master status to get the GTID executed -unlock tables -copy that snapshot to a new server to /var/lib/mysql -install mariadb on the new server would mariadb upgrade that data in /var/lib/mysql Any recommendation or another ideas on that? Ju 

I made it work. The problem is how the bootstrap script tries to start the server. I tried on different machines and all had the same symptoms when trying to bootstrap the cluster using the script galera_new_cluster. It has something to do with systemd, I guess. bootstrap the new cluster "by hand" using 

It seems like you are running SQL Server together with an application on one server. SQL Server will consume all the memory it can by design. (The default MAX memory setting in SQL Server being 2147483647 MB.) If you changed the default MAX memory setting to something else, then SQL Server will start consuming memory after a reboot for data cache, query plan cache, and for other SQL Server relevant components. At some point in time the SQL Server will pass the MIN memory setting. SQL Server will not release memory back to the OS past this setting. Later on the SQL Server instance will possibly reach the MAX memory setting. SQL Server will not pass this line for data cache and plan cache. However, the SQL Server process can use more than the MAX memory server setting, because some objects run outside of the MAX memory setting (depending on version) and SQL Server can overcommit memory. This is discussed in the following article Memory configuration and sizing considerations in SQL Server 2012 and later versions Your SQL Server will now consume memory between the MIN and MAX memory setting until you reboot the SQL Server instance. 

Ok. Let's connect to the instance and carry on researching (I used in my example, because I am on the server itself): 

The disk and/or disk controller is set to use a WRITE CACHE mechanism which is unable to keep up with the import of large amounts of data. The corruption is occurring on flushing. 

Restore the most recent backups of the system databases: , , (): When restoring the database start the SQL Server instance with the Trace Flag 3608: 

I'm on 2 debian8 box's with mysql-5.7.19. I have a master slave replication running, replicating one db (db1.1) from master to slave (db2.1). Replicated db's on master and slave have same names. Master has another db (db1.2) that pulls some statistical data out of db1.1. That happens by means of some views (getting data from db1.1) in db1.2 and an event in db1.2 that calls a procedure. Now I like to take that statistical workload of from master and put it on the slave. I created another db, db2.2 on slave with identical table and views as in db1.2. Names of db1.2 and db2.2 are different. Created same procedure on slave as on master and an event with another name on slave.db2.2 that calls that procedure. If I call the procedure by hand on slave it does what it supposed to do. Copies all data as expected. But calling that procedure by an event on slave doesn't run. Names of the events on master and slave are different. What I'm doing wrong? 

Starting point at the sandbox sb1, sb2, sb3: All boxes identical. A Fresh debian 9 install mariadb 10.2 Galera3 build a test galera cluster with empty databases works fine. All three nodes come up and work as expected. then after stopping the test cluster copy a LVM snapshot from a production mariadb server over to sb1 start mariadb server with standalone config to see if all databases and tables are correct. (config I took from the server the data come from) shutdown and restart the standalone to see if there is a problem. All is fine, server starts and stops as expected. Then change configs to fit galera try to bootstrap with > galera_new_cluster and that $URL$ is what happens. my.cnf 

You will receive a list of SQL Server logins for your SQL Server instance. Note: These are the SQL Server Logins and not the database users. Database Users Database Users can be queried by querying the system catalog view of each user database by issuing the following query: 

Check that the FULL and/or DIFF backups of the database in question are recorded in the msdb database and verify that you don't have any long running transactions on the msdb database. Reschedule (the/other) jobs to run at a slightly different times if you have multiple jobs running at the same time. 

Forcing a TCP/IP Connection In the SSMS connection window perform the following steps to force a TCP/IP connection: Basic SSMS Login window 

Reference: CREATE LOGIN (Transact-SQL) (Microsoft) Explanation When you link a Windows login with SQL Server, the SQL Server will trust the Windows login which has already been validated by the account logging in to the Windows system. The chapter Connecting Through Windows Authentication in the article Choosing an Authentication Mode explains how Windows Accounts login to a SQL Server instance: 

Moving even further forward (in the reference) the examined time (vertical axis) moves forward and reaches the Failure. 

Reference: Oracle Data Pump Quick Start (Oracle.com / PDF) ...or run the command with the account. Side Note In some rare cases where either or have to many roles assigned to their accounts, you might have to run the command with a dedicated account that you would have to create from scratch. 

Filegroup 'xyz' Is Default If you receive an error message when trying to remove the filegroup's logical file that looks like this: 

So, for the after world. I did it by following my idea and it worked out well. A few minor things has to be taken into account. After copying data over from one server to the other. The *.pem and the auto.cnf files in /var/lib/mysql/ have to be deleted on the new machine. Deleting auto.cnf is really important because it holds the servers ID and you don't wanna end up running several servers with same server ID, what will cause you problems afterwards. On a fresh installed machine, before installing mariadb, there isn't a user mysql nor group mysql on the system, so change the /var/lib/mysql and it's sub folders to be owned by root:root. I copied the entire /etc/mysql folder from source machine to destination machine, to make the mariadb install script believe there was a running mysql installation before on that machine. In the config file /etc/mysql/mysql.conf.d/mysql.conf I changed the value of the server_id variable to be unique in the entire server landscape. After that you are ready to fire the mariadb installation on the new machine using apt. While installing, mariadb install script detects the mysql stuff and tries to run the mysql-upgrade on it. That will probably fail, as in my case, but that's not a big deal. It is because the install script tries to run mysql-upgrade as root user on your freshly installed mariadb server with old data in place. But there are differences between mysql and mariadb in system tables and in what root on a local machine can do and what not, and system tables needs to be upgraded by the upgrade script. I never run things as root user on the database, so I have my own user with rights do do everything on each of my databases, and that user credentials come with the data from the old machine. So I run the update script just from the command line using my user credentials instead of the root credentials. And it turned out to run well, complaining about some missing stuff, but that is what the update script is written for. To detect missing or changed stuff and correct it. Restart mysql and there we are. All my users and 230+GB of data right into access managed now by mariadb on a debian 9 machine. Hope it helps someone. Ju 

The database owner displayed in the files section of the database properties is not displayed in the Security branch of the database. This is by design. Explanation Database Owner The database owner in the file setting of the database properties is the owner of the database and does not have to be explicitly listed in the security tab. This is normally the SQL Login that created the database. 

Creating SQL Server Login with password () Creating a database user in the database () Granting permissions to the database user (in various tables, depending on the privileges) 

However, according to the default documentation 3.4 Securing the Initial MySQL Accounts, there is either the user or the anonymous account (blank/empty). 

The following list of article might provide adequate information for you to put together an Azure SQL Data Sync: 

Browser Service If the browser service is DISABLED or has not been started, then connections cannot be routed to the relevant port. In this case the DAC port has to be retrieved from the ERRORLOG file of the instance. You should find a line with something like Dedicated admin connection support was established for listening remotely on port 63389. for the DAC port. This port number is the port the DAC will listen on. You are required to supply the relevant port for the Dedicated Admin connection and the corresponding port for the SQL Server connection if your Browser Service is turned off. You do not have to add the instance name to the connection string when using the port, because the port is reserved for the instance. 7 In short the Browser Service is responsible for converting instance names to ports. If the Browser Service is not running, then you have to supply the port instead of the instance name.