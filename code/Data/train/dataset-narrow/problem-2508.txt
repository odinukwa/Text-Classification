Are there any algorithms to draw a billion node graph or to aggregate the information? The idea would be to allow for it to be parallelized using map reduce so it could be done in realtime I was wondering if there were any other algorithms? A google search turned up nothing. Very large graph drawing I have found are as follows 

What kinds of systems are available that accept a certain program $P$ and attempts to figure out "the program does terminate" or "the program does not terminate" and output a proof of one or the other? 

Googling "learning boolean function problem" from M. Alaggan says that BBB and BBB-F is at most NP-Hard and you can optimize the problem for certain inputs. 

From $URL$ A knot mosaic is the representation of a knot on an n Ã— n grid composed of 11 tiles here are them below. This is my starting point in asking you for a mosaic knot table with a set of restrictions. What I want to ask you is to give me a table with the following properties 

PSPACE proof attempt of Portal 2 by reduction from TQBF Application of section 2.2 of Gaming is a hard job, but someone has to do it! On portal 2. A direct proof of the statement: Given Portal 2 can you encode a TQBF in the game? We disallow portals in certain parts to simplify the proof since this is allowed in the game but, we will show that if all surfaces were white then this would allow you to bypass the proof. This either changes the topology of the graph or collapses quantifiers into being the same quantifier. 

A $(+,\times)$ circuit is skew if at least one of the two inputs of each product gate is a variable. Such a circuit is actually the same as switching-and-rectifying network (a directed acyclic graph with some edges labeled by variables; each s-t path gives the product of its labels, and the output is the sum of over all s-t paths). Already 40 years ago, Markov proved a surprisingly tight result: a minimal monotone arithmetic skew circuit for $S_k^n$ has exactly $k(n-k+1)$ product gates. The upper bound follows from Fig. 1: 

So far, I can only answer Question 2 (affirmatively) under the one-sided error scenario, when we additionally require $\mathrm{Pr}[\mathsf{C}(x) < f(x)]=0$ over the min-plus semiring (minimization), or $\mathrm{Pr}[\mathsf{C}(x) > f(x)]=0$ over the max-plus semiring (maximization). That is, we now require that the the randomized tropical circuit can never produce any better than optimum value; it can, however, err by giving some worse-than-optimal values. My questions are, however, under the two-sided error scenario. 

A majority vote function is a partially defined function $\mathrm{Maj}(x_1,\ldots,x_m)$ which outputs that element $x_i$ (if there is one) which appears more than $m/2$ times in the input string. 

In the movie Inception Cobb asks a asks Ariadne to design a maze that takes twice as much time to design. This lends itself to a generalized problem where we have an situation where we are resource limited by some amount and whoever will verify that this problem is in the given complexity class that either will take more time and or space to solve. Is this a novel problem? 

Anything to do with Machine Learning has a lot of career prospects because you could be employed by either finance or technology companies in general. 

No there is no current system that does all four steps in your system. If you want to design a system one of the first requirements is homoiconic language. At minimum you would want your core programming language that you have as small as possible so that when you enter the system and start to make it interpret itself it will work. So therefore you want a metacircular interpreter which was pioneered in lisp. Other languages have done it also but there is a enormous amount of existing research on lisp. The first step if you want to do this is to have a homoiconic language like Lisp or some framework where you can reason about a running program. Lisp is used for this for the sole reason that you could define a metacircular interpreter in the language or you can just treat your code as data. Treating the code as data is the most important thing. There is along discussion about what homoiconic means on c2 wiki. For example in Lisp your "Program" datatype is valid lisp programs. You pass the lisp programs to an interpreter and it computes something. It gets rejected by the interpreter if you don't program a valid "Program". Therefore a homoiconic language does three of your requirements. You can even in lisp define the idea of a formal program. Can you model lisp inside lisp? Yes this is frequently done mainly as an exercise at the end of a lisp programming book to test your abilities. SICP At the current time issue four is a research question and below is what I have found that attempts to answer this question. I would say there are many types of programs that attempt to do this. Below is all of the programs that I know about. 

If we consider monotone versions of circuits -- no Minus $(-)$ and no Not $(\neg)$ gates -- then $B(f)$ can be even exponentially smaller than $A(f)$: take, for example, the shortest s-t path polynomial $f$ on $K_n$; then $B(f)=O(n^3)$ and $A(f)=2^{\Omega(n)}$. But what happens in the "non-monotone world"? Of course, big gaps cannot be known just because we do not have large lower bounds on $A(f)$. But perhaps there are at least some small gaps known? 

Example: An $s$-$t$ path $p$ = $s\xrightarrow{e_3} u_1 \xrightarrow{\phantom{e_3}} u_2 \xrightarrow{e_1} u_3 \xrightarrow{e_2} u_4 \xrightarrow{\phantom{e_3}} t$ in $G$ represents the path $q=(e_1,e_2,e_3)$ in $K_n$. 

Footnote$^{\ast}$ The Bellman-Ford-Moore algorithm for this problem takes as subproblems $f_k(j)$ = length of a shortest path from the source vertex $s=0$ to vertex $j$ using at most $k$ edges. The terminal values are the lengths $f_1(j)=x_{s,j}$ of edges incident to the source vertex. The DP recursion is: $f_k(j)$ = minimum of $f_{k-1}(j)$ and $f_{k-1}(i)+x_{ij}$ for all $i$. 

Usually, in applications, only large thresholds do work: we usually need thresholds of the form $2^{n^{\epsilon}}$ for $\epsilon > 0$. Say, if $F:\{0,1\}^n\to \mathbb{N}$ counts the number of $s$-$t$ paths in graph specified by the $0$-$1$ input, then for $t=m^{m^2}$ with $m\approx n^{1/3}$, the threshold-$t$ version of $F$ solves the existence of a Hamiltonian $s$-$t$ path problem on $m$-vertex graphs (see, e.g. here). 

Yes, an example of a system that performs this task is T2. It does not solve the halting problem but instead it only attempts to solve certain special cases. A overview is at $URL$ . The newest version of this system is at $URL$ . 

So lets encode the trefoil in a machine readable format. We take each tile and assign them a number (01-11). Using the programming language racket it will look like this 

--Begin amended algorithm-- Step 5 is due to @vzn answer: Add a visualization of local regions. Therefore we define a region as a set of points that are "close" due to some locality measure. Pagerank is an example so you have a pagerank of 2 you are in the region. 

Take a graph layout algorithm (a force directed layout algorithm) Create a window of locality using a graph metric that you define Draw everything in an epsilon of that graph metric. Iterate the window throughout a n-dimentional space. Where n is defined as the amount of data points you have and a tag is a $S \in $ the set of strings. (vertex, edge, $tag_{1}$, ... $tag_{n}) 

Held $\mathrm{BPP}\subseteq \mathrm{P/poly}$ in these two semirings, this would mean that randomness cannot speed-up so-called "pure" dynamic programming algorithms! These algorithms only use Min/Max and Sum operations in their recursions; Bellman-Ford, Floyd-Warshall, Held-Karp, and many other prominent DP algorithms are pure. 

Concerning $Q1$, a word of caution is in order: even logarithmic depth if far from being understood, not speaking about poly-logarithmic. So, in the non-monotone world, the real problem is much less ambitious: 

$P_n(x)$ = minimum or maximum of some arithmetic combination of the subproblems $P_m(x)$ for $m < n $. 

P.S. This "length times width" argument (when all $s$-$t$ paths are long enough) was earlier used by Moore and Shannon (1956). The only difference is that they do not allowed rectifies (unlabeled edges). So, this is, in fact, a "Moore-Shannon-Markov argument". 

NOTE [added 07.10.2017]: In the context of derandomization, the VC dimension of a class $F$ of functions $f:X\to Y$ is defined as the maximum number $v$ for which there are functions $f_1,\ldots,f_v$ in $F$ such that for every $S\subseteq\{1,\ldots,v\}$ there is a point $(x,y)\in X\times Y$ with $f_i(x)=y$ iff $i\in S$. I.e. we shatter not the sets of points via functions but rather sets of functions via points. (The two resulting definitions of the VC dimension are related, but exponentially.) 

Clause Satisfaction I model clause satisfaction by companion cubes. Assuming you can always move companion cubes between rooms if one companion cube is with you then the $or$ operation satisfies and you can pass. Note that each door is dependent on the next one if they are in a line in portal or if they are in one path. For the reverse operation on 2.a I allow you to portal backwards and have a piston allow you to go up. Removal of Portal Restriction If we allow for unrestricted portals and your portal simplifies the problem occurs then this removes quantifiers and sets the variable to be true. For 2.a and 2.b if there is the ability to shoot a portal past the door then you skip the quantifier. For 2.c if you allow successful portaling you skip the whole clause. Further work What does the physics engine do for computational complexity? 

Currently bitcoin has a proof of work (PoW) system using SHA256. Other hash functions use a proof of work system use graphs, partial hash function inversion. Is it possible to use a Decision problem in Knot Theory such as Knot recognition and make it into a proof of work function? Also has anyone done this before? Also, when we have this Proof of Work function will it be more useful than what is being currently computed? 

Note [added 27.11.2017] My question actually is: can we capture THE barrier for derandomization in the uniform setting? After Adleman's theorem, one serious "barrier" for extending it to circuit (or decision trees) working over infinite domains $D$ (like $\mathbb{R}^n$, instead of $\{0,1\}^n$) seemed to lie in the infinity of the domain. Adleman's theorem simulates probabilistic circuits by majority vote of about $\log|D|$ deterministic circuits (Chernoff bounds then suffice). But this (infiniteness of $D$) turned out to be no barrier: it is then enough to replace $\log|D|$ by the Vapnik-Chervonenkis dimension of deterministic circuits. 

Motivation: Problems of this kind are related to the complexity of combinatorial optimization algorithms. But they seem to be interesting in themself. Why should we seek for algorithms that are efficient on all graphs? In reality, we are usually interested in the properties of small pieces of one (large) graph (network of streets in a country, or facebook, or the like). 

Motivation: Every monotone boolean function $f$ defines a natural minimization problem: given an assignment of nonnegative weights to the variables, compute the minimum weight of a minterm of $f$; the weight of a minterm is the sum of weights of its variables. One can show that $B_r(f)$ is a lower bound on the number of operations used by any "pure" dynamic programming algorithm approximating the minimization problem on $f$ within the factor $r$; a DP algorithm is "pure" if it can be implemented as $(\min,+)$ circuit. 

Now lets see a knot table made up of mosaic knots: a knot mosaic is a type of representation of knots which use tiles instead of being strings in a three dimentional space. 

Which corresponds to $3_1$ in the above table by Rolfesen. Now, lets see a trivial task. Once again using racket 

If I wanted to define my own complexity class would you first define it as a set of problems with reductions to those problems? How would one go about doing this? 

For your first question I believe this paper may help a bunch. It has a 6 bit combinator calculus that is also an UTM. Also it has a universal combinator that seems to have size 7 with one element given what you want. They call it Zot. $URL$ I am not sure if you can say or prove that there is a minimal combinator. The paper would suggest it would have to be at least be less than 6 bits. 

Yes, ask your professor to give you a problem that you may solve as an undergraduate. You can also look for publications that say that the problems are appropriate for undergraduates. I think that a research project that you could do that would be interesting would be to create a language that would compile to the EVM (I suggest scratch $URL$ Another would be to explore user interface design for voice systems like making an Alexa App or one that you create yourself to solve some problem that you face. A good example can be found at $URL$