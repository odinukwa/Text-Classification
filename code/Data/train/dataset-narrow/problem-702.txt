EDIT: Restore process also depends on amount of transaction which needs to be rolled forward and rolled back. If Log file have to many VLF's restore process would take time. Restore will be faster if disk from which restore process is reading data is not facing I/O contention. More details in this microsoft Link $URL$ 

If above works fine IMO your windows installer should not be corrupt but if you still face issue you should refer to This Microsoft Support Article which has details about how to proceed with corrupt installer. This error can also come if installation media is corrupt. So i would like you to copy setup again and start a fresh installation by right click on Setup file and select run as administrator Hope this helps 

Your best bet is to test it out. You did not told us what would you do to the transaction log backup job on primary will it keep on happening as per schedule?, if so do you have enough space on drive holding transaction log backups ? Also for this exercise it would be better to have secondary database in standby mode before you recover it If you do not disable the backup job then you have to make sure you keep all the log files intact and after you add the secondary back the mammoth task of restoring all those files would be on restore job and it will sure fire some alerts that log shipping is out of sync but since log chain is not disturbed it should eventually catch up. Now other scenario can be you disable all the log shipping jobs and is ready to run primary database exposed (which would not be correct thing, its your call) and now you go ahead and remove secondary from log shipping for 24 hours. When you will add it back, subject to condition you can do it successfully, the log shipping should work. The reason I say it should work is I do not see any log chain which is disturbed or broken and after adding the secondary server. The challenge here also is whether you are successfully able to restore the snapshot, please note I have seen many a times this thing failing that is why i stressed on testing it. 

You must also check if there is any job running daily which is shrinking data file or may be shrinking whole database using command or may be using command. Of course this could only be complete answer if you confirm whether any such activity is going on in database. 

You have to either test it yourself or ask the vendor, as for question that can snapshot backups which under the hood use VSS to connect to database and take backup break the backup chain the answer to this is yes it may and I am saying this because I have faced this issue. Also note that the characteristics of breaking that backup chain lies with snapshot backup only. TP tools which take normal backup also use VSS but they do not break log chain at least I have not faced such issue but you need to be careful with snapshot backups and I guess your tool is doing the snapshot backup because it is freezing the I/O to get consistent view of the disk and then taking snpahot. 

Example: Look at it is totally not usable at all. It would be correct decision to first disable it and then remove it. Look at the index is both read and updated but updated more than read. The division value is .80 which is almost 80 %. You can keep this index it both being utilized and updated, I dont see issue with this index. Look at the division give .33 value and percentage is 33 %. This index again has to be looked into this is doing more harm than it is doing good. The whole idea about percentage is based on how good knowledge you have about your database. The decision to keep or remove an index should be largely based on requirement. Its quite possible index might be utilized fortnightly or weekly but updated every day. This may be because a job runs weekly or fortnightly and utilizes those indexes only at that time. Moreover you should not worry about small indexes which have page count < 2000, again this is ball park figure, such indexes cannot do any harm. 

The major difference I know is Normal Column Encryption The normal Column encryption which was introduced from SQL Server 2005 uses function Encryptbycert to encrypt the columns. It is not as secured as compared to Always Encrypted in terms that with this method data is submitted as clear text in SQL Server and this data can be seen from traces. A DBA, who has admin access to SQL Server, can see the data so this is actually not fully secured. Always Encrypted With always encrypted the encryption is done at clients app by API, like ADO.net,ODBC. Drivers are installed at clients end to do this encryption. This will not allow SQL Server to see text data hence not revealing it to DBA's and one who have admin access on SQL Server. Always Encrypted allows clients to encrypt sensitive data inside client applications and never reveal the encryption keys to the Database Engine. Quoting from Docs.microsoft 

My first question where are you looking for SQL Server memory consumption. Please don't use task manager or process monitor, these do not show correct value when SQL Server service account has Locked pages in memory privilege. just use below query to see memory consumed by SQL Server 

Backup size as such is not influenced by much by recovery model it determines the amount of data loss you can have in case disaster strikes. Moral: Use backup compression it might solve all your queries. 

Moral: If you are not seeing any anomaly after enabling LPIM I suggest you leave it as it is but before doing this speak to your VMware admin and make sure the VMware configuration is correct 

As you already wrote in your question that you fiddled with registry and in this process you made registry inconsistent so SQL Server is not able to proceed with installation of Setup files its failing at setup support file installation like below 

Yes it does needs space in transaction lo file to rollback. Rollback is mostly single threaded and undoes what the transaction has done. Rollback: What happens when you kill a session 

No buffer pool and VAS are not the same thing. In SQL Server direct physical memory access is not allowed any memory request which comes is first mapped to process VAS and then if SQL Server find memory free it would map this VAS address to physical memory and then memory becomes committed. Bufferpool is physical memory VAS is virtual memory. VAS VAS is Total amount of Virtual address space visible to process. Total VAS in windows OS is divided into VAS for OS process and VAS for application. SQL Server runs as an application. For 64 bit system total VAS is 16TB. So now both SQL sever and Windows process gets VAS of 8TB. Whenever a new process wants to read data or write data into memory it would reference memory in its VAS region so the new process would see VAS of 8TB and then it would be mapped to physical memory. This physical meory would be your buffer pool Buffer pool A buffer is an 8 KB page in memory, the same size as a data or index page you can consider buffer as a frame which holds data and index pages when they are brought from disk to memory. SQL Server buffer manager manages the task of reading data pages into buffer pool and also writing it to disk. It is a reserved memory store for SQL Server and by default if you do not set value for it it will take as much memory as possible. Buffer pool only allocates memory to requests which requires less than 8 KB pages this feature changed in SQl Server 2012 where buffer pool has no meaning its just consumer. It is easy to allocate small contiguous amount of memory than large contiguous amount( Large contiguous amount might not be free or present to allocate). 32 Bit system In 32 bit system SQL Server has VAS of 2G. If system is WOW it would have VAS of 4 G. So this becomes limitation for process which requires huge amount of continuous memory and such memory is not satisfied from buffer pool but outside buffer pool.