I believe your problem boils down to clustering time-series of different lengths. According to your question, you want the longer time-series of a power user to be considered similar to time-series of similar pattern but much shorter. Therefore you should look into clustering techniques and distance metrics which allow for these properties. I don't know your language of choice but here are some of the many packages in that you might find interesting : - Fr√©chet distance - one of the packages offering this is kmlShape - Dynamic Time Warping included in base - Permutation Distribution Clustering - package pdc This would also solve your data formatting problem as to setting values to or would not be needed anymore. hth. 

You could give the package a try. You basically code up the plot you want first with and then call at the end, which will render an interactive version of it. You get zooming in on mouse selection for example and labels of points on hover. It has a pretty extensive documentation too. I can try and help you out with a specific example if you post some code. Another cool package you can check out is . hth 

It will highly depend on the quality of the classifier though, but I think it's worth a try. hope this helps, and let us know what did you end up doing - will be interesting to hear. 

I would go for parametrised Rmarkdown reports. I think it adresses all your needs, it's simple to use and maintain, offers great flexibility, you can embed all kinds of things and it offers different output formats. 

Depending on the language of your choice, you may or may not have to normalise the data yourself - for example the package in does this automatically for you. As this is built off the 'libsvm' library, it might be that this is also the case there - the library documentation is your best source. As for the normalisation values, you should definitely use the same [min,max] values from the training set for the test set as well. Also, I would reccomend reducing the dimensionality of your data first, than normalising before running a svm. hth 

Since your question and the nice answer from @Stephan Kolassa discuss ARIMA and neural networks in particular, i wanted to mention that you can give the package in a go - it has a function that trains a simple feed forward neural network with 1 hidden layer and lagged inputs. Maybe you could try something along the lines of: 

This will eliminate at least the problem you are facing now. I am not sure if I understand the rest of the question though...as I get it, you have some other character vector called for example, and inside you are trying to look for elements of the vector and, if matched, replace them with the corresponding vector element from right? 

I believe it will help if you add the exact regex anchors to the pattern you are trying to match. In your case adding as the pattern you are trying to match will look for strings starting and ending exactly like that. That way you have: 

and predict the future values of your var of interest based on these inputs. Additionally, you could also think of including the the observed mean and variance/deviation on each given day of the value you want to predict. This would mean that you would have to first forecast your expected mean and variance with e.g. ARIMA then add that as additional input to the approach mentioned above. hth. 

I have a pipeline built which at the end outputs a bunch (thousands to tens of thousands or more) of named entities. I'd like to do aggregates on those named entities (to see, e.g. how many times a specific named entity is mentioned in my corpus). A problem that I am arriving at; however, is that the named entities often don't match up with each other even though they are the same entity. For example, one instance of the named entity might be "Dr. John Smith" while another instance is "John Smith" or one instance might be "Google" while another might be "Google Inc.". This makes aggregating quite hard to do. In order to deal with this issue and set "Dr. John Smith" to be the same entity as "John Smith", I was thinking of doing word matching between my named entities. I.e. I would check if named entity A has a word in common with named entity B and if they do set them to be the same entity. This approach is obviously seriously flawed. I will be equating "John Nguyen" and "John Smith" as the same entity even though they are obviously not. What's potentially even worse with this method though is I might run into similarity chains where I have "John Smith" linked with "Richard Smith" linked with "Richard Sporting Goods Inc." linked with "Google Inc." etc etc... While I may be willing to allow issues arising from former problem through, the latter problem appears to be catastrophic. Are there any accepted techniques in the NLP community for dealing with this issue? 

Many neural network examples you see in the literature are doing classification problems, E.g. LeNet, AlexNet, Inception, etc are all image classification problems. In this domain, it's useful for the neural network to give outputs between 0 and 1 because an output between 0 and 1 can be interpreted, in some sense, as a probability. The reason these networks output numbers between 0 and 1 is in the layer activations of the network. The last layer in these networks is usually a softmax layer (or, if you're doing just binary classification, a sigmoid layer). Softmax and sigmoid functions have the nice property that they give outputs between 0 and 1 (softmax has the added nice property that it gives outputs which sum to 1). If you want your neural net to be able to output numbers that aren't between 0 and 1, simply change your activation function. Instead of a softmax last layer, you could use a linear one. In this case, it also makes sense to change the loss function you are using to perhaps something like Mean Squared Error (binary cross entropy, for example, won't work too well on negative numbers). There's nothing stopping you from using a deep neural network to perform regression rather than classification. 

Say I'm building a neural network to fit some classifier of some sort. To make things concrete, let's take the example of predicting housing prices using features of houses. What should I do if one or two of my features consist of many more numbers than the other features, or even all other features combined? For example, say I have a few housing features: size in sqft, age, median income of location. These are 3 numbers. And then I have another feature, height of the roof for each square foot of the house (it's a bit contrived for this example of course) for which I would have actually "size in sqft"-numbers for this feature. So now my feature vector looks like this: X = [1500sqft, 34 years, $54,000, 10ft, 10.1ft, 10.3ft...1497 more numbers here...] It seems that if I just naively put this into a neural net that the first 3 features would essentially be ignored since they only account for 3/1503 features. But they might actually be important. One try might be to simply average the "height of roof" feature over all of its elements to get an "average height of the roof" feature. That makes sense for this example, but what if sometimes I don't want to take this average? Are there any industry practices on what I might try if I ran into a problem like this? 

Please note, Hadoop is not a distributed file system (as mentioned, and corrected already). Hadoop is distributed storage and processing platform. The distributed storage component of Hadoop is called the Hadoop Distributed File System (HDFS), and the distributed processing component is called MapReduce. Hadoop has now evolved slightly. They keep the HDFS part for distributed storage. But they have a new component called YARN (Yet Another Resource Negotiator), which serves to appropriate resources (CPU, RAM) for any compute task (including MapReduce). On the "overhead" part, there is noticeable overhead with starting/stopping a Java Virtual Machine (JVM) per tasks (map tasks, reduce tasks). You can specify for your MapReduce Jobs to reuse JVMs to mitigate this issue. If "overhead" is really an issue, look into Apache Spark, which is part of the Hadoop ecosystem, and they are orders of magnitude faster than MapReduce, especially for iterative algorithms. I have used Hadoop to compute pairwise comparisons (e.g. correlation matrix, similarity matrix) that are O(N^2) (n choose 2) in worst case running time complexity. Imagine computing the correlations between 16,000 variables (16,000 choose 2); Hadoop can easily process and store the results if you have the commodity resources to support the cluster. I did this using the preeminent cloud service provider (I won't name it, but you can surely guess who it is), and it cost me < $100 and under 18 hours. 

Ordinary Least Square (OLS) regression? Since you have a class imbalance, you might want to combine that with boosting algorithms. If you have a function to quantify the cost involved with FP's and FN's, use any optimization technique you can find. My favorite is genetic algorithms. You may also try linear programming. 

Data volume is not the only criterion for using Hadoop. Big Data is often characterized by the 3 V's: 

Plot a bar graph. The bar graph will clearly show jobless people are often choosing NO. Try an 1-way ANOVA test. If the p < delta (i.e. delta=0.05), try a post-hoc test (i.e. Tukey's HSD) to do a pairwise comparison. Like I said earlier, try a multiple comparison test (1-way ANOVA) first, if there is a statistically significant difference, you can try a pairwise comparison test (post-hoc test). Maybe try a clustering algorithm? Be careful, because the marginal sums (by rows or columns) are not equal. Maybe create a similarity matrix by profession? To me, it seems that Employees and Businessmen are in one group (very similar), while Workers and Jobless are each in their own group. If you turn those frequencies into proportions, then you might just have 2 groups; one for employees + workers + businessmen, and one for jobless. Use contingency table analysis to see if the responses (yes/no/don't know) are associated with profession. 

More V's than these 3 have been invented since. I suppose the V's were a catchy way to characterize what is Big Data. But as hinted, computational intensity is a perfect reason for using Hadoop (if your algorithm is computationally expensive). And, as hinted, the problem you describe is perfect for Hadoop, especially since it is embarrassingly parallel in nature. Is Hadoop a good choice for you? I would argue, yes. Why? Because 

Hadoop is open source (compared with proprietary systems which may be expensive and black boxes), your problem lends itself well to the MapReduce paradigm (embarassingly parallel, shared-nothing), Hadoop is easily scalable with commodity hardware (as opposed to specialized hardware, and you should get linear speed-up in your performance with just throwing hardware at the problem, and you can just spin a cluster as needed on cloud service providers), Hadoop allows multiple client languages (Java is only one of many supported languages), there might be a library available already to do your cross-product operation, and you're shipping compute code, not data, around the network (which you should benefit from, and as opposed to other distributed platforms where you are shipping data to compute nodes which is the bottleneck).