Well, for the first part a lot of modern games are coded in C++, which supports namespaces. Namespaces allow you to group a collection of related code within part of a whole. So you could have a collection of namespaces such as 'Render', 'Input', 'AIProcessor', etc (note: I am making these up) Building these subprojects into the main project allows all of them to be shipped without forgetting to include a DLL in the installer (imagine the controversy if a developer forgot to include a subproject DLL in the installer upon release - the game wouldn't work for the end users until the developers released a patch with the missing DLL!) Now, I only work with a small fledgling indie studio, but we have namespaces such as 'RenderEngines', 'SystemEngines', 'Interfaces', etc. in our game. Its far easier to include these in as namespaces instead of exporting them out to their own DLL, especially when I ship the next build to the team - I have enough problems with missing content files every now and then. As for DirectX, often when installing (going from watching installers) they ask if you want to install the specific version of DirectX the game was built with. This gets installed to a predefined location on your computer, and the game loads the DirectX DLL's when you run it. Even if you don't install the specific version, the DirectX install is smart enough to reference another version and use that. I have had problems previously with a game before requiring a very specific set of DirectX versions to work properly, otherwise it would crash if I started fiddling around with the graphics settings. 

As for assigning some numbers, lets assume weapon speed is between 1 (snails pace) and 10 (roadrunner) where 5=1 attack per second and 10=2. Damage ranges from 1 to 200 (because we have 'drop large rocks on head' traps), and range is between 0 and 100 (cause our maps aren't that big). Now, lets make up some numbers. 

I've added comments so you can see the changes I've made, so hopefully you can understand how the added/changed code works, but basically I've loaded each meshes Material, grabbed the diffuse color from it, and instead of setting a default color, I've converted the Assimp Color4D to XNA Color inline when creating each vertex. Again, untested, so it may or may not work. 

Open Visual Studio, and go to your server project Right mouse click on 'References' and then left click 'Add Reference' Switch to the .NET tab, and scroll down to find 'Microsoft.Xnz.Framework' Select it and then click on OK Add 'using Microsoft.Xna.Framework;' to your server class files. Use Vector, Matrix and Quaternion objects as normal. 

However, some of the paths between nodes are one way, so there may only be a shortcut back towards from that the security system can use if triggered. You can upgrade the program if you choose through the course of the game to make your hacks harder to detect (lowers security rating on nodes), allowing you to hack higher security systems, or improve the fortifying system which allows you to fortify individual nodes to slow down the security system if it detects you. You can implement something similar in you game by requiring your hacking system to have different modules/upgrades/addons that allow it to attempt to hack different computers/software. You have to somehow acquire or improve these modules in order to hack different devices and gain access to them, or allow for easier hacking. You could have a similar web, which allows you to choose the route to take - do you take the longer route with many low ranked nodes and thus more (low) chances of detection, or the shorter route with 2 higher ranked nodes (that will most likely alert the security system on one of them) to the objective? And if the security system detects and starts tracing you, do you continue to try and get that datastore like node down the dead end, or focus on capturing the system to stop the trace and possibly prevent an alarm from sounding? 

Or however it was the entities happened to be placed. You can have pools for all of the components and for entities and use the entity pool as the "master," such that collisions are checked against the entity array. But of course you get the problem of recycling components and entities. If your game design allows it, you could plan ahead where each type of entity goes so you could get the most efficient packing possible. Say entities 0-20 are reserved for tanks, entities 21-30 for houses, and 31-60 for BGTrees. You might not be able to efficiently spawn infinite baddos, and kinda defeats the dynamism of component systems, but it would solve the problem. I don't see a way to have your cake and eat it too. I was thinking about ways to maybe speed up the render pass where you have a that contains all the data that the rendering system needs so it's able to just blow through an array of these things, but then there's overhead of copying data. Also, any time you dereference a pointer you're thinking about whether or not it's still in the cache. If you want a super speedy game, I'd say plan your allocation out. If you want a flexible game architecture, roll out the hashtables and string IDs. Any time you want flexibility you need to build abstraction, and therefore will incur overhead. TL;DR; Based on what you described, I would create a higher level with pointers to and components and give it the necessary references when you initialize the entity. (Apologies for any perceived rambling, I've been thinking about this in my system as well, so this was an opportunity to think through it) 

Is this an instance of Unity hiding information to provide a simplified API? Or do standard 3D realtime collision detection techniques just not collect this information? And for the second part of the question, what's a surefire and relatively efficient way to get a surface normal for a collision? I know that raycasting gives you surface normals, but it seems I need to do several raycasts to accomplish this for all scenarios (maybe a contact point/normal combination misses the collider on the first cast, or maybe you need to do some average of all the contact points' normals to get the best result). My current method: 

Grant Kot has put some of his fluid simulation code up on Github with implementations in both javascript (canvas) and C++ with OpenFrameworks: $URL$ He has a few demos up on his youtube account: $URL$ I have no idea how it works, but I know it runs fast and there's all sorts of variations to build with it. A good keyword to search for might be "multigrid particles". 

You can effective think of these categories as all being on their own timeline. Each timeline here has a bank of sounds they can choose at random, and parameters for how frequently they trigger. Examples of parameters: 

I can't recommend any specific books on speech, but you might want to look at Festvox, CMU's open source speech synthesis library, as a starting point. Awesome idea though, if you can produce voices near the same quality as Nuance or A Capella and be indie-friendly, that would be a huge opportunity for you and a great benefit to indie devs. 

LÃ–VE isn't as a library that you import into Lua. What it does is embed the Lua interpreter and expose its game functionality to that interpreter. If you'd like to interactive play with the API, there's a couple of libraries built for debugging and live coding: 

What this does is effectively scale your update logic to move according how much time has elapsed since the last update. If you move at 1 meter/second, and you update 10 times a second, each update will move you forward 10cm. Update 20 times/second, move forward 5cm each time. This has the advantage of keeping everything moving at the same rate on different machines despite the number of updates occuring. 

You shouldn't be trying to ensure that all your updates happen after X milliseconds - the existing game loop does that already. Instead, what you should be doing is applying delta time correction to your updates to ensure your updates, no matter how frequent or infrequent, regular or irregular, all happen at the same rate. An example is as follows, and is rather simple to implement. 

Of course, this relies on the server having the Xna game studio installed on it. If you don't have the Xna framework installed on the server, you can either download and run the installer from here or search the GAC (Global Assembly Cache) on your build computer for the Microsoft.Xna.Framework.dll file, and then drop it into the bin folder of your server program when it gets deployed, but the framework installer is (IMO) the easier and safer way to go. You can also add Xna assemblies to a project without making it an Xna project, its just that an Xna project has all the Xna framework references added by default. I currently have a Form and a Class Library project using Xna references, and they still run/compile as a Forms project and a Class Library .dll 

Your basic OBJ, or Object Wavefront file only contains geometry data - vertices, normals, texture co-ords, and optionally material data in an second file. It does not contain any sort of skeletal structure or motion data. Collada on the other hand contain both geometry data and optionally skeletal structure and motion data, along with scene information (eg light sources, camera), and a texture and material atlas. Both file formats are regarded as interchange formats for transfering model data between modelling programs and to/from game SDK's. Format wise, both are a plain text file format, with the OBJ file having one entry per line, making it easy to be read a parsed. If you know what section you are reading, you can process the line appropriately. Collada has a much more complex XML based structure that is much more difficult to parse. However, due to their plain text format, and the fact they need to be processed, loading them is generally rather slow when compared to a binary optimized file format. ** In terms of writing parsers for the OBJ and Collada file formats, Wikipedia describes the format well enough that with a simple sample file you can write a loader. Collada, on the other hand, is much more complex. The best information I have found on loading Collada files is this tutorial by Wazim. A bit more information on Collada can be found on Wikipedia, mainly the links to various libraries capable of loading and parsing Collada files. There may also be a link to the spec somewhere in there as well. However, unless you want the challenge of both writing a Collada importer, and supporting it for the minor variations that different programs produce, your probably better off using a library with an established importer. ** I managed to go from a 1 minute load using raw .obj files to <1 second using a custom binary format that mapped directly to my games Scene object, not to mention the files were about 25% +/- 5% of the size of the original OBJs. I haven't done profiling on Collada yet. 

Are you using a lot of memory on textures already? If you make all your texture rect sizes uniform (rects being the slice of the texture that represents a single frame of animation) and draw them all on the same size quad, are you drawing a lot of transparent pixels to the point where it's taking too long to render a frame? (more problematic on mobiles) Are your art assets already in one format or the other? Is it easy for whoever is creating your art to do one way versus the other? 

This seems to catch everything, but all those raycasts make me queasy, and I'm not sure how to test that this works for enough cases. Is there a better way? EDIT If this really is just the way things are with 3D collision, an overview of why in the general case would be just as welcome as something specific to Unity. 

First things first: If you're targeting XBLIG and Windows desktop, you're using XACT, right? Just making sure. Unless you have a compelling reason not to, you should be using XACT. It's got warts, but it solves too many problems for it not be used. That is, unless you're looking to also compile with MonoGame or deploy to Windows Phone. Then it's not so useful. 

With XNA you have two approaches: mix your own filters as Bjorn describes in his answer with (it's fun, try it :) ). The other option is XACT Variables. Watch this video to see somebody use XACT variables to dynamically change an engine sound over time using pitch. To accomplish what you want, do something similar, but use it to adjust the parameters of a low pass filter (XACT should have it built in). You can adjust the variables via and . See the MSDN docs for more info. Unfortunately, Microsoft has retired XACT, so all the detailed documentation on the tool has disappeared. But there are still blog posts and videos like the one I linked that can show you how to get stuff done. 

Retains the structure and static typing of Java, but offers less verbose syntax and to option for more dynamic typing and, if you care to get into it, functional programming like you'd get with Ruby blocks. You obviously wouldn't want to throw lambdas around in your game loop, but shader programming has functional characteristics so the learning is still valuable and relevant. And you can import Java libraries and thus use JMonkey, Slick2D, or whatever you need. It also has a REPL, which I think would be a hugely beneficial educational tool and reason to go with something like Python, Ruby, or Scala. 

There's a lot of different directions you could go with this. What kind of game are you making, and what does type Mob represent? It sounds like you need to separate your concerns more. 

Look at the command line tool for ImageMagick. It allows you to do batch processing on images, including transforms such as rotation. It's also useful for generating simple spritesheets (not the "packed" kind, but the kind where each the image is cut up into frames of equal width and height). 

The wording of your question suggests a misunderstanding of how Unity works (please correct me if I'm wrong), so I'm going to recommend you just try out Unity. "Unity3D scripts" are just .NET classes that inherit from or . There's nothing stopping you from writing freestanding C# classes or pulling in .NET libraries (assuming they are compatible with Unity's version of Mono, which seems to cover the important parts of .NET 3.5). Whenever you create a dependency on something not included by default in a Unity release deployment (ie: ) Unity sees your statement, sees what members of that namespace you use and automatically bundles in the correct assemblies from the standard Mono distribution that it includes (you can also drop in your own .NET DLLs). So long as any third party .NET code works in the .NET 3.5 subset that Unity's version of Mono supports, you can use it. Be wary of libraries that provide too much abstraction, though, or at least use them sparingly. This is game development, not enterprise software. We do some dynamic scene construction in our Unity project, and all of the data for that is handled in pure C#, no namespace references except for where it wouldn't make sense to re-implement a data type that Unity already has (ie: ). We reference and could use JSON.NET if we wanted (but that lib's a little fat, so we use LitJSON instead).