The qualifier specified which attribute the comes from. Fragment shader outputs have the same concept. Each output goes to a location; if you don't explicitly specify the location, then the shader will arbitrarily assign them. And no, the shader is not required to start from zero and assign them sequentially. So you should use the same syntax in your fragment shader. You set up your draw buffers like this: 

Well, look at the Quake system. In Quake, you have 3 different kinds of armor: Green, Yellow, and Red. With Green armor, the armor absorbs 1 point of damage for every point of damage the player takes. In that way, it acts like doubling health. However, consider the complexities of that situation. If you have 10 health, and you pick up a 100 health powerup, you go back up to full 100 health. However, if you pick up 100 Green armor, you now effectively have... 20 health. Remember: you die when you run out of health, not armor. Point #1: It can reward you for maintaining a state of high health. Consider the same situation: you have 10 health. You come across 100 health, and then you come across a 50 health pickup. You still have 100 health. Joy. However, if you have 10 health and come across 100 Green armor, and later get a 50 health pickup, you now have effectively 120 health. Point #2: It provides a way of breaking the health cap, while still allowing the cap to exist and matter. Now look at the Red armor. For every 6 damage you take, 5 goes to the Red armor, and 1 to you. Red armor comes in lots of 200. Even if you are at 10 health, you effectively have 60. Point #3: Different grades of armor allow for different qualities of effects. Some can provide more of a reward in certain situations, while others are more situational rewards. Thus leading into: Point #4: It allows you to provide more rewards for player exploration. It's a different kind of reward from health, weapons, ammo, and other powerups. Remember: Quake is not a modern-style hyper-linear FPS. It's more of an adventure game where you shoot people. Rewarding exploration is important, so you need a good set of viable powerups of different qualities. Armor is merely another quality to choose from. This is why modern FPS games don't use it. They don't need it, since they're very linear games. 

There is one piece of information that I'd like to add: when documenting the actual design of the game (ie: the rules), provide clear explanations for why you're making a particular rule design choice. One of the things you're more likely to forget when you go about implementing something is the exact reason why you added a particular rule. Also, one of the things you're very likely to do is to add rules and game elements just because other games have them, not because your game needs them. By adding a section on exactly why a game element exists, it forces you to justify the use of that element in terms of the overall game design. And later on, it allows you to effectively evaluate whether a particular element is actually serving the needs you intended it to. If it's not, then you can remove it and replace it with something else that does serve those needs. Even better, if you find the game isn't working out, and you want to replace multiple elements to make the game more fun, you can look back at your design document and understand why you choose those elements and what new elements need to accomplish. If the needs of your game design change, then you can update your list of what the game elements are supposed to do. 

You want to make the texture smaller so that it takes up less memory on the GPU. You want to make the texture smaller so that it takes less time to load/requires less harddrive space, resulting in a smaller download. 

This way, isn't responsible for finding places to put stuff. You have functions for that. Nor does it have to have knowledge of or other types; that's all taken care of elsewhere. 

The biggest advantage to a Lua-script based approach is that... it's Lua. While it can be pure data, it does not have to be. So if you have some repetitions of stat blocks, you can easily have the Lua script generate these data for you. All this is is a Lua script that returns a table; the table is what you read into your in-memory data structures. The disadvantage to this approach is mainly if you are not using a tool to write these files. If you have a tool that you use to edit these enemy files, then the Lua approach is fine. But if you're hand-editing them, then that means your loading code that walks the Lua table needs to verify the input. It needs to check that the necessary fields are there, that each number value is a valid number, etc. And while that's not exactly difficult code to write, it is exceedingly tedious. The advantage with XML is that you can validate it with a RelaxNG or WXS schema. There are even XML editors that have schema-guided editing, so that it becomes impossible to write an invalid XML file. If you need to add a new field, just adjust your schema, and you're fine. If you change the file structure, again, adjust your schema and revalidate the files, correcting errors where they appear. You can even write an XSLT tool to automatically convert files from one format version to another. Of course, you have to know how to write schemas, and you have to have a schema-driven XML format. Otherwise, the Lua script will be no worse off, since you have to validate the data either way. And the Lua script is arguably easier to parse through, since it allows you to query the data directly. Given a Lua table that contains an enemy definition, you can query for specific "elements" by name. With an XML parser, you have to process the elements as they come to you, which is generally a bit more complex to write. 

My tutorial on impostors has an example of using core geometry shaders. GS's aren't really the most useful things in the world, so it's hard to find legitimate examples. Indeed, the only future tutorial I have planned that uses them is for layered rendering for things like rendering to cube-maps. 

This is just me personally, but I don't like difficulty levels. The pacing of the game, the change from level to level, area to area, challenge to challenge, is the most important part of the game. That pacing changes when you just arbitrarily decide that skill level X will have fewer monsters or less mechanics or whatever. This makes the increase in challenge of the game over time less deliberate. And worst of all, since you're clearly designing the game to play best at the normal difficulty level, the people playing at reduced difficulty are going to have a sub-optimal gaming experience. You can't just yank out mechanics and expect everything to play fine for them. Either the game is going to be too easy, too hard, or too inconsistent in its difficulty. 

I would go so far as to say that this doesn't constitute a GUI library. It's just a bunch of rendering functions. Rendering the GUI is the easiest part of making a GUI. Take a text box for example. I'm going to assume the easiest possible case: a simple single-line entry text box. will just draw a text box. It will do some simple text measurement and draw the glyphs on the screen. It will not 

What is your purpose in compressing these images? There are generally two reasons to compress a texture: 

The number of textures that can be bound to OpenGL is not 32 or 16. It is not what you get with . That function retrieves the number of textures that can be accessed by the fragment shader. See, each shader has its own limit of the number of textures it can use. However, there is also a total number of textures that can be used, period. This is defined (in OpenGL) by . So there are two limits: the textures-per-stage, and the textures-total-bound. OpenGL 3.x defines the minimum number for the per-stage limit to be 16, so hardware cannot have fewer than 16 textures-per-stage. It can have a higher limit, but you know you get at least 16. 3.x defines the minimum number for the textures-total-bound as 48. AKA: 16 * 3 stages. Similarly, GL 4.x defines the numbers to be 16 textures-per-stage, and 96 textures-total-bound (ie: 16 * 6 stages, including compute shaders). Again, these are the minimum numbers. Hardware can (and does) vary. As for specific hardware, you can expect any DX10-class hardware to match these numbers. DX11 class hardware has some variance; NVIDIA (GeForce 4xx+) and higher-end AMD chips (aka: GCN-cores) may have more than the 16-per-stage.