EDIT (Aug 22, 2011): I am further simplifying the question and putting a bounty on the question. Perhaps this simpler question will have an easy answer. I'm also going to strikethrough all the parts of the original question that are no longer relevant. (Thanks to Stasys Jukna and Ryan O'Donnell for partially answering the original question!) 

On the other hand, if you're interested in the standard classical PAC model only, using quantum computing as a post-processing tool (i.e., no quantum samples), then Servedio and Gortler [1] observed that there is a concept class due to Kearns and Valiant that cannot be classically PAC learnt assuming the hardness of factoring Blum integers, but can be quantumly PAC learnt using Shor's algorithm. The situation for Angluin's model of exact learning through membership queries is somewhat similar. Quantum queries can only give a polynomial speedup in terms of query complexity. However, there is an exponential speedup in time complexity assuming the existence of one-way functions [1]. I have no idea about the second question. I'd be happy to hear more about that too. 

This is the communication problem for which both papers you linked to prove a sign rank lower bound. If you look at Corollary 1.1, they're talking about this function, not the Minsky-Papert DNF. Note that any communication problem can be represented as a matrix, by having $x$ index rows and $y$ index columns. The papers prove lower bounds on the sign rank of this matrix for the above communication problem. (Rank and sign rank being measures that make sense for matrices.) What Minsky and Papert showed was a sign degree (or threshold degree) lower bound on the Minsky-Papert DNF. Degree (and sign degree) are measures of Boolean functions. 

Boolean Function Complexity: Advances and Frontiers by Stasys Jukna. (Preface) (Table of Contents) A free draft used to be available as a direct download a while ago (if I remember correctly), but now it seems you can obtain it by filling out a form on his webpage or emailing him. 

The problem is defined on page 5 of the arxiv version. Additionally, they also define a similar problem that is $\text{QMA}_\text{EXP}$-complete, which is the bounded-error quantum analog of $\text{NEXP}$. (The classical bounded error analog of $\text{NEXP}$ is $\text{MA}_\text{EXP}$.) 

Both surveys do a great job of explaining the formulation within the first few pages. In Wagner's survey, he says "it turns out that practically every complexity class considered so far can be described by leaf languages." My question relates to this statement. I know there are some classes for which we do not know a leaf language characterization, so this means either the classes don't necessarily have such a characterization, or we haven't found it. Do we expect every complexity class (say between P and PSPACE) to have a leaf language characterization? (Let's restrict ourselves to "natural" complexity classes.) Is there any result of this sort in the literature? (A related question that I'd be happy to know the answer to: Is there a (heuristic) method to come up with a leaf language for a given class?) 

Reposting my comment: From a quick look, it seems like your question should be answered by "Manindra Agrawal, Eric Allender, Steven Rudich, Reductions in Circuit Complexity: An Isomorphism Theorem and a Gap Theorem, JCSS 57: 127-143, 1999." They say "we prove that all sets complete for NP under AC0 reductions are complete under reductions that are computable via depth two AC0 circuits." But I may be missing something. 

What I know: The best such characterization I have found is in this paper by Servedio and Gortler, using a parameter they attribute to Bshouty, Cleve, Gavald√†, Kannan and Tamon. They define a combinatorial parameter called $\gamma^C$, where $C$ is the concept class, which has the following properties. (Let $Q_C$ be the optimal number of queries needed to learn $C$ in this model.) 

Moving on to time complexity, using the same quantum PAC model, Bshouty and Jackson showed that DNFs can be quantum PAC learnt in polynomial time over the uniform distribution [4], further improved in [5]. The best known classical algorithm for this runs in $O(n^{\log n})$ time. Atici and Servedio [6] also show improved results for learning and testing juntas. 

Obviously any decision problem that can be reduced to factoring can be solved with a factoring oracle. But since we're given the ability to make multiple queries, I tried to think of a non-trivial problem for which one would want to make multiple queries. The problem of computing the Euler totient function seems like such a problem. I don't know how to solve the decision version of this problem by a Karp-reduction to the decision version of factoring. But with Turing reductions, it's easy to reduce this to factoring. 

I'm going to try to make the question more precise, and then answer it. (My version might not be what you had in mind though, so let me know if it isn't.) We have a deterministic TM with access to a random number generator. This TM now computes some function (an actual function, i.e., a deterministic map from an input space to an output space) making use of the random number generator in some way. So is the TM with access to randomness allowed to make error? If not, then the DTM must give the correct answer no matter what random bits it was supplied. In this case the random bits are unnecessary, as you could just take the random string to be 00000... If the DTM is allowed to make error, but should get the right answer more often than random guessing, then we can still do without the randomness source. This DTM computes the function $f_i(x,r)$, where x is the input, r is the random string it got from the oracle, and the $f_i$s are the bits of the output. The DTM can now loop over all possible strings $r$ and see what the majority output is, and output that. 

Leaf languages are a beautiful way to uniformly define many complexity classes. Most complexity classes are usually specified by a model of computation (e.g., deterministic/randomized TM), and a resource bound (log time, poly space, etc.). However in the leaf language formulation, there is only one model of computation, and the class is specified by giving its leaf language. The details are too long to explain, so I'll direct interested readers to either of these two surveys: 

A monotone CNF formula with m terms on n variables ($x_1,\ldots,x_n$) is a formula of the form $f(x_1,\ldots,x_n) = \bigwedge C_i$, where each $C_i$ is an OR of some subset of the variables $x_1,\ldots,x_n$, and $i$ ranges from $1$ to $m$. For example, $(x_1 \vee x_3 \vee x_4) \wedge (x_2 \vee x_4)$ is a monotone CNF formula with 2 terms on 4 variables. I'm looking for the shortest formula (not necessarily monotone, not necessarily CNF, any formula will do!) on the same set of variables that represents the same function as a given monotone CNF formula on n variables with n terms. (Note that the number of terms and variables is the same.) One obvious way to construct a formula is to expand out the given CNF definition, which will give us a formula of size $O(n^2)$. (Let's define the size of a formula to be the length of the formula when it is written down as a string.) I want to know if this is the most efficient general construction or if for every n-term monotone CNF there exists a formula of size $o(n^2)$. I just want to know whether this is possible, I'm not really interested in an algorithm. If this is not possible, a function that serves as a counterexample would be great. Pointers to where I can find an answer in the literature are also appreciated. EDIT: I'm adding an example to make thins clearer. Say the input formula is $f = (x_1 \vee x_2) \wedge (x_1 \vee x_3) \wedge \ldots \wedge (x_1 \vee x_n)$. This is a monotone CNF formula. A shorter formula which represents the same function is the following: $x_1 \vee (x_2 \wedge x_3 \wedge \ldots \wedge x_n)$.