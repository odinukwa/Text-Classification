There are two sets of gibberish: and . The former is passed to the function and this is the only place it's used. The latter is used in the function and that's the only place it's used. Both are decoded by the function. So: they're base-128 encoded strings which store font and image data. Source: CTRL+F plus following the variable and function names. 

There are no "tileset systems." The only generic solution games pick up is how tilesets work on a basic level. Here's how tilesets work: 

All the black space: Some saved kilobytes. Each region is a small world in itself. To pass between regions, a region transition would say "go to region X, coordinates (X,Y)." Since your regions have no particular arrangement in space, put them in a 1D array. 

I know beggars can't always be choosers, but I'm hoping there's something high quality out there. If there isn't, maybe someone would like to jump on that opportunity and fill the void. 

If you serialise an object then change its class's definition, you will not be able to recreate that object, meaning changes to your game will invalidate past saves. So whilst serialisation is definitely the simplest method, it has this flaw. A more robust method for a game that will be changed is a manual sort of serialisation where you determine what variables are important to save, and save them - and when you recreate your objects, create them with those variables. The end result is you don't depend on serialisation, and changes to your class definitions do not invalidate past serialised data, allowing changes to your game to operate on old saves. 

People who build in Unity or UDK have immediate access to a 3D level editor. People who build their games in XNA or from scratch have no such thing. I'm looking for 3D level development tools available to these people. 

You didn't say in what way it's not working (is it crashing, or taking forever?). You ought to do that. However, it strikes me as immediately absurd that your recursive flood fill has a loop. You could either write a loop to fill everything (which wouldn't be a flood fill), or you could write a recursive flood fill: 

If the entire model uses only one texture, theoretically you can set that texture and draw the model's vertex buffer and index buffer in one call, since the entire model is stored in a single vertex and index buffer. Except, when you load the model the indexes for various mesh parts will not be relative the vertex buffer as a whole, but rather the mesh part's vertex offset, making that impossible for no good reason. So to draw the entire model in one draw call you will have to create a new index buffer with corrected indexes. 

This is very possible. You can use a custom shader with spritebatch. The source to the default spritebatch shader is available from the XNA 'education catalog'. What you will need to do is get this shader and change the texture filtering in the shader from linear to point filtering, and then use your new version of the shader with spritebatch. To use it with spritebatch, call spritebatch.Begin, but set the sprite sort mode to immediate (This effectively means no batching). Then, apply the correct technique on your new effect. Then draw your sprites. Spritebatch will draw them immediately with whatever effect is currently applied. IIRC using a custom shader with spritebatch is far simpler in XNA 4.0. 

Sprite batch is implemented with 'camera-facing polygons with Z set to zero'. IIRC it even has rotation, and if it doesn't, you can supply your own transformation matrix. Your choices are equivalent. Ask yourself how much work you want to do duplicating spritebatch instead. 

To do this in XNA, you will need to use a shader. You will need to render your scene to a texture (Or, render just the portion the cursor covers), and then draw the cursor using that texture and a shader that inverts the color. Unless you've already got a deferred renderer, this will probably be more hassle than it's worth. If you do, you can use the existing depth/color buffers, and re-shade the pixels covered by the cursor in your color-inverting shader. 

There's a better and simpler way to find the closest block under the 'mouse'. XNA provides a ray and an AABB type, and the function Ray.Intersects. Intersects returns the distance to the intersection or null, if there was none. You can test the blocks that may be under the 'mouse/reticle' and pick whichever block is closest. Obviously, checking every block would be terribly in-efficient. You can use a simple tree of bounding boxes to narrow the search down to individual blocks. Here is some code I ripped out a project of mine that does exactly this. In this example, imagine that 'prism' represents a rectangular prism of blocks, and Prism.Split splits the prism on it's longest axis, unless it's smaller than a threshold, in which case it returns false. 

I agree with Petr: There is no set way to do it. How you want to do it is a matter of how you want to design your game. In this circumstance, however, I think it's immediately obvious the sort of mechanic you're trying to get at: you just want things to produce as fast as possible, within the amount of mass you have available. Producing within capacity I'm going to take a leaf out of Supreme Commander's book, since you're doing a system very much like theirs: If you're producing above capacity, the neatest way to deal with it is have production slow down across the board. Lowering production capacity is actually pretty simple. A production speed mechanic Each update step, your factories don't just produce a set amount: they operate by a production speed, which determines how much progress they make in each step and how much mass they use up. When you're producing at 75% capacity, your factories make 75% as much progress each step and use up 75% the mass compared to 100% capacity. To calculate the production speed, before building anything at all, you should query your factories to determine the total resources that would be used this step at full capacity. Then you perform a simple calculation: 

Tetrad covered general intersection in his post. Here I'll cover an algorithm that returns the specific points of intersection based on the formulae in this concise article. I'm matching my variable names to those in the article, so keep this diagram in mind - and probably in view too! 2 $URL$ The language is Python. You can verify your results in Wolfram Alpha by running a query to determine the intersection of two circles like this: 

returns the string from position 1 (i.e. after the first character) to its end, which in this case ends up as something like . Here's how you stop getting your error: don't do that. If you meant to just take the first digit, use: 

A book on video game geometry is probably not going to help your brother much. It will talk about mathematics topics used in video games, not necessarily those covered in his curriculum, and may entirely skip over certain things he needs to know to pass his subjects. Plus, just because it's related to video games doesn't mean it's going to be fun - it's a maths book either way. Have you tried pointing your brother to Khan Academy? It's a free (as in Wikipedia) library of lectures which cover, among other things, almost every topic in the American curriculum including geometry. They're short and explained in a way that's quite easy to understand. If your brother is struggling because he doesn't quite understand how to do things, rest assured he'll be able to learn from Khan Academy. 

If it's in the vertex shader's input structure the shader needs it in the vertex stream, whether you use it or not. XNA is enforcing that. You're implementing optional texturing improperly. If you do it this way, you'll need to supply texture coordinates always. Also, branching is still to be avoided. Instead, have two techniques, referencing two different vertex shaders, with two different input structures. One input structure has texture coordinates, the other does not. Then, choose the correct technique for drawing. You don't need to have a 'texture enabled' constant in your shader at all. 

In all of your examples, there is a terrible problem. The health component needs to know about every component type that might need to respond to the entity dieing. Therefore, none of your scenarios are appropriate. Your entity has a health component. It has an animation component. Neither depend on or know about the other. They communicate through a messaging system. When the health component detects that the entity has 'died', it sends an 'I died' message. It is the responsibility of the animation component to respond to this message by playing the appropriate animation. The health component doesn't send the message directly to the animation component. Maybe it broadcasts it to every component in that entity, maybe to the entire system; maybe the animation component needs to let the messaging system know that it's interested in 'I died' messages. There are many ways to implement the messaging system. However you implement it, the point is that the health component and the animation component never need to know or care if the other is present, and adding new components will never require modifying existing ones to send them appropriate messages. 

This will call the action passed in for every block coordinate that intersects the ray. You should be able to figure out how to make it choose the block closest to the camera. Another solution is to use a raycasting algorithm, but I'll let someone else write that one up. 

It looks like you're drawing your skysphere after your HUD. You should draw the skysphere after drawing the world (the depth buffer will save you a lot of overdraw), and draw the hud last. 

You modify the original and overwrite it. Then you modify based not on the original but the modified . Then you modify based on the modified version of both of those. Preserve the originals, and calculate this: 

My XNA game is component-oriented, and has various components for position, physics representation, rendering, etc, all of which extend a base class. The player and enemies also have controllers which are currently defined in C#. I'd like to turn them into Python scripts via IronPython (a .NET implementation of Python). My problem is that I'm not sure how to interact with those scripts. The examples in Embedding IronPython in a C# Application suggest I'd have to create something like a Script component which compiles a Python script and calls the controller's Update method via Python - essentially, it'd be a wrapper class for C# to interface with Python. I feel that I'm missing something in my research. There must be a way to load up a script, instantiate a Python object (either in the Python script or in C#) and then then have a direct reference to that Python object in my C# code. Is there a way to work with an IronPython object directly, or is a wrapper required? 

But basically... no, you're limited to those options, and none of them are inherently 'superior' options. That said, why do you need to make a browser-based game? If you're just learning to program in a new language, make a simple program, then make a simple game, then make an actual game that could even be an independent EXE. Just because you've been developing for the web for the past two years doesn't mean you have to continue developing for the web. 

In my game, I'd like my character to be able to grab and hold onto ledges, and to be able to pull themselves up if there's room to do so. How do I detect if there's a ledge, and if the character has enough space to climb up? 

where for each of the two circles, h = the x-coordinate of the centre of the circle, k = the y-coordinate, and r is the radius.