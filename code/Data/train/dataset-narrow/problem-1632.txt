You have to delete the entire "xampp/htdocs" folder (well, only what's inside it). Can you post your "error.log" file please? This is my configuration: 

Why not make all the SSL on port 443 and use vHosts to use multiple domains? You're trying to do that, but you're overlooking it. Try this: 

In windows, I think if "domain.com" is mapped to localhost, it is independent from sub.domain.com. You need to specify every single subdomain in the hosts file for it to work. 

Just be sure to uncomment mod_proxy and its reverse from the apache modules section of the config. And change the 127.0.0.1:port to the port and local IP of the "game boxes" And for the port thing, all of these requests are served on the external IP/port of the apache server. If you are trying to serve non-HTTP requests (a real game server) then you are better off using a NAT or DNS load balancer for this, and the client should connect to the default port. (Example: connecting to a minecraft server at mc.domain.com with no port specified, assumes port 25565. Http traffic assumes port 80, ssl is 443, etc.) 

If your PDF files are mainly text based (few to no images) and your server has a lot of traffic accessing the same document and can handle the compressing , then yes, mod_deflate or mod_gzip is a good idea. If you're unsure, try it out first, and if the performance goes down, just undo it. I've been serving all content except images and video with mod_deflate for over a year now, and it's cut my bandwidth to under half (Lots of text documents and scripts). Also consider looking into a cache system if not already, as this will really reduce the workload on the server. 

What I generally do is seperate static content and process it in another location directive. Something like: 

So, to sum up my question, how would you guys go about virtualising x86_64 guests on an Itanium server? 

I personally prefer using process accounting for this kind of activity monitoring. It is also the one that is the most similar to what you are looking for (commands summary, login summary...). 

Also, it should be noted that if an account is locked due to too many authentication attemps, you won't see that in /etc/shadow. You can find out the failed logins count of an account with 

Infrastructures.org has a good checklist of best practices and general guidelines. The information looks a little bit outdated, but most of the things they suggest are still to be considered when setting up a large data center environment. Some of the topics covered: 

If you really want to use , you need to first select a window with , but be aware this configuration does not configure logging for all windows... 

Of course, this is some really basic usage. Read the manual or online how-tos to get more advanced usage. Here's a little how-to about reliable forwarding with rsyslog. To tell your servers to receive logs: 

We have a spare Integrity blade (2x Tukwila quad-core + 16Gb RAM) laying around which I would like to use has a Virtual Host for a couple of Linux VMs. I am having some concerns finding the best solutions for our situation (if a solution is possible at all?). Here's what I'm dealing with: 

Use Process accounting Write a shell wrapper based on script or similar and make it the default shell Or use snoopy which uses LD_PRELOAD to wrap around exec system calls and logs it to syslog 

This means, wherever the virtual host's files are taken from (root directory) you should put that specific favicon.ico file. 

Maybe this would help? $URL$ or this: $URL$ EDIT: And .htaccess files are supported by most server types. Well, any server if they are configured to look for them. 

You can't do that without vHosting. If you can wait till 4pm eastern, I'll give you the code to do so. I'm not around my server now. 

The error log can display notifications as well. Does the intended task actually work as you want it to, even with this message? For example, Apache says stuff like "Apache started on port 80" and "starting child threads" and such. Not a big deal, since it's only notifying you. 

I'm sure a once-a-week benchmarking and error checking will suffice in "burning in" hard drives. Though since your post I've never heard of such a thing. Quoted from "6_6_6" on Stroagereview.com 

In a business sense, and if there a lot of users, first initial then last name. Not dots. jkerry or gbush or bobama or such. 

Try that. You'll need to put it in each article folder in a .htaccess file, since each article folder has a different URL. 

You could just install it with Xen without changing the ISO, then edit the files you need after it's installed, then make a clonezilla image for future use. 

Did you install SQL secondhand, (with XAMPP or something?) And if not, and it was the official installer, make sure you GOT ALL OF THE files and not just program data. You really do need everything. I hope you still have the original files. 

Version Control Gold Server Directory/Authentication Servers Network File Servers Configuration/Application management Monitoring ... 

Right now, I've thought about dd, cp and rsync, but I'm not sure on the best one to use and the best way to use them... 

I'm looking to transfer data across 2 lv of an HP-UX server. I have a couple of those transfers to do, some of which are mostly binary (Oracle tablespace...) and some others are more text files (logs...). Used data size of the volumes is between 100Gb and 1Tb. Also, I will be changing the block size from 1K to 8K on some of these partitions... Things I'm looking for: 

I have a mounted NTFS partition under Windows (2003) and Linux (RHEL 5.7) at the same time. The LUN resides on SAN and is presented to both servers at the same time. At first, the setup looks ok as I initially can see files from both Windows and Linux. Writes are only initiated from Windows and I mounted the partition under Linux with read only (ro) and no access time (noatime) options. But when I add files from Windows, I can't see them under Linux. Is there anything I'm missing? Is it even possible at all? I would like to achieve this in order to avoid copying from the network for a data migration of > 1Tb. Do you see any other way to do it? 

When adding a new drive, it took over /dev/sda1. Now my old drive is /dev/sda2 and it messes with the current fstab setup of the server. I know I can get away with using UUID or labels (what I just did), but I would still prefer having the primary drive take /dev/sda1... So, how do I force a disk to take a particular device number? 

What are you actually trying to accomplish? You probbably don't want to edit a script which was installed by the system, but you might want to create a wrapper. Assuming you are overriding , move it to (maybe using diversions if you are on a Debian-based distro) and write a new something like 

What you are asking about is fairly tricky to do in Procmail. There is no facility for looping over a set of matches. A somewhat desperate workaround would be to collect the matches into a variable, then to a different recipe file which will process one value from the beginning of the variable, then to itself again while there are values left in the variable. It doesn't have to be very complicated but it's decidedly hackish, to the point where you have to ask if Procmail is really the right tool for the job. Of course, there is also the brute-force option; create a sequence of recipes to handle each possible 60xx pattern. 

As is customary in Procmail recipes, the whitespace inside the square brackets should consist of a space and a tab (both places where the Return-Path header is being matched. I could not write literal tabs from the mobile device I'm typing on). 

I speculate that the first 122 processes are consumed by Bash itself, and that the remaining governs how many concurrent processes I am allowed to have. The documentation is not very clear on this. Am I missing something? More importantly, for a real-world deployment, how can I know what sort of is realistic? It's a long-running daemon which spawns worker threads on demand, and reaps them when the load decreases. I've had it spin the server to its death a few times. The most important limit is probably memory, which I have now limited to 200M per process, but I'd like to figure out how I can enforce a limit on the number of children (the program does allow me to configure a maximum, but how do I know there are no bugs in that part of the code?)