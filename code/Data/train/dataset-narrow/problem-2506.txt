By your constraints, we also have the stronger opposite relation: if POSITION-COMPLEXITY is in a class $C$, then so is MOVE-COMPLEXITY, since it suffices to test the finite number of available moves. (I assumed by "finite" you meant "constant", if it is arbitrary then the complexity might change). Then it suffices to look at some natural games where POSITION-COMPLEXITY is asymmetric. We will always need some asymmetry between the players to create such situations, but hopefully it will be as natural as possible. In my opinion partial observation games are a good example of this: they are played on finite arena, and one player knows the current vertex at all times while the other only knows in which group the current vertex is (they are arbitrarily grouped together). The most classical example of this is parity games, where the number of moves is infinite. There the POSITION-complexity is EXPTIME-complete for the partial player versus linear/quadratic/NP$\cap$coNP for the full player, depending on the complexity of the winning condition. See here for a reference on the subject. I think from this we can design a game played in finite time where one player has partial observation, and the other full observation, and the POSITION-complexity as well as MOVE-complexity are very different. Natural try is partitioning vertices in $P_1$ and $P_2$ and setting the winning condition to "play $p(n)$ moves, Player $i$ wins if we end in partition $P_i$". 

By simplification I understand either minimization or determinization. I'll try to sum up what I know about both problems, in the quite general setting of weighted automata over arbitrary semiring. The original works were done by Marcel-Paul Schützenberger (who introduced them), and you'll find a nice account of what is known about them in the book Elements of Automata Theory by Jacques Sakarovitch (also available in French): For shorter explanations, check out the lecture notes by Jacques Sakarovitch again: For both minimization and determinization (called "sequentialization") there are nice theoretical answers. For instance, every weighted automaton over a field can be minimized in polynomial time (see for instance this lecture note). 

The Generalized star-height problem : "how many nesting of Kleene stars do I need to represent this regular language, with a regular expression with complementation allowed ?" We don't even know if the algorithm that always returns 1 (except 0 for star-free languages, which is a decidable case) is correct. 

The volume of a unit sphere of dimension $n$ first grows as $n$ grows ($2,\pi,4\pi/3,\dots$) but starts decreasing for $n=6$ and eventually converges to $0$ as $n\to\infty$. 

To complete the other answers: I think that Turing Machine are a better abstraction of what computers do than finite automata. Indeed, the main difference between the two models is that with finite automata, we expect to treat data that is bigger than the state space, and Turing Machine are a model for the other way around (state space >> data) by making the state space infinite. This infinity can be perceived as an abstraction of "very big in front of the size of the data". When writing a computer program, you try to save space for efficiency, but you generally assume that you won't be limited by the total amount of space on the computer. That is part of the reason why Turing Machines are a better abstraction of computers than finite automata. 

I am curious to know when open problems have been solved by expressing them in a specific logic, and then showing that this logic is decidable. I have two distinct cases in mind: 

The run can also continue forever... As for non-deterministic Turing machines, the input is accepted if there is an accepting run. It is easy to simulate this machine with a non-deterministic TM, thanks to the existence of the bound $N$ (which is a parameter of the whole model). Conjecture: For $N$ big enough (probably no more than $10$ to get the necessary gadgets), this model is Turing-complete. 

Is there somewhere where the main intuitions for proving graph minor theorem are given, without going too much into the details? I know the proof is long and difficult, but surely there must be key ideas that can be communicated in an easier way. Are there other relations on graphs that can be shown to be well quasi-orders, maybe in a simpler way than for the minor relation? (obviously I am not interested in trivial results here, like comparing sizes). Directed graphs are also in the scope of the question. 

Is there an example of a language which is in $NP$, but where we cannot prove this fact directly by showing that there exists a polynomial witness for membership in this language? Instead, the fact that the language is in $NP$ would be proven by reducing it to another language in $NP$, where the link between the two is not trivial and needs careful analysis. More generally, are there some interesting examples of problems in $NP$ so that it is hard to see that they are in $NP$? A semi-answer would be the problem of deciding the winner in parity games: to show that it is in $NP$ (even $NP\cap coNP$), we need the positional determinacy theorem which is deep and non-trivial. However this answer is not ideal, because it still boils down to the existence of a polynomial witness for this exact problem (the positional strategy), and does not reduce to another different $NP$-problem. Another one would be the AKS primality algorithm: deciding whether a number is prime is polynomial, while there is a priori no small witness for this fact. Let's say we rule out the "surprising polynomial algorithms", since many of them would fit the description above. I'm more interested in surprising $NP$ algorithms which are not deterministic. 

For the possible reduction you are mentioning, if you find such a reduction from SAT to this particular edge-coloring problem, and additionnally you assume OC, then it would indeed mean NP $=$ co-NP. However, it would be very surprising: it would mean that basically, up to encoding, you found a way to always provide a short certificate that a formula is not satisfiable. This seems quite unlikely to reach with a simple construction. 

To account for your additional requirement of a nondeterministic universe, another way to go would be arbitrary precision information about physical constants. For instance the code of a Turing Machine which computes gravitational constant $G$ (in $m^3·kg^{−1}·s^{−2}$) with arbitrary precision. It would be indeed surprising that such a machine exists, but assume we get one with this guarantee written on it. At the beginning we would just be able to test that the machine matches the current precision on $G$, which is nothing extraordinary. But as technology advances and measurements gets finer and finer, we would be convinced with increasingly high precision that the machine indeed computes $G$.Therefore, assuming scientific progress goes on, we could reach arbitrary precision on the accuracy of the machine, and on the fact that it is "supernatural", because at least as advanced as any level of knowledge we can achieve. This assumes we are never able to prove that the machine computes $G$, which is based on the assumption that there is no computational link between physical constants (here $G$, and the various constants used to define unities, like the speed of light $c$). This assumption is reasonable in the current state of knowledge, but we never know... 

Not exactly a paper, but I think in the spirit of your question you'll appreciate JofUR: Journal of Universal Rejection. Their website include numerous reasons why you should submit there, detailed instructions for authors, and interesting proceedings. 

Intermediate problems between P and NP are quite famous, and are sometimes considered as complexity classes by themselves. Do you know of any problem that is known to be PSPACE-hard and in EXPTIME, and resisting all efforts to be proved complete for one of these classes ? Lifted (succinct) versions of problems between LOGSPACE and PTIME are accepted, but even more interesting would be problems that are not of this form. Here are some I found, this area of complexity theory seems to be the realm of games: 

For each letter, count in how many of the targets it appears. Let $a$ be the letter appearing in the maximal number of targets. Add $a$ to all partial products that point at one of these targets, producing new partial products. If some target containing $a$ was not marked by any partial product, create a new partial product with $a$. Update targets containing $a$ by removing one occurrence of it. Update the marking of the partial products. 

For inclusion, using your condition that non-final states can be mapped to final states does not work. Consider for instance that $A$ is a rejecting sink $p_0$, and $B$ is the minimal automaton for any non-trivial language with a transition $q_0\to q$. Then no such morphism can exist, because we must have $h(p_0)=q_0$, but also $h(p_0)=q$ because of the second condition, although $L(A)\subseteq L(B)$. If you add the condition that nonfinal states are mapped to nonfinal states, it corresponds to language equality. You actually just need $B$ to be minimal for the equivalence to hold, assuming all states of $A$ are reachable. First, notice that the morphism is indeed unique, as you must map the initial state of $A$ to the initial state of $B$, and then the whole morphism (if it exists) is induced by your second condition, since all states of $A$ are reachable. We can now prove the equivalence. First it is clear that if the morphism exists, then $L(A)=L(B)$, since accepting runs of $A$ are mapped to accepting runs of $B$ and vice-versa. Conversely, assume that $L(A)=L(B)$, we have to show that the morphism $h$ exists. The only problem we could have when building $h$ in the forced way, is if two words $u,v$ lead to the same state in $A$ but two different states in $B$. Since $B$ is minimal this means $u^{-1}L(B)\neq v^{-1}L(B)$. But $u^{-1}L(A)=v^{-1}L(A)$ since both words reach the same state of $A$, we reach a contradiction with $L(A)=L(B)$. As Andras Salamon mentioned, the minimal automaton is indeed defined as the DFA $B$ such that for any DFA $A$ for the same language, such a morphism $A\to B$ exists. 

For tree automata, you have the Mostowski hierarchy, which is about the complexity of acceptance condition: each level is of the form $(i,j)$ with $i\in\{0,1\}$ and $i\leq j$. Being at level $(i,j)$ means that there is a parity automaton using parities from $i$ to $j$ recognizing the language. For more on parity condition, see here: $URL$ This hierarchy exists in 3 versions: deterministic, nondeterministic, or alternating, depending on the model of automaton you are looking at (although the deterministic hierarchy does not cover all regular languages). There is an other hierarchy called Wadge hierarchy, with a more topological flavour, but it is getting further from complexity of acceptors: $URL$ 

If you use Mealy machines, it forces your functions to be length-preserving, and therefore you cannot encode PCP with them. Your regularity theorem holds with length-preserving functions. If you want to allow length-increasing functions (that you need for PCP), you need a more powerful transducer model, for which undecidability quickly kicks in. 

It depends in which sense you mean "undecidable". If you evaluate $M$ on the empty input, and want only to find a yes/no answer, then the algorithmic problem is trivially decidable, as answered by Gamow, since either the algorithm outputting "Yes", or the one outputting "No" is correct. you don't have to know which one is correct to prove decidability: there exists an algorithm solving the problem. If your Halting problem on a specific $M$ still accepts the input $x$ of the machine as input of the problem, then it is in general undecidable. This is because it is equivalent to the general Halting problem by using a universal Turing machine $M_{univ}$, and giving as input the encoding of the Turing machine you want to test. For simpler machines, of course, this problem can become decidable. But coming back to the first version with no input, interestingly, there are Turing Machines for which the answer is actually mathematically undecidable. This means that the machine does not halt, but you cannot prove it using your usual mathematical theory (say ZFC for instance). To see this, consider a machine looking for a proof of contradiction in ZFC, and halting when it finds one. If ZFC is not contradicatory, the machine won't halt. But by Gödel's second incompleteness theorem, you cannot prove that this machine won't halt, since this would amount to prove there is no proof of contradiction in ZFC. Remark that if the machine halts, then it is always possible to prove it, by exhibiting the full run of the machine. So in my opinion, the answer to your question is: "the Halting problem can be undecidable for a specific Turing machine, even with no input", but we have to be precise about the meaning of "undecidable" here: it is in the sense of mathematical undecidability, i.e. independent of the axioms. 

In the case of undirected graphs, there is literature about such morphisms called graph emulators. They are a refinement of the notion of covering graph. A covering graph maps the neighbourhood of a vertex $u$ bijectively to the neighbourhood of $h(u)$, while an emulator is only required to do it surjectively, which seems equivalent to your question. This notion appears in the context of characterizing graphs having planar covers or planar emulators, which yields several open problems, see for instance this paper for a survey. 

Problem: Satifsiability of an MSO (monadic second-order logic) formula over finite words. Theorem: MSO is equivalent to finite automata over finite words. The above can be lifted to infinite words, finite trees, infinite trees. 

From your example, it is easy to derive a language $L$, such that neither $L$ nor its complement is recognized by a DBA. Take an alphabet of four letter $\{a,b,c,d\}$, and let $L=((a+b)^* a^\omega)+(c^*d)^\omega$. It is not DBA-recognizable because of the $\{a,b\}$-part, and its complement is not because of the $\{c,d\}$-part. For a less artificial example, you can for instance take on alphabet $\{a,b,c\}$ the language $L$ of words with infinitely many $b$ and finitely many $c$. Both $L$ and its complement have to check that the number of something is finite, so both are not DBA-recognizable. 

Loop these steps until all your targets are empty. You should end up with the minimal set of partial products you need to compute. Notice that this algorithm produces an optimal output, but may not be optimal in complexity. 

A pushdown automaton is a particular case of ISM, so it is possible to recognize a context-free language with ISM. How would you give your ISM to the algorithm? Anyway a lot of problems are already undecidable for Pushown Automata (particular case of ISM) like equivalence or universality, so I guess the answer would be no for any reasonable question here. 

I would like to add that there are some Turing Machines for which the Halting problem is independent of ZFC. For instance take a Turing machine which looks for a proof of contradiction in ZFC. Then if ZFC is consistent, it won't halt, but you cannot prove it in ZFC (because of Gödel's second incompleteness theorem). So it is not only a matter of not having found a proof yet, sometimes proofs don't even exist. 

The level $\Sigma_2\cap \Pi_2$ of the alternating hierarchy (i.e $L$ is both Büchi and co-Büchi definable) corresponds to the weak level and is characterised by weak alternating automata, that give themselves rise to a hierarchy: 

The main teams I know that study cellular automata are in the following laboratories (non-exhaustive list, probably biased towards french labs): 

According to their definition of PFA, to compute $Pr(w\Sigma^*)$ you simply need to compute the probability of having read $w$ after a random path of length $|w|$, which is easy. Their model of PFA differs from the usual model: usually, for each state $q$ and letter $a$, we have $\sum_{q'} \delta(q,a,q')=1$, so you assume that in a run, the word is fixed beforehand and probabilities are played upon reading each letter. Here, the setting is different: for each state $q$, we have $F(q)+\sum_{a,q'} \delta(q,a,q')=1$, meaning that a path is chosen at random (including the end), and induces a word. That is what makes the problem easier. 

More of an extended comment with a conjecture, but here is a condition that seems to capture the problem, in the context of regular $L$ for $S(L)$ to be context-free. Condition In the minimal DFA $A$ for $L$, any accepting path contains at most one loop. Exception: two loops are allowed if their labels and the label of the prefix before the first loop all commute, and the suffix after the second loop is empty. For instance $aa^*b(aa)^*$ is ok. Recall that two words $u$ and $v$ commute if they are powers of a same word $t$. We can assume the suffix empty, because it cannot be non-empty and commute with the label of the second loop in a DFA. Sufficient Assume the condition, you build a PDA for $L$ by treating each accepting pattern $xuy$ of $A$ where $u$ labels a simple loop. We want to accept words of the form $xu^nyxu^ny$. We read $x$, push a symbol for every occurence of $u$, read $yx$, then pop a symbol for every occurence of $u$, and finally read $y$. About the exception, if we are in this case, a basic accepting path is of the form $xuyv$ where $u,v$ are the labels of the loops. We accept words of the form $xu^n y v^m xu^n y v^m$, but by assumption ($x,u,v$ commute) it is the same as $u^nxyu^n v^mxyv^m$, which can be done by a PDA: push $n$ times (for occurences of $u$), read $xy$, pop $n$ times, push $m$ times (for $v$), read $xy$, pop $m$ times. The final PDA is the union of the PDAs for each pattern. Necessary (handwaving) If there is a path with two loops, even in the simplest case where you must take one then the other (for instance $a^*b^*$), you must remember how many times each one is taken, but the stack structure prevents you to repeat them in the same order. Notice that the fact that the DFA is minimal is important in the characterization, to avoid using two loops when one could suffice. For now the necessary part is only a conjecture, and more exceptions could be needed to get the exact condition, I would be interested in counter-examples.