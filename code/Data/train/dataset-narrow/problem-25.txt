It is a common misbelief that “DevOps” is a role in a company. The word merely denotes an organisational shift in software companies, this shift can be shortly described by the “You build it, you run it!” coined by Werner Vogels: 

From the operational perspective, this breakdown of the parametrisation matches the natural degrees of freedom of the deployment problem – aside from the credentials that could be bundled with the runtime configuration, but it is better to separate them to avoid spreading them carelessly. 

A file added by some docker instruction and removed by some later instruction is not present in the resulting filesystem but it is mentioned two times in the docker layers constituting the docker image in construction. Once, with name and full content in the layer resulting from the instruction adding it, and once as a deletion notice in the layer resulting from the instruction removing it. For instance, assume we temporarily need a C compiler and some image and consider the 

Kubernetes doesn't use CloudWatch metrics for scaling, it manages scaling by setting the ASG desired number of instances through internal mechanisms and therefore isn't subject to the issue you've described. 

From my experience in managing a Nagios deployment with version controlled configuration files and CI/CD, it works really well. You can collaborate with other teams more easily since you can grant access to a git repository, and you gain all the benefits of CI/CD e.g. rollback and automatic testing. One thing that may be a bottleneck is how frequently you're reloading Nagios, but this would only be an issue when you have many deployments per hour. Nagios itself also has a lot of limitations and is missing a few key features for a modern environment (scaling, configuration inheritance, APIs), but strictly speaking this doesn't detract from using CasC with Nagios. 

Alice rename DatabaseClient to DatabaseClient_v1 and create a delegate class called DatabaseClient that uses an object DatabaseClient_v1 and implements an interface called DatabaseClientInterface. (If possible, this DatabaseClientInterface should be a code artefact but duck-typed languages not always support this.) Bob reviews changes made by Alice in 1 and is aware that his maintenance job should happen on DatabaseClient_v1. Alice introduces a new configuration flag in the application that governs the behaviour of the DatabaseClient delegate and implements a DatabaseClient_v2 placeholder, a class implementing the DatabaseClientInterface whose methods all throw a “Not implemented” exception. 

My understanding of Ansible roles is that they are the unit of reusability when implementing processes using Ansible, similarly to what a class or a package is in some computer languages. It therefore seems natural to use roles to make all tasks understanding a given data structure in a specific role, but this yields the question of how to select the actual tasks to perform? Is it a good design to use the file in the task as an entrypoint to select actual tasks according to role parameters? For instance a role could feature: 

What you are specifically after (building from a bare repository on a local filesystem) isn't functionality offered by Docker, and by extension, docker-compose. Docker supports building from a few different URLs, but not bare repositories on local filesystems. You can try a few workarounds: 

One best practice would be to log everything to the same location. Your "Current idea" suggests that you'd be running the Elastic stack locally, which is great for a local development environment, but for anything outside that you want to be shipping the logs from all your microservices to the same location. This enables you to do correlation between logs, and have a "single pane of glass" approach to your logging. To achieve that, you're going to have to run it on a server or use a managed service such as Elastic Cloud or AWS Elasticsearch. You can install the components through package managers e.g. yum or apt, $URL$ or it's also possible to run it in Docker. The repository is great for running locally, but it's not suitable for any sizeable deployment due to a lack of scalability. The endpoint you ship to will depend on what method/protocol you're using to ship logs, for example Nginx running on an AWS EC2 instance might use Filebeat and ship to a load balancer that sits in front of Elasticsearch, or if you're using Docker you might use the gelf Docker logdriver to ship your logs to Logstash. Some more best practices: 

each having three scripts called , and . Now that the organisation of automation items has somehow been clarified, let's turn our attention to configuration. The main conditions and requirements about the configuration organisation are set by the verb when applied on a service-like artefact. The verb should have the following parameters: 

After this, Alice and Bob can collaborate without explicit synchronisation, because code written in their respective iterations is subject to the DatabaseClientInterface. This minimises the risk of a conflict resulting from their concurrent work. Iterations from Alice can be very short, like implementing a test, implementing a method, or even partially doing so, because in production, the code is not selected for use and does not need to be fully functional. The automated testsuite should be configured so that the DatabaseClientInterface always uses DatabaseClient_v1 while Alice can easily toggle to DatabaseClient_v2 when running the testsuite locally – or in a custom CI setup. Once everything is ready, a single commit can perform the change, by updating the configuration value governing the DatabaseClient delegate. 

They should be roughly equal. If the CI system is faster than running it locally, your local development is going to be uncomfortably slow. If your CI system is much slower than running it locally, it will become something that is an obstacle rather than something provides value. 

A service that you connect to is suitable to be defined as configuration, so the use of env vars is appropriate here. 

There is currently an issue open to share Gradle cache between containers: $URL$ I think the best solution at the moment is to bake as many dependencies in to the Docker image as possible, and then use a volume to share between sequential builds, limiting it to one concurrent build per host. You can mount the cache on to the host with a docker-compose.yml like so: 

As long as you're not doing anything funny with the entrypoint in the container, this will leave files owned as the user that invoked Docker. 

At work we are currenly using a multi AZ Kubernetes cluster on AWS and we're using along with Terraform ( generates the Terraform configuration files) to provision the cluster. What is not clear to me is if your intention is to run a single multi-cloud cluster or if you want to run multiple clusters in multiple clouds. Anyway, our current setup is a multi-master highly-available multi-AZ Kubernetes cluster. I'll try to explain step by step. The first thing in order to create the cluster is to generate the Terraform configuration with (you could directly apply the changes in AWS by directly using , but in our case we think it's best to keep the Terraform files versioned in git, to be able to change details about this configuration and inspect them, also). For instance, this could be the command we used: 

My organisation is experiencing an explosion of microservices. We currently have no formalised way of bootstrapping new projects. I'm finding that a team will come to me with a bug in their deployment or build process, and I will spend time on it only to realise I've already resolved it in another project. There's also a lot of inconsistency between projects that I'd like to see standardised. The changes often involve a single file (e.g. serverless.yml or a Makefile) so a solution involving shared libraries e.g. git submodules doesn't seem viable. Each project will have its own set of configuration that needs to be maintained, e.g. Dockerfiles or serverless.yml, so centralised configuration management solutions for VMs aren't really applicable. How can I ensure that new microservices conform to organisation standards and include bugfixes/features from existing projects in a way that's easy and intuitive for developers who want to start new projects? What are some best practises around resolving these issues? The current workflow we have is to ask the person next to you "what project should I clone from to use as a template?" and then delete all the stuff that's not necessary for that project. 

whose complexity in comparison to the Ansible variant is probably tolerable: it just uses the plain, regular, boring constructs from the language. Random documentation step 3: Testing strategies Last, we meet what turns out to be the first actually interesting feature of Ansible: “Ansible resources are models of desired-state. As such, it should not be necessary to test that services are started, packages are installed, or other such things. Ansible is the system that will ensure these things are declaratively true. Instead, assert these things in your playbooks.” Now it starts to be a bit interesting, but: 

Feature flags are an engineering device that can be used to avoid long-lived branch and conflicts in product development. Here is how it can be used the context of an object-oriented language to help developers collaborate on a specific product feature while one handle a new version. This solution can also be used in non object-oriented contexts, provided a notion of “interface” exists. (cf. OCaml module system.) For the purpose of illustration, we assume a tool presenting reports about data stored in a database. The code implements a DatabaseClient class used to perform requests. As the dataset grows, it becomes clear that some alternative data layout would improve the application performance. Therefore Alice will develop a new version of the DatabaseClient able to retrieve data from the structures with improved layout, while Bob will maintain the historical DatabaseClient. With the following steps, Alice and Bob can collaborate on short-lived branches while minimising their conflicts. 

I'll add an answer of what my solution is so far, but I'm still really interested in hearing how other organisations are solving this problem and the best practices they have. To resolve the issue of not having a consistent base to create projects for, my idea is to create a repository (repositories?) of boilerplates/templates and use cookiecutter as a tool to scaffold out new microservices. This way, each project is created from a standard base with all the lessons we've learned as an organisation integrated in to it. Any changes we make can be integrated upstream in to the boilerplate repository. I imagine we'll have templates for Nodejs Docker images, Serverless SPAs, Python lambdas, etc. To resolve the problem of changes made to the templates being propogated downstream to every project, my solution is to implement a process where owners of microservices are made aware of changes to the template and are then responsible for propagating those changes to their microservice.