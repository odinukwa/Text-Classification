Check out Ramsey Theory -- basically a significant generalization of the pigeonhole principle which underlies a lot of automata and formal language theory (or should I say, the pigeonhole principle is the simplest case of Ramsey Theory). It basically says that even highly disordered structures turn out to necessarily contain a lot of order if they are sufficiently large. For a small example just beyond the pigeonhole principle, note that if you take any six people, then either three of them mutually know each other or three of them mutually do not know each other. This paper looks like a nice place to start for connections with computer science, but you can google for more. It's more combinatoric than algebraic in its basic nature, but has many applications in algebra and theoretical CS. And also check out the story of the inventor, Frank Ramsey -- truly a remarkable polymath who made fundamental, even revolutionary contributions in economics and philosophy as well as mathematics, many unappreciated until much later, all before dying at the age of 26 -- just think! In fact, Ramsey's original theorem, the basis of Ramsey Theory, was a mere lemma in a paper with a bigger aim in mathematical logic. 

It is common wisdom that database field is firmly grounded in the two math disciplines: predicate logic and set theory. However, this is very fuzzy observation, and reality is more subtle. The structure of the basic building block - relation - is described in set language, but that's about it. This is not really very insightful, because the whole mathematics is written in set language. The fact that probably caught your attention is that the foundation of SQL - relational algebra - has distinct Boolean flavor. Please also note that SQL actually operates not with relations but multirelations which are bags(multisets) of tuples(rows). Therefore, its algebra is not a [boolean] algebra of sets. There were various attempts at rigorous theory of multirelations, with provenance semiring being the most recent development 

The above two are addressed in Derandomizing Valiant-Vazirani?. However we can still ask whether there is a possibility of P is not BPP and still if it would be possible to derandomize Vazirani-Valiant. 

Can we have randomized $2^{n^{o(1)}}poly(m)$ time in above statement? Is there a similar result that would give $E\not\subseteq SIZE(2^{\delta n})$ (this would give $P=BPP$)? How large can $o(1)$ be in the statement above and in 1. if applicable (can it be as large as $1/\log\log n$)? 

A guess that we can think of (1a) as following: Consider problem: (3) Given $n^2$ integers is there a way to partition the integers into disjoint subsets of size $n$ such that at least one of the subsets sum to $0$? This problem sounds much similar to problem in definition $2$ in section $1.2$ here $URL$ May be we can show (3) is $\mathsf{NP}$-complete and find a way to reduce (1a) to (3)? 

In Relational Databases: Tutorial for Statisticians Joe R. Hill casts probability view onto database theory. In Table 1 the author summarized the parallels between the two disciplines, describing relation structure together with three relational algebra operations in probabilistic terms. I seek clarification on 2 items: 

Many others like commutativity and associativity of [relational] join operation, or permutting selection via join are trivial in the sense that they are fundamental lattice laws. You mentioned theorem provers; not surprisingly, some research has been facilitated with Prover9. 

This may sound like theoretically void question, because certainly permutation is expressible even on the lowest level of Chomsky hierarchy: 

Let $G$ be an undirected Cayley graph over an abelian group. Let $H$ a regular graph whose independence number and chromatic number are known. Let $inj(G,H)$ be the number of injective homomorphisms from $G$ to $H$. It is known SUBGRAPH ISOMORPHISM is NP-complete. Consider the CAYLEY SUBGRAPH ISOMORPHISM problem: Given an undirected Cayley $G$ and a regular $H$, is inj(G,H)>0? Is the above problem NP-complete? Since linear codes are abelian, I am extending the question. Given two $[n_i,k_i,d_i]$ linear codes $C_i$ for $i=1$ and $2$ and $n_1<n_2$, is deciding $C_1\cong D \subset C_2$ NP-complete? Note that code isomrphism is similar to graph isomorphism. 

In practice, however, proposition that the only way to describe SQL syntax is permuting "where", "group by", "having" (and many more similar clauses in some SQL dialects) is silly. Boolean grammars allow succinct expression for permutation 

Relational Lattice is axiomatic foundation for Relational Algebra. Predictably, query transformations reduce to equational reasoning in that axiom system. Here are examples: 

Still the analogy is weak: there is well known interpretation of Functional dependencies in terms of entropy. 

What probability distribution corresponds to empty relation? An intermediate step in Dr.Hill's paper is indicator function -- which is standard trick of thinking about relations in functional terms. My understanding is that the author generalizes {0,1} valued indicator function to probability distribution. There, the 1 valued tuples are assigned not vanishing discrete probabilities (assuming discrete domain), while all the tuples not belonging to relation inherit their 0 indicator function value as probability. My objection is that this would work for nonempty sets of tuples only. Missing from the parallels is Relational Algebra union operation -- what probability concept is it analogous to? If we take average, then it would fail to honor associativity law. 

$FPT=W[1]$ does not collapse the $W$ hierarchy however falsifies $ETH$ belief. Is there non-trivial consequence if $W[i]=W[i-1]$ and any other consequence at $W[1]$? 

I will post an answer which gave a high level view on the chapters I read. Handbook of Theoretical Computer Science: Algorithms and complexity, Volume 1 edited by Jan Leeuwen. It has big name contibutions like H.W. Lenstra, Valiant etc. This is not a text per se. However, reading this after some preliminary understanding gives more insight and goes into topics of interest within TCS. It is also mathematical with each chapter providing an introduction into a topic before diving into the topic. Note that the topics have moved on ever since the book came out in $1990$. 

I'm still not sure why you want it in strict quadruple form, with a set of structure-less states. That's a model that mainly intended for doing the abstract mathematics surrounding state-transition systems, but famously ill-suited to actual computation unless you are looking for the extreme speed offered by "pre-compiling" into deterministic form, at the expense of storage space. User834 is correct that this is a fairly simple sub-problem of regular expression matching, with the added feature of counting matches, so you may take my solution in that vein. I'm not a RE maven, but I think there is a way to get match counting out of REs in most implementations. So that's an approach you might consider for practical implementation without all the trouble of constructing your own FSAs. I also agree that this probably belongs in the CS area rather than theoretical CS. If I read your problem correctly, it amounts to taking a set of strings $V$ and looking for every occurrence of a string in $V$ as a maximal substring (prefix, suffix or interior) of $x$, the input to the DFSA we'll call $D$. That count is the "penalty" for $x$. Here's one way to do it, though following your prescription not to worry about performance, takes no advantage of any structure or redundancy in $V$. In your example, $V=\{abd, abe, acd, ace, add, ade, b...\}$. Pre-multiply all the sets $V_i$ into strings of $V$ in tree form, with elements of $V_i$ all on level $i$, each descended directly from each element of $V_{i-1}$. Level $0$ is an abstract root, say $\epsilon$. For your example, descended from $\epsilon$ are $a$ and $b$, the elements of $V_1$. On level 2, descended from each of $a$ and $b$ are the members of $V_2$: $b$, $c$ and $d$. So there are 6 nodes on level 2 altogether, the 3 members of $V_2$ repeated twice. And so on to the leaves. Each path from $\epsilon$ to a leaf of the tree represents one "penalty string" in V. You did not make clear what happens if a string appears more than once in $V$. If you don't want it to count for multiple penalties, then you should prune duplicate strings out of the tree by some suitable algorithm. Construct the a non-deterministic FSA $D'$ as follows. States of $Q$ are pointers to nodes of the tree. Each state thus represents a complete string in $V$ or a prefix of such a string, to be represented here by $[x]$ (though that $x$ isn't unique to a node -- I assume there is a pointer to the actual node of the tree). The transition function $\delta$ contains three kinds of edges: $\langle[x],a,0,[xa])\rangle$ where $a$ is a direct descendant of $[x]$, and $[xa]$ is that descendant node. Note that we output 0 at this point because we aren't sure we've reached the maximal match. $\langle[x],a,1,[])\rangle$ where $a$ is not a direct descendant of $[x]$ in the tree, and $[]$ is a dead state. We output $1$ here because $[x]$ is matched but it is maximal, since $[xa]$ is not matched. If we were dealing with prefixes only and not interior and suffix matches, we'd be done and this would be a deterministic automaton. To account for non-prefixes, we need to non-deterministically circle back to $[\epsilon]$, the start state, at every stage with an edge like this for every state $[x]$ except $[\epsilon]$ and $[]$: $\langle[x], \epsilon, 0, [\epsilon]\rangle$ Convert that NFSA to a DFSA and you are done. 

In db query area arguably Provenance Semiring enjoyed the most attention recently. The "provenance" adjective is just marketing connecting it to a large body of research. Nevertheless the idea that one may have much more elegant mathematical foundation for database query languages is compelling. My personal view is that semiring perspective (which works wonders in formal language theory) has to be complemented with Relational Lattice. Here is another view of what happened in the last decade. (The speaker holds a record of continued PODS admittance:). On less theoretical note lets mention Dedalus, and plenty of Tutorial D enthusiasts; both, however, are hardly the recent ideas. 

It seems likely that Von Neumann knew about Babbage since Aiken did and was pretty open about it as far back as 1937. See this. Also, Flowers, of Colossus fame did as well. Von Nuemann's famous paper appeared in 1945 (see here and here), and does mention Aiken's work. But I can't find any direct evidence. Good question, and a bit of fun to briefly research it. 

If you choose a crisp, symmetric model of NFA $A$ with state set $Q$, where an input symbol maps a subset of $Q$ into another subset of $Q$, with initial and final (accepting) subsets of $Q$, then your sketch is practically a proof. In fact, it will work even if you start, more generally, with an NFA rather than a DFA. (You do have a bit of confusion about final vs accepting states -- they are the same thing, and you'd simply interchange them) To formalize it, you would indeed use induction to define the transition relation on strings and subsets of states: $\delta (Q_1,xa) = \delta (\delta (Q_1,x),a)$ and the reverse: $\delta_R (Q_2,ax) = \delta_R (\delta_R (Q_2,x),a)$ and show that you get an NFA $A_R$ that accepts exactly the reverses of strings accepted by $A$, the crucial step being that $\delta (Q_1,x)=Q_2 \Leftrightarrow \delta_R (Q_2,x)=Q_1$ for string $x$. Finish by applying that to the initial and final state subsets, which define the language accepted by $A$ and its reverse by $A_R$, string reversal also being given by an inductive/recursive definition. 

Do we know of a randomized $O(poly(nd\log q))$ algorithm to find an irreducible polynomial in $\Bbb F_q[x_1,\dots,x_n]$ given $d_1,\dots,d_n\in\Bbb N$ with $d=\max_{i\in\{1,\dots,n\}}d_i$ and $d_i=deg(x_i)$ at every $i\in\{1,\dots,n\}$? Does derandomizing PIT derandomize these unconditionally? 

Khachiyan and Porkolab in 'Integer optimization on convex semialgebraic sets' gave an $O(ld^{ O(k^4)})$ algorithm to minimize a degree $d$ form with integer coefficients of binary length at most $l$ over integer points in a convex set in $\Bbb R^k$. Has this ever been implemented in any package? 

Does a single tape Turing machine with access to $\mathsf{PSPACE}$ oracle needs more than $\mathsf O(1)$ working tape memory and $\mathsf O(1)$ working time to solve $\mathsf{NP}$-complete problem? What is largest complexity class oracle that a single tape Turing machine could need so that it will need $\omega(1)$ Space time resource (as against separate space and time) to solve $\mathsf{NP}$-complete problem?