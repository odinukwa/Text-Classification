On some level, you're going to have to manage gamestates, your video hardware, audio hardware, etc. While it can be a good learning experience to dabble with DirectX, DirectSound, and the like, if you immediately want to make a game, it's best to use some layer of abstraction. SDL is cross-platform, open-source, works with C++ natively, and has great documentation and tutorials to get you started. SDL Website 

Angular velocity would seem the obvious choice based on what you're already doing. But unless the objects will be moving and turning with a constant velocity, acceleration on both counts might be a better predictor for any given velocity. 

The solution is not to delay deceleration. When you throw a ball up in the air, it isn't moving at a constant speed until it reaches its maximum height, but decelerates from the moment of impulse. Gravity is not a velocity, but an acceleration. So if a player has a speed upwards of 20 units, and gravity is -10 units, on the next tick, the speed upward would be 10 units, on the next, 0 units, etc. The reason why your jumps are seeming so diagonal is because your player's speed up and down is constant. So if you literally draw a line following the path of the player, you will see a line with the slope, positive or negative, of your gravity value over the change in the x position. For your player to control the height of your jump, your player should be given some initial velocity on impulse, gravity should be turned off, and a special gravity value (less than regular gravity) should be applied to the player's velocity. Once the jump button is released or the player velocity reaches 0, normal gravity should be applied. This way, the player will see a nice curve during their jump, whether they are decelerating by regular gravity or not. 

You also aren't allowed to distribute the full XNA studio installer in your install package, so if you are creating a tool to be distributed with your game the content pipeline isn't a great fit. It's likely not reasonable to expect end-users to install a developer tool to be able to use your custom tool. 

Are you using a SpriteBatch to render your overlay in the second image? If so, SpriteBatch in 3.1 sets render states when drawing (including disabling the depth buffer) that you need to restore before drawing in 3D. See this article for the exact states changed. 

There is no built-in Kinect support in XNA currently, so any Kinect development on the Xbox 360 is out of the question. If it is one day introduced, it may well be similar to the available Windows SDK, but there has been nothing announced. As for licenses and fees, you can develop for the Xbox 360 if you have a $99 AppHub account, available from $URL$ 

My guess is the try/catch overhead for each iteration of a potentially large nested loop was killing your performance and that the analysis tool somehow affected the exception handler overhead. You could easily test that by removing the exception handling and running normally, without the profiler. You definitely don't want a try/catch on the inside of a tight loop. You would be much better off ensuring that you account for anything that can generate an exception within your loop via conditional checks, or at the very least put the try/catch around the loop as a whole. 

What I am trying to do today is to import a full project to Android, but no tutorials are available for that that I have seen. My approach was to create a new android project, copy all the classes and resources in the folders and calling ./build_native.sh but I get an error because most of the files are not being included in the project. I tried opening the Android.mk and I can see why "LOCAL_SRC_FILES := AppDelegate.cpp \ HelloWorldScene.cpp" are the only files linked. Should I manually modify the make file or can it be automated by some way I don't know? Thank you. UPDATE: I manually added all files and headers to the make file and I get errors linking Box2D or cocosdenshion libraries. 

If I have a texture with known metrics (pixel size, byte type) and a GL surface to render to of a know density and measures, and I want to draw a quad composed of two triangles that correspond to the size of the texture in proportion to the size of the surface. For that I need to recalculate the needed quad's vertexes. Can someone explain me the math involved in this process? Example: I have a screen/surface of 800x600 and a texture of 100x20 that I want to position in (20, 20). How do I calculate the vertex of the quad needed for it. My shaders are simple v 

It sounds like for each bone you are currently defining the texture to be rendered - you might as well allow for more flexibility and include a texture origin offset in your bone structure as well (relative to either of the joints you choose). That way you can be sure the rendered texture will be consistently placed. 

If you know in your Update method that you don't need or want to render anything simply call SupressDraw() on your game object ($URL$ You don't need to add any additional logic into your Draw method to handle this, and your frame skipping logic can be moved into your Update call. 

When playing and you hit the P key your if(CurrentGameState == GameStates.Playing) block is executed, changing the state to paused. Then the if(CurrentGameState == GameStates.Paused) block that follows also runs (because you just changed the state to paused above and the P key state hasn't changed), changing the game state back to playing. This is why you never experience the paused state. At the very least, I'd make the code for each state exclusive within the update method, either by using a switch statement or the following: 

The problem was in the Android manifest. My main class inheriting from Application was not added as the main application class in the description. Once added, the app called a new object and the OnCreate method where I could initialize OpenFeint. As OpenFeint is open you can now statically call the OpenFeint functions to open the different views. 

is not accepting the context parameter that I am giving him, which is a "this" reference to the main class. Main class extends from Cocos2dxActivity but I don't have any other that extends from Application. Any suggestions on fixing it or how to improve the architecture? EDIT: I am trying a new solution. Make the bridge class into an Application child, is called from Main object, initializes OpenFeint when created and it can call the OpenFeint functions instead of needing an additional class. The problem is I still get the error. 

J2EE is the superset for Java SE and Java ME, meaning that you have as many libraries available as you would for those two. Now, it does not make much sense choosing EE, because most of the additions are oriented to big servers and databases. 

Obviously you can improve the performance of this example and could remove touch Ids from the list of those tracked when the TouchLocation state is released, but the basic idea of tracking which touches you have handled and ignoring them on subsequent updates is the same. You could also limit firing a bullet to the initial touch location by simply checking that the touch state is TouchLocationState.Pressed, which should only be true for the first frame in which the touch is active. I haven't used that method myself. 

Vector2 uses floating point numbers, so when you calculate the difference between where you want to go and where you are (goTo - player.Position) it will almost never be exactly zero. This leads to some jitter, which is likely worse at some locations. If you can't switch to integer-based positions (i.e. Point) you will end up having to cap the movement as you have found out. One way of doing this is to compare length of the direction vector before you normalize it and if it is under a set value simply go to the target position. If your margin of error before snapping is small enough you will not notice the snapping at all. 

I'm implementing engine tools for my hex board game and this one is becoming messy. I want to get a list of all the positions that a cone of size N would have, given "caster" origin X,Y and origin in X0, Y0 taking direction into account. So far I have been able to get a size one cone using a "simple pattern" approach, but it doesn't translate well for N-sized cones. This is the original cone 

Install the Tegra Android Development Pack. It includes Android simulator, the SDK and preinstalled Eclipse just in case: $URL$ Then go to the android-sdk-windows folder and open AVD Manager.exe. In that screen you can create a new emulated device with any specs you want. Then use Start to open it. It will have internet connection so you can try your remote app. The thing is that none of the emulators (iOS/Android) are near the performance most devices would give you, so you can't measure performance and framerate. 

I am trying to implement OpenFeint for Android in my cocos2d-x project. My approach so far has been creating a button that calls a static java method in class Bridge using jnihelper functions (jnihelper only accepts statics). Bridge has one singleton attribute of type OFAndroid, that is the class dynamically calling the Openfeint Api methods, and every method in the bridge just forwards it to the OFAndroid object. What I am trying to do now is to initialize the openfeint libraries in the main java class that is the one calling the static C++ libraries. My problem right now is that the initializing function 

8 kilobytes per second is the number I have seen tossed around on the AppHub forums. There is a short description of how headers and voice affect this number on Shawn Hargreaves blog. 

Once you have handled a touch by firing a bullet you need to record that you have already reacted to that touch and that you shouldn't on subsequent updates. Each touch location has a unique Id field that is maintained for as long as the touch remains active, even across frames. A simple approach would be to maintain a list of all the touch Ids you have already handled, and ignore those touches when performing your update. 

You need to have the full XNA game studio installed on every machine that will use your tool. From the WinForms2 sample page you linked to: 

Looks like the Unity docs are for the most recent released version only. The Set method was added in version 3.5.0*, which is why it isn't available in 3.4.2. *based on the information at $URL$ 

I don't think your issue is timing related. If you change your object velocity so that the amount of movement per update is very low (i.e. less than 0.5 units per update) my guess is that your object will never move at all! Currently, you are tracking a moving position over time as an integer (SDL_Rect is integer based). Any fractional movement associated with each update is lost due to the casting to an integer. Over time, these missing fractional movements add up and lead to jittery, non-smooth movement of the object overall. This is especially obvious for slower moving objects where the rounding doesn't average out as well and the discarded fractional portion represents a larger part of the overall movement. The solution is to track your positions in floating point coordinates, then convert to integer coordinates only when rendering. 

Given that the event bus post is synch the results are the same, so it all boils down to architectural differences: centralized logic and hundreds of event objects or disperse logic with less objects. 

I am trying to create a generic C++ bridge to use OpenFeint with Cocos2d-x, which is supposed to be just "add and run" but I am finding problems. OpenFeint is very exquisite when initializing, it requires a Context parameter that MUST be the main Application, in the onCreate method, never the constructor. Also, the main Apps name must be edited into the manifest. I am trying to fix this. So far I have tried to create a new Application that calls my Application to test if just the type is needed, but you do really need the main Android application. I also tried using a handler for a static initialization but I found pretty much the same problem. Has anybody been able to do it? This is my working-but-not-as-intended code snippet 

I'm putting together a ECS for my game with another two main components: an event bus for communication and a Lua interpreter to load scripts. Now, the parent element is a framework/game object with references to all this three components. My question is, what is the best communication pattern: drill the interpreter and any other orchestration objects down to every system or centralize all those calls in a subscriptor for the eventbus, and make everything from there. Example: // Plan A