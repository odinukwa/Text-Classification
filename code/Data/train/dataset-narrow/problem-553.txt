We recently migrated to a new SQL Server and the SQL Services are running under a Service Account. I did observe that the Service Account do not have rights on G drive and the old files are not being cleaned up. Question: Why doesn't the procedure when it cannot delete a file OR simply move on instead of waiting for around 9.5 minutes? Also, doesn't the job error if it cannot delete the old backups? We will not know until we receive alert !! Here is the log details. 

Full Backup started on 4/21 12 AM. While backing up one of the database, it is stuck. sp_WhoIsActive shows following information 

From my searching, it seems like postgresql has crashed due to an error. If a proper shutdown is initiated, the message is different. 

I'm getting this error and I have no idea where it's coming from or what it means. I can't find any documentation on frontend message types in the PostgreSQL documentation. I tried enabling the log of every statement, but this error isn't occurring after any specific statement in the log. The statements are different each time, and when run via pgsql, the statements run without error. Is there anyway I can print out what statement or message is causing this error? I really don't know how to proceed without knowing the source. PostgreSQL Version 

I just by chance added alert for Error 825 and ran sp_Blitz again. And the message for Finding "No Alert for Corruption" was not displayed for Error 823 and 824 !! After Alert setup: 

There is AD group on created on . The domains each other (per IT team). Now, we have a which is also trusted for both Domain1 and 2. We added AD group to . When either of Domain1\User1 or Domain2\User1 try to Login to SQL Server on Domain3 - we get Login Failed message. 

Is there a way to resolve this to make work on Domain3 SQL Server? Also, creating a group and adding the individual userID's from other domains worked too. We don't want a new group just for this. 

No differences. Eventually the memory usage will cap and will kill the database backup (among other processes). I've also tried tuning some system variables. There was Managing Kernel Resources and also Resource Consumption. These have affected the running postgres processes that are used up by the server, but it had no impact on the process uses. It still rose to 2.2 GB before FreeBSD started killing processes. I've read through the pg_dump manual and haven't really seen anything that will help besides the multiple jobs. At this point I'm not really sure what to do. Is there a way to cap the resources that is allowed to use? I don't mind if the backup is slower. Just don't run the system out of resources where the OS has to start killing processes. 

DatabaseBackup - USER_DATABASES - LOG: This job fails saying "Executed as user: Domain\XXXX-SVC. Unable to open Step output file. The step failed." The error is only with LOG backup job. The other DatabaseBackup jobs (FULL, DIFF) works just fine with same SVC account. So the service account have appropriate permissions. The Output File(Job Step properties-->Advanced) is F:\SQLAgentLog\ which is same for all jobs. Only problem is with LOG backup job. Has anyone else experienced this and is there any solution? Current environment: SQL Server: 2012 SP3 CU8 OS: Windows Server 2012 Note: This was working all good on a Windows Server 2008!! 

I am currently using default logging options. What do I need to change in order for PostgreSQL to log errors? Requested Information /etc/hosts: 

As the backup is being completed the associated postgres process keeps rising in memory usage. It gets to the point of 2.2 GB for that process alone. At this point memory is all but used up and starts killing processes. I've tried to change how the backup is done. For example, I tried using multiple jobs (and thus changed the format to directory). 

Is it possible to limit the system resources used up by ? I have a fairly resource intensive server that uses a database. and it is running on . The server has 8 GB of memory. I have a backup run with the following command. 

However, if the Domain1/User1 and Domain2\User1 are added as individual accounts then we could Login without issues. 

Also, I see another backup on the same database started 30mins later (Backup to VirtualDevice - I know this is AppAssure backup tool). From SQLSkills preemptive_os_waitforsingleobject, I see And this is blocked for 2 days - I don't think one of the session will terminate itself until I kill the other. However, LOG backups were happening without any issues. Only FULL backup and DIFF backup for that particular database was blocked. I killed the AppAssure session and all the long queue went away from AppAssure. I killed the DIFF backup as well. Now the only process left is this FULL backup with 100% complete with same and not willing to complete!! I had no other options but to kill the FULL db backup and restart backup jobs. And, the USER_DATABASES full refuses to start saying but showed nothing. Also, there was nothing in state. CurrentJobActivity in msdb showed that the job was active. Had to right-click-stop under jobs and then start the job again!! Any idea on how do we avoid this situation? (other than telling the IT-team to stop AppAssure?) [EDIT]: Adding the version 

So I know it's not a proper shutdown of the database service that is occurring. I am logging to syslog on a FreeBSD system. The log is very basic and essentially only shows me shutdown and startup attempts. 

I'm running a PostgreSQL database and from what I read, the database is unlimited in size. Is there any material I can read to understand what occurs when the HDD fills to capacity? What sort of monitoring must be done in order to insure continuous operation? One solution would be to create an arbitrary limit of free space and once that free space has been reached, you would force the user to purge off older data. Is that a proper solution? I'm interested in learning what other solutions exist and how databases are properly maintained.