and then look for the move that will lead to the maximum score N turns in the future. You may also want to avoid moves that lead to any score below X (say, the cost of dying) N turns into the future. Once you've scored all the possible moves, added bonuses for how well it might turn out in the future and deducted for how poorly it might turn out in the future, then you just sort the array and take the best move. Let us know how it turns out! 

Minecraft is pretty quick, even on my 2-core. Java does not seem to be a limiting factor, here, although there is a bit of server lag. Local games seem to do better, so I'm going to assume some inefficiencies, there. As to your question, Notch (Minecraft author) has blogged at some length about the technology. In particular, the world is stored in "chunks" (you sometimes see these, especially when one is missing as the world hasn't filled in, yet.), so the first optimization is to decide if a chunk can be seen or not. Within a chunk, as you have guessed, the app has to decide if a block can be seen or not, based on whether or not is is obscured by other blocks. Note, too, that there are block FACES, which can be assumed not-seen, by virtue of either being obscured (i.e., another block covers the face) or by which direction the camera is pointing (if the camera faces North, you can't see the North face of ANY blocks!) Common techniques would also include not keeping separate block objects but, rather, a "chunk" of block types, with a single prototype block for each one, along with some minimal set of data to describe how this block may be custom. For example, there aren't any custom granite blocks (that I know), but water has data to tell how deep it is along each side-face, from which one can calculate its direction of flow. Your question isn't clear if you're looking to optimize render speed, data size or what. Clarification there would be helpful. 

To compute the camera size you will only need to scale it down from your maximum camera size if the map is smaller than that size. When scaling, you need to select the smallest dimension of your map, vertically or horizontally, and work out the >1 ratio of width:height or height:width. You want to do this because you always want the graphics to fill the scene-view and the larger of the two dimensions to reach off-screen. Working that out and using it to scale your map will assure that your scene-view is always full. You also want to do a separate bounds check, as Cong Xu mentioned, so your camera follows your character, except the camera's position is bound within a camera safe region. That region will be 1/2 camera width and half camera height in from the edges. Notice that this will need to be recomputed for each map as the camera size will change. 

Also, you need to be passionate, but without too much ego. That is, you have to care enough to want to make things better, but ok with frequent shooting-down of your ideas for improvement, and not let it drive you bonkers. Back to your original question: what makes being software-QA (games or otherwise) an easy entry-level position is that the skill-set is something that anyone can develop, and doesn't require a lot of schooling. As above, tenacity, attention to detail and reliability are more important than many technical skills. It's also a good growth position. It's easy for a motivated person to go from "entry level QA" to "lead tester" in just a couple of years, and promotion opportunities are many. While it CAN lead to a development position, typically QA and developer skill sets are very different. It's also a lot of hard, frustrating work. It is NOT "playing games all day long"! Some folks love it, some folks leave to do something more enjoyable, like flipping burgers. The difference lies with the individual more than with the job. Btw, if you want to beef up your resume for an entry-level game-tester position, volunteer to do some beta-testing for games online, and learn how to write a decent bug report. (You can Google this. A good report is not "paladins suck" or "the space orb needs nerfed." Find out what it means to write a good bug report and then go out and write some. When you go to a job interview, take along 2-3 of your best to show, and explain that you have no professional training, but that this is what you were able to learn on your own. That's valuable skills, right there. Good luck! 

I agree mostly with Asher, XNA is ... was a good language to learn on and C# is very intuitive and far easier to work with than C++. C# and Java are incredibly similar, so you'll feel something familiar there. What you know in C++ can be applied to C#, you just have to forget about all the annoying and confusing stuff :) But if you are going to learn a framework, just start learning SlimDX, I've recently given up on XNA because well... it's based upon DX9, an aging framework, and it looks like XNA has reached the end of the road. It cannot run DX10/11 under the hood, and that's what you want to be using. That is current technology. Using SlimDX is incredibly similar to using XNA but it is far more powerful and you know you are learning current technology. 

I'm working on a strategy game. It's turn-based and card-based (think Dominion-style), done in a client, with eventual AI in the works. I've already implemented almost all of the game logic (methods for calculations and suchlike) and I'm starting to work on the actual game loop. What is the "best" way to implement a game loop in such a game? Should I use a simple "while gameActive" loop that keeps running until gameActive is False, with sections that wait for player input? Or should it be managed through the UI with player actions determining what happens and when? Any help is appreciated. I'm doing it in Python (for now at least) to get my Python skills up a bit, although the language shouldn't matter for this question. 

Well, this is both funny and painful because of how much time I spent trying to resolve this issue. The corruption might have been a clue. I loaded up the program tonight and the issue is non-existent now. It turned out to be a driver issue, because I have just installed the AMD Catalyst 11.10 Preview driver and haven't touched the re-sizing code. That makes sense. :) 

Can I just suggest that you absolutely forget about biomes if you can't make and use height-maps yet. Step by step is the way to go. 

If anyone knows how to set a uint to the shader that would be useful. Though now that I know the 'unpacking' works ok, I'll be passing in the blendweights via a Texture2D. 

From my experience, mass is either: a) A global value that applies to all spatial objects equally (or no mass scalar at all). or... b) An individual scalar value (e.g., pounds, kilograms) directly associated with each individual object. This approach obviously doesn't scale well. or... c) Defined by a base "type" (e.g., wood, rock, water, flesh, weightless...) with a scalar value associated with the type. That value could be used on its own or it could be used in conjunction with the size of the object to determine the final scalar, depending on the accuracy required. Not sure about the Frostbite engine but I would assume it uses something similar to c). 

you just have to provide the vertex data, which you've edited during the frame. Maybe even read about dynamic buffers, they might give you even better performance, but I don't know about that yet. edit : Just to clarify, this is SlimDX (DX11) code, so it should translate easily to straight DX11 code. edit2 : And just to answer one of your questions above, you can also have flat geometry and use the vertex shader to shape your terrain, but you still need to get the height data in to your shader. So you can avoid sending new geometry in, but then you have to send a height map in. So you are still updating gfx resources. Which is faster depends upon your vertex and height map formats.. importantly, their data sizes. In my case, the terrain only has Position & Normal, so it's not too large. My UV's are derived from position. And I think by updating the vertex buffer itself, then it's done, and you've got your vertex heights precalculated, rather than having to sample from a heightmap, which does have a cost. 

I understand the concept but applying it is another thing entirely for me. And to clarify, I'm not wanting an animation, I simply want to create an icosahedron from the vertices of a tetrahedron. EDIT: So I now have an alternative way to create an icosahedron using golden rectangles. That's fine for the purposes of my particular project. However, I'd like to leave the question open for solutions to the original problem, i.e. mathematically converting a tetrahedron in Cartesian co-ords into an icosahedron (not vice-versa). 

Going off this information and the fact that were will likely be several hundred objects rendering on-screen at any given time, my question is as follows: Which method is likely to be the most efficient/optimised and why: 

Forget about tessellation and compute shaders. You simply want to maintain a system copy of the terrain and send it (or parts of it) to the GPU every frame. Yes it's slow, but it ain't that slow :) The trick is to make the section your updating small enough to not bog down the computer. So you don't want to be updating a terrain 1000x1000 tiles. Use chunks of terrain, I use 16x16 tile chunks with 4 tri's per tile, indexed. I can update a terrain chunk in real time no problems. I was going to suggest a dynamic vertex buffer, but you don't even need that.. here's the code i use to update geometry, just use the default resource usage :