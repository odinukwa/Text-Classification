You're better off to not compress the data. rdiff-backup does analyze files for differences, but if they're compressed archives, it may not be able to find any differences and thus be forced to store the entire new file again. Also, you can use to compress the ssh connection and save some bandwidth. Finally, if possible, you should get some more bandwidth; that's barely better than dialup (or maybe it is dialup?). Backing up 12GB of data would take weeks over dialup, and even the 2GB difference could take days. 

On my Linux box, I have various daemons which can bind to all IPv6-enabled interfaces on . When they do so, Linux sends IPv4 requests to that daemon mapped as, for instance, . I would instead like IPv4 connections to be refused and only IPv6 connections accepted when a daemon binds to . To receive IPv4 connections, I want the daemon to have to explicitly bind to (as well as ). In other words, I want to run a service exclusively on IPv6, and not on IPv4. Is there a way to accomplish this? 

Another thing: Get rid of this script entirely. For starters, you really shouldn't be rebooting your server via a cron job. If you think you want to, you have another problem, which you should actually find and fix. Any reasonable server should be able to remain up and running for more than a day without intervention. Second, the command will happily alert all logged on users (and screen sessions!) automatically. If you really must reboot, try using it to schedule your reboot. 

is an IPv6 address, so you have to remove it from the list of IPv6 DNS servers, not the IPv4 list. Windows unfortunately keeps two separate lists... 

Ubuntu (finally) switched to systemd with 16.04 LTS. Under systemd, there is no output when you manually start or stop a service, and the request succeeds. There is only output when a service fails to start/stop. 

Later (post-RHEL 7) versions of firewalld do include a way to save the running configuration, and this is available now in Fedora and in RHEL 7.1. In this case the command is simply: 

When iptables reaches the end of a user-defined chain, flow returns to the next rule in the calling chain. The RETURN is therefore implicit; it does not need to be explicitly given. 

Your local X server does not support the "RANDR" extension. Most likely this is because it's a Windows-based X server. Try using a different X server, or better yet a Linux desktop (as all Linux desktops have this extension). 

You've tried to do something which is such an amazingly bad idea that firewalld simply will not let you do it. By default, an input rule allowing all traffic from localhost appears very early in the firewall, and takes priority over all user-defined rules. It is not made visible in firewalld's CLI tools, and cannot be changed or removed using them. It's theoretically possible that you may have a real need to do this, but it's extraordinarily unlikely (and note well that you may think you have a real need, and actually do not). Firewalling localhost is a great way to break your entire system, as many many programs rely on localhost communications, which is why you can't easily undo this. 

RFC 793 states repeatedly that the acknowledgement number is the sequence number of the next packet that end expects to receive. Thus it will always be higher than the sequence number. For instance, in section 2.6: 

The source code was so short and simple that it only took a moment to find the only place within FreeBSD's utility where that particular message is printed. Specifically, it occurs when PAM has failed to authenticate the user. In other words, one of these things: 

This is called an email relay, and any mail server can do it easily. A setup with Postfix, the usual default mail server, is as simple as installing it from packages and then setting in to the IP addresses of the machines allowed to send mail through that host. 

Remember that typically LXC containers drop capabilities on startup. You need to, at least, allow CAP_SYS_NICE in the container. This capability allows for calling which is the call you need to set SCHED_RR. An example for reference LXC configuration: 

This complaint is specifically about the IP address appearing in some form in the PTR record. This is not advisable for a variety of reasons, one of which as you've discovered is that many destinations will mark your mail as spam or reject it outright. Set the PTR record to something appropriate, which does not include the IP address. The actual FQDN of the server is usually the best bet. 

You specified only a path within the container for your volume. In this configuration, Docker creates a new volume each time the container is recreated. If you want the volume data to be persistent, you need to specify a path accessible to the container host where the volume data can be stored. For example, relative to your : 

You're trying to install the wrong package. First, attempt to locate the correct package containing the file you need. 

Make something up, that is unique and won't match anything else. That field in is just a key, and it's used as a lookup in the specified . If you have a static key, then all the lookups will match the same, and the limit for that zone will be effectively global. For example: 

Books are all well and good, but very out of date books may not be so useful. Even IPv6 has had significant revisions in the last ten years. The best source of truth is the relevant RFCs, both the original ones and any that are marked as having updated or obsoleted them. RFCs are specified in sufficient detail to allow conforming implementations to be written. You can learn all the details of neighbor discovery by reading RFC 4861. 

This means the files directory you use for uploads should not be under the . Of course you have to specify its location in if you already completed the installation. 

MySQL 5.6 has only just reached GA on February 5. It will take some time (days or perhaps weeks) before any packagers have stable builds available, because changing the MySQL version affects many other system packages. It will be days or weeks beyond that before Amazon AMIs become available. 

iLO 2 supports IPv4 only. (Note that 2.12 was a security and bugfix release only, and added no new features.) For IPv6 support, you need iLO 3, firmware revision 1.50 or higher, or iLO 4 (any firmware release). 

You don't. The web server is allowed to decode percent-encoded characters which don't decode to special characters before applying rewrite rules, and is allowed to decode the remainder of percent-encoded characters before passing the data to your web application. (See RFC 3986.) What you should be doing is applying the front controller pattern in your web application, and handling all the percent decoding (and request routing) yourself. In this case you will simply redirect all requests that don't match a file or directory to and then read the URL out of . This is how major PHP-based web apps like WordPress and MediaWiki handle this. 

Let us see... The IP address 165.254.162.243 is on AS14627, which is a company named Vitalwerks. WHOIS tells me that they have the entire /24. A brief look at Google tells me Vitalwerks is the business name of NoIP.com, a dynamic DNS provider. Have you installed a dynamic DNS update tool, or any other software, from this company? If so, you'll likely find it is the source. If you have not, then you may find the source is malware. A few years ago, you may recall, Microsoft got a US federal court to authorize an extremely overbroad seizure of noip.com's domains in order to stop a botnet that was using some subdomains. 

You have several locally generated and delivered messages, which you should read, and which (if you don't really want to read them on this server) you should forward somewhere. Once you know what the messages are, you can then take any appropriate action. Most likely these messages are being generated or processed by a process which still thinks the old hostname is in effect, i.e. it has not been restarted since changing the hostname, thus the old hostname shows up in the message ID. Reboot the computer to take care of this. You have one message which was attempted to be delivered via Amazon SES, but this was rejected, presumably because your mailer didn't login with the right credentials. Finally, since you say you installed virtualmin, you probably should wipe the whole thing and start over with a fresh installation which does not include such software. It's impossible to say anything further with the information given. 

Long term solution: Mobile IPv6 on the laptop. The client will then always have the same IP address when connecting to the internal resource. Short term solution: VPN on the laptop. The client will then have an IP address when within the internal network, and be able to obtain an IP address on the internal network when outside. 

The library is certainly there, but you need the 32-bit version of it to install a 32-bit RPM that depends on it. This is failing due to a packaging error on the part of whoever packaged the RPM. Try installing it yourself: 

Sorry, but CUPS is the only thing out there for Linux right now that supports what you said you want to do. Big or small, it's all you've got - as far as software goes. If you can't use CUPS, go buy a cheap print server (or an expensive one) that supports IPP and plug the printer into that. 

Pay for your Red Hat subscription and register the machine on Red Hat Network. Use a RHEL clone such as CentOS. 

If the nameservers aren't changed during the transfer, and there's no reason to think they would, then it will go fine without any noticeable interruption in service. I've transferred numerous domains using exactly this procedure. 

We can see from the call trace that Apache tried to delete a file, and got hung up waiting for a lock to be released. Since the files are on an NFS server, you should be looking at the NFS server and the network connection between the web server and the NAS. One thing you may want to make sure of is that you have explicitly specified to use NFSv4 on both ends. It is much more reliable than NFSv3 and solves a lot of problems that used to plague previous NFS versions. The server should already be doing this if it's, e.g. RHEL 6 or later. It just remains to ensure that you have specified to use NFSv4 in your clients' mount options. (For instance, filesystem type, or filesystem type with mount option.) 

You can't put sockets for interprocess communication in . RHEL/CentOS 7, Fedora, etc., use private /tmp directories, meaning each daemon configured for it (in this case, at least nginx) has a completely different view of than any other. To resolve the problem, either place the socket in another directory or use TCP connections. And don't blindly things without understanding what's going on. You'll likely open up some security hole. 

If you have three or more geographic locations you're going to deploy to, I'd go ahead and spend the effort to go multi-master. If you only have two locations, you can get by with a read replica and proxy for now. 

Fix your firewall and/or service-on-the-wrong-port issues, and you should find things start working. 

It first lays out what the perceived benefits of NAT are (and debunks them when appropriate), then describes the features of IPv6 which can be used to provide those same benefits. It also provides implementation notes and case studies. While it's too long to reprint here, the benefits discussed are: 

The permissions on the directory and/or the files within it are wrong on the remote server. You can fix these manually yourself, or just use the utility to copy your public keys over to the server. This will also fix any broken permissions of this type. 

You should be able to accomplish this using SELinux MLS (Multi-Level Security) policy as a base, and adapting it to your needs. This is not a simple task, and if you don't already know SELinux you will have to learn, or find someone who does. This is also not a policy for a one-man operation, as it splits the security roles normally handed by root three (or more) ways and you therefore ideally should have three (or more) people who administer various aspects of the system. 

The log file format is different between your two examples. Since webalizer is expecting the first format, it can't parse the second format. In the second example, fields 2 and 3 (each of which is a here) have been removed. You have a couple of options: You can edit the log file to replace the missing fields, or you can change webalizer's configuration to ignore the missing fields. Either way, you'll almost certainly have to split the log file at this change to work with it. 

allows any confined web server to read files in user home directories in . allows Apache to use its directive (i.e. URLs that look like ). If you are just mapping domain names to users' directories, it should be sufficient to enable the first one, , but if you want to use Apache user directories, you should enable both.