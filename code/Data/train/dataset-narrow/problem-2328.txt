Using this recurrence we can compute the value of $p$ on all valid $s$, $i$, and $c$ in time polynomial in $N$ and $K$. Furthermore, the predicate $\phi(c) = p(\frac{K}{2}, N, c)$ can be interpreted as "does there exist a subset of $S$ of cardinality $c$ whose sum is half of the sum of $S$?" or equivalently as "does there exist a partition of $S$ with cardinality discrepancy $|N-2c|$?". Thus, after finding all the values of $p$, we can simply look through all the values of $\phi(c) = p(\frac{K}{2}, N, c)$ and select the value of $c$ with $\phi(c)$ true for which the cardinality discrepancy $|N-2c|$ is largest. Call this value $c_0$. If $\phi(c)$ is never true then there is no partition of $S$. All that's left is to actually find the partition of $S$ one of whose sets has size $c_0$. Here's an algorithm for doing this: 

Has $C_3$ previously been studied? Is $C_3$ known to equal any other complexity/computability classes of interest? Is the class $C_3$ robust to changes in model. For example, if the TMs used are allowed to stay in place during a single transition (as opposed to always moving either left or right) or if the tape is made to be infinite in both directions instead of just to the right, does the class of languages recognizable by 3-state 1-tape TMs change? How does $C_3$ relate to the class of regular languages, $Regular$? (In particular, is every regular language in $C_3$?) 

Your problem is exactly equivalent to the 2-colorable perfect matching problem: On input a graph, color the vertices of the graph with two colors such that each vertex has exactly one neighbor of the same color. The 2-colorable perfect matching problem was introduced in "The complexity of satisfiability problems" by T. J. Schaefer and is NP-complete. 

I assume the generalization you are thinking of is the following: Given value $d$, and values $s_i$ and $r_i$ for $i = 1,2,...,k$, find (if possible) an $\alpha$ such that $$\sum_{i = 1}^k\min(r_i, s_i\alpha) = d$$ Consider the expression $\min(r_i, s_i\alpha)$. This expression is sometimes equal to $r_i$ and sometimes equal to $s_i\alpha$, with a threshold between these two behaviors at $\alpha = \frac{r_i}{s_i}$. Then consider the $k$ thresholds of this form for the $k$ different $\min(r_i, s_i\alpha)$ expressions. These thresholds separate the number line into $k+1$ sections. In each section, the behavior of each $\min(r_i, s_i\alpha)$ expression is known. Therefore, we can rewrite the expression $\sum_{i = 1}^k\min(r_i, s_i\alpha)$ for each section without the $\min$s. Then in each section we get an expression of the form $a+b\alpha = d$ which we can solve for $\alpha$; if in any section we find a value $\alpha$ that is both a solution to the equation in that section and a value within the section of the number line, then that $\alpha$ solves the whole problem. Another way of thinking about this is in terms of your idea of trying every combination of which expressions the $\min$s evaluate to. If you do it by brute force, you have to try exponentially many cases, but using the idea of these threshold values it is possible to narrow down the possibilities to just $k+1$ cases. 

One concern is that we might wish to connect two terminals with a wire but be unable to do so because any "wire" between those two terminals would have even length. However, that is not the case: we can always choose a route for a wire to make that wire have odd length (and therefore be a valid wire). Replacing any horizontal segment of wire of length 6 with the following length 7 wire segment can fix the parity of the wire length: 

The problem is NP-hard for $L = A^*$ where $A$ is the finite language containing the following words: 

Note that each element of $V_1$ has exactly two neighbors (which is ok since $d \ge 2$). This reduction is clearly polynomial time, since each part of the output instance can be computed from the input instance very quickly. Suppose the input instance in a yes instance. Then let $B$ be a clique in $G'$ of size $k'$ (which exists since the input instance is a yes instance). Let $A \subseteq E'$ contain those edges of $G'$ which are not in the clique $B$. There are $\frac{k'(k' - 1)}{2}$ edges in the clique, so $|A| = |E'| - \frac{k'(k' - 1)}{2}$. Thus we have found $A \subseteq V_1$ and $B \subseteq V_2$ with $|A| \le l = |E'| - \frac{k'(k' - 1)}{2}$ and $|B| \le k = k'$. The only thing left to do in order to show that the output instance is a yes instance is to show that $A \cup B$ is a vertex cover. So consider any edge $(e, v) \in E$ (where $e \in V_1 = E'$ and $v \in V_2 = V'$). If $e \in A$ then the edge is covered. If $e \not\in A$ then $e$ must by one of the edges in the clique $B$ (in graph $G'$). By the definition of $E$, $v$ is an endpoint of $e$ (which is an edge in the clique $B$). Thus $v \in B$ and again the edge $(e, v)$ is covered. We see that $A \cup B$ is a vertex cover. We showed above that if the input instance is a yes instance, so is the output instance. Now suppose that the input instance is not a yes instance. Suppose we have $A \subseteq V_1$ with $|A| \le l = |E'| - \frac{k'(k' - 1)}{2}$ and $B \subseteq V_2$ with $|B| \le k = k'$. Since the input is not a yes instance, there is no clique in $G'$ of size $k'$; therefore fewer than $\frac{k'(k' - 1)}{2}$ edges in $G'$ have both endpoints in $B$. Then since $V_1 \backslash A = E' \backslash A$ contains at least $\frac{k'(k' - 1)}{2}$ elements, each of which is an edge of $G'$, we conclude that at least one edge in $E' \backslash A$ has an endpoint not in $B$. Let $e = (w, v)$ be an edge in $E'$ with $e \not\in A$ and $v \not\in B$. Then the edge $(e, v)$ (which is in $E$ by the definition of $E$) is not covered, and so $A \cup B$ is not a vertex cover. We see then that in the case that the input instance is a no instance, the answer to the output instance is no as well. We showed above that the reduction is polynomial time and answer preserving. Since the input problem (clique) is NP-hard, the output problem is NP-hard as well. If $k$ is a fixed constant then the problem is polynomial time solvable The number of sets $A$ with $|A| \le k$ is $|A| \choose kl$, which is polynomial in the size of the input since $k$ is a fixed constant. Furthermore, these sets are easily enumerable. For each candidate value of $A$, we simply apply the lemma to determine whether there exists a corresponding value of $B$ such that $A \cup B$ solves the problem. If a solution is found, the answer to the overall problem is yes, and if no solution is found, the answer to the overall problem must be no. If $l$ is a fixed constant then the problem is polynomial time solvable The number of sets $B$ with $|B| \le l$ is $|B| \choose l$, which is polynomial in the size of the input since $l$ is a fixed constant. Furthermore, these sets are easily enumerable. For each candidate value of $B$, we simply apply the lemma to determine whether there exists a corresponding value of $A$ such that $A \cup B$ solves the problem. If a solution is found, the answer to the overall problem is yes, and if no solution is found, the answer to the overall problem must be no. 

Solving this problem is NP-hard. In particular, even deciding whether there exists an answer key consistent with the given answer choices and scores is NP-complete. We can prove this by reduction from 1-in-3 SAT. Given a 1-in-3 SAT formula with $c$ clauses and $n$ variables, we construct an instance of your problem with $n$ questions, each with 3 choices, and $c+1$ sample answer/grade pairs. For each variable $x$, one of the questions is "what is the value of boolean variable $x$?" and the three possible answers are "True", "False", and "17". One student answers every question with the answer $17$ and gets a score of zero. The remaining students are each assigned a clause. For every positive literal $x$ occurring in the clause, the student answers the question about $x$ with the answer "True". For every negative literal $\neg x$ occurring in the clause, the student answers the question about $x$ with the answer "False". For every other question, the student answers $17$. Every such student gets a score of one. An answer key must correspond with an assignment of binary values to the variables (since no question has $17$ as the correct answer as shown by the fact that the student who always answered $17$ got zero points). Furthermore, there must be exactly one true literal in each clause under this assignment in order for the answer key to match the scores given to the students. In other words, the satisfying assignments to the input 1-in-3 SAT formula are in a bijection with the answer keys consistent with the student scores. Clearly then, deciding whether an answer key consistent with the student scores exists is NP-hard. Similar arguments can be made to show that for example counting answer keys is #P-complete. 

You can get the situation you describe by choosing weird functions $f(n)$ and $g(n)$. For example, let $g(n) = n^3$ and $$f(n) = \begin{cases} n & \text{if $n$ is odd}, \\\ 2^{n^5} & \text{if $n$ is even}. \end{cases} $$ Then choose $L_1$ and $L_2$ as follows: $L_1$ is a language containing only strings of even length which can be decided in time $O(2^{n^5})$ but not in time $O(2^{n^4})$. The existence of such a language is pretty easy to prove from the time hierarchy theorem. $L_2$ is a language containing only strings of odd length which can be decided in space $O(n^3)$ but not in space $O(n^2)$. The existence of such a language is pretty easy to prove from the space hierarchy theorem. Then we have the following facts: $L_1 \in TIME(f(n))$: To decide whether a string is in $L_1$, simply check whether the length $n$ is even. If it is, then continue to use the $O(2^{n^5})$ time decider for $L_1$ whose existence is guaranteed by the definition of $L_1$. If $n$ is odd, immediately reject since $L_1$ does not include any odd length strings anyway. This procedure decides $L_1$, runs in time $O(n)$ when $n$ is odd, and runs in time $O(2^{n^5})$ when $n$ is even. In other words, this procedure decides $L_1$ in time $O(f(n))$. As desired, $L_1 \in TIME(f(n))$. $L_2 \in SPACE(g(n))$: By the definition of $L_2$, $L_2$ can be decided in space $O(n^3)$. Thus, $L_2 \in SPACE(n^3) = SPACE(g(n))$, as desired. $L_1 \not\in SPACE(g(n))$: Suppose for the sake of contradiction that $L_1 \in SPACE(g(n)) = SPACE(n^3)$. We know that $SPACE(n^3) \subseteq TIME(2^{O(n^3)}) \subsetneq TIME(2^{n^4})$. Thus, there exists a decider for $L_1$ which runs in time $O(2^{n^4})$. This directly contradicts the definition of $L_1$. Then by contradiction, we see that $L_1 \not\in SPACE(g(n))$. $L_2 \not\in TIME(f(n))$: Suppose for the sake of contradiction that $L_2 \in TIME(f(n))$. This means that there exists a constant $c$ and an algorithm $A$ deciding $L_2$ such that on any input of size $n$, algorithm $A$ terminates in time $c\times f(n)$. We construct a new algorithm $A'$ as follows: given some input, walk through the entire input, keeping track of whether the input length is even or odd; if at the end of the input the length is determined to be odd, return to the start of the input and run $A$; otherwise, reject. For any input of odd length, $A'$ returns the same answer as $A$. For any input of even length, $A'$ rejects, which matches the expected behavior since $L_2$ contains no even length strings. Thus, $A'$ also decides $L_2$. On even length inputs, $A'$ runs for exactly $n$ steps. On odd length inputs, $A'$ runs for exactly $2n$ steps more than $A$ requires. But $A$ requires at most $c\times f(n)$ steps, which for odd $n$ is $cn$. Thus, in all cases, $A'$ runs in at most $(c+2)n$ steps. In other words, algorithm $A'$ decides $L_2$ in time $O(n)$. But since $TIME(n) \subseteq SPACE(n)$, we can conclude that $L_2 \in SPACE(n) \subsetneq SPACE(n^2)$. This contradicts the definition of $L_2$. Thus, by contradiction we see that $L_2 \not\in TIME(f(n))$.