Many to one NAT (many computers with private addresses behind one public address) works like this: The router keeps track of outbound packets and when an answer is received it can send it to the internal computer which sent the original request. So this works fine, if you visit a website with a public ip-address. It is, however, not possible to send an initial packet from the outside to one specific computer on the inside, unless a forwarding rule is defined on the router: There is no way to address a specific computer and the router does not have information in his connection table because it is not an reply. Skype made a technique popular that is called firewall hole punching: A server with a public address is contacted by the clients. Then it sends an answer back to client A telling it to send udp packages to the router of client B on a port it expect the router of client B to use as source port for the next outbound packet. And it tells client B to send a packet to the router to client A on a port it expects the router of A to use as source port for its next outbound packet. If the prediction is correct, A and B can now talk directly which each other. Firewall hole punching requires a server with a public ip address to act as a moderator. And it requires a lot of knowledge about the implementations of common NAT router to predict the outbound source ports correctly. Although there are open source implementations available, you should try to avoid this technique because it is unreliable and causes lots of headache. Skye falls back to using the server with the public ip address to relay all packets if the predictions fail. 

Then I was under the assumption that we just draw everything directly to the screen, then when performance becomes an issue we just add a new implementation of the above like so: 

Usually in 3d drawing you want to ideally have fewer larger textures rather than lots of smaller ones, and make sure you render the same kinds of textures at the same time. So there is less texture swapping going on behind the scenes. This is not a difficult thing to do as most textures are purely used for models or terrains/structures. So you may have a terrain texture, a structures texture and a couple of player/enemy textures. Then just draw the terrain, the structures and any enemies and the player, only requiring a few texture swaps there, and if you are also using some sort of model instancing for the enemies you can get away with some other improvements there. Anyway now enter the 2d drawing world, rather than applying a texture and then drawing lots of vertices using it you are giving a texture to each draw command. So I am wondering how XNA handles this behind the scenes. Take for example a top down 2d game, you have a tileset for the level containing many ground sprites, an enemy sprite sheet which may contain anywhere from 10-20 enemies sprites and animations, then possibly a player/equipment sheet which contains anything for them. Now in this instance if I were to draw my level which was lets say 64x64 tiles (a tile being an x,y,tileSetIndex), and I have a tileset with 8x8 sprites (lets say 32x32 each): 

In Stendhal we use a relational database for game logs because that is the easiest way to allow performant ad-hoc queries. If you use a custom log format, you basically have to code all those queries when need arises. And doing that with sufficient performance gets rather difficult. Our gameEvents table has 51,429,139 rows (last year) and we have a dedicated itemlog table which has 60,360,657 rows (all time) for 15,893,831 items. 

We did something like that in Stendhal for raids. We did not aim for completely avoiding restarts. So changes to our core infrastructure services such as client/server communication do need a restart. But adding entities, creatures and NPCs, and modifying existing objects does work. (Oh, and sometimes live bug fixing, reflection can be used to manipulate even private fields). Since we do not only want new object based on new data (like another skin), but want to add new behaviour, the world program needs to be able to load new class files. We call them "scripts", but they are real compiled Java classes. Those classes implement the Script.java interface. Maria.java is a simple example. She is a new NPC that sells drinks and food to players. We can define very complex objects in there, too. A new class is loaded this way: 

assuming no real optimisations and just looping through every tile would this just retain the tilesetTexture in memory, or is it going to keep removing/adding the texture after every Draw() call? As I do not know how it can manage this unless it keeps some state under the hood between draw calls (maybe thats what Begin/End is for on spriteBatches). So will I be getting 4096 (64x64 tiles itterated) texture swaps, or will it only do 1 texture swap in this instance? 

Now in this example you could inherit, but your Update may become a bit tricky then without changing your base class to alert you if you had changed, but it is up to each scenario to choose if its inheritance/implementation or composition. Also the above implementation will re-cache within the rendering cycle, which may cause performance stutters but its just an example of the scenario... Ignoring those facts as you can see that in this example you could use a cache-able component or a non cache-able one, the rest of the framework needs not know. The problem here is that if lets say this component is drawn mid way through the game rendering, other items will already be within the default drawing buffer, so me doing this would discard them, unless I set it to be persisted, which I hear is a big no no on the Xbox. So is there a way to have my cake and eat it here? One simple solution to this is make an ICacheable interface which exposes a cache method, but then to make any use of this interface you would need the rest of the framework to be cache aware, and check if it can cache, and to then do so. Which then means you are polluting and changing your main implementations to account for and deal with this cache... I am also employing Dependency Injection for alot of high level components so these new cache-able objects would be spat out from that, meaning no where in the actual game would they know they are caching... if that makes sense. Just incase anyone asked how I expected to keep it cache aware when I would need to new up a cachable entity. 

In Stendhal we solved the performance issue by adding game events to a queue and then processing them asynchronously in the background. In our case the events are not just records but objects which have a little bit of logic because in some cases we need to do two inserts with a link between them. For example the first time a item is handled in game, it needs to be inserted into the item table first before an item-event can be logged. But writing the log is only one side of the problem: What questions do you want to answer with the logs? It is easy to just read the complete log in chronologically order; or to filter it for one player. But there might be questions like: 

I have quite a lot of custom content pipeline components, and I was just wondering if under the hood XNA knows about these things when doing its magic... Here is my scenario. I have animation objects which basically contain 2d animation frames and timings etc, which can be loaded as self contained objects or can be embedded within other object. Now I was expecting that my CustomObjectAWriter could contain an instance to AnimationObjectAWriter and internally just call through to that to write out each animation object, i.e: 

This is a slightly vague one but I am currently looking at a couple of areas of my current framework, such as spatial partitioning and UI based menus, and with UI menus it makes sense to have an event based system so you can tell if the user has clicked on it etc... its like your own small version of winforms. However for some other areas it got me thinking that I could expose a lot of evens for other things, such as when an object moves so it could be re-allocated in a spatial tree of some kind if needed, or if it needed to calculate a collision it could return an event. Anyway I quite like using events everywhere as it decouples you from having to know about who needs to know what, however I was wondering if there were any hidden gotchas with using events on the Xbox/Phone. I read a few older posts that mentioned that there are performance penalties with events on non PC platform (i.e $URL$ So is this still an issue or has XNA and the .net implementation on these machines improved in this area, as it would be nice to add events of all kinds to high level entities, like Player.HealthChanged, Creature.AnimationStateChanged etc, but I dont want to go exposing these for usage if there is a major performance overhead with doing so... 

In object oriented designed there is the sate pattern for this. It boils down to having one interface per state machine. And a class per possible state which implements this interface. To give an example: There would be an interface DamageMode and subclasses NormalDamageMode, InvulnerableDamageMode and InvincibleDamageMode. Whenever the player collidates with an enemy the method DamageMode.collision(enemy) is called. It is handled by the class responsible for the current state. So if damageMode == NormalDamageMode the player will be damaged and the state variable will be set to InvulnerableDamageMode. In InvulnerableDamageMode nothing happens and in InvincibleDamageMode the enemy will be damaged. Of course there needs to be timers to go back from InvulnerableDamageMode and InvincibleDamageMode to NormalDamageMode. The main advantage of the state pattern compared to if-elseif-elseif-elseif-blocks is that it allows to structure your code better. 

However as AnimationObjectAWriter has its Write method protected I am unable to access it, however I was wondering if WriteObject will know of the AnimationObjectAWriter so if I did would this work? 

I am in a situation where I am writing a framework in XNA and there will be quite a lot of static (ish) content which wont render that often. Now I am trying to take the same sort of approach I would use when doing non game development, where I don't even think about caching until I have finished my application and realise there is a performance problem and then implement a layer of caching over whatever needs it, but wrap it up so nothing is aware its happening. However in XNA the way we would usually cache would be drawing our objects to a texture and invalidating after a change occurs. So if you assume an interface like so: 

I am looking for a lightweight javascript library that allows the server to push update information to the client reliably and regularly. We use a fixed turn time of 300ms and often there are only about 20 bytes of changes. So doing polling using XMLHttpRequest would imply a huge overhead (3-way tcp handshake, http request headers, http response header). There area number of alternatives, but they have limited browser support: 

How to prevent abuse of the decrypted password elsewhere? The second attack vector can be prevented by not storing the real password in any decryptable form at all. But a token generated by the server or a password hash that the server will accept instead of the password. How to prevent unauthorized access to your game? We are assuming here, that the attacker has access to the users computer in order to retrieve the password file. Based on this assumption it is likely that the attacker has write access, too. But if he has write access, he can modify program files and do all sorts of nasty things. So we have lost. That being said, there is a number of things you can do to make it more difficult for the attacker. Based on my experience with Stendhal most attacks are done by family members, who don't have a deep knowledge. So easy tricks make a difference: 

Hopefully this will be a simple answer, but as RenderTarget2Ds are Texture2Ds under the hood I was wondering how it handles swapping in and out. Lets say you create a default one and assign it as the render target at the start of your Game.Render(). Then at a few points during your render process a new RenderTarget is swapped in, rendered to and then kept as a texture for later and the original one is then put back in. Some more rendering occurs and another entity swaps in its own RenderTarget, puts it in another texture and then swaps back to the default RenderTarget, and finally everything is rendered and done. Now as the RenderTarget2D is a Texture2D without setting preserve mode on the RenderTarget will you be able to swap it out and swap it back in without losing your current contents of the RenderTarget? I know there are some issues with the Preserve settings for RenderTargets on the Xbox, but if the render targets are being stored as a class member somewhere, are they subject to different rules? I am sure the answer is, they obey the RenderTargetUsage behaviour, and will be subject to the same rules regardless of how they are stored in the game, but I just wanted to be sure. 

Normally the main compatibility issues are between major versions. If you compile for Java 6, it will not run on Java 5 but throw an java.lang.UnsupportedClassVersionError. So a program complied on Java 6 Update 24 is supposed to work on lower versions of Java 6. But there is a small risk that you invoke a method that was added in a minor release, resulting in a java.lang.IncompatibleClassChangeError or one of its subclasses. The chance for this to happen is really small, usually you get away without explicitly testing older versions. Stendhal targets Java 6, but tries to be mostly compatible with Java 5. Over the last year the number of users with Java 5 has decreased a lot. I think that is because of the huge improvements Sun made to the automatic update of Java. It is now around 0.1% for us, so we are considering dropping support for Java 5 completely.