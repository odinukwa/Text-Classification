Theorem provers have been used to some extent for proving correctness of software, hardware and protocols. See, for example, here or here. The problem of data flowing in undesired ways through programs (an thus causing a potential leak) has been modelled theoretically using the notion of (non-)interference; get pointers here. 

The area you want to look at for answers to is machine learning. You have desribed a graphical model. I think in this case methods as easy as Belief Propagation should suffice. 

This is a rephrasing of Emanuele Viola's answer with the goal to be more understandable. We show that the given problem $P$ is undecidable by reducing the general halting problem $H$ to it. Let $(M, x)$ be any instance of the halting problem, that is we have to decide wether $M(x)\downarrow$ ($M$ halts on $x$). Construct a Turing machine $M^*$ that works as follows: 

Let me mention linear bounded automata (LBA) which can compute a proper subset of the function Turing machines can handle. LBA do model real computers better than Turing machines in the sense that no computation can use an infinite amount of space but there is no (constant) bound on space either. Of course, real computer do not have to have a linear bound. 

For a quantum channel $\Phi$, let us write $J(\Phi)$ to denote the associated state: $$ J(\Phi) = \frac{1}{n} \sum_{1\leq i,j \leq n} \Phi(|i \rangle \langle j|) \otimes |i \rangle \langle j|. $$ Here we are assuming that the channel maps $M_n(\mathbb{C})$ (i.e., $n\times n$ complex matrices) to $M_m(\mathbb{C})$ for whatever choice of positive integers $n$ and $m$ you like. The matrix $J(\Phi)$ is sometimes called the Choi matrix or Choi-Jamiolkowski representation of $\Phi$, but it is more frequent that those terms are used when the $\frac{1}{n}$ normalization is omitted. Now, suppose that $\Phi_0$ and $\Phi_1$ are quantum channels. We may define the "diamond norm distance" between them as $$ \| \Phi_0 - \Phi_1 \|_{\Diamond} = \sup_{\rho} \: \| (\Phi_0 \otimes \operatorname{Id}_k)(\rho) - (\Phi_1 \otimes \operatorname{Id}_k)(\rho) \|_1 $$ where $\operatorname{Id}_k$ denotes the identity channel from $M_k(\mathbb{C})$ to itself, $\| \cdot \|_1$ denotes the trace norm, and the supremum is taken over all $k \geq 1$ and all density matrices $\rho$ chosen from $M_{nk}(\mathbb{C}) = M_n(\mathbb{C}) \otimes M_{k}(\mathbb{C})$. The supremum always happens to be achieved for some choice of $k\leq n$ and some rank 1 density matrix $\rho$. (Note that the above definition does not work for arbitrary mappings, only those of the form $\Phi = \Phi_0 - \Phi_1$ for completely positive maps $\Phi_0$ and $\Phi_1$. For general mappings, the supremum is taken over all matrices with trace norm 1, as opposed to just density matrices.) If you don't have any additional assumptions on the channels, you cannot say too much about how these norms relate aside from these coarse bounds: $$ \frac{1}{n} \| \Phi_0 - \Phi_1 \|_{\Diamond} \leq \| J(\Phi_0) - J(\Phi_1) \|_1 \leq \| \Phi_0 - \Phi_1 \|_{\Diamond}. $$ For the second inequality, one is essentially settling for the specific choice $$ \rho =  \frac{1}{n} \sum_{1\leq i,j \leq n} |i \rangle \langle j| \otimes |i \rangle \langle j| $$ rather than taking the supremum over all $\rho$. The first inequality is a bid tougher, but it would be a reasonable assignment question for a graduate course on quantum information. (At this point I should thank you for your question, because I fully intend to use this question in the Fall offering of my quantum information theory course.) You can achieve either inequality for an appropriate choice of channels $\Phi_0$ and $\Phi_1$, even under the additional assumption that the channels are perfectly distinguishable (meaning $\| \Phi_0 - \Phi_1 \|_{\Diamond} = 2$). 

Peter Shor essentially suggested the formulation 1. in his comment above, and I’ll let experimentalists answer this question. The question 2. seems strange, but I bring it forward because its answer is positive : In a 2009 paper (arXiv:0909.4673, paywalled version), Dan Browne, Elham Kashefi, and Simon Perdrix showed that Measurement Based Quantum Computing (MBQC), is equivalent up to a classical side-processing of logarithmic depth, to the quantum circuit model augmented with unbounded fanout gates. They basically recall that the unbounded parity gate is a Clifford gate and can be therefore be expressed as a measurement pattern of constant depth (arXiv,paywalled PRA) and show that a fanout gate is nothing else than a parity gate “sandwiched” between two layers of Hadamard gates, and can therefore be simulated in constant depth. Therefore, your question 

In his 1995 paper Polynomial-Time Algorithms for Prime Factorization and Discrete Logarithms on a Quantum Computer, Peter W. Shor discusses an improvement on the order-finding part of his factorization algorithm. The standard algorithm outputs $r'$, a divisor of the order $r$ of $x$ modulo $N$. Instead of checking if $r'=r$ by checking if $x^{r'}\equiv 1 \mod N$, the improvement is the following : 

There will generally not exist a set of $n$ linearly independent vectors $x$ such that $Ax = x$; this can only happen for $A$ being the identity matrix. On the other extreme, there may be no such vectors at all. For example, the matrix $$ A = \left(\begin{array}{cc} 0 & 1\\ 1 & 1 \end{array}\right) $$ has full rank, but there are no nonzero vectors $x$ such that $Ax = x$. This is consistent with the fact that the characteristic polynomial of $A$ is $\lambda^2 + \lambda + 1$, which is irreducible over GF(2). If you want to find the maximum number $k$ of linearly independent vectors $x$ such that $Ax=x$, compute the nullspace of $A - I$. This can be done using Gaussian elimination in time $O(n^3)$. Several other algorithms for this task also exist, and are described in textbooks on computational linear algebra. 

We will apply the main theorem from that paper for $A_1$ and $A_2$ being languages and $\mathsf{C}_1$ and $\mathsf{C}_2$ being complexity classes as follows: 

There are many examples in quantum information and computation where quantities of interest are expressible as optimal values of semidefinite programs. Here are a few beyond those mentioned in the question: 

As suspected by Peter Shor, it is not true. Almost a counterexample Let $ω_{ABCD}=Φ_{AC}⊗ψ_{B}⊗ψ_{D}$, with $Φ$ being a maximally entangled state and $ψ$ a pure state. Let $U$ be the unitary $I_A⊗σ_{BC}⊗I_D$ swapping $B$ and $C$, so we have $ω_{ABCD}=Φ_{AB}⊗ψ_{C}⊗ψ_{D}$. All the systems are supposed to be of dimension $d$. Your assumptions are almost fulfilled, since $$\begin{align} S(ω_B)=0&<S(τ_B)=\log d \\ S(ω_A)=\log d&\ge S(τ_A)=\log d \tag1 \\ S(ω_{AB})=\log d&> S(ω_B)=0 \end{align}$$ but we have $$\begin{align} S(τ_{AB})-S(ω_{AB})=0-\log d&< S(τ_{B})-S(ω_{B})=\log d -0 \end{align}$$. In this case, the condition (1) is not fulfilled, since you asked for a strict decrease in $A$’s entropy, and kept $S(A)$ constant with a unitary not touching $A$. This can be changed by perturbing $ω$ and $U$, to have a slight decrease in $A$’s entropy. A real counterexample A concrete way to do this without a pertubative argument is to add another system $A'$ to $A$, which is entangled to another system $D'$ given to $D$. $$\begin{align} ω_{AA'BCDD'}&=Φ_{AC}⊗Φ_{A'D'}⊗ψ_{B}⊗ψ_{D}\\ U&=σ_{A'D}⊗σ_{BC}⊗I_{D'}\\ τ_{AA'BCDD'}&=ψ_{A'}⊗Φ_{AB}⊗Φ_{DD'}⊗ψ_{C} \end{align}$$ In that case, we have $$\begin{align} S(ω_B)=0&<S(τ_B)=\log d \\ S(ω_{AA'})=2\log d&> S(τ_A)=\log d \\ S(ω_{AA'B})=2\log d&> S(ω_B)=0 \\ S(τ_{AA'B})-S(ω_{AA'B})=0-2\log d&< S(τ_{B})-S(ω_{B})=\log d -0 \end{align}$$ Despite all your assumptions fulfilled by at least a $\log d$ margin, your final inequality is violated by a $3\log d$ margin The physical intuition begin these counter examples : conditional entropies The inequality you want to prove and your third assumption are thinly disguised conditional entropies. Moving $S(ω_B)$ to the left-hand side of our third assumption, one obtains $$H(A|B)_{ω}≥0,$$ which is verified by all state which are separable across the $A|B$ split (including my counterexamples.) Your final condition is equivalent to $$H(A|B)_{τ}\stackrel{?}{≤}H(A|B)_{ω}.$$ Since the right-hand side is positive by assumption, any negative left-hand side is a counterexample. $H(A|B)$ can only be negative for states which are entangled accross the $A|B$ split. In both my counterexamples $H(A|B)_{τ}=-\log d$ because of the entangled state $Φ_{AB}$. The increase in $B$’s entropy is provided by the move of the half EPR pair from $C$ to $B$. In the second counter example, in order to have a decrease of $AA'$’s entropy, I artificially increased the initial entropy of $A$ with the state $Φ_{A'D'}$. This entropy is sent to $D$ by $U$. 

Ad 4: You break your desired invariant for $R$ here since the last node in $x$ does not necessarily occur in $w$ at all. Example: $x = abc, y=adc, z=adce, w=ae$ I believe a worst-case instance might be the complete graph with $w(i,k) = 1$ for $i$ the starting node and all $k\neq i$, and $w(j, k) = 0$ for all $j,k \neq i$. Paths with more nodes will never remove those from earlier iterations so the tree is never shrunk at all, growing up to having $n!$ nodes. 

String Matching, used all the time in application software and on database level. In the exact case, there are several quite involved algorithms (KMP, Boyer-Moore) with some that achieve sublinear expected runtime. They are also interesting to study from a CS point of view. Approximate string matching, that is alignments, is probably even more interesting. You know "autocorrecting" features? Also, searches in noisy string data (e.g. DNA) is done using alignments. 

You can use attribute grammars. They give a formal framework for describing transformation of trees but are also in practical use, e.g. in ANTLR where you can define compiler from trees to trees (or code) using tree grammars . 

For the sake of clarity, the fact we will prove is $\mathsf{NP} \not\subseteq \mathsf{P/poly}$ implies $\mathsf{NPI} \not\subseteq \mathsf{P/poly}$. Under the assumption that $\mathsf{NP} \not\subseteq \mathsf{P/poly}$ we have $A_1\not\in\mathsf{C}_1$ and $A_2\not\in\mathsf{C}_2$. It is clear that $\mathsf{C}_1$ and $\mathsf{C}_2$ are closed under finite variations. Schöning's paper includes a proof that $\mathsf{C}_1$ is recursively presentable (the precise definition of which can be found in the paper), and the hardest part of the argument is to prove that $\mathsf{C}_2$ is recursively presentable. Under these assumptions, the theorem implies that there exists a language $A$ that is neither in $\mathsf{C}_1$ nor in $\mathsf{C}_2$; and given that $A_1\in\mathsf{P}$, it holds that $A$ is Karp-reducible to $A_2$, and therefore $A\in\mathsf{NP}$. Given that $A$ is in $\mathsf{NP}$ but is neither $\mathsf{NP}$-complete nor in $\mathsf{NP} \cap \mathsf{P/poly}$, it follows that $\mathsf{NPI} \not\subseteq \mathsf{P/poly}$. It remains to prove that $\mathsf{NP} \cap \mathsf{P/poly}$ is recursively presentable. Basically this means that there is an explicit description of a sequence of deterministic Turing machines $M_1, M_2, \ldots$ that all halt on all inputs and are such that $\mathsf{NP} \cap \mathsf{P/poly} = \{L(M_k):k=1,2,\ldots\}$. If there is a mistake in my argument it is probably here, and if you really need to use this result you will want to do this carefully. Anyway, by dovetailing over all polynomial-time nondeterministic Turing machines (which can be simulated deterministically because we don't care about the running time of each $M_k$) and all polynomials, representing upper bounds on the size of a Boolean circuit family for a given language, I believe it is not difficult to obtain an enumeration that works. In essence, each $M_k$ can test that its corresponding polynomial-time NTM agrees with some family of polynomial-size circuits up to the length of the input string it is given by searching over all possible Boolean circuits. If there is agreement, $M_k$ outputs as the NTM would, otherwise it rejects (and as a result represents a finite language). The basic intuition behind the argument (which is hidden inside Schöning's result) is that you can never have two "nice" complexity classes (i.e., ones with recursive presentations) being disjoint and sitting flush against each other. The "topology" of complex classes won't allow it: you can always construct a language properly in between the two classes by somehow alternating between the two for extremely long stretches of input lengths. Ladner's theorem shows this for $\mathsf{P}$ and $\mathsf{NPC}$, and Schöning's generalization lets you do the same for many other classes. 

If I understand correctly, you are clear about converting functions that contain no other function calls but to themselves. So assume we have a "call chain" $F \to F_1 \to \dots \to F_n \to F$. If we furthermore assume that $F_1, \dots, F_n$ are not recursive themselves (because we have converted them already), we can inline all those calls into the definition of $F$ which thusly becomes a directly recursive function we can already deal with. This fails if some $F_j$ has itself a recursive call chain in which $F$ occurs, i.e. $F_j \to \dots \to F \to \dots \to F_j$. In this case, we have mutual recursion which requires another trick to get rid off. The idea is to compute both functions simultaneously. For example, in the trivial case: 

They are not and they can not, in general. We can only treat a countable number of inputs (and outputs and functions) with our models of computation. In particular, any input has to be finite but not all real numbers have finite representations. You could, I guess, assume some kind of oracle that yield the next digit of a certain real number upon request (sth like a stream). Otherwise you will have to live with (arbitrarily precise) approximations. 

Brief (negative) answer This claim is incorrect as soon as you have three (or more) qubits, as shown by the GHZ paradox, briefly described below, which shows a 3-partite Bell inequality which is beaten by a state stabilized by Pauli operators, which can be prepared and measured by Clifford operations. This paradox is named after Greenberger, Horne and Zeilinger, who found it in 1989 (2007 arXiv reprint here). The point is that the Gottesman-Knill theorem does not care about locality, but on simplicity. The Gottesmann-Knill theorem (wiki, arXiv) gives a polynomial hidden variable theory for a state constructed with Clifford gates. Nothing prevents this theory to be nonlocal, as the GHZ state shows, but its complexity is bounded : a $n$-qubit state is described by $2n²$ binary hidden variables. On the other hand Bell inequalities characterize local hidden variable theories, without taking care of their complexity. The violation of a Bell inequality by the GHZ states means that it cannot be described by a model where each player has access to a different local hidden variable. Details of the GHZ paradox The paradox can be explained by the following game, with 3 cooperating players and a referee. the referee asks a question, either $X$ or $Y$ to each player, which answers ±1 without communicating with the other players. The referee either asks $X$ to all the players or asks $X$ to one of them and $Y$ to the others. The players win if the product of their answers obeys the equality below corresponding to the question asked: $$\begin{align} XXX&=+1\\XYY&=-1\\YXY&=-1 \\YYX&=-1 \end{align}$$ It is easy to see that the above set of equation is not consistent, and tha no local hidden variable theory allows to win the game with a probabiliyt greater than 3/4. On the other hand, if each of the player has a qubit of a GHZ state $|\mathrm{GHZ}\rangle:=(|000\rangle+|111\rangle)/\sqrt2$, they can win with certainty. Indeed, $|\mathrm{GHZ}\rangle$ is stabilized by the following Pauli operators : $$\begin{align} S_0&=+XXX\\S_1&=-XYY\\S_2&=-YXY \\S_3&=-YYX. \end{align}$$ Therefore, measuring the Pauli operators corresponding to the referee’s question allows the players to always win the game, and therefore violate a Bell inequality with certainty. Furthermore, this state can be prepared from Clifford operations, which invalidates the idea expressed in the paragraph you cite. 

Imho this is one of the few key points in (TM) algorithmics that you have to accept, as it is a very dry fact with little to understand. You could try to derive a contradiction from the students' wrong premise. By the same reasoning they apply to KNAPSACK, integer factorisation is in polynomial time and even reasonably fast. Why is it that common encryption methods can rely on factorisation being hard? 

A professor at my university does this in his algorithms course. His language of choice is Modula. I don't think the particular choice of language matters, though. Just stick to one (per paradigm) that fits your level of abstraction best. 

It is not allowed to be larger, it has to be larger! If you allow the right side being shorter, you have context sensitive deleting grammars which have the same power as unrestricted grammars, thus leaving the realms of CSL. The space limitation you mention relates to the automaton concept that is equivalent to context sensitive grammars, not the grammars itself. 

It was the first to have impact and thus has been established, especially in complexity theory. This is a weak reason, but people work that way. We work on old open problems first instead of declaring new ones. 

No relationship is known to hold between QMA and AM, and it is reasonable to conjecture they are incomparable. If QMA were proved to be contained in AM, it would be an absolutely enormous result in quantum complexity. Of course it would imply that BQP is in PH, which itself would be huge, but it would go beyond that -- it would surely require major revelations about the structure of quantum algorithms and quantum certificates. Having said that, the evidence against is not very convincing. An oracle relative to which QMA is not contained in AM would help, and it seems like such a result may not be far off -- but we don't even have this yet. A proof of the reverse containment, AM in QMA, would also be huge. At least here we have an oracle relative to which AM is not contained in QMA (and in fact is not even contained in PP). 

This is called the (linear) assignment problem. It can be solved efficiently through linear programming over the Birkhoff polytope. 

For a given choice of complexity classes $\mathsf{C}$ and $\mathsf{O}$, by which we mean sets of languages and nothing else, the class $\mathsf{C}^{\mathsf{O}}$ is not well-defined: we need the definition of $\mathsf{C}$ to determine how oracle queries are defined. Sometimes even then there could be ambiguities that need to be resolved, or the definition might not provide a reasonable notion of an oracle query at all. (Attaching oracles to space-bounded complexity classes is one example in the first category, where the relativized classes we obtain are very sensitive to the exact capabilities of the oracle tape and whether we consider that it contributes to our space bounds.) So, I don't think you can possibly say anything about $\mathsf{C}^{\mathsf{O}}$ without using the definitions of the classes, because if you don't use the definition of $\mathsf{C}$ you aren't working with a well-defined mathematical object. If I have misunderstood your question, please clarify what sort of properties of $\mathsf{C}$ and $\mathsf{O}$ you permit to be used.