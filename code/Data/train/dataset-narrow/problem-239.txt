When we talk of console connection, i understand the following: Someone has a physical access to the device(say, a router)and has inserted a cable into the console port of the router/switch.The other end of this cable goes into the client(say my laptop) hosting some application like . Q1: Is the above understanding correct ? Q2: But quite a few times, i hear that devices which are thousands of miles away can also be accessed by .Is this actually possible? How ? Q3:Using this access, they bring the connectivity up. Henceforth, the device can be accessed using an ip address. Please explain how this is achieved. Q4:What we did in step 3(Q3 actually), is it called (out of band access)? 

In one of the articles i read the following regarding Bridge assurance: "When enabled, BDPU’s are sent out all ports including the backup and alternate for each Hello Period. How this feature works is that it monitors the receipt of BPDUs on point to point links. If it does not hear a reply it changes the port state to an inconsistent state. This prevents any frames forwarding and a loop is avoided. The same is true of UDLD aggressive mode where a port err-disables." Q: When bridge assurance is enabled on a port, does that mean that it will start sending out BPDUs(irrespective of it's STP state)? If Bridge Assurance is enabled on a BLOCKED port, will the Blocked port also start sending BPDUs? If so, why? From what i know, the BPDUs are sent out ONLY from Designated ports once the STP is converged. Please correct me if i am wrong. 

Short answer: no. While the STP handover in step 4 or step 3 is usually faster than 1 second there's always a gap. Make sure you're using RSTP, MSTP or RPVST though. The original and largely obsolete STP is slow on convergence. One tiny thing might reduce the gap a little further: before step 3, decrease the trunk's STP priority value below that of the yet active port. This will already initiate the handover in step 3, so it doesn't need to be a shutdown reaction but a more 'flowing' process. As this seems to be very delicate connection I'd stage the exact process in a lab before doing it in production. 

With FTTx they likely use an obligatory ONT/router that you can just interface with Ethernet. However, the 827 is pretty aged and seems to run only 10 Mbit/s - unless the customer doesn't require any significant speed, a new router is probably indicated... 

The thing that makes most routers static is the localized uplink using landlines. These localized uplink are required for high-speed and high-volume connectivity. However, there are also a lot of (small-ish) 3G/4G routers around, using a mobile network as uplink - many of these routers are mobile themselves. Also, quite a few medium-sized networks are around on board of trains, planes and ships. Technically, there's no reason mobile routers are limited to simple hotspots and such, except for the speed/volume problem and associated cost. 

Q1:As you see, my BGP neighborship is stuck in active state.From what i understand, R1 expects the neighborship packets from R2 with a source-ip of If you do on R2 for 11.11.11.11, you see that it is learnt via as . Therefore, the bgp neighborship packets sourced from R2 will use this egress source ip() Please confirm if my understanding is correct Q2:I add the following on R2. 

So essentially, as we place a router in a network and assign ip addresses, we are creating new broadcast domains. 

While reading up on front-door vrf concept here, i am just wondering , what if we made the network statements more precise/specific or used different subnets altogether, we would never have our tunnel go down due to Can you please confirm if this is a good approch to understanding concept? 

From the cisco docs i have: "vPC and HSRP/VRRP Object Tracking As Figure 67 suggests, it’s important not to use HSRP/VRRP link tracking in a vPC configuration. Assume HSRP/VRRP object tracking is configured on both vPC peer devices and L3 uplink failure occurs on switch 7K2. This event triggers the HSRP/VRPP object tracking and the resulting SVI with associated HSRP/VRRP configuration is set to DOWN state. So everytime 7K2 receives a frame destined to HSRP/VRRP vMAC, it bridges this frame over vPC peer-link because the other vPC peer device is able to process this frame (as SVI with associated HSRP/VRRP configuration is still in UP state). Using vPC with HSRP/VRRP object tracking may leads to traffic blackholing in case object tracking is triggered: the reason is that vPC systems will not forward a packet back on a vPC once it has crossed the peer-link (because of the vPC loop avoidance rule), except in the case of a remote vPC member port failure. " Refer the attached image: 

Internet links through geostationary satellites suffer from very high latency - something like 500 to 600 ms RTT as minimum - each bit needs to travel some 36,000 km twice per direction. Less generous provisioning can easily increase latency to 1500(!) ms and more. It's OK for background data transmission, but a pain for interactive use and completely unusable for real-time applications like VoIP. 

If you want to do this on layer 2 entirely, you need to remove regular ARP from the servers. You can either filter ARP on the OS level (e.g. Linux with arptables) or on the switch level using ACLs. Then, you generate gratuitous ARP somewhere to make the clients use the destination MAC that's currently desired. Doing this on layer 3 requires a router in between. There are two basic variants. 

To be exact, each switch removes the (layer 1) Ethernet packet around each (layer 2) frame on receipt and puts a new Ethernet packet around it when forwarding. So, layer 3 uses layer 2 for transport which in turn uses layer 1 for transport. Layer 1 is where the bits actually get moved. 

As you see, on R1, the route to 100.0.0.0 no longer exists. Moreover, the BGP vrf peering is in Active state. Why is this happening ? is there any relation between and ? Is it mandatory for to have neighbor activated for vrf routes to be exchanged? 

ICMP is the result of initiating the ping from a source to a destination.It has got nothing to do with ARP as such. But for any 2 devices to talk to each other, each device would need to know the or layer 2 address of the other device(assuming the devices are in same network; if not in same network,they need to reach their gateway at least). This is where ARP comes in. ARP says, can you give me the mac address for this IP address? ARP helps in building the control plane(say building a road), before the actual ICMP traffic in this case(the data plane) starts moving. 

I have to make sure that the loopback interface of R1(1.0.1.1/32) is learnt on R2 but with a few constraints. Step1: The loopback of R1 is learnt in global routing table of R2 via ospf Step2: R2 and R3 are ebgp neighbors for address-family ipv4 (on interface f0/2--which is in global routing table) and address-family ipv4 vrf (on interface f0/1 which is part of vrf TEST on both R2 and R3) Step3: At R2, I redistribute the ospf learnt routes to BGP (ipv4 address-family). Step4: R3 learns the bgp routes from R2 via ebgp (with a next hop of 192.16.2.9) in global routing table. Step5: At R3, I do a route-leaking from the bgp ipv4 address family to bgp vpnv4 vrf TEST address family for 1.0.1.1/32 So, R3 has a route to 1.0.1.1/32 in vrf TEST with a next hop of 192.16.2.9 (which is in global routing table) Step 6: R2 learns again the 1.0.1.1/32 route via ebgp address-family ipv4 vrf TEST with a next hop of 192.16.1.10 Now my objective is to make sure R2 can ping the 1.0.1.1/32 via the vrf TEST(but as expected it fails) Any suggestions on how to get the above scenario working. (One of the ways,this can be done is to configure the interface f0/2 on both R2 and R3 as below: 

UDP poses a problem for NAT as there is no traffic to indicate whether a connection (port pair) is in use any longer or not. UDP reverse routes have to aged out in contrast to TCP connection states which can usually be tracked by traffic and just need some timeout for cleaning up. Imagine a DNS request: a client sends a UDP datagram to an outside IP address. The NAT router translates the source address & port and needs to remember where to forward any reply to - but it can't be sure when the replies are actually finished. Aging out these entries too fast breaks several protocols, aging them out too slowly wastes router resources (to the point where it doesn't work reliably any more). 

10BASE-FX is no official IEEE 802.3 standard - various, non-compatible versions may exist. The 10 Mbit/s standard PHY is (was) 10BASE-FL. Fast Ethernet has 100BASE-FX as common standard. These are physical layer standards that define the way data is transmitted on the wire/fiber, what kind of cables are required etc. 10BASE-T requires category 3 cables, 10BASE-FL runs on pretty much any fiber, usually FDDI 62.5 µm multimode fiber was used. 100BASE-FX also used FDDI fiber but was also very often deployed over OM1. Later and faster physical layers require better, "faster" copper cable categories or fiber types. The "boxes" you refer to can be any type of network equipment: repeaters, hubs, switches, routers, media converters, ... 

I want to ping from R2 to vrf lo0 of R1; but it fails, even though i have configured static route leaking. Please suggest why it fails 

I am reading up on VxLAN and understand the encapsulation process somewhat as below: Step1: Take your original Ethernet frame. Step2:Put it inside VxLAN encapsulation. Step3:VxLAN should then go inside of UDP header. Step4:UDP goes inside of IP(this should be the transport IP, i guess) Step5: IP goes inside of whatever the transport is(e.g.Ethernet) Q1: Please confirm if the above understanding is correct. Q2:Why do we need VxLAN header to go inside UDP, why not send it over plain IP? Q3:In other tunnel mechanisms, like the OTV, we don't use any layer 4 protocol(like TCP or UDP), so why use it here? Any specific reasons. Q4: Why use UDP(since it is best-effort based), why not use TCP? Q5: Can i look at VxLAN the way i look at HTTP or Telnet(both are applications and operate at layer 7), HTTP uses TCP port 80, telnet uses TCP port 23, what i am trying to understand is VxLAN an application that operates at layer 7 and fits into osi model ? Also, which OSI layer would OTV be operating at and why?One answer below says that OTV can be done using UDP as well rather than MPLS/GRE, does that make OTV a protocol that operates at layer 7? I have also attached a snapshot of packet capture of VxLAN header from one of the video lectures. 

It depends on what layer you want to/can discover devices. At the link layer, LLDP comes to mind but it requires you to directly interface with the device and only gives just a few items. In a layer 2 network, you can scan for MAC/IP addresses by ARP. The vendor specific part (OUI) of the MAC tells you the vendor. Reverse DNS possibly tells you the device name. When it comes to applications, it gets hard. You'd need to do a port scan which takes quite a while and only tells you on which ports a device accepts connections. Port probing might reveal what is behind a port but requires to know what you're looking for. SNMP is a standardized protocol for exactly this purpose and it allows you to efficiently collect a wide range of information. If you want to collect detailed info without SNMP you'd probably need to do it manually (ie. look at each config). 

Specifications from most vendors follow the same rules: Bandwidth from non-blocking ports is simply added and counted twice for full-duplex: 40 GbE ports => "80 Gbit/s" - this is a theoretical in-flight maximum The packet forwarding rate is a bit more real-life. It's the (best case) forwarding capacity of the backplane. Unlike bandwidth it's only counted once. A 40-port GbE device has a physical limit of 10^9/672*40 = 59.5 Mp/s. (672 bits is the minimum Ethernet packet size.) A lower forwarding rate means you won't get full wire speed with small packets. Note that the packet forwarding rate is best case - any additional processing (ACLs, NAT, firewall rules, ...) may eat into the forwarding rate, exactly how depends on the device and its architecture. 

Q1:As you see R1, learns the route 100.0.0.0 in the vrf TEST11. Even though i did not activate the neighbor under , but still R1 learns that route. How? Is the acting as the transport carrier for that route? Q2:In another scenario, i removed the neighbor from the vpnv4 address family on both R1 and R2 as seen below On R1 

Is it possible to implement the below topology? I see that there is a port channel going downstream to the firewalls. By any chance, are the firewalls running as one virtual entity? As we see here are 2 different downstream firewalls, and we cannot run the portchannel. So if we cluster the FW01 and FW02 as a single entity and run the port channel in no LACP suspend mode, does that possibility exist? Note:SW01 and SW02 are N5k Peer KA link denotes peer keepalive link. Peer link denotes vpc peer link. 

Similary for X.600 part. Q1:What exactly is the bridge group part used for?What if i remove it? Q2:I understand that any frame coming to the switch with a tag of 500, will be put onto interface Bundle-Ether1.500 and also onto interface Bundle-Ether2.500. This tag will be stripped(at ingress ) and pushed back at egress(when the frame exits these interfaces(because of symmetric command). Is that correct understanding? Q3:Bridge-domains represent ONE broadcast domain.So all the interfaces under one bridge domain are part of SAME broadcast domain? As for above, the Bundle-Ether1.500 and Bundle-Ether2.500 are part of SAME broadcast domain BD1. Is that CORRECT understanding? Q4:Why at all do we need to group these Bridge-domains? What advantage am i getting?Why are we tying all the Bridge-domains under a single bridge group? Q5:What role is l2vpn command playing in above? 

You can't solve this problem on a port-forwarding, reverse NAT basis. You'll need a reverse proxy that terminates the HTTP/S connection and uses the backend server to serve the request based on the URL requested. Squid and nginx come to mind, but I'm afraid proxies are off-topic here. Alternatively, you need more than one "routed" public IP address. Note that the router will not forward through the DNS server. When a DNS name is used for forwarding the external port, the DNS server is used to learn the IP address of the server and the router then forwards the packets directly. 

Using port for an ephemeral port is simply an API convention (ie. something between the application and the OS's IP stack). Technically, there is no reason why it can't work but practically, because it isn't used anywhere and potentially might trigger implementation weaknesses it's not unlikely to get filtered. In order to actually create a socket on port 0 it might be necessary to generate "raw" IP packets and write your own TCP handler. 

There is a vPC domain, with vPC 20 for Sw2 and vPC 10 for Sw1. vPC peer link exists between NxOS1 and NxOS2. Suppose, Sw2 sends broadcast traffic.This broadcast traffic (after hashing) will choose any of the links while going upstream to NxOS1. Now the broadcast traffic is received on NXOS1. NxOS1 sends broadcast traffic to all ports except port20. Hence, NxOS1 will send the traffic egress via Port 10 and the Peer link. Now, the NxOS2 receives the traffic, it knows what was the status of port 10 and port 20 of NxOS1 (via CFS protocol). So, NxOS2 knows that SW1 might have received traffic from NxOS1 via Port 10 of NxOS1. NxOS2 also knows that (via CFS protocol) the broadcast traffic would have come to NxOS1(on port 20) from SW2. (I believe when the port channel is established, the system-mac of Sw2 is known to both NxOS1 and NxOS2). Hence, NxOS2 DOES NOT further send broadcast traffic(in egress direction downstream) on port 20 and port 10 of NxOS2. Q1:Please validate if my above understanding is correct. Q2:Here, CFSoE is playing a great role(for mac address synchronisation).What would happen if CFSoE stops working(assume peer link goes down)? Even then how would loop occur in above scenario?