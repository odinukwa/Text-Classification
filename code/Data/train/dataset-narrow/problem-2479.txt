We believe code-based public-key cryptography to be post-quantum. In fact, code-base cryptography has the longest history record among post-quantum public-key schemes, but the key sizes seem impractically large, like 1MB in McBits. We use error correcting codes in lattice-based public-key cryptography too, which employ a reconciliation phase like Felipe Lacerda mentioned. In fact, our current best bet for a post-quantum key exchange is the Module-LWE scheme Kyber (lattice-based). 

There is a sound theory of overloading operators and functions realized by type classes in Haskell, and to rougher extent by traits in Rust, etc. In mathematics however, there are many situations where one set carries the same structure in multiple ways, like the integers being a monoid under both addition and multiplication. We normally just give these different names, but potentially one wants to abstract some tougher mathematical function, or a proof done in the type system. In principle, one could do this the way mathematicians do it, by applying a type class to a type that associates the operations to the base type, as opposed to just the set itself with a fixed association. Is that the "right" or "only" way to gain this flexibility? Or is there something else? In particular, there are a bunch of languages like Scala that do overloading of overloading rules in a rather dangerously complex ways, well even incoherent instances in Haskell probably. It'd be interesting if there were clearer "more parametric" way to achieve the ends that motivates those design decisions. 

How much is known about nondeterministic linear time? I'm aware that $$ \mathrm{NTIME}(n) \neq \mathrm{DTIME}(n).$$ Is there an $m > 1$ so that $\mathrm{NTIME}(n) \not\subset \mathrm{DTIME}(n^m)$? Are there any arguments that $\mathrm{NTIME}(n) \subset \mathrm{P}$ should be unlikely? 

Apologies in advance for this a soft question which has no closed, correct answer. This is probably the best forum to ask my question. I am a third year graduate student in theory group of a top-15 school in US. So far, I've been doing decently well. I have a first author theory paper and a first author practical paper so far. My advisor has been superb in helping me honing my skills but I feel stuck (and helpless). So far, my advisor has been a helping hand and a guiding force to always point me right directions and pose the right questions (not too abstract, not too concrete) which have been instrumental in me finding the answers to research problem. As I try to be more "independent", i.e, ask the right questions and prove results, I feel I have failed miserably and quickly feel overwhelmed. I feel that I don't have the maturity of a theory PhD student yet where I can ask myself the right questions and come with answers. In other words, given the right definitions and some hand holding, I am able to do things but otherwise, it becomes very hard. My sloppiness when it comes to writing proofs doesn't help either. I am looking for advice on how can I sharpen my skills and be more "theory-minded" where I can grasp things quicker and require less hand holding. While one answer is simply to keep working and hope that experience makes me wiser, I am not sure how this will work out. The only solution I have is to actually go through come recent papers in my area and write down proofs by hand in as much detail as possible to help me nail proof writing skills and build intuition. Any advice would be extremely helpful. Please let me know if question is unclear or needs more detail. 

A Turning machine with insertion and deletion operations can be simulated by an ordinary Turing machine with a quadratic time cost. Do we know how insertion and deletion fit into the polynomial time hierarchy though? In particular, does anyone know a quadratic single-tape Turing machine that cannot be simulated by a linear time single-tape Turing machine with insertion and deletion? I've gathered that separation results are often more powerful, and maybe easier to prove, for the nondeterministic time hierarchy. Is that perhaps an easier place to attack this? If so, that's great because I'm ultimately most interested in rewrite systems anyways. 

There is no reason to quibble over conceptual cleanliness when the pedagogy so clearly dictates the easiest path, and every computer science undergrad must take this elementary course, including all those who still don't understand proofs. 

I'm interested in an computational geometry problem that's sensibly expressed as an infinite dimensional 0-1 integer program. I'm not worried about finding an actual minimum for the objective function, any solution with isn't stupidly big will do. It thus seems natural to apply an approximation algorithm that starts by running simplex or similar restricted to $[0,1]$. I'd expect the solutions usually require only a few hundred dimensions, but any naive restriction of the problem space yields millions of dimensions. As I understand it, good implementations of a linear program solver should be polynomial time in both the dimension and constraints on average cases, but nevertheless this problem chokes GLPK. Should GLPK really choke on a million dimensions? I've therefore started looking for less naive restrictions of the problem space, which lead me to LP-type problems. In particular, there is a claim that Clarkson's algorithm applied to linear programs are equivalent to running the simplex algorithm on the dual problem. In what sense is this true? I find this claim highly dubious with respect to complexity for several reasons. First, Clarkson's algorithm does not exploit any $[0,1]$ solutions with fast average case solutions, but merely randomly chooses pivots. Second, Clarkson's algorithm has running time worse than exponential in the dimension $O(dn + d! d^k \log n)$, which doesn't rule out polynomial time for average cases, but I haven't found that fact yet. As an aside, any nice examples of improving a restriction of an infinite dimensional linear program over time? 

Can this problem be transformed into a linear program by taking logarithms? Is there any literature reference or reduction showing that linear programs with non-convex quadratic constraints is an NP-Hard problem? 

I will begin by linking a previous post where I asked a general question for a stochastic setting which I describe below. It turns out that my "proof" for a restricted case had a mistake and there is a much simpler setting where showing hardness should be easier. Please let me know if I should amend the original question instead. Consider a graph $G = (V, E)$ with $n$ vertices and $m$ edges. Each vertex $v_i$ can take positive value $a_i$ with probability $p_i$ and value $0$ with probability $1-p_i$. We will restrict $G$ to be a cycle where every vertex has degree $2$ (and $m = n$). The challenge is to assign weights $w_e$ to each edge to maximize the objective function $E = \sum_{e = \{i,j\}} w_e \Pr[X_i + X_j \geq w_e]$ where $\Pr[X_i + X_j \geq w_e]$ denotes the probability that that the sum of values taken by vertex $i$ and $j$ is greater than $w_e$. The additional constraint is that the weights $w_e$ need to be sub-additive, i.e., for any two edges $e'$ and $e''$ that "cover" edge $e$ meaning $e'$ and $e''$ include the vertices that make $e$, it holds that $w_e \leq w_{e'} + w_{e''}$. Observe that the deterministic version where $p_i = 1$ is trivial. Any suggestions on possible directions for hardness or PTIME algorithm would be very helpful! 

Based on posts from or-exchange and some internet reading, the following algorithm works. We adapt the cutting plane method to binary search for variable $y$. For my problem, the upper and lower bounds for all variables are known (but if these are not known, one can find a bound on $y$ by solving the LP by removing the first constraint). Let $l \leq y \leq u$. Fix $y = (l+u)/2$. This converts the program to a linear program. If the resulting constraints are feasible, update $u(l) = (l+u)/2$. Keep performing the binary search until we reach the optimal solution with an additive $\epsilon_0$. The running time of the algorithm is $O(PTIME)\log\frac{u-l}{\epsilon_0}$. While this algorithm can find the optimal solution within a small additive constant, I am still not sure about the hardness of the problem for solving exactly. Any comments regarding complexity are welcome! 

In fact, I'm probably content with a easy quadratic program that finds the midpoint of the entire polytope since centrality matters more than minimality, just vaguely curious if other linear programming algorithms offer relevant properties. Update : I've reduced the underlying problem to a simple constrained minimization problem solvable with Lagrange multipliers, but the question above remains interesting anyways. 

There are a wide variety of determent-like constructions. Some like the permanent or immanents are variations on the ordinary determinant for matrices over fields or commutative rings. Some like quasideterminants extend the theory of determinants to non-commutative rings. At least permanents have a rich complexity theory, perhaps the others do to. For any of these constructions, is there a quantum algorithm that asymptotically out preforms the fastest classical algorithms for computing it? I'm asking because some post-quantum crypto systems like $URL$ and code-based crypto suffer from extremely large key sizes due to representing public keys as matrices. A priori, it might be possible to "compress" that large matrix into something like a characteristic polynomial but using some non-commutative analog of the determinant. This approach sounds less viable if quantum computers could compute some analogs of the determinant more quickly. 

I'll concur with JɛﬀE that MS degrees are viewed as "consolation prizes" in the sciences in the U.S. because people usually take them when they fail qualifying exams in Ph.D programs. And who pays to do an MS when they'll pay you to do a Ph.D directly? I'd also concur with David Harris that mathematics might prove the most efficient route to doing serious theoretical work, but this depends entirely upon the program. Ask any math or comp. sci. departments who make offers how they feel about students taking courses outside the department though. I do recommend that you broaden your interests in more applied computer science of course, but do so by reading something. There are mathematically entertaining topics around databases, like Bloom filters, as well as fun applied papers, like the CryptDB articles. 

I am confused whether $\mathsf{APX-hard} \subseteq \mathsf{NP-hard}$. My confusion stems from a result on graph pricing from this paper which says the following : "Unlike the general case of the graph pricing problem, the bipartite case was not even known to be NP-hard. We show that it is in fact APX-hard by a reduction from MAX CUT". It seems like the authors are implying that APX-hardness is a stronger property than NP-hardness Since $\textsf{APX} \subseteq \textsf{NP}$ by definition, the above statement is true for MAXCUT as it is in $\textsf{APX}$ and also in $\textsf{APX-hard}$ but I am not sure if $\mathsf{APX-hard} \subseteq \mathsf{NP-hard}$ in general. Any pointers/counter example problem is appreciated! 

Consider the following linear program, $$\min y \\ xc_1 \leq c_2 + yz,\\ x = x_1 + \dots + x_n,\\ z \leq x_1 + x_2, \\ z \leq x_2 + x_3, \\ \vdots\\ z \leq x_{n-1} + x_n, \\ x,x_1, \dots, x_n,y,z \geq 0 $$ where $c_1, c_2$ are constants. This is an example of quadratically constrained linear program where I have 1 quadratic constraint. I wish to find out if this problem is NP-Hard or not. The quadratic constraint can be expressed in the form $\vec{y}M\vec{y}^T$ where $M$ for my problem is not positive semidefinite (and thus, non-convex) which is perhaps evidence of hardness Listing specific questions below: 

Consider a set of $k$ continuous variables. Each variable $x_k$ is associated with a hidden distribution from which its value is sampled independently of other variables. I am given a set of observations of the sum of $k$ variables, i.e, $\sum_{i = 1}^{k} x_i$. The challenge is to learn the hidden distribution from the given observations. This is the general variant of the problem I am trying to study. To simplify the problem, I can make the assumption that the hidden distribution is uniform and of the form $[0, u_k]$. Then, the challenge is to find $u_k$ for each variable $x_k$. I am not very familiar with learning style algorithms but I am sure variants of this problem have been studied in great detail. Are there any references that I can look at to find out more about this problem?