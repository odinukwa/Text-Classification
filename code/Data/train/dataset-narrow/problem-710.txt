I have another example in : MySQL Create Table with Partition Slow on server machine Each partition is treated as a separate InnoDB table with a distinct tablespace. What overhead exists ? 

Make sure you make a backup of the database and load it into a dev/staging DB and then run ALTER DATABASE against dev/staging. 

Actually, you should raise the max_connect_errors way beyond the default of 10. The range is 1-18446744073709547520. I would set it to 1000 for now. However, you have a bigger problem. mysqladmin requires you connect to mysqld before it does anything. If max_connect_errors is reached too quickly, you cannot make mysqladmin do anything at that point. Even a cron job will fail in this respect. Since you are using MySQL 5.5, your best option is create a scheduled event within the MySQL Instance to go off every 5 minutes that will only do one thing: run . I just did this in MySQL 5.5.12 on my PC 

DiskSpace Metrics nrgram_rec has 17 bytes per row 8 bytes for ngram_id (max unsigned value 18446744073709551615 [2^64 - 1]) 8 bytes for 4 smallints (2 bytes each) 1 byte MyISAM internal delete flag Index Entry for ngram_rec = 10 bytes (8 (ngram_id) + 2 (yr)) 47 million rows X 17 bytes per row = 0799 million bytes = 761.98577 MB 47 million rows X 12 bytes per row = 0564 million bytes = 537.85231 MB 47 million rows X 29 bytes per row = 1363 million bytes = 1.269393 GB 5 billion rows X 17 bytes per row = 085 billion bytes = 079.1624 GB 5 billion rows X 12 bytes per row = 060 billion bytes = 055.8793 GB 5 billion rows X 29 bytes per row = 145 billion bytes = 135.0417 GB 

No, not at all !!! The MySQL Query Optimizer will do the right thing if the main column(s) needed is leftmost in the index. If you did make such an index, the MySQL Query Optimizer may opt never to use that index if you always perform GROUP BY job_id,keyword_id. MySQL Query Optimizer may or may not use the index if you gather records by job_id only, but then you have a redundant index wasting space anyway. If the table is MyISAM, making such an index would just bloat the MYI file. If the table is InnoDB and innodb_file_per_table is 0, making such an index would just bloat ibdata1. If the table is InnoDB and innodb_file_per_table is 1, making such an index would just bloat the .ibd file of the table. In summary, you do not need to make that additional index !!! 

The thing you need to do to change, what I will call, the reference point for replication. Since Servers B,C, and D have binlogs enabled, this will be handy. You gave 

Whatever you do, do not use the MD5 function to make new passwords. Use the PASSWORD function. It is very different from MD5: The password function PASSWORD function is the equivalent of 

Please don't ask me how I made this. It took a lot of thought and trial-and-error. Anyway, take this query and create the DELETE for it: 

If dates are partitioned correctly, then you have a bug-infested mysql in relation to the query optimizer. If dates appear in a partition that do not belong, I would reload the table from scratch as follows: 

If you installed MySQL as a service, you need the following: STEP 01 Open Windows Command Line as Administrator and run 

Since MyISAM requires a full table lock for INSERTs, UPDATEs and DELETEs , this makes the table have the same mechanical behavior as a sequence. CAVEAT You periodically need to clean up the table You could just truncate the table 

Thus, kumar@'%' can only drop the kumar database. kumar@'%' cannot drop any other database. CONCLUSION The user kumar@'%' can drop the following: 

The beauty of this is that creating a MERGE table takes milliseconds. Just make sure every table has an index on EmpName. Better to do 75 indexed lookups that 75 full table scans. If there is no index on EmpName, you need to do this: 

Of course, you cannot import that into MySQL until you want the string NULL to be the value to be imported. 

Get the output of date +"%s.%N" from the OS on the slave, store it in a variable t1 SELECT tmstmp FROM replagdb.replagtb and store this in variable t2. Set variable df = t1 - t2 

Hey, not bad. Deleted 131,072 rows in 5.49 seconds. You need to use the stored procedure passing in a comma-separated list of values. Give it a Try !!! 

sounds like it does not make sense. What does FULLTEXT indexing a column in ascending order mean? You should run it like this: 

From your question, let's assume your table is called TNAME You should collect the ids that are valid First create a table to hold IDs and a process status per ID 

This indicates that that the IO Thread is still downloading entries from its Master's binary logs. The longer you take to address the SQL error, the more the will pile up. If the Master is in a heavy-write environment, relay logs will pile up quickly and puts the Slave at risk for disk space issues. If you do not want to monitor , you can always set the relay_log_space_limit. This force a cap on the amount of disk space allow for relay logs. For example, if you set this: 

In the strict sense of the word, no you cannot set foreign keys on views. Here is why: InnoDB is the only built-in storage engine for MySQL that features foreign keys. Any InnoDB table will be registered in information_schema.tables with engine = 'InnoDB'. Views, while registered in information_schema.tables, has a NULL storage engine. There are no mechanisms in MySQL to have foreign keys on any table that has an undefined storage engine. 

GIVE IT A TRY !!! Bad News: Backing up will not scoop up mount volumes. You will have to resort to doing mysqldumps. That should not be an issue if you have 5GB mounts. 

Getting replication lag from the binary logs yourself takes a lot more leg work. mk-heartbeat checks for a heartbeat table and record only. Using a live table on a master and comparing the slave's copy of the heartbeat table to UNIX_TIMESTAMP() on the slave is a much more concise realtime lag measurement. You should go with mk-heartbeat. 

You can let mysqldump create the dump in such a way that it does not create or select the database. EXAMPLE : You are dumping the database db1 and loading it into database db2 This will put in the CREATE DATABASE and the USE commands in the dump 

The biggest thing most people forget about TRUNCATE TABLE is that TRUNCATE TABLE is DDL and not DML. In InnoDB, the metadata within ibdata1 contains a numbered list of InnoDB tables. Using TRUNCATE TABLE causes the internal metadata id of the InnoDB table to shift. This happens because TRUNCATE TABLE effectively does the following: Example: To truncate an InnoDB Table called mydb.mytb 

There are two issues you need to look at ISSUE #1 : Characters Vs Bytes Since UTF-8 uses 3 bytes per characters, you may not have allocated enough for character fields. ISSUE #2 : InnoDB Row Length 

I found PalominoDB's How to recreate an InnoDB table after the tablespace has been removed. Based on the paradigm in that post, I would suggest doing a manual truncation by running the following: 

Instead of throwing all your eggs in one basket (all SSD or all HDD), you should consider a hybrid disk layout. What do I mean ? 

Before you perform any mysqldump to fully restore a Slave, you should consult the output of . Let's start with a sample : 

you need good indexes that will accommodate these two queries. In your particular case, you will need just one index. If the table is MyISAM, here is that index 

That's it !!! CAVEAT #1 Repeats all these same steps to sync ServerD to ServerB CAVEAT #2 If you have done these steps and still don't trust the data, please download Percona Tools and use pt-table-checksum to verify each Slave against the new Master. If there are differences, you can run pt-table-sync to generate the SQL to repair the differences. UPDATE 2013-09-05 12:28 EDT You just made this comment 

If you are moving the users to another DB Server running the same major version of MySQL, copying is not sufficient. If the users have access to specific databases, copying brings the user and the password. Then, you would have to copy the following 

In my answer to the 6-year-old question, I showed the query of this tabled used by a Percona Nagios Check plugin: