Show that function f is in #P. Show that the independence number of G can be computed from two integers n and f(G) in time polynomial in n, and conclude that the independence number can be computed in FP#P[1]. (If this is not clear from item 2,) conclude that the independence number can be computed by a polynomial-time oracle Turing machine which calls the oracle for the permanent just once. 

It cannot. Your problem is the linear feasibility problem in the standard form, with an extra condition that the constraint matrix is sparse. Now note: (1) It is well-known that linear programming is equivalent to the linear feasibility problem in the standard form. (2) You can easily convert a linear feasibility problem in the standard form to one with the extra condition that each row of the constraint matrix has at most three nonzero elements. For example, decompose w−x+y−z=b into w+y−t=0 and t−x−z=b, where t is a fresh nonnegative variable. (The detail is left as an exercise.) These together mean that an algorithm for your problem can be used to solve the linear programming. Equivalently, you cannot hope for an essentially simpler algorithm for your problem than an algorithm for linear programming. 

In the step 2, such i always exists because i=M(f(x)) satisfies the condition. Moreover, this algorithm cannot output a wrong answer because g(x, i, M(f(x))) must be the correct answer. Therefore, this algorithm solves L correctly. QED. If I am not mistaken, the same idea can be used to prove that PΠ[k(n)]⊆DTIME[nO(k(n))]. This implies that NP⊈PΠ[k] for any constant k unless P=NP and that NP⊈PΠ[polylog] unless NP⊆DTIME[2polylog]. However, this idea alone does not seem to rule out the possibility that Π is NP-hard under polynomial-time Turing reducibility. 

Here is an easy estimate. Here we call a set S⊆X an ε-net of a metric space X when for every point x∈X, there exists a point s∈S such that the distance between x and s is at most ε. If you want a strict inequality in the definition of ε-net, you can tweak the value of ε slightly. It holds that ||A||∞ ≤ ||A||C ≤ n2||A||∞, where ||A||∞ denotes the entrywise max-norm of an n×n matrix A. It is easy to construct an ε-net of the metric space ([0,1]N, d∞) with size ⌈1/(2ε)⌉N, and it is not hard to show that this size is the minimum. (To show the minimality, consider the ⌈1/(2ε)⌉N points whose coordinates are multiples of 1/⌈1/(2ε)−1⌉ and show that the distance between any two of these points is greater than 2ε.) By setting N=n2 and combining this with the aforementioned comparison between the cut norm and the max-norm, the minimum cardinality of an ε-net with respect to the cut norm is at least ⌈1/(2ε)⌉n2 and at most ⌈n2/(2ε)⌉n2. 

The nonuniform version of AC0 is defined as the class of problems which are decided by a (not necessarily uniform) family of boolean circuits of polynomial size and constant depth with unbounded fan-in. Since there is no uniformity condition, you can use completely different circuits for different lengths, implying that you can decide any unary languages (including undecidable ones). This is the motivation of the uniformity condition. For detail, see Proposition 11.2 of Computational Complexity by Papadimitriou. 

Points with the same x-coordinate do not cause any substantial problem. However, if you implement the divide-and-conquer algorithm carelessly, they may cause a problem. One way to deal with them is by using symbolic perturbation. 

(I am posting my comments as an answer in response to the OP’s request.) As for Question 1, let fn: {0,1}n→ℕ be a family of functions whose arithmetic circuit requires exponential size. Then so does fn+1, but fn+1 is easy to decide by a trivial monotone arithmetic circuit. If you prefer to avoid constants in monotone arithmetic circuits, then let fn: {0,1}n→ℕ be a family of functions such that the arithmetic circuit for fn requires exponential size and fn(0, …, 0)=0, and consider fn+x1+…+xn. 

Many other complexity classes which have appeared in literature are defined in terms of the number of accepting paths. Just for fun, examples from the Complexity Zoo include GapP, AWPP, C=P, Few, FewP, LWPP, ModkP, SPP and WPP. Also do not forget the logarithmic-space versions of these classes. A serious fact is that the definition of randomized complexity classes such as the very important BPP can be viewed as based on the number of accepting paths. As for the class of decision problems which have a nondeterministic polynomial-time Turing machine such that yes-instances have a prime number of accepting paths and no-instances have a composite number of accepting paths: As Philip White and other people wrote in comments on the question, you could define it. Whether that class has any interesting property or not is a separate issue. 

(Here RGW = 0.878… is the approximation ratio of the Goemans–Williamson algorithm.) However, some people prefer to use the term “UG-hard” as: 

Update: If my calculation is correct, a better lower bound Ω(n/ε)n2 can be obtained by the volume argument. To do this, we need an upper bound on the volume of an ε-ball with respect to the cut norm. First we consider the “cut norm” of a single vector, which is the maximum between the sum of positive elements and the negated sum of negative elements. It is not hard to show that the volume of an ε-ball in ℝn with respect to this “cut norm” is equal to $$ \varepsilon^n \sum_{I \subseteq \{1,\dotsc,n\}} \frac{1}{|I|!} \cdot \frac{1}{(n-|I|)!} = \varepsilon^n \sum_{r=0}^n \binom{n}{r} \frac{1}{r!(n-r)!} $$ $$ = \frac{\varepsilon^n}{n!} \sum_{r=0}^n \binom{n}{r}^2 = \frac{\varepsilon^n}{n!} \binom{2n}{n} = \frac{(2n)!\varepsilon^n}{(n!)^3}. $$ Next, since the cut norm of an n×n matrix A is greater than or equal to the cut norm of each row, the volume of an ε-ball in ℝn×n is at most the nth power of the volume of an ε-ball in ℝn. Therefore the size of an ε-net of [0,1]n×n must be at least $$ \frac{(n!)^{3n}}{(2n)!^n \varepsilon^{n^2}} = \left(\Omega\left(\frac{n}{\varepsilon}\right)\right)^{n^2}, $$ where the last equality is a boring calculation in which we use Stirling’s formula: ln n! = n ln n − n + O(log n). 

For the statement to hold, f must grow exponentially, even with the unary alphabet. [Edit: The analysis is improved slightly in revision 2.] Here is a proof sketch. Suppose that the statement holds and let f be a function such that every NFA with at most n states that accepts all strings with length at most f(n) accepts all strings whatsoever. We will prove that for every C>0 and sufficiently large n, we have f(n) > 2C⋅√n. The prime number theorem implies that for every c < lg e and for sufficiently large k, there are at least c ⋅2k / k primes in the range [2k, 2k+1]. We take c=1. For such k, let Nk = ⌈2k / k⌉ and define an NFA Mk as follows. Let p1, …, pNk be distinct primes in the range [2k, 2k+1]. The NFA Mk has Sk=1+p1+…+pNk states. Apart from the initial state, the states are partitioned into Nk cycles where the ith cycle has length pi. In each cycle, all but one state are accepted states. The initial state has Nk outgoing edges, each of which goes to the state immediately after the rejected state in each cycle. Finally, the initial state is also accepted. Let Pk be the product p1…pNk. It is easy to see that Mk accepts all strings of length less than Pk but rejects the string of length Pk. Therefore, f(Sk)≥Pk. Note that Sk ≤ 1 + Nk⋅2k+1 = o(22k) and that Pk ≥ (2k)Nk ≥ 22k. The rest is standard. 

Honestly speaking, I do not think that Stack Exchange is a suitable place to ask for a future prediction. Despite this, I will post a response because it is fun to play with the idea of fortune telling. As far as I know, the possibility of P≠RP=NP has not been ruled out. Moreover, there is a language A such that RPA=EXPA [Hel83, Kur83], which immediately implies that PA≠RPA=NPA. (I have not checked [Hel83] or [Kur83], and I took the result and the references from the remark after Theorem 6 in [Hel86].) In other words, even proving the implication RP=NP ⇒ P=NP requires a nonrelativizing technique, and therefore it is understandable that this implication has not been proved. (Lance Fortnow has discussed a similar result in the Computational Complexity blog: Oracle Results are Good For You.) Now let’s turn to the fortune-telling part. How much does this oracle result tell about the likeliness of P=NP in the world where RP=NP has been already proved? Not much. At the very least, it should not be taken as evidence that in the world where RP=NP has been proved, it is still likely to be difficult to prove P=NP. In such a world, some new, powerful nonrelativizing techniques are known to human, and therefore it would not be reasonable to interpret “requires a nonrelativizing technique” as evidence for difficulty. Speaking more broadly, if RP=NP has been proved despite all the beliefs (and also proof technique barriers) against it, then our current intuitive understanding about efficient computation is likely to be very wrong. Obviously we cannot apply our current intuition to reason about the world where our current intuition fails spectacularly. I do not think that we can make an educated guess about such a world except for what has been rigorously proved. References [Hel83] Hans Heller. On relativized polynomial hierarchies extending to two levels. In Proceedings of Conference on Computational Complexity Theory, pp. 109–114, UC Santa Barbara, March 1983. [Hel86] Hans Heller. On relativized exponential and probabilistic complexity classes. Information and Control, 71(3):231–243, Dec. 1986. DOI: 10.1016/S0019-9958(86)80012-2. [Kur83] S. Kurtz (Stuart A. Kurtz?). The fine structure of NP: Relativizations. In Proceedings of Conference on Computational Complexity Theory, pp. 42–50, UC Santa Barbara, March 1983. 

The question contains some ambiguity in what you mean by “vertex colorings of a graph G are edge colorings of a graph H,” but it is NP-hard to construct a graph whose edge chromatic number is equal to the (vertex) chromatic number of a given graph. Formally, the following relation problem is NP-hard. Representing chromatic number as edge chromatic number Instance: A graph G. Solution: A graph H such that the edge chromatic number χ’(H) of H is equal to the chromatic number χ(G) of G. This is because Vizing’s theorem gives a (trivial) efficient algorithm which approximates the edge chromatic number within an additive error of 1 whereas the chromatic number is hard even to approximate in various senses. For example, Khanna, Linial, and Safra [KLS00] showed that the following problem is NP-complete (and later Guruswami and Khanna [GK04] gave a much simpler proof): 3-colorable versus non-4-colorable Instance: A graph G. Yes-promise: G is 3-colorable. No-promise: G is not 4-colorable. This result is sufficient to prove the NP-hardness that I claimed at the beginning. A proof is left as an exercise, but here is a hint: 

This question is about Ramsey theory. In the case of the complete graphs, you can take a=1 by considering partitioning into only two sets. The Ramsey number R(k,k) is the minimum integer m such that however you partition the edges of the complete graph Km into two sets, at least one of the sets contains Kk as a subgraph. This immediately implies that if m < R(k,k), then the edges of the complete graph Km can be partitioned into two sets so that neither set contains Kk as a subgraph. Erdős proved that R(k,k) grows exponentially: R(k,k) > k⋅2k/2/(e√2). This means that if m is sufficiently large, then m < R(k,k) for k = ⌈2 log2m⌉ = O(log m). In other words, you can take a=1 with two sets. 

The problem is coNP-hard; you can easily reduce the UNSAT problem to this problem. A more precise characterization is that the problem is C=P-complete. In fact, one definition of the class C=P is that it is the class of problems which are polynomial-time many-one reducible to this very problem (usually this definition is stated in terms of GapP functions). But since this does not tell much, let me define this class in another way. Let C=P be the class of problems which are polynomial-time many-one reducible to the following problem: given a boolean circuit φ and an integer K (in binary), decide whether the number of satisfying assignments of φ is equal to K. By a standard reduction which shows the #P-completeness of #3SAT, we can restrict φ to be a 3CNF formula without affecting the class. The class C=P contains a class called US, which contains both UP and coNP. With this definition, your problem is C=P-complete. Actually, the C=P-hardness is easy to see from the definition of the class C=P (which uses 3CNF formulas). To prove the membership in C=P, suppose that we are to decide whether two given CNF formulas φ1 and φ2 have the same number of satisfying assignments or not. Without loss of generality we can assume that the two formulas have the same number of variables, say n. Construct a boolean circuit φ which takes n+1 bits as input so that the number of satisfying assignments of φ is equal to c1 + (2n − c2), where c1 and c2 be the numbers of satisfying assignments of φ1 and φ2, respectively. Then the number of satisfying assignments of φ is equal to 2n if and only if c1=c2. 

I am not sure if I understand the question correctly, but the proof by Dobkin and Lipton [DL79] that the uniqueness problem on n numbers requires Ω(n log n) comparisons in the linear decision tree model is much easier than the stronger result in the algebraic computation tree model by Ben-Or [Ben83] (not surprisingly). References [Ben83] Michael Ben-Or. Lower bounds for algebraic computation trees. In Proceedings of the Fifteenth Annual ACM Symposium on Theory of Computing (STOC 1983), pp. 80–86, April 1983. $URL$ [DL79] David P. Dobkin and Richard J. Lipton. On the complexity of computations under varying sets of primitives. Journal of Computer and System Sciences, 18(1):86–91, Feb. 1979. $URL$ 

This is not a reference, but an NP-complete problem cannot have a polynomial-time self-reduction which halves the input size unless NP has a nO(log n)-time algorithm, even if we allow Turing reductions. Suppose there is a p(n)-time Turing reduction from an NP-complete problem L to itself such that given an input of length n, the reduction only makes queries to strings of length at most n/2. Then you can convert this reduction to a standalone deterministic algorithm for L by using recursion. By writing down a recurrence relation for the running time of this deterministic algorithm, it is not hard to see that it runs in time nO(log n). 

Edit: As Sasho and Joe pointed out in comments, the reduction in revision 1 was incorrect. Here is an observation which is too long for a comment. The stated problem for a graph with n+1 vertices is equivalent to the problem of deciding whether a given n×n symmetric matrix whose entries are in GF(2) is singular or not. Here is a reduction from the problem in question to the problem of deciding singularity of a symmetric matrix in GF(2). Given a graph with n+1 vertices, label the vertices from 1 to n+1, and let A be the adjacency matrix ignoring vertex n+1, except that each diagonal entry Aii is set to 1 if and only if the degree of the corresponding vertex i is odd. Consider the one-to-one correspondence between the 2n partitions of n+1 vertices into two sets and the 2n vectors in GF(2)n defined by setting xi=1 if and only if vertices i and n+1 belong to the opposite sets. Then it is not hard to see that this partition is a solution to the problem in question if and only if the corresponding vector x is a solution of the linear equation Ax=0. Clearly the trivial partition corresponds to the trivial solution x=0 of the linear equation. This shows that the reduction above is a correct reduction. The reduction in the other direction should be easy to see from the reduction above. 

Therefore, we have c3≠c4≠c5≠c6≠c7. But this implies c3=c5=c7, making the hyperedge (357) monochromatic. This contradicts the assumption of the 2-coloring. 

I claim that for a “natural Boolean CSP,” if the k-restricted version is in P for every k, then the unrestricted version is also in P. I will define a “natural Boolean CSP” below. Schaefer’s theorem states that the Boolean CSP on a finite set S of relations is in P if at least one of the following conditions is satisfied and it is NP-complete if none of them is satisfied: 

Here are some upper bounds. By repeated squaring, the problem is in PSPACE. There is a slightly better upper bound. The problem is a special case of the BitSLP problem: Given a straight-line program starting from 0 and 1 with addition, subtraction and multiplication representing an integer N, and given i∈ℕ, decide whether the i-th bit (counting from the least significant bit) of the binary representation of N is 1. The BitSLP problem is in the counting hierarchy (CH) [ABKM09]. (It is stated in [ABKM09] that it can be shown that the BitSLP problem is in PHPPPPPPPP.) The membership to CH is often considered as an evidence that the problem is unlikely to be PSPACE-hard, because the equality CH=PSPACE implies that the counting hierarchy collapses. However, I do not know how strong this evidence is considered to be. As for the hardness, BitSLP is shown to be #P-hard in the same paper [ABKM09]. However, the proof there does not seem to imply any hardness of the language X in the question. References [ABKM09] Eric Allender, Peter Bürgisser, Johan Kjeldgaard-Pedersen and Peter Bro Miltersen. On the complexity of numerical analysis. SIAM Journal on Computing, 38(5):1987–2006, Jan. 2009. $URL$