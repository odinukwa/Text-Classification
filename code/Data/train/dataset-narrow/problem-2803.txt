As you can see, the entity is about to get stuck on the obstacle. That's because it doesn't sense it's about to collide, because the obstacle doesn't contain the edge of the 'ahead' vector. So: what would be a good solution to this problem? How should I implement the algorithm? 

For each entity in the "sight distance" radius from the entity, we check if it contains the the 'edge' of the ahead vector, marked with a red dot (actually the vector itself treated as a point): 

A can read user input and control the entity accordingly, while an would implement a state machine to control the entity. The controllers would use the entity's public interface to control it. The only doubt I have about this approach is that it forces the entities to offer a lot of public methods to control them, such as and . Conceptually, it doesn't "feel right" that the entity would expose methods like these to the outside world, when 'conceptually' it should be it's own job to control itself. Just like it isn't possible to control a human's legs or heart from the outside. Feels like it breaks encapsulation. So my question is: what do you think of this approach? Can you recommend a better one? How is this often done in games? 

This vector (scaled by a scalar ) is the avoidance force. We apply it on our entity, and it should avoid the obstacle. However, what happens in practice after applying the force is this: 

I implemented collision detection in my game using SAT. The detection works, but I'm trying to use the algorithm to figure out the penetration vector of the two OBBs and push them apart (before doing the 'actual' collision handling). I think I got the penetration vector successfully. However I'm not sure which of the two entities in the collision to apply it on (i.e. add to the position of which entity). If I apply it on both entities, obviously nothing happens. How can I know to the position which entity I need to add the penetration vector so the entities 'touch' at the exact point of collision? 

I think so far this is standard (if not, please say so). Now my question: During movement invoked by player input, I want the to be constant. So when the player presses the right arrow key, the will always be 2 - and not 2, and then 4, and then 6, etc. I could easily acheive this be having , but then other forces acting on the entity will be ignored. What is the standard way to implement this? 

(I asked a similar question, but it had more questions inside it and I feel it wasn't clear enough, so I'm opening a new one). Until recently I implemented all my games using an inheritance hierarchy. Those were simple games. For example: 

But what if, for example when a hits something I want to apply an impulse on the hit object? (In addition to the physics that always happens on collisions, in ). This is easy to do by simply adding about 3 lines of code to the method in : 

In a lot of games the player can choose whether an entity will be controlled by the AI or by the player. For example in the game Little Fighter 2, the player can choose how many of a maximum of 8 characters would be AI-controlled and how many of them would be human-controlled. I was thinking how I can achieve this in my game. Currently in my game whatever controls the characters is hardcoded into them. I even have an abstract superclass that all AI characters derive from, and a class that represents the player-controlled entity. I realized that in order to be able to choose dynamically if an entity will be controlled by the player or by the AI, I need to decouple the entity itself from "it's brain", i.e. whatever controls it. By "the entity itself" I mean the attributes and actions of the entity: it's mass, it's image, the way it implements shooting a missile, etc. By "the brain" I mean the system that decides when, and possibly how, to act. As I said, currently "the brain" of my entities is hardcoded in their function. My class responds to player input in it's method, and my subclasses usually delegate to a of some sort in this method. So I was thinking: how can I decouple the entities from their "brains", in order to be able to choose dynamically whether a is player or AI controlled - and without a lot of ugly code duplication. The solution that comes to mind is creating an abstract class, with subclasses that can be plugged into the entities. Then the entities simply delegate to their controllers in the 'update()` function, and the controller controls the entity through it's interface. To demonstrate: 

I learned how to implement the Obstacle Avoidance steering behavior from this tutorial. The approach depicted in this tutorial (simplified) is this (note that I'm using rectangular OBBs for obstacles, not circles): The entity that avoids obstacles will have a 'ahead' vector, representing the entity's 'sight'. It will be equal to the velocity vector, but scaled to some length (the "sight distance"). 

The proper way to make this 'knockback' movement is by applying an impulse on the knocked object. The impulse will be in the direction of the velocity of the hitting entity (the projectile), scaled to some number that fits your game (that should probably take into account the masses of the two objects). To make the entity slow down gradually after the hit and eventually stop, you need to constantly (every frame) apply on it an 'air friction' force (actually more of an impulse applied every frame since it changes), which is a force opposite to the entity's current velocity, scaled to some number. Do this for all entities every frame. This will make them always slow down gradually after being hit. (This is also (generally) what makes a car in the real world not move forever after being hit by another car, but gradually slow down and stop moving). This will allow you to apply an impulse on an entity in a collision and then not worry about it anymore, things will take care of themselves. To understand this you need to have a good basic understanding of vector math and basic physics. If you're not familiar with these topics I suggest you learn them. Once you understand them a lot of physics-stuff becomes simpler. 

I'm trying to implement the Obstacle Avoidance steering behavior in my 2D game. Currently my approach is to apply a force on the entity, in the direction of the normal of the heading, scaled by a number that gets bigger the closer we are to the obstacle. This is supposed to push the entity to the side and avoid the obstacle that blocks it's way. However, in the same time that my entity tries to avoid an obstacle, it Seeks to a point more or less behind the obstacle (which is the reason it needs to avoid the obstacle in the first place). 

I would think this is a common issue, but I couldn't find an answer that helped me. Help would be appreciated. In my game I have rectangular objects. They have rotating bounding box, aka not AABB but boxes that rotate with the entity and always match it's exact shape (I think it's called OBB). When two objects collide, they often penetrate each other a little: 

However, I'm not sure if updating the state of entities in response to collision should be the job of . Maybe it should be the job of , which runs after the collision detection in the gameloop. Is it okay to have the code responding to collisions in the collision detection system? Or should the collision detection class only detect collisions, report them to some other class and have that class affect the state of the entities?