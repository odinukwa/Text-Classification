Convention violation: logging to Your 'default' log destination is . For a well-behaved program, a more natural logging destination would be . Nonsense: checking assertion conditions after an assertion The fragment: 

Bug: Use of in does not check length It's possible for to be longer than ; in this case, your call to will smash memory beyond the end of . You should at least use to avoid out-of-bounds accesses; preferably, you would ensure that the sizes all add up, by either: 

Your approach is basically reasonable, but you aren't taking advantages of Python's more powerful features, or any of the more interesting parts of the standard library. 

There is a wonderful module in the standard library called . This library is my first thought in Python whenever I want to do something involving sequences of any kind, and it contains a little function called which will do a lot of the work for your program. Basically, you give a sequence of data items and a sequence of selectors, and you get back a sequence of those data items for which the selector is true. So in your example, matching your regex against the columns would give you the "selector": 

this could be useful in some situations, although you might want an option to turn it off, or to adjust the order (lots of tools can be configured to reference pairs in various formats back to the source line, as a way of handling e.g. compiler messages). Naming consideration: and are very similar. The visual difference between and is tiny. Using more different names (e.g., , ), or passing the log_level as a parameter to a single function: 

This is still quadratic, but now the quadratic thing has been moved inside a single generator expression, with the quadratic expansion coming from a part of the standard library; I'd guess that this would be a relatively good place to start if you wanted to use multiprocessing to speed this up. The greater use of optimised standard functionality also gets us a performance win: about a factor of two (so 4x faster so far than the original). Indexing Constant-factor performance improvements don't win us very much for \$O(n)\$ problems with largish \$n\$; some kind of algorithmic improvement is necessary. My initial thought when trying to come up with an improved approach was that matches were likely to be quite sparse---that is, most sets won't share three items (or whatever is) with each other; I would expect that most sets will share no items with each other. This is true of my randomly-generated sample data; it may not be true for your real-world data. If that assumption holds, then the obvious place to start seems to be with a simple index, mapping elements (ids/whatever) to the sets which contain them. Then, we can perform our existing quadratic comparison, but only on sets which we already know share at least one element. If most elements only participate in a small number of sets, we are then doing our quadratic process many times with small \$n\$, rather than once with large \$n\$; this should improve performance. Starting immediately after the line from the previous version (also needs an for the ): 

Others have already given excellent reviews of the implementation code. I thought it would be worth giving some review comments on your test code, as you posted it. Very large tests You have two very large tests; each contains many assertions and can fail for many reasons. Smaller, more granular tests (each with approximately one assertion) are easier to read, and provide more useful feedback when they fail. To manage the initialization code for such a large number of tests, you probably want to use the annotation to define common setup code. Used well, that approach makes tests sufficiently "cheap" that each one doesn't have to do very much. Verifying the standard library In some project contexts, it makes sense to check that the language and standard library are behaving as expected, and to . I don't think this is one of those contexts. The first half of (up to the creation of the combined iterator) is just testing the behaviour of the iterators for and ; it's probably reasonable to assume that those work as intended. Checking for thrown exceptions The pattern: 

I find this makes it easier to cope with C's lack of 'real' namespacing. Dependency-management suggestion: include your own header first Opinions vary on this, but if you start your implementation file (e.g., ) by including your header file (i.e., line 1: ) then you can tell immediately if your header file has an accidental dependency on some type or macro introduced by another header file you're including. I prefer to make my header files self-sufficient; including them first anywhere guarantees this. Subjective layout suggestion: implement top-level interface first This is overwhelmingly subjective, but I would at least consider the overall layout of your implementation file. Personally, for a module like this one, I would prefer to forward-declare the functions, then define them at the end. This way, the file reads top-down. In other contexts, that might be less clear, and it is more typing, so it's a judgement call. 

(assuming you have already filtered your tokens using or similar). List comprehensions List comprehensions are one of Python's most pleasant features. They're far too large a topic for me to sensibly explain in an answer here; that link will give you a good introduction, and there are many other articles and introductions around. Roughly speaking, list comprehensions (and their cousins, generator expressions) are a nice syntax for creating sequences from sequences, doing "something" (transforming, selecting, etc.) on the way. For example, you could write a list comprehension like this: 

From the tenor of your question, I'm going to just give some high-level suggestions of approaches you might use to make your code simpler and more manageable, rather than an in-depth line-by-line review. Performance You expressed a few concerns about performance and mentioned design decisions you'd taken for performance reasons. I wouldn't worry about parser performance too much: partly because premature optimization is sadness; partly because in this kind of application, parser input is generally small and parsing is relatively infrequent; and partly because optimizers are generally quite good at optimizing well-structured code. Unless you are using your calculator in some surreally absurd way, parser performance is not something you should be worrying about. So I would suggest that you not make your life more complicated for the sake of performance. Parsing balanced expressions You have a lot of special-case code and state flags to handle being in particular parts of the expression (like , various checks that is a particular kind of character, etc). All of this stuff would be easier to manage with a less ad-hoc approach to parsing. A recursive descent parser would probably be the easiest approach to get started with, but generally thinking about the grammar of your input language and looking at "standard" approaches to parsing should lead you in a helpful direction. I'm sorry if the above seems a little vague---it's quite a large and broad point. But I would suggest you read up on parsing. Parsing numbers Numeric literals (in every context I can think of, and certainly as you have implemented them) form a regular language. You will probably find that the easiest way to parse them is either to use (simple!) regular expressions, or an explicit state machine. There are a number of standard implementation techniques for implementing finite-state machines; the state pattern is one obvious choice, although for a language this simple I would consider a simple conditional/switch statement implementation. Input representation Your parser currently expects to be given a string which exactly contains a literal. This means that you effectively have to parse everything twice: once to determine the boundaries of the literal, and once to determine the meaning of the literal. This has a minor performance impact, but more critically, means that you have to smear multiple versions of your parsing code all over the place. I would expect that you would find things more straightforward if you allowed parsing functions to greedily consume as many characters as they felt appropriate from a "stream" of input characters (either an actual stream, or some arrangement with string+offset, with each parsing function updating the offset). It should not be too difficult to arrange your language such that greedily consuming characters is always correct (although you might need a few characters of lookahead). Evaluation You have a little throwaway comment about an evaluator that takes a String and produces a String. I suspect it would work better if the evaluator took either a string or a parsed representation, and returned some richer object as a result (e.g., a `Literal). Character identification You have a lot of code like "c == '{' || c == '[' || c == '('" etc. I expect that you would find it easier to work with sets of characters, either represented using Java , or, for convenience (with small sets) strings; then you could just ask . On a similar note, a function like that returned for , for , etc. would simplify various things. 

This is still quadratic (sadly), but the early exits combined with the other improvements does speed things up somewhat (about a factor of two on my machine with my test data). Using Whenever I have a problem that looks somewhat like this one (fiddling around with sequences and collections), I wonder whether the standard library module could help. It usually can. In this case, we can use to generate all possible pairings of sets (not including pairings with themselves). Then, we can intersect each pairing, and keep both sides; doing this for all pairings gives us the set of sets which we wish to exclude from the output. The full program looks like this: 

I think I've previously explained all of the things that go into that final version. This version seems to have good performance overall; the thing which costs it most performance seems to be increasing the size of the input sets. Increasing the size of would also cause problems. Playing around with various input-generation parameters, it seems to generally handle inputs of a few hundred thousand sets in a few tens of seconds. It should also be straightforward to parallelize this version: the expensive operation is generating the index; partial indexes can be generated independently, merging indexes should be quite cheap, so it's a good candidate for multiprocessing. Having the indexes available would also enable more interesting behaviours, particularly if the element->set index from the previous version was also available. For example, it would be straightforward to keep some filtered sets (say, the single largest filtered set) to avoid dropping elements entirely. Perhaps I got a little carried away with that, but it was enjoyable to poke at. 

Once you can easily generate lists containing exactly the elements you want to output, you don't have to fiddle around doing and similar; you can just do: 

is quite a common one when using test suites that don't support expected exceptions, and it isn't particularly unpleasant. On the other hand, JUnit 4 does support expected exceptions, so you can just write that test as: 

which you will recall is exactly what you need to feed to to filter to just those columns. (Actually, it will produce a list of s and regex match objects, but those evaluate to / in a boolean context, so don't worry too much about that). 

For most inputs I tested, this approach has both better constants and scales better than the previous programs. But it is possible to generate pathological inputs. The index built here also introduces the possibility of doing some kind of clever filtering---for example, to avoid filtering out all the sets which mention some element (of which we have a convenient list). ngram Indexing Having had some success with indexing, it's reasonable to ask whether there's more to be gained from that approach. The problem with the element-based index was that it could only tell us whether sets had any elements in common; a quadratic-time operation was still necessary to filter the sets with common elements. So a natural question is whether a different kind of index could do more work for us in the data structure. I can't think of a better way to transition this discussion, so I'll just say: we can get what we want by using ngrams as keys for our index. This requires only a small evolution of the previous approaches: we can use with as the length parameter to generate all of the possible -length subsets of each set. (We need to sort the input to to get consistent output). Then, we can just look up each key (unique -length subset); whenever a key maps to more than one input set, those input sets have at least elements in common. The code is straightforward: 

This is shorter and clearer, and lets JUnit both easily verify that the correct exception was thrown and give you a useful error message if it wasn't. 

Is an overwhelmingly common C idiom, and I'd be inclined to use that form instead (even if you do end up with a slightly lonely-looking variable declaration at the top). Redundant reference data As another answer pointed out, it seems a bit superfluous to maintain completely separate sets of reference data for upper- and lower- case letters. Using in would be one approach; personally, I would be tempted to wrap in another function which checked the case of its argument and called as appropriate---but that might feel like overkill for only a couple of character classes. The explicit list of consonants also feels a little funny to me. I think of consonants as "those letters which are not vowels", and there enough of them that I'd have to think far too hard if I were to type them all out. I'd be certainly tempted to generate the consonant set at runtime, iterating over the range to and excluding the vowels (which I would explicitly enumerate). Naming: The signature looks a little odd to me. Converting characters to characters? I'd probably instinctively reach for something like 

So I found this quite an interesting problem, and poked at it a little. I'm mostly going to talk about performance, because that's what you asked about. But along the way, I'll try and make some observations about readability, and answer the other questions you had. Sample input You provided some sample data, but to test performance, quite a large volume of sample inputs are needed. The following small program generates those: 

is bizarre. While it's true that the assertion could be compiled out with (meaning the condition is reachable), one generally works quite hard to ensure that turning off assertions does not change the behaviour of the system. Either fall back to default, or raise an error; don't do different things depending on whether or not the program is being debugged. Questionable: file extensions are ignored AFAICT, the extension parameter is just dropped on the floor; the file extension is always . Suggestion: use dynamic allocation You have lots of ugly fixed-size buffers for path components etc. While these are mostly probably large enough to not run into issues, there are a lot of awkward edge cases if you get near the edges of those buffers, and awkward interactions of sizes. Unless you have some hard performance/memory requirement, it would be much easier just to a chunk of memory the size you need (which you can work out easily from the various strings you're given). Feature suggestion: accept a user-provided filehandle A client of this library might want to take advantage of the logging functions, timestamping, and log level management, while managing log location themselves. It would be very straightforward to have the option of specifying a filehandle rather than a collection of path components. Feature suggestion: consider wrapping your logging functions in macros to get location For debugging purposes, I generally find that it's very helpful to log the filename and line number of the call to a logging function (depending a little on the context you're using the logger in). If you wrap and in macros, you can get these out automatically using and . For example, if you had as: 

Presumably so that you get an unanchored match (i.e., one which can start at any point in the string). has a method which will do unanchored matching by default; you can anchor the match to the start of the string with , as you would expect. See search() vs. match() in the documentation. Manipulating whole data structures There are a number of specific points below, but the broad thrust of them is that you will have a much nicer time doing large-scale operations on whole data structures, rather than fiddling around with indexes and individual elements. This is true in most languages, but one of the strengths of Python is the rich set of data structures and operations which are available built-in or in the standard library. 

would in my opinion be easier to read (you might choose to make the log level names a little shorter, e.g., , , in that case). Naming consideration: prefer systematic naming This is probably quite subjective, but: in the case of a module such as this one, my inclination would be to prefix all of the names with , like so: