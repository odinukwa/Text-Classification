Drivers for dBase (or Access or Excel) are not installed as part of the SQL Server install. It is likely that VS 2010 installed on your workstation is connecting through the old Jet drivers, which are installed on developer's machines. The problem with Jet is that it was never ported to 64 bit. I don't think that the old Visual FoxPro drivers were ported to 64 bit, either. Microsoft replaced Jet with "ACE", which is available in 32 and 64 bit packages. ACE drivers were first released with Office 2007 and supplant the older (and probably deprecated) Jet drivers. You can download the ACE 2010 drivers here. Since you are using a 64 bit server, you want the 64 bit drivers for linked servers. If you plan on running 32 bit packages on the server, you would need to install the 32 bit ACE as well. You might be able to find a similar package for 2013 by now. I have not used these more recent drivers, so I don't know if the the older formats (like dBase, Fox, etc) are still supported. After you install the drivers, they generally need additional configuration inside of SQL Server. IIRC, if you see errors that seem to be security-related, you need this additional configuration. In short: 

I suspect that there is some confusion about terminology here. Maintenance plans do not delete transaction logs. Maintenance plans delete transaction log backups. Transaction log files are required for the operation of a SQL Server database. Every SQL Server database has at least one transaction log file. By convention, these files are given a "LDF" extension. SQL Server log files do not behave like Oracle's redo logs. You can't just copy a log file and/or delete it. In your configuration (FULL), when the maintenance plan runs it should be configured to execute a transaction log backup command. This (more or less) makes a copy of the information in the transaction log file and places that information in a separate file called a transaction log backup. The transaction log backup command then marks the relevent space in transaction log file as free for use (again) by SQL Server. If this "marking of space" does not occur, the transaction log will eventually fill up. (Things work differently if the database is running in SIMPLE mode, but you aren't doing that.) With the FULL model, if the transaction log backup commands do not execute "often enough", the transaction log file can fill up. When that happens, depending on your exact configuration, the transaction log will either be automatically grown or updates to the database will start to fail. "often enough" is determined by how much space you have available, how big your files are, the rate of change of data in the database, the exact nature of how you do updates, your point-in-time recovery requirements, etc. Note that you can schedule transaction log backups in a highly flexible way: once a day, once an hour or once a minute or once every few minutes. You can even run transaction log backups more (or less) frequently during busy periods. The next time the maintenance plan runs, it will do the same thing as it did the last time but it will vary the name of the transaction log backup file (using a timestamp) so the earlier file is not overwritten. The maintenance plan runs the transaction log backup command based on the schedule that you configure. As the minutes and hours and days pass, an ever-growing set of transaction log backup files is created. At some point, those files need to be trimmed back by deleting them or moving them to somewhere else. If you are running some sort of log-shipping scheme, it's possible that you would be moving the transaction log backup files to some other safe location. The key concepts here are that the data is copied from the transaction log file to a separate transaction log backup file. These transaction log backup files should be stored for an appropriate period of time. A maintenance plan can be configured to automatically delete those files, you you can delete them manually or by some other scheduled method. Generally, most sites keep things as simple as possible and that "appropriate period of time" would be until your next full backup. For example, if you are doing a full backup every Sunday, you will need to keep at least seven days of transaction log backups. (I'd keep eight days, I'd like a little bit of overlap just to be safe). If you only keep three days of transaction log backup files, you will not be able to fully restore your data once you get past Wednesday. In the simplest FULL strategy, in order to restore a database you need the last full database backup and all of the transaction log backups from the time the full database backup was taken until the time that you need to restore to. If you are taking full database backups on Sunday with a three-day lifetime on transaction log backup files, when it gets to be Friday you will be boned since the maintenance plan has deleted the transaction log backup files from Monday and Tuesday. You will only be able to restore the database using whatever was in the last full backup. I have seen people fall into that trap. I'll close by saying that any person who is new to the way that SQL Server backup works should experiment/test restoring their database onto a spare machine, just to be sure that everything works the way you expect it to. You don't test a backup, you test a restore. 

As someone else pointed out, you can't upgrade directly from SQL 2000 to SQL 2012. you will need to upgrade to an intermediate release, it seems like you probably have sql2005 around somewhere, and then you can upgrade from there. This upgrade process is very simple, essentially you would backup your sql2000 database, restore it to sql2005, backup that sql2005 database and restore it to sql2012. The upgrade processing happens during that restore operaton. After you are done with that restore to sql2012, you should be sure to perform a full reindex of the database (per MS best practices) and I like to do a full DBCC CHECKDB. The amount of time required will mainly depend on the size of your database and the speed of your disk systems. If I have a small outage window available, I always like to try this once on a test machine before I try it in production so I have a good idea of how long it will take. If you can't do that, you could look at how long it takes to back up the database (restoration generally takes a bit longer) and the time it takes to do the current checkdb and reindex processing and use those as estimates. If you are moving to a new server, it is probably faster, so your estimates using the old server will probably be on the high side. BUT: That is the easy part. The more complicated part is testing your application so that you have some level of confidence that it will work properly on the new version. SQL Server isn't 100% forwards compatible. For example, if the old application is using system tables for anything, those system tables may have changed quite a bit (particularly from sql2000 to sql2005). Another example might be that the app makes assumptions about there being very loose security on the server (xp_cmdshell being a popular culprit) and that might no longer be true. Another issue might be required conversions from DTS to SSIS. Another issue might be lack of source code for some critical extended stored procedure that your vendor wrote, or something that prevents you from porting it to the SQL CLR. Another might be a lack of 64 bit drivers to third party databases. It's hard to quantify how much testing time is needed, even if you are pretty familiar with the app, and it's very, very hard to know how much time would be required to fix the code if you do find a problem. Since you don't have a good relationship with the vendor, that makes things harder. Since the app wasn't upgraded from sql2000 to sql2005 back in 2007, I can't help but suspect that there was some sort of roadblock discovered then and that it probably hasn't been fixed in the interim. In short, getting the data onto sql2012 is easy. Making sure that your app works isn't. If it were me and I had no budget, I'd be looking at running a P2V on the existing old server and sticking the image into a VMWare (or HyperV) infrastructure that already exists. That way, you can junk the old server and won't have too much work to do.