The initial value of the CNN kernels can be seen from the documentation found here. The default Conv2D layer looks like 

The code The dataset for this code can be found here. The function which will train the weights takes in the feature matrix $x$ and the targets $y$. It returns the trained weights $w$ and a list of historical weights encountered throughout the training process. 

But, in your case you know what your data should be so you can simulate it. I do this as follows and make a training and testing set. 

Yes this problem is extremely well suited for machine learning. However, I think you should be careful as to which algorithms you tend to use. A machine learning algorithm should be structured as follows: feature extraction and then your model. These are two things that should be done separately. Feature Extraction This is the bag of words, n_grams and word2vec. These are all good choices for text examples. I think bag of words is a good choice in your case. However, if this generates a sparse matrix then maybe n_grams can be better. You can test all 3 methods. The Model Theoretically, the more parameters in your model the more data you need to train it sufficiently otherwise you will retain a large amount of bias. This means a high error rate. Neural networks tend to have a very high number of parameters. Thus they require a lot of data to be trained. But, you have 1000 instances!!! Yes. But, you also have 500 classes. So imagine you have a very young child and you want him to be able to correctly classify 500 different types of images. Then you can't just show the kid 2 different examples of each class for him to truly understand what each class really means. As a very general rule of thumb, the number of instances you need to train a model increases exponentially with number of classes. So you will need a MASSIVE amount of data to properly train a neural network model. I would suggest a less intensive model. Moreover, looking at your example, it seems that the classes should be linearly separable. So you can use something really simple, linear regression, logistic regression, naive bayes or knn. These methods would do MUCH MUCH better than a neural network. My Suggestion I would start with bag of words and then use knn. This should be a good starting point. A neural network is 0% recommended for the amount of data you have. 

Receiver Operator Curve (ROC) This was invented during WWII as a means to detect aircraft using radar. For example, if we have a sensor which requires some kind of threshold to detect planes. We can determine the true positive rate (TPR) and false positive rate (FPR) which results in our experiment. We will then plot these as the x-axis as the false positive rate, and the y-axis as the true positive rate. $TPR = \frac{\text{True Positives}}{\text{Positives}}$ $FPR = \frac{\text{False Positives}}{\text{Negatives}}$ If the sensor is perfect we will always have $0$ false positives and always a $100\%$ true positives. This results in a curve which looks like the blue curve. If the sensor was completely random and garbage, then you would have a random guess which is the diagonal line. 

Forward pass As you observed the forward pass of the convolutional layer can be expressed as $x_{i, j}^l = \sum_m \sum_n w_{m,n}^l o_{i+m, j+n}^{l-1} + b_{i, j}^l$ where in our case $k_1$ and $k_2$ is the size of the kernel, in our case $k_1=k_2=2$. So this says for an output $x_{0,0} = 0.25$ like you found. $m$ and $n$ iterate across the dimensions of the kernel. Backpropagation Assuming you are using the mean squared error (MSE) defined as $E = \frac{1}{2}\sum_p (t_p - y_p)^2$, we want to determine $\frac{\partial E}{\partial w^l_{m', n'}}$ in order to update the weights. $m'$ and $n'$ are the indices in the kernel matrix not be confused with its iterators. For example $w^1_{0,0} = -0.13$ in our example. We can also see that for an input image $H$x$K$ the output dimension after the convolutional layer will be $(H-k_1+1)$x$(W-k_2+1)$. In our case that would be $4$x$4$ as you showed. Let's calculate the error term. Each term found in the output space has been influenced by the kernel weights. The kernel weight $w^1_{0,0} = -0.13$ contributed to the output $x^1_{0,0} = 0.25$ and every single other output. Thus we express its contribution to the total error as $\frac{\partial E}{\partial w^l_{m', n'}} = \sum_{i=0}^{H-k_1} \sum_{j=0}^{W-k_2} \frac{\partial E}{\partial x^l_{i, j}} \frac{\partial x^l_{i, j}}{\partial w^l_{m', n'}}$. This iterates across the entire output space, determines the error that output is contributing and then determines the contribution factor of the kernel weight with respect to that output. Let us call the contribution to the error from the output space delta for simplicity and to keep track of the backpropagated error, $\frac{\partial E}{\partial x^l_{i, j}} = \delta^l_{i,j}$. The contribution from the weights The convolution is defined as $x_{i, j}^l = \sum_m \sum_n w_{m,n}^l o_{i+m, j+n}^{l-1} + b_{i, j}^l$, thus, $\frac{\partial x^l_{i, j}}{\partial w^l_{m', n'}} = \frac{\partial}{\partial w^l_{m', n'}} (\sum_m \sum_n w_{m,n}^l o_{i+m, j+n}^{l-1} + b_{i, j}^l)$. By expanding the summation we end up observing that the derivative will only be non-zero when $m=m'$ and $n=n'$. We then get $\frac{\partial x^l_{i, j}}{\partial w^l_{m', n'}} = o^{l-1}_{i+m', j+n'}$. Then back in our error term $\frac{\partial E}{\partial w^l_{m', n'}} = \sum_{i=0}^{H-k_1} \sum_{j=0}^{W-k_2} \delta_{i,j}^l o^{l-1}_{i+m', j+n'}$. Stochastic gradient descent $w^{(t+1)} = w^{(t)} - \eta \frac{\partial E}{\partial w^l_{m', n'}}$ Let's calculate some of them 

If you have 1000 instances of these sequences of events which have 50 historical values then your matrix should have shape (1000, 50, 1) 

Alright so now we have 4 distributions with different labels. Let's split the data for sanctity's sake. 

Yes, different toolkits are suited for different purposes given they contain different algorithms. This is due to the lack of a general AI (an AI that is intelligent in all respects). Modern AI has different algorithms which are better suited for different tasks. For example a CNN framework is much better for images than a NN would be, and much better than encoders. However, a LSTM framework would be better suited to capture temporal dependencies in the data. However, if two frameworks are using the same algorithms they should both be relatively the same. Differences will arise due to the underlining codes being different as can be seen between Keras and TensorFlow. Although, this should be limited. Worry more about the algorithm you are choosing for your task than the framework. Coding up most machine learning algorithms is not that hard if you want to customize it. 

You can write your own algorithm. I drafted something up quickly. It can be significantly optimized. Let's make some random data 

What are we optimizing in backpropagation? Backpropagation allows you to update your weights as a gradient function of the resulting loss. This will tend towards the optimal loss (the highest accuracy). After each forward pass of your training stage, you get an output at the last layer. You then calculate the resulting loss $E$. The consequence of each of your weights on your final loss is computed using its partial derivative. In other words, this is how much loss is attributed to each weight. How much error can be attributed to that value. The larger this value is the more the weight will change to correct itself (training). $\frac{\partial E}{\partial w^k_{i, j}}$ How can we compute such a random partial derivative? Using the chain rule of derivatives, and putting together everything that led to our output during the forward pass. Let's look at what led to our output before getting into the backpropagation. The forward pass In the final layer of a 3-layer neural network ($k = 3$), the output ($o$), is a function ($\phi$) of the outputs of the previous layer ($o^2$) and the weights connecting the two layers ($w^2$). $y_0 = o^3_1 = \phi(a^3_1) = \phi(\sum_{l=1}^n w^2_{l,1}o^2_l)$ The function $\phi$ is the activation function for the current layer. Typically chosen to be something with an easy to calculate derivative. You can then see that the previous layers' outputs are calculated in the same way. $o^2_1 = \phi(a^2_1) = \phi(\sum_{l=1}^n w^1_{l,1}o^1_l)$ So the outputs of the third layer can also be written as a function of the outputs of layer 1 by substituting the outputs of layer 2. This point becomes important for how the backpropagation propagates the error along the network. Backpropagation The partial derivative of the error in terms of the weights is broken down using the chain rule into $\frac{\partial E}{\partial w^k_{i, j}}$ = $\frac{\partial E}{\partial o^k_{j}} \frac{\partial o^k_{j}}{\partial a^k_{j}} \frac{\partial a^k_{j}}{\partial w^k_{i,j}}$. Let us look at each of these terms separately. 1. $\frac{\partial E}{\partial o^k_{j}}$ is the error caused by the output of the previous layer. For the last layer, using R2 loss, the error of the first output node is $\frac{\partial E}{\partial o^3_{1}} = \frac{\partial E}{\partial y_{1}} = \frac{\partial }{\partial y_{1}} 1/2(\hat{y}_1-y_1)^2 = y_1 - \hat{y}_1$ In words, this is how far our result, $y_1$, from the actual target $\hat{y}_1$. This is the same for all previous layers, where we need to substitute in the errors propagating through the network, this is written as $\frac{\partial E}{\partial o^k_{j}} = \sum_{l \in L} (\frac{\partial E}{\partial o^{k+1}_{l}} \frac{\partial o^{k+1}_{l}}{\partial a^{k+1}_{l}} w^{k}_{j,l}) $ where L is the set of all neurons in the next layer $k+1$. 2. $\frac{\partial o^k_{j}}{\partial a^k_{j}}$ This is where the current layer's activation function will make a difference. Because we are taking the derivative of the output as a function of its input. And the output is related to the input through the activation function, $\phi$. $\frac{\partial o^k_{j}}{\partial a^k_{j}} = \frac{\partial \phi(a^k_{j})}{\partial a^k_{j}}$ So just take the derivative of the activation function. For logistic function this is easy and its $\frac{\partial o^k_{j}}{\partial a^k_{j}} = \frac{\partial \phi(a^k_{j})}{\partial a^k_{j}} = \phi(a_j)(1-\phi(a_j))$ 3. $\frac{\partial a^k_{j}}{\partial w^k_{i,j}}$ a is simply a linear combination of w and the subsequent layers outputs. Thus, $\frac{\partial a^k_{j}}{\partial w^k_{i,j}} = o_i$ Finally You can see that the activation functions of your layers are evaluated separately in the backpropagation algorithm. They will just be added onto your ever growing back-chain as independent terms within your chain rule. 

How do the weights affect the decision boundary. We want the two different classes, circles and x's, to be on opposite sides of this boundary in order for us to be able to correctly classify them. The weights are trained iteratively using gradient descent. We can see that the decision boundary starts off terribly and then gets progressively better. $0 = -1.0 - 1.0x_1 - 1.0x_2$ 

Try to categorize them as efficiently based on what you care about. If you want to stay true to the color wheel than just use the RGB values for the colors you are using. However, if not then you can use any mapping, but be careful because it will affect your Euclidean distance even after you normalize the feature (which is highly recommended for K-means).