What sort of stats are you looking to capture? Bytes per second? Number of 200/300/400/500 responses per second? Unique IPs per second? This link to the Apache traffic stats can help you capture some of that data and get it into ganglia. Assuming you have ganglia installed (and you should.) I'm sure you can figure out how to modify this setup for many other things you'd like to capture. 

Note that I've never done this and I don't think that it's a particularly good idea. Make a backup of your data first. Good Luck! -Dave 

That's just asking for trouble. I'm sure you can find a way, but please don't do it. RPMs are meant to be installed without user interaction. 

You won't be able to see the "GET /" from layer 4. That is only available at layer 7. It is best to block attacks as far away from the backend as possible. The sooner you can mitigate it, the better. You want it to consume as few resources as possible. If you can block it at the load balancer, great! At the firewall, even better! Prevent it from entering your network all together, best. Botnets can very easily overwhelm your internet links. If someone is really intent on taking you down, you will need external mitigation. 

That's the linux version, but there are Windows equivalents. Graphing that in your favorite tool is left as an exercise for the reader. It should be noted that this gives the power draw into the motherboard. Power supplies are not ever 100% efficient, so add about 15% to that number to get the input into the power supply. Or connect it to a watt meter and measure the efficiency yourself. PSUs are most efficient in the middle of their stated range, somewhere about 50-60% of the rated capacity. If you are concerned about power usage you might consider using an L-series processor. What happens when you draw more? That depends on the provider. You'll likely just get a warning (if they even notice at all.) And that's also the scary part. What if everyone draws just over and the circuit breaker trips? How closely do they monitor those circuits? Is it active monitoring or passive monitoring (is there a meter on the circuit or do the building engineers do spot checks with a clamp on meter?) If there is a meter is it per power port or per circuit? Overall, it's just best to monitor the draw yourself. How do you know before you order the server? Well, that's a guessing game. Unless you're really cranking on the HW you won't get near the peak. 

$hostname is obvious, $check in this case is 'raidcheck', $state is the nagios service state (0 = OK, 1 = warning, 2 = critical, 3 = unknown, 4 = dependent.) and $status_info is an optional message to send as the status info. Now we can test the check on the command line of the client: 

Using it for swap is a bad idea. If you need more RAM, get a bigger instance. SSDs may be fast, but they aren't nearly as fast as actual RAM. If you need MySQL cache, use ElastiCache (since you're already on AWS.) This will likely be faster than that SSD. For your use case, I don't see a use for the SSD. If you were retrieving a file (audio, video, photo) from S3 for conversion, this would be a good place to store it while you were processing it. 

This gives us a nagios passive check that expects to be updated every freshness_threshold seconds. If the check isn't updated, check_command (check_failed in this case) is run. The example above is for a nagios 2.X install, but will likely work (maybe with minor modification) for nagios 3.X. 

I think you're running into a shell expansion problem here. My guess is that the subcommand (in back ticks) is being executed locally, not on the remote system. I'd suggest creating the bash script locally, copying it to the remote server and then executing it there. 

I've only done this via SNMP set commands and I've only disabled it so the ports DON'T power on after a power failure as I've also been in the power-off/power-on/power-off situation. 

You mention that these two UPSes are connected to two separate circuits. Are these two circuits connected to the same power panel (and therefore connected to the same upstream power source) or are they connected to two separate power panels each backed by a different generator? If they are not connected to two separate generators then you might be complicating matters by adding two UPSes. At large scale, having two separate UPS systems is lost if they are both backed by the same generator. If they aren't backed by a generator at all, you might just be adding complexity instead of availability. If power is lost and it's just a matter of time before you need to shutdown, do the shutdown. If this is really a mission critical application there will be a budget for keeping the system online (via an associated cost for the downtime, aka insurace.) When that happens invest in a very good data center space. If you are just trying to maximize your runtime, connect your server to both UPSes and everything else to just one. Setup the the server power supplies to prefer your dedicated UPS and only shutdown when the shared UPS is low. You should be able to setup the power supply preference either in the BIOS or via the DRAC/IPMI. This assumes that the server draws more than all of the other equipment combined (which is probably a fair assumption..?) then again, we're now getting into power math which is it's own beast. 

If you've ever been on pager duty, you've probably needed to solve this problem. Maybe you should google 'pager duty'. Or you could setup your monitoring solution to follow dependencies. 

It sounds like the file is still open by some process. You'll need to restart that service for the disk space to be freed. 

Check the output of . That will tell you how much swap is active. It appears from the nagios info that you don't have any swap currently active. Use to activate it. 

Your upstream distribution (in this case Ubuntu) provides and supports a particular set of packages. It would be much more advantageous to upgrade your whole distribution to get a newer version of grep (or really any other package.) The way to do it, if you choose to go this route, is to create your own .deb package with the newer version. Place that package in your repo, enable your repo on the system. Then you can install that deb with apt.