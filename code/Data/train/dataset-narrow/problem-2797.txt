Here is a returns the duration of a wave in samples, which is actually a little tricky for formats other than PCM: 

In DirectX 10.x/11.0, constant buffers are intended to be updated as a unit (i.e. you have to update the whole thing). This is why our performance recommendations is to arrange your data in constant buffers by frequency of update rather than having large cbuffers that contain variables that are updated frequently (per-object) and others that are updated occasionally (per-frame or on window size changes). See Windows to Reality: Getting the Most out of Direct3D 10 Graphics in Your Games With DirectX 11.1 on Windows 8 or later, and appropriate drivers, you can make use of partial constant buffer updates with constant offsets. It's an optional hardware feature indicated by and . This allows you to use new parameters on to achieve partial updates. These optional hardware features are not supported with DirectX 11.1 on Windows 7. See MSDN. 

The main issue the OP is hitting is that VS Graphics Diagnostics does not support DirectX 10/DXGI 1.0 applications. For DirectX 10 on Windows Vista, you used and created a class instance. This is "DXGI 1.0". For DirectX 11, you should use and which is DXGI 1.1. It is also important not to mix different versions of DXGI in the same application. If you are explicitly creating a DXGI factory and enumerating the devices, then as long as you use you should be fine. If, however, you are creating the 'default' device and then need to get the DXGI factory that was used to create it, you should use this trick instead: 

The design is for you to implement your own and then you can return your own custom for custom shaders. You can also control the individual subset drawing instead of calling . See ModelMesh for details. The object is a factory for 'stock' states. The drawing uses it to set the default states. You can use it directly. For example, to set a wireframe rendering mode: It's a helper object so you don't end up creating lots of redundant states for common combinations. The interface you pass to the loader is the abstraction for creating instances (i.e. shaders) and for loading textures. The default ones also handle 'material and texture sharing' so you don't create unique instances for every single model's material. I can't tell exactly what's wrong based on our snippet, but a common thing to have go wrong is right-handed vs. left-handed view coordinates vs. the winding of the model. You can try passing a 'true' at the end of the loader to see if that worked. 

Clear() is the only way. To understand why, you need to consider that Direct3D is an abstraction layer itself over the underlying hardware to present a way for you to code against them all. If you dig a little deeper behind the scenes on depth in particular, you start to discover that each manufacturer is free to implement (and therefore optimise) depth as they choose, as long as they adhere to the interface presented. The link here describes a little about some of the different techniques that have been used, it seems to date from 2002 so things will have advanced since then, but it gives you an idea of why they hide the underlying implementation from you. The Wikipedia link on HyperZ here also talks a little about some of the optimisation methods used and the efficiencies they get from them. 

I'd recommend a good clear separation of input and the rest of your game. I'd also recommend a layer that allows you to map different inputs onto different results (i.e. press key A maps to Left, S to Right). If you tightly couple the game with the input you won't easily be able to handle people remapping keys to suit their tastes, you also would have trouble adapting to maybe using a controller (i.e. 360 pad) instead of the keyboard later, or even being able to use something like Kinect to control input with enough abstraction. In a driving game for example, I would have something that parses the current input state from the device currently in use (i.e. keyboard, pad, wheel, etc) and use the values I retrieve to build up a structure more suitable to my specific need, i.e. turn the values I parse into a steering value, an accelerator pedal, a brake pedal, etc. This structure could then be passed around to systems without having to worry about what input method had generated these values or whether they used analogue sticks, d-pad or keyboard. 

I'm sure there are circumstances where people have done as you have above, but personally I've always favoured engines as a collection of libraries, with bits you can pull in as needed. That would ultimately give you more flexibility of choice to swap different components in/out based on their suitability to a specific type of game (i.e. you could choose a 2D or 3D physics library or renderer depending on the type of game) without having to have all the other alternatives resident in memory, or you could choose between a rendered based on DX9/DX11/etc). 

By design, DirectXMath returns for the same result as you'd get from the following (inefficient used only for testing) scalar code: 

The main thing to remember is that only affects the struct/class layout, is respected for local or global variables, but has no affect on heap allocated memory. In other words, it doesn't matter if the member variable of a class is marked with alignment if the class is allocated with . Heap allocations by default with x86 (32-bit) are only 8-byte aligned, so you have a 50/50 shot of getting the required alignment that way. By default x64 native (64-bit) alignment is 16-byte. Otherwise you need to make use of to get other alignment behavior from heap allocation. See MSDN for some more notes on this. 

DirectX REDIST (aka DirectSetup) The answer here is that most developers are using the REDIST because they don't understand what it actually does. Or more importantly, what it doesn't do. Ideally, most games would never use the legacy DirectX SDK anymore (see Living Without D3DX), but there are still a few specific scenarios where you need to rely on it. And the main reason they use the REDIST is that the License Agreement doesn't allow you to do application local deployment of any of those DLLs. Back in the day, DXSETUP installed DirectX components like DirectDraw, Direct3D, DirectSound, etc. The modern REDIST, however, never installs DirectX components. As of Windows XP Service Pack 2, these are all part of the OS and are only updated through Service Packs, Windows Updates, or new versions of the OS. The legacy DirectX SDK REDIST is still required to deploy D3DX9, D3DX10, D3DX11, XAudio 2.7, XInput 1.3, XACT, or D3DCompile #43. XAudio 2.8, XAudio 2.9, and XInput 1.4 are part of the Windows 8.x and Windows 10 operating systems, and again are never deployed by the legacy DirectX SDK REDIST. D3DCompile #46 and #47 are available to be deployed application local in the Windows 8.x SDKs and Windows 10 SDKs. D3DCompile #47 is part of the Windows 8.1 and Windows 10 OS, so you don't have to deploy it application local for these platforms. Ideally you'd never do any HLSL compilation at runtime and ship all your shaders prebuilt, but you need the D3DCompile DLL to use any shader metadata reflection APIs. D3DCompile #46 and #47 are never deployed by the legacy DirectX REDIST. 

If you call store and there is no state stored for this object ID, the object ID is added to a list among with its state. If there already is a stored state, it is updated to the new state. The load method searches the list for the object ID (for fast access, consider a hashtable, so you don't have to perform a linear search or a sorted array, so you can perform a binary search) and returns the stored state or 0, in case no state has been stored (0 should always represent the default state for all objects). When you now open a map screen, you initialize all the objects on that screen. The objects all perform a call to the current game save object to find out, what their initial state should be. For treasures, if it is 0, they display as closed and if it is 1, they display as opened. What is inside the treasure is usually hardcoded in the level data, unless you want to make it random, but if it is random, you don't have to store that in the state either, it will be randomly chosen when the treasure is opened. You may also make it partially random (e.g. the treasure must contain rubies, bombs, etc. and the amount must be at least between X and at most Y). Depends on how (un)predicable you want the game to be. I think the original TLOZ is rather predictable. If the user now opens a treasure, the treasure updates its state in the game save object, indicating that it has already been opened. So next time the user enters the map screen, the treasure displays opened. Whenever the game is stored to disk, the game save objects simply writes all known objectIDs and their states in the list to a file. This can be a simple list of two consecutive 32 Bit values like 

I would also go for the ID solution. You should give every object in your whole world (not just on the current map) a unique ID. A 32 Bit int should be sufficient. Further every object can store a state value, also a 32 Bit int value. You can squeeze a lot of information into 32 Bit, e.g. you can make 32 flags out of it to store 32 bool values. Or you can use the higher bits for flags and the lower bits to hold a numeric value. For something as simple as a treasure, you only need to store a bool, where a value of 1 means opened and a value of 0 means closed. The you have a game save object with two methods: 

All versions of D3DX are deprecated and not included with the Windows 8.x SDK. This is covered on MSDN and on my blog. Ideally, you should change your program to not use D3DX. A full list of replacements for D3DX functionality can be found here. In summary: If you are on Direct3D 10, port to Direct3D 11. Then use the wide variety of Direct3D 11 support libraries instead of D3DX: 

You could do something as simple as XMVector3TransformNormal of the direction light with the original Rotation. Generally in SIMD-friendly coding, individual component access is a performance hit, so you want to avoid doing it whenever possible. That's why in DirectXMath (aka XNAMath version 3) the individual element members _11 - _44 were removed from XMMATRIX. If you need to do individual matrix element access, you'd use XMStoreFloat4x4, XMStoreFloat4x3, XMStoreFloat3x3 and then extract the value from the non-SIMD structures XMFLOAT4X4 / XMFLOAT4X3 / XMFLOAT3X3. 

VS 2013 only supports Win32 desktop development when hosted on a Windows 7 system. You can certainly develop a DirectX app on such a system as a Win32 desktop app, but there's no built-in magic template to get you started. You create a standard Win32 desktop app, then add support for Direct3D from there. See Direct3D Win32 tutorial. PS: The Windows 8.1 SDK is included as part of VS 2013 Express for Windows Desktop, VS 2013 Pro+, VS 2013 Community. You can download it as a standalone as you did as well. 

The general approach for games is that models are created and edited in some 'source' format (like WaveFront OBJ, Autodesk FBX, etc.). The models are then "exported" to some format which is optimized for runtime usage, usually something specific to the game engine being used. DirectX Tool Kit supports loading Models from VBO, CMO, and SDKMESH as example runtime formats. CMO files can be created by VS 2012+ directly from FBX, DAE, or OBJ files. SDKMESH files can be created from FBX files using the Samples Content Exporter. All three can be also be created from OBJ files using the meshconvert command-line tool in DirectXMesh. See this wiki for more content file formats. 

If you are only building for x64 native, this code is perfectly fine since it is always 16-byte aligned. 

You can submit command lists multiple times across frames, but the current design makes it less than ideal for "display list" style rendering because you can't change modify or inherit state once the command list is created. You can modify resources (constant buffers, textures, shaders, etc.). The DirectX 11 command list model is really intended for multi-threaded submission. See the MultithreadedRendering11 sample. See this blog post for some presentation links. 

Are you just trying to scale the value of the alpha coming out of the texture? If so you can just supply a floating point value between 0 and 1 as a scaling value in the part "vec4(colour,1)" instead of the 1. 

A 10-minute implementation of a simple spring system (or so he says on his blog ;) ). The system can handle multiple warps and other things distorting the grid. Updated to add some minor addition detail: A few other details. From an interview that used to be hosted on the Bizarre Creations website (that site has now disappeared due to the company closure) there was a question: Q: One of the most striking new graphical features in the game is the "gravity grid" play area. How did you make this look so cool; does every object in the game really have its own gravity? The grid itself is made up of 60,000 points, each one exerting a small amount of force on its neighbour. The simulation itself sits on the edge of stability which is what causes it to swing about so much when one of the game objects gives it a small push! Only a few types of object affect the grid. As the grid system is rather expensive to calculate, it actually runs on the second core along with the audio system, (the first core being dedicated to gameplay and particles, the third is used to render the audio). 

Microsoft makes a lot of effort to not break compatibility between different versions of their operating systems. Windows 7 is widely available and cheap to purchase, the best thing you can do is buy a copy, install it, then see what if anything is broken, then attempt to fix it. If nothings broken, you've nothing to worry about. You could always purchase copies of XP and install them onto the new PC's? 

There are lots of factors to take into account, type of game, speed of connection, number of peers, how much data you want to send, if people have limited bandwidth allowances you don't want to over use, is this over a LAN or internet, etc. Lets say for example, you have a 64kbs (64 kilobits per second or 8 kilobytes per second) connection (which is slow by modern standards for average home internet but not necessarily slow for phones), with 8 players and you want to update as often as possible for a real-time game, you'll need to send to 7 people at most 9kbs each (64/7). Assuming your update packet size was 1kb (1024 bits or 128 bytes) for each update, you'd only want to send an update roughly 8 times per second, or put another way for a game running at 60fps, every 7 or so frames. You'll need to do your own calculations based on what your target bandwidth is, packet size, etc. There's nothing standard that will scale this for you, however it's fairly easy to keep track of when the last update was done and not send another for X frames or X milliseconds, etc. When calculating the size of your packets, you'll also need to take into account packet header sizes which will potentially vary by the platform you use and apply and a specific overhead to sending anything (which for UDP over IPv4 seems to be 20 bytes). UPDATED due to extra info (and switching TCP reference above for what it should have been, UDP): You'll want to be using UDP instead of TCP as the overall overhead of TCP is more than you want in a real-time game. You don't need/want the guaranteed delivery of packets as it'll require each packet to return a successfully delivered reply (plus by the time it's then re-sent the data is out of date anyway). For the internet you'll need to assume at least a certain level of packet loss and how you cope with this (you can even simulate this in your code by randomly not sending or not sending every Xth packet). You'd also using UDP need to take into account that packets can arrive in a different order to that being sent, so you'd also probably want to send some sort of number (be it time, or some incrementing value) to indicate that if you receive packet 200 first, then that's the current good state and then receiving packet 199 it should be ignored. You could also potentially do other network optimisations, such as sending a less frequent "big" update (say position, orientation, velocity, etc) with more information, then send more "smaller" partial updates (such as controller input, or delta's). Smaller packets allow more to be sent for the same bandwidth (again you need to take into account packet header overhead, you want to have a good ratio of actual data sent to header size). This mostly applies to peer-2-peer over the internet. If this is just for a local area network (unclear from the question), then it probably isn't a concern on how often you send the data unless the actual sending or receiving the data is somehow computationally expensive (not usually). You'd most likely want to send it as fast as you can in a LAN environment for responsiveness.