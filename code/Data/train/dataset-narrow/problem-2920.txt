The tile map may be simply a two dimensional array with the indexes/ids o each unique tile. Also, have a class (for example called TileIndex) to manage your unique tiles may be useful. The tiles indexes may be unload and load when you change room/scenario/level, because you probably want different unique tiles for different rooms, tiles needed to represent ground of a cave don't need to be loaded when exploring a scenario with grass in the ground. Have all unique tiles of the game loaded at all times may not be optimal, except all your game use the same tiles all the time. The array contains only the ids of the tiles, because you build your scenario repeating tiles as smart as possible so the player won't get tired looking at the same patterns all the time. Optimization tip: For most games you probably will need some kind of scene organization, to quickly find objects in the screen rectangle and for efficient collision detection. If you already have payed the cost of a tile map floating around in RAM why have a separate structure like a quad tree or a grid to organize your scene. You can make the map contain in each element of the 2D array more than a tile id, in addition to the tile id you can have a pointer/reference to the entity/character/game_object occupying the tile, or if your game need more than a single entity in the same tile at the same time, then a dynamic list rather than a single pointer. For simplicity you can consider only objects centers to consider them occupying a tile. But consider their rectangle is not so hard as it sounds, but then a given entity can occupy more than one tile at the same time because its rectangle won't be always aligned to the tile rectangle. You can force all characters to always stop at tiles centers (like some old 16 bit JRPG games), or allow single pixel movement, but again, in this last case you probably need to allow a character to occupy more than one tile at a given time. 

(MusicTracks is an enum). Is this the correct way to make sure I'm not using more RAM/Resources than required? Or should I be looking into XACT? To be clear, I don't need to play multiple Songs at the same time (I do need to play 1 Song and a few SoundEffects though) and I don't need any crazy effects apart from setting the Volume of the music independently from the soundeffects, which should be straight forward with MediaPlayer.Volume. 

I'm interested in learning about Shaders: What are they, when/for what would I use them, and how to use them. (Specifically I'm interested in Water and Bloom effects, but I know close to 0 about Shaders, so I need a general introduction). I saw a lot of books that are a couple of years old, so I don't know if they still apply. I'm targeting XNA 4.0 at the moment (which I believe means HLSL Shaders for Shader Model 4.0), but anything that generally targets DirectX 11 and OpenGL 4 is helpful I guess. 

I've been looking up the definition of radians and found out that mathematicians prefer them because they are derived from pi instead of being completely arbitrary like degrees. However, I have not found a compelling reason to use them in game development, possibly due to my complete lack of related mathematical understanding. I know that most sin/cos/tan functions in languages what radians, but someone could just as well create library functions in degrees (and avoid the inherent rounding errors when using pi). I don't want this to be an opinionated poll, I would just like to hear from people that have done game development (and the associated math research) where radians offer a superior experience over degrees, as opposed to "We're using radians because we always used them", just for the sake of helping me (and possibly others) to understand what they are good for. 

I want to make a quick demo program showing a cube, or a user loaded model, rotating in screen rendered with one of three projections: perspective, isometric and cavalier. Using the fixed pipeline, how can I build a projection matrix for cavalier projection? I think I can start with the orthographic projection matrix and then tweak the values, by eye, until I get the z of the vertices go to the right and up as farther the z is. I want the lines parallel to the z axis rendered as vertical lines 45 degrees rotated to the right. 

In resume: in 2.5D an sprite is either in front or behind another sprite. In 3D, a mesh is made of triangles, but triangle is not the minimal unit when testing for depth, you can have pixel precision. Of course, camera rotation in 2.5D is impossible as assets were created for a fixed camera angle, while in 3D is natural, if the angles of the camera are restricted by design in a 3D game is another subject. 

Very simple and reliably. You leave your AABB implementation as is. The phantom AABB may have a dedicated loop that process them, that only check for simple collisions, and do not waste time calculating the penetration vector. This loop must be before the normal collision and response code. You may apply gravity during this loop, for those sprites on the air apply gravity. If the phantom AABB is in itself a class or structure, it may have a reference to the sprite it belongs to. This is very similar to the other proposed solution where you check if your player is jumping. I giving a possible way of detect if the player has its feet over a platform. 

The C64 only supports 8 sprites per horizontal scan line, so I don't think that everything in the middle of the screen can be a sprite? I would assume that anything requiring a collision would be a sprite (since I can get hardware collision detection with sprites), but even then I quickly hit the limit of 8 sprites. Also, my weapons can fire much more than one projectile - my ship, the satellite and 6 bullets would already be 8 sprites on a row (look at about 50 seconds into the video). Also, which graphics mode would a game like this use? The Programming Handbook lists Bit Map Mode which essentially modifies screen memory directly. Is this the mode I should usually be working in? How would I compose all the non-sprite elements together to get them on screen? A lot of the stuff in the score and status bar is static ("Area: 01" or the "frame"), so I guess I'll just populate them once when the level starts. Things that need updating - the score, the charge bars at the bottom - would be updated by filling the screen memory with black and then drawing the new score every frame? Or do I have to draw the entire screen on every frame? 

When using the "Each sprite know how to render itself" approach a render system became unnecessary. Then I ended with a main loop that used functionality of the scene "class" to efficiently cull the scene and then loop through a sprite array representing the visible part of the scene calling each sprite render function. As sprites are allowed to contain render code, anything can be an sprite including a health bar that needs no image data and is renderer only with lines of different colors (easy done with canvas calls). Also note that with the second approach sprites and entities are the same thing. I called them sprites because it was 2D game. In the first approach sprite was a "structure" that contains data for the renderer renderSprite function and a separate entity "class" that refers to a sprite was needed. In resume, my position is: 

By using the same pixel representation that the potential APIs with those your game engine will have to interact you save having to do expensive format conversions later. 

I tried to model a render system for an html5 game and learned the following: We use render code separated from other game code with the intention of change graphic api at any time without having to touch anything except the renderer implementation. But, for html5, do we need this? Canvas is already all the multi platform it can be. The browsers are already responsible of implement the platform specific part. A render system, if used, must be very generic. I don't think a method called renderATree() should be in the renderer. The sprite representing a tree must contain the data that you need to pass to a render generic function to produce a result that looks like a tree. 

When writing a C64 game in 6502 Assembler and loading the game using , I can choose the address where the game is loaded to. The most popular address I saw is , closely followed by , but I also saw and used a lot. Why would I choose one over the other? I understand because it's close to which you have to write the instruction to, but the other addresses all seem arbitrary. Can someone shed some light into this? 

Nowadays, most music seems to be prerecorded, but that means they are rather static and take up a lot of space. I wonder if MIDI is still a viable option (especially considering consoles or iOS) and if I can expect General Midi 1 to be available everywhere? (Note: Referring to the software instruments for sound generation from notes) Alternatively, are there vendors of embeddable software instruments that can generate the desired sound at runtime? The whole point is to re-create a dynamic soundscape in which instruments can change their volume, speed or pitch - this can be partially simulated with individual tracks, but it doesn't offer the same flexibility. 

id Tech 3 isn't really free - it's GPL, so your entire Game has to be GPL. You used to be able to license a non-GPL Version for $10,000 but that options seems to have disappeared after the Bethesda-acquisition. Apart from it's age, id Tech 3 doesn't have much in the realm of Single-Player AI. So if you want to make a "traditional" shooter, you have a lot of AI work to do yourself. Another problem is the tooling. There are a lot of Map Tools, but that's about it. There is very little assistance in the Asset Pipeline or Shader creation. On the upside, the Team Arena source contains an early version of MegaTexture and supports relatively large outdoor environments. 

Game B, 2.5D Render, sprites are ordered by the z value of its position vector. In this example positive z is down and negative z is up. z-axis and y-axis are parallel but z is scaled by a factor of 0.5 of y. So if the visible area is from 10y to -10y, in the same area we have from 20z to -20z. Objects with a greater z will be drawn latter, so they will be seen as being in front of objects with lower z. Shadow of player character looks weird because shadows are in a superior layer than the floor, but in an inferior layer that all the other objects, so the player character shadow never is on top of the cube. 

Game A, 3D Render. Depth buffer (also known as z-buffer) is used for pixel precision depth testing. So, an object does not need to completely occlude another, not even a triangle needs to completely occlude another, we have pixel precision depth test. We can rotate the game objects in any way and still get realistic results when they interact. 

Demonstration: Crude but functional collision detection and response Video: $URL$ The idea is that the player controlled sprite (actually a 32x32 pixels red box) can raise the speed of its next move, but it cannot go back to original speed except if it collide with something. Also if speed is enough the green wall can be "damaged" until it finally is destroyed. Gravity can be disabled. This situation shows AABB in action. In the video, the red text shows some game variables, penx y peny are the lengths of penetration vectors into each axis (of the player sprite into other objects). T.x and T.y are the coordinates of the 2d vector that go from the center of a box to the one again it is tested. If you go for AABB as I recommend, you will need T. The formula used for T is: 

And in this case, that would work because dx is a constant. But in general, dx can be zero, so you usually want to use: 

You want the angle of the arrow at any point in time. You remembered that in order to compute an angle, there's a tangent. But here's where your thinking started to go wrong: 

The coefficient c is a small number, and friction will tend to slow down the projectile so it always operates in the opposite sign of the moving projectile. You need the direction of the projectile, which is the vector: 

but this is scaled according to the velocity. If you want to apply a negative acceleration, first compute the magnitude (already computed as v above) Now you can generate a vector 1 unit long in the direction of the projectile: 

You need a reality check if you think you are going to handle instability, tumbling, or anything like that. You don't have the math for it, and it will take years to get it right, as well as massive amounts of CPU you don't want to devote in a game. You can try to fake that if you like. But if you want somewhat realistic slowing down of the projectile, that's relatively easy. 

Generically speaking, how would you handle a huge 2D Map of which only a part is displayed? Imagine the old top-down racing games like Micro Machines. I would know how to do something with a tile-based map, but I want to create completely custom Maps. Target Devices are iOS, Windows Phone 7, Android, Mac and PC. Assume the Map is too big to fit to fit into a single Texture. Would I have multiple textures, 4096x4096 each and load them all into RAM? Seems wasteful, and if textures are uncompressed I might actually run out of graphics memory. Would I only load the max. 4 Textures that I need at any given point (when I'm at the intersection)? Or would I have one huge image file and load parts of it? In that case, are there any image formats that make it easy (O(1)) to find the file offset and length which I would have to load? Or is there a completely different algorhithm? Are textures the wrong idea? How would you implement a game like Micro Machines? 

The Score bar, with different fonts The ship itself A satellite attached to the ship, detachable Secondary Weapon Projectiles Primary Weapon Projectiles Moving objects (can be enemy ships) The Status bar, featuring an image of the ship, the number of lives and three sections that can fill The primary weapon charge bar, can fill to the end A scrolling starfield in the background (not numbered on the screen) Solid objects like rocks or metal walls that are part of the background 

There are different tricks to give the sensation of being in a 3D world when you only can render 2D graphics, I only presented a quickly crafted example using some assets of an abandoned project of mine. Why not just use 3D always and forget about 2.5D? Well, I can think in some examples of why a developer may prefer the 2.5D approach: 

What about teleporting sprites? If you represent teleporting as a large displacement, using the same moves component as a normal move, then no problem. If you don't, then you have to think a way to mark the teleporting sprite to be processed by the collision code (adding to a list dedicated to this purpose?), during response code you can directly displace the standing sprite that was in the way when the teleportation occurred. 2 - Phantom AABB Have a secondary AABB for each sprite affected by gravity that starts at the sprite bottom, has the same width of the sprite AABB, and 1 pixel height. The idea here is that this phantom AABB is always colliding with the platform below the sprite. Only when this phantom AABB is not overlapping anything gravity is allowed to be applied to the sprite. You don't need to calculate penetration vector for the phantom AABB and the platform. You only interested in a simple collision test, if it overlaps a platform, gravity cannot be applied. Your sprite can have a boolean property that tells if it is over a platform or in the air. You are in the air when your phantom AABB is not colliding with a platform below the player. This: 

Your language looks like CSS, but it isn't. It's your own Domain Specific Language. Ask yourself this: Do you really want to create your own file format, for which you need to write a parser. This parser needs to be fast and robust. You also need to document your file format and teach people how it works - after all, it's a customized language. You then need to be aware that you may run into issues you never thought of - maybe someone thought it's a great idea to create a 50 MB file and your parser crashes, corrupting a savegame or so. Or you decide you need to add a feature that can only be implemented with a breaking syntax change, thus breaking all the existing files. The reason why formats like XML are so popular is because XML has these problems solved. You can find many great XML parsers that are proven to be robust, fast and leak-free. Also, many people know XML files and how to edit them, and because it's such a generic but well defined syntax you can be sure that you can extend later. Your motivation seems to be easy editing by hand, which is common in community SDKs. Now, the reason people edit those files by hand is that they don't have the tools the Game Devs use. You can assume that a company developing a game for several years has some graphical tools for editing such files - they may not be great and bugfree, but they edit the files for you and developers only rarely edit them by hand in order to tweak something. Those tools are rarely released in 'Modding SDKs', so most modders edit by hand. So my initial reaction would be: Instead of spending time developing a new, unproven format that is easy to edit by hand, I'd rather use a battle-proven format and spend the time writing tools that make editing easy. But blanket statements don't work like that. It always depends. If you spend 3 or more years writing a big game with a sizable dev team, then you can spend a lot of time developing, testing and finetuning your system. If you have 15000 files to parse, then finding ways to reduce memory usage becomes important. But for small/medium/indie games, I'd go with a known and well-supported format like XML and a nice tool to edit it.