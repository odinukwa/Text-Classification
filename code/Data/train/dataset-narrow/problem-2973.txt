The book has the philosophy that exceptions are only used for program bugs. variance, invariance, preconditions, and post conditions. Everything else should be checked traditionally. You will be surprised at how much simpler this makes things. You hardly ever see or use a catch clause. The philosophy makes it easy to get things right: if you forget to check an input, or have an out by one error, then the program will tell you that you have a bug, and tell you where it is. 

Reason 1 : Because without printing it out you can not weigh it. When I was an university, there was a myth that some lazy teachers (I don't know the technical terms for the roles), would weigh your reports, and give a grade base on that. I heard of one student that handed in some work with a load of blank paper attached, and got a good grade. Reason 2 : To see how complex it is. I remember a story by Michael Jackson, about judging how brilliant some one is. I will include the last 3 paragraphs here. 

I would start by ensuring that you have a system with a good command line: Such as Gnu/Linux (A implementation of Unix, with freedom). It is also Free Software. While using it you may discover some piece of software, that you would like to improve. You could do what I did at Uni. We were asked to re-implement the basic Unix tools: cat, ls, grep, etc, this is good practice, and a good place to start. It will also help you learn about what Unix can already do. (What can be a 3 month project on windows, can sometimes be a single line of shell code in Unix.) 

Literature class There are a lot of poetry, jokes and literature about computing. Books, plays, film etc These can be good to study, and ask are they like real computers? Why not? What can we learn from them? 

Exponents representing the values of the digits in positional number systems. e.g. the-arabic-system / denary / the-system-you-learnt-in-primary-school. 

We are often asked to plan: We are asked to make lesson plans; When I was a programmer sometimes I was asked to create a plan; We are told to ask our students to plan their projects. However there is often a problem with this: 

The book “a touch of class” — bertrand meyer. Teaches Object orientation in a first year undergraduate cause. He claims that in his course he teaches Eiffel, then a bunch of other OO languages at the end (C#, Java, …) quicker than any of the others can be taught alone. This seems reasonable, as Eiffel is very well mapped to OO. There is on the most part a one to one mapping between Eiffel and OO. This makes it much easier to learn. There are few gotchas (there is one), few work arounds. What is more all the nice new stuff from C# (possibly also Java), came from Lisp or Eiffel (generics, contracts, get/set properties). Simple syntax 

I have been teaching databases, over the last through weeks, to key-stage 3 pupils (year 7 and 8). The school I am at uses Microsoft's Access. This seems adequate in many ways. However it has many problems, that frustrate pupils and thus, get in the way of learning. For example: 

In UK at A-level We cover the following. Multi-core, semaphores, queues, process pipeline, SISD, MISD, SIMD, MIMD. We don't specifically cover how to write programs using these. A student could also get a good grade and know little about there. 

The properties in «» are from Christopher Alexander's book “The nature of order”. They are what patterns are made of. see $URL$ for a list of all 15. 

It has been shown that as lines of code increase performance decreases. As assembler programs grow there performance drops. It is hard to write big programs in low level languages. You can not consider all of the low level stuff and all of the high level stuff at the same time. Therefore choose a language that keeps lines of code low. (This is not the only factor.) Even if you make a highly optimised assembler program, that is faster than the high level alternative. It will not be faster (or won't work), on a different processor: Different optimisation decisions need to be made for , , , , . However if an [efficient] high-level language is used, then you just recompile your system (or get someone else — such as Debian — to do it), and you have a new faster system. The assembler code stays slow, until re-written. Reasons of Yes 

This is not a complete answer, and it misses the "drawing an accurate picture of work in the field" goal, but I think it shows an approach worth mentioning. I'm not sure you can show the picture accurately without a hands-on experience with coding. 

A few tweaks to expression classes, and basic caching is there. Another idea to add common implementation would be listing free variables occuring in the expression (after adding variables ofc). First, make subclasses implement method (returning list of subexpressions, e.g. in case of sum). After that, implement method in Expression, and override it in Var/Variable (to return the single variable used there). The effect should be something like: 

¹ Actually, the course, called "introduction to programming", had 2 variants: imperative (mainly for beginners) and functional (for people with some experience). The first one was the sieve, for the second one it was mostly a non-issue. 

That may not be the best metric. Even if it's actually possible to tell apart populations of people with basic programming abilities and those lacking them, it's not enough of the solution. Some people may be quite capable, but still dislike the process. So there will be people trying to study CS that will eventually want to leave. Maybe it's better to just make these people leave quickly The way that my university was approching this was to put fast paced programming course with focus on algorithms in the first semester. The course, apart from teaching obvious skills, had an explicit purpose of failing or discouraging all the people without the skill or interest necessary to finish the studies¹. And then in the second semester, it was followed by writing a sizable GUI application as an individual project. While I don't have any numbers, I believe it worked kind of well. It seems that whoever survived the first year and was willing to stay, was well capable to finish the undergrad course and find work in IT. However, there are some caveats The main issue with the presented approach is that it's strongly negatively biased. It discourages all the people that should be discouraged, but perhaps discourages also some happened to be just a little bit to slow. And while a university sucking up in all the best country talents may afford being picky, I'm sure it doesn't work everywhere, at least not at this scale. It also must be more tricky in a private school. My university was public, and people generally paid no tuition. 

Implement nested arithmetic expressions. Let me start with what it can look like, and then I'll explain why it's a great example. It starts very simple: 

Starting languages for non-programers Vastly depending on what is the purpose, but for some people it may be beneficial to choose for a first language a scripting language, that is used only as snippets in a wider context. The main advantage is that you get useful stuff basically from the point zero, and not only after learning half a language. If you stop learning after 5 hours, you may still have some benefit from it. Some possible choices: 

Where is the inheritance? I'd like to point that I didn't use Python's subclassing at any point here, and it was on purpose: Python's subclassing is mostly about implementation inheritance, and here it's not necessary at all. Of course, if you use type hints, you should define an interface, but only in that case. Python is generally duck-typed and there's not much point in pretending it's not. However, you can also add some shared implementation to this example. Adding implementation inheritance There is at least one thing that all kinds of expressions may easily share: caching. Example base class could look like this: 

Note: Initially my answer was just about computational complexity, but then it grew a bit, so I broke it into multiple sections and tweaked each a bit. Thanks to commenters for pointing out the details to fix. Understanding computational complexity That may be covered by your "understand better how these structures behave", but it important enough to deserve its own place. It is very hard to appreciate the computational complexity behind a library structure operations. You don't need or should care how things work under the hood, you should be happy with information that given operation is guaranteed to run in "O(log n)" or "O(container size)" or in "amortized linear time". But to get a good grasp what all that O-speak means, you should actually write the code that iterates over a linked list or finds stuff in a BST. Once you have some well set expectations of how things work, you can move on and perhaps never write own containers again - but you will forever remember what happens under the hood when you call some random library method (or at least have a rough estimate, see Certainty about behavior). General knowledge about writing containers (mostly inspired by Buffy's answer) If you ever happen to actually write a container (e.g. one missing in given language), you will not only benefit from specific knowledge about containers you wrote, but, more importantly, from general knowledge about writing containers. There are several reoccurring patterns about containers design, and knowing them from the "internal" perspective certainly helps. Certainty about behavior That one may be important for educational value. Only writing your own structure or algorithm gives you certainty that it behaves as you expect. Built-in structures may often contain extra optimizations and don't necessarily implement any "canonical" structures. They differ in details. Avoiding over-complex library APIs Library containers not only may behave in "non-canonical" way. Their APIs usually contain many additional functions that, while useful in production code, for learning are just unnecessary distraction. E.g. in C++ containers have multiple variants of every method just to allow optimized memory management, or some syntax shortcuts. C# is not very different. De-mistyfying library code Direct answer for question "why do we have to do this": to see that there is no magic. You can do all that things, using libraries is mostly just about saving time. Debugging your own components will likely help you appreciate that libraries are well tested and patched, but should also show that writing similar code isn't something unreachable. 

Summary Always choose good name for you objects, and don't do too much Hungarian. When I was programming in C++, we also had at the beginning of a name for parameters, for local, for a member variable (We did this to avoid name collisions, in retrospect I think that these 3 were not needed. We could have used instead of ). That was it just 5 Hungarian pre/post fixes. You don't need any more, probably less, in a strongly typed language. 

Racket is also Free Software, so I would go with that. (Sorry I said that I would not recommend one.) 

I often see people mixing up files and filename in variable naming. It will result in mixed up thinking. I think it is important to come up with clear names. I like to start with giving them lots of code. They then read the code, analyse, modify. In my code I use clear names. We discuss naming, and how this affects readability. Also to discuss with class: I have included some questions about some statement. Use your discretion as when to ask them. I am not suggesting you ask them in a sequence as presented. When you call a subroutine it takes a thing or a name of a thing. e.g. takes a string [or the name of a string]. Is `/dev/null' a string? Why is it not a string? Is it the name of a string? Why is it not the name of a string? When you define a subroutine it takes a name of a thing. Why does it not take a thing, why only a name of a thing? Is that a name of a thing? 

In like languages (C, C++, Java, C#, …), always use in the form (there may be some exceptions, but rare). So you are using to construct a foreach, as the language does not have the higher level structure. (C# has ; C++ has library implementations; Java has foreach, but uses keyword ) 

The additional dangers of software over other engineering fields. Who is in charge All software is a form of artificial intelligence, by this I do not mean artificial consciousness (e.g. skynet, I Robot, ExMachina, robby, and every other robot from the movies). I think that the probability of artificial consciousness arising soon is very low. However some form of artificial intelligence is in every bit of software. The danger is not the artificial intelligence, but who controls it. A lot of software to day is controlled by big corporations. Users of the software are not free to: choose how they use it; study how it works; make changes to it; share it with their friends. Therefore all software should be Free Software. I am not referring to Open Source. Although (Software that is Free Software) ≈ (Software that is Open Source). I am referring to the concept of Free Software. The freedoms, for it is the freedoms that we need. These freedoms are also in the Open Source definition, but are usually over looked. I am also not saying that all Free Software is ethical. There are many sides to being ethical. There may also be proprietary software that is more ethical than a particular bit of Free Software. Free Software is necessary but insufficient, to being ethical. Just as obeying one of the 10 commandments is necessary but insufficient, to being good (Even obeying all of the law is insufficient). 

The ideas in your question are far too difficult, for a one hour introduction. Yesterday I had a look at Haskell and learnt some. I have over 30 years programming experience (20 years professional). Have experience with functional programming. Yet it took me several hours, and did not get far enough to be able to do your suggestions. Mathematics You say that your students have a maths background. Take advantage of this. Choose some math problems. That Haskell is ideally suited to solve. And explain why you are doing this. Ensure that you have more than you think you will need, as some students will be much faster than you expect, but don't expect to use them all. There are some good ideas here $URL$ also some of the other answers, to the same question: sort, search, interpreter (this one may take too long), factorial. Avoid bad examples Don't do problems that are more difficult in a functional language than in a procedural one (Reversing a list, using procedural techniques, in $O(n)$, is easy. If by using functional they will probably get a $O(n^2)$ solution, and $O(n)$ is hard, then you are teaching a disadvantage on day one.) Fibonacci is, I think $O(2^n)$, for simple recursive implementations.