p0 and p1 are the control points and m0 and m1 are their respective tangents calculated elsewhere. Previously I said I had no idea what I was doing with the math, but that was only because the derivative route felt too easy, so I figured I must have been doing something wrong. I went ahead and tried it and implemented it anyway. This is the formula that results: 

Let's say, for example, that I have a working spline. I want to use this spline to create a mesh, but I'm not quite sure how to go about it. For example, I want to create a road along this spline. I can interpolate through the curve and generate my segments and use that. If I were just making a single straight line I could take the normal of that vector and extrude the endpoints to get the vertices for a quad and do it that way, but how should I handle the curve part? I can't just use the endpoints of one quad as the start of another because they won't line up at different angles. What would be the proper way to extrude a spline into a mesh? I'm tagging this as Unity since that's what I'm using, though the answer I assume will be engine-agnostic. 

When you set the new angle that you want to rotate to, use that as a target rotation, and then in you can continually interpolate the character's current rotation to the target rotation using . The rotation speed variable will be an arbitrary float that controls how quickly the character moves to the target angle. 

After tinkering with this for a while, I've found a solution that works. Or rather, it works to solve this particular problem, and I don't know yet what other issues it causes. But at least for now it works perfectly. To solve it I just iterated through each of the possible collisions, checked the translation against the others, and kept the vector with the greatest magnitude, or the successful resolution that resulted in the greatest distance. 

The question of whether it should be in a grid is really up to you. If you're dealing with presenting data, like a statistics screen, then using a fixed width for all characters could make things easier. If you're just printing lines of text, on the other hand, it makes much less of a difference and you can choose freely, as you can find both ways in use. 

Taking the Ys series as an example, there are times where boss fights essentially end up being the whole point of the game, with the dungeon crawling in between serving as a mechanism o advance the story and power up the character. In games with emphasis on pace, reflexes, and skill, boss fights can be a major way to test the player's abilities within the confines of the provided systems. These bosses are notoriously difficult and force you to learn the boss to be able to beat it, and while this may not appeal to many people, it has its popularity. The goal in this sense isn't to provide a sense of epic scale as far as I can see, and it's not about punctuating the story. Sure, as a matter of general pacing and storytelling it may fulfill either of these roles to throw in a boss battle, but that's just a consequence of storytelling. The boss fight is rather a spectacle in itself, and the sense of relief and reward when completing these challenges is wonderful. And even if you manage to beat a boss, there are still harder playthroughs or faster times to go for. In fact the games themselves emphasizes this boss-battle-centric approach by including time attacks and boss rush modes. Ask anyone who knows the Ys series to say something about it and they will invariably mention brutal boss battles. This shows that boss battles can be a crucial centerpiece to a game, and it's a model that has demonstrated appeal. 

I've been using XNA for a while to tinker with 2D game development, but I can't help but feel constrained by the content pipeline when targeting PC only. Things like no vector fonts or direct use of graphics files make it a pain while other frameworks do these things with no problem. I like XNA because it's robust and has a lot of support, but what are the specific benefits that I'd get developing exclusively for PC, if there are any at all? 

Should work whenever you call monster.get_attack(). Note however that it's generally a bad idea to use hard coded "magic numbers" like this. It would be a good idea to define a monsters attack stats as members of the monster class. It seems like you're making monster a class because you read somewhere that it should be a class and not because you're going for an object oriented structure. Read up on object oriented programming 

When a rectangle is on the far edge on any side of another rectangle, a force can be applied, in this example down, the pushes one rectangle into the other, particularly a static object like a wall or a floor. As in the picture, the collision is coming from above, but because it's on the very edge, it translates to the left instead of back up. I've searched for a while to find an approach but everything I can find deals with general corner collisions where my problem is only in this one limited case. Any suggestions? 

OK, I continued fiddling with it and I went ahead and just tried to do the math. This is the equation I am using for the interpolation between two points: 

You need to interpolate between the camera's position and the target position. It looks like libgdx has a linear interpolation method that you can use, however if you want something that has a smoother ease in/out you'll need to use another method, which it seems you can do using . Call one of these methods every frame and your camera's position will move smoothly to the target position instead of snapping. 

It looks like you're constantly moving the platforms to the left, as you explain, but you're only checking for collisions along the Y axis. So what happens if you fall down a pit? The platforms will continue moving to the left, the collision will register from the right side of your player, and the position will be adjusted back up to the surface of the platform. You need to implement another check that stops the player from moving horizontally in the platforms and resolving back up to the top. If your world is moving around your character then your character's x velocity will be 0 relative to our view, but when the player collides with a platform either the world has to stop moving or the player has to move back to avoid progressing through the platforms. If the world is moving around you then you might just want to make an instant game over condition if you're colliding with the side of an obstacle rather than landing on it, or just stop the movement and let the player fall. 

EDIT: After some further tinkering and testing, I'm finding that the problem is more specifically that the movement seems to jump from frame to frame rather than move smoothly from one spot to another. It seems like it's moving the right speed, but this kind of really fast start/stop gives it that jerky feel. Is this normal behavior? Shouldn't the delta time multiplication smooth out the movement and give it a more interpolated feel? This happens even if i avoid the normalization method and just multiply the axis by speed and time. 

Unity will use the first camera tagged as , so you'll need to change the tag of the camera you want to be main and remove the tag from the old main (or just delete it). 

I was looking at the descriptions of various curve techniques here and noticed the mention of circular arcs. I want to implement something like this, but I'm not quite sure what the correct formula to use is. I can easily find formulas for Bezier or Hermite curves, but when I search for circular arc splines or circular arc interpolation I get a lot of ultra technical articles that are far beyond what I need. My hunch is that I take the angle formed between the endpoints and the control point and use that radius, but I'm still a little too wobbly conceptually to be able to guess a formula. For those who cannot follow the link, the circle data is given by a starting point and end point which lie on the circle as well as a control point which is used to control the angle. What formula can I use to interpolate over and approximate an arc of a circle given these three points? 

This is what my resolution method looks like at the moment. I had a recursive call to handle jittering in corners but that gave me a stack overflow when testing against certain rotations, so for now I'm just resolving it twice. Fixing that bug shouldn't be too hard, though, and it can be possible to make it into one elegant method that handles everything. 

I think the problems I'm having with this come mostly from translating physics concepts into data structures. For example, earlier in the code there is a calculation of the axes to be used, and these are stored as , and they are found by subtracting one point from another, however these points are also stored as s. So are the axes being stored as slopes in a single ? Next, what exactly does the produced by the vector projection code represent? That is, I know it represents the projected vector, but as it pertains to a , what does this represent? A point on a line? Finally, what does the scalar at the end actually represent? It's fine to tell me that you're getting a scalar value of the projected vector, but none of the information I can find online seems to tell me about a scalar of a vector as it's used in this context. I don't see angles or magnitudes with these vectors so I'm a little disoriented when it comes to thinking in terms of physics. If this final scalar calculation is just a dot product, how is that directly applicable to SAT from here on? Is this what I use to calculate maximum/minimum values for overlap? I guess I'm just having trouble figuring out exactly what the dot product is representing in this particular context. Clearly I'm not quite up to date on my elementary physics, but any explanations would be greatly appreciated. 

I haven't actually implemented this system yet. I'm trying to work through the major conceptual hurdles before I actually start writing code, and the proper way to generate IDs is a little confusing to me. Should I just give each entity an integer ID in the order that it's created? Use the C# guid? What is the proper way to assign IDs in such a way that there won't be issues later on? 

If you want to do it the old-fashioned way, then yes, you can use it in a grid. But if you want to use any kind of variable or half-width characters, like writing 5 instead of ５, then you'll need to get off the grid. The characters are all the same width anyway so if you're not using any non-Asian characters then it should align by itself. I don't think having it not on a grid would make any difference in readability. As a demonstration: 

It's only randomized the first time because you're only calling the random function one time (when you create the monster object). When you have in your class then you are creating that variable with a random amount at that time, but you are not altering it. In order to get a random value every time you need to reset the value every time you perform an attack. Notice how you do this when you set ; you need to do it the same way with . If you want to be able to generate a random attack, you need to create a method to do it. Something like this in your monster class: 

Previously I used a plain cylinder with open caps as an example, and finding edges that were only used for one face might have been able to do the job, but in a case like this, it would end up selecting any vertices in the middle along the bottom as well, which I don't want. I want to be able to find the ends of a particular side like those that are selected in the picture. Theoretically I can then manipulate these into new positions if I wanted to, for example, string cylindrical segments into a curved cable structure. For what it's worth, I'm trying to accomplish this in Unity with C#, but it's the algorithm I need help with. 

OK, I've found an answer to my own question, however I'm not sure that it's the best answer. Basically the problem was in the order that the axes were checked which resulted in the hangup happening in some directions but not others. So to resolve this I simply do the check one more time in reverse order. I was previously doing this recursively but not reversing the list. Here's the "working" code: 

The problem with resizing spritefonts is that when you make the spritefont, a file is made with an image of the font at the size you specify in the xml file. Because of this, you are not going to get the scalability of vector fonts, meaning that when you make your fonts bigger they will be blurry. The only way around this is to create several sprite fonts of varying sizes that you can switch between when the quality starts to get too bad. Alternatively you can check out the Nuclex Framework which has support for vector fonts. 

I have a working collision system implemented, and it's based on minimum translation vectors. This works fine in most cases except when the minimum translation vector is not actually in the direction of the collision. For example: 

I've been working on implementing my SAT algorithm which has been coming along well, but I've found that I'm at a wall when it comes to its actual use. There are plenty of questions regarding this issue on this site, but most of them either have no clear, good answer or have a solution based on checking grid positions. To restate the problem that I and many others are having, if you have a tiled surface, like a wall or a floor, consisting of several smaller component rectangles, and you traverse along them with another rectangle with force being applied into that structure, there are cases where the object gets caught on a false collision on an edge that faces the inside of the shape. I have spent a lot of time thinking about how I could possibly solve this without having to resort to a grid-based system, and I realized that physics engines do this properly. What I want to know is how they do this. What do physics engines do beyond basic SAT that allows this kind of proper collision resolution in complex environments? I've been looking through the source code to Box2D trying to find out how they do it but it's not quite as easy as looking at a Collision() method. I think I'm not good enough at physics to know what they're doing mathematically and not good enough at programming to know what they're doing programmatically. This is what I aim to fix. 

I'm not 100% sure on this but it seems that the problem may be in the fact that in each frame for gravity you are adding 0.15 to Y velocity, but then casting it back down to an integer when you do your rectangles. So if technically you've adjusted your position by a fraction of a pixel, then when you do collision checks it will say you are not colliding (because you are casting that 0.15 down to 0) and then (I assume) drawing the sprite to the fractional pixels. You can try casting the positions in your draw method to integers before you draw it. This could prevent the jittery between-pixel drawing. 

I was looking at a video of a system that extrudes meshes along a curve, connecting them end to end but adjusting the vertices for a smooth connection. It does this with a mesh that as far as I know is guaranteed to have open ends that are later capped with a separate mesh. Here is a video showing the effect I am trying to reproduce. Let's suppose I have a mesh, then, that is open like in the picture below. How can I find the vertices that are on one edge only of this mesh? For example the ones that are selected here. 

I'll let this picture do the talking. I'm trying to create a mesh from a bezier curve and then add a texture to it. The problem here is that the interpolation points along the curve do not increase linearly, so points farther from the control point (near the endpoints) stretch and those in the bend contract, causing the texture to be uneven across the curve, which can be problematic when using a pattern like stripes on a road. How can I determine how far along the curve the vertices actually are so I can give a proper UV coordinate? EDIT: Allow me to clarify that I'm not talking about the trapezoidal distortion of the roads. That I know is normal and I'm not concerned about. I've updated the image to show more clearly where my concerns are. Interpolating over the curve I get 10 segments, but each of these 10 segments is not spaced at an equal point along the curve, so I have to account for this in assigning UV data to vertices or else the road texture will stretch/shrink depending on how far apart vertices are at that particular part of the curve.