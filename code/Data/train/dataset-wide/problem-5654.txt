Propositions in intuitionistic logic (IL) can be translated into S4 modal logic via the GÃ¶del-McKinsey-Tarski translation. 

The Church-Turing thesis is a non-provable thesis, rather than a theorem, because it is a claim that our informal, non-theoretical understanding of what counts as effectively computable is entirely captured by what is computable by a Turing machine, or equivalently, by a general recursive function. The term hypercomputer is used to denote a computing device that can compute things that are not Church-Turing computable, so another way to express the thesis is that it is the claim that there are no hypercomputers. The claim that there are no hypercomputers is not unfalsifiable, but a negative claim like this can only be supported (not proved) by doing our level best to devise a hypercomputer and showing that it is unrealizable. Several theoretical models of hypercomputation have been proposed but none have been found to be feasibly realizable. One might go further and argue that in order to implement a hypercomputer, it would have to operate in a way that is consistent with the laws of physics, and given what we currently know about physics, this is inherently implausible. A hypercomputer would have to be based on weird physics: even more weird than quantum mechanics, since quantum computers are consistent with Church-Turing. An ideal analog computer could potentially be a hypercomputer, but it would have to be able to process real numbers to infinite precision, which is not consistent with the picture of the universe that QM offers us. So it is not unreasonable to accept that the Church-Turing thesis is correct and base scientific work on it, even though we cannot prove it. 

Looking at a bunch of numbers or other data and trying to judge whether it is 'random' (whatever your definition of random) is not easy. As you say, people are not good at inventing data that is supposed to be random. The effect you mention is called the clustering illusion: the tendency to overestimate the significance of runs or clusters. Another common error is to ignore Benford's law: financial auditors use this to identify cooked books. It is true quite generally that people are remarkably bad at reasoning with uncertain information. And it is not just the lay person: scientists, researchers, economists, business people, lawyers, etc., no matter how well educated constantly tend to overestimate their ability to calculate with probabilities. Some of the common mistakes are confusion of the inverse, the base rate fallacy, assumption of independence, gambler's fallacy, confusing conditional probablity with marginal probability, Simpson's paradox, Berkson's bias, etc. If you don't mind getting upset about a real life tragedy, look up the case of Sally Clark for an example of how an expert witness in court screwed up a probabilistic inference and it resulted in a serious miscarriage of justice. 

There seem to be two questions in one here. The first is, what justification can we give for using deductive reasoning generally? The second is, what justification is there for one particular system over another? One cannot really address the second without attempting to answer the first. The first question is seeking to understand what is the epistemology of logic. How do we know logical truths are true, or that valid arguments are valid? There have been many different responses to this question. Broadly, they divide into internalist and externalist categories, and each in turn has several variants. Some have defended the idea that our intuition or insight as rational beings provides a kind of privileged a priori knowledge of logic that is incontrovertible. One might challenge this on many grounds. The history of philosophers claiming that various things are intuitively and certainly true is not a happy one: often the claimed truths turn out to be false or even absurd. Our intuitions aren't really that reliable. Also, if logic is incontrovertible, why is there so much disagreement between competent logicians about which logic is the 'correct' one, or even concerning what logic is fundamentally about? Some hold that logic is justified inferentially by the relations of logical consequence that we consider correct. This is often defended by appealing to the concepts of logical harmony and logical stability. This runs into a circularity objection, pointed out by Lewis Carroll. Some contend that logic is justified purely syntactically by the proofs it is capable of generating. Or that proofs correspond to computations, and so logic is justified indirectly by our understanding of computation. Another approach is to try to base logic on a concept of analyticity. The idea is that some sentences have no empirical content and are therefore true 'come what may', or true in virtue of the meaning of the terms they contain. This position was popular with the logical positivists in the 1920s and 1930s and still has some defenders today, though it took a fair beating from Quine, Putnam and others, and does not appear to be especially popular with philosophers. Another possible attempt at justification would be to appeal to natural selection. If we were not good at logical reasoning, we would be selected against and be less like to survive and propagate. This runs into the objection that we cannot be sure that logic always provides a strongly positive selection bias. Also, we know that humans are quite spectacularly bad at reasoning with probabilities and uncertainties, among other things, so it seems dubious to place too many expectations on natural selection. Another approach is called anti-exceptionalism and maintains that logic is similar to a scientific theory. It has no special properties of a priority or analyticity and is potentially revisable in the light of empirical discoveries. On this account, logic is justified in the same way scientific theories are: we subject it to criticism and attempt to solve problems with it. If we succeed we keep trying more problems, and if we fail we look for something better. The logic or logics we are left with are the ones that work best because they have survived critical testing. Which of the various systems of logic is 'correct'? On the rational intuition account, presumably we must just consult our intuitions on the matter. For myself, I don't see how this helps. Are the defenders of the various different logics just wrong in their intuitions? Is it intuitively obvious that the principle of explosion should hold, or that it should not? Is it intuitively obvious that universal statements have existential import, or that they do not? On an analytic account, we would have to come up with a theory of meaning for natural language and argue that one particular logic does the best job of correctly accounting for, or at least conforming to, that theory. Michael Dummett took this approach in arguing for intuitionistic logic. Quine and the later Wittgenstein argued that this approach does not work. Anti-exceptionalism potentially allows for logical pluralism, so the question of which system is 'correct' need not arise. There are a number of useful references in my answer to this question. 

There is an interesting book called "A Farewell to Entropy" by Arieh Ben-Naim, in which he shows how the thermodynamic concept of entropy can be reduced to information theory. Just as statistical mechanics underpins classical thermodynamics and shows how the bulk properties of matter can be explained in terms of the properties of ensembles of micro particles, so statistical mechanics is itself underpinned by information theory. Ben-Naim proposes replacing our understanding of entropy as disorder with entropy as lack of information. This might be of philosophical interest, because it may help to clarify the relationship between information and epistemic probability on the one hand, and the laws of nature and physical propensities on the other. 

Confusing a term's definition with its connotation is a linguistic error of mistaking the strict meaning of a term with its associations. Someone who is told, "I love you with all my heart," and responds, "Hearts are just lumps of meat," has clearly failed to understand the intended connotation and is guilty of that confusion. It does not imply any fallacious reasoning as such. I don't see how the two examples you give relate to this. To say, "Terrorists are cowards because they are evil," is simply a non-sequitur, since not all cowards are evil and not all evil people are cowards. To say, "The minimum wage is not socialist because without it, many people will go into poverty," seems to be a claim that supporting the minimum wage does not make one a socialist, because one might agree with a minimum wage without taking on board all the rest of the socialist ideology. As such, this is a reasonable claim. More generally, arguments of the form "B because A" (or "A therefore B") are not all about explicating definitions, so it is not correct to dismiss an argument just because B is not part of the definition of A. Plenty of arguments involve more complex lines of reasoning that go beyond merely understanding definitions, and plenty more are not deductive at all, but abductive or inductive: this does not make them fallacious. Speaking of fallacies, the modern obsession of looking for fallacies everywhere, and asking, "What fallacy is this?" is misleading and unhelpful. Soon I will have to start a petition to get the word fallacy banned; it is one of the most overused and misused words around. Logic is not about fallacy hunting. If you think a particular argument is bad, just say what is wrong with that argument, without trying to compare it with others. Referring to fallacies is only helpful if it is unclear exactly what defect in an argument you are trying to draw attention to.