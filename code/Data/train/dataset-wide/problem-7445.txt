Let $A$ be a (Borel-)measurable subset of $[0,1]$.Let $\lambda$ denote Lebesgue measure. Is it possible that there exists a constant $c>0$ such that for all intervals $I \subset [0,1]$ we have $$ \lambda(A \cap I) \geq c \lambda(I), $$ other than in the trivial case when $\lambda(A)=1$? If the answer is "yes", then what is an example of such a set? 

Sauer's lemma, a well-known result in computational complexity theory, learning theory, and combinatorics, states the following: Let $\Phi$ be a collection of subsets of a set $U$, and assume that for all $d$-element subsets $x_1, \dots, x_d$ of $U$ we have $$ \Big| S \cap \{x_1, \dots, x_d\}:~~ S \in \Phi\} \Big| < 2^d. $$ (That means, $\Phi$ is of Vapnik-Chervonenkis dimension at most $d$.) Then for all $x_1, \dots, x_n \in U$ we have $$ \Big| S \cap \{x_1, \dots, x_n\}:~~S \in \Phi \Big| \leq \sum_{i=0}^d \binom{n}{i} \leq \left( \frac{en}{d} \right)^d. $$ Question: Let $m$ be a fixed positive integer. Assume that $\Phi$ is of VC dimension at most $d$. Let $x_1, \dots, x_n \in U$. Furthermore, let $\mathcal{A}$ denote a family of sets which has the property that 

It seems that you are interested in a "tractability problem", that is, a problem which asks whether the solution of a very high-dimensional problem can be efficiently approximated. As far as I know some research has been done in this direction, but much more for numerical integration than for PDEs. It may make sense to look for QMC methods (Quasi-Monte Carlo methods) for solving such problems (that means, using cleverly chosen deterministic points instead of random points). Look for example at the following: $URL$ 

Look at the expression $$ f(x_1,x_2,x_3) = x_1^2+x_2^2+x_3^2+x_1x_2+x_2x_3+x_3x_1. $$ The numbers $x_1,x_2,x_3$ are non-negative, and I assume that $x_1+x_2+x_3=3$. This is a sum of squares and "cyclic correlations" of consecutive variables. Then you can check that $f$ is minimized for the values $x_1=x_2=x_3=1$. Now look at $$ g(x_1,x_2,x_3,x_4) = x_1^2+x_2^2+x_3^2+x_4^2+x_1x_2+x_2x_3+x_3x_4+x_4x_1, $$ under the assumption that $x_1+x_2+x_3+x_4=4$. Again, this is minimized by $x_1 = x_2 = x_3 = x_4=1$. A similar thing happens if I add "second-order cyclic correlations": Let $$ h(x_1,x_2,x_3,x_4) = x_1^2+x_2^2+x_3^2+x_4^2+x_1x_2+x_2x_3+x_3x_4+x_4x_1+x_1x_3+x_2x_4+x_3x_1+x_4x_2, $$ again under the assumption that $x_1+x_2+x_3+x_4=4$. This is also minimized for the values $x_1=x_2=x_3=x_4=1$. Is there a simple explanation for this? Is there a simple argument showing that the same will happen for, say, 12 variables and correlations of order up to 3? 

Let $X$ be large, and let $\mathcal{P} \subset \{1, \dots, X\}$ be a set of primes. What is a good upper bound for $$ \sum_{\substack{1 \leq n \leq X,\\ p \nmid n \text{ for all }p \in \mathcal{P}}} 1. $$ From standard arguments in sieve theory (Brun's sieve, I think) one obtains that the sum in question is $$ \ll X \prod_{p \in \mathcal{P}} \left(1 - \frac{1}{p} \right). $$ However, if $\mathcal{P}$ is close to maximal (close to containing all primes in the range $\{1, \dots, X\}$), then this estimate seems to be far from being optimal. For example, when $\mathcal{P}$ contains all the primes in this range, then the sum equals 1, since not other number in $\{1, \dots, X\}$ is coprime to all primes in this range, while the upper bound above is around $X/\log X$. That was a trivial example of course, but what happens when $\mathcal{P}$ contains "most" primes in the given range? Assume, for example, that $\mathcal{P}$ is so large that $\sum_{p \in \mathcal{P}} p^{-1} \geq (1-\varepsilon) \log \log X$, for fixed $\varepsilon$. Then what is a good upper bound for the sum above? (As noted, here $\varepsilon$ is fixed and "small", and $X \to \infty$.) 

The distribution of the pair correlations of the eigenvalues of the GUE satisfies (in the limit, when being normalized appropriately) $$ g(u) = 1 - \left(\frac{\sin(\pi u)}{\pi u}\right)^2 + \delta(u). $$ The same pair correlation function plays a (conjectured) role in the theory of the Riemann zeta function. See for example $URL$ Question: Is there any simple way of constructing an increasing sequence of real numbers whose pair correlations distribution is as given above? I mean as a kind of (more or less simple) stochastic process. The result should be an infinite sequence. I know that this is related to the theory of determinantal point processes, but do not really understand how to do it. Maybe someone can help. 

What is the asymptotic order of $$ \int_0^1 \left| \sum_{n=1}^N e^{2 \pi i n^2 x} \right| ~dx $$ as $N \to \infty$. This should be known, but I cannot find it in the literature. 

Your question belongs to the context of normal numbers, which are real numbers whose digits and blocks of digits are uniformly distributed in the sense that each digits (or block of digits) occurs asymptotically with the correct "fair" frequency. The number you suggest is called "Champernowne's constant", it is known to be normal in base 10. For a first introduction, see for example here: $URL$ A number which is normal in all possible (integer) bases is called absolutely normal. If the distribution of digits is not "fair", then the number is sometimes called "abnormal". See for example here: Martin, Greg. Absolutely abnormal numbers. Amer. Math. Monthly 108 (2001), no. 8, 746–754. It is not known whether $\pi$, $e$, $\sqrt{2}$ etc. are normal in any base. However, it is conjectured that all algebraic irrationals are absolutely normal. See for example here for more information: Bailey, David H.; Crandall, Richard E.: On the random character of fundamental constant expansions. Experiment. Math. 10 (2001), no. 2, 175–190. 

I remember there is a result from the early 1980s, which states that the tail probability of a binomial distribution is always at least as large as the tail probability of the normal distribution (at least when $p \leq 1/4$ or something like this for the binomial distribution is assumed). However, I cannot rememeber the name of the theorem and the author, resp. Can someone help me? 

Let $c>1$, and let $A$ denote the set $$ \Big\{ \lfloor n^c \rfloor, \quad 1 \leq n \leq N \Big\}. $$ Thus $A$ consists of the first $N$ elements of a so-called Piatetski-Shapiro sequence. The additive energy $E(A)$ of $A$ is defined as the number of solutions $(a_1,a_2,a_3,a_4) \in A^4$ of the equation $a_1 - a_2 = a_3 -a_4$. Question: Is there an upper bound for $E(A)$ known? In particular, is it true that $$ E(A) \ll N^{3 - \varepsilon} $$ for some (small) $\varepsilon>0$, as $N \to \infty$? (The case $c \geq 2$ is quite easy, but how about the other values of $c$ in the range $(1,2)$? Note that for $c < 2$ the set $A$ is not necessarily convex.) 

As I understand it, you might be interested in a quantity called the inverse of the star-discrepancy. Given dimension $d$ and some $\varepsilon > 0$, the inverse of the star-discrepancy $n(d,\varepsilon)$ is the smallest possible cardinality of a point set in $[0,1]^d$ which has discrepancy at most $\varepsilon$. It is know that (somewhat surprisingly) the inverse of the star-discrepancy depends linearly on the dimension (and not exponentially, as some suspected). More precisely, one has $$ c_{abs} d \varepsilon^{-1} \leq n(d,\varepsilon) \leq c_{abs} d \varepsilon^{-2}. $$ The optimal dependence on $\varepsilon$ is an open problem. An admissible value for the constant on the right-hand side is 10. See for example Heinrich, S., Novak, E., Wasilkowski, G. and Woźniakowski, H. The inverse of the star-discrepancy depends linearly on the dimension. Acta Arith. 96 (2001), no. 3, 279–302. and Aistleitner, Christoph, Covering numbers, dyadic chaining and discrepancy. J. Complexity 27 (2011), no. 6, 531–540. The sort of question you ask (considering the influence of dimensionality on computational complexity) is called tractability theory. In the context of discrepancy, see volume II of the book of Novak and Woźniakowski: Tractability of multivariate problems. 

I think the most reasonable thing to do is to contact Johann Brauchart (who wrote the paper you cited above) and ask him how he computes his discrepancies. He is a very nice guy (I know him quite well), and I'm sure that he is happy to help. Actually he might also be interested in your research, so contacting him is a good idea in any case. 

Every set $A \in\mathcal{A}$ is of the form $S \cap \{x_1, \dots, x_n\}$ for some $S \in \Phi$. For two sets $A_1,A_2$ we have $\big| A_1 \triangle A_2 \big| \geq m.$ 

First the basic definitions: Let $H$ be a family of sets, and let $P$ be a set of points. Then $H$ is said to shatter $P$ if $\{ h \cap P:~h \in H\}=2^P$, that is, if every subset of $P$ can be obtained by intersecting $P$ with an element of $H$. The Vapnik-Chervonenkis dimension of $H$ is the maximal cardinality of a point set $P$ that is shattered by $H$. See also $URL$ Let $A$ be the family of axis-parallel boxes in the $d$-dimensional unit cube $[0,1]^d$ having one vertex at the origin. It is known that the VC dimension of $A$ is $d$. Let $B$ be the family of all axis-parallel boxes in $[0,1]^d$ (not necessarily anchored at the origin). The VC dimension of $B$ is known, it is $2d$. Now the question: Let $C$ be the class of all axis-parallel boxes on the $d$-dimensional unit torus. You could also thing of $C$ as the class of all sets in $[0,1]^d$ which are the $d$-dimensional Cartesian product of elements of $D$, where $D$ is the collection of all subintervals and all complements of subintervals of $[0,1]^d$. Now, what is the VC dimension of $C$? 

You are asking whether a number $a$ is a normal number in base 2 or not. This is an extremely complicated problem, and very far from being solved. Generally speaking, there exist several constructions of normal numbers, but we don't have any tool to determine whether a given number is normal or not. It is (sometimes) conjectured that all algebraic irrationals are normal, but a proof of such a statement is very, very, very, very, very far away. You may be interested in the paper Bailey, D.; Crandall, R.E.: On the random character of fundamental constant expansions. Experiment. Math. 10 (2001), no. 2, 175–190. where this topic is discussed. (By the way, the topic has a connection with ergodic theory. You are looking at the orbit of $a$ under the map $T:~x \mapsto 2x \mod 1$.) 

There is a classical theorem of Jackson stating that the $N$-th partial sum $S_N f$ of the Fourier series of a Lipschitz continuous function $f$ (which is periodic with period 1) satisfies $$ |f(x) - S_N f(x)| \leq c \frac{K \log N}{N} $$ uniformly for all $x \in [0,1]$, where $c$ is an absolute constant and $K$ is the constant in the Lipschitz condition. (This is stated in a more general case in the Wikipedia article here: $URL$ ) Question: does anybody know where I can find a numeric value for the constant $c$? (It is particularly important for me that $c$ is independent of the function $f$ - this fact cannot be seen from the statement in Zygmund's book, for example). Be careful: Jackson's theorem is often stated in the form of the error between $f$ and the "best approximation" of $f$ - this is not the same as the error in the approximation by the partial sum of the Fourier series! If you know where I can find the requested inequality, please let me know. 

You should certainly read Matousek's book "Geometric Discrepancy - An Illustrated Guide", which is very accessible. Another good introduction is Chazelle's "The Discrepancy Method: Randomness and Complexity". 

Let $A$ be an $n \times n$ matrix, for which I know the size of the sum of all its entries. Now I want to select an $m \times m$-submatrix, whose sum of entries is as small as possible. Is there any result on how well I can do? (In my case, $A$ is symmetric) Clearly, it will depend on some kind of irregularity of $A$. For example, if all entries of $A$ are ones, then the sum of elements is $n^2$, and any $m \times m$-submatrix will trivially have sum of elements $m^2$. But what if, for example, $A$ is such that each row and each column has all the numbers $1, \dots, n$ in it. Then I can calculate the sum of elements, and use an averaging argument to show that there is a submatrix whose sum of elements is at least as good as average. However, is there a better result? (For example, in the case of the matrix above, I can find a $1 \times 1$-submatrix whose sum of elements is 1, which is much better than average. But what for larger submatrices? In my application, I will rather need $m \approx n$ or $m \approx n/\log n$ and not a small fixed value of $m$.)