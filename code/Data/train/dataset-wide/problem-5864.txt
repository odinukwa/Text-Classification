Now regarding the Turing test itself, there are different ideas. From one point of view, if the computer is so good, that you can't distinguish it from a human, then why would you call one intelligent and another not? This is a valid observation, if you consider intelligence as a measure of the output of the system. Some argue that this does not necessarily define intelligence. I'm one of them. Let's take bees and humans for example. If in danger, a couple of humans think that "there is safety in numbers", you would take that as an intelligent thought. If bees stick together when in danger, no one calls that intelligence; it's merely hardcoded in them. As you can see in the example above, given the same behavior, we ourselves call one intelligent and the other not. Let's take another example. Do you consider Deep Blue an intelligent computer? Did you know that Gary Kasparov (who lost to Deep Blue) was convinced that no computer could have thought of the winning move of Deep Blue and therefore it must have had been a human deciding that move? Well, I think we can say Deep Blue passed the Turing test: it was indistinguishable from a human. But Deep Blue is a useless piece of junk now (sorry, I mean it's a valuable item in a museum). However good it may have been in chess, I doubt anyone would call it "an intelligent machine" because it passed the Turing test. Conclusion Like I said, this is rather controversial, but in my opinion, Turing test is perhaps a necessary condition for intelligence, but most probably not sufficient. 

Searle's Chinese Room arguments depends initially on the assumption that, if there is an intelligent system, some component of the system must be intelligent. Carrying this a long way to a conclusion, each lepton and quark in the Universe must be intelligent to some extent. The alternatives to that conclusion are either (a) there is nothing intelligent in the Universe, or (b) intelligence is an emergent phenomenon. I'm going with the latter. Searle then attempts to answer all objections (such as emergent intelligence) by indulging in more or less relevant discussion before claiming it reduces to the original Chinese Room, which he showed was not intelligent. This is an excellent example of begging the question, in the classic definition (assuming the proposition to be proven). The most relevant other discussion is the claim that a computer could not be intelligent in the human sense without having human-type senses to sense things like a human. How is a computer to know what a hamburger is without eating one? This seems like a good line of argument, but Searle does not pursue it. Searle claims, without support, that intelligence must be biological, and states that we know intentionality is biological in nature. I haven't seen this claim anywhere else, so I don't think we do know that. 

There are at least some guidelines, but it's impossible to know for sure. If there is a plausible line of causation, it increases the likelihood of causation. For example, making a hole in a water jug can plausibly be responsible for the water leaking out. Simplicity is useful here, as many complicated arguments can look plausible. If we have multiple instances, not spaced according to pattern or long-term trend, that's more convincing. One example might be leaded gasoline and its effect on crime: apparently the introduction of leaded gasoline into countries eventually raised the crime rate, and removing it eventually lowered the crime rate. Going over numerous countries, this becomes more convincing. As a special case, if we do A repeatedly, and get effect B reliably, it sure looks like causation. When I want my car to move forward, I put it in a D gear and release the brake, and that happens reliably. 

This is quite a controversial issue, but before getting to whether the Turing test is legitimate or not, let me respond to the second part of your question. 

P.S. You may also be interested in learning about a newer concept, called computational sapience (wisdom) that apparently is more powerful than artificial intelligence. This about page of the W.I.S.E lab of the University of Regina gives some introduction. In short, given a function (a behavior for example), an artificially intelligent system tries to find , but a sapient system also tries to find . In other words, artificial intelligence mimics behavior, while sapient system understands behavior. 

So computers also learn. It may not be as easy as it is for us, after all we had millions of years of evolution to develop our brain while the robots are merely a few decades old. However, they are not too stupid either. See this video for example on a couple robots that learn to play ball in cup or ping pong by imitation learning and reinforced learning. 

It's not. You are comparing the encoding of Chinese with understanding Chinese in the brain. The encoding part is comparable to the eye, not the brain. The brain could be comparable to the software that processes that binary coding. 

If we were to pass some text in Chinese to our eyes, it would CONVERT that to electrical/chemical signals and read. 

The brain ONLY PASSES SIGNALS AROUND. Yet there is learning. In fact, an artificial neural network uses pretty much the same mechanism as the brain. So the optic character recognition software that converts an image of Chinese text to their unicode encoding is similar to a part of brain doing the same thing. The software that takes that binary encoding and produces its English translation (for example google translate) is also pretty much like what the brain does; map the encoding to meaning. 

I would say that we can divide criticism to logic as pre-logic and post-logic. In pre-logic criticisms, people don't quite understand logic and are resistant to it already. Often they have only that stereotypical notion that logic turns a person into a non-sensitive robot. All their contact with logic was superficial and at a distance. In post-logic criticisms, someone knows logic well enough to get close to its boundaries. Then that person can start to discern where logic can or cannot go, and even deal with that kind of statement that "I can imagine such and such". Probably the person you're refering to is in the first category, but using ideas that are dealt with by people in the second one. The approach I try in those cases is usually acknowledge what the person is arguing, but saying that those things can only be really dealt with after you have some good grasp of logic. And to do so, first you have to get within its boundaries, and within its boundaries, necessary truths are... necessary. :) Besides, when a person argues like that, they are usually trying to make a point by using logic - at least in some sense. They are trying to make you conclude, by the premise of their imagination, that there can be such a universe. Logic is a wonderful system that we stumbled upon - maybe by inventing it, maybe by discovering it - that for some reason works amazingly well. And I think that is enough for us to give it a good credit, even if afterwards we question its limits.