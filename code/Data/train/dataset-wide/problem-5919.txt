I see here two different questions, conflated. One is a question about the right to speak in a certain way, given some circunstances. The other is a question about of the virtuousness of a specific line of action, given those same circumstances. The first one is about free speech, the second, about moral duty. I'd say, preventively, that freedom of speech is something that applies to silence also. You should be free to not manifest about something. It is typical of fascist regimes to capture free speech by first capturing free silence. That's an old trap, and we must always be vigilant to avoid falling in it. To answer your question more directly: your definition of "horrendous" is casuistic (and that does not mean I disagree, neither that I agree with it). For some concrete line of action to be defensible (ethically), it is enough that it can be aptly defended. That some concrete attitude is "defensible" doesn't take away one iota of responsability from the agent. Also, the ethics of concrete action ("is it right to do x?") is normally the subject of law scholars or ideologues, not philosophers. Additionally, I'd say that there can be efficacy in not acting, as there can be in acting. Political action is, first of all, strategy. Tactics comes in a distant second place. 

The short answer is that pure mathematics has to be free from empirical determinations of any kind (not just physical, but also psychological) to be what it is. In other words, knowledge becomes essentially mathematical when it can be considered neutral in its relationship with experience of any kind. Three observations arise from this preliminary point: 1) Mathematicians themselves live in the world of experience (and so will any kind of concrete mind that thinks mathematically), and that is why this desirable "purity" of any mathematical object is, in practice, a process, not something that can have a referent in the world. That can be said, regardless of metaphysical considerations - for instance, if mathematical objects exist or not (which is a big philosophical problem, check this out: $URL$ 2) The connections between mathematical knowledge and its "applications" in natural science is not trivial, at all. Your could even say that, whenever they are spotted for the first time, these connections normally appear surprising, uncanny, even overwhelming, for both sides. Physical science can be about nature, but it is not itself "natural". When science changes the way we see the world, it changes the world, and itself. So my answer to your nuclear question is that the patterns that mathematicians formulate are thinkable, and the patterns that empirical scientists identify are evident. Whatever happens between these two stances is game, and the game of science is not made of trees and branches, it is whatever scientists do. It may very well be that one day knowledge will no longer be so easily departmentalized. Many authors have discussed this trend, and I won't try to be encyclopedic here, so let me just suggest this reading (Isabelle Stengers): $URL$ 3) In the end, the utility of knowledge is in the eye of the beholder. 

The substance of the computational machine; The computational machine's hardware, its organization; The computation that it is running, its "performance", which is what is (or is not) amenable to identification. 

The "creative" ability of a cellular automaton is not different in nature from that of any other computational device, in that what it produces is entirely enveloped (causally determined) by its initial state, and its transition rules. What may be interesting here, is that the behavior of the automaton cannot be determined in advance by an external observer, using a general method. The problem, therefore, is not metaphysical, but epistemological. In other words, it is not a problem of determining where did those patterns came from, but how to deal with the fact that it is impossible to know what is going to happen (with the exception of a minority of trivial examples) without analyzing each individual automaton, on its own, as a singular problem. Someone could say for that matter (and in a very materialistic way) that each one of them has a mind of its own. Have your heard of Stephen Wolfram's famous book, "A New Kind of Science"? If you didn't, I think you'll find it mind blowing. 

Reason (rationality) is one of the archetypal philosophical problems. When sciences adopt a term so overloaded, it is not by accident. Scientific hypotheses are usually formulated over a dogmatic background. When scientists borrow a philosophical term, they are actually taking a stand, justified by desirable ethical/practical implications, and this is especially true in the humanities. In other words, they are choosing a specific philosophical approach (materialism, empiricism, idealism,...), and pragmatically converting it into doctrine. There's nothing wrong with that, it's part of the game. Science needs to move fast, and travel light. Philosophers may have quarrels and narcissistic tendencies, but they usually do not expect to reach some form of perfect agreement about the definition of concepts. "Unification" is not exactly a philosophical project, which is why I wouldn't hold my breath waiting for it to happen any time soon. Your concern may come from the fact that many scientific doctrines that are based on some notion of individual rational behavior happen to be in critical condition nowadays. Not just psychology and economics, but also sociology, political science and law studies, among others. It is probably a good moment for the practitioners in these fields to return to philosophy for inspiration - and I believe this is happening. 

I'll give you the standard, schematic answer, but be aware that this question opens a Pandora's box. Irrational numbers are those that cannot be indicated by a fraction of two integers. Because it is a negative definition, it can be a bit misleading, and unhelpful. See, all numbers that are not rational have to be... irrational. There is, however, an "outer circle", a set of numbers that aren't rational, but that can be positively defined as those that are the solution of some algebraic equation. These are called the algebraic numbers. The next circle outside is the set of computable numbers. These are, roughly speaking, the numbers that can be approximated to an arbitrary precision by a finite calculation process. Numbers that are not algebraic are called transcendental. Most of these numbers are also not computable. Another negative definition, as you can see. There are (and probably will always be) more things that we do not know about these numbers than things that we do know, so if you are perplexed by them, you are in good company. 

Consider that a programming language - as they are used today - is a language that has an operational semantics, and that a natural language is a language with which, say, you could set up the Turing test. You see where this is going: the possibility of using them interchangeably would be a concrete refutation of the Turing test. That said, it is Pierre Lévy's contention that it is possible to create a language with which you could express both meaning and computation (which is a different thing than using it for those two purposes interchangeably, or simultaneously). If successful, it could be a game changer - and it is intended that way, actually. A more fundamental concern is that the term "language" in "programming language" has a very strict connotation that is almost completely unrelated to the phenomenon that linguists study. Also, the term "natural" in "natural language" is philosophically problematic, far from consensual. It can easily be defended that human language, in its manifestation, is entirely artificial. 

I would add that the level of formality is not related to the usage of symbols, or abbreviations - in other words, to the way things are "encoded" and/or expressed - but to what is missing in the conventional mathematical text, and missing on purpose, as much as possible: metaphors, non-technical explanations, merely evocative commentary. There are at least two issues at stake in the way this conduct has been incorporated in the tradition of mathematical work: 1) First of all, it manifests the position that mathematical definitions and proofs are not made more cryptic than they could be, in the absence of these non-formal "appendages". The thing here is to try to understand, not only what is written, but why it has been written, namely, to convey a kind of knowledge that is (supposed to be), at least originally, immune to practical implications or worldly agendas. This is, of course, highly debatable. 2) There are usually, nonetheless, non-formal paths towards the understanding of a new mathematical object or problem, even for the initiated. That these paths are rarely, if at all, documented in any way, can be considered a problem for a field that remains extremely elitist, at a time when science desperately needs to be able to communicate better with the general public. There is, of course, remedy for that. 

These "strategies", so to speak, are not to be taken as a rhetorical devices. Their efficacy, as is usual in the philosophical debate, relies on a predisposition to mutual understanding. 

I am going to interpret your question in broader terms, as an phenomenological argument about the observability of a computational machine's behavior/functioning, insofar as cognitive abilities can be identified and attributed to it. As you can imagine (and I think you have) this discussion is extremely rich and vast, and I do not expect to be able to go much beyond the surface here, but I think that some methodological pointers can be proposed in this short format, that may be useful for future reference. First of all, let's assume that the problem of identification, in that specific scenario, assumes that there are at least three instances at play (I'm being overly schematic here, but bear with me, it's just an exercise): 

The presence of quantified probabilities in your question indicates to me that you are asking if this problem can (or cannot) be converted in the computation of a utility function. In the end, you point out a possible exception to this approach: the presence of a singularity: whether the girl is the person's daughter, considered as a unique individual, not as the member of a genus. An ethical dillema can stay unresolved in both cases. A utility function is just one of many possible candidates, and even if you come to decide for a particular one, it can easily be too hard to compute, or even impossible (undecidable). A singularity can move you towards some kind of response, but this is not the same as moral judgement, in that it doesn't relieve you of the responsability to decide (to judge) what is your standing, considering what happened, even if you had no part in the actual event. Philosophical theories of moral judgement begin by assuming that genuine moral dillemas stand on their own feet as phenomena, in that they are not reducible to what can be coded as law, or attributed to chance. Will these theories necessarilly lead us to metaphysical considerations? Well, that's another question. 

That conscience is a phenomenon, and not a concept (or even a construct, a fiction of sorts), is already a philosophical position. A host of thinkers have distanced themselves from it. I'm actually having trouble remembering one that doesn't, at least partially (help me in the comments if you do). Another thing entirely is to talk about having experiences. Here, the key difference to be made is if you take computers to be artificial, just because their hardware was assembled, not "grown". That is why many people are uncomfortable with the "artificial" in Artificial Intelligence. The thing is, you don't have to "solve" the nature vs. artifice problem to assume that experience is possible in non-conventional settings. In fact, what you may be forced to do, when thinking about these things, is to leave the problem open. 

Even if your line of argument does not implicate universal doubt - only the doubt that comes from the absence of immediate evidence from the senses - it is a form of skepticism that can easily lead us to discredit even the "certainties" that come from direct testimony: How can you be sure of having counted those eight bars correctly? And those other three on the left side, did you actually count them, or just subitized? Aren't your perceptual certainties also subjective, in the end? A result of insistence, mere beliefs? They certainly are beliefs too, even if that is not all what they are. The starting point of knowledge - of science - for Peirce, is the inevitability of hypothetical thinking. Any mind is a factory of hypotheses, unproved assertions, first guesses. This is the ground zero, not doubt. How we respond to the hypotheses we are condemned to make, that's where the problem of method begins. 

My answer to your very rich and complex question is that religious freedom is not given, it is historically constructed, and in singular ways. There are countries on which it is relatively easy for people to be unaffiliated to any religious denomination, and to publicly manifest themselves this way. This is a distinct feature of modern cultures, where the effective separation of state and religious traditions has been institutionalized, and republican traditions are strong. In some others, what happens is that the dominant religion has become more and more tolerant towards how its members treat their private life, and mitigated in the ways it disciplines public conduct, creating what can be viewed as de facto religious freedom. Historically, this has been more frequently the result of the ascension to power of empires that dominates over large regions, constituting multinational and/or multiethnical societies. These two situations are not the necessary outcome of a deterministic process. Social and political expressions of religion are very dynamic. In a broad sense, and as far as we know, religion is a strong human impulse, pervasive in all cultures and times. Although we can all lean towards the defense of religious freedom as an ethical proposition, is it possible to have a society where religious practice is never strongly binding, and where to be or not affiliate is always a decision taken lightly and playfully? Is it desirable? The jury is out on these, and other questions. The debate continues. 

It is already hard to interpret Nietzche's prose when translated from the German language, let alone when reading just isolated excerpts, so I am assuming you read (or intend to read) the entire "Genealogy of morality", not just the fragments where this image is used (1-11 and 2-17). It has been argued that the author does not imply a particular race of humans, but refers to the emergence of a primitive disposition for dominance of the majority by a minority inside a group of humans, recurrent in history (see, for instance, this). Be careful to realize that his main target, particularly in the second essay, is what he calls bad conscience, a precursor of nihilism, the "will to nothingness" of the civilized man. In that respect, the "blond beast" is not spared of Nietzche's harsh criticism. Look at how 2-17 ends: 

There are different ways in which beliefs are fixated (I'm coming from Charles Sanders Peirce's "The fixation of belief", here). It can be argued that the scientific method conveys the most stable and robust of these ways, but this doesn't imply necessarily that this is how it should be, or that we won't come up with some other process that is even more stable, in the future. Beliefs are events, things that happen in the world. They are not just propositions. 

I'll divide my own answer in three sections. What is it to be "human" (what is it to be "somebody") is obviously a philosophical question, but it is first of all a question that has an existential urgence for any living being whose mind finds itself entangled in self-referential thoughts that they can't control. This is a quality that can, in principle, be artificially (as in technically, by virtue of τέχνη) produced in a physical body. The success of such project has to do with technological sophistication, but mostly with philosophical creativity, as was the case with the invention of the computer. Of course, to talk about it now, as if something so distant from our current experience had already been acomplished, can only be a hypothetical exercise. The question could be reframed by assuming that, in a way, all sentient minds are by necessity "artificial", in that they are accidents, or singularities, not belonging to any natural genus by virtue of that quality. The awareness - or lack thereof - of this frail condition would be the predisposing condition of disease ("dis-ease"). In that sense, disease is the normal human condition, as has already been defended by many, if not most, philosophers. I'll tentatively postulate here that a greater awareness predisposes to depression; smaller or absent, to psychosis; inadequate understanding, to neurosis; misplaced, to sociopathy. Inevitably, the distribution of mental disease in a human population is a historical process. As with any complex system, it is extremely sensible to initial conditions. Local equilibria can be reached, but in the grand scheme of things, these are bound to be ephemeral. We may be living one of those moments of great instability. The concept of an "artificial" intelligence (as the one of an "extraterrestrial" intelligence) could be read as an attempt to normalize what is foreign to our present equilibrium. A futile attempt, if you ask me.