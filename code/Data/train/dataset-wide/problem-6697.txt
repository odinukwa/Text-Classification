The Cardinal Vowel chart is a rough, impressionistic tool. Nobody is claiming that it is a precise measurement of the quality of a vowel but rather that it is "good enough" for the purposes of recording and conveying an impression of the approximate quality of a vowel. Although it is true that as far as normal, spontaneous speech processing is concerned, listeners may be desensitised to subtle variations in vowel quality around the targets of phonemes in their native language(s), this doesn't necessarily preclude that with training, phoneticians can still judge the quality of vowels precisely enough for the purposes of the Cardinal Vowel chart. The CV chart isn't very well suited to studies relying on precise measurements of vowel quality. For such studies, it is more common nowadays to take an approach similar to that outlined by JoFrhwld, in which vowels (or indeed, continuants in general) are analysed for their formant frequencies. With some judicious mathematical jiggery-pokery, you can just about contort formant frequency measurements into something resembling a CV chart. But there's not always much motivation for doing so: once you're analysing in terms of measured formant frequencies rather than impressionistically, you may as well just plot those measurements on some graph or other, even if it doesn't quite look like a CV chart. So the bottom line is: if you are asking "how do I find the precise position of a vowel on the CV chart?", that's probably an indication that the CV chart isn't suitable for your purposes. 

It works best and is most common for first person pronouns, either singular or plural. If a third person pronoun is omitted, it usually implies neuter, i.e. es and neither er (m) nor sie (f). Interestingly, it’s not only used if the inflected verb is unambiguous on its own, e.g. ich bin, du bist, es ist; wir sind, ihr seid, sie sind. However, elision may be suppressed if it would create ambiguity, e.g. not *geh’ nachhause which would be equal to the imperative, although ich geh’ nachhause is pretty much standard now. Second person pronouns are only omitted in questions, but more often they’re just shortened, becoming a verbal enclitic: 

Following the first Greek grammars or even older sources, there is a traditional and apparently arbitrary order used for cases in most if not all living European languages, e.g. in declension tables. It often starts like this (NGDA): 

In modern language teaching, it seems to become more common to group the cases by morphologic similarity to aid memorization. This results in NADG instead of NGDA for German. I’ve seen NAGD for Old English, though. Latin should probably use NVABDG, Russian maybe NAGPDI because Acc forms agree with either Nom or Gen depending on animacy. How much does similarity of case morphemes differ by language? Is there a logical canonical order of (nominal) cases across (Indo-)European languages? 

It appears to be a word in a Siouan language, though Chattaroy, WA was not founded until the early 1880's. 

Older shorthands included the Tironian notes (notae tironianae), Greek tachygraphy (of which not much is known), and various forms of scribal notation (although these were usually purely phonetic in nature). Remnants of these can be found in modern European languages, e.g. and. Finally, there is the Moon System of embossed letters for the blind. In addition to symbols for the English letters, it includes signs for: 

This, generally speaking, corresponds to the fields of text mining, entity extraction, and automated (meta)data extraction. It's not part of linguistics per se; it's more applied linguistics with relations to information science and library science. It's an enormously important field right now: consider, for example, the Google Books project. Google needs to be able to mine through thousands of scanned books to extract author, publisher, title, date, etc. so that it can create metadata to index the books with. They don't solely use text mining to do this, but it is one of the methods. I don't know if these methods are good enough to find genre, characters, etc., but it's a similar idea. If you're looking for software, I suggest starting with the list of FOSS Information Extraction tools found in Wikipedia as a starting point. 

A partial answer to this is that it will probably depend on how native-like the speaker's pronunciation of other parts of the utterance are. So taking a very simplistic example with your two French vowels as an example, the words "clé" and "craie", in addition to having "l" vs "r", generally differ in that the final vowel is /e/ and /ɛ/ respectively. So if a speaker does not differentiate /e/ and /ɛ/, this puts more 'pressure' on the /l/ vs /r/ distinction to differentiate these two words. (N.B. it turns out that /e/~/ɛ/ are actually in free variation much of the time in French and pronunciation of either is highly subject to effects of assimilation or "vowel harmony", so this pair isn't necessarily the most compelling example.) Extending this isolated example out to many different phonemes in a more complex utterance, and you'll see that the situation quickly becomes very complex. Listeners are expecting all sorts of phonetic cues to decipher what they hear, and if you eliminate one particular cue in a specific place it's difficult to predict exactly what pressure this will put on which cues elsewhere. You would also need to think about what exactly you mean by two phonemes being "similar". If you mean specifically vowel quality, what other features of the phoneme (e.g. duration patterns, propensity to assimilation, phonotactics) are you then disregarding and does the cost-benefit ratio actually work in favour of your assumption? For example, maybe speakers have difficulty in distinguishing the quality of English /I/ vs /i/. But maybe they can easily pronounce these vowels with different durations and that it is primarily the duration that is perceptually important. (cf Tajima et al, 1997, "Effects of temporal correction on intelligibility of foreign-accented English: they found that by re-synthesising foreign accented speech to correct specifically the timings of segments, this apparently improved intelligibility even though vowel quality may been quite 'far off the mark' in some cases). In that case, you have thrown out a priori a distinction that speakers could potentially have made quite easily because your system decided that it was "too difficult to be worth making". Or, to put it more succinctly: what you're proposing doesn't sound as though it will achieve its objectives. 

Kiswahili might be a candidate. There are a few different verbs that correspond to English 'to be'; kuwa 'be, become' is regarded as the main equivalent as far as "existence". It is also used for "to have" in conjunction with na (i.e., kuwa na='to be with"='to have") And also, Kiswahili has a negative conjungation, so 'to not be' and 'to be' are different conjugations. So exact equivalency, as noted above, is tough. But to the point here: for kuwa the "exist" verb, the present tense forms are identically ni in the modern language; and for the other tenses the forms are regularly conjugated off the root -wa. I am ni You are ni He/she/it is ni We are ni You are ni They are ni I was nilikuwa You were ulikuwa He/she/it was alikuwa We are tulikuwa You are mlikuwa They are walikuwa I will be nitakuwa You will be utakuwa He/she/it will be atakuwa We will be tutakuwa You will be mtakuwa They will be watakuwa However I am not an expert in Swahili so it may be that I am missing some suppletive form in a strange tense or something. EDIT: See also this nice handout. 

What is the linguistic terminus technicus for this phenomenon? I’m looking for one that is more specific than ellipsis. 

In informal German, e.g. spoken conversation or text chat, it is possible to omit certain personal pronouns and sometimes inflected forms of sein ‘to be’, too (similar to Russian). 

There are quite a few examples, even within the roman script. The OpenType font standard has a feature tag for this very purpose: . There is also diachronic variance, hence . The most prominent examples are not the base letters, though, but diacritic marks. The French accent acute is flatter than the Polish kreska, for instance, though coded the same. On the other end, there is no proper justification by way of a minimal pair to treat cedilla, ogonek and comma below as separate diacritics. A written language that has only one kind of diacritic, say German umlaut double dots, will allow much stylistic variation thereof (e.g. look like macron, tilde, double acute etc.) which would be different letters in other languages, say Hungarian. 

All Romance languages have some historical traces of ablaut. For example from Spanish: hacer: infinitive with /a/ hice : preterite with /i/ hecho : past participle with /e/ French faire: infinitive with /ɛ/ fis : preterite (passe simple) with /i/ fait : past participle with /ɛ/ Portuguese fazer: infinitive with /a/ fiz : preterite with /i/ feito : past participle with /ej/ Romanian a face: infinitive with /a/ făcui : preterite with /ɨ/ făcut : past participle with /ɨ/ Italian fare: infinitive with /a/ feci : preterite (passato remoto) with /e/ fatto : past participle with /a/ However this now acts like root suppletion and is not productive with new words. Occitan and Catalan have productive vowel-altering processes sometimes called ablaut, but they are not derived from PIE ablaut and are not grammaticalized. 

Here are a couple papers that may help illustrate the point. Kerswil, in "Children, Adolescents, and Language Change", directly and extensively tackles your question of whether linguistic innovation comes from the speech of children. (He does restrict his study to language change resulting from language contact.) His findings are basically that different age groups are responsible for different types of language change in accordance with the usual order of language acquisition, which he gives as: