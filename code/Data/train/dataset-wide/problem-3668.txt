is it possible that something in custom_require.rb is being called relatively, but since you are running from rc.local there is no defined (or at least not properly defined) $PATH, versus when you log in bash (or whatever shell) sets your path and then it runs fine? 

Adding the following registry entry solved the issue: HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\MSExchangeIS\ParametersSystem\InternetContent\MimeHandlers{85D2DDB8-6225-11D2-BDF1-00C04FD655B5} FixRecipientTrackStatusTime DWORD 1 I rebooted it after making this change, though the KB article does not indicate this is necessary. I have no idea if this was required or not - the machine needed it outside of this change. From: $URL$ 

Not clear from your question, but i think what you want is called multihoming. its trivial in linux. never tried it in windows, but it cant be that difficult. $URL$ Linux (from the wiki article): $URL$ Windows (again, from the wiki article): $URL$ 

Is there a way to change the block/cluster size when formatting a disk using unattend.xml & Windows Deployment Services? It keeps defaulting to 1024k, and I need something smaller. 

OpenVPN does some odd stuff with routing (as compared to other VPN solutions) - the connection the clients get is on a /30 network for each individual client for easier compatability with windows, so thats why youre seeing the 252 netmask. you can change this behavior if all your clients use linux. does that cisco router know about these routes, and whats the default route for all the boxes on the internal network? i had a similar issue where our core router was getting all the traffic and then dropping it because a) it was non-routable addresses and b) it didnt know what the proper route was. what i suspect you need to do is create a static route for this whole 10.10.11.0/24 subnet in your cisco router with the gateway as the 192.168.1.X address of the openvpn server. ensure packet forwarding (ie routing) is enabled in the openvpn box, and you should be good. TL;DR: Routing requires definition in both directions (either static or dynamic), and it sounds like you need to add a route to your cisco box telling it where to find 10.10.11.0/24 

It may depend on how your application works - if it uses absolute URIs in places, and those point to something that users behind the proxy cant get to - that may be your problem. Say you have proxy P, server S, and the user. the server has a given hostname (possibly more) and one of those is probably associated with the webserver (lets call it server1). Users may or may not be able to make requests directly to server1. In all likelihood, with a reverse proxy, they have to make requests to the proxy, and that in turn queries your server. They see $URL$ - while the app actually lives at $URL$ (or some other arbitrary path). If your app is configured in such a way as to make direct reference to $URL$ and the proxy doesnt pick up on that and modify the code that gets sent to the user to so that it directs to $URL$ it will break functionality. Kind of a stab in the dark here, but i ran into a similar issue with Sharepoint. 

why not just give those hostnames a bogus IP (either via CNAME or A) in DNS rather than dropping the packets. seems like it would be less of a load on your firewall (and fewer rules). 

Maybe the line-ending conversions in vsftpd were written inefficiently, and since binary mode is most commonly used, no one has bothered to improve the algorithm used in vsftpd. Or, it could just be that passing data from a tcp socket out to disk really is a lot faster than having to check every character for CR and LF. The check could introduce enough latency in the connection to reduce your transfer speed. Are you running tests locally on Ethernet (low latency, would be affected greatly by additional latency) or across the Internet? 

For one-shot deals, scp is handy. If it's a lot of files, then rsync is a good idea. If a connection is dropped, rsync can pick up where it left off. I knew that rsync had compression (), and have just learned that scp does as well (). 

Two weeks ago, I was notified by my VPS provider that my server (CentOS 5.5, yum is up to date) had originated "NULL byte/Directory Traversal" attacks agains some servers at DreamHost. I spent a few hours going over the server with a fine toothed comb and didn't find anything. Before logging in, I retrieved a copy of the sshd binary and confirmed that it hadn't been modified. I installed a rootkit checker (chkrootkit-0.49) that found nothing. I checked the web logs of the websites I host, looking for a hit that may have triggered a script on my server to initiate the attacks but found nothing. Checked /var/log/secure and /var/log/messages around the times of the attack but found nothing. Checked , but found nothing. Did a on key directories looking for files modified in the past 3 days, but nothing. What else can I do to to find the cause of the attacks? I wrote a script to check for outbound TCP connections on port 80, but only came up with legitimate connections (SpamAssassin and ClamAV downloading updates, Joomla checking its site for updates, etc.). Even if I did see an active outbound connection, would I even be able to dump data from the process (in the directory) to show me the account originating the attack? After watching the server for a few days, I gave up. Now I've received another complaint from DreamHost, so it's happened again. I've requested detailed logs from DreamHost, but then what? Where else can I look? If I can't find the source, is there something I can install to monitor the server and log data when it starts making outbound connections to tcp/80 in the DreamHost IP space? What would I log? Just get a of all traffic in that timeframe and try to sift through it manually? Update See my accepted answer for the solution I came up with. I'm still interested in options for logging the source of all outbound port 80 traffic -- a way to know what the source process is and perhaps its parent process (and the parent's parent). 

CentOS 6.2, bind 9.7.3, rsyslog 4.6.2 I recently set up a server, and I noticed that named had stopped logging to after the logs had rotated. I thought that was odd, since all logging happens through and doesn't write directly to the log file. It was even more odd because I had HUPed after updating a zone file, and it still wasn't logging. After I stopped and restarted named, logging resumed. What's going on here? The syslog PID hasn't changed (/var/run/syslogd.pid matches the PID shown in ps). Is rsyslog opening a new socket when logrotate rotates its logs and HUPs it? /etc/logrotate.d/syslog: 

I need to delegate permissions to edit user information (phone numbers, address, etc) in AD. Its a 2003 domain. Ive already delegated: 'Read all user information' and 'Read, Write, Read and write general information, Read and write phone and mail options, read and write public information, read and write personal information. So far none of these have helped the specific user edit details. Its been logged off and back on already too. What am i missing? 

We recently had a full power outage and had to shut down basically all devices in the server room. Being a smaller org, we still have some very small business practices im working to change over time, like having a bunch of external disks in production use. In this case, all those disks needed to be powered down, but some of them were connected to the primary rack PDUs and had to be unplugged manually, and then replugged later. What would have been very nice would be to have some/most of these types of devices on their on plugstrip for easy control. Does anyone know of plugstrips (bonus points for ones that do a good job managing wallwarts) that have covered switches, to prevent accidental switching? 

why on earth would you have a router using DHCP for addressing? the frequency will depend on the lease its already obtained from the DHCP server. powercycling should also force it to recheck, as will configuring the interface statically and then switching back to DHCP. 

Reading over (and then testing out on a test database) the setup for mirroring it appears that one is supposed to leave the mirror database in restoration mode for normal operations. is this correct? at whatever point it becomes necessary to initiate the failover (im not using a witness), will the primary database be put into restoration mode? this seems goofy. 

both produce: Set-CDDrive Operation is not valid due to the current state of the object What state might that be? Is set-cddrive dependent on either CusomizeVM_Task or ReconfigVM_Task? The kicker here is that the operation appears to succeed, even though it returns an error. Edit: error has now changed to "ide0:0 already exists" without any changes to scripting. Found this KB, indicating it might be a bug: $URL$ 

the power suspicion seems most likely - how big is your power supply, and what exactly do you have connected at this point? 

Windows can be configured to not show UAC prompts, but i believe thats a system wide config (ie youd see the same thing at the console as you would over RDP). They can definitely show up though, so it sounds like your servers have some configuration differences. heres a technet article about the various keys: $URL$ 

Im trying to get some users printing from a remote citrix server at another company. It seems as though they require local administrator privileges to do so, however Ive been instructed not to give them that. They can print normally from their desktop without issue. Is there some special permission to allow citrix to print through to local/network printers short of granting local admin to these users? 

So the short answer is that the temp directory for those users was set to something it shouldnt have been.