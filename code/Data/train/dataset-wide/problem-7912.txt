The only known finite projective plane with a transitive automorphism group is the Desarguesian plane $PG(2,q)$ and it seems likely that there are no others, although this is not (quite) proved. However all the papers that I have seen dealing with this problem or variants of this problem say things like "It is a longstanding conjecture that a transitive projective plane is Desarguesian" or "It has been conjectured that ..." and none of them actually say who made the original conjecture. I've looked in Kantor's papers on flag-transitive planes, Dembowski's book on Finite Geometries, Ostrom and Wagner's paper proving that planes with doubly transitive groups are Desarguesian and Higman and McLaughlin's paper on ABA groups. So is the conjecture folklore? Or can anybody point me to an explicit reference? EDIT: Question has been up for a few days without answer so I'm giving up and assigning the result to "folklore". In the meantime, I've written a blog post about it for posterity: $URL$ 

Homomorphisms into Kneser graphs are another way of describing fractional colourings; an introduction to how this all works is the topic of one of the chapters in my favourite book on Algebraic Graph Theory. There are other much more detailed references on fractional colourings, but not necessarily from the homomorphism viewpoint. But just as there is no useful "characterization" of, say, graphs with 3-colourings (unless P=NP) there is no characterization of graphs with a given fractional chromatic number (except for a few trivial cases). 

In a paper that I am currently writing, we have an individually-authored appendix, although the author of the appendix is also a co-author on the paper. In this situation, the appendix is a relatively long and technical proof of a fact that is used peripherally in the paper. The proof is not sufficiently important to the main thrust of the paper to be incorporated into the body of the paper, and the major results of the paper do not rely on it. However it provides an explanation for some of the phenomena we describe (and prove) in the paper. Although this self-contained fact is not proved in the literature, it is probably not enough to make a separate paper without the context and motivation provided by the rest of the paper. As it is solely my coauthor's work it makes sense to include it separately with only his name attached. I imagine that the same applies to an appendix with a separate author not among the main authors - a piece of work that is self-contained, of sufficient scale and scope that it warrants separate authorship, and yet whose significance is greatly enhanced by the motivation, context and results of the main paper. 

I am not a matrix theorist, or numerical linear algebra expert, but I have a problem and my proposed solution leads me to a question that I cannot answer. I can give more details, but the gist is that I have a matrix $A$ which depends (smoothly) on a variable $x$. For a nice value of $x$, call it $x_0$, I can symbolically compute lots (but not all) about $A$ and its eigenstructure. In particular, I can find its leading eigenvalue $\lambda$, the corresponding eigenvector $v$, and I also know the derivative $K$ of the leading eigenvalue wrt $x$. I want to know what happens when $x_0$ is perturbed to $x_0 + \epsilon$ where I don't care how small $\epsilon$ is. In particular, I want to know how the entries in the leading eigenvector change (relative to each other). So what I want to do is to express everything as series expansions, truncated at the linear term, in $\epsilon$, so I will have 

Here is an example for you to enjoy. Take two disjoint copies of $K_{2,3}$, and form a cubic graph on 10 vertices by joining each of the three vertices of degree 2 in one copy to one of the vertices of degree 2 in the second copy. Here is Sage's picture of this graph. 

I also conclude that the unique $18$-vertex graph with maximum Cheeger constant is the Pappus graph. I can't actually remember why I calculated these numbers, but obviously whatever it was for did not lead to anything, and I haven't seen anything in the literature about Cheeger numbers of cubic graphs in particular. There are a few papers about isoperimetric numbers of families of graphs, but I am sure you can Google them as well as I can. ADDED: There are 11 cubic graphs on 20 vertices with the same extremal Cheeger constant as the Pappus graph. I expect that they are all minor perturbations of the Pappus graph, but do not know for sure. 

You've probably done this already, but here are the exact numbers obtained just by counting the 4-colourings over all plane triangulations: each line gives $m_1$, $m_2$, $m_3$, $m_4$ 9 regions: 21, 16, 12, 9 10 regions: 44, 28, 21, 20 11 regions: 85, 48, 44, 41 12 regions: 172, 92, 85, 84 13 regions: 341, 176, 172, 169 14 regions: 684, 348, 341, 340 15 regions: 1365, 688, 684, 681 All of these values are uniquely realised, and all fit your formulas. I would be reasonably confident that this is not known to this level of precision. On the other hand, most people who have thought about this would quickly arrive at the conclusion that the biwheel (the dual of your picture) is the one with the maximum number of vertex 4-colourings. 

Yes, here are some Graph 1, order 17. 0 : 5 8 12 13; 1 : 6 9 13 16; 2 : 7 10 13 15; 3 : 8 9 14 15; 4 : 9 10 11 12; 5 : 0 11 15 16; 6 : 1 10 14 16; 7 : 2 11 13 14; 8 : 0 3 12 14; 9 : 1 3 4 15; 10 : 2 4 6 12; 11 : 4 5 7 16; 12 : 0 4 8 10; 13 : 0 1 2 7; 14 : 3 6 7 8; 15 : 2 3 5 9; 16 : 1 5 6 11; Graph 2, order 17. 0 : 5 8 14 15; 1 : 6 9 15 16; 2 : 7 11 13 16; 3 : 8 9 10 13; 4 : 9 11 12 14; 5 : 0 10 11 15; 6 : 1 10 12 16; 7 : 2 12 13 15; 8 : 0 3 14 16; 9 : 1 3 4 15; 10 : 3 5 6 13; 11 : 2 4 5 16; 12 : 4 6 7 14; 13 : 2 3 7 10; 14 : 0 4 8 12; 15 : 0 1 5 7 9; 16 : 1 2 6 8 11; Graph 3, order 17. 0 : 5 7 11 13; 1 : 6 8 13 15; 2 : 7 9 10 15; 3 : 8 10 14 16; 4 : 9 11 12 14; 5 : 0 11 15 16; 6 : 1 12 13 16; 7 : 0 2 10 13; 8 : 1 3 14 15; 9 : 2 4 12 15; 10 : 2 3 7 16; 11 : 0 4 5 14; 12 : 4 6 9 16; 13 : 0 1 6 7; 14 : 3 4 8 11; 15 : 1 2 5 8 9; 16 : 3 5 6 10 12; Graph 4, order 17. 0 : 5 7 14 16; 1 : 6 8 12 13; 2 : 7 9 10 12; 3 : 8 10 11 15; 4 : 9 11 13 14; 5 : 0 13 15 16; 6 : 1 11 12 16; 7 : 0 2 10 14; 8 : 1 3 14 15; 9 : 2 4 12 15; 10 : 2 3 7 13; 11 : 3 4 6 16; 12 : 1 2 6 9; 13 : 1 4 5 10; 14 : 0 4 7 8; 15 : 3 5 8 9; 16 : 0 5 6 11; Graph 5, order 17. 0 : 5 7 11 13; 1 : 6 8 12 15; 2 : 7 9 10 15; 3 : 8 10 14 16; 4 : 9 12 13 16; 5 : 0 11 15 16; 6 : 1 11 12 14; 7 : 0 2 10 13; 8 : 1 3 13 15; 9 : 2 4 14 15; 10 : 2 3 7 16; 11 : 0 5 6 14; 12 : 1 4 6 16; 13 : 0 4 7 8; 14 : 3 6 9 11; 15 : 1 2 5 8 9; 16 : 3 4 5 10 12; Graph 6, order 17. 0 : 5 7 12 13; 1 : 6 10 13 16; 2 : 7 8 14 15; 3 : 8 9 10 12; 4 : 9 11 13 14; 5 : 0 10 11 15; 6 : 1 12 15 16; 7 : 0 2 14 16; 8 : 2 3 11 12; 9 : 3 4 13 15; 10 : 1 3 5 14; 11 : 4 5 8 16; 12 : 0 3 6 8; 13 : 0 1 4 9; 14 : 2 4 7 10; 15 : 2 5 6 9; 16 : 1 6 7 11; Graph 7, order 17. 0 : 5 7 11 14; 1 : 6 11 13 15; 2 : 7 8 12 13; 3 : 8 9 14 15; 4 : 9 10 11 12; 5 : 0 10 13 16; 6 : 1 12 14 16; 7 : 0 2 12 15; 8 : 2 3 11 16; 9 : 3 4 13 14; 10 : 4 5 15 16; 11 : 0 1 4 8; 12 : 2 4 6 7; 13 : 1 2 5 9; 14 : 0 3 6 9; 15 : 1 3 7 10; 16 : 5 6 8 10; Graph 8, order 17. 0 : 5 7 13 14; 1 : 6 11 13 15; 2 : 7 8 10 12; 3 : 8 9 15 16; 4 : 9 10 11 14; 5 : 0 11 12 16; 6 : 1 12 14 15; 7 : 0 2 10 13; 8 : 2 3 14 16; 9 : 3 4 12 13; 10 : 2 4 7 15; 11 : 1 4 5 16; 12 : 2 5 6 9; 13 : 0 1 7 9; 14 : 0 4 6 8; 15 : 1 3 6 10; 16 : 3 5 8 11; 

Maybe I'll summarise everything from the comments as an answer. Firstly, a perfect matching $M$ of $K_{n,n}$ can be identified with a permutation of the set $[n] = \{1,\ldots,n\}$ simply by numbering each side of the bipartition with $[n]$ and letting $\sigma$ be such that $(i,\sigma(i))$ is an edge of $M$. Therefore $K_{n,n}$ has exactly $n!$ perfect matchings. It is not immediately clear to me as to whether there is anything gained by thinking of perfect matchings as opposed to just thinking of permutations. Now move on to disjoint perfect matchings. Two perfect matchings, viewed as permutations $\sigma$, $\tau$ will be disjoint if and only if $\sigma^{-1} \tau$ has no fixed points and therefore is a derangement. If we simply label things so that $\sigma$ is the identity, then $\tau$ will be disjoint from it if and only if it itself is a derangement. Luckily we know the number of derangements, as it is the closest integer to $n!/e$, so we can count the number of disjoint pairs of perfect matchings. Now we want to add a third perfect matching, disjoint from both. We can write down everything so far in an array, where each row is a permutation written in image format (in other words, just a list $\sigma(1)$, $\sigma(2)$, $\sigma(3)$, etc). So the first row can be the identity, just $1$, $2$, $3$, $\ldots$, $n$ and then the second row will be a derangement, and thus no column of the $2 \times n$ array we have constructed will have a repeated symbol. Adding a third perfect matching disjoint from the two first is precisely equivalent to adding another row to the array such that none of the columns of this $3 \times n$ array have repeated symbols. This can be continued, until after $d$ pairwise disjoint perfect matchings, we have built a $d \times n$ Latin Rectangle. Simple counting shows that $d \leq n$ because by the time the $n \times n$ Latin square has been constructed every edge lies in a unique perfect matching already accounted for, so there are no more edges. Counting Latin squares is a well-known very difficult problem, and there is no simple counting technique or formula that can accomplish this. 

So this suggests that around $10\%$ of the cubic bipartite graphs on $40$ vertices will have the right determinant, leaving me with something like $7 \times 10^{11}$ graphs, probably a bit more. My question is really whether I can do better than this? Are there known counting results and/or determinant results that I can use to improve my two estimates? Added in response to Brendan If the matrices have order $3k \times 3k$, then the determinant must be a multiple of $9$, hence none of $\pm 3$, $\pm 6$. To see, suppose that $A$ is such a matrix. Use elementary row operations to add rows $2$, $3$, $\ldots$, $3k$ to row 1. The top row is now all-$3$s, but the determinant is unchanged. Repeat the process with columns. Now we have a matrix where the $(1,1)$-entry is $9k$ and all the other entries in the first row and column are equal to $3$. Consider now each transversal of the matrix, and the contribution to the determinant made by the product of the entries picked out by the transversal. If the transversal uses the $(1,1)$-entry then it automatically contributes some multiple of $9$, while if it doesn't then it must use the $(i,1)$ and $(1,j)$ entries for some $i$, $j \ne 1$ and as each of those values is equal to $3$, contribution is also a multiple of $9$. 

The Robertson-Seymour theorem on graph minors leads to some interesting conundrums. The theorem states that any minor-closed class of graphs can be described by a finite number of excluded minors. As testing for the presence of any given minor can be done in cubic time (albeit with astronomical constants) this implies that there exists a polynomial time algorithm for testing membership in any minor-closed class of graphs. Hence it seems reasonable that problem should be deemed to be in P. However the RS theory does not give us even the faintest clue as to how to determine the guaranteed-finite set of excluded minors, and until we have these at hand, we may not have any algorithm of any sort. Worse still, there is no known algorithm to actually find the excluded minors and even if you have a big list of them, there is no way that I know to verify that the list is actually complete. In fact, could it perhaps actually be undecidable to find the list of excluded minors? So, does it make sense to view a problem as being simultaneously polynomial-time and undecidable? It seems a bit odd to me (who is not a particular expert in complexity) but maybe it's quite routine?