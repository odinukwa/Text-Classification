If you mean "lack voiceless bilabial stops", there are a number. In Afro-Asiatic I know of Somali, Tigre, Soqotri, Berber languages in general (there may be specific exceptions), Beja. Proto-Athabaskan has no bilabials so this carries over to many daughter languages (Tanaina, Tutchone, Tanacross, Tagish, Sarcee), and they are also lacking in Tlingit, Eyak and Ket (related) and Tillamook (not related except maybe areally, with Athabascan influence). Most Irooquoian languages lack it (Cherokee does) -- e.g. Mohawk, Oneida, Seneca, Cayuga, Tuscarora; add in Yoruba, Efik and a number of Grassfield languages. 

As far as I know, this is a scientific distinction not generally recognized by the average person in the street. "Poison" is a most general term, "toxin" is a subcase of that (poison produced by biological function) and "venom" is the injected subset of that. French also has "poison, venin, toxine", and I assume those terms exist in quite a number of languages. If a Norwegian-speaking toxicologist would weigh on we could get a definite answer, but I think there is no general term for venom which is the same as "poison" = "gift", though toxin is "toksin". You can say "slangegift" = "snake poison", but nothing that covers the whole class of vena. One could check a journal of toxicology that publishes in Norwegian, but I don't think there are any. 

"Stress" is a property of syllables, not consonants, so you could drop the restriction "stressed". In fact, no words in English end in [h], leaving out spelling where it is an orthographic device to indicate something else. There are some languages with final h (Sundanese, Arabic, Somali and North Saami in one interpretation), but it isn't common across languages. Having words like [mæʒh] would be particularly challenging to pronounce, and if final [h] appeared only after [ʒ] then that smacks of misanalysis (like, why not just say it's a pronunciation feature of final /ʒ/?). Arabic being a relatively widely-taught language, it might be best to "get the hang" of final h by practicing it in Arabic, and then transfer the skills to the conlang. The downside is that online teaching materials usually require you to read the script. Perhaps fdb knows of a pedagogical list of online final-h words with recordings. 

As a general rule, English speakers don't learn the pronunciation of place names from speakers of that language; they use general rules for pronunciation. Hence [br̩lɪn] instead of [bɛrlin], [ɔzlow] instead of [uʃlu], [pɛrɪs] instead of [paʁi], and Qatar (Standard Arabic [ˈqɑtˤar]) is a real problem, so I've heard [ˈkɑɾṛ], [kəˈtɑr] and [kæɾr̩]. Colin Powell would pronounce it as [gʌtr̩], close to the local dialect pronunciation [ˈgitˤar]. We also never pronounce Mandarin "h" as [x], and "zh" and "j" are not distinguished. Additionally, in American English, front vowels are raised a bit more before the voiced velars (g, ŋ) since there's no tense-lax contrast. 

I'll just add a bit of fuel to the above fire. As Sumelic notes, Zulu (and other Nguni languages) have /ɮ, ɬ, l/. The fact that /ɮ, l/ contrast suggests that /ɬ/ which is a voiceless version of /ɮ/ is not "voiceless l", it is a voiceless lateral fricative (as he notes), and not a voiceless /l/. Similarly, the existence of /ɬ/ in Lushootseed and numerous other PNW languages, plus the fact that there aren't other voiceless versions of sonorants, indicates that Lushootseed /ɬ/ is a voiceless lateral fricative, not a voiceless /l/. Same goes for lateral fricatives in Chadic. Contrarily, evidence from Klamath indicates that would-be voiceless sonorants are phonologically aspirated. The language has /l l' ɬ/, that is plain, glottalized and "voiceless" /l/ (there is also a plain, glottalized and voiceless contrast in obstruents and sonorants). When /l/ or /n/ stand before /ɬ l'/, the result is [lʔ, lh]. This makes sense if /ɬ/ is really an aspirated sonorant, and the rule splits a geminated aspirated sonorant into a plain sonorant plus the corresponding laryngeal glide. Ito & Mester 1989 in their Rendaku paper mention a number of reasons for treating the "voiceless sonorants" of Burmese as being aspirated. (A similar argument from Lhasa Tibetan could probably be made, based on aspiration throwback in negative verb, but I don't have a datum on any /ɬ/-initial H toned verb). It has been observed for English that r,l "devoice" in "pray, clay", but not "spray, splay", but this is exactly where you get aspiration differences on stops in English. Although English does not have "voiceless" liquids, it does (in some dialects) have voiceless glides, e.g. "which; human". There is evidence that these should be treated as "aspirated". The argument centers on the general distribution of aspiration in English: it has to be foot-initial (at the beginning of a syllable, and not immediately preceded by a stressed syllable unless the syllable with aspiration is also stressed). This not only determines aspiration of voiceless stops, it also explains the distribution of h and its deletion in prò(h)ibítion vs. prohíbit. This also affects the realization of wh which is "voiceless" in where, what, but voiced in anywhere, somewhat. So it has been conjectured that there are no "voiceless sonorants", instead, there are aspirated sonorants (and glottalized sonorants), and plain sonorants. I have not seen a convincing example of [-voice] sonorants in any languages, though that is the usual description of how aspirated sonorants are produced. 

I think you're referring to a "folk etymology", where the form or linguistic analysis of a word changes because people don't know the actual history of the word. Hence the original Nahuatl word for avocado "ahuakatl" → Spanish aguacate is attested in 1697 as "Avogato pear", subsequently avocato, avigato, avocado. "Avocado" is said to be influenced by Spanish avocado "lawyer". 

Properties of individual languages don't necessarily solve problems. Spanish children learn gender of nouns because it would be wrong to say "el aguo", and they learn what their parents say, who in turn learned what their parents said, an so on back to Latin and before. "Gender" is just one version of noun class systems. It's not clear whether you mean "gender" in the narrow sense (masculine, feminine, neuter; or animate, inanimate), or in the broader sense that also includes for example Athabaskan shape, Niger-Congo classes which cover various semantic properties including. Gender systems seem to have developed historically (over millenia) from systems where the gender distinctions signaled some useful fact such as "is male", "is small", "is alive". 

I suggest starting with UPSID, which is a collection of sounds from 451 languages of the world, listing 919 segments. There are various queries that you can perform, such as finding the shared segments in the inventories of two languages, or find out what languages have a particular segment (or class). The database is available for your own manipulation, if you want to construct your own queries. The original DOS program is still available from UCLA. UPSID presents what appear to be phonemes (that is, the authors did not do a rigorous phonological analysis of all of the languages, but it is not just a list of all of the surface phones reported in a source). You can also supplement that list with Ladefoged and Maddieson's book The sounds of the world's languages, which gives you a property-focused survey of the range of variation in languages. It does not give you complete inventories, but for example if you want to know if there is a difference between an epiglottal and a pharyngeal consonant, you can read about that in the book. 

Basically, given that there are 7,000 or so known languages, then it is always possible to select some approximate meaning like "god; cow; eat; big" and pick words from those 7,000 languages that are sufficiently similar in meaning and form that you could assume some deeper significance to that coincidence. As a starter, to establish significance, you would need to show that these forms that you offer are actually the words for "god" in those languages. As a case in point, there is no language "South African". That word (Setswana) means "Man-eater", which is an expression used to refer to "God", and derives from the verb 'eat' which is /li/. If your criteria for "similarity" are loose enough, you can always find a "similarity" in a half-dozen languages. I would not be surprised if readers here could identify a half-dozen tangential similarities in the form of the word for "cow" across human languages. 

Since the term hasn't been redefined in linguistics in a special way, all you can get here is the ordinary meaning of the word, which as, as reported in the OED, "a group of two letters expressing a simple sound of speech". A reasonable interpretation of "simple" is "one, single". So the two letters "ff"express not two speech sounds, but one. The term is not defined in terms of phonemes or morphological analysis. Nor is it defined in terms of underlying forms or any other abstraction -- it is defined in terms of "speech". Webster's Third International dictionary provides two definitions: "a group of two successive letters whose phonetic value is a single sound (as ea in bread or ng in sing) or whose value is not the sum of a value borne by each in other occurrences (as ch in chin where the value is \t\ + \sh)" – basically the same as the OED definition, and "a group of two successive letters" – basically, this is wrong, because it would then make "ad" in "admit" (idem "dm" in that word) a "digraph". Because "digraph" is not a technical linguistic term, all we can offer is standard, well-respected dictionary sources. Theoretically, one could devise a study to determine the definition of the term that best matches the intuitions of the largest set of English speakers, but nobody has done or will do that experiment. Even then, that would be a question about English language word-meaning and usage, not linguistics. 

Addressing the question in the title, the answer is no, because no single language has all phones. The question is somewhat ill-conceived, being framed in terms of "phones", since a "phone" is a concrete sound (it would be way too involved to properly explain what a "phone" is). The IPA does not have separate symbols representing the phonetically distinct vowels transcribed for instance [a] in all languages. Thus there is no single language sound corresponding to IPA [i], instead, very many similar sounds are subsumed under the transcriptional symbol [i]. Articulatory explanations of how to pronounce particular sounds are generally of only ancillary utility: what you need is cleanly-recorded models that you can imitate. You would have to explain what method you're talking about, in order for anyone to give you examples of that method, or tell you if it has a name. [EDIT] The linked description isn't a conventionalized and general method with a name, it's a description of how an individual (may have) learned to pronounce [r]. The magic step is "I somehow tried to hold the [ɾ] instead of immediately lowering my tongue". There may be individual descriptions of what people think they did physiologically to learn to pronounce novel sounds, but generally speaking, such descriptions are not a lot of help and are often just wrong. You need a native speaker with a bit of patience and a good ear: that is how I learned the exotic sounds of Lushootseed. Note that there is not just one phonetic type of [ɾ] and one phonetic type of [r], so if you want to master the trilled [r] of Finnish, you need a speaker or at least recordings of Finnish. Or, you could go to London and sign up for the official IPA course. 

There is no such thing. What can be recorded (i.e. what occurs in speech) is an allophone, and phonemes are abstractions built from allophones. Every allophone occurs in a particular context, so the acoustic value of /k/ in "keep" is different from the value of /k/ in "cool". Allophones also do not have well-defined acoustic beginning and ending points; for example the acoustic properties of [t] in "bat" extend backwards into the vowel [æ] so that one can (somewhat) identify "bat" as distinct from "bad" before reaching the consonant [t]/[d]. 

It is way more efficient than the alternative. The alternative is to compute some acoustic measure over a chunk of speech in question, an analysis which takes a long time to set up and to perform. Auditory transcription on the other hand is remarkably quick, once the system has been set up. An implication behind any transcription is that there are a small number of discrete categories of the property, for example length might be reduceable to two or three distinctions (so that a plot of duration values would show two or three regions of high population, not uniform grey). There is also the presumption that the phonetic categories will turn out to correlate with some other cognitive state (generally, something pragmatic like sarcasm). There are some counterindicating factors which indicate that the categoriality assumption is not completely true. This is where phonetic iconicity comes in. For example it is very common to find prolongation used on distal demonstratives (though it would be strange in English). If "there" is the ordinary word for a location away from you and me, prolongated "the-ere" would indicate "further away, "the-e-ere" would be "even further away", with the only limit on the number of distinctions being the non-linguistic ability to distinguish two durational patterns. Iconicity would be a kind of limiting noise on prosodic transcriptions, meaning that if an acoustic property signals "surprise" (which implies a categorial analysis "surprise is signalled with H"), there could still be continuous ranges of pitch raising signalling greater degrees of surprise. But you would not find for instance that "beyond 500 msc of added duration, prolongation signals shock rather than happiness".