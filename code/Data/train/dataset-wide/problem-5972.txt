More basically, can any assumption at all be put into purely mathematical terms? I would contend not. Things can be bound to mathematical formalisms by theories, but math itself is not about reality, and cannot really be rendered so. It can only codify interpretations, it cannot make them or express them. The actual assumptions are made in the framing of the theory that makes the math seem to say something, and they cannot really be captured precisely at all, because of the theory-embeddedness of language. The math can pull out and summarise the systematic parts of a theory, but you already have to understand the linkage between reality and the measures involved. Those are the assumptions. There is no content in the mathematics not implicit in the unstated bond between the math and the science involved. Edit: I should be explict about the framing. I adopt a kind of specific neo-Intuitionist model of mathematics as the creative process of exploring and elaborating the contents of shared intuitions about thinking that are not optional. By reality I mean external, shared reality, not including mental contents. If mathematics is all the built-in machinery necessary for us to apply thought to reality, then it is all about us, and not about external reality. And by assumption, I mean something that could be decided otherwise and matter. The axioms of mathematics are not assumptions in this sense, they could be made otherwise, but to the extent they were, they would not matter anymore, at least to the problems at hand. They would apply to a different set of problems. In that sense math is not made of assumptions we make, it is made of assertions that are made for us, that we inherit by virtue of having our minds, or that we creatively contrive by observing those basic assumptions. The linkage that actually makes the application of mathematics to reality is not mathematics, it is made by the assumptions of some theories, and the mathematics would be there whatever assumptions you did make or theories you held instead. To me, the language metaphor is good here -- English is not a discourse, it does not have real story or argumentative content, and it would be there no matter what discourse you chose to have in it. It is a part of our communications other than any discourse. Likewise, math is a part of all out descriptions other than any theory or decision... So theory and mathematics are pretty much two independent aspects of a single process. 

Equally near the opposite ends of Western philosophic history, Diogenes of Sinope and Nietzche would both clearly agree with you on that. In The Gay Science, Nietzsche several times refers to 'actually moral people' as 'monsters and scarecrows', because he sees any moral system that could be elaborated or explained as so rigid that it must necessarily either ultimately cause massive harm, or reduce its adherents to non-thinking manikins. It is the essence of his 'Perspectivism' that every individual has some part of the truth missing from all others' viewpoints. Therefore every person has an obligation to change morality, to re-evaluate values and change their valuations, at least a tiny bit, or they serve no moral purpose whatsoever and simply constitute 'herd beasts'. Diogenes founded Cynicism on the basis of a Delphic assignment to 'deface [all] the currency'. He first attempted to do this literally, by destroying mint equipment. But when that did not pacify the oracle, he realized that it was a moral imperative: that 'currency' (the original Greek term translated, as well as our word in English) meant 'what is now popular' as well as 'passable coinage'. From this point of view, equally, whatever is the current morality will always be lacking and will need to be 'defaced' by those who can see through public opinion. Given some of the things he is recorded as saying about food, sex, art, etc., part of that change is adapting rigid rules to fit personal preferences. For either of these thinkers, necessarily, that bending morality to suit oneself is an integral part of the purpose of morality itself. 

Sartre's answer to this was 'genuine responsibility'. Even if you are utterly determined, you still do not know the right answers to the questions you pose to yourself until you decide them. That ability to decide is all we have ever asked of free will, and it is the ONLY important part. All attempts to deal with free will as something other than the basis of accountability are just attempts to use other branches of philosophy to evade ethics and are basically a classical equivocation -- using the same word for two different things, and then declaring the things equivalent because you did. It does not matter, from that point of view whether free will exists in any other sense. If you do not assume your decision process is free, it is impossible to survive as a human being and retain moral accountability in a genuine way. You become inauthentic as an actor, and cannot function as a human social agent. If you believe that you have no free choice, and remain responsible in a real sense, you are being inauthentic in a different way. You are directly lying to yourself about what you believe. But that means that physical theories of determinism and free will are not contradictory (as Calvinists and Catholics alike ultimately agree). You have free will if you experience moral responsibility, whether or not you feel that is consistent with your physics. 

We should not let go of either of these, we should let go of the notion of dichotomy that infects the idea of illusion. We tend to badly overuse the notion of illusion, and the answer to questions like this depend very heavily on what is really meant by the word illusion in particular circumstances. You seem to have oversimplified our grasp of Self from one kind of partial reality into 'an illusion' and translated that into 'a mere convention', then jumped to the conclusion that anything contingent on a mere convention must also be a mere convention. But you give no 1) argument against the Self being some more stable form of partial reality. And give no 2) consideration of consider whether mere conventions can have real effects. You need to address those two things, before your complaint makes any sense. Because both of them are highly debatable. There are many forms of partial reality In some sense, language is always deceptive, and anything with a name is therefore an illusion. There is no rule for deciding which molecules make up any given supposed 'chair' or 'brain'. But you are still using words, so you are obviously not put off by the fact of that 'illusion'. Because we see how it is simply a simplification, and a convention for coping. If we are going to address questions like this, we need to refine our notions of relative reality much more closely, and discard the ones that are childishly dismissive, like the notion of 'illusion' itself. How is a collection of psychological dispositions not at thing? It has effects, it makes the world more predictable, and in order to do so, it has to exist in some sense. If that is what the Self is, then, how is that an illusion? That is not an illusion, it is an epiphenomenon: It has reality and arises from things that have reality, but we misunderstand the direction of causation (or imagine a direction in a case of mutual causation). How does that make the concept less useful, or the pattern less effective? If reality is a continuum, instead of a collection of isolated entities, again, how does that make any of it an illusion? Each thing is an unattained approximation, but that does not, again, make the concept less useful, or the pattern less effective. Newton's use of the calculus as a basis for physics has shown us very well how unattained approximations have enough reality to base a metaphysics that works. If all is one and distinctions are conventions, how does that make those conventions into illusions? Our language and our culture is a set of conventions, but they are negotiated conventions and hardly arbitrary. We know our culture, we hold it and use it, as a repository of earlier thinking negotiated by relative survival, the trials of politics, and a shared group aesthetic. There is a huge distinction between "Human understanding of the world is never perfect and endlessly incomplete" and "All is illusion". The former is an obvious deduction from the modernist enterprise, the latter is a pointless canard, meant to forestall real philosophical inquiry (and protect religions from unwanted challenges.) The notion of 'illusion' itself is as much of an illusion as anything you might try to label an illusion. Things like 'optical illusions' are the closest meaningful use, but they are themselves useful features of sensation that do not reconcile with our overall model of space and its features. So they are gaps between two levels of multiple realization of the same emergent continuum, which have evolved quirks for different local goals. They are neither wrong nor misleading when used together in context. And when observed out of context, historically, they have guided most of us to the notion that neither the data, nor the model is paramount and uncorrupted, but both are real. Given this range of options Free Will is unlikely to be mere convention, and more likely to be, like almost everything else, an epiphenomenon, an unattained approximation, an apparent inconsistency between multiple realizations of an emergent phenomenon, a simplification of some real effect by negotiated convention, or some other aspect of reality that does not fit well with our intuitive presumptions. But none of those things is just an illusion, each is partially illusory, but still real. Less real things can create more real things Traffic laws, a fiction of convenience, create delays in real time, and occasional tragedies in real lives -- you miss your court date and lose custody, you end up stuck on bridge in an earthquake and die. Religions generate wars that obliterate millions of lives. To the extent that personalities are epiphenomena of mental traits derived from physical systems shaped by social development, and ... Human pairing, and which actual children are born, is decided by things with a very limited claim to independent reality. 

'You are rich because you are blessed' only means that riches is one possible effect of being blessed, not that they are always an effect. Any blessing may cause riches, it is not true that every blessing does cause riches. It can happen that one person is rich because he was blessed, but that another person would be blessed in a different way. 

If time as we (or any mechanism we construct) can observe it were infinitely divisible, the uncertainty of the energy of an object would always have to be infinite, because we would be able to observe the particle basically frozen in time. But we have Heisenberg's inequality. The only way to make delta E times delta t exceed h-bar over 2, if delta t can be arbitrarily small, is for delta E to be arbitrarily large. I am not sure that makes anything 'mind-dependent', but it does mean that physical reality would not really cohere if we had this power. So if it were really possible, everything we observe would have to be an illusion of some sort. (But I do think we already had that result from Zeno, and from Kant's Atomicity Antinomy paraphrased by @PhilipKlocking in the first comment. You appear to disagree. So I am not altogether sure I understand the question.) 

If all self-evident truths are tautologies or are somehow redundant versions of the same thing, then Mathematics suddenly becomes a vacuous and pointless domain. The elements of Peano's arithmetic are self-evident -- to over-simplify them a bit: we understand equality (of discrete and finite things) correctly, we can always get another number, equals added to equals net equals, and complete induction leads to meaningful generalizations. Yet there is a great deal of content to arithmetic, not just silly redundancy, and even a bit of controversy. (E.g. we can always get bigger numbers, but we believe in infinity. So how many infinities are there, and can we identify them all?) Some things are apparent because they make communication possible, and it is taking place. Basic math falls in that heap. Whether those are 'ultimate' truths that in any way transcend human language, or whether they are just genetic biases that come naturally to most healthy and complete human brains is another issue altogether. But the whole of math is not empty, redundant or tautologous. 

Most folks you are pointing out on the right, from Mussolini's notion that each race has its own truth to Karl Rove's dismissal of 'fact-based people' are not really post-modernists, they are relativists in a degenerate way which is actually based in the realpolitik of how easy intellectual manipulation is for a cult of power in an atmosphere with too many sources of information. This idea has been around at least since Machiavelli, and does not rely on any reduction of essentialism at all as its basis. So it really isn't post-modern in origin or content. Blaming this on post-modernism is just pretense, both by the people doing it, and by the folks taking them at their word. Which just proves their point, you are being successfully manipulated by their lies. 

A paradox like the Grandfather paradox is not a contradiction, it is the reduction of a premise to circularity. In this case, it is the suppressed premise that there is only one sequence of causation -- the premise of physical determinism. Only if you then assert that premise do you have a contradiction. In this case, in universes where a single deterministic timeline holds, then, there really is no paradox. Either you cannot go back in time, or if you do go back in time to kill you Grandfather, you already did so, and you cannot succeed. But we do not really have proof this is such a universe. So to make that deduction is really begging an important question. More direct paradoxes like the liar paradox, or the Berry Paradox or even the sorites paradox for instance do not point out a premise you did not insert. The premises they render circular are automatic assumptions about language, that no one ever states. To assert the problematic premise and precipitate the inherent contradiction, you would have to deny the ability to refer meaningfully to arbitrary timeless, stateless true statements with discrete referents. But this is a reflex deeply embedded in our basic grammar and logic. We would find it impossible to make definitions without these premises. (In restricted domains, like math, I assert one should do just that. But even there, I am in a tiny minority.) It would make normal language insanely difficult to use correctly. So they remain paradoxes.