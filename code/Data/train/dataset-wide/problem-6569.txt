In his March 2014 MIT lectures, Chomsky continues to claim that 'internal Merge', which yields the traditionally problematic 'displacement' property, is, in fact, the simplest and most economical structure-building operation possible, since it minimises 'search'. Of course, the latter observation is true to the extent that the 'target' of 'internal Merge' is locally available in a limited domain of the computational system's 'working space' (a previously built syntactic object {X, Y} that functions as the current active 'locus' of the computational operations), whereas in the case of 'external Merge' the 'target' must be searched for, at best in the whole 'working area', or even worse, in the whole of the speaker's lexicon, if initial one-step lexical insertion via 'numerations'/'lexical arrays' is considered stipulative and dispensed with. However, this 'elegant' argument of Chomsky's has always made me uneasy, because I cannot help asking myself two very naïve questions: 1) Why should it be 'economical' to make a 'copy' of Y if the 'original' Y is already there (in the object {X, Y}) and whatever the computational system may have had to do to Y (possibly nil, if 'no tampering' holds, a highly dubious hypothesis) has already been done to it when the {X, Y} object was formed at the previous 'external Merge' stage? Or, in other words, why doesn't 'internal Merge' violate Economy? And 2), since a) 'internal Merge' occurs only when some other head Z is attached to {X, Y} by 'external Merge' yielding a new syntactic object {Z, {X, Y}}, b) is triggered by some feature of Z that requires 'licensing' (checking, valuation,...), and c) entails 'looking into' {X, Y}, a previously built syntactic object, and replicating Y, to what extent is it coherent to claim that 'internal Merge' respects 'strict cyclicity'? Or, in other words: Why shouldn't the minimal computational 'cycle' (i.e., a single application of 'external Merge' to two objects X and Y) count as a 'cycle' when it is the 'basic principle' of the Language Faculty that is at stake? [I know that only certain computation 'cycles', i.e., 'phases', are supposed to 'count' for this purpose, but, of course, that is a stipulation, and, as Chomsky insists, any stipulation is a step backwards on our way to genuine science]. Question: Is this reasoning of mine in any way unfair to, or, simply, the result of misinterpretation/misrepresentation of, Chomsky's position? 

In a sentence like His name is Joseph, but you can call him Joe the names Joseph and Joe are not used 'referentially' (to name a certain male individual) but just 'mentioned', i.e., they are used 'metalinguistically' to refer to themselves. Otherwise, of course, such sentences would be nonsensical, as Quine explained long ago, and, for that reason, I instinctively enclose them in quotation marks whenever I have to write sentences like that. Yet, as far as I know, at least in English (but also in Spanish, German, French, Italian,... Mandarin) they are not orthographically treated as metalinguistic expressions at all. I mean, they are never enclosed in quotation marks or otherwise marked as cases of 'mention' rather than ordinary referential 'use', are they? Does anybody know why? Are there languages out there in which parallel names in equivalent sentences would be orthographically marked, via quotation marks or similar devices, as cases of metalinguistic, rather than ordinary referential use? 

Spanish is another language in which the intransitive use of the verb to drink, Spanish beber, automatically means 'drink alcohol to excess', as in (1). That happens unless the speaker uses it in the imperative form and the verb is not really used intransitively, as the context supplies the understood direct object, as in (2). (1) ¡Pobre mujer! Su marido bebe. [Poor woman! Her husband is a drunkard] (2) Toma, bebe despacio. [Here you are, drink slowly][Offering a glass of cold water] Of course, we also have certain other intransitive verbs used in a colloquial register that specifically mean 'drink alcohol [to excess]', such as soplar, pimplar, trasegar, etc. 

In addition to the popular right test that WavesWashSands refers to, evidence showing that here is a preposition - and not an adverb - comes from the fact that it can postmodify nouns (cf. The people here do not like changes), whereas real adverbs cannot. If, on the other hand, here were of some other category, say an adjective or a noun, it should be able to premodify other nouns, but, of course, it is not (cf. * The here resources are insufficient). Since a V, a Det, a Q, a Deg, etc., it cannot be either, analysing it as an intransitive preposition is virtually inevitable. Here cannot by itself in general be analysed as a phrasal category (= PP), though, because it can be accompanied by its own dependents - not only right, but also PP's, as in Here in London, housing is terribly expensive __. The fact that, in such an example, Here in London can be 'extracted' ( ?topicalized) as a whole from its VP/AP, but in London on its own cannot (cf. * In London, housing is terribly expensive here__) constitutes further evidence that 1) here in London is a unitary constituent, and 2) that both here in London and in London are PP's, because, otherwise, the extraction of the PP complement in London would not violate Ross's 'A over A constraint' (or: 'minimality', under later approaches to movement) and should be grammatical (as are other PP complements extracted from non-PP's above them), but of course it is not - which follows nicely from the 'A-over-A constraint'. Then, obviously, if here in London is a PP, here must itself be a P, because it is the head of that phrase, as shown, and phrases are endocentric, according to the X-Bar principles. That is a desirable outcome, because, if here is the head of the PP here in London, its non-extractability from it (cf. * Here, housing is terribly expensive __ in London) needs no explanation, as heads of PPs (contrary to those of, e.g., VP's or AuxP's) can never be extracted, cf. * In, I have never felt at home _ Berlin. That, by itself, is fairly strong evidence, I think, that here is, indeed, the head of the PP here in Berlin and, according to the endocentricity principle, a preposition, a conclusion that reinforces the evidence already presented in paragraph 1. [The only other alternative (i.e., that the head of here in London were the preposition in, with London - its 'internal' argument - in its complement position, and here somewhere else, either as an adjunct or as a specifier) would not change things much, as we know from the arguments above that here cannot be adverbial, adjectival, nominal, etc., and must be prepositional anyway, but, apart from that, that possibility can be safely discarded for different reasons: PP adjuncts like here in London are 'predicates' whose 'external' argument must be 'discharged' by the 'e(vent)' variable associated with the VP/V' they modify, and, therefore, they cannot project their second argument in their specifier position, because, if they did, they would become 'saturated' and would no longer be able to 'take' the 'e(vent)' argument associated with the 'VP' they must modify. The specifier slot of such PP adjuncts, therefore, must be empty, which excludes here from that hypothetical position. Hence, if the head of the PP here in London were the preposition in, here could at best be an 'adjunct' of in (one under the scope of right, cf. right here in London vs. * here right in London), but, if so, it would also have to be a phrasal category, i.e., a PP. PP pre-modifiers, however, are severely restricted in distribution; short of in (semi)-lexicalized expressions such as an out-of-print book), they practically never occur, and, in particular, locative PP's seem impossible to construe as modifiers of other locative P's like in London; in all the examples I can think of, the analysis must be different, in terms of two independent locative PP's]. In sum: there is rather solid evidence, I believe, in support of the claim that here is, categorially speaking, an intransitive preposition, and a 'head', although, of course, it will also function as a phrasal category whenever it occurs on its own (i.e., without the ?adjunct right or complements like in London). [I deliberately leave aside here the question whether here should also be analysed as a P, instead of a 'nominal' (a DP) in postpositional expressions like hereafter, etc. 

The answer to your question is 'yes', and, of course the restrictive/non-restrictive distinction makes sense for indefinite NPs, too! Why shouldn´t it? You can easily generate as many examples as you want of non-restrictive relative clauses accompanying indefinite NPs (be they 'specific' or non-'specific') by choosing NPs that name unfamiliar objects and, therefore, if used, are likely to require a bit of explanation from the speaker to help the hearer get an idea of what is referred to (which, as you know, is the characteristic function of non-restrictive relative clauses; these cases are exactly the kind of cases we might expect to need such explanatory clauses, there is nothing special at all to say about them). For example, if I had reasons to assume that you are not likely to know what a guqin (or any other, from our perspective, 'rare' object) is, I might perfectly well say to you something like a), where the indefinite NP is non-specific (i.e., 'intensional', non-referential: such an object existed, but might not be available anymore), or one like b), where it is specific (i.e., referential: there is, indeed, an old guqin in my music room): a) I am currently looking for a guqin, which is a sort of Chinese sitar with seven strings [+ e.g., but I want an old one and they are very difficult to come by]. b) I have just bought a guqin, which is a sort of Chinese sitar with seven strings [+ e.g., and I am fascinated by its sound, but it is an old one and it has cost me a fortune. I'd better not tell my wife!] You can even build examples that contain such non-restrictive relative clauses before restrictive ones, as parentheticals, as in c): c) Tom told me about a former patient, who had never before done any harm to anybody, that one day, for no apparent reason, went into a school with his rifle and killed thirteen children. Again, there is nothing in c) worth special comment: the non-restrictive relative clause must be adjacent to its nominal 'antecedent', but since the NP in this case also contains a restrictive relative clause that ends in an NP (= thirteen children) that could itself be interpreted as such, to avoid ambiguity the non-restrictive relative clause must be inserted next to 'a former patient'. Since, if it were inserted without commas, it would be interpreted as restrictive and that is not the intended interpretation, there is no choice but to insert it as a parenthetical. Finally, if you are familiar with the syntactic and semantic tests that generally distinguish restrictive from non-restrictive modification, as I assume, given the way you have worded your question, there is nothing special to add about heuristics: apply the standard tests to a), b) or c) if you are in doubt (but you need not be). 

Formal semantics is simply a (set of) metalanguage(s), a (set of) formal system(s) of representation, and is compatible with any 'ontologically substantial' theory of meaning, no matter whether meaning is all in the mind, as 'conceptualists' (e.g., present-day cognitivists and Chomskian minimalists) believe, or all outside the mind, as radical 'realist' referentialist theories of meaning traditionally claim, or partly in the mind and partly in the extramental world, as 'dualist' theories say, or even all in Language itself, as in the 'immanentist' approaches of early structural semantics inspired by people Saussure, Hjelmslev or Coseriu, or Katz, and arguably by Chomsky himself for as long as he believed in a non-trivial Faculty of Language. This list, of course, is not exhaustive, it does not quite capture Frege's 'idealist-realist' view of sense, nor Quine's hybrid behaviourist-conceptualist view, nor the late Wittgenstein's conception, nor Putnam's view, etc., but the point is just that formal semantics is not a theory of meaning in the sense all those are or were. The 'entities' (sets, functions, possible worlds, whatever) that the 'alphabet' and the well-formed formulae of formal semantics 'denote' may, ontologically speaking, be 'anywhere', so to speak. No wonder, then, that it should be able to co-exist with any conception of semantics. You can do 'formal semantics' starting from a cognitive semantics perspective. Obviously, to the extent cognitive semantics works with fuzzy categories, representing its analyses according to the rigid standards of 'formal semantics' may be less straightforward, but the conceptual-methodological difficulties defining and operating with fuzzy categories may raise are the cognitive semanticist's concern, not anything 'formal semantics' itself should worry about. Whether formal semantics is ultimately adequate or not to model meaning in natural languages is a different matter, but the same question can be asked with respect to cognitive semantics or any other 'substantial' theory of meaning.