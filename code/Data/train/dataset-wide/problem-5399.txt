It's not. You are comparing the encoding of Chinese with understanding Chinese in the brain. The encoding part is comparable to the eye, not the brain. The brain could be comparable to the software that processes that binary coding. 

The brain ONLY PASSES SIGNALS AROUND. Yet there is learning. In fact, an artificial neural network uses pretty much the same mechanism as the brain. So the optic character recognition software that converts an image of Chinese text to their unicode encoding is similar to a part of brain doing the same thing. The software that takes that binary encoding and produces its English translation (for example google translate) is also pretty much like what the brain does; map the encoding to meaning. 

P.S. You may also be interested in learning about a newer concept, called computational sapience (wisdom) that apparently is more powerful than artificial intelligence. This about page of the W.I.S.E lab of the University of Regina gives some introduction. In short, given a function (a behavior for example), an artificially intelligent system tries to find , but a sapient system also tries to find . In other words, artificial intelligence mimics behavior, while sapient system understands behavior. 

Now regarding the Turing test itself, there are different ideas. From one point of view, if the computer is so good, that you can't distinguish it from a human, then why would you call one intelligent and another not? This is a valid observation, if you consider intelligence as a measure of the output of the system. Some argue that this does not necessarily define intelligence. I'm one of them. Let's take bees and humans for example. If in danger, a couple of humans think that "there is safety in numbers", you would take that as an intelligent thought. If bees stick together when in danger, no one calls that intelligence; it's merely hardcoded in them. As you can see in the example above, given the same behavior, we ourselves call one intelligent and the other not. Let's take another example. Do you consider Deep Blue an intelligent computer? Did you know that Gary Kasparov (who lost to Deep Blue) was convinced that no computer could have thought of the winning move of Deep Blue and therefore it must have had been a human deciding that move? Well, I think we can say Deep Blue passed the Turing test: it was indistinguishable from a human. But Deep Blue is a useless piece of junk now (sorry, I mean it's a valuable item in a museum). However good it may have been in chess, I doubt anyone would call it "an intelligent machine" because it passed the Turing test. Conclusion Like I said, this is rather controversial, but in my opinion, Turing test is perhaps a necessary condition for intelligence, but most probably not sufficient. 

There are innumerable ways to express conditionals, so even if there are standard ways to translate some syntactic structures into logical notation (e.g., "If A, then B" = "A only if B" = A â†’ B), you can only get so far with these. Also, not every sentence that seems to be a conditional is actually a conditional. Consider the difference between "Men are grumpy when they're hungry" and "Men are bachelors when they're unmarried" which have the same syntax but different logical form. So you need 2 things. First, a way to tell if a sentence is really conditional, and second, a way to tell which of the conditions in a conditional sentence is sufficient and which is necessary. The easiest way to do this is to draw a truth table for your sentence. Basically, you have to ask if the sentence you're considering is true or false for every possible distribution of truth values for it's clauses. For this sentence: Raimundo appears in every photograph that Yakira does not appear in. You have to consider what happens if: R appears and Y does not = T (Both clauses obtain) R appears and Y appears = T (1st clause obtains but second does not) R does not appear and neither does = F (2nd clause obtains and 1st one does not) R does not appear and Y does = T (Both clauses are false) When only one of these possibilities makes your sentence false, and it is one in which one of the clauses is false and the other is true, you know that you're dealing with a conditional sentence. The false clause in that possible world is your necessary condition, the true one is a sufficient condition. 

Most metaphysicans would probably accept that it cannot be the case that (1) is true but (2) is false. However, this would count as an invalid argument in a logician's sense. Question 3: Yes, the argument is formally valid. The reason it is formally valid is by convention, but this convention was motivated by your modal considerations. It cannot both be the case that the premises are true and the conclusion false, since the premises can never be true! 

I recommend looking at the SEP article on "Knowledge How" here. It gives a great overview of the distinction between the three kinds of knowledge you are asking about. As a followup, the bibliography at the end has several excellent papers on the subject. Lastly, you might want to look at the Knowledge Argument against Physicalism here. It turns out that the main positions in the Knowledge Argument divide on whether knowledge of experience is propositional knowledge or non-propositional knowledge. 

whether or not it is valid or not is a purely syntactic notion about symbols. In any introductory logic textbook you learn the correct syntactic derivations for what counts as a valid argument. However, your question uses modal terms like "can" and "cannot". For much of the intuitive content of what it means for an argument to be invalid, your equivalence is correct. This intuitive consideration is what motivates the formal definitions of what it means to be valid. To get out of metaphysical waters about modality however, logicians have tried to steer away from your formulation. To appreciate the subtlety, consider the argument: 

Question 1: The first sentence describes a valid argument; the second describes an invalid argument. If you want to describe it a bit more metaphysically, in the former case the truth of the premises necessitates the conclusion, and in the latter case they do not necessitate the conclusion. So, they are opposites in that way. Neither of them share the characteristic "All premises must be true." For example, a valid argument where not all premises are true is: 

I highly recommend Anscombe's Modern Moral Philosophy if you want to see the contrast between Aristotle and modern ethics. If you want to delve into the details of Aristotle's views on practical reason Wiggins' Deliberation and Practical Reason is good. 

The relation between needs and public policy is not straightforward. Discussions about what people "really" need are hard to settle, and even if people agree that X is needed, a lot of questions concerning how to satisfy X and how important is to satisfy it, given that we also need A, B and C, have to be answered. Also, in some situations, there might be a conflict between satisfying need X and being just, brave or honest, and it's not clear that we should always put needs on top of these other values. Since your question is tagged as a reference request, I highly recommend David Wiggins' "Needs, Need, Needing", available here, if you wanna delve into the topic of needs, "Claims of Need", also by Wiggins, is an excellent paper, but is not available online. Your question is too open ended to give a meaningful reply. In a sense, every major brand of moral theory tries to tell you what is needed to make a better world, or to do the right thing, or to be a flourishing human being; but the notion of need seems to acquire meaning only after we decide which of these things are really worth getting. 

You have to consider that Talbot's book is for beginners and that it oversimplifies a lot of stuff. In this case, explaining Aristotle's ethics in terms of 'the right action' makes it easy to compare his view on ethics with that of Kant, who believed that the right action can be determined using the categorical imperative, and with that of Mill, who believed that the right action is the one that causes more happiness. But this is a simplification. So the problem is not Aristotle, but Talbot. I'll just list the inaccuracies: 

Question 2: It depends on what you mean by "invalid argument". For example, when talking about a purely formal argument like 

The sentences are: (1) People of a similar character associate with one another. (2) Guilt by association is frowned upon by most people. Now I don't know what you mean by "somewhat of a contradiction", but saying that two statements are contradictory is a strong assertion. It is saying that those two statements imply a statement of the form "P and not-P". These statements are not in contradiction. An easy way to notice this is that both statements are empirical truths, and there is no way that two empirical truths can generate a contradiction. Having said that, instead of (2) you might have been thinking of: (2'): Guilt by association is morally wrong. Note that (2') differs greatly by (2) since (2') is a normative claim and (2) is an empirical claim. Now, you might think that (1) and (2') are somewhat in tension: if someone in your group is guilty, and you have roughly similar character to them, doesn't some guilt transfer to you? This strikes me as fundamentally unfair since you didn't do anything. You can only be found morally responsible for what you in fact did. 

Krauss was being a bit sloppy. It's easy to see that science can tell us what is true iff science can tell us what is not true. (You can always rephrase "Is X true?" with "Is not-X untrue?"). Putting this verbal quibble aside, it seems that Krauss was making the (not original) point that it's much easier to falsify claims with "always" or "never" than to verify them. To falsify (or show to be untrue) the claim "All ravens are black" you only need to observe one non-black raven. However, to prove that "All ravens are black" one would have to observe every raven, and then one would somehow have to scientifically verify that there are no ravens that you haven't seen (which looks to be impossible). Karl Popper famously advocated the thought that science is about falsifying hypotheses rather than verifying them. As a last point, it turns out that falsifying a claim scientifically is often not as easy as it appears, as argued by in the Duhem-Quine thesis.