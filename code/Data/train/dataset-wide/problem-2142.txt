Since your final result set will be grouped by departments and sections, "counting it only once" means you need to pick where they should be counted. For example: 

Yes. You will cut out 2 bytes per row for the pointer data, and 1 bit for the null flag. I believe the number of bytes per row that you save per table will be approximately*: 

Yes, certainly. As mentioned in 3, null data is stored efficiently which helps sparse tables. *using integer division, i.e. 

This can be broken out into different steps if you want (i.e. variable for the count from the characteristics table). But something with this logic should work. Assuming unique constraint on (ID_SALA, NOME_CARATERISTICA) in getSalas, and unique data/constraint on (CARATERISTICA) in tabc_valor or whatever source data you have to compare to. If those aren't necessarily unique, then you will only have one extra step to group by those columns first and sum the counts. In one query: 

You also should check how many pages you reduce the table size by. There is a 96-byte header per page. The table metadata would also be removed, but that is probably negligible. 

I have a query where I will be using the same value twice for one of the parameters. This query will be run under IBM Data Studio to see the results. Below is a sample query: 

We have a table that contains the log record number for each database captured every minute. This data spans back a full year, or shorter if the database is newer than that. We have to watch the log record number to ensure it will not go over the maximum number of bits that it can have. Currently I'm tracking this information with a simple query and adding it into a spreadsheet. Sample Query: 

Is there a way to use named markers in DB2 for z/OS to indicate that the value will be the same so graphical tools only prompt for one input? On queries that have 20+ inputs, this can be time consuming. Is there a better way that I should be doing this? 

Because the table name was fully qualified with "MYAPP" instead of supplying it later, they cannot simply copy the code that they already have within the same DB2 and just change the schema name. They would like entirely new DB2 subsystems to avoid this issue. Is there any way to avoid this? Are there any bind parameters or other strategies I could employ to have duplicate schema names running on the same DB2 subsystem? 

Is it crucial for the business to ensure that a large block records has been transferred in a large batch, such that anyone accessing the source table will not see them at the exact point in time anyone access the target time will be able to see them? Or, is it necessary for users of the target table to see large blocks of records appear in the target table all exactly at the same time? If no to both of those, I second SpÃ¶rri's below statement... 

When you create the certificate on the destination server, you specify both the certificate file, and the private key file, along with the password you used to back up the certificate on the source server. Here is the example from MSDN: 

Initially working through this issue there were errors in the event viewer. However, now that I have used to give configuration, , and rights for the SQL Agent account to , there are no messages showing in the system log -- just the above message in the SQL Agent job history. I'm looking for the master tome of Windows configuration but there does not seem to be one. Do I need to set up auditing or traces to see what privileges are being requested? 

I believe it is possible to used named parameter markers in other RDBMSes to indicate that the value should only be given once. Example: 

We have several application teams that are looking to do a re-write of large legacy applications. This is mostly COBOL going against DB2 for z/OS (v11). The COBOL code was generated using a tool, so we don't have any access to the source. Let's say the SQL cannot be changed for the sake of this question. They would like environments (dev/test/perf) where they can copy the existing data and test the re-written application (still using the same SQL) while still having a team supporting the legacy system through dev->test->perf->prod. Current SQL example: 

I would like to instead develop a report that a technician could run to determine through stat regression when the log records would be out of bits. So I now need a select statement that would retrieve the LogRecordNumber for each interval of time where we have a log record. Getting the log number once a week would be appropriate and allow me to make a reasonable regression guess at when we will be out of bits. Again these data can be as far as a year back or as soon as a few months ago, so hard coding something like DATE(CURRENT_TIMESTAMP) - X WEEKS is not possible. Is there any way to do what I'm suggesting with a query, or do I need to rethink this? If it matters, the database in question is DB2.