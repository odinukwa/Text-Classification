Say I have a table with 3 columns: Say ID has an index on it, name has an index on it, and there is another index which combines id and name. Lets say I now have an update statement which looks like this: 

1) User would login using their username and password 2) User could get friends by getting their USER entity based on their username 3) User could add/remove friends by getting the entity of user1 and user2 and either adding or removing friend via transaction to make sure they are consistent. 4) User could get all the message they have sent by using indexing the the 'from' attribute (limit of 10 message per request). The same could be done to view all the messages they have received by using the 'to' attribute. When the message has been seen for the first time I would go to the message (1 get) and update the entity (1 write + (4 writes x 3) = 13 writes to update the entity). My major concern - If a user gets 10 messages, this will require 10 get requests plus if all 10 messages are new I will need to update each entity and if all of them are new that is (10 x 14) 140 writes. Then if I get another 10 message for this user the same process and this could all add up very quickly. I then thought of creating an entity to store all the sent/received messages in a string for a user inside of a single entity: 

+1 for the answers from @CadeRoux and @ChrisS, they make valid points. Your comments to those answers highlight that this is essentially a proof-of-concept venture at this stage and you want to minimise your capital investment. If that's the case, forget spending $1000s on hardware and licenses, rent. You don't appear to need to store a vast quantity of data, so your early build-deploy-test cycles may target subsets of the 100GB (after 9 years) that was mentioned. Even at 100GB you should still fit comfortably into a wallet friendly Amazon EC2 instance. You can technically/legally deploy a developer SQL license to a bare EC2 VM while you're pre-production, cutting costs further. Brent Ozar posted an interesting analysis of SQL Server on EC2 last year that would help you weigh the pros and cons. I'd also weigh the merits of SQL Azure, especially now that the tooling (SSDT) is better geared toward the platform. 

We are having some discussions about partitioning some application tables in SQL Server 2008 based on their quickly growing size. One is an event table that is typically used for INSERTS (80% of the queries) or SELECTS that look for the primary key of the table (20% of the queries). The other table is a "mapping" table that is all SELECTS looking up the primary key. Would partitions along the primary key be helpful here? I've done a lot of reading and all the classic examples of partitioning seem to be data warehouse tables that are partitioned on dates. It also seems that partitioning can sometimes cause more harm than good. What do you think about these tables? 

We have been receiving complaints from a particular SSRS user that her reports run slow. I investigated in the table in the database and I observed something strange. Fairly consistently, the is much longer than other users. Both and are near the averages of other users. I am puzzled. The reports all use the same shared data source that runs as a service account. I would think if it was a crappy user computer issue, I would see differences in the rendering time. Same if there was a network issue. I don't know where else to look - any ideas? 

Have never encountered anything remotely like this and suspect something has been lost in translation. I will of course apply the usual caveat for licensing questions, "don't take anything you read here as gospel, check it with your licensing partner, and Microsoft, and call both back to speak to a different individual. There's a good chance you'll get a different answer the second time around". You get a key, you install the software. Any CPU limitation is a product of the physical environment or version of SQL Server. For standard edition that is: 

What about SSMS + <--insert schema comparison tool-->? This is definitely a step in the right direction and takes away much of the manual effort required to maintain scripts. But (and it's a big but), typically there are manual steps involved. The popular schema comparison tools can be fully automated and integrated in to the build process. However, in my experience the more common practice is for a comparison to be run manually, the resulting scripts eyeballed, checked in to source control, then executed manually to deploy. Not good. Anytime we fallible humans have to get involved in the process of build or deployment we introduce risk and we make the process non-repeatable. If you and your team are among the few that have fully automated schema comparison and deployment, hats off to you! You guys are the most likely to be open to the benefits that VS2010 has to offer as: 

We believe this will work for, but we currently have an active community of users and have estimated when we roll out the feature it will be heavily used. Thus we would also like to plan for the future to be able to scale (premature now, but we think this is a very simple feature and are hoping to design it well now to save us time in the future). If in the future we need to scale horizontally we do not think our design will scale very well. We don't believe an auto-incremented message_id pk will work in a multi node environment. We looked into setting a UUID for this column ($URL$ but have read that this can really hurt performance since the indexes will be large. Reading this article we see paging can be an issue too. $URL$ In our current design we don't really see a great shard key which can be used for all our queries. We would like our queries to reach one shared server if possible. So my question is what would be a an efficient way to implement this basic messaging feature so that in the future it scales well with the queries we need. I have only ever worked with a single instance of MySQL so I am not an expert on scale out design with MySQL by any means and am open to ANY ideas (complete redesign too)! We believe sharding will be inevitable since our instance types are not very large. PS: We know some may say NoSQL is a great option for this scenario, but we looked into NoSQL options for this feature (Cassandra,DynmoDB,Google Datastore, Azure DocumentDB, FileSystem like AWS S3 or Azure storage) for a few months but due to costs for performance (indexes are very expensive in managed NoSQL environments), lack of ACID compliance (we have other ideas which will need true transactions), and more we decided on MySQL. 

This is a purely academic question, in so much that it isn't causing a problem and I'm just interested to hear any explanations for the behaviour. Take a standard issue Itzik Ben-Gan cross-join CTE tally table: 

Simplistic approach, you could record current log usage from the dm_io_virtual_file_stats DMV before and after your batch process. This would be polluted by other server activity however, so only useful if you can test in isolation. 

Newsgator is documented as running a 2.5 billion row, 4TB full text implementation and FileControl as having a 2 billion, 1TB system back in 2005. Given the other options available today, would they do the same now? Given the licensing cost of SQL Server I'd be inclined to consider alternatives if they fit your use case. Lucene or Solr are the obvious open source choices. 

I was going to post the same question for SQL Server having done a bit of digging around recently. How about the Transaction Processing Council (TPC) workload generators? 

This way I could store all the message (under 1mb) inside of this one entity, but I would have to keep track of which entity each user is at (if the user exceeds the 1mb limit I will have to create a new entity). This proved to also not be too efficient because if I send a message to perform 2 gets to see which message entity I am currently at and which message entity they are currently at. From there I must now use another 2 reads to get those entities and another 4 writes to update them both (considering I do not need to create another entity if it is full). I was looking for any ideas to accomplish what I need in a more efficient way. I have nothing implemented yet so I am open to ANY ideas. My main concern is for this to be efficient, Cheers! 

I'm not aware of this being possible with SSDT unfortunately. Depending on how big the project is and how many procedures you intend to enhance with 2012 goodies, it may be manageable with Composite Projects. 

Depending on the size of the table, an index on IsDefault (DESC) might result in one or both of the queries below avoiding a full scan. 

You have a user defined in the database. Good odds someone mis-clicked once upon a time and created the spurious user in accidentally. is the template for any databases created on an instance, so if a user exists there it will exist in all databases you create. Run the script below (on a development instance!) and you'll see a user created in model is added to the TestForModelUser database. 

If you dig into the internals of how snapshot isolation is implemented in SQL Server, the reason why remote access is not supported becomes clear. When snapshot isolation is enabled, up to 14 bytes of versioning information are appended to each row that is modified. The additional bytes contain the transaction sequence number of the transaction that modified the row, along with a pointer to the versioned row in tempdb. A transaction running at snapshot isolation will see the version of a row that existed at the point it started (that exists at the time the first statement is executed, rather than ). It is the transaction sequence number that is used to identify the correct version in the version store. As there is no correlation between the sequence numbers on your local and remote server, it's impossible for the remote server to retrieve the correct version. There are undoubtedly ways a SQL Server to SQL Server connection could manage this first issue, should the SQL development team decide it was worth doing. But there is a second problem, how would you deal with removing versions from the version store? The background process responsible for cleanup again uses the transaction sequence number to determine if a row version is still required. This requires nothing more than identifying the oldest running transaction sequence number and removing any versions that are older than this. With a remote connection... sounds ugly, which is why it isn't supported. Could a different approach be taken, perhaps enforcing or on the remote connection? No, not without compromising consistency as the row at the remote server could not be locked at the time your local transaction started. You could not rely on the behaviour, compromising ACID compliance. Row Versioning Resource Usage and SQL Server 2005 Row Versioning-Based Transaction Isolation contain most of the salient detail. How best to workaround this will depend on what you're trying to achieve. If you can expand on your specific scenario we can explore the alternative approaches. 

I have set up a predefined replication alert (as outlined here) in SQL Server 2008 and the alert for Replication Warning: Transactional replication latency does not appear to work. This is triggered by error 14161. I found a number of posts around the web that indicated this was a bug, but the posts were so old, I'm not sure that it is still the case. Is this still a broken feature? If so, can anyone suggest a work-around? EDIT/ADDITIONAL INFO: I see there are a number of scripts that have been highlighted in similar questions. To refine my question, I'd like to confirm this is a bug and I am looking for a work around that is rather out-of-the-box... that is, just another way to write the SQL Server Agent alert to get it to work... 

If I create a data driven subscription in SSRS and use the query to return some value for the username and password, how "safe" is this password? Let me explain. I am looking to set up a data source on the SSRS Web Portal that uses Credentials stored securely in the report server and Use as Windows credentials when connecting to the data source. This data source, in turn, would be used in the data driven subscription. The user setting up the data driven subscription would not have access to the data source's credential password. I would then like to permit the user to pull a username and password using this shared data source and then use in their subscription as the user/pass to save the file to a shared file area... without the user knowing what the user/pass is. Make sense? If so, is this a risky thing to do, security-wise? (Ultimately I am thinking about using this as a way to consolidate the password for shared file area subscriptions into one place.) Thanks! 

I'm going to approach this answer with a different context to the others, not sure if it will work! A very short answer is that no, they are not good guidelines. You are attempting to reduce a broad, complicated topic to a simple yes/no decision tree that will fit into a forum Q&A. It can't be done. Why not? 

The query returns 1 row so there is no further result set to process. I'm inclined to suspect there is other code further up the stack that's causing the problem. 

A Profiler trace on Lock:Acquired/Released events and/or use of trace flag 1200 on an isolated test machine can be very useful for understanding the sequence of locks applied and released at different isolation levels. 

Sounds like we hold similar views on trigger usage but I'm very interested to hear the opposite opinions from other DBAs. Personally, I view them as a last resort and have only implemented triggers where there is no other option. The exception being INSTEAD OF triggers against views. Triggers are often the only option when you're enhancing a 3rd party solution and the extension points are not exposed by the systems API. Where I have full access to source, I've not yet encountered a situation where a trigger was my first thought. Audit is a good example. In a 3rd party application, triggers may be the only choice. If you have access to source, it is certainly not the only option, though it may be lowest risk/cheapest/easiest (delete as applicable) option. If the database API is well designed, there will be other entry points to add audit. Despite my thoughts on triggers, I wouldn't impose the strict policy you are suggesting. In my opinion, the DBA vs Developer mentality that persists in many organisations arises from the way this type of guidance is perceived. Try to encourage consultation, rather than dictating.