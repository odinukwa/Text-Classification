I am kind of sad you chose my first answer, and did not contest it. So I am going to give another answer as well. I agree with @NelsonAlexander that there are actually a huge range of answers. But, as the comment on my first post on the nature of purpose indicates, I think they fall along a continuum between two stable positions (three if you include simply being a happy animal.) Kant represents one of these quite clearly. The other is best expressed by Nietzsche. Nietzsche's answer would be to diagnose the question as the symptom of an ailment. Why is it difficult for you to accept that whatever choices you make, they will ultimately be for your own self-interest? Some fragment of the wider sense of purpose that we feel as a race is embedded specifically in you. And it has its own agenda. Why not pursue that agenda? Who are you, to question you, when it is pretty obvious the 'other you' is eventually going to get his way, anyway? His answer is that you are under the influence of the will not to be dominated, which has overdeveloped to such an extreme that it has become a will to constantly be dominated by something higher and higher. So, you don't want to be a slave of your body, or of your culture? Be the slave of this religious principle instead? Don't want to be dominated by some silly tenet? Derive an abstract theory of tenets, and be a slave to that! But then isn't there something even better out there? It is an endless tower, and yes, we see better outcomes for everyone when we see more people working from the higher than from the lower tiers of it. But it is not ultimately a solution to the weird yearning to be both subject to and dominant over some imaginary being made of thoughts and impulses. We are all basically religious, in a way that is really hard to escape. That does not mean you have to fall back on what is comfortable for your body, or your society, or that you should just take up a religion at random and ignore this very central human motive. But you, in a greater sense, are already one of these beings made of thoughts and impulses. Why not contrive some way to consciously and conscientiously be a slave to and a dominator over yourself. He refers to this choice as the drive to "Make Art of the Self", and it starts with attempting to derive what inclinations of your own are rare, or complex, and considering what those might mean for everyone else. We see from a succession of Great Creators (Plato, Christ, Einstein...) how clearly divining and expressing those unique qualities, and putting them out into the world, becomes a source of power, and how, even if it does not allow you to control those around you in the present, it might guide multitudes for generations. Even if it is only an inflection on one of these powerful streams, (Luther, Calvin, Wesley...) it may easily play itself out in a way that saves and destroys lives. Since we readily see how much we are already driven by power, even when we distort it into a paradoxical form, we should accept that impulse, taking into consideration these new potential dimensions of power. Our current dependency upon the gifts of the great creators of history shows us how much that developing trend is really not about ourselves, but adds to the lives of the rest of society. 

You can't be sure that there is one. The universe is not made up of separate, non-overlapping causes, in the way a brick wall is made up of separate, non-overlapping bricks. The cause of a cause causes all its later effects, in a way that a no small brick's smallness provides smallness to another collection of bricks. OTOH, does all of humanity have a first ancestor? Because that first ancestor is then the ancestor of humanity, as a first cause would then be the cause of the universe. (Not that I think this is a great argument, but it has legs. Aquinas danced awfully well.) There are even more ways in which 'has a cause' and 'is small' are different. There are not enumerable separate smallnesses. Smallnesses, to the degree we can invent them, would 'nest' and not extend through a specific direction in space the way causes chain together and extend backward in time. etc. So, depending what P1 means, this can be the start of a genuine argument that refutes the parallelism of the supposedly analogous arguments. Analogies have structural assumptions but leave them unarticulated, and those based primarily in language are prone to have completely misleading forms that depend on the similarity of surface structures reached by unrelated grammatical paths. ('cause' and 'small' are not even closely related parts of speech, which is why 'smallnesses' are easy to mock.) So simply refusing to accept an analogy, especially a superficially verbal one, even without pointing out the specific violated assumption, is not necessarily a fallacy. It is a demand for better articulation of the analogies assumptions, which, at some point, will turn it into a formal argument. 

It seems obvious that we project our intentions on the data well before it reaches the point of really thinking. All this error is explained by the success it enables. By being a little too aggressive with our assumptions, we can see things we are looking for faster than we can ordinarily interpret them. It is common for some reaction times to be shorter than would be possible if the brain were to fully interpret the input. Sensory content is clearly afferent, but we do not passively receive information. In fact, unexpected information can fail to register. For many, that means the best theory is that the brain is reaching out into its pool of data to confirm suspicions about what is present. It is not simply observing the patterns that are present and deducing the layout of the world. If there is no suspicion, we may fail to perceive the otherwise obvious. Change blindness seems to be quite the norm. This implies that the ideas of things that are to be checked for may originate in the mind and then get shaped by testing against the outside world, instead of getting incorporated from sense-data. They are sculpted rather than molded or drawn. Inappropriate assumptions are made and then removed when they are found not to fit into the model we are testing against. In that sense, you can say that reaction timing and eye tracking physiology supports the idea that sensory impressions and interpretations are not built up from the data, but originate in the mind, and must be more available to it than sensory data. 

In the strongest sense, an ideology is a specific way of looking at ideas in terms of a chosen motive. It differs from a mere theory in that it makes ideas fit into it, or rather makes them fit together in terms of itself, instead of trying to fit together with other theories as though they are on par with it. So prescriptive religions are ideologies, and to a certain degree so are non-prescriptive religions, (the earlier answer's choice of Buddhism is excellent.) But so are other overarching philosophical constructs like Marxism, psychoanalysis, pacifism, statism, or paradigmatic Science. If you accept them as presented, they propose a given way of manipulating all other ideas and forming your overall worldview into a structure subsidiary to themselves. So to your main question -- the question of whether you are following a given ideology is most easily answered by asking what would cause you to consider it irrelevant. For a follower, the ideology is relevant to any fact or idea even distantly logically connected to it, and the new idea must always be first vetted in terms of the ideology, not the other way around. To the second point -- yes. It is easy to take things that are intended to be ideologies and treat them as simple theories, to consider whether they provide a good way of looking at things under certain conditions, but never using them as a guide to your overall process of learning. This is especially relevant if a number of ideologies impact your life at the same time. Orthodox religious people throughout history have always done this to sciences; theist scientists often do this to religion; old-fashioned feminists and pacifists subordinate Marxism to their own ideology, but can make extensive use of it as a motivating explanation, and may still do this within a more strictly scientific framing based upon statistical observation. Things can get as layered as you choose, but if there is intellectual bedrock, you are following an ideology. 

This idea that we are flawed observers, because all observation is inherently flawed, is also now a basic principle of quantum dynamics. So I fail to see hot this is about the 'exact' sciences in particular. All of our sciences, from anthropology to physics have different ways of counteracting the natural flaws of observation, which become immediately obvious when measurements based on different assumptions need to be integrated. Whitehead, in "Science and the Modern World" declares the excessive reliance upon shareable frames of reference, which mechanizes science, to be one of its more limiting anti-intellectual factors. He spends a good part of the chapters on modern theories of physics trying to lay out how that natural human facility can understand modern science without elaborate wrapping, through native ideas of event and organism that we have Procrusteanized in Western scientific culture. 

I would answer based on the Weak Anthropic Principle. Even within our Universe, space is actually pretty sparsely populated. Some modern theories of cosmology require a lot of nothing. A lot more nothing than just one largely empty universe. So it is probable, in order to support 'something' there are lots and lots of places where there is nothing, or at least virtually nothing. But we, being something, are not close to those places. We would find it hard to exist there, as we require energy flow to maintain ourselves. Even if it were easy to get there and stay around, had we originated there we would not have faced the complex challenges that made us into beings capable enough to talk about it. Our existence is not evidence of the pervasiveness of existence, any more than our body temperature of 98.6F is an indication that this should be the average temperature of the universe. Such a deduction is a premature generalization. That said, we have good evidence that virtual particles exist: that empty space is constantly falling apart into pairs consisting of a positive and a negative version of some random particle, which temporarily exist and then annihilate each other. Observations like black hole radiation and the nonuniformity of cosmological background radiation make this theory likely. That would support an assumption that there is a tendency toward things existing, if only a slight bias. Once energy exists, it does not go away. Without some kind of miracle, it is endlessly conserved. So it is not 'more work' to keep the energy around, taking more complex patterns over time, than for it to have come into being to begin with. It would be harder to invent the negative energy necessary to get rid of the accidentally occurring energy. One current rendition of the Big Bang theory then says it was the bad luck of a particular virtual particle to be trapped in a very small space, and as a result we have a universe. But that eons after that, the star just happens, because the energy released by that trapped particle has to go somewhere, and that star was the easiest place. 

It was Galileo who first seriously suggested we remove the distinction created by Aristotle between two realms with distinctly different physics. In "... The Two Chief World Systems ...", he introduces the notion of the inertial frame of reference, as experienced on a boat, as the normal compromise between the stationary and the moving, and suggests reasoning about the heavens as large moving objects more like boats, and less in an idealized a priori way. Newton had already a century or so of other thinkers inspired by Galileo before he proposed a single unifying law in a mathematical form that would explain both equally well. This included Kepler, who solved the primary problem Galileo's astronomy introduced -- that circular orbits do not capture most of the subtleties of planetary motion, but elliptical ones do. Newton has to have been moved by the quadratic nature of Kepler's astronomical geometry, and Galileo's knowledge that gravity on earth was quadratic. (The rule is captured in the book in terms of Fibonacci numbers, but that breaks down straight into squares.) So our tendency to think this was just single act of genius and not an integration of scientific details, is kind of overstated. In fact, if Hooke is not lying, both of them computed the same position of a comet based on Kepler, by fitting it to a conic section, before Newton's work was published. In the text, Galileo does not seem to employ the principle of sufficient reason per se, but he relies strongly on the idea that needless variation, especially when it must be extreme, is an indication of a poor argument. For instance, if the stars move on the spheres, some spheres spin at different rates than others to achieve the apparently consistent motion of the skies on Earth, the farthest spheres must turn quite quickly, whereas if the Earth spins, then stars at all different distances from us just move at some fairly consistent speed. (He also continually points out that Aristotle himself would not put up with the level of authority assigned by everyone to Aristotle himself. So he may have wanted to avoid dependency on other a priori notions in Aristotle on the modern side of his argument.) Whitehead in "Science and the Modern World" seems to think that from Thales on, almost everyone presumed that physical laws were uniform throughout the universe. He thinks that this notion of trustworthy uniformity is somewhat characteristic of the West, reflected in Greek drama and Roman Law, and is a sort of shared para-religious impulse behind the nature of our science. That makes Plato's and Aristotle's notion of two separate realms kind of an aberration, that was eventually ironed out.