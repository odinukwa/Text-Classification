The one thing I get form this is that the was not forced, PowerShell went with the and bound the text string I passed in to the property. If you want to see the full output of this: 

I would say that SQL Server does care when you change the IP address of your server. It is all based on the configuration of the TCP/IP settings for that given instance. 

Ok, I have not messed with the file share subscriptions so I had to set this up locally on my machine to mess with it. The only thing I can even come across in MSDN that talks about the username for this type of subscription is here: 

To get the information for a single instance you would use value for the function. This will give you the days until the password expires. You can then cast that as an integer and use the function to get the actual date. 

If you are within a domain environment you can setup a proxy account that has permissions on . However, using remote PowerShell is a bit of overkill and adds an unneeded layer to troubleshoot. If you do not have remote PowerShell enabled on both servers and firewall access between the servers configured properly it will have issues. I would simply use UNC paths to the server. Whether you use the admin share like or create share directly to . Unless you want to give the SQL Agent service on permissions to that backup directory you would need to create a proxy account that has the appropriate permissions. Your script will be much more simply if you just go this route: 

This all depends on what product your IT department is using for server level backups. For example, in a virtual environment VMWare will take snapshots of the server. If SQL Server is involved VMWare has an option that most Admins enable (or it could be by default I don't know) that will freeze the IO for the databases during the snapshot. Now while this should only take seconds you have the potential for that to cause problems on your application, and is not really a trusted method to use for restoring database. If you are using a 3rd party product to do server level backups the likelyhood is this is just taking file-level backups of your databases. In that as well it has to have the ability to take backups of files that are locked, because SQL Server has any attached mdf and ldf files locked from Windows perspective. Symantec's BackupExec for example utilizes Advanced Open File Option to perform this, so it can basically take a picture of that locked file. Just the way that sounds will make most DBAs cringe if the have to restore the database with a backup like that, think about the conistency the database is when it takes that backup. There is no guarentee if the backup is fired while a data load process is ocurring, what part of the data load did that backup get? SQL Server native backups are trustworthy to the respect they are verified as good backups. You know exactly what state they were in when you fired the backup for a FULL, whether you have this scheduled around data loads and such. A log backup for FULL recovery model guarentees you can restore that database down the second. If your manager is dead set on using the server level backup I would heavily research the product they are using. I would find out if there is any SQL Server "add-on" or backup agent that can be purchased to let it do VDI backups of the databases. Something to also consider and discuss with your manager is what involvement you will need to have on verifying and troubleshooting if SQL Server backups fail. I have used Netbackup heavily at previous jobs and had a client few years back wanted to me to go through testing use of Netbackup's SQL Server agent for their environment. This included other DBAs that had to also provide support. I told them upfront that troubleshooting backup failures for SQL Server required you to know a good bit about Netbackup. Netbackup master servers generally are run on Unix servers, so you now have to know some Unix....can be fun but more of a pain if you are already busy. Just something to consider and can be a good discussion point with your manager, and find out who is responsible for troubleshooting failures. 

Boring...whoever told you that did not love being a DBA :) Now I am a SQL Server DBA but the market I am in down in Alabama is full of Oracle jobs. It is difficult to get in with no experience. The job openings I am seeing are not folks leaving junior or beginner DBA positions, they are senior level. So you will find job postings that require 5 or 10 years experience. I saw one the other day that wanted 20+ years experience. Getting into SQL Server positions, I'm not sure if Oracle would be the same, is usually done from within the company. You will see system administrators that do minor support for SQL Server and then decide to get more involved with it, then eventually become the DBA for the company. That is how I got into. I did system admin work for about 7 years and then wanted to be a DBA. Since I had supported SQL Server for about 5 of those years I had enough experience to back it up, along with a few certs I had earned. The best thing I can tell you is to start volunteering for DBA work, either within your company or around your business community. 

The problem you are experiencing is with the PowerShell subsystem in SQL Server Agent. It is a bit flakely with using other modules becuase you are put in the context of the SQL Server PowerShell Provider (SQLPS.exe). So it works the same way as if you opened up and then try to execute your code. One thing to keep in mind with dbatools module is that it will conflict with both SQLPS and the module that MS now maintains separate for SQL Server. Last I checked the main thing that it conflicted against was TEPP that we have in the module now, it just can't load that code. [Caveat: I'm a major contributor to this module.] The dbatools module has custom types and styles built in so when you run the scripts under PowerShell host that also has SQLPS or the SQLServer module imported your results will vary. To utilize dbatools in a SQL Agent step make sure you only use the CmdExec subsystem (step type) and then call PowerShell host to execute your code. If you do not want to maintain a file for each script you can put your code in a SQL Agent CmdExec step in the manner illustrated below, but more complex script it is easier to maintain via files.