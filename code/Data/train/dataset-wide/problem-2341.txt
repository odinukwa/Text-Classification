Do you want to perform the update once or on a regular basis? If the update on million rows is done once, then the best solution is to create a temp column "processed" on #testing2 table of bit (int,tinyint) which will serve as your null filter. The index on bit or int columns works a lot more optimal than on varchar. Also, having 2 type of values on index definition (0 for null 1 for not null) will be very fast. Keep your indexes and add the second index and you will have the following Plan if you change the filtering options in the query on "processed" column as it is marked in the picture below with the plan: 

Also, important stuff to pay attention to understand the different behavior: are the DB2 and DB3 identical in minor versions of MySQL? You only provided the major version which is 5.6. But from 5.6.6 there have been some important changes mainly on this issue. The replication to DB3 is done using the binlogs created by DB2 and applying the sql_mode specified on DB3. So these should be checked and seen what exactly is trying DB3 to replicate from the binlogs created by DB2? Can you paste the query here? Out of curiosity , if you test an insert from DB1 to DB2 and it goes ok, mysql doesn't throw any warnings? 

Some things to check, read up on, or try not knowing the Server OS version, etc. (Sounds like a Windows Update broke something with the OS and SQL error log is catching it (extended event notifcation) but perhaps not able to send a notification, etc.) 

Can you point the 'full path' to the UNC path i.e. instead and see if that works? Just like when you map the "X" drive to just use that in the full path of one of your packages and run to see if it'll work. If one of your jobs work like that (assuming most all are setup the same and this way, etc), you can probably script out the SQL Agent jobs through SSMS by pressing F7 (once SQL Agent jobs is highlighted), selecting them all from the right pane window, right click, then create to new query window, then do a mass CTRL+H and do a find and replace to replace with , and then run that. Just be sure the SSIS proxy account or the SQL Server Agent account has appropriate NTFS and SHARE permissions where the SSIS packages reside to read them. 

For addtion, when you delete some rows in table. Table will be fragmented. Remove the fragment will make your table is shinked. Optimize table like Ike Walker said will help. Optimization table makes downtime for mysqld. 

I am using mongo 2.6.7 I deploy a sharding cluster follow the guide: $URL$ My sharding cluster include: - two replica sets (one primary + one secondary for each replica set) - three config servers - two mongos I make sure sh.getBalancerState() is true. I prepared a amount of data about 1G. When I recheck by sh.status() 

I only get data of testshard from test_repl_set and there is no data of testshard from test_repl_set1. I don't know why testshard is not being migrated and why mongos tell me there is only one chunk on test_repl_set1 ? 

Some people tell me that the backup database on-the-fly using rsync is possible. I think it is possible but not safe because some log, buffer... is not flushed. Database is being recovered from the backup would not consistent. Actually I am not sure why the backup using rsync is not safe. Could anyone explain me the underlying of mysql for the reason ? 

Following Gaius post: You can create an .SQL script which does what you need with use db in front of the script -> create a SQL Agent job of Operating system type which calls the script: sqlcmd -E -S SERVERNAME -i"c:\YOURSCRIPT.sql" -o"C:\YOURSCRIPT_LOG.log" Add new step and use msdb.dbo.sp_send_dbmail procedure to send email. This feature can be customized to display inside the mail a specific query from SQL tables to confirm the execution of the script... for example dbcc showcontig of your rebuild indexes. 

I don't think you can find this by an easy way but it is possible anyway to get through this. Profiler offers many event class types that can be used in analyzing the performance of a query. Start a new Profiler session and check following events: 

I think you are misusing the explicit_defaults_for_timestamp. In your case this variable should be set to 0. Enabling it you are in fact restricting the insert of Null values into timestamp data type columns. $URL$ 

once the filter is activated, slave server will skip all the statements which meet the given pattern. but before doing any change read how MySQL handles replication rules because you can skip important tables if you don't understand the rules. 

Additional Resources (These articles seem to have some references to potential parameters in SSIS package areas to set for smaller transactions, etc. The titles or the steps may be for a different ultimate goal, but there is potentially applicable content in these for what you may need to change in your SSIS logic to rectify your issue so these may be worth a simple read.) 

You can also run this adhoc this way without SQL Agent scheduling specifying the correct DateTime variable when you want it to stop. Once the process has run, you just go to the file and open it as usual. See script logic at bottom with comments on how to confirm this isn't running any longer, etc. -- any traces for that matter and how to stop them from running if they are. NOTE: In my case we scheduled this job start with SQL Agent job at 7 AM and then put the DateTime variable value for the @stoptime argument passed to the sp_trace_create object so it quit running at 8 AM on this day. Once in the office and reviewing this, we were able to sift through and determine the issue and correct. We filtered our trace criteria down as much as we could though beforehand when we built the script file that saves to disk to give the TSQL for scheduling. 

I have implemented a cluster include three nodes: two stored nodes and one garbd (also haproxy - load balancer). Some information about servers: SSD 480G Raid1 Memory 32G Swap 16G 2xCPU, number of cores: 24 Maria Galera Cluster 10.0.14 mysqld process consume CPU percent so much 229.3% - 300% The highes CPU load 20-30. When CPU load grow up, there is some log like that. 

I have read about balancing window in MongoDB document. I see mongo tell about how to modify balancing window but I don't see the default of balancing window. I see only one document about chunk size in collection settings in config database. Do you know the default of balancing window ? 

Some people tell me about mydumper. I have not used it before but it is very hopeful. About mydumper: 

Some bulk data loading tips from mysql document is possible useful. $URL$ You can increase insert speed by some ways: 

I am using MySQL replication with GTID. I did mysqlbinlog to see some binary log. This is a section in binary log that I am considering: 

I don't know why galera get cert fail because I am using master-slave. There is only node receiving writeset from clients. Some solution I am applying: