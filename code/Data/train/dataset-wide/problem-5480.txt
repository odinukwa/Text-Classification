While not a criminal case, you do allow for "ideas." The Trolley Dilemma is a classic in the realm of ethics. If not familiar with it; the general idea is there is a trolley on path to strike and kill 5 people. You have the ability flip a switch in order to switch tracks before the catastrophe, although on that track is one person who would consequently be struck and killed. The choice and the reasoning behind it can be attributed to several different notions of ethics and morality. This website gives an overview, options you have, and the corresponding view of morality associated with said options. $URL$ 

I think that with your interpretation you are adding in travel between these realities as well as between times. If indeed we can be this omniscient time traveler we could (almost) all find "our price" for betraying our morality and settle in that reality/branch of decisions. Before now I do not believe I have heard of an interpretation where we can have this ability. If we had this power even in our own single reality, I'm sure we could also find a perfect path for ourselves among the near limitless options in front of us. While a lot of people here may have some inherent problems with the notion of asking a "should/shouldn't" question, I would have to agree that it would be within our best interest and potentially the best interest of humanity itself to explore a lot of these options before "deciding." As for your final question. We are certainly hampered or limited, whether for better or worse, by our reality and the constructs within. Note that some of these will certainly be for the better though. For every "good" scenario stemming from the many worlds theory there can be at least just as many "bad" realities. 

The box and the diamond are duals in this logic, so we introduce the abbreviation: ♢φ ≡ ¬▢¬φ. Now we're ready to invalidate (1) in (S5) in this 2D framework: 

It appears that "nothing" is a subject in these sentences, i.e., a thing about which other things are said. But actually the semantic value of "nothing" (i.e., what "nothing" contributes to the meaning of the entire sentence) is not some object, but a function from sentences to truth-values. "Nothing", like "everything", "no one", "each day", "exactly one", and so on, is a generalized quantifier. Before getting to the particular cases (1–2), let's look at a standard way of giving the semantic value of "nothing": 

Since S and ¬S are inconsistent they cannot both be made true, therefore, whatever else may be contained in Γ and whatever Q may be, it follows that {S, ¬S,...,Sn} &vdash; Q. It is an immediate byproduct of the classical definition of consequence. There are, of course, many non-explosive logics, such as Belnap and Anderson's relevance logic where from a contradiction an arbitrary Q isn't allowed to follow because implication has to meet special 'relevance' requirements. Look at that last SEP article for the details on how exactly that works. Most relevantly, there are many paraconsistent logics specifically created to handle this so-called 'paradox' of material implication. Worth checking out. 

Forgive me from straying from symbolic logic, but I think your answer is found without it. Sometimes the system of symbolic logic can be a little deceitful when we are using it as more of an equation separate from the underlying meaning of the words. To doubt something is to cast uncertainty towards something (idea, fact, conclusion, etc). I doubt you are taller than me. I doubt "that" is a fact. I doubt "it" will turn out that way. etc. This doubt comes from within your mind. In order to doubt something that is also within your (rational) mind you need to again be uncertain about whatever that is. For example, you can doubt your ability to do something. To "doubt your own doubt" you must be uncertain if you are uncertain about something. It is incompatible. There may be a "certainty scale," however "certain" is an absolute while everything else is uncertain. When one begins to doubt their uncertainty, they are still uncertain and therefore their original doubt is not actually doubted. It becomes a redundancy. When the scale begins to tip towards your doubted doubt becoming a certainty (no longer in doubt), it eliminates the uncertainty of the doubt towards your original doubt. Note: wording gets a little tricky with so many "doubts"... I will try to reword ASAP if not understood correctly. 

The shape of the conclusion suggests that we attempt to prove this directly: by assuming the antecedent (P ∨ S) and trying to derive the consequent (Q). So assume (P ∨ S). Now we proceed by cases: assume P and get some conclusion X, assume S and get that same conclusion X, and conclude that X. 

To say F of Socrates, that is, to say that Socrates is an Athenian whose name is 'Socrates', you simply predicate F of him. F, extensionally speaking, is the set of all those Athenians whose name is 'Socrates'. Presumably Socrates was an Athenian named 'Socrates', so Socrates is a member of that set. That makes the predication F(s) true. The further claim, namely that Socrates is the Athenian whose name is 'Socrates', requires that there be no other person who was an Athenian and was named 'Socrates'. I personally know a Greek person, now alive, who is called 'Socrates', so the set F contains at least two individuals: the famous philosopher and this Greek guy I know. That means that "Socrates is the Athenian whose name is 'Socrates'" is not a good definition; it's similar to defining 1 as the closest integer to 0 (not including 0). The lesson is the following. Even if F was a singleton set containing Socrates the philosopher: 

All that (Probability-)Frequentists mean when they claim: "The next coin toss (that is executed under conditions X) has a probability of 90% to land heads" is really: "The next coin toss belongs to an infinite sequence of coin tosses that are executed under conditions X, and which have the limiting relative frequency 90%." or Whether they actually mean something different and I just missunderstand them 

The or rather one of the Frequentist interpretations of probability claims that the statement "The next coin toss )that is executed under conditions X) has a probability of 90% to land heads" simply means: "The next coin toss belongs to an infinite sequence of coin tosses that are executed under conditions X, and which have the limiting relative frequency 90%." Let (x1,x2, .... ) be the infinite sequence of coin tosses under condition X. My question now is why this should give me any confidence that the next coin that I am interested in (and that is executed under conditions X) will land heads. It seems to me that the 90% are only relevant to my single case, if I make the additional assumption that the next coin toss that I am considering is somehow randomly chosen from this infinite sequence. Or alternatively I have symmetric evidence that the next coin toss be x1 or x2 or x3 or ... . However I have never read anything similar to that from a defendant of the frequentist notion of probability My real question is therefore whether: 

Another method would be to use valuations (truth-tables). We want to show that v(¬(A ∨ ¬(A ∧ B))) = 0. The useful fact is: v(¬φ) = 1 - v(φ). We proceed as follows. 

With these we can define what it means for a formula φ of propositional modal language to be true in a Kripke model with respect to a world of evaluation: 

There are lots of other points of similarity and contrast between modal and non-modal languages. Familiarity with graphs, trees and induction would be helpful, but since you have some experience with first-order logic, I would recommend that you just jump into the study of modal logic without preparing for it. (Keep Enderton on the side if you come across topics you haven't seen before.) 

I think you might misunderstand what is meant with long run frequency: Consider the case of a coin toss. According to the Frequentist notion of probability, a coin toss has a probability to come up heads because I can repeat it many times under similar conditions, which will yield an approximate estimate of the probability. One way to imagine this is that you make some random draws from a box that contains 0s and 1s (with replacement) and you don`t know the proportion in the box. (1 denotes tails, 0 denotes heads) Furthermore a (Probability-) Freqentist will claim that it ONLY makes sense to talk of probabilities in cases where you can actually repeat your experiment under similar conditions! So to come back to your case: What would the repetition under similar circumstances be in your example, or framed differently from which box are you drawing? Whether blue is a more popular colour than red does not depend on randomness at all, you will always obtain the same result (given the opinion of people does not change, but if it would, you would test a different hypothesis) You will always obtain the same answer: either yes or no. (So maybe you can even say that it has probability 1 or 0). Maybe another example makes it clearer. Can a Frequentist sensically talk about the probability of a coin to have probability 0.7 to land heads? The answer is, it depends. You might imagine a situation in which someone offers you a game: He will first draw a coin randomly from a box with various coins. And he will then toss the coin 10 times. If #heads >5 he wins, otherwise you win. In this case it makes sense for a Frequwntist to talk about the probability of the coin to have a probability of 0.7 to land heads, because the probability itself is a random variable, it depends on which coin is drawn from the box! The probability of the coin to have probability 0.7 is then simply the long run frequency of obtaining a coin that has the long run frequency of 0.7 to land heads. But now imagine a different scenario. Someone offers you a similar game: He tosses 10 times with a given toss and if heads >5 he wins, otherwise you. (Which coin he tosses with is fixed) Then it does not make sense for a Frequentist to talk about the probability of the coin to have a probability of 0.7 to land heads! It is always the same coin, its probability to land heads is not random, it is fixed. It is important to note, that for the Bayesian it does make sense to talk in a probabilistic way about the hypothesis "blue is more popular than red". Because if we claims: "I believe with a probability of 0.5 that blue is a more popular colour than red", then he simply expresses his own subjective ignorance on the subject. Even if a parameter (such as the truth or falsity of your theory) is fixed, it might simply be that we don`t know which value it has, and it is this lack of knowledge Bayesians express with probability. The Bayesian does not demand that the experiment be repeatable under similar conditions for a probabilistic statement to make sense! You can always express your beliefs about something. 

doesn't require an intensional treatment, because concept(x) could simply denote the of x in a given world. That being said, I think an intensional interpretation of concepts is much stronger and therefore less susceptible to criticism. The criterion above can be slightly modified to work in a possible worlds framework exactly as you proposed. I'm not familiar with any objections to the intensional interpretation of this particular criterion of analyticity (Kant gave another two: one also in CPR A7, another in Prolegomena p. 266). But there might be. There are lots of different ways of explicating analyticity; this is just one, old version of it. Carnap has more interesting formulations of it (see, for example, Appendix B of his Meaning and Necessity). Since Quine's "Two Dogmas of Empiricism", analyticity has been subject to a lot of debate. But Quine's attack wasn't against any particular formulation of analyticity, but with the very distinction. If you think there is such an informal distinction between analytic and synthetic truths, then you will not find Quine's objections problematic for this intensional formulation of Kant's criterion. If you're interested in the messy details of this debate, G. Russell's Truth in Virtue of Meaning is a very readable, recent defense of the analytic/synthetic distinction. I highly recommend it.