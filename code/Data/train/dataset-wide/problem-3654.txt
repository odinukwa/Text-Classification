In this example, the device connected on interface will be able to communicate with the other one connected on the , even though they are on different vlans (and that default route is not required). 

You can easily find nowadays Layer 3 switches, i.e., switches with routing capabilities. It works by creating virtual interfaces (vlan interfaces) with IP addresses. Just doing that you create entries on the switch routing table (yes, as I've said, it behaves as a router!) and the vlans will communicate with each other. You can add static routes (as a default route pointing to your firewall, for example) or even enable a dynamic routing protocol (ospf, bgp...), depending on the hardware and firmware available resources. And your hosts and servers can use this switch as their default route. Here is an example on a Cisco switch: 

I set Outlook to move every new email from the Exchange server to my computer (i.e., in a local PST file). When I upgraded from Outlook 2007 to 2010 my rules were not listed in my E-Mail Rules tab anymore, but I know they were hidden somewhere, as my emails were still being classified and filtered as before. I ran the as suggested by Bart and the old rules were gone, but when I added new ones they weren't shown either... darn. To solve that I had to create a brand new PST... then the rules issue was fixed. 

This is the rule I use here (and working fine on several routers), using an empirically based method: 

Clearly, it takes some resources to run . However, the amount of resources it needs is tiny, so the performance impact will be negligible (probably not even measurable). If we take Linux as an example, all does is read a couple of small pseudo-files in , format their contents and print out the result. 

How do I establish that the session is indeed authenticated? How do I go about troubleshooting this further? 

I am trying to configure Postfix so that it would accept mail from authenticated clients outside . When I try to send a test email from my iPhone, which is configured to use port 25, SSL and password authentication, the mail gets rejected by Postfix. I get the following in : 

The measured throughput is 1.3Gb/s. This is 7.5x below the theoretical maximum, and only 30% faster than 1GbE. What steps can I take to troubleshoot this? 

What exactly is the meaning of and ? for writes is 72 seconds(!) -- would you say this is abnormal and, if so, how do I go about troubleshooting this further? 

I have two Linux machines, each equipped with a Solarflare SFN5122F 10GbE NIC. The two NICs are connected together with an SFP+ Direct Attach cable. I am using netperf to measure TCP throughput between the two machines. On one box, I run: 

I am seeing the following messages in my server's . They look like stack traces and are not preceded by any narrative (e.g. "such-and-such has gone wrong"). I am almost certain they are related to I/O problems I am experiencing, but it would be instructive to understand what exactly these messages are and what triggers them. 

I also changed the somaxcon config of my Ubuntu. Can someone please help me to hit a higher limit for my MYSQL server ? Because currently my Processors are only at 10% and my RAM at 6GB out of 64 and MYSQL is slowing my website/api down (too much traffic). What is the "perfect" config (I know it doesn't exist). Oh and I am sure the problem is on that server ; everything runs smoothly if I cut all MYSQL connections and only use my Mongo/Redis ones (each service runs on a different server). Please help, I am tearing my hair out. Please tell me if you need any screens from MysqlWorkbench. 

I Currently have a service with a very high traffic (about 1000 connections/second, and this is not reducable with optimization anymore). Until 1 week ago, I was at AWS and had twiched some of my apache/NGNIX configurations to handle that load. There was no issue at all. I now want to change host and I went with OVH ; the new server config is 4x better than the latter (128GO RAM, 24 Core last gen processor with 30mb cache...) Now comes the issue ; on the new server I somehow get 503 errors (by apache) as soon as I pass the 600 connections per second. - First of all : Of course I know I must loadbalance the connections and I intend too ; but I want a clean config before i replicate it. - Apache is configured to handle 4000 concurrent connections and it does when I stress test simple So my Hypothesis : - Either OVH (new host) blocks my internal connections when too often. But they tell me they only block if I go over the 1GB/S bandwith (I don't - far from it) - Either Apache configuration is a bit different and makes server go into 503 faster than before (maby it doesnt like the 0,5 second between connecting to mysql and getting an result). Indeed there is a major difference ; on the new server (Ubuntu) my apache is behind an NGNIX reverse proxy and is in a docker-container whereas before it was a simple LAMP Does someone have an explanation of what is happening? I am totally lost & depressed. Thank you so much in advance. 

The plan for the two WAN interfaces is as follows. All outbound traffic will go to the primary, with exceptions based on destination IP/subnet or possibly on src+dest IPs/subnets. Such exceptions should be routed to the secondary. It would be very nice if, should the primary go down, the secondary would automatically take over for all outbound traffic. I am reasonably sure that I can put something together based on dd-wrt. However, I'd like to hear from you what alternatives are out there (especially something easier to set up for my use case, even if it means paying more for the hardware.) 

After much experimentation it turned out I had to add to (not to be confused with ). This has fixed it. 

I have an NFS3 server with multiple clients. Each client is sequentially reading a different large file, and performance is very poor. Here is what I am observing in on the server for the disk where the files reside: 

As you can see, is 100%. At the same time, the aggregate I/O throughput () is about 18MB/s, which is 10-20 times slower than what the disk is capable of. This, and the ratio of to , lead me to conclude that instead of reading large chunks of each file at a time, NFS ends up reading the files in smallish chunks with lots of interleaving of chunks between different files. This in turns leads to lots of disk seeks, killing performance. Would you say the conclusion is justified by the evidence? What would you recommend as a way to address this? I can change the reading app, and can tweak NFS settings on both the server and the client. I am using RedHat 5.6 with kernel 2.6.18, which I believe limits to 32KB (I'd be happy to be proved wrong on this). edit: This is how things look when there's only a single client reading a single file: 

The answer were the backlog configurations. You can find some on your linux system (on your docker) but also on mysql, on mongodb ect... When you have high traffic, you need to twitch those settings as well. I also changed the limit of TCP connections ; by default these are limited by Linux. 

I am looking for some help to twich my MYSQL server. I am running a 5.7 MYSQL server on a 64 GB high end processor server (nothing else on it) and I just am unable to set the config for it to use all available ressouces. So first off, I know I should soon replicate the server and have Slave/master Mysql - ill do it as soon as I exploit my first server fully. I also spent weeks in optimizing the queries and different caching (apache side) to limit the amount of queries. Now I need to make some config for it to be nice. The situation; I have a huge amount of traffic and a huge amount of queries - and mysql seems not to be able to handle it anymore. I currently run at around 700 Selects/second (only 20 Updates and 30 Inserts) (My website and apache runs at 3k simultaneous connections). My first thought was MaxClients that I took up to 250; I however noticed that I never have over 7 simultaneous "Connections" (says MysqlWorkbench). I tried understanding things the "Performance Report" tells me but I do not find any wierd numbers. This is why I need your help. This is the current configurations I did for MYSQL :