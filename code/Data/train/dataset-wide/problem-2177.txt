I recently had to do essentially the same thing, except that I wanted to migrate MySQL tables and data to SQL Server. I tried: 

As you learn more about SQL Server you will discover (to your delight) a number of things you can do in SQL Server at the database level that you previously had to do in Access at the application level. Some examples include: Triggers: Procedures defined at the table-level to make stuff automatically happen whenever there is an INSERT/UPDATE/DELETE on the table. Stored Procedures: Somewhat similar to Access macros and those little VBA procedures (s) you built in Access to do "useful stuff", except that in SQL Server they are part of the database itself. So, you can write a Stored Procedure (SP) once and use it (almost) anywhere, even across applications that share the same database. Functions: These are somewhat analogous to the little VBA s you wrote in Access to incorporate into queries, except that SQL Server Functions, like SPs, are more tightly bound to the database. Also SQL Server Functions can be Scalar-valued (return a single scalar value) or Table-valued (return a rowset). Fun SQL tricks: There are lots of SQL features available in SQL Server that are not supported in Access (Jet/ACE) SQL. "Common Table Expressions" (CTEs) and " and " are the ones that gave me "'aha' moments" as I was getting started. I could go on, but these are the things I remember discovering early on that got me "thinking in SQL Server". Don't get me wrong, I still think Access is an excellent tool when used appropriately, and should be given serious consideration as a way to 

I know that transactions are meant to group several operations as one. But if for example in the same table one transaction does 

When having a table in SQLite that has a data type, is there any implication if the length of the contained string differ significantly? 

If you have a big table that you want to partition and you have 2 candidates as the partitioning key (in the sense that 50% of the queries use one column and 50% of the queries use the other column and almost no query uses both in the same SQL query unless all the code is rewritten to do that) how can one determine which key is the best candidate to be used? Does it matter for example if the "entity" that one key represents is "fixed" and the other is constantly increasing? E.g. as an example of what I mean "growth" (taken just as an analogy of what I am asking) if you have decide between using the doctor id or the patient id as the partitioning key where we can have only so much doctors but infinite number of patients 

OR do I need any transactions or locks for the DELETE vs INSERT/SELECT? It seems not but I was thinking I may be misunderstanding something Note: My question is not about transactions and their benefits.My question is if 2 statements from different processes on the same table SELECT/DELETE need for any reason to be synchronized 

Sometimes the before insert on payments will trigger an update to the main record which fires my BEFORE UPDATE trigger which selects the total payments into for it's own conditionals. However, at this point is from the this perspective because the insert on payments hasn't completed, but this isn't important. What's very odd is that the @amountPaid variable in the payments trigger is now 0. So now I'm curious as to how scope works in MySQL? 

This application has stopped responding a total of 3 times today, a couple hours apart. All three times the other applications which connect to this database server continue to function normally. The first time it happened I didn't get a chance to look at mytop before restarting mysql, but the other 2 times I had mytop running on another monitor and watching it and connections piled up both times. We're a small company, and do not have a DBA. I'm a developer and have been able to manage and troubleshoot MySQL over the last couple years, but it seems as we grow we're running into things that I just don't have the experience to resolve, I'm talking to the owner of the company about hiring a DBA consultant to help fill the gap in our development team, but in the meantime I have no idea where to look next to continue to troubleshoot this and would really appreciate all the help and advice I can get at this point. 

I read that I can have different isolation levels per connection and in the server. The default isolation level is REPEATABLE-READ. So if I have a transaction that issues a to the client connection, how does it interact with other transactions from other client connections? Do they all end up being serialized? From set transaction seems not: 

When using triggers, if an update is done to a table then a trigger is executed. This is very convenient. But what I would need is to execute an external script. Is it possible to configure MySQL somehow so on a trigger/change of a value in a table an external process/scrip is executed? 

But this seems useless to me. I mean if I set serialized to a client connection then I would want all currently running transactions to be sequential, right? Otherwise what's the point? 

I have a table with a column that is of type . I am doing the following filter which can not use and index: 

I read somewhere that InnoDB can store all the tables in a single file or in separate files. Is this a configuration option? What is the default setting? A file for all tables or a file per table? What is the recommended setting? 

Can someone please explain why the delete shows a different number of rows than the count? I am using the same join. Are they not equivalent? 

I work in Transportation/Freight and we have these things called "PRO" numbers or freight bill numbers, which you can think about as and Invoice and Tracking number for a shipment. Our carriers send us blocks of 2,000 sequential PRO #s at a time. Previously, we'd just work from Excel and mail-merge basically just printing off the barcode and changing the cell's color to keep track of what's been used. We want to automate this process now in the system that creates the shipping documents. Creating the list of PRO #s in MySQL is easy. The problem is that each PRO # can only be used once, but we have multiple people generating shipping documents at any given time. How can I retrieve a single PRO # from the database and be certain I've only ever used it once? I'm open to other solutions that are not based. Maybe I can game the system MySQL uses and use an based system? That would possibly be easiest to implement but I think it could possibly cause problems and could possibly get quite messy and tedious to maintain. EDIT: This is a Multi-Tenant system and transactional as well. 

I have a couple triggers that automatically update invoice data and set some statuses in the database. However, it appears that if 2 Triggers have variables that are named the same, they get overwritten when one trigger performs an update the causes the other trigger to run. For Example, My BEFORE INSERT trigger on my payments table sets the variable 

Edit I just ran another test on a sample table of 400,000 rows and the code above completed in under 7 seconds 

Otherwise the characters really are converted to question marks if SQL Server is unable to map them to corresponding non-Unicode characters, even in an column. 

Unfortunately, no. The basic Find (Ctrl+F) and Replace (Ctrl+H) functions in the Access UI search the resultset of the form row-by-row. For an ODBC linked table (any ODBC linked table, not just PostgreSQL) once Access has gone past the end of the rows that it pre-fetched when it displayed the form it retrieves one row at a time until it finds a match or reaches the end. (Find and Replace is often considerably faster for Access linked tables - as opposed to ODBC linked tables - because the Access Database Engine works directly with the database file, retrieving 4KB pages of data at a time. If consecutive rows happen to be on the same page, or if the 4KB page for a given row has recently been cached, then Access can "get" that row without another round-trip to the database file.) However, there is one workaround that may be helpful: If a Filter has been applied to a Form or Datasheet view then Find and Replace operations are restricted to the filtered rows. Access can take advantage of indexes and (at least some) server-side processing when applying a Filter to a form bound to an ODBC linked table, so you might be able to get the job done faster by Filtering the records first (even a non-sargable filter such as ), and then performing the Find and Replace on the filtered set. 

Started having issues with our central production MySQL Database Server today. We have 1 central production MySQL 5.7.11-log server which is bare metal with 32GB mem and 12 core CPU with 2 SSDs in RAID. This server houses 3 databases which are each used by 1 VM running Apache for Each of our custom Web applications (total of 3 VMs running Apache). One of the Web servers started to slow down this morning and after a few minutes came to a halt entirely. The other 2 Web apps continue to function and perform normally. We started digging in Apache, restarted the Apache daemon, no effect, restarted the VM with no effect. I restarted the MySQL daemon and the app starting running fine again. A couple hours later in happened again, I restart mysqld and we're good for another couple of hours. I've dug through Apache logs, PHP logs, MySQL logs. The only thing that stands out in the mysql error.log is there is nothing in the other logs I've looked through and been monitoring today that looks out of place. I've been staring at htop, iotop, iftop, and mytop all day and server load on MySQL and the Web VM remains well withing what is normal on any other day. One thing I do notice is in mytop as the slowdown is happening I see a lot of connections piling up from this Web app, almost as many sleeping connections (22) as there were connections waiting or creating (21). 

These block each other but not always! I can not understand this. These refer to different rows why do they block each other? 

id is the PK of the table. These statements execute without blocking each other. Makes sense since they refer to different rows. Next: 

Databases use the file system to store the data. As far as I know it is not possible to delete a record from a random access file. So does that mean that when we do a the size of the table i.e. the file that stores the table never decreases? So databases essentially keep growing and never reduce in size? 

I have noticed that even on huge tables with millions of records when I do a the index is created immediately (I get the console back in nsecs). Why is this? Doesn't it create the B-Tree with the table data at that point? I can only assume not due to the immediate return of the . But then how is the index created? On each access? 

Let's say I have an entity which has a location as part of its attributes Now a can have N of other that are close by. So seems to be a self referencing relationship 1-N (optional) If we know before-hand which exact are close by each other what would be the best way to represent that? Since we have a self-referencing 1-N relationship I think another table would be needed In this case we would store e.g. etc to show that pizza store with id 1 has 22, 23 and 78 near by etc Now in order to get these rows back in-order I would need to create a PK and query based on that. I was wondering would an auto-increment guarantee the insertion order? Or would I need to use a float representing the distance e.g. (where 2.04 is the distance in miles) I was also thinking is there a better way than this? We know that if is close to then is also close to right? Is there a more efficient way to represent this information? I think it would suffice to store just the row to capture that is close to and that is close to . But this way we are losing the order Update: All the answers are very useful. One thing though that perhaps is not clear. I already have the order of the entities based on the distance on insert time. I.e. I have a set of ids of objects already sorted based on distance and I want to insert this set in the database in a way that I can retrieve the rows back in the order I have inserted them. I want to avoid sorting on distance on retrieve since I already had the order at insert time. These ids would be used to join to another table (they are ids) and I want to retrieve the rows in the insert order 

Note that the query uses syntax, which is generally preferred over the older method of putting the join conditions in the clause. 

If you want to insert Unicode text in your statement you need to supply a Unicode string of the form , as in 

An "After Insert" data macro can certainly modify records in other tables. You can use the LookupRecord, EditRecord, and CreateRecord Data Blocks as required. However, a data macro cannot run a VBA script. Your actions are limited to those available in the data macro environment itself. 

Instead of trying to insert directly into the table you could insert your data into a temporary table ... 

Finally, even though you will be working with SQL Server 2005 I highly recommend that you get a copy of SQL Server 2008 (or 2012) Express for learning, mainly because of the IDE enhancements in SQL Server Management Studio (namely, auto-completion and interactive debugging). Just be aware of any newer (2008+) features you may encounter and don't rely on them for your production code. (Or, use them as bullet points for your pitch to upgrade from SQL Server 2005....) 

Yes. The Access Database Engine is designed to work with "real" Windows file sharing and Samba – or at least some versions of Samba – apparently do not implement all of the low-level features of the SMB protocol that are needed for the Access Database Engine to work reliably. (ref: Corrupt Microsoft Access MDB Causes - Samba)