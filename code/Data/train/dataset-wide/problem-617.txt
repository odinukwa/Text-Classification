As others have mentioned, when ESA eventually comes up empty-handed and their deception is revealed, they will have neither respect nor funding, and end up a disgrace not only to the EU but to the entire scientific community. My advice is therefore don't even try. 

You are correct in assuming that "the primary obstacle is something something signal diffraction" The way to think about diffraction is something like this. Imagine a wave of light headed towards you. If the wave hits one side of your telescope before the other, then you know that it must have come slightly to the side of where you are pointing. However, if the angle is so small that the difference in between when the wave hits each side of the telescope is less than the wavelength, then you can't tell that one hit before the other. You can only get around this by making your telescope larger to exaggerate the difference. Although the precise number depends on the shape of the telescope, the minimum diameter required can be approximated by: $$ D = \frac{\lambda d}{b} $$ Where $d$ is the distance to the target, and $b$ is the desired resolution. We can plug in some estimates for the quantities, assuming that the distance is from Earth to the Alpha Centauri binary, the resolution is typical for Earth-observing satellites, and a wavelength in the middle of the visible spectrum: $$ \begin{align} D &= \frac{500~\text{nm}\times 4.3~\text{ly}}{15~\text{m}} \\ &= 1.4\cdot 10^6~\text{km} \\ &\approx 0.01~\text{AU} \end{align} $$ The required size scales inversely with the resolution. To get the same $0.5~\text{km}$ resolution as a next-generation geostationary imaging satellite the required size is only $42\,000~\text{km}$; but to acheive the $30~\text{cm}$ resolution of modern satellites the required size balloons up to $0.46~\text{AU}$. Atmospheric turbulence (seeing in astronomical parlance) is not an issue here. As usual, Randall does a good job of explaining this. So to detect human-size targets you would need a telescope the size of Venus's orbit constructed around one of the stars, and to detect an aircraft carrier you'd need a telescope just slightly larger than the Earth. 

Edit: to be more specific, the context and usecase of this technology is that user input is now handled through some sort of a matrix of electrodes implanted into the brain, capable of reading the user's brain activity/thoughts. The software handling the output of this matrix already tries to transform brain activity to some sort of "universal brain language" that covers up the differences between human brains, but still requires an analog/real numbers/wave signal for fine precision (not as in error-free, but as in descriptive) and high throughput. Analog signals were chosen because the brain can easily recover from small errors and discrepancies and because it is more similar to the way the human brain works, but due to limitations of the feedback system, "lag" and slow transmissions is something that you would generally not want to get in your wetware, which is why digital signals were discarded: the electrodes array requires a continuous stream of data, so buffering and processing something to compress it and send it over the network would make the brain "halt" waiting for the next signal, essentially damaging your psyche on the long run (think of becoming deprived of your senses or getting mind-frozen in place every two seconds, which is what the digital transmission could do, compared to seeing some static in your viewport every few seconds, which is what you could get when on analog). This is also the reason computers perform operations on their continuous output analog stream concurrently, to reduce the time the user waits for a reply. It is also the reason all algorithms that directly read from the user wave are also concurrent: it is better to update the wave late than to halt it until the answer is processed. In addition, due to the nature of the brain, a thought or sequence of thoughts can be read and predicted as it is being formed, but can't be confirmed until it is fully formed. This detail is extremely important, as the plot device is based around this fact. Think of the exchange of information between a computer and a human as a regular conversation between two humans (it would be more like telepathy, but for simplicity's sake, let's assume they are just speaking). 

In imperial units, a mile is divided into yards, feet, and inches (like days are divided into hours, minutes and seconds). However, in the metric system the subunits are based on powers of ten and named with prefixes: the kilometer is divided into meters, centimeters, millimeters, etc. For a metric time system, I would apply the same concept to the base unit of one day. Instead of hours and minutes, you would have subunits like centidays and millidays. For example, would be equal to: $$ \frac{1}{2}~\text{day} + \frac{10~\text{hours}}{24~\text{hours}/\text{day}} + \frac{18~\text{minutes}}{24\times 60~\text{minutes}/\text{day}} + \frac{42~\text{seconds}}{24\times 60\times 60~\text{seconds}/\text{day}} \\\approx 0.92965~\text{days} $$ (Where the extra half-day comes from the .) The subdivisions of the day would be: $$ \begin{align} 1~\text{day (d)} &= 1~\text{day} \\ 1~\text{deciday (dd)} &= \frac{1}{10}~\text{day} = 2~\text{hours}~24~\text{minutes} \\ 1~\text{centiday (cd)} &= \frac{1}{100}~\text{day} = 14~\text{minutes}~24~\text{seconds} \\ 1~\text{milliday (md)} &= \frac{1}{1000}~\text{day} = 1~\text{minutes}~26.4~\text{seconds} \\ 1~\text{microday ($\mu$d)} &= \frac{1}{10^6}~\text{day} = 86.4~\text{milliseconds} \end{align} $$ For fun you can come up with nicknames for the different units. E.g. deciday could be "metric hour," "deci," or (based on the abbreviation ) a "dud." Milliday could be "metric minute" or "mid." We could add an additional "convenience unit" also based on the powers of ten: $$ 1~\text{metric second (s$_\text{m}$)} = \frac{1}{10^5}~\text{day} = 0.864~\text{seconds} $$ So we might write our time from before () in metric time as: $$ 9~\text{dd}~29~\text{md}~65.3~\text{s}_\text{m} $$ Or simply as or even . This makes the representation of dates easy too, since we can just put a whole number of days in front of the decimal point. In fact, we could throw away months altogether and just use day numbers. For example, today is (eleventh of February, 2016). January has 31 days, so February 1 is day 32, and February 11 is day 42. Thus, in the metric calendar today is "day 42 of 2016." Putting it altogether, is . 

What really happened here is that the user made a request for the deletion of a specific file. As the user formed its sentence, the computer already started doing all the necessary preparations for its execution, much in the way we humans converse: we can identify a word by its lexeme before the word is completely formed, so we can more or less guess what will come next, but we can't completely understand the full implications of this word until we hear all the morphemes (if any). Likewise, we can try to make a wild guess about which word may come next and try to understand what the other person is trying to tell us, but we will not be sure about the specifics until the whole sentence is complete. Likewise, a single sentence might throw some light into the context of the topic at hand, etc. After the user's request was completed, the object vanished from the user's viewport in a fraction of a second. This point is extremely important because the hackers of the future will attempt to trick the machine into doing something else (or just bring it to a halt) by surprising it with some sort of "punchline" capable of surprising it. Since security programs are concurrent, they can't really understand the full scope of the user's actions until it's already too late. Think of it like setting up a trap for the enemy king in chess over several turns: most of the "illogical" movements made earlier start to make sense the moment your king is killed. The paragraph talking about cranes was actually talking about birds and not boxes, but the computer could have never seen that coming since it mostly operates on sentences and not contexts as big as a paragraph or small text; generally, the precision of its predictions are drastically reduced the bigger the scope is, although it can still operate in bigger schemes if specifically programmed to do so. To identify what the user's trying to say, modern CPU incorporate a neuronal network that allows the OS to retroactively make some sense of words after hearing a string of letters. More often than not this is abstracted from userland programs through the use of libraries and APIs, although they may get access to the wavestream depending on their permissions. The "biometric authentication" system I mentioned before actually operates on big segments of the stream. Since the automatic conversion to "universal brain language" reduces (not removes!) the variance between user brains, trying to identify a user by these differences alone is impossible (not to mention that the, although small but random, noise the line may have, such a level of detail would be impossible). This is why the user authentication software operates on a larger set of thoughts: it detects the approximate state of mind of the user (excited, angry, relaxed, etc) and "mannerisms" they may have. This is more or less the equivalent of the accent a person may have or stylometric analysis of their texts: it identifies them with a high degree of precision, but it's not infallible. Hackers may again try to disguise themselves as the system operator of a device by using meditation techniques to appear as if they were thinking like the legitimate user of said computer. This "universal brain language" I talk about would be more or less like any human language (such as English). It encodes information so everyone can understand it, but it's not digital because the way you speak it may say something more about your message than what the language can express. That means, in the conversation example, the user may be thinking of deleting as symbol A with modifying factor B, while the software translates it to symbol X with modifying factor Y (which may be equal to B, although I haven't thought of that yet. I don't think it actually matters). The modifying factor is what tells the computer that you didn't just think of deleting, but that it also seems to sound as if the user was somewhat distressed or angry: it is analog metadata that would be difficult to translate to digital without butchering its meaning. Here is where the CPU's neuronal networks try to take a guess about what does this metadata mean, much in the same way a human would try to guess what does that tone of voice mean; it may be easier to guess when the modifying factor is stronger. What I originally meant with this question is: how could the CPU process this brainwave? Could some technology directly operate on this wave through the use of analog operation programs or would conversion to digital be required for all cases? Mind you that the CPU has a digital coprocessor that can process those problems where the analog computer can't process that well, although communication between these two may be slightly slower in the same fashion memory to on-die cache transfers are slow. Could the analog CPU be a universal Turing machine, independently of how practical that could be? Alternatively, if this isn't the case, would analog emulation on a digital CPU (emulated neuronal network simulations, like a partial brain simulation) be the only way to tackle this problem? In addition, could information about a wave be persistently stored somewhere? Could said stored wave be actually stored as a wave and not as a "parametrization" of a wave? 

We've actually already solved most of these problems: we send computers into space! They can be extremely small, with low power requirements, and can handle extreme conditions of temperature, vacuum, and acceleration. Since there are no assets to capture in space (no resources [that would be economical to obtain] or cities [see, space is a bad place for people, above]), space combat will likely be all about destroying your opponent's spaceborne assets (weapons platforms and intelligence-gatherers). For this task, only one form factor makes sense: an anti-satellite missile. So to answer your question... (tl;dr) The closest equivalent to a space fighter would probably be slung under a real fighter, carry no people, and spend less than five minutes in space before exploding. Hey, you asked for realistic, and reality is disappointing. Sorry. (Realistic spaceflight is only fun for hardcore space nerds like me, handwave away the problems and let yourself have fun with it instead!) Update: Star Wars celtschk makes a good point: if space fighters don't make sense for offense, maybe they make sense for defense? To answer this, let's take a trip back in time to the 1980s; no, not for movies, for the other Star Wars. At this point in history, something like antisatellite weapons already exists, called ballistic missiles. Antisatellite missiles existed too, but ballistic missiles were the bigger threat. Lots of people were figuring out ways of stopping said missiles. Typically you can't stop the missiles in their boost phase, before they leave the atmosphere, since this would typically entail having weapons in your enemy's airspace, which they don't really like. It's also hard to stop the warheads when they reenter, since they're moving very fast. Therefore the only place to stop them is in space. Since explosions don't work in space, you'd stop a warhead (or antisatellite missile) the same way that an antisatellite missile would destroy a satellite: just before impact, explode into a cloud of shrapnel that strikes the target, ripping it to shreds. There is no defense against this, especially when the closing velocities are tens of kilometers per second. Here, the same disadvantages for humans that I mentioned above are even stronger. You want your weapons to be extremely small and light so that they can be put on an intersecting orbit within seconds. If Star Wars systems were ever deployed, they would have been completely automatic, as having a human in the loop makes the response too slow to be effective. You also need your interceptors to be inhumanly accurate and expendable (see, "explodes into shrapnel," above). A plausible defense system consists of IR and UV cameras aimed at the Earth (both detect heat from the exhaust plumes of missiles, but UV has the advantage of not penetrating the ozone layer, so you only see spaceborne sources), and a constellation of kinetic kill vehicles that coordinate to intercept and destroy each of the incoming warheads. These systems were called Brilliant Eyes and Brilliant Pebbles, respectively. Why are these systems not in place today? You run into a scaling problem. Your enemy can release not one, but dozens of warheads from a single missile. All of them but one are inert. Since they are basically cans, they cost almost nothing to add to your missiles. However, you can't distinguish which ones are which, so you have to deploy enough interceptors to destroy all of them. The catch is, none of your interceptors can be duds! They all have to be fully-functional, expensive systems. This is why laser systems that destroy missiles in their boost phase before they can separate their warheads are so attractive. However the same issues of detection, targeting, and speed come into play, so any laser weapon would be computer-controlled. You might stick a person on board to deactivate the system in case of a false alarm, but then you need all the support equipment for that person, making you a huge target. Beyond The Infinite There is one change that could make space fighters plausible: reactionless drive. All spaceflight under known physics is fundamentally limited by the rocket equation: $$ \frac{m_f}{m_p} = e^{\Delta v/v_e} - 1 $$ This equation comes from the fact that momentum is conserved, so in order to change your momentum, you have to emit something with momentum opposite the change you want to make. The reason this equation is so bad is that the change in speed is in the exponent, meaning that the required fuel mass fraction increases dramatically as you increase the amount of maneuvers you can make. But what if: $$ \frac{m_f}{m_p} = 0? $$ A reactionless drive doesn't require any propellant to be expended. This would change the whole game, as now spaceflight is no longer a mass-minimization exercise. You can put anything in space that you want, and move around as much as you want once you're up there. This invalidates most of my arguments against space fighters, although it requires breaking the laws of physics to do it! 

I am trying to write a sci-fi setting in a not so distant future in which analog signal (brainwaves, in this case) processing is one of the main points of the plot and pretty much required to explain some of the mechanics going on in the universe. Thing is, analog to digital conversion is expensive, and it may compress data into a easier to handle finite set of values that would, in exchange, make it drop some information in the process. This is something I don't want, since some of the mechanics required to develop the plot require subtle differences in a person's brainwaves (in this case, used as some sort of biometric key). This last part can be avoidable by just throwing more resources at a regular digital computer, but that's lazy and something I don't want, as an analog computer could allow for more interesting details and implications. Just how viable would it be for the world to go back to analog? In the past we had analog computers, but we changed to digital because apparently they weren't designed with programmability in mind (as in, they were like ASICs) and soon digital became better than analog so there was no reason to try to improve a deprecated technology. Likewise, most of our telecommunication devices operate on waves and analog signals, but they are translated to digital at some point of the process (ie. the modem) and lose all the properties an analog signal has. DARPA tried to build an analog "cellular neuronal network" CPU (project UPSIDE) for computer vision back in 2012, but there is not much information about it. Apparently, it allows for much faster speeds at a lower energy cost, at the expense of some errors from time to time and what has been described as requiring a much different way of tackling problems. Problem is, it says nothing about how programmable it is (which it apparently is, but it doesn't mention if it's Turing complete by itself or not). In addition, it seems to be a hybrid analog-digital computer, which is the concept I initially thought about including in my story. In the future, could we see the following things? How superior would they be to their digital counterparts? Would they have any limitations?