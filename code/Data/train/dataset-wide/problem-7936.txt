In order to have any hope of getting a universal property you have to think in terms of order-preserving functions (ie categorically) and not picking elements one at a time (graph theoretically). The subject that would have results like this is called domain theory. It assumes that the poset already has (honest) joins of directed subsets. The most likely kind of universal property is that $E$ is the image of the least co-closure. A co-closure is an order-preserving function $f:X\to X$ such that $f(x)=f(f(x))\leq x$ for each $x\in X$. In the example where you construction arose, can you construct such a function? If so, that's your universal property. If not, you're at sea. Edit in response to Werner's: Look up SFP or bifinite domains, on whom the main authors are Gordon Plotkin, Mike Smyth and Achim Jung (though the word bifinite was mine). However, you still haven't told us where the question came from. 

"every bijective morphism determines an isomorphism" I think you mean that the forgetful functor reflects invertibility. Let $\bf A$ be the "category of objects with structure" and their structure-preserving maps (homomorphisms), $\bf S$ the category of carriers (maybe sets and functions) and $U:{\bf A}\to{\bf S}$ the "forgetful" functor between them. In fact, just let $U:{\bf A}\to{\bf S}$ be any functor you like. Now let $f:X\to Y$ be any morphism of $\bf A$. You are saying that, whenever $U f:U X\to U Y$ is an isomorphism (such as a bijection) then $f$ was already an isomorphism. The forgetful functor from any category of algebras has this property, as more generally does the right adjoint of any monadic adjunction. However, the underlying set functor from the usual category of topological spaces does not, because there are many different topologies that can be put on a set. 

Let's say we have a maximization linear program that looks like this: maximize $\vec{c}\vec{x}$, subject to $\matrix{A}\vec{x} \leq 0$, $\vec{x} \geq 0$. If we take the dual, we have "minimize $0\vec{y}$, subject to $\vec{y}\matrix{A}\geq\vec{c}, \vec{y}\geq 0$". I'm particularly bothered by the "minimize $0$" part of the dual program - but does the duality theorem still hold - that is: is it true that if there is a $\vec{y}$ that is feasible for the dual program, then for all $\vec{x}$ that is feasible for the primal program, $\vec{c}\vec{x} \leq 0$? Thanks! 

Let $G$ be an Abelian group. Let $A \subseteq G$. In additive combinatorics, one of the primary measures of the additive structure of $A$ is its additive energy, defined as $E(A) = |\lbrace(a_1,a_2,a_3,a_4) \in A^4 : a_1 + a_2 = a_3 + a_4 \rbrace|$. A related quantity that I'm interested in is: $F(A) = |\lbrace (a_1,a_2) \in A^2 : a_1 + a_2 \in A \rbrace|$. It seems to me that $F(A)$ captures the notion of "closed under sumset" more directly. How come $F(A)$ isn't studied more in additive combinatorics? What kinds of statements can one make about the relationship between $F(A)$ and $E(A)$? In particular, I'm mostly concerned with situations when $G$ is a vector space like $\mathbb{F}^n$ for some finite field $\mathbb{F}$. 

Let $F$ be a finite field. Let $F[X]$ and $F[[X]]$ denote the ring of polynomials and power series over $F$, respectively. I'm trying to show a statement like the following: Fix a $d > 0$. Let $g\in F[[X]]$. If there exists a set $C\subseteq F[X]$ of polynomials (with no constant term) of degree at most $k$ such that for all $c\in C$, $g(c)$ -- $g$ composed with $c$ -- is a degree $kd$ polynomial, and $|C|$ is "large" (some function of $k$, $d$, and $|F|$), then $g$ must actually be a polynomial. I'm trying to beat the bound that one might be able to get via Schwartz-Zippel, where $|C| > kd |F|^{k-1}$ (where $kd \ll |F|$). What bounds on $|C|$ can we get? Thank you, Henry 

Whilst the definition of addition of Cauchy or Dedekind real numbers is "obvious", multiplication is rather more tricky. Unfortunately, most accounts, including [RD], leave it as an "exercise for the reader", without even giving a hint about what the problem is, so the questioner is right to ask about this. The difficulty is intrinsic to multiplication: the only difference in the intuitionistic setting is that we must do the job properly, instead of bodging it by treating positive, zero and negative numbers separately. The point is that, if you want to achieve precision $\epsilon$ in the product of two numbers, one of which is bounded by $B$, then the other must be given within $\epsilon/B$. [MD] is not quoted verbatim in the Question, but it is close enough, whilst the accounts in [AH] and [AT] are essentially the same. [TD] gives a more general account of uniform continuity, taking explicit account of the modulus of convergence of Cauchy sequences (the function that says how far down the sequence you have to go to get a desired accuracy). This is needed elsewhere in constructive analysis. [BB] has by far the clearest treatment that I have seen of the arithmetic of Cauchy reals, building the modulus into the definition. (I admire this book for its "can do" attitude, not dwelling on the counterexamples.) It gives the explicit (but snappy) proof of correctness for multiplication. [BT] defines multiplication for Dedekind reals and proves correctness. It shows how Dedekind reals are the limiting case of intervals and also considers "back-to-front" (Kaucher) intervals, which are related to existential quantification just as ordinary intervals are related to universal quantification. [JC] defines multiplication in a completely novel fashion for Conway (surreal) numbers. This is adapted to multiplication of real numbers in a topos in [PJ]. Since [MD,AH,AT] do not give the explicit answer to the Question, here it is. As above, $\langle r_n\rangle$ is a Cauchy sequence if $\forall k.\exists n.\forall m.|r_{n+m}-r_n|\lt 2^{-k}$. We write $\alpha(k)$ for such an $n$ for each given $k$; this is the modulus of convergence. In particular, with $k=0$, for any Cauchy sequence $\langle r_n\rangle$ there are integers $N=\alpha(0)$ and $K=\log_2(r_N)$ such that $\forall m.-2^{K}\lt r_N-1\lt r_{N+m}\lt r_N+1\lt 2^{K}$. Let $M$, $L$ and $\beta$ be the corresponding integers and modulus for the Cauchy sequence $\langle s_n\rangle$. Now, given $h$, let $k\geq h+L+1$, $l\geq h+K+1$, $n\geq\alpha(k)$ and $n\geq\beta(l)$. Then, for all $m$, $$\begin{eqnarray} |r_{n+m} s_{n+m} - r_n s_n| &\leq& |r_{n+m}| |s_{n+m} - s_n| + |r_{n+m} - r_n| |s_n| \\ &\lt& 2^K 2^{-l} + 2^{-k} 2^L \leq 2^{-h}. \end{eqnarray}$$ Hence $\langle r_n s_n\rangle$ is a Cauchy sequence with modulus $\gamma(h)=\max(\alpha(h+L+1),\beta(h+K+1))$. We can avoid considering equivalence of sequences explicitly, by observing that two Cauchy sequences are equivalent iff they are both subsequences of the same Cauchy sequence. Rationals are represented by constant Cauchy sequences and the new operation for them agrees with multiplication of rationals. This argument amounts to saying that the new operation is continuous with respect to the Euclidean topology. Also, the rationals are dense amongst Cauchy reals. Hence the new operation is the unique continuous extension and it follows that it obeys the usual algebraic laws for multiplication. [BT] Andrej Bauer and Paul Taylor, The Dedekind Reals in Abstract Stone Duality, in Mathematical Structures in Computer Science, 19 (2009) 757-838. [BB] Errett Bishop and Douglas Bridges, Foundations of Constructive Analysis, Grundlehren der mathematischen Wissenschaften, Springer-Verlag, 1985. [JC] John Horton Conway, On Numbers and Games, Number 6 in London Mathematical Society Monographs. Academic Press, 1976. Revised edition, 2001, published by A K Peters, Ltd. [RD] Richard Dedekind, Stetigkeit und irrationale Zahlen, Braunschweig, 1872. Reprinted in [DW], pages 315–334; English translation, Continuity and Irrational Numbers, in [DE]. [DE] Richard Dedekind, Essays on the theory of numbers, Open Court, 1901; English translations by Wooster Woodruff Beman; republished by Dover, 1963. [DW] Richard Dedekind. Gesammelte mathematische Werke, volume 3. Vieweg, Braunschweig, 1932; edited by Robert Fricke, Emmy Noether and Oystein Ore; republished by Chelsea, New York, 1969. [MD] Michael Dummett, Elements of Intuitionism, Oxford University Press, 2000. [AH] Arend Heyting, Intuitionism, an Introduction, Studies in Logic and the Foundations of Mathematics, North-Holland, 1956. Third edition, 1971. [PJ] Peter Johnstone, Topos Theory, London Mathematical Society Monographs 10, Academic Press, 1977. [AT] Anne Troelstra, Principles of Intuitionism, Lectures presented at the Summer Conference on Intuitionism and Proof Theory (1968) at SUNY at Buffalo, NY, Lecture Notes in Mathematics 95, Springer-Verlag, 1969. [TD] Anne Sjerp Troelstra and Dirk van Dalen, Constructivism in Mathematics, an Introduction, Number 121 and 123 in Studies in Logic and the Foundations of Mathematics, North-Holland, 1988. If you know of other explicit accounts of multiplication for Cauchy or Dedekind reals then please give the references in comments below. 

An important component of algorithms for factoring multivariate polynomials over a commutative ring $R$ is Hensel lifting. Here's a brief, concrete example to set the stage for my question: Let $f \in F[X,Y]$, where $F$ is an algebraically closed field. Suppose that for some $b\in F$, $f(b,Y)$ is square-free; call such points base points. Let $\alpha^{(b)}_1,\ldots,\alpha^{(b)}_n$ be roots of the univariate polynomial $f(b,Y)$, or equivalently roots of $f(X,Y)$ modulo the ideal $(X - b)$. Hensel lifting gives an algorithmic way to lift the roots $\alpha^{(b)}_i$ of $f$ modulo $(X - b)$ to roots $g^{(b)}_i$ modulo $(X-b)^t$ for any $t$, where we have the property that $g^{(b)}_i = \alpha^{(b)}_i \mod (X-b)$. Call these roots Hensel roots. (In a polynomial factorization application, there would be a way to take the $g^{(b)}_i$'s and convert them to actual factors of $f$). 

The celebrated Big Theorem of Picard's is that, in every open set containing an essential singularity of a function $f(z)$, $f(z)$ takes on every value (except for at most one) of $\mathbb{C}$ infinitely often. Now - is the converse true? Is this a way to characterize the existence of an essential singularity of a function? For example, if you're given a non-constant function $f(z)$ that is holomorphic on some open set $\Omega$, and you know that there is an accumulation of 0's towards some point $x$ on the boundary of $\Omega$, then do you know that there must be an essential singularity at $x$? 

Consider arbitrary unit vectors $w,x,y,z \in \mathbb{C}^d$. Is there an explicit formula for what this average is? $$ \int \mathrm{Tr}( \psi \psi^* \, \, w x^* \,\, \psi \psi^* \,\, y z^*) d\psi $$ where the average is over a Haar-random unit vector $\psi \in \mathbb{C}^d$. Here, $\psi \psi^*$ is the rank-one matrix formed by the outer product of $\psi$ with itself. I'm looking for a formula that relates this average to inner products between $w, x, y, ,z$, for example. A related question I'm wondering about is what the expected value of the following inner product is: suppose you pick a Haar-random vector $\psi$, followed by a Haar-random vector $\psi^\perp$ that's orthogonal to $\psi$, and then look at $\langle \psi, x \rangle \langle y, \psi^\perp \rangle$. Thanks! 

The programme that I propose for answering questions of this kind is described in my paper Foundations for Computable Topology. I had in mind that this might be done for (the opposite of) the category of (commutative) rings, though I confess that my efforts to do so drew a blank. Thank you for telling me about Schlomiuk's paper. To me now it seems pedestrian and too closely wedded to sets of points, but that is completely unfair because it was written a long time ago. (I would say that it resembles Lawvere's work on the category of sets long before the invention of elementary toposes.) I notice that Schlomiuk includes an axiom with some similarity to what I call the Phoa Principle, in the form that the Sierpinski space (which he calls $E$ and I call $\Sigma$) has just three endofunctions. It also uses extremal monos, as I have done, coincidentally with the same name but in ignorance of previous work. The analogue of the Phoa Principle for affine varieties would be that any endofunction of the base ring qua space is a polynomial. The analogue of my exponential $\Sigma^X$ for rings should be polynomial ring or free symmetric algebra on the underlying abelian group (ie forget the existing multiplication and freely adjoin a new one). However, whilst this works fine for locally compact frames, for rings it goes badly wrong for cardinality reasons. There is some work by Mike Barr on Banach algebras that might help here, though I couldn't get my ideas to work with it; I will look out the references if you are interested. 

One version of Hensel's Lemma is the following statement: Let $R$ be a commutative ring with a unit. Given a polynomial $Q\in R[X]$ and a root $\alpha$ of $Q$ modulo some ideal $I$ (i.e. $Q(\alpha) \in I$), assuming some non-degeneracy conditions (e.g. $Q$ is square-free), then for every $t > 1$, there exists $\beta_t \in R$ such that $\beta_t = \alpha \mod I$, and $Q(\beta_t) \in I^t$, and furthermore, $\beta_t$ is unique. The multidimensional generalization of Hensel's Lemma is often presented as: Given $f_1,\ldots,f_n$ in $R[X_1,\ldots,X_n]$ and a simultaneous root $\alpha \in R^n$ modulo an ideal $I \subset R$ (i.e. $f_i(\alpha) \in I$ for all $i$), assuming some non-degeneracy conditions (e.g. $\det J(\alpha)$ is a unit), there exists $\beta_t \in R^n$ such that $\beta_{t,j} = \alpha_j \mod I$ for all $j$, and $f_i(\beta_t) \in I^t$ for all $i$. Here, $J(\alpha)$ denotes the evaluation of the Jacobian of $f_1,\ldots,f_n$ on $\alpha$. My question is: is there an intermediate generalization in between the univariate case and the multivariate case above where we only consider one polynomial $Q\in R[X_1,\ldots,X_n]$, and we simply want to lift roots of $Q$ modulo an ideal $I$ to roots of $Q$ modulo $I^t$? It seems intuitively like an easier thing to do (we don't require simultaneous solutions to a system of polynomial equations). Does this intermediate generalization exist, and if so, what non-degeneracy conditions would we require? Thank you! 

Picard's Big Theorem says that if a function $f(z)$ has an isolated essential singularity at a point $w$, then in every neighborhood of $w$, $f(z)$ hits every complex number infinitely many times, with perhaps at most one exception. Is there a version of Picard's theorem that goes something like this? Let $V$ be an open disc (finite radius) such that $f(z)$ is holomorphic on $V - \lbrace w \rbrace$, and has an essential singularity at $w$. Let $0 \leq \theta < \phi < 2\pi$, and define $Cone(w,V,\theta,\phi)$ to be $V \cap \lbrace w + re^{i\varphi} \mid r > 0, \theta < \varphi < \phi \rbrace$. Think of this as a "pizza slice" of the disc $V$. Is it true that there exists an $\alpha$ such that $f(z) = \alpha$ for infinitely many $z\in Cone(w,V,\theta,\phi)$? 

Please would somebody better qualified than me to do so write accounts here of Reallisability and Proof Mining. 

The article on Heyting algebras and frames is one of many that are truly awful in Wikipedia. Frames and complete Heyting algebras are completely different things. They are algebras for different theories and (so) their homomophisms are different. Johnstone's convention, which Tom has described and to which there are now few dissenters, allows one to use the algebraic machinery to speak in topological language, but without mentioning points. For example, in Johnstone's book you will find definitions of locally compact locales and of open (continous) maps. 

Since orthogonality respects composition, it follows that $E\perp M$, whilst by construction $E;M$ is the entire hom-class of the category. Therefore $(E,M)$ is a factorisation system. The things that I have assumed are all proved in my book but I don't have a copy to hand to look up the references. In the question as stated, it is given that $M_0\subset M_1$, but there is no order-relationship between these and $R$. This is why it was necessary to introduce $R'$. The construction gives a way of handling expressions in the lattice of factorisation systems on a category, so it would be an interesting exercise in lattice theory to find out whether this is modular or even distributive. 

The relevant piece of categorical folklore here is the notion of arithmetic universe. This was studied by André Joyal in 1973 with the goal of proving Gödel's Incompleteness Theorems in a categorical fashion. However, André never published anything and many people have tried without success to obtain any notes from him. I went to his office in Montréal in 1991 to get them, but just came away with a copy of Lawvere's thesis. Thanks to Todd for providing the link to Milly Maietti's recent paper, about which I did not know. Since it provides much of the technical information and bibliography, I will just give a more informal description. An arithmetic universe is essentially set theory as it is taught to computer science students, ie with finite powersets instead of general ones. So it has 

Hello all, I'm trying to find a good resource for a discussion on the relation between say, the p-norm of a vector (from a finite dimensional vector space) and its Euclidean norm. In my search on the internet and in various books, I only encounter basic, standard inequalities such as the Cauchy-Schwarz and Holder's inequality. Are there textbooks that go more in depth than these two? In particular, I'm interested in the following: if I have two unit vectors $\psi$ and $\phi$ (from $R^d$, say), that are $\epsilon$-close, meaning that $\|\psi - \phi\|_2 \leq \epsilon$, then what can one say about $\|\psi\|_p - \|\phi\|_p$? Intuitively, they must be close as well, but does the closeness depend on $d$, the dimension of the vector-space? Any references or links or pointers would be greatly appreciated! Thanks, Henry 

I love the following example: approximating pi. Ask a person to come up with a relatively efficient algorithm to compute the digits of pi, and unless they already know some math, most will draw a blank. Here's something that anybody with a basic geometry background will understand: Simply generate many random 2D points (x,y) in the box [-1,1]x[-1,1], and count the number of points within distance 1 of 0 (call this number A) and the number of points in the box total (call this number T). You can then approximate pi with $\pi r^2 /4r^2 \approx A/T$, but $r=1$, so $\pi \approx 4A/T$. 

It is known that solving systems of linear equations is reducible to SVD in a straightforward way; if you want to solve $\mathbf{Ax}=\mathbf{b}$, then you can perform SVD on $\mathbf{A}$ and minimize $||\mathbf{UDVx}-\mathbf{b}||$. However, is there a reverse reduction that is also very efficient? That is, if you can solve linear equations, you can solve SVD? EDIT: Because of Denis's comment/answer below, it looks like there isn't a reduction in general. But I'm interested in these problems over $\mathbb{C}$; so, the new question is: If we can solve linear equations over $\mathbb{C}$ exactly or approximately, can we perform an "approximate" SVD (for some suitable notion of "approximate")? The answer still seems to be in the negative, but I defer to people who actually know something about this.