For the notion of absolute not to exist would be an absolute absence, a requirement that everything lack this kind of perfection. This, of course, would contradict the absolute absence of perfect absoluteness. At least one thing would be absolutely required -- that no rule be absolute. That may strike you as a word-game, but it is not. Logic depends very strongly on principles that are intuitively absolute. Contradiction is possible only if the truth of certain kinds of propositions is absolute. Otherwise, carefully cultivated, the tiny risk that all the things we find contradictory actually admit exceptions slowly add up to a basic incapacity to process the world (or an enlightened state of non-dualism that breaks one's obsession with trying to process the world -- Samsara is Nirvana -- same thing, different day). Arithmetic works only if equality is absolute, as does the rest of mathematics. Even our science's understanding of the lack of absoluteness, in statistics, requires a notion of 'real randomness' -- an absolute lack of predictable order -- in order to become tractable. We could go on, but in fact, the notion of absoluteness is almost everywhere. Whether that notion has any basis in actual experience, or in physical reality is another question entirely. But, as the list of examples in the paragraph above could go on for quite some time, it is clear that our internal experience is shaped very strongly by a search for absoluteness, and an ultimate compromise with the inability to find it. (Like the philosophy of mathematics, I think the best approach to the philosophy of religion is upward through psychology. So the rest of this answer is from various psychoanalytic perspectives that many people put outside the boundary of philosophy proper, and surely outside of theology.) From a Lacanian point of view, it is the imagination that is absolute. A human has only a limited capacity of attention, and what is missing from any internalized image is missing absolutely. Firm boundaries are drawn around each imaginary object. (Even if those boundaries are 'drawn in fuzziness' like the fake fur on CGI animals, or inked with the 'non-color', we kind of live in cartoons.) But from that perspective, the ability to symbolize, and thus to communicate, depends entirely upon using current reality to create scenarios in another person's imagination. You can point at a rock, and claim you have communicated without invoking imagination, but there is an imaginary signification of that rock as special. You have 'named' it, personified it a little bit, and you are telling a story about it. Giving up entirely on idealism and absolute statements always fails (Buddhist miracles notwithstanding), even if you consider it entirely hopeless, because idealization is the bedrock of our basic concepts of language. Since language is what we will use to capture a rule, every rule is implicitly absolute, even if it says otherwise. It is also therefore just wrong in some unforeseen way. (Ask any three-year-old, wait a bit, and ask her again at nine.) We know that is not real, but it is our natural framing. Even the resulting relativism is expressed in terms of purposive refusal to choose a preference, rather than having some normal, positive expression. That is why, going back to Lacan, the natural human mental state is slightly neurotic. Following on that, it is also why we have a major personality trait among the "Big 5" for resentment and distrust (Neurotic), while all the other major personality components admit positive characterizations (Open, Conscientious, Agreeable, Engaging). Going back to the God question, this is why, from a Jungian point of view, religion is mandatory in human psychology. If you displace your religious inclination purposely from a given fixed perfection, you still must choose an object of baseless faith, be that human potential, scientific process, or the nature of suffering. Your dependence upon that new fixed object will be just as absolute a religion as the one handed down to you -- though it may make more sense in your context, and it may change daily. Because that is not really a change, either: Religious people's religion is also coped to their context, and whether they like it or not, it also changes daily. 

From one perspective, this aligns exactly with the argument against the death penalty, and it doesn't apply to animals for exactly the reason we do not consider the killing of an animal to be murder. Death is very final, and mental states and states of health are less so. Just as in the death-penalty argument guilt is not certain, neither, in this case is the suffering. (Nor ultimately is the death we are choosing. We have examples like Anna Quinland, who was euthanized and failed to die, only to recover completely and speak out ardently against euthanasia. And we have many people hideously maimed by failed suicide attempts.) Obviously suicidality is often the consequence of a mental disease, which may be ameliorated, or naturally pass. The cost of the loss also does not fall only on the deceased, but on those who had hopes for them, or who depended upon them. So if the avoided outcome is not outright inevitable, they are not the only ones who should make the decision. And we do not know that those making that call by proxy are also seeing things in a way that is fair to the person killed. Who should make that call may be an intractable question. So the question is how to decide when a current mental state outweighs a potential later one, and another is making the distinction between when someone rationally sees no way out, and when they are mistaken. Most cultures choose not to choose, and await the natural outcome. Our laws and religious codes come from such times. But we now have the ability to maintain life almost indefinitely, so we need a real solution, which is proving very hard to attain. 

Do we no longer take Plato seriously because he proposed the celestial spheres? Do we reject Marx on the basis that he reasoned partly from Engels' incorrect anthropology? Do we discard Kant because his psychology does not allow for the current behavior of physicists? To what other philosopher do we apply the standard you propose here -- consigning them to irrelevance because they chose their exposure to science badly? The standards of philosophy rest on what resonates with human logic, not what caused the thoughts to be put forward. The field lies in the humanities for a reason. Philosophers borrow evidence from all over the place and claim no skill at evaluating its truth. They use science liberally but realize they are not scientists. They argue from history and are not historians. They assemble something that makes sense. And if their sense continues to hold interest and reflect value when their data rots away beneath them, the philosophy remains relevant. I would not try to impose Conifold's proposed balance. I would leave it to the natural evolution of what cognitive dissonance our collective mind will tolerate. At some point, good science becomes part of common sense and limits what will be reasonable to use or present in philosophy. But ideas that are of real value either get understood in context or get filtered for what sense they make, and what can be carried forward and re-expressed in less objectionable forms. Foucault has not reached that point, or you would be seeing people rewriting him, stripping out the nonsense, the way you see secondary treatments of older philosophers that make more sense than the originals. Instead, he is best presented like Neitzche is by Kauffman (or the Gita is by everyone in the West) -- unmodified, but with a huge collection of contextualizing footnotes. We should let him lie there until his lies outweigh what is to be garnered from his consideration of them. (And we should, in fact, honor the power of those lies.) 

@MoziburUllah is correct, but it is not so ambiguous as all that. At least not lately. Since starting to dwell on its roots, math really has accepted a slightly less ambiguous formulation of than coherence we have had historically. The current model of math (along with the main forms in which formal logic is taught) is dual. It really only involves two proof positions -- deduction of implication via grammar of combination, and construction of 'worlds' or models via a grammar of description. (These two positions, along with the distinction between them, go back to Euclid. So people who want to limit or minimize the assumption of coherence can easily just ignore the intermediate positions, and claim they were just spurious nonsense. This is what modern formalists do.) Consistency may not be available via formal construction, but people's real intuition of validity or consistency is the one based upon models, not the one based on formal proofs. Then from a point of view focussed mainly on mathematics as the psychology of shared intuition, we really do not believe, deep down, that formal language is what really proves things. It is only a way of checking ourselves when we act upon our other intuitions, which we presume reliable, as long as we do not pursue them too far. From that point of view, we can look at the stripped-down 'universes' of Von Neumann's V, or Goedel's L, (or even Conway's "Surreal Numbers") and agree that our system has a model. Then even if our formal manipulations ultimately do not really apply directly to the objects we are studying, our chosen base model does contain something isomorphic to them. So, in any case where we are explicit enough about what we are saying to define isomorphism clearly, we can validate that what we are doing would not have a contradiction in it, by mapping its interpretation back onto our chosen base model. This is the formalist escape from the ultimate weakness of formalism: to claim mathematical claims "only exist up to isomorphism" and to ignore the reliance of the existence of the base models upon intuition. 

Various pacifists (including my favorite version of Starhawk) have also put forward this basic notion. Its theoretical practicality relies upon an assumption that 'We are psychologically more like bonobos than dogs'. (This is not entirely obvious. We are genetically more like bonobos, but we created the psychology of dogs to be like our own from very early in our history. Many dogs, and few bonobos, understand what it means when you smile playfully, or when you point at something. But the genetic distances make it highly likely.) Various theorists have suggested, largely based upon the differences between chimpanzees and bonobos, that competition to have more 'stuff' than your neighbors is a trained response and not an intrinsic one. Other theorists have reinforced this by arguing for the apparent egalitarianism of tribes at the height of the paleolithic era, suggesting that differences that afford domination, like gender and size, do not seem to have predicted better individual health in that period of prehistory. From this point of view, human competition is properly social in nature: about mating opportunities or enforcement of will in a more abstract sense, and not really about resources. But we are raised in a culture that emphasizes scarcity as a primary social motivation. We are trained to value ourselves through providing resources to those about whom we care, or through demonstrating that we can and will do so when the time is right, because much of human history after the period of Paleolithic Affluence has involved continual scarcity and particularly has involved forced deprivation of the socially disapproved. Even taking that as a given, so the state is possible, the issue remains whether whether there is any path to it. We cannot simply dismantle a basic aspect of all human cultures, even if we know that underlying the resulting dysfunction is a different motivation that would not be as destructive. This ultimately faces the major obstacle to all forms of pacifism. Unless we all abandon manipulation through unnecessary competition at once, some backward cultures will still create artificial scarcity by pretending to play along, but really harboring their old motives. Then they can take advantage of the fact that others are not working against them to hoard security without limit, and consequently create artificial scarcity. It is not clear we can get there by half-measures. Many schemes have been put forward, but they all seem to require either incredible luck, or virtually infinite intelligence. I think the Venus Project people are basically believers in what Kurzweil called 'The Singularity' -- the point at which technology amplifies intelligence into something so readily adaptable that its only limitation is the maximum rate at which things can change. At that point, it might as well be infinite. So, from that POV, there will be a time very soon, when they can address this limitation with technology. 

(If your focus is directly on Empedocles, pardon the disconnect.) There are three different ways the elements can be opposed to one another, and Western esoteric traditions have used all three of them to good effect. Different perspectives arise from different contrasts between the behaviors of the elemental ideas. Hermes Tresmigistus is said to have that name because his discipline involved three focal traditions: Alchemy, Astronomy and 'Theurgy'. Each of these is invested in a different pattern of pairing the elements. In traditional Alchemy, the two oppositions respect motivation and stability as aspects of work. Fire (exciting) opposes Water (calming) and Earth (solid) opposes Air (adaptive). In Astrology, the two oppositions respect seasonal contrasts. Fire (hot, Summer) opposes Air (cold, Winter), Earth (solid, Autumn) opposes Water (fluid, Spring). In most other Hermetic domains (including what has evolved into modern Witchcraft, Ceremonial Magic, and Jungian psychology), the two oppositions respect traditional interpersonal conflicts. Fire (passion/intuition) opposes Earth (stability/sensation), Water (merger/feeling) opposes Air (separation/thinking). One way of looking at all the patterns is on the points of a tetrahedron. Then each point of the tetrahedron can be seen as representing one of the elements. Looking onto the figure from the point of view of the different edges shows each of these potential patterns, depending on the edge. Looking at the triangles surrounding each point calls out the Cardinal, Fixed and Mutable concepts associated with using that element as a model. (I am not sure how much of any of this is philosophy. But it presents interesting seeds for meditations on how sets of ideas fit together.) 

This is a pile of category errors in search of some sense. 1) A reference to a thing is not the thing. The Library of Congress Catalog could have a shelf entry, then we would know that the Catalog is in the Library of Congress. But the entry is in the Catalog on a given page, the Catalog is not in the Catalog on that page -- it clearly would not fit. God's knowledge of his own omniscience would logically be referential in this way. I would not require that the contents of the omniscience should be spelled out in the statement of the omniscience itself. 2) A convention is not its domain. Set Theory is a model of human intuitions about containment, it is not a true description of how all language must be done. The fact that there are multiple versions of it, alone, prevent it from really being definitive in any argument about God. 3) Actual meaning does not go away because it fails to fit a model. The collection of all things other than Joan of Arc is not Joan of Arc, so she is in it. The Category of Categories is a Category. We can define the direct sum of Groups as an operator, and get a Group, in a real and meaningful sense, even if that violates our Set Theory. Collections contain themselves, referentially, all the time. You can quibble over whether 'set' is a specific kind of collection or not, but you can't just say collections cannot contain themselves. There would be a problem with listing out everything God knows, but that is not required. We can formulate the rule that if there is something to be known, it is in the collection of things that he knows. That rule can be one of the things he knows. And even if the rule were to be represented by the contents it refers to, there is no contradiction between that statement and Set Theory, because this is not math. 

Clearly there is cocaine produced for ordinary legal use, like eye surgery. Would it be harmful if you were to illegally buy cocaine stolen from a surgical center's pharmacy? Would the purchase of that cocaine matter less than the purchase of criminally produced cocaine? Can you tell the difference? And if there were no illegal market for the legally produced cocaine, would the unregulated production even exist? We got to this point from a purely legal Victorian import trade that was only oppressive, and not deadly. Social situations also adapt to the composite needs that drive them. We do not know that this situation is necessarily this way, and could not be arranged in a totally different way, given a different pattern of use. You seem convinced that specific consideration of existing consequences is the right way of making this decision, but in making that assumption you are taking upon yourself the recovery of information that is lost or hidden and the prediction of actions which no one can trace or control. So, I suggest that the first way one should always address something like this is from a reasonable approximation of a Kantian point of view. If it is already a bad idea from there, then it cannot become a better idea by looking at further factors, only a worse one. If it is ambiguous from a fairly abstract point of view, THEN we should work outward, and look at other issues. Even in most such cases, we should not judge the behavior, but the implementations around it, and we should see if they can be rendered morally safe. Eating meat is not immoral just because factory farming is cruel. It should just be more expensive. Americans don't need food prices so low we all get diabetes, anyway... By judging actions on the basis of their current implementations you discard a moral duty to do adequate moral maintenance of the institutions around us. Before considering larger and larger circles of effects, it pays to start from the point where you have the most control and the most responsibility, and it pays to look at those in terms of motivation and realistic knowledge. So I am rejecting your framing, and I am going to answer the question without it.