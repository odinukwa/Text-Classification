What is the maximum number of spheres that can be placed in 3D such that all inter-touch? One can of course place four unit spheres tetrahedrally and then add a smaller sphere in the middle, so this number must be at least 5. [By the way, I was trying to extend the "five points in 2D cannot be inter-connected without a crossing" limitation to 3D with a simple statement, but this was sadly the best I could do. If anyone knows a better simple extension, please comment.] 

Computer multiplication can be sped up by looking for patterns and re-writing this with minimal additions/subtractions (in terms of simple zero-cost bitshifts). To keep 64-bit accuracy, the best I could do was 13 steps: 

What integers are not in the range of $a^2+b^2+c^2-x^2$ (for all integer combinations of a, b, c, and x)? This form is similar to that of Lagrange's Four-Square Theorem, for which the answer would be "none". The generalization by Ramanujan only seems to cover non-negative coefficients. 

$ A $ has no two-sided identity. $ A $ has a right approximate identity (r.a.i.) norm-bounded by $ 1 $, which we denote by the net $ (e_{i})_{i \in I} $. 

Let $ A $ be a Banach algebra satisfying Conditions (1) and (2). Let $ \mathbb{L}(A) $ denote the Banach algebra of all bounded homomorphisms from $ A $ to itself, where multiplication is defined by composition and the norm is simply the operator norm. The only leap (not too great, I hope!) of imagination required is to notice that for $ (a,\lambda) \in A \times \mathbb{C} $, $$ \sup_{b \in A, ~ \| b \|_{A} \leq 1} \| a b + \lambda \cdot b \|_{A} $$ represents the operator norm of $ L_{a} + \lambda \cdot \text{id}_{A} \in \mathbb{L}(A) $, where $ L_{a} $ denotes left-multiplication by $ a $. Define 

Consider the unit square $ S = [0,1] \times [0,1] $. For each $ n \in \mathbb{N} $, we can tessellate $ S $ by the collection $$ A = \left\{ \left[ \frac{i}{n},\frac{i + 1}{n} \right] \times \left[ \frac{j}{n},\frac{j + 1}{n} \right] ~ \Bigg| ~ i,j \in \{ 0,\ldots,n - 1 \} \right\} $$ of $ n^{2} $ smaller squares whose sides have length $ \dfrac{1}{n} $. Let $ C_{1} $ be a finite sequence $ (S_{k})_{k = 1}^{M} $ of squares in $ A $ such that 

In the simplest asymmetric Colonel Blotto game with 2 players, dividing their given Ni soldiers (i=1,2) over 2 battlefields, what are their expected utilities, Ui (i.e., expected number of battlefield victories), in a Nash Equilibrium? If the continuum Ni case is significantly easier to solve, you can consider the individual soldiers to be divisible. I’d also like to see an explicit Nash Equilibrium strategy for the two players, but it seems that there might be many cases, so it can’t be written down simply. 

Is there a positive 128-bit integer whose square has all middle bits equal to 1? (The "middle bits" are naturally the 65th bit through the 192nd bit, defining the 1st bit as the least significant bit of the full integer.) 

Given two vector sets, $\vec x_i$ and $\vec y_i$ (for $i$=1,2,...N, but the dimensionality of each vector can be more than N), let their sum set be $\vec z_i = \vec x_i + \vec y_i$. It's easy to compute the scalar inter-distances: $x_{ij} = \Vert{\vec x_i-\vec x_j}\Vert$, $y_{ij} = \Vert{\vec y_i-\vec y_j}\Vert$, $z_{ij} = \Vert{\vec z_i-\vec z_j}\Vert$. But, what's the quickest computation method to go backwards (i.e., from all of the inter-distances to any "high-dimensional embedding")? It seems I'm forced into ugly numerical "trial and error" methods even for small N=4 though there are easy analytical methods (for any N) if I didn't need to match the sum's inter-distances. 

Let $ A $ be a non-trivial $ C^{*} $-algebra and $ n \in \mathbb{N} $. Setting $ \mathcal{D} \stackrel{\text{df}}{=} A^{n} \setminus \{ (0_{A},\ldots,0_{A}) \} $, we can define a function $ f: \mathcal{D} \to \mathbb{R}^{+} $ by $$ f(a_{1},\ldots,a_{n}) \stackrel{\text{df}}{=} \frac {\displaystyle \left\| \sum_{j = 1}^{n} a_{j}^{*} a_{j}^{\phantom{*}} \right\|} {\displaystyle \sum_{j = 1}^{n} \| a_{j} \|^{2}}. $$ Observe that $ \operatorname{Range}(f) \subseteq \left[ \dfrac{1}{n},1 \right] $. The upper bound of $ 1 $ is pretty obvious, and it is attained if we let $ a_{1},\ldots,a_{n} $ be equal to any non-zero element of $ A $. The lower bound of $ \dfrac{1}{n} $ is gotten as follows: 

Here are some definitions to get started. Definition. Let $ \mathcal{H} $ be a Hilbert space and $ T $ a densely defined linear operator on $ \mathcal{H} $. Then a vector $ v \in \mathcal{H} $ is said to be analytic for $ T $ if $ {T^{k}}(v) $ is defined for all $ k \in \mathbb{N} $ and there exists an $ s > 0 $ such that $$ \sum_{k = 0}^{\infty} \frac{s^{k}}{k!} \left\| {T^{k}}(v) \right\| < \infty. $$ Definition. Let $ \mathcal{H} $ be a Hilbert space and $ (T_{i})_{i \in [n]} $ a finite sequence of densely defined linear operators on $ \mathcal{H} $. Then a vector $ v \in \mathcal{H} $ is said to be jointly analytic for $ (T_{i})_{i \in [n]} $ if $$ \left[ T_{\alpha(1)} \circ \cdots \circ T_{\alpha(k)} \right] \! (v) $$ is defined for all $ k $-tuples $ \alpha: [k] \to [n] $, for all $ k \in \mathbb{N} $, and there exists an $ s > 0 $ such that $$ \sum_{k = 0}^{\infty} \left[ \sum_{\alpha: [k] \to [n]} \frac{s^{k}}{k!} \left\| \left[ T_{\alpha(1)} \circ \cdots \circ T_{\alpha(k)} \right] \! (v) \right\| \right] < \infty. $$ 

Given coprime positive integers M,N, and a corresponding integer z outside of the range (for all integers x,a,b,c) of $Mx^2-N(a^2+b^2+c^2)$, is there any such z which is "deceptive", meaning that it is modularly inside the range of the smaller components, i.e., inside the range of both $Mx^2$ mod N and $-N(a^2+b^2+c^2)$ mod M? Feel free to replace $a^2+b^2+c^2$ with "All integers except for $4^a(8b+7)$" per Lagrange. 

Is there any integer N such that 2^N=3 mod N? I understand that N must be an odd non-prime. I checked up to a million with no success (but, FYI, 2^N=5 and 2^N=7 have solutions). 

Dirichlet's theorem shows that, for any fixed prime integer a, "big prime numbers mod a" are uniformly distributed between 1 and a-1. If we similarly pick different prime integers b,c,..., are these uniform distributions independent of each other? 

It sometimes happens that 1D problems are easier to solve by somehow adding a dimension. For example, we convert linear differential equations for a real unknown to a complex unknown (to use complex exponentials), or we compute a power series' radius of convergence by thinking in the complex plane (or use complex analytic properties in path integrals), or we evaluate $\int^\infty_{-\infty} e^{-x^2}\ dx$ by squaring it... So, are any 2D problems easier to solve in even higher dimensions? I can't think of any. 

Here is a complete argument proving automatic continuity for any $ C^{\ast} $-dynamical system $ (G,A,\alpha) $ where $ G $ is discrete. 

$ D $ exists and is dense because it is the linear span of all invariant domains on which $ T $ is a representation of $ {\frak{g}} $, and the original invariant domain, being one of them, is dense. 

Proof By Theorem 3, if $ T $ is integrable, then there exists a dense linear subspace $ D' \subseteq D $ of vectors that are jointly analytic for $ (T(X_{i}))_{i \in [n]} $. Joint analyticity is a much stronger condition than separate analyticity, so every element of $ D' $ is analytic for $ T(X_{i}) $ for each $ i \in [n] $. If $ D' $ is not already $ T[{\frak{g}}] $-invariant, then we can enlarge it to a $ T[{\frak{g}}] $-invariant linear subspace $ D'' $ as prescribed in the previous section. $ \quad \blacksquare $ Note: By the answer to Question 1, the requirement of $ T[{\frak{g}}] $-invariance in the statement of Theorem 2 and its converse can be dropped. 

Let $W(t)$ be a standard brownian motion in $E \triangleq \mathbb{R}^d$. The transition probability from a state $x \in E$ at time $t$ to a state $y \in E$ at time $T$ is $$ p(x,t;y,T) = \frac{1}{\sqrt{2 \pi (T-t)}^d} \exp \left ( -\frac{1}{2} \frac{\|x-y \|^2}{T-t}\right ). $$ Using the Chapman-Kolmogorov equation, it is clear that for all $n \geq 0$ and for all finite sequence of states $x_0 = x, x_1, ... , x_n, x_{n+1} = y$ and $t_0 = t < t_1 < ... < t_n < t_{n+1} = T$, we have $$ p(x,t;y,T) = \int_{E^n} \frac{1}{\sqrt{2 \pi}^{nd}} \exp \left ( -\frac{1}{2} \sum_{i=0}^{n} \frac{\|x_{i+1}-x_i \|^2}{t_{i+1}-t_i}\right ) \prod_{i=1}^n \frac{d x_i}{\sqrt{t_{i+1}-t_i}^d}. $$ I am not so sure that the limit as $n \to \infty$ makes sense in the right hand side above but I believe that it can be interpreted in terms of the Wiener measure on $\mathcal{C}([0,\infty);E)$ and $$ C(x,t;y,T) \triangleq \{ \omega \in \mathcal{C}([0,\infty);E) \: | \: w(t) = x, \: w(T) = y \}. $$ (if no mistake) how to interpret $p(x,t;y,T)$ in terms of $\mu$ and $C(x,t;y,T))$? 

I believe the current lowest-memory algorithm for computing the $n^{th}$ binary digit of $\pi$ requires $O(log(n))$ bytes and $O(n^2 log(n))$ days (I pick Bellard over Bailey–Borwein–Plouffe for speed). Can any of the common irrational constants be currently computed with the same low memory, but in faster time? Please consider constants which combine integers and $\pi$, natural exponential functions, and/or root functions (e.g., $\pi$, $\pi^2$, $e$, $e^{-\pi}$, $\sqrt2$, $\sqrt{2\pi}$). For any such constant, I am also curious about the randomness in its binary tail. These digit extraction constraints cause correlations in the constant's tail bits which probably go to zero for high $n$ (but, for $\pi$, the Bellard/BBP constraints are too subtle for me to conclude anything). If anyone has a low-memory method to distinguish a tail of some common irrational number from random bits (with the same speed in the limit of high $n$), please comment. 

Since Gerry Myerson is too humble to take answer credit, I'll make it even simpler and close out my stupid question: $0^2+(x+1)^2-x^2=2x+1$ ranges all odds, so $1^2+(x+1)^2-x^2$ ranges all evens. Just 3 integers are enough (a is 0, b is 0 or 1, c is x+1).