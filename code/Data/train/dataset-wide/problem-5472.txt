A computer is a finite device so there is an upper bound on the size of proof that a computer may inspect. There are decidable propositions (in ZFC, for example) whose proofs are of arbitrarily large size. Therefore, no matter how much memory you give your computer, there will always be provable propositions beyond the reach of your experiment. Considering that there are formal proofs (in ZFC, for example) of arbitrarily large size, the "set of all proofs" (if such a thing existed) would then be countably infinite, and therefore no man or computer could produce such a set. No computer can "run through all proofs" because there are infinitely many. Further, it is not at all clear what you mean by "the set of all proofs" - viz. : 

Schopenhauer begins by noting that when we view an object, the information that is impressed upon our retinas is upside down (since the light rays cross after entering the eye). He then notes that if seeing was simply the sensation resulting from the light rays entering our eyes and impressing their information upon our retinas, then we would expect our mind to model our surroundings exactly as this impression demands - i.e., we would perceive an upside down object. Thus, there must be a subsequent "intellectual process" which manipulates this information so that our mind models reality in the "correct" orientation. The italicised text justifies Schopenhauer's conclusion by noting that if we change our orientation, by, for example, lying downward on a hill, then our mind models our surroundings correctly - i.e., we still know what's up and what's down. This is because our intellectual processes include information about our orientation. This information cannot be from the light rays since the light rays cannot contain any information about our orientation. 

(See SEP Entry on Informal Logic) This seems a garden variety of questions and indeed most question might be legitimate topics in vastly different disciplines: cognitive bias -> psychology; argumentative exchange in different social contexts -> sociolinguistics; etc. This thematic pluralism (and disunity) is not just due to the many approaches used to tackle given questions, but is a product of the very aim of informal logic, namely to develop assess and analyze arguments that occur in natural language discourse. Since natural language is used in vastly different contexts and in a variety of ways for a variety of aims, the studies tend to multiply and branch off in different directions. Researching 'the role of emotion in argument' may be vastly different when analyzing legal arguments of lawyers in front of a jury than when studying Euclid's diagrammatic reasoning. In this sense, informal logic vastly fulfills your desideratum that 

As far as I know, the tradition advocating the view "etymology matters philosophically" held that this connection (what we call evolution of language) was a successive series of obfuscation and distortions. It is a form of linguistic essentialism. Martin Heidegger probably was the most important proponent of this tradition, as he thought that ancient Greek had a special philosophical significance: 

This is correct, if we read the original naive formulation of set theory (as per Cantor) as being that of our intuition. It is also misleading to suggest that it is Badiou who is identifying these issues, since they were well known and dealt with by mathematicians long before Badiou came along. A more complete extract, which largely makes sense, is : 

Eliran H's (accepted) answer gives an excellent and interesting response from a classical point of view, and I thought it may also be useful elaborate further on the non-classical views. Philosophers find it convenient to divide paradoxes into two types; the semantic and the set-theoretic. Semantic paradoxes express paradoxes of truth, denotation, predication, and the like, while set-theoretic paradoxes express paradoxes of membership and cardinality. The example you site of "This proposition is false" is (obviously) a semantic paradox. There are some philosophers, such as Graham Priest who take the view that semantic paradoxes are bona fide sound arguments. Such a view requires that one adopt a non-classical logic, specifically what is called a paraconsistent logic. According to Priest's methods, if we let A denote the statment "This proposition is false", then the proposition A ∧ ¬A is true. In other words, both A and its negation are true. Another alternative take on this paradox, as mentioned in Eliran's answer, can be found in the work of Saul Kripke. While I am not entirely familiar with Kripke's work, I believe that Kripkean analysis would entail that the liar paradox, as stated, is not true, and so, according to Kripke, we should assert this. On the other hand, Kripke's methods would have nothing to say about the possibility that the proposition is also true, as is the case with Priest's paraconsistent view. As I say, I am not familiar enough with Kripke's work to be certain of my comments so perhaps someone else can elaborate. Ultimately, I believe that how one views such paradoxes all comes down to is whether or not you accept that natural languages satisfy Tarski's theory of truth. 

If this doesn't seem sufficient, because it doesn't invoke philosophy of mind, then just consider that the mathematics of logic and proof is just one very very technical hyper formalization of one part of 'philosophy of mind'. 

An algorithm is a specification (particularly of operations to take on a machine). As a specification, it is an encoding of many possible things but none of them particularly algorithm specific. It can be an encoding of what you imagine, an encoding of some behavior viewed empirically, an encoding of some desired end. The qualifier 'foreign to human understanding' is something orthogonal to the construction of an algorithm. One can create a random algorithm (or any kind of mathematical encoding) and it might be inscrutable (there are theories that attempt to quantify this inscrutability). This line of thought leads towards algorithmic information theory. As to scientific phenomena evolution or consciousness, I think that's a matter of scientific exploration. There is an attempt to determine the knowledge exactly (through experimentation) where if it is a process one could presumably specify a Turing machine. But some phenomena have been found to be inherently non-deterministic (quantum mechanical processes). Of course one can always attempt to model such phenomena mathematcally (and here in particular much work has been done in quantum Turing Machines and quantum complexity. But simply, if you don't know something about your process, you really can't specify it. That is a specification really is a form of encoding of knowledge. So if there are unknowable things, then they can't be specified (by definition). One might be able to encode something -about- that lack of knowledge (like in say a probability distribution or non-deterministic rules). 

We can do the same for every compound tense composed of P and F in a consistent manner. Thus, McTaggart's argument fails. 

Regarding the first part of your question concerning our ability to acquire knowledge of the ideal world, as we agreed in my answer to your previous question, we can never really be certain if our formalization of a particular theory or (non-trivial) ideal is either correct or fundamental. We can be guided by principles like Occam’s razor or we can appeal to aesthetics and experience, but none of these techniques can provide certainty. Ultimately we can never know. On the plus side, the remarkable utility of our mathematical theories tells us that even if we are creating emergent theories rather than fundamental, ideal-world theories, what we are doing has real value, including intellectual and artistic value (if that's not too airy-fairy), and we are guided by Plato's vision in this regard. 

According to the paper I have referenced (above) the term “totalize” means to “count as one”, or “count as a set”. If this is a correct interpretation of “totalize”, then Brassier is plainly incorrect in the context of set theory. It is not clear if Brassier is expressing his own opinion or interpretting that of Badiou. The original naive statement of set theory (as per Cantor), which is based on set as predicate, runs into inconsistencies which imply problems with unrestricted “totalization”. However, these problems are removed by the axiomatic formulation of set theory which followed - i.e. ZF Set Theory. This is reflected in the statement : 

In this sense one can certainly know (i.e. have animal knowledge) without knowing that one knows (i.e. having reflective knowledge). 

The claim seems at first sight quite plausible ("why not?"), but this is more a problem than a feature. While the general assumption above is often taken for granted, it is difficult to assess more specific claims like yours, because they rely on very loose analogies between one domain (professional background, e.g. biological methods) and another (abstract doctrines covering a lot of other things outside of biology). This is a problem, because with hindsight many other connections (including other analogies) can be set up at will, without any good methods to test them. This problem is known as the construction of just-so stories, especially when these "stories" are used as explanations ("Aristotle tend to treat object of study as an organism because he was used to dealing with animals and plants"). To sum up: Drawing these kinds of causal connections is, in principle, unproblematic. However, in single cases it is difficult to build good explanations, because it is complicated, if not impossible, to assess their validity. 

It's not particularly a restriction to philosophy that language acts as a restriction. We have all sorts of ideas in our heads for which language somehow seems not enough to convey. We can use pictures, hand movements, actions themselves to convey an idea. Some philosophy can use language so vaguely that it is not stating literally the thoughts that the author is trying to get across but the author hopes that cultural knowledge and history of the topic being discussed is enough to disambiguate. The language may not be expressive enough to evoke ideas exactly enough, but there is still the desire to remove things as imprecise as pictures or other artifacts and replace with language because language tends to be more accurate (and checkable) than other methods. Having someone throw a rock at you might convince you of the reality of the outside world, or it might just make you think they're a jerk. 

To go in reverse order, you wonder if 'there exists' implies that there exists exactly one. No, the stipulative definition of the logical 'there exists' (used in mathematics or in ordinary discourse) says that there is at least one. In order to state that there exists exactly one, you need to specify additionally the 'exactly' part, or also say there is at most one. As to your primary concern, I think there is overlapping but not identical use of the word 'exists' for numbers (like '1') and other things (e.g. friends, a verifiable theory, an afterlife, other minds, an apple in front us). Surely it is very immediate to say that 1 apple exists if it is sitting in front of us. But what does it really mean to say that '1' (oneness) exists? Does it exist in the same way as the single apple itself? What about negative 1? When the notation was introduced in Europe, there was quite a bit of controversy whether 1 was actually a number, and then later 0 itself and later negative numbers and complex numbers. But people got past all that (it is still a bit of a controversy whether one 'has' a negative number of apples). Anyway, numbers are (ahem) one way of describing sets. Suppose the set 'exists' by one standard of existence. Then certainly the ability to describe sets using numbers comes with the ability to talk about sets at all which is a different thing than the circumstances of that particular set's existence. So in that sense, the existence of 1 (and other numbers) comes before your particular claim of existence. Executive summary: Yes, '1' comes first (or rather together with the machinery of mathematical existence).