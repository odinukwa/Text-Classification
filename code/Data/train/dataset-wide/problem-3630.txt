I have a powershell script to capture a screenshot. If Run it in powershell or ISE it runs fine, takes the screen capture without issues. When I schedule a task on windows Task Scheduler it just saves a blank image instead of the screen capture. Any ideas why? Script: 

I have exchange 2010. If I go to $URL$ and send an email by entering an email address that exists on my exchange server in the "from" box and send it to my gmail address, My exchange server goes ahead and sends the email. Gmail blocks it because its spoofed. Here is the deliverable message I got in my inbox from Gmail. 

I want to sysprep a Windows Server 2008 R2 SP1 machine that has SQL Server 2008 R2 SP1 installed (for reference, SQL Server 2008 R2 has a new sysprep feature that allows the instance to be sysprepped). On the server is a SQL Server client alias that points to the default SQL Server database engine instance. For reference, the alias is called Alias-SQLServer and has been configured in both 32-bit and 64-bit cliconfig versions (that is, both registry keys exist) The alias points to the local instance as the image will be used to create development VMs and the installation script for the application that is being developed will use the SQL Server client alias in order to generalize the installation scripts. I can't seem to find information about whether the sysprep tool will update the SQL Server client alias's registry keys with the server's new name once it's unsealed. My guess is that it is not; how is sysprep to know that the server name the alias points to will be different for each image? Right? Perhaps if the alias points to localhost instead of the server name this will work? 

I have been trying this many different ways.I get errors like "cannot validate argument on parameter 'Path'. The argument is null or empty. 

I have a Domain Controller that for some reason beyond me has ADCS installed on it. The domain controller is a 2008 R2 server and needs to be demoted, but first I need to do one of two things. This same server also runs DHCP, NPS (RADIUS server),and other third party software. My Options (according to me) 1. Migrate ADCS to a different server (it would be a new machine with 2012 R2). $URL$ 2. Spin up an offline non-domain joined root CA and have a live domain joined issuing CA. I would then backup ADCS on the domain controller, revoke any issued certificates and remove the server roles. It would seem that for option 1 to work i need to migrate the computer name and IP as well. If I go with option 2, what steps can I take to mitigate the possible impact. Currently the CA has issued 9 certificates. However, only 3 have not expired, 2 of those expire in the coming week, the third one a year from now. What would be the best way to get ADCS off this domain controller? 

Terminal Services Manager (located in Administrative Tools) lists the connections made to a terminal server (includes computers with remote desktop for administration enabled, which is your situation). It's an mmc snap in, so you wouldn't normally have it running but it will show you the connections (who and when, etc). I suppose if you have a very large desktop you could have it running in an unused part of the screen. 

I have set up a lab with a number of Windows Server 2012 R2 machines. The lab has an Active Directory domain (DFL: Windows Server 2012 R2, FFL: Windows Server 2012 R2) and these machines are joined to the domain. By default if left unattended these Windows machines will automatically lock. I do not want the machines to lock automatically. I do not have any security concerns with having the machines remain unlocked as this is an isolated lab. I have created a group policy object that sets a number of configurations and the machines still lock. I have verified that the GPO has been applied to the machines. The GPO configures the following settings: 

I have this foreach statement that goes through a list of usernames and puts each name in the path listed below, then it copies and pastes a file to the individual users startup folder. For some reason i get an error that a portion of the path was not found. Any ideas what the problem could be? 

If I use this spoofing website to send an internal email, lets say from my co-worker to myself it arrives safely in my inbox. I have looked through my send and receive connectors and cannot find a way to stop this. 

I have tried changing the way the path for my $destination variable is written and i get the same results 

Two things. First, make sure that the content database is set to online (Central Admin -> Web applications -> Content Databases) and not offline. When offline user name changes do not propagate. Since you said this is MOSS, make sure your SSP user profiles are set to synchronize on a schedule (they are not by default). Set a schedule if not set up. You can also try to force a user profile synchronization them by running 

stsadm -o backup and stsadm -o restore. This moves site collections and not sites. Lots of people are talking about sites when they really mean site collections. This is usually the easiest method and can move data at a rate of about 15 GB/hr. If your site is the only site in the site collection, this is your best bet. stsadm -o export and stsadm -o import. This moves sites. Not as easy to use as backup/restore, but does the trick. There are gotchas when it comes to permissioning, so make sure the site is accessible as expected after the move. You cannot import a site into a site collection where it already exists (which shouldn't be a problem in your case). You will need to make sure all customizations (templates, web parts, features, solutions) are deployed to the new site collection you are importing into otherwise it's error time. stsadm -o mergecontentdb. This can move a site collection from one database to another. This seems more complex at first, but is easier to use than backup/restore. This moves a site collection within a farm. Create a new content database and move it to the new db, detach, and reattach the database in the other installation (farm). stsadm -o gl-moveweb part of Gary Lapointe's stsadm extensions (every farm should have this installed). This moves a site within a farm. (gl-movesite moves a site collection). Most 3rd party SharePoint backup applications have a feature to backup/restore a site to another farm. 

I had to create an account at the teradici website, their website just says its in binary format, but they do provide a script in python to convert it to a pcap. KB2484. The script says i'm not allowed to post publicly so I wont do that. Link 

So i realized that all the space between c:\users\ and Public was just white space. So i edited my list to remove all the white space after each username and after that it works. 

Unless someone has blocked outbound/destination ports to (specifically 8530) your clients should not have any problems checking for updates from your WSUS server. You may inadvertently be blocking the client connections on the WSUS server itself. Even if by default port 8530 is open, I would verify by testing the WSUS server for port 8530. You can use Putty or another telnet emulator to connect via telnet, just change the telnet port to 8530. If the connection is successful then and clients are unable to connect to and get updates from WSUS then you have other problems. Give this link a try WSUS Troubleshooting. 

My question is similar to Powershell Remoting: One way trust, however there are differences and the resolution (adding the server to the trusted list) does not work for me. Scenario: I have two domains. DOMAIN and DOMAINDMZ. DOMAIN has an incoming trust from DOMAINDMZ. That is DOMAINDMZ trusts DOMAIN, but not vice versa. I have an administrative user who is a member of the Administrators local group on several servers in the DOMAINDMZ domain: , , , etc. I can log into these servers with DOMAIN\myadmin from the console or RDP. I am attempting to log into SERVERA and run a PowerShell script on SERVERB using PowerShell remoting. Remote Management is enabled on SERVERB. I start an elevated PowerShell session on SERVERA, and then attempt to use the cmdlet. I receive the following error: 

I am having trouble running my command to create a file screen for each drive that contains a share. I have to run this on a lot of servers, any ideas? Here is where i am at now: I can create a file screen if i manually enter the path in this first line. But I need to automate that, each serer will have different shares. 

I have a script that scans a server for drives that contains shares. After that I need it to create a file screen from a template that is already created with the same script, that part works fine. Here is how I am getting a list of drives that have shares: