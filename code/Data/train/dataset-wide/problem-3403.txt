I'm currently using the free hMailServer for SMTP, POP3, and IMAP. It has been pretty solid in the couple years that I've been using it. I've run it on Windows 2003 R2 and Windows 2008 Standard and Enterprise. I'm using SquirrelMail for webmail. This is PHP, but it wasn't that hard to setup. This is free as well. The best commercial experience that I had with a non-Exchange server was MDaemon from Alt-N Technologies. It has the best OWA like UI, and it has a connector for Outlook, so that it thinks it is an Exchange server. The price for this server is not as much as others, but still too much for me. There are several other email servers: Open Source/Free 

There's several good alternatives now days: Free: CollabNet Subversion - $URL$ VisualSVN Server - $URL$ Commercial: PainlessSVN - $URL$ 

If you don't mind a commercial solution, there a business telnet client called TeSSH, that has a rich scripting language, and can be run from the command-line. It has support for writting scripts in vbs, perl, and lua. It's fairly inexpensive at $34.95. You can also visit the TeSSH Support Forums. 

I fought with this for a few weeks. Here are the settings that I'm using on 3 ASP.NET websites that use SMTP gateway to send their emails: Address: smtp.gmail.com Port: 587 1) The port is very important. You may have to enter it like smtp.gmail.com:587 in your SMTP server. I haven't touched Microsoft SMTP in years, so I can't remember what the setup screen looks like. 2) Make sure to enable SSL for SMTP, as gmail requires it. 3) SMTP Authentication should be set to Basic. 4) Make sure that you are using an actual email and not an email alias to authenticate. This one gave me lot of trouble. This is how I got it working. 

There are many more servers out there. The ones I listed here are the ones I had tried at one point in the past. 

then its a permissions issue. Also keep in mind that doing a capture on port 69 alone will not show you all the trace. The tftp server will use a different source port than 69 for the transfer. This is why tftp usually breaks down if there is some NAT involved. So the full exchange usually goes like this for example: 

You can also add just '%' and it would work for any host, its like a wildcard. If you can't even get into the database to make the above changes, then you should change your hostname to localhost from mydomain.com. Your allowed connections to the database should at the very least be the localhost ip 127.0.0.1 UPDATE: 

Make sure you uninstall anything you added from the Centos 7 Epel repository as well. That should do it. 

As you can see a tcpdump capture on port 69 will not show you the full dialog. Also if you have NAT, once the server attemps to send a file from a source port other than 69, most NAT implementations will fail to forward the packet (only a full cone or restricted cone NAT will work, but Port Restricted or Symmetric NAT will not). 

I think you can see the point. If you are not familiar with military timezones here is the list: $URL$ You can also try to use zdump to see if your zone file is not really what you are expecting: 

The above will exit the script in case of 60 second timeout or if received a denied response in case of bad password. Otherwise if it receives a "sent" text it continues. 

Get rid of it. Thats is not an openvpn parameter. UPDATE Yes, I see you needed to add the client parameter as well. I am in the habit of setting up OpenVPN between networks with static keys and IP addresses. I never need the client parameter in those cases. 

My favorite utility is RAdmin by Famatech. My favorite feature is the ability to work behind NAT firewalls. It is mainly a remote control administration tool, but it has different connection "modes" that lets you work with the specific computer in different ways. There's another tool that I want to try, but haven't yet. It's called Network Administrator by IntelliAdmin. It will let you a lot of stuff in the background, without interrupting your users. These company also has several other useful tools. 

There are several ways that you can do this: Use a build server I've heard of teams using CCNET.net or FinalBuilder Server for this. Basically, what happens is that the build script has code to push the latest build, every time somebody makes a check in. I wouldn't recommend this for production though. This should work fine for a staging environment though. I'm not very familiar with build servers on Linux, but I know that there are a few. There's also Ant, and even Make scripts that could be used for this. Put a working copy on the staging server Just do a check out, and map the correct folder to be the root of the web app. Somebody on the team will have to manually update this working copy, but this gives you the flexibility to revert to a previous version if necessary. Caveats You'll need to make sure that you exclude the .svn folders when you pointing the website to the working copy. I wouldn't recommend using a Subversion hook script for this. You can pretty much use any scripting engine that available in Linux to do post-commit scripts. I typed "post-commit hook script linux" in Google, and got some good hits. 

One way of doing this is through path-based authorization. This way you could setup the archives to be viewed only by those people in your team. Here is a page from the Subversion Red Book about Path-Based Authorization: $URL$ You will be able to set the permissions using what's called an authz file. Just make sure to test this with different users. Play with the different settings. Once the authorization settings are to your liking, then you can open your firewall port to the WAN. Subversion has 2 servers, svnserve (svn:// protocol) and Apache-WebDAV (http:// protocol). I recommend that you use VisualSVN, if you choose the HTTP protocol. I have a product that handles the svnserve server. It's called PainlessSVN. There's a couple places where you may be able to get help. WanDisco Subversion Community Subversion Forums 

So what you need to do is add mydomain.com as a permited host in the users table, mysql database. For example: 

the important thing to note here is that it is lightning fast! That is because huge number of ip networks can be represented by a single hash instead of hundreds or thousands of lines of iptables rules. For blocking countries see this example: 

here you define a class to which a rule is applied (in this case a rate of parameter $3, which is egress in kilobits): 

The first thing I would do before proceeding further would be to test port 25 end to end with a tool like netcat. The tool comes standard with most linux distros. For example on CentOS I would stop postfix to release port 25. Then I would start netcat like this: 

if $TZ is unset and /etc/localtime is UTC then why are you using timezone T (Tango) in the date command? On my system I have a localtime of EDT. 

The first thing to check is to see if the DNS request is actually leaving for the right destination. Open 2 terminal sessions. On one type: 

As you can see the first parameter ($1) is the device interface, for example it could be the wifi interface. It also resets interface ifb0 which is an alternative to tc filters for handling ingress traffic, by redirecting it to a virtual (ifb0) interface and treat is as egress traffic there. The idea is that you can shape egress traffic but not ingress traffic, thereby if you can make all traffic egress then you can shape it. This line creates a scheduler (qdisc) for the traffic on the interface supplied in paramter $1: 

The only way one can guess at it is to check its reverse DNS entry. For example if the server detects a connection from 

Your sendmail.mc looks ok. Apart from stopping and starting sendmail again (which I would guess you have already done). I would look at the actual configuration file which would be called sendmail.cf. Make sure you see the lines: 

This sounds like a perfect job for Windows Sysinternals Process Monitor. This powerful tool allows you to monitor almost every activity on your system. While it is powerful it can be also dangerous because when not using proper filters and logging methods it can have a considerable impact on your system (Virtual Memory exhaustion to name one). In your case I'd do the following: 

This should give you some hints about what exactly is happening to your files while having low impact on your system. 

You do not need to configure the equivalent of /3GB while using a 64bit version of Windows. A 64bit version of Windows will even assign a 4GB virtual address space instead of 3GB for 32bit applications compiled with /LARGEADDRESSAWARE flag according to in this article. 

To test whether the service is running using WMI you can use this query: . However relying on the service status might be misleading if the service is started manually without a wireless card present. You can also search the adapter names for anything containing "wireless" with this query: (% is WMI's wildcard for zero or more characters). There is another class in the namespace (previous queries were using the default namespace) that represents an 802.11 configuration entry, however I found out that support for it is not always present so it shouldn't be used as the only method of detection: . I've had no experience with using WSUS Local Update Publisher so I can't help you with the exact implementation of WMI queries, but you can test them in PowerShell using or if you require a custom namespace. 

Open and double click , go to tab and note which services are required for this service to be started. Once this is done try starting up each of the dependencies that are not already started, if for some reason they are unable to start you'll be given a communicate and there should be an event in the Event Log corresponding to that problem. Depending on which service is unable to start there are different methods of further diagnostics. 

while you attempt to download a file. If you don't get any entries then its a firewall issue, if you get something like: 

Full info of components of Linux Traffic Control can be found here. UPDATE: by the way, in a regular linux box you can see the status of the traffic shaping queues by using tc -s. For example you could try to issue the following commands in your phone and they should work too: 

That is a traffic shaping (also known a throttling) script. It appears to take 3 arguments. The interface, the receive limits and the transmit limits. This first part just deletes everything: 

If you do not even see the outgoing packet, then there is an internal problem with the name resolution config on your server. 

But to answer your question, I have seen this behavior many times (at both the ISP level or the individual router level). If I read you correctly, your existing sessions still work during the "incident" but new ones do not. This is caused by either your ISP placing a limit on the amount of sessions an end user can establish, or because the router simply choked on the high amount of sessions established. It could also be the ISP's modem/router having a limit on the amount of sessions per IP. That would explain why your 'computer 2' with another IP continues to work fine. ISPs place these session limits to prevent malware like bots/trojans/viruses spreading like wildfire and bringing a network to its knees. Just imagine a home user with a 50Mbps connection opening hundreds of thousands of sessions all over the place. Then multiply that by X users and you see how this cascades down into total chaos. I suggest you retest under a more controlled environment. Maybe just one PC and in safe mode to prevent any strange software from loading that is opening the sessions (maybe a bot/virus/trojan). Then put a permanent ping (no -c or -w). I would be pretty confident that you would not see the loss of connectivity every 15 minutes. UPDATE Here is a new test for you to narrow down the issue. Since you say the failure lasts 40 seconds, it should give you plenty of time to do the following. As soon as the failure is detected, change the wan IP of your router (from 192.168.0.10 to maybe 192.168.0.20). If the connectivity is restored, it will prove to you the ISPs modem is limiting sessions based on IP.