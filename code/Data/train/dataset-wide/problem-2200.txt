Also, when I run I don't see the user that's allegedly a "slave" on Master. BUT, I do see that has replication grants: 

Unfortunately the mysqldump above creates a query. How can I skip this? What I want to happen... Say has 950 records. And has 1000. I want records 901-1000 from on , as well as the 1-900 already on (just leave them be). Replacing/Overwriting records 901-950 on is preferred. What Currently Happens... After running the above, only contains records 901-1000, and is now missing 1-900 (due to ). 

Assume shows , that master and slave are in the same datacenter (same timezone) and slave doesn't catch up to master until after the above is completed. If the two are 600s different, what is the best practice to use instead of ? 

I've analyzed the (turned on slave temporarily) to estimate 9/10 queries are a regex of the above query. 

I'm running out of disk space on a newly initiated MySQL slave server. The bulk of disk space is in where I see both and logs, each 1.1G. Does a traditional read-only MySQL slave need both of these? goes all the way back to which leads me to believe these aren't used. Here's the relevant information from my : 

In a simple MySQL replication Master-Slave configuration I have a problem where Master tries to connect to itself as a slave on reboot. So when I restart MySQL on Master, I see errors related to the same server trying to replicate to itself and I have to manually run every time I restart MySQL. How can I disable slave on master for good? Here's the relevant portion of : 

I'm currently catching up to Master, so I expect to see a bunch of 's on Slave, but I'm not sure why it also needs 's. The Master also has a lot of 's, but I expect it there. 

Apart from this, replication is running fine. Writes to Master show up flawlessly on the real, read-only, Slave. 

I'm running out of disk space on a slave due to MySQL binary logs () being stored on the slave. Here's the relevant portion of the slave's : 

I'm not sure what to think about this plan, other than I noticed that 80% on that clustered index scan. Hopefully this is what was being asked for, if not, I can repost. Thanks again! 

Currently by design, there is only ever ONE record in the INSERTED table (we are only updating one record at a time from a UI). What we have discovered is that, as the number of records increase in TABLE_B, trigger performance degrades rapidly. For example, with around 12000 or so records in TABLE_B, this update statement takes around 40 seconds (we established a timeout of 30 seconds). As I remove records from TABLE_B, performance gradually improves. As this was an unacceptable solution, I had to find ways to improve this update statement. Through testing/profiling, I found that the problem was with the second update statement (update TABLE_B). The first update statement works without problem; if I change the second update statement to its equivalent SELECT statement, it also runs fast. The solution that I found was to shove the singular record in the INSERTED table into a #TEMP table and join on that instead. I was also able to do this with a table variable as well, but performance was terrible until I created an index on it. This immediately resolved the problem and the update now runs almost instantaneously. My question is this - why did this solve the performance problem? Perhaps I am looking at this in the wrong way, but I can't imagine why I would need an index on a one record table. I have read that the INSERTED table isn't created with an index on it, but it still seems odd to me that I should need one. Thanks in advance! EDIT: As pointed out, I forgot to mention some other relevant table structure tidbits. TABLE_B indeed has a compound primary key/index created as follows: 

TABLE_C has the same index as above. All indexes were rebuilt at the start of testing. Both tables have additional triggers that are being fired - however, during testing, I disabled these triggers to determine where specifically the performance hit was. Disabling all other triggers did not improve performance. EXECUTION PLAN: I'm not super savvy on execution plans for triggers, but as far as I can tell, you can view them from the profiler with the showplan option turned on. I believe this is the relevant plan: 

I am using two MySQL server instances on the same server to filter replication to a third external server. My filter slave is using the blackhole engine as described here: $URL$ Both master and slave use statement based replication. The documentation says: 

The above statement makes me assume that if I had both of my MySQL instances set to row based replication, nothing would make it to the third, external database. Which kind of makes sense since there are no actual rows in the filtering blackhole database. However, I have been thinking... Would it not be possible for the filtering middle instance to simply pass on any row based instructions it receives to its own binlog, i.e. would a row-row filtering blackhole setup not work? 

Please note, it does not say it was unable to create the directory. It seems to assume the directory should exist at this point, but due to the removal of the mysql startup script, it never gets created. I believe this process does not attempt to create the directory. If it did attempt, one would assume a permission problem. I have disabled apparmor, and I have tried running these processes as root to rule out permission related issues. I can of course do: 

It is interesting to note that MySQL creates the /var/run/mysqld directory when the server is started, and deletes it when the server is shut down (and no other process is using it). In my /etc/init.d I have two related startup scripts: mysql and mysqld_multi. When the mysql script runs, it checks the my.cnf file, finds that there is no [mysqld] group, and therefore, starts a server instance with default settings. It creates the /var/run/mysqld directory, as mentioned above, and gets everything going. At this point I have a server instance running with default values that I did not specify. Then comes the mysqld_multi script. It looks for groups of [mysqldN] in my.cnf, and starts server instances accordingly. This will start two additional instances according to my specifications. At this point I have three server instances running instead of the two I requested in the configuration file. If I remove the mysql script from /etc/init.d, the default instance will not start, but neither will the other two because: 

I have a trigger (MS SQL Server) on TABLE_A that fires on an update that looks basically like the following (I've changed the names of the tables/trigger to simplify): 

Thanks in advance for the help! This has been wracking my brain. Note that I am re-writing the original query, which had HORRENDOUS performance due to lots of joins on the main table (which is also large). Oh yeah, there should be another couple of columns in the index, but I'm more concerned with getting the correct result set first and THEN I'll consider the performance next. 

So here's what I'm trying to do: I am trying to write a query that returns an XML formatted document that represents an 'Audit' of any particular date range. That means that the user will enter a date range and a report will be produced that includes all records from the MAIN table in that range and their history (description/explanation fields only) from the AUDIT table, as well as the current state of the record and the very original state of the record. Note that the 'current' record will always be found as the highest UNIQUE_ID in the audit table for a given combination of TABLE_UNIQUE_ID and TABLE_USER_ID. So basically, from the given picture, I should have XML similar to the following: 

However, I am running into problems where I don't capture all the history OR original records (because the DATE_INDEX on the historical records don't necessarily fall in the date range defined by the user). My question is - what might be the best way to produce output, for a given date range (which will be queried in the date_index column), that selects the following: 

This table represents records and associated actions from other tables, where the TABLE_UNIQUE_ID and TABLE_USER_ID are a composite key from the table they originated, XML is the XML representation of the data, and the DATE_INDEX a date the user defines for record (which doesn't necessarily equal the timestamp). This table is large, ranging from 1-10 million records. The main table that records are inserted from is generally in the thousands to hundreds of thousands range. In short, each set of TABLE_UNIQUE_ID and TABLE_USER_ID combined (and TABLE_NAME, but I'm not worried about that right now) represents one record in the main table and everything that ever occurred to this record (they are uniquely identified by the UNIQUE_ID) For example, here's a set of records from this table that represents ONE record and its history in our 'main' table: