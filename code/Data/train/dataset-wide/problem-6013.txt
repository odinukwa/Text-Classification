The funny thing about this is that you get two outcomes from one of the branches. This not infrequently happens in probability and statistics, and it's no problem at all, but you have to decide what to do about it. The Sleeping Beauty problem is typically formulated as Miss Beauty essentially conducting an experiment each time she is woken up. (Maybe you'll give her a cookie if she's right.) So half the time you get one experiment, half the time you get two, and by construction in the problem you're supposed to lump all of these together. (If you had an army of Sleeping Beauties and you were tallying all the answers, this is what you'd want to do.) So now we have three s in our sample space: 

You're absolutely right--given your premises you shouldn't presume that you can come up with the correct answer to the question of what God there is. You have marshalled impressive evidence that this is not possible for a typical person (that many average people have mutually contradictory beliefs), and postulated that you are average. Thus, the honest position to take is weak agnosticism: someone might be able to know, but I don't. The only way out, if there is one at all, is to become atypical in some way. You needn't necessarily become an expert in all relevant areas (theology, philosophy, science, maybe others?), but you at least need some strategy that is not generally followed but which, upon reflection, seems highly reliable. Keep in mind that the problem of knowledge is a hard one; there is no widespread consensus among philosophers about what knowledge is or how to acquire it. SEP has a lengthy summary if you're interested. So being completely assured in your knowledge seems an unlikely endpoint unless you fool yourself. One could just give up and adopt a pragmatic approach: act as though you believe that which is most convenient for other reasons (social, emotional, etc.). Or one could try to find experts who are demonstrably very accurate in certain conclusions (e.g. about the age of the earth) and see if there is a good argument about why that reliability ought to extend to conclusions where the accuracy is hard to directly check (e.g. they are not Buddhists because...um...???). Or one could seek to understand why different people disagree and thereby detect the traps into which people fall, and also become enough of an expert to not rely wholly on the opinions of those who have fallen into traps--and then, despite the odds, you might actually have a decent shot at being correct or at least less egregiously wrong. 

This means that, in order to apply negation to the different truth values, you apply it (classically) to each of its components: 

Inductive inference. All humans have died so far, therefore (in all likelihood) all humans die at some point. You are human, I take it, so there you go. 

There is no accepted term for the study of change in metaphysics, analogous to ontology for the study of what there is, or mereology for the study of the parthood relation. Many scholars resort to the phrase "the problem of change", or "the problem of persistence". 

The right way to understand Mandelbrot's claim is: the coast of England can be profitably modelled as a fractal (for some purposes). It's exactly the same kind of claim as "The granma pie at Luigi's is a rectangle". So, no: the coast of England is not literally a fractal, and it's not in the world of forms -- it's actually in England :) 

I'm not exactly sure how to classify Paul Churchland's views, but they seem to be something like what you're looking for. There's a strategy which one can take to end up as a non-foundational non-relativist of a sort, but you might quibble with one (or both!) of the non-'s: you adopt a basically coherentist point of view, except you note that, conveniently enough, people all seem to end up bound by physical laws (i.e. that is what is coherent), and so you're not really relative in any meaningful sense--even though you formally allowed the possibility, in practice people agree that, for example, snow is white, and anyone who says otherwise (when looking at white snow) is wrong, not operating with a different set of mostly-self-consistent propositions. In my opinion, this is the approach that the neurophilosopher crowd seems to take (Dennett, Churchland, etc.), although I don't recall having any of them spell it out in exactly these terms. (One could argue that they are foundational because they take as axioms something like the scientific method to learn about the world and do not question those; one could argue that they are relativists because if it so happened that there were ten different societies with radically different but equally predictive interpretations of the physical world then their approach would force them to accept all of them as "true".) 

will be supertrue (superfalse) iff under all (no) acceptable precisifications of the predicate "bald", the sentence comes out true. A precisification will have the form "... has n hairs", where, e.g., n = 0 is acceptable, but n = 10^6 is not. Sadly, the sentence above is supertrue -- which is the supervaluationist criterion for accepting it as true. Luckier folk, such as, say, Andy, might come out bald according to some precisifications and not bald according to others. Thus, 

EDIT: The above is how one can see that negation as suggested by Belnap and Dunn is reasonable. But I agree with the questioner that it is unclear that the logic, so described, is a product system. A bit more detail on how to see Dunn/Belnap's system (DB henceforth) as a product system: In DB we have four truth degrees: 

From what I have seen, there is disagreement because the premises differ (both based on self-interest): the latter group takes the value for granted and reasons from there; the former takes the creation of the work for granted and reasons from there. Of course, neither is true in some deep sense. If we could monetize and restrict the supply of oxygen, it would become extremely valuable, but that does not mean it would be beneficial; one should not simply take for granted the value of a song under the current scheme where distribution is restricted. Likewise, even for music, but especially for expensive propositions like software creation and movies laden with special effects and stars, it is clear that models that cannot fund the creators will be destructive, and therefore that being a freeloader is aiding oneself at the expense of others (which is pretty widely considered immoral). I have not seen any philosophically sophisticated treatment of the various considerations. Lawrence Lessig has written some of the more carefully-reasoned material taking the side that copyright as used now is having a sizable negative impact, but he is a professor of law, not a philosopher. I am unaware of an equally eloquent proponent of an opposing stance. 

The result of this body of work was a true change of tide in contemporary philosophy: today, many accept the existence of de re modalities, and endorse one version or other of the causal theory of proper names -- and post-Kripke descriptivism bears little resemblance to pre-Kripke descriptivism. This contemporary essentialism is, of course, a huge improvement above the Aristotelian variety. For one, it benefits from the advances in formal logic of the XXth century -- and one of the key developers of modal logic was Kripke himself --; it is also informed by contemporary science and contemporary linguistics, and, well, everything between Ancient Greece and now. If you have any more concrete interest on how contemporary essentialism differs from Aristotelian essentialism, let me know and I will try to elaborate (if I know anything about it). Kripke, S. 1980. Naming and Necessity. Blackwell. Putnam, Hillary. 1975. “The Meaning of ’Meaning’.” Minnesota Studies in the Philosophy of Science 7: 131–193. 

Atoms do not contain little tags that say "I am part of user63152", and whose unique properties determine the actions of user63152. Indeed, aside from differences in isotopes, and a handful of observables like nuclear spin, atoms of the same type are indistinguishable from each other. Thus, we needn't care whether the atoms are replaced every minute, every decade, or never. That ongoing entity which is you is you by virtue of emergent properties (like thought) which are robust to changes in which atoms you are made from. So while time may have some bearing on how we choose to prosecute crime, it should not be because there has been some swapping around of functionally equivalent parts. 

meaning that if you know you're in the midst of the experiment and it's the first time you woke up, there's a 2/3 chance you're on the heads branch. (, and by the construction of this sample space.) This is actually a more flexible framework to use--it is just as true as the other one; it's just a different formulation suited for calculating different things. The key is recognizing how the sample space maps onto what may have actually happened; if your sample space doesn't match the question you're asking, you'll get the wrong answer. For example, if Miss Beauty wants to maximize the number of cookies she's awarded, and she gets one per correct guess, she will reason: 

Well, such sentences will be true for all precisifications, because either Andy has n hairs or he doesn't, for all n. Therefore, the sentence comes out supertrue -- this is the supervaluationist for accepting it as true. Its negation ("it's not the case that Andy is bald or Andy is not bald"), by the same token, comes out superfalse. The same will happen with every other vague sentence: the supervaluationist semantics validates LEM. Supervaluationism is a semantics that validates LEM but not PB. 

is that such a statement is as hard to falsify as the original statement is to verify -- and, conversely, as easy (!) to verify as the original statement is to falsify. This point is not new, of course; it was already made by Hempel back in the day. 

The less natural cases in your examples are allowed, as is any case involving any sentences whatsoever as long as they have a truth value. This is a feature, not a bug: logic is supposed to be fully general. Having said that, typically, pragmatic (as opposed to semantic) considerations will guide our judgments about whatever a speaker means to say when they utter a sentence involving conjunctions or implications. 

Your postulate is not a tautology: whether or not one's brain is made up of modules, if the module computes both some aspect of an experience and a verbalization thereof, then the experience would be effable. There is nothing about the concept of specialized modules that prevent this kind of dual structure. Thus, one must refer to additional evidence to confirm or deny your postulate. If you want to know whether the brain actually is made up of modules, we don't yet know enough to say for certain, but see books by Oliver Sacks and V.S. Ramachandran for extensive evidence that there are very specific functions executed by certain portions of the brain. There isn't much evidence for verbalization distributed on a per-module basis; lesions in Broca's area suggest the opposite, actually. If you want to know whether certain experiences are ineffable, that will depend on what you count as experiences. Given that your behavior can be altered by things you are not aware of, the answer is presumably "yes". I'm not sure where that leaves your hunch, though an apt summary might be, "Cognitive science is messy, and details matter." 

I know nothing about the Tao Te Ching, but the sentences you quote are not (logically) contradictory, or paradoxical: 

In any event, that we can think and talk about stuff we are not (in Russell's turn of phrase) acquainted with is unproblematic: we become competent users of a singular term that refers, say, to Socrates (whom neither I nor anyone I know have ever met) by becoming a link in a chain of speakers that takes us all the way back to people that was acquainted with Socrates. We are, as Gareth Evans puts it in "The Varieties of Reference", introduced to a name-using practice. You may want to check Mark Sainsbury's "Reference Without Referents" for a more contemporary discussion of these ideas. In Sainsbury's version of the theory, a name-using practice can exist even in the absence of a referent -- think of the unsuccessful name 'Vulcano', that tried to refer to a (nonexistent) planet between Mercury and the Sun. This would be an example of speech (and thought) without an entity we are thinking or talking about. Believers in God, hell, and the like, I take it, believe that we have been introduced to name-using practices of terms that refer to those entities: think Moses, or Christ, who were, the story goes, acquainted with some of those things. An interesting case is our apparent ability to refer to abstracta ("the number 2" successfully refer to the number 2, it seems). Here, of course, acquaintance or causal contact of any kind is impossible. One idea that I find attractive is that we don't really refer to such entities. We merely make believe that we do; we fictionalize about them. For the best worked out theory along these lines, read Kendall Walton's "Mimesis as Make-Believe", or the latest papers by Stephen Yablo on the philosophy of mathematics. 

Everything people do is political to some extent, if we conceive of politics as the intentional influence applied to individuals / everyone as a consequence of outlooks or beliefs held by a majority or a group of individuals in a position of sufficient power. The point of politics is to influence people. If it didn't work, people wouldn't bother with it. That said, the sociology around science is awfully good at shielding the methodology required for generation of reliable and lasting knowledge from the pressures to get results of a certain sort that would be convenient or desirable (from the perspective of individuals or groups in a position of influence). (Incidentally, I do not know why you say that science (as a process) is not a way of testing explanations. That is just about all it is.) "Hard" sciences are very heavily data-driven, and no matter how much you might want data to come out a certain way, it is very hard to get those wants to reliably produce the "right" results especially across different labs and after taking the precautions that one is supposed to take (scoring done blind or double blind, appropriate controls, etc.). It is possible for enough pressure to be applied that normal processes are not followed, but it's almost always painfully obvious when you really look into it. (A lot of normal, uninfluenced science doesn't have proper methodology or controls also. Scientists need always be on guard for such things.) Because one is not supposed to lie or fabricate data (and the consequences are supposed to be, and usually are, really horrible socially), and because one is supposed to report clearly one's methodology (and it is obvious when one has not), coming up with apparently very strong evidence that something is true when in fact it is not is incredibly difficult. That, if it could happen, would be the most damming kind of non-objectivity. Instead, politics is limited to kind of a soft power to influence results: by allocating funding to only look in certain areas or by making one a pariah if one gets certain kinds of results. This may leave our knowledge incomplete or uncertain in politically-motivated ways, but it doesn't much taint whatever we conclude we know robustly. Of course it's always possible for everyone to be so strongly culturally biased that nobody manages to see through a flaw in interpretation, or for nobody to challenge the dominant view on things, but because of the data-centrism you typically notice in such cases that we just don't understand the process very well: the science is not all that predictive. And that goes for practically all of the softer sciences. So whether or not they are influenced, we already know we shouldn't be too sure of these results. So the hard sciences are tarnished a bit by politics, but not terribly much.