The main objective of differential backup is to reduce your Recovery Time Object(RTO). In more simple terms in event of disaster you can quickly recovery database using differential backup. Supposing you do not have inbuilt script to restore backups so restoring full and lot of transaction log backups after that is time consuming as compared to restoring full backup then latest differential backup (since it is cumulative) and few log backups after that. In two scenarios which you have shown above in case of disaster you would have to restore 

VAS: Virtual address space is total amount of virtual memory a process can see in the system when created. When SQL Server process requests memory it is first mapped to VAS address in the region. VAS is 8TB for 64 bit system and 4 GB for 32 Bit system. Every process which requests memory sees virtual memory which equal to 4GB or 8 TB as per architecture(32 or 64 bit) it is running on. Now after process is mapped to VAS memory manager finds out physical memory to which it can be mapped and finally commit memory to this process when this is eventually done the memory is allocated and is called physical memory allocated to process. Virtual_memory_committed: This is total memory used by SQL Server (RAM+ PAge file). This is basically sum of physical memory used and memory used in page file. Virtual_memory_reserved: This is total VAS reserved by all SQL Server processes. Pages_kb: Amount of memory pages allocated to process. Suppose this value is 600 so memory allocated is 600*8 (a page is 8 KB) =2400KB or 2 MB approx. I hope this clears few things for you 

If you are using 2008 R2 and above(I can see you tagged question as SQL Server 2014) you can use DMV sys.dm_server_registry to get all information about registry values for SQL Server. Just go to SSMS and run below 

Edit: Regarding low virtual memory condition its coming because page file is not set correctly. You must use This Link and This Link to configure appropriate value. This link will help to guide how to change There can be many reasons for low virtual memory condition. The current workload which is running on OS is memory hungry and OS due to limited RAM has to use virtual memory for temp storage and ultimately its getting so much utilized that its giving warning. So you must check what all processes are running. Page file is adjusted as per memory committed if more memory is committed page file value changes use below counters to determine appropriate value of page file Memory: Committed Bytes Number of bytes of virtual memory that has been committed. This does not necessarily represent page file usage - it represents the amount of page file space that would be used if the process was completely made nonresident Memory: Commit Limit Number of bytes of virtual memory that can be committed without having to extend the paging files. Paging File: % Usage Percentage of the paging file committed Paging File: % Usage Peak Highest percentage of the paging file committed 

NOTE: DBCC CHECKDB does not performs complete consistency check of transaction log it only checks the active portion of the log. The active portion of the log is checked and used as a by-product of creating a database snapshot to run the consistency checks on. There’s no consistency checking of the transaction log – only checksums that are checked as log records are read, for whatever reason. To get with log corruption I suggest you read this SQLmag.com article. Paul has given reply to transaction log corruption. What he has suggested is 

When you failover a cluster resource group from a node to different node SQL Server instance and other resources which are part of this resource group is stopped on current node and then ownership is changed to node which you are failing over to. After ownership is changed SQL Server is restarted with owner as new node. During failover SQL Server might go in crash recovery mode so any Inflight transactions( transactions which were running) will be rolled back. SQL Server goes through process of recovery to rollback and rollforward transactions so as to bring database in consistent state as it was just at time when failover happened. Cluster disk, netwrok name and MSDTC are also part of resource group so they also move to different node. 

Edit: As per question regarding believe me its not showing correct value for buffer pool. For my system with 4 G of RAM target pages are 7979008 with almost nothing running on the system. This is totally absurd and I would request you not to look at this counter. I had a chat with one of the experts on this field to confirm the behavior and he told me you should avoid looking at buffer pool output and target pages specially on NUMA system its calculation( way of calculation) is not correct. I can raise a connect Item but it would take few months to get response from MS team. Not every thing in DBCC MEMORYSTATUS output matters to normal users many things are internal to MS and they would just not give any information regarding the same. If you want to monitor SQL Server memory usage please use below query. 

PLE on system is measure of how volatile your buffer pool is, its also measure of amount of I/O activity going in your SQL Server. MSDN says that 

I would suggest to setup one job that would backup the transaction logs (serially). This would also make sure backup does not heavily utilities the I/O because you are running backup for database one at a time. What could be possible drawbacks with running in parallel 

= 29116348 KB which is This is total SQL Server memory utilized (RAM+Pagefile) by SQL Server. So you can see now amount of SQL Server memory curently paged out to disk is 27G -0.4 G. You need to find out why and what has caused SQl Server to request so much memory. I strongly suggest you to appply SP3 ASAP. 

As far as I know if you change recovery model of database during maintenance window time or when load is relatively less there wont be any problem. It wont create a situation. 

I am sure you are running shrink job by changing database recovery model to simple and then changing it back to full and then shrinking it. This would break log chain and you would need full backup again to start the log chain. That is why log backup is failing 

Question is little incorrect or not properly formed. For one principal you can have only one mirror server. Its is not like Logshipping where you can have multiple standby servers for one primary server. 

If you run it you can see lot of information related to database, pages,extents,locks ect. But it would be difficult for you to extract information from it as it requires a level of expertise to decipher the output. If you read Books Online document SQL Server Transaction Log architecture and Management it says Many types of operations are recorded in the transaction log. These operations include: 

Yes there is. The header of each page in cache stores details about the last two times it was accessed, and a periodic scan through the cache examines these values. A counter is maintained that is decremented if the page hasn’t been accessed for a while; and when SQL Server needs to free up some cache, the pages with the lowest counter are flushed first. The process of “aging out” pages from cache and maintaining an available amount of free cache pages for subsequent use can be done by any worker thread after scheduling its own I/O or by the lazywriter process. Having said that I would like you to read How It Works: Bob Dorr's SQL Server I/O Presentation Take the following as an example where the table is 1 billion rows. Simplified the process to discuss.