I assume that $r(t)$ is continuous. The idea is that, this Poisson process with time-varying parameter $r(t)$, as the limit of Bernoulli trial with time-varying probability of success, is memoryless: For a generic finite partition $\mathscr{P}$ of $[0, T]$ as $\{[0,t_1),[t_1,t_2),[t_2,t_3) \ldots,[t_{n-1},T]\}$, let the $n$th cell following a Poisson distribution with a fixed parameter $r(t_n)$, so $$P_{\mathscr{P}} = 1 - \underbrace{e^{\sum_{k=1}^n-r(t_k)(t_k-t_{k-1})}}_{\text{Probability of no accidents}}$$. So $P = 1 - e^{-\int_0^Tr(t)dt}$. Notice that the Riemann integral $\int_0^Tr(t)dt$ is the limit of a net indexed by the set of all finite partitions of $[0,T]$ with vanishing maximal length of cell with respect to number of cells. $f(x)=1-e^{-x}$ is continuous, so this limit preserves. 

What's the relationship among universal type space, Aumann's semantic knowledge model and Samet's syntactic knowledge model? Here's my confusion: Regarding universal type space and the model in Aumann's Agreeing to disagree, I used to think they're really the same thing from two different angles. The type space construction is a bottom-up construction. It starts with all the payoff relevant parameters from players' point of view, and generates a set of states of world in the end. Aumann's model is top-down. The set of states of world and players' knowledge as partitions are exogenous. Interesting results are derived by imposing some consistency rules. It seems to me, there's a one-to-one correspondence between a player's type in the former and a cell( or atom, block) in the selfsame player's partition in the latter, because a player's strategy has to be measurable with respect to them in these settings. But after having a skimming of an unpublished paper by Robert Simon,The Common Prior Assumption in Belief Spaces: An Example, I found it's not the case. In that paper, he actually imposed a partition on Merten and Zamir's type space(he claimed so) for each player, so there's no such correspondence. Another thing that is weird is that it seems to me he's actually not working on on a belief space. It looks like he's working on a model in Dov Samet's Ignoring ignorance and Agreeing to Disagree, which is homeomorphic to a Cantor set, a set which is generated by assigning truth values on underlying propositions and the use of non-repeated knowledge operators of the same player. It seems to me Dov Samet's model is not homeomorphic to Merten and Zamir's type space, because we might need to add operators of belief from probability 0 to probability 1 in Dov Samet's model to do that, and the generated set of state of state of world will have a cardinality strictly larger than a Cantor set. 

In your basic introduction to information economics, the two classic interpretations of screening with hidden information correspond to monopolistic screening or a principal agent problem. Viewing the situation through the lens of the principal agent problem; there is a firm who wants an agent to produce a good, and the agent has private information as to how costly it is to her to produce a good of a certain quality. That is there are multiple types of agents--if there is just one type, this is just the full information (first-best) case, and the screening problem is trivial. The producer's problem is to design a contract in order to maximize expected social value while minimizing the agent’s rent. The basic problem with moral hazard, on the other hand, need not concern an agent with multiple types. Instead, the agent has multiple choices of effort. Now, the principal's problem is to choose the optimal level of effort and the best contract with which to elicit that effort level. To sum up, in the hidden information (screening problem), there is an agent with a private type, and the principal designs a contract in order to maximize some objective, given this information asymmetry. In the moral hazard problem the principal chooses a contract in order to elicit the optimal level of effort. Finally, as a caveat, this distinction is only clear at the introductory level, where the problems are very basic. One can easily have more complicated mechanism design problems that incorporate elements of both. 

In this video (from 7: 30 to 9: 00)on Youtube, Battigalli mentions the state of world for a simple three-legged centipede game, which, in his own word, is 

I'm interested to know the exact magnitude of impact of Subprime Mortgages crisis on major players in investment banking. In particular, how can I find data for percentage of revenue from Subprime Mortgages in total revenue for major banks, like Goldman Sachs, Morgen Stanley, The Bear Stearns and Lehman Brothers? 

What does Pierpaolo Battigalli really mean? If the actions for a player chooses has been specified, then it automatically specify a pure strategy. By this methodology, he seems to want to distinguish a game structure with commitment and a game without, but how? Added: Here is the slides used in the video, and here is the corresponding paper. 

I would like strongly recommend David Kreps' latest textbook, Microeconomic Foundations I: Choice and Competitive Markets . It contains true virtuosity and is very inspiring. Take utility representation theorem as an example. Kreps forsake the assumption in MWG of taking $\mathbb R^n$ as the underlying space so that readers won't be left with the false impression that this theorem is of limited interest. I also $\heartsuit$ the presentation of GE as a generalized NE which helps developing connections between different areas. 

I think this is a poor oversimplication of Robert Lucas's maxim. It's one thing that Robert Lucas models markets as if "always in equilibrium", it's quite another Robert Lucas claims it's an empirical truth that "market is always in equilibrium". Lucas(1978) explained briefly why he chose such methodology which doesn't faithfully reflects reality: 

This is just @Sadem's argument formalized. Note that we do not need to use any utility function representations, we can use just the preference over lotteries in conjunction with the axiom of independence. The axiom of independence, formally stated is: $L'' \succeq L'$ $\Leftrightarrow$ $$\alpha L'' + (1-\alpha) L \succeq \alpha L' + (1-\alpha) L$$ $\forall L, L', L'' \in \mathcal{L}$ and $\forall \alpha \in (0,1)$. Define $L'' := L_{1}$, $L' := \big((0,1/11), (5,10/11)\big)$, $L := L_{1}$, and $\alpha = .11$. Thus, the first statement implies $$\alpha L'' + (1-\alpha) L \succ \alpha L' + (1-\alpha) L$$ Now, define $L''' := (0,1)$. Hence, the second statement implies $$\alpha L'' + (1-\alpha) L''' \prec \alpha L' + (1-\alpha) L'''$$ Thus the independence axiom is violated. 

Nope, every pure strategy equilibrium can be characterized as a degenerate mixed strategy equilibrium. That is, it is a mixed strategy in which a pure strategy is played with probability $1$. 

Hence, $$\begin{split} M &= 1 - \int_{0}^{7/11}\frac{2-a}{3}da - \int_{7/11}^{1}\frac{3a-1}{2}da\\ &= 1 - \frac{259}{726} - \frac{32}{121} = \frac{25}{66} \approx .3\bar{78} \end{split}$$ Finally, $$T=1-\frac{25}{66}-\frac{101}{264} = \frac{21}{88} \approx .238\bar{63}$$ Since $$\begin{split} \frac{101}{264} &> \frac{25}{66}\\ \frac{101}{264} &> \frac{21}{88} \end{split}$$ the result is shown. 

History $(D,D)$ (Yes, this is with some abuse of notation.): On Path: Each player gets an average payoff of $4$. Deviating: Say player $1$ deviates and instead chooses $H$. Then the resulting sequence of actions is the alternating sequence, $(H,D)$, $(D,H)$, $(H,D)$,... Accordingly, player $1$’s sequence of payoffs is $(8,0)$, $(0,8)$, $8,0$... Player $1$'s average payoff is $(1-\delta)\big(8 + 0 + \delta^{2}8 + 0 + \delta^{4}8 + \cdots\big)$, which is $$(1-\delta)\frac{8}{1-\delta^{2}}=(1-\delta)\frac{8}{(1-\delta)(1+\delta)}=\frac{8}{1+\delta}$$ Hence, there is no profitable deviation here iff $$\begin{split} 4 &\geq \frac{8}{1+\delta}\\ 4\delta &\geq 4\\ \delta &\geq 1 \end{split}$$ Thus, $\delta \geq 1$ is a necessary condition (not necessarily sufficient because we still need to check that following tit-for-tat is still optimal for the other histories. I'll leave that to you!) 

Maybe it will be useful for you to start: [$URL$ As asked I summarize the core ideas, written in the link. So, higher interest rate decreases the supply of the money: 

I'm not a Marx expert, but I've read The Capital some years ago and as far as I can remember Marx said that only the workers produce value. All others' wages (and the workers' wages too!) and other costs are covered by the produced values of the workers, so the others decrease the "profit", which could remain at the workers otherwise. Therefore Marx suggested the workers to make collectives without any capitalists. 

If a capitalist does the same work as any other worker, then he/she is in a worker state. No matter he/she is the owner meanwhile. All others' wages and costs (owner, who doesn't work or "just" organize the process, the management, etc) are covered by the value produced by the workers, who produced the products, which were sold. Of course there are useful activities, which leads to higher productivity (for example invent new technologies), but until they are not in use they are only take money...but from where? From the profit. And to reach a profit an extra value has to be produced by the workers. If these new technologies are started to be used, who guarantee that the extra profit from it will be shared with the workers if not the workers own their tools, equipments and manage their own collectives? There is a difference between these two cases: a; when the workers are the owners, but also have to do activities which don't produce real value or b; they only "working powers in human bodies" for someone else. Of course, Marx didn't take today's technologies into consideration, because he lived in the XIX. century. That was a different world, where the human working power was the main source of the production, because it was the cheapest (even against the machines at that time). I think he mainly raised his voice against the exploitation of the workers, who lived in deplorable circumstances, while the factory owners became richer and richer. Finally, his opinion maybe wasn't perfect, that's why "critics of Marx" exists. :-) 

As a caveat, disclaimer, I am not too familiar with Evolutionary Game Theory and it is quite outside my research area/main areas of expertise. However, I can show here that range of $(a,b)$ for which $B$ is a best response is strictly greater than for either of the other two strategies. To that end, You can characterize the range of $(a,b)$ for which $B$ is a (strict) best response by solving the system $$\begin{split} 4−2b−3a &\> b+2-2a\\ 4−2b−3a &> 1+a-b\\ \end{split}$$ Or, $$\begin{split} 2 &> 3b + a\\ 3 &> 4a + b\\ \end{split}$$ Or, $$\begin{split} a &> 7/11, b<3-4a\\ a &\leq 7/11, b<\frac{2-a}{3}\\ \end{split}$$ 

I agree with the comments that suggest that the question is almost indecipherable. However, it should be easy, given the cdf, to derive the bounds. Why? Well we know for a cdf $F$, we must have $F(\underline{S}) = 0$ and $F(\overline{S})=1$. We can use the latter to work backwards from the upper bound i.e. We guess that $F(s)$ is of the form $$F(s) = k\bigg(\frac{S-v_l}{v_h-S}\bigg)$$ We must have $F(\overline{S}) = 1$ and using your solution, we have $$\begin{split}F(\overline{S}) = F\bigg(\frac{7v_h+3v_l}{10}\bigg) = k\bigg(\frac{\big(\frac{7v_h+3v_l}{10}\big)-v_l}{v_h-\big(\frac{7v_h+3v_l}{10}\big)}\bigg) &= 1\\ k\bigg(\frac{7v_h+3v_l}{10}\bigg)-kv_l &= v_h-\bigg(\frac{7v_h+3v_l}{10}\bigg)\\ \frac{7kv_h - 7kv_l}{10} &= \frac{3v_h-3v_l}{10}\\ 7kv_h - 7kv_l &= 3v_h-3v_l\\ k &= \frac{3}{7}\end{split}$$ Thus, I suspect that your mixed strategy for the high type is given by the cdf $$F(s) = \frac{3}{7}\bigg(\frac{S-v_l}{v_h-S}\bigg)$$ 

You're correct on the definition of the strategies: Albus' strategy set is $S_{A} = \big\{N,E,S\big\}$, and Minerva's is $S_{M} = \big\{a, b\big\} \times \big\{a, b\big\} \times \big\{a, b\big\}$. Remember, a strategy is a contingent plan that prescribes an action at every possible node at which a player plays. Then, the unique equilibrium (via Backward Induction) is $(N, b, a, b)$. The others you mention are not equilibria, because they involve incredible threats, e.g. if Minerva found herself at the decision node following a choice of $E$ by Albus, she would never choose $b$.