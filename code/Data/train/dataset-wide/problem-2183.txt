A few options: Allocate different ID ranges for each user, use composite primary keys, use UUIDs or use some of the mechanism that enables the auto_increment feature to be used in master-master replication: 

Is creating columns for all the combinations the correct way? Based on the little information you have given us: No, columns for all combinations is probably not the right solution. Imagine if you suddenly get more products, then you will need to add more columns. Or if some products are removed. Designing your schema so you have to alter a table to deal with something as trivial is bad practice. No, you should probably use records instead. Let's say you have a table, something like this: 

Source: Multi-Master Replication (Percona XtraDB Cluster - this page also has a diagram which explains the problem). Another approach is to define one of the nodes as the 'master', and then write only to that node. Critical reads should then also be directed at the 'master' node, whereas less-critical reads can go to any node. PS: Note that if you plan to write to all the nodes, you might find the following article useful: Galeraâ€™s big gotcha for MySQL users. 

Assuming you access the cluster through a DB proxy, then use a monitoring tool (Nagios, Zabbix, maybe PMM, maybe MONyog, ...) and log the availability of the cluster. Uptime is then the time since the last failure. the error log on each of the cluster nodes to find the timestamp of the most recent bootstrap. This coincides with the timestamp for when the status variable is equal to 1, and can be found in the error log with something like: 

Yes, the server would still be accepting remote connections. And yes, it probably did what it was supposed to do. doesn't set neither in MariaDB nor in MySQL. It does however allow you to remove root accounts that are accessible from outside of localhost, as you have already done. If you don't have any database users with host != localhost, then remote login shouldn't be possible. You can of course also block the MariaDB server port in your firewall. 

This seems like a problem with mysql-workbench (tested with version 6.3.9 on Fedora and MySQL 5.7 (CentOS)) where emojis are not converted to the correct unicode. In the command-line client the emojis get converted to codes when they're pasted in, so the query 

... then you could use the same statement as before. There would be no column to worry about, the would be unique (since it's the primary key) and the sequence could be seen from the new column (which might be useful on its own). You can alter your current table to get the new one with a statement similar to this: 

Just to be sure, you can explicitly specify the port in the command by adding . (This was the solution to another question where error code 2003 was the issue.) To check that slave_user has the right grants, run this on the master: 

For some use-cases, the (usually) small delay before the data appears on the slave isn't a problem. For "critical" reads, you could send them to the master only. Another solution would be to use so-called synchronous replication, though actual synchronous replication doesn't really exist. The technology used in Galera Cluster (used by MariaDB Cluster and Percona XtraDB Cluster) is virtually synchronous. The same is true for MySQL's InnoDB Cluster. 

I think the answer to both of your question could be MaxScale. MariaDB MaxScale is a database proxy which supports connection pooling, load balancing, automatic failover, query routing, read-write splitting and more. The query routing feature is used to achieve sharding. For a tutorial, try e.g. this one. An alternative solution could be ProxySQL, which is a competing database proxy product with some of the same features, including sharding. The advantage of ProxySQL over MaxScale is the license (GPLv3 vs BSL). 

Additionally, it's possible that another software (such as cPanel) might change the variable dynamically after MariaDB has started. To see which options the MariaDB server will get from the option files, run: 

For any row with in that doesn't exist in the and columns will be NULL. If it does exist, the and columns will have the values from . For any row with in that doesn't exist in , the whole row will be added to the new table . 

Have you tried creating the /var/run/mysqld directory, with rwx permissions for the mysql user? Judging by the error messages, that seems to be a good place to start. The other error message should probably also be addressed, regarding not writing to syslog and the mysql error log at the same time. I'd suggest inspecting your MySQL config files under /etc/ to see if you can disable the syslog option. Also, it looks a bit strange that you're using mysql-wsrep-5.6 with MySQL 5.7. Is there a mysql-wsrep-5.7? If not, perhaps you need to use MySQL 5.6. 

Then you can update the "default" state. (If you use DELETE/INSERT, then you need a different trigger): 

Additionally, for warning messages, the log_warnings variable need to be > 0. There are different warning levels, and the higher the value of log_warnings, the more kinds of warning messages are logged. For details, see the documentation for the log_warnings variable. To see you current setting, run: 

You will probably run into more conflicts than just what is listed in the question, e.g. TCP port, datadir, /etc/my.cnf, as well as maybe pid and socket. I think these configuration issues can be overcome by using different settings (MariaDB-specific sections in the .cnf files). I'm not sure whether installing MariaDB from packages alongside a standard installation of MySQL (from packages) is feasible. has an option and which allows you to set a non-standard install path for rpms marked as relocatable. Not all rpms are reloatable. However, see Installing MariaDB alongside MySQL (mariadb.com) which talks about installing MariaDB 5.5 from source code alongside an existing installation of MySQL. See also Running Multiple MySQL Instances on One Machine (mysql.com) which talks about installing multiple MySQL instances on the same server. This may or may not be useful. Perhaps the solution that would require the less effort would be to install MariaDB in a Docker container. See e.g. MariaDB and Docker use cases, Part 1: 

This is probably a character set problem. To verify, you'll have to find the character set of the column, or if none defined, then that of the table, or if none defined, then that of the database or or if none defined, then your MySQL default. To see the character set and collation of your columns and table, you can do e.g.: 

Then wait for an interval of your preferred length, and then re-run the query, and store the difference somewhere. (Obviously, running the query itself is a SELECT, so it will influence the result, as will an INSERT query be if you store the results in the same MySQL instance.) For reference: Server Status Variables: Com_xxx 

You can specify a different AUTO_INCREMENT position when you create the tables for each individual employee's database so that there is a range of IDs allocated for each employee. E.g. 

This is just a warning, and in itself isn't a cause for concern. I think it's unlikely that this caused the node to stop. See also Percona's blog post about it. And then: 

So you can store the result from in the column, and then retrieve it using . The above code is also compatible with MariaDB (at least 10.2). MySQL additionally supports an init string to the and functions, see the example at the link to above. MySQL also offers InnoDB tablespace encryption, but that will encrypt the whole table, not just individual columns. 

Maybe consider if the geometry types (POINT) would be useful instead of your , doubles. Geometry types are indexable in InnoDB as of MariaDB 10.2. Looking at your configuration, I think your query cache is set quite large. (Though it might make sense in your specific case, I don't know.) This can result in degraded performance due to lock contention, as the query cache is locked while it's updated. I can see how the query cache might make sense in your use case if you're not writing to the database all that frequently. Note however that MySQL is retiring support for the query cache in MySQL 8.0. I don't know what the fate of the query cache is on the MariaDB side. 

And the warning is code 1411 . ANSI_QUOTES is not enabled, and I get the same warning if I use single-quotes. From what I understand reading the documentation, the query should work: 

I'm surprised that time_zone values and give different results for , given that my time zone is GMT, +0000. This looks like a bug to me, but maybe there's something I'm not understanding. 

I understand from the comments that your application is writing to more than one DB node. This is known for causing deadlocks, and this appears to be the underlying problem in your first crash log that you uploaded to the MariaDB Jira. If you're using a DB proxy (like MaxScale or ProxySQL), then make sure to use a read-write splitter so you write to only one node, but read from all. 

If you want persistence, then obviously you can't use a RAM disk for the data files. If you're planning to use a RAM disk for all the database files (table data files, log files, temporary files, ...) then it would seem you will need more than double the amount of RAM as required by a memory-only database system, since you're storing both the tables themselves and their data files (which would normally be persisted to disk) in RAM. How are you going to guarantee that the RAM disk is large enough for all possible use-cases? For example, on-disk internal temporary tables can be created when a query is too large to handle in memory. So if you use a RAM disk as your disk storage, then you risk running out of "disk", which is likely to have some detrimental effect. (And this leads me to think there are good reasons why MemSQL has such large RAM requirements ...) Maybe there is a way to configure your storage / RAM disk so that part of the storage is on the RAM disk (the part that is used first / preferred) and the other part is on real disk? 

The most common solution is, as commented by @Akina, to store images in the file system, and just store some kind of reference (file path or similar) in the database that allows you to uniquely identify the image in the file system. However, there are also use cases where it makes sense to store the images directly in the database. Maybe you don't have permissions to store files on the file system. Maybe you have a lot of RAM and you don't expect the images to take up all that much space, and putting the files in the database means you only have to backup the database and not have to worry about a separate backup of the file system. One of the big disadvantages of storing the images in the database is obviously that they can make your database grow to an unmaintainable size where backups take a long time and you may have to take special steps to avoid disrupting users (i.e. to avoid locking) for very long while running the backup. Maybe you can also no longer fit the whole database in RAM, which will lead to slowness. In addition, images usually require columns, and these come with their own set of disadvantages. 

It's not entirely clear what you're asking, and your SQL statements don't work, but assuming you mean something like this: 

You need to drop and re-create the database. So you need to use some extra / different options when creating the dump file: 

As of December 2017, unfortunately the answer to all three questions a), b) and c) is no. One thing you can do is try to avoid that unnecessary data get loaded into the buffer pool. One way this could happen is when you backup a database with logical backup tools such as mysqldump and mydumper. So instead you could use Percona's xtrabackup or other physical backup tools, and/or you could tweak and so as to minimize the impact of logical backups as well as full table scans. (See e.g. this for more details.) 

(Note however that all the s for existing records will then be set to the current timestamp when you run the .) 

First of all, the relationship between tables and is the wrong way. You want many per , so therefore you should remove from the table and add to the table. This would then be a foreign key to . Similarly, the relationship between and is the wrong way - you want (potentially) many files per message. So remove chat_messages.file_id and add chat_files.chat_message_id, and make that an explicit foreign key. You should add an id column (primary key) to the table, and make be a foreign key to that. You may in the future find that you need to store more information, e.g. for the users. You can then add extra columns as the requirements become clearer (which is usually not a problem, especially with the right tools such as pt-online-schema-change), or you can anticipate these requirements now by adding more general-purpose columns that your application then has to "decode" or interpret. If you're using MySQL 5.7+ then you can even use the JSON data type and store JSON data in these columns. 

In principle, yes. Though it depends on the s for your particular database user. If you can't change the values, then try another database user or create a new user with the correct s. You should be able to click on a table to list its records (it's the right-most icon when you hover over the table in my MySQL Workbench version), then double-click on the value you want to change, change the value, then hit the 'enter' key on your keyboard, then click the 'Apply' button below the table listing. 

You can obviously modify this to use the start value, step and end value of your choice. As for the second question, it's then trivial to expand the above (with inspiration from part of Ronaldo's answer): 

That said, there are cases where InnoDB will create on-disk temporary tables even if the query could potentially have been handled in memory. See 8.4.4 Internal Temporary Table Use in MySQL for details. These are cases when a RAM disk could perhaps have been helpful. Here's a blog entry (from 2012) about how to put the MySQL tmpdir on RAM-disk. However, any RAM used for the tmpdir in a RAM-disk solution is RAM that could potentially have been used for the all-important InnoDB buffer pool. So make sure you have a large enough buffer pool for your data working set before you consider using any of your RAM on a RAM disk. Assuming you put the tables' data files on the RAM disk and you plan to snapshot it, then you also need to take steps to ensure you're getting a point-in-time consistent backup. These kinds of steps will make the RAM disk slower. So alternatively, instead of using a RAM disk, you could use Galera as is, but take all possible precautions to avoid the creation of on-disk internal temporary tables. You should obviously also make sure to use SSD instead of spinning disks. Another technology to consider may be MySQL NDB Cluster: