Therefore the measure of spikiness is usually based on estimators of a shape parameter of an assumed data generating distribution. For example, If you assume the data is generated from a beta distribution, then the spikiness can be measured by an estimator of its shape parameter. This is the classic thinking when a parameterized model is assumed for the underlying probability distribution that generates the model. Following this idea, a classic test of comparing how similar two probability distributions are is the Kolmogorov-Smirnov test. It induces a nonparametric measure of similarity, and therefore could be used for exploring spikiness. In this direction of characterizing spikiness. In other words, spikiness can be measured by an appropriate choice of norm on the space of probability distributions supported on $[0,1]$. To be honest I think this is more like a reverse Schwarz inequality rather than a Jesn inequality since I do not see how convexity comes into play. If that is the case, then such a sufficient condition reduces to a choice of $S$ such that majorant conditions hold. For any isotonic functional $A$, including most norms, $0\leq A(f^{2})A(g^{2})-A^{2}(fg)\leq\frac{1}{4}(M-m)^{2}A^{2}(g^{2})$ where $m\cdot g\leq f\leq M\cdot g$ In this case we can take $f=g$ and see if we can related the majorant coefficients $M,m$ with the $\lambda(S)$, which I believe is a common pratice in deriving a bound since the above inequality provides a sharp bound. [1]Gray, William Charles. Variable norm deconvolution. No. 19. Ph. D. thesis: Stanford University, 1979. [2]Dragomir, Sever S. "Reverses of Schwarz inequality in inner product spaces with applications." Mathematische Nachrichten 288.7 (2015): 730-742. 

The Kauffman bracket polynomial for a knot diagram $D$ is a Laurent polynomial $\langle D \rangle \in \mathbb{Z}[A, A^{-1}]$. Although it is invariant under Reidemeister moves of type II and III, performing a type I move on $D$ will change $\langle D \rangle$ by a factor of $-A^{\pm 3}$. So $\langle D \rangle$ is not a knot invariant. One solution to this is to define a normalised bracket polynomial: $$ X(D) = (-A^3)^{-w(D)} \langle D \rangle \quad \textrm{where $w(D)$ is the writhe of $D$}. $$ This is invariant under type I moves too and so is a knot invariant (it also turns out to be a reparametrisation of the Jones polynomial). However an alternate solution is to simply say that the bracket polynomial is only defined up to multiplication by a power of $-A^3$. Although this appears to be disregarding some information, it is still possible to use it to show that many pairs of knots are distinct. For example, as $$ A^{16} - A^{12} - A^4 \neq (-A^3)^k \times 1 \quad \textrm{for any $k \in \mathbb{Z}$} $$ we can still conclude that the trefoil is not equal to the unknot. However, is this actually a weaker knot invariant? That is 

More generally I do not think there will be a characterization in a simpler form than [Eichelsbacher&Reinert] of $X \sim Q \Leftrightarrow E[(\mathcal{A}f)(X)]=0$ as you asked for. Here is my reasoning, since in discrete probability distributions the joint density of sample function usually contains order statistics as sufficient statistics. The related empirical process will based on the order statistics[Daly et.al]. If we write the stochastic empirical process in characterization(that is what Stein did) of some differential equation like $E[(\mathcal{A}f)(X)]=0$ then it must include such a sufficient statistics. Moreover if you read [Eichelsbacher&Reinert] carefully you can see they argue that in general a Gibbs measure must contain necessary many terms to describe the sample functions. References [Hwang]Hwang, Jiunn Tzon. "Improving upon standard estimators in discrete exponential families with applications to Poisson and negative binomial cases." The Annals of Statistics (1982): 857-867. [Eichelsbacher&Reinert]Eichelsbacher, P., and G. Reinert. "Stein’s method for spatial Gibbs measures." Preprint (2003). [Daly et.al]Daly, Fraser, Claude Lefèvre, and Sergey Utev. "Stein's method and stochastic orderings." Advances in Applied Probability (2012): 343-372. 

This question is inspired partly by this question Any reference on Brownian Motion continuity. In this post, the author asked if the following three axioms can define a Brownian motion without assuming the continuity axiom "4.$W(t)$ is continuous with probability one. i.e. $\lim _{h\rightarrow 0}P(|W(t+h)-W(t)|>\epsilon )=0,\forall \epsilon>0, t\in S$" By assuming this, Brownian motion is a special case of Levy process. 

First a little background. In racing it is possible for a player to win a tournament without winning a single race, however, how bad can a tournament winner actually be? Can a player win a tournament without even doing better than coming third? Or even fourth? Obviously this depends on the scoring method used for awarding points for each race. More formally, suppose $p$ players, named $\alpha_1, \alpha_2, \ldots, \alpha_p$, play a game consisting of $n$ races (with no possibility of ties for a position). Suppse that player $\alpha_i$ finishes race $j$ in position $\beta_{i,j} \in \lbrace 1, 2, \ldots p \rbrace$ (with $\beta_{i,j} = 1$ being the best possible result for player $\alpha_i$). And that for each race the points scored by a player are given by a non-negative, strictly decreasing function called a scoring function $f : \lbrace 1,2, \ldots, p \rbrace \to \mathbb{N}$, i.e. the player coming first receives $f(1)$ points, the player coming second receives $f(2)$ points and the player coming last receives $f(p)$ points. Let $\text{score}(\alpha_i) = \sum_{j = 1}^{n} f(\beta_{i,j})$ be the total score obtained by player $\alpha_i$. Let $\text{best}(\alpha_i) = \min_{1 \leq j \leq n} \lbrace \beta_{i,j} \rbrace$, be the best position that player $\alpha_i$ came in. We say that player $\alpha_i$ is a winner iff $\forall j \in \lbrace 1, 2, \ldots, p \rbrace$ $\text{score}(\alpha_i) \geq \text{score}(\alpha_j)$, note there may be more than one winner of a game. 

Note that the Laguerre orthogonal polynomials are in form of [1](bearing combinatoric interpretation) and [3] $L_{n}^{\nu}(x)=(-1)^{n}\sum_{m=0}^{n}\left(\begin{array}{c} n\\ m \end{array}\right)\prod_{i=1}^{m}\left(\nu+2(n-i)\right)(-x)^{n-m}=\sum_{m=0}^{n}\frac{\Gamma(\nu+n+1)\frac{\Gamma(-n+m)}{\Gamma(-n)}}{n!m!(\nu+m+1)}x^{k}=\sum_{m=0}^{n}c_{m}(n,\nu)\cdot x^{k}$ The connection between Wishart matrix and the Laguerre polynomial is that the eigenvalues of the Wishart matrix $M_{s}=\frac{1}{s}Z_{s}Z_{s}^{T}$ where $Z_{s}\sim\left[Normal\left(0,1\right)\right]_{n\times s}$ are the zeros of appropriately scaled generalized Laguerre polynomials as explained in [2]. Therefore the spectral density of the Wishart distribution can be written in terms of Laguerre polynomials, and we know that the moments of distribution can be directly derived from its spectral density. Now we obtain relation inbetween moments of Wishart distribution $\beta=1,2,4$ and corresponding Laguerre polynomials in [3] when the Wishart distribution is central. For noncentral case, the derivation in [3] may also apply but with slight modification of the intermediate quantity $\mathcal{Q}(r;m,\ell;\alpha):={\displaystyle \int_{0}^{\infty}dxx^{r}e^{-x}L_{m}^{\alpha}(x)L_{\ell}^{\alpha}(x)},$ which is no longer of the simple form $\sum_{k=0,\cdots m,k'=0\cdots\ell}c_{k}(m,\alpha)c_{k^{'}}(\ell,\alpha)\Gamma(1+r+k+k')$. Reference [1]Kuriki, Satoshi, and Yasuhide Numata. "Graph presentations for moments of noncentral Wishart distributions and their applications." Annals of the Institute of Statistical Mathematics 62.4 (2010): 645-672. This reference is pointed out to us by Carlo. [2]Dette, Holger. "Strong approximation of eigenvalues of large dimensional Wishart matrices by roots of generalized Laguerre polynomials." Journal of Approximation Theory 118.2 (2002): 290-304. [3]Livan, Giacomo, and Pierpaolo Vivo. "Moments of Wishart-Laguerre and Jacobi ensembles of random matrices: application to the quantum transport problem in chaotic cavities." arXiv preprint arXiv:1103.2638 (2011). 

Suppose that $M$ is an $n \times n$ matrix where each entry is a positive integer. Then $M$ is Perron-Frobenius and so has unique largest real eigenvalue $\lambda_{\textrm{PF}}$. 

i.e. For any bound $n$ there is a word $w$ that must be made more than $n$ letters longer during any sequence of group actions that take it to it's 'first' word. 

Is deciding if an integer square matrix has determinant $\pm 1$ faster that calculating the determinant of the matrix? 

Note that when $n = 2$: $$ \lambda_{\textrm{PF}} = \frac{1}{2}\left(a + d + \sqrt{a^2 - 2ad + d^2 + 4bc}\right) $$ and so $a, b, c, d \leq \lambda_{\textrm{PF}}^2$. Additionally, if we remove the requirement that the entries of $M$ be integers then the answer is no as for every $k \geq 1$ the matrix $$ \left( \begin{matrix} 1 & k \\ k^{-1} & 1 \end{matrix} \right) $$ has Perron-Frobenius eigenvalue 2. 

I've produced a table of monodromies for about 63% of the hyperbolic, fibred knots listed on knotinfo. This is available at: $URL$ $URL$ (this link now contains significantly more data - for the origional data look under /source/Fibred Knots/). This was done by producing a triangulation of every possible surface bundle over the circle for the surfaces $S_{1,1}, \ldots, S_{5,1}$ made from a composition of at most 15 Dehn twists about generators. Non-hyperbolic and non-knot complement manifolds were discarded and for each pair of isometric triangulations the short-lex later one was also discarded. Finally, for each hyperbolic, fibred knot complement listed on knotinfo, SnapPy was used to find a bundle on this list isometric to it if it existed. As Sam points out, there is no canonical choice of generating set for $\mathop{Mod}(S_{g,1})$ so I used the Humphries generating set in each case. However, the monodromies obtained are the short lex earliest for each knot with respect to this generating set and the ordering of the generators shown at the bottom of the page. This ordering was chosen to minimise the running time; a different ordering can run several orders of magnitude slower. I should point out that these results don't show the millions of knot complements that were also found but that don't (yet) appear on the knot tables. This simply comes from the fact that my tables are ordered by monodromy length whereas knotinfo's is ordered by crossing number. 

(1) If we put a uniform distribution over $\mathcal{S}_n$, i.e. $Pr(S=S_i)=\frac {1}{n}$ for $\forall i=1,2,\cdots n,S\in\mathcal{S}_n$ and let such a random permutation $S$ act on another fixed set $M\subset\mathbb{R}^{n\times n}$ of matrices of compatible dimensions. Is there existing result stating that by choosing $M$ appropriately, the resulting $S(M)$ will follow some kind of probability law? (2) Now if we put a uniform distribution over $\mathcal{S}_n(\beta )$ of the collection of $\beta$-avoiding permutations, with the same question in (1), is it possible to choose the set $M\subset\mathbb{R}^{n\times n}$ to make $S(M)$ follow some kind of probability law? (3)If the answer to (1)(2) are affirmative, what will such a probability law look like when $n\rightarrow\infty$? Will it break down? I primarily thought of (2) but later think (1) will be easier to illustrate. Reference [Fox]Fox, Jacob. "Stanley-Wilf limits are typically exponential." arXiv preprint arXiv:1310.8378 (2013). [Hoffman&Rizzolo]Hoffman, Christopher, Douglas Rizzolo, and Erik Slivken. "Pattern avoiding permutations and Brownian excursion." arXiv preprint arXiv:1406.5156 (2014). $URL$ [Marcus&Tardos]Marcus, Adam, and Gábor Tardos. "Excluded permutation matrices and the Stanley–Wilf conjecture." Journal of Combinatorial Theory, Series A 107.1 (2004): 153-160. 

When you try to test all your assumptions, did you carry out the KS test over all variables or just variables separately? I have to admit that this is the first time I saw KS test on a stochastic process model so I was curious how you carry out your test? 

Yes. If two pseudo-Anosov mapping classes are conjugate then they must have the same dilatation. So take any pseudo-Anosov $f$ and any mapping class $h$ not in the centraliser of $f$ and let $g = h f h^{-1}$. Then $f$ and $g$ are distinct, both pseudo-Anosov and have the same dilatation. However, even if you require that $f$ and $g$ are not conjugate the answer is still yes. For example on the twice-punctured torus, let $f = T_aT_bT_c^{-1}$ and $g = T_aT_b^{-1}T_c^{-1}$ where these are Dehn twists about the curves $a$, $b$, $c$ shown below. 

In "Automorphisms of Surfaces after Nielsen & Thurston" by Casson & Bleiler (on pages 75 - 80) they discuss classifying automorphisms of a surface. They show that, if $S$ is a closed orientable surface, $f \colon S \to S$ an automorphism and $c$ is a geodesic 1-submanifold of $S$ such that $f(c) \simeq c$ then $f$ is reducible map. Suppose $S = T^2 \sharp D^2 \sharp D^2$ (the twice punctured torus) and $\delta$ is a loop around one of the boundary components. Then $\delta$ is non-trivial in $H_1(S, \mathbb{Z})$ but $\forall [\phi] \in \mathcal{MCG}(S)$, $\phi(\delta) \simeq \delta$ or $\phi(\phi(\delta)) \simeq \delta$. Hence this statement doesn't hold for $S$.