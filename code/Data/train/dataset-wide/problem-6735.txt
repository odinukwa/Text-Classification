Languages often disappear when they coexist with an other language. Official languages are often institutionalized (national, supranational), whereas dialects are in general more volatile (currently Catalan vs. Spanish). Frisian in the Netherlands one official language, in Germany quite lost. In general in an ever smaller world dialects, regional/ethnic languages may fear extinction. Languages came into (stronger) existance by the creation of Israel in the previous millenium, the balkan fragmentation (Croatian becoming more "Croatian" as opposed to Serbian). Separate evolution of a language like American English from British English is hard to judge. So total disappearance might be measured, but other numbers are (1) hard to collect numerically and objectively (language like Catalan being part of ethnic pride). One might for instance count languages in the internet... - a minority. Or are there sufficient linguistic studies? 

The English perhaps: can happen, and the Dutch misschien (geschieden): might happen have similar roots. The German vielleicht seems to deviate on first sight, but there is the Dutch wel-licht with the same meaning: "yes easily (possible)" - wel = indeed, yes, yeah (compare the English well). Both vielleicht and wellicht stem from the same spoken form evidently. 

Because nations and national languages grew out of a standardization/demarcation of regional spoken dialects which did not have closed borders, and were alike to neighbors (a communication media). Mercantile and military traffic, large migrations, conquerors, the churches all had their influence. And out of such an amalgam a national language is standardized by institutions (initially literary), and by shaving speech and grammatical constructs to the same style. Going back still further, humanity took its origin in Africa and then split up. So even American Indian languages may contain a couple of recognizable words. However development may drift apart, as migration under duress of small groups, that may loose common language. (In understandable language.) 

Double negation is an extremely common linguistic feature for languages in general and almost universally serves not as a logical predicate but rather to emphasize the negation of the general idea being conveyed. For example, in the phrase "They don't NEVER skip school", the double negative does not mean (they (not (not (skip school))) i.e. they skip school, but instead NOT (they skip school) i.e. it is not the case that they skip school. It may not be a prescribed feature of Standard English as taught to second language learners or in primary school grammar class, but it is certainly a feature of the English spoken in many dialects and regions of the world. Here are for example some phrases you would be likely to hear in Southern American English and African American Vernacular English: "You aint never gonna get there on time." or "He don't know nothing." or even "We don't need no education". This type of double negation was also very common in Standard English during Chaucer's time and even into Shakespear's as well. So where did all these "logical rules" for English negation come from? Well, back in the 18th century a bunch of logicians decided the language should be more logical and started writing grammars that discouraged the usage of double negation constructs and over time it sort of stuck, even though like I said in many English dialects you would sound wierd if you didn't perform double negation. references: $URL$ 

Low threshhold: internet news, internet television, subtitled movies. Reading of light lecture. Passover in the country, at best something like a pen pal conference, goal oriented (whatever is of your interest). Quiet tourist evading others, in a pension. To the flash cards, which one acquires relatively passively. Try stories, sentences, fibulation. Talk to yourself. Finding a native speaker and making it work is hard for me. Maybe sit in on a group of native speakers, if they meet in a student caf√©, to at least learn by hearing. 

(It goes without say, that I personally still see some viral power in Esperanto. It would at least cost least effort, go fast and provide quality. A nice light-weight second language.) 

It seems qualitative requirements of such a World Language have still not been mentioned. Other qualifications: The (as yet) failed Esperanto shows that pure rationality is not the sole issue. (I am both Esperantist and anglophile.) 

English spelling did deteriorate, due to almost abruptive historical changes. It will never become phonetic (nation versus national), and we won't see much reform there besides through/thru. So evolution is not an automatically proceding process. We live with a much richer language in qualitative terms. Philosophics showed the historical introduction of a Greek notion for (non-religious) soul (Latin animus). So nowadays we have a bag of notions like creative, tolerance, open-minded. Nevertheless philosophy, or psychology did contribute nothing to our linguistic mental toolset describing mental processes themselves. We did not become better argumentators. And are still as gullible to wrong arguments (financially supporting child raising, despite world over-population; energy saving lamps, despite very toxic waste). Despite better expressiveness. So the meta-level of language did not evolve. It is interesting in this respect to look at the artificial language Esperanto. (I am Esperantist and anglophile.) The language can be seen to correct many of the grown short-commings of evolution: instead of the many suffixes to make a word adjective (-al, -ic, -ive) or noun there is just one -a or -o. The spelling is again phonetic. Rules are few and without exception. A linguistic evolution in general has no such opportunity to make a clean break. Modern Hebrew was such a forced effort and might be worth readding upon. In general language evolution is a process of growth, friction and fitting. Missing are aspects of the biological evolution that made so good survivors: hunt, competition for the same resources, colaboration, genetic reproduction. Hence language evolution is nothing to be overly optimistic about. Especially as there is a large qualitative equality between languages. Historical or otherwise. 

Perhaps the most widespread argument for the analysis of to as an auxiliary is that it is capable of elliptical stranding, a property characteristic of auxiliaries. Notice that both finite and non-finite auxiliaries have this property. 

Additionally, in Verb Phrase (VP) topicalization, auxiliaries are not fronted with the VP but left behind. This is true of both finite and non-finite auxiliaries. Sentences with fronted auxiliaries are ungrammatical, even when they are non-finite. 

The fact that to follows negation is therefore not an argument against its status as an auxiliary; it should actually be considered evidence that it is. Another property which comes as a consequence of to's being a non-finite auxiliary is that it cannot undergo inversion, which is what a previous answer seems to be getting at with the claim that to must follow "complementizers, foci, [and] subjects." Tensed auxiliaries undergo inversion in English, for instance in questions and stylistic inversion, but non-finite auxiliaries do not; as a non-finite auxiliary, to is completely unexceptionable in this respect. Here is a summary of the above evidence that to is a non-finite auxiliary: 

This answer is based on chapter 2 (section 8: "Infinitival to) of Minimalist Syntax: Exploring the structure of English by Andrew Radford (2004), and "Auxiliaries: To's company" (2012) by Robert Levine in Journal of Linguistics. Infinitival to is an auxiliary. It is the same category as the other auxiliaries, but it is considered "defective" in a single respect; it does not have inflected forms. It's as simple as that. All the properties you can come up with in which to seems to differ from finite auxiliaries, it shares with non-finite auxiliaries. What are some reasons to believe to is an auxiliary? The most intuitive one is the structural parallel. Like other auxiliaries, to takes as a complement a verb phrase headed by a bare verb or non-finite auxiliary. 

For this scenario to happen, something drastic has to happen in China. Maybe some reform. As China is a major driving power in the world. Conclusion: I doubt the future will take this course. Considering the parallels with the decline of French, and the smaller world, English will dominate for another 20 - 30 years. World resources are draining in absolute numbers. So it may well be a world crisis turns over our international culture in another direction. Hopefully not Basic English with reformed spelling. 

As to the definition wikipedia, agglutinative language Esperanto indeed is highly-agglutinative. And "malsanulejo" (there exists a hundred year old alternative, but rare, "hospitalo") indeed is often cited by both the pro and contra E-o factions. Having the same stem and same endings for deriving adjective , noun , verb () is one property. For E-o this has a funny effect on the "internationality," but assumedly makes the language easier for members of other language families. The "highly" makes only sense with sufficient affixes being used: 

Fundamental language differences are rare. Considering the existence of plural maybe allows over-generalisations, hence ethnic prejudices. That would be a bit far-fetched argument. W.r.t. normal variation of speech: non-objective monikers like terrorist / rebel / freedom fighter, that far more influence our mental state. Nevertheless for speculations enjoy a bit of science-fiction classics: Null-A from A.E. van Vogt, and The Languages of Pao of J. Vance. Having a regular number-forming systen is said to help in arithmetic: short / single syllable digits, regular (10+3 / 7x10, Esperanto) as opposed to thirteen / seventy. I doubt there is a measurable effect for adults. 

The most complex words seem not to be labeled as common. The number of words making up a synonym increase as complexity increases The word length increases as complexity increases. 

So it looks like its a weighted combination of those 3 factors. You'd have to try it out against a set of words and their corresponding complexity level sets to get at the exact algorithm, and you might find out there is another factor or two involved (such as number of synonyms available, etc). 

In the late 14th century the term "verbe", adopted into English from Old French, was being used to mean "word; part of speech that expresses action or being". The Old French verbe itself came from the latin word verbum meaning "word", which was an incarnation of the Proto-Indo-European root *were- (to speak). So here we can observe the change in meaning over time from PIE, to Latin, to Old French and into modern English. Now, if we look at the origins of the names for the other parts of speech, we find that Noun comes from the latin Nomen (meaning name as in the name for a thing i.e. tree, river, or Jack), Adjective creeps in from the Old French Adjectif and the before that the Latin adjectivum (to throw or place something near to). The word preposition shares the usual history of Latin (praeponere) to Old French to English and dissected means prae "before" ponere "put", or "to put some before". What I think we are observing here, is the way in which authors of grammar books chose their naming conventions based on how the words behaved in sentences. Also worth noting is that these authors were almost always translating from Greek / Latin into English and had to create words that did not exist in the English of the times. For instance, "adverb" was coined by Flavius Sosipater Charisius as a translation for the Greek epirrhema "adverb," from epi- "upon, on" + rhema "verb". Essentially, the words for the parts of speech are "scientific terms" translated from the original Latin or Greek terminology. The choices made are those translators choices and generally reflect their best intentions to transfer the meanings they observed in the corresponding Latin or Greek texts. references: $URL$