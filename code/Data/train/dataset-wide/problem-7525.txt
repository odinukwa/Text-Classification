By Gauss' method, you may find a basis $v_1,\dots,v_k$ of $X$ such that $s(v_1)<s(v_2)<\dots<s(v_k)$, where $s(v)$ is the number of the first nonzero entry in $v$. Using these vectors, you may inductively construct a vector with nonzero entries at positions $s(v_1)$, \dots, $s(v_k)$, so at least $k$ nonzero coordinates are always achievable. Clearly, $m=k$ is the maximal value, in view of the example $\mathbb F_q^k\leqslant \mathbb F_q^n$. 

$\def\perm{\mathop{\rm perm}}$This is a partial answer for the case when $n$ is large enough. In particular, we show that for $k=2^\ell$ and $n\geq 2\ell$ we have $s\geq n+2\ell$, supported by the model $U_{2i}=U_{2i-1}=\{2i-1,2i\}$, $i=1,\dots,\ell$. For convenience, let us consider the permanent reformulation of the problem. Let us show that for every $s=n+\delta$, if the sum of elements of a 0-1 matrix $A$ is $s$ then $\perm A\leq 2^{\delta/2}$. The base case $\delta\leq 1$ is clear. Take the row or column of $A$ containing the least number $t$ of 1's (WLOG this is the first row). If $t=0$, the statement is clear. So assume that $t\geq 1$. Then $$ \perm A=\sum_{i=1}^t \perm A_i, $$ where $A_i$ is obtained from $A$ by deletion of the first row and the column with $i$th one. Let $s_i=(n-1)+\delta_i$ be the sum of elemtents of $A_i$; then $\delta_i\leq \delta-2t+2$, because the deleted column had at least $t$ ones. Thus $$ \perm A\leq t2^{(\delta-2t+2)/2}. $$ Notice that $t2^{-t}\leq 1/2$ for positive integer $t$; so $\perm A\leq 2^{\delta/2}$ as required. Remarks. Notice that if $t\geq 3$ on some step, then the estimate makes less by a factor of at most $3/4$. On the other hand, if in some deleted column we have more than $t$ ones (for $t=1$ or $t=2$), then the estimate also decreases by at most $\displaystyle\frac{\sqrt2+1}2<\frac34$. In particular, one may see that this estimate can be tighten for all odd $\delta$. Right now I do not see how to extend this for larger values of $k$; but it may happen that the optimal example still consists of several blocks on the diagonal of almost the same size. 

This way we can study noncommutative geometry by studying the bounded derived category of the category of finitely generated modules over an algebra. In this way we can introduce interesting classes of algebras corresponding to interesting classes of commutative spaces. For example an algebra $A$ is called d Calabi-Yau if the d-th shift in $D^b(A)$ is a Serre functor, this then corresponds to open CY-varieties. This can then be extended to DG-algebras and $A_{\infty}$ algebras. A very nice paper covering these algebras, and thus to some extent this point of view of noncommutative algebraic geometry is the paper Calabi-Yau algebras by Ginzburg. 

I think that the best way to remember these things is to have a good example of each of these constructions in your head. If you remember the direction of the arrows for them, and if the example is "natural" enough the direction will be obvious, you will have the direction in the general case. Just watch out, sometimes two constructions will yield the same things in specific examples so you want to have examples that distinguish between the various notions. An example of this is that finite products and finite co-products have a habit of being the same in categories in which I search for examples (additive categories like categories of representations). 

It seems to me to be common that if one author (call her author A) contributes significantly less then the others, but still enough to warrant more than an acknowledgement, the paper will be attributed to the other authors (in the normal alphabetical order) with an appendix by author A. This seems to me to be a reasonable way of doing things, since first of all the normal alphabetical order is kept and secondly author A gets credit for her work. 

Let me rephrase the answer in different terms. Since $H_i$ are idempotent and self-adjoint, they are orthogonal projectors onto some subspaces $W_i$. Set $U=W_1\cap W_2$, and let $U_i$ be the orthogonal complement of $U$ in $W_i$. Finally, let $U^\perp$ be the orthogonal complment of $W_1+W_2$ in the whole space $V$. Then $V=U\oplus U_1\oplus U_2\oplus U^\perp$ (but $U_i$ are not necessarily orthogonal to each other). Notice here that $H_i(U_{3-i})\subseteq U_i$ by orthogoality. Now, each vector $v$ is uniquely expanded as $v=u+u_1+u_2+u^\perp$ with each summand lying in the corresponding space. If $v$ is an eigenvector of $H_\mu$ with the eigenvalue $\mu$, then $$ \mu u+\mu u_1+\mu u_2+\mu u^\perp =H_\mu v =u+\mu u_1+(1-\mu)H_2(u_1)+(1-\mu)u_2+\mu H_1(u_2) =u+\mu(u_1+H_1(u_2))+(1-\mu)(u_2+H_2(u_1))+0, $$ the terms in the right-hand part also lie in the corresponding subspaces. Hence $u=u^\perp=0$, $H_1(u_2)=0$ (so $u_2\perp U_1$), and $(2\mu-1)u_2=(1-\mu)H_2(u_1)$. The last equality cannot hold unless $u_2=0$ or $\mu=1/2$, since $u_2\perp U_1$. So $v=u_1\in \mathop{\rm Im} H_1$ and $H_2(u_1)=0$ (thus $u_1\in\mathop{\rm Ker} H_2$), as required. Perhaps, this language is better for generalizations? 

Finally, impose the restrictions on the neighboring tiles as you wish. That is --- prohibit some $n\times (n+N)$ and $(n+N)\times n$ arrangements where the bordering complete squares are of types which cannot be neighbors in this way. (Recall here that we enumerate all translational types, so rotation of a Wang tile changes its type!) 

Look at the graph with edge set $E'(T)=E(G)-E(H(T))$. It is a forest (since $E'(T)\subseteq E(T)$), and the set of its odd vertices coincides with the set $V_1$ of odd vertices of $G$. In particular, if $G$ is even then this forest should contain no edges (as domotorp has already showed). Next, I claim that each tree $T$ contains a unique subset $F(T)\subseteq E(T)$ such that $E(G)-F(T)$ is even. Indeed, one such set is $E'(T)$. On the other hand, the existence of the edge $uv$ in $F(T)$ is determined by the parity of the number of vertices from $V_1$ in (any) component of $T-\{uv\}$. This yields that $H(T)=H(T')$ if and only if $F(T)=F(T')$. This provides a fast algorithm of checking this property: $F(T)$ can be found pretty fast, and then one just needs to check whether $F(T)\subseteq E(T')$ (then necessarily $F(T')=F(T)$). Finally, take any forest $F$ such that $G-F$ is even. Then $F$ lies in some tree $T$, and $F(T)=E(F)$. Therefore, each even subgraph $K$ such that $E(G)-E(K)$ is a forest is realizable as $H(T)$. 

I second Kevin's suggestion of Huybrechts' book, but if you want to to look at something shorter first I recommend the notes by Hille and van den Bergh. 

Recall that the (first) Weyl algebra over $\mathbb{C}$ is the algebra generated by $x,y$ with the relation $yx-xy=1$. It can be realized as the algebra of polynomial differential operators in 1 variable, i.e. $\mathbb{C}[x]$ is a faithful representation, where $x$ acts by multiplication by $x$ and $y$ acts by $\frac{\partial}{\partial x}$. In many places I've seen the q-Weyl algebra defined as the algebra generated by $x,y$ with relations yx-qxy=1, where q is some fixed nonzero scalar. This seems like a natural way to do it, and seems to be quite common. Now in the notes Introduction to representation theory Etingof et al. define an algebra which they call the q-Weyl algebra. This is the $\mathbb{C}$-algebra generated by $x,x^{-1},y,y^{-1}$ with the relations $xx^{-1} = x^{-1}x = 1$, $yy^{-1}= y^{-1}y = 1$ and $xy=qyx$ where q is some fixed nonzero scalar. My question then is: What is the reason for the name 'q-Weyl algebra' for the algebra defined by Etingof et al.? 

In the finite case at least, the answer is yes. It is a tensor category, and one fundamental result is that the category of representations of G is equivalent, as tensor categories, to the category of $\mathbb{C}G$-modules, where $\mathbb{C}G$ is the group algebra. The same holds if you just look at the finite dimensional representations, and finite dimensional modules if I remember correctly. As for considering it as a ring, the answer is also yes, if you allow formal combinations of them (so called virtual representations) (thanks for pointing that out Jose and Qiaochu!). It has a basis the irreducible representations, and the multiplication is the tensor product, with the trivial representation as 1. 

It seems that the matrix you present as an example is $A/2$, not $A$; I assume that $A$ is exactly what is defined (so, e.g., $A_{11}=2$, not $1$). Well, $A$ is the Gram matrix of the basis $\psi$ with respect to the scalar product $(f,g)=\int_{-1}^1 f(x)g(x)\,dx$; so, if we pass to the orthonormal basis of (normed) Legendre polynomials $\tilde P_n(x)=\sqrt{\frac{2n+1}2}P_n(x)$, say $(\tilde P_0,\dots,\tilde P_{p-1})=\psi S$, then $A=S^{-T}S^{-1}$. Thus $A^{-1}=SS^T$, and hence the polynomial you need is $P(x)=(\psi S)(\psi S)^T=\sum_{n=0}^{p-1}\tilde P_i^2(x)$. It seems to be well-known (?) thath the maximum of $|P_n(x)|$ on $[-1,1]$ is attained at the endpoints; thus the claim follows. 

Firstly, notice that you may apply your condition to the triangles $ABM$ and $A_1B_1M_1$ and iterate this process. So, e.g.. for every points $X$ and $X_1$ on $BC$ and $B_1C_2$ with $BX/BC=B_1X_1/B_1C_1=k/2^n$ with integer $k,n$ we obtain $AX=A_1X_1$. Since the binary rationals are dense on $[0,1]$, the same holds for every ratio. Similarly, we may apply this to other sides and hence see that the affine transform mapping $ABC$ to $A_1B_1C_1$ is metric-preserving on the whole triangle $ABC$. THis already should suffice. Indeed, consider an equilateral triangle $ABC$; by an affine transform we may assume that it is equilateral also in the Euclidean metric. Take a triangle $A'B'C'$ inscribed into $ABC$, with $A'$, $B'$, $C'$ dividing the sides of $ABC$ at the same ratio. Then $A'B'C'$ is also regular (in both metrics), and under the affine transform mapping $ABC$ to $A'B'C'$ the metric scales at the coefficient $\mu$ depending only on the ratio at which the vertices of $A'B'C'$ divide the sides of $ABC$. If the sides of $A'B'C'$ are rotated at $\pi/n$ with respect to the sides of $ABC$ (angles are also Euclidean) then we may iterate inscribing such triangles $n$ times getting a triangle homothetic to $ABC$ with a known ratio. Since the metric on this triangle is $\mu^n$ times the initial one, we obtain that $\mu$ is the same for both metrics. Thus the ratios of segments rotated at $\pi/n$ is the same in our metric and Euclidean one. This is what we want. For passing to an arbitrary space, see Anton Petrunin's answer... 

I use "a legendre b" for the Legendre symbol. I know this is probably not very common and a bit idiosyncratic but I think it is quite clear. 

I first saw an introduction to the deformations of associative algebras in the very nice paper of Braverman and Gaitsgory. I think it's a very good place to start. 

I really like Goodman & Wallach. This is a new revised version of their old book which was called, "Representations and Invariants of the Classical Groups". It is really clearly written and covers a lot of material. It might suit your interests, since it's a bit bent towards the algebraic groups part of Lie theory, but it does also cover the analytic side. 

I was raised by a pack of wild mathematicians. We roamed the great planes proving theorems and conjecturing. 

I enjoyed The USSR Olympiad Problem Book: Selected Problems and Theorems of Elementary Mathematics by Shklarsky, Chentzov and Yaglom. 

At a lower level then Hartshorne is the fantastic "Algebraic Curves" by Fulton. It's available on his website. 

You can think of Cayley's theorem as the special case of Yoneda's lemma, where the category has only one object. If you take the additive version of Yoneda's lemma, and you plug in an additive category with one object then you get the desired statement for rings that's in Jack's answer. Viewing Cayley's theorem like this let's you generalize it to many other structures then groups. 

Hilbert schemes of points in the plane come up in representation theory. More specifically in the representation theory of rational Cherednik algebras. Rational Cherednik algebras, and more generally symplectic reflection algebras have a close connection with symplectic resolutions, algebraic combinatorics, integrable systems and more and are thus very interesting. See for example: This paper and This paper 

It is not necessarily true. Set $a=(0,3,4)\;$ and $b=(0,0,2).$ Then possible sequences of the form $\sigma(a)+b\;$ (reordered) are $(0,3,6),$ $(0,4,5)\;$ and $(2,3,4),\;$ so $$ \mathop{\mathbb E}\mathop{\rm gap}\nolimits_2(\sigma(a)+b)=\frac83 <3=\mathop{\rm gap}\nolimits_2(a). $$ 

Well, by Cayley--Hamilton, each matrix $A\in {\rm GL}(n,p)$ generates an at most $n$-dimensional subalgebra ${\mathbb F}_p[A]\subseteq M(n,p)$ thus containing at most $p^n-1$ nonzero elements. Hence the order of $A$ cannot exceed $p^n-1$. On the other hand, consider a degree $n$ monic polynomial $P_n$ whose root is a generator $\xi$ of ${\mathbb F}_{p^n}^*$. Then a matrix with $P_n$ as its characteristic polynomial has order at least $p^n-1$ since $\xi$ is its eigenvalue. ADDENDUM. if you wish the order to be the power of $p$, then the answer is $d=p^{\lceil \log_p n\rceil}$. Since the order of $A$ is divisible by the multiplicative orders of its eigenvalues, all the eigenvalues should be $1$. Hence the characteristic polynomial is $(x-1)^n$, so $A^d-I=(A-I)^d=0$. On the other hand, if $A=I+J$ is the Jordan cell of size $n$ (with eigenvalue 1), then $A^{d/p}=I^{d/p}+J^{d/p}\neq I$, but $A^d=I+J^d=I$. NB. The subgroup of all (upper-)unitriangular matrices is a Sylow $p$-subgroup in ${\rm GL}(n,p)$. So you may concentrate on it when looking at the elements of this kind. ADDENDUM-2 (much later). This is to answer the question in the comments about the maximal order of an element $f\in AGL(n,q)$, where $q$ is a power of $p$. Write $f(x)=Ax+b$. If $1$ is not an eigenvalue of $A$, then $f$ has a fixed point (the equation $f(x)=x$ has a solution), so we may regard it as an element of $GL(n,q)$, and the maximal order of $f$ is again $q^n-1$. So we are concerned with the case when the minimal polynomial $\mu(x)$ of $A$ vanishes at $1$, say $\mu(x)=(x-1)^k\nu(x)$, where $\nu(1)\neq 0$. Then $A$ is similar to a block-diagonal matrix with blocks having minimal polynomials $(x-1)^k$ and $\nu(x)$ (in view of $\mathbb F_q^n=\mathop{\mathrm {Ker}}(A-I)^k\oplus\mathop{\rm Ker}\nu(A)$). So the order $d$ of $A$ does not exceed $p^{\lceil\log_p k\rceil}(q^{n-k}-1)$ if $n<k$, and $p^{\lceil\log_p n\rceil}$ otherwise. If $n>3$ (or $n=3$ and $q>2$), one may easily see that this bound does not exceed $q^{n-1}-1$. So $f^d$ is a translation, which yields that $f^{pd}=\mathord{\rm id}$, and $pd\leq p(q^{n-1}-1)<q^n-1$. Thus the maximal order of $f$ in these cases is still $q^n-1$. We are left with the cases $n=1$, $n=2$, or $n=3$, $p=2$. When $n=1$, the answer is obviously $\max(p,q-1)$. When $n=2$, the only case left is $d=p=q$ achieved when $A$ is similar to the Jordan cell $\begin{pmatrix}1&1\\0&1\end{pmatrix}$. In this case, $f^p(x)=x+(A^{p-1}+\dots+I)b=x$ unless $p=2$, when $f^2(x)=x+\begin{pmatrix}0&1\\0&0\end{pmatrix}b$. So the answer is still $q^2-1$ when $q>2$, and $4$ otherwise. Finally, if $n=3$ and $q=2$, then the order of $A$ having eigenvalue $1$ exceeds 3 only if $A$ is similar to $3\times 3$ Jordan cell (then $d=4$); but in this case $f^4=\mathord{\rm id}$. So this is not an exception. Summing up, the only cases when the order may be greater than $q^n-1$ are: (1) $n=1$, $q=p$ (the maximal order is $p$), and (2) $n=2$, $q=2$ (the maximal order is $4$).