To add to John Baez's answer, you can regard the symmetric Fock space over $L^2(X)$ as a measurable tensor product of the Hilbert spaces $l^2(\mathbb{N})$ over the index set $X$, and the antisymmetric Fock space over $L^2(X)$ as a measurable tensor product of the Hilbert spaces $\mathbb{C}^2$ over the index set $X$. Spelling this out a little, in the symmetric Fock space $\mathbb{C} \oplus L^2(X) \oplus L^2(X)^{\otimes 2}_s \oplus \cdots$ (the direct sum of the symmetric tensor powers of $L^2(X)$), the initial $\mathbb{C}$ represents the vacuum state. An element $f \in L^2(X)$ of the second summand represents the direct integral over $x \in X$, weighted by the scalar function $f(x)$, of the state of the system which is in its first excited state at $x$ and vacuum everywhere else. Elements of $L^2(X)^{\otimes 2}_s$ are direct integrals of states of the system in which two fibers are in their first excited state or one fiber is in its second excited state, and all other fibers are vacuum. And so on. The antisymmetric case is similar. This is discussed in Section 2.5 of my book Mathematical Quantization. 

Use the fact that $\sigma(ST) \cup \{0\} = \sigma(TS) \cup \{0\}$. So if $A$ and $B$ are positive then, except possibly for the point $0$, $\sigma(AB)$ equals $\sigma(A^{1/2}BA^{1/2})$. If $AB \neq 0$ then the latter is a nonzero positive operator, and hence it has a nonzero element in its spectrum. Therefore so does $AB$. 

Well, I think this is false. Start with a family of $2^{2^{\aleph_0}}$ mutually non-homeomorphic connected spaces, and attach them to the non-isolated points of $\beta {\bf N}$. (I.e., start with the disjoint union of $\beta {\bf N}$ and the other spaces, and factor out an equivalence relation which identifies each point of $\beta {\bf N} - {\bf N}$ with a point of one of the other spaces.) Any homeomorphism between $X$ and $X^\sharp$ has to take isolated points to isolated points; taking closures, it takes $\beta{\bf N}$ onto itself; and by connectedness it takes each of the extra spaces onto itself. So it has to fix each point of $\beta {\bf N} - {\bf N}$. Now the question is whether a bijection between ${\bf N}$ and ${\bf N}$ minus a point can fix $\beta {\bf N} - {\bf N}$ pointwise. The answer is no because iterating the map, starting on the missing point, yields a sequence within ${\bf N}$ that gets shifted by the map, and it is easy to see that this shift does not fix the ultrafilters supported on that sequence. 

The answer to your immediate question is no: there is no other possible solution for $\phi$. To see this, consider that $$\phi(-1) + i\phi(1) = 2$$ implies $${\rm Re}(\phi(-1)) + {\rm Re}(i\phi(1)) = 2.$$ If $\|\phi\|_\infty = 1$ then both terms on the left are at most 1, and equal 1 if and only if $\phi(-1) = 1$ and $\phi(1) = -i$. So these values are forced. By a similar argument, the only unitaries in $l^1$ are the elements of the form $\alpha e_n$ where $(e_n)$ is the standard basis and $|\alpha| = 1$. However, there is an easy counterexample. Consider $\mathbb{C}^2$ with the $l^1$ norm, i.e., $\|(a,b)\| = |a| + |b|$. Give it the product $(a,b)\cdot(c,d) = (ac, ad + bc)$. This is a Banach algebra because $$\|(a,b)\cdot(c,d)\| = |ac| + |ad + bc| \leq (|a| + |b|)(|c| + |d|) = \|(a,b)\|\|(c,d)\|.$$ The element $(1,0)$ is the unit, and it is unitary, but so is $(0,1)$, which is not invertible. 

As I explained in the comments, the nonzero eigenvalues of $\left[\matrix{A&B\cr B^T&0}\right]$ and $\left[\matrix{A&2v\cr 2v^T&0}\right]$ are the same. So there's no reason you should expect interlacing between the eigenvalues of $C$ and the eigenvalues of a principal submatrix of $D$. I went to an eigenvalue calculator and threw in a few values and quickly found a counterexample. Take $$A = \left[\matrix{10&0\cr 0&20}\right]\qquad v = \left[\matrix{1\cr 1}\right]$$ so that the nonzero eigenvalues of $C$ are the eigenvalues of $\left[\matrix{10&0&2\cr 0&20&2\cr 2&2&0}\right]$, which came out to $-.573$, $10.371$, and $20.201$. Whereas the eigenvalues of the principal submatrix $\left[\matrix{10&1\cr 1&0}\right]$ of $D$ are $-.099$ and $10.099$. So, no interlacing. 

Not always. Let $(e_n)$ be the standard basis of $l^2$ and take $x = e_1 - 2e_2$. For any $k$ the vector $S^kx$ is orthogonal to the sequence $(2^{-n})$, so $x$ is not cyclic. You ask for a handy criterion that $\overline{\rm span}(x, Sx, S^2x, \ldots)$ equals $l^2$. I don't know, but note that this subspace is invariant for $S$, so it is necessary and sufficient that it contain the vector $e_1$. So a sufficient condition for cyclicity is that the series mentioned by András in the comments should converge. I guess that is probably pretty close to a necessary condition, too, because you need to use a series close to this one in order to get close to $e_1$. I suppose my conjecture is that $x$ is cyclic if and only if András's series converges weakly. You can see that weak convergence might be necessary by taking $x = e_1 - e_2$. This vector is cyclic because anything that is orthogonal to $S^kx$ for all $k$ must be a constant sequence and hence, if it is in $l^2$, the zero sequence. But the series you get by trying to solve $\sum a_k S^kx = e_1$ is $x + Sx + S^2 x + \cdots$, which only converges weakly. 

See my paper Analysis in $J_2$, where I explain how core mathematics, particularly abstract analysis, can be developed within a concrete countable set $J_2$ (the second set in Jensen's constructible hierarchy). 

I can now prove the existence of a good pair if, after rescaling so $A = I_4$, some nonzero Hermitian matrix in the span of $B$ and $C$ has a repeated eigenvalue. (But as I learned from Robert Bryant here, that generally will not be the case.) But in this special case, since $(v,w)$ is good for $A$, $B$, and $C$ iff it is good for every Hermitian matrix in their span, wlog we can assume $B$ has an (at least) double eigenvalue. Subtracting a scalar multiple of $A = I_4$, we can assume this double eigenvalue is $0$. If $0$ is a triple eigenvalue, then it is easy to find a pair of vectors in this three-dimensional eigenspace which is good for $I_4$ and $C$, and that solves the problem. The solution is also easy if the two nonzero eigenvalues of $B$ have opposite sign: say $B = {\rm diag}(a,-b,0,0)$ with $a,b > 0$, wlog with $\frac{1}{a^2} + \frac{1}{b^2} = 1$. Then let $W = \left[\matrix{\frac{1}{a}&0&0\cr\frac{1}{b}&0&0\cr 0&1&0\cr 0&0&1}\right]$, so that $W^*BW = 0$. Then find a pair of vectors $v_0,w_0 \in \mathbb{C}^3$ which is good for $I_3$ and $W^*CW$ (easy) and set $v = Wv_0$, $w = Ww_0$. The hard case is the one where both nonzero eigenvalues have the same sign. The case where they are equal is the one I treated in an earlier answer, which I'm retaining below. If they are not equal, wlog say $B = {\rm diag}(1,a,0,0)$ with $a > 1$. Similarly to the case where $a = 1$ presented below, it will suffice to find $0 \leq \lambda \leq 1$ and a $2\times 2$ unitary $U$ such that $$sC_1s + cUC_2^*s + sC_2U^*c + cUC_3U^*c$$ is a scalar multiple of $I_2$, where $C = \left[\matrix{C_1&C_2\cr C_2^*&C_3}\right]$ and $s = {\rm diag}(\sqrt{\lambda},\sqrt{\lambda/a})$, $c = {\rm diag}(\sqrt{1-\lambda},\sqrt{1 - \lambda/a})$. This is done as in Robert Bryant's solution when $a = 1$ where again, when $\lambda = 0$ the expression is just $UC_3U^*$, which becomes the Hopf map when you pass to the $S^3$-$S^2$ picture (which we can do if there is no solution to the problem). But it's a little harder here because the $\lambda = 1$ extreme no longer reduces to a constant map. However, not so much harder because some computation shows that the image of $S^3$ under the $\lambda=1$ map misses a point on $S^2$, and is therefore null homotopic, leading to the same contradiction. 

The other answers are perfectly correct, but I'd like to add that the implication Con(ZFC) $\to $Con(ZFC + $\neg$CH) is not only provable in ZFC, it is provable in Peano arithmetic. I consider this a better and more natural version of the result --- better since PA is much weaker than ZFC, so this version is more informative, and more natural because consistency is a number theoretic concept (no number $n$ is the Gödel number of a proof of 0=1). The reflection principle indeed operates outside of ZFC --- it is a "theorem scheme" consisting of one theorem of ZFC for each sentence of set theory. However, the pattern of the proofs is quite simple, so that we can prove in PA a single theorem to the effect that each instance of reflection is a theorem of ZFC. A nice elementary way to treat forcing from the point of view of PA is to introduce a new system ZFC${}^+$ whose language is the language of ZFC augmented by a constant symbol $M$ and whose axioms consist of $\bullet$ the axioms of ZFC $\bullet$ the single assertion that $M$ is countable and transitive $\bullet$ the relativization of each axiom of ZFC to $M$. We then use reflection to prove, in PA, that if ZFC is consistent and we can construct in ZFC${}^+$ a set $N = M[G]$ in which both the axioms of ZFC and (say) $\neg$CH hold, then ZFC + $\neg$CH is consistent. I believe this technique is due to Shoenfield. (Shameless self-promotion: this is the approach I use in my forthcoming book on forcing.) 

It seems to me you could just tensor a unital example with the compacts. Any closed ideal of $A \otimes K$ has the form $I\otimes K$ where $I$ is a closed ideal of $A$, etc. 

Yemon, I have used the term "weak Banach algebra" for such things. I don't think there is a standard term, though. I vaguely recall seeing people simply call them Banach algebras (probably in some older papers when the terminology in the subject hadn't really stabilized). (I ran into this issue when dealing with the Lipschitz algebra $Lip_0(X)$ for $X$ a complete finite diameter metric space. You really want to use Lipschitz number as the norm, even though this only makes it a weak Banach algebra. There's no real penalty for doing this, and the advantage is that it allows you to identify $X$ isometrically with the normal spectrum of $Lip_0(X)$.) Edit: I've just realized that this is what Gelfand meant by "normed ring". E.g., on the first page of his book Commutative Normed Rings (1960) he writes: "A normed ring is a complex Banach space in which an associative multiplication is defined that is permutable with the multiplication by complex numbers, distributive with respect to addition, and continuous in each factor." and there is a footnote which says "In another terminology, a Banach algebra." A few pages in he proves that you can always achieve $\|xy\| \leq \|x\|\|y\|$ by renorming. 

Okay, so $X$ is a finite metric space and $D(X)$ is the positive part of the unit sphere of $l^1(X)$. We can consider $X$ as sitting inside $D(X)$ by identifying a point $x \in X$ with the function that is $1$ at $x$ and $0$ elsewhere. The literal question you have asked is whether the mass transport metric on $D(X)$ is the only metric on $D(X)$ whose restriction to $X$ recovers the original metric on $X$. The answer to this question is clearly no; if you want to add a point to a metric space you generally have a lot of freedom to assign distances from it to the other points. All the more so if you are adding many new points. But you probably meant to take the affine structure of $D(X)$ into account. $D(X)$ is the convex hull of $X$, so we can ask: if $X$ is isometrically embedded in a Banach space $E$, is the norm on its convex hull in $E$ uniquely determined? The answer is still no. For example, let $X$ have three elements, such that the distance between any two of them is $1$. We can embed $X$ as the vertices of an equilateral triangle in the euclidean plane, or we can embed it as the points $(0,1)$, $(1,1)$, and $(1,0)$ in $l^\infty_2$. The two metrics on the convex hull of $X$ aren't the same. (Look at the distance from the average of two of the points to the third.) However, you also asked whether the mass transport metric is "canonical". Yes, it is. It is universal in the following sense: Theorem. Let $X$ be a metric space and let $e \in X$. Then there is a Banach space $AE(X)$ together with an isometric embedding $\iota: X \to AE(X)$ such that $\iota(e) = 0$, and such that if $f: X \to E$ is any nonexpansive map from $X$ into any Banach space $E$ with $f(e) = 0$, then there is a unique nonexpansive linear map $T: AE(X) \to E$ such that $T \circ \iota = f$. The mass transport metric is the restriction of the metric on $AE(X)$ to the convex hull of $X$. So this theorem could be rephrased in terms of the mass transport metric being the universal metric on $D(X)$ relative to nonexpansive affine maps. In other words, it is the metric for which distances are as large as possible, given the original metric on $X$. There's a nice little book on Lipschitz algebras that covers this material, but I forget the author. 

I presented a system for reasoning about arbitrary concepts, including the concept "is a concept". It's located at arXiv:1112.6129. The system has full comprehension; there is no restriction on "subconcept" formation. The paper includes a consistency proof. The key idea of my paper is that we do not have a global notion of an object falling under a concept, in exactly the same way that we do not have a global notion of an assertion being true. The best we can do is talk about provably falling under, referring (as constructivists do) to the general semantic notion of provability, not to provability within some formal system. My system deals with concepts like "is a concept that does not provably fall under itself" by restricting the axioms relating to provability. One of the basic axioms that you expect to hold for provability turns out not to have a clear justification. Maybe no one can read this paper because you'd have to be familiar with both Fregean concepts and intuitionistic logic, as well as comfortable with substantial technical content. 

Basically you're asking for the map to take almost every fiber into itself. For bounded operators this is equivalent to commuting with every operator of the form $M_g$ with $g \in L^\infty({\bf R}_+)$, defined by $M_gf(s) = g(s)f(s)$. Or, equivalently, to commuting with all unitaries of this form, and that version of the condition makes sense for unbounded operators too, so I think that's a nice natural characterization of the operators you're looking for. 

I propose the axiom that any isometry between two such sets must take the center of one onto the center of the other. This axiom by itself is consistent with the existence of a center for every weakly compact convex set by the Ryll-Nardzewski fixed point theorem (we need the group of isometries of $S$ onto itself to always have a fixed point), and it alone already uniquely determines the center in some cases. For example, let $S$ be the positive part of the unit ball of $l^p({\bf Z})$ for $1 < p < \infty$. Translation (taking the sequence $(a_n)$ to the sequence $(a_{n-1})$) is an isometry of this set onto itself, and the only fixed point is the origin. This example shows that the center will sometimes be an extreme point, which may be counterintuitive. But it's actually reasonable if you look at the center of mass of the positive part of the unit ball of $l^p_n$; as $n \to \infty$ it does converge to the origin (weakly, regarding $l^p_n$ as sitting inside $l^p$). 

If $X$ is any metric space, $Y$ any subset of $X$, and $f: Y \to \mathbb{R}$ a Lipschitz function, then there is an extension $\tilde{f}: X \to \mathbb{R}$ of $f$ with the same Lipschitz constant. This easy result (just extend the function one point at a time) has been rediscovered many times. See Theorem 1.5.6 of my book Lipschitz Algebras. The result does not follow from the paper of Johnson and Lindenstrauss that you mention. The case when $X$ is "metrizable" is meaningless as you need an actual metric to have a notion of Lipschitz map. The answer by MKO is basically unrelated to the question as far as I can tell.