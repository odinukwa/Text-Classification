You could use mod_proxy or SQUID easily. Really, options are endless. I use SQUID for this purpose but that's because it fits better within my current infrastructure. 

You would specify these settings under the share. Be certain to reload SAMBA after the configuration change, which could be done via the init script. 

The least privileges necessary to accomplish the task should be used in all cases. Apache starts as root but spawns off children as a different user. This is specified by and within httpd.conf and is non-root per default. Non-root users can bind to ports >1024. MySQL does not need to run as root and runs on port 3306. 

You could also use something like expect. Some clients do not always handle input redirection without additional effort. For logging, you can use tee and redirect STDERR and STDOUT when running the main script. Example: 

No, not on the network layer. You could perhaps achieve your goal using something like a proxy. You could also emulate the behavior using a script but it would likely be fallible. To be clear, my point was that you cannot dynamically route based on hostname. I am not contesting what splattne said. 

Linux defaults to pretty high on the kernel level these days, so you likely won't have to tune outside of SQUID for the FD. If you provide log output, chances are it will indicate the exact issue, and we could provide more detailed recommendations. 

When I want to log a root session I use rootsh. If admins are required to use sudo for all commands, it will also log all commands. You might take a look at screen too, as it might accomplish what you're attempting to do. Ultimately, logging may not be the best situation for your workflow. Requiring a motd, wiki, or simple Web site to be updated for all changes may be better. 

If the disks are part of the same array, the smallest disks would dictate the size used on the larger disks. That being the case, the 600GB would be utilized as 450GB. Generally speaking, it's not advised to run different types of disks in the same array. Depending on how fickle your controller is, it may not handle the mismatched disks. However, most modern controllers are tolerant of this. 

Your gateway, for whatever reason, has 192.168.135.101 bound to it. I bet if you brought down eth0:1 and the ARP table didn't have an entry for the 192.168.135.101, it will still respond to an ICMP request. Focus on the machine with the 00:1A:A2:2D:2A:04 address, it's the culprit. 

Ultimately, good anti virus software will potentially reduce the technical risk. However, it's unlikely to be much if you have good security policies. Usually the most risk will be introduced with unrestricted users who are not very technical. Servers on more restricted subnets with specialized purpose and software will often not have anti virus software installed. At one point, it was recommended not to install on certain server roles. I believe this is less common these days. 

The previous list is far from comprehensive. Depending on the type of IT shop, there are varieties of differing roles within that. Roles can involve responsibilities ranging from architect to support. Some of these roles are not available in all shops and some roles are very different between shops. External IT services can be many things. Consulting services and contract or staff augmentation services often overlap, which are often contact to hire. 1099 and corp. to corp. consulting are very different, which are often contract based and better resemble freelance consulting. What do you want to do? I do not want to do many of these things, as they are entirely outside of my career focus and not things I enjoy. One consulting firm can may large interesting projects using the technologies you enjoy, where another may churn out support contracts as the primary focus. Most fall somewhere in between. My favorite type of internal IT shop is where one can have substantial involvement in the direction of technology, which seems to be more common in technology-focused companies. These shops often involve higher-level architecture as well. The contrast would be an internal IT shop focused on providing support to the intranet and internal end-users, which can have a substantially smaller budget and less responsibility as opposed to engineer roles. Ultimately, IT is a big space. If you feel that you are stuck in a support role and not interested in business or management, chances are you can find a highly technical role that does not involve support. These choices are not necessarily distinct between consulting and in-house IT departments. 

Specifically in regards to availability monitoring, I'm a huge Nagios fan. If you haven't considered it, I'd strongly recommend it. Others like monit. 

Please provide the exact procedure you are personally using, not the documentation you're referencing. You're likely making a mistake. I suspect it has to do with either the old table's files or data not being fully removed. 

The domain name registrar will not affect the availability of your domain. There is substantial architecture that is necessary to reach "6 nines" availability. You will not insure that level of availability by simply having multiple DNS providers. 

If you do not want to change ownership of the files, most options are going to involve root privileges. These include putting a script in sudo, utilizing the SUID bit, or simply taking the actions as root directly. 

Following that, remove if you don't want to keep a copy. doesn't "overwrite." Using relative paths is a bad habit and will be something that you will easily regret. I recommend using full paths whenever reasonable. 

In a nutshell.. is where logs are stored. is able to be written to by anyone. is where user data is stored. is typically where software is installed. If these locations were stored on a single filesystem, that filesystem could be fully utilized. If were full, it could potentially prevent the system from operating properly. Additionally, separate filesystems can be mounted with different settings. For example, I like to mount with and . If an application were compromised and had files written to , not being able to execute files would distinctly limit the ability to further compromise the system. I would recommend reading more about the Filesystem Hierarchy Standard to better understand those locations, as my description is summarized and not complete. 

There would be no performance increase over a RAID0's normal performance with that quantity and type of drives. 

This will result in interruption of service. Update the init file to contain the commands necessary to re-create the root user. The procedure is documented here: $URL$ 

With an older 2650 I was able to use afasnmp. Unfortunately, I will not be able to give you a definitive recommendation for all chipsets. Edit Hm, I get really frustrated with Dell sometimes and their tendency to default to Windows approaches on UNIX. Don't get me started on the MD3000. It sounds like if you run MegaCLI from command line, it produces the status as desired. I hack out scripts in Nagios all the time. I'll tie a script on the source server, often a simple shell script, it will be in SNMP. On the Nagios server, I'll use a PERL script to pull the mib and produce the results in a fashion that Nagios can use. Would this work for you now?