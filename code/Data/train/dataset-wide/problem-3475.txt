The problem is that Apache in Debian's default configuration (and yours, as posted) is expecting Mailman to be served from whereas you want to use instead. The offending line is in your file: 

You appear to have hit a long-standing issue in Android. In particular Android will only load the autodiscover XML over HTTPS. If you serve it over HTTP then Android will refuse to even attempt to use it. As described in the bug, Android does not use DNS SRV records to locate mail services. 

You don't need to create a new subnet for every single Layer 3 subnet that the network people create. Instead, create subnets corresponding to the IP address allocations for the entire site. Here's a quick example. Say you have two sites. Let's call them "New York" and "Mountain View". New York's entire IP allocation is 10.187.128.0/22. Mountain View has 10.187.132.0/22, but it also has some old cruft hanging around in 10.244.0.0/16. The network guys will divide all those addresses into tiny subnets of as small as /29, there will be thousands of them, but they're all contained within those supernet blocks. Within AD, though, the New York site only needs the one subnet defined, and the Mountain View site only needs the two subnets defined. They cover all the possible IP addresses within their respective blocks. 

Even supposedly "idle" machines run occasional background tasks that consume CPU, memory, disk, network, etc. If it doesn't need to be running, and you're as resource-constrained as you say you are, shut it off. 

There are many other things covered in IBM's guide I referred to earlier, but these should give you the most bang for your buck. 

No device is going to try to connect to a password protected AP without explicit instruction from its user. When showing a list of available APs, the devices are only receiving, not transmitting. So I don't think this is something you need to worry about. 

Don't set default gateways for interfaces which don't connect to the Internet. Remove the default gateways that are defined for those interfaces. That is, delete the line from the and files. You do not need to worry about the route metric at all. 

Your output plainly shows that is only listening on localhost. If you want to make remote connections to it, you must tell it to listen to connections from remote hosts. In you have: 

So we see their ASN really is AS24940. Now, we do a much more complex query at RADb to get all of the known routes for that ASN. 

You can only create or extend LVM volume groups onto physical volumes. To resolve the issue, create an LVM physical volume on the desired partition. 

The format of specifying a network interface alias as has been deprecated in Linux for many years, and should not be used anymore (being deprecated, it may be removed in the future). Today, all of the IP addresses you may need are added directly to the interface, without the need for aliasing. So you need to change to . (And only needs to appear once.) You currently have: 

The obvious use of VOLUME is to populate a new persistent volume with data supplied by your container. Regardless of what sort of application you are deploying, there's almost always some initial data you need to start with. The documentation makes clear that this copy only takes place when the volume is newly created. 

Recent versions of can also listen on IPv6 and then forward the connection to an IPv4 address. A sample configuration which listens for IPv6 connections on port 3389 and forwards them to port 3389 of an internal IPv4 address: 

This happens when your IP address is listed in the Spamhaus PBL. This DNSBL contains a list of known dialup/dynamic IP address ranges which should not ordinarily be sending mail via SMTP. To fix the problem, change your mail client's outgoing mail server settings to connect to port 587 instead of port 25. 

The only thing you are missing is to quiesce the guest filesystem before taking the snapshot, to ensure that it is consistent. This can be done with if you are using libvirtd. For example, the order of operations is: 

You're using rvm, so the proper way to deal with ruby not being found is to use an rvm wrapper (on SysVinit and upstart systems). First (optional) create an alias for your app to the gemset you want to use: 

Partition consists of one partition on . If I wanted, I could have had another partition on , e.g. , and also used that for LVM. My volume group uses , and if I'd created any more PVs, I could have added them to the volume group as well. Then, logical volumes would have spanned across all of the physical volumes. Finally I have some logical volumes, which ought to be familiar enough. For a detailed explanation of how LVM works, see Chapter 2 of RHEL's Logical Volume Manager Administration document. 

NOTE: This operation destroys all data on the named partition. You can then extend the volume group onto the physical volume. 

If you're unable or unwilling to purchase a Red Hat subscription, consider migrating to CentOS to avoid the problem. 

These messages originate from the user ID running your web server and its web applications. In short, your web site has been hacked, and it is being used to send spam. 

To compile programs from source code, on RHEL systems, you need to install their corresponding packages. For instance, for SQLite support, you need to install . 

Save a copy of your configuration files. RPM will do this anyway with an extension for any files you modified, but it's best to be doubly sure. Forcibly remove all of the packages: 

Debian will eventually have systemd, so this is the way to do it on a Linux system which uses systemd (and many do already; you might consider switching distributions). Systemd can handle keeping the service alive for you automatically; no other tools are required. Simply make sure that is set in the service file's section. 

You will never see a process name for a service handled by the kernel itself, such as the NFS server, which is what runs on TCP port 2049 (and UDP 2049, but you usually shouldn't use UDP for NFS). 

The version of nginx you got from the PPA is compiled with . You can see this by inspecting the output from . 

If your version of nginx shows TLS SNI support when you do then you're ready to go. If you want to run your without regard to the IP address, then don't use an IP address in the SSL web 's directives to use SNI for that virtual host. For instance, change: 

You need, at minimum, in the section of your unit file, to ensure that the network is up before starting nginx. I have no idea why your unit file doesn't have it. Here is a complete example from my handy Fedora system, as shipped by Fedora: 

You didn't accept the default, and gave your key a specific filename. If you had accepted the default, then ssh would simply look in that default location anytime you make a remote connection to anywhere, and try to use that key. In order to use a key other than the default key, you have to specify it explicitly when using ssh, for instance: 

It will slow down legitimate logins. Typically the slowdown will be imperceptible, as DNS lookups don't take that much time, but they can take several seconds or just time out completely. What do you do when that happens? Do you refuse a legitimate user? More importantly, it will completely block legitimate logins, even when everything is working perfectly. Many users have the misfortune to be on dynamic IP addresses, and they may themselves be on a malware-riddled computer which is participating in a botnet, causing the IP address to be listed in a DNSBL, or have recently been assigned an IP address which is DNSBL listed even though they themselves are clean. 

The command failed for some reason. Check to see if it logged anything (separately), check its configuration, make sure it's actually still installed, etc. 

You do need a . But that's not why nginx isn't serving your static files. The problem is you forgot to specify a directive in your block. So nginx uses its compiled-in default, which is system-dependent and almost certainly isn't where your web app is located. Thus, all requests, including for static files, go upstream to uWSGI. To fix the problem, set a directive pointing to your app's static resources. 

You have an error in . You've defined , which is a great way to break localhost. This should not be present and should be removed immediately. 

means that the recipient email server believes that the email address does not exist at the destination domain, and therefore has no way to deliver it. Unless you simply made a typo in the email address, this is not something that you can fix, and must be addressed at the other end. 

There are no redirects in your nginx configuration, so it is most likely that the application (WordPress) is sending the redirect. If you accidentally set up WordPress with the URL of then it will always attempt to redirect to localhost. In this case, you will need to change the URL that WordPress uses. 

There's no reliable public list of IP addresses for Starbucks Wi-Fi, nor is there any reliable way to determine if an IP address corresponds to Starbucks Wi-Fi. After Starbucks (at least in the US) switched from AT&T to Google for Wi-Fi service, Google has been providing the service via any available ISP, whether Google owned or not. For example, the local Starbucks Wi-Fi provided by Google is run on a Comcast Business cable connection. There's no way to distinguish its IP address from any other Comcast Business customer. Therefore, in order to ban Starbucks customers, you will need a fairly large IP address range: 

This is happening because your daemon is only listening on IPv4. IPv6 is the default protocol, so if a given hostname has both IPv4 and IPv6 addresses, the IPv6 address is always tried first. In your case, has the IPv4 address and the IPv6 address . But your daemon is only listening on . So, when tries to connect to it first connects to , finds nothing is listening, and returns . It then tries to connect to and finds your daemon. 

Looks like the server's iRMC (the piece of hardware that supplies out-of-band keyboard, video, mouse, virtual CDROM, IPMI management, etc.) is malfunctioning. Replace it. 

Barring firmware bugs that actually prevent booting from virtual media (e.g. some old G5/G6 systems had a problem where they would not boot from virtual media if there were external USB devices connected) you should be fine to boot from a virtual DVD and update your firmware. 

This might still fail, however, if Amazon's repos are actually out of sync. Unfortunately this happens far too often for my liking, which is one of the main reasons I don't recommend using Amazon Linux. 

OK, this is a very strange scenario, and you seem to be on the right track. Instead of the , though, I would and use an to define the 404 error page. For example: 

To resolve the issue, set up a VPN between your corporate network in UAE and a server in another country without censorship, the sole purpose of which is to carry your company Internet traffic. 

The packages are probably installed, but if they're the ones you downloaded from mysql.com then the actual package names are in all lowercase, even though the file names are in mixed case. With that out of the way, the mysql.com packages are not 100% binary compatible with CentOS and a lot more than this will likely break. If you don't absolutely need 5.6 then it's probably best to use 5.5 from a trustworthy repo such as remi, until such time as compatible packages become available.