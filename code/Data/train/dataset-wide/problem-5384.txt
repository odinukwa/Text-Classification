Unfortunately we must treat the result as an axiom as well, for it does not follow from the assumptions. Nowhere does it state there cannot be infinite truths. In fact, the claim that there cannot be infinite truths is highly questionable because arithmetic suggests there are indeed infinite truths. Consider "for each a,b from Z, the set of all integers, there exists a c from Z such that a + b = c" is true. Arithmetic would claim this statement is true. From this one truth, we can create a series of truths in the form "for each b from Z, there exists a c from Z such that A + b = c is true", where we may use any integer value for A to construct this new truth. Since there are infinite potential values for A within Z, we have already constructed an infinite number of truths. 

If we want to discuss unusual possibilities like highly delayed perception, then we probably need to make sure we all agree on what the terms mean. I would define a "delayed perception" to mean at least that our perceived world is highly correlated with our environment's state was at some time in the past (a delay period). We can define perception to mean something more if we like, but this seems like a reasonable minimum to work from. The most natural place to disprove this claim would be in our ability to perceive responses to our own actions. If we choose to do something, such as fire a gun, we can then time our perception of the reactions of others to this gunfire. If it appears to us that the delay between us firing the gun and us perceiving a person reacting to it is short, then we must assume either: 

As a general answer, they are trying to shape the language used in the conversation to help further the conversation along. I have found the most useful viewpoint on this topic for myself is created by flattening out all of the complexity of defining such words into two directions. One directon occurs when a philosopher seeks acceptance for their theory of what something is by suggesting that a word everyone else has used informally is actually describing the something they are looking at. In such a case, if a philosopher can make an argument that this commonly used informal word is actually the concept they are exploring, they can describe what they are looking at much more succinctly. The other direction I see for such definitions is to create room for a new category where that category was previously crowded out by others. A trivial example would be if one believed everything was either "good" or "bad," and that it was always clear which was which. A philosopher might try to pin down your definitions of "good" or "bad" enough to suggest that there may be a middle ground between the two extremes where things are a bit murkier. (Likewise, a philosopher engaging in the first direction might seek to take that murky middle region and define "good" and "bad" such that you don't feel there's a need for that middle region at all). This becomes very important in philosophy because often philosophy deals with extreme scenarios, and controlling the meaning of the words becomes very important. As an example, "do unto others as you would have done unto yourself" gets complicated when one is talking about solipsism, or facing Laplace's daemon. It becomes very hard to interpret such phrases without very exacting meanings for mundane words such as "do." 

As user4894 pointed out, it's trivial to have such a set of trials. One such example would be a set of trials which included a one-time event, perhaps which consumed a resource that is no longer in the universe. Miracles might suffice as well. Such a set of trials would generate a sequence of success and failures like (1, 0, 0, 0, 0, 0,...) If we constrain the problem to only independent identically distributed random trials, which is a typical assumption in scientific experiments you run into more interesting issues. Such random variables, by definition, must have an associated probability space which has an associated probability measure. This is the mapping from events to the probabilities of those events occurring. From the definition of a measure, we have to map our events (1 or 0) to a number on the "extended real number line," which is all real numbers, + ∞ and – ∞. This will be a conundrum because you're going to need an infinitesimal to describe the probability of event 1, and infinitesimals are not part of the extended real numbers. Basically, the concept of random variables falls apart when you try to explore such a system. Similarly, you can construct the probability of a given set of events (such as "all infinite set of trials with only one success") by using the usual rules. This would be a way of saying "given a finite possibility of a 1, how unlucky do you need to be to get only a single 1." You can try to explore things like the p-value of such a result, but you quickly run into similar issues where the probability of a set of events is an infinitesimal. 

Several answers have said "no," which is the correct answer. However, in the spirit of helpfulness, I would like to provide a similar situation which, while also physical rather than theoretical, is closer to something which Occam's razor is applicable to. Consider that you have two taps you can choose from. For purposes of tapping water lines, they are identical (not even different sizes, as in your original question). However, one of them uses a laser, dremel attachment, a leak-detector, and a small microcontroller to do the task, while the other uses a simple screw and a punch. If, for all intensive purposes, you cannot determine the difference in quality between the jobs the two taps do, it would be reasonable to claim Occam's razor and choose the simpler of the two devices. The physical analog for the razor is, "this one has fewer parts that can break or get in my way or surprise me, and does the job just as well." Now consider the opinion of a different contractor while is working in a more demanding environment. In the environment he is working in, leaks are bad news; lets give him a motivation and claim he's working in a nuclear missile silo and a leak could launch the missile! In his situation, he can distinguish between the quality of the work done by the simple tap and the insanely complicated one: the complicated one has a built in leak detector that improves the quality of his work product! Because his situation is different (he can tell the difference in functionality between the taps), he cannot apply Occam's Razor. He must do a cost benefit ratio and make a full decision. In your situation, where there was no material difference between the performance of the same taps, you could apply the razor (or at least its physical analog). 

Dualism merely states that existence is fundamentally made of two forms of substance, typically named "matter" and "mind." Any theory with these two traits as the foundation of existence qualifies as dualism. Thus there are plenty of ways to define dualistic theories which are consistent with evolution. One of the larger challenges I have found people have with such consistency is that evolution is a scientific theory, and science and measurement go hand in hand. However, measurement and mind go together like oil and water. Consider IQ tests, which are oft criticized as only recognizing one form of thinking, or MBTI, whose efficiency has been questioned because it lacks bimodal distributions which its typification entails. As a general rule, measuring mind has been fraught with difficulty for thousands of years. Accordingly, do not be surprised when it is difficult to measure the claims of a dualist theory. Half of what they define is the unmeasurable. To give an example of such a theory that I find helpful for shaking up ideas, consider a worldview where anything can have intelligence, even rocks. All you need is for a mind to elect to bind itself to a material object. However, powerful minds tend to elect to bind (for some definition of "bind") themselves to material entities which have the capabilities to manifest their will. Thus there is a general pattern of the most capable material beings, H. sapiens, being imbued with the most powerful intelligences. However, every now and then an intelligence may choose to bind to a "lower" creature, such as a dog, resulting in above average animals. Is this the "true" world view? I don't know. It's entirely possible it is, but its real purpose was to define a dualist worldview which is fun to explore. For example, artists often claim that the canvas or the materials "spoke to them," and such claims have a 1:1 corresponding behavior in this worldview. Drugs can "shake your mind loose of its material body," and many religious patterns map into it. It is decidedly unmeasurable, but it should be a good reference point for arguing that dualism and any scientific theory can be treated as compatible. It also shows a third potential answer, as an alternative to A and B: C) the relationship between mind and evolution is one of a statistical correlation, and thus not fitting into any simple monotonic gradient. 

The universe does not obey our laws. The universe does what the universe does. "Gravity" is sometimes called a law, but it is more accurately described as a model to describe the world which has been so sufficiently tested that there is no reasonable reason to question it. Many of these stricter models (rephrased from "stricter laws") stem from the nature of science. Scientists generally appreciate stricter laws. Consider: photons used to have a "position." Now days we accept that that they are better modeled as a quantum wave. However, in the middle of that process, there was a period where we had to accept a fuzzy law that "photons have a position, except in these funny situations where they appear to not have a position." Scientists spent very little time suggesting that the photons should be arrested for their bad behavior, and spent their time working hard until they had a strict model that could supercede the previous one. One of the great successes of science is the concept of the random variable. Scientific measurements are always made with an error range around them. Consider that science, and indeed logic itself, would gravitate towards modeling the portion of life which can be modeled as an equation plus a random factor. If one wishes to take a non-realist bent on the situation, one only needs to have a reason to converge on a roughly realist outcome. One only needs a slight fraction of miracle (such as a virgin birth) to be not 100% realist. It would be trivial to define a world which was purely thought, but which nearly all thinking entities agreed upon a portion of our existence. 

So there's dozens of fancy directions an answer to this question could turn. We could talk about whether the goodness of an answer is objective or subjective. We could have fun with the unknown-unknown as you bring up. However your actual question focuses on "understanding." It is something that I think we all feel similar enough about that I can answer it directly: An answer is too complicated for you to understand when it leaves you with no new questions. If you finish an answer, sit back, and think "Wow. That really settles that, doesn't it?" then you may need to reread it for understanding. These questions and answers are not mountain peaks to be scaled: they are the pitted surface of the much bigger mountain that we are all climbing. If an answer does not make you look up a new mountain pitch and say, "I wonder what is on the other side of that rock field?" then it wasn't leading you towards climbing the mountain that matters to you. For myself, this definition is important. I could easily get lost in the question of whether I had fully comprehended the author's true meaning. It's just how I am. But if an answer makes me peek up above a boulder and see a path full of questions that I could ask beyond it, then I'm comfortable saying that I understood it enough, and the rest is history. 

There is also a belief in the definition of First Order Logic, which I think is a basic assumption for nearly all of humanity, but I can't call it a real basic assumption because there are schools of thought that do not depend on FOL. 

Declaring Creationism to be a science is only a problem if you fundamentally believe it needs to be a problem. If the word "science" bestows automatic rights to an idea, it could cause issues. For instance, if the mere fact that it is scientific makes it canon, you could be validly concerned with this issue. Honestly, I have read plenty of scientific literature defending Creationism. You can do it. The issue arises when that literature then tries to claim it is part of the larger body of secular science, which it is not. It starts from a different set of presumptions, so secular science simply doesn't accept it (it doesn't help that secular science arrives at results that contradict Creationism). It's like two different entities developing their own opinions with the same approach. Personally, I find no problems with this. If a group of people believe they can have a monopoly on science, they should find themselves mistaken, for the same reason one should find themselves mistaken if they try to claim a monopoly on the ability to do arithmetic. Using Kuhn's approach, secular science's position for countering Creationism would be to wait for the cycle to continue. Eventually the Creationist scientists will enter a revolution phase to deal with new data (there's questions as to whether the data is already there, and they're ignoring it, but that's another debate)*. They will have to come up with new, more complicated theories to make sense of the data. Eventually, they may find that this revolution phase cuts the wind from their sails, and Creationism peters out as the theory grows too unwieldy to digest this new evidence. Or, alternatively, they may find something the secular community never considered, in which case, their theory gains more credit, and secular science has to struggle to catch up. In either case, science itself wins. * I am constantly fascinated by the debates regarding the accuracies of dating methods. If nothing else, Creationism has kept science honest about its abilities in dating! 

So you have a very good idea, but it's not quite what the mathematicians were looking for as they dealt with the paradoxes of that age. The big issue is that you are offering an approximation to a paradox, rather than actually resolving it. This is useful, mind you, but it's not what the mathematicians were looking for. In particular, they needed to make sure that the meanings of True and False withstood literally infinite applications without becoming ill defined. Redefining truthhood from a binary value to a real is meaningful, but its not the spirit those like Russel were going for. For one thing, probability is a COMPLICATED layer of mathematics, and they were trying to pin down the absolute simplest layers with the fewest assumptions possible, or even no assumptions at all. Starting from probability would be a tough pill to swallow. The second issue is one that may appear as you flesh the idea out: there may be some paradoxes which result in infinitely divergent results, where categorizing the result with a bunch of draws averaging at 0.5 true does not capture the fact that the underlying math was ill defined. Those issues aside, what you describe is not unlike a Quantum Computer. We've actually built them, and had them do things classical computers bounded by True and False, cannot match (well, fine... we've factored 15 into 3 and 5, but we did it in polynomial time, so chew on that, classical computers!) Quantum Computers solve some really neat problems that are quite unrealistic for classical computers to solve. Many even theorize that there exist problems quantum computers solve that can't be done with classical computers (part of the so called PSPACE class of computational difficulty)