The issue here will be the main criticism of the Popper's solution to the problem of induction. Popper said that induction is not justifiable. That a theory has been corroborated in the past "says nothing whatever about future performance." Popper said that it is possible to avoid assuming that the future will, or probably will, be like the past, and this is why he has claimed to have solved the problem of induction. We do not have to make the assumption, he tells us, if we proceed by formulating conjectures and attempting to falsify them. He says that, as a basis for action, we should prefer "the best-tested theory." Popper never adequately defined the notion of severity for tests, a concept on which much depended, since the more severe the test a theory passed, the better its corroboration. This can only mean the theory that has survived refutation in the past; but why, since Popper says that past corroboration has nothing to do with future performance, is it rational to prefer this? Corroboration is not another term for confirmation since it does not involve any notion of inductive support for a theory. Theories remain as unsupported hypotheses or conjectures forever. Corroboration is not a measure of verisimilitude. Saying that the better corroborated theory is also the one that is closer to truth would be no more than a guess. Why is it rational to act on the basis of a decision informed by the best tested and corroborated theory, to apply it to new situations, to decide to use it as basis for practical action? Corroboration says absolutely nothing about the future performance of a theory. In what sense, therefore, is the decision to act a rational one? The reply of Popper is that since it is the best theory, what could be more rational than acting on such a theory, than holding a “pragmatic belief in the results of science”. This reply is not entirely satisfactory. For under the circumstances, the rational thing to do is not to act at all. If our best theory provides us with no clue as to the prospect of achieving our goals, then it cannot sufficiently motivate us to act. For our best theory to guide us in our actions, its past success should give us some reason for its future success. In short, Popper must allow for inductivism. The concept of corroboration cannot explain why it is rational for scientists to base their future predictions on the best corroborated theory. To do this, it is inevitable for them to accept some kind of principle of induction. Without the inductive assumption, the fact that a theory was refuted yesterday is quite irrelevant to its truth-status today. Corroboration is also uncertain and can never be quantified by degree of probability. Wesley Salmon in his paper “Rational Prediction” focuses attention on the practical case in which one must decide on a course of action on the basis of a theory. Salmon asks how one is to choose between alternative theories which make conflicting predictions as a basis on which to act. According to Popper, the action should be based on the most highly corroborated of the competing theories. But this suggests that corroboration has inductive force. For while corroboration relates to a theory’s past success in surviving tests, if it is to serve as a basis for future action then past survival of tests must be of relevance to what will take place in the future. But if corroboration is to be taken into account in determining a future course of action, this amounts to an inductive inference from past success in surviving tests to the likely continuation of such success into the future. Again, it therefore appears that Popper’s falsificationist philosophy of science rests at base on an assumption that is inductive in nature. Popper’s theory of method suggests that theories are to be rejected the moment they entail a false prediction. Lakatos denies that there are critical tests, in the Popperian sense, in science. Ruthless elimination of theories does not appear to be the norm in actual science. The point here is that the ‘falsification/corroboration’ disjunction offered by Popper is far too logically neat: non-corroboration is not necessarily falsification, and falsification of a high-level scientific theory is never brought about by an isolated observation or set of observations. Such theories are, it is now generally accepted, highly resistant to falsification. They are falsified, if at all, Lakatos argues, not by Popperian critical tests, but by research gradually grinding them to a halt. Popper's distinction falsifiability does not in the end do full justice to the fact that all high-level theories grow and live despite the existence of anomalies which are incompatible with the theories. The existence of such anomalies is not usually taken by the working scientist as an indication that the theory in question is false; on the contrary, he will usually, and necessarily, assume that the auxiliary hypotheses which are associated with the theory can be modified to incorporate, and explain, existing anomalies. Philosophers of science who hold that the actual practice of science is of relevance to the normative methodology of science will be little inclined to adhere to the Popperian picture in the face of historical evidence of anti-falsificationist practice in science. To Martin Gardner, every falsification of a conjecture is simultaneously a confirmation of an opposite conjecture, and every conforming instance of a conjecture is a falsification of an opposite conjecture. If Popper bet on a certain horse to win a race, and the horse won, you would not expect him to shout, "Great! My horse failed to lose!". For Popper, the more tests for falsification a theory passes, the more it gains in "corroboration”. It's not so much that Popper disagreed with inductivists as that he restated their views in a bizarre and cumbersome terminology. 

According to the Stoic theory, there are eight parts of the soul, the "commanding faculty","ἡγεμονιχόν", or mind, the five senses, voice and certain aspects of reproduction. The mind, which is located at the heart, is a center that controls the other soul-parts as well as the body, and that receives and processes information supplied by the subordinate parts. 

(The author of the question didn't give a formal definition then: dictionary - epiphany - a sudden, intuitive perception of or insight into the reality or essential meaning of something, usually initiated by some simple, homely, or commonplace occurrence or experience.) Yes, there is. But in psychology and not in philosophy. The Eureka effect, also known as the aha! effect, refers to the common human experience of suddenly understanding a previously incomprehensible problem or concept. Some research describes the Aha! Effect, also known as insight or epiphany as a memory advantage, but conflicting results exist as to where exactly it occurs in the brain, and it is difficult to predict under what circumstances one can predict an Aha! Moment. Insight can be conceptualized as a two phase process. The first phase of an Aha! experience requires the problem solver to come upon an impasse, where they become stuck and even though they may seemingly have explored all the possibilities, are still unable to retrieve or generate a solution. The second phase occurs suddenly and unexpectedly. After a break in mental fixation or re-evaluating the problem, the answer is retrieved. Some research suggest that insight problems are difficult to solve because of our mental fixation on the inappropriate aspects of the problem content. In order to solve insight problems, one must “think outside the box”. It is this elaborate rehearsal that may cause people to have better memory for Aha! moments. Insight is believed to occur with a break in mental fixation, allowing the solution to appear transparent and obvious. Currently there are two theories for how people arrive at the solution for insight problems. The first is the progress monitoring theory. The person will analyze the distance from their current state to the goal state. Once a person realizes that they cannot solve the problem while on their current path, they will seek alternative solutions. In insight problems this usually occurs late in the puzzle. The second way that people attempt to solve these puzzles is the representational change theory. The problem solver initially has a low probability for success because they use inappropriate knowledge as they set unnecessary constraints on the problem. Once the person relaxes his or her constraints, they can bring previously unavailable knowledge into working memory to solve the problem. The person also utilizes chunk decomposition, where he or she will separate meaningful chunks into their component pieces. Both constraint relaxation and chunk decomposition allow for a change in representation, that is, a change in the distribution of activation across working memory, at which point they may exclaim "aha!". Currently both theories have support, with the progress monitoring theory being more suited to multiple step problems, and the representational change theory more suited to single step problems. 

Yes, it is possible, it can occur, for example through the State: Prostitutes, pimps, blackmailers, thieves, gangsters, must pay taxes. For the State, "Pecunia non olet", "money does not stink". The crack tax which was passed by the Tennessee General Assembly in January 2005, levies on illegal drugs like moonshine, cocaine, and marijuana. It is up to drug dealers to pay at the state revenue office, and then they receive as stamp to provide evidence that they have paid. The "claim of right doctrine" in the United States, which is to hold that illegal proceeds could not constitute income because the taxpayer has no claim of right to the income and is under an obligation to return the proceeds. This doctrine was rejected by the United States Supreme Court in 1961 in favor of an "economic benefits approach", which asks the question whether the taxpayer "'has such control over an ill-gotten gain that, as a practical matter, he derives readily realizable economic value from it'". The rejection of the "claim of right doctrine" was based on a clearly-delineated policy decision by the Supreme Court: "We should not continue to confound confusion, particularly when the result would be to perpetuate the injustice of relieving embezzlers of the duty of paying income taxes on the money they enrich themselves with through theft while honest people pay their taxes on every conceivable type of income." In addition, "the purpose of Congress was to use the full measure of its taxing power". The courts in the United Kingdom have reached a level of clarity: proceeds will be taxed as long as they arise or accrue from a trade, whether legal or illegal. This standpoint appears to be underscored by a move away from the idea that the State, by taxing illegal proceeds, condones the activity from which these proceeds spring, to the idea that the State should not allow the wrongdoer to benefit from advantages which are denied to the honest taxpayer. In England, various courts have repeatedly rejected the argument that a trade ceases to be a trade for the purposes of the Taxes Acts because it is illegal. The reason why they have said that profits of burglary are not taxable is not because burglary is illegal but because burglary is not a trade. Conversely, if the activity is a trade, it is irrelevant for taxation purposes that it is illegal. It is not necessary to reach any conclusion as to whether profits from an illegal trade are assessable to income tax under the present law of England. There may be lawful trade, there may be unlawful trade. But it is still trade. 

Nietzsche traces the master and slave morality back to the masters and slaves of ancient times. He suggests that our most cherished values originated not among those who were the best and brightest of their times, but among those who were the most oppressed and impoverished. The dominant emotion in the evolution of morality, in other words, was not pride in oneself or one's people, but a defensive prejudice against all of those who succeeded and achieved the happiness that one could not oneself achieve. Nietzsche argues that the roots of ressentiment morality are to be found in the history of the Jews. In ‘Jewish hatred’ for the Roman oppressor lie the seeds of Christian faith and morality. The ancient Hebrews and then the early Christians simmered with resentment and concocted a fabulous philosophical strategy against their ancient masters. Instead of seeing themselves as failures in the competition for wealth and power, they re-valued their values and turned their resentment into self-righteousness. Morality is the product of this self-righteous resentment, which is not nearly so concerned with living the good life as it is with chastizing those who do live it. In its extreme form - asceticism - it is the active denial of the good life, the ultimate outlet of resentment as self-righteous self-denial. Nietzsche suggests then, on the basis of this analysis, that Christian morality is inherently structured as a form of slave morality's ressentiment toward the masters, and it accomplishes revenge imaginatively, by means of passing judgment. The strong, active traits of the masters are vilified by the slavish, who come to regard their own passivity and weakness as virtues. This pattern pervades the moral ideals of Christianity. Many modes of self-assertion and self-expression are analyzed as sins on the Christian scheme, while passive suffering is deemed characteristic of the blessed. Since Christianity is based on "slave morality' it must be a point of honor for the "strong" to overcome it. For them it is"indecent" to still be Christians. Nietzsche assert with regularity that religion is necessary primarily or solely for the weak.