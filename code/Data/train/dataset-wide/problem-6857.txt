For game theory: Game Theory by Fudenberg and Tirole Repeated Games and Reputations : Long-Run Relationships by Mailath and Samuelson The Theory of Learning in Games by Fudenberg and Levine Evolutionary Game Theory by Weibull 

The von Neumann-Morgenstern (vNM) utility function takes the form \begin{equation} U(p,x)=\sum_{i=1}^np_iu(x_i) \end{equation} where $x=(x_1,\dots,x_n)$ with $x_i$ being the (monetary) payoff associated with outcome $i$ and $p=(p_1,\dots,p_n)$ with $p_i$ being the probability that $i$ occurs. In behavioral economics, generalizations of the vNM utility usually happen in either (or both) of the following two channels: 

It's called reference-dependent preference, a notion belonging to the intersection of economics, psychology, and neuroscience. Here is a set of brief introductory slides on the concept 

Converting my comments to an answer: I think your answers to 1 and 2 are correct. For 3.1, your intuition that "as well off as" should be interpreted "indifferent" is correct, and indifferent is about comparing utility levels, not MRS. You answer to 3.2 looks correct. 

What you're asking seems to me just a matter of interpretation. Note that $\mathbb Z$ and $\mathbb Z_+$ have the same cardinality. So it makes no substantive difference which index set you use. Moreover, in a continuation game with finite history, any strategy can be interpreted as a (possibly non-stationary) Markov strategy in a continuation game with infinitely long history. If a history of infinite length is what you really care about, then may be looking into the literature of continuous-time repeated game will provide some insight. 

LaTeX with The package of LaTeX allows you to draw game trees with pretty simple syntax. After copying a pre-set template into the LaTeX preamble, one can build up the game tree using a nested syntax, then the program takes care of node placement/spacing/etc. 

Hidden information concerns characteristics that are unobservable by one side of the market. For example, a consumer's willingness to pay, a worker's productivity, the quality of a used car all fall under this category. The characteristics in question are typically assumed to be fixed or very costly to modify. Moral hazard concerns actions that are unobservable by one side of the market. For example, the effort that a CEO puts into managing a company and the care that an insured driver takes to maintain the condition of his car both fall under this category. By their very nature, the (unobservable) actions can be easily changed to suit the incentive structure of the problem. 

Suppose your conjectured strategies are $\{B,C\}\times\{A,B\}$ (it doesn't really matter what the basis for your conjecture is; you're going to find out one way or another whether that's correct). Next, calculate the probabilities using players' indifference conditions. Let $p=\sigma_1(B)$ and $q=\sigma_2(A)$, we have \begin{align} -3p&=-1&&\Rightarrow\quad p=1/3\\ 3q+1-q&=1-q&&\Rightarrow\quad q=0. \end{align} [This suggests that your calculation for $q$ was incorrect.] Lastly (this is the most easily forgotten step), check that no one has an incentive to deviate from this equilibrium. In this case, player 1's payoff is $1$, which is already highest given player 2's strategy of choosing $B$ with probability 1. He'd be indifferent between mixing in other proportions over $B$ and $C$, and his payoff is strictly lower if he plays $A$ with positive probability. Player 2's expected payoff in this equilibrium is $-1$, which is also the highest given player 1's mixed strategy. She's indifferent between mixing over $A$ and $B$ with any other proportions and is strictly worse off if $C$ is played with positive probability. So, one MSNE is $((0,1/3,2/3),(0,1,0))$. This is only borderline consistent with your initial conjecture because $\sigma_2(A)=0$. But it's nonetheless a MSNE. In fact, there are infinitely many MSNEs of this form: $((0,p,1-p),(0,1,0))$ where $p\ge1/3$. This is a full description of all equilibria (including the pure one) in this game. 

A bit late to the game, but I'm surprised no one has named the equation to calculate OLS estimates: $$ \hat\beta=(X'X)^{-1}X'y $$ 

The transversality condition may be more easily understood if we start from a problem with finite horizon. In the standard version, our objective is to $$ \max_{\{c_t,k_{t+1}\}_{t=0}^T} \sum_{t=0}^T\beta^t u(c_t) $$ subject to $$ \begin{aligned} f(k_t)-c_t-k_{t+1}&\ge0,\quad t=0,\dots,T &&\text{(resource/budget constraint)}\\ c_t,k_{t+1}&\ge0,\quad t=0,\dots,T &&\text{(non-negativity constraint)} \end{aligned} $$ with $k_0$ given. The associated Lagrangian (with multipliers $\lambda_t$, $\mu_t$, and $\omega_t$) is $$ \max_{\{c_t,k_{t+1},\lambda_t,\mu_t,\omega_t\}_{t=0}^T} \sum_{t=0}^T \beta^tu(c_t)+\lambda_t(f(k_t)-c_t-k_{t+1})+\mu_tc_t+\omega_tk_{t+1} $$ The FOCs are $$ \begin{align} c_t:&& \beta^tu'(c_t)-\lambda_t+\mu_t&=0,\quad t=0,\dots,T \\ k_{t+1}:&& -\lambda_t+\lambda_{t+1}f'(k_{t+1})+\omega_t&=0,\quad t=0,\dots,T-1 \\ k_{T+1}:&& -\lambda_T+\omega_T&=0,\quad T+1 \tag{1} \end{align} $$ with the Kuhn-Tucker complementary slackness conditions: for $t=0,\dots,T$, $$ \begin{align} \lambda_t(f(k_t)-c_t-k_{t+1})&=0 & \lambda_t&\ge0 \\ \mu_tc_t&=0 & \mu_t&\ge0\\ \omega_tk_{t+1}&=0&\omega_t&\ge0\tag{2} \end{align} $$ Since resource constraint must be binding in all periods, i.e. $\lambda_t>0$ for all $t$, it follows that at the last period $T$, $\omega_T=\lambda_T>0$, which in turn implies $k_{T+1}=0$. Usually we assume $c_t>0$ for all $t$ (the Inada condition), and this implies $\mu_t=0$ for all $t$. So the consumption FOC becomes $$ \beta^tu'(c_t)=\lambda_t \tag{3} $$ Looking at conditions $(1)$ $(2)$ and $(3)$ in the last period $T$, we get $$\beta^Tu'(c_T)k_{T+1}=0$$ Extending this to the infinite horizon, we get the transversality condition $$\lim_{T\to\infty}\beta^Tu'(c_T)k_{T+1}=0$$ The intuition of the transversality condition is partly that "there is no savings in the last period". But as there is no "last period" in an infinite horizon environment, we take the limit as time goes to infinity. 

If the price ceiling is above equilibrium price, then the market would just settle for the equilibrium price, and the price ceiling would have no effect. Same thing for price floors: if the price floor is below equilibrium, then it'd have no effect. 

In a typical GE model, price (including wage and rent) is determined by the market clearing condition, which requires that supply equals demand. Specifically, 

In a typical OLS model, $Y=\alpha+\beta X+\epsilon$, endogeneity exists when $E[\epsilon\,|\,X]\ne 0$, which results from $X$ and $\epsilon$ being correlated with one another. In your case, $Y$ uncorrelated with $\epsilon$ implies only that $E[\epsilon]=0$, which is not the same as the exogeneity condition $E[\epsilon\,|\,X]= 0$. Moreover, $Y$ uncorrelated with $X$ just means that $\beta=0$. Again, this does not save you from the endogeneity problem. Actually, in addition to endogeneity, you now have another (bigger?) problem to deal with; that is, using a regressor that is a very poor predictor of the dependent variable. 

First remind yourself what weak convexity means. Then compare the utilities that the individual gets from the following pairs of bundles: 

If there were such a spectrum, it would not be one dimensional. For instance, we could compare the competitiveness of markets with homogeneous products in terms of the number of firms in that market, and have the following spectrum: 

He then goes on to explain this using an example of weather forecast. If the temperature in a region typically varies between 85째F and 95째F, then it would be wrong to predict 50째F one day and 115째F the next day (although this would be approximately right on average). What exactly is underlying mathematical principle for when he says "the predictions can't vary more than the thing being forecast"? Do forecasts have to get both the mean and the variance right to qualify as rational? 

Let's write \begin{align} x&=ap+(1-a)r\\ y&=aq+(1-a)r \end{align} You want to show that $x\sim y$. But \begin{equation} x\sim y\quad\Leftrightarrow\quad x\not\succ y\;\text{ and }\;y\not\succ x. \end{equation} So the given proof tries to establish that $x\not\succ y$ (and in a similar way, $y\not\succ x$) is true. To show this, use proof by contradiction. Suppose the contrary is true: $x\succ y$, and try to derive a contradiction. This is what the given proof is doing. 

Thaler, and Kahneman and Tversky before him, mounted copious evidence that people consistently deviate from the behavioral benchmark set by the homo economicus. But to people like Friedman, this is not a sufficient cause for a change of paradigm, unless one brings conclusive evidence to show that the predictions made by rational choice models are wrong. It didn't help that experimental economists like Vernon Smith were successfully showing that (in the market context) people's collective behavior leads to outcomes consistent with rational choice theory. (In this regard, it does seem a bit ironic that Smith would share a Nobel with Kahneman). Another reason against the paradigm shift could be in the interest of parsimony. Including more realistic behavioral foundations in economic models inevitably makes the models more complex. But if the simpler, albeit less realistically-founded, rational choice model can get things right just as well, there is a philosophical reason for favoring the latter. In a way, this is similar to the if-it-ain't-broke-don't-fix-it mentality. Eventually, however, rational choice theory were found to fail to predict a lot of phenomena. For example, Nash equilibia are notoriously inaccurate in predicting how people actually behave in many games (e.g. Prisoners' Dilemma, ultimatum game, public goods game, and so on). And adding behavioral assumptions/relaxing the rationality assumption seemed like a natural way to "fix" existing models to increase their predictive power. Hence we have the rising popularity of behavioral economics these days. Still, these "behavioral patches" are often met with skepticism from of many traditional "rationalists". See this post for example. 

Consider the following counterexample: \begin{array}{|c|c|c|c|} \hline &L&C&R\\\hline U&1,3&3,4&3,0\\\hline M&2,3&0,1&0,4\\\hline D&0,0&1,2&2,1\\\hline \end{array} In this game, $L$ is never a BR to any of player 1's pure strategies. However, if player 2 believes player 1 will play a mixed strategy that assigns $\frac12$ probability to $U$, $\frac12$ to $M$ and $0$ to $D$, then $L$ becomes a BR. 

You may be interested in reading "Economic Models as Analogies", a 2014 article by Itzhak Gilboa, Andrew Postlewaite, Larry Samuelson and David Schmeidler, four well regarded economic theorists. They argue, somewhat contrary to your view of economic theorizing, that economic models are better viewed as "theoretical cases" rather than general rules akin to the laws of physics. Predictions are made by drawing analogies between the world in which the models live and reality. In Section 4 of the paper, they do propose a "model of economic models" that formalizes their argument. Although this model is probably not the one you were looking for, it may help clarify your (mis)perception of the methodology in theoretical economics. The paper's abstract is as follows: 

You intuition about the assumption is correct. Given the usual assumptions of downward sloping demand curve ($p'(q)<0$) and non-decreasing supply curve ($c''(q)\ge0$), if $p(0)<c'(0)$, then demand would lie entirely below supply. This means the equilibrium quantity must be zero---as if the market did not exist. Therefore, for the analysis to be non-trivial, the assumption of $p(0)\ge c'(0)$ is maintained. With the use of calculus, we are assuming implicitly that quantities are infinitely divisible. Thus $c'(0)$ can be roughly interpreted as the cost of producing the "first infinitesimal unit" of the good. Mathematically, \begin{equation} c'(0)=\frac{\mathrm d\, TC(q)}{\mathrm d\,q}\Bigg\vert_{q=0}=\frac{\mathrm d\,(FC+VC(q))}{\mathrm d\,q}\Bigg\vert_{q=0}=\frac{\mathrm d\,VC(q)}{\mathrm d\,q}\Bigg\vert_{q=0}. \end{equation} Thus $c'(0)$ is the derivative of the variable cost function, evaluated at $q=0$. 

As the graph notes, the red segment of the demand curve is relatively inelastic, meaning that compared to the blue segment, the red segment of demand is relatively insensitive to price changes. This does not mean that price elasticity anywhere on the red segment is less than 1 (which implies inelasticity in the absolute sense). 

I should add that Sen is particularly good with giving people credits. So the bibliography section of his books/articles will surely have many more useful sources on this topic.