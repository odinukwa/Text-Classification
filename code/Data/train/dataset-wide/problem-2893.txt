This is a class from my personal code library, and from a package which deals with integer sequences. It implements an interface 

I concur with VisualMelon's observations on this constructor: there's no reason to prohibit empty inputs, there's no need to populate the pool yet, and there's no reason to require rather than . 

There are a couple of points which the existing answer missed, one of which I consider quite important. Datatypes 

The table generation can certainly be simpler and faster by removing the direct binary-to-decimal conversion: 

Given the problem description, I'm not entirely sure why is a parameter of . Could you not hard-code ? 

This is also unnecessary, because AES only supports one block size. However, you could argue that it's future-proofing. I personally would remove it. 

The stated goal is to handle "encrypted plaintext in the order of kilobytes". Depending on how tight that constraint is, you may have a problem here. I have recently learnt the hard way that some providers have (not obviously documented) limits on the size of ciphertext or plaintext that they will handle correctly in . 

Memoisation support in Python 30 seconds with Google turned up $URL$ . If you know that you're only going to want 10000 different arguments memoised then 

Alternatively, working forwards, if the points are (, etc.) then the sharpness condition is that $$\widehat{Q-P} \cdot \widehat{R-Q} < \frac{1}{\sqrt 2}$$ which is equivalent to $$(Q-P) \cdot (R-Q) < \frac{\sqrt{(Q-P)\cdot(Q-P)} \sqrt{(R-Q) \cdot (R-Q)}}{\sqrt 2}$$ corresponding to 

Don't count. Calculate. The Wikipedia article on partitions gives the Hardy-Ramanujan estimate \$P(n) = \Theta(n^{-1} e^{k \sqrt n})\$ with \$k=\pi \sqrt\frac23\$. Since your code finds the partitions to count them, and since the "average" partition has a lot of \$1\$s, your running time is \$\Omega(e^{k \sqrt n})\$. The Wikipedia article also gives a number of recurrence relations, including one which uses generalised pentagonal numbers (giving a running time of \$\Theta(n^{1.5})\$), and another which uses the sum of divisors function (giving a running time of \$\Theta(n^2)\$ if you pre-calculate the sum of divisors using e.g. the sieve of Eratosphenes). An alternative quadratic approach (which you could find by following the Mathworld link from Wikipedia) uses the auxiliary function \$P(n,k)\$ for the number of partitions of \$n\$ into parts of which the largest is exactly \$k\$ and the recurrence \$P(n,k)=P(n-1,k-1)+P(n-k,k)\$. 

I've looked over the rest of the code briefly, but without any comments I didn't have much idea of what it was trying to do, and I didn't feel like reverse engineering it. 

I would find this more readable as a static method (note the extra in !). Then the listener would be something like 

This is quite confusing use of names, especially if you later want to refactor from a balanced collection to a balanced map. 

This should have the invariant that after the th time round the loop it has added elements to . Either the first two cases need to add a single element, or they need to . 

Basic number theory: unique prime factorisation, greatest common divisor, finding it efficiently; Sane factorisation of a small number (and \$10^{12}\$ is very small in these terms) 

does a lot of copying behind the scenes. Especially if you have a complex string, you'd be better off with a in a loop. Something like (untested code): 

For the same problem but with a single deletion, it's easy: for every run of consecutive characters, you have identical strings, so you discount of them. There are possible deletions, so the number of distinct strings is . With two deletions, there are various cases to consider. 

That's a misleading name: it strongly implies that the return value is a single set, whereas in fact it should be a list of sets. 

If is the registration page then (a) it seems rather lacking in content; and (b) there seems to be a catch-22 with rendering it for the first time in order to submit data. 

I'm not familiar with Spark. It's obvious that this code isn't thread-safe ( isn't thread-safe, and is accessed without any explicitly locking), but I don't know whether Spark provides the thread safety. The cookie handling is missing two important parameters: 

Huh? Where did those reciprocals come from? Also, you seem to have started changing to and got distracted part-way through. 

Not just ? As a matter of taste, I prefer to have the special case dealt with inside the recursive call. 

Actually, if \$N\$ is large enough relative to \$k\$ you can do even better with a more complicated approach. Treat it as a Markov chain and find a matrix power of the \$0-1\$ matrix which indicates the successor function. That takes \$O(\lg N)\$ matrix multiplications of a \$k\times k\$ matrix. 

Two things: Firstly, a statement at the end of a loop does precisely nothing. This code is directly equivalent to 

Could use some documentation explaining what and are. I think is the number of bytes to process, and is the number of bits corresponding to the fractional part. 

Now I can come back to modular division. Essentially needs to calculate a modular reciprocal of (i.e. such that ) and then return . There is always such a as long as it is coprime with , and is deliberately chosen to be a prime number, deliberately chosen so that you can divide by any number which isn't a multiple of it. The standard approach to calculate a modular reciprocal is the extended Euclidean algorithm, and is described in so many millions of web pages that I won't try to give my own explanation here. To wrap up the explanation, I must address a point raised by Rick Davin. If you rewrite so that and are both , how to handle the test case ? If we look at how is used, it takes part in addition and multiplication. So the way to do this is to do the modulo in and then cast to : 

is just plain wrong. It turns a linear operation into a quadratic one through looped copying. The fast approach here, using Gray codes, would look something like: 

Here we have a familiar culprit when code runs too slow: . Testing whether a list contains a value takes linear time: if you want a fast test, use a :