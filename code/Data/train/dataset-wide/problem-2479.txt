Performance The first part will be slow (300ms on my laptop). It doesn't depend on the pattern, so you could calculate it once and cache it with or . took less than 100ms. The second part is really fast though. For , the trie version is more than 1500 times faster than @200_success' code (40 µs vs 68 ms). The trie code gets a bit slower with more placeholders, it's always a few orders of magnitude faster than the other answers, though. 

Python strings are basically tuples of characters, so you don't have to change much in your code. The above example is isomorphic to yours and is much more concise. KeyError When calling , you're hoping there won't be any . Your example would fail with : 

looks like . With Sympy You can delegate the job to and be sure you'll get a correct result with arbitrary precision: 

You get more information, it's more robust, you get diagrams if you want, it can handle more complex cases and (who knows?) it might be faster than your solution for large datasets. 

Theory Calculate prime factors For a semi-naive approach, you could calculate the prime factors of first: 

Another alternative would be to work with generators and join the letters at the end instead of building a new string character by character. 

Upper bound for p_n There is a known upper bound for the n-th prime. It means that you don't need to guess how large it could be. tells us in less than a micro-second that the desired number cannot be larger than . You just need to apply the Sieve of Erathosthenes up to 114320 and you're done: 

You seem to think that this code would display 500 numbers between and . It doesn't. Instead, it displays , , and returns . You need to replace with . Alternative You can use to look for the substrings, them and replace them: 

? Your current algorithm doesn't seem to take it into account. A might help, for example to keep a list of nodes beginning with and another list for nodes finishing with . Output format If you only sort the edges, without grouping them in connected components, you're losing information which you have to recover later. You could return a list of sets of edges instead of a flat list of edges. 

Looping over your array and sorting out, which ones you don't like. You could play with this Fiddle 2) The "functional" approach 

There are more efficient ways to implement this: 1) If you only need a dictionary to keep your data together without semantics, you could split as follows: 

First: I have to admit, I do not know a single line Elixir. But on the other hand, I think I get, what the code does. I can not give you advice, how to implement the improvements, but I hope to help you anyway. In the description you have the following definition: single minutes: When it is 1 minute past the hour, YOOO is returned. When it is 2 minutes past the hour, YYOO is returned. When it is 5 minutes past the hour, OOOO is returned. single hours: When it is 1 hour past, ROOO is returned. When it is 2 hours past, RROO is returned. When it is 5 hours past, OOOO is returned. What both have in common is the pattern and the result . That should result in one function, which takes the following parameters: number,Symbol and produces the according output. Your code has: 

Supposing, splitting by \w+ gives in most cases, what you want. Another solution would be . Depends on your demands. Go play with it! 

But while skimming through the code, two questions come to my mind: 1) Why is this called a - besides the case, Chris mentioned, what makes it really fast? I am seeing the usage of a . Hopefully it is fast. I see nothing special in your code, that makes it fast. 2) I do not see a single usecase for this. At best, you have some kind of which describes your Inputfile. Why waste time and put a wrapper around concrete data. 

I've seen, that you made up this code as an example, so I hope, that this is not your production code: 

is in fact a model with a key called "content" (e.g. {content:"blah!"}), which is used to render the template, so that <%= content %> is substituted with the actual content. And many more stuff to discover. Referring to your problem - you could abstract your problem with backbone like the following: Every tab you need to display is a view to which belongs a template to determine its html as well as a model, which represents the content of the tab. You could embed each tab in another view, such that you have one embracing view to control the whole tabbing system and nesting views, which represent each individual tab. You could write a custom show() method to show an individual tab and a method which coordinates which of the tabs is shown and which should be hidden. So instead of doing the annoying work yourself, it may be a good idea to use a library to help. Some places to start (besides the official API and documentation): $URL$ $URL$ $URL$ $URL$ 

Besides great performance improvement due to 's suggestion, the code can also be improved. I have put comments to indicate changes: 

I am not familiar with Autofac (I am a Ninject fan), but I expect similar concepts and implementations, so I have a few ideas: 1) data models serialization I see attributes in your data models, which leads to serialization (?). As far as I know, directly serializing EF data models is not a good idea because it might lead to circular references caused by navigation properties (which crashes the serialization). One way is to define some service models that are obtained from data models. Mapping can be done quite easy using a auto mapping library such as AutoMapper. 2) Repository implementation can be extended with some useful functions 

What happens if your dice changes into a larger polyhedral one? Your ifs statements will not handle the value at all. So, a reasonable version is to use something like 5) Encapsulate your damage simulation in a class Since main is much slimmer now, we expect that everything is handled by a special designed class: // created new class to separate things 

Generally, it is easier to think your program logic top-down than bottom up (doing little things and merging usually requires more skill): 

and call this function by providing / to your parameter. Also, functional scalability might be an issue: what if you have to handle 11 eleven floors in the future? (0 -> 10). You will be forced make several changes to handle a simple request like this. In order to accommodate larger values, I would dynamically define your array and not base my condition on char (which allows only one character). Something like this (not tested): 

Complexity should be as all dictionary operations are done in . If your documents were copied from some other data structure to your response, I think it is better to construct the dictionary from that data structure and obtain from the merged data. Otherwise, you have to use a loop to remove documents already merged (somewhat more convoluted than version). 

Second: Technically, it would have the same effect, to declare an array step by step or in a row. And no: there is no real way to convert your code automatically from the former to the latter. But perhaps, your question goes in another direction. Perhaps you want a solution to easily build combined arrays. For that task I suggest to take a look at underscore's zip function: 

I can't find any reason for your global variable. As far as I can see, it is declared and overridden in the success handler of your ajax request. So why not declearing it inside the success handler? Next: Why didn't you use a parameter in 

I think, there is room for some improvement: 1) You are mixing OOP with procedural code If you choose one paradigm, you should stick with it. Besides: why are you abstracting into a class and not the whole ? 2) DRY - Don't repeat yourself 

»If the book is or the book is blank throw an « Btw. Why did you you use the negative from: instead of just ? 

You have a instead of a plain variable. This helps you to encapsulate: 1) The name/filename (in case you need it somewhere else) With the constructor, you are free to define a naming scheme for your files. For the sake of the example, I simply used ".dat" as a suffix. 2) The actual datastructure (here for the sake of the example a list named »array«) 3) The calculation function This is, what OOP was invented for: keeping together data and functions, which work on that data. In the -function, you see, how you set up things: 1) the are made of a simple tuple, holding the name as the first element and the function as a second element 2) the configuration of your "variables" is done via list comprehension . For more complex tuples, I would go with namedtuple which allows you to reference the content of the tuple via proper names than indices, which would result in better readable code. But in this scenario, the indices do the trick. Your -function should take the list of objects as a parameter. And you are done. 

One way is to have a function that returns a table composed of two s, corresponding to each of your s: 

4. Tests - it is a good habit to accompany a function with a test suite. It is particularly efficient when the code changes much (regressive testing) and helps to cover scenarios that are usually missed when developing (developers have a tendency to think in terms of making it work, not making it fail). 

5) Try to use mainstream frameworks such as EntityFramework to handle data fetch dirty work. Fetch would look like this: 

2) Error handling function does not handle any incorrect formatting. Any line which is not in the format name=value will not be imported correctly. You can explode into an and check if elements are defined and exactly two. 3) A more powerful config reader This is a good exercise, but ini files have a more complex format that seems to be handled by parse_ini_file function. 

Your models project should contain only functionality related to data models such as: data models themselves, data context, repositories. Provided code does a simple thing: gets a model based on its identifier, so this can be included in a Repository. E.g: 

in $configFile = !isset($configFile) ? $defaultConfigFilePath : $configFile; Hopefully, they will introduce a coalesce operator soon to simply write: 

3. Checking for duplicates - The algorithm itself can be improved by thinking in terms of set. I am not very familiar with Java language and I have used data structure, but the bottom idea is the following: if current element is already in the set, it is a duplicate. Else add it to the set. This solution also has the advantage that avoids hardcoding the number of allowed characters (26). 

This last function is particularly useful to debug some persistence errors which are quite hidden. 5) Base service (optional) Since almost all your services use unit of work, it would make sense to spare unit of work factory and assignment, by having them in a .