Depends on what permissions are granted to the schema you're connecting to on the Oracle side. Have you applied latest patches to your Management Studio client? 

Another way to really speed up SSMS opening is right-click the shortcut for it, choose properties. Change the Target to this: "C:\Program Files\Microsoft SQL Server\100\Tools\Binn\VSShell\Common7\IDE\Ssms.exe" -nosplash The change is the addition of the -nosplash flag at the end. This will speed you up quite a bit opening. I learned this trick at SQL Saturday. 

If your office is expecting to remote into another office server on your own network, why would you want to go through the internet? If its on the same network you should just be able to use RDP regularly. If you're not on the network check with your sysadmins about a VPN connection. 

VMware released a Powershell toolkit you'll probably want to check out: $URL$ And here's a blog with Top 10 Powershell scripts VMware admins should be using: $URL$ 

For me I'd say that x64 bit support is huge as more resource intensive apps could benefit from x64 environment. Another benefit of coming up to speed is it will make your migration that much easier if you decide to jump up to the ESX-class virtualization solutions. 

I run production SQL Server environments under VMware ESX 4.0 Some things you have to be aware of is HOW virtualization technologies work. If this is just test environment then all servers don't need 4 GB RAM each. The web servers can probably get by fine on 512MB each, same with App and at least 1 GB for database. I'm part of a Virtual Chapter for PASS that specializes in these kinds of setups you should check it out. It's at $URL$ , no sign-up needed. We syndicate blogs from some of the top virtualization experts in the field today and we do free webcasts on various topics. Another great resource is Brent Ozar's posts on virtualization (he leads the Virtual Chapter). You can find those at $URL$ 

Does the application throw up any errors? Is there anything in the Application/System log that could point to a possible issue? Maybe the app has some sort of memory leak. Also is this x32 or x64 system? 

We use Lumension's (formerly Patchlink) Patchlink software for updates. $URL$ Works well, lots of reporting capabilities via Patchlink Enterprise Reporting Server, which takes advantage of SQL Reporting Services. Worked well for us thus far and with SQL backend lets me roll my own reporting solutions if needed. 

Depends on the solution you have in place for your enterprise. For instance we use CA's Arcserve Backup product which relies on agents on target machines. You install the proper agent on machines you want and throw them into a backup rotation and you're good to go! The agents not only pick up drives but Registry states so you can restore bits/pieces. As for storing data on your servers, you're going to have to otherwise your solution is for naught. If you keep backups on the machine you're backing up and the machine goes missing or damaged, what are you going to restore from? If you're truly backed into a corner here then use Windows native backup tools and partition your hard drives. If there's corruption in Windows then at least having backups on different partition provides some sort of protection. 

Like so many questions given to solution developers, it depends. There's nothing wrong with using Scheduled tasks and as long as whatever solution you're developing clearly states in the documentation what/how you do something you should be fine. There are advantages for running something as a service such as being able to script a solution for a non-admin to run a service if they don't know how to use the services.msc console. Or even being able to monitor said service via Powershell or a network monitoring program such as What's Up Gold. With Scheduled task you can run your program on a schedule you decide but you can also add arguments (which you can also do with services technically) but you can do so in an easy GUI format. Again, whatever you decide is easiest and most useful for your situation. 

In addition to the advice K Brian Kelley gave also look into partition alignment. If you're using Windows 2008 you shouldn't have to worry as partitions are automatically aligned for you but on Windows 2003 you'll need to do this manually. Read this whitepaper to understand the who/what/why you should do this. You can get up to 30-40% performance boost by just aligning your partitions. $URL$ 

Ummm, why would you want to restrict the network traffic? This type of setting I believe would have to be done at the switch level. If not what you can do is set your NIC to 10 Mbps half/full if you want to do that sort of thing on the server-side. 

I somewhat answered this in another answer recently but this is a good topic. One of the key issues between IT and "the Others" (sue me, I'm a Lost fan) is that in the Dharmaville we call IT, we know what we're doing. We're happy. We understand our parts (for most part) and know how to do it well (again, for most part). The problem comes in how IT is utilized. In the past IT was the hammer that drove the nails. We came out, provided dumb terminals and as long as the mainframe and network were up nobody really questioned anything. Nowadays IT NEEDS to be seen as BUSINESS PARTNER. Nothing gets done without IT involvement now and when people fail to realize that you can't plan to put in a massive product and not even know if 1) It really will help anything 2) If it even works with what we have and if it doesn't what do we need to do to get there. We need to evolve our thinking and update our policies and procedures to accept these new changes or we'll always be stuck in the same old rut. 

Ooh I just read this last night in SQL Server 2008 Internals book (thanks Paul Randal). If it runs out of space the snapshot gets deleted. What I mean is in SQL 2005+ the internal engine is actually creating a snapshot behind the scenes and running checkdb against that. You can't access this snapshot as its invisible to you but it still takes up space on the filesystem the files are on. If it doesn't have enough space to create this system snapshot it will throw an error and rollback that snapshot. What you can do is manually create a snapshot of the database on another volume that has enough space and run checkdb against that. Your results should still be valid as the snapshot is simply a collection of differences in page changes against the base data. I'm sure Paul could answer this more eloquently but this is the basic gist of it. Also yes, you can cancel a running checkdb query. 

Your risks are that staying with an older system that eventually they'll stop supporting it. As for benefits check VMware's site for 2.0 features and see if it applies to you: $URL$ New Features in VMware Server 2 

First off my condolences for using Arcserve (I'm stuck w/ it right now and hate it). We have different media pools for stuff like (2weekstaging, 2wkstag_daily, 2wkstaging_mthly, etc.). Our setup is that staging is a VTL before doing migration jobs to tape. The diff pools are needed for each job, not server. 

Sharepoint needs to be treated like a SQL database because it IS a SQL database so take all your regular SQL setup precautions in setting up shop. As for backups you should not only be backing up your databases regularly you need to back up your 12-hive which holds all of your SP information. Check out this thread for more info: $URL$ 

How long have those snapshots been in place? Typically you don't want a snapshot around longer than a few days otherwise you're liable to run into issues. Best thing I can recommend is either committing those snapshots (might take awhile if they're large/have been running for awhile. Virtual Center might time out but its still deleting in the ESX if its really large). Snapshots are just delta files of a particular VM so there's no way of applying system-wide changes across multiple ones. Update: Why snapshots can stop machines for long time: $URL$ VMware Admin guide (PDF): $URL$ Horror story of "the long snapshot" which should be quite painful for you guys if you decide to commit: $URL$ 

Here's a nice blog post: $URL$ White paper on disk alignment: $URL$ In short your OS should be on RAID 1, your data files on RAID 10 (preferably) and log files on RAID 1. SQL Performance article: $URL$ PDF on top 10 best performance tips: $URL$ Also remember to put your TEMPDB on a separate disk for performance reasons. I'm sure Paul Randal will come in here and blow your mind with why in a bit. MS says why for tempdb: $URL$ 

Do you have some sort of firewall between the data centers doing any sort of filtering? Have you done a tracert between the offices and seen where in the transaction the "hold ups" are happening? This might help you better figure out where your problem lies. 

Run sysprep on the system. This will reset the SID and should fix whatever machine account conflict the network is seeing. Was this machine cloned? 

I'm kind of confused but I'll take a crack at this. In terms of remoting into a server using RDP you can use the console connection so that you can run apps that need that console state. Click on Start-->Run and type in 'mstsc.exe /?' (without single quotes). This will bring up the help switches for whatever version of RDP you're currently running. You can use these switches to launch RDP using the console session. For instance for the version I'm currently running (Windows 7 RC) I would type 'mstsc.exe /v:exampleserver /admin' to connect to the console session for the server named exampleserver. Be aware that there are differences out there in RDP versions because that /admin switch used to be /console. If you want to be sure then connect to your target server and run that /? command and see what it expects for the console connection. 

MSDN on linked server security: $URL$ Configuring linked servers for delegation: $URL$ Similar problem to yours (i believe): $URL$ another solution on SQL Server Central: $URL$ 

Your answer lies in Powershell but I lack the programming knowledge in that language to give you an exact solution 

On Mac hardware the virtualization platform you'd probably want to go with is VMware's Fusion. Solid product and can't go wrong with VMware. You can also look at Parallels. Both of these products are aimed at desktop virtualization though (i.e. running vms locally for testing). You looking to run a prod Linux server from this solution? 

Communication, communication, communication. Every problem between a sysadmin and a dev can pretty much always be tracked back to a lack of communication. If prior to a project the sysadmins (or a representative thereof) and the devs got together and had a nice framework discussion, SOOOOOOOOOO many problems could be avoided down the line. I can't tell you how many things get fouled up because you develop everyone on one box in development only to watch it go down in flames in prod because the app then gets separated in to App server + DB server + interface server, etc. Kudos for bringing this topic up. 

Did you have any pre-prod releases of software (i.e. .NET framework, SQL, Visual Studio) on your system prior to VS? I know that Visual Studio had a bug that couldn't connect because of CTP/beta products on system. Another thing that drives me nuts is installing stuff in proper order in regards to VS products and .NET framework. 

Yes, you CAN but like so many things doesn't mean you should. I've seen a virtualized ESX server running a virtual machine that has another virtual ESX server within it. Granted it was a test just to see if it could be done (and it can) I really wouldn't recommend it. 

Honestly if you're going to get into advanced tweaking like that you're better off scripting a solution and then scheduling it via Agent. Maint Plans, while nice for really simple tasks, really has its limitations. 

A fun way to do this across many machines using the power of SQL 2008 is by using the new policy based management. Create a policy that sets the max memory to a number of your choosing. Apply your policy against the target server and your setting will change. If you don't have a SQL 2008 instance in-house yet you can download the 180-day trial of Enterprise Edition and try it out. Try SQL 2008: $URL$ Policy Based Management team blog (great resource): $URL$ Blog regarding PBM against 2000/2005 servers: $URL$ 

If you're running SQL 2005 or higher there is a default trace already running that gives you a certain level of auditing. Read about it more here: $URL$ You can also create your own server-side trace to audit what you need. I blogged how to do it here: $URL$ You can also watch a video on how to use the Profiler tool to see what's going on: $URL$ 

For Windows XP deployments you can get a TON of tweaks/suggestions here: $URL$ Be aware, however, that not all tweaks are necessarily "good". That site, thankfully, has had editors follow up with warnings on some of those. 

I know this is a bit of a pain but have you tried a 3rd party file copy utility? Windows tends to be kind of dumb/slow about file copies sometimes. Lifehacker did a top 5 list of these utilities, try one of them out and see if you still have the same issue. $URL$ Also, like towo said, check your virtual memory settings. Best practice is that your pagefile should be x1.5 your memory (i.e. 1 GB mem = 1024 MB; 1024*1.5 = 1536 MB page file)