This "naturalist dualism" is Chalmer's explanation for experience. As explained above, he believes in the physical nature of the world and experience itself. Thus, he is certainly not conveying some form of idealism, nor a "spiritual or mystical" dualism. His version of dualism is quite physicalist, perhaps unlike other more familiar versions. Since he wants a physicalist explanation, one maybe a little empirical unlike most dualist theories, he seeks to attribute all phenomena - in this case, that of experience - to the physical. This answers your question: 

I imagine that such a development will split the world of ethics in two, each side with vastly different ideas: On one side, people will claim that such simulated minds, by virtue of their verisimilitude to human minds, have civil rights. Physicalism, especially the more complete kind (everything is physical, i.e. a Materialist view) is likely to attract many to this view. Physicalists will see the simulated minds as equivalent to human minds; since they view all phenomena to be physical, they will think of a replication of the human mind with advanced AI to be equivalent to the human mind itself, possessing the same neurological connections and storage in the form of transistors and memory. On the other side, people will claim that despite the verisimilitude of these simulated minds to human minds, they do not and should not have any ethical rights. This is because they are just physical objects, and lack the consciousness and sentience of human beings. Dualists in particular will be attracted to this view, because they do not view the human consciousness as replicable by purely physical means. Therefore, regardless of how powerful the AI of computers are, they simply will not have the minds of people, and so one cannot attribute any particular rights to them. Ultimately, it seems to me that the ethics of computers and advanced AI is highly dependent on one's ontological views; those inclined toward metaphysics would be more likely to deny rights to computers, while the pure physicalists would be more likely to attribute rights to computers. 

If, as Nietzsche says, "God is dead and we have killed him," then these remnants of our worship to God will be all that remains once we have fully realized this ultimate murder. Among people God will be but a distant memory of ages past, if even that; their strengthening life-instinct and growth toward the overman (i.e. that gradual progression of humans toward a stronger race which Nietzsche advocates) will mean that there is simply no use for the idea of God - hence, his death. 

This is an important part of Hobbes' principles (you'd have to read his first three chapters to really get an complete understanding), and in short, it demonstrates how Hobbes considers anything in the pursuit of peace (as opposed to "warre") as moral, and that these pursuits are listed in his "naturall lawes". Now, the second of these natural laws (derived from the first, which is simply that one must pursue peace or prepare themselves for war if peace is not possible) represents your very question of sacrificing happiness for moral duty: 

Where the string is not inert like in most languages, but dynamic and self-processing (sort of like a quine), so that it can self-simulate without needing some external compiler and processor. The way I've presented it, the instructions for how to process the string would be in the "constant rules." 

Seriously. Just look at stoicfury's answer and tell me there's no philosophy (read: critical thinking and rational analysis) in it. It is futile to argue that philosophy has no practical use, because to do so you'd have to use philosophy (and in the process contradict yourself, proving that you just used philosophy for a practical purpose). So, the next time someone says that philosophy (or anything) is useless, ask them this: How do you know? You'll have them using philosophy in an instant. 

Well, I dug up my copy of Descartes' Meditations, and I'll try to provide a supplementary (but not substitute) answer in support of the others here. For reference, mine is translated by Donald Cress. In "Meditation One" of his Meditations (there are six, all in one book), Descartes begins with what is called radical doubt. He notes that, having seen how questionable some of his views have been: 

Truth. Now, there is a whole lot of extensive discussion on the nature of truth, but these are mostly ontological. People generally agree on what makes something true (although the conflict between Rationalism and Empiricism is pretty important) and regardless, I don't think it makes a big difference to the question at hand. Let it suffice that by definition (at least the one being used presently), knowledge simply must be true. Given this, I want to make the first point of my answer: we are not always aware of what is and is not true, regardless of our perceptions and beliefs. False beliefs aside, we may simply not realize that something is true because we have never given it consideration; note, however, that this does not keep it from becoming knowledge. It does not matter whether we know something is true or not, as long as it is true and the other two criteria are satisfied. Belief. The SEP defines belief as "the attitude we have, roughly, whenever we take something to be the case or regard it as true." Then it makes a very important point regarding your question: 

This is an excerpt from the end of Section 9 of the first essay, "Good and Evil," " Good and Bad," which can be found (though by a different translator) here. Now, the passage seems to me to suggest that free spirits, and thus Nietzsche, are democrats (all of you Nietzsche scholars are probably shaking your heads in pity: "Oh dear, he has taken Nietzsche out of context again!"). I see several possible explanations: 

The book continues to describe the concept of Atman, and how it is "the infinite soul that suffuses the universe, at once everywhere and nowhere at the same time. It is infinity, and it is nothing." 

Since you said a standalone deduction is fine, I'll offer what I think might work having extrapolated the sort of reasoning used in the second one. The way "a brown horse and a dark ox" might be "three together" is this: 

Try Computational Models of Ethical Reasoning: Challenges, Initial Steps, and Future Directions by Bruce McLaren. It does not include formal logic like the Lokhorst paper, but it specifically discusses two programs, Truth Teller and SIROCCO that implement different methods of ethical analysis. Although neither are strictly consequentialist, both do reason on ethical situations; Truth Teller can draw comparisons and contrasts when presented with two ethical dilemmas (perhaps drawing from a master dilemma to make a decision?), and SIROCCO can determine relevant ethical issues and cases when given a single problem, thereby finding the specific ethical problem to be dealt with. Some relevant flowcharts and such are included, and the text is very interesting as a whole.