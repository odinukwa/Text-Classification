It is an interesting question. Actually your guess about dependence on measurement parameter $p$ is correct. The minimal Wasserstein distance between two copulas (In your case the collection of all probability distributions with same uniform marginals is a copula, which also includes the 2-d uniform distribution. Let us denote the 2-d uniform distribution by $\pi_0$ in following discussion.) actually depends on the measurement parameter $p$ of the Wasserstein distance. See Prop 1.1 of Alfonsi&Jourdain. So it is not hard to see that the maximal Wasserstein distance will also depend on $p$ using the "coarest" Fréchet–Hoeffding copula bounds on each dimension of marginals and hence the calculation of Wasserstein distance. A concrete example where $p=2$ can be found in [Cuesta-Albertos et.al]. Now come to the other part of your question that what is the maximal Wasserstein distance to $\pi_0$. Then it is equivalent to find geodesics on the submanifold determined by copula $C_{unif}$ on the probability space metricized by Wasserstein distance. This problem is generally unsolved, if you do not restrict the family of probability distributions under consideration, to my best knowledge. One noticeable attempt is [Ambrosio et.al] whose work is also on $p=2$. If you metricized this copula, then I think you only need to find the complementary geodesic in a circular neighborhood of $\pi_0$(geodesics in a circular neighborhood of $pi_0$ correspond to the distributions possessing the minimal Wasserstein ($L^2$) distances to $\pi_0$ ) Again for general case $p\neq 2$ I am also interested in knowing more. One more comment is that Wasserstein distance is a measure of dissimilarity, and thus we usually talk about its minimization instead of maximization. OP seems asking a bound on Wasserstein distance for a general family. As you said in the comment, if the motivation is only a convex optimization problem, I was wondering if it could be re-phrase into a minimization problem by some sort of duality. Reference [Alfonsi&Jourdain]Alfonsi, Aurélien, and Benjamin Jourdain. "A remark on the optimal transport between two probability measures sharing the same copula." Statistics & Probability Letters 84 (2014): 131-134. [Cuesta-Albertos et.al]Cuesta-Albertos, Juan A., Carlos Matrán Bea, and Jesús M. Rodríguez Rodríguez. "Shape of a distribution through the L2-Wasserstein distance." Distributions With Given Marginals and Statistical Modelling. Springer Netherlands, 2002. 51-61. [Ambrosio et.al]Ambrosio, Luigi, Nicola Gigli, and Giuseppe Savaré. "Gradient flows with metric and differentiable structures, and applications to the Wasserstein space." Atti della Accademia Nazionale dei Lincei. Classe di Scienze Fisiche, Matematiche e Naturali. Rendiconti Lincei. Matematica e Applicazioni 15.3-4 (2004): 327-343. 

Black pixels are points where the software cannot detect periodicity. The correspondence between colors and numbers is as follows, where 'Unk' means 'Unknown': 

A first simple idea is the following: given a permutation $a$, count the number of $i$ such that $a(i+1) \neq a(i) +1$, where $0 \leq i \leq n$ and index addition is performed modulo $n$. A natural variation on this idea would sum $|a(i+1) - (a(i)+1)|$. I haven't thought about either of these too carefully yet. Do they appear in the literature somewhere? Some nontrivial internet searching hasn't turned anything up. 

Category theory: There is an isomorphism between a vector space and its double-dual which does not depend on choice of basis. It is natural in the sense that every vector space has such an isomorphism, and these isomorphisms commute with every linear transformation. This should be contrasted between the isomorphisms between a finite-dimensional vector space and its dual. These depend on a choice of basis and are not natural in this sense. This example constitutes the first two paragraphs of the first paper in category theory! Eilenberg-Mac Lane: General theory of natural equivalences. In Categories for the working mathematician, Mac Lane writes that the purpose of discussing categories is to discuss functors, and that the purpose of discussing functors is to discuss natural transformations. 

Therefore the measure of spikiness is usually based on estimators of a shape parameter of an assumed data generating distribution. For example, If you assume the data is generated from a beta distribution, then the spikiness can be measured by an estimator of its shape parameter. This is the classic thinking when a parameterized model is assumed for the underlying probability distribution that generates the model. Following this idea, a classic test of comparing how similar two probability distributions are is the Kolmogorov-Smirnov test. It induces a nonparametric measure of similarity, and therefore could be used for exploring spikiness. In this direction of characterizing spikiness. In other words, spikiness can be measured by an appropriate choice of norm on the space of probability distributions supported on $[0,1]$. To be honest I think this is more like a reverse Schwarz inequality rather than a Jesn inequality since I do not see how convexity comes into play. If that is the case, then such a sufficient condition reduces to a choice of $S$ such that majorant conditions hold. For any isotonic functional $A$, including most norms, $0\leq A(f^{2})A(g^{2})-A^{2}(fg)\leq\frac{1}{4}(M-m)^{2}A^{2}(g^{2})$ where $m\cdot g\leq f\leq M\cdot g$ In this case we can take $f=g$ and see if we can related the majorant coefficients $M,m$ with the $\lambda(S)$, which I believe is a common pratice in deriving a bound since the above inequality provides a sharp bound. [1]Gray, William Charles. Variable norm deconvolution. No. 19. Ph. D. thesis: Stanford University, 1979. [2]Dragomir, Sever S. "Reverses of Schwarz inequality in inner product spaces with applications." Mathematische Nachrichten 288.7 (2015): 730-742. 

In particular, one can see the behavior along the positive real axis matches the description above. (Although there are no axes in this picture, I have verified separately that the transition point in the picture is correct.) Unfortunately, I have no idea how to explain the rest of the picture! Although I have been careful writing the software, I can't say with certainty that the picture is correct anywhere other than the positive real axis. This question is in danger of being too general, so here is one specific question to answer: Is the cardoid-shaped region colored 1 correct? I would, of course, also be happy to hear any other verifications of features in this picture, or other behavior of $P(z)$ not depicted. 

Are there standard or known weights/metrics on cyclic orders? Cyclic orderings are different ways of listing elements from a finite set, where you call two lists the same if they differ only by a rotation. For example, the ways that 4 people can sit at a circular table, where you ignore rotation of the table. So the following 4 rankings of a 4-item set should be considered the same: 

To be more precise and in response to @RHahn comment below, I do not think "conformal" is an arbitrary choice of word, since Vovk mentioned that 

There is few posts on MO that asked about reference on this topic, and I found some difficulty during the process of getting myself into the subject so here is the question. I really want to hear from someone who is familiar with this wonderful field of random matrices. 1 I would like to know a self-study material on the subject of random matrix theory, which should be more advanced than [Tao]. I did read into [Tao]'s "Related article" part but found it focus on dynamics instead of a general interest like the content of [Mehta] covered. 2 About the classic in the field [Mehta], I am confused about its editions since some probabilist said the 2nd edition is better than the third one while 3rd edition is almost 200 pages of more than the 2nd edition. Since I have not started to read it yet, I would like to know which edition of [Mehta] is better to start (as a newcomer to the subject) with, and what is the difference between these two editions(besides those newly added references Mehta mentioned in the 3rd edition's preface, which is not very informative to me...)? 3 Maybe this should be another post, but how much (statistical) mechanics should I know if I want to read [Deift&Gioev] in order to understand it better? Since my basic interest is in the mathematical side, is there any good-and-short introductory paper providing an overview about the subject of statistical mechanics? 4 Lastly, I would really like to know if there is some must-read or introductory paper on the subject of random matrices. (Besides [Tao].) And a roadmap of learning this subject, if possible, will be greatly appreciated. Reference [Mehta]Mehta, Madan Lal. Random matrices. Vol. 142. Academic press, 2004. [Deift&Gioev]Deift, Percy, and Dimitri Gioev. Random matrix theory: invariant ensembles and universality. Vol. 18. American Mathematical Soc., 2009. [Tao]Tao, Terence. Topics in random matrix theory. Vol. 132. Providence, RI: American Mathematical Society, 2012. $URL$ 

Notes on the software The software computes 500 iterates, and then looks at the next 30 iterates. It returns the minimum $n$ such that there are two successive subsequences of length $n$ whose corresponding terms are within $\varepsilon = .001$. If no such $n$ is found, it computes 500 more iterates and tries again. This is repeated 6 times. If no such $n$ is found, the pixel is colored black. Decreasing $\varepsilon$ by a factor of $10^4$ or so takes longer but does not result in a substantially different picture. 

Motivation Two of my colleagues were discussing the behavior of cos along the positive real axis on our department mailing list. I was curious about the complex behavior, but this is outside my field, so started making pictures like the ones shown here. I've been thinking about these off and on for a little over a year, but not really made any progress or had anyone give me a useful reference. So I wanted to see what the wider MO community has to say. If you want some higher-resolution pictures for cos, see this G+ post: $URL$ 

If you are concerned with the order statistics, you usually want to restrict yourself to a narrower class of distributions, say the classic paper [2]. For a general distribution family, it is almost impossible to obtain a tail-bound on the order statistics due to the concentration of measures phenomenon. Another keyword you may want to look into is "U-statistics" because the (full) order statistic is an example of U-statistics, the following quote from [1] is the best description of the power of U-statistics 

Negative curvature is favorable due to various comparison theorems in Riemanian geometry.(See a different opinion from Kloeckner's comment below)a strictly negative curvature can be regarded as convexity of the family of measures under concern making the minimizer of KL divergence unique. The reflection of this point in information geometry is the natural relation between KL divergence and Fisher-Rao metric, which correspondence Wasserstein distance does not have.[1] Meanwhile the Wasserstein metric has a natural connection with optimal transportation theory which Fisher-Rao metric may not provide. 

Now, maybe there's some other way of modeling connective spectra with strictly symmetric monoidal but topologically enriched categories. But I think our work proves it can't be done in a way that generalizes the ordinary classifying space functor when the enrichment is discrete. 

This last one, for the sine function, is even more bewildering to me. There is something that looks very much like a Mandelbrot set there. Why? 

Do strictly symmetric monoidal topologically-enriched categories model all connective spectra? If your modeling functor is some reasonable variant of the ordinary classifying space functor, I think the answer must be No. What I know for sure about this question is written (with Angélica Osorno) in this paper: Modeling stable one-types. In that paper we study how to model the Postnikov data of spectra with just two nonzero homotopy groups (in dimension 0 and 1). The Postnikov data in such a low-dimensional case consists only of the two (abelian) homotopy groups $\pi_0$ and $\pi_1$, together with a Postnikov invariant. Therefore we restrict not only to symmetric monoidal categories, but to those symmetric monoidal categories where all morphisms are invertible and all objects are invertible up to isomorphism. (The standard term for these is "Picard categories", but a more descriptive name would be "grouplike symmetric monoidal groupoids".) The sloganized summary of the paper is that the symmetry of the Picard category is the data which corresponds to the Postnikov invariant of the stable 1-type. (There's a neat connection with the theory of quadratic maps, and some calculations of Eilenberg and Mac Lane from the 1950's, which partially explain why you might expect this.) I'll skip the precise details here -- you can try the paper, or just ask me later. For a specific example, we write down a symmetric monoidal category which models the Postnikov truncation of the zeroth space of the sphere spectrum. It has a strictly associative and unital monoidal structure, but the symmetry is nontrivial.