How large your corpus should be depends on what exactly you want to use it for, and what alternatives are available. If you want to know the 2,000 most frequent words of a language, a 1 M. word corpus will be sufficient to conclude that these words should be taught earlier than the words with frequency ranks 10,000 to 12,000. Of course, if a much larger corpus is available (say, 10 M. words), you will want to use this one. But in 1967, the Brown Corpus of American English, the first modern computer-based corpus, just became available, with a size of 1 M. words. Nowadays, much larger corpora are available for many languages and dialects. But for a smaller language, if a 1 M. word corpus is available, it will allow you to answer many questions (regarding frequent lexis etc.) that you couldn't hope to answer without a corpus of this size. 

I will be extremely grateful for a fully-fledged answer, but I will also appreciate any comments, references, examples anyone can offer. And if someone can even come up with appropriate Czech equivalents, it will be just perfect! On the other hand, I won't object to migrating this question to another, more appropriate forum, if necessary. 

EDIT: Having found out that my answer has been voted down by three people, I have decided to revisit the topic and explain in a bit more detail my view regarding some cases of man-formations being suffixes rather than compound members. In order to do so, I have summarized my views at the very end of my answer and provided two corroborating quotations from references I have recently discovered on the Internet. 

In addition, the strictly binary system also fails to account for the reality of [+low] generally decreasing the (ease of) articulatory "implementability" of either [+round] or [+front] due to physiological constraints, again, as if [+low] were somehow opposed to [+front] and/or [+round], at least to some extent. The same is true of the derived, nasal subsystems in which much stronger nasalization is required in the open vowels for their nasality to be perceived than in the closed ones. Hence my question in a somewhat different wording: 

Language standardisation has variously been described, for example by Einar Haugen, as a process involving the selection, codification, acceptance, and elaboration of a linguistic norm. I'm concerned here with the selection of a norm. Often this consists not of selecting a dialect that is already present in its entirety, but a process called koinéisation takes place - the levelling of differences between dialects. Apart from regional varieties (dialects), social varieties (sociolects) also play a role. I think I have heard/read repeatedly that linguistic structures/words etc. used by educated speakers are more likely to become part of the emerging standard than linguistic structures used by less educated speakers. This is, I think, because educated speakers play a role as gatekeepers due to their social, economic and political power. In consequence, the varieties used by uneducated speakers are often looked down upon. However, in the literature on language standardisation (such as Language Standardization and Language Change I could not find any reference to the importance of educated speakers in language standardisation. Can anybody provide academic references for this? (of course I would also be happy to consider references denying the role of educated speakers in language standardisation) 

In Czech orthography, for instance, we keep both <y> and <i>, and both <ý> and <í>, although their pronunciations have merged to [ɪ], and [iː], respectively, in most varieties of the language. While it helps the reader to distinguish <bit> "beaten" from <byt> (both pronounced [bɪt]) "flat/apartment", and <bít> "to beat" from <být> (both pronounced [biːt]) "to be", it has a major impact on school children who have to memorize close sets of words preserving the <y>'s and <ý>'s. Another example from Czech is the use of graphemes for voiced obstruents (such as [d], [ɡ], [b], [z]) in devoicing environments or their voiceless counterparts in voicing environments to maintain the underlying phonological information to some extent. This, unlike the <y/ý>/<i/í> distinction, can actually make things easier for learners, who usually retrieve the underlying information from the various inflected forms anyway, hence they know, for example, they have to write <plod> [plɔt] "a fruit", because the genitiv singular is pronounced [plɔdu], and they know they have to write <plot> "a fence", because the genitive singular is pronounced [plɔtu] etc. So the answer is not simple at all and depends largely on your preferences as a reader or learner, as well as various properties of the language in question plus its orthographical system. Notice that one of the main obstacles Czech learners of English have to face is the high level of spelling unpredictability (spelling-to-pronunciation mapping and meaning-to-spelling choices) and I also remember reading an article mentioning the very same kind of problems pre-to-early-school native speakers of English have to face (which is why it seems to take them much longer to acquire basic reading and writing skills than it takes children trying to acquire a more predictable orthographical system, such as the Czech one). On the other hand, of course, learning the English spelling system trains learners' memory, which could be considered a pro rather than a con. For what it's worth, being a non-native speaker (and forever a learner) of English, I would welcome a radical reform leading to a simplification and regularization of the English spelling system. :-) 

There is a broad distinction between open-class and closed-class words. Open-class are those that easily admit new members, such as verbs, nouns and adjectives. They also consist of a large number of individual words - It's a daunting task to count all the English nouns listed in any given dictionary. Closed-class are those that do not readily admit new members, such as personal pronouns (I, you), interrogative pronouns (who, what), quantifiers (all, many, one) , negative particles (not) and determiners (this, that). They also consist of a rather small number of individual words - It's easy to count all the personal pronouns of the English language. Most individual closed-class words also occur much more frequently in oral and written language than most individual open-class words. Now, frequency of occurrence happens to be one of the main factors influencing likelihood of historical change in linguistics (see, for example, Diessel (2007). Basically, the mental representation of a word is reinforced every time you hear or use it, and children are less likely to come up with innovations in language acquisition, if they hear a certain word very often. It is not true, as @Darkgamma stated, that 

It is well known that consonant lenition or weakening tends to be far more common cross-linguistically than the opposite process called fortition or strengthening. Now, some languages have been considered as having undergone the historical change of affricates to plosives. Here's a list of examples I've been able to collect so far: 

Intuitively, I feel the mainstream view has a potential to produce less ambiguous results, but how can we quantify that? Once again, I should stress that this would only be about a potential ambiguity, which could only be confirmed or refuted by psycholinguistic experiments, as correctly pointed out by commentators. Similarly, we can generalize the question and set the software tool to find out, whether reading a text T writing by means of writing system W1 leads to greater nubmers of possible readings than writing system W2, whether also representing the same language, or a different one completely. Some Follow-up Remarks: What are the most significant caveats never to be neglected? Some questions to be asked and parameters my tool should obviously take into account and probably include: 

Dialectology is the study of geographical varieties of a language. The study of (for example) older dialects of English (such as the dialect spoken in the Northeast of England around Newcastle) and more recent dialects (such as Indian or Australian English) can contribute a lot to other areas of linguistics. For example, the authors of "The Dialect Laboratory. Dialects as a testing ground for theories of language change" argue that dialectology can contribute in many ways to the study of language change. Q: Does dialectology also have something to contribute psycho- or neurolinguistics (the study of the cognitive and neural mechanisms underpinning the ability to use language)? Or the other way around? Are there any studies relying on this connection? 

English-speaking children frequently do not acquire /θ/ and /ð/ until age 5 or later. Q: Are there marked or "hard" phonemes that are acquired even later in First Language Acquisition? Q: Also, are there any phonemes that (are so marked that they) are not acquired at all by a substantial part of the population (say more than 5 %)?