To answer the specific question, I believe the largest hf in the world is Bridgewater (assets under management of around 120bn USD). Assets of around 500m USD would be considered average and north of 1bn usd large. Bridgewater is an outlier. I do not know if one larger has ever existed but I doubt it. As to what effects they have on the economy well, funds can serve as catalysts for economic events (e.g. Soros' fund and others catalysing the UK exit from the ERM). They serve as vehicles for pooling and allocating capital and so act as intermediaries between those who wish to lend (investors in the hedge fund) and those who wish to borrow (firms issuing bonds etc. which the hf buys). This function only applies when the hedge fund is making a primary investment though - when it is buying something in the secondary market rather than a first issuance funds do not have this role. They largely determine things like commodity prices, exchange rates through the bulk of money they control together, although no hedge fund is large enough to control these markets directly. 

A common calibration for depreciation rates within RBC models is to assume 10% depreciation rate (based on NIPA stats, for instance). This implies a half-life of about 6.5 years. But this estimate seems a little low for advanced economies where capital is often in the form of computerized technology etc, which would seem to depreciate at a much faster rate (say 25% pa, implying a half-life of more like 2.5 yrs). Further, with technological advance you have the problem of obsolescence - the useful life of a capital good may end long before it depreciates away fully using the 10% pa rate. There is an element of unpredictability around obsolescence as well. How can this be accounted for within RBC and DSGE models? Would obsolescence pose a problem for calibrating a model assuming delta is approx. 10%? Thanks in advance, R. 

If you want to forecast it is common practice to split your sample up into two parts - the "estimation sample" and the "forecast sample". The estimation sample is used to, you guessed it, estimate your model, which you then use to forecast the data for which you already have true values contained in your forecast sample. You then compare your forecast predictions to known data and to those of other forecasts. You can do this using r2 or adjusted r2 over the forecast sample. We also commonly use measures like means squared error, mean absolute percentage error, Theil's U, etc. etc. 

Is CPI accurate relative to... what? If you are asking whether CPI is accurate as a measure of the true cost of living, the answer is no. One reason for this is that the CPI is computed using a weighted Laspeyres index of prices of different goods and services, weighted by their share in consumption. Prices are continually updated but weights are not, and hence the headline CPI index neglects substitution effects. Let me present a highly simplified example; two goods in the economy, apples and oranges, both consumed equally (weights 0.5 / 0.5). At the start, the price index computed using CPI methodology will be 100. Now the price of apples rises 10% and the price of oranges stays the same. As a result, people substitute out of apples and into oranges - so apples' share of consumption falls from 50% to 25%. The consumer price index would now stand at 105, implying a 5% increase in the cost of living. However, the true increase in the cost of living is 2.5% - CPI has overstated inflation in the cost of living through failing to take account of substitution. Most countries reset their CPI weights yearly. Some, e.g. Japan I believe, reset once every decade only. Obviously the less frequently you reset your weights, the worse CPI will be as an accurate measure of the cost of living. 

The field of performance marketing makes ample use of attachment bias. For example, skiers often purchase race-level ski boots and skis which are too stiff relative to their ability, so the product is actually detrimental to performance. In this case, self-attachment bias causes buyers to overestimate their own ability. The ski manufacturers know this and market and price the stiffness of this equipment at a premium even though it is not objectively helpful for the vast majority of consumers. In pharmaceuticals, attachment bias to familiar medications like Tylenol cause consumers to pay premiums for this medicine even while knowing that the generics next to it on the shelves contain exactly the same active ingredients and are often made by the same manufacturers. Here, attachment bias to a familiar product causes allows manufacturers to pay a premium, and the manufacturers tune marketing messages to amplify the attachment bias ("Tylenol, what matters most", "Advil, the original round tablet). 

During the global financial crisis of 2008-2009, both the US and UK undertook quantitative easing (QE) in conjunction with a policy to fortify banks against risk by increasing reserve requirements. So there are recent cases which illustrate what happens. A rise in reserve requirements constrains a bank's ability to lend. So it seems to counteract the idea of QE. So why did both the US and UK implement these two seemingly antithetical policies? Because the two policies also accomplish other objectives. 

India still has a low-cost workforce, so they do export items where cost is very important (e.g. clothing, sneakers). More importantly, India exports services (call centers, software offshoring) because it's much easier to lay down fiber optic cable than to build a railroad so certain cities (Hyderabad, Mumbai, Bangalore) have developed strong export services industries which do not need to depend on a lot of outside physical infrastructure to create viable exports. 

An increase in capital requirements for banks was thought to be necessary to restore investor confidence in a badly shaken credit system (raising reserves was not done to counteract inflation). Investors did not have confidence in the quality of assets on bank balance sheets, so requiring banks to retain cash deposits was one way of ensuring that banks had (a) a clear base of assets that were not obfuscated (e.g. subprime); and (b) limitations on how much risk (via lending) they could undertake. So investors could feel safer about their deposits and the fundamental strength of the banking system. Quantitative easing was aimed at injecting liquidity into an economy paralyzed by loss of confidence and liquidity, resulting in low spending and investment levels. In order to offset the negative effects of raising capital reserves, the QE programs needed to be very large, which is why vast amounts of money were pumped into circulation in both countries. 

The second part of your question is around follow-on economic effects. Using the dynamics above you can infer the likely effects. Raising capital requirements had the effect of exactly that. It also had the effect of requiring larger volume of QE to counteract the drag on lending (in effect, money velocity or money multipler) cause by the higher reserve requirements. Had QE not been sufficient to overcome the higher capital reserves, you would have seen bank balance sheets swell while lending remained low....which is exactly what happened in the early to mid stages of QE while banks shored up their balance sheets before timidly starting to lend at risk again. 

I don't think cash could be described as a security... one of the characteristics of securities is that they have imperfect (if very high) liquidity and provide a return (be it fixed or variable). Cash is the definition of liquid and inherently provides no return - you could earn interest on cash by depositing it in a bank but then you are creating a debt obligation in effect - the cash inherently, as in cash in a physical safe, generates zero return nominal by definition. You could think of cash as a debt security where a debt is theoretically placed on the issuer. But: in practice the debt is impossible to pay. You cannot bring a bill into the fed and demand they honour it. So I suppose it would be a debt security in the theoretical sense but it lacks almost all properties of debt securities: cannot be repaid in practice, never intended to be repaid, perfectly liquid etc, and it has a value that cannot be expressed in terms of anything but itself. 

I'm not sure I fully understand what you mean by computing it endogenously? The nominal interest rate would be endogenous in the NK framework because the output gap and inflation are endogenous. There'd be feedback between nominal interest rates and inflation, which both feed into each other for example. So in that sense I'd consider the approximation of interest rate policy using a Taylor rule as entailing that interest rate policy WAS endogenous wrt. the output gap and inflation. As for why we'd use the Taylor rule as opposed to some more complex but accurate approximation for interest rate policy... well I can only suppose that the Taylor rule is a sufficiently good approximation such that the marginal benefit of adding more complexity / accuracy is minimal and perhaps less than the computational cost of doing so. There comes a point where you start to prioritize parsimony more and more. Perhaps this is the motivation. 

Well, adjusted R2 has more merit than R2. R2 will always rise (or at least stay the same) as you add more variables (even if the variables are not statistically significant). Thus in theory you could achieve a very high R2 by just bunging a load of nonsense variables into your regression. Adjusted R2 compensates for this by adjusting the R2 by a penalization factor that increases as the number of variables rise - hence adding a new variable will always raise r2 but will raise adjusted r2 only based on its explanatory power. Information criteria such as the Bayesian information criterion (also called Schwarz criterion) or Akike information criterion can be used to choose between competing models. Intuitively, they measure explanatory power but penalize for "bigger" models which are more prone to overfitting and other problems. The BIC penalizes additional parameters more heavilly than the AIC, for example. You would prefer the model which minimizes the information criterion score. Note that, unlike R2, the values of information criteria are not inherently very meaningful - you cannot say "this is a good model because it has a BIC of -50", but you can use them to choose between. What matters more than either P values or measures of goodness of fit is that the model is theoretically sensible and that the Gauss-Markov assumptions hold. This is what makes a "good" model - ability to explain a high proportion of the variance is the icing on the cake, nothing more. If I regress rainfall in the UK on US GDP for instance, I will get a P-value of close to zero and an R2 of above 0.95 - yet obviously there is no genuine economic relationship here. So a sensible model with solid theoretical foundations which satisfies the OLS assumptions is a good model even if its explanatory power is limited. Conversely a model with high r2 / low p values which doesn't satisfy econometric assumptions or lacks theoretical credibility can never be a "good" model.