is mapped by default to the MIME type , which is why the browser tries to download it. To fix this, override the MIME type mapping within your block: 

Please check the environment variable is defined and is equal to . If it is not, then define it as such and try again. 

You can't use switch port security on the Cisco since all the VMs will be sharing a physical switch port. And you can't use Linux because the traffic is being bridged, not routed, through the hypervisor machine. But you can emulate switch port security on the hypervisor with Linux , which is a lesser-known layer 2/3 firewall on the Linux bridge. A quick and dirty example (and likely incomplete; I don't generally bother with this): 

On your upstream nginx, use the RealIpModule to get the real IP out of the header that you are sending from your downstream nginx. For example: 

makes absolutely no sense inside a container. The point of is to unmap unused storage on the backing store, whether that's a local SSD or thin provisioned SAN storage mounted via iSCSI, FibreChannel, or whatever. Such a process needs to run on the host, rather than inside a container. The specific errors you see are because attempts to call the FITRIM ioctl on each mount point, and mount points inside a container do not correspond to the actual block devices the host is using. This is generally true even if the container is privileged. Why Ubuntu puts in a container image is a complete mystery. If you're stuck with Ubuntu containers, I would suggest disabling that cron job. 

Monit is quite strange in that it expects the private key and TLS certificate chain to be concatenated into a single file specified by , so you can't use certificates retrieved with certbot without some further processing. You will need to set up a deploy hook in certbot in order to concatenate the certificates into a single file and set permissions on that file. An example script might look like: 

Note that this doesn't install input methods or change the keyboard layout, but those don't really apply to a container. 

Try the other method of configuring a proxy server for Subscription Manager. This will also make the configuration persistent so that you won't have to specify it every time. 

I just look for the AMI ID (it's in your list of instances) and Google it. It always returns a result in the Amazon marketplace. 

You can add a period to the regex, if it's meant to be valid in a user name. But the best approach is to handle these within your application using the front controller pattern, like many other popular web applications do. 

Only a few hundred megabytes, and your disk will be full again. You said you expected to have much more disk space than this shows, so I would recommend you contact Linode to find out what's going on. 

Zabbix has no direct analog for this page, and I for one am glad. That Nagios page really doesn't give me a good sense of priority, precisely because the alerts are grouped by host. So it's much less useful than it could be. The best you can really do (and probably should have already done) is to define IT Services. This will give you a more high-level, priority-based view into your infrastructure, as well as filtering out some noise for you. 

Why do you want to? There is absolutely no need for what you're trying to do. The reason that appears in the is that on Red Hat, PHP and its modules are generally built separately; PHP actually gets built three times (or maybe it's four) during the RPM build process to account for each SAPI. Once the resulting binaries are installed on your system, though, there is no functional difference. 

The log entries you posted indicate the most generic possible failure, . This says absolutely nothing about why the message was rejected. It could be because the mail server isn't functioning correctly, or because it just doesn't want to talk to you, or any number of reasons. The only real way to find out what's going on is to contact the postmaster at the remote domain. 

e2fsprogs as shipped with CentOS 7 is slightly too old to understand the ext4 filesystem feature metadata_csum with which that disk image was built. Userland support appeared in 1.43 (as the way outdated wiki suggested it might). The wiki also states that old tools which don't understand the feature aren't safe to use with it. Thus, you were advised to: "Get a newer version of e2fsck!" In my ideal world Red Hat would backport this bit into e2fsprogs, or just rebase it, but I wouldn't count on that. Since you're building newer operating system images, you should consider using a more modern operating system as the workstation. I use Fedora (currently 27, occasionally betas) for similar purposes. 

A better practice would be to use the pwauth plugin, which lets you run jenkins as a non-root user, and only pwauth itself needs to be setuid root to perform the actual authentication. 

Install APC Zend OPcache and W3 Total Cache and watch your CPU usage drop back down to almost nothing. APC Zend OPcache alone should give you some breathing room. Note that W3 Total Cache is not fully multi-site aware, and so it has to be configured on each site individually. It can be set up to use your existing memcached for caching. You can also get rid of Apache. It's doing absolutely nothing for you. (Note: APC is deprecated and has proven to be unreliable in practice. I currently recommend using Zend OPcache instead.) 

Also keep in mind that SELinux works in addition to regular UNIX permissions, so the relevant files and directories must also have the appropriate ownership and permissions, whatever they will be for your specific use case. 

Of course, with such a long display as might generate, the headings may scroll off your terminal. As you use the commands more, you'll eventually learn which columns are which without having to refer to the headings. 

You need to enable the remi repository in order to install the matching packages from it. I presume you had previously enabled it by some means, in order to get its version of PHP in the first place. Edit and make sure that is set in the section. (If it isn't present, make sure you installed RPM first.) 

I build virtual machine images for Azure using Hyper-V, of course. The primary thing to worry about is that you have to use a VHD disk rather than a VHDX disk. For Windows, you need to sysprep the image, and for Linux you need to install the Windows Azure agent in the guest. See also Microsoft's documentation on creating a Windows image for Azure and creating a Linux image for Azure 

Funny, I just did exactly this the other day after finding my RHEL instance on EC2 only had 6GB or so of the 10GB space allocated to it... 

PHP will log a warning if fails. However, you may have logging disabled or going to an unexpected place. Check your and related configuration files to ensure that logging is enabled and to specify where the logs are written. To diagnose this problem without access to logs, try running PHP from the command line. For instance: 

The reason you don't have to escape is that is not a delimiter. It sounds like you are accustomed to writing regular expressions in other applications, where a delimiter is required. For instance, in Perl you might write something like: 

You almost certainly can't because of forward secrecy. MongoDB, for some reason, has a hardcoded SSL cipher list of . What this results in depends on the version of OpenSSL it was built against, but on a modern system will result in ciphers that use forward secrecy being preferred over those that don't. You can see the generated cipher list on the target system with: 

However, the key exchange never succeeds. Each side keeps attempting to retransmit the UDP packets over and over, never hearing a response, until they finally give up. I started on one end and observed that the UDP packet was being fragmented, and that an ICMP port unreachable was being returned after the second fragment came in. An example of such a failed exchange (sanitized for your protection): 

You have multiple issues here: First, the repo is not compatible with repositories. Since you are using PHP from remi, you should disable and remove the IUS repo(s) (and find other sources for any other packages you might have from IUS). Second, it looks like your system somehow got connected to an out of date mirror. I would clear the yum caches with and try again. Third, you should persistently enable repos you are actually using such as remi and remi-php72 etc. These ship disabled, but if you forget to enable them with each command, you will run into dependency issues. Finally, you enabled remi-test, the contents of which may be unstable or change at any time. It's likely you've got some bad packages from there, in which case disable it and see: If this still persists, I would run to ensure that all the installed packages match what is actually available in the repositories. 

It sounds like your server thinks it is domain.com and is therefore trying to deliver the mail locally rather than sending it out to the Internet. The easiest solution is to rename the server. But this won't cover the case of getting local mail to be delivered remotely. In that case, move on to: Next easiest is to configure the mail server to send all mail to a smarthost (in this case Google). How you do this depends on which MTA the machine is running (sendmail, postfix, etc.) but instructions can be found easily enough by searching the Internet. 

The code in RPM that is supposed to detect file differences fails on this edge case, where the destination has been made into a symlink. In the case of these particular files, they are generally safe to replace with the new versions that came in the new RPMs. 

RFC 793 states repeatedly that the acknowledgement number is the sequence number of the next packet that end expects to receive. Thus it will always be higher than the sequence number. For instance, in section 2.6: 

(But note that if you create the directory and leave it empty, the service will be masked and unable to start!) The use of a drop-in will also be shown whenever you request the service status. For example: 

While you're at it, you should also check to make sure you have the correct IP addresses for the incoming SIP traffic you're expecting. If the upstream provider ever changes them, you're in trouble. 

Use the CF-Connecting-IP header which is set by CloudFlare in your nginx real_ip configuration. For example: 

pg_conftool isn't packaged by CentOS or EPEL. You could always check out the source yourself and use the included .spec file to build your own RPM. 

You're almost certainly using an OpenVZ-based VPS. In this case, the host must enable the ppp kernel module (and anything else you might need) for you. Open a support ticket with your hosting provider. If they are unable or unwilling to make this change for you, buy another VPS, that doesn't use OpenVZ, so that you can choose your own kernel modules. 

Fix the reverse DNS entry (PTR record) and possibly the forward entry (A and AAAA records) for the host in question. 

Or you can select some other folder with Browse if you want to select a background image from somewhere as a wallpaper. 

(Where imagefile is the name of the disk image file that came out of the tarball.) You should see what looks like a partition table. If all looks well with the partition table, run: 

When I set up FreeRADIUS last year with an internal CA, and all BYOD devices, this was an issue on every desktop and mobile OS. I simply instructed the users to click Accept, and if they were truly paranoid, they could stop by and see me to manually verify the certificate. A few did. If you don't control the devices and can't install your CA certificate on them, you don't really have any other good options. 

This specifies whether and for how long OPcache should wait before checking to see if a file on disk has changed. In this case, yes, and after two seconds. First, try re-enabling this option, as it sounds like you have turned it off. 

NFS over IPv6 support first appeared in Ubuntu 10.10, Maverick Meerkat. Most of the work on NFS over IPv6 in Linux was actually done by early 2010, too late for inclusion in 10.04. Since you have 10.04, you cannot use NFS over IPv6. Your only option is to upgrade to a newer supported release (12.04 or 14.04 LTS). 

This is a known bug in OpenShift. I suggest you add your name to the bug, and also contact Red Hat Support if you are using OpenShift Enterprise. 

Amazon replaced the PHP 5.3.20 package with a newer point release (for security fixes, etc.). Just update to it instead: 

Creating the CNAME is what you're supposed to do, according to Amazon's documentation. You point it at the name of the Elastic Load Balancer that you were given, which you can find in the management console. So you set up a CNAME record like: 

Your is trying to load the file you specified, , which doesn't exist. Remember that you need to specify the path relative to the document . 

The void lookup limit was introduced in RFC 7208 and refers to DNS lookups which either return an empty response (NOERROR with no answers) or an NXDOMAIN response. This is a separate count from the 10 DNS lookup overall count. 

IPv6 addressing is different than IPv4 is usually managed. IPv6 is managed by subnet, not by individual address as in IPv4 today. So in Amazon AWS, you need to first assign an IPv6 CIDR block to your VPC. Then you can assign individual IPv6 addresses to your instances. See Amazon's guides for getting started with IPv6 and understanding IP addressing. By default your instances will obtain IPv6 addresses automatically. If you don't want this, you can assign a specific IPv6 address to it. But unlike IPv4, with IPv6 you assign addresses to the network interface of the instance, not to the instance. Use to assign IPv6 addresses to your instances' network interfaces. 

You were in command mode. Thus you were sending those commands to the telnet client, not to the open connection to the remote host. To switch back to the open connection, press Enter (alone) at the telnet prompt. (And press Ctrl+] to switch back to command mode.) 

Generally the bit in a package name means that it's a package from which CentOS has removed some Red Hat branding, artwork or other intellectual property. Someone appears to have forgotten to keep the tag on this package. 

Security Update for Exchange 2000 Server (KB959897) is listed as version 6.0.6620.9. You should already have Update Rollup for Exchange 2000 (KB870540) installed before applying it. 

The other sysctl, , allows some extra time for existing connections using a temporary address to finish up. You can also reduce this, especially if you don't anticipate long running connections. Here I reduce it to 1 hour: 

Note that some mail servers will reject email from senders not in compliance with the relevant RFCs. 

The Apache Software Foundation publishes many bits of software, one of which is a web server named . The httpd project sources include among other things an sample configuration file, which is installed by default in or . You will find httpd named as such on most systems. However, long ago and far away, someone in the Debian GNU/Linux distribution decided to change the name of the software within that distribution from to . Thus on a Debian system you will find a configuration file named in a directory named . I don't know who did this or why, but it's a perennial source of confusion on par with calling Windows "Microsoft" or ESXi "VMware". Distributions based on Debian, such as Ubuntu, inherit this strangeness. Even stranger, they then include a file which is d from into which users can place custom configuration. So the answer is, if you're on a Debian-based system, you bend your brain into doing things the way Debian wants you to do it. Otherwise you generally do things the normal way as the upstream httpd project does it.