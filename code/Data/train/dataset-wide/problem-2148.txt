AFAIK there are three major structure types used for storing Oracle index data: B-tree, R-tree and Bitmap. All indexes use one of these structures. However, not sure about CONTEXT, CTXCAT and CTXRULE Oracle text indexes... 

Suppose we have a server that has only 1 CPU with 1 core, so we need 1 Oracle database license for installing a database into it. Now, if we would need to add a second server, combine them into cluster and install database into it, then how many licenses do we need - 2 database licenses and 1 Clusterware licenses or 1 database license and 1 cluster license? I'm not sure, how Oracle treats joined into Oracle cluster servers - as one server or still as separate servers? Because we would need to buy expensive Oracle cluster software, then it would be logical for Oracle to treat joined servers as one. 

10 Mio rows, table size ~2GB, index size 3,4GB The runtime was about 55 minutes (not complaining here). The amount of generated WAL files was unexpectedly huge. The aforementioned WAL archives are on a dedicated partition with has 100GB and at the point the query started, around 30GB were free. It was not enough as after 15-20 minutes disk space was <10GB and I started to delete "older" WAL archives. I had to do this constantly up to the point were I was pretty sure I already had to delete WAL archive files generated by this very statement. The tables in question were not used by any other process during that time but "normal" operations of other tables continued. 

Oracle has partitioning and clustering features. Partitioning enables to split table or indexes into multiple tablespaces and store on various servers. So it's done manually. Clustering enables several servers to make operate as one. This IMHO is handled transparently. However, it's possible to have several tables (in different server databases) and group them as one, and use it. From the perspective on table partitioning and table clustering, IMHO both ways implement shared everything because the data is split into the different locations. The theory about shared nothing architecture is that each database node is independent. But how this looks in practice? Both ways (partitioning and clustering) splits data into different sources and could be also described as horizontal partitioning. However, if we had for example, two different database servers we would need to synchronize the data between them... Anyway, any thoughts on that would be appreciated :) 

The issue with Query 1 .. unknown. It uses the index; if the index does not exist, it takes as long as 5s. The issue I see with Query 2: it does not use the index but the index. However, when I do the following changes, Query 2 uses the index: 

I've marked the time where I started the query and where it ended. You can clearly see where I deleted the WAL archive files :-) To me, why so many are generated is a mystery and it currently is a problem because it's hardly foreseeable how much is needed and when operation strike which need one. What am I missing to better understand how much space is needed? Are these things avoidable? Am I doing something wrong? 

I have been reading up on innodb as a storage engine, mainly because I have recently moved to AWS and they do not recommend myISAM which my databases current run on (and have for about 10 years) So moving to a new engine is a little bit of a scary operation. I am apprehensive about the move, as it has been on myISAM for so long without issue, but if it gives me peace of mind long term, then it is better for the DB. I have read the whitepapers on InnoDB and it seems fairly straight forward, The one thing that I want to clear in my mind is the innodb_flush_log_at_trx_commit option By default this is set to 1, however from my reading this causes additional overheads, if the data was credit card transactions or something like that, I can understand its needs to be there, but it seems when dealing with non life changing data, that innodb_flush_log_at_trx_commit=2 is a better option. What I want to know is, this does not affect the time that the query is actually committed does it? It only affects its recovery ? I just want to make sure that when I do an insert or update that the query will run right at the time of processing and not 1 second later, no matter what the flush_log is set to. My understanding is that in the case of a crash , setting to 1 will allow it to recover all queries run on the server, where as setting it to 2 may lose the last second or two of data when trying to recover from the crash, is this correct? Also, if there is slow periods of updates/inserts (ie, not much happening on the server) does setting it to 2 add additional overheads on the server, or is it a case of the benefits of applying innodb_flush_log_at_trx_commit=2 to the database when the database is busy outweighs any additional overhead caused during slow times? 

In MySQL I could force certain queries to use specific, to my knowledge PostgreSQL does not provide such a think. Is it possible to speed up the queries with the current schema? 

I've around 5.000.000 entries with varying and I've two queries I regularly perform against this table. Think of usually having 200 to 500 chars. There are about 600 distinct in this table. Query 1: 

What else can I do to improve things without severely putting my data at risk? Ee.g. I don't want to . Although I can re-do this migration, this additional time would still be unwanted. Additional setting after Feedback 

The trigger does not contain autonomous transaction procedure with commit inside that, so who is commiting the insert? This triggger works like a charm and inserts new record into log table after user logon. It smells like hidden Oracle functionality and I can't find any reference in Oracle docs about that. I'm using Oracle11g. 

You can create an index and define prefix length, so the index will store only first starting symbols from each of column value. It looks like this in MySQL: 

We can create the database trigger on concrete schema event (ON SCOTT.SCHEMA) or on all schemas (ON SCHEMA). However, we can also use ON DATABASE when creating database trigger. What is the difference between them? Is it some legacy stuff? ON DATABASE should be used when using AFTER STARTUP or AFTER STARTUP because it's definitely related only to database but the same stuff that is done using ON SCHEMA might be done using ON DATABASE, so what's the difference? I can't find references in Oracle docs about that. 

I'm using pgloader to perform a one-time migration from MySQL to Postgres. For that purpose, I want to temporarily configure Postgres specifically for that workload. 

I'm constantly caught by surprised how certain operations generate me huge amount of WAL files. I want these WAL files for point in time recovery (I also perform a nightly full dump in addition) so the basic functionality provided is wanted and I don't want to change that (i.e. I'm not searching for a way to turning WAL archives off, etc.) Using Postgres 9.5 with these settings: 

I am in the process of moving my servers from stand alone hosting to AWS using RDS (MySQL) for database usage. One of the first things RDS states is that in order to use their backup, and snapshot features of RDS the tables must be using InnoDB. My site has always run on MyIsam, probably mainly because 10+ years ago, it seemed like the right choice. Because of this, my database structure is quite simple, and quite separate, there are no join queries on the site, so every select is only getting data from one table. some of the tables have quite a few indexed fields, The site requires, frequent inserts, regular updates and many reads, I don't use full text searching, the majority of queries revolve around either the UserID or the tables autoincrement ID So, my question is, what to expect if i was to move to Innodb? I am not that worried about the transaction side of it. and for this reason MyISAM is ok. I am more concerned about backup, previously I had a cron job that would automate the backup , but of course this came at a price of lockouts while the backup was in process. MY understanding of InnoDB is that because it does row level locking, this would not be an issue. But what about performance? I have read so many reviews and bench tests, but i dont know how they relate to my situation. Can I move over to InnoDB without worrying about setting up foreign keys etc, can i keep things as simple as they are now, or would that negatively affect the system if using InnoDB. I realize that InnoDB has become the default option in MySQL these days, which makes me think that all dbs should be running on it anyway. What I dont want to do is have my database fall over because I didnt set up innodb properly. Is it even worth moving my tables over to it, given its been running just fine on MyISAM for years. Or is it a case of, this is good cause to change?