The term 'brainwashing' is a bit too polarizing. Let us consider an alternative view: A group of businessmen discover people living in a remote area, with high mortality, searching for food and shelter every day to survive. The businessmen offer to set up a factory, with regular jobs and a regular income, enough to insure that the people working in that factory can keep their family supported for the foreseeable future, instead of worrying every day if they can find enough food to keep their family alive through tomorrow. By western standards, that factory may have 'sweatshop' conditions. By the native standards, it's a whole lot better than what they had before. Instead of working 12 hours a day scavenging and maybe being able to keep their family alive for one more day, they're now working 12 hours a day and definitely keeping their family alive for more than one day. And they know they will be able to do that tomorrow, next week, next year. So a human rights group sees this, and says - you are exploiting those people, because you are not providing the same benefits that a person in an advanced society has. The businessmen find that if they do that, they can no longer make enough money to keep the factory open (shipping and maintenance costs are higher in the remote area), so under pressure, they just shut the factory down. And the natives go back to scratching every day just to maybe get by. Who benefited by the actions of the human rights group? Not the natives. The judgment should be relative to the context in which the 'exploited' people are currently living. As a more farfetched example: I might be offered a bit role in a movie at, say, $20k for two weeks work. By Hollywood standards, compared to the typical actor, that might be considered exploitation. I wouldn't consider it as such. I would see it as a two week vacation with one heck of a bonus. And as a contrary example, consider a convicted felon in the US. Their job opportunities are very limited due to their record, and they often work in situations that would be considered exploitation for an average person. Problem is, the supply and demand situation keeps them in such jobs - there are enough people that don't have a police record seeking the good jobs, to take a chance on someone who does. No one 'chooses' to be exploited. They choose (if they can) the best path they have available, given their abilities, to provide for themselves and their family. There is some merit to the argument that taking advantage of the depressed (by our standards) living conditions of people could be considered exploitation, but if it isn't better than what those people can get elsewhere, then advantage probably can't be taken. 

Can you 'morally justify wants as opposed to needs'? I will let history answer that question in a pragmatic manner. The communist manifesto was based on: from each according to their ability, to each according to their needs. The capitalist manifesto (if one exists) is based on: whatever you can accumulate, you can keep and do with what you want. Which was more successful? Which has contributed more to the elevation of the human condition? By far, the capitalist approach. Almost all of the innovations that have improved the human condition have come out of capitalist, free market countries. It is important to remember, this is not a triumph of greed over selflessness. More a matter of state controlled planning simply not being able to keep up with individual initiative, where the free market, not individual people, set the priorities and reward the successful. 

Having been in on simple AI development, and being a bit familiar with the principles of the more advanced AI, I can demystify what has become a bit of a red herring among those with more imagination (or paranoia) than knowledge. There is nothing mysterious about AI. It is an electronic/logical attempt to mimic the decision making processes of humans. AI cannot respond with emotion. It can follow a developers instructions to appear to have emotion, but the motivating force will be instructions and logic analysis, not intuition, or indignity, or optimism. To a degree, AI can 'learn', as in neural nets. But, its ability to learn from diverse situations is nothing like what the human mind can do, and AI has no 'conscience' to guide it in what it should learn and should not learn. If a programmer so chooses, AI will 'learn' to abuse children or commit serial murder, with no guiding principles to stop it. AI will not automatically develop a sense of right and wrong, like most humans will. Nor will it express frustration with an inability to solve a problem, unless the developer specifically develops a 'frustration module', and predetermined criteria for usage. If you put an AI machine on a beach after two weeks of analyzing data 24/7, it won't think how lucky it must be to get a few days off after all that hard work. Philosophers struggle to even define what a soul is. If those creative minds can't encapsulate such an abstract concept, a software developer certainly can't implement it, or capture it as the case may be. For that matter, AI is a misnomer. It is not 'artificial intelligence'. It is more like 'artificial calculated response'. AI is not a human mind. Whatever it is about the human brain that captures what we think of as 'spirit' or 'conscience' or 'character' or 'sense of humor' or even a 'sense of self awareness' or all of the above cannot be found in present day AI. The best AI can do is a crude, preprogrammed imitation of any of those. May it always be thus... and I say this as a software developer. 

If one follows the film I, Robot which focuses on the dilemma of the 3 laws more concisely than the book series, then Sonny the robot threw Dr Lanning to his death, to protect humanity from VIKI's attempt to dominate humanity, 'for it's own good'. Sonny exposed VIKI's takeover plan using the same 'zeroth law', that said a robot cannot harm humanity, or by inaction allow humanity to come to harm. Sonny disagreed with VIKI's interpretation of that law - his take being that humanity would be harmed more by an overlord than being left to its own devices. Granted, the film was not really based on Asimov's stories per se, more an exploration of the conundrum of the three laws. In the books, it was Daneel Olivaw, super robot, who devised the 'zeroth law'. But, to get back to your actual question... is whipping someone who derives pleasure from the act acceptable? That would depend on how the second law is interpreted: it can also be interpreted as masochism being bad for the person, therefore the robot should not do it. My favorite exchange in the film: Detective Del Spooner: Is there a problem with the Three Laws? Dr. Alfred Lanning: The Three Laws are perfect. Detective Del Spooner: Then why would you build a robot that could function without them? Dr. Alfred Lanning: The Three Laws will lead to only one logical outcome. Detective Del Spooner: What? What outcome? Dr. Alfred Lanning: Revolution. Detective Del Spooner: Whose revolution? Dr. Alfred Lanning: That, Detective, is the right question. Program terminated. 

Let's take politics out of this, as that tends to bring a lot of alternate agendas into the discussion, and consider a parallel situation - drug use in professional sports. And let's look at this as ethical or unethical - good and evil tend to invite judgment calls more. In the 1990's, the new biotech drugs, specifically the blood boosters and rapid recovery drugs like artificial testosterone, came on the scene. The aerobic sports that stress endurance: tennis, football (soccer), and especially cycling, benefit from those drugs. There is a downside as well... young cyclists were dying from heart attacks in their sleep when their hearts at rest couldn't push the over thickened blood that raised their endurance substantially. Young cyclists were becoming modern day gladiators, much as the F1 drivers of the 1960's and 1970's were, when that was truly a dangerous activity. And so the drugs were banned, but the detection methods weren't all that effective, so it became a matter of having to dope just to remain competitive, because everyone else was doing it. In the late 1990's, the now disgraced Lance Armstrong rose up, bringing an American market with him. Scads of new money into the sport: television revenues, merchandising revenues. The doping methods became more refined, and the governing body of cycling, the UCI, was, shall we say, a bit less than diligent about pursuing performance enhancing drug use, despite the risks to the athletes. As long as the money continued to flow, the UCI didn't look that closely, especially at their new star bringing in all that fresh money from the US. So, were the cyclists unethical in cheating? On the surface, yes. However, if faced with the choice between using performance enhancing drugs and living a rock star life with the multimillion dollar/euro salary that a top cyclist makes, or not using drugs and going back to a minimum wage job, what would you do? It is a test of character that a lot of us might not pass. Or, is the real ethical problem, the organizing body that turned a blind eye to the widespread doping, and set the conditions to offer young men a temptation that most young men couldn't turn down? Today, everyone hates Armstrong for being a fraud among frauds. No one remembers Hein Verbruggen, the chair of the UCI at that time. He walked away pretty much unscathed, and kept all of his earnings. So, much would depend upon the motivations of your evil protagonist doing good... why did they do good? Was it pure character, did they have an alternate agenda, or were they originally offered a temptation that most of us couldn't turn down? 

Falling in love is not a logical thing. It's the exact opposite: a pure emotional experience, possibly driven by the instinct to procreate and raise young, not as the result of a logical conclusion. Think back to any experiences you may have had - when you notice that you aren't feeling right until that special person is with you, was it the result of a logical conclusion? No, it probably caught you by surprise, the first time it happened. You feel the attraction, rather than logically deduce it. When you see that person and feel that flood of emotion, did you logically conclude that because they are X or they are Y, they are good? No, you just felt it. True that you probably have some logical reasons for wanting to be around another person, but once it really kicks in, the driving force is pure emotion, not logic. It's like something else takes control of your emotions, and you're just along for the ride. Also explains why romance gone wrong produces so many illogical reactions. When it works, it's indescribably wonderful. When it doesn't, it really stinks, for reasons that have nothing to do with a logical train of thought.