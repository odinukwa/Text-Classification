The likelihood of generating two keys that are duplicates is \$\frac{1}{36^{16}} \approx 8\cdot 10^{-24}\$. So if you generate 10000 (ten thousand) bulk keys, the likelyhood of not having any duplicates is: $$(1-\frac{1}{36^{16}})^{10000}=99.99999999999999999987\%$$. In other words, you are not very likely to get duplicates as long as your random function is good (hence the use of instead of . To be certain you have to always check against your database anyway as a last step so I would just not bother with duplicate checking on the client side as the likelihood of finding duplicates is so very low. 

Turning my comment into an answer by request. You should be able to do what you want by simply using the functionality already built into LibGDX. Caveat: I have not tried this, I just know that the class exists and it should be possible to extract the data you want from it, so: some assembly may be required on your part. LibGDX has functionality for loading and dealing with bitmapped fonts. See the documentation here. You can use the class to load the font data. It supports AngelCode BMFont formats. Hiero which you are using can output to BMFont. Create a new instance of the : 

Express your intent as clearly as possible, and let the compiler worry about generating high performance code. Compilers are pretty smart... Always, always, always measure. 

and similarly for the inner loop. Depending on the ratio camera size to level size (if I'm interpreting your code correctly) this can give a big speedup. Hint: The y direction iteration start and end values are independent of the current iteration in x direction so calculate the yend and ystart before entering the first loop. Caution: The above and may be off-by-one as I don't know what all the variables are, adjust to taste. Edit: Oops just realized this is what Neil mentioned in the first point on his answer. But I'll leave this here as it's an example of what he said. Edit2: Missed the incrementation of prior to entering the loop. 

Simplify branches by realising invariants Realize that is always defined by the and variables hence we can define it inside of the loop as a temporary. By doing so and keeping in mind that the array is sorted we can simplify the code as follows: 

API and Naming To me the names of and are not very apt as they don't reflect the way I think about a queue and they don't match the naming of the STL queue. I would much prefer if your class implemented the same API as where applicable. Or at least used the same terminology such as and . Performance This: 

Universal references This here is a universal reference, the parameter will inherit whatever qualifiers the constructor was called with. 

And I'm sorry for being unable to provide a runnable example, but I feel like that would be too much work for the reviewer. If you do wish to run the code you can check it out from the github repository at the top and run the gradle setup script to get the dependencies. 

Which means, you probably shouldn't show if to your students on the first multi-threaded program they see, lest they get the idea that it is something they need to use. Second we need to understand what actually does. It only gives a hint (which the OS or JVM is completely free to ignore) that the OS might want to give the core to some other thread. It does not in-fact act as any sort of synchronisation or way to implement thread-to-thread communication. And frankly in your case I do not see why you would want to call where you do. In general the usage of indicates a design problem with the program. Any place where you use you should probably block your thread on a signal or mutex instead. These also let the OS schedule something else on the core, thus having the same effect as but instead of being just a hint they actually stop execution of the thread. Some examples: 

The singleton pattern as I implemented it has well defined construction and destruction which means that all code paths that exit the program normally will invoke the destructor and perform clean up. You do not need to call explicitly to clean up. The standard guarantees that memory for members will be laid out contiguously in memory which is good for your cache hit/miss ratio. Granted that the compiler may likely place your statics contiguously as well, this is not guaranteed though. If you at some point decide to allow multiple game instances, say you make a multiplayer server, object oriented code is much easier to adapt. 

which proves that this scenario is possible and likely to happen when you get enough items. In comparison, the first upper bound would achieve: 

If it indeed is integer arithmetic you will have an integer overflow if you're dealing with large arrays. You should implement it as: 

Which method to choose depends on how long the expressions , and are and which one you find more readable. Your code Use with caution! I might have missed something as my PHP is rusty. 

Adoption to your templates and other missing operators such as and const correctness are left as an exercise for the reader. 

Accessors (Setters & Getters) Although getters and setters can be a code smell avoiding them in this convoluted way that you're trying to is the wrong way to go. Look at the description of , it has no functionality, it is not an object in an OO sense; it is simply a data structure, an imaginary row in a database table somewhere. Because of this, it is natural for it to have accessors for its members. It is perfectly acceptable for your data model/class to have accessors. If you had an object with behavior, for example: 

Other comments You should keep your in format for accuracy. Also you can move the variable into the scope of the where it is initialized and used. 

Again, I have not tested this. You may have to fiddle around or use other properties of the glyph to get the wanted result. But the data you need is all in there, you just have to pry it out. The LibGDX documentation (and source code) is your friend. 

As I said, it is not bad design per say. Although it makes testing in isolation with unit tests difficult. Masquerading procedural code as a class is a big no-no for me. 

Naming Manifest constants typically use for space in Java. So for example should be . Also I believe that the name is quite misleading as a name because the class isn't actually your main loop but rather a timing helper. Avoid unnecessary conversions You don't need the double precision here: 

No even number besides '2' can be a prime so skip all even numbers in your iteration after removing all factors of '2'. Limit your search range to the largest possible factor of n, i.e. 

In the end your algorithm is \$\mathcal{O}(n\log n)\$ although there is a lot of iteration going on and I would say it's on the slow side of the spectrum. A better solution A faster way of doing this would be: 

will not bind to temporaries because it must be able to take the address of the argument. Other than that it will bind to reference to because will be deduced to . So this constructor covers all legal use cases that the one with universal reference does, so you can remove either one. I suggest you nuke the universal one because it is slightly harder to understand. Stream operators Your two stream operators: 

Again it is not bad design but use the correct pattern for it. And yes, statics tend to complicate things when you start multithreading but in your case it is no less complicated if using the singleton pattern. 

Oops I realize after writing all this that the above example code misses some functionality that OP's macros have. But it solves the motivational example that was given to get the index and value during the iteration of a range based for loop. 

As you are using universal references this means that will bind to anything and retain it's qualifiers. Even r-value references... which means that the following will compile and run doing some manner of undefined behaviour: 

You should also implement move constructor and move assignment operator. You should also used as the backing store, this way you don't need the or members. Your code will simplify a lot and you will not need to worry about manually keeping track of the memory. Using in a C++ program is a code smell. But all in all, the above is pretty pointless because you really should use and save yourself the trouble of maintaining and coding your own string class. 

Do not repeat yourself, your copy constructor and assignment operator share a lot of code. You can implement copy constructor like this: 

Don't load the same resource repeatedly I don't have much time to give a full review but I can point out one big thing that I saw while looking through the code. 

You have the data set apparently, profile and see where the time is spent. Determine the time complexity of your algorithm. These types of problems almost never require you to "optimize" your code to make it faster, they need you to nail the correct algorithm. Let me rephrase that, even a shitty, most sub-optimal implementation of the correct algorithm with the right time complexity will likely pass the time requirement (in fact this is typically one of the design goals when making the data sets: A poor implementation of the right algorithm must pass while a super optimized version of the wrong algorithm must fail). If you're getting time limit exceeded, you most likely have the wrong algorithm and time complexity or you have a bug (infinite loop or w/e). 

Not mentioned elsewhere: Dial back on the excessive use of new lines. Readability is important but remember that scrolling impairs readability as well so try to keep your code a bit tighter (but not too tight!). Why are and public functions? You're not testing them in the unit tests and they make no sense to be public to me. I believe that you should extract the node finding in the method to functions. 

See if the contains \$c=-a_k -a_i\$. If it does, add \$-a_k -a_i\$, \$a_k\$ and \$a_i\$ as a tuple to the list of found tuples. If there are \$i\$ left to try, go to step 5.1, otherwise set \$k=k+1\$ and go to step 4. 

As you can see no bias here. The things to take note of: The reroll takes care of the bias; and using the largest possible chunkSize and thus using the largest part possible of the output range of rand() avoids the issue with the low bits being of poor quality (unless you have a very large range but then you're SOL anyway). The probability of a re-roll is: