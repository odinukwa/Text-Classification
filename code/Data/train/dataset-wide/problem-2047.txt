There is no priority in SQL Server for commands which ever comes first would be executed first. There would always be , of course you would not be able to notice it. 

Reading transaction log using fn_dblog is not supported by Microsoft. So you should avoid running this command on production server. You can run this on UAT/Test environment. What do you exactly want to read from output of fn_dblog, can you be precise. There are myraids of information you can get from output of fn_dblog. Its not easy to read the output and one requires some level of expertise to read it. I will give you a Demo. 

This can cause a bit of more time being spent by optimizer in preparing new better plan and I/O bringing pages into memory but this would just be the first time. But there would not be much performance degradation. In many cases the new plan would execute query much faster and this would outweigh the time taken by optimizer to build new plan and I/O to get pages into memory. Since you are interested about plan cache I suggest you read Plan Cache and Reuse. As per the document among other following two can also cause plan to recompile 

As per above the corruption is with non clustered index (Index ID 10) and there are possibilities that if you rebuild these non clustered indexes the corruption may disappear without data loss. The chain linkage problem signifies that somehow storage has corrupted the whole 64 KB of page and there is no "correct link" between the pages which used to be before, the index pages are linked by doubly linked list (using the m_nextPage and m_prevPage fields in their page headers). Again blog Use DBCC Page to find what would be deleted in repair would be helpful in giving you idea what could get removed if you run repair. 

Buffer descriptors as already mentioned returns information about all the data pages that are currently in the SQL Server buffer pool. IMHO buffer pages . If there is request to fetch large amount of pages from disk to memory its quite possible that SQL Server will flush datapages to disk if it finds it needs to create space in buffer pool to bring in the new pages in memory and thus decreasing the amount of data page present in memory for particular database. So what you are seeing via sys.dm_os_buffer_descriptors is not incorrect but I would you to use Buffer descriptor DMV to gauge PLE on server. This would not be a correct approach. 

The whole Log is filled with security exceptions and it was when SQL Server installation tried to access Reg key HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Microsoft SQL Server. Workaround A work around in below scenario might be 

You can read about uninstall parameters from Books Online. You can also have a look at how to uninstall existing instance of SQL Server If you want to remove SQL Server 2005 This support article is very well written 

Now this means that registry is inconsistent and ACL checks cannot be performed. In that case we have to manually provide access. 

The database would not be changed at all, whatever would be changed is backup size. So if you have 2TB of database on source then when you take backup with compression it might be around 1 TB(A simple guess, size may vary) but when you restore the same backup on destination the size required would again be 2 TB. Compression is just to make backup size small, it has NO affect on database original size 

If it comes out clean you can restore the backup to get back the database. The data loss also depends upon the recovery model of database if it is simple you can only restore full and differential backup if it is bulk logged and Full you can restore full ,differential and log backups to get minimum data loss. Are you able to take backup of current database with continue after error. Please see if below command works, I guess it would 

Example: Look at it is totally not usable at all. It would be correct decision to first disable it and then remove it. Look at the index is both read and updated but updated more than read. The division value is .80 which is almost 80 %. You can keep this index it both being utilized and updated, I dont see issue with this index. Look at the division give .33 value and percentage is 33 %. This index again has to be looked into this is doing more harm than it is doing good. The whole idea about percentage is based on how good knowledge you have about your database. The decision to keep or remove an index should be largely based on requirement. Its quite possible index might be utilized fortnightly or weekly but updated every day. This may be because a job runs weekly or fortnightly and utilizes those indexes only at that time. Moreover you should not worry about small indexes which have page count < 2000, again this is ball park figure, such indexes cannot do any harm. 

That is not exactly the place from where you can uninstall SP, you have to go to add remove programs and then on top left you would see 

For your case since you are changed recovery model to simple so you DONT need to take any backup to actually make it behave in simple recovery. I am not talking about normal backup you take for your dev databases. You should continue taking normal full backup of your dev databases. 

Database mirroring feature is not present for SQL Server express edition. From question it seems you want to create a replica of your current database. In this scenario backup restore would be best. Replication would also not fit in your scenario as its also not complteley available for express edition(subscriber only is avaialble). You can take backup of your current express database and restore it on already present database or restore it as new database. Backup would include all objects(views,sprocs,tables,indexes etc) present in source table. Since database has limitation of max of 10G( I am assuming you are using SQL Server 2008 R2 and above) it wont take much time to backup, copy and restore. You can also create a manual backup job, copy job and restore job with help of CMD and a batch file. Please refer to this link for automating jobs using windows scheduler and batch file. You can also Schedule and automate backup job in SQL Server Express. 

This is a workaround. The solution here would be to find out what is causing stress to VM machine. You should fix that. If you feel Wmware Balooning is the issue. You can use RAMMAP tool to track memory which is consumed by . In RAMMAP tool if you see Locked driver taking huge memory its sign of VMware balooning. Take help from the team to configured/disable ballooning for the virtual machine on which SQL Server is running Befor giving LPIM you must make sure you have set optimum value for max server memory and have left ENOUGH memory for OS to perform efficiently. If you do not follow above two points and if OS comes under severe memory pressure due to LPIM OS processes would be paged out because it cannot force SQL Server to release memory(its locked/non pageable due to LPIM) and thus leading to tremendous slowness of OS processes. 

Starting from 2008 onwards Index rebuild is fully logged in full recovery model. If you rebuild huge index in full recovery model its bound to produce too much logs. So in this table you have how many indexes? Are you rebuilding all such indexes in one go. If you are doing this you must consider doing it piece meal. One index at a time Of course you can switch to bulk logged recovery model when rebuilding index but you would loose point in time recovery for period the index rebuild operation is going. After index rebuild is done and if you still continue with bulk logged recovery model and some transactions are done which are not defined as minimally logged in BL recovery model they would be fully logged Consider below before switching to Bulk Logged Recovery Model 

If you are planning to open case with Microsoft I suggest you move them to some other location just in case. If you have those dumps you can give more information to support personal who would be looking at your case. Also note that its quite likely that the dump produced would not capture all information related to the issue and support personal would ask you to enable trace flag and wait for the next dump to occur which will capture all the related information. If you really like to delete it, delete the old ones and leave the new ones. 

You can read this article and use queries given to calculate appropriate value for autogrowth size. Proper initial size would pre-alllocate space and would avoid frequent autogrowths which are not so good events 

requested_memory_kb will tell you memory which query requested granted_memory_kb will tell you what actually was granted to the query. I strongly suggest you to read Understanding query Memory Grants to know about how memory is granted during life cycle of a query 

If above still does not helps can you find SQL Server logs at location Drive:\Program Files\Microsoft SQL Server\MSSQL.n\MSSQL\LOG\ERRORLOG and ERRORLOG.n files.And post the contents in question. Where Drive is system drive on which you installed SQL Server. It can be system drive C or any user drive (D,E,F...) . MSSQLn here means version number of SQL Server n=10 for SQL Server 2008/2008 R2 n= 11 for SQL Server 20012 n=12 for SQL Server 2014. For more details about this issue please read this link EDIT: IMPORTANT NOTE Please don't install SQL Server 2012 with SP1 with slipstream method there was issue in slipstreaming process with SP1 which caused setup to fail. Only install SQL Server 2012 you can uncheck the SP1 setup during installation. The issue was removed with SP2 slip stream Edit: Following are from logs you provided 

The message is pretty much self explanatory you cannot perform shrink operation inside transaction. As already pointed IS THERE A GRAVE NEED TO SHRINK LOG FILE ?. What you want to achieve by shrinking log file, are you worried about the space transaction log is using. Delete operation is fully logged where by each row which is being deleted is logged into transaction log and so Transaction log file will grow. . Shrinking of log also has performance implications as there is no instant file initialization for log files and when log files grow other transactions wait for this event. You have to find better way to manage transaction log space. There are two things you can do 1.Decrease the number of rows being deleted in TOP command. You can also use dummy code as below 

So what this means is of all committed memory SQL Server is not using 40 MB of the memory. . A committed memory is one that is backed by physical RAM. When a process starts it can address any physical memory address in its VAS but memory will only be committed if that VAS region is backed by physical memory. 

Just have a look at REQUEST_MAX_MEMORY_GRANT_PERCENT=100 now this seems a very wrong configuration to me. According to BOL document 

Just go ahead click and apply the service pack, you can safely ignore this process. The check is to handle scenario where end user does not want to restart after applying service pack in that case you need to make sure all such processes are stopped, but in any case I strongly recommend to start windows machine/node on which you are applying service pack. The only thing which can happen is after successful upgrade you need to start the windows machine. This as such is NOT going to cause SP to fail 

I will take you question point wise 1.In my opinion its higly unlikey for an unused large table to cause issue with query running for diffrent database. SQL Server memory is dynamic in nature if suppose large portion of memory is occupied by datapages of DB1 Lazy writer and checkpoint pages will work together to age out pages which are not used recently or have committed records. So if DB2 data pages require memory they would be granted and I dont think memory crunch would be there 2.No, I dont think so like I said a query for particular database(DB2) will have no affect with records present in other database(DB1) IF that database tables of DB1 are not used in this query. Can you define your performance issue is it query slowness, disk slowness memory crunch what?. Please use this link for analysing slow running queries 3.Yes there are lot of monitoring tools available in market I have Spotlight in my enviroenment you can use SCOM as well. You would liek to refer this whitepaer Troubleshooting performance problems in SQL Server