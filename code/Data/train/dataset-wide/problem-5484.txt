I think a major source of confusion here is that you're (quite naturally) associating the creator with a Neo-Platonic image of the One God as the unity of all perfections. However, although this passage definitely refers to a version of the "One" (which Plato here calls the "Eternal Essence") Plato isn't calling it the creator. The creator is just a craftsperson who makes the world in imitation of the Eternal Essence (just as, in Ion, poets make poems, or in The Republic, statesmen make city governments, in imitation of that same Essence, imitations which inevitably fall short). There's no strong suggestion that Plato actually believes this creator/demiurge even exists, it just appears in the story as a tool to help people interested in accounts of creation reinterpret the appearances of the universe as reflections of the Eternal Essence. To compound the confusion, some places where Plato appears to be talking about the creator ("he was" versus "he is") only make sense if we take them as solely referring to the Eternal Essence instead (even though the Essence is not otherwise personalized here). As far as the terms, I'm not a Greek scholar, but Plato always uses words in an idiosyncratic way in any case, so an exact translation of any word can only be at best a starting point. I follow an approach to interpreting Plato that takes everything he writes as an attempt to explain his concept of the Eternal Essence (more often called the Ideal of Good) as explained through innumerable metaphors aimed at different audiences. The core belief is that there is a perfect, eternal godlike ideal in a kind of conceptual heaven. That core ideal is surrounded by increasingly imperfect copies. In what, if nothing else, is a wonderful example of form matching function, this leads him to a certain sloppiness in language that can be perplexing to those used to philosophical precision. Since Plato believes the perceptible surface expression is always an imperfect attempt to point to the perfect but imperceptible meaning, he's quite willing to play fast and loose with the superficial details. Thus, each time he uses a term meaning eternal here, it has a slightly different connotation, which we have to glean from context, not from the actual word choice. This particular dialogue is an original creation myth, presumably aimed at an audience of mystical theologians, and using terms and concepts that would have been familiar to them. As always, however, Plato tweaks those terms to support his own unique vision of Ultimate Reality. As I understand this passage, the general idea is that the Eternal Essence is both everlasting and not directly perceptible --transcendent, if you will. It lasts forever and never changes. The heavens are a higher order copy of that ideal, they last forever, but they are not perfectly unchanging. Humanity is a lower order copy of the ideal, we are neither eternal nor unchanging. When we see the heavens, they are a bridge between ourselves and the imperceptibly transcendent Eternal Essence. The heavens are an image of perfection, but are not themselves perfect, because no image is perfect (every image is an imperfect copy). Where the Eternal Essence is everlasting because it is entirely outside time, and therefore never changes, the heavens are everlasting within time. They are cyclical ("revolves according to a law of number"), which is what everlasting looks like when you combine it with change. They are therefore not eternal "in its fullness," which is necessarily static. The reason for creating the heavens is so we can see what something eternal looks like, but in a form that changes like we change, so we can identify with it. That helps us understand that we too are formed in imitation of the Eternal Essence. 

There are many competing definitions for informal logic, but it's probably best to understand it as a retronym (like "analog clock"), a term made up to distinguish older approaches to logic from the newer, more mathematically rigorous approaches collectively known as formal logic. In other words, the various branches of formal logic were developed to reduce and eliminate the ambiguities of arguments in natural language, and thus provide a consistent, rule-governed approach to logical argument. However, in doing so, many subtleties were inevitably lost (just as converting an analog recording to digital inevitably loses some aspects of audio quality while enhancing others). The modal logics with which you are wrestling are an attempt to pull a wider range of what can be considered by natural argument into the realm of surety represented by formal logic. However, it's arguable whether or not this has provided the desired utility and benefits (since it's not clear how well the various modal logics do actually capture the desired aspects of natural argument). If you do make the move to informal logic, you'll be plunged back in the realm of subjectivity and ambiguity. That's still the realm, however, where nearly all substantive debate on real-world issues (i.e. abortion, gay marriage, gun control, climate change) takes place. From that point of view, the real utility of formal logic is that it gives you the mental tools and insight to better construct or critique informal arguments. 

Informally, the idea that I believe Plantinga's argument is trying to capture formally, is that free will isn't worth much without consequential choices. If all the choices are between the good and the good, are they really choices? It's like your mother saying "do you want to go to bed now, or in five minutes?" It has the form of a choice, but your agency is illusionary. 

According to the Stanford Encyclopedia of Philosophy, the answer is yes. One of the usages they cite is answering questions about decidability. Another is "bisimulation": 

It depends on what you mean by "objective" and "existence." Personally, I'd be very well-disposed to acknowledge that Santa has at the least a functional existence --after all, some entity delivers gifts to all those children, even it it isn't a physical human being dressed in red to who lives at the North Pole. So, you might say that Santa exists, we're just significantly wrong about the nature and the details of his existence. With that said, you might want to keep in mind that I'm also inclined to grant "existence", under my definition, to any number of conceptual and collective entities who other people might be inclined to argue against. 

You might also find it worth reading any one of the innumerable collections of the wisdom of the Sufis and the Zen Buddhists. Note: the links above are to older translations freely available on the internet. In most cases there are more modern and readable translations available, but not for free. 

In Medieval Europe, the study of logic and reason was closely allied with the study of theology. This arguably reached its peak with the publication of St Thomas Aquinas' influential (and lengthy) masterwork of Aristotelian logic-based theology, the Summa Theologica. In more modern times, however, the disciplines have largely parted ways, at least in the English speaking world. Modern logic was developed through the analytical school of philosophy, whose leading figures, such as Bertrand Russell, have often been atheistic. Conversely modern Christianity has moved away from logical and intellectual defenses of faith, and towards a more directly spiritual and emotional connection with the divine. Some people might still consider logic and reason a prerequisite for the study of theology, but I'd imagine that's more likely a minority opinion than a common expectation. 

A mature science deals with structured, testable predictions, within a preexisting conceptual framework. However, most (arguably all) sciences are preceded by philosophical treatments of the same territory. The philosopher establishes, or at least outlines the conceptual framework the scientist will later use. During the development phases of a science, empirical and philosophical questions are likely to interact. Even in the case that the subject of study is the same, it's no surprise that science and philosophy can attract widely different personalities. The innovator of a science must have at least one foot in the world of philosophy, but a researcher in a (mature) science often finds success through avoiding the kinds of open-ended questions that most appeal to a philosopher. It's worth noting that a science can stay in a developing stage for a very long period of time. Logic, for example, only reached maturity recently, after several thousand years of development. 

It is not unusual in mathematical definitions for the first member of a set to be defined differently, or seemingly more arbitrarily than the subsequent members of the set. This is particularly true in cases where the first member plays a key role in the general definition. Mathematics in general, however, has a odd metaphysical status. It simultaneously seems like something we create, and something we discover. Many mathematical rules and procedures seem arbitrary from one point of view, yet written in stone from another. There is a seeming definiteness and purity to mathematics that can be deceptive. What this means in practice is that there are times when we assign a number to a set --1 to the set of odd numbers, for example, or 2 to the set of prime numbers --less because it fits a general definition, but because it "works," because it is useful, or because it creates less problems and exceptions when defined that way. This may be frustrating to those who think this heuristic falls short of mathematical perfection and precision. Every good idealist should know, however, that reality always inevitably falls short of the ideal. 

The closest match is probably the Utilitarian ethical theory called "Enlightened Self Interest". The basic idea is that we act ethically once we learn it is in our own self-interest to promote the interests of others. 

Many young children are frightened of going to sleep. I suspect that philosophers may continue to notice the similarities between sleep and death long after most people. I myself was well into adulthood before I got used to losing consciousness. However, we all do it an average of at least 365 times every year we are alive, so it at last becomes a well-practiced activity. It's also a restorative necessity. It does seem like there are at least some people who, by one route or another, eventually come to a place in their lives or their minds where the passage into death is as fearless for them as is the passage into sleep. 

This may superficially seem like a question of ethics --a moral commitment against racism as opposed to the practical value of profiling --but I think that both overstates the practicality of profiling, and understates the practical value of minimizing racial biases. If the suspects --or the guitars! --were arguments, what you are talking about would be the genetic fallacy, judging something on its origins, rather than examining it for its own merits. It also suffers from confirmation bias, where we remember the things that match our preconceived patterns of thought, and forget the others. For instance, is it actually the case that most terror attacks in the United States are --to use your example --committed by people of Arab background, or is it the case that the media typically only conceptualizes a violent attack as "terror" when a person of Arab background commits it? Is Ethnic Group A really "notoriously" more violent than Ethnic Group B? Or is it that when a person of Group A (Arabs) is violent, that is presented as being typical and intrinsic, but when a person of Group B (Caucasians) is violent, that is presented as exceptional and anomalous? It isn't possible to quit seeking generalizable patterns --that's an essential part of how people conceptualize the world --but it is possible to become aware of your own biases, and work to prevent them from leading you to bad decisions. In other words, don't be blind to the possibility that there may be a well-crafted Chinese guitar out there (or a poorly crafted Japanese one), or to the fact that the actual perpetrator of a "terror" attack might not be the person your biases have trained you to expect.