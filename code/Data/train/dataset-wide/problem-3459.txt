Mail servers are located by an record. Mailgun should provide a name for the mail server to target. I've included SPF records which you may want to include. If they provide multiple host names add more records. Some servers don't support the SPF record type, in which case SPF will use the record. 

sda is not processing I/O requests promptly. If it is not the drive, then you have an imbalance in I/O. Do you have a swap partition on sda? If so you could have memory issues resulting in thrashing of memory pages in and out of swap. Make sure you have swap space allocate on both drives at the same priority. The program sar may be helpful. 

Default MTU is 1500 which is the maximum value usable on the Internet. Smaller values may be required when tunneling traffic. Most traffic will be fragmented and reassembled it it exceeds the maximum available MTU on the link. Only if the DNF (Do Not Fragment) option is set must the packets be less than or equal to the MTU. The local MTU sets an upper limit for the usable MTU. As most hosts have an MTU of 1500. It is a good default value to use. Some ISPs provide links using tunneling protocols like PPPOE which provide a smaller MTU. Likewise many IPv6 early adopters may be using a tunnel and may have a smaller MTU. You are most likely over thinking the problem. In the real world, you can't rely on the local MTU to determine the link's MTU. Nor can you count on it being a static value. If required packets will be fragmented and reassembled. For example block size for NFS is typically 4096, and are usually sent in fragments. 

should already be aliased to a local user-id. Configure it as above or alias it to a different user. For delivery to a relay server configure your mail server to use a smarthost, and specify the desired server as the smarthost. Typically, Debian will use or rather than . should already be configured for the above to work. I believe postfix is also configured similarly. The prefix is used internally to deliver some failure notices, and is available for other uses, such as yours. 

The advantage is that you can safely use the port. Many programs will use a pseudo-random port, or can be programmed to use a port. In either case, if you don't close the port, they may be accessible from other hosts. As Francois noted, a closed policy is safer. Begin with all ports closed and open those you need in the appropriate direction. It is common, to require services for which you don't have or want a local server. DNS is usually required, but you don't need to allow incoming requests. Several ICMP types (3,4,11) are required for proper network functionality, but others may be safely blocked. It is common to enable (8) selectively, which should enable incoming (0) messages if packets are accepted. Most firewall builders such as Shorewall, will allow the these ports in their example or default rule sets. 

Spamhaus and/or greylisting will drop most of the problem addresses. Requiring FQDN in the helo/ehlo messages will catch a lot of the rest. Dropping messages from servers which don't accept messages won't work if they also do the same. There are a number of legitimate senders who don't accept bounce messages after the fact. Bounce the message during the connection not afterwards or you will contribute to SPAM through backscatter. DNS and rDNS need to agree for your server. If your address is listed as dynamic at Spamhaus, you will be refused by a large number of servers, mine included. 

I run munin on my virtual clients to gather this kind of information. Information is gathered every 5 minutes and available in graphical format via rrd. Data is available via http from my munin server. 

Consider setting up DMARC with a reporting address so you can determine if you could set a policy. You will get reports on how well you are following your policy and failure rates. Use a disposition until the only failure reports you get are for email that does not originate from your domain. Don't set your SPF policy to until you are sure you have listed all the valid senders in your SPF record. 

Try the following commands to determine if you have a lot of connections coming from one address or if you are under a distributed attack. 

A signature from the sender's domain is most reliable, and may be required by the sender's email policies. With the introduction of it is now possible for domains to publish a policy with desired actions for email which does not meet the policy. is intended to match the sender from the header, which may not be the envelope sender. validates the permission of the envelope sender to send mail for the domain using the sending server. ties the two together, to provide a better policy framework. All three mechanisms require data to be published in the DNS tree of the domain involved. from a third party merely indicates whether or not the signed content has been modified after signing by that domains. This may be useful for repudiation, but not for sender reputation. 

The first listed host depends on the order the configuration is loaded. Different distributions have different mechanisms for loading the files. On Ubuntu, sites should be defined in . These are enabled by creating a link in . The enabled sites are loaded in canonical order from that directory. Files in that are not linked to are not loaded. The configuration loads files from and are loaded prior to loading sites from . If you enable the info module, you should be able to review the configuration by navigating to . Check the order of the virtual hosts on this page. It is also possible to place Redirects in file located in the document directory. It is also possible to place redirection directives inside containers other than a container. You may want to verify which redirections are occurring by dumping the server headers. I use a command like . This will show the headers from each redirection. 

In your case, the ProxyServer would be your Debian server. I have setup clients using keys to open tunnels with PuTTY. It wasn't that difficult. 

I believe you only need on rule in the tables as well as an accept rule. Add you or to the first rule. 

I highly recommend implementing SPF and related policies so that you can use a strict policy. You can also use BATV (Bounce Address Tag Verification) to sign the envelope from address on outgoing messages. My article on Signing Return Path Addresses with Exim describes how I implemented. Once you have this running for a couple of weeks you can start identifying faked bounce messages with ease. 

You can get more detail from a script run from , or included in . However, this will only work if the user logs in to an interactive session. If you don't need immediate notification, the program can notify you hourly of any accesses in the last hour. You will need to add appropriate rules to the configuration. EDIT: Ubuntu uses the incompatible format to execute shell commands. The follow rule is what I implemented: 

GDM has problems with XDMCP. I had it working before upgrading to Lucid, but it is now broken. I was unable to find a solution. I went with a split implementation using both XDM for XDMCP logins and GDM for my console. My post on Remote Desktops with VNC and RDP details how I made it work. I have been using RDP most of the time as it handles different resolutions more easily. 

Basically this is the final delivery router with the transport changed and check_local_user removed. Test before using. 

You likely have a rule to accept connections. To reset active connections, temporarily place a reject rule for SSH above that in the chain. Remove it once the connections have dropped. If you are accessing the server remotely, open an alternate SSH port to connect while you are doing this. Otherwise you may kill your connection. 

You can add the email notification to accept rules as well. If you don't want the notifications, you can remove them. If your service does not log accesses, you can use a similar rule to log access by sending a message to the log daemon. 

Choose a domain name for your mail server. The MX record should point to the FQDN (Fully Qualified Dommain Name) of the mail server, such as . All domains should use this FQDN in their MX. Use a priority higher than 1 so that you can add servers with both higher and lower priority. Something like: 

I would only do this on a development server in a secured environment. Many PHP applications will generate the file to the screen so that it can be copied safely to the configuration directory. The quick (and insecure) way to do this is to execute from the directory where the file should go. Before doing this run to get the permissions you will be setting them back to. In some cases the required directory will not exist, so you will need to create it first. Immediately after the configuration file has been written, reset the directory to its original permissions. The correct command is likely or run from the directory. Verify with the ls command. Change the permissions on the configuration file so that Apache can no longer write to it (). Applications often come with example configuration files. Placing one of these in the configuration directory and editing may be a better approach. This requires that you learn and understand the configuration options. You may be able to use the online configuration script to assist your edits. 

If you are configured for only HTTP to your proxy, then you loose the advantage of encryption. SSL Labs and the browsers will notice. You can install the same certificates on the proxy as you have on your servers. This will take more management. If the proxy is serving multiple certificates on the same IP address and port, then only browsers which support SNI will always get the correct certificate. The most important leg is to have SSL between the browser and your proxy. This means you will need to install one or more certificates on your proxy (nginx). That will retain your rating with SSL Labs and the browsers. Between your proxy and your servers you have a couple of options. You can use HTTPS to the server, which requires additional certificate installation. These can be be self signed. Self-signed certificates make it easier to ensure traffic is only arriving from your proxy or another internal source. If you connect from the proxy to the servers using HTTP, you will need to inform your servers the connection arrived on a secure channel. Many web containers can be configure to use a cookie to determine if the connection arrived to your network securely. If you choose this route, strip the cookie at the proxy (at least for HTTP) connections and add it back in. If your servers don't believe the connection is secure, they won't accept secure-only cookies. Likewise, if the browser connection is not HTTPS, they won't send secure-only cookies. Any login tokens should be using secure-only cookies Running HTTP only in the data center is simpler, and is as secure as your internal infrastructure. People working in the data center will be able to sniff traffic relatively easily. You can mix HTTP for lower security needs, and HTTPS for higher security needs. The proxy does add another location where a man-in-the-middle attach can be launched. Keep it secure.