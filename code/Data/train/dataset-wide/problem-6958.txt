High poverty rates are generally a result of two factors A) Low per capita income (GDP / capita) B) High inequality (frequently measured as the Gini coefficient) There are multiple potential reasons for any country's income level and degree of inequality (not just for Mexico's). Moreover, one can decompose your question into two. 1) What makes some countries (in general) richer than others? 2) Is Mexico poorer because of some Mexico-specific factors? The answer to the first question is kind of the Holy Grail of empirical economics, and if any single economist had been able to answer that he would have definitely won a Nobel prize. The consensus view is that there are different factors contributing to cross-country differences in income. Literacy and education, which you mentioned (and which fit into the economists' definition of Human Capital) are mostly likely a key factor. However, another one which appears to be particularly important to Mexico's case is the quality of a country's economic and political institutions. See below a highly recommended reading from an economist who's likely to win a Nobel for growth theory, which in his very readable book frequently uses Mexico as a case-in-point for his theory. $URL$ 

I apologize if this question is very basic. I have the following plain vanilla Instrumental Variable model. $Y=\alpha+X\beta+\varepsilon$ $X=\delta+Z\gamma+\eta$ $\varepsilon\perp\eta,\quad Z\perp\eta \quad$ true I am interested in testing $\varepsilon\perp X$, that is, whether X is a valid instrument for the first equation (very informally stated, one might say I want to test whether $X$ is exogenous, or whether I need to instrument $X$ with $Z$) My idea is: estimate the IV model using 2SLS or GMM, using both $X$ and $Z$ as instruments, and then perform a Sargan/Hansen test. My guess is that the test's power will depend on how strongly $Z$ predictx $X$ (that is, on how relevant of an instrument $Z$ is for $X$). In 2SLS, the first stage will fit perfectly and the test will be basically a test of whether the OLS residual are orthogonal to $Z$. Is this reasoning correct? Is the Sargan/Hansen test a valid test for $ \varepsilon\perp X$? 

The microstructure noise is, roughly speaking, the small-scale noise introduced into the market as a result of the way the market is designed. For example, suppose that there is an asset and the "real" price for this, is 126.6. That is, if we magically knew everyone's honest, perfect maximum buy and minimum sell prices and could match them off and arrive at the equilibrium price, then it would be 126.6. However, imagine that the market only quotes in whole numbers. That means you can either buy at 127 or sell at 126, but it is physically impossible to trade at 126.6. Intuitively we expect to see a sequence of trades switching between 126 and 127. This is called "bid ask bounce" and is perhaps the simplest example of microstructure. Even with such a trivial example, we can start to do interesting things. For example, since the price is closer to 127 than 126, we might expect to see more 127s than 126s. We could use a simple logit function or something to select the probability the next tick is on the near or far side. Also we can "what-if" the market has a different tick size? Clearly we expect in our model the bid ask bounce to reduce. In our example the latent price is a constant, but that is not very realistic. For a better model one would usually assume some dynamic model for this hidden price process. Perhaps Brownian motion, for example. Now you can see how with our model from above, we will see trade prices bouncing either side of our hidden price. As the price gets closer to a whole number, more trades are done on that, until it crosses and then we start seeing trades on the next tick along. As you can imagine, you can continue to play this game, making the latent price process more complex, and adding more complex microstructure models to generate the trades around that price. And all along we have assumed independence of latent price and microstructure noise. That is to say, our microstructure process does not impact the latent price, and the microstructure process stays the same, regardless of what the price is doing. This is a useful assumption to make, since it separates the problem out - without it you probably wouldn't be able to solve much and the usefulness may be limited. That said, it is easy enough to think up possible models that would break this: e.g. 

1) I think it is not legal. Coins are produced by single countries; in theory Greece could destroy her own coins, but in Greece you may find not only Greek coins, but also coins from other EU countries, what do you do with this coins? 2) Paper bills are produced by the BCE, which --if I am not wrong-- has the property of these bills. This is the same in most of the countries: central banks have the property of the bills. (this is linked to the previous point, do central banks from single countries have the property of the coins they produce? if yes, can you destroy these coins?) 3) There could be retaliations of some kind. It is an act that would acquire potent meanings, that go beyond the simple material act of destroying coins and bills; Greece would destroy a symbol of the EU, which only a few years ago got the Nobel prize for peace. Sure, the "Euros destruction" would be charged with political negative meanings (e.g., Greeks reckless people enemies of the peace). In conclusion, this solution is out of the realm of the possible things to do for Greece. What I think that they advocate is not actually destruction of the euros, but their conversion. People would have to go to banks and convert the euros into drachmas. So, they would not destroy their own cash, but only convert into a new currency, like they did when they converted drachmas into euros some years ago. But I see that ultimately the question would be similar to your original one. What could single banks do with the collected euros? Can they destroy it or put it back into the foreign market or use it as a currency reserve for trades with countries that still use the euros. 

What do you think about this new re-scaled variables? Could this solution be considered data manipulation in bad sense? (like, am I inventing data and get results that do not reflect reality?) I am using the sharp RDD, is this appropriate? If sharp RDD is appropriate, should I use also the fuzzy RDD as robustness check? (As robustness checks I already use different tools, as proposed here)