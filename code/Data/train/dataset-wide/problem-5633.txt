Quote from: Chalmers, David J (2003) "Consciousness and its Place in Nature" in Stephen P. Stich and Ted A. Warfield (eds.), The Blackwell Guide to Philosophy of Mind, Blackwell Pubishing, Malden, pp. 102-142 

"subjected by reflection" I think means that the state of belonging in all things to an abstraction is caused by reflection (theoretical thinking). I don't think there's any philosophical import there... just the usual sense of the word "subjected". On "reflection", I got the sense in Kierkegaard that the concept is simple, but it's hard to discern because we're so embedded in that mode of thinking, rather than "reflection" in itself being a complicated concept. 

I think Cavell's criticism can be readily applied to this question. How much of philosophy is wisdom, and how much of it is an aversion to ordinary categories - a sense that, like physics, human understanding can and must be broken down to atoms and its boundaries and mechanisms worked out for us not to be made fools - fools to religion, fools to superstition, fools to ignorance? We're driven to dissect, and by dissecting we kill it. Ever noticed how whenever you hear "philosophy of", the meaning of the noun that follows tends to disappear into obscurity? Epistemology is a rumination on knowledge by one struggling to, but never genuinely succeeding in, overcoming a denial of knowledge. The quote is from Stanly Cavell's essay "Must we mean what we say?" 

Quantum mechanics goes a lot further than what is often represented. It implies that there might not be properties at all (no reality, as we know it), independent of a measurement event. The measurement event is not just a physical interaction (that results in just another entangled state). Einstein, Podolsky and Rosen (EPR) wrote a paper that came to be known as the EPR paradox. It was based on a thought experiment around the entanglement, separation and then measurement of a property of a pair of particles. EPR pointed out that the theory implied that a measurement on one particle had an instantaneous effect on the distant particle. Einstein argued that god does not play dice or use telepathic methods... his argument was that there must be something wrong with quantum theory, as it seemed to imply that one has to give up either or both 1. reality or 2. locality. That can't be right, they argued. So quantum theory, it was suggested, must be incomplete. It mustn't contain all the variables. There must be some hidden variables that explained how there seemed to be instantaneous action at a distance or non reality. These "hidden variable" theories were first tested with John Bell's theorem (Bell inequalities) . Using entangled pairs of spin 1/2 particles, Bell devised an experiment. By measuring the spin on these entangled pairs of particles at varying angles, the hidden variable theories predicted a different statistical outcome than the quantum mechanical theories. Numerous experiments appear to confirm quantum mechanics. Consensus has been to preserve reality, but lean towards entanglement.. that faster than light influence is possible. But something else I read today suggests a more recent theorem and corresponding experiments which implies that the assumption of reality is problematic as well. Physicsworld.com cites the journal Nature as the source for the statement: 

I always assumed that those numbers were to be approximated as well as possible -- short of coming up with a machine for measuring Intensity of pleasure and pain, how else could we know? I think this is evidenced by the fact that the equations typically used for a hedonistic calculus are a. always symbolic and b. never quite right. For example, I tend to see that intensity should be multiplied by duration, when anybody who understands basic calculus understands that it must, rather, be integrated over time. I don't think the development of the calculus serves as anything more than a thought experiment -- "here's how you should think about ethics. Think of ethics as an equation, a mathematical function that spits out a 'do X' or a 'do not do X.'" The details of the equation are only there to show you that such an equation can take many details into account, and appear quite valid on its face -- it does not seem that it is for actual use. 

I personally define art as any attempt to be understood. The value of art -- I suppose, the quality -- may be some function of 

War is a political concept. War is something that a country does when its constitution says "this is the set of conditions under which a war happens." There might be things that don't fit that technical definition, but are practically similar to wars. You might call those wars, or "armed conflicts," or whatever... But the basic idea of war is just that it's a construct of how countries interact with one another. You might say that, for some countries, one individual leader has the authority to declare war, but that would only be as a function of the country's processes. You can ask whether it's my brain or heart that thinks (obviously, my brain), but if you're asking whether I'm thinking, yes, I am. So if a subset of the country is given authority to declare war on the country's behalf, the country has declared war. To be clear, in the United States, no one person can ever declare war. Only congress can declare war, and that involves many people. You might also ask whether I, as an ordinary citizen and civilian, am a party to that war, or am morally responsible for the war. But the country definitely declared the war, and went to war. 

All arguments which turn on observations of some regularity (i.e. appeals to the outside world) and projects them into the future are going to be inductive in nature. When you say "any alternative method", I still think you're thinking of induction - you're thinking of past observations of the world projected into the future. If an argument is made using deduction, it is qualitatively different from an inductive argument. Deductive arguments turn on definitions and what is, and as long as you know what the words mean and what is, you can judge the validity of the argument. Induction seems to require one to accept without any other assurance that what happened today will also happen tomorrow. Induction as a problem I think catches people's attention because it seems to mirror the scientific method (observations of the world), but it seems invalid! I've been a bit perplexed about the "problem" of induction. To me, when we make a statement saying that all swans are white, we're not so much making a statement about the world, as we are making a statement about our (my personal view, or the collective wisdom on the matter) understanding of the concept "swan". When we actually find a black swan, we update our notes on the concept "swan". If there actually is a black swan, but nobody has seen it, and therefore the concept "swan" still allows no black members, then the statement "all swans are white" is true, as long as we acknowledge that by "swan" we mean our concept "swan" - which is what I think we are doing when we're speaking: we're weaving together our concepts, not weaving together entities in the world. So we find a black swan, and we update our concept of swans. Before we found a black swan, all swans were white - I would call that true. After we found a black swan, swans are either black or white - I would call that true too. I don't think there's a contradiction there, nor do I think there's some inductive 'leap' going on. 

You have to ask, given your understanding of sociology and given how well you've otherwise arranged society, what the likelihood is that the mass surveillance will be abused at the expense of those worst off. Then, you have to consider what the benefit will be to those worst off. Imagine this from such a perspective, and make the "selfish" choice. Personally, I feel that some version of effective encryption will, from this point forward, always be necessary, even in the most ideal society one can realistically imagine. Until we reach such an ideal society, I think the US Constitution provides pretty good approximations of the boundary line, and that the current extent of US surveillance is unconstitutional. I particularly feel that metadata is more sensitive than judges have yet understood. But, that's all me answering the question as a realist, and I think of Rawlsian philosophy as an idealistic one... I'm not sure how much more surveillance I would abide in a more ideal world, but I think it would be more. 

I personally define Art as any attempt to be understood. This reflects essentially all writing, rhetoric, painting, and the like. Some of those things involve sentiment, and some do not. An attempt to be understood which does not involve sentiment might include a passage in a math textbook, or a scientific paper (depending on what you consider sentiment to be, and what threshold level of it is relevant). Personally, I feel that expressing a mathematical truth in such a way that it can be understood is art, whether there is sentiment in it or not. Euler's Formula is a rather beautiful piece of art, I would say, and the derivations I have seen inspire me in much the same way as other art does. Your question hinges on how you define art. If you would like a cold mathematical textbook with no sentiment in it to qualify as art, as I do, the answer to your question is "no." If you would not like to consider that art, the answer seems to be "yes," but we still need a definition to see if we can falsify the premise. Try not to use the word "sentiment" in your definition. 

Does the assumption that all "knowledge" must fall neatly into one or other of the two categories of rationalism and empiricism, actually hold up? Or are they the wrong tools? Aren't the right tools the full richness of everyday language? To quote Stanley Cavell: 

I get the sense that the later Wittgenstein and the ordinary language philosophers are of this school. They're not designing litmus tests of dreaming (private language), or "proving" that the fact of language means that we cant be dreaming, but to reveal those questions as absurd, and to bring us back to a position where thoughts of skepticism about other minds etc don't arise. The quotes are taken from a pseudonymous work of his, Concluding Unscientific Postscript, extract from Kierkegaard, Søren. The Essential Kierkegaard. Edited by Howard Vincent Hong and Edna Hatlestad Hong. Princeton, N.J.: Princeton University Press, 2000. pp. 221-222 

I took a class in Kierkegaard and it was represented that Kierkegaard's use of pseudonyms was highly significant. Either he meant what he said, or he was being ironic, or something else entirely. Is there an academic consensus forming around the meaning behind the pseudonyms, or were the pseudonyms just something people did in those times, and we can take the pseudonymous writings as though they were signed by Kierkegaard himself? 

But "reality" here is meant as the kind of reality we can understand - the reality of observables. Physics does postulate that something behind that might be said to "exist" - the wavefunction. But the use of the word "exist" in this context is problematic. I mean, we can kind of conceptualise Schrodinger's cat... but that's not supposed to teach us about cats, but rather get us thinking about the kind of thing the cat is entangled with. What is it? We cant seem to ascribe reality to it. And at that point, I think it's kind of wide open. You could think of it as Kant's noumenon. Might as well say it's calculations in the mind of god. Or you can just leave it as the wavefunction. Could even call it nothing. It's all equally non-sense, in a way. So I think modern physics can be seen to reinforce Berkeley's idealism, not undermine it. Where Newtonian physics seemed to close a lot of doors, quantum physics seems to open them.... and at those extremities, one is so lost.. the choice of how to view existence seems more an aesthetic choice than a scientific one... and maybe an aesthetic choice at the boundaries can be said to be a religious one. 

If you think you're the smartest person, then that's one way to know you've made a logic error. Kidding. Socrates famously was the smartest person because claimed to know nothing. I read yesterday (sometimes I don't notice the obvious) that rational starts with ratio. Maybe being rational is all about weighing different probabilities, and keeping some balance, rather than making claims with 100% certainty. But you asked about logic errors, which could be different if only concerned with the validity of logic. Not rationality, per se. In that case, the smartest person should encode their logic in a computer program and see if it compiles and executes properly. Far more reliable than human minds. In the realm of pure logic anyways. 

The primary downfall of contemporary philosophy is that it takes one of two positions, reality is observer-dependent or reality is observer-independent. The shared assumption is there is one type of real, one level of existence, one way of being. Our experiences and sensations are undeniably real, and so are the physical objects around us. But they are just the relative reality, just shadows on a cave wall, that exist because of a deeper reality. This has been true from Plato to Everett. 

Contemporary notable philosophers? Nope. But Barbour is certainly the closest. Leibniz, Kant, Newton, Spinoza, Einstein, Schopenhauer, and many others certainly had a far more complete view than the notable philosphers today do. They all had notions of relative time existing because of absolute time. Here again is Newton's definitions: $URL$ Today we argue whether time is this or that. Fundamental understanding is about why this and that (at two different levels of reality). 

This is a start: $URL$ Think of it like this. You think everything is pretty obvious, you live in your town in your country on Earth with other people and there's a Sun and a Moon and stars and video games and stack exchange. And that's reality. One day, while meditating you realize all of that seems to be some kind of illusion. There is an Ultimate reality that's real. Those are the two extremes. The middle way is to deny neither. We have our relative reality and we know it's based on absolute reality.