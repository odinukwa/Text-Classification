The short answer is that waves that are "in the apparatus" are indeed stretched. However the "fresh waves" being produced by the laser are not. So long as the "new" waves spend much less time in the interferometer than it takes to expand them (which takes roughly 1/gravitational wave frequency), then the effect you are talking about can be neglected. Details: There is an apparent paradox: you can think about the detection in two ways. On the one hand you can imagine that the lengths of the detector arms change and that the round-trip travel time of a light beam is subsequently changed and so the difference in the time-of-arrival of wavecrests translates into a phase difference that is detected in the interferometer. On the other hand you have the analogy to the expansion of the universe - if the arm length is changed, then isn't the wavelength of the light changed by exactly the same factor and so there can be no change in the phase difference? I guess this latter is your question. Well clearly, the detector works so there must be a problem with the second interpretation. There is an excellent discussion of this by Saulson 1997, from which I give a summary. Interpretation 1: If the two arms are in the $x$ and $y$ directions and the incoming wave the $z$ direction, then the metric due to the wave can be written $$ds^2 = -c^2 dt^2 + (1+ h(t))dx^2 + (1-h(t))dy^2,$$ where $h(t)$ is the strain of the gravitational wave. For light travelling on geodesic paths the metric interval $ds^2=0$, this means that (considering only the arm aligned along the x-axis for a moment) $$c dt = \sqrt{(1 + h(t))}dx \simeq (1 + \frac{1}{2}h(t))dx$$ The time taken to travel the path is therefore increased to $$\tau_+ = \int dt = \frac{1}{c}\int (1 + \frac{1}{2}h(t))dx$$ If the original arm is of length $L$ and the perturbed arm length is $L(1+h/2)$, then the time difference for a photon to make the round trip along each arm is $$ \Delta \tau = \tau_+ - \tau_- \simeq \frac{2L}{c}h(t)$$ leading to a phase difference in the signals of $$\Delta \phi = \frac{4\pi L}{\lambda} h(t)$$ Interpretation 2: In analogy with the expansion of the universe, the gravitational wave does change the wavelength of light in each arm of the experiment. However, only the waves that are in the apparatus as the gravitational wave passes through can be affected. Suppose that $h(t)$ is a step function so that the arm changes length from $L$ to $L+h(0)/2$ instantaneously. The waves that are just arriving back at the detector will be unaffected by this change, but subsequent wavecrests will have had successively further to travel and so there is a phase lag that builds up gradually to the value defined above in interpretation 1. The time taken for the phase lag to build up will be $2L/c$. But then what about the waves that enter the apparatus later? For those, the laser frequency is unchanged and as the speed of light is constant, then the wavelength is unchanged. These waves travel in a lengthened arm and therefore experience a phase lag exactly equivalent to interpretation 1. In practice, the "buildup time" for the phase lag is short compared with the reciprocal of the frequency of the gravitational waves. For example the LIGO path length is about 300 km, so the "build up time" would be 0.002 s compared with the reciprocal of the $\sim 100$ Hz signal of 0.01 s and so is relatively unimportant when interpreting the signal. 

This is really a computing problem, but I suppose the only point from an astronomical perspective is what the RA, Dec distributions of your catalogues look like. I'm not that familiar with optimal search techniques but I guess that you want roughly similar numbers of stars in each region. If your catalogue is just of the brightest stars, then these are fairly uniformly distributed around the sky, so splitting them up in equal bands of right ascension would probably do. However, if you are dealing with much larger catalogues then there is likely to be a significant concentration towards the galactic plane. In these circumstance you might be better off splitting your regions in terms of their galactic latitude. So you would calculate galactic coordinates by transforming the RA, Dec and then plot the distribution of number of stars versus galactic latitude to see where you would split your regions. 

The key formula for signal-to-noise calculations in photometry can be written as something like $${\rm SNR} = \frac{S_{\rm star}}{\sqrt{S_{\rm star} + S_{\rm sky} + \sigma_R^{2}}},$$ where $S_{\rm star}$ is the photons counted from your target star, $S_{\rm sky}$ is the amount of unrelated photons in your photometry aperture (due to sky or other stars) and $\sigma_R$ is the readout noise in your detector. The numerator is of course your (interesting) signal and the denominator is the noise. The reason the noise terms are added in the way they are is that each term inside the square root is a variance. i.e. The variance of the detected signal from the star is equal to the number of detected photons (a property of Poissonian counting statistics). Now for more complexity we can express the signals as being photons per unit time (I'll use a small $s$ for these), such that $S_{\rm star} = s_{\rm star} t$, where $t$ is the integration time. $${\rm SNR} = \frac{s_{\rm star} t}{\sqrt{s_{\rm star}t + s_{\rm sky}t + \sigma_R^{2}}},$$ Now the thing defined as $\sigma$ in your plots is the inverse of the SNR, plotted on a logarithmic axis. $$\sigma = (s_{\rm star }t)^{-1}\sqrt{s_{\rm star}t + s_{\rm sky}t + \sigma_R^{2}} $$ $$\log \sigma = -\log s_{\rm star} -\log t +0.5 \log(s_{\rm star}t + s_{\rm sky}t + \sigma_R^{2})\ \ \ (1)$$ This is being plotted against the $I$ magnitude, which is proportional to $-2.5\log s_{\rm star}$. So if we now look at each of these contributions individually, we see that the noise due to "shot noise" on the star should indeed be a straight line on your plot. From eqn (1), ignoring other sources of noise $$ \log \sigma = -0.5\log s_{\rm star} -0.5\log t$$ Thus in units of parts per million and scaled for the square root of the exposure time, this will appear as a straight line in a log-log plot with gradient of $-0.5/-2.5=+0.2$. Now just look at the contribution due to the sky background, from eqn (1), ignoring other sources of noise $$\log \sigma = -\log s_{\rm star} + 0.5 \log s_{\rm sky} -0.5 \log t$$ So the gradient here is -1 in log space (the sky term is just a constant offset in the log-log plot) and +0.4 in terms of (log) ppm/magnitude. Hence the gradient due to the sky noise term is twice as steep. Finally, looking at the readout noise contribution $$\log \sigma = -\log s_{\rm star} + \log \sigma_{R} -\log t$$ Therefore this has the same gradient as the sky contribution (as you can see in the plot), but the offset in the log-log plot should depend on the exposure time. This makes sense because the brightness at which readout noise will dominate does depend on how long the exposure is. So there is some unspoken (at least in the caption you show) assumption about how long the exposure time is in order to place the contribution from readout noise on the same graph, although the gradient is understood. 

Some galaxy clusters do have global rotation or line of sight velocity gradients, probably as a result of previous mergers. Evidence for this comes from an analysis of the positions and redshifts of the constituent galaxies (Hwang & Lee 2007). In principle one could look for similar signatures in X-rays from the hot intracluster medium, but the technology is still lacking (Bianconi et. al. 2013). The most recent survey I could find is that of Manolopolou & Plionis (2017) using SDSS DR10 data. Abell 1689 is not on their list. According to earlier studies (e.g. Lokas et al. 2006), the velocity structure of this cluster is complex, with multiple structures along the line of sight. The similarity of the cluster gravitational potential inferred from gravitational lensing and from X-ray emitting gas under the assumption of hydrostatic equilibrium suggests contributions from rotation or turbulence in the intracluster medium are small (Tchernin et all. 2015). 

The current ideas are that both terrestrial planets and giant planets start their formation in a similar manner. Dust settles towards the mid-plane of a predominantly gaseous disk, starts to stick together and eventually small (km-sized) planetesimals are formed. This process may be quicker in the outer parts of the solar systems where the gas is colder and the condensed material (ices) is probably "stickier". The planetesimals then interact with each other gravitationally and can grow by merger. The rate of growth is controlled by their spatial densities and their relative velocities, but is thought to occur quite quickly in both the inner and outer parts of the solar system ($\sim$ 1-3 million years, e.g. Righter & O'Brien 2011). Thereafter, the inner and outer parts of the solar system differ. The gas is cold enough in the outer parts of the solar system to accrete onto rocky cores and build giant planets on timescales of another few million years. In the inner solar system the gas is too hot to be accreted and instread the next tens of millions of years are characterised by high velocity collisions between planetary embryos and planetesimals. This indeed may be sculpted and influenced by the early migration inwards of Jupiter to about 1.5 au, followed by migration outwards - the so-called "Grand Tack model" (Raymond & Morbidelli 2014). Overall it probably takes the inner solar system and terrestrial planets of order 100 million years to settle down into its final configuration. The collision that formed the moon may have been several tens of millions of years after the formation of the Sun and certainly long after the giant planets formed. 

It is generally thought that Jupiter "formed" first via the core accretion process. An icy core forms first and then sweeps up the gas around it. This process is generally thought to take from a few million to ten million years. After that, the solar system gas was dissipated and Jupiter was basically as it is today, but larger and hotter. Earth formed on a longer timescale in the maelstrom of rocky planetesimals that made up the inner solar system. An essential part of the process was the collision that formed the moon, which probably occurred between 30 and 60 million years after the protosun began to form. Further heavy bombardment of the Earth that may have significantly changed its surface and atmosphere continued for some tens of millions of years after that. The wikipedia page on planet formation in the solar system looks ok to me $URL$ I may add dome more academic references subsequently.