To see how the estimated rows decrease as we approach the RANGE_HI_KEY, I collected samples throughout the step. The decrease is linear, but behaves as if a number of rows equal to the AVG_RANGE_ROWS value just isn't part of the trend...until you hit the RANGE_HI_KEY and suddenly they drop like uncollected debt written off. You can see it in the sample data, especially in the graph. 

The formula for estimating rows gets a little goofy when the filter is "greater than" or "less than", but it is a number you can arrive at. The Numbers Using step 193, here are the relevant numbers: RANGE_ROWS = 6624 EQ_ROWS = 16 AVG_RANGE_ROWS = 16.1956 RANGE_HI_KEY from the previous step = 1999-10-13 10:47:38.550 RANGE_HI_KEY from the current step = 1999-10-13 10:51:19.317 Value from the WHERE clause = 1999-10-13 10:48:38.550 The Formula 1) Find the ms between the two range hi keys The result is 220767 ms. 2) Adjust the number of rows We need to find the rows per millisecond, but before we do, we have to subtract the AVG_RANGE_ROWS from the RANGE_ROWS: 6624 - 16.1956 = 6607.8044 rows 3) Calculate the rows per ms with the adjusted number of rows: 6607.8044 rows/220767 ms = .0299311 rows per ms 4) Calculate the ms between the value from the WHERE clause and the current step RANGE_HI_KEY 

The complete list of characters in need of a special treatment is at the above link. However, it is best to have the intermediate language deal with such problems. For instance, in PHP you would call ; other platforms and languages provide similar facilities. 

(Edited to be consistent with new version of question) You cannot if you want to single elements of the lists which make up the field. You have to disaggregate those lists in a subselect: 

which outputs the SQL definition of the table or view, even with the original comments (exactly the same as , with less typing. works too.) 

To shut down the Report Manager web portal, open up the RSReportServer.config file. This is located in the install directory (usually C:\Program Files\Microsoft SQL Server\[Instance Name]\Reporting Services\ReportServer). Under the element, there will be several elements that begin with "Is". These control which services/functions are enabled. The last entry will be . 

I expect with a single call to each source table (AdWordsData and WebSkuLookup), this will shave the execution time down quite a bit more. 

Note: I can't tell what date type is, but be careful to account for exact matches. Because there aren't any or in the ranges, exact matches may be unaccounted for if the date type isn't DATE. By creating a multiplier column, we can make just one trip to get the source data and do the work from there. Try using this as your view definition: 

To resume the situation for people who don’t want to follow the link to the original question on SO: the OP is querying a Mysql DB via an unspecified interface which (sensibly) refuses to show the values stored in fields with encrypted data, and (rather dumb-mindedly) still shows a label for the value returned by calling on them. The answer given on SO was to cast those results as , which from a DB perspective makes little sense, but in this way the interface shows the results as text and everybody is happy. The question here is: if I have to use , how can I handle longer values? My answer is: you don’t say which interface you are using (your screenshots are not enough for me to recognize it), but I’d bet that if you cast as instead of it still works and you have no size limits that you should care of. So: 

It looks like this query is making a lot more round trips than it needs to. Whenever you have multiple select statements bound together by UNION, you can look for ways to consolidate down to a single query. If I'm reading correctly, the date ranges in the WHERE clause are conveniently exclusive of each other yet inclusive of all possible dates. These date ranges are linked to a multiplier: 

Change this value from True to False. Save the file and close. Some changes to RSReportServer.config require a service restart, so you may have to restart the RS service to get this change to stick. Once it does, the RS service will no longer respond to requests to the Report Manager portal but the separate web service that processes report requests will continue running. You can read more about RSReportServer.config and switching individual services on/off here: $URL$ 

Having such junction table might improve performance, and it allows creating indexes. If the junction data is dynamic in such a way that keeping a junction table in sync is too difficult (a very unusual situation, I’d say), we can avoid the junction table but, at the very least, using instead of arrays is way simpler: 

You should read about string literals in MySQL. There you’ll learn that a backslash character is used to escape some special strings, and to have literal backslashes in your strings (as in Windows pathnames), you have to double them: 

Note the steady decline in rows until we hit the RANGE_HI_KEY and then BOOM that last AVG_RANGE_ROWS chunk is suddenly subtracted. It's easy to spot in a graph, too. 

To take the Reporting Services databases out of commission on this server without disrupting the service itself, you'll need to point the service to databases elsewhere. To do this, open Reporting Services Configuration Manager on the server running the RS service, and change the "Database Name" entry in the Database menu page: 

To sum up, the odd treatment of AVG_RANGE_ROWS makes calculating row estimates more complex, but you can always reconcile what the CE is doing. What about Exponential Backoff? Exponential Backoff is the method the new (as of SQL Server 2014) Cardinality Estimator uses to get better estimates when using multiple single-column stats. Since this question was about one single-column stat, it doesn't involve the EB formula. 

The safest way is to define product_id's with the finest reasonable granularity, to the point that if you decide to sell half the stock at a discounted price, you should define a new product_id for the items in promotion, all things being equal but the price. In this way you will manage to balance sales and returns without too many corrections. So I basically agree with blobbles's answer. You will have many ways to group your products together, e.g. same name, same size, same producer, same provider, and so on, and you will do that in separate tables associating the product_id with those features. 

This gives us 160767 ms. 5) Calculate the rows in this step based on rows per second: .0299311 rows/ms * 160767 ms = 4811.9332 rows 6) Remember how we subtracted the AVG_RANGE_ROWS earlier? Time to add them back. Now that we're done calculating numbers related to rows per second, we can safely add the EQ_ROWS too: 4811.9332 + 16.1956 + 16 = 4844.1288 Rounded up, that's our 4844.13 estimate. Testing the formula I couldn't find any articles or blog posts on why the AVG_RANGE_ROWS gets subtracted out before the rows per ms are calculated. I was able to confirm they are accounted for in the estimate, but only at the last millisecond -- literally. Using the WideWorldImporters database, I did some incremental testing and found the decrease in row estimates to be linear until the end of the step, where 1x AVG_RANGE_ROWS is suddenly accounted for. Here's my sample query: