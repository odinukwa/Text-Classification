You're right, defining the physical properly is not an easy task. There are two types of approaches: you can start a priori by assuming some defining characterisics -- among the various propositions, being located in space-time, having only objective properties independent from the mental, being structural or amenable to mathematical description, being constituted by ponctual entities... The risk with this approach is ending up assuming that what physicists study is not physical after all. Many past intuitions on the physical are now known to be false (fundamental particles are not perfectly localised or impenetrable, their evolution is not strictly predictable, ...). Or you can define the physical a posteriori: the physical is whatever physicists say it is, or whatever an ideal physics would say it is. The problem is: in the first case, your conception will be superseded as soon as new theories are discovered. In the second case, your conception might render physicalism vacuous. Of course everything is physical if "physical" is everything that is addressed by an ideal "theory of everything". This conception is not very informative. Or perhaps you have to say more about what theorising is about and what is admissible in physics (then you introduce some a priori characterisics). I suppose the argument you develop in your question is directed against this brand of physicalism, which seems not far from a vacuous position. Although no approach is devoid of difficulties, there are arguments on each side and attempts to overcome these difficulties. You'll find an interesting, open access book chapter on the topic (from which I took my inspiration) for more detail and counterarguments on each sides: $URL$ (chapter 3) 

One formal difference is this: in the case of explicit definition, the term can be replaced by its definition in every occurrence without any change in meaning (think of bachelor and unmarried man), whereas this is not possible with implicit definitions. In the context of philosophy of science, this plays a role for realists who want to argue that a term such as "mass" or "species" still refer to the same properties even when theories change (this is combined with the idea of meaning as direct reference mentioned above). One can argue that the aim of theorising is to find essential characteristics of real properties, which will take the form of revisable implicit definitions, and that a certain continuity in theories is good enough to claim that we're still "taking about the same properties". This would be more difficult to maintain if all terms were explicitly defined. More generally, if there's no explicit definition, operationalist epistemologies (the idea that the content of scientific theories strictly reduce to operations and observations) are difficult to sustain. So the consequences are quite important. 

If according to some compatibilist free will is something that makes sense in a social context (where the notions of personhood, of responsibility or of agentivity take their appropriate meaning) then this is no argument. Evolution theory does not undermine the fact that we live in organised society. The question becomes "at which point in evolution did organised societies appear?". Maybe they appeared gradually and maybe proto-societies even exist among animals. Or maybe there was a gap. But in any case it is sufficient to note that we do live in organised societies to accept that we have free will. If free will is not restricted to social contexts, a similar argument can be made: at which point it appeared in evolution, and whether it was gradual or not, is a different question that should not bother us that much. I don't think the question of determinism is related in any case. There is no problem in conceiving free will as something gradual. Perhaps, for example, an addicted person or an ignorant child has "less" free will than an educated person who is fully aware of his own personal bias and who is able to rationally control his desires, impulses, or natural tendencies. 

Your question is about metaphysical realism and skepticism. There are indeed radical sceptic arguments against realism such as Descartes's demon, brain in a vat or the idea that one is actually dreaming, but also reasons to resist these arguments. First note that there can be no empirical evidence for or against such radical scepticism because these arguments purports to undermine empirical evidences themselves (even if we could go "outside the vat" the question would remain at the higher level), so both realism and radical scepticism are dogmatic positions. The question then moves on a priori rational grounds: is it a priori rational to entertain such a radical scepticism? Some philosophers would argue that it is not. For example Wittgenstein argued that all doubts must hinge on some background knowledge otherwise it becomes meaningless: doubt occurs within the context of things undoubted (you can read "on certainty"). After all, claiming that we are brains in vats requires that "brain" and "vat" are meaningful words. Similarly Putnam argued that the idea that we are brains in vats is inconsistent because then "vat" wouldn't have the meaning we think it has ("vat" has meaning only if it refers to things external to ourselves) and this belief is self refuting. One could also provide a transcendental argument to the effect that a minimal form of realism is a prerequisite for knowledge, so that realism is a priori justified. There are also more pragmatic arguments to the effect that systematic doubts about the world would make no practical difference (whether this table is real or is a simulation makes no difference for all practical purpose). Following a pragmatic attitude, one could be a quietist: one chooses to remain silent about the question of realism or to consider it meaningless, because what matters and what is meaningful is what has practical imports. There are also arguments for realism that say that it would be a miracle that our concepts are so successful if they were not corresponding to real entities. Brain in a vat scenarios are kind of conspirational, and would need extraordinary evidence to be warranted (but they cannot have evidence by their very nature). EDIT: here is a text that defends this kind of arguments against scepticism: $URL$ All this is related to the debate on the foundations of knowledge. You can have a look at these resources: $URL$ $URL$ 

Following the general understanding of what a theory is in philosophy of science, this is quite the contrary actually: a simpler theory is more easy to falsify, and this is precisely why, if confirmed, it is more likely to be true (if one think parcimony is an indicator of truth, which is controversial). Indeed as Popper argues, a complicated theory with many parameters is easy to adjust to fit any data set. For example, you could approximate many more curves or data points with a polynomial of high degree than with a simple line. This could mean that if both fit, the polynomial of high degree is less confirmed by evidence (because, intuitively speaking, its fit was too easy to obtain) than the line. But this is merely an intuitive argument. Now Solomonoff is not so much concerned with actual scientific theories than with predictive algorithms (that produce sequences of data that match or not a given sequence). This is very unrealistic from the perspective of philosophy of science, but since your question concerns this particular framework, I would say you're mostly right that a simpler algorithm is less likely to be falsified by subsequent data. But here "simpler"means shorter algorithm, not theories that posit less entities (as"parsimony"is generally understood). I suspect the reason for this result is that Solomonoff starts from the assumption that actual data are produced by an algorithm, and a lot of algorithms will produce the same subsequent data than a simple one, whereas complex algorithms will produce "unique"data sets that are less likely to occur. This is a very specific way of weighting data probabilities (in terms of how many algorithms would produce them) which seem to me not metaphysically neutral and unrealistic with regards to what actual scientists are doing. Regarding the second aspect of your question: I would say all these are different theories indee although perhaps they could count as scientific theories as generally understood (if x and y are qualified, or at least they could count as observation laws), they don't count as theories for Solomonoff because they do not produce any sequence of data. 

One can take a scientific theory to be the best explanation of observable phenomena. Scientific laws are not located in time as facts are, so a natural law suddenly changing is a contradiction in terms. If one day the sun rises, then it's not the law that changed: we'd discover that what we thought was a law was not a law after all, but an approximation, and we'd have to find new generic principles that can account for all past and present phenomena. In any case all this is Hume's problem of induction: a generalisation can never be deduced from a finite amount of particular facts (rather particular facts are deduced from generalisations: the generalisation purports to be an explanation for the facts we observe). All we can have is credence in scientific laws. 

You're right. Here is a counter-example. Suppose T means having a very rare disease : among 1000 persons only 10 have it. Suppose S means having blond hair. (2) says that most of the 10 persons having the disease have blond hair. Imagine it's 9 persons. (3) says few of the 990 persons without the disease have blond hair. Imagine it's 99. (4) says most people with blond hair have the disease, which in this case is false: 99 don't have it, only 9 have it. Now add clause (1): most people have blond hair. Then the disease cannot be a very rare disease after all (that would be inconsistent with (3)) and (4) turns out true: (1) Most people have blond hair. Imagine 900 have blond fair, 100 don't. (3) most people without the disease are among the 100 non-blond. People without the disease cannot exceed 100 by large. Imagine it's 110 and only 20 are blond (2) most people with the disease have blond hair. This is already constrained by (1) and (3): 880 over 890. From which (4) follows as well: most people with blond hair have the disease: here 880 over 900. Obviously no counterexample will be found in this case because we started with no particular assumption. 

I'm not very sure this is always the case. Take the explanation for why a house burnt: it was made out of inflammable materials and there was a spark. These are not constituents of the fire. Or take the evolutionary explanation of why giraffes have a long neck. This involves environmental selection, which are not part of the giraffes'neck. It's even more easy to find non reductionist explanations outside of science (involving, say, God). There's a huge literature on explanations in philosophy of science. Some think that explaining is giving a causal mechanism for a phenomena. Others that it appeals to a theoretical framework that unifies the phenomena to be explained with other phenomena in a common scheme. In any case, reductionism seems to be part of the way causal mechanisms are generally presented, or a characteristic of unifying theoretical frameworks, but not specific to explanations. I would say that what gives you this impression is that most theories function this way: they unify various phenomena by analysing their constituents, or they allow one to describe mechanisms where part constituents interact. But that's a characteristic of contemporary science that is not specific to explanations in general. 

First, physicalism and naturalism are distinct positions (some naturalists accept strong emergence). Second, physics explains phenomena, but consciousness is not obviously a phenomenon. Perhaps aspects of it are (the complex behaviour of human being), but for some philosophers consciousness is not itself a phenomenon, but that which allows knowledge of phenomena: the very fact that we are aware of phenomena. This make of consciousness a peculiar object of inquiry --if an object at all: isn't it the subject of any inquiry?