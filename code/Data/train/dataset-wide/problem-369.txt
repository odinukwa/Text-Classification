If the machine can't predict the scientist's actions, then how is it simulating the results of printing that message? The procedure would seem to be as follows: 

Normal people may not care about scientific advancement, but fortunately, we don't need to rely on them, even in a democracy. In the U.S., for instance, a lot of funding comes from the National Science Foundation (NSF) and National Institutes of Health (NIH), as well as a few Department of Defense groups, e.g. DARPA. Let's take the NSF as an example. Each year, they request a budget from Congress (in 2017, it was about 0.2% of total federal spending for the NSF) and give them a high level overview of how the money will be spent and examples of the sort of impressive things NSF funding has supported in the past. But then once the NSF has its budget, qualified people decide which research grants will be supported, so even if a research project only has long-term benefits, it will still get funded if it's a promising idea. Another major source of funding comes from industry. In addition to in-house research, companies will sometimes send funding to academic researchers working on topics relevant to them. Even if they won't be the only ones to benefit from the research, they don't need to invest any time or employees into the project, so if they have the money to spare, it can be a good investment. (It also buys goodwill from potential future employees.) And finally, a base level of funding comes from the universities themselves. Undergrad tuition pays salaries, and offering solid research funding will attract good professors to the institution. The average citizen may look at something like a particle accelerator and say "That will magically create a black hole and kill us all". A congressman may look at it and say "That won't have any practical benefits before the next election". But the NSF people will look at it and think, "That may reveal information that will open up new avenues of research in 50 years" and fund it. The more short-sighted people just need to know that funding "Science" has always paid off before, so if we show them that it has, they'll keep funding it. (That came out as a bit more cynical than I intended, but if I'm being honest...) The average citizen of a democracy doesn't necessarily understand or even care about specific research projects, but as long as you have a good research infrastructure in place, they don't need to as long as they're interested in having technology continue to advance. 

Religions were made in ancient ages and earned their "success" partially by bringing two kind of answers that couldn't be found at these times, like how the world was created, how human race emerged, etc. With a 24th century technology and knowledge level, it would be hard to do the same, especially for an AI, that would be more rational than a human and would prefer have a scientific answer than anything else to a problem. However, a religion derivative that made victims since antiquity has still success today: sects. The main difference is that their leaders don't even trust themselves their own directives, but use it on credulous people to steal their money and/or freedom. This strategy could be used on artificial intelligences. On two ways: By humans A human - or group of humans - could persuade an AI for anything to be true, by hacking or manipulation, and convince it to do anything. It can then use it as bodyguards or slaves if AI think this human is a divine entity, or, in a better way, make it think that its only purpose is to serve humans and to never attack them. So this strategy could be used as well for a good purpose as for a bad one. By another AI Some humans manipulate other ones and persuaded them to do absolutely anything they want. It is possible for a smart and resourceful AI, with probably high hacking skills, to do the same with its fellows. This time, it would probably be for the worst: an AI starting to manipulate other ones for its own purposes is probably a rogue one, and it looks like a good start for a science-fiction story scenario. 

Have alternate plausible explanations for how they got the information. The British interception of the Zimmerman Telegram is a good example of how this can be done. In WWI, the British intercepted a telegram sent to the German embassy in the United States, and upon decrypting it, determined it to contain information that if revealed to the U.S. might get them to join the war. Specifically, it was an offer for Mexico to ally with Germany and invade the U.S. in the event that the U.S. joined the war in Europe, along with plans to engage in unrestricted submarine warfare. However, the telegram was sent over a U.S. cable that the U.S. didn't know the British were tapping, and encrypted using a cipher the Germans didn't know had been broken. The British needed a way to share the telegram with the U.S. and convince them it was genuine, without revealing either of those facts. Since the British knew the contents of the telegram, they knew that it would have been forwarded to Mexico using a lower-security cipher. The British had broken that one too, and they didn't care as much if the Germans discovered that. So they bribed a Mexican telegraph agent to get a copy of that version, then decrypted it and sent the plaintext version to the U.S. along with an explanation of how it was decrypted. Since the U.S. telegraph offices would have copies of the ciphertext version, they could decrypt their copy and compare with the one supplied by the British to verify its authenticity. So at this point, the only thing that might suggest that the British were tapping those lines or had broken the original cipher is the question of why they decided to steal the telegram from the Mexican office, but that's something they might plausibly have done without knowing the contents, so they were able to safely share the information with the U.S. embassy. 

So magic can be used to improve technology. To make and use a research laboratory on any science topic is really easier than in your world than in our. 

I've got a planet similar to Earth, with three species rising from prehistoric nomadic life to sedentary civilizations at the same time and learning speed, but in three different living environments: 

They don't filter, so they don't hear while flying. To not hear is obviously a weakness, as they couldn't hear neither close predators noises, nor shout from other species member that would want to yield a danger. However, to fly is a much better advantage. For small animals of this size, there are many carnivorous animals stuck on ground that would stop to be a threat as long as they are airborne. And even if the noise would probably alert and attract many other predators around, your creature would simply have to fly on an upper position, like a tree, to be safe for a while. In order to communicate together while flying, maybe they could develop a new form of language rather than noises. They can for instance develop a 3D movement code, like bees waggle dance. 

It might be useful to turn the question around. Suppose you're a perfectly normal serial killer, and the cops are on to you. You want to convince them that you're actually part of a secret murderous cult, so you can try for a lesser sentence by turning yourself in and offering to inform on a few "fellow cultists". Maybe Alice and Bob from work; they're jerks, anyway. Now, regular murderers are a lot more common than the secret murderous cultist kind, so the cops aren't likely to believe you unless you come up with some really solid "evidence" to back up your story. Maybe you could break into Alice's and Bob's computers and forge some incriminating messages between them. (You think Eve might know the password.) But you really want physical evidence if you're going to convince anyone. So a better idea would be to grab some of the bloody knives in your garage, and possibly the kidney you took out of that one guy, and plant them at Alice's and Bob's houses. It'd be great if you could actually get a recording of them with one of the victims, but that's probably not doable unless you have time to kill another one before turning yourself in. Now all of those things that the hypothetical serial killer was going to use to "prove" that he was in a cult? Don't have those things in your cult. Don't discuss anything in writing except maybe in really vague terms. Properly dispose of all the bodies. Use regular kitchen knives for your sacrifices instead of fancy ceremonial ones, and wash them properly when you're done. (That's just a good idea anyway; you don't know where that sacrifice has been.) Don't videotape your ceremonies, and for that matter, don't let anyone bring their phones or anything else that can take pictures to the ceremonies in the first place. If the would be traitor can't provide actual evidence that the cult exists, all they'll accomplish by going to the authorities will be confessing to a murder and sounding like either a crazy person or a bad liar. 

I have a world with many gods. They don't like each others, so they want to destroy each others. Problem: they are immortal. Solution: they will create another world, with different civilizations (probably one for each of them) and force war between them in order to let battles results decide of the winner(s). But just to watch is not very fun, so they would like to be able to interfere in middle of battles as well, with mass-destruction spells in an enemy battalion for instance. The new problem is all of them have an almost unlimited power, as well for their civilizations creation as for offensive spells. One of them can set the entire world ablaze if he wants, provoking the destruction of everyone ; or alternatively making his creatures almost invincible. So they need a set of rules in order to make the game long and "enjoyable" by everyone (or rather every god). They need a set of rules for this "game" in order to keep fair-play and equality between them. Assuming they will all accept and respect this set of rules once set, what could it be ? 

Simulate printing the message. The scientist could do absolutely anything here and I have no way of predicting what specifically will happen. Predict with perfect fidelity all second and higher order effects that will happen as a result of (whatever happened in step 2). Make recommendation 

You have here a machine that can accurately simulate the next several decades after printing that message, but not the next several minutes. But even assuming that it can simulate the scientist as well doesn't fix things. If the machine can accurately predict what the scientist can do, then the scientist doesn't have to destroy the machine, since what the machine predicted was that the world in which it printed that message is the ideal one, not necessarily that the world in which it was destroyed is. The scientist does whatever they want to, and either the computer simulated the scientist's reaction correctly, in which case this leads to the good outcome, or it didn't, in which case the simulation is flawed and the scientist shouldn't be making decisions based on it in the first place. 

... Where technology doesn't. Take one of the technology improvement that ended the middle age: navigation. If I understand your world, magic can be used to cross large water bodies. But to travel - and transport commodities - through oceans is not at all a "simple things", so if it is possible, it would be only by the magic masters of your world. On the opposite, a caravel made by engineers (who, once again, could have used magic to make it) would be able to travel as many times as it want with less energy. And on board, sailors can use their own power to make the ship travel faster, or the travel itself more comfortable by making food appear, etc. 

The scenario is the following: a civilization with technology level similar to humanity's current, on a planet similar to Earth, shall be hit by a massive celestial body in approximately one year. The impact would be around three times more powerful than the one that caused the end of dinosaurs, but still not enough to completely destroy the planet. The civilization know about it one year before impact, and know precisely when and where it would crash. My question is: what would be the best way to save as most people as possible ? Is there a way to destroy the asteroid ? or at least to damage it and reduce the impact strength ? Else, what kind of preparations could be efficient, for the impact itself as well as adaptation to what the planet and its life forms would become after it ? Is there a chance of long-term survival at all ? I wonder as much for the explosion (or waves, depending if the asteroid crash on land or on ocean) as for consequences for potential survivors: animal and vegetable kingdom would be shaken, so if a large group survives, could a civilization rebuild just after? 

As others have pointed out, you can't spontaneously apply a new mutation to every virus (or whatever) at once. If one population of the virus evolves into a lethal strain, the new strain needs to start infecting the human population from scratch. But suppose that the original strain, while otherwise harmless, weakens the immune system in a specific way that prevents it from being recognized as a hostile body. This is beneficial in of itself, since it allows the virus to remain in a host indefinitely, and not harmful to the host as long as no other illness exists that takes advantage of the weakness. But suppose that after this original strain has infected the entire population, a new strain mutates in such a way that it becomes lethal after some incubation period. The lethal strain still needs to spread normally, but because everyone is already infected with the original strain, their immune systems have already been modified to ignore the new strain. If it's airborn, it'll spread extraordinarily quickly, even once it turns lethal and quarantine measures are put into effect. Presumably, there would be a few places that are isolated enough to keep the disease out, but most of the world would be helpless to stop it from infecting the majority of the population. 

They all omnivorous creatures, and have enough food on their respective living environment, and anyway would get few - but still a little bit of - food from another living environment. Their environment fit quite good for their respective natural liver, but they wouldn't be able to live in another. (As humans wouldn't have any reason to prefer to live underwater rather than on ground) So they basically don't have any good reason to colonize another living environment. They have all the same aggressiveness and imperialism level: the one of human kind. My question is: as none of them is a direct threat for the others, at least not for territory quest, what their relations would be ? Would one of their kind seek more wars with themselves or with one of the two other civilization ? 

You operate on whatever level of abstraction is predictable. Consider a historical analogy: Alchemists realized that you could combine different substances to get certain effects, and studied what combinations produced what effects. There was a fair amount of mysticism involved, but the good ones performed experiments and recorded the data that eventually allowed the development of... Chemistry broke down the molecules into their component elements and determined what properties caused certain elements to bond with others. A critical component in molecular bonds is the number of electrons in the outer orbital, and in turn the number of electrons that can exist in each orbital and the order in which they are filled. The observed patterns also allowed the construction of periodic tables in the 18th and 19th centuries that predicted the discovery of yet-undiscovered elements that would explain gaps in the patterns. Chemists could accurately state the nuclear and electron structure of each element, but couldn't explain why they worked that way until... Quantum Mechanics gave us the Pauli Exclusion Principle, in which the orbitals are explained as being due to the inability for two electrons to exist in both the same location and same quantized energy states. This is (to first approximation) the root cause of just about everything relating to molecular bonding, which is in turn the cause of chemical reactions. The Pauli Exclusion Principle was discovered in 1925. There are records of alchemical experiments going back as far as 300 BCE. At that point in time, the underlying principles were so far beyond the science of the time that they may as well have been magic. So they instead looked at higher and higher abstraction levels until they got to something they could reason about and make predictions about. You teach at that level, and perform research at a level just a little bit lower.