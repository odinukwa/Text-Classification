Here is this answer written in the most elementary way I can: Let's first look at the case you started with, where the vector are evenly spaced at angle $\theta$. Let $g(\theta)$ be the matrix $\left( \begin{smallmatrix} \cos \theta & \sin \theta \\ - \sin \theta & \cos \theta \end{smallmatrix} \right)$. Then we have $$g(\theta) \left( \sum a_i a_i^T \right) g(-\theta) = \sum \left( g(\theta) a_i \right) \left( g(\theta) a_i \right)^T = \sum a_i a_i^T$$ where the second equality is because multiplying by $g(\theta)$ permutes the $a_i$'s. So the sum $Q:=\sum a_i a_i^T$ obeys $g(\theta) Q g(-\theta) = Q$. This is a collection of four linear equations in the entries of $Q$. (Computationally, you may find it easier to work with the equivalent $g(\theta) Q = Q g (\theta)$.) As long as $\theta$ is not a multiple of $\pi$, the space of solutions is $1$-dimensional, spanned by the identity matrix. So $Q=r \mathrm{Id}$ for some $r$. Taking traces of both sides, $r=n/2$. Now, what to do in higher dimensions? Are the vertices of a cube regularly spaced? What about a dodecahedron? The answer is yes, and group representation theory is the correct vocabulary to explain why. Let $g_1$, $g_2$, ..., $g_k$ be a finite collection of orthogonal matrices permuting the $a_i$ amongst themselves. So, the rotational symmetries of the cube or the dodecahedron or, back in your original example, the matrix $g(\theta)$. Set $Q = \sum a_i a_i^T$. Just like before, we deduce that $g_1 Q = Q g_1$, $g_2 Q = Q g_2$, ..., $g_k Q = Q g_k$. This is a bunch of linear equations for $Q$. If the space of solutions to these equations is one-dimensional, we win! We now come to a nontrivial theorem: The space of solutions to these equations is one dimensional if and only if there is no linear subspace $V$ of $\mathbb{R}^d$ (other than $(0)$ and $\mathbb{R}^d$ itself) such that $g_i V = V$ for each $g_i$. For the cube, the dodecahedron, the original evenly spaced points, and many harder examples, this is easily checked. For the case darij raised, of two points evenly spaced at distance $\pi$, this condition fails: every line through the origin is taken to itself under $g(\pi)$. Some vocabulary: It is usual to work not just with the $g_i$, but with all of their products. (For example, working with not just $g(\theta)$ but $g(2 \theta)$, $g(3 \theta)$, etcetera.) Let $G$ be the set of all of these products. Since they permute a finite set of vectors, $G$ cannot be infinite. (Experienced mathematicians will see that I am glossing over something here, please let me do so.) For example, in our two dimensional example, $\theta/\pi$ cannot be irrational. So $G$ is finite, and is what is called a finite group. Every element of $G$ is a symmetry of $\mathbb{R}^d$, so we say that $G$ acts on $\mathbb{R}^d$ and those actions are by linear maps so we say that $G$ acts linearly. In this setting of a group acting linearly, we say that $\mathbb{R}^d$ is a representation of $G$. The condition that there be no subspace of $\mathbb{R}^d$ which is taken to itself by $G$ is usually stated using the technical term: $\mathbb{R}^d$ is an irreducible representation. A personal note: If you aren't comfortable switching between matrices and bilinear forms, you don't know the vocabulary of groups and group actions, and you have never seen any group representation theory, you might fit in better at math.stackexchange.com than here. That said, nice problem! I may save it for when I teach representation theory. 

My guess is that this is going to be hard to solve in reasonable time if you have a large number of dimensions (thousands or more), and don't exploit any particular 'nice' features your lattice might have. However, I believe it is in NP. The following, while probably impractical, should in theory do what you are asking: 1) Find a reduced lattice basis (LLL algorithm) 2) Use the reduced basis to enumerate all lattice points within a sufficiently large box encompassing the point "P". 3) Compute the Voronoi diagram of this set of points. (Bowyer-Watson algorithm) You should then be able to find the nearest lattice point by inspection of the Voronoi diagram. If you really need to compute this sort of thing, the trick would be to see if you can avoid step 1) completely, and integrate steps 2) and 3). Otherwise, simply storing the Voronoi diagram will use an explosive amount of memory. 

An iterative scheme may do the trick. I would suggest looking into algorithms such as GMRES. Since you have a large, sparse matrix, there is a good chance you already have your matrix in a format that can be accepted by an iterative solver. 

Consider applying the permutation (1,3,0,5,2,7,4,6) to the integers (0,1,2,3,4,5,6,7) three times. I call this a "dance of minimal cost" because all unordered pairs in {0..7} meet each other, and the total movement of all the "dancers" is minimal. For a pair to "meet" I simply mean that, at some point during the dance, they occupy adjacent positions. Say that n=8 in this case. Here is a crude illustration of the dance: 

It looks something like a braid. We can define the cost of a dance to be the sum of the distances by which each element is displaced. For the dance above, the cost is 42 (3 permutations x cost of 14 each). The permutation (1,3,0,5,2,7,4,6) has a cost of 14 since it displaces all 8 elements up or down by 2, except for the second and second-last elements which move up and down by a distance of 1. I should mention that the dance above is not unique, for example there are other dances on {0..7} which also have cost 42 but consist of different permutations, not repeated application of a single permutation as illustrated above. I am reasonably confident that the cost of 42 is minimal for the n=8 case but do not have a solid proof. The question I have is this: what can be said about dances of minimal (or approximately minimal) cost in the following restricted case: suppose we introduce a radius r, and require not that every pair of dancers meet, but only those initially within distance r of each other. For example, a dance on {0..7} with n=8, r=2 and initial configuration (0,1,2,3,4,5,6,7) does not need {2} and {5} to meet, since these are initially separated by a distance 3, greater than r. Edit: Can this notion of restriction be cast in the language of forbidden patterns, I wonder? 

Here is a sort-of-but-not-really explicit answer, following up on Helge's idea. Set $h = e^{\pi^2/(12 \log 2)}$. Recursive define the $b_i$ and $q_i$ as follows: $q_{-2} =1$, $q_{-1}=0$ and $q_i = b_i q_{i-1} + q_{i-2}$. If $q_{i}^{1/i} > h$, then $b_{i+1} = 2$, otherwise, $b_{i+1}=4$. This is clearly a well defined recursion; you can decide whether or not you think the result of this process is explicit. Lets first study, in general, the situation where every $b_i$ is either $2$ or $4$. Write $r_i = q_i/q_{i-1}$. Then $r_i = b_i + r_{i-1}^{-1}$ so $b_i < r_i < b_i + 1$. Note that $3 < h \approx 3.28 < 4$. So, our algorithm has the property that, if $q_i^{1/i} < h$, then $r_{i+1}>h$ and vice versa. Set $s_n = \log q_n = \sum_{i=0}^{n-1} \log r_i$. So, if $s_n < (\log h) n$, then $s_{n+1} = s_n + \log r_i \in [s_n+\log 4, s_n + \log 5]$ and we see that $s_{n+1} - (\log h) (n+1) \in $[(s_n - (\log h) n) + \log 4 - \log h, (s_n - (\log h) n) + \log 5 - \log h]$. Writing $t_n = s_n - (\log h) n$, we see that 

Let $k$ be a field and let $X$ be a finite type scheme over $k$, explicitly given by finitely many affine patches which are $\mathrm{Spec}$ of finitely generated $k$-algebras, glued along other affine opens which are $\mathrm{Spec}$ of finitely generated $k$-algebras. Is there an algorithm to check whether $X$ is proper over $k$? I assume the answer is yes, because I've never found it hard to do. But I just realized that both definitions of "proper" involve quantifying over very infinite sets: All $k$-schemes $Y$, if one is using universal closeness, or all maps from $\mathrm{Frac}$ of a valuation ring to $X$ if we use the valuative criterion. (We can make the valuation ring into a dvr, but that's still pretty darn infinite.) 

The dimension of $S_{21}(V)$ is $(n+1)n(n-1)/3$; it is only $8$ if $n=3$. The other half of Schur Weyl duality says that $S_{21}(V)$ is a $GL_n$ (not $S_3$) irrep; namely, the one which is indexed by the partition $(2,1)$. Similarly, $\mathrm{Sym}^3(V)$ and $\bigwedge^3 V$ have dimensions $(n+2)(n+1)n/6$ and $n(n-1)(n-2)/6$ and are $GL_n$, not $S_3$, irreps. 

Let $G$ be a connected compact Lie group, $T$ a maximal torus, $M$ the character lattice of the torus, $W$ the Weyl group and $\Phi$ the root system. Let $\Phi_{+}$ be the positive root system, let $M_+$ be the chamber of dominant weights and let $\rho = \frac{1}{2} \sum_{\alpha\in \Phi_{+}} \alpha$. For $\lambda \in M_{+}$, let $V_{\lambda}$ be the corresponding representation and let $d_{\lambda}$ be $\dim V_{\lambda}$. Let $\pi_{\lambda}: G \to V_{\lambda}$ be the representation map and let $\chi_{\lambda}(g) = \mathrm{Tr}\ \pi_{\lambda}(g)$ be the character. We fix a positive definite Hermitian inner product on each $V_{\lambda}$ so that $\pi(g)$ is unitary. We normalize Haar measure so that $\int_G 1 = 1$. Let $f$ be a continuous function on $G$. Clearly, it is enough to prove pointwise convergence at the identity. Define $$\bar{f}(x) = \int_{g \in G} f(gxg^{-1}),$$ so $\bar{f}$ is a class function. Lemma Pointwise convergence of $f$ at $1$ is equivalent to pointwise convergence of $\bar{f}$ at $1$ (with the same ordering of irreps). Proof Choose $v_1$, $v_2$, ..., $v_{d_{\lambda}}$ an orthonormal basis of $V_{\lambda}$. The Fourier series of $f$ at $x \in G$ is, by definition, $$\sum_{\lambda \in M_{+}} d_{\lambda} \sum_{i=1}^{d_{\lambda}} \sum_{j=1}^{d_{\lambda}} \langle v_i,\ \pi_{\lambda}(x) v_j \rangle \int_{g \in G} f(g) \langle v_j,\ \pi_{\lambda}(g) v_i \rangle .$$ (Some $g$ and $g^{-1}$'s may be switched here.) Taking $x$ to be the identity, we have $\langle v_i, v_j \rangle = \delta_{ij}$ so the sum simplifies to $$\sum_{\lambda \in M_{+}} d_{\lambda} \int_{g \in G} f(g) \sum_{i=1}^{d_{\lambda}} \langle v_i,\ \pi_{\lambda}(g) v_i \rangle = \sum_{\lambda \in M_{+}} d_{\lambda} \int_{g \in G} f(g) \chi_{\lambda}(g).$$ Since $\chi_{\lambda}$ is a class function, the integrals are unchanged by replacing $f$ with the class function $\bar{f}$. $\square$. From now on, we assume that $f$ is a class function. So $f$ is determined by its restriction to $T$, which is $W$ invariant. Until I say otherwise, assume that $f$ is sufficiently smooth that the Fourier coefficients $\int_{\theta \in T} e^{\mu}(\theta) f(\theta)$ decay faster $|\mu|^{-N}$, where $N$ is some integer depending on $G$ which you could extract from the proof. Noting that $d_{\lambda} = O(|\lambda|^K)$ for some other constant $K$, this will make all sums absolutely convergent, so we can rearrange at will. For $\alpha \in M$, let $e^{\alpha}$ be corresponding character of the torus. We will also sometimes abuse notation by writing things like $e_{\alpha/2}$, which is only defined on the double cover of the torus; our total expressions will be well defined. Let $\Delta :T \to \mathbb{C}$ be the Weyl denominator: $$\Delta(\theta) = \prod_{\alpha \in \Phi_{+}} \left( e^{\alpha/2}(\theta) - e^{- \alpha/2}(\theta) \right).$$ Using the Weyl integration formula to convert integrals of class functions $G$ to integrals over $T$ and the Weyl character formula to express $\chi_{\lambda}$;, we want to show $$f(1) = \mbox{constant} \cdot \sum_{\lambda \in M_{+}} d_{\lambda} \int_{\theta \in T} \Delta(\theta)^2 \frac{\sum_{w \in W} (-1)^w e^{w(\lambda+\rho)}(\theta)}{\Delta(\theta)} f(\theta)$$ $$= \mbox{constant} \cdot \sum_{\lambda \in M_{+}} d_{\lambda} \int_{\theta \in T} \Delta(\theta) \sum_{w \in W} (-1)^w e^{ w(\lambda+\rho)}(\theta) f(\theta) $$ $$= \mbox{constant} \cdot \sum_{\lambda \in M_{+}} \sum_{w \in W} (-1)^w d_{\lambda} \int_T e^{w(\lambda+\rho)}(\theta) \Delta(\theta) f(\theta). $$ (Here the constant absorbs $2 \pi$'s, signs and $|W|$ in some combination that isn't worth keeping track of.) For $\mu \in M$, define $d(\mu) = \prod_{\alpha \in \Phi_{+}} \langle \mu, \alpha \rangle$. If $\mu = \lambda + \rho$, then $d(\mu) = d_{\lambda}$ by the Weyl dimension formula. If $\mu = w(\lambda+\rho)$ for $\lambda$ dominant, then $d(\mu) = (-1)^w d_{\lambda}$ by noting that $d$ is clearly $W$-antisymmetric. If $\mu$ is not of the form $w(\lambda+\rho)$ for any dominant $\lambda$ and any $w$, then $\mu$ is on one of the hyperplanes $\langle \ , \alpha \rangle =0$, so $d(\mu)=0$. In short, we can make the change of variable $\mu=w(\lambda+\rho)$ and write $$\mbox{constant} \cdot \sum_{\mu \in M+\rho} d(\mu) \int_T \Delta(\theta) f(\theta) e^{\mu}(\theta).$$ 

Sorry for my comment based on thinking of Weil divisors only in terms of closed points, something I have still not completely unlearned. In the Weil divisor approach one runs naturally into (4) but it can be avoided at the cost of doing something a little deeper (see earlier remark about a strange question). There are no real mathematical issues, just a matter of taste about how to proceed. To illustrate, suppose homogeneous polynomials $g_i$ of the same degree represent $\phi: P^n_k \to Y \subset P^m_k$, with $Y$ not in a hyperplane. Then $y_0$ on $P^m_k$ induces an effective Weil divisor on $P^n_k$. This is basically a polynomial, up to scalars. Is it $g_0$? In general, NO! It is $g_0/g$ that will give $d$, where $g$ is the gcd of the g_i. Under field extension does the gcd remain the same or can $d$ decrease? This is just (4). Of course (4) is no more than an easy exercise with polynomials and fields, based on adjoining an element that is either transcendent, separable, or (say) a $p^{\text th}$ root. There are several slightly deeper prooofs, including a slick one by flatness. What I find astonishing is that despite its relevance it seems to have gone unnoticed. While still searching in many likely places, I have so far found NOTHING. As a more didactic point, via (4) one needs little machinery to obtain a result on the field-independence of factoring rational maps on $P^n_k$ through Veronese embeddings, and to see that if a rational map is defined over $k$, so is its associated divisor. This does not come close to Chow´s result that there is a well-defined smallest field of definition of a divisor, which may be properly contained in $k$. Presumaby there are now more modern approaches than the original via Chow coordinates. I would like to close by thanking Prof. Qing Liu for taking the time to help clarify the ideas involved. 

This is a response to the last comment, but I don´t know how else to post it (too long). The above explains well what happens over algebraically closed fields. Pulling back hyperplanes gives a a unique divisor class dH, hence d, which it seems will not change under field extension (see below for a detail). This is the sort of divisor theory I am trying to unlearn, which led to my posts, and reading Liu´s book would be one of the best ways to proceed. I hope he won´t mind some statements about what goes wrong with divisors over arbitrary fields, which is presumably one more reason (after base change) why the sheaf approach is so prevalent. With $\phi$ and the $h_i$ as before, look at the zero set of a $k$-linear combination of the $h_i$, or of an irreducible factor of it. Is it defined by a single equation? Think for example of sections that are elliptic curves, restricted to small fields $k$. How then would we define $d$ over $k$? What happens when the field is extended? Supposing a sufficiently nice situation so that such problems can be ignored, when the field is extended the section still gives the class dH, but there is still the strange question about whether $d$ could decrease, which would happen only if the $n+1$ equations used to define the base locus (a possibly empty set) define over $K$ a variety of codimension 1. This is ruled out by the almost trivial (4), or via more sophisticated ideas about dimension such as heights of prime ideas, as in Liu´s book, or transcendence degrees. (4) does in fact have something to do with divisors, so perhaps I should write more than in my original post (not having seen this anywhere). If we think of divisors on projective space via homogeneous rational functions rather than hypersurfaces, not worrying about geometry nor 0-gradings to get partial functions, it always makes sense to extend from k to K and say what is meant for a divisor over $K$ to be $k$-rational. Given $\phi$, we can only work directly with functions of quotients $h_i/h_j$, and can in the usual way define the least divisor $D = D_\phi$ such that $\phi$ factors through $\mathcal L(D)$, then ask whether this $D$ could change under field extension. The fact that is does not is just a translation of (4). In other words, if a rational map $\phi$ between projective spaces over $K$ is definable over a subfield $k$, the same is true of $D_\phi$. This divisor turns out to be the least common multiple of the $h_i$, assuming the gcd of these is 1. No doubt all this is well-known, but what references are there?