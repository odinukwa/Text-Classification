You get a Non-authoriatative answer back, because the name server we just queried doesn't maintain the records for Google, it simply has them cached for us. You can use the set q=NS command after starting nslookup to query a domain name's authorative name servers: 

Now if Google was to update their DNS records on their ns1.google.com name server, it could take between 1-8 hours typically for those records to propagate over to other caching name servers. So to answer your question, your local DNS server knows how to resolve your domain name, because when you registered your domain name you had to point the name server records to a valid DNS server, making that DNS server (name server) the authoritative server for your domain's DNS queries. All other name servers on the net, such as Google's 8.8.8.8 will cache your server's response as people search for your domain name. A good example is that your local ISP could be caching DNS queries. For instance if your next door neighbor just got the authoritative DNS records returned for your domain, and then you looked them up right after, more than likely you'll get a cached response from your ISP's name servers rather than the request having to possibly break out of the network just to receive back the same results a minute later. If no one in asks for your domain name over a 24 hour period, it could be possible for the DNS records to decay and fall out of cache based on their TTL (Time to Live) setting. If this was the case, when someone went to query your domain again, the first thing that would happen would be a whois lookup on your domain seeing what the authoritative name servers are for the domain, and then you'd be getting an IP address resolved back from your local DNS server that you've setup to handle those requests. Name servers and DNS are a pretty complex topic, if you need any further explanations let me know, as I've written extensively about them: $URL$ 

I use rsync v. 3.0.4 and when I need to move something I use it with the --remove-source-files. I prefer rsync than mv. Unfortunately, when I use --remove-source-files, the directories are left on the source side (as said in the man). Is there a way to remove directories too once moved all the files? 

Is there anyone aware of someone seriously working on thunderdbird to get write support on ldap shared addressbook? 

the process gets stuck on the installation of libssl because it requires the user input to restart some services (ssh ntp exim4) 

I never had experience on that precise model but generally the answer to all your questions is YES for every nas like that. Even the last question should be yes because the nas should be capable to rebuilt the array from the meta information stored in the disk and also because a mirror raid is not that hard to be rebuild. If you extract a running disk you can mount it on another host (the filesystem used by Iomega should be XFS, so every linux can mount it). Bonus question: If I understand well what you mean, the action is SWAP. Hot swap is when you can exctract a disk without turning off the device. This Iomega is not hot swap. Apart this in the recent past (last 3 years) we sold 12 Iomega Storcentre nas. We had 100% warranty emergencies on them: broken disks, bugs in the GUI, broken power units. We stopped to sell Iomega for this reason. I don't mean that this model is affected too but I would suggest you Buffalo $URL$ 

Some versions of support a or flag to show the tree of relationships between processes. If your version doesn't have that, check for , a stand-alone package to do the same thing. It can help in cases like this. 

But again, getting such a command just right might very well take longer than installing a minimal system and setting it running. 

First, you would normally want to use or or to get root privileges for an X application. Second, why are you using on Debian? (I mean is even enabled? It's not by default on Debian, as opposed to Ubuntu or OS X.) Third, I can't think of any circumstance where you actually need to run a browser with root privileges. There are cases when you need a gui application as root - say, you want to edit a system file (/etc/network/interfaces for example), and you're most comfortable editing with . That's not an unreasonable thing to want to do. But you would want to use or a similar utility to transfer the privileges. 

Unfortunately this is shown inside the terminal and I couldn't find any way to hit "ok" and then, of course, I get this message. 

The title should be self explanatory but more in detail I'm looking for a way to protect the ldap from LAN brute force attacks. It would be fine to prevent password guessing by locking a password for a specified period of time after repeated authentication failures. It doesn't matter if this can be turned into a DOS. Unfortunately I can't find a way to do this and the documents I've found are really confused. 

The orange led doesn't mean that the drive is broken: it means that it's marked as failed. Recently I had the same issue on a ServeRaid 6i: two drives disappeared. The raid was level 5. I put one of the two online and I rebuilt the second. At the end of the process I got my array rebuild. Of course it was not a broken disk but a weird bug into the controller or into the disks. Some disks seem to have broken firmware that cause the disk to deattach from the array randomly. 

It sounds like you are trying to setup custom name servers so you can give any web-hosting client of yours pretty name servers with your domain in them (NS1/NS2.MyCoolCompany.com), as opposed to showing that you are actually reselling hosting when you tell them to point to (NS1/NS2.MyUnCoolHostingCompany.com). Setting up custom name servers with GoDaddy would simply be a process of logging into your account and then getting to the control panel for the domain name that you want to use as your custom name servers, be sure you click on the domain name to get into the more detailed info for it and don't go to the domain's dashboard. Then just click on [Host Summary (Add)] at the bottom-left of the page. Add [NS1] as the host name and then enter an IP for it, then (Add) again and do the same thing for [NS2]. It's Ok if you have them both point to the same IP address if you were only given one by your web-host. Doing the above steps affectively registers your domain as a name server although you might have to wait up to 12 hours before you can point to it. Then it's just a matter of popping into WHM or another control panel software and setting your server's name servers to also reflect the (NS1/2.YourCoolCompany.com) host name, or you can add it manually as well. 

I just purchased a license of safelyremove. It has command line support. It's very nice. There is a full trial on the website $URL$ 

I just purchased a license of safelyremove. It works with sata controllers too not only with usb. It's very nice. There is a full trial on the website $URL$ 

What CRC does exactly? Accordingly to wikipedia it should be an integrity check but how does it work? I discovered that setting this parameter to false my disks are finally recognized as sata2 rather than sata1 and speed are really increased. Why? I found this IBM paper in which they say: 'CRC Checkingâ€”(Default: No) Determines whether the controller verifies the accuracy of data transfer on the Serial bus. CRC Checking should be disabled on the controller and all devices if any device supported by the controller does not support CRC Checking." How do I discover if a hdd supports CRC? If CRC is disabled and a breaking event occurs, is there a risk? 

I have a X3400 with 8 x (43w7598 250GB SATA 3GB/S HDD) set in the frontal bay and connected to ServeRaid 8K controller. The raid array works well but, even if I set the controller PHY to 3.0 (rather then Auto or 1.5), all the disks negotiate 1.5Gb/s with the controller. This sounds really weird to me because the disk are WD Caviar Black Sata2 disks (bought from IBM). The firmware is the latest available from IBM (accordingly to the IBM ServeRaid matrix). Any tip? 

I think that 2 is cleaner and better in the long run, but either should work fine. The issue with 1 is that if your work habits change, you will need to remember to remove that line, or it will drive you crazy every time you open a shell. 

Put this at the bottom of your file (it's in your user's home directory): cd /a/very/very/annoyingly/long/path/name Edit your . This method gives you quick tab-completable directory changes Mine looks like this, for example, since most of my shell work is in the two directories 'iliumSvn' or 'unix.varia'.: export CDPATH='.:~:~/iliumSvn/:~/unix.varia' 

If the problem is simply that you have to start every session in the terminal with this: , then I can think of two solutions. 

I like PmWiki quite a lot. It's easy to install, easy to customize, and it doesn't require a database. (Neither does Ikiwiki, which I've also used and liked.) PmWiki supports a great deal of customization through cookbook recipes, and it appears that it can do what you want in terms of user authentication and permissions. See this page. But I haven't used it that way, so I can't confirm how well that works. Edit: In response to the OP's comment, I have used BoltWire (check your spelling and your link - both are incorrect), and I prefer PmWiki. They are both reasonably easy to install and both pretty lightweight. I didn't dislike BoltWire at all, but I found PmWiki more fully-featured and easier to configure. Edit 2: Since you mention in a comment on another post that you are using Debian, both Ikiwiki and PmWiki are available in Debian and pretty trivial to install using your favorite APT package manager. I would recommend that you try both out and decide for yourself. 

Of course I can work around this by continuing the installation by hand through the virtualbox GUI but this should not happen in unattended installation. How can I force the installation process to restart the services without waiting for the user input? 

I can't answer to your question but I want to point on you on a detail that might be interesting: several sata hdd have a jumper to set them sleeping by default (the controller has to send a sata command to wake up the disk. [not all controllers can do that]). Is the jumper already set? Dam 

We are working on a project which involves different hardware all hosted in a single rack. The machines are mainly IBM servers: 2 x206 (scsi), 1 x226(scsi), 2 x3400(sata) and another assembled machine with sata controllers. We are using several raid controller. Some machines have only one Serveraid controller, others have one or more controllers not always Adaptec ones. All the firmwares and bios are updated. All the servers and connected devices are under ups. Over the last 4 months we experienced several strange behaviours in our hardware. Suddenly and randomly we loose 2 or 3 drives and the raid volumes stop to work. It can happen once a week but never at the same time of the day or week. Most of the times a rebuild process fixes the problem, sometimes we loose the data. Very often we just need to unplug the raid controllers, restart the server and the problem is fixed. At the beginning we thought it was due to firmware bugs but we performed an accurate update for every machine and raid controller and there is nothing else we can do on the hardware. We have really no hint on what's causing all these troubles. We are starting to think that it's an environmental problem but we don't know if there could be something interfering with our hardware. Have you ever heard of something like that? Do you have any idea on how to investigate the problem?