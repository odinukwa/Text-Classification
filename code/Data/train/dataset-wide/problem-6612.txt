I'm using Praat for the first time. When I try to annotate a Chinese speech segment, for some reason the Chinese characters I entered all get displayed as blocks in the corresponding tier: 

For typological questions you can consult related databases, such as The World Atlas of Language Structures (the most widely used), AUTOTYP, SSWL to get the answer. As mentioned, Arabic might be one such example. 

Complements mostly immediately follow the head. They bear a much closer relation to the head than adjuncts 

My mother tongue is Chinese and I speak neither Japanese nor Korean yet I don't think they really sound close. I will definitely not mistake Japanese speakers as speaking Korean. It's very easy for "close" languages to borrow and share a lot of features. An example I remember quite well is the pronunciation of "r" in became quite similar in French and German over time (for a lot words at least), even though those languages fundamentally don't have much to do with each other, however that doesn't make them belong to one language family. So the issue in a large part is how do you separate features borrowed from neighboring, but essentially unrelated languages from features that stemmed from a common language family. It's true that Japanese and Korean share certain common features (e.g. grammar) between themselves and also with some other languages in the area, for example Manchu Language, but the sources of such similarities are debated. Also, the Altaic hypothesis is largely based on the idea that a large portion of the ancestors of modern Korean and Japanese came from north/northeastern Asia (and then they mixed with the population coming from further south to form their respective races), which might be true to a large extent. However, even if that's true, since the geographical conditions of those two places were largely isolating (especially Japan), and also since there were another large portion of the population who came from completely different places (e.g. from Southeastern Asian islands in the case of Japan), they might well have developed a lot of their own features during the tens of thousands of years so that it would be hard to still classify them as belonging to the same language family. Apparently all human beings eventually came from the same place... So at what point of a language's evolution do you draw the line on language families is a somehow subjective issue actually. 

I'd also recommend qTree - if you've ever sat in a syntax class or had to work with natural language parsers, it will be very easy to use: $URL$ 

Peter Roach's fourth edition of English Phonetics and Phonology: A Practical course (2009) has a more detailed list of rules and explanations than your link, if you're interested (Chapter 11: Complex Word Stress). 

Although I usually study within the Humanities faculty, I am in Computational Linguistics class right now, and can recommend Speech and Language Processing, 2nd Edition, 2009, by Jurafsky & Martin. There is another book I've tried, Language Processing with Perl and Prolog by Nugues & Pierre, but I found that it was much more difficult to get into for me, though perhaps handy if you are able to keep up with it. Getting familiar with a few research papers on human language processing (dealing with ambiguities, etc.) was helpful in understanding the textbooks and relating it to NLP as well. 

There really isn't just one high-level, abstract, "language production/comprehension process". That view would be much Chomskian and is now generally derided. Language production/comprehension is the result of cooperation between several cognitive capabilities. There are definitely overlaps for spoken and sign languages, especially in meaning comprehension and production (not in the sense of the final muscle movement, which is different of course). There would also be differences, in terms of concrete perception mechanisms. Language acquisition researchers also looked into the acquisition of sign languages (e.g. for children that are born deaf). Those who had normal parents showed demonstrably worse results than those with also sign-language using parents, presumably because the normal parents can't provide an immersion environment. This is the same as what happens in the acquisition of spoken languages. 

One research group at our university is particularly interested in the statistical properties of language. One professor, Michael Ramscar, is teaching us some classes this semester on related topics. And basically the idea is that this kind of logarithmic/exponential distribution is considered optimal in an information theory point of view, since it ensures that the entropy of the whole probability distribution would be the lowest, ensuring the most effective communication in general. Some of these ideas can also be found at his blog, for example this article about the distribution of names. P.S.: Actually he also made the argument that the "Zipfian power law" view is not entirely accurate while an "logarithmic/exponential" distribution might be a better description. He said that the shape of the curve under the Zipfian power law would be largely impacted by the sample size, while the shape of the curve under simple logarithmic/exponential distribution wouldn't, because it would only have one parameter, while the Zipfian power law distribution also gets a scaling factor besides the simple exponential factor. I'm not sure I completely got this point to be honest, but the point about entropy should still stand regardless, since I think Zipfian distribution is basically logarithmic/exponential as well. 

I am not to well versed in all of the inner and outer workings of the international phonetic alphabet, and I was curious if /∅/, not to be confused with /ø/, could always be used for silent characters. A fine example would be with the word light, transliterating it as [ˈlaɪ∅t] as opposed to the usual [ˈlaɪt]. 

Anglo Saxon did not distinguish by voicing usually, particularly with the sounds /s~f~z~v/. After the adoptions of the Latin Alphabet letters "f" and "s" were doubled when representing a voiceless sound in the Wessex dialect's accent when it fell between two voiced sounds in the same syllable. That being said, are there any runic writings that attest to something similar them-in? or was this something that seems to have just been introduced by those who introduced the latin script? *I am aware of the younger futhark introducing dots to distinguish voicing and I am aware of some anglo saxon rune sets introducing the letters kalk and gar to have runes that specifically only made the sounds /g/ and /k/. 

Are the languages spoken in various Arabian countries actually mutually intelligible? If no then it makes more sense to regard them as separate languages. In China the government likes to officially categorize various Chinese languages as "dialects", but the reality is that the difference is really huge between some of them, e.g. comparing Mandarin and Cantonese is more like comparing Italian with Spanish than American English with British English. Most Mandarin speakers don't understand nor speak Cantonese at all. Therefore there are many language codes for various Chinese languages as well and it makes sense to me. I wonder whether the situation is similar in Arabic: If you can't even understand some of the Northern African Arabic then how can you claim they're the "same language"? Some people might try to do so politically but linguistically it would be far-fetched. The situation is just fundamentally different from American vs. British English I suppose. 

Speaking just about my own personal experience: I can only understand a little Russian because of the similarities I can find from two other Slavic languages I speak: Ukrainian and Polish. As someone who has never been exposed to Russian before, I feel that I would not be able to understand Russian with just one of the other Slavic languages. Therefore, I don't feel that I can agree with the notion of Russian/Polish understanding. In fact, I feel that this might even be a cultural misconception, as I've had quite a few experiences where Russian speakers insist on speaking Russian at me, convinced that I will 'magically' understand them. I've also noticed that non-Slavic speakers believe this as well. however, in the Czech Republic, speaking Polish will get me nowhere, but speaking Ukrainian will get me by quite well indeed. Again, I'd like to stress that is just personal experience.