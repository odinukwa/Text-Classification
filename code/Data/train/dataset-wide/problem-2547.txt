Another advantage is that the built-in function is more efficient than your implementation. Let's see on a resampled version of your dataset with 1 million rows: 

The number of combinations of size from a set of size can be computed with in R, and if you have multiple values you can just pass in a vector for . Therefore your code can be simplified to: 

As you can see, is returning row numbers instead of row names; this yields an identical reordered data frame: 

You are summing from j=1 through j=i by looping through the values individually and adding them up. In R you can get significant speedups by using the vectorized function: 

It seems that you are looping through seeds to find the one that causes a randomized procedure's output to match the output from a previous run. If you had set the random seed immediately before running the randomized procedure and have simply forgotten the seed you used, then this in theory would work; all you need to do is loop through the billion or so possible input seeds until one matches. There's no real way to speed up the process (beyond parallelizing, which would be easy because the problem is embarrassingly parallel). is just a wrapper on a loop, so that would not speed up the process. Unfortunately, more likely than not you did not set the random seed immediately before running the code. Therefore you would really need to test all the internal states of the pseudorandom number generator (PRNG) that you used to find the one that matches the results. Unfortunately there are intractably many internal states; for instance, the most popular implementation of the Mersenne Twister, which you are likely using, has a period of 2^19937 - 1, meaning it has at least that many possible internal states. Clearly it's impractical to test this many states, so it's probably hopeless to try to match an exact PRNG state if you hadn't set the seed immediately prior to running your randomized procedure. 

You don't do this in though. If you have a list of length 4, the call will look past the end of the list. That's a problem. One that's easily fixed by the same checks as above. You probably also want to validate the input for . You don't want a position as input, and neither do you want an input past the end of the list. 

There is an unnecessary amount of calls to . Each iteration starts by evaluating all points of the simplex: 

I have been refactoring this code myself as well in the meanwhile, so I thought I'd post some of the insights I have gained myself. Class inheritance Instead of passing a instance when creating a , by making a subclass of , I was able to reduce the amount of information that was stored in both classes. This makes accessing the attributes and methods of in 's methods shorter as well. does nothing 

Only during shrinking do we have to evaluate more new points. So we can extend the code where we break the iteration with a modification of the array and move the loop evaluating the simplex to outside the while-loop. 

In addition to the other remarks: does exactly the same as , so you could either call that directly: 

This post is specifically for the GUI, since this is my first time working with PyQT, so I am not sure if all is done properly. The file with the file with the classes Query and Universe and an example JSON file can be found on GitHub. 

I have been trying my hand a bit at creating a big integer class in C++. This is a continuation of a homework assignment. The class stores a big integer in a double linked list. Each slot contains 8 digits of the number. It is possible to create an instance from an integer or char array. Negative numbers are supported with a bool sign indicator. I implemented addition, subtraction and multiplication, aswell as their operators. I didn't manage to come up with a good division algorithm though. The code: BigInt.h 

whereby the Modify Accessor is a composite instance of the class, it adds instances to an internal enumeration and orders by weight. the Skill classes calls its composite Modify.Calculate(_baseValue) or something and still returns the combined result and all is safely encapsulated. 

If you had that in your constructor you could perform all the quest handling without any implementation detail knowledge, allowing you to (amongst other things) test the handler without relying on a database. 

So now if you decide to completely change how Foo's are delivered to the UI, replace the presenter but all views still work, want to make a different representation of the same data? make a new view object, finally your presenter could also contain a datamodel which could be swapped out between storage methods, different database's or config files or we service or whatever. 

Well I would personally want to cut down on all of that exception handling code. The easiest way in my mind is to create your own exceptions. Now, I understand you seem to need a message and enum associated with each chunk there so why not make that as a base transactionException and overload each case. 

and with all that in place you should be able to throw a number of custom exceptions and wrap the whole thing in one catch block that will log the associated message and return the associated enum. 

Of course if any of those properties are required then the constructor is the way to go, but the lack of null validation makes me think they are not Also there is a lot of magic strings going on. At minimum, you should make those constants. I would personally just do an enum but that is a design choice: 

which has some nice features like auto deactivating the button when the CanExecute fails. and having the ability to have a canexecute is nice. Good separation of concerns. Also if you decide down the line to maybe go fill ViewModelLocator using the interface as a binding in your view allows some hot swapping of views/models. So what i mean by that is 

I am currently learning C# since the last week. I have little to no prior experience with any of the C family of languages. I implemented the Nelder-Mead algorithm for numerical optimisation of a function. My implementation exists of a function that takes two arguments, the function to optimize, and the amount of dimensions that the function has. So for a function that goes R^N -> R, the second argument would be N. The implementation is based on the algorithm shown in the linked article. Along with the algorithm, I also implemented two functions for evaluation of the algorithm: The Himmelblau function and the Rosenbrock function. 

Length You provide a method to calculate the length of the list. But from the moment of creation of the list, you should be able to track this length. If you add a private counter, increment it whenever a node gets added, and decrease it whenever a node gets deleted, you should be able to instantly provide the length, instead of having to compute it each time the user requests it. Repeated code You provide methods for deleting the first node, the last node, and any node. In the first two methods you kind of repeat the code of the latter method. You could redefine those by calling the latter: 

However, in most cases, only one of the points of the simplex changes between iterations. So only one point needs to be re-evaluated. Conveniently, this re-evaluation is already done in the previous iteration: 

Because I am new to C#, I am interested in advice/commentary on good form, but I am also interested in the efficiency of this implementation. 

This checks if the minimal and maximal function values of the simplex are sufficiently close together, but an easy counterexample shows that this nowhere near guarantees convergence: Consider the function . Of course this is trivial to minimize, but using this algorithm, we would have a simplex of 2 points. Let those points at some point using the algorithm be and . Then the functionvalues will both be , and the algorithm will stop. Instead, I changed this to checking the value of the centroid of the simplex.