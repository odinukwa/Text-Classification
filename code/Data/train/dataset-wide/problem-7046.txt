There are $N+1$ bidders. So we only care about the second highest bid. That's the same as finding the highest bid amongst the remaining $N$ bidders. The expected second highest bid is given by: $$b \cdot Pr[b] \cdot Pr[b \geq b_{-i}] = b \cdot f(b) \cdot F(b)^{N-1} = b \cdot dF(b)^{N}$$ As expected value is an average, we divide out by the probability that $b \leq \beta$, which is $F(\beta)$. Thus, we have: $$\mathbb{E}[b^{[2]} | b^{[2]} \leq \beta] = \dfrac{1}{F(\beta)}\int_{0}^{\beta} bdF(b)^{N}$$ 

The matching generated by the Gale-Shapely algorithm is in the core. An imputation belonging to the core satisfies the property that no coalition can collude their initial endowments and improve its members' outcomes. An imputation is Pareto optimal if no set of agents can improve their outcomes without another player's outcome being less favorable. So core allocations are Pareto optimal. For more on Gale-Shapley, check out my blog: $URL$ 

If you aren't interested in learning from a game and decision theoretic perspective, I'm not exactly sure why you're posting on an economics forum. Because that's what learning really is, from an economics perspective. AI really breaks down into three subfields: logical, behavioral, and machine learning. The logical subfield deals with logical reasoning, automated proof-writing, automated conjecture making, and such. Behavioral AI is really more in line with theoretical economics- game theory, decision theory, mechanism design, etc. Machine learning is really what constitutes mainstream AI research nowadays. This is really due to the fact that we now have the resources and tools to better deal with big data, rather than a philosophical revelation or technical breakthrough. Hot topics in computer science are very industry and money driven (as a theorist, I would argue too much so). Machine Learning really boils down to applying a stochastic process and refining a model. There isn't so much learning going on, just enhanced stupidity that works well sometimes. That's not to dismiss Machine Learning, but we should call it what it is. I would definitely recommend AI, Machine Learning, and Evolutionary Game Theory, though. Russell and Norvig is the established classic AI text, and it has sections on Machine Learning as well. Link: $URL$ Evolutionary Game Theory uses similar techniques as Machine Learning. It relaxes the assumptions of Neoclassical Game Theory. Agents need not be perfectly rational. They can have imperfect information and adjust their strategies myopically. The game is played repeatedly. We then see how "mutation" (such as human error or experimentation) in enough agents drives changes in equilibrium. So we have a dynamical process to select equilibria in games. We can apply dynamics such as the imitation dynamic, the best response dynamic, etc. Weibull ($URL$ and H. Peyton Young are both good introductions ($URL$ I took a seminar in Economics this past spring, the first half of which was Evolutionary Game Theory. We went through a bunch of papers as well; a subset of the following. One paper I enjoyed was Competitive Behavior in Market Games: Evidence and Theory. It showed that as the number of agents was made sufficiently large, that evolutionary forces drove the Nash equilibrium to the Walrasian equilibrium (under certain assumptions). This provides a behavioral motivation for the study of r-fold replica economies in the general equilibrium setting. Mark E. Schaffer (1989): “Are Profit-Maximisers the Best Survivors?” Journal of Economic Behavior and Organization, 12, 29-45. Mark E. Schaffer (1988): “Evolutionarily Stable Strategies for a Finite Population and a Variable Contest Size,” Journal of Theoretical Biology, Vol. 132, No. 4, 469-478. Hehenkamp, B., W. Leininger, and A. Possajennikov (2004): “Evolutionary equilibrium in Tullock contests: spite and overdissipation,” European Journal of Political Economy, Vol. 20, 1045–1057. Duffy, J., A. Matros, and T. Temzelides (2011): “Competitive Behavior in Market Games: Evidence and Theory,” Journal of Economic Theory 146, 1437-1463. Kandori, M., G. Mailath, and R. Rob (1993): “Learning, Mutation and Long Run Equilibria in Games,” Econometrica, 61, 29-56. P. Rhode, and M. Stegeman (1996): “A Comment on ‘Learning, Mutation, and Long-Run Equilibria in Games’,” Econometrica, 64, 443-449. W. Sandholm (1998): “Simple and clever decision rules for a model of evolution,” Economics Letters, 61, 165-170. Young, P. (1993): “The evolution of conventions,” Econometrica, 61, 57-84. Young, P. (1993): “An Evolutionary Model of Bargaining,” Journal of Economic Theory 59, 145-168. M. Saez-Marti and J. Weibull. (1999): “Clever agents in Young's evolutionary bargaining model,” Journal of Economic Theory 86, 268-279. Matros, A. (2003): “Clever Agents in Adaptive Learning”, Journal of Economic Theory, 111, 110-124. Ellison, G. (1993): “Learning, local interaction and coordination,” Econometrica, 61, 1047-1072. Glenn Ellison (2000): “Basins of Attraction, Long Run Equilibria, and the Speed of Step-by-Step Evolution,” Review of Economic Studies, 67 (1), 17-45. Bergstrom, T. and Stark, O. “How Altruism Can Prevail in an Evolutionary Environment.” American Economic Review, May 1993 (Papers and Proceedings), 83(2), 149-55. Eshel I., L. Samuelson and A. Shaked (1998): “Altruists, Egoists, and Hooligans in a Local Interaction Model,” The American Economic Review 88(1), 157-179. Matros, A. (2012): “Altruistic Versus Egoistic Behavior in a Public Good Game,” Journal of Economic Dynamics and Control 36, 642-656. Robson, A., and F. Vega-Redondo (1996): “Efficient Equilibrium Selection in Evolutionary Games with Random Matching,” Journal of Economic Theory, 70, 65-92. Josephson, J., and A. Matros (2004): “Stochastic Imitation in Finite Games,” Games and Economic Behavior, Volume 49, Issue 2, 244-259. 

Each player seeks to maximize his or her revenue. As you said, in the Cournot model, the player varies the output. In the Bertrand model, the player varies the price. So we first solve for $Q_{2}$ as a function of $P_{2}$: $$Q_{2} = 200 - 2P_{2} - 0.8Q_{1}$$ We then substitute $Q_{2}$ into $P_{1}$ to get: $$P_{1} = 100 - 0.5Q_{1} - 0.4 (200 - 2P_{2} - 0.8Q_{1}) = 50 - 0.18Q_{1} + 0.8P_{2}$$ Player $1$'s maximization problem is: $$\max_{Q_{1}} 50Q_{1} - 0.18Q_{1}^{2} + 0.8P_{2}Q_{1}$$ Which yields the first order conditions: $$0.36Q_{1} = 50 + 0.8P_{2} \implies Q_{1}^{*} = \frac{1250}{9} + \frac{20}{9}P_{2}$$ Now we can substitute $Q_{1}^{*}$ into $Q_{2}$ to get: $$Q_{2} = 200 - 2P_{2} - \frac{4}{5}(\frac{1250}{9} + \frac{20}{9}P_{2})$$ Now maximize $Q_{2}$ with respect to $P_{2}$. Can you take it from here? 

I followed Oliv's suggestion, which was quite fruitful. So we have the differential equations: $$g_{1}^{\prime}(b) = \dfrac{1}{2} \cdot \dfrac{g_{1}(b) - 1}{g_{2}(b) - b}$$ And: $$g_{2}^{\prime}(b) = \dfrac{3}{2} \cdot \dfrac{1}{g_{1}(b) - b}$$ With the boundary conditions $g_{2}(0) = 0$ and $g_{1}(\overline{b}) = g_{2}(\overline{b}) = 3$, where $\overline{b}$ is the maximum bid. Now we guess that $g_{1}(b) = \alpha b + \gamma$ and $g_{2}(b) = \delta b + \lambda$. Applying $g_{2}(b) = 0$ yields that $\lambda = 0$. Next, I substitute $g_{1}(b)$ into $g_{2}^{\prime}(b)$ to obtain: $$g_{2}^{\prime}(b) = \dfrac{3}{2} \cdot \dfrac{1}{(\alpha - 1)b + \gamma}$$ Integrating $g_{2}^{\prime}(b)$ yields $$g_{2}(b) = \dfrac{3}{2(\alpha - 1)} ln( (\alpha - 1)b + \gamma)$$ We note there is no constant when integrating, as $g_{2}(b) = \delta b$. We now apply $g_{2}(0) = 0$ again, concluding that $ln( \gamma) = 0$. And so $\gamma = 1$. Thus, $g_{1}(b) = \alpha b + 1$. We now solve: $$g_{2}(\overline{b}) = 3 = \dfrac{3}{2(\alpha - 1)} ln( (\alpha - 1)\overline{b} + \gamma)$$ From this and noting that $g_{1}(\overline{b}) = 3 = \alpha \overline{b} + 1$, we obtain: $$e^{2(\alpha - 1)} = 3 - \overline{b} \implies \overline{b} = 3 - e^{2(\alpha - 1)}$$ Plugging this into $g_{1}(b)$ yields: $$g_{1}(\overline{b}) = \alpha(3 - e^{2(\alpha - 1)}) + 1 = 3$$ Which implies that the solution $\alpha = 1$. Thus, $\overline{b} = 2$. So $\delta = \dfrac{3}{2}$. Thus, $g_{1}(b) = b + 1 \implies \beta_{1}(v) = v - 1$; and $g_{2}(b) = \dfrac{3}{2}b$ implies $\beta_{2}(v) = \dfrac{2}{3}v$ as desired. 

Actually, it's a discrete model. In more traditional fields of economics, we have continuous variables. So linear programming makes sense. We could actually formulate an integer-linear program for the stable-marriage problem if we look at it from a graph theoretic perspective. Matching problems can be formulated in the language of flows. And we can write flow problems as LPs. The flow constraints form a convex polytope. If the graph is bipartite, the vertices of the polytope are the matchings. The trick here is that we have to add additional constraints to ensure we end up with the correct matching (since the matching from the Gale-Shapley algorithm is unique, regardless of the order in which the men propose). Even if we go to the trouble of formulating the linear program, solving an LP for this problem by hand or by a computer is less efficient than using the algorithm. 

The Weierstrass Extreme Value Theorem guarantees this. However, it's used so frequently that economists take it for granted or omit it in graduate courses and research papers. MWG is a maturity book. Part of mathematical maturity is being able to fill in the details for a proof. 

MR and MC are first derivatives of the Revenue and Cost functions respectively. If for every point greater than 0, we have Revenue greater than Cost, then no global maximum exists. This usually isn't the case though. And if we have multiple points where the tangency condition holds, we have to check each one to find the best. 

Econ isn't as sequential as physics. The two core undergrad classes that everyone takes are Intermediate Micro and Intermediate Macro. Varian is the standard for Intermediate Micro. Undergrads also take some sort of econometrics class, which can widely vary depending on the target audience (i.e., business majors vs double-majors). It's not uncommon for there to be an Econ degree geared towards double majoring. After these courses, students generally pick about 5 electives. The classic books largely depend on the subjects at the undergrad levels. For Game Theory, Osborne is a good text as is Fudenberg and Tirole. The latter is a solid grad textbook as well. A good Auction Theory text is Krishna's. At the grad level, folks generally go for PhDs over Masters degrees. While Masters programs exist, they aren't as common as in math, physics, or CS. A good math for economists text is Simon and Blume. Mas-Collel is the classic for the grad micro sequence, which highlights game theory, IO, and general equilibrium. Jehl and Reyni is another good reference for micro, and it's a friendlier read. Folks at the grad level also take sequences in macro and metrics. You may wish to check out Aris Spanos' text for metrics. 

Game Theory is not quite pure math, but not quite applied math either. A lot of areas within mathematics converge in game theory as well- real analysis and topology, linear programming and polyhedral theory, linear algebra, and graph theory amongst others. I would suggest a senior undergraduate sequence in real analysis, a course in optimization (linear or integer programming), and a graduate course in linear algebra. Some bonus courses are graph theory, a course in algorithm design with an emphasis on complexity, and graduate real analysis (measure theory). Optimization courses generally touch upon polyhedral theory, especially integer programming courses. Granted, economics models tend to be more continuous. Game theorists have become increasingly interested in networks, so graph theory is very nice to have. There are papers in the last ten years that have adopted spectral techniques in networks which makes linear algebra at the graduate level very important. Really, the advice to major in math is spot on. Econ grad students either have the math background or continually struggle with it. The latter is a bad position in which to be. 

If you are looking for a good, general graph theory reference, Doug West's textbook is the way to go. It's very readable, and has good material on network flows, matchings, and random graphs as well (which are particularly relevant in economic networks). You may also be interested in reading some of Hans Haller's papers on economic networks. Haller has recently focused on strategic network formation. He isn't on Ideas, but his CV as of March 2015 is here: $URL$ Networks, Crowds, and Markets is another good read: $URL$ 

Chess is EXPTIME-Complete, which makes it significantly harder than NP-Complete problems. Perhaps you are interested in the study of economic networks. Strategic network formation sounds like a good starting point. A lot of the work examines when certain classes of graphs arise under pure strategy Nash equilibria. There are exponentially many pure strategies. Enumerating the vertices of the polytope is likely not feasible. Edit: Some of the big names in the area include Matthew O. Jackson, Rachel Kranton, Sanjeev Goyal, and Hans Haller. I would start with their papers. In particular, Matthew O. Jackson has a book on the subject. Here are links to their homepages/CVs so you can scout out their publications. Economic networks are a pretty hot area at the moment, so you can likely look at journals like Econometrica to see what is being published. $URL$ $URL$ $URL$ 

Any pure strategy Nash equilibrium is implicitly a mixed-strategies Nash equilibrium. Since the valuations vary, it's a good indicator we want to consider mixed-strategies. The fact that the problem tells us this is a stronger indicator, though I'm sure not the axiomatic justification you are seeking. :-) Consider player $1$. We have player $1$'s expected profit: $\mathbb{E}[\Pi_{1}(b)] = (2-b) Pr[b \geq \beta_{2}(v_{2})]$, where $b$ is player $1$'s bid, $\beta_{2}$ is player $2$'s bidding strategy, and $v_{2}$ is player $2$'s valuation. We can assume $\beta_{2}(0) = 0$ (because if $\beta_{2}(0) > 0$, player $2$ can improve upon this by decreasing his bid). Since we are only considering two potential valuations for player $2$, we can assume $\beta_{2}(v) = av$, for some constant $a \in \mathbb{R}_{++}$. (That is, given the two points $(0, 0)$ and $(2, \beta_{2}(2))$, we just draw a line between them). Observe that $Pr[b \geq av] = Pr[v \leq \frac{b}{a}] = \frac{b}{2a}$, with the last inequality since we have a 50-50 chance on the valuation of player $2$. Now for a Nash equilibrium, player $1$ seeks to maximize his expected value. This is given by the following optimization problem: $$\max_{b} (2-b) \cdot (\frac{b}{2a})$$ This yields the first order conditions: $\frac{1}{2a} \cdot (2 - 2b) = 0$, and we obtain that $b = 1$ is our only solution for player $1$. This answer should be reasonably intuitive. Now player $2$ only wins if his valuation is $2$. So he players $\beta_{2}(2) = 1$ and $\beta_{2}(0) = 0$. 

If you are talking pure strategies Nash equilibria, then yes. Otherwise, you could have infinitely many mixed strategies Nash equilibria. Take a matrix in which all cells have the payoff vector $(1,1)$. So any convex combination of pure strategies is a Nash equilibrium.