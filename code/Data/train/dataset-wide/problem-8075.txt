Let $(\Omega, \mathcal{A},P)$ be a probability space, and let $(\mathcal{F}_k)_{k \geq 1}$ be a filtration which converges to $\mathcal{A}$. I suppose it is true that $$ E \left( \big(E \left( X | \mathcal{F}_k \right) \big)^2 \right) \to E \left(X^2 \right). $$ How to prove this? I guess one will need Jensen's inequality and a convergence theorem for submartingales, but cannot find the right reference (I am working on number theory, not probability). (If you know an answer, please also provide a citable reference.) 

Let $A$ be a set of $N$ distinct positive integers. For every integer $n$, write $rep(n)$ for the number of representations of $n$ as a difference of two elements of $A$. Then the additive energy of $A$ is given by $\sum_n rep(n)^2$. Assume that the additive energy is large (between $N^3/(\log N)$ and $N^3$, say). Examples for this would be the sets $$ \{1, \dots, N\} $$ or $$ \{k, 2k, \dots, Nk\} $$ or $$ \{k+1, k+2, \dots, k+N\} $$ for some positive integer $k$, or randomly (in a suitable way) constructed subsets of a segment of the positive integers. Now in all these examples, the set of those number $n$ for which $rep(n)$ is large (in other words, those numbers which make the essential contribution to the additive energy) has a very strong structure (it is an interval, or consists of a fixed integer multiple of all integers in an interval). This seems to be necessary - for example, it seems that for the sets $\{n: ~rep(n) \geq N/100\}$ or $\{n: ~rep(n) \geq N/\sqrt{\log N}\}$ one cannot get any arbitrary subset of $\mathbb{N}$, but only sets which have a very strong ("interval-like" or "self-similar") structure. Is there any theory for this? 

Let $B(n,p)$ be a binomial distribution, where $p$ is fixed. Let $\varepsilon > 0$ be fixed and "small". I need a lower bound for the tail probability of this distribution, at distance $\varepsilon n$. It seems to me that for a random variable having this distribution one should essentially have $$ P ( |X-np| \geq \varepsilon n) \gg e^{-\sigma^2 \varepsilon^2 n/2}, $$ where $\sigma^2$ is the variance. Can someone give me a reference for such an inequality? (I suppose one could show this using heavy machinery, such as Kullback-Liebler distance etc., but it should be a simple and basic fact. Anyway, I have not found a reference. Thanks for your help.) 

A $\sigma$-algebra $\mathcal F$ over $\Omega$ is generated by an countable partition if there exits a countable partition $\mathcal B = \{ B_i \}$ of $\Omega$ such that $\mathcal F = \sigma(\mathcal B)$. Now let $\mathcal G$ be an arbitrary $\sigma$-algebra over $\Omega$. Is it possible to find $\sigma$-algebras $\mathcal G_n$ generated by countable partitions approximating $\mathcal G$, i.e. such that $G_1 \subseteq G_2 \subseteq G_3 \subseteq \ldots$ and $\mathcal G = \bigcup_n \mathcal G_n$? One naive idea of me is to take some arbitrary $A_1 \in \mathcal G$, and then set $\mathcal B_1 = \{ A_1, A_1^C \}$ and $\mathcal G_1 = \sigma(\mathcal B_1)$, then take some $A_2 \in \mathcal G$ with $A_2 \cap A_1 = \emptyset$ and set $\mathcal B_2 = \{ A_1, A_2, (A_1\cup A_2)^C \}$ and $\mathcal G_2 := \sigma(\mathcal B_2)$ and so on. But this will not work, for example if $\mathcal P(\mathbb N) \subseteq \mathcal G$ and I choose $A_i := \{ i \}$, then as the "limit" $\sigma$-algebra I will get $\sigma(\{ A_i \}) = \{ M : M \subseteq \mathbb N \mbox{ or } X\setminus M \subseteq \mathbb N \}$, which has not to be the the original $\sigma$-algebra with which I started, for example if $\mathbb G = \mathcal B(\mathbb R)$ if fullfills $\mathcal P(\mathbb N) \subseteq \mathcal G$. 

In his classic textbook Foundations of the Theory of Probability Kolmogorov defines Independence a little bit differenent then it is usually done today. He denotes a probability space by $(E, \mathcal F, P)$, on page 9 he wrote: 

What do you know about the complexity of this decision problem, is it in $P$ or in $NP$? Is it in $P$ if we fix $k$? 

Furthermore, if $\mathcal A$ is not permutation-free than there exists a word $w$ and $n > 1$ states $\{ s_1, s_2, \ldots, s_n \}$ with $\delta(s_1, w) = s_2, \delta(s_2, w) = s_3, \ldots, \delta(s_n, w) = s_1$. Meaning $\delta(s_1, w^n) = s_1$, so in an permutation-free automaton $\delta(q, w^n) = q$ always implies $\delta(q, w) = q$, meaing that if $w^n$ has a loop, then already $w$ has a loop. 

I think I have an answer for the case p = 1, K = 2. I write "I think" because my computation does not coincide with the example values for $N=4$ posted earlier by OP in a comment, but I really cannot find any error in my proof, so I wanted to share it. As already mentioned, we only need to consider permutation measures of the form $\mu = \sum_{i=1}^N \frac{1}{N} \delta_{i,\sigma(i)}$, since these are the extremal points of the set we optimize over. For any such $\mu$, we can define a coupling $\pi$ by $\pi_{(i,\sigma(i)),(i,j)} = 1/N^2$ for $i,j \in \{1,...,N\}$ and $\pi_{(i,j),(i',j')} = 0$, if $i,j,i',j'$ are not of the form as before. That this is an admissible coupling in the definition of $W_1$ is trivial. The corresponding "value" is $$ \sum_{1\leq i,j,i',j' \leq N} ||(i,j)-(i',j')||_1 \pi_{(i,j),(i',j')} = \sum_{1 \leq i,j' \leq N} |\sigma(i) - j'| \frac{1}{N^2}. $$ We further show that this value is minimal if $\mu$ is the monotonic or comonotonic measure, which will yield the claim. I only show this for the monotonic case, $\mu = \frac{1}{N}\sum_{i=1}^N \delta_{i,i}$. Then for any admissible coupling $\hat{\pi}$, by the constraints in the calculation of the Wasserstein distances, we see \begin{align*} \sum_{1\leq i,j,i',j' \leq N} ||(i,j)-(i',j')||_1 \hat{\pi}_{(i,j),(i',j')} =& \sum_{1\leq i',j' \leq N} \sum_{1 \leq i \leq N} ||(i,i)-(i',j')||_1 \hat{\pi}_{(i,i),(i',j')} \\ \geq& \sum_{1\leq i',j' \leq N} \sum_{1 \leq i \leq N} ||(i',i')-(i',j')||_1 \hat{\pi}_{(i,i),(i',j')}\\ =&\sum_{1\leq i',j' \leq N} |i'-j'| \frac{1}{N^2}, \end{align*} where the inequality is elementwise and the last term corresponds to the value for the coupling $\pi$. Note that this only shows that monotonic/comonotonic measures are maximizers, but not that these are the only maximizers. 

Let $(E,d)$ be a bounded polish space (separable, complete metric space satisfying $\sup_{x,y\in E} d(x,y) < \infty$). By $\mathcal{P}(E)$ we denote the space of Borel probability measures on $E$ endowed with the topology of weak convergence. We fix $\varepsilon > 0$, $\theta \in \mathcal{P}(E)$ and a stochastic kernel $\pi$ on $E$ (I.e. $\pi: E\times Bor(E) \rightarrow [0,1]$ such that $\pi(x,\cdot)$ is a Borel measure for all $x\in E$ and $\pi(\cdot,A)$ is measurable for all Borel sets $A\subseteq E$). We assume that $\pi$ satisfies the strong Feller property, i.e. $x_n \rightarrow x\in E \Rightarrow \pi(x_n,\cdot) \stackrel{w}{\rightarrow} \pi(x,\cdot)$, where $\stackrel{w}{\rightarrow}$ denotes weak convergence. We define \begin{align*} M := \{ \mu \in \mathcal{P}(E^2) &: \text{If } \mu = \mu_1 \otimes K, \text{ where } \mu_1 \in \mathcal{P}(E) \text{ and } K \\ &\text{ is a stochastic kernel on } E, \text{ then } \\ &W_1(\mu_1,\theta) \leq \varepsilon \text{ and } \\&W_1(K(x,\cdot), \pi(x,\cdot)) \leq \varepsilon \text{ for } \mu_1\text{-almost all } x\in E.\}, \end{align*} where $W_1$ is the first Wasserstein distance on $\mathcal{P}(E)$ given by \begin{align*} W_1(\nu,\mu) &= \inf_{\pi \in \Pi(\nu,\mu)} \int_{E^2} d(x,y) \pi(dx,dy)\\ &= \sup_{\substack{f:E\rightarrow \mathbb{R},\\ |f(x)-f(y)| \leq d(x,y)}} \left( \int_E f d\nu - \int_E f d\mu\right) \end{align*} and $\Pi(\nu,\mu)$ is the set of measures on $E^2$ with first marginal $\nu$ and second marginal $\mu$. Question: Is M closed? Remarks: By boundedness of $(E,d)$ weak convergence is compatible with the Wasserstein distance, i.e. $\mu_n \stackrel{w}{\rightarrow} \mu \in \mathcal{P}(E) \Leftrightarrow W_1(\mu_n,\mu) \rightarrow 0$. If $\pi$ does not satisfy the strong Feller property, $M$ is in general not closed. Take for example $\varepsilon = 0.5, E = [0,1], \theta = \delta_0, \pi(0,\cdot) = \delta_1$ and $\pi(x,\cdot) = \delta_0$ for $x \neq 0$. Then $M\ni\delta_{1/n} \otimes \delta_0 \stackrel{w}{\rightarrow} \delta_0 \otimes \delta_0 \not\in M$. Even if $\pi$ is constant, I don't know whether $M$ is closed and would be very interested in an answer for this case as well. 

Every finite abelian group is the direct product of its cyclic groups of prime order, and every commutative monoid divides a product of its cyclic submonoids. Could these results generalized to locally commutative semigroups? Here a semigroup is called locally commutative if for every idempotent $e \in S$ the semigroup $eSe$ is commutative. 

Two infinite words $\xi, \eta \in X^{\omega}$ are separated by an (Büchi-)automaton if it accepts one but not the other. Denote by $F_n(\xi)$ the factors of length $n$ of an infinite word $\xi$ and also by $F_n^{\infty}(\xi)$ the factors of length $n$ that occur infinitely often. Define two equivalence relations on words: $$ \xi \sim_k \eta \mbox{ iff } \xi[1\ldots k] = \eta[1\ldots k] \land F_k(\xi) = F_k(\eta) $$ and $$ \xi \sim_k^{\infty} \eta \mbox{ iff } \xi[1\ldots k] = \eta[1\ldots k] \land F_k^{\infty}(\xi) = F_k^{\infty}(\eta). $$ Now I am interested in two questions: 1) If for two infinite words $\xi \sim_k \eta$, i.e. their prefix and factors of length $k$ coincide, what is the size of the minimal automata separating them, and 2) if for two infinite words $\xi \sim_k^{\infty} \eta$, what is the minimum size of an automata separating them? For i) I believe there is no interesting relationship, cause consider $\xi_i = 0^i 1 0^{\omega}$ and $\eta_i = (0^i1)^{\omega}$ then $\xi_i \sim_i \eta_i$ for all $i$ and they could always be separated by a two-state automata which stays in the first state as long as it read $0$'s, switches to the second state on the first $1$, and then stays there as long as just $0$'s are read, so accepting $\xi_i$ but not $\eta_i$. This lead me to consider the second equivalence relation. Here for example $\eta_i = (0^i1)^{\omega}$ and $\xi_i = 0^i100^i1000^i1\ldots$, then $\xi_i \sim^{\infty}_i \eta$ and I guess the minimal automata needed to separate them has $i+2$ states, reading $0$'s in the first state, switch to second state on first $1$, and then a loop which counts the $0$'s (need $i$ states for the loop) and goes back to the second state if $i$ $0$'s are followed by a $1$, so passing the second state an infinite number of times. This automata accepts $\eta_i$ but not $\xi_i$. Are there any lower bounds on the size of an automata separating two words with $\xi \sim_k^{\infty} \eta$? Added: A finite automata accepts an infinite word according to the Büchi-condition if there is a prescribes set of states such that the infinite words enters some state of this set an infinite number of times, see Wikipedia.