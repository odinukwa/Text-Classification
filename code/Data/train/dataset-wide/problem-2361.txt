In the dialog you ensure the TCP/IP properties are set and that the option is set, so that it looks likes the following screen shot: 

I'd recommend reading up on the CREATE TABLE statement and on the String Functions. Then carry on to the Data Type Conversion documentation and have a glimpse at the sp_executesql syntax. Good Luck. 

When you look at the General tab in the Login Properties of the sa account, you will notice different settings. One of them being Enforce password policy. I discussed this setting in my answer to the question How to lock a sql login after N unsuccessful login attempts. Possible reasons for change in lockout behaviour If you previously didn't have an Active Directory policy for locking out accounts, then ... 

So even though you seemed to have dropped, converted and re-created the relevant information, your query was still creating an execution plan based on old information. Cleaning up the database with rectified your issues. 

Fixing Permissions To alter the directory and file permissions you would have to set off two commands like this: Directory Permissions 

SQL Server will then use this policy if the option is checked. A technical overview of the account lockout policy can be found here: Reference: Account Lockout Policy Technical Overview (MSDN) Reference: Account lockout threshold (MSDN) Locked out SQL Login Here is what happens after a SQL Login has been locked out after the set amount of incorrect logins (15 in my case as domain policy). You can see the is set. This can be unset to unblock the account. 

This will create a database with three files which all have the *.txt extension. Query sys.master_files 

You might be able to query your database with the help of the Needle in a Haystack code. From the author 

Here is an example of a script that can be generated when you iterate through your steps and instead of clicking on OK, you click on the generate script icon and send to a new query window: 

So far no space has been released inside the TLog file for the database Engine to reuse... Automatic Truncation of The TLog File ...but if the Database Engine has some cycles to spare and is not under very heavy pressure it will occasionally have a look at the TLog file, notice the Checkpoint and release the VLFs for reuse. The space inside the TLog file is still used by the VLFs (same size, same location) but they are free to be reused. This is documented in Transaction Log Truncation: 

There is a slight chance that native backups could encounter an issue when the 3rd-party software triggers the SQL Server VSS Writer service, which mostly results in an message in the SQL Server . Having native backups run at this time could possibly result in errors. Then you have noticed that 

...then you might want to consider using the EXPDP (see: Data Pump Export) and IMPDP (see: Data Pump Import). These tools provide you with the ability to obtain schema-specific data and import the data into different tablespaces; or to filter the export via table names, dependencies. On import the schema can then be re-linked to a different schema (see: REMAP_SCHEMA), etc. SQL Developer SQL Developer has the capability to export data using a wizard. This is similar to the built-in EXPDP and IMPDP tools provided with the RDBMS installation. A quick guide to using the wizard can be found at: Exporting and Importing Metadata and Data and there in the section Using SQL Developer for Exporting and Importing (Tools | Database Export). 

As you may have noticed, the list of components to select from in the Custom installation type is much shorter than the list of items that actually get installed. Or put differently: For each product component that a user selects in the Available Product Components screen in a "Custom" installation, multiple items (from the above list) will be installed in the background. My Question Is there a document/source/link that explains which items get installed when I click on an individual product component in the Custom installation type? A document that nearly achieves this is: 12.1.0.2 client component description for windows (Doc ID 2126734.1) Background It makes a big difference in size if I select the "Administrator" (1.5 GB), the "InstantClient" (350 MB) or the "Runtime" (1.1 GB) installation type. Keeping the client installation thin ("Custom") will have its advantages... References 

A PostgreSQL instance will keep a client connection up and running until the connection either reaches a specified client timeout or the client (application) closes the connection. A change of password has no effects on existing connections and will only affect new connections. There is no mechanism that constantly checks if the connection is still "password valid". A client connection is a one time authentication and if it was valid at the time of authentication will keep on being valid until closed. 

An then verify the settings for the portion, by checking that ... a) TCP Dynamic Ports is set to (No value/empty) b) TCP Port is set to (No value/empty) c) The screen should look like this: 

Instance | IP | Port | Alias (CNAME) Each instance is related to an IP address and each IP address has an individual Alias (CNAME) so that the SQL Server can always listen on port 1433. This simplifies the firewall configuration as the rules only have to be added for the default SQL Server port. Hmmm. 

Basically, I set a string values, output that value, and output the value, then the ed value and output it. Results The results were quite interesting: 

(non-official) use case for There is a case that has been blogged about by Thomas Kejser in which he uses "faked" s to populate a "smaller" table with values that could possibly be produced in the future. He goes on to explain a possible situation in which you would want to implement "wrong" statistics in order to deceive the query analyzer to use "fabricated" statistics to produce a better execution plan for values that have only just been inserted and are thus not normally updated fast enough: 

It's a little tricky with multiple IP addresses and different ports when configuring SQL Server. The most important bit, is that the whole configuration has to be done with the SQL Server Configuration Manager. 

You then switch to the IP Addresses register and find your first IP address. In this example the settings for the first IP (192.168.0.30) are found at the IP2 section. It will look like this: 

In the case that this doesn't work you may have broken ACLs (permissions) at some level in the SQL Server Program Files structure. SQL Server Accounts And ACLs Your service still isn't starting and it could still be an issue with permissions (ACLs)? Then you might have to fix the file/folder permissions. The full list of SQL Server Account and the required permissions are listed in the following exhaustive documentations: 

This means that if the record for the previous DIFF or FULL backup was unable to be recorded in the msdb database, then the TLOG files will never be deleted. Special Solution 

Adequate TLog file sizing Don't try and shrink the TLog file too much. It will grow again. Instead try sizing the TLog file according to your observations, allow for a little growth and monitor how full the TLog file is. Frequent TLog Backups If you have a look at my simplistic model, you may have noted that the TLog didn't have a lot of CHECKPOINTS logged. If the database has to handle a lot of transactions modifying data, then shortening the interval between TLog backups can help keep the TLog from growing, because a TLog backup creates a CHECKPOINT which allows the data to be written to the database. Let's add an example using my over simplistic model. Additonal Backup A backup is performed and logged in the TLog and during the backup a user modifies data: 

I would recommend consulting with a consultant/company that specialises in migrating Oracle Forms and Reports. Why? Because we recently performed a similar migration and after 2 months we were not finished. Oracle has changed some things internally and features that previously worked can cease to function with the new version. Oracle has a special site dedicated to this task: Fusion Middleware Upgrading Oracle Forms 6i to Oracle Forms 12c I know this is not a complete answer, but so much depends on the complexity of your current environment, that it would be very hard to give you an estimation. 

SQL Server Agent Jobs Not Being Logged in Msdb There are cases then the job steps of jobs executing are unable to enter the details into the msdb job tables due to contention (locks, blocks, long running transactions). The tables required by the backup job are being locked by another process (another maintenance plan / other 3-rd party tools / cleanup jobs / a long running transaction) and might be determined as the victim of a deadlock and rolled back. The data is missing in the msdb database and because no FULL or DIFF backups exist, nothing gets deleted. Ola checks this with the following part in the stored procedures: 

Solution (only if the above mentioned matches) The solution is apparently to turn on the trace flag 1224 which will turn off lock escalation: SQL Server Lock Escalation and Blocking 

Reference: How much memory does my SQL Server actually need? (SQLSkills.com) There are some other good articles out their that explain how SQL Server uses RAM. 

Mongodb with volume doesn't work (Operation not permitted) The initial person writing the issue had already determined that it wouldn't work and was in search of a solution. 

To come back to your example with the sys.colums view: You have been granted the permissions to SELECT from the view, but you do not have permissions to actually execute the sysconv function directly, which is the definiton of a column in the result set. It has been hidden from your prying eyes. 

... varying performance, index fragmentation resulting in slightly worse performance than when defragmented. Possible solutions 

Your question would be better suited for the Unix or Ubuntu site because it looks like a basis Linux issue. Anyway here goes. Solution After you have logged in to your Ubuntu server, you should be on a shell prompt similar to the following: 

Everywhere where MSSQLServer is referenced in the documentation, replace with the account you wish to run your SQL Server (INSTANCE) with. For example when checking the Reviewing Access Control Lists Created for SQL Server Service Accounts section of the document, ensure that your YourServiceAccount has access to: 

Reference: Database Components and the SYSAUX Tablespace If you can reduce the size of the data being stored by the components, then you can reduce the size of the required SYSAUX tablespace. The largest portion of the SYSAUX tablespace is occupied by the Automatic Workload Repository (AWR). The following size recommendations are provided by Oracle to determine the AWR size and to a large portion the size of the SYSAUX tablespace: 

Of course, you could omit the search predicate and enjoy the information overflow of the 2072 objects found in a SQL Server 2014 instance: 

If the part is left in the it breaks the Simpana backup, which is why we omitted it. The above configuration should result in the WAL files being copied from the directory to the directory, when ... 

Well you could run the following query to retrieve the jobs run between two times or you could change the expression to catch jobs that ran for a certain duration. 

...then you might not have Enterprise Management Console installed. The Management Console is not required to have a fully functional Oracle RDBMS instance up and running. 

Basics of Transaction Log files Transaction Log files (TLog) are like a notepad with pages that hold all the information on anything that has changed during the day. The TLog (notepad) has a beginning and an end when it is opened. The TLog (notepad) will also know where it was before based on the LSN (log sequence number) (notepad: Post-IT Index). If deletes/inserts/updates are finished they are marked as COMMITed and (can be) removed from the TLog (notepad) when a backup occurs which results in a CHECKPOINT being set in the TLog file. In the notepad analogy the old notes get removed from where they were and because your notepad is always the same size, the removed pages get replaced with fresh white empty pages; be it at the beginning or at the end for your notepad. Why? Because your notepad only has space for 100 pages. The removed notepad pages are then stored in your central storage (binder). Following is a simplistic view of the TLog file. TLog after database has come online 

Try this query for your tablespace maximum chunk size tsfree.sql. This case of ORA-01658 concerns needing to make the tablespace bigger, which can be done by either extending your file, or adding another one. This is a good solution for ORA-01658 because repository tables need to be meticulously created keeping the extents of the table in mind. This information was taken from ORA-01658: unable to create INITIAL extent tips from the dba-oracle.com website. Disclaimer: I am in no way affiliated with the company. 

Alternative You could equally create a blocking firewall rule or hack the routing table on the server / network. 

SSMS is only a tool that connects to a SQL Server instance. SQL Server listens on a specific IP address for connections. It doesn't really care which tool is connecting. SQL Server is not like PostgreSQL that has a where you can restrict connections, nor is it MySQL where you assign permissions to a combination when creating the user login. Answer It's not currently possible by using simple means (PostgreSQL, MySQL), but if you are willing to start creating Logon Triggers (Microsoft Docs), then you might be able to build a restriction that meets your requirements. The SQL Syntax for triggers can be found in the article CREATE TRIGGER (Transact-SQL) (Microsoft Docs). The article lists an example for a Logon Trigger. Because your requirements are pretty dire, I am unable to provide a solid solution. Please edit your question and provide as much details as possible.