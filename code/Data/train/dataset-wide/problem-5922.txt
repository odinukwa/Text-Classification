Marx claimed that machines cannot "produce surplus value" but only redistribute labor and provide individual firms with a temporary market advantage. Nonetheless, many thinkers across the spectrum seem to believe in a globalized concept of "technological unemployment" or the idea that someday "robots can do all the work." While machines can clearly alter the nature of work and redistribute labor, can they globally "replace" labor? All other arguments aside, doesn't this ultimately violate the laws of entropy? After all, "life" is the only "perpetual motion machine," and without humans all machines would quickly cease to output "work." Ideally self-perpetuating machinery like the Von Neumann Replicator or Maxwell's Demon remain mathematical and "frictionless." Peripheral evidence supports this. Obviously, machines are made, fueled, and maintained by humans. Further humans feed, raise, and support the humans who make the machines, etc. Additionally, since the rise of "labor-saving" technology, employed global labor has only increased tenfold. This also suggests that machines redistribute, alter, and subdivide labor globally, but do not "reduce work" in any absolute, quantitative sense. While this is slightly trickier, I would also suggest, following Maxwell's Demon, that "mental labor" is not free and can only increase on a pyramid of "physical labor." The machine, in other words, only reduces work locally and always contains equivalent "work" as human labor distributed elsewhere in space and time. Even with "free," nonfossil solar power, the most efficient way to transform it into "socially useful labor" is to capture it photosynthetically and feed it to humans. Isn't this a perfectly plausible argument? Doesn't the common idea of "robots doing all (or most) of the work" violate the second law of thermodynamics? Isn't machine replacement of human labor in an absolute and global sense ultimately fallacious? Is there really a physical "free lunch" inside the labor capacities of machines? Note: I posted a similar question on Economics Stack, but I believe it requires a broader, more interdisciplinary approach best suited for philosophy. The logical implications of entropy often appear here. Note 2. I am having a temporary Java-script issue preventing use of "Comments," so may comment or inquire about answers later. 

I have always been perplexed by a seeming paradox in probability that I'm sure has some simple, well-known explanation. We say that a "fair coin" or whatever has "no memory." At each toss the odds are once again reset at 50:50. Hence the "gambler's fallacy." After 10 heads, the odds of another head are still said to be 50:50. The same after 20, 40, 80... heads. Yet we also know that the series will converge upon an equilibrium of heads:tails. And indeed this is countable in fairly short order. The convergence appears pretty quickly. How can both be true? Isn't there something in the physical series of tosses that "remembers"? Isn't there necessarily some slightly better chance of a tails after 10 heads? How does logic resolve this absolute randomness in the particular events with a general law of convergence? I imagine this must be a well-known issue. I suppose it raises the larger issue of what sort of "causality" probability is. Note that I do not know symbolic logic so, embarrassingly, formal demonstrations are beyond my ken. 

No, your refutation is absolutely not sound and valid. But just for the sake of perversity, I will argue that it is, probably by accident, not necessarily invalid. The second law of thermodynamics holds for any and all "closed" systems and can be reversed locally, as with a refrigerator, by importing energy. As far as I know, we have no way to adequately define the state of "the universe" in these terms. And it is not as if the "big bang" or "dark energy" are comfortably understood. So while your question is by no means a refutation of a fundamental law of physics, it does perhaps expose the overreach of today's cosmological and highly speculative theories. Don't wait up for a call from the Nobel committee. 

Kant does explicitly address the question of suffering and suicide, rejecting such conditional applications of morality, but unfortunately I have no books presently at hand, so can't provide a reference or details of his reasoning. Even without the details, we can appeal to one basic aspect of Kant's transcendental and "deontic" morality. The case for "ending suffering" is clearly a personal and "consequentialist" approach to moral acts. The act is based not in the universal structure of rational being itself, but in the perceived consequences. Kant argues that such justifications presume we can predict the outcome, which we cannot. The limits of "pure reason" deny us this very knowledge. Here is precisely the slippery slope of secular, utilitarian ethics he was keen to avoid. In the case of personal suffering, two considerations intercede. First, we cannot know the outcome for others of our willed death... or of our reluctantly continued life. Second, we cannot even know the outcome for ourselves, since we must accept, as Kant did, both the limits of our knowledge and the a priori assumption of the immortality of the soul. Moreover, the structure of the "categorical" imperative as the "willing of a universal law" is meant to transcend personal, contingent circumstances, especially those guided by mere physical pleasure or suffering. By responding to such contingent determinants, we slip from the realm of "rational freedom" into the natural realm of mere physical reaction amid brute cause and effect. To justify suicide, we would have to assume that somehow bodily suffering is itself inherent to "rational free" existence, leading "rationally and freely" to self-termination, which obviously cannot be universally compatible with such "rational being." (It is worth noting that without Kant's Christian assumptions, existentialists might hold similar views, yet extend human freedom to the uniquely human act of suicide.) However, I have not addressed the vexed question of how exactly one is to judge various specific "actual" conditions in applying the categorical imperative, which has been criticized on precisely such grounds as an "empty formalism." I hope others can provide more detail, and the suicide citation. While most people would not accept Kant's pseudo-Lutheran strictures today, there is a great deal of wisdom in his concerns about the plasticity of "consequentialist" ethics. 

This is very good and possibly tragic question, and I am not the best one to answer it. But the short answer is: No. There is no faster "royal road," as Euclid first phrased it, to either mathematics or philosophy. Unlike the natural sciences, philosophy never erases its history. Thales and Heraclitus are still studied. Unlike mathematics there is no illusion of axiomatic closure and no obvious place to begin, except historically. So, one way to start is at the beginning. Whatever your field, it is always good to study some Plato. In your case, if you take a course you may want to look at his relationship with the Pythagoreans. You might also look at some related mathematical history. For example, the way in which Greek geometrical proofs using only straight edge, compass, and hand movements. No numbers. Do not neglect the history of your field, which does intersect with ancient philosophy. Or you could go in the other direction. Modern philosophy begins with Descartes, who, as you may know, was the first to link geometry and algebra. It continues up to Kant. And here you must be alerted to a fork in the road, referred to in philosophy as the "Continental" and "Analytic" traditions, and commencing roughly with Husserl and Frege. The "Analytic" tradition leans far more heavily on mathematics and logic. So this may be more in line with your interests. I would say that its central concern is how mathematics, whatever that is, links to logic and then language. But be aware, if you read or take a course in recent "analytical" philosophy about, say, logic, possible worlds, computing, AI, and such, that's fine, but you are not engaging with philosophy per se, from Thales and Plato all the way through to Kant, Husserl, Hegel, Heidegger, Sartre, etc. In the "Continental" tradition, on the other hand, "phenomenology" and "hermeneutics" hold sway. Or did...this old divide is now regularly breached. The common ground between both traditions is, to simplify, the meaning and structure of "language." And my guess is that you went into math because you perhaps subconsciously find "language" frustrating. Very understandable, very "Analytic." One good thing about analytical philosophy is that the terminology does not proliferate quite as rapidly as in the "Continental" tradition, where each philosopher tends to reconstruct his/her own terminology... very annoying, but there is usually a good reason. Language is real, unavoidable, and not axiomatic. Assuming you are still in school, I would make three suggestions. First, just take a beginning in philosophy course or a course on Plato, if you haven't already. Two, get a couple of books on the history of mathematics, which leads back into philosophy. Three, just invest in a good dictionary of philosophical terms so you can look up "epistemology"and "constructivism" and all those other terms. It just takes a bit of time and usage, like learning in French. If you find you have a taste for it, perhaps take a course on Descartes. If you love mathematics, you really should get acquainted with the old, frustrating "spouse of mathematics," philosophy.