My Googlefu was failing me today. In the pane of IIS Manager, I needed to uncheck "Reverse rewrite host in response headers". 

In the above case is . I have also attempted using from the set misc module for the second regex. How can I get NGINX to remove the path components in the same format as the client provided them? 

When I close my browser without doing a proper disconnect, Socket 1 is closed while Socket 2 is still open. The Service is seeing that nginx is still connected and still is continuing to push messages on there. Here is the scenario I'm seeing with wireshark. 

I guess something was wrong with and the regex variable or something else. Using the single argument form of works. 

This works well for most normal cases for URIs such as . However when I introduce special URL encoded values, things go south. When the URI is , is decoded and is passed to as . This isn't a valid URL. I've tried to work around the limitations of NGINX by using a conditional to match against and , but the results are either double encoded or unencoded. 

We are using nginx, right now 1.6 to reverse proxy our services to the client. We are also using Server-Sent Events, a layer on top of HTTP that keeps the socket open. Here is a piece of required config. 

Does Active Directory Lightweight Directory Services support account lockout like how the full Active Directory domain services does? 

Is there a simple script I can use to give a destination folder and the AD group I want to use and it would generate a set of folders with the members of that AD group and delegate the proper permissions to those folders? I have gotten as far as and it returns a list of FQN's. Here is an example of what I am looking for... 

For other users on same machine exactly, it stays in the directory it was launched, and able to find the required files, so it works fine. I double checked my .rpmmacros, and the only entry is the topdir pointing to rpmbuild directory. The SPEC file is: 

I tried both Kemp and Coyote entry-level (~2000$) LB, and was happy with their performance, but got recommendations here to check out www.loadbalancer.org, who have a similar priced product. Did anyone had to chance to use them in production, and can give any recommendations, including how they compare to Kemp or Coyote? Thanks. 

We have set up a XenServer, and trying to set-up a CentOS 6 guest VM. The installation went fine (using RHEL 6 template), but I'm unable to properly configure the network. The guest VM is able to ping the host machine, but unable to ping any outside machines or gateway. The network settings look just fine - same subnet range and valid IP. Any idea what else I can check? Thanks! 

From reading Dell help, and the following document: $URL$ It seems the last configuration will the best performance one - is this correct? Also, is there any real difference between UDIMM and RDIMM for this kind of configuration? Thanks! 

We connected the card to our system and have created a new mirror RAID 1 virtual drive, Now we want to clone our existing single drive to this new virtual drive, but our cloning software Acronis True Image Server doesn't see it. We also don't see the SAS controller in BIOS boot order. Any idea how to make the drive visible to system? Thanks! 

We use GnuPG for encrypting data, which we upload to a central storage. The public key is being stored on a web-server, and the encrypting script re-downloads it if it's changed. This was done in order to easily refresh the public key every so often on all the servers. After some security thinking, I got the paranoia, that someone can (unlikely, but potentially), break into the web-server, and replace the public key with his own. This would give 2 very unpleasant effects: 1) The hacker could read the data, if he manages to break out into the central storage as well. 2) Even if he doesn't - we won't be able to read the data as well as the private key got changed, and it all can be considered as lost! Can someone advice how to prevent this threat, or perhaps suggest a more robust, but still convenient, key refresh approach? Thanks! 

I'd second the option to do RAID 0 (stripe) with a hardware RAID controller. I quoted a video encoding server and the scratch drives are 15k SAS in RAID 0 and it chews through video like nothing else. 

There is an option for expiring passwords in the user "profile" options in Local Users of MMC. Let me find a screen shot. $URL$ 

I just registered a new domain last week. I associated it with my Google Apps account. Apparently, some spam bot is using it with fake account names to send spam and I'm receiving a ton of bounces. What can I do to help against that? I do have an SPF DNS record 

I've cranked up Failed Request Tracing and thats how I saw steps 5 and 6. What could be causing IIS to rewrite the header before ARR? Are there any other IIS tools I can use to figure this out? 

The client requests $URL$ with a URL such as $URL$ in the request. ARR then forwards the request to $URL$ The server responds with the header set to $URL$ and HTTP 302. I've verified this with Wireshark. IIS somewhere in the pipeline is changing the header to $URL$ This is where the problems begin. ARR sees the originb URL in a PATTERN_MATCH step for the header. ARR reports the originb URL as the header in the GENERAL_RESPONSE_HEADERS step. The client blindly accepts the URL and redirects to the non-existent $URL$ instead of $URL$ 

What is the best way to resize partitions on a server with a Dynamic Disk? I have 4 volumes in what appears to be 2 partitions. I have ghosted each of these volumes to separate image files. I will need to have the drive letters remain the same when the server OS boots back up. I know I need to use but I do not know how to make this work. Thanks. 

We have an Exchange 2003 SP2 server on 2003, whose store got corrupted after IBM RAID got bad-stripes and bad-blocks. Unfortunately the backups were discovered out to be out of date, so now we facing almost a month worth of data loss (and very certain ire of management), unless we manage to merge the data from that old back-up, and users Outlooks. So my question, if the following possible? 

Have anyone ever managed several geographically distributed systems with Puppet? I have several almost exactly similar deployments (except the server IP's), which management I'm looking to convert to Puppet. I have 2 options: 

After several years of using MySQL, I've encountered some security issue that quite baffle me. I create a new database, and a new user, then grant CRUD rights only to the new DB, to this user. But when I log in either via some MySQL client, or via CLI mysql, I can read and change data in all databases. I double-checked myself and verified that I should have access only to single DB - still I can access every DB. Is there any setting for MySQL that just cause it to ignore the security, and I have accidentally turned it on? Thanks. 

We seem to have some issue with recovering Exchange 2003 data via BackUp Exec 12.5 to Recovery Storage Group. We have set-up a dial-tone Exchange database, and now trying to restore latest backup to new recovery group. Problem is, it seems as BackUp Exec recovers the data to the dial-tone database instead of Recovery Group. There is no way to select destination in BackUp Exec, but I was sure Exchange alone knows where to restore data. I also double-checked the "this database can be overwritten by restore" check-boxes on dial-tone and recovery data-bases - it's unchecked on dial-tone, and checked on recovery, as instructed in every article. Following this guide doesn't seem to help - it still restores to dial-tone: $URL$ P.S.: if this doesn't work, how safe is restoring the backup directly to dial-tone, and just using it as the production data-base from now on? Thanks for any ideas! 

I will suggest you if you really want to build system like mail chimp,constant contact etc then first of all you need to understand their system how it works,what protocols they use to determine spamers ,how feed back loop works, and how they monitor their whole network. After that you need to know how to configure your network and servers to achive this kind of services and how you will authenticate your clients mails using DKIM,SPF. You should also implement rules on your clients that they should not use purchased mailling lists/database. 

This shows your yum server do not have all dependencies for perl-Net-SNMP that's why this showing dependency resolution error when you are installing perl-Net-SNMP first you need to install these dependency's manually from another repository after complition of dependency resolution/installtion you need to run this commond yum install perl-Net-SNMP you can get this dependency's from pkgs.org,rpm.pbone.net and other repositories. 

If you want real load balancing for web server's than you should think about Haproxy . It has high efficiency using reverse proxy and failover system (keep alive & Heartbeat) Haproxy load balancer will work as a front end server for your web server. To know more about Haproxy you should read $URL$ and $URL$ 

Need not to worry someone is trying to connect from your server but the sasl username and password he/she using for login is wrong that's why it's creating unsuccessful sasl login attems log. your server is secured from open relaying. 

Setting up DKIM on my Postfix/CentOS 5.6 server. It sends and signs the emails, but Google still showing it neutral. The errors I'm getting are: 

First you have to confirm which udev version you have installed. run this command rpm -q udev If you have udev installed then this will show you the name and version of rpm. then you want to remove udev without removing dependencies for this run this command rpm -e your udev rpm name --nodeps for example rpm -e udev-095-14.24.el5 --nodeps I hope this will solve your problem. 

Solved by splitting to two VD's, one small with just enough space to contain the boot partition, and the other with the rest of partitions. 

Any idea whether Google bills for IP that are attached to stopped VMs, and is it the same rate as for an unused IP? (which actually makes sense). 

I'm trying to install CentOS 5.11 on DL160 G5, with 4 bays holding 3TB sized drives. The installation with default partition layout completes successfully, however on boot I get to a blinking cursor screen - it's not even reaching GRUB. I've tried updating BIOS to latest one available (17/11/2011), and even manually sizing the boot partition to 200 MB - it's still has the same effect. I presume a GPT needs to be used (rather than the default MBR), however unable to find how to enable it during the installation. 

I have quite strange situation, where my CentOS 5.5 box loads are high, but the CPU and memory used are pretty low: 

After one of the drives in our IBM RAID gone, we bought a new one and replaced it. The rebuilding went fine, but now we see "Bad stripes" reported for the logical disk. Moreover, some data can not be read from the disk, and ServeRAID reports bad blocks. CHKDSK just hangs on 22% of reading, closing it and re-running jumps to the 22% again. Question - is it possible to resolve this situation by synchronizing the logical drive? Or it better leave the CHKDSK running until it hopefully completes? Also, what the synchronization actually does and can it heal bad stripes? The server model is x3400, RAID is ServeRAID 8k-l. Thanks! 

Our old 2003 mail server has died, and we are hastily setting up a new one based on Exchange 2010. We looking for a way to recover the 2003 data into 2010, any idea if possible? Thanks.