I've currently got a lovely working server that has an LSI 9265-8i RAID card in it with 4x1TB RE4 drives, also running CacheCade Pro 2.0 with 2x180GB SSDs in RAID1. I currently have the main array running on RAID6, as much as I like it. I think running RAID 0+1 would be a better choice for the speed and making the server more responsive. Is there a way to 'migrate' my array from '6 to '0+1 without a full backup and restore (which I'd take a full backup anyway if all went wrong)? The total available space will be the same (2TB) but I'm guessing my potential reliability will go down a little (if 2 drives fail simultaneously on the same stripe opposed to any 2 drives failing). Can anyone shed some more light on the subject please? Thank you for your help. 

I guess creating a queue for parent won't work as packets won't be marked on that level (right?), since all packets are VLAN-tagged. I'd like to have the same QoS as I had with FireQOS but what's really important is the VoIP part. So, how should I configure the Queue Tree? 

I'm aware that this is a common question but I've invested two days now to learn this and still could not find a clear explanation... Recently I bought a Miktotik hEX (RouterOS 6, Level 4), used as the main router for a 100MBit down / 30MBit up fiber connection (speed tests show actually 110/33 as my provider adds a 10% margin). I want to prioritize traffic mainly to avoid issues with VoIP calls (via Twilio). I had successfully prioritized traffic before with FireQOS using a custom Linux box (that could not handle more than 20Mbit, though) using the following config: 

We are going to supply our engineers with Note3 phones (due to the fact these are some of the only devices that come with real stylus') so that they can take signatures on jobs etc. I'm grappling with the concept of having to setup individual Google accounts for each user. This is something I want to avoid. I've considered setting up one specific Google account to use on all phones but this seems like a security risk and a pain to manage (lesser so than individual accounts). I may want to install certain apps from the app store, and I would like to use the phone tracking and remote disable features. Is it worth setting up a Google apps account for this purpose? We already have Exchange happily working for the users and I don't really want to scrap our infrastructure just to switch over to Google. Running these phones without a google account somehow feels wrong, and I feel that I'm missing out. What other solutions have people set up to get round these problems, or did that find no problems without a google account? Thanks! 

When two of those devices are in the same network it is obvious that the address causes a collision and should not be used. The DHCP address should be used. The 10.1.1.146 is intended for 1-to-1 connections. Unfortunately, when doing simple things like or when trying to reach the Internet, then the Kernel chooses to use the ...146 IP address as source in such a situation. AFAIK that is because it prefers the /24 network since it's smaller. Question: Can I somehow give the DHCP subnet precedence (perhaps via some command usage), even if there is another subnet that qualifies? 

At the beginning of the website launch I expect that a single EC2 instance will handle the load easily, with perhaps peaks of two or three EC2 instances during holidays. Amazon's own Docker hosting solution (with load balancer and auto scaling) looked very promising, but being an Amazon newbie I haven't been able to get this thing working, also because the configuration looks very complex and you have to get the pieces together yourself. I'm pretty familiar with other types of clusters (mostly Proxmox-based) but still the Amazon Web Services looks complex (at least the configuration console). Is there any alternative solution that makes this easy? I spent a lot of time looking into Docker Cloud/Tutum (seems expensive), Docker Swarm, Rancher, and others (most of them "beta"), but still am confused which way to go. How would you deploy such an application? 

Having some major problems with Server 2012 Essentials. Have setup remote access and installed RRAS console. I can connect to the VPN through SSTP or PPTP no problems. Authentication is fine (NAP is full access!), have checked RRAS, firewall (local and server) and removed and recreated the settings as well as repairing them. After all this, I cannot pass any traffic through the VPN, I've tried assigning IP through DHCP and static. I can't ping the IP address of the remote 2012 server through VPN, or anything else on the network. I've tried connecting from multiple different machines and OSs. If anyone could help me it would me much appreciated :) Thanks 

After much messing around, I rechecked NAP and disabled a block policy that seemed to be blocking the traffic (despite not being mentioned in the security log!). I re-enabled IP routing in RRAS, I changed the ip range given out from x.x.x.20-30 to x.x.x.225-235 and somehow one of these things made it work! I'm surprised and relieved that its working after the hours I've wasted trying to get it fixed. 

I have a relatively simple web application that consists of two Docker containers working together. One container hosts the web server and the other one hosts a image rendering software. On my development machine it works flawlessly using . For production this application will make use of Amazon SES and some database like Amazon DynamoDB. In that combination the containers itself don't need any persistent storage. Because of those services, my first thought is obviously to use Amazon EC2 to host the application. My primary goals now are: 

The bridge works because when I activate the interface and set up some IP addresses (just for testing the bridge), ICMP PINGs work perfectly. 

This only works as long as both machines have running. I can start/stop and consistenly only see replies while the program is running on both machines at the same time. It doesn't matter on which machine I try. Is this a kernel bug or (more probable) has my configuration some problem? Is it normal, that the bridge and bonding interface both show the same MAC address? I only configure it manually for the bonding interface, which apparently changes also the bridge.. FYI, config overview: 

I installed the isc-dhcp-server (version 4.3.3) onto my Raspberry Pi and set it up to assign IP Addresses to devices that are connected to the Ethernet port (via a Switch but that should be unrelated). This network is only for Ethernet purposes and it does not offer Internet access. But if I connect a PC to that Ethernet connection, it will sometimes try to load pages using the Ethernet connection instead of the WiFi network the PC is connected to. Is there a way to make the DHCP server tell connected devices that there is no Internet connection (or to just make the PC skip that connection when trying to load something)? EDIT: For reference, this is my current : 

If I understood you correctly you want all accesses to $URL$ being rewritten to $URL$ To do this you just need to replace the ProxyPass stuff in the port 80 VirtualHost with a RewriteRule: 

I have Linux devices with a single ethernet interface and two IP adresses. The first () is statically configured to . The second () is configured via DHCP and it may happen that it gets a similar IP like , meaning that the subnets overlap. The routing table looks like this: 

Bonding A Linux Bonding interface is now set up. Again, since this is just a first proof of concept test, I'll only add a single slave to the bond. Later on there will also be a real separate Gbit NIC with a dedicated switch that will act as the primary slave (with the VPN being just a backup), but for now the bonding interface will use the VPN only. 

The other host is set up as 172.16.1.1/24 with HWaddr 02:00:0a:01:01:c7. This results in a theoretically working bonding interface: 

One of the decisions left to take is whether to use software RAID1 or hardware RAID1 + BBU. Software RAID is the solution I'm very familiar with (I'm managing a number of servers since 15 years and I know how the tools work). I never had a serious problem with it (mainly only the HDD fail). These are the reasons why I prefer software RAID. What I dislike about hardware RAID is the incompatibility between controller vendors and the lack of experience I'm having with them: different configuration options, different monitoring method, different utility programs - not a good feeling for creating a cluster system. I know that, when using a BBU, hardware RAID can both be fast and reliable (write through cache). However, since all data will be stored in a highly redundant manner in the cluster, my idea is to use software RAID1 and disable barriers in the file system to increase write performance. I expect that this will lead to similar performance like hardware RAID1. Of course, I risk data loss due to the volatile write cache, however IMHO that should be handled by the clustering mechanisms anyway (the whole machine should be able to restore data from the other nodes after failure). I'm not having concerns about the CPU resources needed by a software RAID implementation. Is my assumption correct or am I missing some important detail that would help me making the right choice?