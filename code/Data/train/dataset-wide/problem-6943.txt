I believe the problem is that the steady state may not exist, and the system instead exhibits steady growth (depending on parameters). The reason is because the model is equivalent to the standard consumption-saving problem with exogenous and constant interest rate. To see that, first consider the first order condition for labor choice $f_2(k,\ell) = w$ (here, $f_i$ is partial derivative of $f$ wrt. $i$th argument). Using the definition of constant returns, marginal product of labor is $$ \frac{\partial }{\partial \ell} f(k,\ell) = \frac{\partial }{\partial \ell} \left[ f \left( \frac{k}{\ell},1 \right) \ell \right] = f_1 \left( \frac{k}{\ell},1 \right) \frac{-k}{\ell} + f \left( \frac{k}{\ell},1 \right) $$ which is a function of capital-labor ratio only. If wage is constant, labor FOC determines uniquely the optimal $k/\ell$ ratio as a function of wage $w$ and other parameters. Since marginal product of capital $$ \frac{\partial }{\partial k} f(k,\ell) = \frac{\partial }{\partial k} \left[ f \left( \frac{k}{\ell},1 \right) \ell \right] = f_1 \left( \frac{k}{\ell},1 \right) $$ also depends on $k/\ell$, it will be constant along optimal path. Denote this value of marginal product $r^*$, and denote the return net of depreciation $r = r^* - \delta$. Equations (1) - (2) for dynamics of capital and consumption are then $$ \begin{split} \dot c_t &= (r - \rho) c_t \\ \dot k_t &= r k_t - c_t \end{split} $$ and the specific solution which satisfies transversality condition should be $c_t = \rho k_t$ with $k_0$ given, i.e. a constant part of wealth is consumed at each moment. Both capital and consumption grow at rate $(r-\rho)$, so there is no steady state unless the return on capital (which here depends on exogenous wage rate $w$) equals rate of time preference. 

Short answer: no. Dynare, and linearization/perturbation methods in general, are designed for solving 

because once we impose additional assumptions about preferences, technologies and endowments, we do obtain additional empirical predictions (and of course, different sets of assumptions will lead to different predictions). This is precisely what economists are doing most of the time! It's not 1950's anymore - these days, there is very little research that tries to arrive at general results from abstract axioms. Most theoretical work in macroeconomics will present specific model, derive its qualitative and quantitative implications and often will include an empirical component. Another often-heard argument, present e.g. in the linked piece, is that SMD theorem shows GE models are in general unstable or indeterminate, and thus we must resort to unrealistic restrictions, such as representative agent assumption, to guarantee that our models are well-behaved. But this confuses necessary and sufficient condition: yes, assuming representative agent is sufficient to obtain well-behaved aggregate demand function, but that doesn't mean all, or even most, models with heterogeneity are somehow automatically unstable. And a logical possibility of unstable equilibrium says nothing about whether such situation is empirically relevant (maybe it is, but critics usually provide no evidence for such claims). 

A common practice when computing solutions to stochastic dynamic optimization problems is to approximate an exogenous forcing process $z_{t+1} = \rho z_t + \sigma \epsilon_{t+1}$ with a finite-state Markov chain, e.g. by Tauchen's or Rouwenhorst's method. What would be a good way to discretize AR(1) process with stochastic volatility? That is, if the original AR(1)-SV process looks something like this: $$ \begin{split} z_{t+1} &= \rho_z z_t + \mathrm{e}^{v_t} \sigma_z \epsilon_{t+1} \\ v_{t+1} &= \rho_v v_t + \sigma_v \eta_{t+1} \end{split} $$ with $\epsilon, \eta$ being independent standard gaussian shocks, my goal is to obtain values $z_i$ and transition probabilities $p_{ij}$ ($i,j=1,\dots,n$) such that the corresponding Markov chain approximates the original continuous-valued process. 

The problem is equivalent to maximizing $$ \max_\phi \left( \phi ' \mu - \frac{1}{2} \alpha \phi ' \Sigma \phi \right) $$ subject to $$ \mathbf{1}' \phi = w_0. $$ (boldface 1 is column vector of ones, ' stands for transposition). The lagrangian is $$ L(\phi, \lambda) = \phi ' \mu - \frac{1}{2} \alpha \phi ' \Sigma \phi - \lambda \left( \mathbf{1}' \phi - w_0 \right), $$ and its jacobian wrt. $\phi$ is $$ \mathrm{D}_\phi L(\phi, \lambda) = \mu' - \alpha \phi ' \Sigma - \lambda \mathbf{1}'. $$ First order conditions require that the jacobian is equal to zero (in each element), plus the original budget constraint, which together (after transposing the jacobian) yields a system of linear equations in $(\phi,\lambda)$: $$ \begin{split} \Sigma \phi + \mathbf{1} \lambda &= \frac{1}{\alpha}\mu \\ \mathbf{1}' \phi &= w_0 \end{split} $$ We can solve for $\phi$ as a function of multiplier $\lambda$: $$ \phi = \frac{1}{\alpha} \Sigma^{-1} \mu - \lambda \Sigma^{-1} \mathbf{1} $$ Plugging this into the budget constraint and some algebra yields an expression for $\lambda$: $$ \lambda = \frac{\frac{1}{\alpha}\mathbf{1}' \Sigma^{-1} \mu - w_0}{\mathbf{1}' \Sigma^{-1} \mathbf{1}}, $$ and substituting this into the expression for $\phi$ should yield the result as given in the question. 

I'm not very well versed in macro-labor, but I'm aware of a few papers that might be close to what you mean. One could make unemployment uninsurable, and instead let agents partially self-insure by saving capital, like in Chang & Kim (2007) AER paper. Also Krusell & coauthors have some papers (like 2010 ReStud) where they combine uninsurable unemployment with search/matching framework. The obvious problem is that dealing with heterogeneity is painful, because one must keep track of distribution of variables across agents (e.g. employment status and savings). If you're interested in computation and what can go wrong with it, check out comment on Chang & Kim paper by Takahashi (as well as reply by original authors in the same issue). 

This is somewhat broad and argumentative question, but I'll try to provide one possible answer (disclaimer: I'm not a GE theorist). SMD theorem states that imposing only the abstract structure of general equilibrium has few empirical implications. Fair enough. But it's incorrect to say that 

The question doesn't make much sense to me as stated. If the problem says that exercise is endogenous (correlated with error term), you can't assume the opposite in the solution. Plus, one usually speaks about reduced vs. structural form in the context of IV estimation. If exercise is endogenous, you need an instrument for it (variable that predicts exercise, but doesn't affect health otherwise) to obtain causal effects. For example, if some people in your sample randomly won gym membership coupons, that could be a valid instrument. Identification assumptions would then be 

A model with fixed cost is typically non-smooth, and its behavior away from the steady state may be very different, if e.g. the firm switches from investing to not investing. On the most practical level, a model with fixed cost will typically include equation such as $$ V = \max \left\{ V^{\text{invest}}, V^{\text{not invest}} \right\}, $$ which cannot be entered into Dynare, because max operator is not supported. On the other hand, first order conditions for convex (e.g. quadratic) adjustment cost are still smooth (one simply adds additional terms to Euler equation for investment) and thus can be easily solved with Dynare. To actually compute optimal policy with fixed costs, one has typically to use global method, e.g. value function iteration. I'm not aware of any standardized toolbox for solving such problems, so you may need to code your own. PS: there are some modelling tricks that make the problem smoother, typically in a setting with many, possibly heterogeneous agents/firms. For example, Thomas (2002) keeps track of number of firms depending on how long they didn't invest, and solves the model with standard linearization on this extended state space. Khan & Thomas (2007) assume that the fixed cost is random and iid over time and across firms, so one can average over the realization of fixed cost to obtain smooth value functions. Miao & Wang (2014) use a similar approach in a model with constant returns to scale and show how it aggregates to a version of representative-firm model with only convex adjustment costs. 

Explosiveness The paper contains an error, which causes the explosive dynamics in your simulation (although presumably the underlying computations in the paper were correct). The equilibrium condition derived from eigenvalue decomposition is contained in the third row of matrix $Q^{-1}$ on page 12 of the paper, with variables ordered as $(c,k,h,z)$ (I'll drop tildas, so all lowercase variables are to be understood as log-deviations). Comparing with eqn. (16) on p. 13, we see that coefficients for $k$ and $h$ are switched, and so the correct condition is $$ c_t = 0.54 k_t + 0.02 h_t + 0.44 z_t $$ Simulation First, we can express consumption and labor as linear function of state variables (no need to solve the system at each step of the simulation). The intertemporal and intratemporal equilibrium conditions can be written as $$ \begin{bmatrix}1 & -0.02 \\ 2.78 & 1 \end{bmatrix} \begin{bmatrix} c_t \\ h_t\end{bmatrix} = \begin{bmatrix} 0.54 & 0.44 \\ 1 & 2.78 \end{bmatrix} \begin{bmatrix} k_t \\ z_t\end{bmatrix} $$ so after multiplying by an inverse we get $$ \begin{bmatrix} c_t \\ h_t\end{bmatrix} = \begin{bmatrix} 0.53 & 0.47 \\ -0.47 & 1.47 \end{bmatrix} \begin{bmatrix} k_t \\ z_t\end{bmatrix} $$ Next, transition for states can be written as $$ \begin{bmatrix} k_{t+1} \\ z_{t+1} \end{bmatrix} = \begin{bmatrix} -0.07 & 0.06 \\ 0 & 0 \end{bmatrix} \begin{bmatrix} c_t \\ h_t\end{bmatrix} + \begin{bmatrix} 1.01 & 0.1 \\ 0 & 0.95 \end{bmatrix} \begin{bmatrix} k_t \\ z_t\end{bmatrix} + \begin{bmatrix} 0 \\ \epsilon_{t+1}\end{bmatrix} $$ which can be reduced by substuting for control variables to $$ \begin{bmatrix} k_{t+1} \\ z_{t+1} \end{bmatrix} = \begin{bmatrix} 0.94 & 0.16 \\ 0 & 0.95 \end{bmatrix} \begin{bmatrix} k_t \\ z_t\end{bmatrix} + \begin{bmatrix} 0 \\ \epsilon_{t+1}\end{bmatrix} $$ Now the simulation should be trivial, here's a Matlab/Octave example: 

You could solve for the value function ex-post from the Bellman equation. For simplicity, consider a deterministic dynamic programming problem (in OLG model, you'd have age as another state variable, but I'll abstract from that). If $x$ is state and its next-period value $x'$ is control, $U(x,x')$ is one-period utility and you have somehow obtained decision rule $x' = g(x)$, it must be the case that the value function satisfies $$ V(x) = U(x,g(x)) + \beta V(g(x)) $$ This is a functional equation in $V()$ that could also be solved by projection method. Alternatively, you could iterate on the Bellman equation (on some grid over state space) just like in VFI, but skipping the optimization step (since you already know the optimal choice), and eventually the value function should converge. 

Of course in practice, you should probably recompute the whole solution, including the eigenvalue decomposition, so that you would be able to change parameters, etc. 

I assume 5% is the interest rate. If we knew stock price in each state, formula for call option price in binomial model should be $$ C_0 = \left(S_0 - \frac{S_d}{1+r}\right) \frac{S_u-K}{S_u-S_d} $$ Now just invert the formula to get $S_u$, given values of $C_0, S_0, S_d, K, r$. Where did we get that formula for call option price in the first place? That's pretty important, so I'd recommend you to look into your notes more closely. In short, you want to form a portfolio of stocks and bonds that replicates the option payoff in the next period, i.e. find $a, b$ such that $$ \begin{split} a S_u + (1+r)b &= S_u - K \\ a S_d + (1+r)b &= 0 \end{split} $$ (here, $a$ stands for how many stocks you buy, $b$ for how much you save into bonds) If you solve this system, then the price of the option in current period must be just the value of this portfolio, $C_0 = a S_0 + b$ (otherwise one could make easy profits from the mispricing), and doing the algebra should yield the formula at the beginning.