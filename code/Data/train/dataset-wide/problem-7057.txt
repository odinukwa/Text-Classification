If I'm understanding your question, this typically means the amount of revenue that an industry generates. Usually, the statement "this is a ____ industry" is labeled. For example, "this is a $1,000,000 a year industry." Although recognizing how much revenue an industry generates is nice and is helpful, it may not apply to a person looking to break into an industry. It's important to note that profit and revenue are not the same things. 

There is a great deal to consider when discussing resource rich countries. Countries that rely on a single sector have less diverse economies, which can lead to a number of issues (especially if the price of a particular resource drops). Additionally, resource rich countries tend to have unstable governments, which makes it difficult to diversify and grow the economy. Some of these governments are dictatorships and some are run by those who are wealthy as a result of having a stake in the resource. These particular issues tend to spawn corruption and abuses in a way that is not usually seen in other governments. Of course these are broad generalizations, but they are important. To address your question specifically, I would suggest that there is a reliance on foreign contractors because the necessary skills are not in abundance within the country itself. Since the countries rely on a single resource, most jobs and education are tied to the resource, which means limited available skills. Additionally, if one of these countries wants to develop technologies within the country, it would need to import tons of resources, probably more so than other countries that have multiple resources. My guess is that at this time, importing technologies is more efficient. This isn't to say that gulf countries don't invest in R&D, they do. It just looks different than in other countries. 

It is important to recognize that there are path dependencies to removing different variables from your model. This is due to the fact that variables can be highly correlated (positively or negatively) with one another so that by removing an insignificant variable then other variables can become statistically significant or insignificant. There are very different approaches towards dealing with this. As the previous commenter mentioned you can use some sort of model selection procedure to try and explore the space of the variables you have included. There are many different approaches to doing this (AIC, BIC, SIC, Lasso, Gets...), but ultimately interpretation of the selected model assumes that your original model encompassed the true data generating process. If this is not the case, then selecting from your original model could give you inconsistent parameter estimates. Alternatively you can stick with a purely theoretical approach and specify what you think the important variables are ahead of time (i.e. what you think the DGP is) and then only include those in your model. That way you don't add or remove any variables and you just interpret the estimated model based on your theory of what the true model is. Interpretation also relies on the assumption that your proposed model is in line with the underlying DGP. 

Interesting observation, but I think the answer is partly explained by several factors: First, any calculation of real GDP would eliminate the year-over-year variance that could be due to taste shocks leading to significant price changes. Second, I think your observation is partially true, however. What makes an iPhone more valuable than an old Motorola smartphone? Sure, some inputs might be slightly different, but the "production technology" of the iPhone makes it such that we (in general) do value it higher. While some measures like CPI try to account for some of those issues by considering benchmarks for certain performance criteria (like processing power, memory, etc.), in the end, there absolutely is some taste-based component. I think it's partly accounted for by aggregation, as you mentioned, but I think the third point is that there's a bit of a disconnect between what value is trying to measure, and what GDP is interested in. Theories of value attempt to explain why we attach certain "utility amounts" to different goods. But that doesn't mean the output of any particular "theory of value" is subjective: the observed prices and quantities are quite objective. GDP (like other macroeconomic indicators) is more interested in tabulating those objective outputs of the theory of value and observing their change over time. For example, I know I value the green mechanical pencil in front of me at \$2, despite the fact I only paid \$1 for it. Assuming the production costs are negligible, GDP would observe that as \$1 of economic activity. It doesn't consider how much I would have paid for it, which is what different theories of value attempt to explain. Furthermore, why I value it at \$2 might be for any host of reasons- perhaps its a subjective value, or perhaps that valuation reflects what I think the pencil will be worth in a year's time. Regardless of what that reasoning is, the objective measurements that GDP considers are the price paid and quantity. 

It sounds like you have a background in game theory. Here is a Game Theory text available for free through RAND if you (or anyone else) wants a refreasher: $URL$ Below are some articles from which you should be able to draw information. Most are not specific to recruiting, but the underlying theory is certainly applicable. If you continue to be interested in this topic, you will find a great deal of information in the literature on social capital, product value signaling (one article included below), and value signaling as it relates to credentials. Denesp recommended a great paper; plug it into google scholar and see which papers cite that one. Doing this you may find a ton of information. Here is a paper published that takes a game theoretic look at the legal profession. It doesn't directly relate to your scenario, but the concepts and framing certainly do (this is on google scholar): Rasmusen, E., Raghav, M., & Ramseyer, M. (2009). Convictions versus conviction rates: the prosecutor's choice. American Law and Economics Review, 11(1), 47-78. Here is an article, also available on Google Scholar, that contends with imperfect information: Rothschild, M., & Stiglitz, J. (1976). Equilibrium in competitive insurance markets: An essay on the economics of imperfect information. The quarterly journal of economics, 629-649. Here is one specific to Signaling Games: Cho, I. K., & Kreps, D. M. (1987). Signaling games and stable equilibria. The Quarterly Journal of Economics, 102(2), 179-221. Also about signaling: Kirmani, A., & Rao, A. R. (2000). No pain, no gain: A critical review of the literature on signaling unobservable product quality. Journal of marketing, 64(2), 66-79. Related to employment: Leana, C. R., & Van Buren, H. J. (1999). Organizational social capital and employment practices. Academy of management review, 24(3), 538-555. 

In order to think about the intuition it is important to understand how $R^2$ is computed. We can think of the R^2 as the ratio of the estimated variation over the total actual variation of the dependent variable: $R^2=\frac{SSE}{SST}$ or $R^2=1-\frac{SSR}{SST}$ where $SSE$ is the estimated sum of squares, $SSR$ is the residual sum of squares and $SST$ is the total sum of squares. So what the $R^2$ tells us is how much of the variation in the dependent variable that our model captures. However, whenever we change the dependent variable we not only change $SSE$ or $SSR$ but we also change $SST$. This implies that the new $R^2$ is now using a different base of comparison. Thus, it is generally not comparable for different dependent variables due to the fact that SST is different. Does this make sense? In time series models this is a fairly big concern since modelers often play with the dependent variable by differencing which impacts the $R^2$ and make comparisons invalid even when in some cases it has no actual impact on the residuals. As a result, it is common to use residual based metrics that are invariant to these types of transformations. 

We can break this into three parts: (1) price elasticity, (2) substitutes, and (3) marginal utility. Price elasticity measures price sensitivity (how much a change in price affects quantity consumed). In the example in the book, the product is elastic, which means that a decrease in price increases consumption proportionally more than the decrease in price. Substitutes are any products that can be substituted for another. This is important because a change in price of a product will not only affect it's consumption, but also the consumption of substitute goods. For example, people who want soda have a choice between Coke and Pepsi. Assume that when priced the same, $10$ people by Coke and $10$ people buy Pepsi. The total consumption is $20$. Now, assume that Coke lowers its price while Pepsi keeps the price the same. Some people who once consumed Pepsi will now by Coke, say $5$ people switch to Coke. The total consumption remains the same, $20$, but its distribution is different. It is the case that a drop in price will encourage consumers to purchase Coke who wouldn't normally do so at the initial price. because a price decrease makes the product available to new consumers the total consumption of soda may increase to $25$. Marginal Utility is the amount by which utility changes with each unit of consumption. The text doesn't seem to say this, but marginal utility is subject to the law of diminishing returns. This means that at a certain point, consuming more of a good makes a person less happy. For example, if I eat 2 cookies, I'm happy. With each cookie I consume, I grow happier in total, however this is happiness increases at a decreasing rate. Utility is maximized when marginal utility is zero. After this point one loses...experiences disutility. Essentially, the text is saying that if the price of an elastic good decreases its consumption will increase. The consumption increase comes from (1) "stealing" consumers from other similar products and (2) new consumers that didn't buy the product at the initial price. Since the total consumption increases as did total utility, the increase was small and thus marginal utility decreased. This isn't saying that utility was taken away, its saying the the rate at which utility increased was slower. 

So we can think of an AR(1) process as: $y_t = a*y_{t-1} +e_t$ where $e_t$ is some shock / noise process that we can't explain. Note that we can rewrite an AR process as an MA process where by tracing through we get $y_t = a^2*y_{t-2}+a*e_{t-1}+e_t\approx \sum_{i=0}^{t-1}a^i*e_{t-i}$ So that an AR process is just the weighted sum of all previous shocks where $a$ is what determines the persistence of past shocks. So then what does it mean to say we have an AR(1) process? Well it means that the outcome today is to some extent dependent on the outcome yesterday (as you yourself suggested). In an extreme case we can set $a=1$ so that we have a random walk process where $\Delta y_t=y_t-y_{t-1}=e_t$ This implies that the outcome today depends entirely on the outcome yesterday and any additional change in the series is purely due to random noise. Alternatively if $a\geq1$ we would say the process is non-stationary or explosive while if $a<1$ then the process is stationary around the mean of the process or of the shocks themselves. An MA process has a similar interpretation except we think of it more in terms of unexplainable shocks or noise with some degree of persistence. The important thing is that it is not really something we have a variable for in the MA case but rather this notion that the the process just depends on this noise component. It is more common to find these types of models for forecasting in finance where there's alot of movement but a less clear sense of what might be driving it. In terms of population forecasting, the AR component could definitely be interpreted as you suggested, while the MA component is less easy to interpret. It's really just a sum of shocks that are otherwise unexplained. If you had an explanation for it (i.e. immigration etc.) then you would likely want to include that as an explanatory variable to model it explicitly rather than approximately through the MA process. 

From a quick glance, it looks like the difference is that the new finance minister is including promised payments that the government had previously made, but hasn't had to pay yet. For example, say I borrow \$10 from you. At the same time, say I had previously promised (in an unrelated interaction) to give you \$5 at the start of June. What's my current debt to you? Officially, it's \$10 (from the loan you had given me). But come the first of June, if I haven't paid you back yet, I'll find myself in debt to you for \$15: \$10 from the loan, and the additional \$5 from the promise. Effectively, the new finance minister is counting the debt to be the entire \$15 (that is, current debt obligations, as well as promised future payments to different projects in Malaysia), while the official figure only considers my debt to be \$10 (since I don't yet technically owe you the additional \$5). Technically, the government official figures are correct, since the government can "get out" of the future payments by (I'd assume) changing the law to remove themselves from that responsibility. At the same time, since (it looks like) those payments are to Malaysian government/private company partnership projects, simply refusing to pay would ultimately undermine Malaysian projects, which would hurt citizens. Which is more important depends on the context, and the interests of the individual. 

You can think of the coefficient in the AR(1) model as telling you something about the dynamics of the process. For example, if the model is of wage growth, then a coefficient >0 suggests that higher wages yesterday are associated with higher wages today. If the coefficient is <1 then there is not a complete pass-through from yesterdays wage growth (i.e. a stationary process) whereas if it were >1 then you have a non-stationary process where wage increases are accelerating. In the wage growth or inflation case this could be suggestive of hyperinflation. 

From the sounds of the question, the firm isn't operating at optimal efficiency. As you note, this firm is not on the elastic portion of the demand curve because $|e|=|\frac{.05}{.10}|=|0.5|<1$. As an employee of this firm, you should suggest that they continue to adjust the price until they transition to the elastic portion of the demand curve. Once they do this, the firm should notice that their marginal revenue becomes positive. I think your confusion stems from (1) your ability to think critically and (2) a misunderstanding that its the marginal revenue which monopolies want to be positive. Questions such as these are usually designed to capture a person's basic understanding of a concept, you pulled together multiple concepts..."too smart for the question." As for marginal revenue, this can be negative, but a firm that wants to maximize profit should adjust their business practices if marginal revenue is negative. 

So your question is basically asking why a purely statistical model would be better at forecasting than a model based on theoretical relationships. For example, think about a simple form of the ARIMA model i.e. an AR model where you're just using lags of the process to explain the process itself. Now think about what is contained in the lags of the process... If the true process (i.e. the DGP) is determined by theoretical relationships between other variables then these will automatically be included in the lag. So the ARIMA model is a statistical way of modeling the process to make sure you capture the statistical properties of the underlying relationship but does not necessarily provide an explanation for what is going on. In forecasting, especially when series are volatile and erratic, you often find that simple statistical models such as these do a better job since the underlying relationships may not be very stable or may be more complicated than any theory we can come up with. This is related to a recent article which you may find interesting: $URL$