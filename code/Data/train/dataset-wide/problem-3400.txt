and similar for all runlevels, the links create looked totally perfect in the recovery mode. However, when I was finally able to log back in using the hack described above, I could see that all the links were broken, i.e. 

which worked fine and allowed me to log back in. I then removed all the broken links and created new ones, using update.rc. Again thank you very much for all the help! 

I am not sure this is done correctly or has any effect at all. I also did not find any mentioning of iptables in any file in /var/log. So what else can I do? Thank you for your help. p.s.: After adding the crontab line as suggested by lain, I can find the following in the file /var/logauth.log 

so the relative link now points somewhere wrong. To fix it, I added to the top of another init script the line (ATTENTION: HACK!!!) 

I got it. First of all, big thanks to everybody that was trying to help! For those of you browsing the archives with a similar problem: The initial problem was that the /etc/rc*.d/ links were not set, this sshd was not run on startup. My numerous attempts fixing this were spoiled because of the way ln works: When I create the links doing 

I have found a ton of questions answered about debugging why one cannot connect via SSH, but they all seem to require that you can still access the system - or say that without that nothing can be done. In my case, I cannot access the system directly, but I do have access to the filesystem using a recovery console. So this is the situation: My provider made some kernel update today and in the process also rebooted my server. For some reason, I cannot connect via SSH anymore, but instead get a ssh: connect to host mydomain.de port 22: Connection refused I do not know whether sshd is just not running, or whether something (e.g. iptables) blocks my ssh connection attempts. I looked at the logfiles, none of the files in /var/log contain any mentioning on ssh, and /var/log/auth.log is empty. Before the kernel update, I could log in just fine and used certificates so that I would not need a password everytime I connect from my local machine. What I tried so far: 

OK, we found the culprit. There was some SonicWall VPN adapter that was screwing things up. Disabling that brought balance back to the universe. Thanks for everyone 

I've been trying to get this to work for days now and its not working. After bashing my head against the desk enough times, I've decided to man up and ask. I'm desperately trying to set up a reverse proxy on the pfsense box itself. One because its a pretty powerful box and its not being utilized to the maximum at all and two because I don't have any spare machines to setup squid (or any other reverse proxy [capable]) server on. So, on pfsense, everytime I set up rules (on Services>Proxy Server>General) as so: 

We have a machine that has been chugging along with the burden of both Exchange and DC and DNS all with SBS 2008. We have a better machine now and I'd like to move Exchange 2007 to that machine and take it off of this machine. In fact, I'm planning on formatting the old machine and get rid of SBS all together because it is making the machine SLOW. How would I go about making the move? I've read on previous versions of Exchange (2000), that all you do is install Exchange on the new machine and then start moving mailboxes one after the other. Well, what about all the different rules we have in place? How do those get moved? How do we de-commission the old exchange and set up the new exchange as the primary one? Come to think of it, how do we have both exchanges recognize each other on the same domain? TIA 

This is not a FreeBSD vs [insert favorite linux server distro]. My interest is in knowing the why and how to remedy sch issues if they exist. Primarily, I'm looking to implement a FreeSwitch based PBX for the local Red Cross hospital. Me being me, I want to broaden my horizons. I'm not a full fledged expert in either linux or freebsd, but I'm no slouch either. Now, after much googling, I've been reading that there are issues with FreeBSD and SMPs but not so with linux, though honestly, I have yet to see any issues and I have serveral BSD servers alongside CentOS, Ubuntu and Debian. So, is there an issue? If there is how do you remedy it (if possible, because I read it on the FreeBSD site that FreeBSD was architected for the x86 architecture). 

I am relatively new to AWS and disk performance. I am trying to figure out how much provisioned IOPS does my application need to perform well. Currently My PHP and MySQL application is hosted on EC2 instances with simple EBS volumes attached. The monitoring of EBS volumes provides Read throughput and write throughput with some other matrices. How can I find IOPS of my current EBS volume from Read throughput(~ 400 Ops/s) and write throughput(~ 4000 Ops/s) data? If I go with the unit of operations/second, IOPS reaches about 4.5K, which I think is not a correct one as simple EBS volume is meant to work alright only on 100 IOPS and occationaly few hundred. 

I have been stress testing my PHP application hosted on Linux and using Apache. I am using Apache JMeter for stress test. During the test the normal response times are below 100 milliseconds. But during the test after few minutes the response times go high for the same HTTP requests than it comes down and after few minutes it again goes high. As high as 60K milliseconds. I am a newbie in PHP and Apache. I am not sure from where to start look for the problem. Can anyone direct me on to how can I troubleshoot for this issue? The application is hosted on Amazon EC2. First thing I am thinking about is may be garbage collection is the issue. Am I right? 

I have been exploring Elastic Beanstalk for easy deployment of my PHP 5.4 application. For my application, I need to make changes in php.ini file. After some searching on internet i tried to use configuration files in git directory. Following is the content of my file(.config) in directory in git directory: