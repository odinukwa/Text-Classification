For most Romance languages at least, there's a totally separate set of conjugation forms called the "subjunctive mode", used to indicate things that could/should/might be, could/should/might become, or that somebody wishes they did as opposed to the "indicative mode" which usually indicates stuff the way it is. Usually, subjunctive present has nothing to do with indicative past, nor subjunctive past with indicative past perfect. Even French does this, except its imperfect doubles work as a kind of subjunctive after conditional "Si" (If). So you do can say "Si j'étais riche" but you must say "Quand je sois riche" for "Quand j'étais riche" implies you have already been rich, but aren't anymore. Problem with English is that over time its subjunctive present has mostly merged with indicative past, subj. past with ind. past perfect and so on. Only exception is verb "to be" in formal settings, which goes "if I were you" and "I wish he were a writer" (which both change to "was" in colloquial settings - apparently native speakers can't resist regularizing the conjugation pattern). Latin future tense disappeared in the Vulgar form of the language, reappearing in Middle Ages by using verb "to have" as an auxiliary: "Yo iré" comes from "Yo ir he" (literally "I to go have"), same happened in French with "J'amerai", Italian "Io parleró", etc. Don't know much about proto-Germanic but at least English evolved in a similar way using "to have" or "to shall" for the future. So even if native speakers did feel an affinity between irrealis and the future, the lack of a grammatical future tense most probably stopped such merge to happen. 

Peasants tend to be conservative in their clothing, religious beliefs, customs, and speech. They're resistant to adopting innovations originating elsewhere but in their small communities, albeit when they do acquire innovations they normally retain them for a long time. The urban poor tend to use and abuse the language in an effort to create their own shibboleths. They frequently invent new words, give new meanings to existing words, and from time to time innovate in grammar. These innovations then spread "up" to the urban middle class and from there permeate the speech of the riches/nobles. Once this last group adopts them, they suddenly cease being considered "substandard" and become "The Standard" - whereas the speech of the townsfolk, previously considered an exemplary standard, becomes substandard (until they "upgrade", of course). You can see it everywhere: In France, the further you're from Paris the more conservative the language becomes, either in pronunciation ("moi" sounds as "mwè" in Québec and some parts of rural France, ending in "ils pensent" still being pronounced in some regions) and in vocabulary (some areas retain crevette, mar, chatel instead of chevrette, mer, chateau). Same happens in U.K., with Broad Scotts retaining features Standard English has lost. In China, the southern so-called dialects are much more conservative than Putonghua (an idealized version of Beijing's dialect). Icelandic is almost the same language the vikings spoke, whereas modern Danish and Norse are way different, etc. Happens as well when a languages is imposed via a conquest: in rural Mexico, peasant communities that abandoned their indigenous languages long ago in favor of Spanish speak a grossly outdated version of it: ansina, truje, vide instead of así, traje, vi... that's so XVI-XVII century!!! It's now considered very sub-standard, even though that was the prestigious way of speaking long ago. Cities tend to excercise a standardizing influence over surrounding towns. When you notice small town folks have a strong accent what you're really seeing is people who have not standardized their speech based on how the nearest urban people speak. Cities have the advantage of being highly populated and dense, so have an easier time imposing their ways to the others than the other way around. Disclaim: I'm no professional linguist either, just a linguistics aficionado. 

Though cyco's answer mostly says it all, wanted to add my 2 cents. How can you distinguish between a scientific approach and one that isn't? If you've read Karl Popper, you know the simplest litmus test is that of "falsifiability": for every theory, there must exist at least one possible experiment that could put the theory in the garbage bin by yielding a result contrary to what was expected. "Edenics" and its kin (Intelligent Design) are for the most part un-falsifiable. Since they're based off faith, you can get away with any illogicity or irregularity in them, as well as any deviation between their predictions and reality by simply claiming such is God's will. Nice if you want to make a theological point, but useless if you want to do science - we humans do science with the aim of understanding our world and trying to predict events in it. The reconstruction of proto-Indo-European, as well as proto-Semitic and other last-common-ancestor of various language families has been the result of linguists applying methodic analyses of data, looking further than simple commonalities but to the underlying causes of them and searching for regular processes that could explain them. Claiming everybody spoke a proto-Semitic language and then, ex-nihilo, full blown and totally different grammars appeared in less than a generation with no solution of continuity is a far-fetched proposition that requires a lot of hard data to be demonstrated - difficult at best. Except if it's said as a statement of faith in which case no proof is required. 

This gets explained beautifully in A.C. Moorhouse's "The Triumph Of Alphabet". The Etruscans adopted Western Greek alphabet but then their scribes got lazy and started writing kappa without the vertical line, so it was like a modern day angular parenthesis. The Falliscans, on the other hand, adopted (Western) Greek alphabet verbatim. So when their cousins the Latins started to write, they expanded on both precedents. "Angular bracket" K got cursive-ized into "C" (was put in the place of gamma for in Etruscan "G" sound was an allophone of "K"). Greek "kappa" and "qoph" were imported as well - so they now had 3 letters to represent the "k" sound, when to use each? The adopted solution was a convention: use "K" when the next sound is "a", "Q" before U/O, and "C" if next sound was E/I. Such usage was preserved in the names of those letters which survive to this day in most modern day Romance languages: ka, ce, qu. Over time, "C" expanded its use at the expense of the other 2 until K was almost never used in full-written words. It was retained for some abreviations (as "K" for Caesar) and for a few words like "Kalendae". 

Have you had a look at ISpell or, better yet, HunSpell (for it supports Unicode)? These are more intended for spelling-correction. However, since they also try to grok the conjugations and flexions for languages with them, they could be helpful. These programs expose an interface so you can call them from other programs (such as a word processor or a browser), you could create a script that reads your text file and calls it continuously not for the sake of spelling but to get the "base" word ("comer" in your example) 

Normally, English "k", "t" and "p" are always aspirated, so they have a very slight "h" sound right after them. But, here's the catch: not always! When they're preceded by an "s" they're pronounced pure. Native speakers almost never notice the difference, but it's crucial if you want to pronounce correctly some languages. Practice reading slowly "It's Pete's " versus "it spits" and you'll notice the difference in the way the "p" sounds: 1st one sounds almost as a soda can being opened at the same time the "p" is uttered, such small "h" sound is the aspirated which is missing in the second one. Likewise with "It's Top Cat!" versus "it stops". 

There were some towns in Northern Australia and Eastern New Guinea where the native Austronesian peoples switched from their native languages to Polinesian so as to better comunicate with the sea-faring traders (who were usually Polinesians). Swahili also expanded enormously in Eastern Africa once it became perceived as a language of trade, reaching far away from the area where the Swahili people (with their mixed Bantu-Arab heritage) natively resided. Though in Swahili's case its expansion meant it was "added" to the languages the villagers' merchants (usually polyglots) would learn, as opposed to obliterating them. 

The more I think of this question, the more I conclude it's highly subjective - and what's not subjective might be the result of linguistic background. As a child I was mostly taught US English. The 1st time I was exposed to Received Pronunciation I was awed at how much more clearly I could distinguish the sounds in the language - to me at least, Americans usually speak as though they had a hot potato in the mouth, blurring a lot the sounds they produce ;-) When studying Portuguese, I found I could understand chatting Brazilians better than Portugueses, even with their "ti becomes chi", etc. sound changes - European Portuguese has much more complex vowels. But then I found I could understand written European Portuguese much better than Brazilian (spoken or written) since its spelling is much closer to the one of Spanish plus it retains some grammar constructs that have since diverged in Brazilian. So I guess "clearer" lies in the ears/eyes of the beholder :) 

Seems more a programming problem than a linguistis problem to me. I'd use a fuzzy parser (probably done in Perl) that attempts to divide such variable names into smaller chunks using either underscores or changes in capitalization, then checks all resulting chunks (including original) vs. a dictionary of words in the target language - taking into account either the Levenshtein distance or the longest common substring. You'd get a number of potential matches, assign a score to each (based on less changes required) and, voilá! If a score is high enough, you could be certain it's a match, and thus a word in such language. I don't think there's such a thing as a universal discriminator to check if a word exists in a language or not - some languages (both natural and created) have very weird capitalization patterns, even within a word (e.g. Irish or Klingon) or can have long sequences of just consonants which nonetheless are valid words (Serbian and Bereber). Worse yet, someone could be typing Chinese characters using the Tsang-chieh method: a seemingly random "JWJ" actually encodes the character 車 "car, vehicle"! Ditto for the "4 corners" method: an initial letter plus a series of numbers could be a valid word.