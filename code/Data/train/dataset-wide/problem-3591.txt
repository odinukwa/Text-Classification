And as expectedly, a 404 not found error is delivered. I wonder how anyone can trigger a 200 success with an undefined HTTP_HOST. Does ServerAlias in Apache rely on HTTP_HOST at all? Or could this be a server bug that someone is trying to exploit? UPDATE: This is the output from : 

It doesn't work too. Is this a bug in Apache? Ain't the directive supposed to match directories only? 

I set size as 5M and interval as weekly thinking that the logs would get rotated on a weekly basis and additional rotation would occur if the size of the log exceeds 5M. But what happens is that the log does not get rotated unless it exceeds 5M, which seems to be what minsize is supposed to do. Am I interpreting the manual wrongly? How do I get the log to rotate on a weekly basis AND if it exceeds 5M? EDIT: I am not sure whether the following information is relevant, but just to supplement: I am using rsyslog to do the main logging for messages, secure, cron, maillog, boot. The following are the rotation date and file size of the penultimate logs where size and interval are set as described above: 

Some search engine spiders like Bingbot crawl too rapidly and does not seem to obey robots.txt directive. This triggers the DOS defence mechanism in to generate HTTP 403 forbidden errors. But showing 403 errors to bots for perfectly valid pages is not ideal and may affect page rank. Is there a way to configure to show HTTP status 429 instead of 403? 

My intention is to start Apache only after PHP-FPM and MariaDB has started and to stop Apache before stopping PHP-FPM, stop PHP-FPM before MariaDB. However, I am getting errors on both startup and shutdown: 

I thought a simple redirection would not require SSL. What should be done to get this simple redirection to work? 

The problem is that cron sometimes send out an email despite the test file being empty. Sometimes the subject header "test" is overridden by cron with its own subject header. Without setting "MAILFROM", cron will use root despite the setting in mailx. I am very new to cron, so I am not very sure whether I have done things correctly. Would appreciate if somebody can point out what is causing the problem. 

A bash script is run by cron every hour to email a log file if it is not empty. The script contains the following line: 

My question is, if these connections are not destined to my server, why are they logged under INPUT? If they are being logged, does it mean that my server is accepting them if I do not filter out these explicitly? My current iptables configuration is: 

However, the URL //mysite.com/ matches #1 instead of #2. Is this a bug or am I doing something wrong? I even tried using the regex in #2, but still no love. 

I use iptables to log all incoming connections. While going through the log in , I notice that there are some incoming connections from another computer to an unassigned LAN ip address, example: 

I just upgraded my server to Fedora 17 which made a switch of my bootloader from GRUB Legacy to GRUB2. There are two symbolic links in the folder that points to the files and in and respectively. Though the targets seem correct, the link icons are displaying an X status which seems to indicate that the links are broken. Upon right-clicking the property type, it states "link to unknown". The file size of the link corresponds exactly with the file size of the target file, so, why does the links appear to be broken? The image of the link icons: 

I am hosting a site that allows users to connect with either HTTP or HTTPS. The default apache configuration generates a separate log file for request made through HTTPS with two additional information, namely protocol (e.g. TLSv1) and cipher (e.g. DHE-RSA-CAMELLIA256-SHA). I was wondering the benefit of logging these two extra information, or whether I should just merge it with the access log without these two columns for ease of troubleshooting. 

Background I have a PHP-FPM sitting behind an Apache server. As I need to use two different configurations for PHP-FPM, I can configure it to be connected either on: 

The request doesn't occur at a time when the server is busy. Also, such slowness did not show up on my database slow query log. This is just a one-off event. Since it is a GET query, I wonder why would it cause such a server lag. The output size indicates that my web application has processed it normally and there are no errors in the application log to indicate otherwise. However the output seems to be truncated when it is sent back to the client as is less than . I understand that this could be an attack. But I want to know what could be causing Apache to take such a long time to process the request. 

Someone has managed to pass an undefined server variable to my application script, triggering a series of errors. I am quite perturbed but am unable to replicate this behaviour. My httpd server uses name-based virtual hosting with the following parameters: 

suggesting that nothing is changed. This actually mean that typing followed by pressing enter inside the fsck prompt did not work. Anyway, the following does work: 

Further examination reveals that this error occurs at a time when the server is booting up. The journal log contains the following relevant lines: 

I have been trying for the past 3 hours trying to match an if statement to define a variable within httpd.conf with no success: 

I want to prevent hotlinking to all subfolders in but at the same time allow linking to its index page. I tried doing this: 

But, it doesn't seem to have any effect. The header from address in php mail function has already been set. I have also ensured that SELinux is enabled. What else to I need to do to get the mail delivered? 

The directive works in Apache configuration. However, I need this in , which looks like a file. How to do it? 

I am having trouble limiting the connection to SSH from a unique ip address. I tried the following rules to restrict an ip address from logging to SSH for more than 3 times in 100 seconds, but it didn't work. 

cron is able to send email to external@server.com whenever there is a problem with logrotate. I am not sure why php is unable to do so. I tried making changes to the default configuration in `sendmail.mc with the following: 

Can anyone explain to me why there are two similar entries of "from" and "to" in maillog every time an email is sent? 

I am having trouble getting cron to email an attachment based on a predefined condition set in the bash script. The following is my /etc/crontab setting: 

Luckily after further Googling, I found this article and realize that it is only a matter of choosing the correct device. 

I figured there is nothing wrong with the configuration. My understanding of SSH connection is flawed. A wrong login password does not cause the SSH connection to be dropped. Hence the hit count limit is not affected until I do a reconnect. 

I want to generate a "Request Entity Too Large" error when users upload very big files on my server. With mod-php, this is simply: 

I am doing egress logging on my server using IPTABLES with the following line which is supposed to provide UID information on all traffic that is logged: 

The above command automatically write changes to disk. It would be great if anyone can tell me whether this is a bug in or it is due to something else. 

Both methods do not lead to any change to the user in SELinux security context. Why is that so? Is there any security risk if I don't change the user? And how to make the change? 

But the index.html is forbidden when I tried accessing from a link outside. Next I tried appending a trailing slash. 

I have created a few symbolic links to replace some broken links in . The original links have as the user. The newly created ones somehow have as the user. I am not sure if there is any security implications to this though the target files all have as the user. I tried the following: 

The server is a 1U Dell PowerEdge R210 with the specs here. What could be the cause of such an anomaly? 

Since the PHP error occurs at the 27th second, three seconds after Apache has started, why does PHP complain that it couldn't find the file? In any case, should the starting sequence of Apache, PHP-FPM and MariaDB be reversed so that Apache is the last to get started? 

It is well documented on Wikipedia that a head crash in a hard disk drive (HDD) may result in some data loss. However, there is not much being written about the different modes of a solid state drive (SSD) failure, and whether such failures would lead to significant data loss. Articles that I found on the web mentioned mostly about the complexity of recovering data from an SSD, but nothing is mentioned on the comparative likelihood of an irrecoverable data loss. Has anyone done such a comparison? 

I am trying to structure the shutdown and startup of Apache, PHP-FPM and MariaDB services using systemd: These are the additional configuration files in folder: 

From the above, I note that there is a high loss of DWORD synchronization, which, according to IBM, is an error that occurs when a PHY stops detecting an incoming stream of DWORDs. I tried to search for further information regarding this error but can't seem to find any. How does loss of DWORD synchronization affect the health of an SAS disk? Do I need to worry about it? And at what threshold level should I be monitoring it? 

As can be seen, only messages get rotated. EDIT2: I should have check with . They actually upgraded it with the maxsize option. This should be what I am looking for: 

This file will be emailed to me and rotated every hour using a cron job as long as there is an error. Now, how would this be done using ? The options in seems pretty limited. Do I still require to do this? 

It appears quite strange to me that temperature readings derived from SMART for one disk is different from its twin in a RAID 1 configuration by as much as 9Â°C: 

What are the errors, if any, that would be observed on if an SSD is failing or has failed? I would like to know how such errors would be worded so that it could be picked up by an automated program to warn the user to replace the degraded disk before the second one fail. 

I tried to sending out an email using php function but it failed somehow, complaining that a real domain name is required. The following is observed in the maillog: 

Fedora OS introduces as the new way to log error messages. I learn about this recently when I performed an upgrade. and many other log files are now combined into a file within the directory. I have a custom log that was created specially to log critical errors using the old : 

Question I think the above scenario could be applied generally and not just on PHP-FPM setup. So, my question is, is there any difference between a two ips on one port vs one ip on two ports setup? When would you use one over the other? 

I think the problem has to do with the file security context. I read somewhere that setting the context to public content might help, but not sure if it is a good idea or if there is a better approach.