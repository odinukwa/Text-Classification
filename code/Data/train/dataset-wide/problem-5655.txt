In the following I am not considering substance dualism or idealism, but only materialist/physicalist theories. The Church-Turing thesis states: 

The answer to this is: We can't trust that our current theories are correct, and that is exactly what defines science. Ideally, the scientific attitude is to accept that a theory, no matter how widely accepted and how well supported by experimental evidence, can eventually be proven false and replaced by a another theory. This is the concept of Falsifiability proposed by Karl Popper. A scientist, when stating that they believe that Einstein's theory of relativity is true, should also state the following "under what conditions are you willing to abandon relativity?" - this isn't to say that relativity is false, only that it can be proven false - i.e. there is a possible experiment whose result might show that Einstein's model is wrong and another one should be proposed instead. Contrast this to the religious attitude: When somebody has faith in God, nothing, no set of real world facts or new experiments is going to convince them otherwise. When confronted with facts that might contradict their belief in a benevolent God (the holocaust, the death of children in Syria, hurricane Harvey,...) they would simply reply that "there must be a reason","God works in mysterious ways", etc...and continue believing none the less. One can say that the concept of God is not falsifiable (see this post). Another way of looking at it is the following: Religion is backward looking, it assumes the truth is already established and known, we just need to go dig it up from the right sources. Science (again ideally, not always in practice) is forward looking, it assumes that the complete truth is not known yet, and that more shall be revealed. It should be noted that there are some problems with the falsifiability approach to define science, but discussing them would make this post too long. Look up underdetermination, Quine, Kuhn and Feyearbend on the philosophy and demarcation of science. Overall, Popper's approach provides a working way of distinguishing science and religion, insofar as they are trying to address the same questions. In this sense, science is better than religion, because it is flexible and is willing to admit its mistakes, while religion is dogmatic and doesn't allow for self-correction. 

It should be noted that the type of determinism you mention has been disproved, first by the empirical results of quantum mechanics, and more recently by Wolpert's theorem. Wolpert's result is particularly interesting, since it puts a limit on what an intelligent agent can predict in a universe, regardless of whether the universe is random (by QM) or not, effectively showing that Laplace's demon is impossible. 

You have to be careful about what Carnap and other logical positivists are trying to do. They are not trying to prove a linguistic point about grammar and meaning. They are trying to prove an epistemological point about how language and meaning connect to the world, as expressed in their famous verification principle. The verification principle states that the only statements that are meaningful are those of logic and those that can be verified empirically. Let me illustrate: Consider 3 statements: 

I was reading a text book that stated that Wittgenstein's Tractatus Logico-Philosophicus is rarely criticized in a serious way, since Wittgenstein himself rejected its ideas in his later phase, as explained in his Philosophical Investigations. Are there any philosophers that still take it seriously? and are there any contemporary schools of thought or topics in Philosophy where the Tractatus' ideas are still influential? 

Only then can we argue that workers are entering freely into any labour agreements they sign up for, without any coercion. For the second part: 

From the SEP article on soul-body hylomorphism "The soul bears the same relation to the body which the shape of a statue bears to its material basis,", as well as other definitions (e.g. wikipedia), it seems to me that soul-body hylomorphism is the same thing as property dualism. However it has been pointed out to me in other threads on Philosophy SE, that property dualism covers a wide range of options and that I don't understand dualism properly. My questions: 

Added in response to OP's comment One might go so far as to say that even an addict's behavior still conforms to some internal logic, with the urges and emotions induced by the drug acting as inputs, and the final behavior still consistent given the inputs. This implies then that emotions are somehow separate from thoughts, but I think that emotions and thoughts are much more interactive than that and such a separation is impossible. Can someone think about an ethical or moral issue without their emotions regarding that issue influencing the thought process? I doubt such impartiality is possible - those who do act against their emotions have to exercise great effort in doing so. But let's assume you're right, and emotions are indeed separable from thoughts. Even then, there are cases of denial, people suffering from shock, people have psychotic episodes due to PTSD. One can adopt a computational theory of mind (you are assuming the mind follows some internal logic), and compare the situation to that of computers: What happens when a computer goes into a logical inconsistency? It crashes or goes into an infinite loop, or freezes. It ceases to function, and it calculations are interrupted. This is exactly what happens to people who face experiences so traumatic that they become delusional, catatonic, unresponsive to external stimuli, schizophrenic, etc... 

On a similar note, I've always wondered why mathematics and theoretical physics departments didn't hire a bunch of developers to set up large clusters churning through potential theorems (suitably encoded) and trying to prove or disprove them with genetic algorithms, simulated annealing or survey propagation. Whenever they stumbled upon a positive (i.e. a theorem that is true), they would bring in their human mathematicians to verify and then edit and publish the result if it is relevant. 

Given these 2 developments, does DesCartes' proposition that ideas lack extension because they are indivisible still hold? 

Quantum mechanics is a supposed to be a fundamental theory, the question isn't whether it is compatible with reductionism, but whether other theories can be reduced to QM or not. Moreover, Quantum Mechanic's success is usually ascribed to the fact that other theories have been successfully reduced to QM. The text book example of successful scientific reductionism is usually the reduction of chemistry to QM. You say in the comments: 

I've recently come across several statements to the effect "there are questions science can't answer", mostly from proponents of religion and mysticism, but also from scientists and secular philosophers as well. However it seemed to me that there was an inherent contradiction in statements of the type "Science doesn't have all the answers" or "Science can't answer all questions". This is hinged on what is meant by "answering a question". It seems to me that to answer any significant question is to provide 2 things: 

Philosophical Zombies can have mental states and would still be Zombies. The whole point of Chalmer's Zombie thought experiment is to show that having mental states isn't enough to account for subjective/phenomenological first person experience. After all, computers have "mental states" - their internal memory states and software configurations - but don't have conscious experience. Here's one way of looking at it: Imagine that your Zombie isn't created by evil magic, but instead is a super advanced android, one that is indistinguishable externally from a human in terms of behavior and appearance. Per Chalmers, this android has internal mental states in its robotic brain, but it still doesn't have first person subjective experience. Another way to look at the question is historically: The main materialist position w/r to the mind body problem in the early to mid 20th century was behaviorism. This was the idea that only external behavior was observable and talk of internal mental states was unscientific, since there was no way to measure/observe them. A problem with this view was that most accepted that the same behavior could correspond to different mental states, or vice-versa. If someone is crying, are they crying tears of sadness or tears of joy? To solve this problem, functionalism was proposed in the 1960s, which was basically "behaviorism + internal mental states" - and was inspired in part by developments in computer science (see Hilary Putnam's work on the topic for example). Chalmers' Philosophical Zombie concept is a direct response to functionalism: That even when taking into account internal mental states, materialism (or physicalism) still fails to account for first person subjective/phenomenological experience. 

Consciousness and the mind are non physical phenomena, and computers are physical systems so, no, computers can't be conscious since they lack the non-physical component. The idea that consciousness is non-physical is called (mind-body) Dualism. Consciousness is a physical phenomenon, the brain is a biological computer and the mind is just software implemented on the brain. This position is known as functionalism or the computational theory of the mind. In which case computers can and most likely will become conscious. Consciousness is physical, but has a non-computational or non-algorithmic component. John Searle, of Chinese Room fame, holds such a view: Consciousness is a purely physical phenomenon, but the simulation of consciousness is not the same thing as consciousness, just like the simulation of bird flying on a computer doesn't constitute real flight. In this case, digital computers won't ever become conscious, but different types of futuristic bio-computers might be become conscious, provided we gain a better understanding of the physics and biology of consciousness. 

It should be noted that most scholars believe that monotheism evolved from polytheism in a more gradual way than what you describe. Monotheism (and more specifically Judaism which is the source of most other monotheisms) is thought to have grown out of henotheism. Henotheism is when one worships only one god, but believes that other gods exist, or at least that their existence is possible. It is speculated that the Jews progressed from "there are many gods, but we only worship Yahweh" to "Yahweh is stronger and than all other gods and he will be angry if we don't worship him alone" to "Yahweh is the only god". In the Bible says more than once that Jews are forbidden from worshipping other gods - because Yahweh is a jealous god. If these other gods didn't exist, why be jealous of them or worry about them at all? Christianity and Islam, then picked up on this concept and extended to mean that worshipping more than one god at once is somehow evil. 

You are touching on two different problems in philosophy of mind, the hard problem of consciousness and the problem of freewill. 

There is at least one a priori truth for such a system - and arguably a synthetic a priori truth at that - this AI system will be limited by the Church-Turing thesis. The AI in question won't always be able to solve Turing undecidable problems, i.e. there will be formal decision problems for which it can never guarantee that it will find a solution. 

Strictly speaking, Popper wasn't concerned at all with how science progresses, only with the demarcation problem, that is how to tell the difference between science and pseudo-science. Kuhn on the other hand, was concerned with the history and progress of science, but ended up discussing the demarcation problem as a result of his investigations into the history of science. In fact that was one of his key insights: That it was impossible to separate the philosophical demarcation problem from the history of science and scientific progress. Philosophically, the main difference between the two lies in their assessment of the problem of auxiliary hypotheses that faces falsificationism. Consider the problem of falsifying Newtonian mechanics based on measurements of planets orbits. You measure the orbit of a planet, and if it corresponds to the predictions of Newton's laws, then Newtonian mechanics is confirmed. However if the measurement doesn't confirm with Newton's laws, you are faced with two possibilities: