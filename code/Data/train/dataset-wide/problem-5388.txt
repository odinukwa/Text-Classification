Epistemology, as systematic reflection on knowledge, is traced back to Aristotle who was the first to discourse explicitly about logic, e.g. how some true propositions are obtained from others and cases where it is not so. Gaining epistemological awareness is much like becoming aware of grammar: people can talk and they know lots of things without any 'theory', but, except for radical pragmatists, doing is usually taken to be different from knowing. As the later name suggests it is second order knowledge: bio-logy is knowledge about life and epistemo-logy is about knowledge. Distingishing meta-knowledge became rather important in modern times when the cases science vs. religion were debated. However philosophy also rapidly lost credibility on empirical grounds and it turned more and more into epistemology. Raids into the domain have been carried from the factual side by psychology and cognitive science and from the theoretical - by mathematics. (No need for refs about such well known history.) 

Angst is a key concept for existentialism and the foreign word has been adopted for lack of a good translation. It apperas to have the advantage of not presupposing that the unknown is some object but could be an extraordinary event or just anything unthinkable. Locus classicus and source of the name is a book by Kirkegaard translated with the title The Concept of Anxiety or The Concept of Dread. The French word 'angoisse', popular with the local existentialists, fits rather well the definition "fear of unknown". 

I am currently reading Ian Hacking’s Why is there Philosophy of Mathematics at all, and it is mostly about the contemporary dabate platonism/ nominalism, so I would recommend it as a good place to look for an answer to this question. A crude copy-paste is given below. Hacking asserts that it is Paul Bernays who introduced the modern idea of 'platonism' and further he writes about the different brands of platonism, noting (p228): 

This is of course a rather vast topic with innumerable references, but in a nutshell the mainstream answer seems to be: the world is observer independent but there should be someone to assert this. The details are numerous and tedious. Philosophers have distinguished the cases of many, few, one and zero observers. Also they know that what is true up to the limit is not necessarily true at the limit; so, one can disagree with transposing from the common sense to the singular case and beyond. There are more caveats in passing from 'one' to 'any', with 'possible observers' somehow lurking in the background. Solipsism is not a position that can be refuted and lawyers used to say 'unus testis nullus testis' (one witness is not a witness). Anyway an assertion such as 'the world is observer independent' needs someone to make it, a way to check its content and to decide if this is indeed the case. Ancient Greeks refer to practice of speaking your mind as parrhesia: that is to say frankly and sincerely what you believe the case is. Most people would probably say the world is observer independent. In a larger society with conflicting interests 'truth' became not what you believe to be true but what is provable. This is the positivist turn which governs much of today's philosophy. 'Provable' is taken to mean - by logical argument or by evidence. Skipping the analysis of observer(s), world, existence etc, the last word seems to be that there is not conclusive proof that the world is observer independent. 

Science is a method. The scientific method gives us tools to hypothesize and theorize models to fit what we currently observe about our universe. Science is not an absolute truth; our body of scientific knowledge is a collection of the best models we currently have. Many models are extremely strong, some are works in progress, and some are just starting to develop. We don't yet have models to fit absolutely everything that we observe, and there are also many things that we have not yet observed, could never observe directly, or have not yet even contemplated. We are inside of a complex system, doing our best to make models that explain the system. Physics is the primary tool that we use to explore models for the mechanics of the universe. We use our current theoretical models of the universe and extrapolate backwards in order to hypothesize what came before what we currently observe. The strongest theory I have ever read for the initial inciting force is the necessity for the existence of an "unmoved mover" (also called "prime mover"). It is philosophy that illuminated the unmoved mover. I would recommend reading about it. I will try to find a better link that Wikipedia, but it is a great start. Nothing from astrophysicists that I have read has presented a convincing-enough argument for what comes before the Big Bang. Many refer to a singularity, but the force that initiated the expansion of the universe has not been successfully modeled. This suggests that it is indeed philosophy that so far has been capable of going beyond the current scientific models proposed. (I consider religion as being an aspect of philosophy.) There are various proposed scenarios for the very early universe, most of which differ radically from one another. A discussion of some of them can be found in the Wikipedia entry on the Chronology of the Universe: 

These are uncomfortable questions, but that's because the realities of these issues ARE uncomfortable. We try to hide behind the word "person" to shield us from the discomfort, but we can't change reality to fit our comfort levels. This would allow people of different belief systems to converse more logically about issues that absolutely must be discussed, without perpetuating the current cycle of conflict and misinformation. To summarize, by the argument I laid out (that if it is X at the end, if there is no significant switch, then it must be X from the start), there is not a good criteria for terminating another human's life at any developmental stage to use its cells. The term personhood is inadequate, and more objective terminology should be used in these discussions. Something important to also consider is that this issue will soon be outdated. Pluripotent stem cells are being generated from other sources, and it will soon replace the use of embryo tissues.  I hope this helps generate some interesting thought and discussion, and give you some points to research and consider further as you develop your presentation. 

It is an irony of history that Aristotle's First Philosophy came to be seen as coming last and was dubbed Meta-physics; for Descartes it is still the First and its answers determine the rest. And first of all are the questions about what exists. So in the Discourse part IV Descartes wrote: 

Anarchists are defined by their stance towards society, so a good way to approach anarchist ideology is to acquire some understanding of society - what it is, how it 'works', what are power, property, rights, etc. Specific areas as ecology or information are seen to be more restricted cases. In the study of society economics and politics take too much for granted, so I think the best approach is through cultural anthropology: societies in which the uncle takes care of his sister's children, not the father, or societies in which gifts and prestige are more valuable than property and other 'strange' ways of behaving have been documented. David Graeber's work is a really good place to begin: Toward an Anthropological Theory of Value: The False Coin of Our Own Dreams (2001) оr Fragments of an Anarchist Anthropology (2004) readily come to mind here. 

Apparently Wittgenstein had not received any serious training in advanced mathematics and he never displayed any such knowledge nor some understanding about it. He demonstrates a sustained hostility against set theory without ever showing any grasp for its importance in analysis (for integrals, functions, convergence etc.). Nevertheless he claimed having done 'work' on 'foundation of mathematics'. When this work was made public, some 50 years ago, it was dismissed by people like Kreisel or Dummettt. Later, however, it was claimed that he has been misunderstood. One may suspect that philosophers just cannnot accept that their favorite thinker is incompetent and just wasted his (and their) time. There has been numerous attempts to explain what his 'philosophy of mathematics' is: constructivism, some kind of finitism, pragmatism etc. But the lack of consensus, obvious when one leafs through the literature, suggest that perhaps there never really was such a thing to be called "Wittgenstein's philosophy of mathematics". Is this the answer? 

There is a fascinating paper by Marc Shell The Ring of Gyges (The Economy of Literature/1978, ch.1 p.11-62). Herodotus' and Plato's versions of Gyges are interwoven with emphasis on power, vison and wealth. 

Of course. A progressing science is an ideological construct: one may prefer the status quo. We agree that human actions are somehow motivated and purposeful actions are ideologically driven. The decision to measure things is by no means obvious, especially when we note that the discourses of logic and numbers are not really coordinated in ordinary life (e.g. 'negligible' could mean either zero or non-zero). In practice most questions escape the simple logic of yes/no, producing a kind of shrug ('dunno'), and arbitrary decisions are taken with arguments about criteria and precision which remain always discutable. Science is not mechanical or automatical. 

Embryos are a stage in development of human organisms. To phrase the issue concisely: If something is X at the end of a time interval, then either it must become X during that interval, or else it must have been X from the start. Therefore, becoming X requires a distinct change - "person" is a binary distinction. There are no "half-person" or "3/7ths person" as valid options. But physiologically, genetically, biochemically, anatomically - all development is gradual. (Look at the above link and see how slowly we change - and remember that these are a small number of stop-motion frames over 9 months of gradual development in gestation.) After the formation of the zygote, there are strong scientific arguments that no single defining moment of change in the development from zygote through adult senescence is significant enough of a change to demarcate a change in status to toggle from "not a human life" to "human life." Nor from "not a person" to "is a person." (Even birth is a process of several hours to several days, and a journey of almost 2 feet. At what moment is it a human life or a person? Out with cord cut? Without it cut? Only head out? Cervix dilated?) Cognition is also a very gradual development that can vary widely between individuals. Discussions on this have very diverse opinions. I argue that if one cannot define criteria for a toggle point, there cannot be a solid argument for any point. Therefore, if no toggle point can be established, it defaults to the beginning of the line - the first point of formation of that particular human organism. Otherwise we are stuck in vagueness, ambiguity -- but this is a situation where there absolutely must be a definition; lacking a clear definition of "life" or "person" results in dangerous inconsistencies in discussions on policy, bioethics, and legality. 

Science has limits. We use tools developed inside of a complex system to try to measure and model the system itself. It is likely impossible that we, as component parts of the system, could ever build a cohesive scientific model to accurately define the entire system. Science can only expand by extrapolating from our current models and rulesets. Philosophy is a different type of tool which can explore many things that the scientific method cannot. As such, it is essential. Lastly, philosophy has throughout history originated a good percentage of the concepts that science has explored and tested to construct these models. 

My perspective is as a family medicine doctor in training. Yes, I do find it unethical for doctors to refuse patients who cannot pay on the basis of increasing profits. I work in several underserved, safety-net clinics and hospitals that take all patients regardless of ability to pay. This is my career choice because I want to contribute to the solution of our broken system. These clinics have social workers and financial advocates that help uninsured patients try to get insurance or financial support to cover costs and allow them to get consistent healthcare. These clinics receive some funding from the government as well. None of these practices become filthy-rich, regardless if they are private or state or university-based. The practitioners are paid well, but not as much as in a private practice owned by the physician(s) who charge what they want and only take the insurances they want, rejecting anyone uninsured who can't pay up front. These income-driven physicians are pushing their self-pay (uninsured) patients towards the "safety-net clinics," causing these clinics to carry a high % of the burden of uninsured patients while receiving fewer insured patients to recover costs. That imbalances the distribution of reimbursement to practices. If there were limitless numbers of providers and clinics, it would be a minor issue. But there is very limited space in medical schools and residency training programs. There is a primary care physician shortage in the tens of thousands and rising. These profit-driven physicians are taking up spots in training programs that could instead be taken by people willing to accept a good (but not exorbitant) income while investing in balancing and improving the system, rather than just draining the profits of it. So in summary, yes I do find it unethical. But that is largely because it's in the setting of a broken, ineffective healthcare system (especially the insurance system) that drives costs excessively high and makes access to quality care a commodity, rather than a human right.