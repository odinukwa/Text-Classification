If $d>1$, the paper Anatomy of the giant component: the strictly supercritical regime by Ding, Lubetzky and Peres might be what you are looking for. The paper also has references for the cases $d<1$ and $d=1$. 

Since we are talking about rational exponents, I assume it makes sense to restrict to positive real numbers. If I got it right the question is whether a set $S$ where no element is a product of some others to rational powers is necessarily countable. One can show non-constructively that the answer is no, that is, that there exist uncountable sets with this property. This is because the condition on $S$ is equivalent to $\{\log x: x\in S\}$ being linearly independent over the rational numbers. Since there is a basis for $\mathbb{R}$ as a vector space over $\mathbb{Q}$, and such a basis is necessarily uncountable, there is an uncountable set $S$ with the given property. 

Since there is no requirement that the outer region must be a triangle, the question is not quite as trivial as indicated in earlier comments. The rectangle $[0,n] \times [0,1]$ can be triangulated by dividing it into unit squares and then inserting the SW-NE diagonal in each square. Still, this might not be the kind of grid/mesh one wants. To see the problem, it might be easier to think in terms of angles than to use Euler's polyhedron formula: If there are interior points in the triangulation, then the angles at those points have to be at least $90^\circ$ on average, while the average angle in a triangle is only $60^\circ$. It follows that most vertices of the triangulation have to be on the boundary of the region. 

To begin with, one should think about how the game naturally splits into components, and what it means for a game position to be the “sum” of its components. As the game proceeds, the set of unoccupied sites can separate into components that do not interact with each other. In such a situation, a move consists in making a move in one of the components (this is like the classical theory), and winning in one component means winning the entire game (this differs from the so-called normal playing convention where the game ends when a player is unable to move). In classical combinatorial game theory, games are classified into four outcome classes: Positive (Left wins no matter who starts), Negative (Right wins), Fuzzy (Player to move wins) and Zero (Player not to move wins). In a game like connect-four that can end in a draw, there are nine outcome classes, namely the functions from {Red to move, Blue to move} to {Red wins, Draw, Blue wins}. Just as in the classical theory, the set of positions is an abelian monoid under addition (position means what the board looks like, without information about who is to move), and one may define two positions $X$ and $Y$ to be equivalent if for every $Z$, the games $X+Z$ and $Y+Z$ belong to the same outcome class. For instance, all positions with an even number of unoccupied sites, and where none of the players can win, are equivalent. These might be called “zero-positions”, since they include the empty position (neutral element of the monoid). The additive structure carries over to addition of equivalence classes, but unlike the classical case, it doesn’t become a group. The zero class is a neutral element, but not all positions have inverses. For instance, if $X$ is a position is such that the player to move (whether Red or Blue) can win in one move, then there can be no other position $X’$ so that $X+X’$ becomes zero, because no matter what we add to $X$, the resulting game will still be a win for the player to move. On the other hand some positions clearly do have inverses. There is a class that contains all positions with an odd number of free sites, and where nobody can win. We might call this class $\star$, since it is similar to the class "star" in the classical theory. These positions are clearly not equivalent to the zero positions, since adding them will turn a “zugzwang” into a first player win. But we do have the equation $\star + \star = 0$. There are several games, in particular misère games and card games, where the analysis of a corresponding monoid leads to a solution, see for instance my paper The strange algebra of combinatorial games and its references. A couple of questions: Is the connect-four monoid infinite? What do the connect-two and connect-three monoids look like? Finally, it seems worth taking a look at the Masters thesis of Victor Allis from 1988: A Knowledge-based Approach of Connect-Four. 

A special case where we can avoid one of the two sums in James Martin's answer is when the "determinant" $p_1p_3-p_2p_4$ of the four probabilities is zero. Then we can treat the random walk as a "sum" of two independent one-dimensional random walks, one taking steps $(+1/2, +1/2)$ or $(-1/2,-1/2)$, the other taking steps $(+1/2,-1/2)$ or $(-1/2,+1/2)$. The original walk is back at the origin precisely when both these 1D-walks are. If the transition probabilities of the two component walks are $p, (1-p)$ and $q, (1-q)$ respectively, then the expected number of visits to the origin (including the start) is $$\sum_{n=0}^\infty \binom{2n}{n}^2 p^nq^n(1-p)^n(1-q)^n.$$ In terms of the original probabilities, $$pq(1-p)(1-q) = (p_1+p_2)(p_2+p_3)(p_3+p_4)(p_4+p_1).$$ I'm no expert on this type of sum, but according to Maple, $$\sum_{n=0}^\infty \binom{2n}{n}^2 x^n = \frac2{\pi} EllipticK(4\sqrt{x}).$$ The probability of never returning is the reciprocal of this (with $x=pq(1-p)(1-q)$), in other words $$\frac{\pi}{2EllipticK(4\sqrt{(p_1+p_2)(p_2+p_3)(p_3+p_4)(p_4+p_1)})}.$$ An obvious question is whether this holds also when $p_1p_3 \neq p_2p_4$. Off the top of my head I don't see why it couldn't. 

An example that I came to think of even though it doesn't have to involve infinity is the existence of a finite field with a specified number $q=p^n$ of elements. One can show by an enumerative argument (Möbius inversion) that there must be an irreducible polynomial of degree $n$ over $\mathbb{Z}_p$ (there simple aren't enough lower degree polynomials to factor all of them). If $f$ is such a polynomial, then $\mathbb{Z}_p[x]/f(x)$ provides a field of $q$ elements. An alternative is to use the fact that every field has an algebraic closure, and to verify that the set of zeros of $x^q-x$ in the algebraic closure of $\mathbb{Z}_p$ is closed under the field operations (and that they are distinct). It's true that we really only need the splitting field of $x^q-x$ which, as it turns out, consists of only those $q$ zeros, but that's something that emerges from the proof, and it might conceivably have been much bigger. 

It's easy to see that a ranking that minimizes the number of inconsistencies might have to place a team with fewer victories above a team with more victories. This is because a ranking minimizing the number of inconsistencies can have no inconsistencies between teams adjacent in the ranking (if there were, we could improve by just switching them). So suppose in a tournament that team A loses to team B and wins all other games, team B loses two other games and all other teams win fewer games. Then it can't be optimal in the sense of minimizing the number of inconsistencies to rank A first and B second. Another example is shown in Torbjörn's paper. There are various superficially similar problems that are known to be NP-complete (Torbjörn mentions in his paper the directed optimal linear arrangement and the quadratic assignment problem), and therefore it would be quite surprising if there were an efficient algorithm for finding a ranking that minimizes the number of inconsistencies. But we haven't been able to encode any known NP-complete problem in terms of a tournament requiring a ranking. 

The problem is equivalent to the following: Suppose there are $n$ bins, and repeatedly, we throw balls which fall in one of the bins (uniformly and independently of the history). What is the maximum number of bins with exactly one ball? In the model with the pills, it is explicitly forbidden to draw a pill which has been drawn twice already, but for the current question, this clearly doesn't matter. We can replace discrete time with continuous time, and throw the balls at the events of a Poisson process. This way, the balls falling in a particular bin arrive according to a Poisson process, and different bins are independent. If the problem was to determine the time $t$ to maximize the expected number of bins with exactly one ball at time $t$, then the answer would clearly be to choose $t$ so that the expected number of balls in a bin is 1, and the probability of having exactly one ball would be $1/e$ (we are maximizing $xe^{-x}$). By the law of large numbers, the number of bins with exactly one ball will very likely be about $n/e$ at that time. To conclude that $M/n$ converges to $1/e$ in probability, it only remains to show that "exceptional times" with unusually many bins of exactly one ball are not likely to occur. I guess this can be established by quantifying the idea that if at time $t$ there are substantially more than $n/e$ bins with exactly one ball, then most likely there will continue to be so in a time interval after $t$, which is unlikely. 

Partial answer: If 4b-3 is a prime power, then the Paley graph of 4b-3 vertices will have this property, see $URL$ 

The approaches in the OP already seem quite straightforward to me, and as is clear from the answer by Arthur B, doing the calculation exactly is not too complicated. Anyway, here is my suggestion (after a bit of scribbling) for how one might have seen the solution at a glance. All we have to do is compare the winning chances of person $k$ and person $k+1$ (provided we do it for general $k$). Edit: this is because the winning chances are first increasing and then decreasing, which of course isn't clear a priori, so perhaps the previous sentence should have started "As it turns out...". We imagine two persons A and B who are to occupy places $k$ and $k+1$. We only have to compare the scenarios where the one who goes first wins, to the scenarios where the one who goes second wins (otherwise the order of A and B doesn't matter). Those scenarios first of all require that persons $1,\dots, k-1$ have different birthdays. Under that assumption, the cases where the person to go first wins are when both A and B have a birthday which is already represented among the first $k-1$ people. Counting combinatorially rather than probabilistically, there are $(k-1)^2$ ways of choosing the birthdays of A and B with that constraint. The cases where the person to go second wins are when A and B have the same birthday, and that birthday is not shared with any of the first $k-1$ people. There are $n-(k-1)$ such ways of choosing the birthdays of A and B. Therefore we end up comparing $(k-1)^2$ to $n-(k-1)$, or equivalently comparing $k(k-1)$ to $n$. After having written it down, I get the feeling that this argument is more convoluted than the straightforward calculation by Arthur B, but here it is, for what it's worth. 

I would definitely not introduce any third truth value or other concept of "UNDEF". Here is how I might deal with the issue if it came up in a logic class. I would ask everyone to think of their favorite real number but not tell anyone else. That number is their own definition of 1/0. Now a sentence like $\forall x (x>0 \rightarrow 1/x>0)$ will make sense and be true in everybody's model, while sentences like $\exists x (1/x=0)$ and $\forall x (1/x = 1 \rightarrow x=1)$ might be true in some people's models and not in others. We get some junk like $\exists x (x\cdot 1/x = 0)$ that happens to be true even though it would make the calculus teacher frown. But I don't think that's a problem, and the language will allow a lot of junk like $\forall x (2+2=3 \rightarrow 1+1=2)$ anyway.