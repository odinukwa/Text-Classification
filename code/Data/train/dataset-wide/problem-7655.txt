First off, let's forget the transfinite iteration. As David said, one often interprets algebraic objects such as "group objects" in sufficiently nice categories, intending the word "group" as a cipher for any kind of algebra, so let's also say "space" for any object of any kind of "sufficiently nice" category. Monads provide a notion of "algebraic theory" that can be interpreted in any category. So we can formulate the question more abstractly by asking for a category $S$ (whose objects we call "spaces") for which the opposite category $S^{op}$ is equivalent to the category of algebras for a monad on $S$ (and we call these algebras "frames"). This is exactly the idea behind my Abstract Stone Duality research programme, which was so called because both the duality between algebra and geometry and the "always topologize" slogan behind David's question were due to Marshall Stone. In the ASD programme I developed this idea in the case where the adjunction between $S$ and $S^{op}$ is given by the exponential $\Sigma^{-}\dashv\Sigma^{-}$, where I write $\Sigma$ rather than Todd's 2 for the Sierpinski space. These ideas are summarised from a foundational point of view in Foundations for Computable Topology. Mathematically, the pay-off of the monadicity hypothesis was a theory of computable analysis that satisfies the Heine-Borel theorem, for which see The Dedekind Reals in Abstract Stone Duality with Andrej Bauer. This was applied to the intermediate value theorem in A Lambda Calculus for Real Analysis, which paper is the best introduction to ASD for ordinary mathematicians. This idea works properly for Computably Based Locally Compact Spaces. Can we do something similar taking $S$ to be the category of locales, to get back to David's question? Indeed, Steve Vickers has studied this, using his double powerlocale monad. (I find this easiest to understand as the comonad on frames that arises from the forgetful functor to dcpos.) He uses the name localic locale an object of the opposite of the category of algebras for the monad over locales (or a coalgebra for the comonad on frames), although he has also called them colocales and I like this name myself. We therefore have the categories $L$ of locales and $C$ of colocales, where $C^{op}$ is monadic over $L$, but they are not equivalent. David may therefore ask what the iteration of this construction yields, but in fact it stops at stage 2: $L^{op}$ is also monadic over $C$. Even so, this cannot be the end of the story, because we would like $L$ and $C$ to be subcategories of a single cartesian closed category with finite limits. Steve has used the presheaf category for this and shown that the monad is actually the double exponential in this sense. Reinhold Heckmann constructed a smaller category of equilocales. However, the structure of these two categories is far more complicated than that of equilogical spaces. I am currently studying another categorical idea called equideductive logic, the slogan for which is "a category that lies nicely within its cartesian closed extensions". As in Steve's work, the double exponential brings you back into the smaller category, but I also ask that any subspace of an object in the smaller category (ie an equaliser targeted at any object of the larger category) also lie in the subcategory. 

As Todd has already written an answer for me, maybe I can claim it as an Answer: Exercise 1.1 in my book Practical Foundations of Mathematics (CUP 1999) reads, 

quoting random fragments of what their opponents have said in order to make them look stupid. On the other hand, to say that "constructively, the intermediate value theorem fails" by showing that it implies excluded middle is equally unconstructive. Even amongst mainstream mathematicians several arguments are conflated, so I would like to sort them out on the basis of the generality of the functions to which they apply. On the cone hand we have the classical IVT, and the approximate construtive one that Neel mentions. These apply to any continuous function with $f(0) < 0 < f(1)$. There are several other results that impose other pre-conditions: 

More concisely, it is not far from the truth to say that the purpose of (adding) the minimalisation operation for general recursion is to define inverse functions. That this is Difficult is put to practical use in many methods of encryption. 

You don't really need to construct sophisticated mathematical examples to answer this. The problem is that the word canonical has at best a sociological meaning, not a mathematical one. Are $X\times Y$ and $Y\times X$ "canonically isomorphic" by the switching map? In some contexts it may be reasonable to say so, in order to avoid bureaucratic notation. However, once $X$ is non-trivial and $Y=X$ you have a non-trivial group. All that word canonical means is "I'm too lazy to write down the definition". 

Please can someone tell me the history of the simple argument that any maximal ideal of a commutative ring or distributive lattice is prime? (It is understood that we have found the maximal one using Zorn's Lemma.) How were prime ideals found before the enactment of the Axiom of Choice? How do constructive algebraists find them now? What similar arguments (directly referring to polynomials or algebraic numbers) were used before ideals were invented? My own interest is really in distributive lattices and locales, from a constructive point of view, but I am aware that these notions appeared much earlier for commutative rings. Incorporating my comments: For locales/frames, (the relevant analogue of) prime ideals are (formal) points. To be precise, these are completely coprime filters. In the draft paper [$URL$ on which I am working (and a propos of which I asked this question) I have a partly constructive argument that I also use to find points of inhabited overt subspaces. I am really more interested in the history of the arguments than the definitions (or even concepts). Maybe factorisation is the relevant idea to pursue in order to answer my history question. As Mamuka says, it all comes from prime numbers and therefore probably from the argument by infinite descent in Elements VII 31. 

Mike, if you consider that locally cartesian closed categories provide the canonical semantics for dependent type theories then you may as well just use sets, for which any function $p:A\to X$ provides a dependent type $A[x]=\{a|p((a)=x\}$. Not only is this a very dull notion of dependent type, but it gives no account of the way in which $A{x]$ might depend "continuously" on $x$, something that we probably need to understand in order to give a meaning to the word "recursive". (Local, relative or ordinary) cartesian closure is needed to interpret function- or Pi-types, which do not feature in your question. The appropriate arena is a category with some finite limits and something infinitary to capture the recursion. A class of display maps is a class of morphisms that is closed under (composition with isomorphisms and) pullback against arbitrary maps in the category. This categorical notion is equivalent to that of a dependent type theory in the basic algebraic sense, ie with types, terms, equations and structural rules. As I believe you are more comfortable with a categorical language, you can solve your problem in that setting and then use the equivalence to reformulate it symbolically. In particular, the class of display maps includes - all isomorphisms iff the type theory includes singleton dependent types; - composites iff the type theory has Sigma types; - inclusions of diagonals and hence all maps iff the type theory has equality types; - relative cartesian closure corresponds to Pi types. I had originally interpreted your "recursively dependent" types to mean an infinite chain of dependencies, and hence of display maps. For that you would want the class of displays to be closed under cofiltered limits. Neel, on the other hand, read it as a fixed point equation, which we can interpret categorically as the fixed point of a functor. Unsurprisingly, domain theory would be a useful setting in which to look for models of these situations. Indeed my PhD thesis introduced classes of display maps in order to study dependent types in domain theory, and you might like to look at the last chapter for investigations of appropriate notions of displays of domains. For the theory of display maps and their equivalence with dependent types, my thesis was completely superseded by Chapter VIII of my book, "Practical Foundations of Mathematics" (CUP 1999). For the interpretation of dependent types in domain theory, Martin Hyland and Andrew Pitts gave a comprehensive account in their paper The Theory of Constructions: Categorical Semantics and Topos-Theoretic Models in Categories in Computer Science and Logic edited by John Gray and Andre Scedrov, AMS Contemporary Mathematics 92 (1989). 

The post by John Baez in the $n$-Category Café gives a nice example of how the the Matthieu Group $M_{12}$ can be presented more simply using a groupoid called $M_{13}$. 

Martin's claim seems to be that he can define a field in a category with products and an initial object, but I am skeptical of this. I am uneasy with the language of the definition, in particular with the occurrences of $X\setminus\lbrace 0\rbrace$. This seems to be a mixture of categorical diagrams and a naive mathematical language that possibly assumes excluded middle. I think it would be a good exercise first to try to define an integral domain in this kind of language. Yves Diers did a lot of work in the 1980s on disjunctive theories in his categorical study of commutative algebra. A useful survey paper that will give you a good introdction to this is A syntactic approach to Diers’ localizable categories by Peter Johnstone in M. P. Fourman, C. J. Mulvey, and D. S. Scott, editors, Applications of Sheaves, volume 753 of Lecture Notes in Mathematics pp 466–478. Springer Verlag, 1979. Following the ideas in these papers, one can define a field in an extensive category with products, that is, one can express axioms such as $$ 0=1 \ \vdash\ \bot, \qquad x y = 0 \ \vdash\ x=0 \lor y=0, \qquad \ \vdash\ x=0 \lor \exists y. x y = 1. $$ Any category that one would be likely to regard as a "category of spaces" (in a very general sense, including locales and affine varieties) is extensive. So, if Martin wants to define fields more generally than this, I would first ask why? Does he have in mind some candidate for a "field" in a particular concrete category with products and an initial object but not coproducts? The foregoing comments assume that we working with fields where equality makes sense, such as algebraic number fields. In the case of $\mathbb R$, by contrast, inequality is the more natural relation. I could say a lot more about this from the point of view of different approaches to constructive analysis, but I haven't studied or thought about is in the context of categorical logic. 

I don't have Bart Jacobs' book so I don't know for sure what the context is for this extract from it, but I suspect that it is the categorical semantics of a type of types or universe such as in Martin-Löf Type Theory. This is not treated by Mac Lane or Lambek and Scott but my own book Practical Foundations of Mathematics considers related material, though not Martin-Löf Type Theory. A fibration is a way of presenting the manner in which a mathematical structure varies according to a certain parameter. The parameter is represented by the base category $\mathbb B$ and for each value $X\in\mathbb B$ the corresponding structure is the category ${\mathbb E}_X$, which is called the fibre over $X$. As $X$ "varies" along a morphism $f:Y\to X$, this structure is related by a functor $f^*:{\mathbb E}_X\to{\mathbb E}_Y$. In a fibration, all of these categories and functors are collected together into a single category $\mathbb E$ together with a functor $p:{\mathbb E}\to{\mathbb B}$ with certain properties. In this, the fibre ${\mathbb E}_X\subset{\mathbb E}$ consists of the objects and morphisms that $p$ takes to $X$ and ${\mathsf{id}}_X$. We say informally that these objects and morphisms live over $X$. The clearest paradigm of the use of fibrations in categorical type theory is that of types and predicates. Then the base category consists of types and terms (more precisely, its objects are contexts, ie lists of typed variables, and its morphisms are lists of terms whose types correspond to the target context and whose free variables correspond to the source). The fibre over a particular context consists of the predicates in its variables. The horizontal or prone or cartesian lifting of a base morphism at a predicate has as source the substituted form of the predicate using the terms that make up the morphism. What is a generic predicate? Since any predicate on any type can be a substituted form of it, the free variable of the generic predicate cannot be any ordinary type but must somehow say what it is to be a predicate. If you follow through the definition, you will see that, for a strong generic predicate, this type has to be the subobject classifier $\Omega$ of a topos, whilst a weak generic predicate is the type or kind $\mathbf{Prop}$ of propositions. We can handle universes or types of types in a similar way. Now the variables in the base category denote type-unknowns and the fibre over a particular context (list of type variables) consists of the type-expressions and terms that are definable using that list of type variables. The generic type is a single type variable qua type-expression in the fibre over the context that consists of that single type vaiable. Analogously to the previous case, its type is $\mathbf{Type}$, the type of all types. However, this can only give a weak generic type. In fact, $\mathbf{Type}$ cannot itself be a type if you want the terms to do ordinary mathematics, with equality and functions, although it can be if you're doing domain theory with fixed points. In the former setting, such as in Martin-Löf Type Theory or Homotopy Type Theory, a hierarchy of universes is introduced; this has a corresponding hierarchy of generic types. Personally, I feel that fibrations obfuscate categorical type theory. The naive way of doing this would be to use indexed categories, which are functors ${\mathbb B}\to{\mathbf{Cat}}^{\mathsf{op}}$. In the applications in pure mathematics, we get pseudofunctors instead, where we have to take account of isomorphisms and coherence thereof; this was the reason for using fibrations instead, as explained in a paper of Bénabou that is notorious for its personal language. In the applications to type theory, on the other hand, these isomorphisms are unnecessary because the syntax ensures functoriality. A deeper objection to indexed categories is that the functors mix up internal and external notions and making sense of them in the usual foundational setting (sets or toposes) requires the axiom-scheme of replacement. Using fibrations avoids this and potentially allows us to understand replacement in the context of a topos (see the final pages of my book). The categorical technology that I prefer to fibrations is that of a category with a class of display maps, which is set out in Chapter VIII of my book. In the applications of fibrations to type theory, each fibre usually has a terminal object, with which we can identify the objects of the base category, and we just work in the total category of the fibration (its source qua functor). The display maps are the terminal projections in each fibre, from which we recover the fibration as the codomain. In the paradigm of types and propositions above, an object of the total category is a list of types together with a predicate on them. We may think of this as a subset of a product of sets, or just a mono. A morphism is a commutative square, which is a pullback iff the morphism is prone (horizonatal, cartesian). A base object (context) consists of a list of types together with the true predicate, or a set considered as the entire subset of itself. The display map corresponding to a particular object (mono) is the square consisting of this mono on the vertical sides and identities on the horizontal sides, though more briefly we take it to be the mono. We can think of the display map in terms of its fibres. In the case of a predicate on a single type (or subset of a set), the fibre over an element is the truth-value of the predicate at that element, where we think of a truth value as a subset of the singleton. The mono displays these truth values over the set in that the source of the display map is the disjoint union of these sub-singletons. I leave it as an exercise to see why the map $\top:{\mathbf 1}\to\Omega$ in a topos is the display of all possible truth values over their names. We can now understand a generic type in the same way. The target of the display map is the type $\mathbf{Type}$ of all types. The fibre over each element of $\mathbf{Type}$ (the name of a type) is the extent of that type, so the source of the display map is the disjoint union of all types. I leave it as another exercise to see that, for a model $M$ of set theory, this display map is the global mebership relation, $\{(x,y):M^2|x\in y\}\to M$ by $(x,y)\mapsto y$. I proposed the word prone in this subject because the notion has nothing to do with Descartes and the word cartesian, like regular and normal, is grossly over-used in mathematics. Morphisms of the total category that the fibration takes to identities have been called vertical. However, there are two ways in which morphisms can be orthogonal to vertical morphisms, whilst the English language conveniently provides two words for horizontal, namely prone (face up) and supine (face down).