I do something similar on my side, and I use a MySQL Stored Procedure / Cursor. You loop through each line of the table and record the current datetime entry and plant_status into variables, and then move on to the next line. At which point you compare the current datetime and plant_status with the last ones. If it matches a set condition (in your case != ) you add an entry to a temporary table. And then at the end you simply select * from temporary_table_name to show you all the rows where the status changed. You could easily convert this to check the datetime as well (changing the old_datetime variable each time the status changes), and comparing that to the current one to find out if there is a two hour difference). (this probably should be a comment rather than an answer but I don't yet have enough points to comment - sorry) 

I had a similar problem a while back, and etc refused to fix it. In the end I simply took the table structure from a 'good' database and compared it to the 'broken' one. Then made the necessary adjustments. In my case I found that one column had changed slightly. 

But I am using MySQL 5.5. Is this the correct version of innobackupex to use with my databases, and if not which version should I use? The documentation isn't very clear. I installed it using the following process: 

The relation with the above functional dependencies has two different candidate keys: B and G. You can verify this if you compute the closure of both to see if it contains all the attributes: 

Normal forms are used to eliminate or at least reduce redundancy in data, as well as to eliminate the so called insertion/deletion anomalies. The BCNF eliminates redundancies and anomalies, but decomposing a relation in BCNF sometimes has the unpleasant effect of causing the loss of one or more functional dependencies during the process. For this reason the 3NF is used instead of the BCNF in practice, since a decomposition of a relation in this form always mantains data and dependencies, and reduces anomalies and redundancy (even if to a lesser extent that the BCNF). Another reason is that the decomposition in 3NF can be obtained with a polynomial-time algorithm, while the decomposition in BCNF requires an exponential algorithm. 

So in your example you can see that both and are dependencies in which the left hand side is a key, so the answer to the first question is yes. In the third dependency, instead, is not a superkey, (since ), so, is a prime attribute? To answer to this question, you should know all the keys of the relation, and see if belongs to one of them. And in this case this is very simple, since A is the unique key of this relation, so you can conclude that the relation is not in 3NF. But note that in general, in more complex cases, it is not so simple to answer to such question, since you can have a very large number of keys, actually a number which is exponential with the number of attributes. 

Or would an index on only suffice? It's quite a large table so I don't want to spend time adding the index if it is unlikely to help. 

The config items you added in should have little to no impact on the situation. n.b. you will probably also want , (details) but leave that out until after you've imported the data, of you'll have 100's of GB's of binary logs created. I think the real question is whether your OS is happy with a single file that size, bearing in mind that it wont get smaller, but may get larger. If it's going to be an issue you may want to look at (details) which 'basically' splits the data between and a file for each table. (This involves reloading the dumpfile to take affect) (this is on by default from MySQL 5.6.6) There are pros and cons for both options. 

Try running on the slave to make sure it has got the you think it does. If not you can run and make sure it is set up in the file for when you restart the database. Also check the error logs as there may be additional info in there that can help. 

I'm guessing I'm doing something that's prohibited by MySQL, but can't see what. Basically, I have a set of tables that hold lists of things (, , etc.), and I need to create a joining table to hold each of the ID's (e.g. , , ). At present there is no real relationship between the various lists. This table needs to be automatically populated each time I add a new . To get the matching entry, I need to use a statement to match the first letters of the , and get the relevant entry from the other table(s). My plan is to have a set of Procedures (one for each table I need to join): 

As already cited by others in comments, adding to your table specification can improve in a significant way the performances of your queries (in addition to the very good methodological reasons stated in another answer). The reason is that the query optimizer, knowing that a column cannot have a value, can exclude special tests for such values, like in the vs. case. You can see for instance this blog, where it is shown that not declaring a field (when the table contains always non null values) with a certain query increases the execution time of 500%. The result is shown for SQL Server, but a similar behaviour could be present in other relational DBMSs, like yours (not to mention the fact that your database could be ported to other systems). A general rule that you can assume is that when more information is available to the query optimizer, then more efficient access plans can be produced. 

The decomposition that you have produced is in effect correct, in the sense that the decomposed schemas are in BCNF. However, as you have already noted, it does not preserve the dependencies, in particular the dependency is lost. So you have re-discovered an important point about the decomposition in BCNF: one can always decompose a relation in BCNF, but at the price of sometimes losing one or more dependencies. What does this mean in practice? We can lose (possibly important) constraints. In this case, for instance, the constraint that for each couple of values there is always a single value of cannot be enforced on the resulting schema. Can we do something for this? Well, we could decompose instead in 3NF, because the synthesis algorithm used for 3NF is guaranteed to produce always lossless and functional dependency preserving decompositions. In this case, for instance, it will produce the decomposition and , that maintains all the dependencies. But, wait a moment! we have now a decomposition that does not eliminates all the redundancies eliminated with the BCNF algorithm, since, because of the dependency , we will have the same value of each time we have a certain value for . So, we have now a dilemma: should we prefer the 3NF that preserves the dependencies at the expense of maintaining some redundancy, or should we prefer the BCNF that reduces the redundancies at the expense of losing some “meaning” of the data? The opinion of many is that we should choose the 3NF, since data meaning is considered more important that data redundancy (and not only this, but because the 3NF algorithm is a polynomial algorithm, while the BCNF algorithm is an exponential one). 

I think I found the problem. Apparently the command ended at the symbol, so when the session expired the second part of the command stopped with the session. To get round this I ran: 

What I would do is set it up with sufficient partitions so that your top (MAXVALUE) partition never gets used. In this way when the time comes to add the next partition, you are going to re-partition the 'empty' MAXVALUE partition which should be a lot quicker. So you would start by adding a partition for which replaces the MAXVALUE partition. Then when you get close to 2300000 entries, you would add a new partition for . And because you would be splitting the empty MAXVALUE partition it will be relatively quick. 

which is basically all the (hundreds of) updates listed one after the other, with no indication of which one is which. But how do I find the one that is causing the problem on the slave? (e.g. which one is at position 211713441) There are literally hundreds of updates, one after the other. 

I've been looking to implemement the . So far I have installed it and configured it, and it seems to be working ok. Except, I have installed it on a slave Database as I don't want to run it on my master database (because of the additional overhead, and the fact it requires a DB restart if I want to configure it), and it doesn't appear to be logging any queries. I have set up a script to import the logfile back into a standalone MySQL instance so I can query it, and from what I can tell it only records events that happen locally on the slave, but ignores all queries that are replicated from the master. I implemented it because I need a way to audit the types of statements being run on our databases (, etc.) but if they're not going to be recorded it's not much use. I can't see anything in the documentation for this (either Percona or MySQL). Does anyone else use this, and is it just me that has missed something or am I going to have to go back to the drawing board. I'm running MySQL 5.5 with Statement Based Replication. 

Let's find the 3NF with the synthesis algorithm. The first step is to collect together all the dependencies of the canonical cover with the same left part, that is: 

Just looking at an example of a table is a wrong way of normalizing. You should understand the meaning of the fields to properly normalize. For instance you should know if the salary is the same for all the persons that have a certain role, or if it differs from person to person (in the above example we cannot know, since each role has only a person, so that both interpretations are possible). To know the meaning of the properties you have two routes: either know the meaning of the elements of the domain, through a high level model of it, (for instance through an Entity-Relationship model or a UML model), or to have formalized this knowledge through the definition of the functional dependencies holding between the properties. In your example there are two points that are not clear (that this that are not clear from the example table): is the salary related to a role or to a person? Is the Est. Time related to a project or to the fact that an employee works for a certain project for that estimated time? If the correct anwer to those question is the first one in both cases, your schema is correct (or normalized). Otherwise you must revise it. 

The IP Addresses in your variables need to be enclosed in single quotes in order to make them character strings (as they have been Declared). The variables need to be moved below all the statements. You also need to add a clause above and the matching clause before your final clause. 

will that fail to execute as is the default, or will it succeed as it is that has been changed? All the examples I can find refer to statements, and are quite clear on what will and wont work. But I can't find any examples that refer to DDL statements using . (n.b. I'm currently using MySQL 5.5 in case that makes a difference - upgrading is not an option any time soon) 

But this keeps telling me If I type the filename in manually it works fine. But I have 50 such files, and this will be a frequent process which I need to automate. If I do it works and I get the 'filename'. I tried concatenating it with but that didn't work. I tried creating a stored procedure, but that 'isn't supported'. I tried using a prepared statement, but that 'isn't supported'. Is there a way of doing this, am I missing something? 

The only candidate key of your relation is {D DA HA L NF} (perhaps with R you mean D?) You can verify this by calculating the closure of those attributes, {D DA HA L NF}+, and seeing that it contains all the attributes, while, if you remove any one of them, the closure of the remaining set does not contains all the attributes (this is the definition of a candidate key). The relation is only in first normal form, since the second normal form requires the absence of partial dependencies, that is of dependencies in which non-prime attributes (i.e. attributes not belonging to any key) depends only on part of a key. In this case only the last functional dependency is not partial. 

A BCNF for your example In your example, a BCNF obtained with the classical analysis algorithm is the following (starting with a minimal cover of F and producing a decomposition with a cover of the projection of the dependencies): 

In your relation schema, there are three candidate keys: , and . Since, for instance, violates the BCNF, we can decompose the original relation in: 

Your problem can be solved with the following set of tables: A table location, with attribute id, and attributes common to all location (like position, etc.) A table for each type of location, with all the attributes specific with that table, and an attribute location_id which is a foreign key for the table location. Then you could consider of adding, if necessary, an attribute to the table location that represent in a compact form all the types associated to that location (for instance an array if you use PostgreSQL, or something similar). 

I have the below Data / Query. Is this really the most efficient way of doing this? As it seems like a lot of work to get the result. I've tried reducing it / combining the parts but this is the only way I can get it to work. (n.b. The actual table has a lot more entries over multiple days - hence the WHERE filters at the end) 

After setting it to 0, it will prevent everything in your current session being written to the Binary logs. Setting it back to 1 will resume writing to be binary logs. Everything else continues as per normal. 

The only way for a 'slave' (e.g DB1) to update the 'master' (DB0) is if the 'slave1' (DB1) is also acting as a master to the 'master' (DB0). (commonly known as Replication) You can check if this is the case by connecting to your 'master' (DB0) database and running The result 'should' be blank, most likely it isn't. Look for the fields: and - this is the database from which it is receiving data. It will probably relate to one of your 'slaves' (DB1). and - if these are both 'Yes' then replication is up and running, and any changes made to the database above will appear on your 'master' The quickest way to stop it is to then issue on your 'master' (DB0). Depending on what version of MySQL you are running there are then some things you can do to erase the settings. $URL$ (I recomend making a note of the settings in before issuing any kind of RESET, just in case) Also you may want to add: to your my.cnf file on your master, which will prevent the database starting replication again if the server is restarted. As @ypercube mentions above, you should avoid writing to a 'slave' database, unless you have specifically configured it as part of a master to master setup.