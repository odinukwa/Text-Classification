I just tried this on my SQL Server 2012 instance and it worked. Only way you can do this. To me the big question here is - why is your file system FAT32? What OS is this on? Are all of your databases on FAT32? It is possible to be on FAT32, but the recommendation is to be on NTFS volumes. On FAT32 you don't get certain permission benefits that you get on NTFS - leaving some files open for manipulation and resulting problems, and obviously this CHECKDB issue. 

The short answer is maybe. You can read the SQL Server transaction log (that is your .LDF file) in an online database. Using the fn_dblog function. This post describes that process. There is a slightly longer answer, though: Why/how do you have your .mdf and .ldf from that day? If you had a crash consistent copy of them - in other words, a Volume Snapshot Service (VSS) orchestrated snapshot of the files with a tool that is SQL Server aware - then you are in good luck. If the snapshot was just taken randomly with some other tool that doesn't instruct SQL Server to freeze/thaw the IO before and after the snapshot there is a chance that your log file and data file are not 100% consistent (as in from the exact same moment in time) and it won't be of any use. The steps you could go down are: 

Short Answer: Seeing higher IO stalls may or may not be a problem in an of itself. You need to look at more information to suss out if it you have an issue. It does seem a bit high, yes, but are you suffering? If so, it is probably because either your IO system is not handling the load right (because it can't, because you have everything on one drive or some other reason) or you are doing too much in TempDB (changing the first problem - the IO performance - is probably an easier and more efficient fix, but first determine if you have a problem) The longer discussion/answer: There are two questions at play here - 1.) What do I do when I see high IO Stalls? First off, "high" is in the eye of the beholder. If you were to ask 10 DBAs what "too high" is for IO stalls you'd probably get 2-3 different answers with numbers in them, 5-6 "It depends" answers and one blank stare. My assumption is an average of 400ms is potentially too high here, especially when the other DBs are 2ms or lower for the average stall time. Regardless of which database is seeing the high stalls you should approach it the same way. An IO stall is what it sounds like... An IO request taking longer than expected.. Stalling. These happen. They happen all the time in a system with resources being shared and finite resources (really all of our systems). They become an issue when the stalls become performance problems or lead to them. So I trust that you are looking here as a proactive part of monitoring or because you were experiencing performance issues that you are troubleshooting. We also don't want to get lost in just IO stalls. We are looking at a piece of the puzzle and not the big picture. It can be troublesome to just look at wait stats or file stats since SQL was last restarted because you are looking at all time and some maintenance window or heavy load window could skew counters. So make sure you look at the full picture. But when I suspect I have a disk performance issue or see something off in a query like this, I normally follow a process that looks like: 

Just deleted my previous answer as I started a proposed canonical question for this type of question. In case that flagging doesn't work, a short answer for you here. You have a couple options. Big "Warning" here is - Shrinking isn't always a good thing, it fragments your indexes and takes some time. So proceed cautiously. 

A few thoughts. It sounds to me like you may be able to get away with a couple options if replication is what you end up with. First a word of caution - Replication isn't something that should just be configured in production and enabled/used unless you have some experience with it. This becomes truer with more important workloads and busier systems. Replication can cause headaches if not properly done. I'd invest in mentoring/training/consulting to help you along the path from folks who have been burned by mistakes already. That said. It looks to me like your requirements don't seem to have any 2-way changes that need to be synced up or merged. It looks like you have a bunch of things that need to go one directional. Orders never come in locally, only on the website. Order status never gets generated on the website, only consumed, etc. If that is the case - this sounds like Transaction Replication to me. Merge is more for when you need to have multiple versions that can make changes and receive changes at the same time. The tired old Microsoft example still works - a bunch of sales folk all with a local app that does lead management and a big central server. They can get their leads when in the home office and get data, then they work disconnected and sync up their changes. With Merge you have to deal with conflicts (if the same data is modified in two places, who wins?) Transactional is more what is used when you have changes going in one direction (but you can have it go bidirectional here too even). And you can set replication up to have various tables included or not included in the publication as articles. A couple links to give you a bit more info: Transactional Replication Overview Merge Replication Overview Now if you have data that can be updated on each and needs to be "merged" then merge may be a better answer. When I work with replication - I prefer to stay as close to Transactional as I can, though. It is easier to administer and there is no conflict resolution worries if you don't need it. Depending on your volume - if it is low enough - and your latency - if some lag time is acceptable - you might also consider something more programatic or ETL like. Perhaps staging data and sending it over in batches. Sending messages across as data changes in one side, etc. 

it does the filtering and joining at the linked server. This avoids you having to bring data back to just filter it out, etc with the four part query aproach. The problem, though, is that update is trying to run on the destination. It's basically a pass-through query, so you are trying to pass that update through. So you'll need to do the update locally, but can join to the open query to join to the data on the other side. For more you can see the syntax guide here with some notes. 

You have a few options. There are third party tools that can help simulate a load against your database. There are open simple utilities like SQL Query Stress which can run whatever queries you supply it in whatever frequency you wish. There is also the combination of running server side traces and replaying those traces. This can be as simple as gathering scripts from a trace (as Dan rightly pointed out above don't use the Profiler GUI to capture events, but capture the trace to a file using server side trace) and then replaying the workload if you more care about individual query performance if you care more about individual query performance and less about concurrency. If you need to dig into concurrency and see the workload in real time from multiple angles - you would want to look at using the Distributed Replay features. This allows you to point to a trace in any version of SQL Server back to SQL Server 2005 and run it against any version of SQL Server, also back to SQL Server 2005. Jonathan Kehayias has a step by step walk through of how to setup Distributed Replay. This would allow you to configure the replay from multiple clients distributing the load - a single profiler replay would never allow you to scale. (Please note - you'll see the tool is a SQL Server 2012 tool. Don't let that scare you, the tool came out then, but can deal with your SQL Server 2008 R2 environment) All this said - there is complexity to this either way. Taking a trace for replay has some requirements and steps. Replaying it also has some steps to take to make sure you are starting from the same starting point, etc. This complexity is worth understanding, it can help perform upgrade readiness tests, help understand hardware changes on total application, etc. You could use the RML utilities to analyze the before and after traces also which can help show you how things improved or didn't after. If you just want to see if rebuilding indexes made any changes, you can do simpler tests also. You could take a large repeatable insert and run only that before and after. You could take a few queries with high scans and a few with high seeks and run that before and after. I would make sure you still rebuild statistics either way, though, since rebuilding your indexes does rebuild the index level statistics and that sometimes gives more of a benefit than rebuilding indexes and people attribute the benefit to the index rebuilds rather than the index statistics that got rebuilt. I tend to fall into the "rebuild" camp more often than not, but hardware changes in IO performance, workload patterns, etc all make that not a hard and fast rule necessarily for me. 

Attach that MDF and LDF (note since you want to read the log file, you can't do an attach rebuild log - you need to attach both so see the note above). Attach them as a new Database, lest you overwrite the existing database entirely and then someone comes after you with a question that says "how do I find out who overwrote the production database while trying to find out who dropped a table" it could get messy then. Look to the link I shared above and start seeing what you can see in the log file. 

While shrinking is dangerous indeed for the reasons mentioned here. There is a happy medium between Jimbo's answer and John's answer... You should always seriously consider whether or not you want to shrink your database. In an ideal world - you'd create your DB with plenty of free space to grow into. I call this "Right Sizing" your database. You would allow this free space to be there and not strive to give it back and keep your total size right at your used size.. Why? Because your database will eventually grow again.. Then you'll shrink again.. And you'll be stuck in this horrible pattern of useless shrinks followed by growths - and the entire time, as a few have pointed out, you'll be increasing your index fragmentation. I've blogged about this where I admonished folks to "Don't touch that shrink button!" but sometimes... Sometimes you need to. If you have a large database, just freed significant space and don't expect to grow back into it ever - well then it is okay to consider shrinking as a one time operation as long as you can take care of your index fragmentation afterwards through rebuilding them. The shrink operation can be time consuming so you'd want to plan it for a time where you can pay that price of a shrink running. The approach of creating an empty DB and copying data into it works - but that can become very difficult with larger databases and a lot of data. If you plan on adding that space back to the DB through normal usage and growth patterns into the future, then you may just want to leave the space there. Also You said you "cleared" your transaction log. I'd be curious to know how you did this but as you read the post I shared and the others in the series you'll see some tips on transaction log management. But in short - if you are in Full Recovery mode you should be taking regular log backups to keep the log reusing itself. Otherwise - with no log backups while in Full Mode - the log file keeps growing and growing and growing and always saves what you've done because you told SQL you don't just want to maintain that log for crash recovery but want to keep a manual backup of it to replay transactions/undo transactions to recover to a specific point in time for recovery purposes... If you are in simple and seeing the log grow excessively, this can be a sign (typically) that you are doing a LOT of work in one transaction (whether you said or whether you just issued one big statement and deleted a whole mess of data in one implicit transaction.) I am also assuming that you are looking for this free space on your file system. If you are looking for it within SQL and within that large file you have - it could be that you are waiting on ghost cleanup to complete if looking immediately after your operation. Paul Randal blogs about Ghost Cleanup. 

No way to do this natively through the log shipping GUI or command line with logship.exe You can roll your own "poor man's log shipping" scenario. Basically all you are doing is backing up, copying, restoring with standby or norecovery and building some alerting. An older post but an example of what I mean. 

I just tried quickly to find an answer because there is a lot here, but this is a common question. Didn't find quite what I wanted yet so a few thoughts to guide you: First: It depends is the default answer here. It really depends on what the performance characteristics are of your system. You should review what your waits and filestats look like and consider where your pain points are and build according to that. There are sizing concerns and performance concerns. A few thoughts to guide you: 

Need some more information for the Linked Server error - asked a question in a comment for more info there and will clean this up based on your thoughts there. Though it appears as though you are experiencing issues with kerberos delegation on the face of it. (More info here) For the second question - it sounds like you are just asking how can that user connect directly to the SQL2005 instance without using a linked server. If I've understood correctly - you just grant their login access to the SQL Server 2005 server (either a SQL authenticated login or a domain login) and grant them the database and server access they need. Then they can use SQL Server Management Studio or whatever tool you use to connect and connect directly. 

No way to seed it. That whole "globally unique" part gets in the way. the bigger question here is "do you truly require this?" GUIDs are big, GUIDs -even with newsequentialid, can lead to index fragmentation. If you need GUIDa where do you need them? They typically do not make great clustered index candidates. For both of these reasons and more. 

The article isn't saying "if you want to use a Domain account, we suggest you use a local account" - but I totally see why anyone would read it that way. The article is saying, instead, "Use a domain account where you can. IF your computers are not in the same domain, here's a little trick you can use." That trick, sometimes referred to as pass through authentication has you create an account on each computer. Same name. Same password. By doing that - windows will pass the credentials through and, for all intents and purposes of this conversation, the apps (SQL and Replication objects) won't realize it isn't really a "domain account" - and it will just work. If, however, the computers are on the same domain? Just use the domain account. If you go back to that first link you commented with - you'll notice the "if your replication topology includes computers that are not in the same domain..." line isn't bulleted or indented. Really the bullet about the local to each should be indented off of that.