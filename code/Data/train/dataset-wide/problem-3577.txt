You can remove the log_write from the ACL once you know it is working. For this to work you need to ensure that you aren't using TURN or ETRN to receive mail back on the connection you used to send the message for spam filtering. If you want to try modifying your conditions you may want to look at the match_ip operator instead of in_list. To filter out messages routing within the same domain try a router condition like: 

Configuration for DKIM. doesn't seem to be on the standards track anymore. Replace with the key name you use in when signing. 

Read the canonical answer on avoiding having your email classified as Spam. Search for other answers on delivery issues. 

I didn't know Google allows you to split your name just anywhere. The following should allow the users to place any suffix they desire after their userid which is relatively commonly done. Gmail seems to allow a plus sign instead of a dot. 

You may want to solve this at the application level. You should be constructing a full path to the new location. This should consist of three components: the protocol (https), the hostname (from the request header) and the path (as required by the application). You may want a utility class that constructs links for the application to ensure consistency. For links you may want to use relative paths. These will be sent to the originating host using the protocol they arrived on. Redirecting the request resulting from the redirect, still leaves you with mixed content. This is because the initial redirect will be http rather than https. On the Apache server level, there is a module that will rewrite the paths in the response from http to https. This is one way to fix a broken links sent by an application. However, I would limit that to applications you don't have access to. 

Verify you can connect to the daemon process with the command which should return an RSYNC version. You can also test using rsync with the command which should return a list of public shares. Add your userid and password file to the command to get private shared. If, as it appear,s you are using ssh, use a private key. You can use and to load the key so you don't need to enter the password. Again don't use root unless you must. It would be better to give access to the file using a different group, and setup a userid with access to that group. You can test ssh access with ssh. If the file is always new when you want to copy it, then scp would be simpler than rsync. Try testing access without a copy option. Something like this should work: 

Amanda will use incremental backups as long as you have not disabled them and it will have a full backup within the specified backup cycle. Configure amanda to email you the backup reports. The statistics columns of the report indicate full and incremental backups. The Dump summary reports fill backups as 0 in the 'L' column. Incremental backups will have a value of 1 or more depending on which level of backup they are incremental from. You can configure amanda to always do full or incremental backups for a device. This is covered in the documentation. It is best to allow amanda to schedule incremental backups according to its planning. This will result in full backups being scheduled throughout the week, with incremental backups as needed on the other days. I have done a setup where full backups for offsite storage were run on the weekend. This was done with a second configuration configured to always do full backups and that did not record the backups. Not recording the backups allows the daily backups to schedule their incremental appropriately. It is worthwhile to read the documentation, especially on the strategy used to schedule full vs. incremental backups. 

Check the TLS/SSL chapter in the Exim Specification. If you have TLS enabled, it will be used on outgoing connections to servers which advertise . TLS will be required for hosts listed in the option. This should be set at the beginning of the Exim configuration file. 

Multiple DKIM records are a viable option. DKIM keys and records should be replaced periodically. During the update process the old record remains for a period of time to allow verification of in transit messages. This can also allow re-validating received messages. I don't see any value in using CNAME for DKIM records. It will only add additional DNS lookups before the required TXT record is read. DKIM records should be added each time the key changes. This requires new TXT records and might require new CNAME records as well. 

The techniques I use to identify spam have little to do with volume. They are bases more on how well the server complies with standards and best practices. 5,000 is a relatively small mailing list and shouldn't trigger spam classification. Getting your server correctly configured to use its FQDN and having PTR configured so you pass rDNS validation will get you most of the way there. The spam filter I use triggers on content and looks for indication that the message is similar to previously seen spam. Well formatted text not selling things in a spamish way is unlikely to be blocked by the filter. During some research into the incoming spam I posted an article on Running an Email Server. It is a bit of a rant at marketers who do everything they can to look like they are sending spam. It is mostly mailing lists (including major mailing organizations) and automated systems (including airlines, banks, and others) that tend to be poorly configured. My article on Detecting Email Forgery (which a lot of spam attempts) may also be helpful. EDIT: If everything else is configured correctly, you should be able to send batches of up to 100 using a single connection. Your mail server should handle the batching for you if you get ahead of it. 

Many automated systems don't bother to follow the RFCs and just send email out the Internet. As a result the look more like spammers than legitimate e-mailers. As a result they have problems getting their mail delivered, or get their mail classified as Spam. Either send the mail to your own mail server for delivery, or setup your server with an RFC compliant mail server. It may be easier to relay mail via your own mail server. Review my rules for Detecting Email Server Forgery. It starts out listing the characteristics of a legitimate server. Try to configure your setup to meet all of them. At the end of the document is a list of Verification Services as well as a list of Documentation Resources. 

You should be able to control this at the kernel level with . Setting the net.ipv4 and/or net.ipv6 forwarding values off. 

Normally, your Mail Transfer Agent will log the outgoing messages. Exim uses log files in . Log messages from other MTAs may end up in . This assumes you are using a local MTA to do the delivery for you. Running the command as root may show a bunch of messages pending delivery. These may include some from the bulk delivery. If the software does direct delivery, bypassing your MTA then you will need to see if the application has its own log file. 

Once you have this working you may want to look at the directive. This can be used to allow local access without a password, while requiring a password for Internet access. EDIT: I user an include file for BasicAuth to enable password basedd remote access to content which is normally not available from the Internet. You may not want the directive. This is my file: 

As other have noted, if your server exists in a shared services environment, then you may be sharing the IP address. Otherwise, your IP address provider may not have cleaned up their PTR database. The domain may have previously been hosted on your IP address. Verify the results from the authoritative DNS servers for the IP address. Some resolver configurations may result in reverse look values being returned from or other local databases. There are four requirements for a PTR record to be reliable for reverse DNS spoofing: 

From your question it appears you have a number of computers infected with botnet software. It is important you identify and cleanse these systems. That is beyond the scope of this question. If your routers support it, consider limiting the IP addresses which can originate requests. 

To some extent it is, as you can identify users. In the past you could also pick up their passwords. However, the one userid really worth cracking is which is well known without the password file. The utility of having the password file world readable generally far outweighs the risk. Even if it weren't world readable, a functioning command would render the security gain void. The ability for non-root users to identify files owned by others would disappear. Being able to identify owned (user in passwd file) and unowned files (user not in passwd file) can be useful in reviewing the contents of a file system. While it would be possible to resolve this with appropriate programs, that would add a huge attack vector via those programs. In the end it is a matter of balance, and in this case I would say the balance is firmly on having password world readable. 

It is common to see localhost (127.0.0.1) in the received headers. This indicates that a program running locally is re-injecting the message into the mail stream. Spam filters are often run this way, although it is better to filter spam at the Internet boundary and reject the message before it has been accepted. I often see headers with no incoming address, or a pair of received headers for the same host. Although there is a standard to be followed, it has some flexibility, and several email processing programs seem to invent or guess at the format. I think of a few reasons your name is replaced by 127.0.0.1 in the header. 

You can set up an outgoing server. MX is for incoming only, and does not require a PTR record. However, you may want to consider setting up as a satellite and sending all mail through the central server. This can be done with SMTP auth over TLS if you need to traverse the Enternet. If you do decide to send email directly. These are the basic things you need to do for an outgoing server (example.com).