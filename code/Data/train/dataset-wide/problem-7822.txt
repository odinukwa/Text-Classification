Say $G$ is a reductive group over a field $k$. I usually take $k = \mathbb{C}$ so assume what you want about the field except maybe that its finite. If $X$ is a scheme over $k$ then a principal $G$ bundles over $X$ is a scheme $P$ together with a right action of $G$ and an equivariant projection to $X$ (with trivial action on $X$) such that $P$ is locally trivial in the etale topology. For some groups like $GL_n,SL_n$ and solvable groups principal bundles are locally trivial even in the Zariski topology. These are called special groups and Grothendieck classified them. I'm curious if $G',G''$ are special groups and $G$ fits into an exact sequence $1 \to G' \to G \to G'' \to 1$, then is it the case that $G$ is special? There is a paper by Serre that claims this at least for $G',G''$ commutative and its supposed to be a consequence of the exact sequence $\check H^1(X,G') \to \check H^1(X,G) \to \check H^1(X,G'')$. This is \check Cech cohomology in the etale topology. You have $\check H^1(X,G') \cong \check H^1(X_{zar}, G')$ and $\check H^1(X,G'') \cong \check H^1(X_{zar}, G'')$ and a map $\check H^1(X_{zar},G') \to \check H^1(X, G)$ but it seems you are still short of being able to use e.g. the 5-lemma. This can probably be deduced from Grothendieck's thm but I'm wondering if there is a direct argument. 

Weyl Character formula and multiplicity formula for the weight spaces in a irreducible representation. 

Strassen's factoring algorithm shows that $\text{FACTORING} \in \text{DTIME}(N^{\frac{1}{4}+o(1)})$, but if I'm not mistaken in my analysis it also uses a similar amount of space. By making a trade-off I think it is possible to show $\text{FACTORING} \in \text{DTISP}(N^{k+o(1)}, N^{\frac{1}{2}-k+o(1)})$ for $\frac{1}{4} \leq k \leq \frac{1}{2}$. On the other hand, trial division up to $\sqrt{N}$ demonstrates $\text{FACTORING} \in \text{DTISP}(N^{\frac{1}{2}+o(1)}, \log(N)^{O(1)})$. The only extra space we need is to keep a counter and perform the divisibility test. Is there any deterministic factoring algorithm known to be in $\text{DTISP}(N^{k + o(1)}, N^{o(1)})$ for $k \lt \frac{1}{2}$? I know that there is an $N^{\frac{1}{3}+o(1)}$-time algorithm due to Michael Rubinstein but I can't tell what the space usage would be. This would qualify as an example if the space can be made subexponential. Otherwise, is trial division the best we can do in $N^{o(1)}$ space? We won't be able to prove $\text{FACTORING} \notin \text{DTISP}(\log(N)^{O(1)}, O(\log(N))) = \text{L}$, since that would imply $\text{NP} \neq \text{L}$, an open problem. 

That there are such expressions is not surprising to me, but I am intrigued by the fact that they are so short, and particularly that the last two (the shortest) have very large first counterexamples. So I was thinking why not look at all short rulesets and see how they can be categorized. For example, I'd like to know the shortest ruleset with possibly undecidable convergence. I'd also like to be able to characterize some of the decidable ones. Is there a short ruleset whose convergence is undecidable in PA? I know we can state Goodstein's theorem with a new base-bumping symbol but I wonder if that's necessary. Similarly, is there a short ruleset whose convergence is equivalent to the existence of infinitely many Mersenne primes? I found the Riesel number example while trying to construct one â€” it seems like a new symbol for exponentiation is needed for this. In both cases I understand Conway's construction gives a ruleset whose convergence is equivalent, but it won't be a very short one. Can we build a small ruleset whose convergence is equivalent to some complexity class separation or equivalence like $\text{P} = \text{NP}$? Otherwise is there any simple extension of the language that can express this? I don't see any obstruction since these are usually $\Pi_2$ sentences like twin primes. And aside from whether all numbers converge, is there a short ruleset whose convergence from any starting point corresponds to some non-trivial property of that starting point? In this context "trivial" means something like "is an odd composite" as in the third example. One general fact I deduced is this: the question of whether there exists a path from $x$ to $y$ with length less than some fixed $\ell$ is in $\text{NP}$ (because factoring is also in $\text{NP}$ and we can produce a $(\log(x) + \log(y))^{O(1)}$-bit certificate showing how the numbers in the path match the rules). And in the other direction we can arithmetize a $\text{SAT}$ instance into a single rule, so deciding if $2 \rightarrow 1$ is an $\text{NP}$-hard problem on rulesets. The former property of constant paths being in $\text{NP}$, however useful it may or may not be in explaining the overall situation, is preserved by certain extensions (for example if we introduce variables taking square-free values, or variables with implicit order constraints) but is not preserved by others (such as a $2^x$ operator which would permit short paths with small endpoints and large intermediate values). A compact way of representing a ruleset that I'm considering is this, using the twin primes example: . Here I'm making addition implicit in concatenation and using as a symbol for $-1$. This keeps the alphabet small, although I don't think I'll have enough computer power to consider every well-formed string up to this length. But there are lots of symmetries, redundancies, and easy proofs, so it is possible to reduce the space significantly. If I write a program to analyze all short rulesets, what should I make it look for to help me get some insight into these issues? 

I don't know much about the theory of Hilbert spaces but a research project has me working with them a little bit. In particular requiring an operator to be Hilbert-Schmidt is a recurring condition. According to wikipedia one nice thing about H-S operators is that on a separable Hilbert space $H$ the set of H-S endomorphisms forms a Hilbert space that is naturally isomorphic to $H\otimes H^*$. So I'm wondering what else is nice about H-S operators. And what else works with H-S operators that wouldn't work for another class of operators. Fredholm operators also come up a lot. It $T$ is H-S and $S$ is Fredholm what can be said about the composition? 

This question is largely out of curiosity but also motivated by an attempt to understand vector bundles on elliptic curves better. I believe it is a theorem of Grauert that any holomorphic vector bundle on a non compact Riemann surface is trivial. In fact I think it holds with vector bundle replaced with principal $G$ bundle with $G$ any complex connected group. In particular line bundles on affine algebraic curves should be holomorphically trivial. The ideal $m = (x,y) \subset \mathbb{C}[x,y]/(y^2 - x^3 + x)$ determines a rank 1 locally free sheaf and hence a line bundle $L$. Any algebraic section of $L$ must vanish somewhere but there should be non vanishing holomorphic sections. Can one write down such a section? Presumably it may be hard to do so in terms of the algebraic coordinates $x,y$ but the curve is biholomophic to $\mathbb{C}/\mathbb{Z}^2 - \mathbb{Z}^2$ with the isomorphism given by the Weierstrass function and it's derivative and I would be happy with a section defined on $\mathbb{C}/\mathbb{Z}^2 - \mathbb{Z}^2$. 

The Collatz conjecture can be expressed in terms of a ruleset in the language $\{x,+,1,\rightarrow,;\}$: 

Yes. There is a finite board size that has essentially the same solution structure as all larger boards and an infinite board, and we can find it by solving the game completely for increasing board sizes until that ultimate size can be recognized. (The infinite board is different from a very large board only in that it has no edges or corners, so its solution structure is smaller.) Eventually this is possible, because there are only a finite number of pieces, and therefore only a finite number of equivalence classes of solution structures. When the number of such equivalence classes stops growing, we are done. Basically, all positions with pieces not close to the edge of the board but far from the center (say those with pieces inside an annulus) can be identified with more bounded positions (those surrounded by that annulus), because the pieces with an infinite number of options (Queen, Rook, Bishop) can go anywhere (up to parity) with no more than 2 moves, and the other pieces are forced to walk long distances for which all that matters are their relative path lengths to a certain precision. When one set of pieces moves far enough away from another set of pieces that the two sets are now in general position, these sub-problems interact in an equivalent way, so the description of the complete solution will eventually stop increasing with board size. More generally this strategy works for any chess-like game in which the pieces can be classified into "ultra-mobile" and "para-mobile" types with constant and linear freedom respectively. For example it is also true for checkers because all pieces are para-mobile. I am still unable to specify the equivalence between positions precisely enough to set an explicit bound on the necessary size of the finite board in terms of the number of pieces n, but I guess that it is O(f(n!)) for some polynomial function f whose order is O(n), or in other words O((n!)^(k*n)) for some k, using the construction technique that I have suggested. The super-exponential term is contributed by the para-mobile pieces and the polynomial by the ultra-mobiles. In any case I have intended only to demonstrate that the necessary board size has a computable bound. 

If $X \xrightarrow{f} Y$ is a morphism of schemes then the scheme theoretic image of $f$ is the smallest closed subscheme $Z \subset Y$ through which $f$ factors through. Is this notion defined for algebraic stacks (at least under reasonable assumptions)? If so, can someone provide a reference? 

For $k$ alg. closed you can phrase the statement as $\Omega_{A/k}$ is loc. free iff Spec$(A)$ is smooth. 'Spec$(A)$ smooth iff $\Omega_{A/k}$ is loc free' should be true without requiring $k = \bar{k}$. But if $k \ne \bar{k}$ then the condition on the derivatives is not the same as smoothness. For example if $C$ is a curve defined over $\mathbb{R}$ with smooth $\mathbb{R}$ points but with singular $\mathbb{C}$ points then the condition on $f$ and its derivatives will be satisfied but there will be a maximal ideal of Spec$(A)$ with residue field $\mathbb{C}$ where $\Omega_{A/k}$ will have the wrong rank. You can try this with $y^2 = (x^2+1)^2$ and the maximal ideal $(y, x^2 + 1)$ in $\mathbb{R}[x,y]$. But if $A(k) = A(\bar{k})$ then the original statement should hold over $k$. 

Say $L\mathbb{C}^\times$ is the loop group of smooth maps $S^1 \to \mathbb{C}^\times$. There is a submonoid $L_{poly}\mathbb{C}^\times$ of loops that look like $w_0 + w_1z +w_2z^2 + \cdots + w_nz^n$ where $z = e^{i\theta}$ (as Andrew notes below this is not a group because its not closed under taking inverses). Equivalently $L_{poly}\mathbb{C}^\times$ as a set is just polynomials $p(z) \in \mathbb{C}[z]$ such that $p(z) \ne 0$ for $|z| = 1$. If we mod out by scaling and rotation then the set of polynomial loops describe a subset $X$ of $\mathbb{P}(\oplus_{n \in \mathbb{N}} \mathbb{C})$ (by identifying a loop with its vector of coefficients). I want to look at $X$ from an algebro-geometric point of view, but I have no intuition about how bad or nice $X$ may be; i.e. can it be a variety? The way I've been thinking about it is that $X = \cup_{n \in \mathbb{N}} X_n$ where $X_n \subset \mathbb{P}^n$ are the loops of degree at most $n$. I think $X_1$ is the image under the projection $\mathbb{C}^2 - 0 \to \mathbb{P}^1$ of the set {$(w_0,w_1):|w_0|\ne |w_1|$}. So it seems describable as the complement of a hypersurface in $\mathbb{R}^4$ but probably its not a complex variety. But already trying to figure out what $X_2$ is seems difficult. Also I feel I don't have any `sophisticated' way of thinking about this stuff meaning my attempts to describe $X_2$ seems to always degenerate to just fumbling around with planar geometry. Some specific questions regarding this setup: 0) What is the dimension of $X_n$? 1) Which if any of the $X_n$ or $X$ are a variety over $\mathbb{C}$ or $\mathbb{R}$? 2) If $X$ or $X_n$ are not varieties can you find any positive dimensional varieties contained in them? 3) Can you suggest any tools that might be useful for answering any of the previous questions? Of course if any of this seems to easy you are welcome to replace $\mathbb{C}^\times$ with $GL(n,\mathbb{C})$, polynomials with rational functions or with power series convergent in an annulus containing $|z| = 1$. An extra thought: So $L_{poly}\mathbb{C}^\times$ is not a group, but it seems you do get a group if you look at convergent series in non positive powers of $z$; i.e. loops that look like $\sum_{j \in \mathbb{N}} c_j z^{-j}$. I wonder if there's anything interesting you can say about the $c_j$. 

How about practical numbers? They aren't a superset of primes, but they are a "notion of 'almost primes'" as the title requests. Hausman and Shapiro showed in 1984 that practical number gaps satisfy $\frak{g}$$_n < 2 \cdot \frak{p}$$_n^\frac{1}{2} + 1$. On the other hand, for primes, the best known bound is the Baker-Harman-Pintz or BHP bound published in 2000: $g_n \in p_n^{0.525} + O(1)$. Conditional on the Riemann hypothesis we have $g_n \in p_n^{\frac{1}{2}+o(1)}$, but not $g_n \in O(p_n^\frac{1}{2})$. 

P(A) = It is White's move and White has not yet won in position A. R(A, B) = Position B legally follows in one move from position A. Q(A, 0) = P(A) Q(A, t) = for all B: (R(A, B) -> there exists C: R(B, C) -> Q(C, t - 1)) S(A) = Q(A, 0) and (for all t: Q(A, t) -> Q(A, t + 1)) 

It is an open problem whether or not every polynomial time algorithm can be made $O(\log(n))$-space. Note that every $O(\log(n))$-space algorithm is simultaneously polynomial time because it has $2^{O(\log(n))} = n^{O(1)}$ states. This problem is usually referred to as $\text{P} = \text{L}$. Amazingly, $\text{NP} = \text{L}$ is also open! If we want to talk about particular algorithms and polynomial exponents, we'll also want to get specific about the model of computation. For example, consider the class of models of computation related to a Turing machine by time translations satisfying $T_b \in T_a \cdot S_a^{O(1)}$ and space translations satisfying $S_b \in O(S_a)$. This includes single-tape and multi-tape Turing machines and variations of $\text{RAM}$. We can't say much, since an algorithm with $T_a = S_a$ in one model can have $T_b = S_b^{O(1)}$ in the other, that is, by changing the model an algorithm can be made arbitrarily more space-efficient relative to the time it takes. I posed a related problem recently over on cstheory.SE. 

Not much is known about vector bundles on $\mathbb{P}^2$ but I wonder if the following is a tractable question: If $E,E'$ are non-isomorphic vector bundles on $\mathbb{P}^2$, then is there always a smooth curve $C \subset \mathbb{P}^2$ such that $E|_C$ and $E'|_C$ are still non isomorphic? A related and perhaps easier question: Can a vector bundle restrict to the trivial bundles on every curve without itself being trivial on $\mathbb{P}^2$? 

I've learned when you have a integral smooth scheme line bundles are the same as Cartier divisors are the same as Weil divisors. My question is to what extent does this continue to hold (if at all) when you are talking about ind objects. Since things become more subtle in positive characteristic lets say we are working over an algebraically closed field of characteristic 0. Background I think the situation can be quite different because smoothness, or algebraic smoothness is more complicated. In the non ind scheme case you can define smoothness of a point $p \in X$ as $S^q(m/m^2) \to m^q/m^{q+1}$ being an isomorphism for all $q\ge 0$, where $m$ is the maximal ideal of the local ring at $p$. In the ind case you have varieties $(X_n)_{n \ge 0}$ and $p \in X_n$ for all sufficiently large $n$ so you have $S_n^q(m_n/m_n^2) \to m^q_n/m^{q+1}_n$ for all sufficiently large $n$. Algebraic smoothness at $p$ means that the map $\varprojlim S_n^q(m_n/m_n^2) \to \varprojlim m^q_n/m^{q+1}_n$ is an isomorphism for all $q\ge 0$ Thoughts It is true that if $X$ is the union of $X_n$ and each $X_n$ is smooth then $X$ is algebraically smooth. However algebraic smoothness is not inductive in the sense that there are examples of $p \in X$ being algebraically smooth even when $p \in X_n$ is a singular point for all $X_n$ containing $p$. However line bundles are inductive in the sense that a line bundles on $X$ determines line bundles on each $X_n$ compatible under pull back and vice versa. This suggests to me that you could have a collection of compatible Weil divisors in each $X_n$ which are not the zero section of any section of any line bundle. But I don't have an example. 

I'll write $\longrightarrow$ for some standard iterations and $\implies$ for some possibly non-standard iterations. The relaxed Collatz conjecture is that for all $x$, $x \implies 1$. I'll call counterexamples to the conjecture escapees. First of all, since it's a good example of the notation, a lemma: for all $a$, $4 a \implies 9 a + 1$. Proof: $4a \implies 12 a + 1 \longrightarrow 36a + 4 \longrightarrow 18a + 2 \longrightarrow 9 a + 1$. $\square$ Now here is what I will try to show: Theorem: If $x$ is the smallest escapee, then $4x \implies 1$. Proof: By elementary considerations, $x \equiv 3 \pmod{4}$. If $x \equiv 2 \pmod{3}$, then $\frac{2 x - 1}{3} \longrightarrow 2 x \longrightarrow x$. So in this case, $2 x$ can't be an escapee, and neither can $4 x$. The next case is $x \equiv 0 \pmod{3}$. Write $x = 12k+3$. Using the lemma, $4x \implies 27k+7$. Observe that $x > 9k+2 \rightarrow 27k+7$ if $k$ is odd. Now if $x \equiv 15 \pmod{24}$, we also have that $4x \implies 1$. It's also possible that $x \equiv 3 \pmod{24}$. In that case, we have $x = 24 j + 3$ and $x \longrightarrow 27j+4$. This means $j$ cannot be even. So we drill down again, with $x = 48i + 27 \longrightarrow 81i+49$. This means $i$ cannot be odd. But also, $4x = 4(48i+27) \implies 81i + 92$, so if $i$ is even, the next step brings us under $x$. This covers all the $x \equiv 0 \pmod{3}$ cases. So far, our result is that if $x \implies 4x$, then $x \equiv 7 \pmod{12}$. Now I'll handle that case. Suppose $x \implies 4x$ and $x = 24k + 7$. Then we have: $4x = 4(24k+7) \implies 9(24k+7)+1 = 216k+64 \longrightarrow 108k+32 \longrightarrow 54k+16$. But also, $18k+5 \longrightarrow 54k+16$. This means $18k+5$ is an escapee too, but it can't be, since it's less than $x$. So the hypothesis is false and we have $x = 24k + 19$ instead. Now, consider: $4x = 4(24k+19) \implies 216k + 172 \longrightarrow 108k + 86 \longrightarrow 54k + 43 \longrightarrow 162k + 130 \longrightarrow 81k+65$. By similar reasoning, $k \neq 3 \pmod{4}$, or else we can continue the chain two more steps to get an escapee less than $x$. Finally, $x = 24k+19 \longrightarrow 72k+58 \longrightarrow 36k + 29 \longrightarrow 108k + 88 \longrightarrow 54k + 44 \longrightarrow 27k + 22$. shows that $k$ can't be even, and substituting $k = 4 j + 1$: $27k + 22 = 108j + 49 \longrightarrow 324j + 148 \longrightarrow 162j + 74 \longrightarrow 81j + 37 < x$ completes the proof, since that's all the cases. $\square$ Corollary: if the Collatz conjecture is false and the smallest counterexample leads back to itself then that number is not a counterexample to the relaxed Collatz conjecture. In other words, if $y$ is the smallest number satisfying $\neg(y \longrightarrow 1)$, then $y \longrightarrow y$ implies $y \implies 1$. This is a weaker version of what I originally thought I had proved. Corollary: If $4x$ is an escapee, then there is an escapee smaller than $x$. This suggests to me a recursive descent strategy where we attempt to show $z \implies 4k < 4x$. But it's not clear if number-crunching will get us anywhere further.