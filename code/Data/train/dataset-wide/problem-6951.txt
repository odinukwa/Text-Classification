I was carefully rereading the underlying paper (Bloch, 1996) and found what I was looking for. Let $N = \{1,\ldots,n\}$ denote the set of agents and let $\Pi_{\{1, \ldots, i-1\}}$ denote the set of coalition structures of $\{1, \ldots, i-1\}$ for all $i \in \{2,\ldots,n\}$. A strategy in the game of coalition size is a mapping $s_i : \Pi_{\{1, \ldots, i-1\}} \to \{1, \ldots, n-(i-1)\}$ for all $i \in \{2,\ldots,n\}$. Further $s_1 \in N$. Example with $n=4$. With some abuse of notation (saving curly brackets) we get \begin{align} &s_1 \in \{1,2,3,4\}\\ &s_2:\{1\} \to \{1,2,3\}\\ &s_3:\{\{1,2\},\{12\}\} \to \{1,2\}\\ &s_4:\{\{1,2,3\},\{12,3\},\{1,23\},\{123\}\} \to \{1\} \end{align} 

That's a coincidence, because they assume nondepreciating capital. If $\delta>0$ was positive we'd have \begin{align} \dot K = Y - C - \delta K \end{align} which gives \begin{align} \dot K = 0 \quad \Rightarrow\quad C = Y - \delta K. \end{align} But the static optimization would still read \begin{align} &U(C(t)):=\max_{c(t-n,n)}\int^\infty_0 u(c(t-n,n))dn \\ &s.t.\quad \int^\infty_0 u(c(t-n,n))dn \leq C(t) \end{align} Actually they define an indirect utility function with subject to a resource constraint. In every period (thus static) the sum of individual consumption cannot exceed aggregate consumption. 

This statment is particular useful, because I have a problem in mind where I cannot say anything about (quasi)concavity of the objective function. I'm, however, not sure if I can apply Theorem 1, because the author does not specify when quasiconcavity is imposed for a result. How would I know wether the theorem is applicable? Note that I cannot(!) derive a best response function $x_i^* = \phi_i(\mathbf x_{-i}^*)$, but only the symmetric equilibrium actions $x_j = x^* ~ \forall j$. 

The (partial) derivative of a continuous function is defined as \begin{align} \frac{\partial F(\overline K, L)}{\partial L} := \lim_{\Delta L \to 0}\frac{F(\overline K, L + \Delta L) - F(\overline K, L)}{\Delta L}. \end{align} Now if $L \in \mathbb{N}$, then you have a lower bound for the increment $\mathbb{N} \ni \Delta L \geq 1$. Otherwise the definition above is not well defined for $\Delta L = 0$. Such that we finally arrive at the approximation \begin{align} \frac{\partial F(\overline K, L)}{\partial L} \approx \frac{F(\overline K, L + 1) - F(\overline K, L)}{1}. \end{align} 

Let $q(p) = \frac{1}{p}$ denote the demand function and $p^*$ some equilibrium price. Consumer surplus is defined as \begin{align} CS = \int_{p^*}^\infty\frac{1}{p} dp= \ln(\infty) - \ln(p^*) = \infty \end{align} which is quite unsatisfactory. What's the convention here? Edit: Since I wanna compare welfare under price and quantity competition I found a workaround. Let $n$ the number of firms in the market, $\bar \pi^j$, equilibrium profits of the firm, $\bar p^j$ equilibrium prices and $j \in \{b,c\}$ is the index for the compeition type. Now we may calculate the welfare difference as \begin{align} \Delta W := W^c - W^b &= n(\bar \pi^c - \bar \pi^b) + \int_{\bar p^c}^\infty\frac{1}{p}dp - \int_{\bar p^b}^\infty\frac{1}{p}dp\\ & = n(\bar \pi^c - \bar \pi^b) + \ln(\bar p^b) - \ln(\bar p^c) \end{align} Suppose we get the following relationship \begin{align} \Delta W = \frac{(n-1)(\sigma-1)^2}{\sigma n^2(\sigma(n-1)+1)} + \ln\left(\frac{\sigma(n-1)+1}{n \sigma}\right) \end{align} with $n \geq 2$ and $\sigma \in [0,\infty)$ is a parameter. Clearly $\Delta W = 0$ for $\sigma = 1$ and for all $n$. I wanna further show that $\Delta W > 0$ for $\sigma < 1$ and $\Delta W < 0$ for $\sigma > 1$. Any ideas how to proceed? 

So the deterministic and stochastic value function must be the same. The policy function is then readily given by (use FOC and derivative of value function) \begin{align} \pi(k) = \left(1-\frac{1}{\gamma}\right)k^\alpha. \end{align} Note that this function does not depend on $\sigma$ either. Numerical Approximation I solved the HJB-e by an upwind scheme. Error tolerance $\epsilon=1e-10$. In the figure below I plot the policy function for varying $\sigma$. For $\sigma\to 0$ I arrive at the true solution (purple). But for $\sigma>0$ the approximated policy function deviates from the true one. Which should not be the case, since $\pi(k)$ does not depend on $\sigma$, right? 

Boundary Value Problem As I mentioned above we can easily solve the system by applying Matlab's boundary value problem solver . Using $\tilde c = c(T)$ as a terminal condition we have two ODEs and two boundary conditions. 

Since Ben's notes were already mentioned I'm not quite sure why you don't iterate over time using a forward approximation as he suggests \begin{align} \dot k(t) :\approx \frac{k(t+1) - k(t)}{\Delta t} \Leftrightarrow k(t+1) \approx \Delta t \dot k(t) + k(t) \end{align} which gives \begin{align} k(1) \approx \Delta t (z-c(0)) + k(0) \end{align} 

Hamiltonian \begin{align} H(y(t),u(t),\lambda(t)) = y(t)+u(t)^2 + \lambda(t) u(t) \end{align} First order conditions read \begin{align} &H_u = 0 \quad \Longleftrightarrow \quad u(t) = -\frac{\lambda(t)}{2}\\[2mm] &\frac{d\lambda(t)}{dt} = -H_y = -1\\[2mm] &\lambda(1) = 0 \end{align} Integrate costate \begin{align} &\int \frac{d\lambda(t)}{dt} = \int -1\\[2mm] &\int d\lambda(t) = \int -dt\\[2mm] &\lambda(t) = -t + C \end{align} with \begin{align} &\lambda(1) = -1 + C = 0 \quad \Longleftrightarrow \quad C = 1\\[2mm] \Longrightarrow \quad & \lambda(t) = 1-t\\[2mm] \Longrightarrow \quad & u(t) = \frac{t-1}{2} \end{align} Now integrate state equation \begin{align} &\int \frac{dy(t)}{dt} = \int \frac{t-1}{2}\\[2mm] &\int dy(t) = \int \frac{t-1}{2}dt\\[2mm] &y(t) = \frac{t}{2}\left(\frac{t}{2}-1\right) + C \end{align} with \begin{align} &y(0) = C = 5\\ \Longrightarrow \quad & y(t) = \frac{t}{2}\left(\frac{t}{2}-1\right) + 5 \end{align} If I'm not mistaken necessary conditions are sufficient if maximized Hamiltonian is concave in state (Arrow sufficiency if I recall correctly (see e.g. Caputo, 2005, Ch. 3)) \begin{align} H^*(y,\lambda) = \max_u H(y,u,\lambda) = y - \frac{\lambda^2}{2}. \end{align} Now we have \begin{align} H_y > 0 = H_{yy} \end{align} such that concavity is given. 

Consider the following differential equation \begin{align} \dot x(t)=f(x(t),u(t)) \end{align} where $x$ is the state and $u$ the control variable. The solution is given by \begin{align} x(t)=x_0 + \int^t_0f(x(s),u(s))ds. \end{align} where $x_0:=x(0)$ is the given inital state. Now consider the following programm \begin{align} &V(x_0) := \max_u \int^\infty_0 e^{-\rho t}F(x(t),u(t))dt\\ s.t.~&\dot x(t)=f(x(t),u(t))\\ &x(0) = x_0 \end{align} where $\rho > 0$ denotes time preference, $V(\cdot)$ is the value and $F(\cdot)$ an objective function. A classical economic application is the Ramsey-Cass-Koopmans model of optimal growth. The Hamilton-Jacobi-Bellman equation is given by \begin{align} \rho V(x)=\max_u [F(x,u) + V'(x)f(x,u)],\quad \forall t\in[0,\infty). \end{align} Say I've solved the HJB for $V$. The optimal control is then given by \begin{align} u^*=\arg\max_u [F(x,u) + V'(x)f(x,u)]. \end{align} I'll get optimal trajectories for the state and control $\{(x^*(t),u^*(t)):t\in[0,\infty)\}$. The wiki article says