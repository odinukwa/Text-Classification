which goes right up the logical/relational alley but doesn't hit the physicalist side as hard. He does ultimately link what he's saying back to panpsychism, amongst other things, but his approach seems a little less analytical than what you might be looking for. Would love to see if anyone here can dig up anything more current/directly related to the problem of mind-body physicalism and empiricism. 

It might help to think of it like this: A: I am a qualified chef B: I have great knife skills I pick this example because it's absolutely impossible to be a decent chef, much less a qualified one, if you can't properly use a knife. You'll chop ingredients too slowly, cut yourself (or others) and not know when your knife is dull. I don't like your example because cooking well & being a qualified chef are less distinct from each other than knife skills and how good a chef one is. Lets say , as you did. In the absence of , it still may be true that . It's not hard to imagine an assassin or samurai who is an awful chef yet still has amazing knife skills (i.e. ). We also know that (there's a technical name for this that escapes me). In my case, where I exhibit both (i.e. I'm both awful with knives and a poor chef) it is still true that - it's just that in this case the operator is picking out instead of either one being a possible option. Since is still true, the material conditional itself is also true because of this equality. Hopefully this clears things up for you. 

I have heard that theoretically you can classify all things you can possibly talk/write about into 3 categories i.e. be, do and have. People and things can be something, do something and have something, but that is it. (Beliefs, experiences and intentions fall under the Have category; we have beliefs, experiences and intentions.) What is the significance of this? Is it true (is it possible to categorize all sentences into these 3 categories with nothing left over)? 

If the question was not only about whether materialism and physicalism are the same I want to add a comment about what you said about gravity and electromagnetic forces. Natural forces can seem non physical at first glance and I hear many people talk about them as being the invisible laws that govern the universe. But a less magical way to view it is to see that all natural laws or forces are just functions of matter. If you take away the matter the force disappear as well. Gravity and electromagnetic forces does not exist by themselves as non-physical entities, they are just a way to talk about material change as apposed to mater frozen in time (like your cup of tea). 

In addition to fallibilism, which skepticism and anti-realism both provide stances on "facts" and what we can be certain of. Both of these traditions have a rich history and are worth looking into. While these positions are certainly worthy of debate, it's not particularly philosophical to say "Well since I'm a skeptic/anti-realist there's no point in having discussions about anything because no one can ever know for certain". It's also important to distinguish the concept of "truth" from "fact": if you're committed to logic (which is a main tool of philosophy), you must accept distinction between and , even if you believe that we can never know which category a statement belongs to. To say "it is true that there are no truths" is a contradiction in terms - to say "it is true that there are no known facts" is another matter entirely. 

In my mind: The main difference between philosophy and science is that science is not allowed to tell you how to coordinate desires, i.e. what to do with your own and other people's lives. The main similarity between philosophy and science is that they both try to find out about reality, so good philosophers certainly use scientists or their tool e.g. verifying and falsifying claims in physical reality, trying to be coherent, adding up probabilities, etc. But I do recognize that most universities for various reasons have got stuck in the analytical school which seem to separate science and philosophy somewhere between fact and definition. Leaving life's most important questions of how we should live our lives to be taken over by religion, astrology, and self-help gurus. 

Exactly how bad is attribute A? Is it the case that these people are petty theives, serial rapists, or merely snobby or judgmental? We all agree that qualities like these are bad, but in different levels: while I might complain but ultimately cave to my friend's request to attend a dinner with a bunch of people who are snobby and judgmental, I surely would not cave to a request to go to dinner with a group of serial rapists. There ought to be some notion of how bad A actually is for society (i.e. its consequences) in order for Utilitarianism to effectively solve this problem. Assuming A has highly negative consequences for other people, then we're left at a crossroads. Say we're looking at a group of people who are awful and dangerous drivers - something that is decidedly worse than snobbishness. Lets say that in the source country, thousands of people die each year because of poor driving combined with no safety features in automobiles and poor policing that allows bad drivers to continue running people over. Utilitarianism would say that if we took these people out of this environment, let them harm a few people in our country, which is more well-policed and safety-oriented, and then locked them up for being bad drivers, we'd actually be doing the world a favor. This seems to clash with our intuition about what the "right" thing to do is: many would say that we have no obligation to import these people if many of them will kill our own citizens with automobiles upon coming here. Assuming A has few negative consequences (snobby people don't kill people) then, if coming to the host country will benefit them greatly (say they were starving in their home country), we ought to suck it up and import them. Our discomfort about them being snobby is surely less than what they stand to benefit from coming here. This seems more reasonable than the above but might still rub us the wrong way - are you obligated to help a materially poor yet incredibly rude and obnoxious person? A lot of people would say that you're justified in walking away from a visibly intoxicated homeless person that shouts slurs at you despite the fact that your discomfort about his bad breath and lack of social etiquette is much less uncomfortable than his alcoholism and lack of reliable food and shelter. 

Because we have much more evidence of the impact of old ideas than we do of the impact (or potential impact) of new ideas. Therefore it's much harder to know the relevance of new ideas and much harder to find any consensus of what will turn out to be important in the future. It is easy to deny an idea's relevance based on the lack of evidence and so many will deny it until it is impossible to do so. Maybe for good reasons, but maybe because of my second explanation for why present philosophers don't appear to be as important as those of the past. People seem much more comfortable giving away credit to dead people than people who are alive. (I don't want to go into the potential psychological reasons for this but there could be plenty of alternative explanations for this phenomenon.) 

I'll give the Utilitarian response, out of my own interest. I'm tempted to say it won't end with a lot of great conclusions but lets see where it goes! Lets assume that P is much higher than in the host country, just for the sake of the argument. If we want a host country (and source country, for that matter) with the greatest net happiness, there are several questions that ought to be answered: 

All I can conclude here is that Utilitarianism does a "just ok" job of solving this problem. Basically, the conclusion is that from this perspective, we can't just concern ourselves with how our host country will fare - we must also consider how our actions affect those in the source country as well. In some cases, it may be that despite A being very prevalent and very bad, we're actually helping the world by importing them to a society that will hold them responsible for their evil actions. It's possible that another ethical framework provides a more satisfactory answer (I'd expect deontologists to have an interesting response). I'm not sure if this is the example you were looking for, but it does provide an ethics-based reasoning as to what the best thing to do is. Part of my problem with this question is in handling all the variables - maybe my treatment of some of the variables leads me to this conclusion. Maybe we ought to consider what percent of the migrants would make of the host country upon moving as well? 

I use Humes idea about the 'is..ought to gap' (or my spin on it) mainly to make sure I have good reasons for what I do -and what I advise others to do- and to make sure actions are not based purely on cultural pressures or recklessly induced policies. I don't use it much to judge whether the actions are morally right or wrong but whether we rationally have good reasons for doing or not doing something based on our present knowledge and feelings. Since the introduction of neuroscience I have seen many attempts to bridge the 'is..ought to gap' with facts; especially with facts about what makes us feel better or worse. By seeing more and more respected people claiming that they bridged the is..ought to gab and that the is..ought to gap is a myth I naturally have started to question whether I am wrong to use it THE WAY I USE IT. The argument goes something like: if we can confirm that a specific action consistently lead to a specific chemical reaction in the test subject's brain and if this chemical always makes the test subjects feel good, then we can conclude that this is what we 'ought to' do, regardless of what anyone value. Another version is similar but is based on survival i.e. that if it helps us survive or live longer then that is what we ought to do. Both of these arguments claim to produce logical 'ought to' conclusions without using values. I welcome these studies and think we can learn a lot from them i.e. they can help us get ever closer to objective values (values we all agree from our subjective views are good or bad). But I don't think they bridge the 'is..ought to gap' for at least two reasons: Firstly, because (in the first case) you are implicitly saying that you value feeling good in the particular way the chemicals make you feel, and in the other case you are implicitly saying that you value to live longer. Secondly, because there are plenty of times when you value some other chemical even more (even if it might be true that you as a human always value feeling good in the particular way that chemical make you feel), and there are plenty of times when you value doing something dangerous or unhealthy over living longer. Therefore you can not use even what is objectively valuable (assuming for the sake of argument there are such values) alone to decide what you 'ought to' do. You still have the evaluate each unique situation; you have to 'look inside' and out of all the alternative consequences you can imagine you have to choose what you value most right now before you can decide what you 'ought to' do. Does anyone know a strong case against the fact that 'in order to rationally justify an ought to (i.e. what you should or should not do) I have to present a value'? Or Should I embrace the 'is..ought to gap' if I value having rational reasons for the rules and guidelines I put up for myself and others? ps. I'm not interested in the argument that 'I have a goal' (i.e. a fact) therefore 'I ought to do x'. Since having a goal means (to me) that I have a value i.e. it might be a fact that I have a goal (or even other types of values) but this goal is then a implicitly saying that 'I value...'. Therefore this argument does not bridge the 'is..ought to gap' without a value. Definition background (how I define/understand value): I use both value and desires to mean 'what is compelling to me'. I often separate them in that my desires are my subconscious (irrational) and may values are my conscious (rational) compulsions. But this separation is often useless since few people use it. So to me it make sense to say that I can potentially prove what someone value/desire by seeing what they do but I have only proven what they subconsciously value/desire right now; your rational values/desires have to come from a conscious evaluation in your mind. So you can value one thing but do another and therefore states of affairs can teach you that your subconscious desires are not in accordance with your conscious desires, but ultimately it is up to you whether you decide to leave them like that, reprogram you subconscious desires or change you conscious values. 

Real world situations usually display an amazing degree of complexity, unlike basic statements of arithmetic. Unfortunately, most attempts to extend Gödel's theorems outside of math end up mired in these types of problems. Because these theorems were developed particular to say something about number theory (more broadly, formal systems), it's often difficult for theorists to explain how ethics or other fields might constitute a formal system analogous to mathematics. Not saying it's impossible but it is unlikely that these kinds of theories work out, mainly because of how specific Gödel's work is to the philosophy of mathematics. 

As for your thought experiment, I don't find it particularly motivating. By asking me to "assume that math cannot be fully understood without external input", you're assuming the conclusion to your argument that mathematical knowledge is not necessarily a prior. Once you've sat down with a pencil and paper and actually proved the theorem yourself there's nothing else that can "deepen" your understanding: you already know it through and through. Maybe your understanding can be "broadened" by interpretation or visualization, but even then, these graphs are just visual representations of the logic contained in the math, not akin to how experiments relate to science.