tldr; On the official support page titled AGNPS Climate Data -- agGEM & preGEM you find a download link to a climate data template file. Your data files need to have this format. All meteorological variables are written into this file. The template file contains daily data. It is not clear if either the data has to have daily resolution or the data can be finer (hourly) or coarser (monthly) resolved. detailed answer Everything I write down below is described on one the official support pages for AGPNS: $URL$ (This is the official short link provided by the United States Department of Agriculture (USDA)) Remarks 

The grid of your input data needs to be properly defined in your input file (that is often a problem). 'properly defined' grid Alternative 1 The spatial dimensions of the data variable (SST in the example below) need to be named and . Additionally, coordinate variables and have to exist (time independent!). These need to have correct coordinate variable attributes (see example below). Example: 

The first operator is just appended to . All further appended operators need to have as suffix. example Assume, we have two files ( and ) with some ocean data (, , , , ...). We want to calculate the difference between the of both files. This is done via 

We have a lot of zeros in the beginning of the binary representation of each value (because we have very low values). The shuffling is favorable in this situation because we have a long contiguous memory part filled with the same number/condition (= 0). If we had no low numbers but higher numbers, (but) which are close to each other, we would not have a long contiguous memory part filled with 0s (zeros) but it might be six 1s and then six 0s. Commonly in netCDF files we have much larger arrays. Lets say a 4-dim array with 100 x 200 x 30 x 365 values, which are quite similar to each other. Then we would have often 2.19 x 109 contiguous 1s or 0s in memory, which is quite nice for compression. However, if neighboring values differ considerably, shuffling might not be a good idea. Chunking If we have an uncompressed file (= no chunking; or one big chunk), a n-dim array is stored contiguously in memory: at first all values of the first row (first index) of the array are stored contiguously in memory; then we go to the next row (increment second index by one) and write the second row contiguously into the memory; and so on. We might also start with the last index and do it the other way around ... - depending on the programming language and on the definition of what are rows and columns. But the principle is the same. The figure below shows an example for a 2-dim variable with one spatial and one temporal dimension. The red arrows indicate how the data is aligned in memory. The black dots are individual values in our 2-dim array. 

Please look for "CDO grid" and "grid description" in the cdo HTML Manual to fine more examples and explanation on it. If you don't have a nicely defined grid, you can generate your . This is, what I have often done, because our chemistry transport model setup needed a non-nicely defined grid. 

climate data operators (CDO) define grid We define a lat-lon target grid with 1°x1° grid cell size 30x30 grid cells starting at 40°N and -10°E (=10°W): 

I would suggest using cdo for your purpose. At least for variables, which values are independent of the grid cell size, one can use cdo. cdo cdo (Climate Data Operators) is a command line program to process netCDF and GRIB files. It is developed an maintained by Uwe Schulzweida and colleagues at the Max-Planck Institute for Meteorology in Hamburg, Germany. 

Now we can write down the order of bits in the memory. I wanted to use color. Therefore, you get another picture: 

Commonly, the second pathway is dominant. The relevant aspect is that it leads to the formation of ultra fine sulfate particles (sulfate droplets). Sulfate particles are cloud condensation nuclei. That means that they support the formation of clouds. There are satellite pictures available, in which you can identify shipping lanes by lines of clouds. These clouds were formed because ships emit large amounts of $SO_2$ (at least outside of sulfur emission control areas). Most clouds above the ocean reflect more solar radiation than the sea surface. In general, clouds above the ocean are considered as "good clouds" with respect to cooling the Earth. Since a large proportion of the Earth is covered by sea surface, one might wonder to generate clouds above it - e.g. by releasing $SO_2$. However, as far as I know, this process is relevant in the troposphere. Releasing $SO_2$ into the stratosphere (as proposed in the linked article) is not meant to support cloud formation (correct me, if I am wrong). Nevertheless, the released $SO_2$ leads to ultra-fine sulfate particles. These sulfate particles themselves effectively scatter solar radiation and, thus, prevent it from reaching the Earth's surface. There is also a Wikipedia article available here. Unfortunately, sulfate indirectly degrades the ozone layer: sulfate leads to the release of radicals that (and their successors) catalytically destroy ozone. See Keith et al. (2016) for a more detailed overview. Why $CaCO_3$? The basic idea is to add salts of alkali metals that neutralize sulfuric acid and nitric acid (generated in the presence of sulfuric acid) when we emit $SO_2$. This will reduce the negative impact on the ozone layer. $CaCO_3$ is such a salt (Keith et al., 2016). Why $Al_2O_3$? Foreword: I am not expert on this and just read some articles on this topic. According to Weisenstein et al. (2015), fine aluminum particles (as well as diamonds) are an alternative to sulfate particles. According to them, aluminum is favourable. However, as studies on emissions from missiles and space crafts indicate, $Al_2O_3$ also has negative impacts on the ozone layer (SomeReport; DoD, 2004): $Cl$ radicals are released that degrade ozone. $CaCO_3$ also counteracts here, too. 

Other situations One might force a model also with data from other models. A river run-off model might get input data from an atmospheric/meteorological model, which predicts precipitation and solar radiation at surface level. We could write 

The important aspect is that the data variable has an attribute , which value contains the two lon and lat dimensional variables (I attached a second example so that it becomes clear). Additionally, the and attributes should be properly set at the dimensional variables. 

The difference between time and space slice is the following. The time slice is fast to extract because the values are stored contiguously in memory. The space slices takes more time because only each sixth value is extracted. Is this example the extra work/time spend is low. However, if we have a large 4-dim variable, the time-slice-extraction will be faster than the space-slice-extraction. When we compress data, we can chunk it. That means, that we split our large array-variable in sub-arrays. For the user it looks the same from the outside. netCDF-4 does chunking automatically, when we compress data but don't define a chunking pattern. The figure below shows an example, in which our data was split into three chunks. The red arrows indicate the alignment of our values in the memory. This is just an exemplary alignment. 

Array indexing starts with (not ) in Python. Therefore, it should be because you are interested in the first row; goes from to 1 () but it should go from to so that all columns of the energy are iterated. The order of the and for loops seems to be quite ineffective. Better would be: Or replace latter for loop by 

As defined in the AMS glossary, a parameterization is a simplification of one or several processes in a model. I add that a parameterization commonly adds an error and increases the uncertainty in the model results. In most cases, a parameterization is not derived from physical laws but a fit to data. These simplifications are employed for different reasons. You probably know the following examples and this answer could have been shorter ;-) but I added them for other readers who might not be aware of them. Parameterization due to spatial constraints When we model meteorological and atmospheric chemistry processes in a certain domain, we split this domain into individual grid cells of a given size - such as grid cells of 10 km x 10 km size. Some atmospheric processes have a lower spatial extend than the grid cells - such as small scale turbulence and clouds smaller than 10 km. These things cannot be explicitly calculated by the model (except if we reduce the model resolution). Therefore, we approximate these things taking place on a spatial scale below 10 km. These approximations are denoted as parameterizations. Parameterizations due to computing effort When we consider processes such as particle formation, growth, and coagulation we could consider every particle or even every molecule in a model. However, in real world atmospheric applications we have too much particles than we could consider them individually. Therefore, we need to calculate the growth of particles on the base of some parameters and apply it on (log-normal) particle number/volume/... distributions. Parameterizations due to missing and condensed information Biogenic emissions are a nice example. We do not know exactly where which trees and plants are located (and which atmospheric conditions like humidity and temperature prevail). For some regions we know it: e.g. for the city of Hamburg there is a detailed (non-public) tree inventory existing. When we do not have this information and work in a gridded domain (i.e. 10 km x 10 km) we need to make a simplified assumption - such as 10% of the grid cell ground is covered by urban area, 30% by grassland, 10% by desert and 50% by forest (of which 70% are pine trees and 30% other trees). From this information and the average ground level temperature and humidity we need to estimate the amount of various emitted volatile organic compounds. Doing this, is a parameterizations because we over-simplify the actual real world. But From my feeling I would describe a process representation in a model as explicit/non-parameterized when it is included according to the best current/state-of-the-art knowledge. In contrast, when it is considerably simplified, I would denote it as a parameterization. However, when we presented gas phase chemical processes by differential equations - like as it is done in the gas phase chemistry mechanisms of chemistry transport models -, I would not consider it as parameterizations because due to a large number of identical molecules (and the law of large numbers - probably) we do not actually introduce a large error. 

The figure above shows an array of six 8-bit integers (only 8-bit because it was less painting work ;-) ). The vertical black boxes split in 8 compartments represents on 8-bit integer. The orange arrows from left to right indicate how the bits would be stored with shuffling. Now we assume some example values: We have an array with the values 4, 2, 4, 5, 7, and 6. It is shown in the figure below. The first row shows the decimal representation. The matrix below is the binary representation. Each binary column represents the corresponding decimal number in the first row. The red arrows indicates the normal storage order. The orange arrows indicate the shuffled storage order. 

How to make cdo recognize cdo assumes that your file conforms with the CF Conventions (Climate and Forecast Conventions). Please have a look in the respective chapter of the CF Conventions Document to get a general description. A working grid definition could look as follows (as ncdump output): 

This text is written into a text file. See section 1.3.2 CDO Manual for details and further examples. If you already have a netCDF file which has data on your target grid, you can also extract the grid definition from that file: 

The phenomenon you describe is denoted as a land breeze. It is caused by a difference between the sea surface temperature and the land surface temperature. Surface Temperature During day time the surface temperature at land rises faster than the sea surface temperature, whereas during night time the land surface cools faster than the sea surfaces. As a result, the sea surface temperature is higher than the land surface temperature in the morning. Formation of the Breeze The sea surface heats the air above the sea stronger than the land surface does with the air above land. The warmer air masses above the sea rise to higher altitudes yielding a low pressure region. As a result, the colder air masses from above the land 'travel' to the low pressure region above the sea. This 'traveling' of air masses is wind: wind, which blows from the land to the sea. Here is a nice Figure from Wikimedia Commons describing the sea breeze (A, evening/afternoon) and the land breeze (B, morning). The Figure was provided by Jesús Gómez Fernández. Shower Curtain Example If you shower in a shower with a shower curtain, you might experience that the lower end of the curtain moves towards your legs. The physical processes are similar: The warm shower water heats the air within the shower. The warm air rises which causes a low pressure region at the bottom of the shower. The air is colder at the bottom of the room outside the shower which leads to a high pressure system. The air from the high pressure system (bottom outside the shower) 'tries' to flow towards the low pressure system (bottom inside the shower) which moves the bottom end of the curtain towards you. This example works only if the room temperature in the bathroom outside the shower is not too warm/hot. 

greenhouse gases other than CO2 The gases N2O and CH4 are relevant greenhouse gases besides CO2. They even have a stronger warming impact per molecule. A brief summary for N2O is provided in its Wikipedia article. Edited later on (thanks to Communisty for the comment): The global warming impact of these greenhouse gases other than CO2 is measured/presented in CO2-equivalents: i.e. the warming potential of N2O equals 298 CO2-equivalents, which means that one N2O molecule is 298 times worse than a CO2 with respect to its warming potential. Therefore, CO2 is more visible in the media. Why focus more on CO2? contribution to global warming Although N2O and CH4 have a stronger greenhouse impact than CO2 per molecule, the concentrations of them are considerably lower. Therefore, in sum (heat trapping potential x number) CO2 has a stronger impact on climate change. The figure below visualizes it nicely (please find the reference below): 

foreword: Particles and Droplets Commonly, atmospheric particles can be considered as wet particles. E.g. when we talk about sulfate particles ($SO_4^{2-}$), these particles are actually droplets with dissolved sulfuric acid (or with a dissolved sulfate-cation compound). Mechanism involving $SO_2$ $SO_2$ is released as gas and it reacts to $SO_4^{2-}$ (sulfate). Basically, there are different reaction pathways for the formation of sulfate from $SO_2$: 

generate climate input data files for known locations Use the program agGEM. This program uses an existing statistical parameter file (maybe: == climatological data?) of meteorological data to generate a climate input data file for AGNPS. There are 233 stations in the US, for which such statistical parameter files exist. There is no information on the support page whether the data are measurement or model data. The program can be downloaded without registration from the support page linked above. The existing statistical parameter files can be also downloaded on that page. generate your own statistical parameter file The USDA provides a program called preGEM to generated statistical parameter files. preGEM needs an input data file with a long time series of meteorological data. What long means is to decide by the use. The format of this particular input data file is not clear. According to the agGEM & preGEM documentation file one can choose between two types of text files: csv and fixed format (see the manual what the latter means) during the execution of preGEMs. However, a preGEM input template is provided on the support page, which is a xls file. Maybe one can also choose xls as format for the input data file. Please be aware that there are a lot of options when you save a xls as csv via the spreadsheet software of your choice: delimiters for strings, delimiter between columns (comma, tab, semicolon, ...) etc. Build your own climate input data file There is a climate input data template provided on the given support page. You can generate your own file without using arGEM and preGEM. There is a file header which nicely describes how the file has to be structured. The file looks as follows: