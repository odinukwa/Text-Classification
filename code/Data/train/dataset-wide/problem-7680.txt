This is not strictly an answer to the question since it is a hypothetical rather than an example, but perhaps relevant nonetheless: Suppose that you have some computer program-say for keeping an airliner stable under gusts of wind-and it relies on a numerical algorithm, proved to converge under reasonable assumptions about air pressure and wind velocity, so on. A faster and more stable algorithm is developed for which no proof of convergence is known, though all the researchers in the field assure you that it always converges and that they are certain that it will always converge given the plausible scenarios your code is likely to be used for. I think it is clear that you should not trust their judgment, but rather retain the old code, despite the clear desirability of having a faster numerical algorithm. So from the perspective of the researchers, a proof might not be all that important; it may have only told them what they already knew and generated no new insights in the process. But from the perspective of the consumers of mathematics, knowledge that a proof exists may lead to incremental improvements in technology that would otherwise not happen. Of course, at this point we've come full circle and it becomes important to the researchers to supply a proof. My second point again distinguishes between consumers of mathematics and researchers: It is sometimes much easier to become 100% certain of something than 99% certain. 99% certainty that a given statement is true requires thinking about many concrete examples and developing intuition, whereas 100% certainty requires logically assenting to the statements contained in a proof. By this standard, I would say that I am 100% certain about the bulk of my mathematical knowledge, and not 99% certain. Perhaps this is a lamentable state of affairs, but time is finite. We cannot hope to develop intuition about all the statements we wish to use while working on problems we do wish to develop intuition about. In that sense, proofs encode in a few kb's the vast amount of information stored as the intuitions of all the researchers working on a particular problem. Again under this model, the purpose of proofs is for the convenience of non-researchers. 

In written English (and of course other languages), we have linguistic constructs which tell the reader how to approach the ideas that are about to be presented. For example, if I begin a sentence with "However, . . .", the reader expects a caution about a previously stated proposition, but if I begin the sentence with "Indeed, . . . ", the reader expects supporting evidence for a position. Of course we could completely discard such language and the same ideas would be communicated, but at much greater effort. I regard the words "variable", "constant", "parameter", and so on, in much the same way I regard "however", "indeed", and "of course"; these words are informing me about potential ways to envision the objects I am learning about. For example, when I read that "$x$ is a variable", I regard $x$ as able to engage in movement; it can float about the set it is defined upon. But if $c$ is an element of the same set, I regard it as nailed down; "for each" is the appropriate quantifier for the letter $c$. And when (say) $\xi$ is a parameter, then I envision an uncountable set of objects generated by $\xi$, but $\xi$ itself cannot engage in movement. Finally, when an object is referred to as a symbol, then I regard its ontological status as in doubt until further proof is given. Such as: "Let the symbol '$Lv$' denote the limit of the sequence $\lbrace L_{n}v \rbrace_{n=1}^{\infty}$ for each $v \in V$. With this definition, we can regard $L$ as a function defined on $V$. . . " So in short, I regard constructing precise mathematical definitions for these terms as equivalent to getting everyone to have the same mental visions of abstract objects. 

Let X be an affine variety over ℂ. Consider X(ℂ) with the classical topology, and create the topologists loop space ΩX(ℂ) of maps from the circle into X(ℂ). One can also construct the ind-variety X((t)), whose R-points are given by X(R((t))) for any ℂ-algebra R. Take the ℂ-points of this ind-variety, and give them the usual topology. Is the topological space X((t))(ℂ) thus defined homotopy equivalent to ΩX(ℂ)? Edit: David Ben-Zvi's comment regarding using unbased loops instead of based loops is pertinent. We should be considering unbased loops (L not Ω). This checks out in the case where $X=\mathbb{G}_m$. The affine Grassmannian case also provides positive evidence. Commentary (based on comments): Note that the space X((t)) is not the base change of X to ℂ((t)). It isn't the restriction of scalars either, since $R\otimes \mathbb{C}((t))\neq R((t))$ in general. Regarding putting the classical topology of X((t))(ℂ), one should not be scared of the ind-scheminess. ℂ((t)) has a natural structure of a topological ring, and hence we topologise X(ℂ((t))) in the usual manner, taking the subspace topology using a closed embedding into affine n-space for some n. [paragraph redacted] 

I can give a general solution under the additional assumption that the long word acts by -1 on the root system. Let $\alpha_i$ denote the simple roots and $\beta_i$ be a vector orthogonal to all $\alpha_j$ with j different from i. Let (,) be a W-invariant inner product. The point: For any vector v and any w in the maximal proper parabolic corresponding to i, we have $(v,\beta_i)=(wv,\beta_i)$. A simple Lemma: If $(\gamma,\beta_i)=(\alpha_i,\beta_i)$, $(s_i\gamma,\beta_i)=-(\alpha_i,\beta_i)$ and $||\gamma||=||\alpha_i||$, then $\gamma=\alpha_i$. Since rank at least two, there exists a root $\alpha'_i$ with $(\alpha_i,\beta_i)=(\alpha'_i,\beta_i)$. and $||\alpha'_i||=||\alpha_i||$ Now if $w_0=w_1s_iw_2$ with $w_1,w_2$ in the max. parabolic, lets act on $\alpha_i$ and $\alpha_i$. Since $w_1,w_2$ can't change value of inner product with $\beta_i$, and applying $w_0$ must multiply this product by -1, by our lemma we must have $w_2\alpha_i=w_2\alpha'_i=\alpha_i$, a contracition. 

Yes. For another approach, see "Morse-Sard theorem for real-analytic functions" by Jiří Souček and Vladimír Souček. (Commentationes Mathematicae Universitatis Carolinae, Vol. 13 (1972), No. 1, 45--51) 

Leclerc (arXiv:math/0209133) has given us an algorithm for computing the dual canonical basis of the upper part of a quantised enveloping algebra. Now presumably this algorithm has been implemented by someone somewhere. I am wondering if there are any precomputed tables of dual canonical basis vectors out there (or the software to compute my own). I do know that the quagroup package in GAP computes the canonical basis. I can't see an easy way to extract from that the dual basis. For immediate purposes, I believe I'd be most interested if the dual canonical basis vectors were given as elements of the quantum shuffle algebra, under the standard embedding of Uq(n)* into the shuffle algebra. EDIT. Leclerc (personal communication) informs me that he implemented this algorithm, but it is in an obsolete format. And also that one is likely to run up against size issues in trying to perform this task, since elements of a shuffle algebra have a lot of terms. 

It's well known that the nilradical of a commutative ring with identity $A$ is the intersection of all the prime ideals of $A$. Every proof I found (e.g. in the classical "Commutative Algebra" by Atiyah and Macdonald) uses Zorn's lemma to prove that $x \notin Nil(A) \Rightarrow x \notin \cap_{\mathfrak{p}\in Spec(A)} \mathfrak{p}$ (the other way is immediate). Does anybody know a proof that doesn't involve it? 

Let $\Gamma=<g_1, \dots, g_n>$ $\subset PGL_2(\mathbb{C})$ be a Schottky group of rank $n$. The group $\Gamma$ is called classical if there exists a set of $2n$ pairwise disjoint closed balls $\{B_1, C_1, \dots, B_n, C_n\}$ such that $g_i(\mathbb{P}^1_{\mathbb{C}} \setminus B_i)= \mathring{C_i}$ and $g_i(\mathbb{P}^1_{\mathbb{C}} \setminus \mathring{B_i})= C_i$ for every $i=1, \dots, n$. The group $\Gamma$ is called iso-classical if the balls $B_i, C_i$ can be taken to be the isometric balls associated to $g_i$ and $g_i^{-1}$ respectively. It seems to be a difficult open problem to prove that every Riemann surface can be uniformized by a classical Schottky group. Not being an expert of the field, I don't even know if one expects such a statement to be true and what would be the evidence in favor of it. My question goes in another direction, though: do we know anything at all about those Riemann surfaces that can be uniformized by iso-classical Schottky groups? Do we expect every Riemann surface to fall into this class? 

I'm giving a talk for the seminar of the PhD students of my math departement. I actually work on Berkovich spaces and arithmetic geometry but, of course, I cannot really talk about that to an audience that includes probabilists, computer scientists and so on. I'd rather like to do an introduction to $p$-adic numbers and $p$-adic analysis. I think these kind of things come up to be really cool when you work on it even just for a short time, but I have the ambitious aim to show them something nice and elementary whose statement will be understood by everyone (of course the proof may also be really hard, but there I could give them just its general idea). In other words the question is: if I had prepared something about Galois theory I would have finished with the application to resolubility of polynomial or compass and straightedge constructions; if it had been something about modular forms, it would have been for sure Fermat's last theorem; with 3-surfaces it would have been Poincaré conjecture and so on. What if it's about p-adic numbers or p-adic analysis? I thought about results on valuations of roots of polynomials, but it seems to me already too complicated (par ailleurs since I'm introducing valuations at the beginning of the talk, it won't turn out to be an application to something they already knew).