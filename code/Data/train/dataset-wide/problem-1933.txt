Listen to your father ! Yes droplets of spray are carried on the wind several miles . There are any number of corrosion tables listing atmospheric corrosion more severe on sea coasts. Much of the testing was / is being done at Kure Beach ( N or S ) Carolina. 

LOTS of time for density differences to cause migration miles through relatively solid rock. And beyond the level of the question to point out there is always water and often CO2 which make for some complicated ( for me) physical chemistry. 

It depends on what you want the info for. If you are designing a dam or drainage system for a 500 years event you better not ignore the high points. I recently measured 40 " in my yard during "Harvey". This is dramatically more than I measured in any other storm for 20 years but that doesn't mean it didn't happen. 

No. Grain size is not a factor . Test method depends on the size and shape of the test piece and why the test is being done. Vickers can use different loads so can be used for very small areas and the microscope can be used to select certain locations such as a carburized layer. Rockwell can test larger specific locations such as the components of a weld HAZ. Brinell hits a fairly large area ,it also requires significant thickness like 1/2 ". Vickers and Brinell results are based on the area of the impression , while Rockwell measures the depth of penetration. These comments apply to standard bench testers , portable testers is a different game. 

3. Wind Intensity vs dT/dt Now this is where it gets complicated. So thinking of this in a mathematical sense, the rate of increase in temperature is not going to matter that much because when calculating the wind speed at a given time what matters most is the absolute temperature difference between land and sea. For a temperature difference to occur the rate of temp change has to be fairly rapid as the system is always trying to reach equilibrium (i.e. remove the temp difference). So naturally if you have a parcel of air, it will reach a higher temperature if the heating is fast vs slow. If it reaches a higher temperature then it will result in a greater wind velocity. But if you wanted to make a more complex model of the system then you would need to look into the rate of change of change in Temp. 

In the figure: The top panel is the radar gram measured in depth below ice surface (m). It is flat because when you do the measurement it starts from the surface which is 0m. The distance from the aircraft to the surface would have been relatively constant but the plot starts from the air-ice boundary at 0m. The middle panel is a cross section measured in m above sea level showing the ice surface and bedrock (black), the hydraulic head (blue) relative to sea level. The hydraulic head is calculated by working out the pressure of the ice sitting on top of the bedrock. It is basically the water table of the ice sheet. Whats important is the differences in hydraulic head (gradient) which can tell you if the water is moving or not. The bottom panel is the reflectivity (black) and specularity (blue) of the basal surface. Specularity is a ratio of reflected to scattered energy. Simply put, high reflectivity means the boundary is wet and high specularity means the boundary is flat (Ice-Water), and low specularity means its rough (Ice Rock). 

An important aspect of this is location. Sea-level rise will not be exactly uniform across the globe and tides/storms will cause a lot of regional variability in terms of coastal change. Local governments should not necessarily be planning for an average global sea-level rise but instead develop a regional understanding of the coastal effects they will likely experience. For instance, see California's recent CALIFORNIA COASTAL COMMISSION SEA LEVEL RISE POLICY GUIDANCE here: $URL$ which says 

The continued trend of a warming climate that is expected due to increased GHGs will lead to a net increase in total moisture, since the atmosphere can hold more water vapor at higher temperatures. In general, the equatorial zones and poles will have a net increase in precipitation while lower mid-latitude zones will have reduced precip, with the rain belt moving poleward. Climate models generally show a pole-ward shift of extra-tropical precipitation because the increased heat energy allows convective systems in low latitudes to loft the convective air higher up, which in turn leads to greater horizontal transport (generally poleward) before air completely descends and contributes to the development of an associated storm system. You can also expect the poleward shift since cold temperatures accelerate the precipitation process, and since systems will have to travel a little further poleward to reach those cold temperatures. A 2014 IPCC Technical Summary figure (below) shows change in precipitation forecasted ~65 yrs into the future. The image on the left represents a best-case scenario if we reduce carbon emissions while the right represents more of a business-as-usual scenario. 

The red line or piezometric line is the level to which the water wants to rise - if it were allowed to reach hydrostatic equilibrium. Artesian conditions are anywhere where a confined aquifer sits below the hydraulic head level (the level to which the water wants to rise). In this case the water is confined and cannot reach the water table even though it wants to - this means it is not at hydrostatic equilibrium. This aquifer is described as having a confining pressure or hydrostatic head. If you put a well into anywhere along this confined aquifer, the water will rise out of the aquifer to the level of red line. I think in your case its a bit confusing as the piezometric line sitting above the whole of the confined aquifer suggests the whole area is artesian but the 'flowing' conditions are only where the piezometric line sits above the actual surface, meaning the water will actually rise above the surface. Another example is that if you were to dig a well, to the left or right of the highlighted area, the water would rise to that level but would still be below the surface so conditions wouldn't be described as 'flowing'. ($URL$ 

So wind is caused by differences in atmospheric pressure which in turn is a result of temperature induced density differences. 1. Required temperature diference: A quick search brought up this paper: Miller et al. 2003 SEA BREEZE: STRUCTURE, FORECASTING, AND IMPACTS $URL$ They calculate that a 10 degree difference between land and sea over 20km results in an accelaration of 7.2*10E-3 m/s. Now, this is an estimate. There are many more variables that will affect the complex fluid dynamics of the system. 2. Wind Intensity vs dT. Absolutely if you increase the temperature gradient (difference) the wind speed will be higher. from the paper they mention the sea breeze of Alcoa Bay, South Africa, where the strongest sea breeze occurs in areas with nearby dune fields: 

It seems that the CO2 fertilization has been over-estimated in past studies. From Nature Climate Change article,Large divergence of satellite and Earth system model estimates of global terrestrial CO2 fertilization by W. Kolby Smith, Sasha C. Reed, Cory C. Cleveland, Ashley P. Ballantyne, William R. L. Anderegg, William R. Wieder, Yi Y. Liu & Steven W. Running 

When determining the retrieval algorithm for a spectrometer that will be built, it is first done on highly mathematical software platforms. The software allows to the best curve approximation fitting equations to be derived (across all detected wavelengths) that will work for the proposed optics. This is important because the diffracted light that is detected will interfere with itself very uniquely, depending on the geometry of your optical setup. The data from the spectrometer's detector needs to be interpreted with a good curve fitting function so that you can get good wavelength resolution from your instrument. When building a spectrometer for operational use on a satellite, it is ideal to be able to process the retrieval algorithm using hardware, rather than software. The hardware processor allows real time function that isn't dependent on an operating system that requires lot's of computational overhead. So, you build a breadboard that you can connect to your spectrometer so that your retrieval algorithm is processed using integrated circuits that can be programmed. You essentially hard-code your algorithm into hardware. Search for "breadboard spectrometer" in Google and you will find many examples. Now, to answer your question. A breadboard algorithm is developed using software that is used to help engineer the actual breadboards to be built in the future. The software allows you to predict the response of your proposed circuitry to the spectrometer detector without having to actually build the breadboard yet. Once your breadboard algorithm is setup properly (confirmed by testing the software version of your needed hardware) you can go about building the actual breadboard spectrometer model. Once a breadboard spectrometer model is built and passes quality control checks, you can evaluate the spectrometer performance and see if its worth optimizing and fabricating a standalone instrument payload that can be deployed in the field (or in space). 

Will GW just cause more winter storms in Northeast US or will all of US have colder winters ? This winter in East TX we had three record cold snaps and I lost a lot of Camellia Japonica buds and blooms. Most years I lose a few blooms but usually not the buds also. This is the most I have lost in 20 years. I am hoping we will not get the cold like the northeast.. I have watched the weather channels ; they usually explain how GW causes more storms/ rain, etc, but they have not yet explained the relationship to GW for these storms. 

The metallic part ( essentially all two elements= Iron + nickel) is two phases mixed together : Body Centered Cubic - magnetic, and Face Centered Cubic - nonmagnetic. So the answer to your question is that it is both . Iron ( BCC) starts to form FCC when Ni exceeds 6 %. The proverbial 18 - 8 stainless steel is 8 % Ni and generally non magnetic austenite phase. My educated guess is the classic Widmidststten pattern is ferrite ( BCC ) grains/crystals forming from the original austenite ( FCC ) grains/crystals. But it is not that simple as when hot ( 1500 F ) it is 100 % austenite ( FCC ). Further complication is the austenite ( FCC , nickel rich) makes crystal twins . The twins can also give the Widmanstratten structure. And more complicated because temperature history can also affect the FCC / BCC morphology. [ Maybe I cheated but I searched meteors on the net and learned some but also found some mistakes in the references. ] 

The readme file for all the datasets has a section on units. In this section, they describe how to interpret the numbers (which exclude decimal points in the data files). For the "number of days" data it says: 

In order to attribute climate change to humans, climate models are run with and without anthropogenic climate forcing. When they do so, climate models run without anthropogenic forcing are unable to duplicate the current warming trend. I've attached an image of this from the IPCC AR5 Technical Summary draft which shows a full climate simulation, one without anthropogenic climate forcers, and one with no aerosol forcing for comparison. 

In school, I was acquainted with the Moh's hardness scale. I wondered how malleability factors into this scale and was surprised to find there are many different hardness scales: the Rockwell scale, the Leeb scale, the Vickers, the Meyer, and I'm sure others. What are all the different hardness scales? And, which ones are used in Earth Science? 

Most Earth-Science models are comprised of several sub-models that are developed by multiple members of the international community, requiring an open-source framework to be successful long-term. However, sometimes there are model developments that are done by a consulting company which may have caveats as to how the code can be distributed. Or, you may have a grant that is funded by a private source that can dictate who has access to the final product. So, it really does depend on the source of the money and what the terms of the grant are. Some privately funded products do become well-recognized in the Earth Science community, but it is quite rare, and typically the fundamental equations are published. Sometimes its something as simple as confidential business data that is embedded in the code logic. You can get access to the executable and still do your own testing, but the code itself is private. Usually, though, Earth Science computational models are developed with grant money that comes from publicly funded agencies like the National Science Foundation, NASA, or NOAA. In these cases, the end-product is by definition open-source and will be shared with the scientific community.