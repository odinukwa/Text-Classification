Plus one on the book suggestion and the thoughts on leaving memory for the OS and about the CPU load in Kevin's answer and Kevin brings up some good points but a few more thoughts for you to ponder as you settle on a solution: 1.) Development environments don't always (and in my experience don't typically) match production and I'm not sure you always need to have a dev environment match production in terms of size and performance. In a perfect world with an unlimited budget, sure. As long as you have -some- environment somewhere that can mimic productions performance for you to do serious performance and load testing on you'll be good. 2.) Having 10 instances on one machine will definitely cause you some occasional heartache at times if all 10 instances are being worked on at a time. But then again, so would having all of those databases in one instance with lots of people working on them at a time in the same instance. So look to how you have it set up in prod and why you have it that way. If permissions are different and there are cross instance communications between your applications (do your apps talk to the different prod instances at different times?) then it makes sense to provide some separation via instances in dev. 3.) In prod are you multi-instance or multi server? You might consider looking at virtualization in dev, though that increases some complexity and license cost depending on how you go. It also makes dev look a bit less like production if it is on a virtual, but it is not unheard of at all to give developers virtuals even in a physical production environment. 4.) Sounds like you have the space in dev, but sounds like you won't get the IO performance. I think for dev, this is likely fine, but make sure you have a more prod like environment someplace to do performance testing - or make sure you have the ability to attack performance problems after deploy in production. Not sure what industry you are in, what up-time requirements you have and how your deploys work.. 5.) Also pay attention to the license in dev. SQL Server Developer edition is great. But if production is not Enterprise, make sure your developers are not developing with assumptions that things will just work the same in prod. Dev edition works just like enterprise. So know what features will and won't work in standard if prod isn't enterprise and just make sure your developers appropriately manage this risk. This link will help there. 

The Short Answer: I misread your question a little bit. The below discussion still applies and explains my answer, but I would suggest for your index. Especially because of your partitions and the fact that is included in every query. The question of fragmentation is a good one, and I imagine you'll see some in either of your two choices, but the performance benefit would be best with this way, I feel. The Previous Discussion: This is one you'll likely get a few answers on and I've asked a couple questions in the comments. That said a few quick thoughts to get started (ignoring the multiple system question and the way the IDs are being used): 1.) Presuming you are talking about SQL Server partitioning, a partition aligned clustered index is generally best. So in my mind that is a good vote for . 2.) You indicate that filters will always (is that really always? or figuratively always?) have . In my mind that is another good vote for . 3.) Because you'll be having IDs coming in at both a high range and a low range, you will experience some level of index fragmentation on ID. Assuming is always increasing and you aren't entering data from dates all over the place, you may actually experience less fragmentation going with . You also didn't indicate if this is a fact table or dimension. Assuming it is a fact table, that is another good argument for date in my book. If you are always querying filtering on a date or date range, then the clustered index being on that range scan value should help your queries. The fact that it would be partition aligned would also likely help. If this is a dimension and you will sometimes join on ID to pull data out of it, then there could be a stronger argument for going with , though I'd argue that the unaligned nature of that index to your partition could cause you more grief in the future performance wise. I would not bother adding to the index. Unless you include it enough as a filtering predicate and could actually see an improvement in performance of most queries. Yes, the date column alone wouldn't be unique, but if this table is a , the 4 byte uniqueifier SQL Server adds to the clustered index to make it unique would actually cost less in terms of storage space than that column. These are just my thoughts and they are quick thoughts. This is one of those things you should really test, try a couple ways and see how it works out. Though partitioning sometimes forces your hand a bit. So I would probably end up with the date column only as my first choice and date plus ID as my second choice. Others will likely have alternative ideas on that one, too. And more information edited back into your question will help. 

It isn't inexpensive. I don't know the price tag but you are talking large capital expense measured in hundreds of thousands of dollars. It is an enterprise scale solution that is optimized for large scale enterprise data warehouses. As such, you may find it tough to get a great answer here other than things like the link I provide below. You said you already did the research, so I won't provide you too many links other than the this one which does a great job explaining PDW. If you have the budget and enterprise scale that requires PDW, you would be much better off talking to Microsoft and asking them for discussions with reference customers. This right now isn't deployed en masse, so you will get individualized attention if you are in the market for a massively parallel data warehousing appliance. 

Not sure exactly what you want to grab out of the referenced system view. Much of the data you care about is likely still exposed to you, but through the Database related DMVs which have more or less been around in some fashion since SQL Server 2005 with additions in versions since. You might have some luck with querying a few of these DMVs. You can explore with 

Queries can start to slow down over time for a few reasons and you rebuilding the indexes can be fixing the problem a few ways. I'll share some of the more common reasons in my experience but there could be other causes as well. My guess is you are suffering from one of these issues.. I've also asked some questions as a comment to your question to see if we can get more details. But a few thoughts: Statistics Getting Stale SQL Server maintains column and index statistics. These essentially tell the Query Optimizer how your data is distributed. This information is critical to the optimizer in choosing the right access method for data (Seek vs Scan) and then choosing the join method being used. If you have auto update statistics enabled (default setting in SQL.. At the database level) these get recomputed, but only when "enough" data changes. So if you have some inserts into your table but never manually update statistics and the inserts/updates are not enough to trigger an auto stats update you could be suffering from poor plans for your data distribution... Rebuilding your indexes also recomputes your index statistics I would create a job to manually update statistics on a regular basis, this is a best practice anyway - and the next time this happens try and just run in your database and see if you notice a difference Query plan issues You could be suffering from parameter sniffing - basically the first time a query runs one value is passed in - the query gets optimized for that value. When you next run it with a different value that would benefit from a different query plan, it suffers with the original query plan resulting in a slow query. When things run slow for the app - are they also slow if you run the same query in SQL Server Management Studio? If it is fast in SSMS but slow in the app - that can be a good sign pointing towards parameter sniffing. If it is consistently slow across the board over time for all queries and regardless of parameters, then I wouldn't look here. This article talks quite a bit about parameter sniffing. Not enough memory/too many ad hoc plans It sounds like you are sending ad hoc SQL to SQL Server. This can bloat your plan cache sometimes, especially if you have a separate plan for each execution of a query. Depending on the memory on your server, this can also lead to the issue. How much memory is on your server? Check out this link on the problem with single use plans. You don't have a lot of great solutions in SQL Server 2005 for this problem, if you have it. If you can recreate this problem in a non-prod environment, I would suggest running in your non-prod environment if this happens again. Please note! This is an instance wide setting, if you do this on production - any stored query plans in cache for any database will no longer be there. It means you have to "pay" for compilations again. If you have high concurrency and a busy system, this could prove to cause issues. If this is the only real database and you are suffering from performance issues anyway, it doesn't hurt to try this in production.. If you have other Databases and just want to do it for this database, this blog post explains how to approach a clear for just one DB. Index Fragmentation - It is possible that index fragmentation is the actual issue here, but I'm surprised it gets so bad so quick. If your tables are clustered on a key that causes fragmentation quickly and you have a lot of inserts, this could be the case. It would be made much worse if you were underpowered in terms of memory and disk IO. Setting up a job to rebuild/reorganize your indexes on a regular basis would be good. Based on your answers to some questions in the comments above there may be other things to do to minimize the impact of this. 

So ALTER is the minimum permissions required. You can get that as DB Owner, you can get that as DB_DDLAdmin. Or just grant alter. If you think about what truncate does and how it works, this makes sense, it is a pretty "severe" command and empties the table of data and does it quickly. 

Even a local temporary table (#Table) would work as long as you stayed in a session context. A global temporary table (##Table) is only global in that it can be seen by other sessions. What is probably happening here is your create ##Table session is going out of scope/context and when the session goes away, there goes it's temp table. Whether local or global. So the process that created the temporary table is out of scope and it's temp table is gone. In other words - the problem isn't the scope of the database you are connected to. any temporary table can be access regardless of the database you are using. A temp table isn't created in any of your user databases (DB1 or DB2), they are always created in TempDB. Try using a derived table or consider a staging table, etc.