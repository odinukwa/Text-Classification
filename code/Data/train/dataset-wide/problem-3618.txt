Run a system call tracer (such as , if this is a Linux server) and see if that reveals what lighttpd is doing. 

I am running a JVM to support ElasticSearch. I am still working on sizing and tuning, so I left the JVM's max heap size at ElasticSearch's default of 1GB. After putting data in the database, I find that the JVM's process is showing 50GB in SIZE in output. It appears that this is actually causing performance problems on the system; other processes are having trouble allocating memory. In asking the ElasticSearch community, they suggested that it's "just" filesystem caching. In my experience, filesystem caching doesn't show up as memory used by a particular process. Of course, they may have been talking about something other than the OS's filesystem cache, maybe something that the JVM or ElasticSearch itself is doing on top of the OS. But they also said that it would be released if needed, and that didn't seem to be happening. So can anyone help me figure out how to tune the JVM, or maybe ElasticSearch itself, to not use so much RAM. System is Solaris 10 x86 with 72GB RAM. JVM is "Java(TM) SE Runtime Environment (build 1.7.0_45-b18)". 

Turns out that I had to have an SFP ("mini-GBIC") module plugged into the 0b port and with a physical termination adapter connected to that. The internal termination switch doesn't seem to have any effect. I also updated the "partner-sysid" environment variable in the head's CFE ("BIOS") to reference the other head's serial number. It was undefined. I don't think this had any relevance, though, as I think that's only referenced for clustering, and, again, I hadn't gotten that set up yet. 

My default email address at work is "William.Faulk@…". People frequently send emails to our other William that are intended for me. You might want to consider a last-name-first approach, since last names are more likely to be unique than first names. You probably want a variety of aliases, too, but for people who are too lazy to read their autocompletes, keying off of last name probably makes more sense. 

the kr/s numbers were wildly inconsistent, but those are representative numbers. while ing from (to /dev/null): 

If you're concerned about doing your job properly, you've done your job. Just because no one acts on your recommendations doesn't reflect on you. However, if you're legitimately concerned about their customers' being victims of identity or credit card theft, I'd say to contact the FTC complain department. (Assuming you're in the US. If not, your country probably has a similar government department.) 

I believe the best you could do is write a pair of Applescripts to emulate Cut and Paste and then bind them to keystrokes with Quicksilver or similar. 

Sadly, you'll have to define a new scope. Might be easier to "migrate" the scope to the same computer and edit the intermediate file. Nevermind. Since they suggested you name that file , silly me assumed that it was a text file. Turns out that it's some impenetrable binary blob. 

In the specific case of the problem caused by HP switches, I found (by using , which records every byte sent to the terminal), that the autowrap mode of the terminal was being turned off via the VT100 code "" and then never being turned back on again. † The VT100 code to turn autowrap back on is "", which you could send to the terminal with this command: 

PsTools in general, and PsExec in particular. PsExec will allow you to run arbitrary programs on the remote computer, including cmd.exe and even powershell.exe. Having a remote command-line login to a Windows machine is great. Also, winexe is a Unix utility that allows you the same access to a remote Windows machine. The great thing about these remote access tools is that they require nothing but standard Windows privileges to use. There doesn't need to be any special software installed on the remote system. That said, I've still found them to be more effective than a lot of utilities that do require a server. 

Distribute the certificate database files directly. Package Firefox for installation, including the certificates in your distribution. Use CCK2 to create an extension that adds the certificates. 

What is MTU? MTU == Maximum Transmission Unit. Effectively, it's the largest ethernet packet that your computer will send. The IP spec says that if a router receives a packet too large to send out its (other) interface, it can either fragment the packet or send back an ICMP message that says "this is too big". Fragmenting is bad for performance, though, so many of those routers never agree to fragment. Also, modern OSes use a trick to determine the optimal MTU for a particular path by sending packets in decreasing sizes until they no longer hear a response back about the packet being too big. This is Path MTU Discovery, or PMTUD. What's happening to you is that a router somewhere is refusing to fragment a packet, but your Vista machine is never hearing its refusal notification. When you set your MTU really small, you're telling the OS to always transmit packets smaller than any modern circuit is likely to be able t oaccept, so your packets will never encounter the need to fragment. 

I'm trying to set up a RAID10 set on an LSI MegaRAID controller. It is unclear to me how the RAID controller will actually lay out the RAID set on the physical drives. Part of the problem is that MegaRAID seems to use terms very inconsistently; the same idea often has multiple terms, and it seems as if sometimes they use the same term to refer to multiple ideas. I'm going to try to use the terms that the MegaCli command seems to use most frequently. MegaRAID requires that there be two to eight arrays within a RAID10 set. Each array must contain physical drives in multiples of two. Each array in the RAID10 set must have the same number of physical drives. Is each array a RAID10 set, and then the arrays are joined together? If so, does the fact that the arrays have to be the same size imply that the arrays are being striped? If so, given that each array is striped, and then there's an additional layer of striping on top of that, should I be concerned about that redundancy in regards to performance? (Or would it be a good thing?) If each array is a RAID10 set, though, why does MegaRAID require that you have at least two of them? If each array is not a RAID10 set, why does it require that arrays have physical drives in multiples of two? In the documentation, it refers to arrays as spans, which it elsewhere defines like this: 

Yesterday I babysat a Windows 2008 R2 server for three hours applying multiple rounds of Windows Updates. This is not a good use of my time. This is a server that cannot apply updates automatically; I have to schedule maintenance windows in order to reboot the server. I want to bring Windows completely up to date during that maintenance window, which often means multiple rounds of a check-for-updates/download-updates/apply-updates/reboot cycle. I know that I can download updates and apply them manually, but that doesn't really help when Windows determines after the first round of updates that it needs to apply even more updates. The biggest problem is that it can easily take ten minutes for Windows to determine what updates it needs to apply. It can then take easily another ten minutes to download these updates. Then it can take ten minutes to reboot and finish the update installation. If it decides that you need three rounds of updates, that's an hour and a half, and that assumes that Windows doesn't freak out and make one of those steps take forever, or fail, making you start over. Is there any way to determine all of the updates that would be needed to bring a Windows system up to date beforehand, so that I can just apply them all by hand and avoid having to wait for Windows to perform its interminably long checks and ridiculously slow downloads multiple times during my maintenance window. (I feel like this should be a FAQ, but I can't find it.) 

Unless I'm mistaken, these errors are telling you that you have errors that haven't been corrected by the RAID controller. The RAID controller should be hiding errors like that from you. I don't think you have a simple disk failure. I think you have something more serious going on. 

I have also created a separate network to emulate that office's configuration that's connected to the DC network via LAN-to-LAN VPN instead of MPLS. Joining Windows 7 computers from that remote network works fine. The only difference I can find between the two environments is the intermediate connectivity, but I'm out of ideas as to what to test or how to do it. What further steps should I take? (Note that this isn't actually my client workstation and I have no direct access to it; I'm forced to do remote hands access to it, which makes some of the obvious troubleshooting methods, like packet sniffing, more difficult. If I could just set up a system there that I could remote into, I would, but requests to that effect have gone unanswered.) 2011-08-25 update: I had run on a client attempting to join the domain: 

Feels like an MTU issue to me. I don't know what Vista's MTU algorithm is, though. As a simple test, set your Vista machine's MTU artificially low, like 500, and see if that resolves the problem. If so, we can say that MTU is the cause and go back to looking at exactly how to fix that. 

Turns out that init had simply stopped working properly, probably when the system was having I/O problems with swap. As it turns out, if init exits outside the process of shutting down the OS, it will simply restart. So I sent init a SIGSEGV (to make sure that it wouldn't mimic however it determines that a shutdown is in progress), it restarted init (still as pid 1), and the new init immediately reaped all of those outstanding zombies. However, I should probably reboot to clear whatever other problems might exist due to the swap I/O problems. 

But you probably want to use a different date format so that it doesn't have spaces and junk in it. Something like: 

The Cisco ASA has a feature where a blocked HTTP request can be redirected to a web page hosted on the ASA itself in order to allow the web user to authenticate himself to the ASA and unblock the request. This is configured with the command documented in Configuring AAA for Network Access. The page that the user is redirected to is generic and ugly. Is there any way to get that page to appear different? Things I can imagine include a template on the ASA that can be modified, a way to embed that page inside another web page, or some sort of CSS insertion. However, I'm open to anything. Alternately, if anyone knows of a more configurable way to achieve the same goal of blocking network access to a web page prior to authentication, I'd be happy to consider that, too. 

You might try using and , which help automate the mounting of the drive some. You also might try using PowerShell, if possible. 

RADIUS is a client/server protocol. Effectively, the client speaks RADIUS protocol to the server to ask if the authentication information provided is accurate. The AP is the client and there is another computer that is the server. Your school was considering changing to using RADIUS either from some other authentication protocol, or from authentication directly on the AP. 

I have a NetBackup 6.0MP7 installation running on Windows Server 2003. It functions as the only Master Server and Media Server. I swap a full set of tapes in and out every week, but leave a set of tapes with their Volume Pool set to "Scratch" in all the time. The weekly tape sets then get rotated back in after a period of time. Largely, this works fine. I seldom actually need the scratch tapes, but every once in a while, a backup will run over what I have dedicated to the task. However, one week's set of tapes consistently gets declined in favor of the scratch pool. The backup policies are the same for every week, they all have "Policy Volume Pool" set to "NetBackup", and all of the tapes for every week (beside the scratch tapes) have had their pools assigned as "NetBackup", definitely including the week that always gets ignored. That said, it doesn't ignore all of the NetBackup pool tapes for that week. It does usually write to two or three of them, but it writes to like 20 of the scratch tapes. (I haven't thought to look to see if it's always the same two or three tapes.) And this problem never seems to occur for any other week. It doesn't load the tapes and then reject them; it never seems to try to use them at all. They are not flagged as frozen. They are all active and unassigned when I swap them in. The tapes are in a Quantum PX510 tape library. The NetBackup server is attached to the library/robot via fibrechannel going through an HP-branded Brocade switch. I'm not an expert on NetBackup at all. I don't really even know where to look. Any advice on logs to look at or logging to enable or really anything at all would be appreciated. I'll keep an eye on the question and update it if anyone needs any more info to help. 

There are 12 snapshots on this filesystem right now. (Which seems excessive; I'm going to see if any of them can be deleted.) There's no L2ARC for this pool (or any other pool on the system). I've tried all three values for primarycache, and I've tried reenabling the prefetch, none of which seem to have had any significant effect. The zpool is four 2-disk mirrors: 

The private key file is itself encrypted with a passphrase. You need to remove this encryption so that Apache can load it without you typing the passphrase in manually. You can use to do this: 

I have a Windows 2003 print server that I need to retire, but I need to migrate the print queues off of it first onto another Win2k3 server. I have found some information on migrating, but it all seems to have to do with duplicating the print queue settings. I want to figure out the most transparent way to deploy the new print queues to my clients. Right now, the clients all have their print queues configured manually. I don't really care too much about removing the old queues, though I wouldn't say no to doing that. I just want to automatically add the new queues. It seemed to me that a GPO would be the way to go, but I've never set one up before. (I'm a Unix admin forced into dealing with Windows.) Every piece of documentation I've seen about print queue GPOs seems to reference things that simply don't exist. Print Management Step-by-Step Guide refers to a "Print Management" option that might be in Adminstrative Tools or might be an MMC plugin. It exists in neither place on my print server. The print server role was activated ages ago, and there's no "Update this role" option as referenced in that document. I tried activating it on a different server, and it didn't appear there, either. (That document also says: "Installing Print Management is accomplished by adding or updating the print server role. Note that the computer on which Print Management is installed does not need to be a print server." Of course, you can't add the print server role without sharing a locally-attached printer, so I'm not sure how that statement isn't oxymoronic.) I also found Microsoft referencing a program called PushPrinterConnections.exe, but I can't find anywhere that that program exists. Basically, after two or three total failures in Microsoft documentation, I've given up and am asking in hopes that someone else actually knows how to do it.