So even if an update process should somehow take a whole hour, the reboot that might be necessary should happen at 07:00 in the morning and not nine to ten hours later, shouldn't it? I would like to keep the update process as admin-friendly as possible, i.e., without the need to manually install updates off-hours or to manually schedule a reboot. Q1: Why can it happen that the automatic reboot (always?) happens so many hours after the scheduled update installation time? Q2: Is there any way to gobally prevent automatic reboots during office hours, i.e., to automatically delay an auto-reboot scheduled for between 08:00 and 18:00 to happen at 23:00 instead? 

Yes, On the file server: In "server manager", "roles", "file services", right click "manage shares and memory", "manage open files". You can do so also remotely if you run server manager elsewhere and right-click connect to a remote server. Normally, hardly anyboday besides an Administrator can do that and should not do so lightly (with great power comes great responsibility). 

Issue Are the names returned your two or four nsX.domain.com servers? Or are they name servers of your registrar/provider? For each name server from step 1 issue 

Apache looks for all the way down along a folder path as long as tells it to do so. So my recommendation is to have (in ) for the root directory and whatever only for the directory (tree) where you need it. 

A previously nicely functioning Remote Desktop Server Farm ahs stopped working two days ago. The setup is as follows: 

Possibly other variants exist as well. There is of course one important point: Don't shoot yourself in the foot! For example, 

Note: The fourth step disrupts connectivity from TEMPDNS to your 192.168.10.* LAN, but your remote session is stillworking because it is actually originating from TEMPAD in the 192.168.11.* LAN In step 6 the following magic happens (I hope): The machine asks its configured DNS server 192.168.10.2 (i.e., TEMPDNS) for the address of an AD server. It gets as a reply your original AD servers in 192.168.10.* and 192.168.11.200 (i.e., TEMPAD). Connection attempts to the 192.168.10.* AD servers fail, so ultimately 192.168.11.200 is tried (as I said, it may be better to avoid the attempts to connect 192.168.10.* by crippling the DNS on TEMPDNS). The connection to 192.168.11.200 succeeds: We have a working forward route 192.168.10.36 -> 192.168.10.1=TEMPDNS -> TEMPAD and backward rout TEMPAD -> 192.168.10.200=TEMPAD -> 192.168.10.36. Once all repairs have completed, don√Ñt forget to undo all the crap above. 

One of my users cannot work with RSS feeds. The problem was originally noticed with Outlook (where we get error 0x800C0008), but we can reproduce the problem with Internet Explorer 

The problem is that is the absolute path translated from the URL, that is, for $URL$ it may be something like (depending on how your web server is setup). I suggest you use pattern matching on the URL as in 

EDIT: I should have mentioned that a few clients were lucky and had not peoblems with the RDP farm: those who were still running Windows XP and its older RDP client ... 

That other dude got your links totally wrong cause is in fact the URL encoding of the UTF-8 encoded unicode codepoint U+200E (LEFT-TO-RIGHT MARK). To cath their link juice anyway, the following might work (note the flag): 

In the course of migrating our internal CA we first the old server up and running in order to allow clients to download the CRl from the URL hardcoded in already issued certificates. Meanwhile the old server has been removed completely and there is merely a little virtual webhost active with its name with the sole purpose of delivering the CRL to clients. I hope that this construct will become unnecessary when all old certificates are replaced (in a year or so). However, it would be nice to speed this process, e.g., by issuing new certificates ahead of time where applicable. To thius end, I would like to find out: When I see (from the web logs) a client retrieve the CRL, I can conclude that the client wanted to verify the validity of some (old) certificate. But how can I find out (not at the CA, but at the client maybe) which certificate the client wanted to verify? 

Question 2. Could any of these things cause this problem? Currently, we dropped the server farm completely, i.e., we only have "poor man's load balancing" via DNS round robin (and we especially miss the reconnect-to-previous-session feature of course) Main Question. How can I get my farm into working condition again? 

(This is an old question, but still deserves a reply) Apparently what you did was this: You prepared the new name servers to authoritatively answer quesirws for your domain. Then you switched registration (i.e., changed the NS entries for at the parent DNS servers responsible for to point to the new DNS servers); at the same moment the old name servers stopped replying to queries about (or replied with NXDOMAIN or something). As a consequence, the impact - especially for your main audience - was the following: After one 1hr, any data cached at DNS resolvers at Indian ISPs aged out - but only data for your entries, such as A records for . Hence the resolvers would try to query the appropriate name servers for fresh data. However, the info which server to query had not aged out yet: That info came from the zone and had a TTL of 48hrs (so probably still up to 47hrs, let's say 24hrs on average); as this refers to the now defunct DNS servers at the old provider, failures occur as you observed. On the other hand, querying a remote resolver would succeed as it would be unlikely to have a cached copy of the parent NS records. How to do it properly? The following strategies are possible (in decreasing order of preference): a) Ensure that the old DNS servers keep serving your zone for at least 48 hours after transition (the parent TTL), but not much longer. Actually, this is the method I have used most of the time; the old server admin just has to remember to remove the zones at a later date. b) Ensure that the old DNS servers at allow recursive queries (at least for your zone and at least for 48 hours); note that servers that are "official" DNS servers for some zone typically do not allow recursive queries c) Before moving zones, change your local TTL for all records to 96hrs, say. Then wait 48hrs before doing the move. This way, resolvers should typically have a copy of your DNS records in cache that survives longer than the obsoleting NS records. This method is not perfect and becomes problematic especially if there are "cross-references" between domains or if there are records that are queried less often than the main records. d) Alternatively, before moving zones decrease the parent TTL to 1hr (or to as much downtime as you deem acceptable), wait 48hrs and do the move. Howevre, it may not be possible to change the TTL to such a low value at the parent zone.(they don't want to be queried so often) and even if so, you'd have to consider their zone update schedules 

It's KB3002567. An update that soon after its release became known as "breaking RDP" - or in fact breaking everything. Ironically, a quick research after the first encounter of our problems had already revealed this (at least the RDP problems, as that's what we had googled for), so we marked KB3002567 (and a few other suspicious ones) for uninstall on our WSUS (cf. my optimistic remark to that end in the OP) and otherwise frozen update synchronization for the time being. What we failed to notice was that the Windows server 2003 version of this update considers itself as not uninstallable. Thus while we noticed during a test update how the patch got removed successfully e.g. from a Win2008 server, we thought that the removal has occured sucessfully as well on our AD servers (Win 2003) over night (as they begged for nothing, update-wise, on the next day). Since the probelm persisted, we assumed that the update had not been the problem after all (and indeed rdp was not totally broken - we managed to workaround the problem at the expense of user comfort). The Win 2012 version on the other hand was automatically uninstallable. As a consequence, it depended on which server was used for authentication whether RDP worked or didn't work. We wrongly concluded that server reboot made the previously "installed" problem appear - when in fact the reboot just happened to switch authentication server priorities. We also wrongly concluded that our AD migration tests were the cause of problems and demoted and removed the 2012 server, then starting to look for any problems this playing with AD might have had. Since the problem had steadily increased in intensity anyway, we were not too suspicious when we noticed that failure often had turned into failure always at the same day we got rid of the 2012 AD server (though the connection is obvious in hindsight). When our search kept coming up with the same useless suggestions (check that time diff between servers is less than 5 minutes - check, it's just fractions of seconds; check that all relevant group memberships are set - this really gets boring when doing it a second time; check DNS entries - there's really little in DNS that could have gotten wrong unnoticed; check that KB3002567 is not installed - hey, our WSUS took care of that, didn't it?) we began tearing our hair out. When then another hint towards KB3002567 appeared, we finally scanned through the list of installed updates on our Win2003 AD server (heck, that's really become simpler with modern OSes) to surprisingly still find it installed. Uninstall manually, reboot, everybody happy immediately! 

Is there any way for the users to update the login credentials with the second scenario above? Preferably, is there any way to configure the profile such that connection failure due to login failure makes the username/password dialog pop up, thus allowing the user to store the changed credentials? 

A subdirectory of an apache (ver. 2.2.22 on ubuntu 12.04) vhost webroot is a disk partition of its own. Accordingly, there is also . In my apache error logs I find errors that cannot be read, with a referer like (i.e. when a directory index of that dirctory is displayed to the user). 

This is not a DNS problem (although there is one problem: I get "... has no A record" instead of 204.232.175.78). What you observe with is caused by a http redirect (). 

I'm trying to modify registry entries within HKCU at logoff. The corresponding script works okay when invoked manually. I was afraid there might be issues with a loopback policy kicking in, but according to rsop.msc this is not the case, i.e. the script should be executed. However, the desired effect in the registry is not there upon next login. Is there a general problem simply because the script runs "too late"? If so what can be done? What else could this be? EDIT: I should have specified what my script looks like (minimalized): 

While it may be good for the interwebs as whole that all current versions make it difficult or even impossible to establish a https connection with a web server that supports only weak encryption suites, the needs of a system administrator may differ. Again and again I find myself in the situation that I need to configure systems (e.g., legacy appliances of all kinds) that I have not touched for years, and which can be configured by web interface, and which require , but none of my up-to-date browsers is willing to talk to that old-fashioned embedded webserver. Being in my own LAN, I'd be happy to use just for the moment, but that again is something the appliance rejects. Nowadays, even fiddling with in Firefox, say, seems not to help any more - not to mention the problem that one might accidentally forget to undo such a security change. Not everybody still has an XP box with IE6.0 somewhere in a dusty shelf just for this purpose, so the question is: Is there any method / software / practice / system configuration that is up to date in all respects except that it still allows (possibly with warning) even the most outdated encryptions and cipher suites (and at the same time doesn't make me shoot myself into my feet by being vulnerable in "normal" web access)? 

Sometimes it seemed also that they were simply rejected as if having entered wrong credentials (which they have not, most have saved their credentials) Question 1. Can you explain what is behind this, specifically regarding the "it could not be verified": How does this verification take place if it works? After all, the redirection would not even be attempteed if it were not initiated by broker ... What we tried: Sometimes it helped to replace the name the client connects to with something else (i.e., we added a name "foo" to DNS that resolved to the same IPs and had users connect to "foo"), but this was far from consistent. Later we noticed that always the same few servers appeared as "farmmemberX" in the above error message. We experimentally removed these from the farm (at the members themselves and in DNS) and were thus able to reduce the broken eight server farm to a functional two server farm. As this would not be sufficient tor out user load, I wanted to clone one of these; in order to do so I first shut it down and later restarted it - from which moment on it was as bad as the other six servers. Apparently restarting the RDP servers was the fatal thing to do ... According to the logs, this particular server had not been restarted for about two months. So virtually any change made in the last two months could be relevant. Among these are 

Also, i did not test any of these methods myself, I just came up with them and think they should work. 

I do see that I can't enable the Meltdown/Spectre mitigations in Windows Server 2008 R2 is a similar question, but I suppose that the environment differences may justify different remedies. After installing the Meltdown/Spectre related Windows updates and registry keys, and verifying that the relevant Vmware patch is installed (more precisely, ESXi550-201709101-SG is listed as "considered obsolete by the host", as is ESXi550-201709102-SG, but ESXi550-201709103-SG is installed). The Microsoft testing tool gives me only 

I'm playing with Windows 2012 DHCP server for IPv6. As with IPv4, the client network interfaces can be configured to either obtain an IPv6 address automatically, or use a statically configured address. However, what I observe is that even for those hosts where I configured a static IPv6 address, they additionally acquire a DHCP address. This is even the case for the DHCP server itself! How come? 

Everything works fine except when someone tries to retrieve In fact, what happens is that the client gets a reply with redirection to On the other hand, 

As you can see, I do use the farm name - but I still fail, with settings that worked yesterday. Changes are possibly updates and stuff, but nothing regarding configurations. How can I correct this misbehaviour? My only workaround currently is to provoke the above "myfarmname"/"farmmemberX" error and then try a connect to farmmemberX (which apparently is the currently preferred target) and then connect diretly to farmmemberX. 

So any mail that user sends will use as sender address; incoming mail addressed to either or will end up at that users mailbox; but where does come into play? So the questions I have are 

So, while the last check is suspiciuously short before the reboot, the last actual update took place yesterday (Forefront virus definition update, no reboot required). What can be the cause? What can be done to prevent? Please feel free to ask for more details. 

There is no specific entry in Apache error.log, but it seems that the problem occurs because the Auth requirement is evaluated before the Rewrite, thus invokes the ErrorDocument and that is wrongly still http?? 

plug it into a LAN with internet (or internal upstream WSUS) access and sync it. down and unplug it and carry it to the security lan connect it there and let clients update and report 

If your update is finally selected for installation, you will find additional entries in the windowsupdate.log 

Do they all return the same info (especially, serial number)? Finally, also check the name server entries published in 

DNS translates hostnames to IPs, there is no such thing as a different folder DNS-wise. The translation hostname (or more generally: URL) to folder must be done in your webserver configuration. This is called virtual hosting. (Some problems arise if you need https for several names)