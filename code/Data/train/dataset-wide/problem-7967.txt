The other case that I encountered was the polytope of fractional perfect matchings of a non-bipartite set with $2n$ elements. By contrast, the Birkhoff polytope is the case of a bipartite set with $n$ elements of each type. By definition, it is the polytope of non-negative weights assigned to the edges of the complete graph on $2n$ vertices, such that the total weight at each vertex is 1. Strictly speaking, the Birkhoff theorem is false; not every vertex is a perfect matching. Instead, all of the vertices are combinations of matched pairs, and odd cycles with weight $\frac12$. At first glance this looks like bad news for the application of computing a perfect matching or the optimum perfect matching of a graph. Indeed, if instead you take the convex hull of the perfect matchings, the result is a polytope with exponentially many facets. However, a good algorithm exists anyway; there is a version of the simplex algorithm that only ever uses polynomially many of the facets. 

From one point of view, the classification of finite non-commutative rings or even finite commutative rings is wild and tons of things can happen. From another point of view, finite rings are highly restricted and not all that much can happen. By the Chinese remainder theorem, every finite ring is unique direct sum of $p$-primary finite rings, i.e., rings whose cardinality is a power of some prime $p$. Such a ring is an algebra over $\mathbb{Z}/p^k$ for some $k$, and the finiteness condition is then equivalent to the statement that this algebra is Artinian and finitely generated. We can look at the case $k=1$ for a start, because then you get a finite-dimensional algebra over a field. Rings over $\mathbb{Z}/p^k$ for higher $k$ will look similar to these algebras. A finite-dimensional algebra has Jacobson radical and a maximal semisimple quotient if you quotient by that radical. By the theorems of Wedderburn and Artin-Wedderburn, the semisimple quotient is a direct sum of matrix algebras over a finite field. So that wraps up the semisimple examples. Let's suppose at the other end that the semisimple quotient is a finite field $\mathbb{F}_q$. Any such algebra is a finite-dimensional quotient of free polynomial algebra $\mathbb{F}_q\langle x, y, \ldots \rangle$. In fact it will be a quotient of the truncation defined by killing all monomials of degree $k$, for some $k$. Such a truncation is already an interesting example, e.g. the algebra spanned by $1,x,y,x^2,y^2,xy,yx$, with all larger monomials set to 0. The wild part of the classification is that a general quotient of this type can be very complicated, because it is defined by an ideal or a truncation in a very complicated position. (It is like cutting a riser pipe: The cut can be smooth or very jagged.) The general finite-dimensional algebra will be a combination of these various ideas. That is kind-of glib because you can get things like truncated path algebras, but it is true. 

Let us suppose that $x^{n}+y^{n}= z^{n}$ with $x, y,$ and $z$ relatively prime. By the abc-conjecture, $|x^{n}|\ll |xyz|^{1+\epsilon}$, $|y^{n}|\ll |xyz|^{1+\epsilon}$ and $|z^{n}|\ll |xyz|^{1+\epsilon}$. Therefore, $|xyz|^{n}\ll |xyz|^{3+\epsilon}$ which implies that, for $|xyz|>1$, $n$ is bounded. Unfortunately, this establishes only an asymptotic version of FLT. Nevertheless, if we had explicit information regarding the implied constant in the abc-conjecture, we could in principle determine explicit upper bounds for those $n$'s for which the abc-conjecture doesn't settle FLT. 

In page 21 of A Problem seminar, D. J. Newman presents a novel way (at least for me) to determine the expectation of a discrete random variable. He refers to this expression as the failure probability formula. His formula goes like this $f_{0}+f_{1}+f_{2}+\ldots$ where $f_{n}$ is the probability that the experiment fails to produce the desired outcome for $n$ steps. He goes on to outlining two ways to establish the validity of this formula, but I'm having a hard time to unravel his second proof. I'll insert it here in order for my inquiry to be self-contained: 

This "discussion" has to do with some of the material we can find in pages 183-186 of the translation into English of the first part of E. Landau's Vorlesungen über Zahlentheorie (published by the Chelsea Publishing Co. in 1966). 

The automorphism group of the symmetric group $S_n$ is (isomorphic to) $S_n$ when $n$ is different from $2$ or $6$. In fact, if $G$ is a complete group you can ascertain that $G \simeq \mathrm{Aut}(G)$. The reverse implication needn't hold, though. 

The relation used by Matiyasevich (Matijasevich, Матиясевич), the one to which N. Takenov alluded above/below, is the following: If $F_{n}^{2}|F_{m}$ then $F_{n}|m$ ...... (20) In the 1992 Fall issue of the Intelligencer there was a note by Matiyasevich where he explained, among other things, the importance of that relation on his work concerning Hilbert's tenth problem. Here you have an excerpt from that note: "It is not difficult to prove this remarkable property of Fibonacci numbers after it has been stated, but it seems that this beautiful fact was not discovered until 1969. My original proof of (20) was based on a theorem proved by the Soviet mathematician N. Vorob'ev in 1942 but published only in the third argumented (sic) edition of his popular book [on the Fibonacci sequence]... I studied the new edition of Vorob'ev book in the summer of 1969 and that theorem attracted my attention at once. I did not deduce (20) at that time, but after I read Julia Robinson's paper I immediately saw that Vorob'ev's theorem could be very useful. Julia Robinson did not see the third edition of Vorob'ev's book until she received a copy from me in 1970. Who can tell what would have happened if Vorob'ev had included his theorem in the first edition of his book? Perhaps, Hilbert's tenth problem would have been "unsolved" a decade earlier!" 

You first check that its roots lie in $\mathbb{F}_{2^n}$ by computing $X^{2^n}$ mod the polynomial $p(X)$ and checking that you get $X$. Then you want to know that the roots don't lie in a subfield, i.e., that $p(X)$ is irreducible. So for each maximal divisor $d$ of $n$, compute $\text{gcd}(p(X),X^{2^d}-X)$ and check that you get 1. Then you want to know that a root of $p$ has maximal order. So for each maximal divisor $d$ of $2^n-1$, check that $X^d$ mod $p(X)$ is not 1. The hardest step is to find the maximal divisors of $2^n-1$, which requires the prime factorization of $2^n-1$. If you don't know that, then you are probably sunk. 

Yeah, it's true. Since $\mathbb{Z}/q$ is a principal ideal ring, there is an extension of the Euclidean algorithm to matrices that puts any matrix in Smith normal form. It means that after an automorphism of $(\mathbb{Z}/q)^n$, any submodule $V$ can be put into a standard form in which it is generated by vectors of the form $d_k e_k$, where $e_k$ is a standard basis vector, $d_k$ is a divisor of $q$, and each $k$ only appears at most once. In that case you can check directly that $(V^\perp)^\perp$ is no larger than $V$. (I'm taking the question in the more interesting case in which $q$ might not be prime.) 

The easiest type of counterexample is a space that is not $T_1$, which means that there exist two points $x$ and $y$ such that every open set that contains $x$, also contains $y$. If that happens, then every sequence of points that converges to $y$, also converges to $x$. The most extreme case, as Konrad points out, is $X$ with the indiscrete topology. Then everything converges to everything. Examples that are not $T_1$ are valid but artificial. Given such a space, you can make a natural $T_1$ quotient using the closures of all of the points (even though these closures may be nested), and then ask the question again. An indisputably natural example which is also $T_1$ is the Zariski topology on $\mathbb{Q}^n$. In this topology, a set is closed when it is the solution set to a polynomial equation with rational coefficients. This is a poorly behaved topology, but it is widely used, and (in the version that I am using) points are closed. You can still make a sequence that converges to every point. Number the set of available polynomials $p_1, p_2, \ldots$, and then choose each point $\vec{x}_k$ such that $p_j(\vec{x}_k) \ne 0$ when $j < k$. The construction is also possible in the Zariski topology on $\mathbb{R}^n$, but it is trickier because the polynomials now have real coefficients and there are uncountably many. Nonetheless you can let $$\vec{x}_k = (k!,(k!)!,((k!)!)!, \ldots, \text{$k$ with $n$ factorials}).$$ 

P. Erdős and Leon Alaoglu proved in [1] that for every $\epsilon > 0$ the inequality $\phi(\sigma(n)) < \epsilon \cdot n$ holds for every $n \in \mathbb{N}$, except for a set of density $0$. C. L. mentioned in [2] that as a consequence of the previous result one can ascertain that $\displaystyle \lim_{n \to \infty} \frac{\phi(\sigma(n)) }{n} = 0.$ Does anybody know how it is that C. L. proceeded in order to arrive at such a conclusion? Clearly enough, the fact that an inequality of the type $a_{n} < \epsilon \cdot n$ holds for every $\epsilon > 0$ and a subset of $\mathbb{N}$ of density $1$ does not imply, in general, that the sequence $\displaystyle \frac{a_{n}}{n}$ goes to $0$ as $n \to \infty$. Hope you guys can shed some light on this inquiry of mine. Let me thank you in advance for your continued support. References [1] L. Alaoglu, P. Erdős: A conjecture in elementary number theory, Bull. Amer. Math. Soc. 50 (1944), 881-882. [2] Mathematical Reflections, Solutions Dept, Issue #3, 2009, page 23. 

The corresponding bibliographical details are: Yoshihito Morita, Elementary proofs of the commutativity of rings satisfying $x^{n}=x$. Mem. Defense Acad. 18 (1978), no. 1, 1–24. Does anybody here know if there is a retro-digitized copy of it somewhere on the internet? In the case that it is not available online but you happen to own a hard copy of the paper, would you be so kind as to share with me an electronic copy of it? Please, let me thank you in advance for the attentiveness of your replies. 

According to Wolfram Alpha and the tables in [2], $\pi(10^{10}) = 455, 052, 511$. Nevertheless, in Don Zagier's paper listed below we find that $\pi(10^{10}) = 455, 052, 512$. Wonder whether someone has already noted this discrepancy between the sources elsewhere. Naturally, the discrepancy implies the existence of a bug in either the routines of Zagier or in WA's implementation of the prime counting function. I don't think that it's only a typo in Zagier' note because, if my memory serves me right, there are some other texts in the literature that endorse the computations of Zagier (for instance, see [1, page 7].). References [1] A. E. Ingham. The distribution of prime numbers. Cambridge Mathematical Library, 1934 (Reissued in 1990). [2] H. Riesel. Prime Numbers and Computer Methods for Factorization. Birkhäuser, Second Edition, 1994. [3] D. Zagier. The first 50 million primes. Math. Intelligencer, 0 (1977). 

I can give you a negative answer and a kind of a positive answer to your question. First, similar to what Henry Cohn says, the conventional view of your construction is that it is a restatement of the factoring problem rather than a step to an algorithm. A function with a lot of oscillation is at first glance a function with high information content. So the fact that your setup is numerical rather than discrete doesn't necessarily help anything. In fact, standard numerical integration methods won't look all that different from trial division. Of course it is impossible to rule out some excellent special-purpose numerical integration method, especially because if you apply your transformation backwards, any factoring algorithm is such a special method. And in my opinion subexponential factoring algorithms are a little bit miraculous. You suggest setting up factoring as a 1-dimensional integration problem. But I know of very few numerical analysis algorithms that give a more-than-polynomial gain in speed over obvious algorithms in low dimensions. The main example that comes to mind is spectral methods for solving differential equations or integrals to high accuracy --- but that already starts to look like your construction in reverse. On the positive side, Shor's quantum algorithm for factoring does look a little bit like your oscillation picture. The algorithm does not look for an oscillation frequency that matches a factor of the number $n$. Instead, it computes the exponents of elements in $(\mathbb{Z}/n)^\times$, which is enough to factor $n$ when $n$ is odd. Using $a^x$ as a periodic function of $x$, it makes a vector $\psi$ in $L^2(\mathbb{Z})$ which is approximately periodic on a large scale with period the exponent of $a$. It then takes an approximate Fourier transform of this vector, and then measures a Fourier mode $k$ weighted according to the square amplitudes of the transform of $\psi$. So this is extracting information from oscillatory integrals! However, crucially, the integral is "computed" with quantum probability, in only the weak sense that a simulated random walk "computes" return probabilities. Quantum amplitudes are NOT stored numbers, they are probability-like state. So their approximate integration in quantum computation is very restricted. However, you have the exotic advantage of handling exponentially many amplitudes, just as randomized algorithms have probabilistic access to exponentially many possibilities. 

There is a simpler way to derive the result from the approach mentioned by K. Conrad. You can find it in the following 1997 note by Paul T. Bateman: Bateman, Paul T.: A theorem of Ingham implying that Dirichlet's L-functions have no zeros with real part one. L'Enseignement Mathématique. 43 (1997), 281-284. 

Curiously enough, the Wikipedia article adscribes the first complete proof of the theorem to Pietro Abbati Marescotti. 

I wonder whether any of you guys has already read the homonymous note by R. Beals in the December 2009 issue of the Monthly. If so, would you be so kind as to let me know about the main ideas in Beal's approach? As you know, the whole point of his note is to present a solution to the following exercise in Herstein's Topics in Algebra: Let G be an abelian group having subgroups of order m and n. Prove that G also possesses a subgroup of order lcm(m, n). The funny thing about this proposal is that in subsequent editions of his book, Prof. Yitz would proclaim that he himself didn't have a solution using the authorized tools. Besides, he even went on to saying: "I've had more correspondence about this problem than about any other point in the whole book.". Being aware of some of the history behind this little pearl, I'd really like to know what it is that Beals came up with. Is his approach crystal-clear? Is it somehow related to the standard attack of proving it first for the case gcd(m, n)=1? Thanks in advance for you insightful replies. P.S. The local library is the only access that I have to the literature. Unfortunately, they don't subscribe to any of the MAA periodicals. 

I'm trying to provide a full-fledged proof of the estimate $$\Psi(x,x^{1/u}) = x \, \rho(u)+ O\left(\frac{x}{\log x}\right) \qquad (*)$$ via the sly inductive approach commonly attributed to A. Granville. (For any $U\geq 0$ the formula holds uniformly for $u \in [0,U]$ and all $x\geq 2$; the $\rho$ in it denotes the Dickman function.) As many of you know, Prof. Granville begins his proof by noticing that $(*)$ holds for every $u \in(0,2]$ and every $x\geq 2$ and by assuming afterwards that it also holds for every $u \in (0,N]$ and every $x\geq 2$. Then, resorting to the Buchstab identity $$\Psi(x,y) = 1 + \sum_{p \leq y} \Psi \left(\frac{x}{p},p\right),$$ he obtains that $$\Psi(x, x^{1/u}) = \Psi(x,x^{1/N})- \sum_{x^{1/u}<p\leq x^{1/N}}\Psi\left(\frac{x}{p},p\right). \qquad (**)$$ At this point, the idea is to invoke the induction hypothesis and rewrite every term in the sum on the right-hand side of $(**)$. Given that $$p = \left(\frac{x}{p}\right)^{\log p / \log(x/p)},$$ it follows that if $p>x^{1/u}$ and $u \in (N,N+1]$, then $$\frac{\log(x/p)}{\log p} = \frac{\log x}{\log p}-1 < u-1 \leq N$$ and whence \begin{eqnarray*} \Psi(x,x^{1/u}) &=& x \, \rho(N) + O\left(\frac{x}{\log x}\right) - \sum_{x^{1/u}<p\leq x^{1/N}}\left[\frac{x}{p} \, \rho\left(\frac{\log x}{\log p}-1\right) + O\left(\frac{x/p}{\log(x/p)}\right)\right]\\ &=& x \, \rho(N) + O\left(\frac{x}{\log x}\right) + O\left(\frac{x}{\log x}\sum_{x^{1/u}<p\leq x^{1/N}} \frac{1}{p}\right) - x\sum_{x^{1/u}<p\leq x^{1/N}}\frac{1}{p} \, \rho\left(\frac{\log x}{\log p}-1\right)\\ &=& x \, \rho(N) + O\left(\frac{x}{\log x}\right) - x\sum_{x^{1/u}<p\leq x^{1/N}}\frac{1}{p} \, \rho\left(\frac{\log x}{\log p}-1\right).\\ \end{eqnarray*} Notice that in going from the next-to-last line to the last one, we resorted to the famed second theorem of F. Mertens. Having said all this, my question is the following one: