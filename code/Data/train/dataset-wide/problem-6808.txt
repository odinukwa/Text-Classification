A language is a complex system of communication, spoken or written, verbal or non-verbal. Actually, natural languages are spoken or signed: written language is an artificial creation made by man and this includes also systems like Braille (for blind people), etc. There are many languages that nowadays lack a written form. The idea that spoken language comes before written language is reinforced by two aspects: ontogenesis (single individual), humans learn to speak first and then they are taught how to write and philogenetics (human species), in human history, spoken language developed first as opposed to the written language that developed later. Language properties Some of the language properties are (some of these are translated from other resources so if you spot a mistake, just let me know): 

While chatting with a polish penpal, I've discovered that in Polish the expression for "good morning/good day/hello/good afternoon" varies if compared to the other Slavic languages; later I saw that also Belarusian has the same behavior: they both invert the structure of the expression, see the table below. 

1: As also Mark reminded me in the comments below this answer, the text is cohesive if Ali is a man. Since Ali is also a female's name, the text might lose its cohesion if the text talks about an "Ali = woman". 

Unfortunately this is not going to be a "here it is" type of answer, but I found some information that might be helpful in your research. First of all, apparently, even though interpreting is not a human activity that leaves many traces, the first mentions of such subject have been found in an hieroglyph that meant "interpreter" on some written material dated 3000 BC. I've tried searching for this kind of data but nothing turned up, only other articles repeating the same wording. For this reason, I tried another course of action and I searched Ancient Egyptian dictionaries. I found An Egyptian hieroglyphic dictionary by Sir E.A. Wallis Budge, which is freely available to the public for both online reading and download. The content is quite fascinating but if you search for "interpreter", two results will come up: 

I'm not sure but if I got it right you are asking about how to call a word that has multiple meanings. In that case, we're talking about polysemous words (as opposed to monosemous). In any case I don't see why the type of writing would affect how many meanings a word has. The various meanings are gained/lost through usage: speakers determine them by using the word in a certain context. The 30,000 words in English that you linked to are the words by frequency: English (as most languages) has much more words than that (almost obvious considering that. The exact number is pretty much impossible to determine the most obvious reason being the fact that the vocabulary corpus changes every day, but according to all the studies I've seen we're between ~140,000 and 1,000,000. I'm saying this because you compared what I think is the total count of words in Korean (let's assume it's more or less correct since you gave no reference) to the list by frequency in English. That's not a good comparison of course. You say that words with one meaning in Korean are the exception. That's a strong statement, as we don't have hard data to support that. To me it looks like monosemous words are less common (since language tends to re-use existing words a lot) but my judgement here might be biased. Yes, polysemy refers to words with more meanings, but it's different from homonymy. 

Since you specified about the TID1 in the comments, I made a search specifically about it. What I found is a paper titled "Aspects of Türk İşaret Dili" by Ulrike Zeshan, which analysis various features of the Turkish Sign language. In the paragraph "2.2 Types of nonmanual negation"2, the author address various ways of negating using methods that don't include hand signing: head movements and facial expressions. Concerning the second, which is what we're interested in there is something about the use of the mouth (emphasis mine): 

where we have 元気 (genki - health), です (desu - the copula) and か (particle indicating that this is a question), all preceded by お, the honorific o-. You could say 元気ですか (genki desu ka) and it would still be correct, however not appropriate for situations that require some formality. So, these are prefixes, however, addressing your other point, I wouldn't call honorifics — particles. Particles, when referring to the Japanese language, are a different category and I think you might create confusion in your listener if you called お- a particle. 

If a person is partially deaf, I think they would be able to acquire the language, and actually I've seen partially deaf people speak in addition to the use of a sign language. I suppose this means they can use that language when they think, is this correct? But what happens when someone is totally deaf? Hence my question: what language, if any, do deaf people use for their thoughts? And also, how is this determined? Update: Since this created some misunderstanding, my use of "if any" does not mean that Sign Languages are not languages or that I don't see them as such. I actually do. Rather, I meant to say that I was thinking that maybe totally deaf people could either use no language at all, just images or self-thinking or do like other people and use a mix of images/sign languages. And also how this had been determined. 

Person deixis: those that are used to refer to speaker and addressee (I, you, we); Place deixis: those that refer to spatial context (here, there); Time deixis: these that refer to temporal context (now, then, verb tense markers); Discourse deixis: those that refer to parts of unfolding discourse (next, below, furthermore); Social deixis: those that encode aspects of the social relationship between speaker and addressee (Her Majesty); Perceptual deixis: There's Harry. 

I think that some research has been done on artificial languages, but Linguistics mostly deals with natural languages and especially with spoken language. Written language is not totally excluded but sounds, sound shifts occur in spoken language, not to mention that this is where language evolves the fastest. It's true however that there are many aspects that Linguistics analyses such as Pragmatics, where you study how context contributes and also changes sometimes the meaning of an utterance, e.g. think about saying "Today the sun is shining" where today can apply to any day depending on when you say it. Or also "I sentence the accused to 5 years of prison", where the meaning (and action) changes if it's said by a judge or a friend. Also sociolinguistics (language and society), psycholinguistics (study about the biological and psychological factors that base acquisition, comprehension and use of language), neurolinguistics (interdisciplinary science between Linguistics, psycholinguistics, psychobiology, cognitive neuroscience and developmental psychology), and so on. They are all within Linguistics but you focus on certain aspects. I've never heard of Linguistics dealing with programming languages (as something to study), and I doubt they're relevant under that point of view.