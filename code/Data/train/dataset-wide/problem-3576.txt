1W is the limit at the transmitter, but higher EIRP amounts are allowed for certain kinds of antennae. A 6 dBi multipoint antenna connected to a 30dBm (1W) source yields 4W EIRP - which is within the legal limit. Much higher limits are specified for point-to-point setups. The question isn't so much the claim of 2W but rather where- and how- that 2W is measured. 

There are two basic scenarios- 1.) End host / stub network (i.e. edge of the internet) - These entities know that a packet is either delivered locally or is sent to a default gateway. This determination is made by the IP address of the transmitting device and its subnet mask. 2.) Router with full view/default-free - A router receiving full routes (generally via BGP) has a database of publicly routed subnets. Your 64.34.119.x network may be part of a larger summary route. The router in question finds the shortest match (i.e. longest subnet masks) between the destination of the packet and these locally received subnets. This route will have a corresponding next-hop - the next router to which the packet must be sent. This next-hop router performs the same look-up and forwarding, and so on, until the packet reaches a router with said subnet locally connected (most likely something like #1). Note that there is little or no knowledge of the intervening network(s) between the transmitter and the receiver. Each routing device knows only the next-hop to reach a given destination. 

The "show run int" shows the portion of the configuration in NVRAM that defines the actual interface. The second command (sh vlan) actually shows the live state of the VLAN's (nb - sh vlan id xxx for a single VLAN ID, if platform supports it) as actively kept in switch's database. One command shows the actual configuration, the other a portion of the running state. 

I'll second the requirement for management of DDoS upstream, but as an intermediate measure you might want to employ some kind of policing or shaping of connections at your own router or switch a hop or so before the servers in question. The best way to bounce back from the crash is not to crash in the first place. The router/firewall/switch isn't actually terminating the packets and is (hopefully) designed to run at a much higher rate. 

Here's the MIB - $URL$ I agree about using some kind of traffic generation but it might also be useful if you can borrow an actual hardware test set (i.e. Ixia or Spirent) to both allow you to see fine-grained results of any tuning you might want to do as well as demonstrating the relative benefits of REP vs traditional STP (for example). Using a SW-based traffic generator is most likely more than good enough, my suggestion is just to add a few decimals of accuracy. 

HSRP by itself is going to be limited in terms of what it can achieve. It's nominally just a mechanism to allow a pair of routers to share a virtual MAC/IP in active/passive configuration. In the event that the active dies, the passive router takes over. By definition it's only handling outbound traffic. It's possible to layer other solutions onto HSRP - so, for example, link tracking can be used so that the primary router drops its priority and allow the secondary to take over in the event that an upstream link (or route) is lost while both routers are still alive. To get to something approaching an HA solution you'd need to have some kind of mechanism on both routers that was actively checking the availability of the path between the router. Getting BGP routes from the upstream is certainly a start but ultimately if you can't demonstrate that traffic is actually passing you really don't know if you have connectivity. This would get you into scripting on the router, mechanisms of validating connectivity, etc. There are mechanisms within IOS / XE to do this (PfR and such) to allow you to put it together. Or, alternately, take a look at what's available with iWAN - which puts it all together (and some other useful stuff) to run over any combination of link types, etc. 

The only way that addresses would "hop around" would be if traffic were redirected out of a different NAT gateway / firewall. In most cases this would be the result of some kind of failure. The important part of all of this, however, is that when a UDP (or TCP) session is initiated from an internal (private) IP via a NAT gateway that the return traffic will come back to the outside address of said gateway and will be forwarded back to the initiating host. This maintains a consistent mapping of addresses for a given session. If traffic from a given session is shifted to a different external address then this session will break. 

Moving to transparent mode is a good thing. The transition is a pain, but ultimately you'll end up with a lot less risk. Change the clients to transparent first. Once in transparent mode confirm absolutely that the expected list of VLAN's remains (wait 5 minutes or so). I'd go so far as to suggest copying the VLAN definitions into a buffer to re-paste if necessary. Make sure the configuration is written to NVRAM!! Even running in transparent the VTP domains need to match. Don't change it. 

The included cable is likely DB9 to RJ45. While most Ethernet uses some variant of the RJ45 not everything that uses RJ45 is Ethernet (older digital PBX phones come to mind). Make sure of what you are plugging into - damage can occur (although it is uncommon). 

Look into the umask command. Set it as needed in /etc/profile and your users will, by default, create files with the privs specified. Depending on the FTP software you're using it also may be possible to set this behavior in its configuration file. If you haven't, I'd recommend taking a look at something like this which will encapsulate a lot of the capabilities you need while not necessarily requiring that your users have actual shell accounts. 

Use extended access lists. This will allow you to both insert entries into existing ACL's as well as remove entries without having to remove/re-add the entire list. So, for example: 

Flow control in the generic sense refers to mechanisms that allow for the increase or decrease of traffic across a given data link by a transmitter based on some kind of signal (implicit or explicit) captured from the receiver. Back in the days when serial communication was more common we used hardware flow control (RTS / CTS) to allow the endpoints on the serial link to signal when they were- or were not- capable of receiving data. A DCE (a modem, for example) might have buffers that could be overrun by the sending station. When this device passed a certain threshold of buffering, it would lower the appropriate signal line and the sending station would respond by pausing its data transfer until the DCE indicated that the immediate congestion issue had cleared. A similar mechanism was also implemented in-band (i.e. as part of the data being transmitted) known as XON/XOFF - same ideas as RTS/CTS but implemented as special control characters rather than dedicated hardware lines. More recently (~15 years ago, or so) similar mechanisms were introduced in Ethernet in the IEEE 802.3x standard. This introduced a so-called "pause" frame. As in the serial case, a given receiver can emit such a frame when it is unable to accept more traffic. This is a MAC-layer mechanism (i.e. layer 2) which is has been implemented in a fair number of devices but whose actual usage and deployment has been quite limited. The issue with 802.3x is that when a PAUSE frame is issued then all traffic is held, regardless of the importance of said traffic. More recently there have been newer standards (collectively known as DCB) that allow for more fine-grained controls (i.e. pausing traffic on a per CoS basis) as well as complimentary facilities to define different classes of traffic and how they map to these CoS values. Other examples of extensions to L2 networking for active flow control include buffer credits in Fibre Channel and the feedback mechanisms found in ATM ABR. True flow control isn't really applicable at layer 3, which is largely concerned with reachability and addressing. There are mechanisms at layer 4, however - notably TCP windowing - which allow senders to throttle back transmission based on network conditions. The operation and caveats of TCP windowing deserve their own question/post as there's a huge amount of literature on the subject. Another mechanism that has been specified but not extensively implemented/used for TCP is ECN (explicit congestion notification) which potentially allows a more proactive approach to throttling transmitter bandwidth (vs relying on packet drops for TCP windowing). In addition to strict flow control there are also mechanisms to shape, selectively drop and police traffic on a per-sender basis (i.e. L2 / L3 and some L4 QoS mechanisms) but these aren't precisely flow control, at least in the usual definition of the term. 

There are two connections made for an FTP session - control (port 21) and data (port 20). The normal behavior for FTP is for the client to connect to the server (again, port 21) and then the server opens the data connection back to the client. This breaks in a number of ways in environments using NAT, firewalls, etc. This traditional mode is known as active mode. Bear in mind that many commands that would seem like they'd be control traffic (i.e. listing a directory) actually require a working data connection. Passive mode (PASV) is when the client specifies which port to use. This, in turn, allows NAT (in various forms) to open up a session and allow for data to pass. You need a client (and server) capable of supporting passive FTP. It's all well explained here - $URL$ 

It's normal. IOS translates hostnames at the time of configuration and stores the resulting IP address. This is also true for setting ntp servers, aaa, etc. 

First, the basics - a socket is the 4-tuple of (srcip, srcport, dstip, dstport). If any of these values change, it's a different socket. When a given host opens a TCP (or UDP, for that matter) socket its source IP is already known, the source port is selected randomly from the ephemeral range (greater than either 1023 or 1024 - forget which) and the destination IP and port are supplied to the stack by the calling process. On the server side, a connection is set up and seen coming from the srcip and srcport given and bound to the dstport and dstip. This entry (again - some 4-tuple) is held in the host's connection table which will then allow incoming packets to be associated with the appropriate connection. TCP handshaking is the process by which the TCP stacks on the respective sides negotiate the parameters for sequence numbers, window sizes and such. By the time this occurs the port numbers have already been determined. Again - if any of the values in these tuples changes after the initial connection then, by definition, the packets are no longer associated with the original socket. There are certain circumstances in which other port numbers may be specified by the application in use (i.e. FTP, RPC) but in all cases this calls for the establishment of a separate socket, not the renumbering of an existing one. In the FTP case this would correspond to the initial connection on port 21 (control) from host -> server and then the subsequent connection on port 20 (data) - which, depending on the mode in use, may be set up in either direction. I can't emphasize enough, though, that this constitutes two separate sockets. Referring back to the OSI stack, this would very much be a layer-5 issue. 

CPU spikes of that magnitude are usually either some kind of spanning tree event (read: loop) or excessive traffic hitting the control plane (broadcast/multicast storms most commonly). Is the 4006 connected to any other downstream switches? Is there any possibility of that 4K being accidentally cross-connected to another switch? Are you graphing traffic on these switch ports? Look for radically higher traffic levels. TAC is going to also going to want to figure out what process is consuming all that CPU - what are the major consumers from ? Are you also seeing high CPU utilization on the 4K? Similarly, are there unusual syslogs around the times where you're seeing high CPU? Any changes (to the network or hosts) around the time this all began? At a simpler level, what's the port channel configurations look like on either side LACP? Static? Misconfiguration in this area might cause some problem behaviors. 

Yes - this is expected. You've hit a fairly common issue with NIC bonding to hosts, unicast flooding. As you've noted, the timers on your switch for the hardware addresses in question as no frames sourced from these addresses are being observed. Here are the general options- 1.) Longer address table timeouts. On a mixed L2/L3 switch the ARP and CAM timers should be close to one another (with the CAM timer running a few seconds longer). This recommendation stands regardless of the rest of the configuration. On the L2 switch the timers can generally be set longer without too many problems. That said, unless you disable the timers altogether you'll be back in the same situation eventually if there isn't some kind of traffic sourcing from those other addresses. 2.) You could hard-code the MAC addresses on the switches in question (all of the switches in the diagram, unfortunately). This is obviously not optimal for a number of reasons. 3.) Change the bonding mode on the Linux side to one that uses a common source MAC (i.e. 802.3ad / LACP). This has a lot of operational advantages if your switch supports it. 4.) Generate gratuitous arps via a cron job from each interface. You may need some dummy IP's on the various interfaces to prevent an oscillation condition (i.e. the host's IP cycles through the various hardware addresses). 5.) If it's a traffic issue, just go to 10GE! (sorry - had to throw that in there) The LACP route is probably the most common and supportable and the switches can likely be configured to balance inbound traffic to the server fairly evenly across the various links. Failing that I think the gratuitous arp option is going to be the easiest to integrate. 

Both machines (or any other multicast capable device) can be a sender, a receiver or both. So, yes, assuming the protocol is appropriate your receiving machine can use the same multicast group to respond to the source. 

The configuration is pretty straightforward, but two items pop out: 1.) Are you positive that your ISP has instructed you to lock speed/duplex? A mismatch in this area will cause major performance problems. 2.) If the interfaces are OK then try turning off rpf checking, replacing it with an ACL blocking traffic from your local network (really any RFC1918 addresses) inbound on your external interface. 

Short answer: Customer routes are neither known nor required for much of the network. For the points where they are known they are uniquely identified on a per customer basis. MPLS carriers (and individual private MPLS networks) do peer with one another, although that peering is much more ad-hoc than traditional IP BGP peering. Long answer: 1.) Customer addressing is irrelevant because after the PE/LER the carrier network only sees the labels on the packet. In fact, the packet itself doesn't even need to be IP - some significant portion of labeled traffic carries L2 bridging. This is the "multiprotocol" part of MPLS. One of the traditional design goals for MPLS carriers was the so-called "BGP-free core" - as P / LSR routers would literally need no knowledge of any addressing apart from how to switch labels from one interface to another, thus reducing the amount of network state actually carried in the core from potentially many hundreds of thousands to a few thousand. 2.) Within a typical MPLS network two labels are applied to a given packet - inner and outer. The outer label is what's used by the network to make forwarding decisions as the packet passes through the network. At each hop the label is evaluated, matched against a path defined earlier, the label is swapped with another and the packet is forwarded. This path is known as an LSP (label switched path) and can be configured in a number of ways. This is also the mechanism by which traffic engineering is accomplished (i.e. steering certain kinds of traffic by criteria other than a simple shortest path). The result of the LSP setup process is part of the routing tables maintained amongst the PE/LER boxes via multiprotocol BGP. 3a.) While two labels are typical, more labels can be applied to achieve other functions. In some cases an additional label may be present to help define more granular QoS policies (rare) or, in other cases, a third label can be applied when carrier networks are connected to one another. This situation is known as carrier-serving-carrier (CsC) where a large carrier might provide transit to a smaller carrier. Imagine carrier A operates primarily in a region in the continental US while carrier B has an international presence. Carrier A's customer wants to add a site in Hong Kong but carrier A does not want to extend its network all the way to HK for one customer. A may contract with B to carry its labeled frames (...from what would probably be the closest equivalent to an NNI) via a third label which would then be stripped when it was handed off to A's devices in HK - which would then strip the remaining labels upon arriving at the egress PE. This is most equivalent to a wholesale transit agreement. 3b.) In addition to the option of additional label imposition two carriers might set up a whole series of non-labeled connections which correspond to particular customer networks. As mentioned above, this might be a series of physical links (expensive), VLAN's or even PVC's on a F/R or ATM circuit. The best analogy here would be that the customer network exists independently in the two MPLS clouds apart from a point where the two are joined as traditional networks (i.e. no actual MPLS involved in the peering). This sort of gateway is probably the most typical, as it can mirror traditional peering infrastructure in useful ways. 3c.) It's possible for the carriers to actually share label space - allowing LSP's to be signaled across one another's networks. This requires the sharing of multiprotocol BGP routing information and, possibly, protocols for LSP setup (i.e. RSVP). This implies a great deal of information shared between the two providers. This probably most applicable when one carrier purchases another and wants to integrate networks. 3d.) The outer labels used by the LSP's described earlier are generally dynamically determined and are only locally significant (i.e. the label ID on one link can be the same as a number of others elsewhere in the network with no ill effect). It is possible, however, for these labels to manually defined. Two carriers may agree upon one or more common statically defined labels and then essentially pin them to interfaces that directly connect with an external entity. This is fairly labor intensive but is absolutely in use. 4.) The L3VPN service (RFC2547bis) calls for PE / LER devices to peer with one another via iBGP and that IP routing information from the customer be tagged in a specific manner so as to be uniquely identified. The PE / LER appends what is known as a route discriminator (RD) to each customer route. The RD is a 64-bit value that contains information about this customer and the particular edge router bringing traffic in. One common syntax is a customer's globally assigned ASN followed by a serial designator. The result is that the routes as shared between the PE/LER's are actually 96-bit (RD followed by IP prefix). This assures that -all- routes received from the customer (even duplicates to be used for load balancing) are preserved and in no way have any effect upon either other customers or the infrastructure itself.