It gives you a prioritized list of issues to check out that will impact performance. Around priority 240, you'll find a section on Wait Stats (around priority 240) that tell you what SQL Server has been waiting on. That's what I'd focus on first to figure out what metrics to examine more deeply. For example, if your biggest wait type is PAGEIOLATCH, that means you're waiting to read data pages from a data file - and the TempDB storage speed isn't really going to matter. (Don't worry, you don't have to know what those cryptic wait types mean - just click on the more-info links in the output.) If you'd like help from the Stack folks interpreting the results, you can also run it like this: 

Folks I see going in this direction tend to go with Amazon RDS or Microsoft Azure SQL DB. If you’re interested in reducing DBA costs, you’re also usually interested in reducing sysadmin and hardware costs, too. 

Asking one question here asking for ALL of the differences is a lot like me asking you, "Well, which features of SQL Server do you use?" It's such a tough question to answer because it's so huge (which is also why this question is likely to get closed, heh.) You'll be better off asking individual specific questions about each of the feature/edition restrictions that you don't understand. For example, if you want to know what "Advanced Adaptive Query Processing" is, read the documentation pages on Adaptive Query Processing, and then ask questions specific to that feature. In my experience, the features that usually cause folks to jump to Enterprise Edition are: 

I think what you're looking for is, "What are all the things I need to keep in mind when designing a data warehouse?" There's a lot of good resources out there on it: 

I’m going to reword your questions a little: Q: Should I log Agent jobs directly to a remote file server? No, because if you lose network connectivity or the file share goes down, your Agent job could fail. Your Agent job might not require network connectivity, like an update stats job, so that failure would suck. Q: If I want to centralize Agent job history, how should I do it? Consider logging to a table (and Ola’s scripts support this too.) That way you can centralize the data in whatever method you like, like replication or log shipping. I like logging to a DBA utility database, and then restoring that from all my servers to one central server daily. Then I use union all views to combine the data from all my servers. It’s not up to the second, though. 

Recovery model is changed by a specific ALTER DATABASE statement, and as far as I've seen, there's never been a bug that would change it. Some common sources of that statement include: 

Look at the file stats section, and focus on the physical writes. The SinceStartup data can be a little misleading since it also includes times when CHECKDB is running, and that can really hammer your TempDB. If your average write latency is over 3ms, then yes, you might have solid state storage in your SAN, but it's still not fast. Consider local SSDs for TempDB first. Good local SSDs (like Intel's PCIe NVMe cards, which are under $2k USD especially at the sizes you're describing) have extremely low latency, lower than you can achieve with shared storage. However, under virtualization, this comes with a drawback: you can't vMotion the guest from one host to another to react to load or to hardware issues. Consider a RAM drive last. There are two big gotchas with this approach: First, if you really do have heavy TempDB write activity, the change rate on memory may be so high that you won't be able to vMotion the guest from one host to another without everyone noticing. During vMotion, you have to copy the contents of RAM from one host to another. If it's really changing that fast, faster than you can copy it over your vMotion network, you can run into issues (especially if this box is involved with mirroring, AGs, or a failover cluster.) Second, RAM drives are software. In the load testing that I've done, I haven't been all that impressed with their speed under really heavy TempDB activity. If it's so heavy that an enterprise-grade SSD can't keep up, then you're going to be taxing the RAM drive software, too. You'll really want to load test this heavily before going live - try things like lots of simultaneous index rebuilds on different indexes, all using sort-in-tempdb. 

But be aware that it can produce some stunningly bad clustered index recommendations. The DTA isn't a replacement for basic data modeling for how to store your data. Generally, your clustered indexes should follow the SUN-E method: 

This is a known issue: mapping volumes on Macs isn't supported yet. You can follow that Github issue for more news, like when it's fixed. Until then, no, people aren't doing anything more than simple testing with that combination of tools (Mac, Docker, Linux, SQL Server). If you need to do real, productive development on a platform that's supported today, use: 

Sure, put a clustered index on it. Tables with a clustered index will automatically deallocate space. Otherwise, you're looking at: 

Then, when you get the list of roles, join to this table, and sort by ranking descending (or ascending, if you're looking for lowest privilege). 

Check Windows Event Viewer. Look in the application logs, security logs, and system logs. If you've nailed down all of the obvious stuff (and it sounds like you have), then it could be anything. The file's folder could have Windows domain security on it, and your machine might not be able to authenticate against the DC, for example. 

Yes, reading logs takes a long time in the log file viewer. A few things to fix it: Try using xp_readerrorlog with filtered parameters to get just the data you want: 

Then, in the top result set where it lists the indexes, look at the amount of LOB data stored on the table. If it's a lot, that's probably why compression isn't working. (And you can post a screenshot of the top result set in your question if you'd like more help/clarifications on this.) 

For sp_Blitz, there's an enhancement request filed at Github to add outputs for version, and if you'd like to influence how the work is done (or contribute code), you're welcome to leave comments over there. For sp_WhoIsActive, the author Adam Machanic is considering adding an output to the Messages tab each time it runs. Until then, Oreo's suggestion above of checking the code is the best one. We won't break that intentionally - we haven't changed those strings in years, and don't intend to start, heh. 

Not with the native tools. Thinking about it, I can see how somebody could write a tool to do it, but there's nothing off-the-shelf. 

Sure, start with my Learn SQL with the Stack Overflow Database. It's designed for you to demo with the Stack Overflow public data dump. (I just updated it today, coincidentally.) 

That'll take a 60-second sample of your waits. Post a screenshot of the wait stats section, and we may be able to explain what the server is waiting on. Update: your added screenshot shows 2 seconds of WRITELOG waits in the span of 60 seconds. Basically, your SQL Server just isn't waiting that much. My guess is that your simulated workload involves serial singleton activity: working on one row at a time, from just one thread in a load generation tool. That's not a great way to simulate workloads - you'll want to use a multi-threaded load generation tool, with lots of activity happening at once, and doing more than one row of activity at a time. 

When it comes to CPU core usage, Standard Edition starts with the first NUMA node. Whenever it exhausts the available licensing (2016 & newer, it's 4 sockets or 24 cores, whichever comes first - 2014 & prior, it's 4 sockets or 16 cores, whichever comes first), then it doesn't use the remaining cores. Here's the tricky part: if it exhausts licensing, and whole NUMA nodes remain with zero cores activated, then that entire NUMA node is offline - unusable for CPU work or memory. I've blogged about that in more detail here. You asked about memory, and I have a hunch (although I don't have a server handy to prove it) that it might work the same way. If the first NUMA node contains 128GB or more of memory, then that might be the vast majority of memory in use. It's a very rare edge case, and I wouldn't expect to see any guidance from Microsoft to confirm or deny this. (It's certainly not something they'd test as part of mainstream delivery - if you've got 384GB RAM, you'd wanna use Enterprise Edition instead.) I'm stretching to think about how you might disable this behavior, other than playing around with soft NUMA.