You're getting that error in the Exchange connectivity testing tool because the Network Solutions SSL certificate isn't trusted by default in Windows Mobile phones. The only ones that are trusted by default are: 

We have a Dell Poweredge 2970 with a PERC 6/i RAID controller. We have a one drive RAID 0 array (we wanted to add the drive as a JBOD but the PERC forces you to create an array to access it from the PERC). Can we take the one drive RAID 0 and move it to a new server (one that doesn't have a PERC)? Since there's only one drive in the "array" there's no striping going on...the only issue would seem to be if the PERC has some metadata on the drive that would prevent Windows from reading it. Does anyone have any experience with this scenario? 

Like a lot of people in IT I sit at a desk for 8-10hrs/day working on stuff that needs to get done "now". That usually means eating unhealthy lunches at my desk, and sometimes dinner too. This does terrible things to your health. I have been trying to work some exercise into the workday but I was thinking it would be great if I worked somewhere where I was exercising all the time (walking around, lifting servers, etc.). Does anyone have a job in IT (or know someone) where you are actually moving around (not sitting) doing something for most of the day? 

I just implemented a mail archiving solution for a client a few weeks ago. We went with a 3rd party called Smarsh. Their primary focus is the finance industry (Sarbanes-Oxley and the like). In this case you would have to switch to hosting your email on their servers since you don't have an onsite email server. Rates are around $15-20/user/month. Once you do, they automatically archive all incoming and outgoing emails. You can also upload employee emails to your online archive using PST files. You can find them here: $URL$ Alternatively you can host your own email server onsite and change your DNS/Email settings so that all incoming and outgoing emails go through Smarsh. You may want to do some comparison shopping by Google-ing "email archiving" and see the various companies out there. 

I have a problem which is driving me and a few clients on this server totally nuts. The problem is that PHP (or I guess Apache) seems to be crashing randomly and almost on a daily basis. The dedicated server I have is running Linux and Plesk 9.5 and has 1gb of ram and is only really running 5 websites which don't get a significant amount of traffic. I have gone through the httpd error_log as the web host suggested and I did find a bunch of issues being reported by php for each of the 5 wordpress 3.0 sites. Mainly related to missing php include files and things like that all which I ended up resolving. Unfortunately, none of the issue I fixed seem to have been related to apache crashing so my question to you guys here is what do I do next. Naturally I would like to know exactly why this is happening so I can not only resolve this problem right now but also know how to correctly diagnose a problem like this in the future. My web hosts solution was to just add more ram but although this "may" be the actual reason I can't believe these 5 sites are sucking so much ram. In any case I am just looking for the exact steps you experts would use to diagnose and resolve this. Additionally - Below I have included a few bullet points for other unresolved errors listed within my errors_log file as I don't know if any of this is helpful. 

If you rarely use the IPMI interface it's possible it's still using the default username/password ADMIN/ADMIN (case sensitive). 

We have a Dell Poweredge 1950 that came with Dell Rapid Rails. These are the tool-less mounting rails for 4 post square hole racks. We have some new Dell Poweredge R610s on the way. We were hoping to use the existing 1950 rails but it looks like Dell has a new type of rail for the 11G Poweredge series (yay) called the Ready Rail: $URL$ Does anyone know from first hand experience if the old Dell Rapid Rails work with the newer 11G servers? 

We have a Windows 2008 VM running IIS and SQL Server Express (it's an all-in-one web application). We need to have another copy at our secondary datacenter site. What is the best way to do this? It doesn't have to be running all the time but it has to have almost the latest copy of the current VM. I took a look at VMWare Fault Tolerance and after the heart attack at the price I starting looking for another solution. If need be I wouldn't mind copying it over to a cloud VM provider, if I can find one that lets me copy my own VMs up and start them up without any conversion process. 

We have a 2 node Exchange 2010 server setup with a DAG. I really didn't want to use Public Folders, but we need them for a legacy app. I created two public folder databases, one on each node because you can't make PF databases part of the DAG. They replicate to each other. Right now, I have one of the PF databases selected in the DAG as the default public folder database. It doesn't look like you can select a failover. My question is: Is there any way to load balance across these two PF databases? Or if I can't do that, can I set them up to failover automatically if one goes down? It looks like right now I can only have one PF database on one node in use at a time, and if that node goes down, public folders go down as well. 

I recently decided to include a great system stats plugins with every wordpress install. LINK: $URL$ One of the features of this plugin provides a tab where it analyses specific php/server settings and suggests changes. What I am curious about is what you expert feel are the correct settings for some errors its spitting out at me. These include: open_basedir Out of ALL php settings I seem to always run into issues with plugin installs and even file uploads or plugin installs whenever this is set to a value so I have always set this to "none". What I would like to know is what the ideal value is for this php directive and how important you guys think it is to set this to a value other than "none". As far as I am aware it limits the PHP process from accessing files outside of the specified directories. It is strongly suggested that you set open_basedir to your web site documents and shared libraries only. safe_mode Interestingly, I have always felt this setting to be set to "ON" for security reasons but interestingly, this plugin is saying that this feature is depreciated in PHP 5.3 and is removed in PHP 6.0. Relying on this feature is architecturally incorrect, as this should not be solved at the PHP level. What are you opinions on this? ServerSignature I have this set to "ON" and this plugin claims that by setting this to on it means that your server software version, and other important details are public, which can give hackers information necessary to exploit version and software-specific vulnerabilities. If I set this to off are you guys aware of any issues this might have? allow_url_fopen I currently have these set to ON but the suggestion is to disable allow_url_fopen for security reasons. How do you guys feel about this? Apparently with this set to on it allows PHP file functions, such as include, require, and file_get_contents(), to retrieve data from remote locations (Example: FTP, web site). According to PHP Security Consortium, a large number of code injection vulnerabilities are caused by the combination of enabling allow_url_fopen, and bad input filtering. mod_security I don't have this installed because I alway seem to run into some types of issues with it. What are your opinions on this? 

I usually go with GoDaddy certs for this reason (they purchased Valicert and their CA root awhile ago). That being said, iPhones do trust Network Solutions certs. Are you running Exchange 2003 SP2? iPhones need Exchange 2003 SP2 to sync. 

We currently host all of our clients in one datacenter. We would like to expand to two new datacenters by the end of the year. My job is to figure out how to extend our current network to those two locations. I have some basic designs drawn up (site to site VPNs between the datacenters, OSPF for internal routing, round-robin DNS to distribute the load), but I could really use some advice from someone who has done this before. My major concern is making a design choice that will constrain us or require a redesign in the future. We already have some design choices that will hamper us in the future (e.g. every client gets their own 10.x.x.x/24 subnet with their own VLAN, which will work great right up until our 4093rd client). Does anyone know some good resources on how to create a scalable network design? EDIT: Our business resembles VPS hosting, so as you can imagine, there's all types of traffic. Most of it is web (80,443) and mail though, so throughput is the usual priority followed by latency. The business reason we want to expand is so our clients can host their servers either on the East/West Coast US or South Pacific Asia. The IT reason is to give us a disaster recovery site in case of natural disaster. EDIT 2: Just to be clear I'm looking for resources on how to design the network. The details on how to do it (VPNs, routing, DNS, etc.) I can do.