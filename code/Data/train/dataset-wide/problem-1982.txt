The above answer from @kin is perfect. If at all you are looking for a script that you can use to backup your desired databases then use the below query. I have been using it to configure backup for Express Editions. Here is the query,i have edited the script accordingly, 

It depends on what your needs are. Re-organize is a light weighed operation ,generated lesser logs and always an Online operation. While rebuild is online only for the Enterprise edition of SQL Server and is more heavy operation. 

Database is a vital part of any application and is active all the time.This is why databases are often hosted in dedicated servers where nothing else can hamper the resource utilization for the database. Now coming to your question, there is no problem at all and SQL Server is working as expected. SQL Server is smart enough and caches as much as possible to make operations faster. There is a setting called MAX MEMORY SETTING that can be set to a value at which you want SQL Server NOT to use any further RAM. This is done after keeping aside the memory usage for the OS processes. 

There are few things to consider other than normalization. For instance, you have a column for AGE. Are you going to update that every year? How will you know when to do that? The same goes for years of experience. There are some columns that will probably have multiple values for each applicant: School, Course, etc. You may also want to check your optionality on those relationships. Right now an applicant must have a related exam, but an exam does not have to have an applicant associated with it. I'm guessing that's backwards to how things work in real life. You have similar issues with all the other relationships. It helps if you read out the relationships after you create them. 

It's difficult to give an answer without knowing what the columns are. If the table is properly designed (normalized properly), then having many columns isn't a bad thing. You can use views as suggested, or you can just select the columns that you need to see based on the reason you are doing a query. My guess, though, is that if we saw the columns, we'd find some cases of normalization issues since you already naturally want to see only part of them. That's just a guess, though, not a design rule or anything like that. 

For some reason, MS decided to deprecate the feature, but it still works. See the GROUP BY topic in the documentation. 

You should definitely use only BigFuzzyDB by fad software. There is no other database on the planet, or in the universe, that can process zetabytes of hipo-structured data at near light speed like BigFuzzyDB. Resistance is futile. It uses Heisen-SQL, it's kind of a hybrid of NoSQL and SQL (and none) at the same time, and you can never know which one it is. It has bit-fork-key-pair parallel memory resident indexes, so performance is off the charts. Don't use anything else but BigFuzzyDB! 

You are absolutely correct that if you design your data model and the resulting schema very well to begin with, it will already be in at least 3rd normal form. That said, I believe that it is crucial to understand the relational model, and the normalization rules as helping guides. When you say: 

Patch the passive node first. Move the resources to the passive node.(This will become active now) Patch the current passive node.(It was originally active). 

We have multiple instances on single node of the AlwaysOn setup, all are configured as AOAG. Right now we are connecting using the Listener\InstanceName. The listeners for each AG is having a dedicated port designated. This is why we cannot connect just by using the Listener without the port or InstanceName. I wanted to configure in such a way that just giving the AG_Listener would be enough to connect without using the port explicitly. 

The above will backup all databases in AG except UserDb. For more information please go through the Databases parameter in the below link Ola hellengren 

Other than Logins,Agent Jobs,Triggers and already mentioned points by Max, these 2 can also be looked upon. 

Try making the db to Multi-User from the GUI and not via script in query window.Also run sp_who2 and try to terminate the connection which is accessing the database now. Once the database is accessible to all users, it will not throw the error you have mentioned. 

You need to be looking at SET Operators. Something along the lines of the following query should do what you are looking for: 

Check out this article. I think it will answer your questions and give you the tools to deal with over-inflated number of auto-statistics. The author suggests dropping ALL auto-created stats occasionally, as the one that are required will be recreated when the first query that needs it is executed. It explains the risks / benefits. 

In a relational model every relation describes one 'thing' - the 'Fruits' table models fruits, fruits are not blends. Your Fruits table with a single column, is all key - 5NF. If you don't have a Fruits table, how will you insert a new fruit which has no blend yet? What happens to a fruit you have in stock, but its blend is removed? 

I was going through various articles on Missing indices and Unused Indices. Was wondering how having multiple indices which are un-used causes performance issues. 

This is how SQL Server works and there are limitations to make it perform better as the Page limit is 8KB for all versions of sql server. Pasting something from msdn that will be helpful : $URL$ Row-Overflow Data Exceeding 8 KB A table can contain a maximum of 8,060 bytes per row. In SQL Server 2008, this restriction is relaxed for tables that contain varchar, nvarchar, varbinary, sql_variant, or CLR user-defined type columns. The length of each one of these columns must still fall within the limit of 8,000 bytes; however, their combined widths can exceed the 8,060-byte limit. This applies to varchar, nvarchar, varbinary, sql_variant, or CLR user-defined type columns when they are created and modified, and also to when data is updated or inserted. 

If you have already created these entities/tables, there is a sample macro that comes with ER/Studio that does just this. You'll want to run this on a test model first as you may want to customize it to get the exact results you want. The sample macro is named ADD BASE ATTRIBUTES TO PERSON ENTITY. You, of course, will want it to work on all or selected entities. You could customize the macro to add these attributes based on the table being selected. If you want this to happen for new entities, you can create an entity/table that contains these common attributes/columns, then use that as a template. I have created a macro to create tables with all the properties I want to be common. The advantage to doing this is that macros can be tied to a hotkeys, making the creation of the new table easy. If you don't have the resources to mess with a macro, you could do the workaround of creating a new set of Domains (reusable attributes) in their own folder. Then you can at least quickly grab all 4 or so and drag them on to the tables. Still manual, but only once per table. So the answer you are looking for is dependent upon what the status of your model is currently. 

You concern yourself for nothing. "it's a bottleneck since of each row processing" is an assumption you make, and not necessarily what the optimizer will choose to do, even if it looks to you that you write it that way. SQL is a declarative language, and as such you tell the engine what you want done, and not how you want it done, like you do in imperative languages. The query optimizer, especially in SQL Server, is a mind blowing wizard in moving things around, considering alternatives, and understanding what it is that you want, regardless of how you write it. It doesn't get it 100% right, but it is damn good. Write your query, use several syntax like you did is never a bad idea, and test it against a representative data set. If you see performance challenges, examine the execution plan, or post it here so people can help you. HTH 

If you have already deleted the Imported Tables then you are fine. You will not be required to do anything else. This can happen and to get rid of this Use the Import/Export Wizard or Properly use the databasemame.Schema.Table. 

Now you need to remove the parameters : @CurrentDatabaseNameFS and UPPER(@CurrentBackupType). This will create all your backups to a single location as below 

Since the recent patch where TLS 1.0 was disabled and 1.1, 1.2 Enabled , we are having issues where the SSRS in the server cannot make connections to the Database server. 

I have a request to uninstall one of the test instance which is part of Always ON. I googled around for a clean decommission but did not find steps for Always ON Instance uninstallation. Would be great if Steps can be shared here or any link if you are aware of. As per me I would : 

All the proposed solutions using COUNT may prove to be inefficient as the aggregates will most likely need to be computed for the entire set, unless the optimizer will be able to push the predicate down. There is a more natural solution which IMHO is much clearer, and typically more efficient. It involves wording the question in negative form: 

You are using the 3rd normal form. A relation in 3NF, must also be in 2NF and 1NF. You are asking if you need tools to validate your design, which is something no one can answer. If you design a car, will you use available tools to validate that it is safe, fast, and reliable? or will you just trust that your original design achieved these goals without testing it with any tools? 

An added bonus, is that it also works around the COUNT issue you experienced earlier. Check the execution plans with large data sets, and you will see that this one is easy to index, and will typically perform better than the COUNT technique. The reason is that EXISTS doesn't need to complete the operation - once a row is found, the predicate is TRUE and there is no need to keep processing. With the COUNT, all aggregates have to be calculated. Hope that helps~!