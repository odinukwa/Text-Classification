Let $A \in \mathbb{R}^{n \times n}$ be a real nonsymmetric matrix with eigenvalues $\left\{\lambda_i : i=1..n\right\}$ with positive real part $\Re(\lambda_i) > 0$ $\forall i=1..n$ Let $A=U\Sigma V^T$ be the singular value decomposition of $A$ with singular values $\left\{\sigma_i : i=1..n\right\}$, $\sigma_i>0$. Let $\Sigma'$ be a diagonal matrix with a different set of singular values $\left\{\sigma_i' : i=1..n\right\}$, $\sigma_i'>0$ and let $\left\{\lambda_i' : i=1..n\right\}$ be the eigenvalues of $A'= U\Sigma' V^T$. Is there a set $\left\{\sigma_i' : i=1..n\right\}$ such that there is at least one $\lambda_i'$ with negative real part $\Re(\lambda_i) < 0$? 

Let $A \in \mathbb{R}^{n \times n}$ be nonsymmetric positive definite, if $A$ can be decomposed as $A = A_1 \oplus A_2$, where $A_1 \in \mathbb{R}^{p \times p}$ and $A_2 \in \mathbb{R}^{q \times q}$, $p+q=n$, it is known that \begin{align} W(A) = Co(W(A_1) \cup W(A_2)) \end{align} where $W(A) = \left\{\frac{(Av,v)}{(v,v)}, 0 \ne v \in \mathbb{C}^n \right\}$ is the numerical range anc $Co()$ is the convex hull. Is there a similar property for when $A = R_1^T A_1 R_1 + R_2^T A_2 R_2$ but $p + q > n$? $R_1:\mathbb{R}^n \rightarrow \mathbb{R}^p$ and $R_2:\mathbb{R}^n \rightarrow \mathbb{R}^q$ are orthogonal projections such that their ranges have a non null intersection and the union of their ranges is $\mathbb{R}^n$, i.e. $R_1 R_2 \ne \varnothing$, $R_2 R_1 \ne \varnothing$ and $R_1^TR_1 + R_2^T R_2$ has full rank. I know of $W(A) \subseteq W(R_1^T A_1 R_1) + W(R_2^T A_2 R_2)$ where the sum is element-wise. But I know that if $A_1$ has no kernel in $\mathbb{R}^p$ and $A_2$ has no kernel in $\mathbb{R}^q$, then $A$ has no kernel in $\mathbb{R}^n$, and this doesn't show up in the formula since $R_1^T A_1 R_1$ and $R_2^T A_2 R_2$ obviously have a kernel in $\mathbb{R}^n$. 

Expanding the solution in a Frobenius series $f_{\lambda}(x) = x^c \sum_{i=0}^{\infty} a_i x^i $ gives the indicial eq. $a_0 c (-1 + c) = 0$, which implies $c=0$ or $c=1$. The physical situation dictates that one should choose the $c=1$ solution. Now we are left with one solution for each $\lambda$ (i.e. the one which is regular at the origin). The problem is whether $\lambda$ should be continuous or discrete. To answer this we have to turn to the asymptotics of the ODE for large $x$. If one performs the substitution $f_{\lambda}(x) \rightarrow e^{-(a x+b x^2)/2} g_{\lambda}(x)$, one obtains \begin{eqnarray} g^{''}(x) &=& \left\{ \left[ \frac{k_0^2}{4 \sigma^2} (- 2 \alpha x + \eta)^2 +\frac{k_0 \alpha}{\sigma} \right] - \frac{1}{\sigma} \frac{(- 2 \alpha x + \eta)^2}{x}\lambda^2 \right\} g(x) \\ &&=\left[ q(x) + p(x) \lambda^2 \right] g(x) . \end{eqnarray} Note that for a given $\lambda$, for large enough $x$, $q(x) + p(x) \lambda^2 > 0$. I seem to find a theorem which says in this case the function ceases to oscillate. If this is the case, then it means the function either decays or explodes for large $x$. Indeed, the only special term seems to be the $1/x$-term in $p(x)$. For large $x$, try dropping this term. Then $q(x) + p(x) \lambda^2$ is just a quadratic polynomial of $x$, and the equation is nothing but the parabolic cylinder differential equation. It seems that one solution decays as $e^{-b/2 x^2}$ while the other blows up (as $e^{b/2 x^2}$?). Summing up, the solution that is regular at the origin may blow up at infinity for arbitrary $\lambda$, and it decays only for some (discrete) values of $\lambda$. In the completeness relation for the eigenfuntions, one should sum over discrete values of $\lambda$ rather than enforcing a continuous summation. May one compare the above system with the Hermite diff. eq. or Laguerre diff. eq.? 

Let $A \in \mathbb{R}^{n \times n}$ be a symmetric positive definite matrix, and let $B \in \mathbb{R}^{n \times n}$ be an arbitrary matrix. Define the numerical range or field of values of $B$ as \begin{align} W(B) = \left\{\frac{(Bv,v)}{(v,v)}, 0 \ne v \in \mathbb{C}^n \right\} \end{align} where $(\cdot,\cdot)$ is the euclidean inner product. Would the numerical range \begin{align} W_A(B) = \left\{\frac{(ABv,v)}{(Av,v)}, 0 \ne v \in \mathbb{C}^n \right\} \end{align} have all the same properties than $W(B)$ since the norms are equivalent? 

Let $A \in \mathbb{R}^{n \times n}$ be a nonsymmetric diagonally dominant matrix with $a_{ij} < 0$ $\forall i \ne j$ and $a_{ii}>0$. Let the singular value decomposition of $A$ be $A=U \Sigma V^T$ where the columns of $U$ and $V$ are noted $u_i$ and $v_i$ respectively. I can find the following lower bound for the trace of $U V^T$ \begin{align} tr(UV^T) \ge \frac{1}{2} \end{align} The question is: Is the bound sharp? Some simple experiments suggest a bound depending on the rank of $A$. Proof of $u_i^Tv_i > 0$ \begin{align} U \Sigma V^T =& A \\ U \Sigma =& A V \\ u_i \sigma_i =& A v_i \\ v_i^T u_i \sigma_i =& v_i^T A v_i \\ u_i^T v_i =& \frac{v_i^T A v_i}{\sigma_i} > 0 \end{align} Bound proof: \begin{align} \sum_i \sigma_i =& tr\left(\Sigma \right) = tr\left(U^T A V \right) = tr\left(V U^T A \right) = \sum_i \left(V U^T a_i \right)_i \le \sum_i \left\|V U^T a_i \right\|_2 \\ =& \sum_i \left\|a_i \right\|_2 \le \sum_i \sum_j \left|a_{ij} \right| \le 2 \sum_i a_{ii} = 2~tr\left(A\right) = 2~tr\left(\sum_i \sigma_i u_i v_i^T \right) \\ =& 2\sum_i \sigma_i u_i^ T v_i \le 2 \sqrt{\sum_i \sigma_i^2} \sqrt{\sum_i \left(u_i^ T v_i\right)^2} \le 2 \sum_i \sigma_i \sum_i u_i^T v_i = 2 \sum_i \sigma_i tr\left(U^T V\right) \end{align} 

Is it possible to ensure the normalisation (for the eigenfunctions), $\int_0^{\infty} dx \left[ (\beta - 2 \alpha x)^2 / x \right] e^{a x + b x^2} f_{\lambda_1}(x) f_{\lambda_2}(x) = \delta(\lambda_1 - \lambda_2)$, where $\delta(x)$ is the Dirac delta function? What is the asymptotic behaviour for $f_{\lambda}(x)$? (I expect the set of eigenfunctions to be complete; I suppose that $f_{\lambda}(x) / \sqrt{\rho(x)}$ should behave like sine waves for large $x$ (??), where $\rho(x)$ is the weight function, and thus expect $f_{\lambda}(x) \sim \left[ x / (\beta - 2 \alpha x)^2 \right]^{1/2} e^{-(a x + b x^2)/2} $. Is this correct?) How may one relate an eigenfunction satisfying the above normalisation (if the latter is possible at all) with the Frobenius series solution at the origin. For example, the regular solution $f^{0}_{\lambda}(x)$ at the origin goes as $x^c$, $c>0$. One may define the series solution to be $f^{0}_{\lambda}(x) = x^c g(\lambda, x)$, where $g(\lambda, 0) = 1$. How does it relate to the eigenfunction satisfying the delta-function normalisation? i.e. What is $N(\lambda)$ in $f_{\lambda}(x) = N(\lambda) f^{0}_{\lambda}(x)$? Does $N(\lambda)$ depend on $\lambda$ at all? 

Let $U \in \mathbb{R}^{n \times n}$ be a unitary matrix, $U$ can be nonsymmetric, its eigenvalues can be complex numbers and all have modulus $1$. Is there an upper bound for the maximum singular value of its skew symmetric part (which is not necessarily unitary) depending on its eigenvalues? i.e.: Is there an $f$ such that $\left\|\frac{U - U^T}{2} \right\|_2 = \sigma_\text{max}\left(\frac{U - U^T}{2}\right) \le f\left(\lambda_i\left(U\right)\right)$ ? More details: Observe that if $U=I$ (eigenvalues are real) $\Rightarrow \left\|\frac{U - U^T}{2} \right\|_2 = \sigma_\text{max}\left(\frac{U - U^T}{2}\right) = 0$, and if $U$ is skew-symmetric (eigenvalues purely imaginary) $\Rightarrow\left\|\frac{U - U^T}{2} \right\|_2 = \sigma_\text{max}\left(\frac{U - U^T}{2}\right) = 1$. Therefore there is a relationship between the norm $\left\|\frac{U - U^T}{2} \right\|_2 = \sigma_\text{max}\left(\frac{U - U^T}{2}\right)$ and the argument of the eigenvalues of $U$, i.e. $f\left(\lambda_i\left(U\right)\right) = f\left(\text{arg}(\lambda_i\left(U\right))\right)$. Further notes: in my work $U$ is the unitary factor of the polar decomposition of an M-matrix, but this may be irrelevant.