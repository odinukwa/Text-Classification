There are a number of articles describing why a is quite a bad idea when defined on top of ORM framework. Main reasons are leaked abstractions and abstraction on top of abstraction. And your example shows why - any optimization requires the knowledge of underlying implementation (Entity Framework). Running this process in multiple threads may help, but will put additional load on the database server and thus is not scalable. Note that Entity Framework's is not thread-safe, so you cannot share the in multiple threads unless you spin up a new per request there (which I wouldn't recommend doing). Assuming that you're using Entity Framework 6.0, method returns , you can try asynchronous implementation of the data retrieval: 

I would call this method or similar, since the main action here is actually capturing a timely-limited resource. Result of the method specifies whether resource has been acquired or not. You may also call it to highlight the fact that acquisition may fail. As a side note - you can rewrite the code without locks in case if that's the only place you use the . It will be a bit more verbose though... 

Note that you're using a separate thread (on a threadpool) each time you write something to log, so there will be contention between multiple threads if you write to log quickly enough. I would recommend using existing logging frameworks like NLog or log4net to avoid inventing a wheel. 

You have put too many responsibilities in a single interface and class. Your interface knows not only about graph itself, but also about all the possible methods of traversing this graph. It breaks Single-responsibility principle, Open/closed principle (as you'll have to edit if you want to add more search methods) and Interface segregation principle. What you should do is refactor your interface and implementation so that: 

To figure out what's slow in your code, you've got to profile it. Python make this easy with the package. I used this tool on your code and found that the was responsible for 88% of the run time. After thinking about it, this didn't surprise me. The way you build is very inefficient. Keep in mind the output of is a new array. So every loop iteration requires instantiating a new NumPy array and copying all the existing data into it. A better way is to pre-allocate the array with something like this: 

The last two functions just get rid of the column to get the output in the format you want. If you don't mind having the column there, you don't need them. 

Other It wasn't anything you did with that led to the gaps. That's the matplotlib default. If you want a "tight" border to the graph, try adding a before the . 

In IPython the result of the line profiler is displayed in a pseudo-popup "help" window. Here it is: 

I did actually time this version vs. the old version using the small test case in the OP, and there was an improvement, but it wasn't very dramatic. My untested guess is that my approach will be much more efficient as the problem size increases, if the density of links between knots is large. The caveat is that much larger amounts of memory will likely be required. (If instead there are a tremendous number of knots but relatively few links, Jaime's sparse approach might well be faster.) 

You could make the code forward-compatible with Python 3 by adding a at the top and using instead of . For consistency with most other regular Python functions, you might want to or something similar instead of when the search does not succeed. I'm only slightly joking when I say that Pythonic users might interpret a as meaning that the desired value was found at the end of the array! You don't use PEP8 style recommendations. and would be preferred names relative to and . 

: I think should not be doing this. When the object is created it should be initialized fully. So this line should be placed inside at the start of the part. : What if this call fails? Exceptions should be handled. There is a good chance that someone using this class may trigger file open failure because they may instantiate the same object from another object (constructor is allowing this). If you make low-level stuff easy to do, you should also provide for exception handling where things might go wrong. Files opened are not closed. In fact, it might be a good idea to open/close file handles using and methods, which need to be defined for this class. One of the things I find with file I/O is that users want control on the order in which messages are printed. The application may throw out stdout and stderr prints in a certain order and the user might want to preserve that order. Unfortunately, the current code flushes the queue of one pipe first before moving on to the next pipe. Users of this class might find this to be inadequate. In addition, users might want stdout and stderr to be redirected to files. This is not possible with the current class. It maybe okay now, but sooner or later someone will want this and they will start looking for alternatives. Just a thought: since a getter method is used for , perhaps you can consider a setter method as well. 

Since memory and performance metrics are similar, coding style is possibly the only differentiating factor. Nothing wrong with solution 1 but it takes more time to read it, unless you are paid by the number of lines you write! I guess it is Pythonic to write code in fewer lines so long as readability is not compromised. I prefer solution 3. It reads well and terse. Solution 2 is just as good but it appears to be doing extra work in the sense of creating a list and then counting. Why do that when you can directly sum up the matches? 

I've seen many attempts to abstract particular ORM from application, and all of them at a certain stage of maturity had to break this abstraction. One of the reasons for that is when you need to optimize certain use cases (like eager-loading related entities, or combining several round trips to server into one) you'll need to use ORM specifics that you're abstracting from. And another (more obvious) reason why I vote against abstracting ORMs from the code is that ORM is already an abstraction, so what you do is an abstraction on top of another abstraction that brings little benefits. There is a very good series of articles that describes best practices for managing NHibernate in ASP.NET: 

call is redundant in the , and you can directly convert to to save on memory allocations and transformations 

Not sure I would ever do smth like this for my own production, but here is the code that (IMHO) would clean things up... Implementation of MyListView: 

Filtering is actually done correctly, using the best and recommended approach. All LINQ queries are executed lazily, that is they are not executed until you start enumerating them. So all those calls actually just register additional filtering of the records which would translate to entries in the clause in SQL. One thing to notice - the call to method before is potentially ineffective because it forces the ordering to be done on the client side instead of SQL. I would rewrite it as 

As of code itself it is quite good, the only thing to note is that you can add a constraint on and just use . But as with all self-written DB access frameworks I would suggest to switch to mature ORM frameworks like Entity Framework or NHibernate (if you haven't worked with them previously Entity Framework would probably be easier for you). They have a well-developed environment, proper unit-of-work management, good querying and tuning capabilities. 

Since the function and the function are related by , i.e. , then iff you are OK with the weird approximation for , you should be able to work out a similar approximation for . You might be interested in the module, which provides a generalized capability to compute symbolic derivatives of most NumPy code. 

I didn't know about the option for . Very cool to learn! I like your graphs; the only improvement would be to plot the points and the curve on the same graph (i.e. combine the top panel and mid panel of the graph). Scipy's uses nonlinear least squares regression. In addition to comparing to the "local" results, you might also compare the NLSR results to the results of doing linear-regression on log-transformed data. 

Thanks for an interesting question. My review starts with your main interest -- speeding up what you've already got. It then goes to discuss a number of other topics you may be interested in. Speedup 

Since is a hard-coded variable, Python convention is that it should be in all-uppercase, i.e. is a better variable name. What are and in your code? It's hard to figure out what those variables mean. Could you be more descriptive with your naming? Your call to on is hidden after the very long sentence. For readability I wouldn't hide any function calls at the end of very long strings. Python has multi-line string support using the delimiters. Using it makes the sentence and the code more readable, although at the expense of introducing newline characters that would show up on the histogram if they are not removed. In my code below I use the delimiter and remove the characters I introduced to break the string into screen-width-sized chunks. PEP8 convention is that code lines shouldn't be more than about 80 characters long. You should consider breaking this code up into two functions, one to make generate the data, and one to make the graph, but we can leave that for another time. 

The code itself looks good, but I would look into providing a single way of subscribing to events, it will make the job easier for other developers reading and changing the code. The first method of subscribing (via injection) requires subscriber object to be created first, so it may not receive all events that you may expect it to receive. Every time you create an instance of subscriber it adds a new event subscription thus causing potential memory leaks and side effects. You might need to add method to if you prefer to leave it. Second method (the one I would prefer) is better suited for application-wide events since it moves the responsibility of subscription to the infrastructure thus avoiding multiple subscriptions and memory leaks (comparing to first option). It is also easier to unit-test since part of responsibilities are taken away from subscriber. Update based on question update: Publishing messages also looks good. In this case (following my suggestion to leave only second method of event subscription) I would remove method from declaration, and refactor it to non-generic interface with generic method . 

Having said that, assuming that you are using one of the high-level languages :) and you're developing a long-living solution I would actually recommend you to use one of the ORMs available for your language to interact with the database. It'll take a bit longer at the beginning, but you'll get a more flexible solution in a long term. 

I don't like custom ORMs and would suggest you to use Entity Framework or NHibernate as a data layer, but as an exercise here are the fixes I would apply (.NET 4.5): 

Your logic has a serious flaw: you expect that the consumer of the collection will iterate it till the end. In reality there are or keywords, and exceptions that will not follow your expected workflow, and thus you will be stuck with positive . Note that even moving to method won't help, as you cannot enforce the user of your collection to call it in case they iterate manually, without . I think the whole idea of working around this limitation (which was placed intentionally by the .NET team) is not very good. It would be good if you provide examples where you think you will benefit from a collection like this in separate code review posts, and community may suggest a better approach.