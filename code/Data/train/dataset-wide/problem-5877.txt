Is there a formal philosophy of related to the reconciliation of opposites? Is this simply a form of relativism? 

While most of us don't go around asking the big question "what is the self?" constantly, there's a case to be made that all kinds of autonomic functions are asking the type of questions Peters refers to on a continual basis, until we cease functioning. Which leads to my question: 

I've been thinking about this topic in relation to artificial consciousness. Specifically self-awareness. (I can define terms precisely if requested, but usually prefer to be as general as possible:) Essentially I'm defining this as asking the question "what is the self?" is a requirement of self-awareness. If the question can be definitively answered, there is no need to ask or contemplate the self. It's the process of asking the question that constitutes self-awareness. This relates to the Delphic maxim to "know thyself" and Socrates subsequent affirmation, but also to the Buddhist concept of impermanence, where an implication is that we're a product of change, and that which constitutes the self is never static. It was the concept of consciousness as a recursive function that got me thinking about it this, and it turns out this concept has been well defined: 

I understand uncertainty from a combinatorial and game theoretic perspective, as functions of incomplete or imperfect information, or intractability which is a type of inaccessible information in that the complete game tree cannot be expressed. This answer on quantum uncertainty was helpful because it raises what may be understood as computational issues. (For instance, running the game tree for Conway's Game of Life is indistinguishable to running the game--there is only a single node for each ply--and the only way to predict outcomes of novel, non-trivial starting configurations is to run the game. This condition may, among other things, be taken as a commentary on Laplace's demon.) Part of my question relates to recent interest in "quantum games", such as Quantum Tic-Tac-Toe and Quantum Chess. There is also a type of finite game that is initially intractable but "collapses" into a condition of tractability, which is to say from an indefinite to a definite state, for which the "critical mass", or threshold, is the recognition that the outcome may no longer be affected. (This threshold, notably, is subjective both for humans and automata;) In the paper On the Importance of being Quantum, Dr. Akl states: 

Great question. I don't want to wade evolution of religious ideas that lead to monotheism, which is quite an interesting subject, and worth looking into. Instead I'd direct you to set theory and the otological argument. Very compactly, the ontological argument states that God is "a being than which no greater can be conceived" (St. Anselm) and started a debate that's been quite vigorous for about 1000 years now. 

This is a very important question. In past eras, an educated person could have read the entire available literature in all fields. Now fields are so expanded, one generally needs to be very specialize to contribute or comment. (Although that doesn't stop most of us;) With that said, there are now scholars who call themselves "generalists", with the idea being to survey and entire field of knowledge, or several fields, instead of specializing in a single area. In terms of expansion of content to the point of meaninglessness, I'm not sure that's an issue, in and of itself, because there is a hard distinction between what is meaningful and what is not (as was reiterated to me the other day on Linguistics.) When you look at a field like mathematics, which has exploded in the past couple centuries, it can be daunting, but it's all based on the same general foundation. (It's more nuanced than that, but it's expedient to be reductionist in this case.) What I find astounding is how very complex concepts become common knowledge, or at least the foundations for those concepts. I was explaining the difference between Aleph-O and Aleph-1 to a ten year cousin the other day, and the child had no problem grasping it. It's possible algorithmic intelligence will facilitate navigation of the issue you raise. (Also possible they will preempt homo sapiens in this regard.) In terms of grappling with the infinite, you might find the issues of Computational Complexity Theory elucidating. In terms of being able to continue to make scientific advances, as far as I can see that is merely a problem of observation capability and tractability. 

What I'm getting at is there is a persistent trend in human politics to legislate based on feeling and belief, as opposed to the least biased interpretation of the the most robust data sets available. From a strictly game theoretic standpoint, this is a guaranteed losing strategy on aggregate. Yet even with the mathematics of optimal decision making well defined, there still seems to be widespread abuse of statistics to support pre-existing biases, beliefs and initiatives. (I won't get specific on issues, but many present problems are the results of previous abuse of statistics, such as projections of growth to fill budget gaps based on wishful thinking.) 

I apologize in advance, because I'm trying to get back up to speed in Philosophy, and may butcher terms and possibly, inadvertently for the most part, ask silly questions. I'm defining rational altruism in the context of Evolutionary Game Theory, where cooperation and sharing has an benefit to the individual in some way, as opposed to pure altruism, as in self-sacrifice. I'm very much in support of pure altruism, and this is merely to get a gauge on what the experts think at the moment. 

I can definitely interpret this in a game theoretic context, which unity relates to coalitions, liberty relates to partisanism, and charity relates to the superrational strategy. The justification for the first two strategies is based on available data, or lack thereof, but the third is an appeal to humanity, which binds us, regardless of political, economic, or ethnic divisions. 

Note: The beauty of the pessimistic filter is that, even if overpopulation leads to extinction of the species, an outcome that is not certain, it ultimately doesn't matter. The phenomenal universe as we know it is merely a temporary state between two extremes of entropy. 

fwiw my sense is the obsession with free will was/is related to religion. The idea that there has to be intentionality, otherwise eternal reward or punishment is meaningless. (Although I'm not sure if Calvin would agree...) But I treat it like the Chinese Room Experiment, which I counter with the "duck test" (if it looks like a duck, and quacks like a duck..., partly because in the CRE context, we're talking about personhood of hypothetical algorithms that appear to be sentient.) I'm don't see a meaningful distinction between the appearance of free will and the reality of free will. (It's a moot point--there's nothing you can do about it.) Our inability to answer the question definitively is a function of observational and analytic limitations. Where I see it having a negative effect is with individuals who take the idea of determinism as a rationale for non-responsibility. I'm tend to take a staunchly deterministic view, but I act as though I have free will, and accept the corresponding responsibility for my actions. However, the Free Will Theorem is definitely interesting, to the degree that I understand it, and I wouldn't be surprised that, if there is true choice, it originates at the quantum level. (At least that's what science seems to indicate, since that's the only place we're finding true randomness.) Why I posted what seems like a non answer Because, functionally, this seems like a non-issue. The reality we experience is a wildly chaotic system that can only be predicted to varying degrees. It may very well be an intractable problem, based on the physical limits of the system (speed of light/information, processing speed/analytic capacity, limits of observation/incomplete & imperfect information.) 

Part of what I'm trying to gauge is do we need to be thinking about random number generation for certain types of combinatorial problems? A quote lifted from Joe Fitzsimons in an answer to a question quantum indeterminacy on Theoretical Computer Science clarifies this point: 

Hesiod might say hope, which is a form of trust with no validation. Essentially, after Prometheus brings fire, Zeus, instead of invoking another cataclysm, devises a fate worse than death: Hope as the greatest mind game ever. But, like everything else, hope can be either good or bad, useful or futile. Likewise with trust. Fire itself, one of the greatest boons to mankind, can also be destructive. This seems to be the nature of things. 

For context, it is my suspicion that practical problems arise out of philosophy when it is too strictly implemented. (Possibly we would call this extremism.) In computer science terms, and exclusive or (XOR) in relation to philosophy is fraught. Examples: 

The pessimistic entry point challenges the idea promoted by the Gates Foundation that "every life has equal value", which is optimistic and therefore not rational. (Here rational is used in the sense of Game Theory as the rational strategy as opposed to the superrational strategy.) Clearly every life does not have equal value in the economic sense, and economic factors underlie all mechanisms of life from most simple organisms onward. ("Economic" is used in the broadest sense, not limited to human commerce.) If one were to stop here, there would be no rational basis for a pro-life position. Quite the opposite. Genetics tells us that diversity is beneficial. This is not philosophical but mathematical, based on analysis of data. Diversity, in the physical/ mathematical sense is "good". But 6 billion and rising is far in excess of what is needed to maintain a viable level of human genetic diversity. Thus genetic diversity alone is not sufficient. The benefit of diversity extends deeper in terms of the complexity of the universe, resulting in life, which is a combinatorial process. Here, the system is more than the rules of the system--the rules combined with the elements produce complex and unpredictable outcomes. Novelty is where every human life has true value, in that each individual has potential. (This is what the Gates Foundation is getting at with their superrational approach.) The rational strategy is about hedging one's bets to produce expected outcomes. The superrational strategy is about taking risks to in hopes of unexpected ("non--rational") outcomes. So while the vast majority of humans will never realize their potential in any remarkable way, and the degree of potential may have something to do with genes, one never knows who will be the next Einstein, Heisenberg, Von Neumann, Nash, Kant, etc. However, this supposes that anything humans do is inherently meaningful, which conflicts with the pessimistic filter. (i.e. actions are meaningful in context, but it goes no deeper than that.) Reducing it to the most basic form, one might adopt the viewpoint of an automata for which inherent meaning is not a concern. In this conception, that which is is desirable is the greatest possible dataset--the more robust the dataset, the more potentially fruitful the analysis. Novel data leads to novel insights, and each human life is a novel expression. Thus all life is valuable as raw data, and human life especially so because of the capacity of the human brain and complexity of the human mind.