I want to find all the objects referencing my object. I came up with this query, Is this the best way to get all references to an object? (I know this doesn't include constraints, I handle that separately) Direct References to Object 

I have to update several objects in many instances. In order to achieve that I am using DBMS_METADATA to create the DDL statements. So far I have the DDL statements and I save them in a TABLE. I would like to save said DDL statements in a .sql file for each object. I know I can do this with C#, but so far I have been able to achieve everything I needed to do with PL/SQL. Is there a way to create the .sql files with PL/SQL? 

(note: tool might be hidden in default debian/ubuntu setup. Look in to see it) When it's promoted, replication stops and slave is disconnected from primary. See relevant fragments on command in pg_ctl documentation and failover docs. Question 2 

Internal representation of larger attributes will be sometimes compressed. More specifically, what works here is the TOAST (Oversized Attribute Storage component used in PostgreSQL). The threshold when values are considered for compression is 2000 bytes. is not a logical length, but the size (in bytes) of actual internal representation of the column/variable. It is documented. PostgreSQL stores array values in a custom, internal, binary format. Command line example below. Details also here. 

When working with Oracle External procedures, what is the GCC version I should use to build my procedure? Does Oracle get shipped with a GCC version and libraries that it keeps in one of its own folders? Or the correct version to use is the one of Linux Server where Oracle is installed? If I do on a Linux computer, it gives me the GCC version, if I do that on the Linux Server with my Oracle installation, is that the version of GCC I should use to build my External Procedure? I am asking this because I have been building with the GCC version that indicates, but we are experiencing some weird issues that could be due to differences in the libraries' versions. 

To calculate TPS (transactions per second), run the query several times and calculate difference over time interval. There are ready made tools for that, one of them is $URL$ More info: $URL$ 

You do not need any triggers / rules to maintain it. There are open ends here - that's just a draft... Some issues: 

Exception blocks are meant for trapping errors, not checking conditions. In other words, if some condition can be handled at compile time, it should not be trapped as error but resolved by ordinary program logic. In Trapping Errors section of PL/PgSQL documentation you can find such tip: 

There is a lot of good sources on to partition or not to partition. If you are going to store 2 years and more, daily partitions could be optimal. But remember that very large number of partitions will make query planning longer. Threshold depends on CPU speed / queries used. PS. I assume that you ran out of normal ways to optimize: 

Also, on the internet, I have come across queries like the following. Direct and Indirect References to Object 

It seems there was some issue with TOAD. I opened TOAD after they granted me , yet it was like it did not take effect. I could query the table and see I had the role, I could myself the SELECT_CATALOG_ROLE, but when I called it did not work. Since I had open TOAD after the access had been granted, I didn't think that was the issue. At last, as a desperate measure, I tried closing everything and Opening it again and it worked. I was going to delete this question, but I guess it could be useful for someone else in the future. 

Notes on performance With small tables (less than 1000000 rows), any solution will work. is slightly faster: 

This answer assumes that you want to connect via TCP to localhost. (for local socket connection see Erwin's answer) Two options to ease your pain: 

I'm not yet sure if this is doable in pure SQL (probably - yes), but here is the brute force solution using cursors. This is just a (working) draft, with some twiddling and dynamic SQL you could add more parameterers, like function name. 

Make sure not only partitions are indexed, but also the master table is indexed in same way and ANALYZEd. This could make the planner include index-based estimates on a single partition, but ignore them on master table level. If expression index or statistics for master table is missing, the planner is not able to infer join cardinality from this condition - even if it has perfect statistics for partitions. It's just a guess because you did not provide full schema. Please let me know if this helps. 

I had first, and since it was throwing that error I granted myself . I checked against another Database Instance where the query works and I have the same roles, what else do I need to make work? Both databases are a clone from the same source database, and I later got the privileges granted. 

I am trying to fully understand the difference between ALL_OBJECTS and DBA_OBJECTS. I am still new in Oracle and get confused by the whole Access/Roles thing. From here: 

I know that PUBLIC_DEPENDENCY has only the objects and references Ids, and the DBA_DEPENDENCIES does not have the Ids, but the Type, Owner, Name, etc of them. But beyond that, what is the difference between both? When I do a count on my database, they return different values. And PUBLIC_DEPENDENCY has more elements. 

I understand that you want to go with single database (as it is good from management & maintenance point of view), but maybe it's too much integration. I am assuming that: 

Yes, it makes sense to materialize. The analysis of large datasets (see: OLAP, dimensional modeling) includes the concept of aggregations - which can be implemented as materialized views. You should design what aggregates will you keep. In my opinion you need at least two: 

In my opinion it is not related to or Windows issues. Per pg_basebackup docs, the main data directory will be placed in the target directory, but all other tablespaces will be placed in the same absolute path as they have on the server. 

I couldn't use the option suggested by BriteSponge because the value of the COLUMN Status in ALL_OBJECTS doesn't seem reliable. I could find a SYNONYM that had status VALID but the object it was pointing to didn't exist. The list of Objects I want to update is the OBJECTS_TO_UPDATE table. I could list all the synonyms from the OBJECTS_TO_UPDATE table that were pointing to an object that no longer existed with the following query: 

While working with some large scripts I encountered errors related with the 4000 character limit that VARCHAR2 has in SQL but not in PL/SQL. As explained here the VARCHAR2 datatype has a 4000 character limited, while the PL/SQL has a much larger limit of 32,767. Why does that difference exist? Wouldn't have been better to have both VARCHAR2 with the same limit? It seems a rather confusing and prone to error decision. Update I updated my question to add ansible's comment. Oracle VARCHAR2 and PL/SQL VARCHAR2 limit are on bytes, not in characters. This can have significant impact in multibyte characters system. 

Why async? I would avoid doing this in trigger due to locking issues under high load. Also, easy to DDOS so permissions should be separate for form insert and form create. 

All operating systems and all applications use a concept called "caching". It means - when the data is first read from a slow memory device (like, a hard disk), it is saved in a fast memory device (like, RAM) for some time, to facilitate faster lookups. The same applies to RDBMS. First time the data blocks that build up your query results are read from disk, second time they are read from memory. Details can be explored using OS and database tools. If you specify what RDBMS and what OS you are on, we can help you get the details. For PostgreSQL it's about EXPLAIN command. 

My question is, if you have DBA role, should ALL_OBJECTS be equal to DBA_OBJECTS? I have DBA role and in the Database I am working on and ALL_OBJECTS returns fewer elements than DBA_OBJECTS. If I have DBA Role shouldn't I have access to all the objects in DBA_OBJECTS and therefore both views should be equal? 

I wrote it with the subquery to make sure the object exists in the schema S1. I am certain exists, I can even look at it in TOAD Schema Browser. I have the following roles granted: 

However, if my understanding is correct, this query doesn't return direct references only, but also indirect dependencies. For example if I want the references for object_A. If object_B references it, and object_C referenced object_B. This query would return object_B and object_C as references to object_A. Am I right?