The Grassmannian and projective space are covered respectively by the open subfunctors $\textbf{Gr}(d,n)_I$ and $\Bbb{P}(\bigwedge\nolimits^{\!d} \mathcal{O}_{\operatorname{Spec} \Bbb{Z}}^{\oplus n})_I$. An endomorphism of a vector bundle $\varphi : \mathcal{E} \to \mathcal{E}$ is an isomorphism iff $\det \varphi$ is; 

Therefore to prove the proposition, we reduce to proving the following injectivity statement concerning Brauer groups: 

This may not directly answer your question. However, one reason to introduce the notion of an algebraic space is that sometimes it is easier to show that the diagonal is representable by an algebraic space than by a scheme. Consider the following example. Let $G$ be a smooth algebraic group over a field $k$. Consider the classifying stack BG that parametrizes principal bundles that are locally trivial in the fpqc topology. Since $G$ is smooth over a point, and smooth surjective morphisms \'{e}tale locally admit a section, we note that these bundles are a fortiori trivial in the \'{e}tale topology. Let $T$ be a scheme and suppose we have a morphism $$T \stackrel{(P_1, P_2)}{\longrightarrow} BG \times BG.$$ Here the $P_i$'s are two principal bundles over the scheme $T$. The fiber product $$T \times_{BG \times BG} BG \cong \underline{\operatorname{Isom}}_T(P_1, P_2)$$ where the right hand side is the functor of isomorphisms between $P_1$ and $P_2$. Now choose an \'{e}tale cover $T' \to T$ that trivializes both the $P_i$'s (for instance if $T_i \to T$ trivializes $P_i$ then we can just take $T' := T_1 \times_{T} T_2$). Hence $$\underline{\operatorname{Isom}}_T(P_1, P_2) \times_T T' \cong \underline{\operatorname{Isom}}_{T'}(G_{T'}, G_{T'}) \cong h_{G \times T'}.$$ This shows that the base change of the Isom functor by an \'{e}tale cover is a scheme, from which we conclude that Isom is an algebraic space. 

Official Report Number tends to stand for internal numbers assigned by the University or Research Institution for Technical Reports. For example, ATT Bell Labs often published their internal research documents as Technical Reports, and the Computer Science department at M.I.T. also tends to publish internal research findings, often supported by government sources or sponsored-research funded by corportations, as "white papers" or technical reports. MIT's library is pretty good at finding these things: $URL$ and their webpage defines technical reports as What is a technical report? Technical reports: 

Fourier transforms depend upon the fact that the modeled signal are going to be infinite in time-span and time-extent. While it is possible to get a very good example of a time-limited signal by using a finite set of Fourier coefficients, the finite-fourier-coefficient-approximation always ends up with "ringing artefacts" at any high-frequency edges beyond the bandwidth-limited approximation. These artifacts arise from the fact that Fourier decomposition using the "infinite-time-extent" sine-wave as its base-component. This type of problem in representing "limited-time-span" signals is what led to the concepts of "wavelets" and wavelet-transforms, using such limited-time-span base components such as the Haar wavelet. This is a slightly different problem from having non-equally-spaced-in-time samples extracted from a time series, but even then in these cases, there is the assumption that the underlying time series is continuous over time or is composed of the superposition of multiple discrete events occuring as Bernoulli or Poisson processes over time with some convolution of the discrete events by a smoothing factor (volcano eruption or geyser spouting, with the effluent "smoothed out" by prevailing winds or water currents). 

Let $G=(V,E)$ be a finite graph and let $f$ be any positive function defined on the vertices. Put weights on the vertices $v_{i}$, way $w_{i}$ so that $\sum_{i=1}^{n}w_{i}\leq 1$. Assume that every independent set of vertices, say $I$, satisfies $\sum_{v_i\in I}w_{i}\leq 1/2$. I would like to maximize over all choices of the weights the following expression (the average of f):$\\$ $$\sum_{i=1}^{n}f(v_i)w_{i}.\\$$ Question: is it true, that at least one global maximum is achieved by either i) putting weights $1/2$ on a pair of two neighboring vertices or ii) putting a weight $1/2$ on one vertex and $0$ on all of the others? Remark: the second situation can arise, for example, in the case $G$ is the empty graph and the value of $f$ at one vertex is strictly larger than on the other vertices. 

To prove this, write $K$ as a direct limit of smooth $k$-algebras. Since cohomology commutes with direct limits for qcqs schemes, if a (cohomological) Brauer class $\alpha$ in $H^2(X,\mathbf{G}_m)$ dies in $H^2(X_K,\mathbf{G}_m)$ it must die in $H^2(X_R, \mathbf{G}_m)$ for some smooth $k$-algebra $R$. By smoothness and using that $k$ is separably closed, $\operatorname{Spec} R$ has a $k$-rational point. Therefore the canonical map $f: X_{R} \to X$ has a section $g$ and so on cohomology the composition $$H^2(X,\mathbf{G}_m) \stackrel{f^\ast}{\to} H^2(X_R,\mathbf{G}_m) \stackrel{g^\ast}{\to} H^2(X,\mathbf{G}_m)$$ is the identity. We conclude that $\alpha = 0$ as desired. Finally we remark that in the injectivity statement on Brauer groups, only the ground field is required to be separably closed. There is no requirement on $K$, only that $K/k$ be separable. Edit: The proof also shows that for any \'{e}tale sheaf $\mathscr{F}$ on $X$ such that multiplication by $n$ is surjectve, then $$\frac{H^i(X,\mathscr{F})}{nH^i(X,\mathscr{F})} \to \frac{H^i(X_K,\mathscr{F})}{nH^i(X_K,\mathscr{F})} $$ is an isomorphism for all $i \geq 1$. 

For the example distance matrix which you have given, setting the threshold $20 \le d \lt 40$ will give you what looks like a correct result. Setting $d$ too low results in more isolated components to the graph, setting $d$ too high leads to larger components. 

Might I also point out the unstated assumptions in your question and in the fine answers thus far by Bill Thurston and Sergei Ivanov? The unstated assumption is that we are speaking about opaque objects casting opaque shadows, and that all of the information content we obtain is merely in the outer boundary / envelope of the shadow, whether we are talking about a line segment in $\mathbb{R}$ projected by an object in $\mathbb{R}^2$, a 2-dimensional shadow in $\mathbb{R}^2$ cast by an object in $\mathbb{R}^3$, or by a 3-d shadow cast onto $\mathbb{R}^3$ by an object in $\mathbb{R}^4$, etc. If we start talking about allowing for transparent and translucent objects which pass (or scatter) graded amounts of light based on their local density distribution, we can allow for non-constant shadows. These non-constant shadow projections can allow the observor to use many different algorithms to infer the interior distribution density function of the shadow-casting object. This type of shadow analysis is used in Computerized Axial Tomography, also known as CAT scanning or CT scanning. Multiple 2-d images are acquired as an x-ray receiver (CCD) is rotated around the object to be probed while an x-ray source is also rotated around the object synchronously at a position on the opposite side of the object. The multiple acquired 2-d shadows of X-rays passing through the body can be used to reconstruct a fairly accurate rendition of the density distribution of the body using a Radon transform. Prior to the axial rotation type of scanning, a linear type of scanning was used in a technique called Tomography. The subject is placed at the origin in 3-space, a single piece of x-ray film is placed at position ($-x$, $+y$, 0) at time $t_0$ in the $xz$ plane and translated to position ($+x$, $+y$, 0) at time $t_1$. The x-ray source is placed at position ($+x$, $-y$, 0) at time $t_0$ and is translated to position ($-x$,$-y$,0) at time $t_1$. This is akin to taking a photograph with a long exposure time, keeping it pointed at one point in space as the camera moves along a path in space. The resulting photographic image will have the sharpest focus at the "focal plane" $y=0$, while the objects at further distances along the $y$-axis from the $x$-axis will be progressively blurred. There is a lot of very interesting mathematics involved in the signal acquisition and signal analysis of Axial Tomography and in the image reconstruction algorithms, as well as in MRI (magnetic resonance imaging). Also, as an aside, no one has specified whether the "light sources" casting the shadows are point sources in the near-field at a particular distance $d$ within a few orders of magnitude of the size of the objects, or whether we are assuming that the light source is effectively a point source at infinity casting isometric projections. Also, the specific region receiving the shadow was not clearly defined. I only mention this because of the recent questions on Mathoverflow concerning the importance of rigour in mathematics, and because I do indeed believe in the importance of rigour in the formulation of the questions and, thus, in defining the restricted domains in which the succeeding mathematical calculations can be applied. Allowing for non-opaque shadows makes it much more difficult to find another object in $\mathbb{R}^3$ whose projected shadow would match the intensity distribution of the projected shadow of a translucent sphere. 

If $p_i$ are all bounded away from $0$ and $1$ independently of $i$ and $n$ then, of course, the maximum is at most $C/\sqrt{n}$, where $C$ depends on how far the $p_i$'s are from $0$. Are there bounds that are good when the $p_i$'s are non homogeneous? Like, say, $p_i=1/i$ or even $p_i=c/n$? Are there any precise results known? Then is, can one in general obtain the exact result in some key situations? Say $p_i=1/2$? 

Let us say have a sequence of $n$ 2-$D$ random variables $X_i=(\varepsilon_i/\sqrt{n},i\varepsilon_{i}\sqrt{6}/n^{3/2})$, where $\varepsilon_{i}$ are independent random variables such that $\mathbb{P}(\varepsilon_i =\pm 1)=1/2$. Denote by $S_n$ their sum and take a $2$-dimensional Gaussian random variable $Z$ with the same covariance matrix as $S_n$. Any standard Berry-Esseen theorem (say by Gotze or Bhachattarya or Bentkus) gives us that for any convex set $C$ we have \begin{equation} |\mathbb{P}(S_n\in C)-\mathbb{P}(Z\in C)|\leq c\gamma, \end{equation} where gamma is the sum of third absolute moments of $X_i$, which in this case behaves like $n^{-1/2}$. Question: is there a standard way to pass from the distance between distribution functions to expectations of Lipschitz functions? That is, suppose $f$ is Lipschitz, can we still bound \begin{equation} |\mathbb{E}f(S_n)-\mathbb{E}f(Z)| \end{equation} in therms of $\gamma$? If so, does the same bound of magnitude $\gamma$ still apply? 

The best answer is distance threshold. Look at the problem as defining an undirected graph based on a given distance matrix and trying to create subcomponents of the graph by selectively deleting edges based on the weight of each edge as defined by the distance. If you make the assumption that the underlying metric space (which you have not clearly defined in this case) is Euclidean (linear and therefore homogeneous throughout, I believe), then one simple way of creating subsets of your elements from the distance matrix which you have available is the following. (edit: No assumtion of homogeneity of the underlying metric space is actually required for this approach of selectively deleting edges.)