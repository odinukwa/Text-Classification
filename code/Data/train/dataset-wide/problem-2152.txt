It will not lock master (in case of InnoDB tables) and automatically adjust Slave to Master position 

and leave all other default, than enable slow query logs, and collect query statistics and from query logs and using other tools: 

I suggest look at Percona Innobackupex - $URL$ It also possible run from slave (best if replication format ROW). One more variant fastest from any other than LVM: 

You need check - configuration of server, memory for InnoDB, for FullText compare size of index and FT buffer size, by default it only 8Mb, max value is 80Mb Than next step and profile query - how many records returned, what time of intialyze of index and upgrade 5.6.4 to something more new in 5.6.4 FullText was only implement for InnoDB, many bugs fixed from that time 

even if it after WHERE return just few rows, but server will operate with huge size of data. Solution - split table for: 

as You can see from text of both commands - they not work with data other than single table, so from this point of view - both safe. In worst case - You already have not worked views and continue have them :), but it not expected result. But, in any case - the best practice - make backup before any kind of similar operations, so You always can rollback. Notice in server documentation: 

source - $URL$ and not a lot of ways for optimise queries over it there are few recommendations (very standard for any queries) $URL$ recommendations is really standard and in Your case - with count(*) not help. 

SET portion - is dummy, just for illustration, You need replace it for real procedure logic The logic will proper work with many numeric or dates - simple increment by numeric or date time interval. with tables where PK - combined from different columns without any visible logic, like telecom tables - (prefix, context, priority) it also possible, but little more complicated. 

If You need MySQL 5.7 and not sure with command line - just use installer from Oracle, it do all for You. If version not very important - as suggested use XAMP, most of them use MySQL 5.5 

So, before use index for fk_space_id, MySQL will read ENVIRONMENTS first and there You have only 1 filter condition: 

Server just compare client IP with permission tables and allow or reject access. I do not know method how to tell mysql client (including library to use dedicated outgoing ip). what You can do: 

If You check used indexes, You can see - PL_ProductCategoryId have cardinality 17, it mean it has +- 17 possible values for all table rows. It is very close to full-scan, client_id included in 2 indexes, both time as second part. You can change index PL_SkuName_ClientId - just swap them (client_id, sky_id), or create new index for client_id only. 

Add some visual examples: make a proper test it very hard, but this is small example: was created 3 tables, with only 1 column ID - primary key 

because You are already have dump file - no reason discuss about single transaction or group transactions. 

It possible in theory with ROW binary logs, in this case each changes of tables will be write to the Log. at this moment several companies declare this solution (plus many on GitHub): 

When You SELECT data - You are work with InnoDB memory cache, You not write to disk, You are not log operations. It is normal when same select thousands time faster then DELETE. When You run DELETE command, MySQL must: 

it can reduce replication lags than if the problem not in log-size, but as well because MySQL slave processes single threaded You can test use feature for multi thread slave, it increase speed of apply transactions on the slave server - $URL$ Before this 2 changes on one of my clients, slave server replication lag was always couple of hours in period of high loading hours, after - 0 

more related to other types of manipulation, like - manual edit of BLOB object with text or parameters, but change definer - it just change single column. 

Full list of steps very depends - what OS (source and target)? Generally You can copy mysql between 100% similar computers, but You are must copy ALL folders and after - or start mysql manually or manually add MySQL to run as Windows / Linux service. More easy ways: 

Looking on Your pictures, I can guess - for run subquery You also use MySQLWorkbench. Most of software - not return to You back all rows from dataset, by default it filter up to 1000 records (some less) So select without ORDER BY start work and immediately stop after first XXX rows. In case of create table: 

in case of Slave, ROW based replication - highly recommended. In case of mixed or statement based replication, You must be sure not have opened temporary tables on Slave, or replication will be broken, with ROW based replication - temporary tables not involved in replication process. Of course - same version of MySQL on all machines 

Yes - Microsoft Trial Tools not use activation keys, and start trial period from date of installing Developer Edition include All functions of MS SQL Server and restricted for use in production environment 

manual file level import/export could be useful in production environment where You need automate processes, but also for now it is more backup way, primary and proper - ETL scripts and tools. 

this is really bad practice with applications, exactly because - if You add new column, some of Your code could be broken. For example: 

Single huge file now must not be a problem with most of OS, but could be difficult for edit. In second case, need analyse merging logic simples way - mysqldump with --no-create-info (not CREATE TABLE), but could be problems with duplicate keys. If some duplicate keys (indexes): or edit dump (for big files - use sed) and change insert to INSERT IGNORE or UPDATE ON DUPLICATE or create ETL Job with any of available package and manage merge logic. 

It is possible to create views on Slave without collisions with replication, but ... but feature unpredictable and IT just try to avoid any potentials issues, and they are right. 

To main reasons - optimisation for single engine more easy to tune and MyISAM not affected by --single-transaction 

just notes about comments - "copy/past" it's not a way, even on Your Mac You really do not need file import/export at all just use normal tools like: 

Corrected: with MySQL You can store GUID/UUID data as char/varchar in case of UUID() and UNSIGNED INTEGER in case of UUID_SHORT() My personal vision - UUID_SHORT not working case, it is unsigned INT same as Auto-Increment and You can read restrictions in function description. UUID() will return result as utf8 string - "eabd691c-b552-11e6-942e-ee8ae5dda6a8" Business logic for primary key - work well, You always mange this process and do not need spend time for call function. add after question in comment: performance not depend from business logic or auto increment, it depend mostly from 2 parameters: 

The Best way, use any kinds of database modelling software. Including MySQL Workbench. Where all changes first do on schema diagram, than sync with any number of database. Many of them prepare for You clear SQL scrip which You can run independently. Very good tools - DBSchema. Other possible way - use any kind of database synchronisation software, such as: 

SELECT * always not best practice, but SELECT * without any a additional WHERE or LIMIT it bad at all any queries have several parts: 

return as many rows as many rows child table has with same id and not removed by GROUP BY You need run: 

just not forget in this case You must manually parse situations when parent_id show to 1, because You not use cascade 

Any tools and recommendations always depends from personal experience and of course on the market You can find more commercial and open source tools 

each records take 300kb? what also stored in this table. Good idea to split table for 2 it of course only top layer, always need more details about application and environment. 

Unfortunately, MATCH() AGAINST() not understand SELECT with WHERE condition inside AGAINST() - without WHERE it work, with WHERE - not. It make impossible using direct JOIN command from 2 tables in single and clean query. For resolve this we can use stored procedure, which open cursor from table Company_name and populate table Company_text with result 

I use this form for delete obsolete data monthly day by day, but for update it will work also: adopted for UPDATE procedure example: 

Playing with LEFT + INNER You can change logic of SQL query If You need all from restricted_component - LEFT JOIN But because groups must be for all - INNER