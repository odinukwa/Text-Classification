Specifically, what can you infer about where your pace lies wrt the population of runners on the loop? Are you in the top 5%? Are you above average? Etc. Of course, you'd need to make assumptions about many of these things, fixing $P_d$ for instance. And as a modeling exercise there are several interesting elaborations, such as letting the random variables $D_i$ and $S_i$ be correlated. There obviously isn't one right answer, hence the 'soft' tag. But I'm interested in hearing if others have thought about it, how they might set up the problem and what sorts of assumptions would make the conclusions most interesting. As you take $L$ smaller and smaller so that you have to contend with the possibility of lapping people and getting lapped, things become harder, and in different ways depending on whether or not we allow registering getting passed by the same person. We could also let people go around clockwise or counterclockwise with some probability. It seems so obvious that this information imparts qualitative information about your relative fitness, but quantifying it isn't straight forward. The data is well defined, the question is pretty easy to ask, but the modeling part leaves a lot of flexibility. I'm interested in hearing how the creative brains here at MO would set up the problem to interpret the evidence (or if there is a fun paper on this sort of problem somewhere). 

While I am able to verify the second claim, am not able to verify the first one? How is it true? If this can be done, the rest of the proof is straight forward. I am looking for a rigorous proof. Read this if you are interested to know where this proof heads. Now do the stepwise algorithm earlier with inputs $X_1$ and $A$ to get $x_2$ and $X_2$ such that \begin{align}X_2&=X_1-x_2x_2^T\\&=X-x_1x_1^T-x_2x_2^T\end{align} and $$x_2^TAx_2=\frac{1}{r-1}trace(AX_1)=\frac{1}{r}trace(AX)$$ Then the result of the paper is that you can do this procedure $r$ times and get a rank-one decomposition $$X=\sum_{i=1}^{r}x_ix_i^T$$ with the property $$x_i^TAx_i\,=\,\frac{1}{r}trace(AX),~\forall i$$for any given psd X with rank $r$ and any symmetrix $A$. 

I like the perspective that the set of states is precisely the set of positive trace class operators $M$ of trace one. A state is called pure if $M=pr^{\perp}_{U}$ is the orthogonal projection onto a one-dimensional subspace $U$. So, every non-zero vector $\psi$ defines a pure state. Since the orthogonal projection onto $\mathbb{C}\psi$ is the same operator as the orthogonal projection onto $\mathbb{C}x\psi$, for every $x\in \mathbb{C}^\times$, there is no confusion about equiavlence classes. Concerning the superposition of states, one shows: 

see Example 5.7. To which extend the elements $\mathrm{Hol}_{\mathcal{P}}(\Sigma) \in H/[G,H]$ characterize the 2-bundle $\mathcal{P}$ I cannot say. Maybe you are willing to drop "flat" upon replacing "holonomy" by "parallel transport": even in the classical world it is true that every principal $G$-bundle with connection is characterized by its parallel transport, may it be flat or not. The same statement remains true in the context of connections on 2-bundles: every principal 2-bundle with connection is characterized by its 2-transport. This is one of the main statements of my above-mentioned paper with Urs. 

I would like to know the other cases where $\mathbb{S}$ is convex. Can some body point me to known references? 

I have a set of $N\times N$ hermitian matrices $A_i,~i=1,\dots,M$. Are there any results on the possibility of simultaneously tridiagonalizing them? 

$M=2$, $N\geq 2$, no conditions on $A_i$ $M=3$, $N\geq 3$, no conditions on $A_i$ $A_i$'s are tridiagonal and real in some basis. No conditions on $M$ and $N$. (from Nathaniel Johnston's answer). 

Consider $K$ vectors $x_1,\dots,x_K$ in $\mathbb{R}^N$. Define the $K\times K$ matrix $A$ whose $(i,j)$ entry is given as $$A_{ij}=\exp(-\frac{||x_i-x_j||^2}{2})$$ Is this matrix Positive Semi-Definite? 

I am familiar with Rayleigh Ritz Ratio for hermitian matrices. Let $A_1$ be a given $N \times N$ hermitian matrix. Then the smallest eigenvalue of $A_1$ is given by \begin{align} \lambda_{min}(A_1)=\min_{x^Hx=1}x^HA_1x \end{align} This led me to the following question. Let me define a new quantity \begin{align} \lambda_{min}(A_1,A_2)=\min_{x^Hx=1}\max(x^HA_1x,x^HA_2x) \end{align} where $A_2$ is another given hermitian matrix. Is this quantity known before?. Is any there intuitive way of looking at it? I was able to figure out that I could solve it using semi-definite optimization. Any comments on what happens when I try it for $k$ matrices $A_1,A_2,\ldots,A_k$ 

gives a definition of the de Rham-homomorphism (ยง 6.74). For a general diffeological space, there is no chance that it is an isomorphism. Note that the usual proof one gives for smooth manifolds uses that smooth manifolds are paracompact. The topology of a general diffeological space, however, does not have to be paracompact. Already for infinte-dimensional manifolds (still a subclass of diffeological spaces) one has to require "smooth paracompactness" separately (see Theorem 34.7 in: Kriegl, Michor: The convenient setting of global Analysis). 

I'm using BakomaTex. It has a buildt in spell checker that checks while you're typing (can be disabled). 

Your line bundle $L$ over $BG$ can be seen as a $G$-equivariant line bundle over a point. That is, up to isomorphism, just a continuous group homomorphism $f:G \to \mathbb{C}^{\times}$. Try to lift $f$ along $\exp: \mathbb{C} \to \mathbb{C}^{\times}$ on an open cover of $G$. The error is a $\mathbb{Z}$-valued Cech-1-cocycle on $X$, and $E$ is the total space of the associated $\mathbb{Z}$-bundle over $X$. 

Consider two $N \times N$ hermitian indefinite matrices $A_1$ and $A_2$. Consider their affine combination \begin{align} M(t)=(1-t)A_1+tA_2 \end{align} I am interested in the minimum eigenvalue of $M(t)$. I can write this as \begin{align} \lambda(t)=\min_{x ~\in~\mathbb{C}^{N\times 1}}~&x^HM(t)x \\\ &x^{H}x = 1 \end{align} When I simulated this, I made the following observations 

Let $\mathbf{A}_1,\dots,\mathbf{A}_L$ be $N\times N$ hermitian matrices. Define the mapping from the $N-$dimensional unit sphere to $\mathbb{R}^L$ as \begin{align} \mathcal{S}=\{\left(\mathbf{u}^H\mathbf{A}_1\mathbf{u},\dots,\mathbf{u}^H\mathbf{A}_L\mathbf{u}\right)\in\mathbb{R}^L\mid \mathbf{u}^H\mathbf{u}=1\} \end{align} $\mathcal{S}$ is defined as the joint numerical range of matrices $\mathbf{A}_i$. Let $\mathbf{x}\in\mathcal{S}$, so that $\mathbf{x}=[x_1,\dots,x_L]^T$ is a $L\times 1$ real vector and $x_i=\mathbf{u}^H\mathbf{A}_i\mathbf{u}$ for some $\mathbf{u}$ from unit sphere. Consider the optimization problem \begin{align} \min_{\mathbf{x}\in\mathcal{S}}~&f_0(\mathbf{x}) \\ \text{subject to}~~~~~~~~~~~~~~&~~f_k(\mathbf{x})\leq 0,~~k=1,\dots,K \end{align} where all $f_0(.),\dots,f_K(.)$ are affine functions of $\mathbf{x}$. Is this a convex optimization problem? How do I approach it? Actually, I would like to address the more complicated case where $f_k(.)$ are all convex functions of $\mathbf{x}$. However any direction in this regard is also fine? 

I would make the problem sharper if I could, but the reason I want examples is precisely to help focus my thinking. I find it intriguing that it is not enough to have a well defined condition and a well defined model, one must also justify (by way of interpretation) which limit to take! I anticipate there are many examples from physics of which I am unaware and perhaps some from the literature on finite elements for solving PDEs. (Apologies for the pay-wall links.) 

The intersection between computability theory and statistics is pretty interesting. From this paper by Vovk (2009): "It is widely accepted that advances in computing have brought about deep changes in the theory and practice of statistics. However, the use of the theory of computing, and, in particular, of its core notion of computability, has been very limited in the classical areas of statistics, such as parameter estimation and hypothesis testing." Relatedly, Ackerman, et al. (2011) demonstrate a computable random variable $(X,Y)$ with non-computable conditional distribution $P(Y \mid X)$. Certainly this area is pretty "mathy"; it remains to be seen if it has implications for statistical practice. 

This question arose out of mere curiosity. Given a polynomial equation and I happen to know that its roots are real (but not the roots itself). Does it mean it is the characteristic equation of a Hermitian matrix? And if that is the case, could I just find the hermitian matrix and solve for its eigenvalues?. When I thought about it, looks like determining the hermitian matrix from the polynomial equation looks like a daunting task. Any thoughts on this? 

Let $\mathbf{A}$ and $\mathbf{B}$ be two complex rank-one $N\times N$ positive semi-definite matrices. Let the matrix $\mathbf{C}$ be defined as \begin{align} \mathbf{C}=\left(\mathbf{I}*\frac{1}{\alpha}+\mathbf{B}\right)^{-\frac{1}{2}}\mathbf{A}\left(\mathbf{I}*\frac{1}{\alpha}+\mathbf{B}\right)^{-\frac{1}{2}} \end{align} where $\mathbf{I}$ is the $N\times N$ identity matrix, $\alpha$ is a positive variable. The question is to find the $\alpha$ which maximizes the largest eigenvalue of $\mathbf{C}$. Background: This comes from a real world wireless problem where the largest eigenvalue represents the best power allocation at the transmitter. $\mathbf{A}$ and $\mathbf{B}$ represent the channel matrices. 

The problem is the gluing axiom for this stack. To state it, you have to decide for a Grothendieck topology on the category of smooth manifolds. Here you have again the two choices 1 and 2, and some more. According to the calculations I just did (and I should add that it's late and I am tired), all four possible combinations work. So it's again up to you! Personally, I have a preference for the submersions. If you require fibre bundles, it seems that the manifolds in a "connected component" of the stack are all diffeomorphic, whereas it should be possible to smoothly change the diffeomorphism type.