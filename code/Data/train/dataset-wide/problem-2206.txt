I am working on optimization of some slow queries in my application. I found a query in which datetime comparison has been used. Below is the subquery: 

For example: as per MySQL datatype tutorial MEDIUMINT has 3 Bytes storage and can contains value from to . 

I have a complex query including join of 4-5 tables. 1 months back, I have optimized this query and it was using the index. Also, . Just few days back, I found that this query is appearing in slow query logs again. When I analysed it, I found that one table in this query is not using index which prompts to higher join size as well as higher execution time. As a solution, I executed command on the table which was skipping the index. As a result Query again started to use that index and not appearing in slow query log. Now, I have below question regarding the above analysis: 

The RSAT tool was updated with the general availability of Windows Server 2016. By going to the same link as the preview RSAT, $URL$ you can update your workstation with the new version. 

Per Books Online, compatibility level sets certain database behaviors to be compatible with the specified version of SQL Server. As such, some queries may no longer work or may need to be slightly changed. These may be performance related especially when going to level 120 or higher as those change how the query optimizer works. If you do not change compatibility level before upgrade, the upgrade process will upgrade to lowest level compatibility on the new install, in this case to 100. The benefit of changing compatibility first before migration is to see if any queries need modification (assuming an application is attached to this database). Since this is a migration, one way to test performance is to migrate the databases to the 2016 server and then run same queries on both and gather metrics from them to compare. However, on same server performance should be similar, assuming the query is still able to run. An example of a query that will no longer run after changing compatibility mode would be as follows: 

I have a menu which is parent of multiple menu items and each child menu has their own child menus. This pattern is continued till 5-6 vertical hierarchy level. I don't want to write a query which contains nth level subquery as below: 

To check whether this value is growing rapidly or not, just run the query at the interval of each second. You will be able to see how many tables are being opened per second? There is not a single variable or factor which is responsible for or . (1) open_files_limit: MySQL has clearly mentioned in its documentation about it - As per the storage engine, MySQL maintains file descriptors for each table. So, you must need to check system variables . This link provide you importance about this variable. Luckily, this variable can be increased or decreased in MysQL5.6 on Windows server. At the start of the service, MySQL automatically adjust this value <= specified value of . (2) Query Execution Plan: What is your query and how many tables are getting used? How efficient indexes are getting utilized during query execution. (3) Table Size: Number of records in a table. How big or small it is? (4) RAM: RAM is the physical memory and cache size depends upon the RAM size. In performance of and application as well as speed up the query execution, it plays a vital role. This is not the exact answer but a helpful suggestion. 

I had similar issue before. I had all SQL Services that I needed running on MSA or gMSA except for Reporting Services (SSRS); this stayed this way on Windows 2008 R2 and 2012. This issue went away when moved to Windows 2012 R2. In my experience, SSRS was the only service that would not run on MSA or gMSA on OS prior to Windows 2012 R2 but the database, analysis, agent, and integration services all worked ok with them even when not officially supported (MSA running with SQL Server 2008 R2). At this link, $URL$ it states: 

While it doesn't specifically state anything, something changed in the Windows 2012 R2 OS that allowed using MSA or gMSA for SSRS and I'm assuming it's related to the quote above. I just ran into a similar situation a few months ago during an upgrade/migration to SQL Server 2016. The original OS was running Windows 2012 and I tried everything I could to make it work but it never worked with SSRS until OS changed to Windows 2012 R2. 

Now, to verify whether InnoDB is available or not, I ran command. But, InnoDB is not listed in that. Then, I ran command below command: 

Since MySQL 5.5 database has been added likewise . As we know that tables in information_schema contains statistical information like tables, plugins, partitions, processlist, status and global variables etc. Just like, performance_schema contains a lot of tables. 

There are multiple views behind the logic of creating composite index in a table. Creating composite index is obvious when we have composite primary key. Beside this, we create composite index on the basis of our SQL query requirements. Ordering of column in a composite index plays a vital role in the selection of right index in query execution which improves the performance. If a composite index has only 2 columns then its easy to determine their order. 

After installing MySQL-5.1.73, I placed default my-huge.cnf into /etc/my.cnf and started the mysql service. It was running without any issue. Now, I tunned some parameters in /etc/my.cnf file. Below are the parameters which I changed. 

There is a lot of info out there about this behavior going back years. Here is a thread: SQL Server Management Studio slow opening new windows Common thread there seems to be SSMS is trying to reach a location in the internet. Another thing there states to change the user feedback Opt In setting. Maybe one of these options will speed it up 

Having said all that, I still use it and recommend it. I generally try to let developers use just that tool instead of SQL Server Management Studio (SSMS) because I look at SSMS as a DBA tool and SSDT as a developer tool. 

Based on the comments, it seems the answer is to create a clustered index on the column you want to use to partition the data and then make sure your non-clustered Primary Key index is not partition aligned so you will not need to add the partitioned column to the primary key. By doing this, you can keep the primary key "simple" and use it like you normally would in a non-partitioned table. 

What is the best way to handle datetime comparison towards improving such queries. Below is the table structure: 

I have migrated my Database from Windows to Linux server. In many places, query has been written without focusing their cases (uppercase / lowercase). So, these queries are not getting executed and generating errors. As a result, functionalities based on these queries are breaking. Below is the example query to run in Windows and Linux: 

My application is running on MySQL 5.1.58 community edition. As I studied on SO websites that After acquisition by Oracle, new InnoDB plugin has been released and MySQL 5.1 with InnoDB plugin is the best for performance. Below is the command which displays the current InnoDB configuration in my system: 

So, Value of should be 512MB. To achieve this, I have written below line in and tried to restart it. 

and uncommented these variables for InnoDB.In default file, it was commented even INNODB was active. 

Your server authentication mode may be set to Windows only instead of Mixed Mode, which will allow Windows logins and SQL logins. If true then the SQL login will not work. In SQL Server Management Studio, you can right-click on the server and then go to the properties. Then go to security and see how the server security is configured. You can change it there also. If it is set to Windows only then you will have to use a Windows login. If you want to change to mixed mode to use SQL login, you can make the change but that may require the instance to be reset to take affect. 

Back in March 2016, Microsoft had a blog announcing updates to the SQL Server Incremental Servicing Model (ISM) and one of the things they have there says: 

SSIS can connect to many different servers based on the connection type used in the SSIS package. Since even SQL Server 2016 SSIS still uses Native Client 11 (and has since 2012), you should not have any issues connecting from SSIS 2008 R2 to SQL Server 2016. SQL Server 2008 R2 uses Native Client 10 or 10.1 but has no issues connecting to SQL Server 2016 either. In the connection manager in SSIS, you choose the way to connect to SQL Server. It could be ODBC, OLE DB, or any number of connections types. I say this to say SSIS itself does not care what version of SQL Server you are connecting to but the task you use will determine the connection type. I would assume you are using OLE DB and as such you may choose the provider in the connection string. 

If I run command, system return 73 records. But, column value for every record is . What does this mean? 

After installation, , and are the default database. As per the MongoDB tutorial, when we insert data in collection a database will be listed in command. For a specific purpose, I want to create a new database but I did not find any information about creating a new database. I executed a command like or . For both of the statement I got below error: SyntaxError: Unexpected identifier Can I know what are the steps to create a database? 

I checked and found that pluginis active. By default, Innodb_log_file_size=5MB. As per the MySQL Documentation, 

I am using Oracle LINUX5. I installed MySQL 5.1.73 community edition through RPM command and it was working. Now, I stop mysql by running below command: 

As per my understanding, At startup, mysql first look for my.cnf within then within and then finally . 

LinkedServerName would be the real linked server name and SourceTableName would be the name of the table in the linked server. 

You may have to shrink the data file to reclaim the space. Deleting data will not free up the space to the operating system, it will just make the currently used space less full. Truncate is similar to delete but doesn't log everything like a normal delete does. Here is a dumb analogy I use sometimes: putting a cup on a napkin can take up most of the surface space on the napkin but filling and emptying the cup has no affect on the napkin. In this analogy, the napkin is available space and the cup is your table. In your case you just emptied the cup. Now you have to remove it from the napkin, and shrink will do that for you. But what you should look into is why this table got so big in the first place. You may very well run into the same problem soon so you may have to revisit the space used and add more space to the database.