Stock and Watson use log approximation and quarterly data. Premultiplying the log approximation by 400 could be due to data being quarterly. Your second method is fine too. 

Quality of Institutions. Every since North and Weingast (1989) claimed that Britain's take off in the eighteenth century was possile thanks to its Glorios Revolution when the Crown transferred much of its power to the Parliament. With this transformation, Britain was able to lift itsel from centuries of low growth state, first in the world. Does this give any explanation to why Pakistan faces the problems it has had for years. I would say it does. First. The quality of institutions is poor in Pakistan - rules of the game are not enforced properly. The political and social setting is not condcuive to growth - property rights are not secure, corruption is rampant, it is, possibly, institutionalised, and the presence of the rent seeking political elite obstructs the enforcement of rules. The necessary institutions have eveloved there, but they do not function in a way that permits growth. Daron Acemoglu (MIT) has successfully built on North's work, Acemoglu has a nice book on why nations fail. I would recommend you to read it. Culture. Joel Mokyr has been putting the idea of 'cultural supremacy' in centrestage to explain the Industrial Revoltuion. I think his ideas could as well provide some explanation why Pakistan is facing problems. Historically, Mokyr believes, the beliefs, values, and preferences in society that are capable of changing behavior were a deciding factor in societal transformations. He goes on explaning what these transformations were and how they lead to the take off of Britain. Does Pakistan have the type of culture Mokyr is referring to, possible yes, but it is suppressed due to the presence of the issues outlined above in point 1. (will continue later) Ideology/Religion. Pakistan is a hotspot of religious conflicts. The conflicts are not between religions but within religions. Tribes fighting tribes and depriving the young generation from education (girls and women especially). Such a culture suppresses innovation and discourages innovative behaviour. There is a growing literature on the role of religion in economic growth. Consensus has not been achieved as in other areas, but the papers look into catholicism vs. protestant vs. anglican vs. bhuddism vs. islam vs. judaism etc. vs. growth. It is probably not possible to quanitify religion's role in growth precisely. There is a misconception that religion suppresses innovation. Some papers point at the events of the past, there have been many including the locking up of Galileo for his claims about solar system which we today know were true. Pakistan is an Islamic country (in fact, it is Islamic Replublic of Pakistan). Does Islam hinder growth there? The facts point at No. Islam, like any other religions, promotes peace, grwoth and wellbeing but people adhering to Islam do not follow the teachings correctly. Economic historians agree that during the time of Abbasid Caliphate, Muslims had their golden age. It would not be an exaggeration if I claim that muslims were the only people making progress in all aspects of life at the time. Much of the World was in turmoil (Europeans had not seen a long lasting peace until nineteenth century, spurts of wars hindered growth for a long time). Exceptions could be given to the nations of the Far East (China). So, what is the issue here, it is surely the individuals and groups wages conflicts between various religios factions. These acts do not promote growth. 

This is perhaps a good opportunity to point out that the "certainty equivalence" concept means one thing in microeconomics/choice under uncertainty theory, while it means something different in macroeconomics. Microeconomics/choice under uncertainty The Certainty Equivalent of a lottery/gamble, is the amount of wealth which, if given with certainty, provides the same utility as the lottery/gamble. See for example Jehle & Reny's "Advanced Microeconomic Theory" (2011, 3d ed.), p.113. Macroeconomics "Certainty Equivalence" is the situation in a stochastic model, where optimal decision rules prove to be identical to those that would have been derived in a deterministic framework (see for example Lungqvist & Sargent's "Recursive Macroeconomic Theory" 2004, 2nd ed, p. 113-115). Informally, this is sometimes described as "agents behave as if the stochastic processes are not stochastic", or "the decision rule is not affected by stochastic variability". It is a funny coincidence that both references treat the subject in the same page number... The concepts are evidently linked by the "as if there was no uncertainty" angle, but they are different in essential aspects: the micro-concept is a "buy-out" of uncertainty, providing a certain alternative towards which the agent that faces the gamble is indifferent in terms of utility, while the macro-concept emerges as a property of the solution (and only under restrictive model structures, or linear approximations thereof). 

Prolonged or long economic crises have generally been preceded by bubbles. Bubbles are generally induced by innovations in the market. Also, bubbles aren't new and certainly not modern occurrences. You can find plenty of cases of bubbles leading to long economic contractions: Tulip mania in Holland (1634-1637), South Sea Bubble in the UK (1711), Florida real estate craze of 1926 etc. 

Stock prices follow a random walk process, usually we include a drift term to account for the somewhat prolonged upward/downward drifts. This is basically an AR(p) process, p being the lag order. For instance AR(1) with drift is $X_t=\delta+\beta X_{t-1}+u_t$ where $\beta = 1$. Try testing this model for unit root using ADF test in stata. One lag is enough. You should fail to reject the unit root for an evidence of autocorrelation in the prices. Stock returns are not autocorrelated, they usually follow a stationary process if you take sufficiently long sample. 

Simple answer: Drawing on Ricardian model I can say the Chinese have not lost their comparative advantage in producing many types of manufactured goods. Yuan, on its way to appreciation, has to walk a few more miles to affect the comparative advantage that the Chinese possess. 

Comment: But what do we do when our predictions are not adequate ? Econometrics is based on Mathematical Statistics on the one hand, and on the assumptions made by Economic Theory on the other, which in turn are based on (imperfect) empirical observation, and are then led to their logical conclusions. In other words, Econometrics uses rigorous mathematics, induction, deduction and all the words dear to an epistemologist. Its epistemological foundations are solid as a rock. What hangs on the balance is the observed validity of its abstractions. So the question is not whether Econometrics is a science, in the sense of whether it follows the scientific method or not. It does, fully. The question is whether its results are useful. But what are the criteria in order to determine "useful"? Is it just adequate predictions? That would be a matter of disagreement between humans. And is it a matter of a "yes/no" answer? Or is it a matter of degree to which it is useful? In which case, we have to somehow measure this degree (after we have agreed on the criteria), which brings us back to where we have to collect, analyze, assess, and debate the evidence. 

The nominal GDP grows at a relatively higher rate than real GDP. The economy appears to have grown, in fact, much of this growth is due to rising price levels, not due to positive growth in volume of output. Using the data from the graph, you can see that 

Russia has been ramping up its production of oil since late 1990s after it defaulted on its debt. It has been maintaining positive trade balance since then. 

I tried to empirically estimate the rate of depreciation a couple of years ago. I gave up! Following a large literature on growth, I assumed a constant rate of depreciation eventually. I did not have data for all the variables needed to estimate the model. 

If I understand you correctly, monopolistic deadweight loss persists without gov intervention because of the following: Economies of Scale: if monoplist is able to produce at below the market prices due to the presence of economies of scale, then the monoplist is effectively able to retain its dominance in the market as new firms entering the market cannot undercut the monopolist. Thus, deadweight loss persists. Patenting: Monoplist could patent its products and process innovation. A new entrant would have to come up with a new idea of a similar product to enter the market tha the incumbet dominates. This however is not usually possible due to very high initial R&D investment requirement. Rent-seeking: It is also possible that a monoplist could lobby governments in order to influence policy related decisions. Tobacco and weapons manufacturng companies are known to spend large sums on lobbying efforts. These effectively serve as barriers to entry. In the presence of barriers to entry, monopoly profits effectively transfer income from households to the monopoly. The monopolist could also under-produce in order to maintain monopoly profits. Examples could be the production of "limited edition" goods which are usually priced above average market prices. Because the monopolist earns above normal profits, it may not invest in cost-saving technologies. In order to minimise or elliminate the deadweight loss, governments tend to invoke antri-trust laws and regulate the markets and industries. Deadweight loss persists in the absence of action by governments. 

INITIAL ANSWER March 24 Ok. Let's answer this without answering. Your moral obligation to this community, in case it matters to you, is to report back with your work and your answer. 1) In Economics we use the difference of natural logarithms to express (approximately) something specific. It is essentially stated in the body of the exercise. 2) An estimated relation through regression is essentially an estimation of the expected value, which in turn can be thought of as some long-term average. So don't you think it should validate the assumed long-run values given in the exercise? 3) Given the assumed long-run values in the exercise what is the relation between $C_{t-1}/Y_{t-1}$ , $C_{t}/Y_{t}$, and of $C/Y$, in the long-run? Or between $\Delta \log Y_{t-1}$ and $\Delta \log Y_{t}$ (in light of your answer in 1) above). 4) Given the assumed long-run values in the exercise, do you think that the answer will be of the form $C = a + bY$, or of the form $C = bY$? The final step will require remembering your answer in 1). ADDENDUM April 7th Now that the question came to its proper home, and a two-weeks interval has passed, let's complete this: Given the estimated relationship, in order to be consistent with our model, we accept that this relationship will also hold in the long-run. In the long-run some magnitudes are constant. Which ones, in our case? We are told that the long-run growth rate of Consumption and of Income are the same, constant, and equal to $0.25$. This means that in the long-run we will have the equalities $$C_{t-1}/Y_{t-1}= C_{t}/Y_{t}=C_{LR}/Y_{LR}$$ $$\Delta \log Y_{t-1}=\Delta \log Y_{t} = \Delta \log C_{t} \equiv g =0.25$$ ...since the difference of natural logs approximates the growth rate. Given these, and given the estimated long-run inflation that is given and equal to $$\Delta \log P_{t} \equiv \pi = 0.1$$ the long-run relationship is transformed into an equation with a single unknown, $C_t/Y_t$. Specifically, we have, making first symbolic and then numerical substitution: $$g = 0.8g+0.7g+0.1\ln(C_{LR}/Y_{LR}) -0.15\pi$$ $$\implies g(1-0.8-0.7) + 0.15\pi = 0.1\ln(C_{LR}/Y_{LR})$$ $$\implies 0.25\cdot (-0.5) + 0.15\cdot 0.1 = 0.1\ln(C_{LR}/Y_{LR})$$ $$\implies -0.11 = 0.1\ln(C_{LR}/Y_{LR})$$ At this point, it appears that the "old exam question" made a mistake, because the choices given for answering seem to "ignore" the existence of the coefficient $0.1$ attached to $\ln(C_{LR}/Y_{LR})$. If the relation was $-0.11 = \ln(C_{LR}/Y_{LR})$, we would obtain by taking the exponential $e^{-0.11} = C_{LR}/Y_{LR} \implies 0.896 = C_{LR}/Y_{LR} \implies C_{LR} \approx 0.9Y_{LR}$, which is one of the choices given. But with the coefficient $0.1$ present we obtain $$... \frac {-0.11}{0.1} = -1.1 =\ln(C_{LR}/Y_{LR}) \implies e^{-1.1} = C_{LR}/Y_{LR} \implies C_{LR}\approx \frac 13Y_{LR}$$ which is not given as an option. PS: The standard errors of the estimates are not involved in the above calculations. One could comment that their magnitude compared to the magnitude of the estimates indicates that the estimates are "statistically significant" for confidence $>95$%. 

Yes it is a function, just like you have $f(x)$, read as $f$ of $x$, $c(w)$ is $c$ of $w$ (in layman's words). Simply $c$ is the function of $w$ goods. Depending on the shape of the consumption function, the result is the area under the $c$ curve evaluated at each infinitesimally small intervals on $w$. 

Using the following CES function I backed out factor-augmenting indices $A_1$ and $A_2$ using OECD country level macro data. This process is akin to Solow's (1956) method for deriving technology residuals. I want to examine the bias in the direction of technical change by examining the temporal evolution of the factor-augmenting indices. $$Y=[((A_1L^\alpha) K^{(1-\alpha)})^\sigma+ A_2E^\sigma]^{1/\sigma}$$ The elasticity of substitution parameter $\sigma$ is 0.1 (Estimated using MLE). $Y$ is GDP. $E$ is energy flow. There is no evidence of trend in the two technical change indices until the last few decades of the sample. From there on, the labour-augmenting index grows rapidly. The other index augmenting energy declines gradually. This divergence in the indices coincides with the sudden energy price shocks. It might look pretty obvious that there was a labour saving and energy using bias in technical change. Though, I am stuck at this point, how would I link the derived factor-augmenting indices with factor prices and factor ratios to impart the technical change biases in a systematic way? 

I believe the analysis in E. Silberberg's "The Structure of Economics" (2n ed. 1990), is illuminating, chapter 7. The fundamental comparative-statics result (for constrained and unconstrained problems) is (eq. 7-10 of the book) $$\frac{\partial ^2 f(x^*,t)}{\partial x\partial t} \cdot \frac {\partial x^*}{\partial t} > 0$$ The matter was initially treated in P. Samuelson's "Foundations of Economic Analysis". Topkis's Theorem is a more abstract mathematical treatment that states the condition required in order to have $\partial x^*/\partial t \geq0$. 

To provide some input (which I do not necessarily endorse), the Tax Foundation has used its "Taxes and Growth" (TAG) model to estimate/simulate the effects on USA Economy of Thomas Piketty's proposal that the tax rate for very high incomes should rise to $80$%. The results can be found on a report freely downloadable from here. Their Key Findings are (quote) 

Working with $\min$ (or $\max$) functions can be tricky, especially if one wants to write down the general solution in a fully rigorous way. But in your case you have simple linear functions and a numerically given fixed production level ($200$) for which you want to minimize costs. First, make sure you understand the production function $\min$ expression and what restrictions it poses: A frequently seen initial approach here is to think "ah, this means either the one, or the other. So I will either use $x$ only, *or* a combination of $y$ and $z$ and perhaps only one from the two. There is no point in buying, say, $x$, if production is to be determined by the a combination of $y$ and $z$". What is the fallacy in this line of reasoning? And what the resolution of the fallacy implies? Next, think what it means to want to examine only a given fixed production level: on the right hand side you have the $\min$ function. On the left hand side, you have a specific number, not a general label/symbol anymore. So you have an equation, not a function anymore. And then you have the cost function. And you want to minimize the cost function given the equation, and given what the "fallacy resolution" mentioned previously implies. Take it from there. And please, once you figure it out, post it as an answer here (you can answer your own question is perfectly fine, and even encouraged). 

This will eventually lead to increased money supply and then push up inflation rate, because, those companies who received the newly printed cash will have to pay back existing loans in their books. An illustrative answer can be found here. 

There are quite a few books in the market on global macro strategies, the following could be useful: 

I like Introducing Advanced Macroeconomics: Growth and Business Cycles by Sorensen and Whitta-Jacobsen. An accessible UG book. Another very accesible text is Macroeconomic Theory by Wickens. It is a gradulate level book, but is suitable for advanced UG courses in Economics. 

I think you got the answer, to give more detail: assume a Cobb-Dougblas production function: $Y=AL^{\alpha_1}N^{\alpha_2}K^{1-\alpha_1-\alpha_2}$. The marginal product of land i.e. price is then:$$MPL = \alpha_1 A L^{\alpha_1-1}N^{\alpha_2}K^{1-\alpha_1-\alpha_2}$$ Simulate this model with various factor values. You can build the story yourself using this basic textbook explanation, don't need a paper for empirical evidence. 

The other factors (i.e. low investment, human capital, terrorism, etc.) causing the problems are generally proximate. (I will add more as soon as I have time) 

I am trying to get a better grip on the literature on directed technical change and induced technical change. In other words, I am trying to understand if these concepts are the same and used interchangibly in the literature to refer to endogenous technical change. Also, can anyone please point to a good review of the literature on this topic(s)?