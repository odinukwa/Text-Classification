Apologies if this is too silly. As Brendan McKay pointed out, the important thing is that the bins are chosen without peeking into them. Here's an example showing that this condition is actually necessary: Suppose there are three bins and two balls, and $k=2$. After throwing the balls, let the two chosen bins be the two that have the same number of balls. Then one is empty precisely when the other one is. 

It has already been pointed out that the first player can take either all tokens at odd positions or all tokens at even positions, thereby securing at least a draw. But the example 2-1-2-3 shows that such a strategy is not always optimal. Since the game has only $O(k^2)$ positions (subsequences of consecutive tokens), an optimal strategy can be computed in polynomial time. 

If, as suggested by Ori Gurel-Gurevich, we sample from uniform distribution on $[0,1]$, then $Z$ will typically be of order $1/\sqrt{n}$. A convenient way of generating the points $X_1,\dots,X_n$ in order is letting $W_1,\dots,W_{n+1}$ be independent exponential(1) variables with partial sums $S_k = W_1+\cdots+W_k$, and finally letting $X_k = S_k / S_{n+1}$. We have $$ \left|X_k - \frac{k}{n+1}\right| = \left|\frac{S_k}{S_{n+1}} - \frac{k}{n+1}\right| \leq \left|\frac{S_k}{n+1} - \frac{k}{n+1}\right| + \left|\frac{S_k}{n+1} - \frac{S_k}{S_{n+1}}\right| $$ $$ \leq \frac{\left|S_k-k\right|}{n+1} + \frac{S_{n+1}}{S_k}\cdot \left| \frac{S_k}{n+1} - \frac{S_k}{S_{n+1}}\right| = \frac{\left|S_k-k\right| + \left|S_{n+1} - (n+1)\right|}{n+1},$$ and in particular $$\max_{k\leq n} \left|X_k - \mathbb{E}X_k\right| \leq \frac2{n+1}\cdot\max_{k\leq n+1} \left|S_k - k\right|.$$ It is relatively easy to see that $\mathbb{E}\max_{k\leq n} \left|S_k-k\right| = O(\sqrt{n})$ and consequently that $\mathbb{E} \max_{k\leq n} \left|X_k - \mathbb{E}X_k\right| = O(n^{-1/2})$. This is because $S_n-S_k$ is independent of $S_k$. Therefore if $S_k$ deviates wildly from its mean, then with decent probability (namely when $S_n-S_k$ deviates ever so slightly in the same direction), $S_n$ will deviate just as wildly from its mean. More precisely, $$Pr\left(\left|S_n - n\right| > t\right) \geq C\cdot Pr\left(\left|S_k-k\right| > t \ \text{for some $k\leq n$}\right),$$ where $C$ is simply a positive lower bound on the probability that a sum of independent exponentials deviates from its mean in a given direction. Consequently \begin{equation} \mathbb{E} \max_{k\leq n} \left|S_k-k\right| = \int_0^\infty Pr\left(\max_{k\leq n}\left|S_k-k\right| > t\right) \, dt \end{equation} \begin{equation} \leq \frac1C \int_0^\infty Pr\left(\left|S_n-n\right| > t\right)\, dt = \frac1C\cdot \mathbb{E}\left|S_n-n\right| = O(\sqrt{n}). \end{equation} EDIT: To return to the original problem, we choose $n$ numbers independently and uniformly in the interval $[0,m-n+1]$ and let $$U_1\leq U_2 \leq \cdots \leq U_n$$ be the sorted sequence. Now let $$X_i = \left\lfloor U_i+i\right\rfloor.$$ The sequence $X_1,\dots,X_n$ is now generated according to the question (and therefore not the same as the $X_i$'s earlier in this post). Scaling up the result above by a factor $m-n+1$, we see that the maximum deviation of a $U_i$ from its mean is of order $$O\left(\frac{m}{\sqrt{n}}\right),$$ while the difference between $X_i$ and $U_i$ is of order $n$. Therefore the maximum deviation of $X_i$ from its mean is of order $$O\left(\frac{m}{\sqrt{n}}+n\right),$$ where the first term will dominate when $m>>n^{3/2}$. On the other hand if $m$ is smaller, say of the same order as $n$, it must clearly be possible to achieve sharper bounds. 

I believe that leonbloy's comment/hint is relevant, and whenever $\alpha$ is rational, $P(\alpha)$ is algebraic. For instance, $P(1/3)$ is simply the probability that a random walk on $\mathbb{Z}$ starting at the origin and taking steps of $+2$ or $-1$ with equal probability will ever reach $-1$. If $f(n)$ is the probability of ever reaching a negative point given that the walk is currently at $n$, then $f(n)$ satisfies $$f(n) = \frac{f(n+2)+f(n-1)}2.$$ The standard ansatz $f(n) = x^n$ gives three solutions for $x$: $x=1$ or $x=(-1\pm \sqrt{5})/2$. It is easily seen that the only solution of the form $f(n) = Ax_1^n + Bx_2^n + Cx_3^n$ that satisfies the boundary conditions (at $-1$ and infinity) is $f(n) = (-1/2+\sqrt{5}/2)^{n+1}$, from which it follows that $$P(1/3) = \frac{\sqrt{5}-1}2.$$ Similarly, $P(1/2)$ is equal to the unique root of $x = (x^4+1)/2$ in $(0,1)$, and in general, $P(k/(k+2))$ is the unique relevant root of $x = (x^{k+2}+1)/2$. If $\alpha$ is rational but not of this form, the boundary conditions become a little more complicated. For instance, consider $\alpha=1/5$. This can be modeled by a random walk on $\mathbb{Z}$ where a particle takes steps of $+3$ or $-2$. The corresponding ansatz gives $x^2 = (x^5+1)/2$, which has two roots of absolute value smaller than 1, one positive and one negative. Since the walk can now jump to the left, it can reach a first negative value both at $-1$ and at $-2$. Apart from $f(n)\to 0$ at infinity, we get the two boundary conditions $f(-1)=1$ and $f(-2)=1$. We can now find $f$ explicitly (at least numerically) as $f(n) = Ax_1^n+Bx_2^n$ where $x_1$ and $x_2$ are the roots in $(-1,1)$ and $A$ and $B$ are determined by the boundary conditions. As has already been pointed out, $P(\alpha)$ makes a jump at every rational number. With the approach outlined above, one can in principle compute both the "lower" and "upper" values of $P(\alpha)$ (the upper value being the probability that $S_n$ reaches, but does not cross, the line of slope $\alpha$) whenever $\alpha$ is rational. This is feasible only when $\alpha$ is a relatively simple fraction, but it should still be possible to obtain a good plot of $P(\alpha)$ as a function of $\alpha$. I recall that after this problem was discussed at the open problem session of FPSAC 2003, Pontus von Brömssen made some such plots. I haven't been in touch with him in the last few years, but apparently he has an (inactive) MO-account. I will notify him of this question. ADDED: One might worry about whether in general, a solution obtained as indicated above is the correct one. For instance, in the example with $\alpha = 1/5$, the equation $x^2 = (x^5+1)/2$ has, apart from the three real roots, also two non-real roots, and even after finding a solution $f$ involving only the two real roots other than 1, it might not be totally obvious that there is no other real function of the form $g(n) = A_1x_1^n+\cdots+A_5x_5^n$ that satisfies the boundary conditions (this would be possible if the two non-real roots had absolute value smaller than 1). There is a simple application of Brownian motion that shows that anything that satisfies the recursion $g(n+2) = (g(n) + g(n+5))/2$ as well as the boundary conditions, must be the correct solution. I picked this up recently from Jeff Steif (in a slightly different context), who told me he heard it from Yuval Peres twenty years ago. Here is how it goes: Suppose that someone gives us a function $g$ that satisfies $g(-1) = g(-2) = 1$, $g(n+2) = (g(n) + g(n+5))/2$ for $n\geq 0$, and $g(n)\to 0$ as $n\to\infty$. Since such a function must have the form $A_1x_1^n+\cdots+A_5x_5^n$, it is easy to see that all the values have to be in the interval $[0,1]$ (there could not be a smallest value of $g$). Now start a Brownian motion on the real line from the point $g(0)$, and run it until it hits either $g(-2)$ or $g(3)$. If it hit $g(3)$, continue until it hits $g(1)$ or $g(6)$, etc. In finite time, the particle will reach either $1=g(-1) = g(-2)$ or 0 (in case it went through $g(n)$ for some sequence of $n$'s tending to infinity). It follows from basic properties of the Brownian motion that the probability that it reaches 1 before reaching zero is $g(0)$. Since the process correctly emulates the discrete random walk of steps $+3$ and $-2$, it follows that the probability that the emulated walk on the integers reaches $-1$ or $-2$ before going to infinity is also $g(0)$. Therefore the boundary conditions uniquely specify the solution (and the argument obviously generalizes to any rational $\alpha$). 

I believe the answer to the title of the question is "Quickly". The Wikipedia article on "Gödel's incompleteness theorems" has a nice discussion of the developments in the 1930's. The title of Gödel's paper on the incompleteness theorem is "Über formal unentscheidbare Sätze... I", and apparently he never needed to write part II. It seems that the correctness of Gödel's paper was quickly realized, but rather than taking the heat out of any philosophical debate, it provided new and interesting fuel. 

Write each term of the right hand side as a geometric series, $1/3 = 1/2-1/4+1/8\dots$, $1/5 = 1/4-1/16+1/64-\dots$, $1/9=1/8-1/64+1/256-\dots$ etc. Now the sum of the first terms of each series is $1/2+1/4+1/8+\dots = 1$, the sum of all second terms is $-1/4-1/16-1/64-\dots = -1/3$ etc, giving the alternating sum of the left hand side. 

In a formal theory like ZF (or ZFC), one can say that proper classes don't exist, since the formal language can only speak of sets. Inside the formal theory, one can prove sentences stating for instance that there is no universal set. But if we are looking "from the outside" at a model for ZF, we can speak of collections of objects (for instance the collection of all sets) that do not correspond to sets in the model. We call them classes to distinguish the informal from the formal language. From a technical point of view, the situation is no more paradoxical than for instance a formal theory of the rational numbers in which it can be proved that there is no square root of 2, but that can be embedded in a larger structure where $\sqrt{2}$ does exist. But it's a bit disturbing if one wants to think of set theory as a foundation of mathematics, describing the real mathematical universe. It seems weird to be able to give specific examples of things that don't exist. With everyday non-existing things like circles with integer radius and perimeter you can't, because there simply aren't any. It reminds me of the great Master Cerebron in Stanislaw Lem's "The cyberiad", who lectured for 47 years on the three types of dragon, each of which doesn't exist, but in completely different ways. To understand the situation, I think one has to see the problem that ZF was meant to solve. In the late 1800's, Gottlob Frege devised a much simpler formal theory of sets that turned out to be inconsistent due to the Russell paradox of the set of all sets that aren't members of themselves. Restoring Frege's logic turned out to be quite a challenge. Russell suggested a hierarchy of types, while ZF goes in another direction, squeezing set theory into first-order logic. I'm not familiar with other theories, but it seems that whatever we do, Rusell's paradox will keep haunting us one way or another. Finally, since I'm currently reading it, I can't resist mentioning Logicomix. 

I think $z$ should be chosen so that the deviations tend to go in the positive direction on all scales. The following approach seems to work: Suppose $n$ is a power of 2 (some fix is needed if it isn't). Suppose the points $z_i$ are sorted, say in counter-clockwise direction, and assume without loss of generality that we have $z_0 = z_n = 1$ (indexing modulo $n$). The points $z_0$ and $z_{n/2}$ split the unit circle in two sectors. We pick the larger of those two, and look at the point whose index is the mean of the indices at the endpoints (either $z_{n/4}$ or $z_{3n/4}$, the point that we expect to be near the midpoint of that larger sector). That point splits the sector in two, and we pick the larger of those two and continue. In the end we arrive at two consecutive points $z_i$, and we let $z$ be the midpoint of the sector between them. It should now be possible to get a high-probability lower bound on $\log(P(z))$. I haven't done this in detail, but a simulation for $n=64,128,\dots,4096$ indicates that $\log(P(z))$ is rarely much smaller than $\sqrt{n}$. Since you ask for an idea that might be useful, I dare post this as an answer. UPDATE: Here's a simple argument that should almost, but not quite, give the desired bound. What it ought to show, although some precision in the analysis is still missing, is that for every $\epsilon>0$ there is an $\alpha>0$ such that $m\geq \exp(\alpha\sqrt{n})$ with probability at least $1-\epsilon$. Here's how it works: Since the mean value of $\log\left|P(z)\right|$ is 0, we can always find a $z$ such that $\left|P(z)P(-z)\right| = 1$. Notice that $P(z)P(-z)$ is unchanged if we replace $z_i$ by $-z_i$. Therefore we can start by randomly generating $n$ pairs of diametrically opposite points $\{z_i, -z_i\}$, then find $z$ with $\left|P(z)P(-z)\right|=1$ given only this information, and finally fix the $z_i$'s by $n$ independent coin flips. Now condition on the outcome of the first stage of the process, so that the $n$ pairs $\{z_i, -z_i\}$ are fixed. With high probability there is a bunch of say $n/2$ such pairs for which the quantity $\log\left|P(z)\right| - \log\left|P(-z)\right|$ is affected by at least some constant depending on a coin flip (this just requires $z_i$ to be substantially closer to one of $z$ and $-z$ than to the other). Therefore the standard deviation of $\log\left|P(z)\right| - \log\left|P(-z)\right|$ is at least some constant times $\sqrt{n}$, which means that $\max\left(\log\left|P(z)\right|, \log\left|P(-z)\right|\right)$ should be of order $\sqrt{n}$ most of the time. I guess the argument can be made precise, but this choice of $z$ doesn't let us fix $\alpha>0$ and get a.a.s. the bound asked for. Perhaps this helps to at least clarify the question. What the OP asks for is just beyond what we get with this argument. EDIT: The more I think about it, the more I suspect that the first statement asked for in the OP is not true. Of course $\log\left|P(z)\right|$ will take large negative values when $z$ is extremely close to a $z_i$, but when it isn't, it seems that the irregularities in distribution of the $z_i$ on a smaller scale will be less significant than the large scale distribution. Roughly speaking this is because by the nature of the logarithm, the points $z_i$ close to $z$ will have only a mildly stronger influence on $\log\left|P(z)\right|$ than the points farther away. If the points $z_i$ happen to be unusually but not extremely uniformly distributed on the large scale, it seems that $\max\left(\log\left|P(z)\right|\right)$ need not be larger than any particular constant times $\sqrt{n}$. If this is correct, it means that the values of $\log\left|P(z)\right|$ for different $z$ are significantly correlated even on a larger scale. Needless to say, these speculations are still nothing close to a proof. The second, weaker version, seems to be equivalent to what is claimed in the update above, and it should not be too hard to fill in the missing details.