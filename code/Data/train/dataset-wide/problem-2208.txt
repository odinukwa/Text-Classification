I might be flying blind on this one, but here it goes ... In your question and comments, you stated the following: 

Please note the What was the issue ??? It turned out that DATETIME fields would break replication. How ??? MySQL 5.6 started supporting microseconds in DATETIME values. MySQL 5.5 did not. So, when replication threads attempted to unpack the binlog event from the relay log, the format for DATETIME was wrong in the eyes of MySQL 5.6. My manager's workaround ??? Switch to for binlog_format, use statement-based replication. Everything went fine from there. You said you are using and that's OK. I would just make sure you get away from the 5.1 and 5.5 server as fast as you can (Do the Migration in Haste). Such a setup is fine. A current colleague at my current employer did MySQL 5.1 to 5.7 in stages. No issues (I assumed he used MIXED or STATEMENT). You should try this setup in DEV/STG and make sure DATETIME value don't keel over replication. 

Since MySQL 5.1, there has been a native tool called MySQL for Excel. It is bundled along with MySQL for Visual Studio, a bunch of connectors, sample databases and so forth. The MySQL Documentation has a webpage for 

STEP05) on all Apache Servers STEP06) Change the IP address in the App to Connect to the Slave STEP07) on all Apache Servers STEP08) on the Slave to make sure there are incoming DB Connections If you see DB Connections coming in from the Apache Servers, CONGRATULATIONS you have manually performed a failover without MySQL Downtime. The only downtime there is comes from the Window of time STEP05 - STEP07. 

ASPECT #2 Since the table is MyISAM, why make mysqld jump through hoops to regenerate the table ??? If the table is and your datadir is , copy these 

OK, let's get a little more granular. You said you have reports per Perhaps the query could be adjusted per user 

If the table is InnoDB, that could a little because the data dictionary within ibdata1 would know what the file's name was originally. Notwithstanding, you could rename the file the same way. You should also make sure the file has the correct ownership. 

That's it, right? NOPE !!! If your website has been up this whole time, there may have INSERTs running against s_relations during the loading of s_relations_new. How can you retrieve those missing rows? Go find the maximum id in s_relations_new and append everything after that ID from s_relations. To assure that the table is frozen and used only for this update, you must have a little downtime for the sake of getting those last rows that were inserted into s_relation_new. Here is what you do: In the OS, restart mysql so that no one else can log in but root@localhost (disables TCP/IP): 

UPDATE 2011-10-24 17:37 EDT I created a new table called observations and populated your sample data. I changed the stored procedures to use observations instead of pctable. Here is your output: 

WAMP/LAMP environments was set up with this mind. MySQL would come with the bare essentials for installing MySQL and storing and backing up data. Such bare essential utilities may include: 

That's the old way MySQL 5.0 sets the slow query log. To activate the slow query log for MySQL 5.6 and MariaDB, you must use the following 

METHOD #3 : Binary Logging If has binary logging enabled, get the timestamp of the last binary log after shutdown. METHOD #4 : Error Log You are probably saying, "I DON'T WANT TO LOOK INSIDE THE ERROR LOG !!!" You don't have to. Just get the timestamp of the error log after the shutdown is complete. CAVEAT ON SHUTDOWN Method #1 is not any good to you if mysqld crashes. The other three(3) methods will simply tell you the last time mysqld did any kind of writes, whether it was a clean shutdown or a crash. YOUR ACTUAL QUESTION First off, a trigger is not needed nor would it fire off on shutdown. You cannot write a shutdown time to a table when mysqld is shutting down. The best I could suggest is to capture the shutdown datetime with one of the four(4) aforementioned methods and write it in a script. You can execute that script as follows: Create a file called Run Write inside that script in such a way that the datetime is written to a table Add this line to (see MySQL Documentation on init-file) 

The IO Thread is responsible for communication between Master and Slave. It downloads binary log entries from the Master and stores them in the Slave's relay logs. The SQL Thread is responsible for 

If you do not have this, add it and restart mysql Question 2 Would the resulting bin-log in db2 be exactly the same with the bin-log of db1, to the letter? Answer to Question 2 Yes. Make sure the clocks on both DB servers are synchronized Question 3 What happens to the entries in db2 relay-log once they are committed to the database during the replication process, are they discarded? What role does the relay-log info log has in this? Answer to Question 3 In MySQL Replication, the IO Thread of a Slave will read its Master's bin-log entries and store them in a FIFO queue. For each relay log in a slave, when every entry in the currently processed relay is executed it is rotated out and discarded. If relay logs are piling up, this quickly indicates that the SQL thread died because of any SQL error. Just do to find out what stopped the SQL thread. The IO Thread would conitnue collecting completed SQL statements from its Master. Question 4 How does db1 know where in the bin-log of db2 (somehow dependent on the answer of Question 2), it will start the replication process? Answer to Question 4 When you do , look for the following lines: 

Whatever you do, do not use the MD5 function to make new passwords. Use the PASSWORD function. It is very different from MD5: The password function PASSWORD function is the equivalent of 

The SQL queries themselves are fast. Please read any release notes on WordPress 3.4.1 to see if WordPress upgrade installed any DB-related modules that need tuning or deactivation. Also, check for any data that was added during the upgrade process that may have bloated your tables. 

As a MySQL DBA staring at this, I think in relational terms. I also think in terms of doing JOINs. However, from a NoSQL standpoint, JOINs would have to be done programmatically. Multiple documents, one for each ingredient : This will make smallest amount of static data to place in collections. Yet, you should be prepared for getting references, building temporary collections for yourself with CouchDB or sending data straight to your app. One document with all references : If you are content with mining Collections out of Collections out of Collections ... (inifinity), you are willing to construct such collections, and you are comfortable with it, then storing the data this way would be OK. Please just make sure you are not the only CouchDB Jedi around (unless it's a matter of job security), since you might want your code understandable and maintainable by others. One document per reference : Now, this is a nice middle ground. It will provide some flexibility in the event there are changes in the Collection layout. Simple retrievals for ingredients can be independent of retrievals for spices or utensils. Performing programmatic JOINs is still needed but not all that deep. Those who are a novice to NoSQL paradigms (like myself) would be comfortable understanding and retrieving data without the fear of breaking deeply-entrenched complex data representations. My personal choice would be option #2. 

then an index on just the rank column would suffice and produce a full index scan. CONCLUSION In light of these observtions, it is definitely a thing of beauty to present to the MySQL Query Optimizer two things: 

With reference to the Slave, this will reserve SUPER privilege to just and prevent non-privileged from doing writes they would otherwise be restricted from. UPDATE 2015-08-28 17:39 EDT I just learned recently that MySQL 5.7 will introduce super_read_only. This will stop SUPER users in their tracks because the 5.7 Docs say 

This is what the --disable-keys option embeds in the mysqldump. Also, this is embedded after all the INSERTs are done 

The PRIMARY KEY, or any index for that matter, would be accessed much faster if the length of the PRIMARY KEY was smaller. It is easier to put a 4-byte integer as a unique identified for a fullpath image name than the fullpath filename (of various and ridiculous lengths). Think of the Clustered Index, where the PRIMARY KEY would reside. Row data will occupy a Clustered Index. In MySQL, the Clustered Key would be coupled with other columns in a nonunique index. Wouldn't a smaller datatype (4 bytes) just make more sense? Otherwise, indexes can blow up at a rate of O(n log n). To create a unique number for each image, you need a table that resembles something like this: 

This will give you the opportunity to clean up the data Alternatively, you may decide to make it a regular nonunique index. 

Even though this is right, it would be illogical to script this convoluted method for all rows, especially since some rows have different formats. Therefore, it is in your best interest to convert and columns into or 

You may want to consider setting the database's default character for new tables going forward using ALTER DATABASE. Here is an example using MySQL 5.5.12 for Windows: 

In order to see if a set of 17 columns exist you will have to concatenate them and then query the table like this: 

All these queries make assumptions on the content of the data. Such queries would produce very poor performance results. This is why I suggested creating an external table to perform the JOIN that would couple the id of name and its country together. UPDATE 2012-08-16 17:19 EDT In answer to the last question from the comment 

There is a bit of confusion that needs to be cleared up. MySQL In MySQL, the SQL Clause works with Views only You cannot create any other types in MySQL (someone correct me if this is not so). That's why says is expected. You also cannot create types with the above syntax in MySQL. PostgreSQL You can create types in PostgreSQL, but there is no syntax for creating types. You can use for creating functions and views, but not types. 

No, you do not want to go there. Why ? The mysqld_safe script is responsible for creating and destroying the PID file You can see it when you grep for it 

If it is scenario 1, no worries. Otherwise, either code for handling 64-bit addresses exists (chances slim-to-none) or not. There is a possibility that was a typo left over from a previous 64-bit build. 

I don't think GTID is your issue. You are probably using row based binary logging To verify this, run one of the following: 

This will retrieve the specific info for whatever x, z and type are there. CHOICE #2 : Use x,z,type as the PRIMARY KEY Run this query 

MAJOR CHANGE #2 : Proper Indexing I think you have this already since Query 1 and Query 2 run fast. Make sure you have a compound index on (account_id,email). Do and make sure you have one. If you don't have it or if you are not sure, then create the index anyway: 

To make sure your table is clean and the trigger is working, assuming ID 200 is the default, run these steps: 

Another jazzy approach to this would be to place that command without the ampersand into a shell script. Then, execute the script, by name, in the background. For example, call the shell script in the folder. Here is the content of this proposed script 

What I am about to show you comes from lines 89-122 of the mysqltuner.pl code: You will still have to connect like a mysql client: 

MySQL 5.1 introduced plugins. MySQL 5.0 and prior do not have plugins. My guess is that you had MySQL 5.0 running, you uninstalled MySQL 5.0, and tried to install either MySQL 5.1 or 5.5 and it complained about mysql.plugin being missing. Try cleaning up the 5.0 install as follows 

Their Data and Time Ranges would differ greatly. Note further differences in the MySQL Documentation 

Your myisam_max_sort_file_size is probably too small. Perhaps your tmpdir hasn't got the elbow room. First, kill the repair right now. Add these two lines to 

MySQL 5.6 Documentation The and variables were first introduced for mysqlbinlog in MySQL 5.6.3. Once MySQL 5.6 went GA, those options were not meant to be used at all. How did I know ? Look at the list of options for mysqlbinlog (Table 4.16). They appear in the list between and BUT THEY HAVE NO HYPERLINKS !!! mysqlbinlog Here is something else to consider: mysqlbinlog is not a client program. It is a utility program. In mysql, client programs require logging into mysqld with a username and password. If you look at the list of MySQL Client Programs, please note that mysqlbinlog is not there because it is a utility. You can see mysqlbinlog among the list of MySQL Administrative and Utility Programs. If you are using an option file, mysqlbinlog can never respond to the options under the group header. Why ? According to the Options File Documentation: