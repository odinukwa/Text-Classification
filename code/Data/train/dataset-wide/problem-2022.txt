I'm trying to setup an AlwaysOn AG with T-SQL commands but my secondary is always in a disconnected state (when I failover, my old primary becomes disconnected). This is not an firewall/network issue, I'm able to send messages from SQL1 to SQL2 with a TCP-sender/receiver. The option New Availability Group... in SMSS also generates the same problem. However when I'm creating an AG with New Availability Group Wizard... it works perfect. This is the T-SQL statement I'm using: 

To me it looks like overkill to set processor affinity so a core would be free for Windows. What is your advice about this? 

On the secondary dm_hadr_database_replica_states is empty and the database doesn't show up in sys.databases. When I look in SSMS the database is shown in 'Availability Databases' Is this a bug in SQL Server 2016 SP1 Standard CU2 or is there something wrong with my T-SQL statement? 

I'm a newbie regarding the query store and have some problems understanding what I'm seeing. We have a third-party application (running on SQL Server 2016 Enterprise SP1 CU7) that uses the query-hints and . When I do some monitoring in the querystore I see that some queries has multiple plan ids in the plan summary window. Why can a query that uses and have multiple plans (sometimes completely different, sometimes the same)? And the second question, if there are plans that look exactly the same (same physical operators, same set options, same queryhash), how can one plan have a missing index and the second plan not? This are two anonymised plans: Plan 1 Plan 2 

Your role would be to provide the facts to the business. If the business is willing to accept the risks and proceed with using the data warehouse as a source for an operational system, then I suggest you get that in writing and triplicate. A "best-of-both-worlds" solution would be for the warehouse to publish the data once processed for the operational system to consume. The data could be extracted to a file or replicated to another/the-operational-system's database. This assumes that your warehouse is not "real-time". I must admit that I get the heeby-jeebies whenever someone suggests connecting an operational system to our warehouse. Within our environment, we made the architectural decision that we would not control how users could consume the data, provided it does not unfairly impact our ETL processes or other users. An operational system becomes another "user query", and as such we provide the same level of service wrt to availability and accuracy as we do to Joe Bloggs, the junior analyst in Finance. If a user requires a higher level of service, then we provide the data (via FTP'd files) rather than the user pulling the data (via queries/direct access). This assists in impact analysis for future changes because the extracts are visible within our ETL tool/suite. 

A while ago a consultant said that I should set processor affinity when I'm running SQL Server on VMWare. The advice was to disable CPU0 so it was free for the OS. When I read the "Architecting Microsoft SQL Server on VMware vSphere"-PDF on the site of VMWare I find following: 

Somebody told me there's a difference in the internal working (I not mean a difference in features or supported resources) of SQL Server Enterprise and SQL Server Standard. One difference I remember was that the Enterprise version uses multiple threads for certain operations and the Standard version only one (I forgot the details). I've searched the web for an overview of the differences (+ some explanation) but I was unable to find such a list. I now wonder is there a difference in the internal working between the two editions? 

I've a database on SQL Server 2016 SP1, in the db there is only one table with a Filestream column and a few columns of type . The table is partitioned and every month a new partition is added by scripting. Each filestream partition has its own filegroup, while the other partitions are in the primary filegroup. New data is inserted in the new partition + old data is not be updated. The partition function is created with . I want to hold one year of data (12 partitions) on SSD and archive the rest to slower storage. This will be an automatic process (SQL Job/Scheduled task). 

If your reports are based on a data warehouse that is dimensionally modelled (generally the case for business intelligence solutions), it is highly probable there is a date dimension and time dimension. If there are no such objects, it may be very useful to create them as they become highly re-usable as other reports are required. In the date dimension, there should be an IsHolidayFlag column. In the time dimension, there should be an IsBusinessMinuteFlag column (depending on the grain of this dimension, it may be IsBusinessSecondFlag). The query would then be relatively straight forward and quick, provided the indexes are correct. There is an overhead with the CROSS JOIN (which could be created as a view for re-usability), but for 200,000 rows, it should be negligible. 

There is a forum discussion which discusses this briefly, but quite well IMO: Tek Tips - Using a data warehouse as a source system Some points for consideration: Duplication of effort / Single source of the truth Will the operational system need to apply the same logic to the source data that the data warehouse is already performing? Read-only source Does the operational system expect to write changes/updates back to the warehouse? Timely information Is the operational system happy with the latency of the warehouse? (Generally T-1) Service-level agreement What is the impact to the operational system if there is an outage to the warehouse? In my experience warehouses, inherently, have a lower priority than transactional systems and may have, for example, up to 24 hours to become available (for querying) and up to 4 days for the ETL to be restored, running, and for the warehouse to be up to date. If the operational system is internal and non-critical, this may be acceptable. If it is customer-facing, and retrieving FX rates from the warehouse for pricing, probably not. I think the quote from that forum post that sums it up nicely is: 

After some more research I discovered that when I create an AG with autoseeding SQL Server creates a new worker (that executes the VDI_CLIENT_WORKER command) for each scheduler. To remove those workers I need remove every 'autoseeded' AG and restart the SQL Server service. If I then create the AG with full backup/restore none of these workers are created. 

Is fragmentation on intermediate pages something to worry about and what is causing the increase in fragmentation? 

The second method is twice as fast as the first one. But the disadvantage is that after a few years the archive disk will contain a lof of folders/partitions containing the filestream data + database needs to be offline. As with the first method there is only 1 folder/partitions (or I can split that big partition by year). I hope my explanation is clear enough because it was hard to put all this in writing. What is the best method to accomplish the archiving or am I missing something? 

We have a SQL Server 2016 SP1 CU7 Enterprise server where we enabled the query store on a database. This is a highly used database.The has been set to 200MB and is 1 day. I've used to check the properties of the query store and everything works perfect as long as stays under the 200MB. I've set to Auto but no cleanup happens, normally a cleanup should be triggered when the query store is 90% full. What happens next is that the query store goes into readonly mode because there is no available space left. I've tried changing to Auto but nothings changes.If I then change to 30 days the changes to READ_WRITE and the query store starts capturing again. The just becomes higher than the and after a while the goes back to READ_ONLY. Can anybody explain this behavior? 

There's no way to go wrong and, as @DTest added, this 2 query approach can be faster in some environments (see the link in his comment). Oh, and I took a fast read at MySQL documentation related to Information Functions, there it was on a tiny little silly notice: 

If it was a smart move or not, it depends of your specific case: If the file location is directly affecting any url structure or if you're storing full file addresses in the database (bad), I can say it was a bad move since you will have trouble in case somebody move or rename some directory. But as But if your application is built in a way you simply have to point the files directory and the file access logic is dynamic, you made a smart move for the following reasons: 

This last suggestion seems to explain the strange variable behavior when switching database servers. One might be responding much faster than the other, and since for every found record you will have a secondary query, that hypotesis would explain why the application delays only with a certain amount of queried results (> 30). At least we got to a primary conclusion. Definitely the problem is not with MySQL server istelf. Took a look at the documentation and there seems to be no feature limits that suits your specific situation, also I never had any problem with recursive tables and specific amount of entries. Hope that helps. 

I need to rebuild some big indexes and I'm doing some tests with the various options (sort_in_tempdb, maxdop, online) of the statement on an test index with 4 levels and 800000 pages on leaf level. I noticed when I'm running the statement with the intermediate pages (level 1) of my index are higher fragmented as before (89% in stead of 3%). The intermediate pages only get defragmented when I'm setting . With the options the level 2 fragmentation jumps from 0 to 100. This are the statements that caused an increase of fragmentation on level 1: 

I've setup an AlwaysOn AG on SQL Server 2016 SP1 Standard. Then I created an AG and added a database with autoseeding (synchronous mode). I used SSMS 2017 to create my AG and to add the database. Everything works fine. But when I check the wait stats I get waits of type VDI_CLIENT_OTHER (80%) on the primary with an average resource time of 42 seconds. After some research I found out that the waits are generated by 4 sessions that execute the command VDI_CLIENT_WORKER. As I understand the wait means that a thread is waiting for work when seeding a new AG. But what I do not understand is why I have those waits because my AG is ready and why do I have 4 sessions that execute the VDI_CLIENT_WORKER command? I found out that each scheduler has one VDI_CLIENT_WORKER Can somebody try to explain what VDI_CLIENT_WORKER-command does and how can I solve the problem of the many VDI_CLIENT_OTHER waits?