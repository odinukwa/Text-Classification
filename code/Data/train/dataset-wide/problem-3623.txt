On the server, add a .bat file into the All Users -> Start Menu -> Startup folder. In it add the line: NET SEND yourpcname %username% logged into the server You'll need to enable messenger on both machines. Assuming you have XP because I'm not sure you can receive messenger messages in Vista or 7. 

Super simple: Right-click taskbar -> Start Task Manager -> Performance Tab Slightly more info: As above then click 'Resource Monitor' Individual performance traces: Start -> Run -> Perfmon -> Performance Monitor -> Right click 'add counters' I don't think it gets much simper than that. 

It's a dangerous for a real network because it's applying a narrow metric when you need to take a holistic approach. In graph theory, reliability is best when you can remove the most paths on the graph, and still retain a valid path between all vertices. Hence, a network where each vertex connects to all others with a dedicated paths is the most reliable. In real networks, that's just one of many factors. Reliability is best when your servers and workstations can happily communicate at acceptable speeds come rain or shine and that's determined by a lot more than simply 'how many links to other things do I have?' In real networks, you must take into account: 

Now you can do a few of the individual things you mentioned separately. For example there are distributed computing applications like BOINC/SETI@Home, which if course rely on workloads that enjoy high parallelism (can be processed separately and combined later). There are also Distributed storage applications like Bittorrent/Brancecache. If you have a particular workload in mind that you want to number crunch, and the programming chops, take a look at Beowulf clustering. A really important concept to understand here is how the distance of components affects slower data transfer between them. This is a fundamental principle of computing and explains a lot of things, including the answer to your question. Short version - The further two components are from each other the slower their max communication speed. Consider how fast L1 cache is compared to RAM, then compared to the hard drive. This is a direct function of its distance from the core. 

My take, bearing in mind that I can't know all the facts about your particular situation: If you have an imminent physical move ahead of you, then you absolutely do not want to be migrating your systems to different platforms on an immutable deadline of having to be out of the premises. For one, stuff is more likely to go badly wrong under duress and two, if problems occur and timescales slip (and when has that ever not happened?) you'll end up moving halfway through your migration, and still requiring data center space for your kit. Sounds like an expensive recipe for disaster rather than the elegant cost-and-hassle saving panacea the cloud is supposed to provide. No, definitely do not mash 2 projects into one like this if you can possibly avoid it. Cloud hosting (in the sense I suspect your boss is envisaging it) is great and has its place, it may be a good fit for what you do. But right now I think you have enough on your plate with needing to move your infrastructure as-is, so I would push back on your boss with the clear message that you can't just scrap all the hardware and systems at the drop of a hat, but that moving to cloud hosting for at least parts of your infrastructure may indeed be feasible as your next big project, after the dust has settled from the premises move. On the subject of 'The Cloud' itself. You're already running a local/internal cloud solution - Your VMWare/SAN environment. If you move that off to a hosted datacenter where you just rent a rack and continue to manage your own kit, you've now got a remotely served, private cloud solution. Many non-technical bosses live off buzzwords and cloud computing is no exception (in fact at the moment it's probably the biggest offender in the 'bullshit bingo' category). You can turn this to your advantage and steer things in a more sensible direction by tying the things you already do (running a virtual environment) to your bosses idea of the cloud. It can be as simple as referring to your VMs as 'Instances' and ESX hosts as 'Nodes' whenever you're reporting on it. 

Typically directory listings are generated by the web server itself, and that feature may be disabled on your host (and it's often good that it's disabled, for security reasons). If you have access to the control panel for the web server, you may be able to enable the setting yourself. Unlikely as you indicated you have been provided with hosted space. You can work around it by creating a PHP file which will list out the contents of your chosen directory. See the instructions for this here. 

Configure the tool to watch for specific entries and alert on them Configure the tool to ignore known benign entries and alert on everything else 

Check your wireless router and see if it has somewhere in the DHCP settings where you can set the DNS search suffix. The problem that you have is that your home network currently does not have an internal DNS suffix in which to search (e.g. myhome.lan). If you can set your DHCP server to assign its clients a suffix when they request an IP address, you can then configure the suffix search list on your school PC to search for both *.X.edu, and *.myhome.lan. You could also start addressing your machines via a full DNS name like pinky.myhomelan. Of course, this depends on your home router supporting it. But many do. 

For every IT-related system you maintain, throw it through this filter question: "Do we use this system in a standard manner like other companies?" Good examples of this are Email applications, Desktop workstations, and Intranets. Many companies, even specialist companies with specialist IT requirements, still use email, workstations and intranets in the same manner as most other companies out there. These systems, being used in a standard manner, are ideal candidates for outsourcing to a third party. On the other hand, systems tailored for a very specific "unique to your business" requirement, like a bespoke analog dialinig application which uses highly customized interfaces with the remote equipment. Written in Fortran. On HPUX. Yeah... don't outsource that bit. Maybe outsource the HPUX support element of it, though! Often you can extend this a bit further and find a good route. Maybe say 'OK... currently we have an email system with a bunch of custom forms and outlook add-ons that we depend on to do business. But with a few weeks of development work, and some buy-in from management, we could transition just that custom element out to a standalone system. Once you do this, you can outsource our email. I've seen companies with specialized IT requirements attempt to outsource wholesale, and encounter a whole world of pain. Likewise, I've seen companies with specialized IT requirements identify their differentiators, standardize, then outsource, and end up much more efficient as a result.