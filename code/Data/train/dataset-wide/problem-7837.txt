If a theorem about reasonable objects can be proven predicatively, this gives important information on the consistency strength (i.e. the proof-theoretic ordinal) associated with the theorem. Conversely, we know that some theorems such as Kruskal's theorem cannot be proven predicatively because these theorems lead to proof-theoretic ordinals that are too large. Thus the mathematical analysis of predicativity reveals the full complexity of results such as Kruskal's theorem, rather than obscuring it. This is separate from the philosophical analysis of predicativity. The "computability" consequences of a predicative proof can be extremely important. In the context of a countable group $G$, a "top-down" construction such as "intersect all subgroups of $G$ that contain the set $X$" will only naively give that the constructed object is $\Pi^1_1$ over $G\oplus X$. A bottom-up construction will usually show that the constructed object is actually arithmetical in $G\oplus X$. Examination of the bottom-up proof can then give explicit bounds in the arithmetical hierarchy on the complexity of the constructed object. For example, in the case of a subgroup of a group $G$ generated by a subset $X$, the degree of the subgroup is no more than the Turing jump of $G \oplus X$; this is an enormously better bound than the naive $\Pi^1_1$ result. 

Addendum The difference between extensional and intensional equality is easiest to explain by example. Let A be the empty set and let B be the set of integers larger than 1 that do not have a unique prime factorization. Then we know B is also the empty set: so A and B are extensionally equal. But the definition of B is much different than the definition of A: so A and B are intensionally different. This distinction is often important in contexts like computability and formal logic where the things that you work with are actually definitions (also called codes, indices, Gödel numbers, or notations) rather than the objects being defined. In many cases, extensional equality is problematic, because of computability or effectiveness problems. For example, in my answer above, we know that φ and ψ define the same set in the real world, but this fact requires proof, and that proof may be impossible in the object theory we are dealing with. On the other hand, intensional equality is easy to decide, provided you are working directly with definitions. 

The best way to find cutting edge papers is to attend conferences and see talks about current research. Research journals lag years behind current research. Even preprints often lag behind announced results - in some fields, including logic, people often speak about results that are not yet available as preprints. In logic, the arxiv is not extremely useful for finding new results, because only a minority of practicing logicians publish preprints on it. Logic has very little to do with time series, however, so the conventions may be different for research in time series. 

The original question can be read sensibly as follows: Let T be a true theory of arithmetic to which the incompleteness theorems apply. Consider two sentences in the language of T to be equivalent if they are provably equivalent over T. How many equivalence classes are there, under this relation, that contain a true-but-unprovable sentence? This avoids the issue of sentences like φ∧∃x(x=x), which I think is what the question means by "with decidable tautologies or decidable sentences disregarded". The answer is trivial, though, assuming T is a true theory: there are still countably many such equivalence classes, which is as many as there possible could be. "True theory" means "satisfied by the standard model". First, T + Con(T) is strictly stronger than to T. Also T + Con(T) is a true theory, and the incompleteness theorems apply to it, so it is strictly weaker than (T+ Con(T)) + Con(T +Con(T)). Continuing this way gives an ω-chain of stronger and stronger true theories extending T, each of which adds only a finite number of (true) axioms to T. There is a more non-trivial fact that regardless whether T is a true theory, if T is essentially incomplete then the Lindenbaum algebra of sentences modulo provability over T is the countable atomless Boolean algebra, so it has all sorts of structure. This is because any coatom [φ] in this algebra would correspond to a complete, consistent, effective theory T + φ, which cannot exist. 

Because ZFC does not prove that $\zeta$ is a well ordering, there is some model of ZFC in which $\zeta$ is either not a total linear ordering, or $\zeta$ is not well founded. Either of these can only happen in a non-well-founded model of ZFC, since by definition $\zeta$ really is a well ordering. Although this type of example is related to the type from the question, the proof method sketched here does not make use of consistency statements, so I feel this counts as an essentially different example of the same underlying phenomenon. 

When I was looking around trying to find some inspiration to answer your question, I found the following result of Feferman from 1957: 

I don't believe that Bishop explicitly assumed all functions are continuous. I think that "no discontinuous function can be proved to be total in Bishop's constructive mathematics" is actually a very good way of summarizing the situation. For example, consider how we would state "All functions from $\mathbb{R}$ to $\mathbb{Z}$ are constant" in a Bishop-type framework. A function would be a procedure that takes a representation of a real number and produces an integer, which is extensional in the sense that any two representations of the same real must produce the same integer. Now, if we try to produce a discontinuous function in this sense, we will find that the definition for the function cannot be proved to be total. This is because, if the function was total, then we could prove that for each real there is a finite amount of information about the real which already determines the output (using some version of Weak König's lemma, say), and that would mean that the function would need to be continuous. The key point is that it is not a function that is proved to be total, but rather a definition of a function. In their Varieties of Constructive Mathematics (1987), which is a good reference on the subject, Bridges and Richman work with an non-formal system BISH which is a subsystem both of classical mathematics and of other constructive frameworks. In particular, every proof in BISH is also a proof in classical mathematics, so BISH cannot prove every function $\mathbb{R}\to\mathbb{N}$ is constant, or anything like that. They explicitly describe BISH as "Bishop's mathematics", and because Bridges had already been a co-author for the later edition of Constructive Mathematics by Bishop and Bridges, I take this as a relatively authoritative opinion on Bishop's viewpoint. On the subject of partial functions, the system RUSS of Bridges and Richman adds a classically false axiom: 

Looking at the draft that was linked above, it's more clear what Kunen means. He is just saying that the informal "definition" of the natural numbers that you might think of in school is circular when examined closely. And it is, in the sense that you have to start with some undefined concept, be it "natural number", "finite set", "proof", etc., to capture finiteness. However, Kunen does not dwell on that sort of philosohical point. He is simply saying that there is a formal and non-circular definition of ω in set theory, as the smallest infinite ordinal. This does give a rigorous definition, but it doesn't ensure that "finite" in an aribitrary model corresponds to our actual notion of finite. That is something that cannot be ensured in first-order logic. 

There is an equivalent condition for complete metrizability in terms of a game known as the Choquet game. The game is described, for example, in the book Classical Descriptive Set Theory by Kechris, who calls it the strong Choquet game. The game goes like this. The rounds are labeled with natural numbers. On round $i$, the first player chooses an open set $U_i$ and a point $x_i \in U_i$. The second player then chooses an open set $V_i$ with $x_i \in V_i \subseteq U_i$. At the second and subsequent rounds, the first player must additionally ensure that $U_{i+1} \subseteq V_i$, so the open sets that are chosen are nested $U_1 \supseteq V_1 \supseteq U_2 \supseteq V_2 \supseteq \cdots$. The second player wins if $\bigcap_{i\in\mathbb{N}} U_{i} \not = \emptyset$, which is equivalent to $\bigcap_{i\in\mathbb{N}} V_{i} \not = \emptyset$. It is an easy exercise to prove that if $(A,d)$ is completely metrizable then the second player has a winning strategy. Choquet proved the converse: a space is completely metrizable if and only if the second player has a winning strategy in the game for that space. Only the easy half of the equivalence is needed for our current purpose. So, if you can prove the second player does not have a winning strategy for a space, that is sufficient to disprove complete metrizability. In particular, one possible method in the current situation is to attempt to prove that the first player has a winning strategy in the game. 

There is no computable, countable nonstandard model of Peano arithmetic. This result is known as Tennenbaum's theorem after Stanley Tennenbaum. There is an online paper at [1]. So if you take any sentence $R$ in the language of PA that is not true in the standard model but is consistent with PA, it will be true in some countable model of PA but not in the (unique, up to isomorphism) computable model of PA. But I'm not sure if that addresses your question, because that answer is about models of a theory. In your question, it seems like you're talking about all countable models in the language of particular formula, rather than all models of a particular theory. To make the answer fit that question, we want to replace PA with a finitely axiomatized subtheory of PA for which the only computable model is the standard model. There is a heuristic principle that we should be able to find a subtheory like this by examining the proof of Tennenbaum's theorem, and reference [1] confirms that this does work. Let $T$ be the sentence that is the conjunction of the axioms of this subtheory. Let $R$ be the independent sentence from the first part, and look at the sentence $T \rightarrow \lnot R$. This will be true in every computable model (because the only computable model that satisfies $T$ is the standard model, which satisfies $\lnot R$). It will be false in any countable nonstandard model of PA in which $R$ holds, because $T$ is a subtheory of PA. 1: Richard Kaye, "Tennenbaum's Theorem for Models of Arithmetic", $URL$ (Note: I corrected the last paragraph based on a comment by Sergei Tropanets.) 

In general, the way that people approach these things is to look at provable equivalences over some fixed theory. So, for example, you could prove results of the following form: 

Here's another example. By a "computable well ordering" I will mean an index for a well-founded computable (total) linear order on $\omega$. Because ZFC is an effective theory, there must be some computable well ordering $\zeta$ that ZFC does not prove is a well ordering. This is because: 

In his Stanford Encyclopedia of Philosophy article "The Notation of Principia Mathematica", Bernard Linsky makes the following claim: 

It's interesting to ask how the model can think that its natural numbers are well founded, given that the descending sequence above was completely concrete. The answer is that if that sequence is defined within the model, as $a_k = n-k$, then $k$ can be any number in the model, even a nonstandard one, and the model verifies that this sequence reaches $0$ after $n$ steps. Only from an external viewpoint can we limit $k$ to an external set of "standard" natural numbers. 

You can also diagonalize directly against a purported bound-producing algorithm. Say that $R(j)$ returns a polynomial when run with any index $j$ of a polynomial time function as input. Define a function $B(j,n)$ as follows. On input $n$, run $R(j)$ for $n$ steps. If this doesn't halt, return $0$ immediately. Otherwise, if $R(j)$ does not return a polynomial when it halts, return $0$ immediately. Otherwise, if the polynomial is $p(x)$, waste at least $(n+p(n))^2$ steps and then return $0$. Note that for any $j$, the function $C_j(n) = \lambda n . B(j,n)$ is total and runs in polynomial time, and if $R(j)$ returns a polynomial then this is not a bound on the running time of $C_j(n)$. Now the function that takes a number $j$ and returns an index for the $C_j$ is a total computable function. So we can use the recursion theorem to produce an index $k$ such that $\phi_k(n) = C_k(n)$. Then $\phi_k$ will be a total polynomial-time function, but if $R(k)$ returns a polynomial then this is not an upper bound for $\phi_k$. Note: The previous paragraph requires more than the usual statement of the recursion theorem, it requires some knowledge of the proof to show that $\phi_k$ is polynomial-time. Here is the construction I need. Let $s(j,k)$ be the usual polynomial-time function such that $\phi_{s(j,k)}(n) \simeq \phi_j(k,n)$; the key point we need is that the running time of $\phi_{s(j,k)}(n)$ is polynomially bounded if the running time of $\phi_j(k,n)$ is polynomially bounded, and the first of these is not smaller than the second. This can be checked by examining the construction of $s$ in the chosen model of computation. Now let $d$ be the index for the computable function $\phi_d(j,n) = B(s(j,j),n)$ obtained by simple composition. Let $k = s(d,d)$. Then $\phi_k(n) = \phi_d(d,n) = B(k,n)$ as desired; this is the proof of the recursion theorem. Moreover, the implementation of these functions ensures that $\phi_k(n)$ runs in polynomial time but not faster than $B(k,n)$, because each computation of $\phi_k(n)$ consists of some polynomial-time-in-$n$ invocations of $s$ functions followed by the literal execution of the program for $B(k,n)$.