What we as humans can understand is automatically limited by our processing apparatus. If part of the world were inherently contradictory, we would find some way to pretend that it wasn't, simply because inherent contradiction is beyond the bounds of what we can reasonably abide. We might give up on explaining it at all, but we would never accept that it is simply two opposite things at once. We have a hard enough time with something like the wave-particle dualism where the two things something is at once arise from sort of orthogonal or independent models and are not really contradictory. We can, after all, imagine particles that maintain some kind of rhythm by becoming more and then less real as they move, or we can imagine a transitory wave that is suddenly called upon to be solid and changes instantaneously into a particle. The idea of a wave and the idea of a particle are not opposed, they just fit together poorly in our minds as metaphors. But our experience of true impossibilities are limited to the vagueness of words or the natural weakness of planning in rulesets. We cannot truly imagine a real and necessary contradiction that is not just an error, yet cannot be resolved, and is still meaningful and useful. We impose that expectation on nature as though it is not part of us, and that means that if we encountered it in reality, we simply could not decide to include it in our physics. It cannot be part of our physics, because it is alien to our mathematics. Other parts of logic and mathematics may make other parts of reality world equally hard to accept. And we might, therefore never succeed at explaining them. We might stop trying, or never start. They might pass us right by, and not appear real to us. If mathematics is so deeply a part of human understanding that it filters everything we perceive or interpret in this way, how is it mysterious that everything the filter lets through happens to agree very well with mathematics? 

Some aspects of divinity are implicit in the concept and form of God himself. Those aspects are properly eternal. They logically precede even the idea of time. But for other theistic idealists, there are ground-rules of existence more specific than those. Late idealists notion of divinely mandated Laws of Physics, Aristotle's 'Form and Purpose' or Plato's Ideas are atemporal, unaffected by time, yet they are created as an emanation of God, not predetermined by his form, so they do not apply to limit God himself. This expresses the 'Cartesian version' of omnipotence: God is unlimited not only by time and matter as it is actually, but by the forms and ideals themselves that shape what is and is not possible in reality, as those could have been made different than they are. These principles give time its form and effect, though they are unchanged by it. So although not subject to time, they do not apply outside time to limit God himself. They are not temporal, but they are not eternal. 

I would say that if that were true, we would always be certain of the morality of every one of our own actions. Perfect empathy with perfect communication would simply reduce an individual human into the collective of humanity in emotional terms. But since we are not always perfectly certain relative to ourselves, this combined whole would still not be certain of its correctness, and it would still need an ethics. Perfect empathy with imperfect communication gives us yet another reasons to doubt our collective decision making. You still need a way to determine what to do when you understand the other person completely, but you are not certain you have all the information they have or that they have all the information you have, and you cannot be certain that you can correct that situation. So the assumption of perfect empathy alone still has two strikes against it as a basis for replacing ethics. 

A semiotics is a way of studying symbols, in the same way that an epistemology is a way of looking at knowledge. So there are many, largely distinct, systems of semiotics. Dawkins' 'memetics' could be one of those eventually, but it is as of yet relatively underdeveloped, since it springs from a rather shallow analogy and not from data or a strong psychological or philosophical base. No one knows exactly what kind of unit we should look at as a candidate for 'meme-hood' and the range of options quickly undermines attempts to get started with any realistic argument. And yes, others include Jungian archetype theory, the Lacanian notion of the symbolic realm, and other psychoanalytic attempts to ground interpretation in common experience or literary history. But I do not think those predominate. 

Nietsche held this view. As a materialist with an assumption of Newtonian physics, and without the notion of chaotic strange attractors, which would not come along for quite some time, you are kind of stuck with it. Newton's time and space are infinite, so either things endlessly converge on a boring ending, or they eventually all align in the same state as one they occupied previously, and therefore endlessly loop. Most folks found the latter conclusion too weird, and supposed 'death in fire or in ice'. But this option seems more likely statistically -- things would either actually repeat, or converge so close that the difference could no longer matter. It emphasized for Nietsche that infinities and idealizations really do not remove the urgency of single acts, because time may be infinite, but freedom is still finite. The world may not end, but it might as well, as far as moral decisions go. We need to whip humanity into shape 'this time around'. However, issues of elementary physics cannot be put aside -- Our physics has changed. We now assume premise (3) is flawed: quantum mechanics requires that actual outcomes in particle interactions are necessarily random to a certain degree, and not totally determined by the properties and internal state of the particles themselves. Nor can modern mathematics -- Strange attractors do exist, continuous behavior can devolve into discontinuous chaos and lose all convergent qualities. So there could be causal threads that necessarily have different states at the end of each cycle and bleed into the next, without ever converging, no matter how long the cycle plays itself out. (I guess I did not answer the first part of the question. If mathematics is all part of logic, then no, by this last observation, the OP is no longer logically valid. It is at least no longer reasonable to assert it as necessary or likely, because chaotic behavior is ubiquitous. If advanced mathematics at some point becomes something beyond a part of logic, you need a whole theory about what mathematics is, in order to decide your answer.) 

I think 'non-sequitur' is a vast overstatement, and this is a mere 'over-generalization'. And not even very far 'over': the statement cannot generalize absolutely, but it does generalize pretty well. In a strong sense the homogeneity assumption is itself an application of the Copernican Principle. It is the assumption that we do not happen to inhabit a place where space is especially 'nice', in the sense of having the "Goldilocks" quantity of matter: that we don't live somewhere too special. So this is just a disagreement as to what flavor of 'general' is most objective, and either side relies upon a strong injection of the 'Copernican' ideal, but in different forms. Unwinding your objection to the Big Bang theory -- the weakest point is that it assumes that time is uniform in a very strong sense. It gets into big trouble if you follow the history of expansion back to when space would have to move objects apart faster than the speed of light in order to expand quickly enough. So, you can toss out the uniformity of time, but then the rationale behind continuously extrapolationing time back across trillions of years gets a little questionable. Why shouldn't time have changed again and again? The notion of the field particles arising out of the Higgs boson early in the history of the universe "when the rules were different" is the same sort of thing, it puts the irregularities away from us, so we feel like that place is special, not ours. Why assume the rules got decided at a given energy level and then stuck there forever? Why should they not slowly adapt across time? (And if we don't get to be special, why does anyone else? Harumph, <pout/>.) We end up with the notion that time and other basic forces can be significantly different, but in general they are just like we see them where we live. In the same way the homogeneity of density is Copernican, so is this notion of time and fields. It is about the familiar being general so that we don't imagine we are special again. I don't see the disconnection needed to make this a non-sequitur. The Copernican Principle is properly applied here, and if anything, too healthy. (From a Nietzsche angle, in rejecting the deductions of our slave-morality religion: that we are all equally special and masters are evil cheaters; we have taken up an even more slave-morality position on specialness: that we are not worthy -- we do not deserve it, but someone must.) The principle is internally inconsistent as a metaphysical principle: not all notions of 'general' can be equally objective, because we are someplace, and that place really will have some idiosyncratic properties. And picking and choosing which ones are most objective, just to favor the chosen explanations of our own physics, would violate the principle itself. Our place would be special in that it allowed us to truly see what was and was not special about it from experimental data. But that does not undermine its usability as a component of theories. It just requires compromise between different applications of the principle to be chosen by each theory. We just have to guess what is and is not special about home until we get a good sense of life abroad. ---- Separate second answer: There is also a compromise to be struck between the Copernican principle and the (Weak) Anthropic one. It is not impossible that things work out the way they are because we are here to observe them. A lot of biologists think we are in the "Goldilocks zone" of energy balance, and life is much less likely to arise at any other point on the spectrum of energy balance because small polar molecules in liquid form are scarce. And we do not accuse them of being anti-Copernican, we let this idea guide where we are spending public money looking for planets with life. We could also be in the "Goldilocks zone" of matter distribution, where observers are unlikely to survive elsewhere. The odds of just one hole goes down, but the theory of massive variations in distribution itself could still make sense. 

At least some part of thought is physical, or things like transcranial magnetic stimulation could not happen. And modern animal behaviorism, neurology and evolutionary psychology have given us a lot of indications that many of the reasons for the ways we think can be explained in terms of survival and other aspects of biology. The first part of Dennet's Consciousness, Explained collects up a bunch of those, and points at others. So, what is the resistance to imagining that the rest of thought can be explained by physiological processes? The more important question isn't whether this is true. The question is whether it is relevant. Many people accept that thought is caused by complex phiological functions, but consider it an 'emergent' phenomenon. Other examples of emergent phehomena are things like heat, acidity and molecular bonding. Each of these things has an accepted underlying explanation in a lower level of physics. And yet we cannot use that lower level explanation. There is too much complexity involved. It is nice to know that heat is explained by molecular motion, but we do not measure it that way, and we do not think about it in those terms when we do thermodynamic calculations. We think in terms of entropy, flow, conductance, etc. Apart from theorems that tie the base cause to the basic principles through statistical mechanics, we never think about heat that way at all. We largely use principles from Carnot, someone with an entirely different underlying theory of heat, as a subtle substance. Likewise, is it even helpful to work out the mechanics of thought? Or should we presume it will be as useful as measuring Brownian motion when you have a thermometer? The alternate view points out that we already know a lot of things about thought from an internal viewpoint. Why not use that information as our basis instead of pretending that we learn about thinking by observing others? Because we just don't. So it makes some sense to purposely not bow to the obsession with 'objectivity' that makes us consider alternative formulations misguided. If the real information should come from inside, emergentism is just a sop to throw to materialists. It doesn't gain us anything but an illusion of peace. What is solves is a non-problem. 

(This is all about the last question, not the main topic. I see this whole thing as an elaborate paranoid conspiracy theory, so I will not weigh in on the logic involved. But the people exploring it did exist.) There is an entire tradition of Neo-Platonist heresies, known collectively as "Gnosticisms", inside Christianity, that explore this idea that God is not good (or at least that any good God that exists is not the Creator God to which we have access.) And those people did consider themselves theologians. The most prominent forms were Bogomilism and Catharism, which believed that anything material could only be neutral, never good, and therefore the creator of the material world is merely tricking us into believing he is good. At that point, what could be more thoroughly evil than something that appears to be perfectly good, but is in fact not good at all? What more perverse lie could possibly be contrived? Therefore, they suggest, we should imagine the material world is a trap, so created reality as we know it is not actually even neutral, but evil. They interpreted Jesus and Paul as indicating that there is another world (Heaven) totally beyond this world, and we should forsake the material world altogether and resist the idea that its creator is ultimately good, omniscient, etc. or even well-intended. (They imagine that any world-affirming or gratitude-encouraging parts of the Bible are trickery insinuated later.) This led them to see the Creator and the real Father as two different beings, identifying the traits of perfection with the latter only and often identifying him with the God of Plato. They then clung fast to the Lucifer mythology and elaborated it in extreme detail, identifying the Judeo-Christian God with Lucifer, and considering the entire Church tradition as a misunderstanding. Recently (well recently enough, starting in the 19th century) scholars have uncovered the full texts of various lost alternative versions of the Gospel, that indicate this complex of ideas has roots going back to the same era as the orthodox Gospels. These contain the "words of Jesus" as they appear in most of the other Gospels, but less other shared material, and therefore may be the older, more original form of Christianity. (At the opposite extreme, they may be selectively skewed, trimmed down versions of the Gospel message meant to prove that Jesus himself never said anything that directly contradicted their unusual position. But the historiography largely supports the idea they are older.) 

Things that are true would be impossible to falsify. The exact collection of all truths is huge and not parsimonious, but it would be impossible to falsify -- being by definition a collection of truths. So there is no absolute logic here. And statistically, the shorter statement is more likely to be ambiguous and to fail to make a prediction, so to that degree it is less likely to be found false. No statement makes all predictions. So it is not reliably true statistically either. But Popper's standard of falsifiability is not about truth or falseness, it is about the specificity of the target event that would lead to a loss of belief if it were true. So things that are parsimonious have greater falsifiability. The parts of a theory that are redundant or overdetermined allow for other parts to be omitted or weakened in a way that would leave the theory standing. That means that if my theory is not parsimonious, I could correctly look at the theory, interpret its contents, target a premise, an find it false, without leading to falsifying the theory, because the theory has multiply covered the causal uses of the premise I chose. I would need a larger number of properly well-targeted events to result in the holder discarding the theory. From this point of view the parsimonious theory is "easier to falsify", in the positive sense in which that word is most often used. The faults it has are more easily seen, so it will lead to faster improvement in interpretation of the same data.