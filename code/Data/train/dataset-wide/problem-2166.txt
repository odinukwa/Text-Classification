Others have addressed the issue of whether adding a surrogate key (IDENTITY) is necessary, good, or helpful. I will address your question about whether adding a surrogate key will violate 3NF. The formal definition of third normal form as set out by E.F. Codd states that a relation is in 3NF if and only if: 

Your data model may be high level (entities/relationships only) or lower level (add in attributes with details of data types) and it may be logical or physical. It all depends on what stage of your design process you're at. The point of a data model is to record your database design, which is just an expression of your business requirements for persisting data. Crows foot and ERD etc. are just graphical conventions for showing your data model pictorially. The great thing about standards is that there's so many to choose from, and this is also true of graphical conventions. Read this wiki article for a sampling. Which conventions you choose may depend on what you need to communicate about your model, or it might just depend on what conventions make sense to you. Don't get too wound up about all the different terminology. It's all just your database design and how you choose to record and communicate it. 

Trying to normalize addresses is generally a bad idea. There isn't a lot of value to normalizing addresses. Both of your designs are inappropriate for the vast majority of systems. There are two things you typically do with addresses: 

What you are proposing is a good solution for your requirement of M:N products to categories and hierarchical categories. To avoid exposing yourself to numerous updates: You need to do two things to ensure that you don't have a lot of updates in your intersection table. First, you need to be sure that your categories have a stable, persistent primary key. Second, you need to link food items to leaf categories. Don't join to , , and - just join it to and . Your nested sets take care of all of the secondary (and higher level) associations. 

Taking your form snapshot as a guide, I've divided up the elements of your form into entities which I've colour coded: 

You can OR where clauses to get different sets of filtered data in one result set, but you can't combine multiple aggregations in a single query, unless you use sub-selects. Another option is to collect results from different aggregations into temporary tables and then join the details into a single output. 

If all you want to do is keep track of which authors contributed to which papers, then all you need is a simple intersecting entity (see more) like this: 

In this model each service is for one vehicle, but each service can have many instances of labour, parts and consumables. This model follows the first rule of thumb I mentioned and makes an entity type out of each tangible thing the system cares about. This might be a good first stab at a logical model. One of the issues with the above model is that it doesn't handle one aspect of how your system is likely to want to use the data, at least not very well. One of the most important reasons for tracking all of this data in your system at all is so that you can print off an itemized service invoice. That means that a service line item is itself a thing which is important to your system. If you take that into consideration, you might end up with something more like this: 

Why most of the time yes? The most fundamental answer to that question is that it is pure hell if you ever need to modify a primary key value on any table. Since almost anything a user can see or touch is conceivably subject to an update at some point, using a visible key value is inviting pure hell. Using a surrogate key will keep you from falling into this trap. Having said that, remember that there is room for YAGNI in applying this concept. You don't need to go forcing code tables with IDENTITY keys into every nook and cranny of your schema, just in case someone decides that the symbol for male gender in your employee table needs to change from M to X or something silly. 

You may have noticed that there is a difference between (1) and (2)/(3) when it comes to the nature of the extraction that you need to do. If you need to do both month/year over year and month range extractions then none of these options are perfect. If that is the case, I'd suggest you consider using a combination of (1) and either (2) or (3) - I'd pick (3) myself, since I'd value ease of display/use over storage space. If you do use a combination, make one or the other a computed column(s) and index it for efficient retrieval. 

Can you get a different answer for for any specific pair of and ? No, of course not. Arithmetic is arithmetic. Quantity and price charged depend on and , not on at all. In fact, also depends on and . EDIT: Partial Dependencies are dependencies on part of a multi-part key. Transitive Dependencies are things that depend on non-key attributes. Step one is to look at your initial relation and determine what the key of the whole thing is, or if there are multiple candidate keys, what they are. Here are the pieces that I'd guess make up your key, based on the limited sample data and some common sense: 

You need to look at where your sensitivities are going to lie. How many types of activity will you ultimately be tracking? How often are new types of activity going to be added to the mix? Are you prepared to endure the scorn of colleagues when they see you've implemented a solution with sparse columns (or worse) EAV? When you answer these questions you'll be able to pick the approach which makes the most palatable compromises for your application. 

Important Caveat: You need to look at the link OP provided! It uses the words and as jargon in a way which is similar to, but different than what programmers or even data modellers would do. 

In the past I have found it useful to maintain two sets of date ranges in a history table. The first date range is the "applies to period of time" range. This would indicate when, for your example, the linkage between a customer service and domain is made. You would use this range to determine what gets billed to who and for when. This range is set by your application probably based on some kind of direct action by your users. The second date range is the "when did it look like this" range. This range would indicate when the database actually held the values indicated in the rest of the record. You use this range to show what was the state of data population as of a given point in time. This range is set automatically using defaults/triggers, etc. It is this range that gives you the history.