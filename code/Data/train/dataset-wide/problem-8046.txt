No, as a counterexample take a closed "stadium" in $\mathbf{R}^2$ (the convex hull of two half-circles, I hope the word stadium makes it clear) and remove from it one of the endpoints of the half-circles. This is somehow related to the difference between extreme points and exposed points. 

This can be checked most easily after switching to a Gaussian integral as Yemon mentions. For the lower bound in 1, it may be useful to consider using concentration of measure. If it is a matter of reference, it can probably be extracted from Chapter 5.4 in Milman-Schechtman, "Asymptotic theory of finite-dimensional normed spaces". Indeed, the value of this average is closely related to the dimension of almost Euclidean sections of the space $\ell_q^n$. Edit: let me add more detail. First, (this is true for any norm of $\mathbb{R}^n$, just by rotational invariance of the Gaussian measure $\gamma_n$), we have $$ M = \frac{1}{\alpha_n} \int_{\mathbb{R}^n} \|x\|_q \, \mathrm{d} \gamma_n(x), $$ where $$\alpha_n = \int_{\mathbb{R}^n} \|x\|_2 \, \mathrm{d} \gamma_n(x) $$ is a constant very close to $\sqrt{n}$. Now write $$ M \leq \frac{1}{\alpha_n} \left(\int_{\mathbb{R}^n} \|x\|^q_q \, \mathrm{d} \gamma_n(x) \right)^{1/q} \simeq \sqrt{q} \cdot n^{1/q-1/2} $$ (use the fact the $L^q$ norm of a standard Gaussian variable is or order $\sqrt{q}$). This upper bound is sharp when $q \leq \log n$, this follows from concentration of measure. Finally for $q \geq \log n$, the norms $\|\cdot\|_q$ and $\|\cdot\|_{\infty}$ are equivalent, and the question reduces to estimating the expected maximum of $n$ i.i.d. standard Gaussian variables. 

Has anyone ever tackled this conjecture? Would it be an 'easy' conjecture? Let me make the conjecture precise, for the sake of clarity. Let $N$ be an even number and let $s(N)$ stand for the smallest prime such that $N-s(N)$ is prime (if such a prime exists, i.e. if $N$ is expressible as the sum of two primes.) Define the following set: $$S_m = \lbrace N \vert N \text{ is even and } s(N)^m > N-s(n) \rbrace $$ With this notation, Nash's conjecture asks: Is $S_3$ finite or infinite? Nash calculated the first member of $S_3$, which is 63274 = 293 + 62681. What about other values of $m$? If indeed $S_3$ is infinite, is there an $m$ such that $S_m$ is finite? (I'm tagging this as a reference request too since I know very little about the Goldbach literature and would be intrigued to read any related papers.) 

It is usually the case that this requirement is equivalent to $A_{m}$ having P for all maximal ideals $m$ of $A$. I was wondering which (if any) are the strongest/most interesting local properties $P$ of a commutative ring that do not satisfy the second equivalence. Similarly, I would like to know the strongest/most interesting non-local properties P that are true at all localizations at $p$. That is to say, what are the most interesting properties P of $A$ such that: 

This is well-documented in the case where $C_1$, $C_2$ are unit balls for some norm, and in that case your $C_1 \otimes C_2$ is the unit ball for the so-called projective norm. The set you compare to in the last paragraph is the unit ball for the so-called injective norm, which indeed is a different norm. Googling these keywords should give many results. Also, you may look at Chapter 4.1.4 in the book "G. Aubrun & S. Szarek, Alice and Bob Meet Banach: The Interface of Asymptotic Geometric Analysis and Quantum Information Theory", where we consider such projective tensor products for general convex sets. 

One feature of concentration of measure is that once you know concentration around some of the natural "averages" (mean, median, a given quantile, a given $L^p$ norm), you can derive formally that concentration holds around all of them. In your case $\sqrt{k/n}$ is the $L^2$-average of the function $f : x \mapsto \|P_Vx\|_2$. This discussed in Chapter 5.2 in G.Aubrun and S.J.Szarek, Alice and Bob meet Banach:The Interface of Asymptotic Geometric Analysis and Quantum Information Theory), for the case of $L^2$ average see Exercise 5.46. This possibly won't give the constants you claim in (1). 

The definitions are indeed equivalent. The idea of 'local smallness' is to get for any $X$,$Y$ in $\mathcal{C}^I$ an object of your indexing category to represent, as it were, all (vertical) morphisms between $X$ and $Y$. Both definitions describe this fact, although Johnstone's is, I guess, slightly more 'general' than it needs to be in that it applies the above property to any $X$ and $Y$ in $\mathcal{C}$ (and not to $X$, $Y$ in the same fibre), but that's OK by Theorem 10.1 in Streicher since $\mathcal{S}$ has finite limits. The equivalence of the definitions can also be proved as exercises 8.8.9 and 8.8.10 in Volume 2 of Borceaux. To see that they are equivalent let for simplicity $X$ and $Y$ lie on the same fibre $I$ (WLOG bearing in mind what I said above.) Then Johnstone's definition says that there exists an arrow $\alpha \colon J \rightarrow I$ and a morphism $f \colon \alpha^*X \rightarrow \alpha^*Y$ such that for any $\beta \colon K \rightarrow I$ and any morphism $g \colon \beta^*X \rightarrow \beta^*Y$ there exists a unique $u: K \rightarrow J$ such that $$u^{*}(f) = g$$ and $\alpha \circ u = \beta$. But now if you write $J$ as $H_{X,Y}$ and $\alpha$ as $h_{X,Y}$ you'll see that the last sentence says exactly that there is a bijection between morphisms $f \colon \beta^*X \rightarrow \beta^*Y$ and morphisms $u$ such that $h_{X,Y} \circ u = \beta$, i.e. between morphisms from $\beta$ to $h_{X,Y}$ in $\mathcal{S}/I$. And this is exactly the second definition. 

For the question with the absolute value, the expectation is maximal when the variables are independent (a special case of the Khatri-Sidak inequality). For the question witout absolute value, it is natural to conjecture that the maximum occurs when the variables form a regular simplex in $L^2$. I think I saw this conjecture formulated once in a paper about stochastic geometry. Edit: the question appears explicitly here (page 5). It can be reformulated as the question whether the regular simplex maximizes the mean width among simplices inscribed in a Euclidean ball in $\mathbf{R}^{n-1}$. 

This question has been studied here (but no characterization is given) Marcus, Marvin; Kidman, Kent; Sandy, Markus. Products of elementary doubly stochastic matrices. Linear and Multilinear Algebra 15 (1984), no. 3-4, 331–340. Note also that if we consider the family of matrices with rows and columns adding up to 1 (but allow negative entries) and $\alpha \in \mathbf{R}$, the corresponding result is true, see Johnsen, E. C. Essentially doubly stochastic matrices. III. Products of elementary matrices. Linear and Multilinear Algebra 1 (1973), no. 1, 33–45. 

That said, students will most likely encounter Sylow p-groups before Galois Theory. But that's not really an argument against providing the proof of FTA as a 'spectacular' application - especially if students are familiar with some basic field theory. The Galois theory it uses is in any case very elementary. And of course the key step is to show that $\vert$Gal$(k/\mathbb{R})\vert = 2^m$ which cannot be done without Sylow. If anything this application illustrates exactly what a course on group theory should illustrate which is that a lot of analytic-flavoured questions involve insights that are much more adequately generalized in the framework of algebraic structures. (Of course some elementary analytic facts are still required in the proof.) 

By "proper" here I mean a theorem that is about the properties of a countable set of (first-order) sentences as they are reflected in the properties of their models. That is to say, in the case of Putnam's theorem (which I think is improper), it seems to me that it doesn't really say anything about $ZF$ - instead it describes the metatheory in which it is interpreted using model-theoretic language (and succeeds in doing so by assuming an outer $\omega$ and $\mathbb{P}(\omega)$ which exist independently of the metatheory or the particular set theory being interpreted.) And the related question: 

Yes, a classical result says that every 2-dimensional (real) normed space embeds into L^1. Alternatively, if we assume that the unit ball is a $2n$-gon (the general case then follows by approximation), the corresponding space embeds into $\ell_1^n$. The dual picture is maybe even more transparent : any symmetric $2n$-gon is the Minkoswki sum of $n$ segments, and therefore is a projection of the $n$-cube. (key word : zonoid) 

The inequality is true for $2 \times 2$ self-adjoint matrices, because of the following formula, which is reminiscent of $\max(|a|,|b|)=\frac{1}{2}|a+b|+\frac{1}{2}|a-b|$ $$ \|A\| = \frac{1}{2} | \mathrm{tr} A | + \frac{1}{\sqrt{2}} \| P(A) \|_2 $$ where $\|\cdot\|_2$ is the Hilbert-Schmidt (or Frobenius) norm and $P(A)= A - \frac{\mathrm{tr} A}{2} \mathrm{Id}$ is the orthogonal projection onto the subspace of trace $0$ matrices. Both terms in this sum satisfy Hlawka's inequality (the Hilbert--Schmidt norm is a Euclidean norm). Geometrically the unit ball of $2 \times 2$ self-adjoint matrices looks like a tridimensional double-cone over a disk (extreme points are reflections and $\pm \mathrm{Id}$), which is a geometric way to interpret the formula above. In the non-self-adjoint case I don't have such a clear picture. 

You can prove that the two theories are, in fact, equivalent. By induction (NB: 'meta-induction') on the number of parameters, we can reduce the claim to the case where you have a theory $T$ with the usual induction schema and a theory $T'$ that is an extension of $T$ by a one-parameter induction schema. So assume $T$ and $T'$ are not equivalent. This implies that there is a model $\mathcal{M} \vDash T'$ and a two-place open sentence $\phi(x,y)$ such that $$\mathcal{M} \vDash \phi(0,\beta) \wedge (\forall x (\phi(x,\beta) \rightarrow \phi(x+1,\beta))) $$ but also, $$\mathcal{M} \nvDash \forall x \phi(x,\beta)$$ for some $\beta \in \mathcal{M}$. But note now that the above is equivalent to $$ \mathcal{M} \vDash \exists y (\phi(0,y) \wedge (\forall z (\phi(z,y) \rightarrow \phi(z+1,y))) \wedge \neg \forall z \phi(z,y) $$ and if you call this last sentence $S$ then you get that $S \wedge \phi ' (x)$ violates the usual induction-schema, where $\phi ' (x)$ is the one-place open sentence we get by by closing $y$ under the existential quantifier in $S$. That is to say we have $S \wedge \phi ' (0)$ and $ \forall x (S \wedge \phi ' (x) \rightarrow S \wedge \phi ' (x+1))$ but not $\forall x S \wedge \phi ' (x)$. But that is a contradiction since $\mathcal{M}$ is a model of $T$. Hence the two theories are equivalent. 

Hypercontractivity implies that for a polynomial $P$ of total degree $d$ in Gaussian variables and $q \geq 2$, we have $$ \|P\|_{L^q} \leq (q-1)^{d/2} \|P\|_{L^2} .$$ Applying Markov inequality for the optimal $q$ yields then for $t \geq C_d$ $$ \mathrm{Prob} \left(|P- \mathbf{E} P| \geq t \sqrt{\mathrm{Var}(P)} \right) \leq \exp(-c_d t^{2/d} ) $$ for some constants $C_d,c_d$. 

A self-dual norm on $\mathbf{C}^2$ need not be Hilbertian. Here is an example: $$ \|(z_1,z_2)\| = \begin{cases} |z_1|+|z_2| & if \ \ \ |z_1| \leq |z_2| \\ 2|z_1| & if \ \ \ |z_1| \geq |z_2|. \end{cases} $$ The dual norm $\|\cdot\|^*$ satisfies $\|(z_1,z_2)\|^*=\frac{1}{2}\|(z_2,z_1)\|$. Here a picture for $z_1$, $z_2$ real with $\|\cdot\|=1$ in blue and $\|\cdot\|^*=1$ in red. 

Here is a complete answer in dimension 2. Among all the norms on $\mathbb{R}^2$ which are invariant under the dihedral group $D_8$, the extremal rays are norms whose unit ball are octagons with the required symmetries ($\ell_1$ and $\ell_{\infty}$ appear as octagons which degenerate into squares). The reason is specific to dimension 2: any norm on $\mathbb{R}^2$ is of form $$ \|x\| = \int_{S^1} | \langle x , \theta \rangle | d \mu(\theta) $$ for a positive finite measure $\mu$ on $S^1$. (This measure is unique if we require that it is even.) In other words, any 2-dimensional real space embeds into $L^1$. This fails for the $\ell_{\infty}$ norm on $\mathbb{R}^3$. Under the required symmetries, the measure $\mu$ is uniquely defined by its restriction to the west-northwest part of the unit circle. Among those, extreme rays are Dirac masses, leading to octagons. In higher dimensions you get examples of such norms using Orlicz norms. I don't know what are the extreme rays there. Edit : here are some references, A Class of Convex Bodies Ethan D. Bolker Transactions of the American Mathematical Society Vol. 145 (Nov., 1969), pp. 323-345. Schneider, Rolf, and Wolfgang Weil. "Zonoids and related topics." Convexity and its Applications. Birkhäuser Basel, 1983. 296-317. 

EDIT: After comments and answers received have edited (and expanded) the question. Hope it is clear and unambiguous now. 

You can prove the Fundamental Theorem of Algebra using Sylow 2-subgroups. The sketch of the proof is as follows: 

Now to the title question. In his "proof" (quotation marks because I'm not yet sure whether it is a proof or a plausibility argument) of the Theorem, after reducing the statement to something equivalent, he writes: 

Take a (WLOG) normal extension $k$ of $\mathbb{R}$ of degree $n$ and a 2-subgroup $H$ of $G=$Gal$(k/\mathbb{R}$). Then $[\text{Fix}(H):\mathbb{R}]=\vert G \vert / \vert H \vert $ and hence since $H$ is a 2-group $n$ must be odd and hence trivial. So $G=H$, i.e. $\vert G \vert = 2^m$ Therefore, by taking a subgroup $N$ of $G$ of index $2$ show that Fix$(N)/\mathbb{R}$ is $\mathbb{R}(\theta)$ for a negative square root $\theta$ and hence that Fix$(N)=\mathbb{C}$. Then by a quick argument Gal$(k/\text{Fix}(N))=$Gal$(k/\mathbb{C})=1$ and hence $k=\mathbb{C}$. Hence $\mathbb{C}$ is the only extension of $\mathbb{R}$ and the FTA follows immediately. 

Hidden in the comment by Victor Kleptsyn is a really nice argument. Since nobody upvoted that comment yet (I just did) it's probably worth expanding it. From a probabilistic approach it's more natural to show the equivalent statement that the expectation of $(\det A)^2$ equals $\frac{(n+1)!}{(n(n+1))^n}$. The trick is to realize the uniform measure on the simplex as the distribution of $$ (X_1,\dots,X_n) := \frac{(Y_1,\dots,Y_n)}{Y_1 + \cdots +Y_n} $$ where $(Y_i)$ are i.i.d. exponential random variables (say, of parameter 1). All you need to know is that $\mathbf{E} [Y_i] =1$ and $\mathbf{E} [Y_i^2] =2$. Moreover in this representation $(X_i)$ are independent from $S:=Y_1+\cdots+Y_n$. It follows that we have the following identity in distribution $$ B = D A $$ where $B$ is a matrix with i.i.d. exponential entries and $D$ a diagonal matrix whose entries are independent copies of $S$, with $A$ and $D$ moreover independent. Therefore $$ \mathbf{E} [\det B^2] = \mathbf{E} [\det D^2] \cdot \mathbf{E} [\det A^2] .$$ It is very easy to check that $\mathbf{E} [\det D^2] = (n(n+1))^n$, and $\mathbf{E} [\det B^2]$ can be expanded as $$ \sum_{\sigma,\tau \in \mathfrak{S}_n} \varepsilon(\sigma) \varepsilon(\tau) 2^{Fix(\sigma \tau^{-1})} = n! \sum_{\pi \in \mathfrak{S}_n} \varepsilon(\pi) 2^{Fix(\pi)} = n! \det \begin{pmatrix} 2 & 1 & \cdots & 1 \\ 1 & 2 & \ddots & \vdots \\ \vdots & \ddots & \ddots & \vdots \\ 1 & \cdots & \cdots & 2 \end{pmatrix} = (n+1)!$$ (Here $Fix$ denotes the number of fixed points.)