A CNAME should work the way you want it to as long as the application is not accessed using TLS/SSL, and uses relative rather than absolute URIs for its internal links. But a SaaS application certainly should use TLS, and if it does then you'll get a certificate name mismatch warning in the browser, since the certificate will be for a.y.com (or *.y.com) and not for a.x.com. 

It depends on the Linux image you're running, but generally you can sudo from the initial login user account to gain root privileges. 

No, it can't. There's no reliable way to identify the user at the Ethernet, IP or TCP levels, which is all it has to work with. 

The forbidden image is being cached in your web browser. You need to use mod_headers to set it to never cache. Try: 

Survivor1 and Survivor2 are used alternately. Minor GCs scan everything in one survivor space, and move anything that's still needed into the other one, so exactly two are needed. 

You've divided your 10GB disk, xvda, into two partitions: xvda1 is 6GB and xvda2 is 4GB. So your other 4GB is in xvda2, and you can mount it somewhere if you want to use it. 

FAT32 is your best option for read/write access from Windows, OS X and Linux with no third-party add-ons. Note that it won't support individual files larger than 4GB. 

Assuming that your crashed table is in a DB called current, your restored backup is in a DB called backup, and there's a primary key called id: 

It's impossible to say without detailed information on the performance characteristics of your particular application. If you're serving static HTML via nginx then your current VPS should be fine up to a million pages per day or more; if you have an application that does complicated database lookups for every page served and then runs a computationally expensive algorithm on the result then you're going to need a load balancer and a whole bank of servers to get to 500,000 pages per day. 

That screenshot is not where you would go to create a VPC. You need to go to the VPC section of AWS, not the EC2 section, and create a VPC. Then create an Internet gateway. Then create a routing table and set it to route via the Internet gateway. Then create some subnets. Then, and only then, will you be able to create an instance in the VPC. 

Yes, that should be no problem. Just stop your instance, and you can then change the instance type to t2.micro and start it again. For other instance types, you'd have to worry about losing data from your instance-store volumes, but t1.micro and t2.micro instances don't have any. However, you should note that its IP addresses will change unless you have an Elastic IP Address for it. 

Depends on the subnet mask on the server. If the subnet mask is set so that the .255 address is the last address in the subnet, then there's no way to connect to it over the network. If not, then change the subnet mask on any other machine on the network (Windows or Linux) to match, and you'll be able to connect to it. 

The authoritative name servers for the domain are ns1.netsonic.net and ns2.netsonic.net, and they're refusing requests for that domain name. Either your registrar is pointing at the wrong authoritative name servers, or your DNS provider has screwed up. 

I'm running an nginx instance that's acting as an SSL termination point and basic load balancer on an EC2 virtual server, and seeing very poor performance for the SSL pages served from the upstream source. The EC2 instance is a c1.medium, and ought to be able to sustain a reasonable throughput, but I can't get it above 60 transactions per second. Serving the nginx status page directly off the server, I manage more than ten times the throughput, so it's not purely SSL overhead, but if I reconfigure it to serve the same content without SSL I also do very much better, so it's also not upstream overhead. The CPU is maxed out while it's serving its 60 transactions per second. I'm using ab to test it, with parameters "-n 1000 -c 50 -k" -- 1000 hits, concurrency of 50, keepalives enabled so that the SSL session caching ought to work. Here's an abbreviated config: 

The DNS traversal checker at squish.net is extremely useful for diagnosing DNS issues. In this case, it says: 

You can't, I'm afraid. There isn't another verification method that you've missed. You'll have to do as you suggest -- create inboxes and then delete them. 

To prevent software from being copied illegally, simply authorise the recipient to copy it. Then any copies he makes will be legal. If you want to prevent it from being copied at all, whether legally or illegally, that would be a different question. 

Get an SSL certificate that uses subjectAltName and is valid for both example.com and example.co.uk, and then you can run SSL name-based virtual servers and do the 301 redirect all on the same server. Or if your server and all your clients support SNI you can do the same with two different certificates (the most likely clients that won't support it are IE on Windows XP and Chrome on Android versions before 3.0). 

If you're using spawn-fcgi to spawn the PHP process, just add "-u <username>" to the spawn-fcgi command. 

No, it's unlikely that the distance from France to Canada is making any significant difference, or that getting a Canadian VPN would help. If the server is overloaded, then there's nothing that you can do except for doing your download at a quieter time. The server's operators need to upgrade it. The only exception to this would be if the server's external Internet bandwidth is what's overloaded and you can get a VPN connection that uses a different Internet connection to connect to the same local network as the server is on. But that's very unlikely. 

I'm not sure what you mean by the "@ A name". If you mean the A record for your domain name, then it should normally be pointed at the server IP address. If you mean the MX record, then it should be pointed at whatever server you want to be handling email sent to your domain (and you should have at least a second one, pointing at a different server). None of your DNS records should normally point to the host's nameserver (unless it also happens to be an authoritative nameserver for your domain name, which would be bad practice). 

If it's reinstantiating itself then you've probably got it in an auto-scaling group. Delete that auto-scaling group (or reduce the minimum instance count to zero). 

You have to set it up as a ring -- A is the master for B, B is the master for C, and C is the master for A. And don't forget to set the option so that they will pass on upstream changes, and set to 0 so that the updates won't go round and round the ring for ever. Read this article -- the ring configuration is described on page 2. 

The browser is warning about mixed domains because you're using mixed domains. The fact that they happen to use the same wildcard certificate is not relevant here. Everything is working the way it's supposed to. The fix is to not use mixed domains on your SSL websites. 

When your processes require more memory than you have RAM on your server, they "swap" some of their memory space onto disk, in your swap partition. Accessing this virtual memory is very much slower than accessing real RAM, so if it gets to the point where frequently used data has to be swapped in and out, it will cripple the performance of your system. 

New A records shouldn't have any propagation delay at all, since they aren't cached anywhere. Any DNS client that can't find your new record in a cache should be going direct to your authoritative servers. It's only changes to existing records that can suffer from a delay. 

There's no technical reason why you can't use a wildcard SSL certificate for *.example.co.uk on as many servers as you want whose domain names match the wildcard. But some certificate issuers have commercial terms & conditions that limit the number of servers on which the certificate can be used. It's not a technical limit, and the certificate will still work on as many servers as you want; you'll just be in breach of your contract with them if you use it on more servers than you have agreed. Of course that won't apply to your self-signed certificates that you're using to test it out, but it may when you get round to actually obtaining a certificate that's signed by a trusted CA. 

The first MX means that the IP addresses in the MX record(s) for the domain you're actually attaching the SPF record to should be accepted as valid. The second one means that IP addresses in the MX record(s) for the domain mail.mydomain.com should be accepted as valid. If this SPF record is for the domain mail.mydomain.com, then the second one is redundant. However, if the SPF record is for mydomain.com, then the second MX is not redundant.