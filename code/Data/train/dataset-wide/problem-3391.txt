Very bad idea for the least. I have had a setup before where we had Apache+MySQL on the same server and it would regularly go over 10 load average and the pages would take forever to load. We split both services and put MySQL on a smaller server. Both servers would never go above 0.35 of load average. Do the math... There is a lot of loss into putting Web server + DB server on the same server. Evan also has a good point. Merging things into a machine tends to lead to many shortcuts which make scaling out a lot harder. One service = one OS is a good rule of thumb (would have said one service = one machine but now there is virtualization). 

Also, Windows web server also have some pretty advanced features. Thinking that LAMP is necessarily more customizable by a large margin is not always true. I'm a Linux person myself but I have seen Windows people do pretty advanced things with IIS. Having a GUI kills the 1337-command-line-mad-skills impression but remember that it may only be an impression. Just as an example, AFAIK the Stack Exchange network (so this site included) is run on Windows web servers. That goes to show that you can do great things with Windows. 

Routing is a layer 3 technique that gets your packets where they are supposed to go. Layer 3 information is almost only source IP, dest IP and fragmentation information. Extra information such as domain name is way beyond layer 3, it's more layer 7 (the application layer). Therefore such information is not meant to be used for routing. There are specific techniques that use information above layer 3, such as Policy Routing which uses layer 4 information (TCP/UDP ports) to route specific packets. That is as high as it goes as far as I know. If you have control over that domain name, you could specify as specific IP that will then be routed by your routers in a specific way. If you can't do that, I'm afraid it's not going to be possible as far as I know. 

We have a number of Soekris boxes running Debian Squeeze. They were installed through an automated process consisting of using deboostrap and copying it unto a Compact Flash card. We use puppet to manage the configuration of all these boxes. Before Debian Squeeze, they were running Voyage Linux which is just a "lighter" version of Debian. Since we have switched, we're seeing the /lib/udev/net.agent process take up an aweful lot of CPU. We have so far been unable to find any clue as to what this really does and why it's taking up some much CPU time. In htop we see the following : 

You will find such info in the X.org config file : /etc/X11/xorg.conf. This file manages all graphics card info :-) 

Pfsense can do most of this if you add extra packages which are easily installable inside the distribution. It is also very stable and intuitive to use. 

400MB of space for a video that sounds very uncompressed... That is way too big for 3-4 minutes. For the bandwidth per month, simple math 5000 * 1 * 400 = 2TB per day. That's way too much bandwith for a normal hosting plan package. You should consider getting a dedicated server. You should also consider instantaneous bandwidth. This means you have to ask yourself : "How many users will watch the video at once at peak time ?". You're not going to need as much bandwidth if they all watch it at the same time or if they all watch it one at a time. You have to check the bit rate of your video in order to know a little more about this. 

Two firewalls filtering the same LAN would sound wrong if they were back to back with no other network. You need to check these firewalls and make a map of the network in order to be able to decide. Only this will give you the information you're looking for. 

The kernel will apply different priorities to specific processes. You can see this by running "top" and checking the "nice" column. The time critical OS processes will therefore have a higher priority. Therefore, the OS will run these processes before your specific applications. This will make sure that these processes happen at the right moment. This mechanism makes a core reservation pretty much useless. 

Have you considered using "redistribute static" on the router carrying the static route in question ? EDIT : If the route is not propagating from the "bridge" router, you must do "redistribute rip subnets" in your OSPFv3 configuration. 

Pfsense will do that for you. The feature in pfsense is called Captive Portal for your guests. The user list is either managed via a Radius server or a local database (makes it really simple to setup). For employees, you just have to enter the MAC of their PC and they won't be prompted for username/password. This indeed does require you to install a server but pfsense can really fit on any hardware. 

I'm going to have to disagree here... The fact that the ARM has no virtualization technology is not an argument at all. Xen and OpenVZ do not need processor virtualization extensions. If it makes sense is not so much a question of hardware but of software. In your setup, I would recommend OpenVZ which will create specific environments for each of your services. I'm 99.9% sure Xen will run on it as well but it will be much slower. So, I think it can make sense if you use efficient virtualization software (of which VMWare and Hyper-V are obviously excluded). Will it be blazing fast ? No definently not but it will work. In a more-or-less similar context, I once setup a Sempron LE 1.8Ghz system with 2GB of RAM. With Xen, we had 7 Debian Lenny VM running and it ran fine. Obviously, you can't do that with VMWare but that doesn't mean you can't do it at all. EDIT : Puppet is just automation software. OpenVZ/Xen provide isolation of your services and ressource allocation algorithms to make sure each "box" has a fair share of ressources. With puppet, ressource allocation would be taken care of by regular kernel. OpenVZ/Xen would keep any software conflict from happening (because of the isolation) but with Puppet you're on your own. So we are looking at two very different things. 

I think that is perfectly fine. It wouldn't be a good idea to put their LAN IP because if that ever changes, the DNS resolution may be broken. 127.0.0.1 will never change and will always point to the right ressource so you can just leave this as is. 

Just for the record, as ServerFault seems to be very VMware oriented, this is also possible with Citrix XenServer. It works pretty much like VMWare, you put a CD into a machine and it gets uploaded to a virtualization server which then executes it. The extra advantage is that you can have paravirtualization with Linux/BSD/Solaris which leads to much better performance then VMWare. Also XenServer is much cheaper then VMWare. 

Paris Fire Departement still uses a lot of dot matrix printers to send out information. It is used to print out a bunch of really important telex (oh yeah ! ) 

You should really consider pfsense which is a embedded distribution that does FW/Router and captive portal. It is extremely simple to use and works great. 

We have put in place the two cron jobs that should allow disk space to be freed. They are the following and both run daily : 

There exists VGA splitters that take a single VGA output and emulate a huge resolution which is split on two or three other screens. Matrox makes these I believe. Another way is to go SLI, that will allow you to go up to 4 VGA outputs. 

First of all, both providers must use the same virtualization technology. If that is not the case, forget it (or get lucky). Second, you must be able to get the raw image of your VM which should roughly be the weight of all the data in your VM if it's a sparse image or the size of your partition if it's a full image. This image is usually stored on a SAN or NAS at the provider's datacentre. I have never seen this being possible... An alternative could be backup software. I know that there exists software that are capable of backing up an entire OS but I don't have any names in mind. 

I will complete Zoredache's answer. A L2 switch does switching only. This means that it uses MAC addresses to switch the packets from a port to the destination port (and only the destination port). It therefore maintains a MAC address table so that it can remember which ports have which MAC address associated. A L3 switch also does switching exactly like a L2 switch. The L3 means that it has an identity from the L3 layer. Practically this means that a L3 switch is capable of having IP addresses and doing routing. For intra-VLAN communication, it uses the MAC address table. For extra-VLAN communication, it uses the IP routing table. This is simple but you could say "Hey but my Cisco 2960 is a L2 switch and it has a VLAN interface with an IP !". You are perfectly right but that VLAN interface cannot be used for IP routing since the switch does not maintain an IP routing table. 

You really should consider DRBD (RAID-1 over TCP/IP) with a multi-node filesystem such as OCFS or GFS. You can also consider getting a SAN on which you will be able to put any one of these filesystems as well. 

Yes. What you want to do is impose an open_basedir directive for each site. You specify a directory and therefore no PHP script will be able to crawl out of that directory. This means that you need a specific directive per website so either you set the aforementioned directive via a .htaccess or via a per-site php.ini. To implement the last option, you will need suPHP or something similar. 

Use the open_basedir directive to confine your PHP scripts to their home directory and eventual extra application directories. This is very efficient by itself. Use hardened php because that costs nothing and it can help. Use suPHP to have PHP scripts execute as the owner of the file (one user per website) and avoid using files with bad permissions such as 777... suPHP can also allow you to have on php.ini per website so that one site's stupid requirement don't destroy everything. Mod_security is a big plus but needs to be well used and configured. 

I am unable to answer all the questions you have asked but there is one host who has based mostly all of their strategy on water-based cooling and that is OVH. All their servers are water-cooled which allows them to offer interesting prices. If I remember the stats correctly, they are the biggest hosting company in Europe and 5th in the world. So yes, it can work. Is it simple ? No. They manufacture most of their watercooling equipement which induces steep upfront costs. Nonetheless it leads to great energy efficiency. Can you reuse the heated water? I'm not so sure as you don't want the water to get too high in temperature as it will lose it's efficiency to cool down your servers. 

You will have the choice between SLC (Single Level Cell) and MLC (Multi-Level Cell). SLC is much (at least 5 times) faster then MLC when it comes to writes. Depending on how many servers you are wanting to set up, you should put them in a RAID10 to get even more performance. A 32GB Intel X-25E (SLC) can be had for 375$. A 160GB Intel X-25M (MLC) can be had for 405$. 

Considering the above information, everything seems to be running perfectly fine yet in reality no data gets copied over. I modify the master database and no changes show up on the slave database. What am I doing wrong ? 

I ended up using a "client-config-dir" that allowed me to specify the route behind each client using the "iroute" command. Afterwards, I had the VPN server push a route for all these subnets to all the other clients and it worked fine. 

I am needing help in the configuration process of my Cisco ASA 5510. I have set up 4 Cisco ASA interconnected together via a big LAN. Each Cisco ASA has 3 or 4 LANs attached to them. The IP routing part is taken care of by OSPF. My problem is on another level. A computer connected to one of the LANs attached to an ASA has no problem communicating with the outside world. The outside world being anything "after" the ASA. My problem is that I am completely unable to have them communicate with another LAN connected to the same ASA. To rephrase this, I am unable to send traffic from one interface of a given ASA to another interface of the same ASA. My configuration is the following :