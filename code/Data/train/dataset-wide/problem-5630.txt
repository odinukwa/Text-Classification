What is the name of a/the metaphysic that affirms the reality of all worlds including impossible worlds? Actualism denies the reality of all non-actual worlds, possibilism affirms the reality of all possible worlds, and anti-realism denies the reality of all worlds (including the actual world). 

The argument in red cannot be deduced validly from the argument in green. All they have in common is that they're both arguments with two premises. To answer the question in the title, every conditional sentence (i.e. any hypothetical proposition) has a logically equivalent disjunction wherein the protasis is a negated disjunct and the apodosis is not a negated disjunct. "If P then Q" means "Q or not-P". In conventional notation of symbolic logic, P→Q is a hypothetical proposition that is logically equivalent to the disjunction Q∨¬P. Therefore, modus ponens has the following form: 

There is an important difference between the paradox of the heaps and the fallacy of the heaps. The former also is known as the continuum paradox or the sorites paradox (from σωρείτης), and the latter also is known as the continuum fallacy or sorites fallacy. (soros, from σωρός, is Greek for "heap".) The paradox of the heaps is the paradox described in the prompt-question of this thread. A man was once a boy, but the instant the boy became a man is equivocal. The continuum of a lifetime seems to make arbitrary any rigid designations of time distinguishing childhood from adulthood. Nonetheless, it would be fallacious to argue that this, on its own, implies that a lifetime either is entirely childhood or is entirely adulthood. It is a fallacy of the heaps to argue that the fact of continuum precludes any meaningful distinctions of regions along a continuum. For example, amounts of heat vary on a continuum, and water boils/freezes when it becomes sufficiently hot/cold such that, on a heat-continuum, there are meaningfully distinct regions. Therefore, it is not true that, for every continuum, there are no meaningfully distinct regions. Of course, there are some continuums in which there do not seem to be any meaningfully distinct regions. For example, the real number line, as a continuum of 1-dimensional space, does not seem to have any meaningful distinct regions, although it has meaningfully distinct subsets (e.g. the set of integers, of irrational numbers, and of natural numbers). 

Is finding a solution for a problem in a given context is an attempt to find a solution for the problem in another context? For example, it seems some of the hardest problems of real analysis were not solved till their solutions were found in the context of geometry. Update: I think it makes the question more clear if I provide an example. Lets say I want to prove if x+y=x+z, then y=z, where x,y,z $\in F$, where $F$ is a an algebraic field with operation "+". For example for this problem I can think of context where solution exits and that would be the ring of integers. If 1+2=2+1 then I can show 1=1. Now once this solution is found using this context of integers I can now apply this to the original problem in the context of field. Now what I was asking was that should such a solution exists in some contexts (context as used in example above) for a problem to be solvable. I do not know the background science behind this but it would be great if references can be introduced so I can get to know the right terminology. 

Preamble: I think we have this sort of questions, where we are required to find a solution for them. For example, what is the area of a circle?. I think the way to solve these problems is to try to find similar problems. If the solution to the similar problems does not apply, then we try to figure out why, and this might help us to find the right solution. However, we have another type of problems, where we need to establish the truth of something. For example, proving a theorem, which are in nature different from the first type of questions. I do not think the same approach as before can be applied for these problems. I do not think there exist recipes or structures to follow either once it comes to proving things, but I do think there should be certain strategies or plan as you wish to approach these in mathematics? Questions: Based on the above introduction, I have the following questions: 

In response to (2), "The definite integral, from x=a to x=b, of Euler's number multiplied by itself x-number of times" is not a sentence, but rather is a predicate term when combined with a copula. Therein, it can be a word as a propositional term that is a referent of the aforementioned predicate term. It is a word to the extent that a predicate without a copula can be a word. It is a predicate because it refers to the properties that are in the extension of that mathematical function. To equate the function to something is to create a sentence wherein "equals" is the predicate's copula. For example, "The definite integral, from x=a to x=b, of Euler's number multiplied by itself x-number of times equals the number Z", in first-order logic, has the following form (wherein P is the predicate term "is equal to the number Z" and wherein Q is the predicate term "is equal to the definite integral, from x=a to x=b, of Euler's number multiplied by itself x-number of times": ∃y:Py∧Qy. Whether or not the categorical proposition is true is another matter entirely. It's possible that ∃y:Py∧Qy is false such that ∄y:Py∧Qy possibly is true. 

A category mistake is when, for the ontology of any particular domain of discourse, an element of a set is unjustifiably excluded from the set. An obvious example of this is the statement, "It is a time before time". Time cannot be before time because the extension of time includes the extension of every statement of something being before or after something else (i.e. every B-series statement) such that "a time before time" falsely excludes "time" from the extension of "time". A less obvious example is the statement, "It is before time", however this statement has similar problems to the one before because it is to say, "It is at an earlier point in time than time." This falsely excludes a point in time from time, which is false by contradiction. 

Do you think we as humans in general use certain prove strategies to prove things? Regardless of the topic being mathematics or any other topics, do you think we have finite and limited ways of approaching proof-related problems? For example, see this. If the above is true this means they are certain strategies that we need to follow, where do you think the creativity comes in? If they are certain strategies to follow, where do you think the creativity comes in? Does it come in come in when we try to apply a given strategy to a problem. How does proving things in mathematics differ from real world? 

For example, in real life if we want to prove someone is innocent we simply find a group of trusted witnesses to testify someone is innocent. In other words, to prove q in real life, we can easily find a p which results in q and it is not very challenging. What makes this challenging in mathematics though? Is it because we are not acquainted with mathematics world, the way we are with real world and once we become well familiar we can easily establish truth in mathematics world too? Update: Based on the provided suggestions I would like to narrow down the question a bit further. If we think of a proof as a chain of logical arguments, which starts from the set of axioms (assumptions) and reaches some conclusions (theorems), then how would mathematician try to establish this logical link between axioms and theorems (questions 1 and 2 above relate to this argument). Furthermore, it seems establishing this link between assumptions to the theorems is much easier in real life, regardless of the actual truth of the assumptions (question 3 above relates to this argument) Please see @MarkOxford's answer and comments there for further clarification. 

By 'empirical', Popper means 'a posteriori'. By 'logical', Popper means 'a priori'. The distinction between a priori and a posteriori is a distinction of kinds of truth/falsity rather than kinds of propositions. On the other hand, the analytic-synthetic distinction is a Kantian distinction about the subject-predicate relations of propositions. Examples of all of these will depend on the particular philosophy. First, I'll give examples distinguishing a posteriori (i.e. empirical) from a priori (i.e. "logical"): 

Popper is pointing out that, when these are not properly distinguished by scientists, category mistakes like "it was before the beginning of time" or "something came from nothing" can be made. "It was before the beginning of time" is false a priori because "before" has the extension "is at a time that is followed by" such that "before" is in the category "time" and, thus, it is a contradiction for there to be a time before time if the extension of time includes every referent for "before" and "after". "Something came from nothing" is defective in that identifying any referent for "nothing" falls into a paradox of self-reference and, moreover, such a statement usually is a vague way of saying, "Something presently known came from nothing presently known", which is a categorically different idea from "something came from nothing". 

The fallacy fallacy, which is argumentum ad logicam, is the fallacy of inferring falsity from fallacy. Falsity cannot be validly inferred from falsity.