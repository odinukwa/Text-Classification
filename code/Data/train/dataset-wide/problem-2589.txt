Each evaluation of will take time proportional to the length of the list, which will slow this down. We know that there will be sublists of of length . We can use this to make the code much faster. 

Assuming that each element in is unique, we can remove the call to . We can do this by either using the overload of that gives us the index of the element: 

Having a named makes me think you really want a . Especially since you're later calling which will take time proportional to the number of elements in the list, while for a queue it would take constant time. 

We now need to decide where each element should go. Let's look at your example: \begin{align} A &= \left\{ a, b, c, d \right\} \\ B &= \left\{ b, e, f, g \right\} \\ C &= \left\{ c, e, h, i \right\} \end{align} The resulting sets are \begin{array}{ c | c | c | c } & \in A & \in B & \in C \\ \hline a & \mbox{t} & \mbox{f} & \mbox{f} \\ d & \mbox{t} & \mbox{f} & \mbox{f} \\ \hline b & \mbox{t} & \mbox{t} & \mbox{f} \\ \hline c & \mbox{t} & \mbox{f} & \mbox{t} \\ \hline e & \mbox{f} & \mbox{t} & \mbox{t} \\ \hline f & \mbox{f} & \mbox{t} & \mbox{f} \\ g & \mbox{f} & \mbox{t} & \mbox{f} \\ \hline h & \mbox{f} & \mbox{f} & \mbox{t} \\ i & \mbox{f} & \mbox{f} & \mbox{t} \end{array} So it seems we should put into a new set based on its containment in each of the original sets. Let's use a binary string to represent this: 

I would recommend seeing if RxJS is suitable for your purposes. One of its features is that it allows you to write async-await style code, which can be easier to read and write than using callbacks directly. I've taken your code as a starting point, but changed a few things for the sake of demonstration. We're going to: 

Disclaimer: I'm rusty with Haskell, there may be a cleaner way to do this. Code review: your code looks fine to my eyes, it's just that is overly complex, as you suspected. Also note that can be written as (source). 

Spoilers How would this look in code? Suppose we have a stack containing pairs of the amount of pesticide in the plant and the day on which the plant dies. If we are in the interesting case, where the plant doesn't die on day one, then we keep popping elements off the stack while they have at least as much pesticide as the current plant. While we're popping elements, we keep track of the maximum number of days it takes for these plants to die. If we have popped all elements off the stack, the current plant will never die. Otherwise, the plant will die on the maximum number of days that we've seen, plus one. One we have calculated the number of days it takes for the plant to die, we push it onto the stack. Since exactly \$N\$ elements are pushed onto the stack, we cannot have more than \$N\$ pops. So we can see that this algorithm is \$O(N)\$. 

I made a microbenchmark comparing the two methods that you can find here. For 100,000 calls, the regex solution takes ~2.5s compared to ~0.2s for this version. 

You might also consider taking the input and output file paths from the parameter. Putting it all together (without error checking) could look like this: 

It looks like you can do the filtering and sorting of just once in the view-model constructor (parse results don't change, and doesn't change): 

The class name is not ideal, as the class only deals with a very specialised case, but I can't think of a more specific name. Anyway, you can now use it like this 

Suppose I said that I had a fast way to determine if a number is not semi-perfect; faster than the best possible way to determine if a number is semi-perfect. How would you know I was wrong? Without even looking at my code? Imagine that such a method existed. Well then you could write 

We can use to do the reversing for us. It's not much of a change, but I think it makes it a little easier for the reader to see exactly what is happening: 

All jobs go through 's channel, so that a given URL is fetched only once. kicks off a goroutine for each unique URL it sees, and the goroutine then adds URLs from that page back to the channel. Go's way of thinking is new to me, so my main concerns are 

There are a few code issues that tools like flake will pick up on, but I'll just focus on performance. First up, switching to reduces the runtime on my machine from ~3 minutes to 16 seconds. 

The interface is overkill. As is the class, probably -- as @NickUdell mentioned, a regular expression looks like the right tool for the job here. 

For a method like this, don't worry about performance until you have evidence that performance is a problem. Either way will almost certainly be fast enough. I would suggest instead for readability that you separate the data (key-value pairs) from the construction of the string. If the order of the pairs is not important, you can write 

Output: The solution uses a sweep-line algorithm to find the points where the height of the outline changes. is a silly class to parse the ridiculous input format. In an ideal world it wouldn't exist, but it shaved off a significant amount of time. 

I would recommend against names like , , , , etc. You should also use consistent casing ( instead of ). 

First thing I would do, is remove the and the idea of inserting a separator. If we know where to insert a separator, we can just build up tokens using a . 

We want to hash the properties of an instance of (actually, many instances of ). I assume you're currently getting these properties via reflection. Something like this: 

The largest possible answer then is \$25! = 15511210043330985984000000\$. This value won't fit in an , a , or even a . I would recommend using a . 

I get a time of 0.36s, which I'll take as the baseline. Great, but let's assume we can't write . We can create an equivalent method dynamically. We introduce some helper methods: 

Similar comments hold for . One pattern I like for letting the user iterate over a collection, without exposing the choice of implementation is to 

So we're looking for the longest contiguous sequence that appears in the input, and its reversal. This sounds like another problem, longest common substring (LCS). In particular, $$ maxMirror(S) = LCS(S, T) $$ where \$T\$ is \$S\$ reversed. If we can solve LCS, then we have a solution to . Using dynamic programming, we can solve LCS in \$O(n^2)\$ time, with \$O(n)\$ space. The pseudocode in that article is pretty good, so let's translate that to C#: 

You have the right idea, but there are some overloads we can use that will make the code a bit nicer: 

By returning , client code has no way to stop listening on that port. Consider instead a combination of , , and : 

accepts twice as many strings as there are IPv4 addresses. The reason is the behaviour of the anchor: 

With a big enough input array (10,000 elements did the trick on ideone), this will result in a stack overflow. The site for Algorithms, 4th Edition has a good discussion about this issue and provides an implementation that avoids this problem. There's also some good discussion of partitioning in Quicksort Partitioning: Hoare vs. Lomuto. 

Use the overloads of / that take a argument. If you provide constructors as suggested below, check that the values passed in are non-negative. 

might be overkill for the situation; I find it to be of most use for its method, which we're not using here. You might want to consider something like this: 

Now to the main part of your code. I would say that it's functional and idiomatic, but in my experience with F#, sometimes it's best to compromise on the functional approach. For example, consider . The basic idea is to go through a sequence, building up lists until a certain predicate is met. I feel that the functional approach, with its list reversal, obscures the intention of the code. Here is what I would propose: Edit Fixed a bug where last elements might not be returned. 

The more I think about it, is doing too many things: exact matching, fuzzy matching, and matching within a range. Here's one possible solution. Create an abstract class (or interface) . I went with an abstract class just to keep all the validation in one place. 

This doesn't look like an appropriate use of , but one you've been forced into by the semantics of . In fact, I'm not sure the behaviour is what you want -- if two or more elements of satisfy then an is thrown, and we never check if any elements satisfy . I think what you want is to write a method 

I would consider making the methods take a () instead of a . You can then pass a () from your unit tests, while client code will normally pass a (). This will also allow client code to choose the encoding (which they really should be doing) instead of being forced to use UTF-8. Another reason to consider doing this is that someone calling might want to write to the stream after the call returns. But they will get an exception, since disposes of the underlying stream. For example, we get an when we call here: 

I don't know what the magic numbers (5000, etc) represent, so I just called that parameter . Please take @Vogel612's advice and post a follow-up question. 

This takes ~2.1s on my machine. Just for fun, let's look at what pgAdmin's EXPLAIN visualisation looks like for this query