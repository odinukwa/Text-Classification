I have to modify the number of points in this XML in order to test the performance of another program of mine. Here is an example of the XML I have to modify. performance.xml: 

This is a simple brute force algorithm I have in C. All the program does it print out every possible combination of the given for the given length. I would prefer suggestions on how to improve the algorithm, or decrease run-time. Any other suggestions are acceptable though. 

I've implemented this below. It seems to mimic quite well, even for all the edge cases I've been testing. ls.c: 

Right now, my implementation should run with \$ O \left( n\right)\$ time complexity. This would be unacceptable with the hundreds of thousands of commands my project could scale to. I am looking for reviews on scalability and optimization, and how well my Command structure and function pointer template would scale as well. 

For Khronos, I've had to develop these utility functions to help me deal with storing the files. However, they could also be used in a variety of applications. A description of what the three functions do are given in the header documentation comments. 

Understandably there are parts to this code that I haven't included (some method calls, structure definitions, etc.). Posting all that here would make this question quite large and I would like the reviews to be more specific to certain pieces of code than very general and spread out over multiple files. 

The last part of my speech recognition series: finally training my network. Here's the dataset I did it with (self-generated, small I know), and the code I used. After running this code (takes about an hour on my Mac), I get a validation accuracy of roughly 30%... not spectacular. Any ideas on how to improve the training speed, or the neural network's accuracy? Any other suggestions in general? 

This is the fifth project in my CS1 class. It's a bit more drab than my past projects, so my titles are getting worse unfortunately. 

This is the first program that I have written in my C++ saga that I actually think is useful. The description for this assignment is kinda long and mundane though: 

Removes the loop and compacts your code a lot, making it a lot more readable IMO. Also notice how easy it was for me to extend to capital letters. 

For an assignment I had to create a client and a server that communicate over a well known FIFO. The server is required to use three threads to serve the client, managed by a semaphore. The code was pretty hastily written due to my busy schedule, but works as intended from what testing I've done. Feel free to rip it apart. 

Final Code Please note that this code leaks memory and doesn't contain a unique ID generation method. 

If it were true that a small change in a weight (or bias) causes only a small change in output, then we could use this fact to modify the weights and biases to get our network to behave more in the manner we want. For example, suppose the network was mistakenly classifying an image as an "c" when it should be a "o". We could figure out how to make a small change in the weights and biases so the network gets a little closer to classifying the image as a "o". And then we'd repeat this, changing the weights and biases over and over to produce better and better output. The network would be learning. The problem is that this isn't what happens when our network contains perceptrons. In fact, a small change in the weights or bias of any single perceptron in the network can sometimes cause the output of that perceptron to completely flip, say from 0 to 1. That flip may then cause the behavior of the rest of the network to completely change in some very complicated way. So while your "o" might now be classified correctly, the behavior of the network on all the other images is likely to have completely changed in some hard-to-control way. That makes it difficult to see how to gradually modify the weights and biases so that the network gets closer to the desired behavior. Perhaps there's some clever way of getting around this problem. But it's not immediately obvious how we can get a network of perceptrons to learn. We can overcome this problem by introducing a new type of artificial neuron called a sigmoid neuron. Sigmoid neurons are similar to perceptrons, but modified so that small changes in their weights and bias cause only a small change in their output. That's the crucial fact which will allow a network of sigmoid neurons to learn. Just like a perceptron, the sigmoid neuron has inputs, \$ x1 \$, \$ x2 \$, ... But instead of being just 0 or 1, these inputs can also take on any values between 0 and 1. So, for instance, 0.638 is a valid input for a sigmoid neuron. 

Things you could improve: There is a lot that could be improved in this code, so I doubt I will be able to mention them all. Preprocessor 

Final Program: A quick note about something a few people will want to point out: a portion of the C standard defines the string handling function arguments, unless specified otherwise, must have valid values. I try to mimic that here, therefore excluding the check. This also provides a slight boost in execution speed. 

Not too much to say, looking for a more efficient way to implement this perhaps. Feel free to rip it apart! 

First we care about only unique dates, right? So lets grab indices for their groupings. I'm assuming this original data is stored in the matrix . 

Final Code I've rewritten your code so that it is bug free, and so that it is a bit more dynamic. I also rewrote some bits so you could see what was going on, and so the program was more transparent. 

This looks pretty good! A few notes (some stuff you may still have to learn about since you are a beginner, such as pointers) 

If the user is inputting the text directly I don't believe text can be (I'm not completely sure on this), you can simplify your condition test down a bit using the method . 

Well, I don't know much about PHP; but I know a little about security so that is what I am going to review. First I am going to review your encryption algorithm: AES-192. 

Your program fails when all of the members of an array are negative, it simply returns instead of the maximum negative number. 

It would be good to note that this is a replacement for your block of code as it is right now. If you plan on printing the vowels in a variable amount of strings (perhaps input by the user), then you would want to make a method that would do this for you. In this function you would pass in the precompiled regex and the string to print. I wrote this up really quick in a text editor and didn't compile it, but here is a program that could handle multiple strings better: 

I recently stumbled across this article on how to write a spelling corrector, and figured I'd try to have a go at it in C (mainly because the link at the end of the page for the C code is broken). Here is what I would like reviewed: 

So it turns out we are doing a lot of extra work here. Apple has implemented their own way of accomplishing this. 

This is a to encoder that I wrote a little while ago. The only method that is really called is , which takes in a file, converts it to FLAC, and stores it in the file that is taken in as a parameter. I would prefer suggestions on how to improve the method, decrease run-time, or cut down on the length of the code. Any other suggestions are acceptable though. 

Cost Function I don't see any use of a cost function in your code. I'm going to recommend you read this section in Neural Networks and Deep Learning to get a good reason why you should be using one. In short, the cost function returns a number representing how well the neural network performed to map training examples to correct output. The basic idea is that the more "wrong" our network is at achieving the desired results, the higher the cost and the more we'll want to adjust the weights and bias to achieve a lower cost. We try and minimize this cost using methods such as gradient descent. There are certain properties that you look for in a cost function, such as convexity (so gradient descent finds a global optima instead of getting stuck in a local optima). As the book suggests, I would lean towards using the cross-entropy cost function. The way we implement this in Torch is with . Torch seems to have implemented a bunch of these cost functions, and I encourage you to try different ones and see how they affect your neural net accuracy. 

Over-fitting It could be possible that you fit your data too well, to the point where we don't generalize well enough. An example of this is given in the picture: 

This is the second project for my CS1 class, this time I'm actually getting it reviewed before I submit it 

I've made GUI's before, but it's been a few years and I know that the language has updated since then. Any suggestions for improvements? Perhaps ways to make it look more visually appealing? 

When run with some given input, it runs the method associated with that input. Since this is a scaled down version of my project, it can only run two commands. 

Disclaimer: I'm not sure if this code will be the solution for SPOJ. You don't check if the input number is an . 

The Sigmoid Neuron is defined as: $$ \sigma(z) = \dfrac{1}{1 + e^{-z}} $$ Torch implements this neuron type here. (1) Excerpt with minor edits from Neural Networks and Deep learning 

Please feel free to rip the code apart! In my opinion, I think the in could be DRYed up a bit, but I wasn't sure how. 

Gradient Checking For more complex models, gradient computation can be notoriously difficult to debug and get right. Sometimes a buggy implementation will manage to learn something that can look surprisingly reasonable (while performing less well than a correct implementation). Thus, even with a buggy implementation, it may not at all be apparent that anything is amiss. Therefore, you should numerically check the derivatives computed by your code to make sure that your implementation is correct. I found an implementation of gradient checking with Torch here. Be warned that this check is computationally expensive, so once you've verified that your implementation of backpropagation is correct you should turn off gradient checking. 

A few notes: (I implemented this in Octave, so there may be differences between my code and a proper Matlab implementation, but there shouldn't be). 

Now you want to know how many seconds are these clock cycles. For that, you want to know how many seconds a single clock takes, i.e. . If you find that, simply multiply by 50 to get total time taken. For that, OpenCV gives second function, . It gives you frequency, i.e. how many clock cycles per second. You take its reciprocal to get time period of clock. 

Now that I have generated training data, I need to classify each example with a label to train a TensorFlow neural net (first building a suitable dataset). To streamline the process, I wrote this little Python script to help me. Any suggestions for improvement? 

During each iteration of the loop check for length zero to see if the token is actually valid before passing it to . Bail out of the loop if the token has length zero. 

So I built a system of classes to handle all of this, these two here are the base two. How can I improve this code? Any new Java 8 features I'm not taking advantage of? Position.java: 

I must use at least two functions in this project. In addition, I am also supposed to count and output the number of occurrences of each character. : 

Here is a Bitcoin address validator I am looking to have reviewed in C. Normally I would have the and function prototypes declared in a header file, but I decided for the purpose of this question to integrate them into one for easy copying and compilation. 

Other than that, the program looks pretty good. You didn't include , so I couldn't do too much refining without making sure I wasn't breaking the program. Final code: 

I think it's a great project! But it could do with a few improvements: Neuron Type(1) Suppose we have a network of perceptrons that we'd like to use to learn to solve some problem. For example, the inputs to the network might be the raw pixel data from a scanned image of a signature. And we'd like the network to learn weights and biases so that the output from the network correctly classifies the digit. To see how learning might work, suppose we make a small change in some weight (or bias) in the network. What we'd like is for this small change in weight to cause only a small corresponding change in the output from the network.