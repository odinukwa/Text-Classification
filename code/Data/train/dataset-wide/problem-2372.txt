Likely what's happening here is that your second set of data (after the does not return any data, and so only the first part is returning anything. Because you are passing a 0 for the date, this is 1900-01-01. All of the results are going to get grouped for that date. Here's a similar mockup, but this one returns data after the 

This is a warning message that comes up due to a missing dependency (it also means that the SQL dependency tree may not be correctly set, and so you won't have correct entries in sys.sql_expression_dependencies which can be useful down the road). This is just a warning however, and so long as the dependent object is created you will have no issues with running your code. You can also repush the items you get warnings on, and that will fix the dependency list, but again, not critical. 

Yes. The limitation here is that a database can only reside within a single AG, and that all nodes must be in the same WSFC. Be aware though (going back to your licensing question) that if a server is a primary for databases then it must be appropriately licensed. 

You can use SQLCMD mode in SSMS (or SQLCMD itself) to do this. The following query would connect to an instance, check for the database in question, create the login if it does not exist, and then connect to the database and add a user for that login. 

If you are stuck running SQL Server 2012 then SqlWorldWide will unfortunately not work for you (although it you are 2014 or higher it is the way to go). I ended up writing my own function to handle this on the lower version... 

A couple of things that you should note, DBCC DBREINDEX is deprecated, you should really be using ALTER INDEX REBUILD instead. As an additional item, rather than trying to reinvent the wheel there are free solutions out there that have been written by folks with many years of experience, such as Minionware Reindex. These are designed to be quickly and easily deployed and to provide simple management. 

It's been a while since I've used the GUI, however you can do it using TSQL with the command sp_add_log_shipping_secondary With this command you would specify the name of the secondary database and the primary, which would then restore the transaction logs to the relevant database name. 

Personal observation from experience with both FCI and AG failovers, with reasonable high volume transactional system (40k trx/sec). For each consider 6 databases ranging in size from 500MB to 4TB in size. Times listed for failover are what it takes for the database to up and in a writeable state on the new node. Your mileage can, and will vary, but this is at least a data point for you. Cluster failover: 47 seconds (avg) AG Failover: 10 seconds 

The trouble here is that the script evaluates the IF statement, and then the logic applies to the first statement afterwards. To handle multiple statement you need to put them within a BEGIN...END block. Something like this should work for you 

Take a look at using sp_executeSQL instead. It is fully paramaterized and so provides a much greater sense of safety to dynamic queries (and using alongside EXECUTE AS USER within procedures with strict permission sets make it even better). 

I would expect you to see the default endpoint, as well as the Dedicated Admin endpoint. You will need to add another endpoint: 

You can quickly read the data back using the GUI, or use sys.fn_get_audit_file to query the data directly from SQL Server. 

In the first instance, confirm that there are no attempted email sends from your script. For the second the DBA might not have set the permissions correctly on the trigger itself, and so it is attempting to send an email using your credentials. Work with the DBA to either grant you permission on msdb..sp_send_dbmail so that emails will flow, or to fix up the trigger. 

SQL Server 2012 SP1 CU7 is from November 2013, and so not sufficiently current. There is no SP1 cumulative update that would support pulling that information. You would need to move to Service Pack 2 with CU9 at the least. As a side note, SQL Server 2012 SP1 was no longer supported as of July 2015. Service Pack 2 will stop being supported in January of 2017 (as detailed in the Microsoft Lifecycle Policy). You should look to upgrade to Service Pack 3 as soon as possible to remain in support. 

Your issue, rather than a corruption problem, is a sparse file limitation caused by the command taking an internal snapshot of the database (for consistency reasons) and checking that. There are really only two ways to resolve this: 

A further note to filegrowth. If you do not have IFI enabled then you will have IO stalls on writes to the data file that cause it to grow. Those stalls will last as long as it takes to grow out the file and zero it out to ensure the space is clear (2016 does not use zeroes, however the concept is the same). With IFI enabled (requires Perform Volume Maintenance Tasks permission for the service account, this can be done at install time with SQL 2016) then the data file can grow instantly and does not need zeroing out. Log files do not have the option for IFI (for security and data safety reasons), so any growth on that file will cause IO stalls while that completes, impacting performance. The MAXSIZE settings in the create database statement will prevent the files from growing beyond those values. This would mean that you could not store more an a total of 10MB of data (including system data), and that no individual transaction could be larger than 5MB in size. Both of these values can be adjusted using an ALTER DATABASE statement. 

The only significant memory that would be held would be if SSMS was being run on the server itself (and then you'd still be limited to the 2GB of memory space that SSMS can allocate). There will be a very small amount of memory allocated to maintaining the connection in SQL, but that's truly trivial. Of course, if you leave an open transaction, that's a whole other level of pain, but it doesn't sound as if that's the trouble your developers are trying to avoid (unless this is what they are trying to avoid, but came up with a PC way of telling them that).