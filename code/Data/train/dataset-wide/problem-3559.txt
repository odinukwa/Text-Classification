The short question: can I share file and block level traffic on the same SAN? Perhaps more importantly, should I? The gory details are below... I'm hopefully putting the finishing touches on a new SAN design, and our new planned storage (EMC VNXe3100) will support being an iSCSI target, our original goal. It also supports file-level storage as well via CIFS and NFS. Some of the features we hope to use (particularly deduplication) are only available via file-level shares. The VNXe3100 has 2 controllers with 2 NICs per controller. Each NIC is going to a different switch, so either the controller or the switch can fail, and we should still be in business. This means that both file and block traffic would need to be enabled on each NIC. I'm assured by our rep that this is possible. My plan is to put the VNXe and the 5 host servers on the same VLAN and subnet (call it 192.168.1.x). This should keep my block-level iSCSI stuff only in that VLAN with no route out. But I would have a route out to the rest of the network for the file-level traffic on a different subnet (192.168.55.x). So each NIC would have an IP address for block traffic in the 1.x range and another for file traffic in the 55.x range. Since we are new to the world of iSCSI and the world of SAN/NAS devices, I want to make sure this isn't some horrible intermingling. But it would be really nice to expose our VMWare as NFS and get the VMs deduplicated on our hardware, and not having to maintain another file server would also be a bonus. If there's something else I'm overlooking, I'm all ears. 

VMware best practice now is to install vCenter on a VM with HA. That's from a VMware training class when 5 originally came out. HA doesn't require vCenter to actually be working once set up, as the hosts know what to do. I have Essentials Plus, use this setup, and can attest that it works well for us. Just make sure that you have enough capacity on your hosts to accommodate HA. 

No downtime needed, but you do need to control your IP address space. If you don't, your ISP may be willing to create a PTR record for foo.bar.com's IP address. The PTR record is just a way of (pseudo-definitively, if you will) reverse resolving an IP address to a host 

There's a nice product that handles your sort of setup. I have a friend who uses one in his small business and he's pretty happy with it, last I heard: Peplink Balance multi-WAN routers. ($URL$ 

On EC2 EBS, I'm right now using xfs_freeze. I'm looking into possibly switching to xtrabackup at some point, but when I gave it a first test run it was very, very CPU hungry. 

We are considering using Amazon's ELB for load-balancing requests to internal API servers. If we use it, do we have to route our traffic through the public IP addresses, and thus lose the speed and cost benefits of sending traffic only to the private IP addresses? (The API servers and API consumers are both EC2-hosted, so we would prefer to use the private IPs.) 

I couldn't find anything online, but I wouldn't count on guaranteed uniqueness, even if the current format would accommodate >4 billion IDs. 

It's actually in /etc/sshd_config that you set the following line: PasswordAuthentication no If you are using a stock install (i.e., you didn't build/install it yourself from source), launchd should take care of picking up the new config without having to restart the daemon. 

I can address the AWS offerings; I'm not familiar with the other vendors. For AWS, there are several different virtual hardware configurations; each configuration, which is priced according to what you get, has fixed RAM and CPU specs. It also has fixed ephemeral-storage specs -- that's the storage that you get "for free" with the instance, but which disappears when the instance is terminated. For persistent storage, most people provision EBS volumes, which have their own pricing model, and attach them to instances. EBS storage is limited only by your platform + filesystem + EBS volume size you initially provisioned. My impression is that some cloud vendors do make their offerings somewhat simpler and easy to grasp than the AWS offerings, which are quite large and always expanding. 

You can configure User and Computer settings in Windows 2003 with Group Policy and Group Preferences, just as in Windows 2008. This may solve some of your configuration issues. Going into all of the details of Group Policy and Preferences is beyond the scope of a simple answer, but Google will be your friend here. Also, each version of the Windows client increases the capability of Group Policy, so you will need to be diligent in verifying that you can accomplish what you want in Windows XP. Group Policy alone won't necessarily solve your problems, at least not without extensive scripting. If you're having problems with programs being installed as a non-admin, you'll likely need to augment Group Policy with other tools. If the problem is people installing programs as local admins, then removing local admins permissions should be your priority before any of this work. As for games, are you talking about online, or installed? Again, Group Policy won't necessarily solve, say, Flash games. There are other network tools to prevent that. Depending on how much of a problem this is, you may need to step up to system management tools, such as Kace or Microsoft System Center. Again, beyond the scope of a simple answer, but this should get you started. 

By request, I'm breaking this out of a comment... WesleyDavid's solution (using PowerShell, presumably in combination with Group Policy/Preferences) is the best solution to fit the problem as described, but that may not be the best solution overall. The questioner should probably consider a dedicated systems management package. If management wants to prioritize ease-of-use for the tech, then it may make more sense to use Altiris, Microsoft System Center, KACE, etc. to accomplish this goal. They're more likely to give reporting that management will like (X% of workstations had program Y installed) and help the less-skilled techs. Also, while a bespoke collection of scripts will give maximum flexibility, the system management packages can probably get you most of the way to your goal in a fraction of the time. If you should run into some particular issue, there's more likely to be a community of support and consultants that can help you out. The trade-off, of course, is money. But given that the questioner is mid-level IT, it may be more useful for him to work on other issues with a more direct business need than to work in an area that has is more of a commodity. My network is smaller than many here, I'm sure: around 120 PCs, 20 servers. I've done scripts and GPOs because I've had to, but we're looking to get one of these up just for the patch management and easier reporting to the powers-that-be. 

This question is two fold. Part 1: Is it a bad idea to virtualize a storage solution and run VMDKs off of that as opposed to the original VMFS datastore. Essentially lets assume I have 2 TB worth of RAID'd DAS. Currently I have a few VMDKs on the DAS VMSFS. What I want to do is remove the VMDKs off the VMFS, allocate a good 1.8-1.9TB for a FreeNAS installation (a big FreeNAS VMDK), and run the other VMDKs off of that via NFS. I don't have the hardware for a NAS but have a bunch of different shares. This would simplify my management. I understand there is some overhead with another layer of storage abstraction (A virtual ZFS file system over NFS backed by RAID'd DAS formatted as VMFS) but I don't see how it could be too bad. The NAS also has more features than a simple VMFS datastore on DAS. Part 2: VMWare frowns on long running snapshots, but what about ZFS snapshots? Is it safe\recomended to run my guest VMDKs (Windows clients, random servers) on ZFS snapshots? This will give me the ability to quickly rollback VMs to earlier states without the implications of long running snapshots directly on the VMFS. 

Common sense would tell me the client (it knows what site it's in since it's in the registry) would do a site-specific DNS query to locate all of the DCs and then choose one to auth with based upon the priorities and weights. 

The VMWare KB and multiple blogs state that long running snapshots are bad for both performance reasons and integrity. They have valid points. Granted this is not with ESXi but rather Workstation\VirtualBox on a *NIX server I do see many blogs touting using LVM (or even ZFS) snapshots. Assuming LVM they essentially store their VMDKs on an LVM volume and take all the snapshots they want. I don't see how this solution is practically any different than simply using the VMDK snapshots but VMWare mentions nothing bad about it from a performance or integrity perspective. A lot of blogs tout this as a snapshoting solution. With that being said are Long running VMWare snapshots bad if they are not true VMWare snapshots but rather the VMDK on an LVM\ZFS volume? Clarification A long-running snapshot is a snapshot that runs for a long time, even continuously. Let's assume I set up a few Windows VMs, snapshot them at the LVM level, and run them for a few weeks or months (perhaps even shapshotting throughout). When I want to roll back I simply roll back the snapshot to return to a previous version. The VMWare KB specifically states (for native VMWare snapshots) "Use no single snapshot for more than 24-72 hours. Snapshots should not be maintained over long periods of time for application or Virtual Machine version control purposes." As we all know people run LVM\ZFS snapshots for enormous amounts of time with no ill effects.