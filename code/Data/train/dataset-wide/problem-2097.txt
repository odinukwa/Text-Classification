Resolving deadlocks can be tricky because you need to be knowledgable about all of the different types of objects and locks and how they can prevent each other's sessions from making any progress. Your stack trace can be used to indicate what resources your process was using, but not the survivor process. Some deadlocks have more than two sessions involved. You have several options to obtain the facts so that an investigation can be conducted. 

You should avoid making the entire call dynamic because of the sql injection vulnerability. Your procedure needs to accept the parameter you are specifying on your dynamic sql call as well 

When I saw this question, I opened SSMS with the intent to read the help documentation on the "Trust server certificate" option only to discover that this is an undocumented feature with no description of what it does on MSDN. My guess is that it can be used to trust expired certificates or those which can't be validated by walking the chain of trust. Since there is no chain of trust for a self signed certificate, SSMS trusts it when it verifies the signature using the public key. I think your suggestion would make an excellent server configuration option for high security implementations of SQL Server. It seems like you want a configuration option to reject all self-signed certificates, since avoiding those is the only real way to mitigate a man in the middle attack. It is exactly the concern that you raise that causes me to recommend configuring the Certificate tab with a domain or public CA certificate. 

If the above SQL returns any rows, then you can't restore on Standard, but there are other options. You can backup databases on Enterprise and restore them to Developer Edition, which supports all Enterprise features, if you want, but you can't restore a backup from a higher version and restore it to a lower version. If the database is less than 10GB, then you can also restore it to an instance of SQL Server Express, which is free and will support restoring encrypted backups but will not support taking encrypting backups. You will also need to backup the certificate and private key from the master database on your Enterprise system and restore it to your target system assuming you are not using an Extensible Key Management system. 

This feature is already built into SQL Server. I had a similar situation and what I did was to change my code to use a custom error number, above 50000, and set up a new Alert, under SQL Server Agent|Alerts in Management Studio, with that custom error number. Under the Options section, there is a Delay between responses section that can be used to mitigate the volume of notifications per hour. I had my process monitoring every 10 seconds, but notifying every 5 minutes because I wanted to know when the critical situation started, but not be overwhelmed with alerts. 

It seems like you've been reading about Snapshot Publications and replication. There are three items in SQL Server with the name snapshot. One is the database snapshot. When a database snapshot is created, one new file per existing data file is created and the database engine will save the original page for any changed page in the database into those files. Database snapshot files are just a collection of pages since the snapshot creation and won't be useful on any other server. Another type of snapshot is a Snapshot Publication, which is part of the replication system. When you create a Snapshot Publication, you specify which articles, which can be tables, views procedures,ect, to include in the publication, specify a subscriber and schedule it for delivery. You can configure it to drop the existing articles at the subscriber and recreate them so they will be replaced every time the snapshot is pushed. It will synchronize all articles between the publisher and subscriber at the time it is run. Which brings be to the third instance of an object named snapshot. Within the replication system there is an agent or executable named the snapshot agent, whose job is to take a snapshot of the articles in the publication at the time it is executed. If you really need to transfer the entire database from one server to another on a regular basis, you can design a backup system that takes full backups once per week, for example, with differential backups daily and transaction log backups hourly for production. Then transfer the full backup once per week to the test environment and leave it there. After that you would only need to transfer the differential backup daily to restore using the full followed by the differential. I would also advise turning on backup compression to minimize the sizes of the files involved. 

If all of this still does not resolve the issue, then locate the job for the distribution agent and add the parameter -ErrorFile (path and filename local to the server). Monitor the growth of this file because it might grow faster than you expect, but it will contain more details about the problem. 

While it's true that anyone with read permissions can browse the database using SQL Server Management Studio, additional permissions need to be granted to use the keys for decrypting the data. The first point to keep in mind is that a certificate is a public object, and it's the related private key that needs protection to ensure that it can't be used by unauthorized users to decrypt the symmetric key and subsequently the data. The private key is encrypted by the Database Master Key and is not visible to any user, even to those in the sysadmin role. Just because a user can see the objects doesn't mean they can use them. The permissions needed to decyrypt data using the encryption hierarchy you described, which is a symmetric key protected by certificate protected by the database master key, are CONTROL on the certificate and REFERENCES on the symmetric key. Without both of those permissions, decryption will not be possible. However, if you grant the CONTROL permission on the certificate directly to the user or the user is in the db_owner, db_ddladmin or db_securityadmin role, then the user can back up the certificate and private key, which is a threat to the security of your encryption. In addition to removing the users from the aforementioned roles, there are several ways to address this issue. One is to use an asymmetric key in your hierarchy instead of a certificate, since there is no backup command for asymmetric and symmetric keys. The other is to use code signing and only grant the permissions to a certificate user. Someone also mentioned that it may be possible to use impersonation , or "execute as" in a procedure, but this may not be the safest choice. If you want to replace the certificate with an asymmetric key in your hierarchy, then you should back up the Database Master Key for the database and backup the database, then restore both in a non production environment so you can create the script and test it completely before attempting this in a production environment. If you really want to hide the names of all of the objects, then you can deny view definition to the users in the database. Again, test in non-production first. 

There are many factors that can affect replication. Some common factors that I've come across are related to slow networking, blocking and storage issues. But the one that may be a factor is the performance problem with virtual log files. If you are initializing a database with a large amount of data and the default growth factors are in place, then sql server will grow the data 1mb at a time and the log 10 percent at a time. To check for the VLF issue, run dbcc loginfo. If that command returns over 100 records, I would be concerned. If it returns thousands of records, then it will have a real impact on performance. There are plenty of articles written on this subject. The basic fix is to adjust the autogrowth settings on all data and log files to reasonable sizes, then shrink the log file and initialize it back to the original size. I would check all of the databases, including the distribution database. There could also be other reasons why the distribution database is slow to distribute the transactions. I've experienced this on several transactional replication systems in the past and was suprised at the impact of correcting this every time. I would also suspect locking at the publisher. Identify the spids involved in the replication and use the dynamic management view sys.dm_os_waiting_tasks to determine which waits are involved in these sessions. This will help identify what these subscriptions are waiting on. 

For all other column level encryption within a user database, backup the Database Master Key, migrate it to the other environment and restore it after restoring the user database. 

First, examine what the distribution agent saved about the error by executing select * from [dbo].[MSrepl_errors] order by id desc in the distribution database. When it comes to poor performance in the distribution database, I've experienced several problems. Besides excessive blocking, which I'm sure you are watching, there are several maintenance related issues. First, I've had virtual log file issues slow my replication in the past. When this happened, there was a noticable impact on performance. To address this run dbcc loginfo on the distribution database. If you get over 100 records returned, it's a slight concern. If you get thousands of records returned, then it's a real problem. Fixing it includes changing the autogrowth settings for the log file to a reasonable value, shrinking the log file, then re-initializing it back to its original size. Unfortunately, the default autogrowth size for data files is 1MB, which should be increased as well. If you don't have this database included in the index and statistics maintenance, you could experience query timeout issues. I once had a specific table in a user database used by a procedure with a recursive function and if this table got fragmented slightly, the procedure would run very long. It is also possible to use Profiler or Extended Events to trace all of the commands that the problematic distributor executes to determine which command times out. Locate the SQL Agent job that runs the distribution agent with the issue and filter by program name using that job name. I'm also not averse to creating new indexes in the distribution database, if necessary. I use the query below to help with this, but don't just create everything without reviewing them to see if you can consolidate. 

When a database master key is created, it is encrypted using two methods. First, it is encrypted by the password that you provided, which in this case is "StrongPassword". Second, it is automatically encrypted by the service master key, which allows you to use the encryption without putting the password in procedures and other code on the server. When you opened the symmetric key, you specified to decrypt it using the private key of the certificate but did not need to specify that the DMK needed to be open to decrypt the private key needed. The system performed that action using the service master key for you. You can see this in the system tables by using the sql statement below: 

The proper key hierarchy is the Service Master Key protects the Database Master Key, the Database Master Key protects either an asymmetric key or certificate, the asymmetric key or certificate can be used for encryption or can be used to protect a symmetric key which is used for encryption. The keys are created in that order. The system creates and protects the SMK, and the DMK and subsequent keys are created by the user. The design of the key hierarchy in SQL Server protects both the data and keys from compromise. Remember that with a symmetric key, the same key is used to encrypt and decrypt data, or in this case other keys. The main purpose of introducing an asymmetric key or certificate into the hierarchy protected by the Database Master Key is to prevent an attack on the DMK and SMK from inside of the database. If someone malicious wanted to obtain the DMK unencrypted, then that person would need to do one of two things. Either decrypt the service master key and use it to decrypt the DMK, which is not possible because only the database engine can use the Data Protection API to do this, or attempt to decrypt from the top of the hierarchy down, which would be possible if there were not an asymmetric key or certificate in the way. All of the signed or encrypted bits of the symmetric keys in SQL Server are in a system table named sys.crypt_properties in each database, including the encryption of the Service Master Key in the master database. There is no system table that contains the private key for either of the asymmetric key types. If all keys in a hierarchy were symmetric keys, then the SMK would encrypt the DMK and the DMK would encrypt the symmetric key that would encrypt the data. Because of the way that symmetric keys work, that would also mean that, if someone opens the symmetric key for the data, then it can theoretically decrypt the DMK and the decrypted DMK can be saved by a malicious user or used to decrypt the SMK because the same key is used for encryption and decryption. This is why an asymmetric key or certificate is required to be an integrated part of the encryption hierarchy. 

I had a server with a similar problem. What I did was to trace the sa account, use the results to determine the permissions needed, then create a new account named SystemAdministrator with the same password and grant the permissions to the new account. Then I switched the names of the two accounts so that the SA account was a regular user account and removed SA from the sysadmin role and changed the password for SystemAdministrator. I also tracked down all of the applications configured to connect with the SA login, which can be identified using the same trace. Once these applications are located, you can add ";Application Name =app1" to the end of the connection string to separate permissions by application because it will be sent to the server as application name or program name. Sessions with a SPID below 50 are generally sessions needed by the database engine to run the server. After switching the login names, you will see that those run under SystemAdministrator. Database owners and SQL Agent job owners automatically changed since the owner sids are saved in the system tables. Refresh any SSMS Object explorer connection before verifying. First, create the trace by going into Profiler or Extended Events and add a column filter for SA. Under Security Audit, you will want to trace the event Audit Database Object Access Event. Run this as a server side trace and specify that the file go onto a large drive. Even though the SA login bypasses the permission check algorithm, it still saves the permissions necessary to execute the statement under a column named permissions in the trace. The following script will use the profile trace file to generate the sql commands necessary to grant permissions to the SystemAdministrator account: