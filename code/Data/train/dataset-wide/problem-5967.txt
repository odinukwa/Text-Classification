It can be done in one step. The first man sees two white hats and says that he knows. But, you say, the problem says that the first man says "I don't know"? Exactly. The problem's definition is also specified by the second man saying "I don't know." Therefore, if you can break the definition of the problem for your two steps, I can break the definition of the problem for my one step. ... 

I can see the power behind the argument because to get around it a person would either have to stretch the imagination into areas that might seem implausible or have to solve a lot of academic problems, if the person is to be satisfied that Mary has all the facts and that all the facts are physical facts. Foregoing the route of solving a lot of academic problems for now, I think we can continue to think about Mary in a way that derives directly from your formulation, RECURSIVE FARTS. The original Mary is characterized with the standard scientific kind, as having descriptive knowledge. If it's implied that she has procedural knowledge, which standardly tends to be an engineering kind, it's not very much. In domains where descriptive knowledge is enough, interfacing with things around you tends to be enough. You don't need to begin an approach to knowing the inner workings of things to the extent of knowing how to reconstruct them or something like them. That is, you don't need to begin an approach that's pointed to knowing things in themselves. At most, you'd need to know enough to create simulations, which, while a lot of times very sophisticated, is not the same. But descriptive knowledge isn't always enough in all domains where physical knowledge is required. Additional knowledge is required to assemble basic components (which are usually for larger systems). Without getting into whether or not Mary has the "right kind" of knowledge about colors, we can already say she lacks some physical knowledge. That is, she doesn't know how to assemble basic components. Or, at least, she doesn't have the facilities to assemble basic components and gain the knowledge of herself going through the process of assembling the basic components. Indeed, this would be just like you said, this would be a posteriori knowledge, RECURSIVE FARTS(). Now that we may begin to question the sobriety of the original caricature of Mary, we may be able to close in on settling the issue. Even letting alone the question of the life-changing subjective quality of strolling through the wilderness, we know that as it stands Mary neither has enough knowledge ab intra nor has enough knowledge a fortiori. However, provided proper education and further facilities, whether industrial or surgically integrated with her body, she would simply demonstrate her sufficiently complete knowledge of the physical world. First she would make basic nanoconstructors. Then she would make physical replicas of everyday inanimate objects. Then she would make physical replicas of archaea. (...) And finally, for now, she would give you a neural implant to complement hers for bidirectional communication of art works and anything else that could be seen in virtual reality. Of course, the tests she had to perform to get such magic right must've involved having knowledge of the physical world to such a degree that it went much beyond descriptive knowledge, and into its superset of acquaintance knowledge. Having physical descriptive knowledge is simply not the only kind of physical knowledge to have. 

Is this an accurate description of what Descartes said? If yes, what does it mean that mathematical theorems can be changed? I don't understand why, if he thinks that laws of nature are fixed with respect to God, mathematical theorems are not? Aren't mathematics more basic than laws of nature? For example, isn't "one plus one makes two" more basic or unchangeable than the fact that things with mass pull each other? 

In discussion of Aristotle's natural philosophy, the concept of "generation and corruption" is often invoked. It's the translated of one of his books' title (On Generation and Corruption). Today in everyday's use the words "generation" and "corruption" are quite generic, but when talking about Aristotle's physics it seems that they refer to specific concept(s). What do they mean and how do they help the study of nature? To my mind, matters don't actually get "generated" or "corrupted" in everyday events, they just change. For example, water becomes ice, hydrocarbon + oxygen become carbon dioxide + water, and so on. But that's me, who, unlike Aristotle, studied modern physics and chemistry. In Aristotle's day, what were generation and corruption and how did they explain natural phenomena? 

something should presumably have to replace the question-mark against all logical possibility. And then even if something did replace it against all logical possibility, humans are at most right now merely demigods compared to dogs. Might this put a substantial hitch on some theoretical maximum of intelligence? Update 1 2014-10-17: While no one has pointed this out yet, during my discussions so far I realized that the frame of mind at around the time of generating this curiosity could readily concede to "The analogy breaks down if superintelligence (including up to hyperintelligence) necessarily must originate from at least as low as human-level intelligence." ... As a corollary, this doesn't bode well for traditional conceptions of God. Update 2 2014-10-17: Responder @ChrisSunami points out that a hunter-gatherer tribe 10 thousand years ago would not have a maximal ontology [in the relevant sense]. Since the main analogy broke down from Update 1, and in light of this hunter-gatherer point, a new analogy becomes forthcoming. 

European colonialism in Asia and Africa last well into the modern age. Most Asian countries only became independent after WW II, and Most African nations became independent only in the 1950's and 1960's. That is way after the enlightenment, after the French Revolution (liberty, equality, ..) and after the likes of Locke, Kant and Hobbes. My limited understanding of those thinkers is that the legitimacy of government come from social contracts, consent of the governed, democracy - government as the agent of the governed, and freedom. These all seem to contradict the legitimacy of colonial governments, which exploit foreign nation for their advantage by the force of arms. Divine rights and natural law might be used to justify colonialism, but after the enlightenment it seems that these theories are obsolete. What are the common philosophical justifications of colonialism in the 19th and 20th century? How did they address the lack of consent, freedom and democratic rights of the governed? 

This analogy happens to have the bonus side-effect that, as most arguments so far have been based on the magnitudes of ontological contents rather than the magnitudes of ontological expanses, it now accommodates this concern by having built into it the altogether irrelevance of the magnitudes of ontological contents. So, to answer the original question, there's nothing to worry about. In comparing modern humans to dogs or to early humans with tight extremophilic analogies, ultimately no great filter to superintelligence or beyond is implied. 

The propositions ~C, ~D, and ~A were not contradictions of any propositions that you derived. For example, up to those points, you had not derived C, D, or A. If you would have, you would have arrived at a contradiction sooner than when you arrived at B and ~B. For your first question, here's a much a simpler problem, and with words, so it's easier to get the idea. 

Imagine these two thoughts experiments The first one, slightly modified from "Jim and the Indians" by Bernard Williams: You come upon twenty people taken hostage by an armed group. The groups's leader tells you that they are going to kill all but one designated hostage. However, they make you an offer that if you kill that one person (with a weapon that they supply) and they will let the rest go. Will you accept the offer? Note: this is slightly different from William's original setup that if you don't take the offer, one hostage will still be alive. Second one, from 7:25 in this video about utilitarianism: You are a doctor and you have 5 patients waiting for, respectively, a heart transplant, a lung transplant, a liver transplant, and two patients needing a kidney each. If they don't get the transplant, they will die soon. You don't have such organ available, but you have an option of killing another healthy person (who happens to be a donor match for all these patients) and taking that poor guy's organ for the 5 patients. It seems that both experiments are equivalent, they are the case of killing one life by one own's hand vs letting many die by refusing to kill. If we go by strict utilitarianism, one should go for the option with less people ending up dead (i.e. killing one person), or if we go by strict Kantianism, one should not kill, so one should refuse the offer in the first experiment and let the patients die in the second. But, intuitively, it seems to me that taking the armed group's offer is somewhat more ethical than killing someone to harvest organs. Are there philosophical differences between these two experiments? Or does it only feel different to me because of some non-philosophical factor (e.g. the way the experiment is packaged, the different in my subjective emotional response, etc.)? 

By assuming the negation of the conclusion, you arrive at a proposition that contradicts a true premise. (We assume our premises are true when the validity, and not the soundness, of the argument is in question. If the soundness were in question then we would also want to know if the premises really are true, but the soundness is not in question right now.) If ~B leads to a contradiction, then it must be false. In classical logic, if ~B is false then B is true. What if we have all true premises and don't arrive at a contradiction by the same method? 

It doesn't seem difficult to determine the appropriate nature of our mind-to-world intentional states. Their appropriate nature is that they match accurately and precisely to the world, perhaps maximally so (except where perhaps this doesn't infringe excessively on most others' privacy). It feels as if this is an obvious and undeniable logical definition. However, it seems much more difficult to determine the appropriate nature of our world-to-mind intentional states. Their appropriate nature is... what? While one good first answer might be that their appropriate nature is that they reflect end-states that already have well-defined routines for satisfying them, we know this answer comes up short. We regularly see people solve problems that at least in large part had no known well-defined routines for satisfying them. This meant that they posed a problem that hadn't been posed exactly like it before (or finally solved one that had been such an open problem). What exactly is the permissibilic mechanism for people to pose unique (previously unsatisfied) problems, unique world-to-mind intentional states? Sometimes people pose unique problems and other people like them for it, and sometimes people pose unique problems and other people hate them for it. Many people act as though they have a thoroughgoing familiarity of the permissibilic mechanism, that here too there's an obvious and undeniable logical definition in effect. But where's the manual – or what is it like – on the necessary and sufficient constraints on posing previously unsatisfied problems, on formulating previously unsatisfied world-to-mind intentional states?