Although is not what you are asking for, I will suggest another approach to test the new server. If you put a load balancer in front of both servers and play with the load balancing algorithms you can at the same time test the new server and gradually replace the old one. You can send 99% of the requests to the old server and the remaining one percent of requests will go to the new one where you can closely review if the service is working as expected. If everything works fine you can increase the load gradually; 90%-10%, 80%-20%, and so on. Hint: Check haproxy and the and options. 

It seems like they are trying to use your web server as an open proxy. As long as you don't see your servers responding with a , you shouldn't be worried. UPDATE: Although there may be ways to handle this with builtin nginx functionality, I found easier to install/enable mod_security and let him handle this and other nasty attacks. As you'll see in the logs below, somebody is trying to reach wikipedia through my server, mod_security knows that this this is an anomaly an takes an appropriate action (It returns a 403 forbidden response). This is an Apache server but it should be exactly the same in nginx. 

In your case, it seems like the package installer has already taken care of creating the dedicated user. 

*1.2.3.4 = I replaced my IP address with this fake IP. I don't need any more strange packets knocking my door :) 

Does anyone have any ideas on why the memory usage is constant like this and not peaks and troughs with usage of the app? Here's the output of the MySQL Tuning Primer script: 

Can I access my network drives on my host machine on the VM? This is possible on Virtual PC but I can't find the setting on VMware. I am running Windows 7, VMWare workstation 7.1.3 build-324285 

This does not generate a failed request log strangely enough - I have set the failed request tracing to trace errors with error codes 400-999. Also worth noting is that if I open the Configuration feature from within IIS I see an access denied error. I have exactly the same set up on my local dev machine to the same UNC path and the same user it works. Just on the test server it does not. What am I doing wrong? 

I have a virtual directory in my site (test environment). It is a UNC share which is also used as a public FTP. It is configured to connect as a domain admin account and "Test settings" says everything appears to be working. However when I try to connect to it I get: 

So it follows that if I run a script to set the ES_JAVA_OPTS at startup before the elasticsearch service starts. I tried a lot of things to try and get the ES_JAVA_OPTS to be set but when looking at the logs I can see it was using the default. I've tried various things: 

You can give selective DNS responses based on location with BIND Views if you are using BIND as your external DNS server. The Technical Preview of the new version of Windows Server also has a feature called DNS Policies which looks very promising. To serve content based on client location and other criteria such as User Agent or schedules, F5 has an appliance called Global Traffic Manager which used in conjuntion with their load balancers achieves what you are looking for. In Cloud environments, Amazon's Route 53 can accomplish the same. In order to keep the data in sync you must have a storage backend capable of do synchoronous replication, or use the replication provided by MySQL, which will keep the replicated data consistent. 

Here is an excelent article explaining in detail how to use this feature: Exchange 2010 Administrator Logging walk-through 

The iptables rule is fine, but according to nmap's output I don't think that you have any service running in that port. Confirm that by running the following command: 

According to the HP DL360 G6 User Guide, the fan 2 is only necessary when the second processor is present: 

The article that you pointed out does not necessarily apply only to domain environments. As noted at the end: 

A couple of things that you can try with Group Policy are the following: -Set up a fake proxy, and add the internal servers URLS in the "Bypass Proxy Server for Local Addresses" list. This can be easily circunvent if your users manage to install another browser that is not affected by group policies. -You can add a bogus route to 0.0.0.0, and then appropiate routes for all your internal subnets. You can achieve this using Group policy preferences and adding to the registry the list of routes under or by adding a logon script with the apropiate commands. You can also enforce a fake DNS server and distribute a custom hosts file with the required servers from a network share, however, this may be become hard to manage in the long term.