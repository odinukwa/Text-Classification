That said, students will most likely encounter Sylow p-groups before Galois Theory. But that's not really an argument against providing the proof of FTA as a 'spectacular' application - especially if students are familiar with some basic field theory. The Galois theory it uses is in any case very elementary. And of course the key step is to show that $\vert$Gal$(k/\mathbb{R})\vert = 2^m$ which cannot be done without Sylow. If anything this application illustrates exactly what a course on group theory should illustrate which is that a lot of analytic-flavoured questions involve insights that are much more adequately generalized in the framework of algebraic structures. (Of course some elementary analytic facts are still required in the proof.) 

You can prove that the two theories are, in fact, equivalent. By induction (NB: 'meta-induction') on the number of parameters, we can reduce the claim to the case where you have a theory $T$ with the usual induction schema and a theory $T'$ that is an extension of $T$ by a one-parameter induction schema. So assume $T$ and $T'$ are not equivalent. This implies that there is a model $\mathcal{M} \vDash T'$ and a two-place open sentence $\phi(x,y)$ such that $$\mathcal{M} \vDash \phi(0,\beta) \wedge (\forall x (\phi(x,\beta) \rightarrow \phi(x+1,\beta))) $$ but also, $$\mathcal{M} \nvDash \forall x \phi(x,\beta)$$ for some $\beta \in \mathcal{M}$. But note now that the above is equivalent to $$ \mathcal{M} \vDash \exists y (\phi(0,y) \wedge (\forall z (\phi(z,y) \rightarrow \phi(z+1,y))) \wedge \neg \forall z \phi(z,y) $$ and if you call this last sentence $S$ then you get that $S \wedge \phi ' (x)$ violates the usual induction-schema, where $\phi ' (x)$ is the one-place open sentence we get by by closing $y$ under the existential quantifier in $S$. That is to say we have $S \wedge \phi ' (0)$ and $ \forall x (S \wedge \phi ' (x) \rightarrow S \wedge \phi ' (x+1))$ but not $\forall x S \wedge \phi ' (x)$. But that is a contradiction since $\mathcal{M}$ is a model of $T$. Hence the two theories are equivalent. 

Proof Suppose $f\in F(A)$ has infinitely many zeros on a bounded interval. Then by Bolzano-Weierstrass the set of zeros has a convergent subsequence in $A$. Therefore, by identity theorem, $f$ must be zero on all of $A$. However, this contradicts our assumption that $f$ is non-zero. Q.E.D. My question: Are there ways of sharpening the bound on the number of zeros? Let $N(f)$ be the number of zeros of $f$. Clear, there is no uniform bound on $N(f)$ for all $f\in F$. However, there a subset of $F$ for which we do have good upper bounds like a set of polynomials of degree $n$ in which case $N\le n$. My second question (or refined first question) is: For a give $f$ which is analytic on $A$, but not a polynomial, are there ways of finding an upper bound on the number zeros of $f$? 

Let me outline the classical proof and explain why I am interested in this question. Choose some function $g(X,Y)$. Then, \begin{align} E[ (X-E[X|Y]) g(X,Y)] \le \left| E[ (X-E[X|Y]) g(X,Y)] \right| \le \sqrt{ E \left[ (X-E[X|Y])^2 \right] E[g(X,Y)^2] }. \end{align} Therefore, \begin{align} E \left[ (X-E[X|Y])^2 \right] \ge \frac{\left| E[ (X-E[X|Y]) g(X,Y)] \right|}{E[g(X,Y)^2]}. \end{align} The proof is completed by choosing $g(x,y)=\frac{d}{dx} \log (f_{XY}(x,y) ) $ and noting that then $ E[ (X-E[X|Y]) g(X,Y)]=-1$. This gives us the Cramer-Rao lower bound \begin{align} E \left[ (X-E[X|Y])^2 \right] \ge \frac{1}{E \left[ \left(\frac{d}{dx} \log (f_{XY}(X,Y) ) \right)^2 \right]}. \end{align} The choice of $g(X,Y)=\frac{d}{dx} \log (f_{XY}(x,y) ) $ always seemed mysterious to me (but this is not the main reason for ask this question). That is why I am wondering whether there is a more "natural" proof where the quantity $\frac{d}{dx} \log (f_{XY}(x,y) )$ appearance is more obvious. For example, it would be nice if we can derive an inequality by showing that \begin{align} E \left[ (X-E[X|Y])^2 \right] = \frac{1}{E \left[ \left(\frac{d}{dx} \log (f_{XY}(X,Y) ) \right)^2 \right]}+c, \end{align} where $c$ is non-negative. 

You can prove the Fundamental Theorem of Algebra using Sylow 2-subgroups. The sketch of the proof is as follows: 

It is usually the case that this requirement is equivalent to $A_{m}$ having P for all maximal ideals $m$ of $A$. I was wondering which (if any) are the strongest/most interesting local properties $P$ of a commutative ring that do not satisfy the second equivalence. Similarly, I would like to know the strongest/most interesting non-local properties P that are true at all localizations at $p$. That is to say, what are the most interesting properties P of $A$ such that: 

The definitions are indeed equivalent. The idea of 'local smallness' is to get for any $X$,$Y$ in $\mathcal{C}^I$ an object of your indexing category to represent, as it were, all (vertical) morphisms between $X$ and $Y$. Both definitions describe this fact, although Johnstone's is, I guess, slightly more 'general' than it needs to be in that it applies the above property to any $X$ and $Y$ in $\mathcal{C}$ (and not to $X$, $Y$ in the same fibre), but that's OK by Theorem 10.1 in Streicher since $\mathcal{S}$ has finite limits. The equivalence of the definitions can also be proved as exercises 8.8.9 and 8.8.10 in Volume 2 of Borceaux. To see that they are equivalent let for simplicity $X$ and $Y$ lie on the same fibre $I$ (WLOG bearing in mind what I said above.) Then Johnstone's definition says that there exists an arrow $\alpha \colon J \rightarrow I$ and a morphism $f \colon \alpha^*X \rightarrow \alpha^*Y$ such that for any $\beta \colon K \rightarrow I$ and any morphism $g \colon \beta^*X \rightarrow \beta^*Y$ there exists a unique $u: K \rightarrow J$ such that $$u^{*}(f) = g$$ and $\alpha \circ u = \beta$. But now if you write $J$ as $H_{X,Y}$ and $\alpha$ as $h_{X,Y}$ you'll see that the last sentence says exactly that there is a bijection between morphisms $f \colon \beta^*X \rightarrow \beta^*Y$ and morphisms $u$ such that $h_{X,Y} \circ u = \beta$, i.e. between morphisms from $\beta$ to $h_{X,Y}$ in $\mathcal{S}/I$. And this is exactly the second definition. 

Let $F(A)$ be a class of real-analytic function on an interval $A \subset \mathbb{R}$ minus the zero function. We have the following theorem for $F(A)$. 

I want to solve the following optimization problem \begin{align} \inf_{ X: |X| \le a \text{ a.s.}} E \left[ \frac{1}{1+(X-X^\prime)^2} \right] \end{align} where $X^\prime$ is an independent copy of $X$ and $a>0$ is some constant. How would one approach such a problem? Is the solution easy to find? At some point I thought that the optimal distribution is given by $X=\{-a,a\}$ equally likely. In which case, the solution is given by \begin{align} \inf_{ X: |X| \le a \text{ a.s.}} E \left[ \frac{1}{1+(X-X^\prime)^2} \right] \le \frac{1}{2}\frac{1}{1+4a^2}+\frac{1}{2}. \end{align} However, I don't have any supporting arguments for this. The following might be useful. Note that by Jensens' inequality \begin{align} E \left[ \frac{1}{1+(X-X^\prime)^2} \right] \ge \frac{1}{1+E[(X-X^\prime)^2]} =\frac{1}{1+2Var(X)}. \end{align} Therefore, \begin{align} \inf_{ X: |X| \le a \text{ a.s.}} E \left[ \frac{1}{1+(X-X^\prime)^2} \right] \ge \frac{1}{1+2 \sup_{ X: |X| \le a \text{ a.s.}} Var(X)}=\frac{1}{1+2a^2}, \end{align} where in the last optimization step we used \begin{align} Var(X) \le E[X^2] \le a^2, \end{align} which is achievale with $X=\{-a,a\}$ equally likely. 

Suppose that we have two independent random variables $V$ and $W$ over $\mathbb{R}$. Suppose that $W$ has a probability density with respect to the Lebesgue measure. My question: Can we find conditions on the density of $W$ the conditional expectation \begin{align} \phi_V(t)=E[V|V+W=t], \end{align} is unique with respect to a distribution of $V$. In other words, can we show conditions on $W$ under which $\phi_V(t)=\phi_U(t) , \forall t$ would imply that the distributions of $U$ and $V$ are identical? This question is very similar in spirit to the uniqueness theorem for the characteristic function. I feel the following decompositin is the key: \begin{align} \phi_V(t)=E[V|V+W=t]= \frac{E \left[V f_W(t-V)\right]}{E \left[f_W(t-V)\right]}. \end{align} 

In general it seems to me obviously not - any version of the strong LST uses some notion of cardinality which surely cannot apply to $L$. What am I missing here? Putnam does add that strictly speaking the Skolem hull construction is also needed, but I don't see how that would help. Can it? I will tag this as a reference request too, in case someone knows whether this theorem has been published elsewhere - by Putnam or otherwise. (His footnote says that he proved it in 1963 but provides no more information.) 

I suspect his terminology might be idiosyncratic, so I'll point out that by an $\omega$-model he means "a model of set theory in which the natural numbers are ordered as they are 'supposed to be'; that is, the sequence of 'natural numbers' of the model is an $\omega$-sequence." My first (not-so-interesting) question is this: 

Has anyone ever tackled this conjecture? Would it be an 'easy' conjecture? Let me make the conjecture precise, for the sake of clarity. Let $N$ be an even number and let $s(N)$ stand for the smallest prime such that $N-s(N)$ is prime (if such a prime exists, i.e. if $N$ is expressible as the sum of two primes.) Define the following set: $$S_m = \lbrace N \vert N \text{ is even and } s(N)^m > N-s(n) \rbrace $$ With this notation, Nash's conjecture asks: Is $S_3$ finite or infinite? Nash calculated the first member of $S_3$, which is 63274 = 293 + 62681. What about other values of $m$? If indeed $S_3$ is infinite, is there an $m$ such that $S_m$ is finite? (I'm tagging this as a reference request too since I know very little about the Goldbach literature and would be intrigued to read any related papers.)