Earlier answers explain the mechanisms of how this works, but I would like to address the motivation. You can accept logical fictionalism, in the sense that 'if there were truth, it would behave as our intuition dictates and satisfy Classical logic, but there is not truth'. We know from the ways we interact that logic contains large areas of relative consistency that allow us to work with facts, but we also have the religious intuition we are "always safe an divinely protected" to some degree and that "miracles occur". We routinely ignore Hume's basic argument and we know almost everything has exceptions. Classical logic accommodates the former, but cannot meet paradox reasonably. Why not admit the latter? Then the issue is not avoiding contradiction, in either of the two ways we attempt this. It is keeping your dependency in areas that avoid obvious pitfalls, and accommodate paradox ad hoc as it arises, presuming that our experience of the stability of natural language means that will not happen very often. The corresponding logical system can simply be Classical logic restricted to observable deductions. You don't need to go all the way to Intuitionist or Constructivist extremes, nor do you even need to artificially sequence self-references. But when there is a conflict, you need an axiom that resolves it. 

I was once quite fond of Roger Penrose, starting from "The Emporer's New Mind", as a way of putting quantum mechanics together with information theory and computing. (I disagree with him at a basic level, but I think he presents the relationships well.) 

Because they are all born of it, at least in the sense of being 'the flesh of its flesh'. The most recent example is Psychology. What we call psychology existed, in a rude state before there was a science for it. And where was that precursor material studied -- in philosophy. Wundt and James were philosophers until they showed there was enough understanding to begin directly studying behavior and cognition, without relapsing back into confusion constantly. And then they weren't anymore -- they were psychologists. They literally held academic positions in philosophy and then outside of it. Each science we know of either peeled itself off of a science that was already functioning or emerged out of philosophical considerations. Aristotle may have been a terrible physicist, but he named the discipline and set its boundaries. Alchemy arose out of philosophy, and eventually gave birth to chemistry as a science. Likewise for biology, mathematics, and even such latecomers as sociology. Before they had enough structure to cohere as independent fields of study, these were studied as philosophy or they were formed as a part of something that originally was. 

The central unifying concept in Nietzsche is the will to power. So effectiveness is what delivers power. The ability to predict the behavior of the external world supports an ability to influence or control people, even if this control is very indirect or hard to see immediately. You can measure effectiveness by your impact on the future through other human beings. 

Your first argument is the fallacy of Bulverism. The second is a false equivalency between the existence of God and the existence of some version of God already explained by someone. So no, as philosophical arguments, these do not cut the mustard. As to the feeling, we could stop at any point and decide that since we keep finding gaps between our physics and reality no underlying physics exists. Frustration is not an argument, either. Given 

A compromise most folks have missed is Hegalianism or (Dialecticalism in the sense of Marx). The purpose of creation supposed by Hegel is working out the conformance of the ideal world and the material world. Evolution is the consequence of the Second Law of Thermodynamics and ideas are injected into our material world from God as the result of Evolution (in a slightly more general sense than Darwin's). But the overall sweep of history is God injecting himself more and more explicitly into reality and conforming himself to the material. It is extremely anthropomorphic, but it captures what a lot of history and psychology mark out as the purpose of human life. 

"Very basic creatures such as viruses, single cell organisms, or plants don't have free will. Their behavior is completely determined by their biological and chemical conditions." does not strike me as true. We would like to think of ourselves as the major actors on the stage, the only things with will, and thus the only things that are free. But a dog makes decisions for itself, and so do the bacteria in your intestines. Those things make decisions the same way you do -- by resolving ambiguous configurations of determining pressures, in other words, by taking opportunities. It may initially strike one as an overstatement to label it 'will', but in any complex, overdetermined system with tolerances for measurements, biological or otherwise, behaviors are not fully determined. There are constantly recurring points where pressures are too close to being balanced and the response cannot be computed from the input. Those with pretentious bent always pull in mathematical chaos or quantum indeterminacy at this point. But even in a plain old Newtonian universe, no part of the system is isolated enough to be protected from minor effects like inconsistent deformation behavior in materials, or the overall gravitational interactions of uncountable far-off objects, or just plain old heat. These constitute a background noise that is basically completely random. (If you insist the universe has a finite life before us, which Newton does not, this is the accumulated chaos since then, which became dense with strange attractors long before life emerged. If not, then chaos remains irrelevant, as we observe heat to be random and can assume it always was.) I would argue that in the biological case this situation is a source of power to an individual, as leveraging the randomness facilitates searching spaces of options, and finding solutions. So, via evolution, which captures power, we have learned to observe it. This resolution of balanced scenarios -- whether we perceive it as being lost, undirected, confused, or free -- feeds back to us, and is what evolves into our sense of 'choice' and 'will'. But as to where it starts, it starts with the first three particles for which the three body problem tends toward endless non-repetition, and every time a ball comes to the top of hill with no residual momentum, free will is expressed. 

One 'mainstream' take on this problem is Jung's analysis of archetypes. From a psychoanalytic point of view, imaginary qualities of cultural artifacts are psychological hooks to a shared library of tropes. So, for instance, in describing the machinery of the "Great Work" in alchemy, a collection of mythical laboratory equipment, his focus was on cultural resonance with other philological details. I don't know how settled the catalog of tropes about one's environment can be, but it seems like a productive way of attempting to categorize mythical places. Proximity to woods, seas or mountains; weather; brightness or darkness; cultural choice of bright colors, etc. are aspects of real places with psychological impact, and they would be mapped onto fake places to shape those places' intended impact. I would presume that the intended psychological impact the culture expects a thing to have is the real meaning that one would wish to capture when cataloging imaginary objects.