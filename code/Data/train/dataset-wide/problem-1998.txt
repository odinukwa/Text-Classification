Our primary OLTP workload is tempdb heavy (both reads & writes) based on virtual_file_stats DMV, and based on SPs all of which heavily use #tmp tables. The server has 400GB of memory, more than enough to fit all tables in databases within in. Tempdb was previously on a local SSD. We recently bought and installed a Micron PCI-E card, and placed SQL (2016 Ent) tempdb data and log files on it. However, I did not see a great improvement in performance, for some workloads it was even worse. The vendor specs lists 4K read-write speeds, whereas SQL uses 64KB (right?). Before I ask the SAN team to run benchmarks on the existing SSD vs new PCI-E disks, would it make sense to format the PCI-E disk as 4KB block size, instead of 64KB.. or does it not make difference for tempdb ? 

I'm trying to troubleshoot a complex deadlock issue. There are 2 separate processes (service and agent job) which often concurrently execute the same SP but with different @BatchID parameters. This SP is called within an explicit BEGIN TRAN. There are 30 different Insert/Update statements within the SP. The 2 processes deadlock 5 times a day on the same table/index, around the same time each day, and the service process is always the victim. The table has many unnecessary/redundant indexes and a couple of Insert/Update Triggers. Lock Escalation is Disabled. Deadlock graph: 

The first table (i.e., ) has an auto-incremented (and thus unique) column , so there is the . I guess that's okay. ;) Both queries using this table only include just the primary key's column, so that's very good already. Then there is the query using both tables, which also includes the column. Does it make sense to use the unique composite here? Or is it redundant, or at least not of great advantage? Please keep in mind that there are just a few different values for the column. The second table (i.e., ) currently has a that consists of the (unique) combination of all three columns. This key is used for the last query using both tables, and also serves as constraint, because for every relationship(_id) and site(_id) there can only be one (or no) content element with a specific ID. There are two queries using just the column in the clause, that's why there is the . Then there is one query that also includes the column. Should one therefore add the composite ? I suppose there is no need for the , which would only be used by a single, very infrequent query, right? Note: The is basically a foreign key to the table. However, as I am working in an environment that allows for MySQL versions/engines that do not include foreign key constraints, I cannot use a real , and all its benefits. But this shouldn't be relevant for my question(s), right? 

We frequently see blocking on our SSRS box which houses both front-end Report Manager ReportingService and the SQL database engine with ReportServer & ReportServerTempDB Catalog databases 

Is vSphere Replication safe for SQL databases? We are a virtual environment (Cisco hardware + VMware hosts + HP san). We have a primary and disaster recovery datacenter, with SAN-level replication already setup for every 4-hours. There are several HA/DR solutions for SQL - alwayson, logshipping, clustering, replication etc. But we want the easiest administrative solution that can deliver good RPO & RTO. So we're looking to replicate at the VM-level instead of SQL-level strategies. Apparently, any VM-level snapshot/backup solution needs to be VSS (Microsoft's volume shadow service) aware to ensure highly transactional applications like Exchange or SQL Server comes back up in a consistent state after restore. VMWare's SRM(Site Recovery Manager) gives you the choice of array based replication or vSphere Replication. I read here that vSphere Replication is VSS aware and can offer utmost 15 minute RPO, which is very acceptable for most of our applications. Does anyone else use this for enterprise oltp applications with 15-minute DR RPO (not high-availability) ? Does it freeze IO on SQL server for unusable period of time ? Does it definitely ensure consistency when VM turns back on at the DR site ? 

But all they have is reads/writes, but not actual number of rows. Is it possible to get this info in SQL 2008 or SQL 2008 R2 ? 

The individual figures represent individual content elements, while their individual type is represented by their individual shape, and their ID is written inside. Each color represents a relationship (i.e., a group of related content elements). As you can see, for any color (i.e., relationship), the shape (i.e., type) is the same, while there is not more than one figure (i.e., content element) from each site. I hope this makes it more clear - and not more confusing. 

// EDIT: Here is a little more context. I didn't put it in the question before just because it was already pretty bulky. Since an answerer asked for more, I will do this now, though. Be prepared, however, it's quite a lot information. The tables are about relationships between content elements (CE). Each CE has an ID and a type. For each type, there is only one CE with a specific ID. There may, however, be CEs and (with types and ), and both have the same ID. Relations are allowed between two or more CEs that A) have the same type, and B) are from different sites (represented by their unique ID). That's why the column is part of the table (rather than being a column in the table). Sites are stored in another table, which I cannot alter in any way. I just use the sites' unique IDs, and that's all. The CEs are stored in type-specific tables, which I also cannot alter in any way. I just use a CE's ID and its type, and thus have a unique identifier. The for the column in the table is used, because there are lots of relationships for a specific type, and I need a unique identifier for every relationship. When inserting a new relationship for a given type, I just have to provide the , and automatically get a unique . That's what is for, isn't it? Or did I misunderstand you, @Rick James? I guess I don't really need . As I reference other tables' columns, however, and as these columns are defined as , I thought it okay, if not wise, to use the same definition. There are two usages of . For the first one, there shouldn't even be more than one entry (because I query for and compare , and is unique). So yes, I could/should remove this, thanks. The second time, however, there might be several entries - all with the same . That's why I happily stop if I got one result. Is there anything else I should provide you with? 

Usually my criteria for dropping an index if all the reads (user seeks+scans+lookups) are 0 (or very close to it), and it has lot of user updates, meaning the overhead of maintenance is not worth the speedup advantage. Below are index usage stats of 2 tables on a server: 

We know that the survivor/victim are SQL sessions (SPID), NOT SQL statements. We also know that the UPDATE statements shown in Frame1 of both sessions are involved in the Deadlock. And How are they involved ? They are both REQUESTORS of the U lock on the Index Key. Am I correct so far.. But which statements are the OWNERS ? And when did they start holding the X lock on the Index Key? One of the standard recommendations for resolving/reducing deadlocks is to Shorten Transactions. But if there are a hundred similar statements, without knowing WHICH statement started holding the lock and WHEN, it's not easy to go about shortening a transaction.. 

Full SP here In what order are the locks being taken ? Is there any way to avoid these deadlocks ? Adding CPU, Memory, Indexes, or Locking granularity ? 

I've been performance tuning SQL servers for a few years as a DBA. I'm trying to create a fast-food version of performance metrics that can quickly (in 5 minutes) and accurately (provable) answer a question from Management "Does this server need more/faster _ ?" '_' being one of these 4 possible bottelenecks in an IT-stack bottom up (from server-perspective, without going in to the app/code/ui):