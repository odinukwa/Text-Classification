Yes, at least according to: T. Altmann, Y. Carmel, R. Guetta, D. Zaslavsky, Y. Doytsher, Assessment of an ‘‘Energy Tower’’ potential in Australia using a mathematical model and GIS", Solar Energy 78 (2005) 799–808. (www) 

The question is still badly worded. If the question is whether "the Syrian conflict was caused by climate change as the media seem to claim?" then the answer is clearly no, and the media article linked in the question does not actually even make that claim. To quote the author of the study from the Independent article: 

This sort of thing is an active research topic (a friend of mine works on it), for example social media can be mined to detect outbreaks of disease before it would normally be reported by health organisations. Here is an example of a workshop held on this sort of thing (although in this case it was motivated via bioterrorism, rather than naturally ocurring events). 

So all in all, there is nothing really surprising here, at least not to anyone familiar with the operation of climate models and aware of the existence of other "old, simple models" (on this case estimates of climate sensitivity) that could equally have been discussed, but which were not. 

The story about the lampshade was presented as being possibly true by the National Geographic society, who say that there is a lampshade that is definitely made of human material and for which evidence "points to" an origin in Nazi Germany. According to snopes there is a book on the topic (the wonders of Google!). However, this turns out not to be the case, see the comment by @Oddthinking below. There appears no shortage of sources for evidence on the numbers killed, see also the excellent answer by @RedGrittyBrick above. I don't see any reason to be skeptical of any exaggeration, so I'd say "no, it hasn't been exaggerated". There also seems good documentary evidence that it was part of a deliberate plan. However I have to say that making a lampshade out of human skin is not by any means the worst thing that happened in the concentration camps. It is a pretty damning indictment of what went on there if being skeptical of whether they made lampshades out of human remains is the level we have to reach before skepticism becomes reasonable. 

The blue whale is a larger animal than any dinosaur with similarly large nostrils (see below) and is also warm blooded. It seems to be able to breathe without any problems (including spontaneous combustion ;o), in an atmosphere with lower oxygen levels than in the Cretateous (see below), which suggests there isn't really any need for higher partial pressure of oxygen. Regarding atmospheric oxygen during the Phanerozoic era, this paper looks interesting [*emphasi*s mine] 

Thus the most recent datapoint in the GISP2 core is 95 years prior to that (i.e. 1855). This means that none of the warming since 1855 in Greenland is shown on the chart, an hence some of the comments made by Easterbrook in his talk (at about 10:25) about a cooler periods from 1880 to 1915 and 1945 to 1977 are obviously nonsense, the ice core didn't "end there" as Easterbrook says, it ended in 1855. The author of the SkS article updated the plot of the GISP2 ice core temp series, to add observed temperatures for 1855 and 2009 from another greenland temperature reconstruction (updated) from Box, Jason E., Lei Yang, David H. Bromwich, Le-Sheng Bai, 2009: Greenland Ice Sheet Surface Air Temperature Variability: 1840–2007. J. Climate, 22, 4029–4049. doi:10.1175/2009JCLI2816.1) which clearly suggest that temperatures there now are warmer than they have been for the last 10k years, and that temperatures have been rising there very fast. See the SkS article for details of how the two datasets were reconciled. 

so while the court did rule that the child should be taken off life-support, the claim that "the only people arguing against continued efforts were government officials and some third party public onlookers." clearly isn't true as the child's doctors and the hospital were arguing against continuing treatment. It is nothing to do with the government AFAICS, but the medics and the judiciary, although it appears to have raised concerns about the availability of legal aid in such cases. Very sad case, and a difficult ethical position for all concerned, but the blog article is not an accurate representation, based on these reports. From the blog article "Except a major feature of the free market, private charity, kicked in wonderfully." seems a rather "nuanced" view to me. Private charities are not a particular feature of free markets. "As government court systems are wont to do, they sided with themselves" the U.K. judicial system is independent of what would be considered there as "government", and quite frequently go against it (see here for a recent notable example). As noted by @GordonM the language of the blog post is rather hyperbolic. These things, considered together, do not give [me] confidence that the blog is unbiased and without agenda. 

See also this article on Influenza surveillance. The particular tool involved in this question is HealthMap, and they provide a timeline of the Ebola outbreak here, which allows you to see what it was saying at different points in time. HealthMap doesn't specifically predict outbreaks of disease, but what it does do is to find and collate relevant information from press reports and social media that allow potential outbreaks to be identified earlier than could be reasonable done manually. It would be more accurate to say that HealthMap alerted us to a potential outbreak of some hemorrhagic disease 9 days earlier than the WHO. 

Yes, some of them clearly were, for example whale fossils have been found in the Sahara at the Wadi al-Hitan. However, while some deserts were once oceans/seas, that doesn't mean all deserts were once oceans. 

In a word, no. Weather stations are (as their names suggest) designed for collecting information for weather forecasting (i.e. short term variations in temperature, precipitation etc.), they were never intended for collecting information for climate research (long term statistical behaviour of the weather). As a result, the instruments used tend to have biases and discontinuities in the records, due to things like moving the station itself, or changing the time of day at which readings are taken, changes of instrument, that are not a problem for weather forecasting, but do pose a problem for climate research. To compensate for these known changes, homogenization steps are taken to correct for these problems. These are well documented and explained in the literature. Trewin provides a nice overview of this research topic, Blair Trewin, "Exposure, instrumentation, and observing practice effects on land temperature measurements", WIRES Climate Change, volume 1, issue 4, pages 490-506, Apr 21 2010, DOI: 10.1002/wcc.46. The International Surface Temperature Initiative is a useful resource for those interested in investigating this topic in more detail. Also of interest is the Berkeley Earth project, which was in initiative set up by initially skeptical scientists to investigate whether the global surface temperature datasets were in fact biased by these adjustments. Using their own independent method, they found that they got the same results as the other groups. There is also the point that the satellite global temperature datasets give similar warming trends to the surface measurements, but the satellite measurements are not subject to the same biases. Note the UAH product is produced by noted climate skeptics John Christy and Roy Spencer. 

Easterbrooks main argument here has already been discussed at Skeptical Science, the article is here. There are two main errors, the first is to treat Greenland as if it were representative of global temperatures. The second, more important error is that apparently it is conventional in this field to treat 1950 as the "present" in this kind of study. 

This paper seems to suggest that the Romans didn't have a specific term for glacier, but their travel writers did describe things that are plausibly glaciers. This would imply that the claim "Nowhere in the detailed travel accounts from Roman times are glaciers mentioned." is ill-informed if not actually factually incorrect. This also implies that we can't expect to be able to unambiguously verify glacial extents from historical sources, and certainly can't use the absence of evidence that Schlüchter's claim is correct. Does this mean that Alpine glaciers were smaller in Roman times? There seems to be some evidence that they were, e.g. Roman coins revealed by glacier retreat (reported by the BBC), however that doesn't mean the Romans didn't traverse the glacier, rather than that it wasn't there, or that the glacier had not transported them from higher up the mountain. However later in the article, we read "The fact that we still find these 5,000-year-old pieces of leather tells us they were protected by the ice all this time, and that the glaciers have never been smaller than in the year 2003 and the years following." which directly refutes the claims. It is worth noting that the BBC article also says "The site is exactly at the point where the glacier responds most sensitively to short-term climate change and temperature variations," he explains. "So if we get more carbon datings from this site, we can get the most precise picture of short-term glacier fluctuations for the past six or 7,000 years.". This suggests we should be cautious in interpreting such regional changes in glaciers as strong evidence regarding global climate. 

Now what does the literature say about this? Well a good start is Easterling and Wehner, which looked at flat trends in the data and in model output, and found that this sort of hiatus is not that unusual. 

These are the anomalies (i.e. the mean seasonal cycle has been subtracted out) for all model runs for RCP8.5 for the temperature at surface (TAS). It is quite clear that the models are not all in perfect agreement about 1990. The revised IPCC diagram faithfully reflects the variability in actual model output, so rather than obfuscating the model-observation comparsion, it has made it more fair. The difference between the two plots is due to baselining. Climate models are better at modelling the changes in temperature resulting from changes in forcings than they are at accurately modelling absolute temperature (some of the variability in the model runs shown above is due to differences in absolute temperature between model runs). This is well known to those who work with models (although it is such common practice it is difficult to find a paper explaining why this is necessary - it is apparently part of the scientific paradigm). However these differences in absolute temperature are essentially irrelevant to the question of the response of the climate to increasing CO2 radiative forcing. The simple solution is to subtract a constant from each model run so that they agree on the mean temperature over some agreed baseline period. Here is what the IPCC say about baseline periods (from the TAR): "A popular climatological baseline period is a 30-year "normal" period, as defined by the WMO. The current WMO normal period is 1961-1990, which provides a standard reference for many impact studies." Long baseline periods are a good idea as it means that the projections are not very sensitive to the effects of internal variability in the observations and in the models (as it is the average offset over an extended period that e.g. contains several cycles of ENSO). If we use just one year and align all the models and observations to that one year, then if it is a particular warm year in the observations e.g. 1990, the models also start hot and this increases the apparent discrepancy later. If we use a cool year, e.g. 1992, the models start cooler as well, and this would decrease the apparent discrepancy later. However the difference between the two is entirely meaningless as it depends on the noise in the observations. That is why the longer baseline used in the revised diagram gives a more accurate depiction of the difference between models and observations. So why did the IPCC use a single year baseline in the original diagram? I suspect it is because it makes the trends (rate of warming) easier to see visially if the models and projections all pass through some common point. HOWEVER this does mean that there is a spurious offset between models and observations, that depends on which year in which the data are made to agree. Far from obfuscating the difference between models and observation, the new diagram presents it more clearly. 

To begin with, the question ought to be reworded as "Can simple, old models of the effect of CO₂ predict global mean surface temperature better than complex modern climate simulations?". GMSTs can be modelled quite well by comparatively simple models of global climate, using physics that has been well understood for many years (see the primers by Pierrehumbert and McGuffie and Henderson-Sellers). The reason that climatologists use GCMs rather than these simple climate models is GCMs can model regional climate, so that for instance we can project the effect of increasing GHGs on Europe, or Australasia or the Arctic. The simple climate models cannot do this as they have no concept of the spatial element of climate. So even if simple, old models can provide a better prediction of observed GMSTs, that doesn't mean that they are more useful than GCMs, as they don't provide the level of spatial detail necessary. The next important part is that there is a big difference between the questions "Can simple, old models ... ?" and "Do simple, old models ... ?" Callendars simple, old model is only one of many, there were others with higher climate sensitivity than Callendars (there is a nice compilation of classic papers on climate edited by Archer and Pierrehumbert). For instance, Gilbert Plass suggested a climate sensitivity of 3.6ºC per doubling of CO2. Had ClimateAudit used that figure instead of Callendar's more modest 1.67 deg, I suspect that the GCM-Q model would have shown much more warming than from HadGEM2 and the conclusion would have been the exact opposite. The important point here is that ClimateAudit isn't using GCM-Q as a genuine prediction as Callendar's low climate sensitivity was selected in the knowledge that a low climate sensitivity seems to match the observed climate better than a high one, having already seen the observations to be predicted. A skeptic ought to ask why ClimateAudit chose Calendar's value of climate sensitivity, rather than any of the higher historical estimates that could have been selected? A better analysis would have been to perform a survey of historical estimates of climate sensitivity and plot the results for each estimate using GCM-Q. This would basically show that modern GCMs lie well within the span of historical estimates, but that if you were so inclined, you could select a historical model that was closer to the observations than the modern models. Would that tell us anything surprising or that we didn't already know? I would say "no, not really". So, does the fact that a lower climate sensitivity seems to fit the observations mean that the modern GCMs with higher climate sensitivities are wrong? No, sadly it isn't as simple as that. The observed climate is a combination of the forced response (i.e. the response of the climate system to a change in the forcings, such as CO2 or solar) and the unforced response (a.k.a. "natural variability", "weather noise" etc., which is changes in the climate that are not directly due to the forcings, such as oscillations in ocean currents, such as ENSO etc.). Now the unforced response is chaotic, which means that it is deterministic, but cannot be predicted a long way into the future because it is extremely sensitive to the initial conditions. This means that GCMs can only simulate the effects of the unforced response that are statistically plausible, but cannot predict them as we don't have sufficient information regarding the initial conditions. The best we can do is to form an ensemble of model runs and take the average. The unforced responses in individual runs will not be coherent, and thus will largely cancel out, leaving us with just an estimate of the forced response (which is also what GCM-Q gives us). However, in comparing with the observations, we need to bear in mind that we are not comparing apples with apples, but apples with oranges. The models give us an estimate of the forced response only, but the observations are a combination of forced and unforced response. So the difference between the two may be due to the models being systematically wrong (i.e. their climate sensitivity is too high) or because the effects of the unforced response has been cooling, rather than warming, which makes climate sensitivity over the period of observation look lower than it actually is, or a bit of both. We only have one observed climate, so we can't work out from the observations which is which, the best we can do is to look at the spread of the model runs (which gives us an idea of the plausible variability due to the unforced response) and see if the observations lie in the spread of the runs. This is as accurate as the GCMs can plausibly be expected to be, and this is pretty much what climatologists actually do (see below).