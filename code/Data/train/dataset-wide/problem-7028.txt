I had an interesting casual discussion with a colleague the other day. A lot of western economies at least, such as New Zealand, have some form of retirement pension. It New Zealand it's called Superannuation. For a single pensioner, the amount received is 40% of the average wage. I mentioned that as we get an aging population, the cost to the tax payer of paying this pension will increase. Currently about 12% of the budget is used to pay Superannuation. One of the common solutions put forward is to raise the age that people are eligible to receive the pension. However, my colleague pointed out that raising the retirement age will likely keep older people in the workforce longer, and pointed out that India in fact lowered the retirement age, as to generate jobs for young people. So this poses an interesting problem - on one hand, increasing the retirement age saves the government and taxpayer money. On the other hand, it possibly takes jobs from young people and stiffles their career. Is there any research on the effect of retirement ages and their effect on employment? 

Here in New Zealand our lowest denomination coin is 10c after the 5c was removed about 10 years ago. I think generally the public is pretty happy about the move. It's quite a common argument to remove the penny from circulation in the United States. The main argument being that pennies are expensive to produce, are virtually worthless, and tie up time when they're given as change. The argument is that they don't actually serve the purpose of currency very well in terms of easily transferring value, because their value is so small for the effort of using them. The question I have is, what economic effect would removing the smallest denomination currency have? Things to consider are: 

In New Zealand our lowest denomination note is a $5 note. For perspective, a can of coke costs $1.50 - $2.00, a Big Mac costs around $5. The idea of a $5 coin is on the cards. The question is - what effect does turning a note in to a coin have? I imagine there would more of a piggybank effect (coins being lost, stuck in collection jars). Are there any studies on what's happened when notes have been replaced by coins? 

Let $y$ be the proportion in $[0,1]$ instead of the percentage. I think the issues here are possible nonlinearity and censoring. You can try including quadratic terms on the right hand side. At the same time, you can try the following models. I. Linear models: If no $y$ is exactly 0 or 1, linear models will be OK. The following four options come to my mind. 

You are saying: $y$ is regressed on $x_1$ and $x_2$, say, and you think it would be better to use cluster errors since you expect $y$ is correlated with habilities (abilities?) for each person. First, $y$ is naturally correlated with the error term $u$ (if you mean the error term by "habilities") because $u$ is a part of $y$. You have no problems with that; $y$ is always strongly correlated with $u$. It also has nothing to do with cluster errors. If you happen to mean cluster standard errors (SE) by "cluster errors", and if you are saying that you would use cluster SE because $x_1$ is correlated with $u$, I would say that the regressor-error correlation (endogeneity) has nothing to do with cluster SE, what so ever. Cluster SE provides valid inference when the the error term show within-cluster (auto)correlation. Please enlighten me if I misinterpreted your question. 

An LPM is a model in which the probability of the binary dependent variable having a particular value is linear in parameters. For example, if $y$ is a 0/1-valued variable and $P(y=1)=x\beta$, it (the equation for the probability) is called a linear probability model. Likewise, if $y \in \{ -1, 1 \}$ and $P(y=-1) = x\beta$, it’s a linear probability model. Or if $y$ is an apple/orange-valued variable and you believe that the probability of $y$ being an apple is $x\beta$, your belief is said to be a linear probability model. Zero/one mean nothing real here; they are only labels. You can label them as man/woman instead if you want. You lose no information by this relabeling as long as you remember the new labels. Also, as Papadopoulus said, it is a model, not an estimator, though we just understand an “LPM estimator” casually as an estimator of parameters in an LPM. 

The question is, is this a genuine dilemma for start ups, or is the rational decision always to 'take as much money as you can'? 

It's quite clear that the expected return on a lottery ticket is less than 1. However, I think it can still be argued that buying lottery tickets is still a economically rational decision by consumers. There are a few lines of reasoning: 

The investor has erroneously overvalued the value of the stock/commodity. The investor is aware that it's a bubble and is overvalued, but believes he can make a profit by selling before the bubble bursts. 

(These programs aren't reducing imports by imposing tarrifs). What would the effect on that country's economy be? Under existing trade rules, are any of these examples likely to breach free trade agreements? On the face of it, a reduce demand for imported goods would correspond with a lower supply of that country's currency, as they need to sell less of their own currency to buy the imports they need. This would raise the price of their currency, and that would in turn reduce demand for the country's exports. However, I'm wondering I'm missing another side of the equation here - eg, selling currency for international investment. 

The borrowers say to country A's exporter, 'I would like to buy some widgets, get the cash from my bank' and exporter (or rather, the exporter's bank, who is based in country A) says to the bank 'Cash please!'. Country B's bank doesn't have the cash to honor every loan they've made, so they're unable to honor the payments and the loan they gave the borrowers is essentially worthless. The exporter doesn't send the goods. The exporter in country A's bank is ok with the promise of payment from the bank in country B. Afterall - there are also exporters in country B selling goods to people in country A, and this will balance out the loan. 

You can also statistically test heteroskedasticity (e.g., White's test: regress squared residuals from OLS on $\hat{y}$ and $\hat{y}^2$, or if you have a simple model, regress $\hat{u}^2$ on $x$ and $x^2$). It's unclear what you mean by your "model having heteroskedasticity" (do you mean the error term is heteroskedastic?) and "impacting the prediction". You can always choose to ignore heteroskedasticity if you want. (You seem to do so, as you mentioned OLS.) Or you can have a different estimator (e.g., WLS) for a better (sometimes only slightly better) predictor using the same model. Or you can even have a model that incorporates heteroskedasticity explicitly as in, for example, GARCH models in time series. Please be more specific if you want more help. You might want to read this post for time series: $URL$ 

It is conventional to report both the total number of observations (1000 in your case) and the number of groups (500 in your case). If you want or are allowed to report only one number as the number of observations, it is suitable to report 1000 for POLS because POLS doesn't mind the fact that it is a panel data set. For FD, it is slightly confusing to me to say that the number of observations is 500. I would probably ask again of the writer what 500 means. 

If I understood you correctly, $\Lambda(x_i'\hat\beta)$, where $\Lambda(x) = e^x / (1+e^x)$. You can use in both R and Stata. Try in Stata: 

Now, if $E_t(x_{t+j})$ converges as $j\to\infty$, then $\lim_{j\to\infty} E_t(x_{t+j}) = \lim_{j\to\infty} E_t (x_{t+j-1})$, and thus $$ \lim_{j\to\infty} E_t(x_{t+j} - \rho x_{t+j-1}) = (1-\rho) \lim_{j\to\infty} E_t(x_{t+j}) = x_t - \rho x_{t-1}. $$ As a result, $\lim_{j\to\infty} E_t(a_{t+j}) = \lim E_t(x_{t+j}) + \lim E_t(z_{t+j}) = \frac{1}{1-\rho} (x_t-\rho x_{t-1}) + 0$. 

Above, we assumed that $E_t(x_{t+j})$ converges as $j\to\infty$. Now we have to show (or check) it. The simplest way would be to write $$ \pmatrix{x_t\\ x_{t-1}} = \pmatrix{1+\rho & -\rho\\ 1 & 0} \pmatrix{x_{t-1}\\ x_{t-2}} + \pmatrix{\epsilon_t\\ 0}, $$ that is $W_t = A W_{t-1} + \xi_t$, where $W_t = (x_t, x_{t-1})'$, $\xi_t = (\epsilon_t,0)'$ and $A$ is the $2\times 2$ matrix on the right-hand side. You then have $W_{t+j} = A^j W_t + \sum_{k=0}^{j-1} A^k \xi_{t+j-k}$, from which $E_t (W_{t+j}) = A^j W_t$. Thus, $E_t(x_{t+j})$ converges if $A^j$ converges. The two eigenvalues of $A$ are 1 and $\rho$, which are real and no greater than unity in magnitude. And the associated two eigenvectors are both real (one proportional to $(1,1)'$ and the other to $(\rho,1)'$). These suffice. (Because $A = V\Lambda V^{-1}$, where $\Lambda$ is the diagonal matrix of 1 and $\rho$, and $V$ is the matrix of eigenvectors, we have $A^j = V \Lambda^j V^{-1}$, which converges as $j\to\infty$ because $\Lambda^j$ converges.) 

If a country has a lower inflation rate than your country, it's currency will tend to appreciate against your currency over time, see interest rate parity. It is true that if inflation is low, house prices will tend to increase less over the next ten years, however, the currency will tend to appreciate, making it more expensive to buy a house in ten years time. 

House prices usually don't rise in isolation. You make some very good points that are all valid. Nonetheless, house prices typically rise, when the economy is doing well, when unemployment is falling, when wages are rising, etc. So when newspapers welcome rising house prices, they treat it as an indicator of the overall health of the economy and this is why it's considered positive. If my salary is increasing rapidly, I might not mind house prices rising even if I don't own a house. A good example is the housing boom in the US until 2007. The economy was booming, people were better off each year and rising house prices were not seen as something negative. In recent years, however, extraordinary central bank policy (low interest rates basically) pushed up house prices, but the economy was not booming to the extent that house prices rose in many countries. In this scenario it is less clear that rising house prices are a good thing, as you also elaborate. 

Investment in infrastructure can increase capital input, because if there are more roads in the country, the economy can produce more goods and services (think about a truck company, for example, which can do more jobs per day if its trucks travel on more direct roads or faster highways). It can also increase total factor productivity, because the proportional increase in output is potentially higher than the proportional increase in capital input. If with a short road I link a town to a national highway network, the benefits can be disproportionally high, as a short road link now provides access to a huge existing highway network. Or think about the 50 mile Panama Canal. It provides ships an 8,000 mile shortcut. 

II. Tobit models: If some $y$ are exactly 0 or 1, you can try Tobit models ( in Stata). Remember that normality is assumed for the error term before censoring. Also, using Tobit models means that "I think $y$ could be bigger than 1 (smaller than 0) if not censored." 

In general, if $c_1$ is endogenous, you need instruments for $c_1$ as well. Example: Even when $x_1$ is exogenous, if $c_1$ is endogenous and $x_1$ and $c_1$ are correlated, then OLS (which is the IV estimator using $x_1$ as IV for $x_1$) is generally inconsistent. Exceptions exist. For example, when exactly identified, if $(Ezc') (Ecc')^{-1} (Ecu)=0$, then your IV estimator is consistent, I guess. (Can derive this using standard technique involving the law of large numbers.) 

(note that person 102 is measured twice), I guess what you want is $A=(1/3) \times [E(temp_{101}) + E(temp_{102}) + E(temp_{103}) ]$. OLS (the unweighted average), however, equals $(1/4) \times (x_1 + x_2 + x_3 + x_4)$, which is an unbiased estimator of $B=(1/4) \times [ E(temp_{101}) + E(temp_{102}) + E(temp_{102}) + E(temp_{103}) ]$. If $A = B$, that's fine, but $A$ and $B$ can be different. When you want $A$, what you want to calculate is $A_{be} = (1/3) \times [x_1 + (x_2 + x_3)/2 + x_4]$, while OLS puts too much weight on person 102. $A_{be}$ is called the panel "between group (BE) estimator". You can get it by . For the above data set, the BE estimate (of $A$) is 37.1, while the OLS estimate (of $B$) is 37.15. Try the following in Stata (copy & paste). 

Yes. If the idiosyncratic error is iid, xtreg (FE) with no options (ordinary se) is valid, but the ordinary se for FD, reg d.(y x), is invalid because the differenced error is serially correlated. Yes, it is. It's cluster-robust, which means OK regardless of the presence of within-group correlation. 

The short answer is no, this is not so when the dependent variable is in log, unless you define the $\%\Delta$ as (100 times) log-difference. The reason is that $E(\log y) \ne \log E(y)$. We don't need a multiple regression model to show this so consider $\log(y)=\beta_0 + \beta_1 x + u$. It is the dependent variable in log that matters, so let us not take log to $x$ for notational brevity. It is true that $\%\Delta y \approx 100 \beta_1 \Delta x$ if $\Delta u = 0$ (ceteris paribus) when $\beta_1 \Delta x \approx 0$. But we cannot interpret it in terms of $E(y|x)$. The reason follows. As you can see, we have $y = \exp(\beta_0 + \beta_1 x + u)$. When $x$ increases from $x_1$ to $x_1+\Delta x$, $y$ increases from $y_1 = \exp(\beta_0 + \beta_1 x_1 + u_1)$ to $y_2 = \exp \{ \beta_0 + \beta_1 (x_1+\Delta x)+u_2 \}$. Importantly, $u$ can also change because $u$ is not held fixed, which is why I wrote $u_1$ and $u_2$. Now, what is the change rate of $y$? We have $$ \frac{y_2}{y_1} -1 = \exp(\beta \Delta x) \exp(\Delta u) -1 \approx (1+\beta \Delta x) \cdot \exp(\Delta u) -1, $$ where $\Delta u = u_2-u_1$. Here, the left-hand side is the change rate of $y$. You can verify that the change rate of $y$ is approximately $\beta \Delta x$ if $u_1 = u_2$, i.e., if $u$ is held fixed so that $\exp(\Delta u) = 1$. But the problem is that $u$ is not held fixed so $\exp(\Delta u)$ can be very different from 1. When $x$ and $u$ are independent, the average growth rate is $\exp(\beta \Delta x) \cdot E(e^{\Delta u}) -1$. How different would this be from $\beta \Delta x$? If $u\sim N(0,\sigma^2)$ and $u_1$ and $u_2$ are mutually independent, then $u_2-u_1 \sim N(0,2 \sigma^2)$, and thus $E(e^{u_2-u_1}) = \exp(\sigma^2)$. For example, if $\beta_1 \Delta x_1 = 0.01$ and $u\sim N(0,1)$, then the average growth rate of $y$ is $\exp(0.01) \times e - 1 \approx 1.75$, that is, approximately 175%, which is hugely different from 1%. Interesting, isn't it? Simulations: Use R to do the following simulation.