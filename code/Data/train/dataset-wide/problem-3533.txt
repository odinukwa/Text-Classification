So far nothing has worked, and the only other ideas that I have (but am not sure I want to try except at last resort) are 

In our organization, we have two test machines running Windows XP. While attempting to test a roll-my-own UDP message server, I found that both could receive small messages (under 2k) just fine. However, when I test sending large packets to both of these machines, one receives them fine, while the other can't receive them at all. Both machines have SP3 and both have their Windows Firewall shut off, but one still isn't working. Can anyone tell me where to look for anything that might be blocking or limiting the packet size on a Windows Machine? Thanks. 

We can use CTRL-ALT-DEL to get to the task manager, and from there run explorer and other programs to get into things to look, but this is really baffling me and our admin. Does anyone know what could cause all of this to happen at once on so many machines? Thanks. Edit: Seemed to be fine for a week, but it's back. Some machines have varying degrees of the above symptoms. 

I then make sure that the authorized_keys file is chmod 600 in the folder chmod 700. I then setup a shell script for cron to run: 

So I asume everything has run as it should. But when I check the remote server no files have been copied accross. If I run the backup.sh file in a terminal as normal it still prompts for a password but this time its through the Mac Key chain system rather than typing into the console window. With the Mac Key Chain I can set it to save the password so that it doesnt ask for it again but Im sure when run with cron this password isnt picked up. This is where I'm asuming where rsync in cron is failing because it needs a password to connect but I thought the whole idea of making the SSH keys was to prevent the use of a password. Have I missed a step or done something wrong here? Thanks Scott 

Entering the password and then confirming it. I then copy the rsync-key.pub file accross to the linux server and place in the rsync user .ssh folder and rename to authorized_keys: 

Splunk looked pretty good, but we couldn't justify the price compared to a roll-your-own, so I had to roll up a basic logging server using a UDP connection. Fortunately, a 64k size limit gives me the ability to send 99%+ of my log messages through with just one UDP datagram. 

We have a number of client machines on a domain that have decided to start exhibiting some strange problematic behavior this morning. All machines are Win XP SP3, fully up to date with patches and symantec av. Several different virus scanners have been tried (separately, of course), and nothing found. The symptoms of the issue are: 

Before I take any of these steps, does anyone have any ideas on anything else I can try to get these two servers talking again? 

I have a web application (IIS 8) on one server (Windows Server 2012) connecting to SQL Server Reporting Services 2012 on another server (Windows Server 2008) that until recently was working fine. About a week ago, it stopped working, and since then, I have not been able to get the system working again. The premise is that my code calls to SSRS to retrieve a report, then serves it to the user (so that the user never has view or access to the report directly for security reasons). The error message in my logs states "The request was aborted: Could not create SSL/TLS secure channel." The web server is reporting "A fatal alert was generated and sent to the remote endpoint. This may result in termination of the connection. The TLS protocol defined fatal error code is 70. The Windows SChannel error state is 105." which says that it's trying to negotiate an unsupported protocol. Fixes tried (and failed): Updated code to force TLS 1.2 Fully patched both servers, and software that doesn't automatically get patched Checked firewall on both servers (it is disabled) Examined and updated the allowed protocols, etc. with IIS Crypto to disable insecure options on both servers. And out of desperation (because it came up in search results and Windows Update notes): Added the LdapEnforceChannelBinding registry entry per MS at $URL$ Followed the directions at $URL$ re security check exemptions Removed the last set of patches from Windows Update 

If you go into the recovery options of that service have you set to auto restart if it fails? If the service is still causing you issues you could use something like FireDaemon Pro with Fusion - $URL$ That way you can restart services over a web interface rather than having to go to the box and reboot. 

Be warned that partitioning disks can result in data loss. What I'd make sure you do before atempting to partition your hard drives is that you do some cloning first so that if you do mess it up you can drop back on your clone copy and be back where you started. The only partion program I've used is partition magic but Norton have drop it from their products now. Gparted is another good one I've heard of and its already mentioned here. $URL$ <-- something like this will come loaded with a load of tools and comes with gparted and a number of clone tools too. Regarding your RAID setup these programs may or may not see your raided disks. It all depends if these tools come pre loaded with some common drivers for raid controller. Anyway ultimate boot cd is a good place to start. There is no harm starting it up and see if it see's your disks? 

(obviously, we are speaking of publicly reachable server). Am I on the right trail - could rooted server be recognized by this approach and how? 

You may use Monit. This program regularly checks (on adjustable time interval - 2mins, 5mins...) number of vital system parameters, and is I think even on by default. When parameter () goes out of the adjustable threshold default is to send to you notification email. If this is favourable, you may login via ssh and do and other standard tools in order to gain quick and rough insight about what is happening. Second option would be to configure Monit's custom script execution instead of (or together with) sending of notification email. This custom script may do simple and you would have good starting point to investigate high load averages. 

may alter your file. It does mean that anyone on the system may do it - and this is potentially a lot of third parties. Let's say you have one hacked Wordpress website, just one among the many others, which runs on apache or designated system user - this site may be used to iterate system in order to find any accessible (readable, writable, executable) file - and guess who is on board? So, stick to general recommendation to provide only minimum rights to the part of your system (whatever it may be) needed to work. permission is rarely used besides non-private non-secret type of files. 

I have a working rsync setup between Mac OS X Server and Linux Centos when run manually in a terminal. I enter the rsync command, it asks for the password, I enter it and off it goes, runs and completes. Now I know thats working I set out to fully automate it via cron. First off I create an SSH authorized key by running this command on the Mac server: 

I check my crontab log file after the above command should run and I get this in the log and nothing else: 

Then give the shell file execute permissions and then add the following to the crontab using crontab -e: 

The backup could take any length of time, from a few minutes to days and if I run the backup via cron every 6 hours what I dont want is two instances of this running at the same time. So what I've done is created a simple locking mechanism. But I'm woried that if the script is killed half way through for what ever reason that lock file is always going to be there and the backup routine is not going to run. Is there a way of enhancing this to be better fool proof? Thanks Scott EDIT: Final bash script I'm now using thanks to the answer below: 

I'm completely confused about question of necessity/benefit of stripping local network host names and IPs from from mail headers. Two years ago I've found an article which states that modern ESPs (Yahoo, Microsoft, Google...) considers like headers somehow related to spamyness of email, and gives email bad treatment consequently. From then, all my Postfix servers strips that info with directive. Recently I've come across KBs that states opposite - that, in short, every header MTA generates is useful and should not be removed forcibly. For now, I'm not experiencing issues, but these two schools cannot be right at the same time - do you know what practice is the best regarding this issue? 

Just to add 2Â¢ more in this answer: file with code provided in question will certainly be marked as suspicious with Shell Detector. But, get ready for possibly many false positives. You'll have to eyeball-check and whitelist them. 

In order to use socket you need to specify: to also, you need to change settings in Postfix consequently: in add: 

SPF and DKIM must not be seen as panacea for email deliverability problems. Period. Depending on many factors (vendor, software & others...), they may increase chances for good outcome, or decrease chances of messages being bounced at SMTP handshake level, provide sender integrity or cause email servers to bounce spammers pretending to come from your domain name, and that's it. It is also important to know that there are senders with long-established good reputation that don't use this two techniques at all (although not using SPF is really weird in 2017). I'd say your problem is well-known - Why Does hotmail still reject my emails? . With the details you have provided, I'd suspect that content of messages does have some significance to antispam software they are using - maybe try to alter content and see the results. 

Have you checked the case differences between the requested file and the file on disk? Don't forget that under most file systems used by Linux, Hello.doc does not equal hello.doc. 

I have a N-Tier system for our clients to access data, and we're finding that our current logging system (built into the server application) is insufficient for storing all the data we need. Now, I need to find a new solution for saving and storing logs, and was looking at two different options that I could find: using a remote syslog setup, and rolling my own system. The problem with a remote syslog system is the 1024 character limit, and a roll-my-own system is undesirable due to stability issues. Ideally, I'd like to have a system that I can just fire off the log entry from the server and forget about it. Does anyone know of any other options I have available? 

We have a utility scheduled in Task Scheduler on Server 2008 R2 that just ran into an issue I haven't dealt with before. The utility hung up (no activity for a day), and selecting end did nothing to end it, so I had to manually kill the task through task manager. After I did, I tried running the task in debug mode from my machine, and it went through until a dialog box popped up. Once I cleared the dialog box, the utility completed its run and exited cleanly. The utility doesn't have any dialog boxes of its own, as it is designed to run under task scheduler, so the dialog box was a surprise to me. It came out of an API we are using, and I took care of the issue that it presented to me, but now I want to know if it is possible to have task scheduler detect and handle these dialog boxes, or if I need to add some extra code to handle the possibility of these dialogs appearing. 

During update process, I was prompted where to install GRUB boot loader - on sda, sdb, md's or all together? What choice is correct? 

This way bat,com,exe,dll,vbs are gone. But, since there's OS's that treats extensionless files like executables, it came to my mind that these should be blocked also. How to have that/what would be regexp to match these files along with known executables? 

You have guessed it all. There is problem with this approach, basically there are no means for receiving party to distinguish whether you are legitimate sender or reckless domain-faking spammer. Even when you do not use niether SPF or DKIM/DMARC recieving party may at least know that email is coming from domain's A or MX record designated host. As this is, as far as I understand your question, not your case, your email massages would be treated bad from the start. Always try to protect your MTA reputation by sending only from domains that it may be associated with by DNS settings (A, MX, SPF, DKIM). Otherwise, your reputation shall not last for long.