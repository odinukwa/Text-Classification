We currently have a 4 Node cluster used for our Availability Groups. 2 nodes in local data center and 2 nodes in remote data center. Currently the 2 nodes local are Synchronous and the 2 remote nodes are ASynchronous. They are setup in a multi-subnet network. We are wanting to make one of the remote nodes Synchronous so that we can manually failover to the remote data center to run production traffic. Our testing turned up a network issue that we did not think about. We use DNS aliases to connect to the listener. (ex. product.company.com) that resolves to the primary through the listener IP address. When we failover manually to the remote node the listener IP stays in the local subnet IP. My question is how can we configure our DNS Alias to automatically resolve to the remote listener to hit the remote as primary with either CNAME or other DNS options. Below is a crude diagram I tried to work up. 

SQL Server 2016 Enterprise Edition SP1 Database Mail was working fine with no problem until a server patching was performed. I tried to do all the troubleshooting available but still all mails got queued and no records in the log. Finally when I checked the database mail program I didn't find the executable file in the Binn folder or any other folders! My questions are how this happened and how to solve it ? 

I see that i don't need all these indexes as they overlapping. What is your recommendation for best performance ? 

note : the counts for IX_CoursePrerequisiteAssignment is not accurate because i just rebuild it These columns are the predicts for the top executed queries 

i would like your help in the best way to tune and re-write a stored procedure. it is consuming a lot of time and don't know what should i do to make it faster 

We are trying to determine our best MAXDOP and Cost Threshold settings for an EDW box. I setup a job to clear the wait stats before the build started and then capture the wait stats after the build was complete. Our server is Windows 2008 and SQL 2008 Enterprise. (Yeah I know, it is are oldest box and we are working on that). There are 8 CPU and 132GB of memory for the box and 118GB max memory for SQL. The wait stats after the run are below. Would you tweak cost threshold (Current 50) or change maxdop (Current 4). 

I am trying to track down the root cause of this issue I keep seeing. We have SSRS running with a custom URL like $URL$ When I connect to that address I can login and see reports. If I progress to a report and click manage I get the report detail and the list of properties on the side screen. Now if I click on data source it gives me a failure to load page and I notice that the URL in the address bar is $URL$ . If I put an "s" in that URL the page loads. I am trying to figure out how I can fix this. Any ideas would be helpful. SSRS 2008 R2 enterprise edition 

I have a table with big text column on which I want to enforce uniqueness, postgres can only do this with a btree index. I get the following error : 

The plans for the simplified query seems to use the index, but not for the second query. plan for simplified query : 

I'm using PostgreSQL 9.6.3 One thing that is very strange, is that the index does get used if I join the table to anotherone, and add a col from the other table in the select, ex: 

It is the exact SQL snippet show on this page : $URL$ And I'm getting the syntax errorL [42601] ERROR: syntax error at or near "WHERE" Position: 2 My exact postgres versions is 

I should probably add that the query returns 5 rows, and the table has 10 millions rows. update 2 Here's an EXPLAIN ANALYZE, with SET enable_seqscan = ON: 

If I am going to set an Alwayson Availability group with 3 nodes, with read-only routing. Do I need to configure a Quorum ? 

I need some clarification regarding Always on avilabilty group in SQL SERVE 2016 connection to the secondary DB. Now i have availability group with 2 nodes. 

Or create 1 index (a,b,c,d,e) (include columns) these are the counts of distinct values for each column. total rows 1446631 , a = 366279 , b= 96 , c = 6 , e = 2 , d= 11098 Thank you 

I don't know much about the feature, my question is as now we can send read-only workload to secondary replica . My question is what will perform better single instance with 32 cpu 1 primary and 1 secondary with 16 cpu each or 1 primary and 2 secondaries 12 cpu each Or in other way is the number of worker threads affected by the number of cpu in the primary only or the number of cpu of all members in Availability Groups 

the index gets used. If I add another column in the select clause that is not part of the index, the index is no longer used, ex: 

I have a jsonb row with objects/dictionairies : {"a":1, "b":2, "c",3} I want to query rows that contain a set of keys, ex: 

What is the additional cost incurred by inserting large volume or rows (millions), in many tables in a single transaction ? Can something be done (tuning parameters) so that the cost of inserting in large volume in a single transaction approaches the cost of doing it in autocommit ? 

However, if the join clause uses a column not part of the index, it will will resort to seq scan. Update 1 For some reason, the query optimizer does not even use the btree_gin anymore. The only way I can get it to use the (btree_gin) index is with SET enable_seqscan = OFF;. It turns out that even by using this index, it is quite slow, so the optimizer is probably correct in not using it, but the question is then why is it slow ? I've used indexes for like query and they work fine, in this case there is not even a wild card. the real query is : 

However the trigger is preventing the user from log although the IP exists in the IPAddress table. Any idea where in the problem in the trigger 

Update I find this Delete in the Query Store , there were 3 plans and I forced SQL to use different plan. I am wondering Why SQL choose to use the most expensive execution plan? 

when the application is busy and there are many deletes coming, the performance become so bad, My questions are. How to make this delete perform better? why the granted memory is so high, it steals the memory from the buffer pool ? Note: there is on delete cascade on the 2 tables Highschoolcourse and highschoolgrade. 

On a QA server I need to give access to specific login from just one IP to log to this server. I wrote This login trigger 

I have recently automated the SQL patching of ~200 development servers. Currently we have 6 servers that run the Microsoft Master Data Services feature. After a SQL patch is applied there is a manual step to go in and open Master Data Services Configuration Manager and do an upgrade of the schema. Since this kills my automation for those 6 servers I am trying to find out if there is a programmatic way to run this upgrade process after applying the SQL patch. 

My company is currently going through a data center migration. We are now down to the SQL Servers and this includes SSRS. The bad thing that is going to hit us is the current SSRS server is being migrated to a new domain. So all users/groups that have access to SSRS are in DomainA and after the migration the SSRS server will be in DomainB. All user and groups were migrated from DomainA to DomainB, supposidly using the preserve SIDs. During a test we could not get this to work. So DomainA\User1 does not work when server is changed to DomainB. We have over 70,000 combinations of user permissions and group permissions across all of our reports. Does anyone have any suggestions or ideas on how we can properly migrate this server from DomainA to DomainB without having to manually duplicate the security settings. Note: This is a virtual machine and is being replicated from one VMWare cluster to one on the new network and then will be dis-joined from DomainA and joined to DomainB. Service accounts will be changed to DomainB and backup of encryption key will be restored after service account is changed. 

This table is very active table and i need to avoid blocking. If i need to create indexes on this table should i create 4 indexes. 

we are going to upgrade from SQL server 2012 Standard edition to SQL Server 2016 Enterprise edition. we can't have a downtime more than 30 mins .The new SQL server will use always on availably group 1 primary and 2 read-only secondaries . I am looking for the fastest way to do this upgrade. I am thinking of creating mirroring between the old server and new primary server , then shut down the application update the connection string , fail over the DB to the new server, stop mirroring, start the application. After the application is up, start in configuring the Availability group. IS this a correct way to use 

If I have database db1 with schema sch1. I want to create another schema sch2 which will be used by different application and the tables in sch2 will be populated from tables in sch1. So my approach is to create triggers on insert, update, delete perform this task So my questions are 1- Is this a good way to do this or there is a better way? 2- I donâ€™t want to affect the performance on db1 so I am want to replicate it to different server and create the triggers on the subscriber DB, so replicated server will have Sch1 and Sch2 on it, Can I do that? This is on SQL Server 2012 Standard Edition Note: tables in sch2 have different names and different columns name. also more than one table in sch2 may get populated from data from sch1