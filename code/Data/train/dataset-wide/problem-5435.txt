This is not about philosophy as much as psychology. (But our systematically skewed perception of social assessments is something philosophers should keep in mind. If someone could formulate it well, there is an interesting question in why the stuff most important to us is most often perceived least objectively.) Estimated via serotonin and cortisol levels, confidence actually predicts competence pretty well in the median-earning range of the population. One theory is that this is the range for whom feedback about competence, especially from our education system, actually bears on self-image, while people of privilege and people of either very low or high ability are often more immune to feedback. And those latter are the people we think of when informally estimating social effects. A history of success predicts future success, and also predicts confidence, up to a point. One theory (from studies of gifted children) is that this is the point where more acute awareness in general may prime more acute self-awareness and lead one to over-correct, (and the curse noted by Bertrand Russel quoted in the comments begins.) For instance on the up-side, IQ predicts both confidence and future income, up to a certain level, and then it stops. Most people's IQ's lie well below that cutoff, but the most noticeable people's lie above it. Something similar happens on the down-side -- e.g. the dumb and the arrogant are both more likely to go to jail, but the bet is on the dumb over the arrogant, while the arrogant are the more attention-grabbing cases. So our perception of how much these traits are correlated is skewed. We overestimate the limitations on this effect, because we are focused on extreme cases, but the mode lies near the median, so we are misled by that impulse. Given that flaw in our perception, we should look at a couple more concrete observations that apply more directly: The feeling of being powerful has been experimentally verified to allow one to think more abstractly more often, which pays off in modern life. When mixed with raw competence, the tendency to frame things abstractly allows for future improvement, in a way that simple hard work does not. So, to some degree, especially in the young, confidence predicts potential future increases in competence. Also, risk taking is necessary to leverage competence for actual achievement. Confident people, especially males, are valued for their ability to face risk productively in situations where more competent people might be put off. In a group setting, you often need one party's confidence in order to adequately deploy another's competence -- we are all familiar with the strange stereotype of the underling who actually does all of the work that creates the reputation of 'the great man'. 

But thwarting one argument against something does very little toward showing it is actually false. There might still be some other way in which violence might be applied to every problem. To really undermine the idea that violence solves every problem, you need an important example where violence never really helps. (If it helped at all, it might still be the lynchpin of the application, the thing that tips the balance, breaks the final impasse, and therefore really solves the problem.) Getting correct information from other people is such an example. Nor is it a trivial example. Much of the functional failure in our society is about ineffective communication. And much of that failure to communicate is based in fear. For instance, leaders arrange to control the knowledge of their acts so that they will not be held accountable, and the decisions they make as a result create opportunities for corruption and political inefficiency. Producers make sure that others do not know how to truly evaluate the quality of their products so that consequences of lower quality seem accidental and are not traced back to them. This prevents honest competition and makes markets inefficient, as well. So failure to communicate truthfully is a major problem for any political system. This fear works in a way that is not amenable to solution by creating additional fear. Since most violence short of murder does raise the level of fear, you are caught in a place where violence cannot help you. (And, obviously, killing someone permanently prevents getting any further information out of them.) To see how adding fear does not help, look at torture. We know from studies of torture that additional fear or pain motivates one to give information, but it primarily motivates lying. If someone will give you truthful information under duress, they would generally have given it to you without the use of violence. This is disputed at great length, and lied about in Congress and in fiction, but the data are clear. No matter how you abuse or threaten someone, with direct pain, psychological force, threats to loved ones, etc., the primary effect is to garner false information, mostly false confessions or false implications of the guilt of innocent people. Other uses of violence to get reliable information suffer the same intrinsic failure -- it is far too easy to lie; lying preserves the speaker's worth just as much as, and often more than, telling the truth; and lying makes one feel like one has some control, some ability to thwart the person harming you and get a minimal revenge. So, knowing that adding fear primarily creates lies, instead of more truthful communication, in what way can violence solve the huge number of problems traceable to this single cause? Since we cannot get better information from others by violence, if violence is to solve our information-related problems, it would have to be by preventing there being information we must acquire from others. We can only have privileged access to all information through some form of totalitarian surveillance. But again, the data are clear. We have studied police states and surveillance in cults. To the degree that actual violence is a part of surveillance, it creates fear of the consequences of misunderstandings. Even if you are innocent, you can look guilty and get punished. People act on this fear, causing subterfuge, sabotage and rampant basic dishonesty to undercut the effectiveness of the surveillance. The logical reaction is to increase the consequences of lying, but enforcing those consequences would require knowing who is lying, which involves getting information that is already being withheld effectively. So there is no actual point of application that will make it a better risk for everyone to tell the truth. So, the problem remains unsolved, and it is hard to imagine better applications of violence that have not been ruled out by what we already know about how people naturally react to being controlled with violence. (We know a lot. We have been doing it for a long time.) You can escape this by defining down violence to more subtle forms. For example cults can achieve very complete control of truth, and surveillance through authority, guilt, and fanaticism, as long as the enforcement is not seen as violence. Once it is, members naturally collude in resisting it. But that is just cheating. Social coercion and more subtle means of control simply are not violence. So even in the most bloody-minded, psychopathic picture of the world, violence fails us in addressing one important range of problems. (Obviously, I don't personally accept this psychopathic, war-of-all-upon-all worldview. But it is part of the general argument for violence, so it is a better frame for an argument toward contradiction.) 

I will take this up from a Kantian point of view Bob simply cannot morally know the necessary outcome of John's actions, but more relevantly, John is a moral agent, still completely capable of not pursuing any prediction that can be made by Bob. If you cannot be defied, you have stripped other agents of their autonomy, in a way that no human wants to be limited. Even if my future is knowable, for it to be known, is immoral. To have free access to prediction universally, the prospect of the delight of surprise would be removed entirely from the universe, and we would not will that: it is not compatible with how humans need the world to be. So whatever thaumaturgy might determine John's fate is not moral, and even if we have done it somehow by accident, we should not act on it. (Kant wants morality independent of species, and this sometimes clarifies arguments. For Kantians who share the religious context of his upbringing, this is the argument against angels, who live outside time and carry the agenda of limiting sin, simply fixing history so the world is perfect. To do so, whatever sin it might prevent, would crush human will.) So, if Bob knows John's future and acts on what he knows, he is already in the wrong. But that puts Bob in the position of acting inauthentically while trying not to lie. He needs some boundary around what would be expected of him. Even in the case with no magic, relying on your guesses about someone else's behavior based on observation too much is prejudice, and becomes immoral quickly. John must be treated as a moral agent with autonomy. If we do not allow in every way for the possibility of basic moral change, John can no longer participate in a 'Kingdom of ends', his autonomy is reduced to logic and he becomes a mechanical part of the universe, a mere means. John then needs to be treated in a way that intends to work out for the best even if he deviated from any prediction we can make, at any point. The only point where Bob can safely control the possibility that John will change the script, and obviate the predicted good outcomes, is in deciding to give or not to give John the money to start with, and that is the only act with predicted consequences that can be judged for moral content. Giving is a good thing. But it is sometimes not a good idea to just give people money at random. If I gift the policeman who pulls me over with $100, this is not to his ultimate benefit, especially if his camera is on. It proposes moral hazard. So automatic generosity in complete generality is not universalizable. Any rule about giving needs to incorporate the proviso that it should not cause undue foreseen risks for the recipient that outweigh the gain of the gift. But with this addendum, the idea that giving away resources that you do not need does seem universalizable. So this condition is a natural part of the proper maxim. Kant's "Kingdom of Ends" is a community of ends, and mutual protection at a respectful and sustainable level is part of the package. John is at risk here, and Bob, knowing of that risk, should provide a level of protection from it that we can generally expect from others, but he should not force John's hand. If John is someone to whom Bob would ordinarily give help, that help should take a less risky form than cash. This is a risk of which John himself would be aware, so accounting for it, and purposely treating him differently, is not a prediction of the future, or a stereotyping of John into a box we assume he cannot get out of. It is acting on a motive that John should have and would approve of, were his functioning not impaired. 

I would suggest that our salvation from this dilemma may come from exactly the sciences it deprives of a decent footing. Classical psychology contains places where it is still possible to study humanities from a skeptical and systematizing perspective with testable implications. The leading light in this kind of endeavor was Jung, who clearly saw his work on such literary content as archetypes and alchemical history as science that would eventually reach a clarity where they could be tested medically on his patients. And there are still Jungians. I would like to inject the idea that we have competing definitions of science, one basically the translation of "Wissenschaft" from German, and the other a more English phenomenon centered on the example of Newton. I would like to call them "Kuhnian science" and "Popperian science", at the risk of overstating those authors allegiance to each form. We want to imagine they are the same thing, but they aren't. Jung was clearly doing the former, and had no real vision of the latter. The question is not whether Popperian science works, but whether that means other means work less well in general including fields like psychology, which comments seem to just decide is a bad Popperian science, instead of something that needs different rules. There are excellent reasons that some sciences, like psychology and anthropology, will have a very hard row to hoe, if they choose to be exclusively Popperian sciences, verifying results against null hypotheses with clear numerical definitions of falsification. Even with the deep elaboration of statistics they have made, the notion of experimentation and falsification are too strong to apply most of the time. Psychologists themselves refer to this notion as 'physics envy'. But they are well on their way to being sciences in the Kuhnian sense -- their squabbling about basic principles is becoming an underlying understanding with various different emphases. If we decide that science itself is this one thing, where all paradigmatically-based disciplines have value only to the degree they pay homage to a specific kind of reality testing, we are avoiding progress in those disciplines, and discarding useful information. As Feyerabend keeps mentioning throughout 'Against Method', the educational programme that basically shut down the teaching of classical Chinese medicine in the name of systematizing it scientifically was not productive, and was eventually reversed. Widening our notion of science back to its older sense cuts across the disparagement that scientists automatically have that any discipline that cannot proceed with a specific methodology must simply be doing it wrong, or things would work. They would become accustomed to the idea that the places where their ideas really come from are the cultural accumulation of the arts, and there might be detente. EDIT: Source of perspective. I totally buy the idea that our own internal processes work by generate-and-test cycles, from Chomsky to fMRI research, this seems predictive. (Dennett has laid this data out very well a couple times in "Kinds of Minds" and in "Consciousness, Explained".) So, as I see it, science of this form is natural to us. And it is a validated approach -- evolution approves -- it is hugely successful. Its larger-scale, more conscious, application works even better for our whole society. But saying, "This is what science really is" and following up with "Science works" (with open quantification) implies this version of science will work in general, everywhere, for all problems, or at least a significant majority. But we have a forebrain that seems to work really hard to deny that projective testing is what is going on 'under the hood'. Therefore most of us hold a model of mind other than the one most consistent with physiology. So much so the one that fits observations was hard to get to because it is hard to hold. To me, this indicates that this way is good for much of our data, but something more deeply constructed is needed for more abstract stuff like understanding other people. 

From a direction at the far edge of psychology away from neurology (object-relational theory interpreting group therapeutic experience in the tradition of Tavistock process) we can think about consciousness as a less personal experience. From that point of view consciousness itself is a shared pool of 'cathexis' (just a term for the mysterious pseudo-energy behind attention that makes things seem more or less important) rather than an individual thread of experience, but our personal memory coalesces our individual sense of our own single consciousness, and that memory resides primarily in a single mind. So it is impossible to identify 'a consciousness' as being the same or different from another, only a set of memories, and your question loses meaning. The set of memories empowered by a given pool of consciousness can be the same as it was yesterday, or it can be different. By virtue of being memory, it has some stability, but it also changes every time it is accessed, (whether you attribute that to "complex formation" or Hebbian learning.) So over time it is less and less the same memory. And if something unusual happens that takes the complex of memories apart, it may suddenly constitute multiple separate streams of memory. (E.g. one remembers some things about oneself while sleepwalking, and not others.) That is my answer, but it needs a lot of framing to make sense to may people. Pardon my long-windedness here. I, personally, just find this fascinating. Humans communicate, not only explicitly in language, but more generally by doing things that have the intention of being observed. That intention is often unconscious, but it creates patterns that create group identity and assign roles to individuals in interactive situations. In an emergency, for example, say if someone spontaneously collapses in a public place, someone will shortly attend to the body, someone else will move to alert authorities, someone will spontaneously start coordinating the event as 'news', guessing 'What happened?' and hopefully controlling the level of fear, while distracting onlookers from interfering, more and more nuanced informal roles arise in more and more complex situations. These assignments of people to roles are made neither explicitly nor arbitrarily, they are negotiated by unconscious interactions within the crowd. This is group decision making, and so it constitutes communication. To oversimplify rather drastically, if consciousness is a prerequisite for communication, all of the consciousness that is unconscious to all of those present, yet coordinating all of this communication, must reside somewhere. If you head far enough down this path and just observe, it seems that the vast majority of the consciousness is not assigned to individuals, but goes back and forth between them in an ongoing group process. At the same time, internal consciousness seems to be driven by the same sort of thing. Different parts of one's experience are 'cathected', pointed at a specific object, and the energy of that thought snowballs or melts away. Different trails of communication result, making up strands of internal conversation like the individual conversations at a party. What integrates a specific one of those strands seems to be the collection of internal referents that the coordinated processes have rendered conscious. Basically, a thread of conscious thought is a semi-organized pile of memories that it has marked as temporarily important, and little more. So thinking of the individual as a coordinated group process, the consciousness that contains all of these threads is likewise held together by its shared pile of memories, and nothing more. Taking that to its logical conclusion, conscious itself is a shared, ongoing process which resides in no particular thread of considerations. When you are with others, you both maintain your individual consciousness and all share a single consciousness, and when you are alone, you segment yourself into multiple parts that do exactly the same thing. What constitutes a given 'consciousness' here is the pile of memories it curates. There is shared memory, in that cultural traditions and other experiences may be reconstituted from multiple people in a sort of ceremonial sharing of the experience, but primarily, we have privileged access only to our own individual memories, which are very much stored in our separate brains.