You can safely remove this line. If you want to do functional testing, I would move such tests into a separate folder to not pollute the main code. Also this test case is not even remotely sufficient ;) 

There is a steep gap after buildins.sum, i.e. you spend most time there. We can use instead (pushing it down to 3.457 seconds): 

This avoids duplicates for corners and edges and I could cache the results for even faster computation (though this is not very expensive to compute). Here is the full example as a gist: $URL$ 

next we can get rid of and instead sample a array of uniformly distributed random numbers and threshold them. This also allows us to vectorize the for loop and stay in numpy even longer (0.786 seconds): 

Again a debug statement. There is not much use of informing the user that a query has been executed. He cares for the side effect of this, i.e. if there have been the correct rows returned 

A) This is not very useful output. I would rather return how many lines have been inserted into the database or nothing at all. The fact that something happened somewhere while this code executed is implied by the user calling the script. B) If the script fails, you should inform the user; however, it is probably better to not catch any exception and then continue. The block will be executed regardless of what happens in . You can omit the entire block. A setup is thought of as a "cleanup block" which will make sure that the finally is executed before any exception is escalated. 

If you can't do that, when you start the new thread, try setting the thread priority to low or tweaking other related settings. 

The BackgroundWorker.RunWorkerAsync() and RunWorkerCompletedEventArgs only accept/return a single object and you need to pass two (the block index and the block itself). You will need to either use a tuple/struct/class or something else to hold both objects when passing back and forth. Finally, You may need special handling for the last block of the file. Some encryption algorithms (zero) pad a short block to the expected length (1K in this case). This means that your encrypted file may be slightly longer than your unencrypted file. If this is the case for your chosen algorithm, your allocated output file size may be slightly longer than the original input. Depending on the file contents, this may or may not be an problem, however you should be aware of it as a potential issue. 

Just because you mentioned recursion it in your post, here is an example, and also an example of implementing this as an infinite sequence. Pure Recursive Note that pure recursive functions in ruby have to be used carefully as ruby has a limited stack. Recursing more than a few thousand times tends to cause a stack overflow. Also note that this implementation does not include support for memoization, so it does a lot of redundant work. It is, however, a pure function. 

If Yes, read the next block from the file, pass it and the block index to the worker and start it. Remove the worker from the list If No, then sleep. 

Classic DFS doesn't use any pruning. That means you should not have a list of nodes; Hence, my question in the comments. This means that for cyclic graphs DFS does not terminate by default which is why people commonly do pruning on visited nodes; however, revisiting nodes may be wanted, e.g. "list all paths from edge 1 to edge 5". Making the choice of using not only makes your graph acyclic, but rather "tree-ifys" (technical term ;-) ) it. 

Large Array There is multiple optimizations you could do, but only 1 that really makes sense here: Bin it. You don't need it. You pre-compute a lot of information that you reuse exactly once and that you can compute on-the-fly. There is no benefit in having this. In fact, you are making it worse by reading the once and then reading the array version of it, which is 40+ times bigger. Not cool :D The short version of it is that is wrapping python s which store 5-tupels worth 40 byte per entry. takes to represent in this format, whereas you can instead stick to a single character worth 1 byte and look-up the value as well as compute using the predecesor (which you know). This will save 40(!) times the disk/memory space (down to after optimization). Here is a version that uses , but saves only a character (worth 1 byte) instead of the tupel (40 byte): $URL$ I've also added as dependency and refactored your code (a lot) because I couldn't make heads and tails of it. Here is an even shorter version that no longer needs : $URL$ I also removed the timing comments, because that can be done more efficiently with or another profiler of your choice. In this scenario, I felt like the prints obstructed the code a lot; now it's easier to read. If a blinking cursor with no output irritates you, feel free to add more prints (at the cost of readability and a tiny bit of runtime). 

Copying the array You are over-complicating the array copy. will copy the objects of the array (but not the object's objects). Using it on array of objects might be problematical, but an array of ints will be fine. 

Set Unions Looking at your code, when you loop through the attrs, you are breaking after you find the first key that is in and in and in the passed . This is also known as the of the arrays. As such you can simplify the inner loop with: 

Put the workers in a list of available threads. In the main thread, check if there is a free worker in the list. 

Background threads tend to run at 100% CPU utilization unless you do something to prevent it. If your requirements allow for it, try adding a Thread.Sleep(10) (or some other number) to the code. 

I'm sure there a few variations of this idea that would work well too. This example is just the first that occurred to me. 

After the worker has completed, it will call the event, where it will return its result (which should be the encrypted block and the block index. The event handler should write the encrypted block to the corresponding index in the output file, and then add the worker back to the list. Repeat until all the blocks have been processed. 

Similar to dankohn's comment, there are really only a handful of operations going on, just with different character sets. Here is my quick implementation. It only handles the base 10 digits, and dynamically swaps out character sets depending on the power of the number. 

Output I've ran the and it tried to create a image. That's (Gigapixel)! as an uncompressed image is no fun. At least on my machine it doesn't fit into memory uncompressed. Similarly, if I look at your it doesn't seem to open correctly; I only get a reddish shadow. On your machine (assuming you have a bigger one, since you can apparently fit 30+GB into memory without issues) you might get more out of this. Fortunately most of these pixels are empty / transparent. In fact for only 2.2% of the pixels are not transparent. Potentially even less, because I've noticed that they sometimes overlap, e.g. a "GC" sequence would only be visible as "C" sticking out to the side. My attempt would be to use matplotlib, however that is still fairly slow and known to not cope too well with big data. It runs slightly faster then your initial version and the memory requirements are better; still its not enough for on my machine. Yet, you get an interactive figure that you can zoom around in and "take screenshots". I like this way to explore the sequence better. Another advantage is that you can specify file format and viewport, legends, axis and so forth. Here is the code for that: 

There is a lot more you could do to the rest of the code, but that is out of scope for this question. 

Assuming is an okay thing to do you don't want to check after ing an element but rather before you insert it. It saves you the overhead of appending and popping visited nodes which can be quite substantial. Further, should be a (as stated in @Alex 's comment). It could also be a good idea to use an actual queue object, be that (for FIFO / LIFO) or a . The latter will slightly reduce performance (insert from O(1) to O(log(queue_size))), but offers a lot of added flexibility and easy scalability to graph search. Setting the priority to: is DFS, is BFS, (or ) is Dijkstra's search, is greedy search, is A*. I think that's a really cool property. 

Create new StringIO objects Set and to my stringIO buffers Execute the code snippet in a object Join the thread Log the results in the stringIO buffers Restore stdout and stderr 

By making your code generic (rather than one function per skill/ability) and making all skills and items just data it will make your project easier to debug and items and skills easier to modify or add to. 

I don't know if it is prefered or not, but if you wanted to get rid of the , you could do something like or instead. Naming seems ok. No comment. I don't know. Your regex for is suboptimal. will pick up any character, but you really only want digits. Something like would be more accurate. 

I think you can add functionality to to make the common ancestor search more ruby like. (I can add a search by value later, if you want.) I've added a parent member that is set automatically, and I've added and enumerators to enable easy traversal up or down the tree. Note: Thinking about it, the search function needs a little more work in case node 2 is higher in the tree than node 1, but I am out of time right now. Let me know what you think. Testing indicates that this is not an issue. 

If you wanted to look more ruby-ish, you could convert your switch statement into a hash and then / your input string. 

Foreach function, these tables show the number of calls and time spent on function call, recursively all the way down. Some portions, like the "range#each" can be ignored as part of of our testing overhead. Looking at the results, I can spot why dominant_2 is the fastest. Integer operations (FixNum) on a processor will always be faster. Floating point (Float) is slow and floating point divisiondividing is slow, and big integers (integer numbers bigger than that hardware can natively support, typically 2^32 or 2^64) will also be slower.