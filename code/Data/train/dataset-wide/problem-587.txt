Not yet. In 2008 I wrote an overview/roadmap of what we knew back then about whole brain emulation, the scanning and computational reconstruction of brains. The main scheme I assumed was a slice-and-dice scanning method where the tissue is mapped on the sub-cellular level. In Apprendix E I gave the reasons for why I did not explore non-destructive scanning methods in detail. However, I had a long debate with Robert Freitas Jr. about using nanofibers, manufactured using mature nanotechnology, to connect every neuron more or less to external read-out devices. The details of the sensing can be read in section 4.8.6 and subsequent pages, and the fiber network is described in section 7.3.1 of his book Nanomedicine Vol I. I think there is nothing physically impossible about this scheme. However, I think the medical engineering challenges are worse than he thought: beside needing fairly advanced nanomachinery it also needs to interact with a dynamic, soft environment that is pretty sensitive and responds. Robert argued back; basically, see Nanomedicine Vol IIA for his assessment, especially section 15.3.6.5. My view is that we will use destructive methods long before we can do the actual read-out using electrodes. That requires a lot of technology development, both of nanotechnology but also handling a messy biological environment. But I do not think it is impossible, just hard and slow. As a further twist, the synthetic biology people are getting involved in the game by thinking about "molecular tickertape", where signals are recorded on DNA inside cells, and "DNA bar codes" where the cell connectivity is recorded. Of course, the current vision they have for reading this involves putting the brain in a blender and then sequencing the DNA pieces... 

but handwaved the power source.  (For the record, I thought of this before I read the answers.)  If there’s power to spare, there are many options.  But the question said that all the solar power is accounted for, and that fuel (for the generators) is scarce, and I assume that the building complex isn’t within walking distance of a forest, a coal mine, or an oil well.  If the spring provides enough power to drive the bucketwheel (or bucket conveyor belt) and lift water 18 stories, that’s great, but that strikes me as unlikely. One idea that hasn’t been mentioned is to have a dual-track bucket conveyor belt.  One track would bring water up; the other would take waste material down, and thus provide the power to drive the belt and lift the water.  I am thinking specifically of toilet-type waste.  There might be others, but I imagine that these survivors would recycle as much as possible. The rate of disposal of waste varies with the time of day.  This is why it’s important to collect the spring water all the time, so the water that emerges from the spring overnight, and at other periods of low waste-disposal activity, doesn’t just go into the ground. Of course, if they’re using washing water, urine and feces in their gardens, this won’t work. 

(By coincidence I was finishing a section of my book dealing with mining black hole energy today) Harvesting energy from stars is easy. But it turns out that the tech (Dyson spheres) you need for it allows harvesting energy from black hole accretion in a stationary way, and this can be very efficient. No, the Penrose process is not the best real or theoretical method of energy harvesting. More detail, and a suggestion for a theoretical but science-based cool way of tapping black holes: The Penrose process extracts angular momentum from a rotating black hole. It is not an easy trick to pull off, but one can do it in various ways (particles, superradiance, matter-antimatter reactions producing pairs of gamma ray beams where one is sacrificed and the other picked up outside...). However, eventually the angular momentum will run out. It is not a renewable source, even though it is big. The most efficient way we know can extract energy from matter and a black hole is accretion disks and jets, since we have observed them. Matter falling into an accretion disk is losing its potential energy as it spirals in, radiating it away. We have good reason to think that the mass-energy conversion efficiency is up to 5.72% for stationary black holes and up to 42.3% (!) for rotating black holes (neutron stars give about 23%). By comparison, fusion is just 0.075%, and stars worse. That energy can be collected using a Dyson sphere (a fairly standard one, if high temperature, for a stellar mass black hole; a very big 1000 AU one for galactic black holes - as you get close to the Eddington luminosity I recommend carbon-tungsten statites or the alloys related to Ta$_4$HfC$_5$). But there is more! The accretion process produces jets that can be about as luminous as the the disk itself thanks to complex electromagnetic effects in the swirling plasma. This is basically a Penrose process but electromagnetic (the Blandford–Znajek process), and possible to replenish by adding matter with angular momentum to the disk. That energy can also be collected using suitable megascale engineering (think giant coils). Catching gravitational radiation looks very hard (weak coupling to matter), even though up to 1/8 of the masses of merging black holes are emitted in one burst. Here is the thing that might make the story/worldbuilding fun: Hawking radiation is a mere trickle, and mostly of interest for far, far future civilisations when the universe becomes cold enough. However, it can be boosted! In this paper, Frolov and Fursaev show that if you dangle cosmic strings nearly onto the event horizon of a black hole each string will emit about the same amount of Hawking radiation as the entire hole. For the right kind of thin strings this can boost the hole output by $10^{31}$ - enough to make a solar mass black hole produce 900 Watt, and smaller ones far more. Of course, solar-mass black holes are about the lightest that can form today, so you need to seek out the rarer primordial black holes that formed during the Big Bang. So my suggestion is that a recent discovery of a way of making cosmic strings (cool objects on their own) enables tapping primordial black holes, triggering a rush. 

I haven’t done the math on this (but (a) you specified science-based and not hard-science, and (b) you’re allowing magic):  The chasm lies under a deposit of some substance that’s many times denser than rock (neutonium?).  It exerts an upwards gravitational pull on the space immediately below it; with enough mass, it should be able to create a region where the gravitational field is zero (or infinitesimal).  Unfortunately(?), that also produces a higher than normal gravitational field on the surface above the deposit (i.e., above the abyss), but (handwave handwave …).          It’s hard to image such a structure occurring naturally, or being stable if it does exist.  It would probably collapse under its own weight.  So enter deus ex machina… it’s a constructed artefact (perhaps by a lost civilization, or by aliens).  (The builders might still live a mile lower.)  To support this notion (pun intended), I’ve added a second layer of the substance below the chasm, with pillars holding up the upper layer. This doesn’t address the viscosity of the air.  But, if you stipulate that the chasm is accessed by tunnels from the ocean floor, you can argue that the atmospheric pressure is much higher than that at the surface, and that’s a start. 

There are some sources of uncertainty that mess up this technology. The prime one is the Heisenberg uncertainty relations in quantum mechanics: the product of the uncertainties about the position and momentum of a particle will always be larger than a certain (small) value. This is not just a lack of instrumentation or even that the measurement will jostle the particle, but seems to be a deep part of how quantum mechanics works. Hence your measurement of the state of the world will by necessity have some small uncertainties. These would not be a huge problem except for chaos (and perhaps quantum randomness). When backtracking the particles the uncertainty in location will grow linearly with time due to the momentum uncertainty as long as they do not interact with each other. But of course they do, and that produces a much faster growth of uncertainty. On one hand nonlinear interactions amplify uncertainties exponentially, and on the other hand individual particle reactions look random on the quantum scale. So go back far enough and you will have little clue where all those particles were. (This is really annoying since quantum mechanics and all the other laws of physics appear to be time-reversible in the small: in a sense the information is there, it is just spread out to such a degree that you cannot reconstruct it) To add to the annoyance, your measurements need to be stored somewhere. Each particle needs 6 values to denote their position and velocity (plus a few more for other particle states). There are about $10^{27}$ molecules in a body, each with about 30 particles (most are water). So if you want to simulate just a body you need $1.8\times 10^{29}$ numbers (each with a certain number of bits). Note that this is an annoyance, not a showstopper. I recently estimated that using all silicon and carbon in the solar system you could get up to $10^{46}$ bits - more than enough for that data. Now, there is another approach to the problem. Instead of trying to scoop up all atoms and accurately predict where they truly were, make a lot of plausible scenarios instead. Not every past is likely: a cloud of air molecules could have been a toy that spontaneously dissolved into nearly nothing, but it is not as likely as past air. A being who wrote an email in English probably had a brain that understood English, and so on. This will not guarantee finding the one true past state. In fact, it might find a near endless number of plausible pasts that could have happened. No problem, just resurrect copies of all of them. 

Now suppose that $\mathrm{O_5}$ is stable at standard atmospheric pressure and temperature.  And suppose that, like ice-nine, it acts as a catalyst, converting $\mathrm{O_2}$ (and maybe also $\mathrm{O_3}$) into $\mathrm{O_5}$, and that this conversion is very hard to undo (think particle accelerator).  It would be quite reasonable to expect $\mathrm{O_5}$ not to react chemically the way $\mathrm{O_2}$ does (remember the differences between the characteristics of diamonds and graphite).  Once this stuff got into the lungs of an oxygen breather, it would convert all the ordinary oxygen (including, eventually, the stuff in hemoglobin) into $\mathrm{O_5}$, which would not give the cells what they need.  You’d suffocate. Or maybe it’s just very, very bad for you — like ozone. I don’t know how $\mathrm{O_5}$ would be created with pre-WWI technology, but the existence of tetraoxygen $(\mathrm{O_4})$ was first predicted in 1924 as a result of experiments with liquid oxygen — so that technology existed then.  You would need very little handwavium to explain how somebody cooled oxygen, past the point where it condenses into a liquid, near to its freezing temperature, and this caused $\mathrm{O_5}$ crystals to form.  When allowed to thaw, they did not decompose, but rather started a Cat’s Cradle-like chain reaction that converted all the oxygen on the planet into toxic $\mathrm{O_5}$. 

I was just answering an old question about hydrogen peroxide life, that might give a hint: use an eutectic mixture of water and hydrogen peroxide. The mixture has a freezing point of -56.5 C, which is more than enough. The main reference I used may have more useful material for this particular plant application - the hygroscopicity of the mixture might be a mixed blessing. 

Most obviously, you have a fairly expendable body. Perfect for dangerous tasks like firefighting, exploration... or assassination. Or being an army. A temporary army, but potentially very well coordinated. Also, since the body is somebody else's originally, it is perfect for espionage and cons. 

There has been serious recent proposals that a hydrogen peroxide - water solvent chemistry could work. This was originally proposed for Mars, since mixtures can have a low freezing point of -56.5 C, are hygroscopic (so water is not lost too easily), and maybe fit the Viking lander results. The organisms would be pretty UV sensitive, though (they better be endolithic). While hydrogen peroxide isn't that good for terrestrial life it is actually part of normal biochemistry, and extremophiles adapted to using more of it doesn't sound that impossible. So I would suggest that a cold planet with little water might be a good place for peroxide life. If the sun is also less UV-bright or there is a good ozone layer it makes more sense. 

Polymorphs are similar to allotropes, but the term allotrope applies only to elements, while polymorph applies only to compounds.  Polymorphs are most often found in minerals and organic compounds (e.g., pharmaceuticals).  There are polymorphs of ice (solid $\mathrm{H_2O}$), but the ordinary ice that forms on puddles in winter (and that we make in our freezers and put into our drinks) is the only one that can exist at standard pressure.  However, Kurt Vonnegut’s novel Cat’s Cradle stipulates that there are others that can exist at standard pressure.  In particular, one called “ice-nine” has a melting point of $\mathrm{45.8\:°C}$ $(\mathrm{114.4\:°F})$, so it is stable at room temperature — and, indeed, on most of the Earth.  It has the additional property that if any liquid (or gaseous) $\mathrm{H_2O}$ comes into contact with ice-nine, it immediately freezes and also becomes ice-nine.  For most of the book, the ice-nine is kept carefully controlled and locked away.  But eventually it escapes into the environment and causes all the oceans to freeze, and it’s pretty much curtains for mankind. Oxygen has allotropes, too.  The best known ones are ordinary, atmospheric oxygen $(\mathrm{O_2})$ and ozone $(\mathrm{O_3})$, but there are others, including tetraoxygen $(\mathrm{O_4})$, which is unstable (or metastable).  Wikipedia notes: 

The highest mountain is limited by the strength of rock; a mountain of height $h$ will exert pressure $\rho g h$ on the rock at the base. So assuming earthlike density and rock strength the possible height scales inversely with gravity: a 2G world would have maximal mountains half as tall as Earth, a 1/2 G world can maintain twice as tall mountains. Calculating the theoretical maximum from first principles is somewhat iffy; Tipler & Barrow's "The Anthropic Cosmological Principle" and Weisskopf gets about 26 km. Doing it using compressive strength of granite gives 10 km. Now, the height of the atmosphere is set by the scale height, $h=RT/mg$. This is about 8 km for Earth. It also scales as $1/g$. So the 1/G G low gravity world will have an atmosphere declining in pressure half as fast as Earth. This means that the top of the tallest mountain, unless the rock composition is vastly different, will tend to be about one scale height above the ground. It will be high up in the atmosphere but not above it.