That is, what you describe is not an experiment at all. Some sources of information used to evaluate models of speech production are: 

These data are usually used to support or weaken the argument in favour of a particular model. In the case of the models discussed, they are designed to address predictions stemming from assumptions about the stages of speech production, and the order (if any) in which these stages are processed. For instance, WEAVER++ assumes that syntactic and semantic information is accessed prior to phonological information. Thus the TOT effect occurs when phonological information is difficult to access. Harely and Bown (1998), showed that words with an unusual phonological form are more susceptible to TOT, evidence that supports WEAVER++. As an aside, the 'priming' studies that Nathan refers to are in fact uses of the masked prime paradigm with a lexical decision task. These are used to investigate the processes involved in visual word recognition (i.e. reading), and are a great way to investigate the information we can access very quickly from written language. For instance, that we compute phonological information from brief (50ms) presentations of non-words (Kinoshita & Norris, 2012). What such information tells us about the mental lexicon is unclear. This isn't meant to be an exhaustive account of speech production. I've undoubtably presented some contentious information, and excluded some important information. Regardless, hopefully I've given you enough resources to make a start on your own research. Most of the articles I've mentioned are accessible through google, at the very least, Dell (1986) and Levelt et al (1999) definitely are. *Don't be put off by the length of Levelt et al (1999). Behavioural and Brain Sciences articles often include commentary by researchers in the same field, so the article itself is only about 35 pages long. The commentary is a great way to a get a feel for how a theory fits in with the rest of the field. Personally, I think it's a great idea. Dell, G. S. (1986). A spreading-activation theory of retrieval in sentence production. Psychological Review, 93(3), 283-321. doi:10.1037/0033-295X.93.3.283 Harley, T. A. & Bown, H. E. (1998). What causes a tip-of-the-tongue state? evidence for lexical neighbourhood effects in speech production. British Journal of Psychology, 89, 151. Kinoshita, S., & Norris, D. (2012). Pseudohomophone priming in lexical decision is not fragile in sparse lexical neighborhood. Journal of Experimental Psychology: Learning, Memory and Cognition, 38, 764-775. Levelt, W. J. M., Roelofs, A., & Meyer, A. S. (1999). A theory of lexical access in speech production. Behavioral and Brain Sciences, 22(1), 1-38. doi:10.1017/S0140525X99001776 Meyer, A. S., & Damian, M. F. (2007). Activation of distractor names in the picture-picture interference paradigm. Memory & Cognition, 35(3), 494-503. doi:10.3758/BF03193289 

Notice that the two 's are bound by two different λ-operators. Thus, this is fact equivalent (switching now to my notation above) to: 

with just parentheses and no periods. For historical reasons that I don't fully understand, using a period to introduce the scope of a λ-binder, e.g. λx.φ, is particularly common (though not universal). 

Importantly, (1b) and (2b) β-reduce to the usual (1c) and (2c), respectively. In both cases, we essentially just abstract over the elided thing: "the turkey" in (1), hence with of type (individual), and "bought" in (2), hence with of type (predicate/set of individuals). 

Once again, must be the functional version of set intersection, but in the λ-calculus, this would actually have a different type than the previous . The first would be of type (intersection of two sets of individuals), while the second would be of type (intersection of two predicates/two sets of sets of individuals). Now, this maybe isn't a very big deal, since you could maybe just define a suitable polymorphic operator, or a family of such operators. But the nice thing about my version is that both cases rely on just one abstraction followed by normal boolean conjunction (∧). 

I'm currently reading Jackendoff's Foundations of language and I've realised that my knowledge of syntax, morphology and phonology isn't as strong as I'd like it to be. I'm coming from a psych background, and I'm quite comfortable reading psycholinguistics texts. However, (and this is a point that Jackendoff makes) I've realised that the psycholinguistics I've come into contact with thus far seems to downplay the complexity of language. As someone who would like to pursue a career in the cognitive sciences and who has an interest in language, I'd like to address this gap in my knowledge. So my question for you is this: What are some good resources for those of us who are curious about language, and can comfortably tackle some of the more basic literature, but who don't have the same level of knowledge that a linguistics graduate would have? Thanks in advance. 

I doubt this etymology just because I can't find any reference of this kind of saying that PIE *dʰegʰ- "day" and *dʰegʷʰ- "burn" are cognates. PS: the reconstructions are based on here, in footnote 8 on page 2 of which the author even deny this connection and E. day comes from PIE *dʰegʰ- "to repeat itself (over and over again); cycle". 

But I can't find the clue to this sound change on Wikipedia, which concludes that PIE*bʰ, *dʰ, *gʷʰ will become L. f-, when they are "At the beginning of a word". 

But I can't find the clue to this sound change on Wikipedia, which concludes that only PIE *b will become PGmc. p-. PS: AHD contains the same etymon dlegh 

A caveat: I'm experiencing the tail end of a three day migraine. This answer may not be as clear as I'd like. The nature of the cognitive structures that make up linguistic knowledge is still a very open question. In fact, the nature of cognitive structures in general is still hotly contested (and rightly so). Before I answer your questions, I think a little clarification is in order. Models of mental processes (at least from my perspective) are not likely to be accurate representations of the actual, real world functioning of the brain. Like any scientific theory, they're only as good as the predictions they make. So just because a model has support does not mean that it captures the nature of cognitive structures. Rather, it means that it accurately predicts behaviour. What I'm getting at is that different processes can produce the same behaviour, and just because a model makes accurate predictions, does not mean that it necessarily is an accurate model of the cognitive processes involved. With regards to your first question. It's important to consider what type of language phenomena you're interested in. Different models attempt to capture the functioning of different processes, and each model has its own set of assumptions about the associated mental functions. Judging by the task you set yourself (which, by the way, is referred to as a verbal fluency test), you're interested in speech production, so we'll look at that. There's two influential theories of speech production, Dell's (1986) spreading activation model and Levelt et al's (1999) WEAVER++ model*. This article, by Levelt, is a great primer on the different types of speech production models. Both models assume that lexical knowledge is instantiated in a network, but make different assumptions about how processing proceeds through the network, and the different steps involved. I won't spend any time describing them since the Levelt article does a much better job of that. Returning to my first point, this isn't to say that these models are accurate descriptions of the mental lexicon. Rather, they're influential models that do a good job of predicting linguistic behaviour. On to your second question... At a the level of experimental design, psycholinguistics experiments differ from what you describe in that they usually: 

So we have two different λ-terms being connected by . Importantly, here cannot be a boolean connective (∧ above), because the two λ-terms are of type , not . Thus, is more like (a functional version of) set intersection (∩): 

After β-conversion, this will of course be equivalent to my (1c) above, so in that sense it's just as valid a meaning representation. However, the difference is that in my version, we have just one instance of λ-abstraction; in this version, there are two. Which one is more "correct" will depend on the particular mapping from syntax to semantics, i.e. how abstraction arises syntactically and whether we want one such instance or two. Another consideration is that, for (2), the analog of GregLee's answer would be: 

The following sentence makes me wonder and have this question: tame is a reflex of PIE *dem-h₂- (“to domesticate, tame”), which has the same formation of PIE *demh₂- (“to build”). Maybe the semantic explanation is "tamed in a house"? tame 

It just seems so peculiar, and I wonder whether it is a rule of sound change or an exception. PS: the PGmc root comes from PIE *pleuk-, enlargement of *pleu- (“flow”). Here are four Gothic words with cognates of PIE etymons starting with *pl- 

These two verbal roots *bʰewg- "flee" and *bʰegʷ- "flee" share the same meaning and very similar forms, the only difference is their ending consonant. I wonder whether they are from a same root or just a coincidence? 

The semicolon in ∀;y is surely a typo. It should just be ∀y, just like the ∀x that precedes it. A period is often used to introduce the scope of a variable binding expression like ∀x, e.g. ∀x.φ. By convention, the scope stretches all the way to the end of the entire expression. So, for example, in ∀x.Px ∧ Qx, the occurrence of x in Qx is bound by ∀x. That is, it's not equivalent to Qx ∧ ∀x.Px (by convention). Some authors instead delimit the scope with square brackets or parentheses, e.g. ∀x[φ] or ∀x(φ), while others don't use anything at all, e.g. ∀xφ. (In the latter case, complex expressions like Px ∧ Qx are defined recursively to contain brackets, e.g. (Px ∧ Qx), which by convention are dropped only when no confusion arises. For quantified expressions, this then yields ∀x(Px ∧ Qx), so that the scope of ∀x is automatically clear.) The author that you quote seems to use a combination of a period and parentheses. This is basically a case of redundancy: assuming by convention that a scope introduced by a period stretches all the way to the right, it would be just a clear to write 

*weid- "to see" and *sueid- "to shine" < *weid-es-weid-, *h₂ǵ- "to drive" and *sh₂ǵ- "to seek" < *h₂ǵ-es-h₂ǵ-, 

The data is from "Consonantal Alternations in Indo-European Roots: Diatopic and/or Diachronic Variants or Functional Mechanism?", published by "Journal of Indo-European Studies The 45 Vol., 2017" 

I am curious about the sound change within the early Romance languages, while this one above maybe not a sound change for its bizarre phonological shift. Although its just my guess, I still wonder whether it is a regular sound change or not. 

Is the sound change PIE *kʷ to PGmc. *f or PIE *kʷ to PIE *p regular though it's uncommon? And does any other example exist? PS: Here is a book about the similar sound change in Modern English.