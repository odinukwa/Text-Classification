One more thing, I forgot to mention one other idea. If you can sort the blockers by the position (rotation), then you can use the last position (last index to moved blocker) to check, whether that blocker is still current for next frame, if not, move to next. Removing the loop cycle completely and having just couple of basic s. 

Well, the runtime of your code can be maybe improved a bit by cleaning up the current code a bit, but the main bottleneck is the inefficient algorithm, so I will not comment on your particular code and style, and I will focus on the algorithm only (if you still insist on code clean-up of current version, let me know in comments, I may try to rewrite few bits of it more to my style to show you a thing or two, but I think reviewing better algorithm would make more sense). Also I would focus on the search algorithm, not on the init. I'm afraid with huge word list even init can be very costly, and worth optimization, but the initial data may be preprocessed ahead, so you then read not only word list, but complete definition of graph with edges between them. You should have posted, if the init itself is important for you as well (can be worth of effort for application where input word list changes often, so graph has to be rebuilt often). Imagine the words as nodes of graph, with edges between words different only in single letter (obviously words of different length form a completely disconnected sub graph, but even with words of the same length the graph can have several disconnected sub-groups). If a starting word has a ladder to the ending one, both should belong to the same sub group of graph. So first optimization may be to store each sub group separately (for example: having for 4-letter words two or more graphs). Then in O(subgroup_size*letters) you can tell if starting word belongs to the group under scrutiny. (with global hash map of words containing index to subgroup and index within subgroup the O(...) can get even lower, depends on hash map search implementation, but the initialization will get longer). Now the ending word must belong to the same subgroup, otherwise the ladder path does not exist at all, so another search of word ( O(subgroup_size*letters) ) will tell you, if the solution does exist. And also you will have both nodes (starting and ending word). Now you should do a "path between nodes" search, I'm not sure if the shortest one is required, or any will do. For these situations something like A* path-finding algorithm can be used. I didn't check A* lately, so just from my head some idea about such algorithm, basically searching the graph from both ends, in a deep/wide way by word_distance: You have to create some and set . will be distance (number of nodes) from starting point. Also set and marks whether belongs to the starting node, or to the ending node. Put both indices in the deque. Now till the deque is not empty, pick the index out of it and it's color. For all it's neighbours: 

Why name like ? Was it just for this review, or is it actual label? Use rather something more descriptive. 

The initial comment: not clear what is entering (deducting it's about byte ) and I would rather use "arguments" or "input" word. Not clear the description is about bits. Not all arguments are described (the code does use also address for ). Typos. Modified registers are incomplete too (again ). Etc.. 

So whatever you plan use that macro for, you should probably stop and look into your SW architecture, as it doesn't make sense. If you want to use it for output formatting, I would suggest to use rather the already created and debugged C/C++ facilities, like . If you still insist to do it by your own, at least produce some kind of , not , which would immediately destroy your rounding (as I shown at the beginning of my answer). 

As you can see, I removed the array ( not needed) and I use the know state after last to avoid . So this is certainly more efficient, but also harder to read and comprehend. 

To get forward from this situation, there are two basic paths possible: 1) keep using HW floating point numbers This has huge performance bonus, so that's why the / are first choice citizens in C++ floating point number calculations. Usually the tiny inaccuracy of results is small price to pay for the HW boost of calculations. Then you should arrange your calculations in such way, that the cumulative error is smallest possible, and store around the values with maximum possible precision for any record purpose. You then round the value to proper number of decimal places only during output formatting, for example like to get the rounded to two decimal places in form of "string". Of course you should be aware of total possible cumulative error, and make sure it's within the acceptable level of inaccuracy for your software. 2) use other encoding of your numbers: some big numbers library One of the possibilities is to use some library for arbitrary precision [decimal] numbers (like Java's class, can't recall any C++ one from head). These encode numbers in some custom binary way (or even as string), and have their own versions of common math operations, working with these numbers. Usually imitating human base 10 number format - which is not perfect either! For example you have two forms for every integer number: , or numbers like Pi can't be written down without infinite number of decimal places. These work like charm for financial software, where human base 10 formatting is actually perfect fit, with all it's quirks and imperfections. The price is of course the performance, as each operation is emulated by several HW instructions, so even thing like simple addition may be 10-100 times slower than the HW . 3) use other encoding of your numbers: fixed math When you need only exact number of decimal places, like for example you want uniform distribution of space coordinates, you can use integers, and assign some bits for decimal part. For example 16b can be split into 8:8 whole:decimal part, supporting numbers from 0.0 to 255.99609375 (255 + 255/256), with constant 256 (inclusive) granularity between every two integer values. It may look a bit confusing at first, but these are easy to use in ASM with bit shifting (to get the whole part of number you only shift the value by 8 bits to right, to add two values you simply add them as two integers, etc). This is also sometimes used for financial software to calculate amounts with 2 decimal places, this is done not by allocating exact number of bits for the decimal part, but by simply having all values multiplied by 100, i.e. $3.59 is stored internally as integer, and when the value is displayed to human, it is temporarily formatted as . The limitation of this method is, that you have to decide the fixed precision for particular values, so it's not universal silver bullet. But compared to the big number libraries, the fixed math has performance very close to HW floating point numbers, on some CPU architectures it may be actually faster (like back in ages Intel 80486).