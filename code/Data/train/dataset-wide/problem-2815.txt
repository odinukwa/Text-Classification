I'd second TopinFrassi's answer, that this is a more or less sensible approach, and the implementation is excellent. However, there are some potential issues, which I'll expand from craftworkgames' comments and your response. Because I can't really find anything that needs criticism in how it's written, this will be entirely design focussed. There are two central issue in passing an interface that claims it can provide 

I think the above should be your default starting point. Building a design means making decisions, and every decision is a potential wrong decision, which becomes technical debt. So you should never build more or earlier than you're driven to by your requirements. But there are some reasons you may immediately want a heavier design than this. For example: 

From there, the solution with and is really just noticing that you can predict what the loop will produce without actually having to go through each iteration, and likewise knowing about the modulo () operator and thinking to use it, to simplify the column bit. But being able to clearly state what you want to do in English and turn that into concise, readable code is a far more general and wide-reaching skill. 

Regarding your original , the names aren't great. Shouldn't be , and likewise shouldn't be ? This also reveals another problem: there's no guarantee that these values are valid (they could be negative, or above the maximum possible). This could be done with validation in a constructor, making the setters . 

The relative merits of those options don't really matter- the first two would mean an interface change and the last would mean any consuming code would need to add null checking logic. None of them comply with OCP. In trying to give yourself better adherence to OCP, with this particular example requirement you'd actually have locked yourself into a design that would need bigger modifications. That particular requirement was just the first one off the top of my head, it may not have been realistic, or perhaps you can think of workarounds, but in general you should work on the assumption that developers are bad at guessing future requirements. So once you realise that header validation of some kind was a requirement, what should you write? Something like: 

Both are s, and in neither case is that really very helpful. But the first provides useful information: that a record was not found, and the id of this record. That immediately means that a person debugging could look at the state of the database, or try to understand why an incorrect id was passed to this method. While somebody could work out that no record was found from the stack trace alone, there's no possible way they'd be able to get to the id, so really the message is just a human-readable way of presenting that potentially vital piece of information. The second, on the other hand, provides nothing useful. "An error occurred", well, we already knew that. "While processing the record"- that's just a much more vague restatement of what we'd get from the stack trace. Handled Here's where it gets more interesting. When we throw an exception that might be handled, there's a new, very important, concern: abstraction level. And this is what the MSDN quote is getting at. As an example, let's take the good old "repository" abstraction, where we have an which hides the consumer from having to worry about how data is persisted. Yes, in reality it's more often than not unrealistic that we'd write an application where we needed to swap in and out totally different types of persistence, but it makes for a nice example. So take two concrete repository classes: and . The former stores a as a row in a table in the database, keyed by the id. The second stores the as serialized text in a text file in a particular directory, named {id}.txt. Now let's look at our method. What happens if I pass an invalid to either of these? Well, they both throw exceptions, but they both throw completely different types of exception. One throws perhaps an (if using like in the example) or , the other throws a . That makes perfect sense, but the problem is they now get thrown up the call stack, through that abstraction layer, and suddenly our abstraction is leaky. No caller could hope to handle these sensibly without also knowing what all the possible implementations of are. In fact, they not only need to know the broad classes, but very specific implementation details. Does a SQL-based repository throw or ? Does a file-based repository throw or ? So in order to maintain their abstraction, the repositories should all throw exceptions that can be understood by the calling code. If they need to signal a particular problem with a particular type of exception, this should be a common exception, which describes the problem at an abstraction level understood by the catcher ("Record not found") rather than a level understood by the thrower ("File not found", "Sql record not found"). Going back to the examples in your question, neither of them do this well. Useful information is only provided in a message. Assuming we're not going to try to parse that message to get useful information out of it (which would be a dreadfully complicated and error-prone way of going about things), no caller can do anything useful with these exceptions. does not specify anything about what went wrong. On the other hand, YAGNI is very relevant here. If you control the code which calls this method, and you know that this kind of exception isn't going to be handled, then going out of your way to define custom exception types to then ignore would be pointless. But the key point is that when writing code which throws exceptions that may be handled by its consumers, ensuring that it throws exceptions at the correct abstraction level is a very good reason for wrapping. Conclusion That was longer than I anticipated, so just to re-iterate the good reasons: 

But now this really seems like a mess. We're relying on two different things- the unit of work and the query helper- to do our data access, at two different levels of abstraction. Which level do we actually want? Well, I think the answer is straightforward. We added specifically because we found ourselves wanting that abstraction over accessing the directly. Moreover, if we look at the problems above, can solve all four of them. It solves 1,2 and 4 by its nature, and it can simply solve 3 by keeping its return types as rather than , and by not exposing any methods which take an arbitrary or to use as a filter. All that remains is to extract the methods that we consume onto , narrowing them and making them more specific to keep them at the right abstraction level when possible. You can probably see the punchline coming- what we actually end up with isn't , but . This can follow the standard generic repository pattern you'll find described all over the place. If you look back at the root problems, you can see these are solved too: now everything relies on a much smaller, more targeted interface, and data access concerns are kept in data access classes, rather than spreading out to every service that cares about entities. Conclusion But what about KISS? Possibly you were already aware of the generic repository, and you wanted to avoid it because of its apparently needless complexity and indirection. Well, yes, as always there's the tradeoff- in a small, simple application, at what point does further SOLIDifying your code consume more development resources than it'll ever buy you back? That's a judgement call you'll have to make. But hopefully I've given some reasons beyond just "So I can swap my ORM" for why you might pick this more complex pattern. Also note that the generic repository is, at its core, not actually all that complex or bulky to implement. It really starts out as just a thin wrapper over . But don't be misled! A repository should not just be an adapter from to an interface you control, it should be a full-blown abstraction layer! So if you do find yourself adding more methods, that's probably vindicating the choice of that pattern. 

(Apologies in advance for any bad F# syntax in this answer) One issue is that you're doing things statefully. In a functional style, you want functions to be pure, as much as possible- i.e. their purpose is to return something, not to change state. Whereas you have global collections like and , and functions whose purpose is to modify those collections. Taking the last part in particular, you do: 

As you added new properties, you'd add them in the same way as . The key here is that each property has a sensible default, so that in tests where you don't care about the publish date, you wouldn't have to specify anything for it. There is a bit of overhead to doing it this way, so a data builder is something you should refactor to when you feel the need. For now, methods on the test class might be good enough, and you may be able to get away in a lot of cases with just returning a default then modifying it directly, since it's (presumably) not immutable. But don't leave it too late to refactor to, otherwise you'll have to go and update a lot of tests! Misc 

First, it seems like the brand and the category checks are more or less separate from each other. It's confusing reading that statement to work out that you're churning through every valid combination. So separate them out into their own methods: 

In general, when trying to reimplement basic collections like this, you're going to have a lot of difficulty getting near the performance of the in-built .NET collections. As others have said, removing frequently from the beginning of a has very poor performance. However, just looking at the circular buffer article already linked, my immediate reaction is "yeesh, that is not complexity I'd want to add to my code!" Especially when I know somebody's already done it for me in the existing ! So in situations like this, the answer is usually to either be willing to sacrifice performance, or to try to make use of the actual collection as much as possible. In fact, all you want is a queue that has a little extra functionality, so why not do just that, using composition? There's no interface in .NET, so we can't implement the decorator pattern, but we can get close: 

You might consider using the data builder pattern. Builders should live in your test project, are often written with a fluent style, and would look something like this: 

The Decorator Pattern - Part 1: DRY () At fist glance, the decorator pattern is nice in that it gives the appearance of very easy adherence to the open/closed principle (OCP) and the single responsibility principle (SRP), but it does have its limitations. The most obvious one is that any decorator is inevitably tightly coupled to its interface. If you find yourself writing code in a decorator that actually doesn't really have anything to do with the specific interface it's implementing, that should set off alarm bells because you're inevitably setting yourself up for a future violation of another important programming principle- Don't Repeat Yourself (DRY). Your is a great example of this. The name is the first sign of this- instead of being one thing, that's two totally unrelated things stuck together, an and a . Does exception logging have anything to do with reading code files? And if not then why is an exception logger being forced to implement the interface? Nothing in that class is specific to the interface it implements apart from the method that is wrapped in a try/catch. So the next time you write a class, and want an decorator for that class, you will find that almost all of the code in will need to be duplicated, hence the DRY violation. The Decorator Pattern - Part 2: Separate and Dynamic Responsibilities () In your answer, you quote a nice list of situations in which the decorator pattern is appropriate. What's interesting is what is and isn't on this list, compared to why you've employed it in this situation. On the list: