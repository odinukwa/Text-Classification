First, I agree with the commenters in not understanding your objection to giving different names to the same mathematical objects if they are used to model different phenomena. The terms "position" and "velocity" can both refer to vectors in $\mathbb{R}^3$, but this doesn't imply that using both terms is bad habit or that there are modeling gaps that need filling in. When modeling some phenomenon, it's important to distinguish between the mathematical structure of a thing and the meaning given to this structure. (For example, in CS we often refer informally to the need for both syntax and semantics.) One good example is the pair $G = (V,E)$ where $V$ is a finite set and $E \subseteq V \times V$. We often interpret this structure as a "connectivity graph" where $(u,v) \in E$ has the semantic meaning "there is an edge from $u$ to $v$" and it makes sense to ask the question "Is there any path from $s$ to $t$?" where a path is a sequence of pairs $((u_1,v_1), \cdots, (u_n,v_n))$ where $v_i = u_{i+1} ~ (\forall 1 \leq i M n)$ and each $(u_i,v_i) \in E$. On the other hand we can also use $G$ as a model of eligible partners where $(u,v) \in E$ has the semantic meaning "$u$ can be assigned as a partner to $v$" and a reasonable question is "what is the largest matching in $G$?" where a matching is an $M \subseteq E$ where $(u_1,u_2),(u_3,u_4) \in M \implies u_i \neq u_j (\forall i < j)$. Of course, you could technically ask the path question in the second example or the matching question in the first example, but it wouldn't make much sense, nor does restricting ourselves to only one interpretation of the formalism $G = (V,E)$. More concretely, it sounds like you might want to check their prior work for more explanation, as they say (p302): 

More extended comment than answer: My understanding is that this is basically the idea behind the Fast Fourier transform multiplication algorithm. My impression is that the intuition behind finding Fourier coefficients is the same as your intuition, i.e., expressing numbers in terms of "basis" elements (like $1000$ in your initial example), and doing so as efficiently as possible, so that operations on these bases are easy. So, for instance, we can view an $n$-bit number as a point in $\{0,1\}^n$ written in terms of the basis points $(1,0,0,\dots), (0,1,0,0,\dots),\dots$. Then we can use the Fourier transform to write it in terms of some other, more convenient basis, do some operations in that space, then convert it back to get the results of our multiplication. But usually this is done in $\mathbb{C}$ and the bases are the $n$th roots of unity. I wish I knew more about this whole process, specifically, why the $n$th roots of unity are chosen as a basis and whether some other basis would work as well; also, I would be interested to know how a general Fourier transform would work for your particular setting (Hamming distance), but unfortunately I don't have the understanding to say. I hope someone else can perhaps respond and explain! Anyway, there's some explanation of the FFT algorithm on the wikipedia page, and an explanation of the FFT algorithm for multiplying polynomials is in Chapter 2, section 2.6 of Algorithms by Dasgupta, Papadimitriou, and Vazirani, available for free. 

I am looking for a construction that can be stated as the following coding problem: a binary code with good distance ($d = \Omega(n)$ where codeword length is $n$) that "resists local decoding" in the sense that, for some $k$, reading $k$ bits is never sufficient to decode (even were the channel noiseless). In other words, for each subset of $k$ locations and each codeword $w$, there exists a codeword $w'$ that matches $w$ at those $k$ locations. To make the question harder, I'm actually most interested in "balanced" binary codes -- every word has Hamming weight $\frac{n}{2}$. But it seems independently interesting to get an answer even without the balanced condition. How large can $k$ be? Can it be $\Omega(n)$? (What is $k$ for the Hadamard code?) Notes: We can restate this as a combinatorics problem (up to a constant factor or two), treating each codeword as a subset of $\{1,\dots,n\}$ indicating the coordinates equal to $1$: Come up with a set of subsets of $\{1,\dots,n\}$, each of size $n/2$, such that pairwise intersection is $O(n)$ (this is the distance requirement) and for each subset $S$ and each $X \subseteq S$ with $|X| \leq k$, there exists an $S'$ such that $X \subseteq S'$. The problem of finding the largest $k$ seems too large for exhaustive search even over very small $n$. Examples: For $n=4$, take all of the weight-$2$ words: $\{1100,1010,1001,0110,0101,0011\}$. Here $d=2$ and $k=1$ (we must read at least two locations to have a hope of uniquely identifying a codeword). For $n=8$, I believe we can take the following weight-$4$ words: $\{11110000, 00001111, 11000011, 10100101, 10010110, 01101001, 01011010, 00111100\}$. Here $d=4$ and $k=2$. 

If we include the larger research community -- economics, computer science, social sciences, business schools, operations research, etc -- I think there really is a partition between combinatorial game theory and what I would propose to call "equilibrium" game theory. Most in econ and related fields who study/use game theory extensively have probably never even heard of the combinatorial kind! And even those who have usually don't encounter it in their research. (For instance the course you link is by two computer scientists and an economist.) And I think this divide illustrates the nature of the partition, namely, "equilibrium" game theory is at home in microeconomics: Its purpose is understanding the behavior of groups of strategic / self-interested agents. I think the following motivation helps illustrate. A choice facing a single agent is simply an optimization problem about maximizing utility and hence, once written down, has a well-defined solution. With multiple agents making decisions, however, one needs to propose a "solution concept" describing or predicting how groups of agents might behave. There is no necessarily right or best answer. The insight developed by von Neumann, Nash, etc was to propose as solution concepts equilibria, where the key point of equilibrium is that all agents are simultaneously optimizing. Essentially all game theory of the second kind, in my experience, follows this motivation and solution approach, hence my proposal for "equilibrium" as the descriptive term. (By the way, for this reason I would argue that "cooperative game theory" is a misnomer. Although it is also taught in the same economics classes, it has little to do with "game theory proper". It fits better within social choice.) On the other hand, while I have almost no experience with combinatorial GT and probably shouldn't risk putting my foot in my mouth, my impression is that it is not generally motivated by modeling strategic agents. Instead, it tends to use a "game" as an analogy or mental picture for describing a well-defined mathematical problem in which issues surrounding strategic behavior, and especially the problem of solution concepts, do not tend to play a role. The question, although described as involving multiple agents, is more about understanding the (well-defined and uncontroversial) optimization problem. To highlight this, in my (limited) experience, even in artificial intelligence where problems related to combinatorial game theory come up (planning, alpha-beta pruning, solving perfect-info zero-sum games like checkers/chess/go), the problem is not really described as falling under game theory (which to that crowd tends to mean equilibrium game theory) but rather simply algorithm design or optimization. So in summary, I'm hoping to put forward two points. The first is that "equilibrium game theory" may be a good disambiguation name for the second kind of game theory you mention. I think the notion of equilibrium actually quite closely capture both necessity and sufficiency for falling into that category. The second point is that, if you look at the broader research community than in mathematics (not to mention popular culture), a large majority equate "game theory" exclusively to equilibrium game theory (and generally out of ignorance rather than conscious choice). I'm not sure what the point of that point is, but maybe it's useful. 

The magnitudes of the heights don't matter, just the order (because we want to find the path from $u$ to $v$ with the smallest height). In particular, we can just imagine that all the heights are powers of two, with the ordering the same. If all the heights are powers of two, and we think of these heights as travel costs (lengths of paths), then it is shorter for a path to go through every vertex smaller than $v$ than it is to go through $v$. (Because $2^1 + \dots + 2^{k-1} < 2^k$.) So the shortest path, when heights are powers of two, is the one that goes through the minimum maximum height. 

For the expectation, linearity of expectation should help a lot. There are ${n\choose 2}$ pairs of chords, and if each chord is drawn i.i.d. then each pair has some probability of intersection of $p$, so the answer is $p{n\choose 2}$. In the case where both endpoints of each chord are drawn uniformly at random, I believe $p=1/3$. Let's call the two chords AB and CD and imagine we first randomly place A; this divides the circle into a line segment, say, clockwise. Now the chords intersect if the ordering on this line segment is C, B, D or D, B, C, but do not intersect for any of the other four orderings. All six orderings are equally likely, so there's a $1/3$ chance that two chords will intersect. 

Intuitively, it should approach zero fast as soon as $|\mathcal S_{\mathsf{big}}|$ is at all smaller than $n$ (even like $n/2$) because virtually all subsets $\mathcal S_{\mathsf{small}}$ will contain some element not in $\mathcal S_{\mathsf{big}}$. (Quick edit: I am assuming that $\mathcal S_{\mathsf{big}}$ and $\mathcal S_{\mathsf{small}}$ are each drawn indpendently and uniformly at random from the set of all subsets of $\mathcal S$ having the specified size.) Let $a = |\mathcal S_{\mathsf{big}}|$ and $b = |\mathcal S_{\mathsf{small}}|$. For any realization of $\mathcal S_{\mathsf{big}}$, there are ${a \choose b}$ possible realizations of $\mathcal S_{\mathsf{small}}$ contained in $\mathcal S_{\mathsf{big}}$. There are ${n \choose b}$ total possible realizations of $\mathcal S_{\mathsf{small}}$. Hence the probability of containment is exactly \begin{align} \frac{{a \choose b}}{{n \choose b}} &= \frac{a!}{(a-b)!} \frac{(n-b)!}{n!} \\ &= \frac{a(a-1)\cdots(a-b+1)}{n(n-1)\cdots(n-b+1)}. \end{align} For $b$ small compared to $n$, this is essentially $\left(\frac{a}{n}\right)^b$. That is exactly the answer you'd get if you had fixed $\mathcal S_{\mathsf{big}}$ and picked $\mathcal S_{\mathsf{small}}$ by drawing $b$ elements independently (although this method would create duplicates). More precisely, $\left(\frac{a}{n}\right)^b$ is an upper bound on $\Pr[\mathcal S_{\mathsf{small}} \subseteq \mathcal S_{\mathsf{big}}]$, and a lower bound is $\left(\frac{a-b}{n-b}\right)^b$. For your examples, we get probabilities upper-bounded by $\left(\frac{n^{1-s}}{n}\right)^{n^s} = n^{-s n^s}$ and by $(\log n)^{-s(\log n)^s}$. Of course both of these approach zero fast. A necessary condition for a limit of $\delta > 0$ as $n,a,b \to \infty$ is that $\left(\frac{a}{n}\right)^b \geq \delta$. I think this implies something like $a = n\left(1 - \frac{O(1)}{b}\right)$. 

More concretely, sort the heights of the vertices from smallest to largest and map these sorted heights to the list $2^1, 2^2, 2^3, \dots$. Create a new graph where each vertex is labeled by its new height. Now find the shortest vertex-weighted path from $u$ to $v$ in this new graph. If the length of this path is in $[2^k, 2^{k+1}-1]$, then $\Phi(u,v)$ is equal to the $k$th-smallest height. To see this, note that this shortest path necessarily includes a vertex with new-height $2^k$, but no taller vertices; and there is no path consisting of only shorter vertices, since that path would have length at most $2^k - 1$ (even if it included all vertices with new heights less than $2^k$). Note you can find the shortest vertex-weighted path by reducing to the standard shortest-path problem. First, make all edges directed and pointing both directions. Make all edges have weight zero. Second, split each vertex $v$ into two vertices, $v_{in}$ and $v_{out}$. Make all the incoming edges of $v$ point to $v_{in}$ and all the outgoing edges point from $v_{out}$. Make an edge pointing from $v_{in}$ to $v_{out}$ with weight equal to the weight of $v$. We can also use all-pairs shortest paths, etc. Let me know if anything is unclear.