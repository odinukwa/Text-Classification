There is no difference in treatment in Oracle between a java and a standard : both are treated as cursors. They are both parsed (="compiled"), executed and (for queries only) fetched. The difference between the two kinds of statement is that : 

The problem with your query is that currently a subquery in Oracle can't access a value from a parent query more than two level deeper. You could also use a PL/SQL function that would contain the inner SELECT. 

Unfortunately it would seem that your customer is running its DB in NOARCHIVELOG mode since the view V$ARCHIVED_LOG is empty. V$LOG_HISTORY only records the switchs of the online redo logs which all DBs have. Only databases that are setup in ARCHIVELOG mode will archive redo logs. I'm afraid your customer is out of luck. At this point you should probably consider contacting Oracle support. 

Root Cause foreign_key_checks is not a global option you can preset at startup. Why ? When you click on that link to the Documentation on foreign_key_checks, there is no chart that says it is global or session scope. Other options will specify the scope in a chart 

Something tells me you are either using a version of MySQL prior to 5.0, you called an older version of mysqldump, or you messed with the settings of the dump. What usually blows up a mysqldump past the size of its dataset is the option --skip-extended-insert. In older versions of MySQL, there was no extended insert. That means each and every row in a table had an INSERT command to itself. If a table had 2,000 rows, the mysqldump output will have 2,000 INSERT commands. That's a whole lot of commas, parentheses, single quotes, and "INSERT INTO" tags to place in a dump file. In newer versions of MySQL, --extended-insert was added to group together dozens (or even hundreds) of rows in a single INSERT. SO, instead of... 

One way to force data to actually be overwritten would be to update it to a meaningless value before deleting the row. This wouldn't work with indexes since updates are translated to delete+insert in a b*tree index. 

In the first case the database will interpret PROCESSED as a variable, and its value, even if constant won't be learned until execution time. An index on will be used only if status has a strong selectivity for all values (ie there are many different values). Since you have only 3 values, Oracle makes a FULL SCAN since from its point of view any of the 3 values could be used. In the second case, an index will be used if you have statistics on this column that show that the value 0 is very selective (ie there are few rows processed). Oracle knows at compile time that this value won't change thus an index scan will always be effective. So, if you're sure that there are few rows processed, you will have to help the optimizer, for example with an hint like . Or you could use comments in your SQL: . Also remember that FULL SCAN are not evil. 

REPAIR TABLE makes no apologies. The documentation sheds no light on reads, so SELECTs would be outright blocked until the repair is completed. All queries that are writes (INSERT, UPDATE, DELETE) would be queued until those full table locks are released. This is true regardless of the storage engine being InnoDB or MyISAM. SUMMARY Read locks mitigate SELECTs depending on the command 

If these do not match the version of mysql you are running on the server, or multiple versions of MySQL exist on the same machine, get that straightened out. Until then, make sure you call the correct version of mysqldump and don't use --skip-opt. 

PROBLEM It is logically possible because --single-transaction gets "thrown under the bus" if any commands are launched intermittently during the mysqldump (See this post from mysqlperformanceblog.com). What happens when a dump faces off against an ALTER TABLE ? 

Only one base table is updated All other tables are key-preserved: each of them must have at most one row for each row of the base table. 

Range partitioning involves a bit more maintenance because you have to create the partitions yourself. However, once the partitions are created, range and interval work similarly. 

Both actions (binding and re-executing) are client behaviours. To Oracle a client that uses a cursor only once or another client that uses a cursor a thousand times are treated exactly the same way: 

Edit: By definition, describes materialized views owned by the current user while describes the materialized views accessible to the current user (the user needs to be granted SELECT on the mview either directly or through a role). 

This is assuming that all records in have an existing recode in . If this is not the case, you'll have to use a LEFT OUTER JOIN to have an equivalent query. 

You could schedule it in the built-in Event Scheduler. First create a stored procedure to do the flush of the binary logs: 

Here is something interesting: According to the book MySQL 5.0 Certification Study Guide, Page 433, Section 29.5.1 The MEMORY engine uses HASH by default indexing algorithm. For laughs, I tried to create an InnoDB table and a MyISAM table with a primary key using HASH in MySQL 5.5.12 

METHOD #2 Capture innodb_buffer_pool_read_requests, innodb_buffer_pool_reads, Sleep 10 minutes, Run Query with Differences in innodb_buffer_pool_read_requests and innodb_buffer_pool_reads 

This would have preserved the internal metadata id. Make sure .frm is always present. I once helped a client restore 30 InnoDB tables he hosed in the same manner. I had to use another DB server and play some games with adding and dropping InnoDB tables to hunt down the correct internal metadata id. The client found this article : $URL$ . We used it and it helped a great deal. I hope it helps you. 

If you're transitioning from SQL Server to Oracle, I would advise to try heap tables at first because they are the standard form of storing data in Oracle. For most workloads, heap tables with regular indexes in Oracle are the most balanced forms of storage regarding DML and query performance. If later you find that you have performance problems or bottleneck, you should look into specialized advanced storage methods such as IOT, partitioning, clusters, reversed-key indexes, etc. Regarding IOT in particular, I would advise against their generalized use because there are lots of "gotchas" that you may not want to get into as a beginner: 

(additional restrictions on updating views apply) In your example you update table only. Oracle has to make sure that for a single row of this table, only one row of the other can be found. This seems to be the case since you have a PK on . Therefore you should be able to update the join. See for example this SQLFiddle with a similar setup. In your case you should either: 

For the sake of simplicity, I recommend MySQL Circular Replication only. Here is why: There are many technologies and topologies that are far superior to MySQL Circular Replication. My favorite, hands down, is DRBD (Distributed Replicated Block Device). However, DRBD works great when the Server Pair is in the same bulding, data center, and rack. It's even better when using a crossover cable in the 192.168.x.x. subnet between the DRBD Primary and DRBD Secondary. Unfortunately, DRBD has horrible performance over a distance between two locations, although DRBD can still work. There are no network topologies around to give you the satisfactory DRBD performance needed between two datacenters. Once you setup MySQL Circular Replication between the two DB servers in two different data centers, the only tuning needed is for the network. In essence, the replication performance is a function of network settings (speed/latency of binary log transmission in MySQL Replication Setup) and disk I/O (DRBD). An alternative you may want for better redundancy is the following for the sake of example: Setup a DRBD Pair in both locations DRBD Pair in Site #1 with VIP 111.111.111.111 DRBD Pair in Site #2 with VIP 222.222.222.222 Setup MySQL Circular Replication between the DRBD Primary Servers under these conditions: For site #1, use 222.222.222.222 as the Master_Host in MySQL For site #2, use 111.111.111.111 as the Master_Host in MySQL Although introducing a level of complexity, now you have two levels of redundancy: DRBD within each site and MySQL Circular Replication between sites. You have the additional benefits of running backups via mysqldump on the DRBD Primary of the hot standby server. As for failover, DRBD provides automatic failover at any one site. Only in the event that a datacenter is totally unavailble would you using the DB VIP at the hot standby site. UPDATE I just did a double take and noticed that you are using Drupal6. I am glad you will be converting all the drupal tables to InnoDB. This will remove any chance of MyISAM table updates causing table locks to freeze DB Connections that are simply reading MyISAM tables. Any DML update (INSERTs, UPDATEs, DELETEs) against a MyISAM table WILL ALWAYS DO A FULL TABLE LOCK !!! Using InnoDB will introduce row-level locking, which eliminates full table locks. In addition, DRBD becomes your friend when everything is InnoDB because crash recovery will be consistent between the DRBD Pair. Contrawise, DRBD with MyISAM buys you nothing because a crashed MyISAM table on the DRBD Primary is simply duplicated to the DRBD Secondary as, you guessed it, a crashed MyISAM table. UPDATE #2 You should use two levels of redundancy Level 1 : At each database center, use DRBD. $URL$ Set up a pair of DB Servers Startup DRBD Startup MySQL on the DRBD Primary This creates redundant data at the disk level. Level 2 : You should setup MySQL Circular Replication between the DRBD Primary of DataCenter#1 and the DRBD Primary of DataCenter#2 Each DRBD Primary will be running MySQL and will act as both Master and Slave to Each Other I have setup for clients topologies like this and I consider it quite stable.