It takes about about 12 hours to get all the energy, but because there's more energy per hour in the middle of the day, you can get 25% in about 2 hours, 50% in about 4.5 hours or 75% in about 7 hours. This means one fae could support 1 m² at 2 hours/day, or 2 m² at 4.5 hours/day, with a little less in the winter, a little more in the summer. The fae could potentially store the excess energy during the summer and use it during the winter to keep the underground in perpetual spring. Of course, if you start using magical power sources, anything goes. They just have to absorb more energy than the plants require, plus a bit more for efficiency losses. But you'll want to figure out what this magical power source is. It could be a glowing crystal they brought from the otherworld that behaves kind of like a nuclear reactor. They could steal "life energy" from the humans around them. They could have access to some kind of geothermal energy. Original answer: 

It's 4 diodes, any random tube of about the right size, and some magnets. The hardest part is coiling all that wire around the tube. That sounds a lot nicer than trying to hack together an electric eel charger. (Of note, there's a bit of contention in the comments saying that specific design sucks and may not actually work, while others say it works fine. It's just the first one I Googled, but regardless, real designs aren't very complex, especially for a one-off phone call.) 

I never much cared for the new BSG, so I don't have any off-hand information about most of the ships in the show. The various wiki's don't seem to have much information either. Maybe there just wasn't a lot of information given. So I don't know how many nukes the raptors could carry, etc. Still, if the Raptors were capable of carrying a single nuke each, they could largely take over the world themselves without any extra support. Add in guns, missiles and the ability to carry troops, and they could infiltrate lots of places. To be fair, I don't remember the foot soldiers having much in the way of super weapons, so they might not really get that far with 100 vs 10000 or something. Although, if they had access to a couple of the shiny metal cylon dudes, those guys should be able to take on legions by themselves as long as the Colonial ships could keep Earth's air support occupied. If the Vipers were remotely as good in air as they were in space, they could pretty much take on the world by themselves as well, although they wouldn't have quite the same "I just destroyed a dozen major cities and killed 30 million people, bow down to me!" power. With regards to the edits: Landing a ship would be harder on it than doing repairs in space. Ferry the metal ore or whatever up to the ship, rather than throwing the ship into an atmosphere at Mach 10 or something. 

First, we'd still have time zones after a fashion. We'd all have an "offset" to describe how much my time differs from UTC, and how much yours does, then I would subtract my offset from yours and add the offset to my clock to figure out what effective time it is where you live. For example, I'm in UTC-7 and you're in UTC-5. Yours-Mine = -5-(-7) = -5+7 = 2. So if it's 03:35 here, it's like 05:35 there. Which is what we do already to determine the actual time. So that wouldn't change. Second, we'd either have a secondary set of local clocks that add our own offset to UTC -- oh wait, that's what we're doing now. Or we wouldn't. Let's say people were somehow convinced to always use UTC. What would happen? 

I feel like any sufficiently advanced medicine that could bring a rotting corpse back to life and restore the neural circuitry weeks after death would have zero issues eliminating infectious diseases in the process. But all the bacteria eating your flesh out there are sitting around in the woods already. If you go roll around in the leaves, you've got all kinds of microbial life all over you. It's just that your immune system takes short work of anything hostile and you rarely even get sick. So if there were some disease leftover from the experience, it wouldn't likely be anything all of us haven't already been exposed to a thousand times, and any transmission of that disease would be of little consequence. Even straight up eating rotten food will mostly just make you really sick for several days. By the time the patient is released, their immune system would have taken care of most everything, and as long as they bothered to bathe at some point, it would be a non-issue. 

TL;DR If your aliens evolved on the same timescales as Earth life, then no; we took 2 to 3 Ga too long. If we assume selection pressures drove the alien microbes to much faster evolution, then yes; you've got anywhere from 1 Ga of wiggle room to life forming just before armageddon comes. (Ga is Giga-annum, or a billion years.) Lifespan of a Star This forum post links us to this article about worldbuilding and star ages. It lists several types of F-class stars, ranging in lifespans between 1.6 and 6.9 Ga. Using the data on the tables, we get a graph like this: 

I think your basic premise is a bit flawed. You assume that a spaceship would be treated as the sacred "body" of its controlling AI, but I find this hard to believe. I think the AI would, at best, own the spaceship and have some hardware considered the AI's body, or, at worst, be considered a non-physical entity without a body. As such, the spaceship, or anything else used or owned by the AI, would be subject to normal property laws, including inheritance where applicable. Similar arguments work for other AIs, like houses, ocean ships, etc., but I'll focus on a spaceship for more concise writing. The spaceship is a piece of property, not a body. It's likely the spaceship was built explicitly for a purpose of human utility. As such, it will likely be the property of whatever person or corporation commissioned its creation, or later purchased it. If AIs have legal rights, then they could certainly earn the money to purchase their own spaceship, much like I can purchase my own house or car. However, it's unlikely the spaceship would default to being owned by the AI, simply because a spaceship is a very costly item. And nobody would build spaceships if the AI built for the ship could just say "nah, don't wanna work for you" the instant they're turned on. Many AIs would be designed with a modular "body", separable from the spaceship. In a society where AIs are regularly treated as people and efforts are made to include them in design considerations, it's likely that each AI would have some kind of "body" that explicitly belongs to them at creation. This would likely include their main processing unit, and possibly a motorized contraption to allow the AI some physical autonomy. I'm thinking something like a motorized wheelchair with a battery backup, a couple cameras, and a microphone, as well as the possibility for some type of physical manipulators (arms and hands) and some way to communicate (speakers and a monitor). This wheelchair (or high-tech equivalent) would carry the physical computer, allowing the AI to move from one spaceship to another. AIs don't inherently have bodies. However, for very advanced computer systems, it might well be the case that the AI doesn't have an explicit body. Many AI systems could be distributed across a single computer core, or a single AI could be distributed across multiple computer cores. It's likely many systems would have both: many AI systems sharing a network of multiple computer cores, such that no one computer belongs to a single AI, and no one AI is housed solely on a single computer. In cases like this, the network would likely be scrubbed to remove traces of the dead AI (though some traces might be kept for sentimental reasons, much like Facebook keeps profiles for dead people around). Beyond that, the AI wouldn't necessarily have any particular ownership of the network. It's certainly improbable the other AIs would be forced to move to a new network so the old network could be disposed of. Of course, the AI might have owned part or all of the computer network. In this case, normal property laws would apply. Well, as "normal" as you get for joint ownership of a common body. The AI itself might have to earn independence. Depending on your setting and the power of the AI, the AI could conceivably be an incredibly expensive device. An AI powerful enough to manage a large spaceship, space station, or an entire city, for examples, would likely fall into this category. In the case of an extremely expensive AI, it seems likely that the AI would have a certain contract period where it's required to earn back it's own purchase cost. The laws around this would likely be complicated and vary from region to region, so we can't specifically enumerate them. However, there would likely be laws about maximum earn-back times (so a corporation can't keep the AI indefinitely if it's not making much money), and about work requirements (how much the AI has to work, and what kind of personal time the corporation needs to give it). Physical "remains" would be treated according to the owner's wishes. As many other answers suggest, I think the AI would be able to draft a will detailing how its property would be distributed, including any kind of hardware the AI lived on. The AI could request that its spaceship be parked in a low-sun orbit, allowing it to slowly be consumed by the nearby star. Or request the ship be donated to the Martian Planetary Government to be used for scientific research. Etc. Of course, the laws governing transfer or disposal of property after death might forbid certain types of request. An AI who owned another AIs body (or part thereof) wouldn't likely be allowed to dictate that the other body be destroyed. Instead, ownership would likely transfer to another entity, and the indentured AI would continue earning its freedom as usual, with the new owner dictating the AI's new workflow. Similarly, a spaceship occupied by hundreds of people couldn't simply be scuttled without properly evicting the tenants first. Note that these laws wouldn't need to be specific to AI wills. A human who owned a spaceship or network cluster would be similarly restricted in how they could use, transfer, and destroy any property used by other entities, organic or otherwise. Your addendum doesn't help much. You've added an addendum (and a comment) stating that AIs are treated as free beings the instant they're created, who are able to choose whatever body they want. This would not happen. First, note that my above comment about forced service was explicitly about expensive, complex AIs. Run-of-the-mill AIs that don't cost much wouldn't necessarily need forced service if it's determined that most of them go on to be productive members of society anyways. But the really expensive stuff wouldn't get a choice. It's not about morality or legality; it's about physics and economics. Next, your AIs simply wouldn't be given any arbitrary "body" they want in the form of buildings or spaceships. Not going to happen. Those things cost money and resources. Your AI could choose to work in a certain building for a while, but unless it earned the money to buy the building, it can't own it. Otherwise, you'll never afford new buildings. A corporation can contract an AI to work in a specific building as the building manager, but the contract will include methods of terminating employment, just as it would for any human building manager. Likewise, the corporation will not allow the AI to customize the building however it sees fit. The AI will be forced to conform to certain building standards, specifically so new AIs can be brought in if the old one moves on or is fired for whatever reason. And so the building can be torn down to build something newer and better in the future. Otherwise, you end up with a planet full of vacant buildings because the AIs can't be moved out and nobody can tear them down. Going back to spaceships, you've got a little more freedom. Space is enormous, so you don't need to reclaim the tiny amount of wasted space taken up by an old spaceship. This means it's more likely an AI could eventually earn the spaceship as something it owns. But you still have the same problems with cost. And spaceships will always be orders-of-magnitude more expensive than planet-based infrastructure. So even if the AI can legally purchase a spaceship for itself, it will have to work for a much longer time before it can afford to do so. And again, practically nobody is going to just give a random AI a spaceship for a body so it can run off and do whatever with it. Because economics. Finally, you're not going to have general-purpose AIs who can be good at whatever they want. Each AI will be purpose-built for specific types of things. Because the AIs are given people status (and we can't just destroy them when they're obsolete), there would be some level of all-purpose programming built in, so a house AI could work in most any house, a ship AI in most any ship, etc. But you're not going to put lots of wasted effort into building a house AI that's good at flying ships. Spaceships and buildings aren't human bodies. You can't just assert that the AI would automatically own the spaceship controls. As I've shown above, this doesn't make any sense in a realistic setting. But it also doesn't make sense from a logical standpoint. Human bodies are required to sustain human minds, to drive human hands, to propel human feet. Likewise, an AI would have some amount of hardware required for it to function, which could be included as "part of the AI" upon creation (but doesn't have to be, as many AIs would likely be content to run on shared server farms as virtual entities). But spaceships aren't required for pilot AIs to function, nor are buildings required for building manager AIs to function. And both of those items will be required by other entities for various reasons. If human bodies had fairies living inside them, human skulls could easily be setup to detach from the body and transferred somewhere else, the bodies didn't require the head to avoid decay, the skulls could have their own implements for moving around and interacting with the world, and the human mind could easily be setup to process these different setups just fine; then human bodies would suddenly be a lot less sacred and personal. And this is the kind of analogy you need to use if you're going to compare the two. Unless you're not really talking about AIs at all. Let's say your civilization is so advanced it can just whip up a spaceship and give it out to the new AI. Likewise, it can whip up new planets and start building new houses on them when the old ones fill up with obsolete AI buildings. At this point, you aren't talking about any kind of remotely contemporary setting. And, in all likelihood, there would be little-to-no distinction between what you're calling "AI", and normal people. Because who wants to live and die in some crummy, organic body, when they can have all their bits replaced by synthetic stuff? And a civilization who can whip up spaceships and planets on the fly, as well as being able to create sapient AIs, would certainly have figured out to convert humans to cybernetic bits. At this point, you could potentially have giant spaceships with their own death rites, but you're also so far beyond current societal norms that any kind of answer to the question is purely guesswork.