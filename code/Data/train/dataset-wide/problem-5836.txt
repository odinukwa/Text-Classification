The idea that our minds and bodies work according to some physical (as opposed to supernatural) laws is often sourced to de La Mettrie, though of course as with any major idea it's hard to give one source. The Wikipedia page on materialism lists thinkers going back as far as 600 BCE; the Cārvāka thinkers had ideas I think Anderson would find quite suitable, for example: 

At the end of the second section of On Liberty, Mill gives a summary of the four reasons why there should be free speech: 

I emphasize "morally relevant" since it is a question for biology to list the anatomical differences, which is of course an important thing to do, but off topic here. Phrased this way, this is the argument from marginal cases. Essentially, the claim is that so-called "marginal humans," such as those with severe cognitive handicaps, have mental capabilities similar (or inferior) to some non-humans. Quoth Singer (from Animal Liberation): 

Yes, of course. This idea is most famously discussed in Nick Bostrom's Are You Living in a Computer Simulation? Note that "Roko's Basilisk" is doing no real work for you here – you don't need any esoteric forms of decision theory to accept Bostrom's argument. 

His home page has links to papers written about this, with reference to science and mathematical beauty. 

With your edit I will venture a guess as to a more specific question, which hopefully is similar to what you want to know: 

Birth {... 4, 5, 6, 7, 8 ...} {... 3, 4, 5, 6, 7 ...} {... 2, 3, 4, 5, 6 ...} {... 1, 2, 3, 4, 5 ...} Death 

Premise: I would argue that any universe that produces (either by computation or by chance) the above sub-structure would be producing my own conscience. At point 3, I would be remembering my childhood. At point 5, I would be dead. Now imagine that a specific universe produces the following: 

Most of the arguments against this kind of rationale base themselves on the impossibility of asserting claims in a kind-of-MUH [Stoeger et al.]: 

In order for a system to be observable, it needs to be "expressive" enough to represent a conscious observer with its own symbols. A conscious observer is thus the mere arrangement of the symbols inside the system he/she/it exists. Consciousness requires a "sequence" of arrangements. The sequence of arrangements may be due to the rules of the system (e.g., it is being computed), but it's not required (e.g., may happen by chance). From the point of view of the observer, the specific order of a sequence of arrangements do not matter, as long as a consistent interpretation of any "specific" arrangement is enough to provide a self-consistent history. 

Birth {... 1, 2, 3, 4, 5 ...} {... 2, 3, 4, 5, 6 ...} {... 3, 4, 5, 6, 7 ...} {... 4, 5, 6, 7, 8 ...} Death 

Dissenters from this argument generally embrace the view that the question is misguided: ethical value doesn't come from having some set of capabilities, but rather arises through a shared contract etc. Carl Cohen defends this view, for example. Entire books have been written about this, if you are interested to continue researching it. On other fronts, you might be interested in the work that Varner, among others, has done to describe the likelihood that various species feel pain which can be roughly summarized as "vertebrates feel pain; insects possibly not so much". And Dan Dennett expresses some uncertainty as to what extent non-humans are conscious, but of course he is quite skeptical of most accounts of human consciousness as well. 

Dennett talks about this as "Skyhooks" vs. "Cranes" A Crane is something which can build great complexity, but it rests on simple, fundamental principles. This is like evolution. A Skyhook (a crane hanging from a helicopter) is something which can build great complexity, but it rests on no firm foundations. This is like creationism. Some of the criticisms you bring up have been brought up by others who say that Dawkins doesn't differentiate well enough between these two in his Boeing 747 Gambit. He may not have presented the argument perfectly, but others have made it more rigorous. 

I think Phenomenology might be a good subject heading for "philosophy of the passions." Wikipedia's description: 

Birth LONG PAUSE {... 1, 2, 3, 4, 5 ...} LONG PAUSE {... 2, 3, 4, 5, 6 ...} LONG PAUSE {... 3, 4, 5, 6, 7 ...} LONG PAUSE {... 4, 5, 6, 7, 8 ...} Death 

Despite the reversed order, if my conscience only relies in any particular "state", I would still remember my childhood at point 3. Now, I can even mix all these states, and produce them out-of-order, but I would still be experiencing the same, from my point of view. Therefore, we have just excluded "time" as a requirement for an universe that sustains consciousness. We may still require "time" to explain the "computation" of states (i.e., why a state follows from a previous one), but, from the point of view of the observer, it doesn't matter. A similar exercise can be applied to space... 

If every state produces exactly the same sub-structure, then no matter how fast or slow these sub-structures are being produced, my conscience would still be "experiencing" the same as before. Now imagine the following: 

Despite epistemological concerns, the most plausible argument against the dust theory is given by Greg himself: 

Because the last point can be confusing, let me give an example... Suppose that a sub-structure of my consciousness has the following sequence of states: 

Which is a kind of distorted anthropomorphic principle; since we are observers, it would be much more probable that the laws of physics would be less strict than those we observe, just to support us as conscious observers. Suppose the dust theory is testable (Egan may already be drafting something along this line, by arguing that a kind of statistical reasoning may point to its own improbability). What would one expect to see in a dust-theory consistent (multi-)verse that we don't observe in our own, and thus render it invalid? 

Cody and Joe gave good answers, but I'd like to add that a common form of argument that you find in philosophy and not so much other places is a Syllogism. This is an argument of the form "P implies Q, P, therefore Q." As an example, a simple form of the argument from marginal cases goes like: 

Skinner, of course, believed that free will is an illusion, so there's nothing to take away. (Hence this conditioning is not immoral.) His book Walden 2 describes a society in which social engineering techniques (like you describe) are used to create a utopia. Your question is timely because a popular ethics book called Nudge has recently promoted some of these ideas. Nudge argues that there are some (relatively benign) ways we can change our environments to "nudge" people towards making the right decision. The SEP's entry on autonomy might be a good place to start. It sounds like you may be new to the wonderful world of differing ethical opinions, but suffice it to say there are several competing schools of thought with diametrically opposed views on the matter. If you are interested in reasons why losing autonomy might be a morally relevant action, you might consider whether rational (autonomous) thought is important for ethical reasoning, whether losing autonomy will make it harder for you or those around you to satisfy your preferences, or whether making autonomous decisions is important for being a "good person". Some classics in the area would be Kant's Groundwork of the Metaphysics of Morals (see e.g. The Categorical Imperative - Freedom and Autonomy) and Mill's On Liberty. Contemporary thinkers tend to be distrustful of the idea of "freedom" in general. (Frankly, I am surprised this question hasn't been answered with a flood of posters questioning whether one can ever make a "free" decision to begin with.) I heartily recommend The Latest Answers to the Oldest Questions which is an introductory-level book to some important philosophical ideas, including questions of freedom.