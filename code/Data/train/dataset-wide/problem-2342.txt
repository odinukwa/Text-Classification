Explanation for Proposed Solution #2 only works with unique indexes and primary keys. In your case, a unique index on was needed for . After making such an index, you can insert all columns except . You could also include id like this 

The log buffer writes redo log information to ib_logfile0 and ib_logfile1 for transactional purposes only. There is nothing text readable within those files. The file /var/log/mysqld.log is the main error-logging mechanism built in mysql. Anything additional would probably be in /var/log/messages. 

SUGGESTION #2 You are using MySQL 5.5 but I do not see any options to make InnoDB access multiple cores. Please add the following to my.cnf to give InnoDB some Enhanced I/O Performance 

If the column has the attribute, you should not specify with a value. It would produce a normal 1062 error (Duplicate Key) for other Storage Engines. SUGGESTIONS Change the to a format that can handle the AUTO_INCREMENT attribute of 

I do not expect my answer to be accepted. The sole purpose of my answer was demonstrate that other answers lose the concise clarity needed to solve your problem. Again, hats off to @yercube. 

STEP02) on the Slave Binary Logging should be enabled in the Slave STEP03) Run the command on the Master using the Slave as its Master 

Every time, run a SELECT against this table, mysqld has to update the table by writing new row information. This is by not adding a new but updating for = 'Handler_write'. An is just a viable a write source as an . Keep in mind that Handler_write is storage engine agnostic. In that case, it's just a metric for write requests without knowledge of the storage engine layer. 

Notice it has a column called . If you run the command , it will echo two lines. The first line will say . When you see , this tells you that all global privileges in the table from that user are 'N'. To prove this, run this command: 

You can do WHERE clauses against the INFO field to look for a specific query, the TIME field against long running queries, or the DB field against a specific database. 

Therefore, at its very worst, MySQL would consume only 9.58% of RAM. ASPECT #2 You did not mention if the Server is a dedicated DB Server or if you are running a full stack. If you are running a full stack, please lower any memory-sensitive settings in the other parts of the stack (Varnish (more like Vanish), PHP, Munin, Nagios, Tomcat, Hibernate, etc). ASPECT #3 Looking at the first crash around 3:36 AM I see 

Any small spike in DB Connections will raise RAM past the 62.5% threshold you see for InnoDB. MyISAM (Side Note) What catches my eye is 

I am sure that there are patient records have the DOB, addresses (zipcodes), and medical histories in the database. I am sure there are queries (SELECTs, JOINs) that can collect this information. This retrieval is what marketers could really use. With said information, marketing firms could search for and decide upon 

What innodb_flush_method does is have the InnoDB storage engine cache any needed blocks to the double write buffer (See the chart). The error messages you have are about the sequence numbers from the logs being misaliged because of the incomplete way you made new logs. 

Trying a standard shutdown of mysqld with no available diskspace complicates the problem. Just kill the process, delete the 18G log file, start mysql back up again, and live with InnoDB crash recovery. Trust me, it is better than looking for alternatives in a Windows environment which will not work because of the same disk issue. 

It is a temporary table. If you restart mysql, how does it get populated? Evidently, it is popoulated during mysql startup. What would be included? Retrieve OS metadata of the table. Let's look at mysql.user from the OS 

When it comes InnoDB and mysqldump, you can lower this number under two circumstances. CIRCUMSTANCE 1 : Set it permanently to 0 Just add this to my.ini: 

never implies doing writes, just blocking other connections in the worst. should abort itself after 4 minutes as a courtesy to other connections. In your case, if there are other processes, wait 4-5 minutes. Then kill the process. If there is nothing else running, kill the process now. Doing a shutdown with it still running may block the shutdown for 4 minutes or more, but will eventually shutdown. Please run beforehand. 

Please keep in mind that OPTIMIZE TABLE does not perform defragmentation. Internally, OPTIMIZE TABLE perform several operations (copying data to a temp file, recreate indexes, recompute index statistics). In fact, the example I have can be performed manually as shown. Example: If you optimize , you enter this command: 

comes from a page in the MySQL Documentation that has to do with how replication sees and handles auto_increment values. This is a vital issue since the order data are written on a Master may get serialized in a different order on a Slave. Just recently (back on ) I answered Does it ever make sense to create an index with additional columns after the primary key?, where I mentioned from the MySQL Documentation that when there is an auto_increment column in a partitioned table, it is mandatory that the column is included in the along with the columns that define the sharding of the table rows. To conclude, let me just say this: support for auto_increment columns in a in InnoDB does not come with any fringe benefits or additional bell-and-whistles like it does with MyISAM. That's why the MySQL Documentation does not have a lot written about it. Support for this was mentioned long ago. If you look in the MySQL 5.1 Documentation on , you see bulletpoint #15 

The first 3 indexes are called covering indexes. They are called such because the subqueries calls for only those exact columns. Therefore, no need to read from the table. The data is only fetched from the index.