It is obvious that the heuristic strives for creating a $CH_{i+1}$ of maximal area when epanding $CH_i$; the rationale for that heuristic thus is to be able to exlude a maximal subset of the points, that are not elements of the final convex hull. Formulated differently, the heuristic strives for the fastest exhaustion of a polygonal convex area; the heuristic easily transfers to exhausting strictly convex regions. $$ $$ 

Given the $n$-dimensional triangulation $\mathbb{T}^n$ of a finite set of points $\{p_1,\ ...\ ,\ p_{n+k}\} \subset \mathbb{R}^n$, is it always possible to find $n+k$ positive real weights $\{\omega_1,\ ...\ , \omega_{n+k}\}$ so that all $n$-dimensional volumes of the simplices of $\mathbb{T}^n$ are equal when lifting their corner coordinates to homogenic coordinates via replacing $p_i$ with $(\omega_i p_i,\ \omega_i)\in\mathbb{R}^{n+1},\ i\in\{1,\ ...\ , n+k\}$? 

let $\quad-1=x_0 < x_1 <\ ...\ < x_n<1\quad$ be a set of abscissas and $\quad(y_0, y_1,\ ...\,y_n)\quad$ a sequence of the corresponding ordinates. 

Interpreting your question that you want to find the shortest paths in order of increasing length, then a nested Dijkstra algorithm may solve your problem also in case of directed graphs. I assume you are familiar with the Dijkstra algorithm, so I shorten the explanation to the essential: 

As hyper cubes of the desired side-length can be constructed with straight-edge and compass, and because hyper cubes are of elementary geometry, that should answer the question 

Background of my question is Barycentric Rational Interpolation is an infinitely often differentable analytic alternative to Splines and NURBS and I wonder, if rational interpolation could also provide infinitely often differentiable analytic closed curves through a set of points e.g. in the plane. 

Question: which online available documents describe the above mentioned Tutte-reduction, resp. can anyone explain it? 

The selection of the vertex, to which a new vertex will be connected, or, which of the candidate edges will be selected, can e.g. be controlled by probabilities that depend on vertex degrees; also the decision whether to add a vertex or an edge, can be controlled by assigning a certain probability to the options. If fluffy graphs are preferred, then the insertion of a new vertex should have higher probability than inserting one of the candidate edges. 

I would also appreciate pointers to good "hands on" material on the Radon transform; preferably online articles and free software. 

I recently stumbled over the "Happy Ending Problem" (cf e.g. $URL$ which made we wonder, if there are other conjectures, theorems or problems, whose names do not give any indication to what they are about or, to which person it is related; the "kissing number" would not qualify here, because it is a definition, but neither a problem nor a theorem. Besides the "Happy Ending Theorem", I also found 

By "mock-parametric" interpolating curves I understand a class of curves that connect a discrete sequence of points with a predefined degree of smoothness and, that correspond to a non-parametric function in a local coordinate system defined by $p_i$ as the origin and, $\frac{p_{i+1}-p_i}{\|p_{i+1}-p_i\|}$ as the local x-axis between $p_i$ and $p_{i+1}$ The reason, why I am interested in that kind of splines is that they seem to combine the simple control of ordinary spline interpolation with some of the flexibility of parametric splines; also the formulation of some optimization goals seems to be easier to formulate: least deviation from the polyline translates to minimizing the Chebyshev norm across all local function-definitions and, because the curvature of functions can be approximated by the 2nd derivative, it seems to be easier to find interpolating curves that come close to optimality w.r.t. conditions on curvature. 

This question is related to Graph-theoretic Algorithm for Path with Minimum Average Edge Length, but in this one is about the LP formulation. Preconditional "facts": 

Why are the lines, over which the integrals in a Radon Transform are calculated, apparently always parameterized as $L(t,\phi,\alpha) := (t*\sin(\alpha)+s*\cos(\alpha),-t*\cos(\alpha)+s*\sin(\alpha))$, (cf e.g. $URL$ resp. have other kinds of line-parameterization ever been investigated? What are the practical and mathematical issues that are related to different kinds of parameterization (positive and negative)? Did Radon himself loose any words about the choice of line-parameterization? 

to me the best possible solution seems to be the sequence of closed Hilbert curves on the Cubed Sphere; that curve consists of six ordinary Hilbert Curves, one for each face of a cube, which, when appropriately connected, yield a space-filling Jordan Curve for the cube's surface. Then centrally projecting those curves onto a cocentric sphere yields a solution without crowding, albeit a slightly higher density around the projections of the cube's corners. A further improvement may result from rounding away the corners in a similar fashion as is used for tennis balls, which is the rounding applied to your example. Yet another, maybe even better, bet would be Hamilton Cycles of Hamiltonian Fullerene Graphs (cf e.g. $URL$ for a discussion); that bet is based on the honeycomb conjecture (cf e.g. $URL$ and on the fact, that Fullerene graphs are the closest one can get to a hexagonal tiling of the sphere (there are twelve inevitable pentagons). Examples of Hamiltonian Fullerene graphs are depicted here: $URL$ 

As an informal motivation the problem, imagine a tower with polygonal footprint, that is located in a beautiful landscape, the "Belvedere Hull" is then related to the directions, in which one would have a view unobstructed by the tower (it is assumed that the tower has roof, so it is not possible to stand on top of it). 

are any formulas for $\arg\max(f(x))$ known (in the context of this question, $\max(f(x))$ shall denote the essential supremum of $f(x)$ over some given domain $\Omega\subset X$)? The reason for asking is two-fold 

The denominator in the formula is intended to represent the average length of the portion of the curve between two adjacent vertices of the polyline. Taking the reciprocal of that average should yield an estimate for the number edges in the polyline. 

As a remark let me explain the name "Moebius Stairway" graph: if the triangles are chosen to be isosceles right triangles and the strip is then drawn in an ascending $45^{\circ}$ angle, it looks somewhat similar to a stairway and, besides that, I liked the idea of providing an alternative to ladders. 

After some fruitless efforts to devise a tree-structure based on subset inclusion and after some investigations on the usability of de Bruijn sequences, I finally arrived at a surprisingly simple method, that is also applicable to countably infinite sets of values: let $\omega(\sigma)\in\mathbb{R};\ \omega(\emptyset):=0$ the function, that assigns a real weight to each subset. let $(\lbrace a_0\rbrace:=\lbrace\emptyset\rbrace,\lbrace a_1\rbrace,\lbrace a_2\rbrace,\ ...\ )$ be the sequence of sets containing as elements the empty set, resp. the elements of the "base set". if $(\Omega_{i,0},\ ...\ \Omega_{i,2^{i-1}}) $ denotes the ordered sequence of all subset sums of $(\lbrace a_0\rbrace,\ ...\ \lbrace a_i\rbrace)$ then $(\Omega_{i+1,0},\ ...\ \Omega_{i+1,2^i}) $ is the merge-sorted union $(\Omega_{i,0},\ ...\ \Omega_{i,2^{i-1}}) \cup (\Omega_{i,0}+\omega(\lbrace a_{i+1}\rbrace),\ ...\ \Omega_{i,2^{i-1}}+\omega(\lbrace a_{i+1}\rbrace)) $ The sketched algorithm also indicates, that its complexity is $O(2^n)$ if the base set contains $n$ elements. If the subset sums are not unique, then duplicates can be skipped without extra effort in the merging process (in that case the index ranges of the sketched algorithm are of course different). I'm aware that the notation may need improvement; please feel free to edit or suggest improvements. 

There is a striking analogy between finding maximum matchings in graphs and determining the chromatic number of graphs: both problems are fairly easy for bipartite graphs, but harder, resp. too hard for general graphs. Now, loosely speaking, in the case of the matching for general graphs, Edmond's Blossom Shrinking algorithm essentially reduces the general case to the bipartite by temporarily removing odd cycles via shrinking them to a single node. It seems a natural questions as to whether Edmond's Blossom Shrinking algorithm could not also be adapted to yield better graph coloring algorithms, because in graph coloring, odd cycles are also the essential source of trouble. A very simple initial idea could be to remove the root-nodes (as defined here) from blossoms prior to shrinking; that would finally result in a bipartite subgraph which could be colored trivially with two colors. The further steps would be to repeat the algoritm for the subgraph induced by the temporarily removed roots and do the bicoloring with the next two available colors, until all conflicts are resolved. Question: are there already algorithms known, that are based on Blossom Shrinking and what would be the expected approximation class of such algorithms? 

At the very lowest level of modelling, one has to make some assumptions about the chosen paths, e.g. that they are the optimal ones connecting a pair of nodes. With that assumption, one obtains for each path a set of edges that defines the path; now in turn, one obtains for each edge a set of paths that contains that edge and the restriction, that the sum of flows through those paths must not be greater than the flow through the edge. For taking time-slices into account, either the edge-lengths or the driving speeds on that edge have to be adjusted to yield a transition time that equals an integral multiple of the time-slice's thickness. Now the system of equations is obtained from combinations of all shortest paths and their start-times that reach the start-node of an edge at a time, that guarantees that the edge is reached within the current time-slice. Already from that model it will be possible to check, whether a unique solution exists (which I doubt) or whether additional knowledge needs to be incorporated into the model. Such knowledge could be a characterization nodes, e.g. into homes and companies along with their working hours. It is a plausible assumption, that an employee drives to a workplace once every weekday and also drives home only once per weekday; furthermore she must start early enough to reach the workplace before the start of the working hours and can only leave after their end. So, put in a nutshell, without incorporating statistical data about a community, it will not be possible to retrieve path-data from flow-data. Some useful techniques could be vertex-splitting to model waiting times (such as work hours) and to model typical time-periods such as a weekday; that would yield the restriction that oppositely directed flows between every pair of nodes must be equal, when summed over the time-period. From an algorithmic point, time-staged flows or flows with gains and losses might be useful to know. 

the modified weight of the cutedges is calculated by solving the system of linear equations $e_{ki}+e_{kj}=P_{rs}$ $e_{jk}+e_{hk}=P_{rt}$ $e_{ik}+e_{hk}=P_{st}$ 

Remark: the number of constraints in the $LP$ formulation can be reduced on basis of the following observation: let $\mu_i$ be the mimimum of the weights of edges, that are adjacent to vertex $v_i$ (in the graph interpretation of the problem); then $\omega_i+\omega_j \le \mu_i+\mu_j$ (because of the non-negativity constraints) and edges, for which $\|e_{ij}\|\ge\mu_i+\mu_j$ trivially satisfy $\|e_{ij}\|\le\omega_i+\omega_j$ which implies, that the respective constraint need not be included in the $LP$ formulation. The impact of that reduction can be increased in some cases by subtracting from all edge weights the weight of the shortest edge and adding it to the $\omega_i'$ constituting to the solution of the modified problem. 

the problem is easily solved by calculating the crossproduct ot tangents of the ingoing and of the outgoing arc; if that vector points away from the sphere's center, then the spherical polygon is oriented counter clockwise (when looking from the outside towards the sphere's center). Another, even simpler solution of the problem is the following: under the assumption that the sphere is centered at the origin, all points on the sphere have equal distance from the origin and can also be interpreted as vectors of equal norm. Lets further assume we are given three linearly independent vectors $$u,v,w\in\mathbb{R}^3\wedge \|u\|_2=\|v\|_2=\|w\|_2$$ of equal length, then the sequence $(u,v,w)$ is left turn on the sphere (and thus indicates counter clockwise traversal) iff $$((v-u)\times(w-v))^Tv\gt0$$ 

The two lower trees are in some sense "orthogonal" to each other in that the edges of the left one "strive" for orthogonality to the boundary, whereas the edges of the right one "strive" for being parallel to the disks boundary and both trees "try" to accomplish that with "short" edges. I can imagine, that a potential use could be in the tesselation of regions for use in finite elements methods. 

and in both cases the orthogonal frames of two locations correspond to a rigid motion, which in turn can be expressed by a rotation about an angle $\alpha$ around a vector or, alternatively by a quaternion and the addition of a vector. 

Vertex Weights are a means to modify the weight of an edge by adding to it the weights of its adjacent vertices. The motivation for adding vertex weights to edge weights is two-fold: the relative order of regular spanners when sorted according to sum of (modified) edge weights is invariant under the addition of vertex weights and they give control over the topology of non-regular spanners whose sum of (modified) edge weights provides bounds on value of the optimal regular spanner. The Held-Karp lower bound for the Traveling Salesman Problem is a prominent example for the successful application of vertex weights, where objective is to determine a set of vertex weights that yields the so-called 1-tree with maximal sum of unmodified edge-lengths. The optimal values of the vertex weights are determined iteratively by increasing the weight of vertices whose degree in the calculated Minimum Spanning Tree is greater than two. 

I am especially interested in knowing the expected relative multiplicity of the leaf nodes. Results related to other kinds of regions (e.g. disks) or other point distributions would also be interesting to know. 

I just found the article "Column Reordering for Box-Constrained Integer Least Squares Problems" by Stephen Breen and Xiao-Wen Chang (available online here: $URL$ which addresses the topic of matrix reordering for Least Squares Problems, albeit for a special case. Meanwhile, I devised the following heuristic for my problem: 

It is known, that $\phi := \frac{sqrt(5)-1}{2}$, is the number, that is hardest to approximate by rationals (cf e.g. the section properties of the golden ratio $\phi$ here: $URL$ In the section Infinite continued fractions on the same WIKI page, one finds the following "explanation" of how the terms of an infinite continued fraction relate to its "degree of irrationality": 

I recently faced the problem of quickly detecting negative cycles in undirected, weighted graphs. Resorting to the Bellman-Ford Algorithm, as commonly suggested, turned out to be very inefficient and also needed some care to prevent the algorithm from ping ponging between a pair of vertices adjacent to a negative edge. Another thing about using the Bellman-Ford algorithm for detecting negative cycles is that it requires $O(n^3)$ preprocessing before it allows the detection of negative cycles, not to mention that experiments suggest, that it gets "stuck" in a single such cycle. Now my idea would be to 

I'm surprised, that the Method of Complements hasn't been mentioned yet. The trick it does, is to replace subtraction with addition and is commonly used in (mechanical) calculators, like the Curta. 

I am currently interested in minimum weight regular d-spanners (i.e. d-factors) of complete graphs. When searching the internet for related articles, I came across this one, which is concerned with that topic under the additional requirement, that the factor be connected. In it I found this statement: