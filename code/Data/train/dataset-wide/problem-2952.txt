A brief detour to consider an especially confounding optimization case—at least, historically speaking… The following instruction: has a register as its destination operand and a memory address as its source operand. On the 286 and 386, this instruction executes in 6 clocks. Had we swapped the order of the parameters, so that the memory address was the destination operand and the register was the source operand, it would execute slightly slower on the 286 (7 clocks) but slightly faster on the 386 (5 clocks). 

Notice that each column follows the truth table for an XOR operation, which basically just says that the output is 1 (true) whenever the inputs differ. That's the "exclusive" part of the OR. Eventually, while doing this preliminary research, I suspect you'd come across someone talking about how XOR operations are used to implement parity checks. Mast's answer here already spilled the beans. Parity indicates whether an integer is even or odd, and can be calculated simply by a XOR sum of the bits. Judging from your comments in the code, you already know that for a binary number, the lowest (least significant) bit determines whether it is odd or even. So the good news is that your code is almost entirely correct. If you change the s to s, it will follow the rules of the assignment and produce the correct result. Thus, you would have: 

There is one obvious reason to prefer method 2, and that is the possibility of overflow when calculating the midpoint in method 1. Adding the left and right widths together first, before dividing, risks the intermediate result of the addition overflowing the destination type. This is not a problem in the assembly code, because you're explicitly treating the values as unsigned and the semantics are well-defined. It is, however, a problem in the QBasic translation, since QBasic doesn't have unsigned types. I'm not familiar enough with the QBasic language specification to say exactly what happens in the event of an overflow, but I believe (based on what I know about its descendant language, Visual Basic) that overflow checks will be inserted after every arithmetic operation (unless you've disabled them in the compiler options, which won't exist for the interpreted-only QBasic). Specifically, instructions will conditionally jump to an error-handling routine in the event of an overflow, which will raise an Error with Basic language semantics. In addition to slowing down execution, you'll have to ensure that you either handle this error (which will slow things down more) or suffer the consequences of code that breaks in edge cases. 

To perform this iteratively, we take the bottom-up approach. We can conceptually treat our vector of integers as a sequence of sorted sub-sequences (initially of length 1, and with the possibility of the last sub-sequence being shorter than the rest). We perform a number of merge passes, merging pairs of adjacent sub-sequences: 

Now, one option is to use conditional indexing to modify . Since it's a 3 channel image (represented as 3 dimensional array), and our mask is only 1 channel (represented as 2 dimensional array) there are two possibilities: 

To me, this is asking for an iterative implementation of merge sort, and IMHO even though you made some attempt by doing 2 top level merges, you failed miserably here, as you use the standard on 25 million values. So, let's go back to how merge sort works: 

As Austin Hastings correctly pointed out, the trick is to use vectorized operations provided by numpy: 

This lacks some details, but we can assume it's text, with average 10 characters per number. At least one character being a separator, that gives us average 9 digits per number, so it seems quite safe to assume they're in range of a 32bit integer. So far so good, although your input code could have some better error handling and provide meaningful error messages when the input fails to meet your expectations. However I think you're being overly pessimistic with having to merge files -- as mentioned in another answer, 100 million 32bit integers take ~380 MiB, so it shouldn't be much of an issue fitting this along with a temporary buffer in the address space on much of current hardware. That being the case, I'd keep things simple, and stick with a 3 step process -- input, sorting, output. As such, I would expect to see at the least 3 functions, one for each of those steps. 

I did a maze thing ages ago that could support any number of dimensions, but it was very slow to generate. To get an idea of how it generally works with the multiplier and stuff, here's a gif of something I made with it: image $URL$ One thing that always bugged me was I couldn't figure out pathfinding, and I thought there'd be some cool looking intricate paths between some stuff. I asked about that (since I'm stuck at home doing nothing due to having a broken wrist), and someone suggested linked lists, so I rewrote it all, and managed to get pathfinding between two points working fairly easily. However, since I'd made the nearest neighbour check run by default, checking for collisions was a huge bottleneck. I tried to optimise it a little, by only doing the pythagoras stuff if the highest coordinate difference was within the combined size of two nodes, which did speed it up like 2x, but it was still quite slow. Someone else suggested that's what you use trees for, and since I have no idea how KD trees work (and also the list is constantly being added to), I spent a good few hours yesterday making an octree that would work in any dimension, so I could find which nodes are near to then narrow down what the collision function has to check through. The result was like 2.5x faster at 1000 nodes, but exponentially going up to like 10x faster at 8000 nodes, which I'm pretty happy with. I've just got it fully working and cleaned up now, so I'm looking for a bit of feedback on either my writing style or anything that could be improved. Also, before the line length is mentioned, I decided to do 100 instead of 80.