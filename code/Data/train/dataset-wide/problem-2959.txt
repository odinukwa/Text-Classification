When testing this with 107 integers, the statement took approx. 70% of the time. But is a highly efficient method, so all in all this is the winner. 

A property bag that communicates data back and forth between the database and object-oriented code. That's obviously it's primary role. A DDD class that encapsulates business logic, i.e. data and methods working on them (the OO principle). A DTO class that communicates between some client (UI or B2B) and the business logic. 

First, you can copy an object easily by getting it with and then -ing it to the context. Even child objects will be added: So, leaving the Id values for a moment, the core of the copying code could be nothing but: 

So what you do is the only way to get the with s and s. There are some improvements to be made though: 

What is this? This is either a copy/paste error or a major design flaw. How can a repository add itself to the it contains? And why the double(!) cast, why the ? "Smelly" is an understatement. Why is 's member internal? The repo is supposed to encapsulate a . What should other classes in the assembly do with it? If you need it to be internal, it's because of something you don't show, and which, again, would be a major design flaw. One method returns untracked entities? (), while and methods don't. That's confusing. It may be useful to have options for applying or not, but a consumer of a repository should not have to know which methods do and which don't. Either the method name should reveal it, or it should be parametrized. in its present form is a useless method. It returns ... 

Your entities have a dependency to a object that's somehow available to them. If this is one instance you may experience technical impediments when reading entities and their nested entities in one statement. But that's not the most important thing. The most important objection is that these "active" navigation properties will always give rise to the n + 1 problem: for each item you pull from the database by query, you will trigger queries to get their related data. That will certainly affect performance and it depends on the amount of data whether that's serious. This effect is aggravated by the fact that the data aren't stored into the parent entities: each time a navigation property is accessed the query is executed. There are more things to consider when it comes to reproducing Entity-Framework's (EF) behavior regarding navigation properties. EF loads entities into a context, which implements Identity Map: i.e. each database record will be represented by exactly one C# object. The benefits of this are hard to reproduce: 

Leaky as an old roof :) An abstraction is leaky if you need to know details about the concrete implementation in order to work with it properly. Leakiness of an interface may reveal itself in various ways, for example: - 

An example of the second option is an against a SQL backend. When it is executed it will emit a SQL query that returns new objects from the database (caching as applied by many ORMs aside). In that case it totally depends on what happens in whether any effect of it is persistent. If only modifies objects in its effect will be lost. If it uses objects in to change some external state (e.g. increment some sum value) its effect will persist. As a conclusion, I wouldn't do this. If you want to apply void methods to any , first materialize it to a list and then apply existing methods. Instead of... 

... is hardly ever an economical way to do querying. It fetches a complete entity from the database of which subsequently all but one property is discarded. Or, when is a lazy loaded collection, everything is discarded. In general a better way is... 

...relies on to have been loaded. If they aren't you have to rely on lazy loading. Lazy loading is supported in EF-core since version 2.1 (currently in pre-release). For lazy loading the context must be active (not disposed) when the collection is accessed. So there's a couple of things that may go wrong here: 

Note that this returns an empty string if no occurrences are found. I think that's more correct for a function that returns "everything until the nth occurrence of x". 

You may have noticed another big advantage, compared to your approach: the method returns meaningful information rather than just a boolean. I'm not even sure how you would supply feedback from your method. As you see, this is close enough to consider refactoring your own architecture, but also different enough to make this more than a trivial operation. It's more at the ground level, while your validation is in an abstraction layer. Another difference is that the EF validation is holistic: it validates an entire object graph, while your validation validates individual entities. Both have their pros and cons. With EF's validation it's harder to get validation errors for one specific entity, with your validation it's hard to validate a mixed collection of objects. 

I like to see controllers as light-weight doorways to web-independent service methods. The services have their own and execute where necessary and, thus, can be used in other applications than just MVC/Web API applications. Controllers receive services by dependency injection. 

Now if this validation is violated, it will also throw a with the custom message in . Notice that the context responsible for saving the item is wrapped in the . This is not so by default. You must override the context's method to add the context to : 

Where's the DDD going here? For the first option the code always needs to know that must have loaded and there may not be a single source of players: they may get loaded from the but also in and navigation properties. The second option is even worse: the caller is made responsible for 's proper state. In DDD you'd use a class that is guaranteed to have all data it requires to execute its methods properly. Objects of this class will be created solely by a factory that ensures their integrity. It's always safe to call their methods (Tell, don't ask). So, to summarize, it may be possible to equip EF classes for executing business logic. It mainly depends on the extend to which it can be guaranteed that the data layer produces entities in the proper state. 

As you see, the property of an entry in EF's change tracker is used to build a clone, which is always a shallow clone of mapped properties. Of course, you can't apply this method inside an entity class, because it requires a context to which the entity object is attached. But is that bad? I'd say no, because this clone method has a very specific purpose which is tied to an EF environment. To me it would break the persistence ignorance principle if a class would require knowledge of the data layer implementation for which it clones itself. 

It may be perfectly valid to combine role 1 with one or both of the other roles, as long as role 1 isn't compromised in any way. Sometimes that's a thin line, but generally the Single Responsibility Principe is a good touchstone. I can be short about combining role 1 and 3. This may be valid in simple CRUD functions, although I don't like the dependency on Json.Net in a data layer class. And who says that in each use case the same properties should be ignored? It's generally preferred to use dedicated DTOs for client traffic. The DDD role is tougher to judge. Let me focus on your example. The method... 

... EF will carry out the validation when is executed. If validation fails, a is thrown that contains a property showing the validation errors. All this happens without even implementing . If however you also implement this interface, you can add custom validations that blend seamlessly with the ones from data annotations/mappings. Here's how to do that, reducing it to the essentials: 

Of course this includes all members, active or not. And (grief), s can't be filtered. Fortunately, there are better solutions for this. The most viable one, in my opinion, is EntityFramework.DynamicFilters, by which you can define filters that will be applied any time a type is queried, also in s. A very technical, but more complete, solution is the one proposed by the EF team's product owner himself, the code and explanation of which is available here. More complete, because it also redirects deletes to setting a delete flag instead of physical deletes. Another, pretty elegant, solution, also redirecting deletes, is here. But it uses inheritance, so it may not play nice with other inheritance schemes. 

So you decide that should save the changes. It might as well have been . Using either one, it's not clear from the code that the other data are saved as well. If you surround the code by a UoW, it's clear that the UoW commits the changes transactionally. I guess this is also the piece of code that raised your question 

I think this library is a gem. One more thing: I my opinion, repositories, if you decide to use them, should be generic repositories. That means, for each entity class they do exactly the same thing. Your method doesn't belong in a repository, rather in a service (that uses repositories). 

if it's very hard (or impossible) to implement the interface with another technology stack than the one for which it was designed. Or if it perfectly exposes major features of one implementation, but would make powerful features of other implementations inaccessible. Or if it enforces a work flow that perfectly fits one implementation but forces other implementations to bend their own preferred work flow. Or If it doesn't tell the whole story, if an implementation has added core features. 

(Note that this changes your model data type.) 2. Use a projection These queries return complete entities. But in the end, you only display one field (let's ignore the fact that in reality you probably do more). So you may as well get that field only. Reducing the number of fields in a query can considerably improve performance, especially when records are wide and many joins are involved. I often see people focus on reducing the number of records, but reducing the number of fields is equally important. In your reduced example, it's enough to get only the names from the database: 

After revisiting this, I finally arrived at the best solution I could find after benchmarking a couple of alternatives: 

is an . If you join it with , i.e. without , Entity Framework will throw an exception about primitive values, which is an obscure way of telling you that it can't translate into SQL. So join in memory, i.e. with . But now all data from will be pulled into memory, which has two adverse effects: neither the reduction in numbers of records by joining with nor the reduction in width of the result set by selecting only a restricted number of properties can be translated back to the SQL query. 

(again, this changes the model type) Now you have one lean and mean query, instead of 1 + 1 + n wide queries. 

tl;dr Together with the points mentioned in the other answer, very much is very wrong. Back to the drawing board. Or back to some generic repository implementation from the internet. They're all essentially identical. 

isn't loaded and lazy loading isn't enabled: the currently active record isn't deactivated and you end up having two active records without even noticing it. isn't loaded, lazy loading is enabled, but the context is disposed. Now an is thrown, like: 

No it isn't. When the choice for Entity Framework has been made (which is good), the simplest repository is the one EF provides out of the box: the . In this case, . Any layer on top of that can be useful, but shouldn't be applied just because it seems such a good idea to implement the repository pattern. It's already there! You emphasize that the application is to be simple, so I wouldn't stack layer upon layer prematurely. The base line The only thing you really need to persist s is the part (slightly rewritten):