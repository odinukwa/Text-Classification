The "law" is Atomic Theory, which states that all of matter is built up from discrete indivisible pieces. They may not be what you or I call "atoms," for we know that we have "split the atom," but rather they use the word to describe its original intent of being indivisible. Atomic Theory is, of course, not a proven theory but rather a set of assumptions which have a history of being useful for physics and chemistry. Its profoundness is not so much that it is "true" as that it is "useful." It's also very versatile. While a modern Quantum Mechanical treatment of a photon recognizes that it does not have one specific position and one specific velocity, it does assume that you can treat the photon as a single entity with a state (typically represented as a tensor). Even in the strange world of QM, atomic theory proves useful. One major aspect of atomic theory which is important is its relationship to mathematics and set theory. If you don't assume Atomic Theory, you have to be careful not to tread beyond the realm of the set theory that is typically used as the foundation of the mathematics behind science. Modern set theory forbids a set to contain itself (there are some non-mainstream set theories which relax this rule). With Atomic Theory, it's quite easy to remain within that safe domain, because you build up from indivisible atomic elements -- a rather safe construction approach. Without Atomic Theory, you do have to pay attention to make sure you don't accidentally create a theory which depends upon sets that are not sets. (Source: personal experience and a solid 2 months of philosophizing down the drain) 

Any system gets murky once it starts talking about its own truth values, not just pragmatism. If the system is a sufficiently powerful formal language, declaring the Truth value of its statements within the system itself is impossible, as proven by Tarksi's undefinnability theorem. "Sufficiently powerful" is defined as being able to prove all of the truths in arithmetic, such as 1+1=2, and 5*4 = 20. We can consider weaker systems, but if we weaken them too much, pragmatism cannot be proven invalid. The "circular reasoning" of pragmatism can easily be short circuited and turned into a recursive series of systems with a boundless number of iterations. Without laws of arithmetic that handle boundless series, it can be markedly hard to disprove the value of pragmatism. This leaves informal systems. It is not clear whether it is possible to prove that two individuals have the same interpretation of an informal system or not. Obviously if interpretations differ, truth values can differ. All of this suggests that pragmatism can never claim to have the one and only answer for every question. However, pragmatically speaking, there are many series of iterations on words which we are generally comfortable having a mathematical limit as to how much misinterpreration can be had. Pragmatically, a realizable system which has a limit pointing towards the behaviors you want to see is more useful than an unrealizable idealized system which has the behavior you want to see. 

Formal reasoning is powerful for two reasons. The first is the simplest to see: it is easily conveyed in a highly objective manner. When trying to discuss things which must be true for all, the more objective the better. The second advantage of formal reasoning is that it can be written using formal languages. This permits the fascinating ability to discuss the validity of a claim through symbol manipulation alone. People can agree that a particular set of symbol manipulations correspond to true semantic meaning, and then determine if the semantic meaning is valid merely by looking at the symbols. My favorite example of where this can be useful is the handling of infinity in mathematics vs. the handling of infinity in Pascal's Wager. The rules of set theory permit a very specific set of behaviors for infinite values, such as the cardinality of the set of all natural numbers. It states that the cardinality of the set of natural numbers is fundamentally smaller than the cardinality of the set of real numbers. Contrast that with Pascal's wager, where Pascal effectively argues that since one infinity appeared in the equation, it clearly had to dominate. It is now trivial to develop mathematical arguments for or against Pascal's wager, using various infinities. It is trivial to discuss maximizing value in the wager by taking the derivative of value and applying l'Hopital's rule (itself a wedging of two infinities against eachother). The only reason these are trivial is because their definitions and proofs are so rigorous that we accept them as valid even if the situation is absurd. The limit to what formal languages can do was explored by Tarski. You are correct in being bothered that people don't want to discuss why formal reasoning is so important. Tarski demonstrated that the semantics of a formal language must be defined in a metalanguage, suggesting eventually you arrive at a non-formal language to describe how to interpret all the formal languages. However, despite this shortcoming, there is still value in them. They permit arguments like "either you must accept this formal reasoning, or you must come up with your own explanation of why 2+3=5 without using the Peano axioms at the basis of modern math." 

Most of the Zeno-like paradoxes involve an infinite sequence of events buried in the language used in the problem. Your example appears to go down the path of doubling the distance between the lines enough times to achieve the desired separation, while Zeno's original paradox depends on halving the distance. In both cases, the tricky part is coming up with a language to describe the problem which is capable of describing this infinite series of steps without contradiction. The problematic portion is typically identifiable with an appeal to reason, such as your "... it seems we cannot create..." It is dependent on the listener agreeing with such a statement. If they agree with that statement, then typically they agree that the problem is paradoxical, and thus there must be something wrong. If one's listener does not automatically agree with you about this statement, one must defend it. Defending it is where the really precise language often comes into play. Mathematics, for instance, has a extraordinarily precise ways of dealing with the concept of infinity, and prides itself on its self-consistency. If one phrases the problem in the language of mathematics, then one can use the strength of mathematics to argue for their position. However, the current "preferred" solution to Zeno's paradox is calculus. Calculus handles these infinities in a way that appears to be consistent with the world we live in without causing paradoxes from self-consistency issues. If your efforts to phrase the question in mathematical terms leads you to use notations from calculus, one will find that the issue is dealt with by the handling of limits which elide away issues that might come up regarding infinitesimals. These methods have been heavily analyzed over the years, so lead people to have a great deal of confidence in answers derived from them. In my opinion, your Zeno-like argument is going down a direction which would be proven using set theory. There are systems for handling sets like ZFC which one would be tempted to use, but your particular construction is likely to go down the path of having an infinite descending set, which is forbidden in ZFC by the axiom of regularity. One would need to look at different solutions, such as Quine atoms which are used in some non-well-founded set theories. Such set theories are much less popular than their well-founded brethren, so they do not encourage the same level of confidence. 

I believe that your definition is rational, both for its use on machines and humans. The difference between machines and humans seems to work its way down to the organization of a machine versus the organization of a human. However, I think the defining difference between organic intelligence and mechanical intelligence at our current level of technology its its flexibility. A machine is very good at a small set of tasks, while a human is very diverse in his or her talents. Consider the edge cases. A person who seems to "only be good for one thing" often picks up wordings usually associated with machines. A machine which seems to be highly adaptable often picks up wordings associated with humans. I believe the implementation reason for machines being good at a small set of tasks stems from the human need to be able to program them. To a non-developer or non-engineer, the capabilities of a smartphone are magic, and perhaps worth of being given human traits, such as a name. However, they are in a society with a bunch of developers and engineers who tell them "its only a machine. I can see how it is built." The developers and engineers can see the CPUs and the memory and the caches and so on. They can see that, while the smartphone appears tremendously flexible, it is actually quite set in its ways. They then proceed to demonstrate their ability to force the smartphone to do exactly what they want, demonstrating that they can predict how the machine will respond to stimulus. With organics, it is much more difficult to draw clean lines to divide an entity into blocks. Every time we do (such as dividing a body into muscles, brains, hearts, etc), we find the inter-connectivity between these is so complicated that we can't demonstrate an ability to predict how the body will respond to stimulus. Consider how many times we have been told "doing X is healthy," only to find out a decade later that it was actually unhealthy, we simply didn't understand the human body well enough. Consider that we can model the brain and say "our sense of hearing is here," and then find a model of a person who underwent a stroke, whose brain has completely remapped their sense of hearing elsewhere. We really have a hard time predicting what an organic living creature will do. On the border between these is the field of Artificial Intelligence. We have tools such as neural networks where even the masters teaching them say "We know why they work, statistically, but we can't look at a neural net and say 'here is why it solves the problem.'" Another major issue for machine intelligence is that machines can be stopped, and their internal state examined. We can stop them because we made them that way. We can take an AI, and clone it, without worrying about any moral implications. However, as we make devices which try to run faster and faster, we're going to have to eventually stop making them easy to stop and examine. Consider an AI which runs on one of IBM's new neural chips. Consider a chip where they make the neurons so slow that each one is a little imperfect. An AI which runs on a given chip may not be clonable to another chip because the AI took advantage of those imperfections. Or consider an AI running on a chip that handles signals so blazing fast that there is no way to stop it mid-process and examine its state. 

This site is not a place for personal philosophy, so in theory asking people to poke holes in their theology is out of scope. However, I see some issues with how the argument is presented which I think could prove valuable to others, so I choose to answer rather than vote to close the question. I think there's value in having examples of how to look at the structure of an argument, while not explicitly agreeing or disagreeing with the outcome. The primary issue I see is how hard it is to find a conclusion. You list 5 very substantial givens. Then the body of the argument consists mostly of defenses of the givens. The only statement I could find in the body of the argument that wasn't a defense of a given was "Hell, being defined as the complete opposite of Gods attributes, would be the right place to send those who do not follow to the perfect process." I can only presume that was the conclusion. You also have several unstated givens. These are things which you assumed, but chose not to enumerate as givens. 

One approach would say yes. Consider a brain that has some noise factor to it. If there is any structure to the brain (which is true for most brains), that structure will color the noise. If one divides the brain into two sections, an inner part and an outer part, we can re-frame the brain-in-a-vat. If we treat the inner part as the "brain" and the outer part as a "vat," we now have sensory input and the ability for output, and the brain may seek to make sense of this outer vat. We have now returns to the traditional brain-in-a-vat puzzle, with sensory input. Of course, this came with the assumption that the brain had structure in a form which facilitates drawing such a boundary. 

I think the limit you're running into is the idea the you either believe in something or you don't. Its trivial to show countless examples where that is insufficient. One approach you could take to reconciling this is to create a tiered system of belief. This would still be an approximation, but it could be enough of a model to help. For a predicate P: 

With poetically similar language such as "destroyer of hope" and "bringer of hopelessness" or "taking hope" vs. "destroying hope", the semantics are typically not obvious. One needs to look at the surrounding context to determine what those phrases mean. However, there are general patterns which do occur in English speech that can be useful. One key aspect is the concept of action. "Destroyer of hope" is an active phrasing which typically indicates an individual who seeks out hope and actively tries to destroy it. A "bringer of hopelessness" is more of a passive phrasing which typically indicates an individual who inspires hopelessness around them, but isn't necessarily actively trying to seek out hope to destroy. If anything, one might say that the cultivate hopelessness, and permit that hopelessness to counteract what hope it finds. Again, this is not a 100% semantic rule, but it is a trend that I find tends to lead an author to choose one phrasing or the other. In the end, both may result in a loss of hope, but the way they cause that loss of hope is different and that is often conveyed by such phrasings. When facing a "destroyer of X," one might rationalize that it's a good idea to hide your X, so that the destroyer cannot find it. When facing a "bringer of not(X)," its usually encouraged to feed your X and make it shine brightly to overcome the miasma of not(X) that surrounds the bringer. "Taking" vs. "destroying" on the other hand, has a more clearcut difference. Taking is an action that obeys conservation. If an individual takes X from you, you no longer have X and they now do have X. The concept of "taking back X" becomes meaningful to talk about. A destroyer does not try to conserve. If an individual destroys your X, you no longer have X and they also do not have X. There's no equivalent meaning of "destroying back X" which could be applied, although the idea of doing that starts to enter the realm of punitive measures as you find some equivalent of X that they have, perhaps X', so that you can say "you destroyed X, so I will destroy X' ". 

A question like this explores the definition of "lucky." One definition of lucky is buried in statistics. One could define lucky based on the P-value of the events that occur around them. P-values look at the probability of a more extreme event occurring. By this definition of lucky, he would still remain "lucky." However, when exploring "lucky" in a non-mathematical sense, we often associate the desirability of the results with how lucky or unlucky we are. Having a freak event destroy one's life is typically not considered lucky. Consider Cassandra. She could pick the correct card, for she can see the future. Cassandra can always predict the future perfectly. It was a gift from Apollo before their marriage day. After she jilted him, he adjusted the gift. She can still predict the future perfectly, but now nobody will believe her. She must go around knowing every catastrophe that will ever happen, but be completely impotent to do anything about it? Is she lucky?