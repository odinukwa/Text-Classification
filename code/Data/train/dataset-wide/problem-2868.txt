Combining all of this with your original code results in something like the below; there are still some opportunities to improve things even further (for example, code duplication exists in the and methods that might be worth refactoring into a separate method (especially if one were to add more robust logic). 

If you're going to spend the time abstracting things then you probably want to invest some effort in refactoring a lot of your common logic into helper functions. Starting with the very first issue, a hard-coded connection string, we can create a function that'll build one out of components: 

Updates: I have refactored class based on a combination of all of the feedback here, on the linked question, and a lot of benchmark results. The current implementation has been split into and and drastically simplified from the original; a change I didn't like when first suggested to me but experimentation proved it to be superior in the end. The compile-time safety suggestions ended up being ignored simply because the original requirement was for based access and one can always add such a helper via a simple extension. Now, about performance. I was quite surprised when I loaded everything up and learned that @MarcGravell's implementation was roughly 4x faster than my own; I knew he'd win but I was shamed to lose THAT badly. It turns out that there were a lot of little details that were getting in the way. I believed that one huge advantage he might have is that he's emitting IL to build a delegate while I was using expressions and so I spent the time figuring out how to emit the IL I needed. The problem? Once finished I only gained maybe 5 ns, he was beating me by at least 20 times that amount! This is when I learned that the slowest part of the entire process is not executing the delegate but extracting it from the cache. I was using and wow is it slow! Really slow, even calling is at least 3 times slower than the normal class. Don't just take my word for it either as others have documented the same experience and I suppose it's not surprising giving the promises that the class has to fulfill. What surprised me more however is that itself is quite slow when compared to the pattern of . Anyways, I was able to refine enough edges and end up with a property accessor that is consistently 3ns or so faster than FastMember. If my math and analysis of our code is correct then this delta is purely a result of the fact that he has a cast to in his IL and I do not. The cast to object allows him to have a single point of entry and exit via a lovely indexer which I was forced to leave out because I wasn't clever enough to find a way to have my cake and eat it too. Benchmark Results: 

I believe one can avoid the bias problem by generating a random float between [0..1) and then normalizing the value between x and y instead of clamping: 

One could get doubles for RGB by using a provider that returns at least 24 bits (such as ) combined with some altered sampling logic: 

Edit: Dunno what PCG is and don't want to read the paper? Maybe this video of Melissa O'Neill (the author) explaining things will be palatable instead. Original: I attempted to answer this question last week and was thrown off when someone mentioned in a comment that my method would show bias. Eager to prove the naysayer wrong I discovered that things were even worse than he suggested as certain ranges will cause things to break down entirely. So I decided to start from scratch, do some more research, and try again. Performance was also much more important to me this time around so I decided to try and find a way to avoid calling to generate every single value. Eventually I settled on PCG as an appropriate modern algorithm. Floating point math has also been entirely avoided while working with integers in order to avoid the sorts of issues I encountered in my previous attempts. Looking for potential ways to speed things up or simplify the code; the branch statements bother me quite a bit but can't envision a better way to include the full range of values without them (the upper bound cannot be generated by the method). Haven't been able to find any bugs so far but that doesn't mean they're not lurking either... 

Most of your code is just repeating the same instructions over and over again. Define arrays newStats, deltas, and statMinimums, and your entire LOSSES block can be collapsed into one line of code: However, before you try to figure out how to implement what you want, you need to clearly define what it is that you want. What exactly do you want as far as the distribution of stat changes? There are several different methods, depending on what distribution you want. For instance, if there are n stats, you can: 

This turns any number from 0 to 99 to words, no recursion. It can easily be extended to -999 to 999, and a little more work would get it to, say, -10^33 to 10^33. 

If something is called "RiemannSum", then it should return a sum. If you want summation to be a separate method, a better term would be "partition"; you could do RiemannPartition.sum(), for instance. Several other variable names are bit unintuitive to me (e.g. rectangles, index). You can eliminate several lines by doing: 

There is no n given in this problem. The n in O(n) isn't just some dummy variable; it refers to an actual parameter in the problem space. Saying "the complexity is O(n)", when you haven't said what n is, is meaningless. Every time you move the window, all but one element is already sorted. You can do a binary search to find where to insert the new element, giving O(log(D)) complexity. For D = 4, that won't save much time and probably isn't worth the overhead, but for large D it would be a significant savings. 

I found that the time taken varied a bit, which is odd since this should be deterministic, but on average this took about half as much time as @Eric Duminil 's solution. 

There was a previous question that I answered regarding Tic-Tac-Toe that I'm too lazy to look up, but this is a common enough subject (as you are apparently aware, there's even a tag for it) that you might want to take a look at other questions and see what applies to your program. Taking a broader look than the other answers to your question, why are you even checking for a win in the first place? If your program is running this function after every move, that's horribly wasteful. All you have to do is check whether the new move creates a win. You only have to check the lines the new move is in, and you only have to check two locations for each line (you know that wherever the current player just moved has their symbol in it, by definition). Also, any time you have , you don't need an ; if the first is satisfied you won't reach the rest anyway. 

If the number is n nines, then the next number should be n+1 ones Otherwise: a) find the first digit that's smaller than the one before it. If there are no such numbers, use the first digit. b) add one to that digit c)replace every digit after that one with ones. 

Putting an function inside a list comprehension seems a bit iffy to me, especially since you don't seem to close it anywhere. List comprehensions are generally better than for loops. The name is a bit misleading, as it's the filename, not the file object. So alternative code would be: 

Since each element can be put in p1 or p2, there are two options for each element, giving a total of 2n different options. Since you are avoiding the cases where p1 or p2 are empty, it's 2n-2, which is twice the Stirling Number of the Second Kind (you're double counting since the Sterling number is based on p1 and p2 being indistinguishable). Since Big O ignores adding or subtracting constants, it's simpler to just give the complexity in terms of 2n rather than putting it in term of Sterling Numbers. And as @Peter Taylor points out, you are looking only at the number of iterations, and ignoring the complexity within an iteration. You can avoid most of the double-counting by taking combinations up to n//2. Anything past that will be just a partition you've already gotten with p1 and p2 swapped. At i == n//2, you will be double-counting, so you can use @Peter Taylor's suggestion and set aside one element and then add it back in to a fixed partition.