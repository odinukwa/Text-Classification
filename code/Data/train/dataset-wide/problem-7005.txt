A very famous study in this direction is Card and Krueger (1994). They look an increase in the minimum wage in New Jersey in 1992. While New Jersey raised the minimum wage from USD 4.25/h to USD 5.05/h, the minimum wages remained at $4.25 in adjacent Pennsylvania. You should have a look at the subsequent research. 

What do you mean by "what is the difference"? Please clarify. These are just different production functions. Suppose there are two different inputs $A$ and $B$. The Cobb-Douglas production function is given by $$A^\alpha B^\beta.$$ You may think of $A$ and $B$ as capital and labor. The Leontief production function is given by $$\min \{ A, B\}.$$ You may think of $A$ and $B$ as number of left and right shoes. If you have 7 left shoes and 3 right shoes, you have 3 pairs of shoes. Or let $A$ be "number of wheels divided by four and rounded down" and let $B$ be "number of car bodies" such that you can produce 5 cars with 7 car bodies and 21 wheels. 

I am not exactly sure what you mean by "block price" and I don't know the bucket buddy. However, I feel like you are talking about what microeconomists term bundling, the practice of selling two (or more) different goods together in one package. Interestingly, bundling can be profitable even without any production-cost related efficiency arguments. It can serve as a tool to sort consumer types and thus can be used to price-discriminate. The classical paper on bundling by a monopolist is McAfee, McMillan and Whinston (1989). For an introductory treatment of the topic read, e.g., Belleflamme and Peitz, Chapter 11 - or the corresponding chapter of basically any other textbook on industrial organization or microeconomics. 

In theory, the answer is yes. In practice, the answer is no, because it is computationally intractable. My take-away from talking to computer scientists was that determining a winner and computing the transfers are NP-hard problems. See, e.g., this write-up by Kirk Pruhs. 

The field that considers settings like the one you propose is called revenue (or yield) management. Since the airline deregulation act (1978), this field has become more and more important - also for other industries. Check Chapter 4.5 "Substitutable Capacity" in Talluri and van Ryzin for input on your problem. What exactly happens in equilibrium depends on the setup. Are there more than 200 consumers? Do they arrive over time or are they present from the beginning? Do all consumers have the same valuations? Are consumers strategic? Myopic? There are many details that potentially drive the model. Note that the Coase conjecture relies on the assumption that the good is not scarce (less than 200 consumers or additional airplane seats can be produced). If that is what you have in mind, consider this (recent and unpublished, but interesting) paper. 

I do not want to do all the algebra, but I give you a hint. You are correct: You are asked about $\pi^C$ in your Condition (1) and you are also right that $\pi^D$ changes. In your parameter setting with $c=0$: $$\pi^C := \pi (q^C, q^C) = (1- 2 q^C) q^C,$$ where $q^C$ is the quantity they coordinate on. Then $\pi^D$ is the profit from best-responding to $q^C$ with some $q^D$: $$ \pi^D := \pi (q^D, q^C) = (1- q^C-q^D)q^D,$$ i.e., $q^D = \arg max \quad \pi^D$. Now you solve $q^D$ as a function of $q^C$ and plug that into $\pi^D$. Having Condition (1) hold with equality gives you some $q^C$ that you can plug into $\pi^C$ again. 

The difference between signaling and screening stems from the fundamental difference in bargaining power- who offers the contract for which her utility is the highest. While in screening the uniformed party proposes the contracts, in signaling it is the informed party. For your general conjecture, I refer to Stiglitz and Weiss (1990): "Sorting Out the Differences Between Signaling and Screening Models": 

I don't know the paper, but I can make a general point. In behavioral economics, agents do not arrive at their optimal choice by maximizing a standard expected utility function. They may maximize some function with other characteristics or, alternatively, they use heuristics to make choices. That is, they may end up with a choice that is not optimal in terms of "objective" expected utility. This paper uses this objective expected utility as welfare criterion - with the true probabilities and true outcomes, not the perceived probability weights or perceived outcomes that led to the choice of the agent. The argument behind this approach is that although the agent makes choices according to a perceived world, he experiences utility in the true world. Therefore, instead of using the expected utility perceived when making the choice as a welfare measure, it makes sense to use the "objective" expectation of the objectively experienced utility. I interpret the footnote without having read the paper: The agent uses subjective probability weights to make choices and incurs 'thinking costs'. The welfare measure ignores these thinking costs. 

There is no such function. The reason is that time itself is not really driving house prices at all. Time can be used as a proxy: An older house is more likely to be designed in a way that was modern at the time of construction and has outdated technical standards (heating etc.), which influences the price; Usually economies face inflation, so the nominal price at the time of purchase is likely to be lower; An older house is more likely to cost more in terms of renovation; An older house may have been build in a location that by now turned out to be great resulting in a value increase, but it could have gone the other way too; and so on. The relationship between time and value depends on the underlying characteristics of the house. To estimate the evolution of your house price you need to give much more information. To illustrate, consider two houses build at the same time. House A is small, House B is huge. House A in Aleppo, House B is in cental Tokyo. I think you see the point. Just considering time does not seem to be a smart idea to determine the value of a house. 

First of all, the general form of the problem you got there is extremely demanding. In multidimensional screening problems, analytically often all hell breaks loose in a sense that it is just not tractable. One way out might be this recent approach by Gabriel Carrol: Robustness and Separation in Multidimensional Screening (also provides an introduction that hints at the intractibility of the problem). Coming back to your question: $(2)$ does not imply $(1)$, because $(2)$ only depends on $f$ and you can add a transfer rule that is not IC. As a counterexample, consider a single good, $m=1$. Take some strictly IC mechanism, $(f, p)$ and consider two types, $t$ and $t'$. So, $(1)$ is $$U(t):= f(t)t - p(t) > f(t')t - p(t')\\ U(t'):= f(t')t' - p(t')> f(t)t' - p(t)$$ and by construction $(2)$ holds as well. Let $t'>t$ and a lager allocation probability $f(t') > f(t)$ is accompanied by a larger expected transfer, $p(t') > p(t)$ - otherwise $t$ would love to fake being $t'$. Now, construct $\widetilde{f}(s) = f(s)$ for all $s\in T$ and let $\widetilde p (t)= p(t')$ and $\widetilde p (t')= p(t)$. Since $(2)$ only depends on the allocation function $f$ and these functions are the same in both mechanisms, $(2)$ holds for $(\widetilde{f}, \widetilde{p})$. Obviously, $(1)$ is violated for the reason named above: $$\widetilde f (t') t - \widetilde p(t') > \widetilde f (t) t - \widetilde p(t).$$ To address your other problem (in your comment), use the integral formulation of expected utility. Rewriting $(1)$ yields, $$f( t)(t-t'))\geq U(t) - U(t') \geq f (t' )(t-t')$$ implying that $U$ is Lipschitz continuous, implying $U$ is differentiable a.e., and equals the integral over its derivative: $$U (t) = U(\underline t) + \int_{\underline t}^t f(s) ds$$ where $\underline t$ is the lowest possible type. Then, you rewrite, $$f (t) t - p(t) = U(\underline t) + \int_{\underline t}^t f(s) ds \\ f (t) t - U(\underline t) - \int_{\underline t}^t f(s) ds = p(t).$$ Suppose $\underline t=0$, then $$p(t) = p(0) + f(t)t - \int_{0}^t f(s) ds.$$ This implies the revenue equivalence theorem: If two auctions have the same allocation rule, payment functions (and thus revenue) can only differ by a constant. The same trick works for multi-unit auctions with multi-unit demand, see, e.g., Krishna, Ch 14. 

I am aware of classic models such as Kreps & Scheinkman (1983). I am also aware of Burdett, Shi & Wright (2001), but note that their buyers are ex-post symmetric as both of them have value $v_i=v=1$. I am also aware of the literature on competing auctioneers, e.g., Peters & Severinov (1997) and Virag (2010). The buyers' equilibrium selection strategy in such models is quite cool: If sellers post second-price auctions with reserve prices $r_1>r_2$, buyers of value $v<r_2$ abstain from buying, buyers of value $v \in [r_2,x]$ visit low-price seller 2 with certainty and buyers of value $v>x$ visit each seller with probability $1/2$. One can solve for this cutoff value $x>r_1$. Under a condition on the lower bound of $F$, there is indeed an equilibrium in which both sellers set the same reserve price (which is below the lowest possible buyer value). Knowing this, one can write down an underlying wasteful costly rationing process that essentially replicates the buyers' selection equilibrium above. However, I find this a little far fetched. Any other approaches? As I said, this is not my literature - I just find the problem too basic to be neglected. 

I suggest John von Neumann and Oskar Morgenstern as obvious candidates - for the fundation of expected utility. Read the Wikipedia page and the references therein as a start. EDIT: I think with vNM it got serious, but you can go back even further. The earliest reference that comes to my mind would be Jevons' book "A General Mathematical Theory of Political Economy" from 1862. 

A "part" of an extensive form game that is not a proper subgame because it does not start at a single node but an entire information set would be called "continuation game". This terminology is fairly standard (Perfect Bayesian Equilibrium). However, I think what you are after is a stochastic game which consists of several states. Each state corresponds to a different game. In your example there would be two states: One state for each player $i\in\{1,2\}$ being the Stackelberg leader. Then you also need a transition process that maps the period-1 state and the period-1 action profile into a probability distribution over period-2 states. You then find equilibria for all state games in period 2 and proceed to solve for equilibria in period 1 with the corresponding (probability-weighted sum of) continuation payoffs. 

I found "Contract Theory" by Patrick Bolton and Mathias Dewatripont to be a very nice and thorough book. It, however, might be too advanced, although you can skip the formalism and just read the intuitions provided. Let me quote how the book is advertised: 

The Gini coefficient is defined as the normalized Gini index. If $G$ is the Gini index, $0 \leq G \leq \frac{n-1}{n}$. The Gini coefficient $G^* = \frac{n}{n-1} G$ is a normalization such that $0\leq G^* \leq 1$. That way you can easier compare different populations with different $n$. In your example it should be that $G= 3/10$ and then $G^*=6/10=3/5$. 

It has nothing to do with refinements such as the intuitive criterion, divinity and so on. These refinements are useful to "refine away unreasonable equilibria". Here, the issue is that the set of PBE is potentially quite rich while some equilibria rely on "unreasonable beliefs". The refinements formalize which of those beliefs are "unreasonable". If you are interested, you can also look at settings that combine signaling and screening. This is the literature on informed principals, initiated by Myerson and Maskin & Tirole (1990, 1992). The informed principal first offers a contract to screen the agent while the contract proposal itself may reveal private information of the principal. 

Not a big fan of solving homework questions, but here is a hint: Suppose you are selling the lottery for price $P$. Then your wealth would be $Y'=10+P$. You are looking for the minimum price $P$ such that $$U(10+P) \geq \pi U(10+10)+(1-\pi)U(10+5).$$ 

You can first find all NE. Then you check which ones are subgame-perfect. Then you proceed and check for which of the NE you can find beliefs that are consistent with the definition of PBE. You can go on and refine the set of equilibria further by kicking out all equilibria that do not satisfy the additional requirements of your stricter equilibrium concept. If by "backward induction" you mean solving the game backwards subgame-by-subgame, then by definition you find all the SPNE (= all NE in which the equilibrium strategy profile also constitutes NE in all subgames). 

My question seems to be a basic one and there should be a rather well-known reference in the (IO or labor) search literature. I will upvote (and comment on) any relevant answer and I will accept an answer pointing to a reference addressing exactly the model below. In the simplest case, consider the following model: There are 2 sellers ($j \in \{1,2\}$) and each seller offers a single good. In stage 1, both sellers set an individual price $p_j$. There are 2 buyers ($i \in \{1,2\}$) who are privately informed about their valuation $v_i$ which is an iid draw from some distribution $F$. In stage 2, buyers observe the prices and decide which seller (if any) they want to visit. Buyers have single-unit demand. Buyer $i$'s payoff is $v_i - p_j$ if they got a good and zero if they got rationed or did not visit any seller. Sellers do not have opportunity costs (and cannot produce additional goods), so their payoff is $p_j$ if they trade. A guess for a reasonable equilibrium candidate: In equilibrium, both sellers post the same price $p_1=p_2=p$, buyers with $v_i<p$ abstain from buying and high-value buyers ($v_i\geq p$) randomize equally over both sellers. To evaluate deviations, it matters what happens when. say, $p_1 > p_2$. Of course this depends on the rationing function, i.e., what happens when two buyers show up at the same seller. Fixing a certain form of rationing (random rationing, efficient rationing, introducing an underlying model in which sellers have additional preferences over customers, etc), one can express the expected utility from visiting each seller in a reduced form and solve. Now I guess my question is: How is this done in the literature (which I find interesting, but don't know much of)? I am happy about references and suggestions and I will provide some myself. 

Your intuition is right, but you are not accounting for fixed costs. The supply curve is the part of the marginal cost curve above its intersection with the average variable cost curve. Marginal costs are defined as the derivative of the cost function (or the variable cost function as the derivative of fixed cost is zero). To get the area you integrate. That is, you get back the variable cost. So the area below the supply curve between $a$ and $b$ is the difference of the variable costs.