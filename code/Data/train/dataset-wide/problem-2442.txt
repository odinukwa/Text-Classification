The last one depending on the itertools.pairwise recipe, which returns all pairs of nodes from the start through end. Do however note, that neither of these methods are tested for efficiency or speed, but are mostly presented as alternate methods on how to do the check whether all the values are in sorted order which seems to the criteria for a binary search tree. 

PS: Code given here is not meant for a new review (that would have been a new post), it is more for a future reference if someone wants to extend this screensaver. Maybe you would want to add new walkers and let them all connect? 

2nd addition: New method Here is some code doing the latter variant of checking whether the last move was a win. I have not implemented any of the other stuff I mentioned, just added this one method (and if I'd change the entire class, then the would have been made a class variable). 

Note that in the temporary table select I chosen a given date, instead of ordering by date (which most likely would throw of the id part quite easily. Another option could be to specify a double order like in . Untested version translated into php-code: 

Of course, this does return mostly the same as your function returns, but it does return some of the basic cases like "0π/1" or "1π/3". These could be handled using some ternary operations, which leads us back to code similar to your original code (but without exposing the calculations, and with compression (not reduction) of test cases): 

To conclude, your code does follow proper indentation, is a little lacking in space around operators, but the main issue is bad naming and unclear intentions of the various code blocks. There is some magic happening in this code, which could benefit from clear comments sprinkled out in the code. 

I kind of prefer building the array, as that allows me easily to change output variants. But you could also opt for using directly, which would eliminate the need for the entire table. I did however removing the original and included that directly in the foreach, as I try to keep intermediary variables to a minimum. PS! Depending on font settings and encoding elsewhere, you could consider calling in addition before using in the URL. 

I don't see the reasoning for building all the intermediate arrays of articles and authors and stuff. I'm also not sure whether to use a full matrix for the result matrix is the best option. Most likely this matrix would be a very sparse matrix, so to avoid large memory usage you could opt for data structures allowing for sparse matrixes (or possibly use a hashed array where the key is the coordinates. Here is a pseudo-code version for looping through the article set once, the author set once with a double for-loop based on author id's afterwards. 

Here we let the Formatter handle the formatting issue, and it does indeed look nicer! And we don't need to make sure the random number is above the legal range, as the formatter handles it. 

Notice there is an extraneous output within the version. using div and mod I then ventured on to test how the integer version could be implemented using div and mod, and ended up with the following version: 

I've given no code in this answer, but I think you're getting the ideas. One comment though on chosen algorithm, is that you calculate the value when on the correct depth, but you don't actually use it before you've traversed all child trees and then hit the end parenthesis.This isn't a problem in the current specification, but if it changed to sum up all values on multiple depths, it would fail miserably. My final comment, is that your code does look clean and tidy with good names. If I'd change anything I would possibly add a little more vertical space, and some comments as to what the method is doing. 

Your code does loop 700 000 multiplied by 65 000 multiplied by the number of elements in each cluster. That is a lot of iterations, and not very useful. The better approach would be to read the smaller file into memory, and then read the larger file line by line. In addition as you iterate over each row in the smaller file, matching each of the keys, it makes sense to switch from a dict with as key, and the different keys as values, to actually using the keys as keys, and list all the clusters it belongs to. This approach would leave the lower memory footprint, but should be rather efficient to work with. Here is some code to start you off with. You might need to adjust a little related to splitting on space or tabs, but I get your wanted output using this. 

So this is not the typical code review, as the code in question is pretty basic in terms of what it does. It is a given algorithm, and you need to do the given operations. The one possible varying factor is the lines. Can this affects times? Let us test the random generation of some numbers using various random generators: 

The code looks OK. Linq can be somewhat tricky to debug, as there is some magic happening behind the scenes. In my world that still doesn't warrant to rebuild it into somehting else just for debugging for a random case which you don't experience just now. Don't worry too much for problems which hasn't occured yet. Some say that worrying beforehand is double trouble. Firstly you worry before you've got a reason to worry, which is unneccessary. Then secondly, if you don't experience the problem, you've worried without a cause, and if it actually happens you get to worry all over again. In short, don't worry until it happens. That does not say that you shouldn't write readable and maintable code, with good tests to test the various cases which might trigger variants of your query. I.e. you should make tests with various counts of parameters, to possibly trigger the RDBMS/database driver. A test destined to fail in a predictable manner, can still be a good test. And you should have tests displaying that the partioning is working as you expect. 

Avoiding the rebuild You're in a class, and a class can have a constructor. Utilize this to build the needed . And instead of having a rather costly I would advice in this case duplicate the reverse map, as well. (Another option would be to use some external library to implement some bidirectional map, like the BiMap from the Guava library). This would lead to code resembling this untested code: 

Whether it is worth it for such a simple case, is a matter of taste, but at least the trick to simplify the vs is a neat trick, and my first code example is a little gentler to my eye. You could also opt for a not so readable, but shorter solution like: 

Notice the trickery using to make that a groupable version of something which might vary just a little. Due to the same reason I also removed the from the column list. Given that I haven't made any stupid typos, this SQL should provide you the sums you are asking for in a simpler statement. 

First of all a style comment: Please use longer descriptive names. Stuff like , , is just ugly, and confusing. You could simplify your query either by using subqueries in the clause, or by creating a temporary table in the clause. You could use the operator, but some think as it is somewhat unclear from the wording whether the range is inclusive or exclusive. In addition if used on date fields, you could have various interesting rounding errors. So it better to stick with ordinary operators. I've commented upon the fact that you'll have a potential issue related to order, and I haven't compensated for that in the following code, only assuming that rows are indeed ordered by . This could/should possibly be enforced. Here is the SQL code to get your rows in one go: 

Regarding questions The anything else part I've already covered up top, and I don't know the package. Whether it is OOP enough? Well, I kind of dislike the amount of work done within the constructor. To me most constructors should do a minimum of work getting ready to answer requests. I would therefore rather have another method like or something similar with an optional clearing of previous result. This would allow for doing subsequent finds and copies from multiple directories. It might require some extra information regarding root in the result map. In chat there has been talked about allowing for partial searches, and that sounds like a good extension. Getting multiple files out of your function could also be nice.