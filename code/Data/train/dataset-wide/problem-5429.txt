Christof expresses an ultimately nihilistic position, even so his answer starts with a denial of nihilism: "You were real. That’s what made you so good to watch." Some forms of nihilism such as existential nihilism can be associated with certain school of thought, but Christof's position doesn't belong to one of these forms. I'd rather think that when nihilistic philosophers discuss similar positions, they try to explain what is problematic about them. Nihilistic positions can arise from a critique of prevalent unfounded positions, like Matthew 7: 

Common to all three position is a strong commitment to the existence of mathematical objects and to the falsifiable consequences of that existence. These strong forms of idealism have actually been falsified theoretically and practically by progress on the foundations of mathematics and the tremendous success of abstract mathematics. (But the strong forms of formalism have also been falsified.) You might want to consider some potential commitments related to strong forms of mathematical idealism: Foundations of mathematics are neither necessary nor possible. Axioms have to be intuitively true, like Euclid's axioms for geometry. Mathematical object are at least as real as any object in the physical world. The question of whether objects like zero, infinity, square root of two, or square root of minus one actually exist is non-trivial and must be answered for each of these objects separately. Note The above description is neither historically correct nor does it give full justice to the corresponding positions. However, I preferred to give a description of idealistic positions which still includes its rough edges, as a contrast to the "why should we care" position of fictionalism. 

But Descartes was a philosopher, not a mad man. So it seems more appropriate to compare his instructions with teachings of other great philosophers like Socrate. He also made statements about himself, like: "As for me, all I know is that I know nothing, for when I don't know what justice is, I'll hardly know whether it is a kind of virtue or not, or whether a person who has it is happy or unhappy." We may assume that Socrate himself knew whether this assertion was true or false. The more interesting question is whether his discussion partners could know whether this statement was true or false. In fact, I believe they could not know this. All they could know was that Socrate was criticizing people who believed that they knew things which felt squarely outside their domain of expertise. 

are implicitly assumed to hold in the proof of the theorem, even so they are never mentioned in the assumptions. However, the resulting calculus seems to be quite robust, even in cases where the classic laws of thought are violated. Take for example the continuum hypothesis. We know that it is neither valid nor invalid, but we might still model our knowledge about its validity by using the prior probability 0.5. It doesn't look like we will be lead to any wrong conclusions because of this. What seems to be true however is that we haven't managed to accurately represent our actual knowledge, and that we might miss some important conclusions that we might have deduced from this knowledge. But how misleading is Cox's theorem really? Are there any investigations of situations where it fails spectacularly? And if yes, do there exists modifications of the used calculus which better handle these situations? 

In the above translation into the context of modern computers, the instruction book is part of the input. This might be an important point, because superficially it looks like the only input comes from Mai, who submits the questions in Chinese. So where does the input come from? My guess is that the input comes from the current and past environment. However, we can't really look far enough into the past to learn where the "initial seed" came from. And in addition, we have the theory of evolution, which suggests that the "initial seed" might have been less important than it seems. Which brings me to another position that appeared utterly absurd to me when I first encountered it. Somebody suggested to me that this world might have been created by aliens. I found this ridiculous, because it begs the questions who created the aliens in the first place. However, after I watched a clip where Richard Dawkins seriously considered that possibility, I have to admit that it might indeed be a consistent position. 

I once met a physicists who held the strong AI position. I was 16, hadn't encountered this position before, and it appeared utterly absurd to me. Even so I'm no longer convinced that this position is utterly absurd, I still don't understand why everybody tries to disprove John Searle. My feeling is that the setup of John Searle's thought experiment can be usefully translated into the context of modern computers: A modern computer offers a certain amount of memory, more precisely a hierarchy of memory with increasing size but decreasing access speed. It also offers a certain processing power, more precisely a cluster of parallel processing units with increasing number but decreasing interconnection speed. This basic architecture is normally agnostic of the programs and input data that will be used to generate useful results with the resources provided by this computer. In Searle's Chinese room thought experiment, John is assumed to take the role of this computer, and provide the memory and processing power for the computation. Actually, he is only assumed to provide the fastest memory, while the really huge but slow memory is external to John in the form of paper and pencil and the "magic" book. But even if John would take the role of the "entire" tape of a Turing machine, why should we expect him (or the tape) to understand the problem instance the Turing machine is currently working on? Well, one reason is that for a universal Turing machine, the program itself was also written on the tape, so the tape had access to all the relevant information over time (except the meaning and interpretation of its final output, but I doubt that this is important here). 

I remember having read about experiments concerning the communication of trees in a popular science magazine (when I was still a teenager). IIRC, the experiment went something like exposing one tree to a poisonous substance, and monitoring whether the nearby trees show (chemical) activity indicating that they were informed about the incident. It turned out that the nearby trees really get informed. Then the experiment went on trying to cut the communication channel. It was possible to establish that the communication channel was chemical (but I no longer remember whether it was above or below ground), even so the exact chemical substances couldn't be identified. I think it is quite probable that trees posses mental qualities like identity and intension. It may be important to keep in mind that although what we can see from a tree are its trunk, branches, and leaves, the most important part of a tree might be its roots. So a tree doesn't care too much about loosing a branch, but is quite sensitive to damage to its roots. There is no question that intentional actions influencing and reacting to its environment are evolutionary advantageous for trees. However, as many questions regarding trees are well suited to be investigated by the "normal scientific method", we don't really need to speculate metaphysically about them. Perhaps philosophy could identify interesting metaphysical questions regarding trees, but a big part of the answers should come from normal scientific investigations. 

Because the Gödel–Gentzen translation gives a perfectly reasonable embedding of classical logic into intuitionistic logic, the answer "of course not!" seems questionable. (Note that this translation even uses the intuitionistic consequence relation, which was Gerhard Gentzen's contribution.) I used a similar translation to make sense of non-constructive results using the axiom of choice even before I knew that this translation always works. (I thought of proofs using the axiom of choice as showing that trying to disprove (of falsify) the given existence claim would be futile.) 

There are multiple closely related representation theorems for Heyting algebras. First note that a Heyting algebra is bounded and distributive as a lattice, and every bounded distributive lattice can be represented as the set-algebra of clopen upper sets of its associated Priestley space. In case of a Heyting algebra, this associated Priestley space is an Esakai space, which is a Priestley space for which the downward closure of each clopen set is clopen. There are also representation theorems for bounded distributive lattices and Heyting algebras using pairwise Stone spaces instead of Priestley spaces, and representation theorems using spectral spaces. 

As a slightly cryptic answer, the relation of the mind to cause & effect is similar to the relation of a computer to primitive recursive functions. Even so there are partial recursive functions which are not primitive recursive, primitive recursive functions are significantly simpler than general partial recursive functions and sufficient for most practical purposes. An analogy to telos might be to characterize the result of a computation as a fix point or a minimization. While this is a nice and concise description, such a description neither ensures uniqueness, existence, nor computability. Hence it can be as suspicious as telos. 

The program of reverse mathematics was founded by Harvey Friedman in 1975. Rota certainly knew it, and I claim it was the motivation why he wrote that paragraph. Let me give some reasons why reverse mathematics is different from the axiomatic method: 

Two of the most important logics which are not (necessarily) two-valued are Boolean algebras and probability theory. (I'm well aware that even a Boolean algebra must be supplemented by additional "instructions" to turn it into a multi-valued logic). Both look like bad examples, because Boolean algebras don't seem to add anything new over classical logic, and probability theory doesn't seem to fit into the formal scheme of multi-valued logic. On the positive side, already a two-dimensional Boolean algebra can be turned into an instructive example of a multi-valued logic with interesting interpretations, where nearly no property of classical logic has to be sacrificed. Probability theory on the other hand seems to be really useful for many "real world problems", and the product Boolean algebra over the sample space can help to clarify the relation to multi-valued logic (clarifying in a certain sense why probability theory doesn't fit directly into the scheme of multi-valued logic). 

The paper which introduced Henkin semantics for higher-order logic explicitly treated Simple Type Theory and contained Henkin's theorem. So completeness & soundness are similar to first-order logic in a certain sense. However, being equiconsistent with Mac Lane set theory means that consistency of Simple Type Theory cannot be proven in an absolute sense. 

Often the things we can be pretty certain of are ontological commitments. Exploiting ontological commitments A typical example is a Henkin style completeness proof for first order predicate logic. We are talking about formulas and deductions that we "can" write down, so we can be pretty certain that we can write down things. We use this certainty to construct a syntactical model of the axioms. (The consistency of the axioms enters by the "non-collapse" of the constructed model.) I don't know whether the earliest (Gödel/Tarski style) completeness proofs also relied on the same sort of ontological commitment. The last section below indicates why it is highly likely that some sort of ontological commitment is required for any completeness proof, as long as no explicit notion of "existence" relative to which we talk about "completeness" is specified. What ontological commitments are really there? One point of contention is how much ontological commitment is really there. Just because I can write down some things doesn't mean that I can write down an arbitrarily huge amount of things. Or maybe I can write them down, but I thereby might destroy things I wrote down earlier. What ontological commitments are really needed? For a completeness proof, we must show that for each unprovable formula, there exists a structure were the unprovable formula is false and all axioms are true. This structure must "exist" in a suitable sense, because what else could be meant by "completeness"? If only the structures that can be represented in a computer with 4GB memory would be said to "exist", then first order predicate logic would not be "complete" relative to this notion of "existence". 

The psychological explanations are more challenging, at least for me. I don't know much about the role of psychology in mathematics, but I certainly agree with Rota that psychology is too important for philosophy to delegate it to the psychology department. But even in mathematics, the point of a proof is still to explain to another mathematician ("to convince him") why a certain fact is true, and psychology is not irrelevant for this. And psychology also plays a role for drawing wrong conclusions from mathematical theorems. The historical analysis really helps set things straight in mathematics (and philosophy) in a way the axiomatic method will never be able to match. Let me again quote myself here: 

Cody Gray recently asked "Why should philosophers feel any different about the existence of emotions than they do about the color of the sky?" as a rhetoric question. But both physics and psychology were once subject matters of philosophy, so there was a time when philosophy actually cared about these questions. But today, psychology takes care to wonder about the consequences of the existence of emotions, so philosophy no longer needs to care, right? I have to admit that I read the popular science books form Richard David Precht about philosophy, and among others he discussed the work of Niklas Luhmann on love. So at least for me, the total separation of philosophy from psychology is all but obvious. But my specific question is whether philosophers should care about the existence of emotions or not. One good reason to ignore emotions might be that they complicate things and can lead to inconclusive controversies. I also could imagine that the intersection of philosophy and psychology - at least as far as emotions are concerned - is considered to be part of sociology (see Niklas Luhmann), so philosophy itself doesn't need to worry about it. But I would also be interested to learn whether emotions are still investigated in contemporary philosophy, or whether they are at least taken into consideration when they might have a significant impact on the practical consequences of some philosophical insight. 

Some sciences like mathematics and medicine are significantly older than the scientific method. This indicates to me that they may use a different fundamental approach than the scientific method. In an effort to get a clearer picture, I took a look at the history of the scientific method: 

The truth values of classical propositional logic form a Boolean algebra. The only subdirectly irreducible Boolean algebra has cardinality 2 (True & False). Hence the equational theory of classical propositional logic is completely determined by the two element Boolean algebra. The truth values of intuitionistic propositional logic form a Heyting algebra. Surprisingly, the class of subdirectly irreducible Heyting algebras is not really smaller than the class of Heyting algebras itself: 

Appendix: Normal (mathematical) induction allows to capture certain cases where it is known how to systematically prove each instance in a series of successively more complex statements in a compact way. But (the simplest) transfinite induction allows to assume that all infinitely many statements that can in principle be proven true by a given (normal) induction scheme are already proven true, and hence can be used to prove a statement based on the simultaneous truth of all these "prior" statements. 

One fixed static universal language would probably run into issues illustrated by Berry paradox and similar paradoxes. Nik Weaver has written some (too easily) accessible short pieces around these themes, see for example the introduction of "Constructive truth and circularity". If I understood the response to a question about these short pieces on the FOM mailing list correctly, these writings are not considered as "wrong", but just as "too trivial". That said, the above objections just apply to fixed static universal languages. There could by dynamic evolving languages which are able to describe unambiguously any problem in the Universe, in the sense that from any concrete language and any concrete problem, another concrete language able to express the problem would be accessible from the given concrete language.