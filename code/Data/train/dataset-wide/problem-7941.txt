First formula and second formula are equivalent. Since $$\frac{{{{\left| y \right|}^2}}}{{1 + {{\left| y \right|}^2}}} \le {\left| y \right|^2} \wedge 1 \le \frac{{{{2\left| y \right|}^2}}}{{1 + {{\left| y \right|}^2}}}$$ See p29 of "Levy processes and stochastic calculus (2ed., CUP, 2009) Applebaum D." and p38 of "LÃ©vy Processes and Infinitely Divisible Distributions[Ken-iti_Sato]". 

I want to know under what conditions does the Mittag-Leffler function ${E_{\alpha ,1}}(z),(0 < \alpha < 1)$ has no real zero, where ${E_{\alpha ,1}}(z) = \sum\limits_{k = 0}^\infty {\frac{{{z^k}}}{{\Gamma (\alpha k + 1)}}}$. ${E_{1,1}}(z) = \sum\limits_{k = 0}^\infty {\frac{{{z^k}}}{{\Gamma (k + 1)}}} {\text{ = }}{{\text{e}}^z}$ or ${E_{0,1}}(z) = \frac{1}{{1 - z}}$ has no zero, how about $\alpha \in (0,1)$? 

You want to have a simpler summation in Faa Di Bruno Formula by avoiding using specific Diophantine equation? See this referrences Voinov, V. G., & Nikulin, M. (1994). On power series, Bell polynomials, Hardy-Ramanujan-Rademacher problem and its statistical applications. Kybernetika, 30(3), 343-358. Mortini, R. (2013). The Faa di Bruno formula revisited. Elemente der Mathematik, 68(1), 33-38. 

The way you state the question currently mixes the abstract notion of derived functor (has nothing to do with fibrant replacements), and the notion of a co/fibrant replacement. I am not sure how to relate the two without some additional condition. However, given $X \in \cal M$, its category of, say, cofibrant replacements $\{ QX \stackrel \sim \to X \}$ is contractible (2.4.8 in this paper, there is also a proof of Hinich of the same fact). This is what in practice guarantees that for $F: \cal M \to \cal D$ sending weak equivalences of cofibrants to isomorphisms, the assignment $X \mapsto F(QX)$ is independent of choices and gives the left derived functor of $F$: the verification of the universal property is almost immediate. Of course, the formula you write usually works in practice, but the ways things are proven is more like this: A statement that is model-categorical in flavour is (the dual of) A.2.9.26 in Higher Topos Theory; the definition of Lurie is minimal in character, he just requires the preservation of colimits, not adjoints. Perhaps it is possible to get away with less than all colimits, especially if the Reedy category in question is simple enough. I have not checked. For a flavour of homotopy co/end theory without replacements and model structures, one could use derivators, as in section 5 of this paper, though they are not exactly answering your question, either. 

Let ${f_x}(m) = \sum\limits_{\left. p \right|m} {{f_x}(p)}$ be a strongly additive function on positive integer number $m$, where $p$ is a prime number. Set $${f_x}(p) = \left\{ {\begin{array}{*{20}{c}} {0,}\\ {1,}\\ 2, \end{array}} \right.\begin{array}{*{20}{c}} {{\rm{ }}p < \ln \ln x{\rm{ }}\ or \ {\rm{ }}p \ge {{(\ln \ln x)}^4}}\\ {\ln \ln x \le p < {{(\ln \ln x)}^2}}\\ {{{(\ln \ln x)}^2} \le p < {{(\ln \ln x)}^4}} \end{array}.$$ Bekelis (1997) say that $$\mathop {\lim }\limits_{x \to \infty } \sum\limits_{\scriptstyle{\rm{ }}p \le x\atop \scriptstyle{f_x}(p) = 1} {\frac{1}{p}} = \ln 2, \mathop {\lim }\limits_{x \to \infty } \sum\limits_{\scriptstyle{\rm{ }}p \le x\atop \scriptstyle{f_x}(p) = 2} {\frac{1}{p}} = \ln 2.$$ But he does not give a detail proof. How to prove it? [1]Bekelis, D. (1997). Convolutions of the Poisson laws in number theory. In Analytic and Probabilistic Methods in Number Theory: Proceedings of the Second International Conference in Honour of J. Kubilius, Palanga, Lithuania, 23-27 September 1996 (Vol. 4, p. 283). Walter de Gruyter. 

Let me address something which is not explicitly mentioned in other answers. Job issues exist, and they exist not only for category-theorists or the like, even much more ''working'' (in the sense of MacLane) pure mathematicians are struggling. In my opinion, the reasons (and possibly the solutions) for this are socio-political in character, we can discuss that elsewhere. To return to math, I have not seen all the comments, but. First, using HTT to prove something, understanding the proofs of HTT, and doing HTT-level of papers are three different levels of difficulty. It is very instructive to have a problem from another field for which you would need higher categories, then it becomes much easier to navigate in the literature to find what you need, or ask precise questions to the experts. Later steps seem to follow as you get sucked in. On the go, you will perhaps start to value the aesthetics of the state-of-the-art in higher category theory, happy days. Even if your pure interest is category theory or something of that form, it helps. You learn more about (higher) category theory by applying it. And, we have to remember that it has been only 20 years since the active development of the field. Various papers which followed since the HTT book show that more thinking leads to more transparency. You mention that there is no Bourbaki for homotopy theory; certain people believe that it is yet to come, and working towards it represents a big prospect in mathematical foundations. 

My question is about quantifying the error that occurs by approximating the continuous Fourier transform on a finite domain by using a discretised version with resolution $N$ for a function of a given Sobolev order $k$. I'm interested in the $L^2$-norm on the full (but finite) discrete grid, which I can prove is at most $\mathcal{O}(N^{-(k-1)})$, but numerically, I see $\mathcal{O}(N^{-k})$. I'm looking for ways to prove this better bound. First let me introduce some notation to formulate the question more clearly. Let $$\Omega:=[0,L]^2, \qquad \hat\Omega=\mathbb{Z}^2,$$ as well as the finite discretisations (taking $N\in 2\mathbb{N}$ for convenience) $$\Omega_\mathrm{fin}:=\left[0:\frac{L}{N}:L\right)^2 \quad \text{and} \quad \hat\Omega_\mathrm{fin}:=\left[-\frac{N}{2}:\frac{N}{2}\right)^2.$$ The notation $[a:b:c]=\{a,a+b,\ldots,c-b,c\}$ is Matlab-inspired (missing $b$ defaults to $1$), with round brackets indicating exclusion of the respective endpoint as for open/closed intervals. Define $$\mathcal{F}[f](\hat x, \hat y):= \frac{1}{L^2}\int_\Omega f(x,y) \mathrm{e}^{-2\pi\mathrm{i}(\hat x \frac{x}{L}+\hat y \frac{y}{L})} \mathrm{d} x\,\mathrm{d} y$$ and $$\mathcal{F}_\mathrm{fin}:=\frac{1}{N^2} \sum_{(x,y)\in\Omega_\mathrm{fin}} f(x,y) \mathrm{e}^{-2\pi\mathrm{i}(\hat x \frac{x}{L}+\hat y \frac{y}{L})},$$ as well as the usual Sobolev Space $$H^k(\Omega):=\{f\in L^2(\Omega) : \int_\Omega \left\lvert\frac{\partial^{k_1+k_2} f}{\partial^{k_1} x \, \partial^{k_2}y}\right\rvert^2\mathrm{d} x\,\mathrm{d} y < \infty, \; k_1+k_2\le k\}.$$ This space can be characterised on the Fourier side as $$H^k(\hat\Omega):=\{\hat f\in L^2(\hat\Omega) : \langle (\hat x,\hat y) \rangle^k \hat f(\hat x,\hat y)\in L^2(\hat\Omega)\},$$ where $\langle z \rangle:= \sqrt{1+\lvert z\rvert^2}$ is the regularised absolute value. The norm I'm trying to bound is $$\left\lVert \mathcal{F}[f]-\mathcal{F}_\mathrm{fin}[f\bigr|_{\Omega_\mathrm{fin}}] \right\rVert_{L^2(\hat\Omega_\mathrm{fin})},$$ which should be $\mathcal{O}(N^{-k})$ for $f\in H^k$, ideally. I'd also be happy with a 1d-proof or a reference (all the references I found so far deal with fft-errors as opposed to the error of discretising the continuous transform). This finishes the actual question, below are my attempts/reasoning for the rate I claim to prove, resp. what a proof for the better rate will likely have to show. I started by analysing the pointwise difference $$\left\lvert \mathcal{F}[f](\hat x_0, \hat y_0)-\mathcal{F}_\mathrm{fin}[f\bigr|_{\Omega_\mathrm{fin}}](\hat x_0, \hat y_0) \right\rvert.$$ Basically, the sum in $\mathcal{F}_\mathrm{fin}$ is the trapezoidal rule approximation to the integral in $\mathcal{F}$. An analysis in terms of Fourier coefficients seems necessary, because the trapezoidal rule in terms of differentiability only achieves $\mathcal{O}(N^{-2})$, regardless of higher $k$. The following idea is from [J. Waldvogel, Towards a general error theory of the trapezoidal rule; in Approximation and Computation, 2011]. By introducing $h(x,y):= f(x,y) \mathrm{e}^{-2\pi\mathrm{i}(\hat x_0 \frac{x}{L}+\hat y_0 \frac{y}{L})}$ and the trapezoidal quadrature operator $$T[h]:= \frac{L^2}{N^2} \sum_{(x,y)\in\Omega_\mathrm{fin}} h(x,y),$$ we see that $\mathcal{F}[f](\hat x_0, \hat y_0)=\mathcal{F}[h](0,0)$. By inserting $h=\mathcal{F}^{-1}[\mathcal{F}[h]]$ into T, we see that $$T[h]=\frac{L^2}{N^2} \sum_{(x,y)\in\Omega_\mathrm{fin}} \sum_{(\hat x,\hat y)\in\hat\Omega} \mathcal{F}[h](\hat x, \hat y)\mathrm{e}^{2\pi\mathrm{i}(\hat x \frac{x}{L}+\hat y \frac{y}{L})}\\ =L^2 \sum_{(\hat x,\hat y)\in\hat\Omega} \mathcal{F}[h](\hat x, \hat y) \delta(\hat x \mathrm{mod} N) \delta(\hat y \mathrm{mod} N)=L^2 \sum_{(\hat x,\hat y)\in\hat\Omega} \mathcal{F}[h](N\hat x, N\hat y),$$ by virtue of the summation property of the roots of unity (after interchanging the sums) $$ \sum_{\ell=0}^{N-1} \mathrm{e}^{2\pi\mathrm{i} j \frac{\ell}{N}} = N\delta( j \mathrm{mod} N) \quad \forall j\in\mathbb{Z}.$$ In particular, we have that $$\left\lvert \mathcal{F}[f](\hat x_0, \hat y_0)-\mathcal{F}_\mathrm{fin}[f\bigr|_{\Omega_\mathrm{fin}}(\hat x_0, \hat y_0)] \right\rvert = \biggl\lvert \mathcal{F}[h](0,0)-\sum_{(\hat x,\hat y)\in\hat\Omega} \mathcal{F}[h](N\hat x, N\hat y)\biggr\rvert \\ = \biggl\lvert \sum_{(\hat x,\hat y)\in\hat\Omega\setminus(0,0)} \mathcal{F}[f](N\hat x+\hat x_0, N\hat y+\hat y_0)\biggr\rvert.$$ By inserting the representation $\hat f(\hat x,\hat y)=\langle (\hat x, \hat y) \rangle^{-k}\hat g(\hat x, \hat y)$ for a $\hat g\in L^2(\hat\Omega)$, we can pull out $N^{-k}$ while the sum is still finite (both $\lvert \hat x_0 \rvert$ and $\lvert \hat y_0 \rvert$ are less than $\frac{N}{2}$). Summing this over the $N^2$ points in $\hat\Omega_\mathrm{fin}$ gives $N^{-(k-1)}$ for the $L^2$-norm. Any further gain (using this avenue of proof) would have to come from bounding $$\sum_{(\hat x_0,\hat y_0)\in\hat\Omega_\mathrm{fin}} \biggl\lvert \sum_{(\hat x,\hat y)\in\hat\Omega\setminus(0,0)} \langle (\hat x+\frac{\hat x_0}{N}, \hat y+\frac{\hat y_0}{N}) \rangle^{-k}\hat g(N\hat x+\hat x_0, N\hat y+\hat y_0)\biggr\rvert^2$$ with a lower power of $N$ than $2$. There is certainly some decay there, but harnessing it is not obvious. In particular, the knowledge that $\hat g \in L^2(\hat\Omega)$ is not easily applied. Thanks for reading through this long question! 

I think the question âwhy we needâ assumes something about âweâ, and in some extent, about âneedâ. There are people who study those objects for their own sake, there are those who study applied PDE and have no need of model categories. Even those who enter the domain which can be covered by model categories often work in a specialised situation where more adapted techniques exist (homological algebra and triangulated categories for algebraic geometry being an example). I guess the meta-reason is that at the current historic moment (or maybe that will remain so indefinitely) any description of entities ââup to homotopyââ from scratch cannot be done without having this ââup to homotopyââ notion already defined. One has to break the vicious circle and pull things down from their ââplatonicââ world. Which brings me to the answer for Since categorical philosophy has proven itself to be reasonably natural, introducing categories with weak equivalences is both a natural step and something reflected in many examples. As we now know, this principle of modelling homotopy phenomena is, formally speaking, just as good as any other higher-categorical approach. Working with an arbitrary category with weak equivalences $(C,W)$ can be impossible in practice, but there are many ways to (homotopically) embed it into a model category. One can consider the category of simplicial presheaves on $C$ for instance, with a suitable Bousfield localisation of the projective model structure. (The examples usually present themselves with better, often canonical, embeddings.) One can thus work with the objects of $C$ by performing operations on the bigger model category and verifying that the answer is sensible for $C$. This adds to the explanation as why the notion is quite ubiquitous. Algebraic geometry (both the field and the community) has different tradition from algebraic topology, yet model categories have found their way here as well. For example, Kontsevich defines a noncommutative space as a suitable DG-category, and considers them up to Morita equivalence. There are a few model structures on DG-categories, which cover both the usual DG- and Morita equivalences, and they have been used to get various results, such as the theorem representing DG-functors between quasicoherent sheaf categories as bimodules. Another issue is the structure of noncommutative cohomological invariants, Hochschild cohomology, Deligne conjecture, and related matters. Many of the results (including laying a foundation of derived algebraic geometry) were obtained by people outside of the core algebraic topology community, with the use of model categories.