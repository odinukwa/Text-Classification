In the scenario of adding a column to a VLDB-class table, it may be worth exploring creating a new table with the new structure and moving records from the old table to the new table in small ranges. It'll keep the individual transaction size small so the high-water mark for the Tlog in Simple recovery would be relatively low. You can't avoid ACID requirements altogether but if you can batch your upgrade as smaller steps instead of one single transaction, you may be able to work around the disk space constraint. 

In the process of removing an usused disk resource from cluster, I would follow these steps: 1) remove dependencies on the disks by the SQL Server resource, 2) take the disk resource offline, 3) delete the disk resource from the SQL resource group, 4) delete the disk resource from the Available storage pool. I was proceeding to do this on a two node cluster with two SQL 2008 R2 named instances (running Win2K8R2 SP1 build 6701, 64-bit). On deleting a resource in step 3 above, SQL would go offline, all the disk resources would go back to the Available pool, and the SQL resources (Net Name, SQL Server, SQL Server Agent) would disappear. SQL services do restart OK after via the services console as all the disks are still on the same node. I ran from the command prompt and I see the SQL service resources are still there, in Available Storage, and offline. To bring the resources back to the appropriate group, can I move them via commands? 

A data warehouse ETL process is querying a read-only secondary in an availability group. The ETL process queries a single table incrementally using datetime range criteria of a minute and read committed isolation level. At the time of execution, 5 records that meet the criteria are committed on the primary, but another 3, with slightly earlier timestamps than the first 5 (but within the criteria range) are still in open transactions. Does the nature of availability groups require all transactions to be applied in LSN order (delaying the visibility of all 8 records until all are committed) or do the delayed 3 records get later LSNs and are applied as soon as they are committed, potentially after the ETL process has adjusted its date criteria? 

I have table blobtable which has a BLOB column blobcol. A user updated the table using a command similar to this: 

Let's say that I want to change a SQL configuration setting like MAXDOP. I know that changing this on an active instance will severely impact performance, as it will clear all of the cached query plans. Doing this while the instance is running is simply not an option. Is there some way to modify the value now, but to "defer" the actual change until the next time SQL server is restarted? What I'm looking for is an option like Oracle's "scope=spfile" for parameter changes. Does such an option exist in SQL Server? 

Backing up to local disk isn't an option because there's not enough storage available locally. Now, the strange thing is, when I enable compression the backup magically works! Whereas if I don't, I see the backup file appear on the share and after about 2 minutes the file disappears and the backup fails with the error above. I'm at a loss and looking for any ideas about what might be causing this. 

I don't think there is a "Replace" option for non-table objects like procedures, packages etc. The best option would be to drop the schema entirely before the datapump import. This way, datapump will re-create the schema and all of the contained objects. 

Note that the file filename.txt existed in the directory before this update was performed. Now, the user is saying that when they select from blobtable (using PL/SQL developer), blobcol contains "Value Error" for this row. Normally, blobcol contains the value "BFILE". Out of curiosity, I tried selecting the same record in SQL*Plus and I get the following value for blobcol: bfilename(directory/subdirectory', 'filename.txt') I'm not very familiar with BLOBs and how they work, so my questions are: 

In the above code, filegroup [DATA_1995] would retain the values beyond the last partition boundary. So, if I elect to add new filegroups and split the function for additional boundaries in this fashion... 

It'll involve 1) removing the user from any database fixed roles like (only will remain), 2) creating a custom role in the DB, 3) granting the new role specific permissions on the one table, and 4) adding the user as a member of the new role. You'll also want to make sure has no grants to user objects as all users in a DB are a part of the role. 

I am using a COTS package to perform index rebuilds across my SQL Server portfolio. The package unfortunately doesn't have an option to set index fill factors globally for an individual instance or DB (I can set them when scheduling rebuilds on an index-by-index basis, but with 1,600+ indexes, I'd like to set them in advance in bulk). Outside of an ALTER INDEX command, is there a way I can redefine existing index fill factors? 

I think this is a pitfall. I recall SQL 2005 and older versions requires active nodes to be updated. SQL 2008 and later versions allow passive node updates like the walkthrough you described. A posting from Linchi Shea explains it well. 

I'm not familiar with this particular error but I've encountered situations when a two-node cluster had multiple failovers due to MPIO issues with the SAN LUNs. More often than not, it was resolved by updating HBA drivers. One other thing to look for is to ensure that the disk dependencies are properly set. The SQL Server service should be dependent on all that disks that are hosting the DB files and the backups as well as the disk with the drive letter acting as the mountpoint host. I've run into a few hosts where a missing disk dependency caused a disk to go offline before SQL could close out the DB files.