As stated, it would really help if you were more specific about what is entailed in "mind-reading". But let's compare it to some real-world scenarios. In normal speech, or when I'm typing like right now, I can be simultaneously thinking about the concepts I'm trying to convey, the speech/text synthesis, that Star Trek episode where Data rattles off a list of mental processes he was considering while kissing his girlfriend, how I should probably be in bed but am instead on Stack Exchange, the fact that I'd really like to get in an hour or so of Fallout 4 so I should type this quickly, and a number of other things that take less precedence like how my right foot has been resting on my left leg for quite a while and the pain in my left leg is increasing but isn't yet bad enough to necessitate moving my foot. I would expect that reading someone's mind would be similarly non-linear, so A) you're not somehow reading every single little process in their head at once (it would be impossible for you to process that much data anyways unless you completely stopped processing any data in your own brain which would be a rather fatal way to read minds) and B) even if the entire mind-reading process turned into garbled nonsense, the rest of your brain would still be wondering whether that rumbling in your stomach is from the nachos you had at lunch or the giant soda you bought on the way home even though you know you're supposed to be cutting back. Like watching a camera that's watching the screen ad infinitum doesn't somehow cause your brain to hardlock. You just say "whoa, trippy!" then go back to finishing your soda because you'll cut back tomorrow. I'm not sure how typical this is, but I commonly experience dissociated cognitive functionality, where one aspect of my thoughts appears as another entity in my head. At its simplest, it's just a bunch of voices screaming different things (or sometimes the same thing), with the most pressing urges being perceived as the loudest voices. In a more interesting case, I often tell myself I need to accomplish some task. At that moment, my mind splits into three pieces. There's my self, then there's the responsible guy, then the lazy guy. In a heartbeat, all three of us know exactly how the conversation is going to play out. I tell the responsible guy I know he's right, but I agree with the lazy guy (who is at that moment telling me he already knows I'm going to slack off so stop bothering to play out the conversation that I'm currently having with the responsible guy who obviously is actually just a facet of me) and remark that it's stupid that I'm having a conversation with myself when I already know the lazy guy is going to remark that I'm going to remark that I agree with the lazy guy and am in fact going to just be lazy. And then sometimes I'm lazy, sometimes I'm responsible, and sometimes I realize it's not even the right day and I don't actually have anything I need to do. Turns out that my own mind isn't capable of figuring out what it's going to do thirty seconds into the future with very good certainty, despite the fact that there are three voices in one head in complete agreement. (FYI, the pain in my left leg just got to the point where it necessitated moving my right foot.) Similarly, I would expect that the act of reading someone's mind which is reading yours would create instabilities because the two minds can't perfectly predict the actions of the other. So the other mind tells you a lie about your own thoughts which you believe as the other mind realizes it made a mistake, then the paradox is perceived differently by each mind, which amplifies the discrepancy. This forces the two minds to act with agency despite seemingly having no choice at all. (And I just realized I spent more than 20 minutes writing this and won't get an hour to play Fallout 4 and am debating whether I should just go to bed or bother playing a little and risk going to bed even later and being really tired tomorrow which will make me less likely to finish my homework when I get back from work. These thoughts occur to me as I proofread once before hitting submit in another example of non-linear processing.) 

The question currently has the hard science tag. I've attempted to link to sources where I can, but most of this falls outside the range of current science so sources necessarily don't exist. Summary The Star Trek holodeck has three primary technologies required to get the desired results, along with a few secondary technologies. The most important technologies are non-existent to impossible, while some of the least important technologies are in use right now. In general, I don't think it's likely to be possible as shown in Star Trek. An alternative to holograms and forcefields is some type of programmable matter such as claytronics. While this would require a tremendous amount of computation and isn't currently feasible, there don't seem to be any physical barriers to the concept. I believe that between a 3D background and a foreground comprised of programmable matter, along with some type of moving floor to keep the user centered in the room, a reasonable simulation could be constructed. As such, I've put these three sections first. Following these sections are sections on simulating acceleration (potentially feasible with a high-end centrifuge, but unnecessary for your use case) and on Star Trek-style "holograms" that I don't believe are feasible in real life. Background Imagery The background of the holosuite is a 2D image projected such that it appears to be 3D. While necessary for full immersion in a Star Trek Skyrim game, this is the least important aspect for simpler tasks like interactive porn, where the major parts of the simulation are within a few feet of the user and the background can be simple or nonexistent with little practical issue. The simplest form of this already exists in the real world. Using methods such as shutter glasses, and tracking the current location of the two eyes in the room, the walls can simply be made of high-resolution monitors that display adequately-realistic 3D imagery using methods similar to modern computer games. In this case, the background strobes a "left eye" image while the right eye is blocked by an opaque shutter, then the "right eye" image is strobed while the left eye is blocked. In order to avoid flicker, this needs to be done at 60 to 100 frames per second per eye (possibly as high as 500 fps, but it depends on the technology used to generate images). Difficult, but certainly not insurmountable. Using advanced technology, you could likely build contact lenses (or internal implants) that act as shutter glasses. These would perform just like existing glasses, but be virtually unnoticeable. While we don't have these yet, there are patents in place for implanted cameras and bionic lenses, leading me to think shutter glasses are very plausible. A different way would involve the use of tiny laser beams located at each pixel. With two beams at each pixel, one pointed at each eye (again requiring proper eyeball tracking), the image could be constructed like a traditional LED monitor, but the collimated light would restrict the left/right images to the correct eye. Physically constructing these tiny laser beams might be very hard, so it would likely work better to use tiny, adjustable mirrors and rapidly strobe some more traditional lasers across them from the corners of the room. I've found research on microscopic mirrors used in conjunction with hologram production, but these require a lens between the wall and the user (and use interferometry which is just cool). These technologies could be expanded to allow multiple people to see simultaneously. Essentially, you just create an image for every eyeball in the room and display it rapidly enough that each person sees a smooth framerate. The human eye has an angular resolution of about 1 arcminute, or 0.02Â°. If we assume the room is cube-shaped with square walls, the room is large enough that the user stays roughly in the center of the room at all times, and that the pixels on the wall are of equal size across the wall, we can compute the pixel resolution needed at about 6900 x 6900, which is about 5.75 times as many pixels as a modern 4k screen, or about 30 4k screens to do four walls and a ceiling. While these numbers are high, this is completely plausible with reasonable advances in technology. 

In all cases, the backup has some critical reason why it's the backup and not the primary. The only exceptions I can really think of are due to ignorance. A guy with R9 270 and R9 380 graphics cards might stick the 380 in his computer and put the 270 on the shelf as a backup because he assumes higher numbers mean more power, despite the 270 being substantially faster. When we were kids, my sister would pass in 5th gear instead of 4th, because she thought higher gears meant going faster without understanding the difference between top speed and acceleration. The 3G vs. 4G issue could be a result of this: some boss guy assumes 4G must be better and makes people use that instead of the older 3G that's better for their specific application. Another exception that's not really an exception is laziness. Maybe the new system is faster and would technically save me lots of time in the long run, but I really don't want to bother learning how to use it. So yeah, it's superior in any externally-objective tests, but it's still locally inferior because that requires me to put forth a lot of effort right now, instead of putting in a little more effort each day that adds up to more total effort.