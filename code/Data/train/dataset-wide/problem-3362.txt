If you run your CPU intensive operations via the scheduling class IDLE using Note, this will only run through the processing queue when the processor has no other work to do, you may find that this behaviour leads to the process becoming far too slow! An off-shoot of this is that your load will always appear just under 1 (since the process will stay for long periods in the run queue without being scheduled). Finally you can use the command to schedule tasks to execute when the load is below a certain value--frankly its not very dynamic and wont be held back once its started. 

The kernel will support 2 million connections with any comfort. Node or java will support 2 million connections with any comfort. 

initially creating the large file with then writing into it. Setting dirty_background_bytes much much lower (say 1GiB) and using CFQ as the scheduler. Note that in this test it might be a better representation to run the small in the middle of the big run. 

If you want something stronger, you can go for something that, say watches for any deletions by a user not normally inclined to do that. For performance the more specific the rule the better.. 

One way you can look to see if other processes are utilizing the disk(s) is to download from the main webpage here. Sysstat is of course available from the repo already but, unfortunately it does not include the command which is needed to check this out. EL5 kernels backported disk accounting into the kernel since EL5.4 without providing an interface to utilize it, but pidstat will work once you've done this. Then run the command to generate useful metrics for disk I/O, in particular what other processes are doing with the disk. You can also use to get a more realtime contention metric of the disk being used. 

Almost certainly to do with SELinux. I bet you moved your main.cf into that location. Try running to fix the labelling. 

That value is calculated by taking the 14th field from /proc//stat which the kernel manages. The value in question -- as far as I understand it -- only ever increases in 'jiffies' (effectively 100ths of a second). Can you cat the value of /proc//stat for that pid ten seconds after one another? 

Assuming here what your referring to is the tradiitional unix hostid. If I wanted to bind software to a system I would use a dongle or some stronger means to identify a system seeing as a hostid is very arbitrary, but nevertheless.. The hostid is retrieved using the library call "gethostid". Its merely a generic value which, if unset will be based off of the ipv4 address of the host system. See "man 2 gethostid" 

Setting that value to is stating to the kernel to use 39062 MiB of memory for TCP. Nearly triple what you have. The second problem is the 3 values for TCP and you set define the min, default and max. Given that your tcp_mem configuration states you never goes into 'memory saving' mode I imagine that you are actually allocating somewhere between 4-16k per socket. So, if I was the kernel and I saw such insane settings I might not behave that predictably either. Try reducing that value down to something you can actually use and trying again. Finally, I will point out that you are living in a dream world if you seriously believe that: 

What you are referring to is process checkpointing. There is some work in the later kernels to offer this (in conjunction with the freezer cgroup) but its not ready yet. This is actually very difficult to achieve well unfortunately because certain resources which are shared go stale after being unavailable for a fixed period of time (TCP springs to mind, although this may also apply to applications that use a wall clock, or perhaps some shared memory that changes state during a processes offline period). As for stopping the process when it reaches a certain memory utilization, theres a hack I can think of that will do this. 

Seeing as nobody else has yet mentioned it, its possible to do this with the module. You'll need to check the pam stack is invoking this module by looking in and adding as an value if it is not there. IE 

This will setup the monitor. Every closed file handle on the filesystem that had a write flag open initiates the event check. 

There is very few benefits to doing this as far as I can tell. You can create more swap on demand and add it to total swap, along with setting up policies for which swap space to use when. Many of the typical benefits of volume management do not really apply when the data you are keeping goes stale on a restart of a service or a reboot. 

Note that your default position on this matter should be not to adjust from what the Redhat repositories are pushing. Instead, make an assessment as to whether you really do need an updated version of a package, in particular what your specific requirements are, what problems it is supposed to fix and what risks it introduces. As a general rule, if you find yourself constantly needing updated software and/or requires multiple parallel versions of the same packages to make things work it is usually an indicator you are doing something wrong. 

This executable does different transitions for different subjects. Because we know that should only be doing a very specific set of things in SSH, it moves into for a transition, which has more restrictions imposed upon it than someone who would transition into . I have added quite a long answer on the subject of transitions below so that people can appreciate what problems SELinux is trying to solve and how it tries to solve them. 

Hardware RAID really depends on the card you get, but the more expensive cards shine when you have very many disks to use and will offer good monitoring and alerting to issues. They also offer hot swapping which can be very useful, but its usually the more costly of servers which offers this facility only. 

In linux, IP addresses have a notion of 'primary' and 'secondary' addresses. The primary is typically the first address you add to the system. Removing the primary address has the implicit operation of flushing the entire list of secondary addresses also. You can avoid this behaviour by setting the sysctl to 1 like so: 

Your version of php is higher than the available php-devel. Either downgrade php to 5.3.3-22 or find a channel/repo that offers you the later version of php-devel. 

We can also check that the rule that is being hit in policy will not get hit in (which it shouldn't). 

Create a new directory called "localftpd" Place the content below into a file called "localftpd.te" inside of this new directory. Run 

This will created a 'downed' link in the container, which you will need to bring up inside of the container and add IP addresses etc to. 

To cover these problems one needs a 'fencing' mechanism (lots of changing of infrastructure) to truly guarantee re-acquiring the lock in another host is a safe operation. 

The way this works is that you can hot-add memory to your server up to the available memory. Your system however is actually given the current memory. When a KVM VM boots up, it starts with the maximum allotment of memory possible to be given (the available memory). Gradually during the boot phase of the system KVM claws back this memory using its ballooning, leaving you instead with the current memory setting you have. Its my belief thats what happened here. Linode allow you to expand the memory, giving you much more at system start. This means that there is a zone at the beginning of the systems lifetime. When the hypervisor balloons it away, the normal zone rightly disappears from the memory manager. But, I suspect that the flag setting whether the said zone is available to allocate from is not cleared when it should. This leads the kernel to attempt to allocate from a zone that does not exist. In terms of resolving this you have two options. 

Judging from the stack output, we can see prior to the panic the most useful function the kernel was in was . In order to determine where we failed, we need to feed in the function name plus an offset into GDB. This is done by de-referencing the address to the function, plus the offset. The stack trace supplies the offset as the first value after the function. I.E means (I was at "mount_block_root" plus 549 bytes (the hexadecimal translation). Finally, we tell GDB to print the source code of that area. In my Linux system, this results in the following 

Each line should report the same result, certainly not a second out. You should try it a few times to make sure you just didnt cross a 1 second threshold during the test. The bug I came across here was that one processor was 1 second out from the other processor. This lead to a condition where mysql would ask for the time, then compare the time again with the next new request (which was -1 second away). Given this is unexpected it would underflow and mysql thought the connection was four billion seconds older than what it was. If this is the problem, you should change the clocksource on the host from jiffies to , or and the problem should go away. 

The RPM installs a module for which you'll need and also a policy for which is also necessary for this to run. The file for this module is installed in . The first stage in this process is to increase the number of categories that the main httpd process runs as, so that it can produce child threads that span the correct range. In the file change: 

Load is a very deceptive number. Take it with a grain of salt. If you spawn many tasks in very quick succession which complete very quickly, the number of processes in the run queue is too small to register the load for them (the kernel counts load once every five seconds). Consider this example, on my host which has 8 logical cores, this python script will register a large CPU usage in top (about 85%), yet hardly any load. 

Pam filter is intended for this purpose. Its not really seen much development and may not do exactly what you want without adding code to do the filtering which it requires. pam_filter I should point out that even with something like this, dont underestimate the power of stupid people to do stupid things. 

Posix ACLs are the only clear-cut elegant way to do this, this is how I deal with shared read/write resource conflicts particularly on web-based systems. Here is a running example. In my example I have a directory called . In addition I have the users , , and First, I have created a group called and then added the users to this group. 

Then I wait for you to update your webapp. Now what happens, is that the vulnerable script switches to . When it does this and runs it finds the program first, which in this case resets the root password, emails the attacker of the new root password, actually calls the real (to hide the fact anything has actually happened) and removes itself from the attack path. As root, you've got no idea what happened and the evidence is erased once the payload was delivered. 

The fragmentation of each zone is bad in the page allocation failure output. There are lot of free order 0 pages with much fewer to none higher order pages. A 'good' result will be plentiful free pages along each order, gradually getting lower in size the higher the order you go. Having 0 high order pages 5 and above indicates fragmentation and starvation for high order allocations. I am currently not seeing a convincing degree of evidence to suggest that the fragmentation during this period is anything to do with slab caches. In the resulting memory stats, we can see the following 

I have 14292208 Kb free. About 300M of memory has been used up. But, if I go by what RSS is telling me I've actually used 10GB of memory! Finally, if you take a look at the process mappings, you can see that the virtual memory addresses are the same as one another. 

I never end up getting a TTL exceeded message however. Check what you have setup in your router and port forwarding, something appears to be incorrectly configured. 

For 5MiB output buffering. See for a list of options. Note this doesn't work with which overrides the the buffer modes. 

The difference is due to tcp timestamps being used in Linux but not in windows. Turning them off makes the problem go away. I have no answer as to why you are losing packets because of this option being on though. 

Why are these different? There are different classes of process schedulers on linux. The default one (CFQ) basically gives an equal amount of time slices to each process wanting to run and queues runnable tasks in such a way that everyone waits on average an equal amount of time for their turn. Some exceptions to this rule exist but thats the basic idea. Another class of scheduler is the realtime scheduler. Realtime is a little different, rather queue runnable tasks into a fair queuing scheme, the realtime process will get CPU time as soon as it is needed by the process, this evict a running process from the CPU in order to make room for the 'realtime' process. What values can they take? What 'priority' does is alter the niceness of procesess so that on login your main process starts at a certain niceness, any child processes you spawn also start at the same niceness. This has the effect of making it more likely to be scheduled in in favour of other competing processes and the user experience can be made to either be more responsive/interactive for the lower niceness values and less responsive/interactive if the niceness is raised. It may be important for normal login users to have a lower priority than serviceable daemons for example, or root to have a higher priority on login than everything else. As for realtime, contention is handled with the 'rtprio' field. If you have two realtime tasks both wanting to run then the 'rtprio' value is used to determine which of the processes to pick for priority first. A higher rtprio produces higher priority tasks. Setting this in the limits.conf permits realtime tasks to be set at a particular priority banding without needing root to set the value. This has no effect on tasks not set to run using a realtime scheduler. The 'nice' value should do the same as 'rtprio' but for standard CFQ scheduling. I've never tried it though. It sets the initial process spawned when PAM is setting these limits to that nice vaule, a normal user can then go to that nice level or higher without needing root to set them. If you dont renice explicitly it means all processes spawned from a shell from that login (for example) will inherit the nice value set in the limits.conf form the parent process that was initially created. What are the defaults? The 'default' limits -- technically are them all being set to what pid 1 is unless explicitly set, resource limits are inherited from the parent process, if no limits have been defined or overridden anywhere then the inheritance from is the default. Other Values 

Its stuck doing something, given you said it had in a strace output I'd say its probably waiting for the other end of a socket connection send it data. Like a website has given up sending you data. Thats a total guess though. There almost certainly should be a file descriptor for 4 which gives more information if you try and see what its up to. 

In this example I've used firefox on my machine but you can change the process name to suit your needs. Here, I'm requesting each thread that lives in the process. The columns mean the following: 

Your filesystem must support it (most do these days, they can be enabled by remounting the filesystem with ACL support on most filesystems). Stuff like NFS wont work. The standard Unix group ACL becomes a mask. I.E if a file says g+x the file is executable with the command above. if its g-x the file is not executable, regardless of whether or not permissions set are rwx in the ACL. This ensures you avoid a situation where you would have to mark all directories rwx in the acl and all files rw-.