The Wikipedia page on Fallibilism (currently) makes the intriguing claim that "Fallibilism is related to Pyrrhonistic Skepticism, in that Pyrrhonists of history are sometimes referred to as fallibilists, and modern fallibilists as Pyrrhonists." This school of ancient skepticism seemed to have as a goal the suspension of judgment, and "ataraxia" or the "freedom from distress and worry". Aside from this, this begs me to wonder, if fallibilism is true and is the idea that anything we believe we know, at any point in history, could be wrong, why should we continue pursuing science? What I thought was ennobling about science was the virtuous question for knowledge and the satisfaction of curiosity, but a falliblist science can offer neither of these. Is the best that can be gained ataraxia? 

Someone suggested that I answer the question directly. The problem you're having is a consequence of one of the changes that were made to "mainstream logic" between the time of Lewis Carol and the time when modern predicate logic was defined. Before Frege, Russel, et al, universal propositions were thought to have existential import if they were true. "All unicorns have one horn" is false simply because there are no unicorns, according to the older, Aristotlean rule. The statement is true according to the more modern view. The matter really boils down to whether you allow empty terms or not. That is, does it make sense to make assertions about things that don't exist. Do unicorns have hearts? Do they sometimes suffer strokes? Are they raced the same way horses are? There is a legitimate intuition that it is nonsense to talk about empty terms and non-existent animals. But it is also legitimate to speak about empty terms hypothetically for the sake of argument, such as if you want to engage in reductio ad absurdum reasoning. But the point is crucial if you want to translate statements to predicate logic. If someone says that "All philosophers are logical," do you really believe that he suspects that "philosophers" could be an empty term? Even if this is a cynical dig at modern philosophers these days, the term isn't empty if there ever were or ever will be philosophers. So to translate this assumption into modern logic, you would make the existence of at least one philosopher explicit: ∃x(P(x)) & ∀x (P(x) → L(x)). You should do the same thing with the second premise. Sure, you could wonder if the author really meant that there are no illogical men. But I would suggest that with most common "practical" reasoning, we don't really deal with empty terms. What you should never do is just translate a sentence naively into predicate logic and then think that the argument isn't valid. Predicate logic itself makes several assumptions that aren't always the case. You need to at least know what those assumptions are. 

The answer is simpler than you think. "Fashion" is the effect, not the cause. Combine two separate concepts: First, that pleasure resulting from a certain aesthetic fades over time. So yes to your first question, it is the aesthetic value that changes. You can only eat ice cream so long until you get tired of eating it, even though nothing changed about the ice cream. Similarly, people get tired of seeing the same kind of clothes being worn all the time. There is a certain pleasure in novelty. Second, fashion has a social value, as well as an individual one. Socially, what people wear is a significant part of our environment, so it's more pleasing to see people well-dressed. Individually, to wear clothes that other people find pleasing arouses our vanity, so we have a personal interest in pleasing our society. "Fashion" refers to this careful equilibrium between social pleasure and individual vanity. 

My problem is with the definition of exclusive disjunction, at least according to Wikipedia. The Wikipedia page for Exclusive Or, at the time of writing, states that "More generally, XOR is true whenever an odd number of inputs is true." This seems useful for computer science, but in logical reasoning I would want a connective that means "only one of these propositions is true" no matter how many propositions there are. For instance, I would like a connective that says "You can either order milk, coffee, or orange juice with your breakfast." But all of the connectives that Wikipedia lists are binary but yields strange results like that exclusive disjunction is true when an odd number of propositions are true. Is there canonical terminology for what I'm talking about or is there no standard terminology? I want to still call this exclusive disjunction, but it contradicts with the usage on Wikipedia as referenced above. Also...is there terminology for other connectives over an indeterminate number of propositions? 

Neither. The fallacy you're looking for is begging the question. If the conspiracy theory is true, then the lack of evidence for the theory would indicate the power and reach of the conspiracy used to hide it. But the lack of evidence for the conspiracy can not reasonably be seen as a valid argument supporting the truth of the conspiracy theory. Those who strongly believe in something often have a hard time doubting it, which is what is required in order to persuade a skeptic. This is where a lot of question begging comes from, in form. If you already believe something is true, you don't generally look for evidence to convince yourself that it is true, and you may not even know how to "think like a skeptic." But of course the first thought a skeptic would have is, "Suppose the proposition is false, would anything appear different?" 

I believe what you are describing isn't a fallacy so much as a cognitive bias. In this case, the closest cognitive bias that fits your description is motivated reasoning where "when people form and cling to false beliefs despite overwhelming evidence, the phenomenon is labeled 'motivated reasoning'. In other words, 'rather than search rationally for information that either confirms or disconfirms a particular belief, people actually seek out information that confirms what they already believe.'" The term logical fallacy isn't always defined the same way, but it generally refers to errors in the reasoning process itself, but doesn't describe the cognitive process by which people commonly acquire false beliefs. Fallacies are often erroneous by their similarity to valid modes of reasoning, such as in the case of hasty generalization where it is difficult to define exactly how much data you need in order to make a valid inference, or in other cases the fallacy is simply deceptive in its own right, in the case of the fallacy of composition. The syllogism you describe doesn't sound to me like a "syllogism" in it's own right because what you describe as an inference really looks like a description of the utterer's cognition, which you may or may not be correct about. 

I'm definitely open to critique here. I see ampliative reasoning (basically, induction or abduction) as different than explicative reasoning (deduction) in that ampliative reasoning adds additional information not contained in the premises. By some people's standards, this is never valid, and I suppose supporters of ampliative reasoning must show how this trick is possible. The understanding that I've kind of developed is that ampliative reasoning adds information by decreasing likelihood. For instance, Pr(Socrates is a human mortal)=99% ⊢ Pr(All humans are mortal)=1%. What would otherwise be an audacious generalization is accounted for by decreasing the likelihood of the assertion. My problem is that I don't even really know if this works out. The numbers in the Socrates example are completely made up, but my sense is that there are a set of probabilities that would make this inference valid. Peirce once wrote that with ampliative reasoning you trade in some security for uberty, and maybe I'm making too much of this relationship. So my sense is that we're trying to quantify the information in both sentences, and for the inference to be valid, you can't add information to the inference, just like in deduction. But this means, in some sense, by saying that a proposition is merely probable, we say that the proposition contains less information. For instance, "Socrates is a human mortal" contains a lot less information than "All human beings are mortal", because the latter tells us something about every human. But is there a way of quantifying the amount of information in these sentences? If there is a way of quantifying the information in these two sentences, such that for instance the second sentence contains a thousand times the quantity of information as the first, then for the inference to be valid, would we just make the probability of the second sentence one-thousandth times the probability of the first? What do you think? 

I guess I'm more looking for clarity here than anything else. I've been reading about the illusions that stage magicians perform, and also found web sites containing optical illusions, but I haven't seen much real explanation about how these illusions work at a more fundamental level. I don't really mean how they are made, but perhaps the more philosophical questions about how they are possible, and given that this possibility, what this means about the relationship between our perceptions and reality. First, I have a terminological confusion. I want to say that illusions aren't really about our senses, but are about our intuitions. But the SEP article on intuition wants to define intuition as a kind of belief or reflective judgment, such as our moral or logical intuition. But when you watch a stage magician fly through the air, this isn't really an intuition in this sense. The Wikipedia article on intuition (psychology) wants to discuss intuition as, for instance, our ability to perceive other people's emotions. Again, this isn't really what I mean. Is there a better word for this, or is it legitimate to tact on another meaning? I want to say that when I watch a magician fly through the air, my perception is correct, but because I am seeing him but not the wires holding him up, my intuition is giving me the illusion that he is flying. I don't want to call this an inference, as I think inferences are more deliberate, but my intuition that he is actually flying is more immediate than any sort of judgment. Part of the reason I want a word like "intuition" is because "illusion", in many cases, goes too far. That the magician flies through the air is both an illusion and an intuition, but a drawing of a cube on a paper, where a flat drawing looks three-dimensional, even though there is no way I could be deceived by the drawing. Again, "intuition" in this sense isn't a mistake in my perception, yet is also more immediate than an inference. Please tell me there is a term for this. Looking at the various optical illusions available online (just Google for it for examples) I see many illusions that seem to indicate the following things: 

One thing about being careful about in informal logic is knowing that there are exceptions to every fallacy. Rather than thinking "appealing to authority is a fallacy", think that there are valid and invalid ways of appealing to authority. In fact, this is one view of what fallacies are. Fallacies are tricky because they resemble valid forms of reasoning. In your case, you're assuming that he is committing a fallacy by asking for the original research about the harmful effects of drugs. I'm not really sure I could defend your argument, as is. Then again, you just had a casual discussion mixed with alcohol, not exactly the hall of reason. Think of logical arguments as the sort of thing you would prepare yourself with thoroughly if you were about to make your case to a rational judge. You should ask yourself if the rational judge would want to see the original research. I doubt the rational judge would need the original research, but he would need more than just a vague sense that you heard that drugs are bad for you. The website Logically Fallacious has a page about the appeal to authority, but with an important exception: