If you mean incredibly long as in 2 or 3 minutes before you reach the OS loading, this is normal. If you mean over 10 minutes before the OS begins to load, there's either a hardware problem, or some diagnostics have been enabled and not disabled again. What information is coming up on the screen during these 'tests'? Can you reset the BIOS to clear it back to how it should operate? 

The 'Host' line under the 'General' tab on a VM indicates the physical host machine that the VM is currently running on. 

Regarding the disconnections, are you running ESXi or ESX? The logging on ESXi rolls over very quickly (especially messages) so you may not be able to go far back enough to see the disconnection information. If this is the case you can rectify it by configuring the host to log to an external syslog server. We've seen host disconnection issues for strange reasons recently, most notably that a checkpoint appliance between the host and vcenter was interfering with packet order (via it's 'Intelligent' IDS) and causing hosts to regularly drop to an unmanageable state until we restarted the management services. Are there any WAN links or firewalls between the hosts and vcenter? 

Check the WINSXS folder and ensure it's not responsible for the 'missing' space. More info on that here: $URL$ 

On the device look under Options -> Messages for 'Auto More'. However there used to be a 'hard' limit of around 40Kb on messages sent to a device. If the messages are over that amount, I'm not sure there's a fix. 

For terminal services, my gut feeling would be that deploying multiple virtual TS instances is your best bet, with TS load balancing. 

You can repeat the above as necesarry to re-create your test environment quite quickly. There's also nothing stopping you raising multiple environments at the same time, as long as you create a seperate host-only network for each instance. There are some limitations of this setup (mainly that having all the machines in isolates networks makes it a hassle to load data) but it'll allow you to setup quickly and ensure you're always returning to a true reference baseline. 

So if this is the only VM you're planning to run on this system, assigning 2 to 3 cores would probably work out fine for you. Assigning 4 would most likely cripple the VM. If you plan to run other VMs concurrently I'd recommend 2 vCPUs. It seems to be a sweet spot for most workloads and systems with 3+ available cores (up to any number of cores). 

I'm guessing someone set a limit based on the previous ram and you'll want to either increase it or zero it out and let the server manage itself. 

Obtain the certificate for your server's full DNS name from a trusted root CA On the server open mmc.exe Add the Certificates snap-in, and choose 'Computer Account' Add the certificate into 'Personal Certificates' 

Transmit load-balancing is quite simple, you just enable it on the NIC and it should send traffic out through both ports. However receive load-balancing is a bit more involved. In short: 

You can work around the 'all explorer windows are slow' problem by enabling 'Launch folder windows in a separate process' option under Tools -> Folder Options. Take a look at the TCP offload settings on both server and clients, as I vaguely remember some issues with SMB browsing if ToE is enabled on the server-side with particular NICs. 

If it's a lone domain controller (the only one in the forest) then you are usually OK to use cloning tools on it, provided the server is shut down at the time it's cloned. The original server must be destroyed if the clone is ever brought online, however, as the two cannot co-exist. The cloned server will also only be valid for a short time, because domain clients have credentials which they use to talk to the domain and they silently update these credentials quite regularly. This means that if you bring your cloned DC online, and a client has updated it's credentials since the clone occurred, your client will no longer talk to your domain. So lots of caveats. General advice is that unless your domain is unimportant (e.g. just being used for some development), don't clone DCs. 

One thing that's not immediately apparent about Windows Storage Server is that it's tied to particular hardware that you comes with it pre-installed, rather than being an OS you can throw on hardware of your choice. So it's probably out as an option, unless you can purchase the additional hardware. For a VM-based solution running on your virtual environment, you could look at Windows 2008 R2 with DFS replication to a remote site. Alternatively, Openfiler with DRDB replication. Both can authenticate via AD if you need this, but I don't think either of them will do data de-duplication at this time. 

You can use a fully qualified domain name that you do not own. However, if you're going to go down this route, make sure you pick an FQDN that is not and could never be owned by a third party. So pick one ending with .lan or .local, as Zaid suggests. The reason for doing this is that if any of your machines are ever used off your local network (e.g. one of them is a laptop and you take it to a cafe), that machine will be trying to resolve network names with the FQDN you chose, on the public internet. If someone else owns that domain on the 'net, then those requests are going to end up on their doorstep. Thanks to a DNS client feature in Windows called 'DNS devolution', even if the exact target DNS name doesn't exist on that remote network, the request will get re-sent with just the base domain name e.g. if you try and resolve mypc.domainname.com and it fails, the machine will then go out and just request domainname.com, then finally just com. Long story short, either buy an externally recognised domain name (it's cheap!), or go with the not-fully-supported-but-still-acceptable .lan or .local suffixes. 

Some folks see this as sloping-shoulders shrugging off responsibility, or are lulled into the notion that they must be able to answer any question authoritatively no matter the subject. Often as IT folks I think we get lulled into a sense that we are expected to answer authoritatively on any subject, and not just the one in which we're knowledgeable. So yeah... Learn and apply appropriate boundaries of responsibility to your role, and the non-IT people in your organisation will appreciate and respect your understanding of how IT fits into the business. You'll avoid a reputation of being a loose cannon, difficult to control, or arrogant. Not to mention protecting yourself against any ramifications that may arise down-the-line if the decision that was taken leads to problems. Oh and in conjunction with the above and as a seperate principle in its own right: Always establish an email trail of decisions so that they can later be traced back and proved. 

sql server and vmware tools fight for memory space in a vm. This is probably compounded by running terminal services and vs. If you haven't already, go into the vm's settings and create a full 4Gb memory reservation under the resources tab. This'll prevent the baloon driver attempting to reclaim memory within the vm. You may also want to configure the options within sql server to ensure it only allocates part of the system's ram. Maybe 2gb max. 

No special configuration is necessary. Just enter the IP of your VPS as the 'A' record for your domain. 

As already mentioned, your exchange install/uninstalls will probably be making changes to the Active Directory environment as well.... and AD doesn't play ball with snapshots. If you roll back a domain controller without carefully rolling back all other DCs at the same time, the domain will pretty much crumble. One possible approach may be: 

I believe the only way to guarantee your snapshots are valid against each other, is to shut both guests down, take the snapshots, then power both VMs back on again. 

No. But as with any change like this, test it out on a non-critical environment first, and perform the actual cut-over during the period where there's least impact if the services do go down. Always plan it like it's going to fail. Traffic for the VMs themselves flow over a seperate VM Network definition. Which could potentially be bound to the same network adapter, but they don't use the service console for traffic. 

Wow, that is a lot of questions with a huge scope. I don't mean to be rude but I think your best approach is going to be to research most of these questions extensively yourself and build up a very complete picture. It's not something we can really cover properly for you in a single thread. A migration like this is a big undertaking, it'll need time & budget & project management, not to mention keeping one eye on politics and not pissing off your users ;) Anyways, I'll speak to some specifics which you may not be able to easily find elsewhere. I (and 1 colleague) migrated a Domino 6.5 environment across to an Exchange 2007 system in May 2008 at an organisation of 250 people, in the UK. These points were all learned along the way when we did that migration: First - Architecture In ex2007 you need to grok the various roles. I would recommend that you deploy a hub transport, information store, and client access roles at your primary site, an information store at your secondary site, and no roles at your branch offices. Instead, use RPC over HTTPS or existing VPNs to connect back to the central exchange. However you need to tailor the above to your organisations needs and limitations. If you have weak WAN links but a strong Internet pipe at the secondary site, and they run under a seperate email domain, you might want to deploy a hub transport there. If your business is security-focused, you may wish to deploy an Edge transport in your DMZ (but this is not mandatory). Depending on your hardware you may need to purchase new servers (you need 64-bit kit for ex2007 as a minimum) and/or bump up the RAM. Ex2007 loves RAM. Second - Preparation Your biggest pain point here is if Domino is being used for 'non email' business purposes. Domino is a jack-of-all-trades database system and is often used for things like document stores or form-input databases. You should focus on decomissioning all non-email uses of domino, primarily by identifying stuff that's not even used any more and removing the NSFs, or for stuff that is in use, migrate to something else e.g. extract the documents and put them on a file share. This takes time, but you can address it in parallell with your main migration, and if necessary keep the Domino server around for a while even after the email roles have moved to Exchange. Third - Migration Invest in the Quest migration tools. You're mainly paying for Quest's support, and they'll help you out through the course of your migration and won't stonewall you if your question isn't strictly related to the Quest apps - They have a lot of migration experts who have tackled your scenario 100s of times over. Worth their weight in gold. Other stuff Blackberry - Talk to your account manager at RIM (if you don't have one, your supplier will). They will be able to supply you with a 'temporary' enterprise BES CAL set for the duration of your migration. So you purchase the Exchange version of BES, build it alongside your Domino BES. Then you apply your existing BES CALs to the new server (no need to re-purchase the CALs!) and apply the temporary licenses to the old BES server. This gives you a 30-day period in which you have co-existence, you save money by migrating your CALs, and the temp CALs they give you should be free or a fairly nominal cost. Clients - For the user side of the migration, leverage the rich OWA in Ex2007 in cases where your users don't yet have Outlook available or configured. This is good becuase it: 

These are all examples which will cost some money and effort to implement, but the cost is recouped after the changes because your environment becomes much more straightforwards to manage. Not having to dedicate as much headspace to the exceptions and gotchas of running lots of disparate kit is really good for your stress levels, too. 

Only the 'User' portion of a GPO can be applied to Users, likewise only the 'Computer' portion of a GPO can be applied to Computers. If you create a GPO with some User settings in it, then attach it to an OU that contains computers, it won't do anything because none of it's settings are considered relevant. There is one exception to this - Loopback processing. But it should only be applied in a few specific circumstances. 

2003's GUI is the same as XP's 'Classic' GUI. It's possible to hack on the uitheme.dll 'shiny stuff' to 2003, but not often done. This gets better in Windows Server 2008 as you can install the 'Desktop Experience' option and get a desktop similar to Vista. 2003's program and driver support is pretty much in-line with XP. Most printer and device drivers that work on XP will also work on 2003, with a few exceptions. Programs work in almost all cases. 

If you're simply looking for a tool to sweep your network and tell you how many 'nodes' (devices) are active right now, then Angry IP Scanner is about as simple as it gets. You feed it your network address range, and it tests every possible IP in that range to determine if it's alive.