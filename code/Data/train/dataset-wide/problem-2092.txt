Assuming that your database character set is (if there is a difference between the two, this is almost certainly your character set) and that all the data is characters that exist in the character set ("english" might constitute more than that depending on the definitions we're using) there won't be any noticable performance differences between a and a . Based on your database character set, Oracle has to do a tiny bit more work reading a string to figure out that every byte represents a single character rather than being part of a multi-byte character. But checking the length of a string in either characters or bytes is a pretty trivial operation. Unless you're doing something like running a TPC benchmark where you're already doing a crazy number of things that you'd never do in reality to get tiny fractions of performance improvement, it's not something worth worrying about. If you were going to go crazy with a TPC benchmark level of effort to get every last thousandth of a percent, it would probably be slightly more efficient to use a database character set of and declare everything using byte semantics given that you only had to store English. Practically, though, if your application is so efficient that this sort of thing matters, though, you've already solved every performance problem so you should be focusing much more heavily on supportability and maintainability which would argue for an character set and character length semantics. 

There is no difference for a single SQL statement. The '/' character on its own line tells SQL*Plus to execute the command in the buffer. You can use the semicolon at the end of most SQL statements as a shorthand for the '/'. If you want to execute a PL/SQL block or to execute a handful of SQL statements like , however, you need to use the '/' 

You can install another database on the same server that is already running one instance of a RAC database, yes. 

You haven't specified a tag in your question so I'll assume that you're asking a generic question despite the SQLite reference (if you're asking a SQLite-specific question, please update your tags). Generally, I'd suggest using a trigger when you can't use a check constraint. Different database engines have different levels of support for what you can do in a check constraint. I don't know of any database engine, for example, that would currently allow you to define a check constraint that references data in a different table or data in a different row of the same table. If your database engine allows you to define the email format rule in a check constraint, I would use a check constraint. If your email validation rules were more complex, however, or you were going to have the same validation rules in many places, you may want to encapsulate them in a function. Once you do that, most database engines are going to require you to use a trigger. For example, you might want to perform more detailed validations that involve checking to see if the domain is valid, whether the email domain on the row in the table was not already in the table, etc. At that point, you're doing something more complicated than what a check constraint can manage. 

If we can declare , , and as , you can create a composite index on that can be used instead of doing the full table scan. Here is a sqlfiddle showing that approach. Note that I applied a hint to force the index to be used since there isn't enough data in the example for a full scan of the index to be less expensive than a full scan of the table. The index full scan path would probably be more efficient in the scaled up example assuming each location has data for many more than the past 26 weeks. That's probably not going to be an order of magnitude improvement, though, unless the table is substantially larger than the index. 

Different tools may have slightly different conventions for how you execute multiple SQL and PL/SQL statements in a script so be aware that this is SQL*Plus specific. 

Query instead (or in the event that you've changed session-level parameters in your current session and want to ignore those changes). is just SQL*Plus syntactic sugar on top of those data dictionary views. 

Walking through an example My database block size is 8k and we'll assume that I'm using the default of 10 (meaning 10% of the block is reserved for future updates that increase the size of the row). I'll create a simple two-column table 

It is possible that smaller values would be slightly more efficient. But if your code is so efficient that one of your larger bottlenecks is the size of your integer keys you are way, way, way ahead of the game and have little left to optimize. It is possible that the database you are using will use a different amount of space to store different numeric values where smaller numbers tend to use less space. Not every database will do this but some will (for example, Oracle uses a variable number of bytes to represent different numbers). If this is the case for your application, then rows with smaller keys will generally be smaller on disk which means you can read more rows per I/O request, fit more keys in each index block, and cache more rows per kb of RAM. Potentially, you might find that restarting the key would allow you to use a smaller data type for the key but that is pretty unlikely. All these will have some potential performance benefit. That said, the size of the benefit is likely to be minimal. In most tables, the size of the primary key will be a small contribution to the size of the row so saving a byte or two on a key will probably lead to slightly more free space on each page/ block which would negate the performance benefit. And even if you get slightly more data on each page/ block, it's pretty unlikely that you'd be able to measure the improvement. Yes, you might be slightly more likely to find a row in cache but it would be tough to quantify such a small improvement. 

There is no need to grant the role. In 10.2, Oracle finally reduced the set of privileges assigned to that role to just but in previous versions, that role has many more privileges than the name would imply. It would be more secure to create one users-- one that owns the tables, procedures, etc. but that does not have privileges and one that has appropriate privileges on the various objects that the application can use to connect to the database. That allows you to do things like prevent the application user from dropping tables or from deleting data from logging tables. Additionally, the owner of the tables is going to need to be granted quota on whatever tablespace or tablespaces that user's tables are going to be created in. You could grant the owner the privilege but it is more secure to grant them a smaller quota on whatever tablespaces they actually need to use. 

If the is a role, you would then need to look at to see what users (or roles) have been granted that role and follow the chain if you have roles granted to other roles. If you need to account for users that have grants because of the (very dangerous) grants (i.e. ), that would require a separate query. If you want to get more sophisticated than simply doing a straight query against , though, you are probably better off using on of Pete Finnigan's scripts like the (or ). Pete is probably the leading expert on Oracle security so these are much more likely to account for every possible corner case than anything I would attempt to cobble together. 

When you have permission to perform an action at the command line but not within a definer's rights stored procedure (and I hope you're using a stored procedure here, not a stored function), the problem is almost certainly that the privilege you need has been granted through a role, not directly to the user that owns the procedure. Inside a definer's rights stored procedure, only privileges that have been granted directly to the owner of the procedure can be used-- privileges granted through a role (such as ) cannot be used. You can verify that the problem is, in fact, that the privilege is granted through a role by disabling roles and then trying to create the user, i.e. 

No, the second query won't work. It will always return 0 rows if is greater than 1. Conceptually, if you have a query like 

you might try rewriting the query using the SQL 99 syntax. That generally makes it easier to notice that you're missing a join condition 

First off, taking a step back, do you really need to solve the inventory management problem on the front end? Since you're selling large volumes of a relatively small set of products, it should be relatively easy to manage your inventory so that you are never out of stock or, if you are, it doesn't prevent you from fulfilling orders. There is a great deal of literature and examples that deal with calculating safety stock which requires just a bit of statistics to follow. It would make far more sense to me to focus your attention on giving the company the tools (if it doesn't already have them) to manage their inventory to prevent stock-out situations rather than trying to prevent them from happening in the sales portal. That being said, I'm not quite sure that I follow your problem with the two scenarios you outline. Even if the database performance was flawless, if you have only 1 of item A in stock and you can't sell an item if it's not in stock, then one of the two customers, by definition, one of the two potential customers is going to lose out. If in the first scenario C2 is going to go away without buying anything if any of his 35 items are not in stock (which seems unlikely if he spent 20 minutes filling his cart), there is nothing you can do in the database to prevent that. Your interface could potentially have some AJAX that alerts them while they're shopping that one of the items in their cart is out of stock much like StackExchange notifies you while you're entering an answer that someone else has entered an answer. It's not at all clear to me, that telling C2 about the problem earlier is going to be beneficial-- if he's going to leave if he can't buy all 35 items in one transaction, he's going to leave no matter when you tell him that C1 bought the item. Realistically, there is no way to design the system so as not to disappoint one of the two customers in that case. It might help if you can explain a bit more about why your application and your customers are so sensitive to stock-out situations. Most customers and most retailers are relatively accustomed to the fact that sometimes after placing an order they get notified that the retailer isn't going to be able to fulfill the order as quickly as they had expected and are given the option to cancel that part of their order, the whole order (assuming the remaining items haven't shipped yet), or to wait for the item to come back in to stock. Assuming that you do something to notify customers while they're browsing that inventory is relatively low (i.e. Amazon will tell you "N items in stock" if you're looking at an item for which they only have a handful of stock left), most customers are reasonably understanding 20 minutes when they get to the checkout and are told that the item is now out of stock since they knew in advance that they needed to order quickly. And most retailers are comfortable that even if they run out of stock of most popular items, they can still satisfy more requests than they have inventory in hand because they undoubtedly have new inventory arriving in the next day or two or they can rush an order for new inventory.