It seems to me that this random walk is recurrent. Denote $Y_n=\|X_n\|$, where $(X_n, n\geq 0)$ is your "spiral" walk. Then, as $x\to \infty$, my calculations imply that $$ \mathbb{E}(Y_{n+1}-Y_n\mid Y_n=x) = \frac{1}{4\|x\|} + O(\|x\|^{-2}), $$ and $$ \mathbb{E}((Y_{n+1}-Y_n)^2\mid Y_n=x) = \frac{1}{2} + O(\|x\|^{-1}). $$ Then, (null) recurrence follows from Theorem 3.5.2 of [Menshikov, Popov, Wade, "Non-homogeneous random walks", C.U.P.-2017, $URL$ ]. 

This does not seem to be true. Take $p=2/3$ and $n=k=1000$. Then, you need that $$ \frac{(2/3)^{1000}}{1-(1/3)^{1000}} \geq (2/3)^{999}, $$ which is clearly false. 

All these questions are answered in paragraph 6 of Chapter III of Volume 1 of "An Introduction to Probability Theory and its Applications" by Feller. In particular: (1) $p=1/2$ is indeed the "right" scale, but the (normalized) number of returns only converges in distribution; it does not converge in probability to a constant; (2) surprisingly, regardless of $n$ the most probable return counts are 0 and 1; (3) the answer is no, because of (1). 

Its meaning should be something like "degree distribution seen from a random edge". Indeed, let us first think of an unoriented edge as of two oriented (in opposite directions) ones. Assume that there are $N$ nodes, where $N$ is large. Then, the total number of (oriented) edges should be roughly $N\sum_d d f(d)$. So, if you choose one edge at random and then ask "what's the probability that the degree of a node where this edge begins is $d$?", it is clear that this probability should be proportional to $df(d)$ (since there are $Ndf(d)$ such edges out of $N\sum_{d'} d' f(d')$). 

Let $(S_n, n\geq 0)$ be the one-dimensional simple random walk started at the origin. Set $X_n=\mathbf{1}\{S_n\geq 0\}$. Then $n^{-1}(X_1+\cdots+ X_n)$ is the proportion of time that the SRW is non-negative; it doesn't converge a.s. anywhere (although converges in distribution to a non-trivial r.v., cf. the arcsine law). Is this sort of example what you're looking for? 

It seems that formula (5.7) of Chapter XIV of the 1st volume of Feller may be used to obtain the full distribution of $C_n$ (as distribution of sum of two independent r.v.'s with explicit distributions). Indeed, to cover the path you must visit both extremes. First, use that formula to obtain the distribution of the hitting time of $\{1,n\}$. Once you hit one of the extremes, you have to go to the other one, and the distribution of this time is the same as the distribution of hitting time of $\{-(n-1),n-1\}$ starting at $0$. Also, see formula (4.11) of the same chapter for the expression for the generating function of the hitting time; this may help obtaining the moments of the cover time. 

I think one cannot find any useful bounds with these assumptions. For example, consider a positive r.v. $\xi$ such that $E\xi^2<\infty$, but $E\xi^3=\infty$. Then, let $\eta_1,\eta_2,\eta_3$ be i.i.d.r.v. (also independent of $\xi$), $P[\eta_k=\pm 1]=1/2$. Set $X=\eta_1\xi$, $Y=\eta_2\xi$, $Z=\eta_3\xi$; then we have $E(X)=E(Y)=E(Z)=E(XY)=E(XZ)=E(YX)=0$, so they are centered and uncorrelated. But $E(XYZ)$ does not exist. 

Let $S_n$ be the one-dimensional nearest neighbor random walk with $ 1-q=p=P[S_{n+1}=x+1\mid S_n=x]=1-P[S_{n+1}=x-1\mid S_n=x]$, where $p\neq q$. Then, there is a (rather surprising) fact that $Y_n=|S_n|$ is still a Markov chain. See e.g. Proposition 4.1.1 of [S.Ross, "Stochastic Processes"]. 

Let $\lambda:=1-\epsilon_1$, $\mu:=1-\epsilon_2$; also, denote $p_L:=\frac{\lambda}{L}(1-\frac{\mu}{L})$ and $q_L:=\frac{\mu}{L}(1-\frac{\lambda}{L})$. Consider a fixed queue (one of those $L$), then it is a (discrete-time) birth and death process with birth probability $p_L$ and death probability $q_L$. You only have to analyse the expected number of wasted times for one queue (for all of them it's just $L\times$ that). Then the limiting behaviour is clear: $W_n/n$ goes to $0$ as $n\to\infty$ for the case $p_L\geq q_L$ (which is equivalent to $\lambda\geq \mu$), since the walk is not positive recurrent. For $\lambda<\mu$ a quick calculation seems to show that it goes to $\mu-\lambda$. If you want exact values for a finite $n$, well, you need to calculate $k$-step transition probabilities from $0$ to $0$ for the above random walk. I think the exact formulas should be available. 

Consider the following simple example of a function $f: \mathbb{R}\to\mathbb{R}$ which is open and discontinuous at all points. If $x\in\mathbb{R}$ is represented as something.$x_1x_2x_3\dots$ in the binary system, then set $$f(x)=\lim_{n\to\infty}\frac{x_1+\cdots+x_n}{n}$$ if the limit exists and belongs to $(0,1)$, and set $f(x)$ to (say) $\frac{1}{2}$ otherwise. Is this example known (I suppose it is), and what's the reference for it? 

You may find it useful to look here: $URL$ (in particular, the link in the 1st post, and also fedja's answer). 

On a more elementary side, the are these probabilistic paradoxes, such as: $URL$ $URL$ $URL$ $URL$ etc. Also, this one is fun: $URL$ 

Basically, the proof goes along the following lines: (1) Take a small $\varepsilon>0$ and show that the expected exit time from the interval $[-\varepsilon\sqrt{vl},\varepsilon\sqrt{vl}]$ is less than $\varphi l$ (this is standard, using the fact that your martingale squared becomes a submartingale with uniformly positive drift, see e.g. Example 7.1 of Section 4.7 of Durrett/Probability) with small $\varphi$. Chebyshev's inequality then will show that you martingale will go out of that interval with probability close to 1 until time $l$. (2) By the Optional Stopping Theorem, with probability bounded away from 0 (in fact, even close to $1/2$) it will exit the above interval through $(-\varepsilon\sqrt{vl})$. (3) now, you only need to show that the walker will remain to the left of (say) $(-\frac{1}{2}\varepsilon\sqrt{vl})$ till time $l$. (4) For this, first note that the Optional Stopping Theorem implies that, starting at $(-\varepsilon\sqrt{vl})$, the probability that the walker exits the interval $[-M\sqrt{vl},-\frac{1}{2}\varepsilon\sqrt{vl}]$ through the left side is at least constant (depending on $M$). (5) Using the Doob's inequality, we then observe that the process is unlikely to reach $(-\frac{1}{2}\varepsilon\sqrt{vl})$ in time $l$. You may find it interesting to look at the proof of Lemma 2.1 in $URL$ it contains all these ideas. 

It's not that simple. See about polar/nonpolar points/sets e.g. in $URL$ If I remember correctly, a set is not polar iff it has positive capacity (w.r.t. logarithmic potential in two dimensions, and Newton potential for $d\geq 3$). 

As for (3) (recurrence in $d\leq 2$ and transience in $d\geq 3$ of simple random walk), there are "electric networks"-proofs of these facts. See the classical book of Doyle and Snell "Random walks and electric networks", $URL$ 

If you are interested in the longest run of 0's in the i.i.d. setting, see this paper: $URL$ Also this: L. Gordon, M.F. Schilling, M.S. Waterman (1986) An extreme value theory for long head runs. Probab. Theory Relat. Fields 72, 279-287. 

In this situation the Foster-Lyapunov criterion still works. Let the state of the system be $n$ when there are $n>0$ customers in the system and the server is working, and $0$ when the server is under maintenance (regardless of the number of waiting customers). Then, $f(n)=n$ still proves positive recurrence, since you have negative drift outside $\{0\}$, and $\mathbb{E}_0f(X_1)<\infty$. See Theorems 2.6.4 (discrete time) and 7.3.4 (continuous time) of this book: $URL$ Let me stress, though, that there is no "easy" way to transfer this argument to multiple servers, because you need the negative drift for all states outside a finite set (and finite mean jump w.r.t. the Lyapunov function from that set). One needs to modify the Lyapunov function in some way (e.g., in such a that the drift towards the "origin" is large when at least one queue is large, this could be achieved by considering e.g. "quadratic" Lyapunov functions). Or use the Foster-Lyapunov criterion "in several steps", see Theorem 2.2.4 of [Fayolle, Malyshev, Menshikov, "Topics in the constructive theory of countable Markov chains"].