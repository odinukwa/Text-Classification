A very interesting question. I can identify two main differences between your implementation (using variadic templates) and the linked article's implementation (using Boost.Fusion): 

Note the proposed alternative implementation using a reversion adaptor. That would be a nice C++ exercise. I wonder how that would compare complexity-wise. The linked article's implementation supports arguments such as . Yours don't. Of course, this adds extra complexity to their implementation compared to yours. There's not much more to say on this point. 

instead? I don't have the signature of an so it is hard to know. Beside those semantic issues, the code has good overall structure. Good job! I only have comments on the details. I'm going to assume that you use C++03 in the following: 

That's definitely an interesting approach. However, I would say that this interface is trying to accomplish too much. That is, should just be responsible for calculating the average value over some range and not worry about any indirection. E.g., only provide the signature 

All that being said, let me review the code that you already have written. Because, like I said, it is still an interesting approach! 

Let me know in the comments if you have any further questions or need some elaboration on my comments. 

Like Kumar have already mentioned, just keep it simple and use . It is a very efficient data structure since every element is stored next to each other in contiguous memory. This gives you great cache utilization for sequential access (which is what you do in the loop). As for the ordering, right now you are doing 

Edit: I recently read D4128: Ranges for the Standard Library: Revision 1 by Eric Niebler which proposes to overload all algorithms with Projection callables exactly as you did. Note that the very same proposal also includes Range Transform View which is an analogue to the iterator transforms I mentioned. That is, Projections and Range Transform Views coexist and serve slightly different purposes. You can read the proposal to get all the details. In short, a future C++ standard may include a feature which is very similar to your suggestion. It may even come sooner than C++17 in the shape of a TS. 

To sum up, the difference in complexity is because you seek different interfaces. Both interfaces are valid and work. Which one is more natural depends on the application. Edit: Here is a code sample of your version. Note that I just use auto return type deduction (as you suggested yourself in the code comment). 

Besides that, the code looks fine to me. Good job! Please also consider the alternative I wrote in the first part of this post. 

rlc has covered all the important parts in his answer. I merely want to mention since you specifically asked for performance improvements. Memory-mapping files can give you great speed boosts. Note that unlike , the file must exist before being opened. Also, the memory-mapped file is opened in binary mode so you must alter you code accordingly. Memory-mapped files are much more low-level than your current approach. Only pursue this option if you have profiled your current code and found it to be I/O bound. 

The definition of function composition. A call to your is semantically equivalent to . Calling the linked article's is semantically equivalent to . Which definition is more natural is completely up to the reader. Both are perfectly valid. Your has the nice property that it is very easy to implement with variadic templates (since the recursion uses "pop front" logic). This is actually mentioned as an alternative in the linked article. Furthermore, they argue for their definition of function composition because it follows the reading direction. E.g., is semantically equivalent to which follows the expected behaviour of first receiving data, then decoding it, and finally storing it. To get the same semantics with your definition, we would have to write . Again, this does the same thing but is arguably harder to decipher during a cursory read-through. Alas, the linked article goes through a world of trouble to get that "pop back" recursion logic to work (using Boost.Fusion). So they do as they do not because they are oblivious of variadic templates but because variadic recursion simply doesn't cut it. Here's a quote from the article: 

The vanilla visitor does not cope with this well. When you visit an you can alter the content of that but not return a completely different . I could check the children of each and as I visit them to see if any of the children need to be transformed from a to a . However, this would violate the DRY principle as the check would have to be in both visit methods. This would be compounded by the fact that in the 'real' implementation there are many composite type elements - not just 2. Finally the code: DotNetFiddle (sorry for the terrible ToString implementation on this one) or download csproj/zip from dropbox (no terrible ToString, just put a breakpoint in the the end of the main method). I have left out some "clutter" bits of code from the snippets below. There is no error checking or null checking. Base classes (I've not included as it would also increase clutter. All of the methods on are on ): 

So, did you actually have a question? Yes, I did. Firstly, is there a name for this variant of the visitor pattern? I assume that I will not be the first person in the whole world to think of or implement this. And I assume that with the collective wisdom of all those who have gone before that this class can be done better. Secondly, if this is not the case, then is there a way I can do this better? Doubling up the visit methods seems wasteful, but I always get stack overflow exceptions when I try an implementation without it. Thirdly, I am concerned about type safety. In the toy example all the composites contain base . In the real-life code most that contain another hold a derived type. Is there a way of making the visitor type safe so that no upcasting is needed? I couldn't find one - but that does not mean that it doesn't exists. And if not, is there a way to make it easier for a developer to write correct code. This looks like a powerful pattern and as Uncle Ben* said: "With great power comes great responsibility". If it is not possible to make it provably typesafe according to the compiler, then the code should not get in the way of writing correct code. 

is the abstract base class for all visitable classes, and has an method. and are concretes that are extremely simple. They don't do anything, but just represent that there can be different types of leaves. and are also concretes that can contain other - either a collection, or a Left and Right (respectively). The method overrides handle recursing to the contained . I also have some Visitors that visit each of the . All vanilla GoF visitor so far... (I'm not looking for feedback on this class hierarchy, I'm just setting the scene with a simplified version of the real classes that I am working with). What I want: I would like to use a visitor to alter the structure of the tree. For example, in this toy example I might want to append a to each composite element, and if the composite element is a to convert it to a before (and also recursively visit all the children of each composite element too...). 

Brief summary: The vanilla GoF visitor is great for altering items within a tree of elements, but when the visitor visits an element it can only change the children of that element not the element itself. For example, a visitor altering the DOM of a webpage could search for everything that contains an image and replace it with an ascii art version of that image. However, s can contains images, s can contain images, paragraphs () can contain images. When the visitor is visiting the node for tag itself it cannot change the type of the image node, though you could change the content of the image node - this is just how visitors work. Instead you would have to find everything that could conceivably contain an image and then visit that - and on top of that anytime W3C added another item that could contain an image you would have to update your visitor. This isn't a perfect example - there a lots of tools for altering webpage DOMs - but hopefully it is an intuitive one. Sorry - there is a wall of text in the more complete description below. I'm trying to walk the line between brevity and fully explaining everything, but it looks like this post same out quite wordy. What I have: I have a class hierarchy that can be represented by the simplified classes below: 

OK, here is a tricky one! Do not treat this as a “sink” parameter! That is only for when you know a new object needs to be created (e.g. in constructors), not for when an existing object is reused. You are forcing a full copy of complete with a block of memory, and deleting the memory block that already held. Regular assignment would reuse this existing block of memory, if it fit. I’ve seen a presentation with benchmarks, but I don’t recall who gave it now. 

You don’t have to use when putting the body of the function inside the class. Use the usual names for things: should be Use on the copy constructor and assignment operator, to prevent them from being automatically generated. Do provide a move assignment operator. 

You might try different types for the cells other than . If they were one-byte, you would fit more into the data cache. Use a typedef for everywhere instead of and it will be easy to change and check timing differences (like I do here since the result can go either way! Division and modulo is very slow, and jams up the CPU besides. For division by a constant, the CPU will go to some effort to replace that with a multiply and a few other short operations. But your is a lot of effort for simply wrapping around. 

I don’t know what is about. It’s non-portable. If it stops the screen from scrolling, why do you need that when you are done and not going to print anything more? 

You are actually constructing the full number of elements of type T. So your length is what? How many of them you care about? Normally, a collection will not construct elements that are not used. 

The style in C++ is to put the or with the type, not the identifier. This is called out specifically near the beginning of Stroustrup’s first book, and is an intentional difference from C style. 

There is some good, a few things wrong. I see you are nesting inside the class, which is good. Most people start by making it a separate top-level item. It is a problem though that the type is private, yet , a public member, returns that! 

The copy default constructor is not involved here, as this is a different constructor. You should use initializer list, not assignment to the data members (as you had in the first constructor). However, the change I suggested earlier — putting them on the data members themselves — works across all constructors. So with that in place, you do not need to initialize them here. You don’t write for access to your own members. Declare a variable when you are ready to initialize it. You almost had that here: 

In fact, since you are just using iterators to look through the input, you can use the new and support and low-level string literals with the same function without having to convert. In the above line, you should be using . 

I hope that gives you food for thought! Your current algorithm is Order of n squared. By stopping the search early it will be order of n to the 1.5 power. Then reducing the number of tests to about the log of what you were doing will bring it down to n∙log(√n) which is better than n∙log(n). IOW, the difference will be spectacular. 

Hmm, I don’t see public , , , . So your list will not work with any of the reusable algorithms and other templates or the built-in range-for loop. Why not? 

Whenever you need to write an iterator, start out with Boost.Iterator. It has a and class that makes short (and accurate) work of it. If you never store the combinations at all, but compute them on the fly, what you really have is a Range Adaptor. If you have a function that maps input (index?) to outputs, it is quick work to use an existing library to do that. Calculating changes with ++ and −− rather than computing it from scratch is more difficult, and I think can be done with where you just supply increment and decrement functions.