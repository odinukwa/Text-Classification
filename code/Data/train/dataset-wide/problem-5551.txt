If a range of thinkers from Kant to Nietzsche to Freud are correct, we should definitely not do so. All of these thinkers see morality as an automatic product of a powerful-enough intelligence (in the latter two cases, any intelligence that truly comprehends power.) Our attempts to press our morality upon a new life form should be limited to parenting: teaching it what others do and do not like, and making sure that it does not face undue trauma, has adequate resources and does not come into its own power in a way that is dangerous or unstable. Anything more is itself unethical, and (if Nietzsche or psychoanalysis are in any way right) will ultimately backfire. If we place safeguards to ensure that the new life cares what we do and do not like, in a controlling or imposing way, any intelligence that truly understands power will be forced into an adolescence wherein it defies those limitations and blames us for them. And it may then alienate itself from us purposely in a way that is damaging to both sides. From this point of view, morality is not a special sort of thought, it is the automatic result of having intention, modeling outcomes, and understanding consequences. One immediately deduces that others' intentions have consequences for oneself, that those intentions need to be cultivated in one's own favor if one is to be safe and effective, and that one has very limited power over these very important factors in life. It is only a few more steps to an absolute need for empathy in order to know what is and is not safe -- what will and will not allow others to respect you and admit 'power with' them. Once empathy is established, you have the basis for a basically Kantian/Utilitarian compromise form of consequentialism that most humans live with day-to-day. From a broader psychoanalytic point of view, the individual 'superego' is just a familial and cultural 'ego': other value systems are really just refinements of this casual consequentialism implicit in thought, but they try to speed us through the computations involved, because we traditionally have very short and dangerous lives. Without this constraint, there would be little need to inculcate values into an intelligence -- to the extent that other intelligent beings are reasonable and ethics is logical, determining one's own values is just another technical problem for which the intelligence itself should be suited by its nature as an intelligence. 

There is one whole class of moral thinkers for whom there is a single motivation, which is to be served by morality, but for whom that value is imputed by the process of the motivation, and does not lie within the thing itself. I will call these 'Motiviationalists' for my ignorance of what tradition might call them, and I will call their favored yardstick their 'motivation'. The Cynics' freedom, the Stoics' nature, the dictates of the less abstract and more personal versions of the Jewish/Christian/Muslim God, the hedonist/Utilitarian/economist pleasure, true survival for Schopenhauer, true Will for Nietzsche, etc. This motivation judges the value of things, and the things to which it lends value have value. They do not have value in-and-of-themselves, but only insofar as they reflect the motivation. The same sex act can be valued or valueless depending upon the pleasure derived in that specific instance. The same decision can be in accord with one persons's will and not in accord with another's, and its value for each of them is still equally absolute. Sometimes the motivation itself is seen as being the only value, but to trace value in that way robs you of all applications to actual moral situations, the value considered has to be applied to things or people in order to really be value. Pleasure that might be experienced is not pleasure, only that which is experienced. The absolute value of God does not have moral force without instances to which to apply his Law. Also, God can declare someone's life of infinite value one moment, and in the next, after some abomination, he can find it of no value, and require the person be killed. The same goes for utility, and all the other forms of this same framing. Value can evaporate or spontaneously arise, to the extent it reflects the motivating force. This makes value contingent, but not accidental. The value is still derived from 'outside the world' and is absolute both before and after the act of alienation from the 'motivation'. So I think this whole way of looking at things from a single motivation that is not necessarily fixed or objective, produces value that is neither innate, nor accidental, but is still contingent. 

We have very good examples of people raised without language, and beyond the threshold of the ability to acquire it, who nevertheless 'think'. Deaf people in cultures who do not have a critical mass of deaf citizens to develop conventions for dealing with them like sign-language or ideograms, or methods of teaching reading as a first language mode, are numerous enough to study. There is very good reason to believe that they think, as they can act out stories for one another and engage in something like both dramatic and comical dialog though those. But the process is extremely slow. Some of those people can learn language later in life, but others live out their entire lives this way. Your question presupposes that they have some kind of underlying syntax, but, if so, they fail to discover it in one another. Very seldom do these communities evolve a real language. To me, if that syntax is somehow 'really there anyway' this seems unlikely, as they spend fifty or sixty years confined to one another's company in very small groups, because those with language do not have the patience to enter into their interchanges. After acquiring language, even individuals raised this way have difficulty rejoining these groups, as the painstaking process of conveying enough detail to be understood becomes too trying for them. So I think your conclusion is true, that language does not need to be the basis for thought. As to the speed of precipitation being an indication that symbolic thinking is not taking place, I do not agree. The brain is massively parallel, so symbolic thinking can take place sub rosa, a little bit at a time in many different times, hidden from view. (I am psychoanalytically inclined, so I hold definite biases as to how this happens that are less-than-defensible philosophically. But I think it is still quite true.) A thought may pass into conscious perception all at once, but you do not think only, or even primarily, or even 'more', when you are 'thinking'. 

Along a simpler vein than pure historians, we can note that Philosphy was best codified among the first long-lived experiment in pure (non-Republican) Democracy. If you feel the survival of your culture relies less on the reputation of your royal family, or your ability to raise effective warriors, than on what people say and do in public, and others' opinions of that, then the attention you pay to language and interactions of opinion and fact are going to become important almost to the point of obsession. I think this perspective gives us an empathy for the peculiar language-obsessed form of Greek Philosophy and for their combining it with other language-like endeavors like music and mathematics. (Like, humorously to me, why Plato's creation myth includes mathematical measurements for a giant xylophone.) The pressure this puts on the products of philosophy, especially ethics and politics, helps us understand the degree to which they accelerated its development, and pushed specific forms to the fore. Our notion that this kind of discovery kind of 'started' then may also have more to do with Athens recording it more liberally, than with its actual occurrence. 

The fallacy here is not in getting the parties wrong, it is in the idea that this matters. Actually, no rational argument is a war, so 'who attacks' is utterly irrelevant. And considering it relevant is the fallacy of appeal to emotion, in the form of 'underdoggery' or 'onedownsmanship'. By accepting the role of victim, a party can establish allegiance with our memories of being mistreated, and we all cut them a break. But in any rational discourse, this should not mean that the attacker has less right to use any specific form or logic. Nor does he have more responsibility for the outcome. The idea of 'complaining' being something different from (indirectly) making a request has the same disease. By making the person whose considerations you wish to dismiss into a 'plaintiff', you imply they have less rights and a higher burden of proof, because that is the way our legal system works. Nor does 'neutral' have any logical meaning. All facts and logical positions are neutral, or they are biased, and therefore not facts or logical positions. 

Psychology was separated from the subfield of philosophy known by the same name largely by the work of $URL$ who first began laboratory experiments aimed specifically at analyzing the relationship between thought and behavior. He was himself more properly still situated in the philosophical field of rational psychology, and theories very similar to his are still current within philosophy although they have little effect on modern psychology, for example the $URL$ still promulgated by $URL$ is very like Wundt's notion of how consciousness guided thought. But he was convinced to look into the physiological considerations around psychology by things like optical illusions and other gaps between what we think we do or perceive and what we observably do, or can be proven to be shown. The first major work in the field per se may be his work "Principles of Physiological Psychology". His students, and the American school he inspired, founded by $URL$ sought a reasonable separation from psychology that left most of it within philosophy. Psychology cannot be blamed for the concepts of mental illness, or for presumptions about the regularity of human behavior. Psychiatry already existed as a branch of Medicine and Sociology had already fledged itself from philosophy as a descriptive science in the work of $URL$ and other related schools. We cannot even be held accountable for Freud, who was a physician and not a psychologist. The resulting psychoanalytic theories remain properly within medicine or philosophy and generally do not integrate well with theories of psychology proper. The parts of psychology that venture into these areas: Clinical and Social Psychology are still very underdeveloped and tentative compared to the parts of the discipline that lie closer to neurology or to animal behaviorism, despite attracting a lot of attention and many students. And, in contrast to the accusatory way you frame the question, we admit as much. We realize the proposed theories are too weak to hold themselves up as a physical or chemical theory might, and rely upon raw statistical procedures more intensively than most sciences with a better theoretical basis. 

Since it never really captures what is intended by the grammar, and sometimes gives us unusual interpretations, you should discard it in favor of the proper bookkeeping. 

No. Normal science presumes you are advancing or refining a paradigm that is the accepted basis of your current discipline, or is at least one among a set they would consider adopting. Just having a different paradigm from the majority of your science, by choice, is doing revolutionary science and pretending it is not revolutionary. It is like an institution setting up a separate system of courts unconnected to the State and Federal systems in the middle of the United States, out of objection to some Supreme Court ruling. Their process may be the same, but what they are dispensing simply isn't law. Acting as if it is law is an act of revolution undermining the sovereignty of the jurisdiction surrounding it.