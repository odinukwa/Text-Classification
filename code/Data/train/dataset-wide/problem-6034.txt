Point 1 (probably) requires some degree of consistency since policy implementations will butt up against the real world, but by no means requires absolute internal consistency, especially since the criterion is "good enough" rather than "best possible". Point 2 only requires the degree of internal consistency that the voters require, which is apparently pretty low. For example, the existence of "single issue voters" means that if a party takes position X (and the other party(ies) take position not-X), then they can be assured of all X-issue voters, irrespective of whether their position on issue Y can be justified using the same underlying principles as were used to justify X. There are some indications, that on average, these voter's decisions are not made fully rationally, nor with a goal of achieving overall consistency. The book "What's the Matter With Kansas" by Thomas Frank, for example, claims that voters in Kansas are not voting with there own self interest in mind, but is more anecdotal. Various studies have tried to tease out the interactions between personality and politics, there is even an entire journal of Political Psychology. Political parties can assemble whatever hodgepodge of issue positions that they require in order to succeed. There will only be a cost to the party in a democratic society if enough of the voters require policy consistency to affect the outcomes of elections. It is plausible that for the majority of voters in most societies are not explicitly rational. To the extent that political party affiliation is not rational, this is not a philosophical, but rather a psychological question. 

In How the Mind Works Stephen Pinker (and references therein) argued that music, in itself, is not a product of natural selection; rather natural selection acts (acted) more immediately on lower level brain functions: pattern matching, sensory processing etc. Music then developed (culturally) to stimulate these adaptive brain functions, in a way that is pleasurable. Here's a short (popular) article on work following up on this idea. By no means is this settled science, I'm posting it mainly to indicate that there is another potential mechanism when looking at evolutionary processes: the feature under consideration is a side effect (without significant evolutionary effects per se) of features that are under selective pressure. There is evidence that other mammals, almost certainly other primates and likely (due to similar brain structure) other mammals, perceive octaves as equivalent. Thus any selective pressure for this type of perception was occurring long before humans evolved. There is also some hypotheses on why octave equivalence could have been selected for in the first place. 

Occam's razor favors hypothesis (ii). There is only one way for everybody to have consciousness; thus consciousness is just part of the definition of person. Figuratively, this is just one extra feature of the world, and is required in order to explain why other people seem to respond to situations similar to the way I do. If some people have consciousness, I have to add an extra label to people, conscious vs. not, in order to describe the world. Figuratively, this is "number of people" additional features of the world. It is these extra conscious/unconscious labels, to people who otherwise act equivalently (to me, and each other), that constitute the "plurality" that "posited without necessity". 

Punishment for immoral actions can prevent additional harm, e.g. incarcerating the criminal prevent him/her from harming society at large. The threat of punishment can serve to prevent some kinds of immoral actions; the threat must be carried through for this to be effective. Thus there can be instrumental utilitarian justifications for punishing criminals. [Note: this is probably not the only way...] 

However, this process can be always be executed by a machine that just recreates (simulates) this whole process on demand, i.e. starts with item 1. and ends up with the results of item 3. Thus there isn't anything new or novel in the "new algorithm" that wasn't already specified in the initial data. So in a very formal, narrow sense, an algorithm cannot create a truly new algorithm; of the content of the later algorithm is encoded, in some manner, in the initial algorithm (and any data used to configure that initial algorithm). 

You've provided the answer in your question: in practice the law does (still) include retribution as a consideration, even though many philosophical theories of how the law should work would remove that feature from consideration. This is one aspect of how legal is not identical with moral (or illegal with immoral). Reconciling the retributive and consequentialist bases of law is part of its ongoing evolution. 

Yes, we live in large societies where on a day to day basis we meet and interact with strangers (usually peacefully). Earlier societies were organized in smaller groups, tribes, villages, where to a large extent "everybody knows everybody else"; in modern societies you are regularly having expendable, effectively one-time interactions with strangers. By this definition "modern" may go all the way back to say, parts of the classical world, but in the recent past, this pattern of interaction has become the norm in many societies. This idea comes from Jared Diamond has written and spoken on the topic of how traditional societies differ from modern industrial ones (and here). Another point that he makes that strikes me is that we almost exclusively eat food that was grown by a stranger. 

I'll follow up with some references below, but first consider these ideas that I, arguably a philosopher, would use to try to convince someone that qualia exist: 

(P) All language activities involve the use of words, whether those words are expressed externally (spoken/written) or internally (your internal monologue). (P) Music composition does not involve the the use of words. (Emphasis on music because we are not talking about lyrics and songwriting) (C) Thus, music composition is not a language activity. 

Dirac just asserts this, but in fact this is an empirical observation Dirac just asserts this, but in fact it is an empirical observation This is LP if it is interpreted as a statement about the formal mathematical theory, and not a statement about "reality". 

In terms of the meanings that Krauss (and many other physicists) would use, his description of "something from nothing" is correct and precise. However, in his popularization, the groundwork for defining these terms is often glossed over (or missed) and thus "something from nothing" comes across as more of a rhetorical flourish. Krauss is a physicist so defines stuff as the quantum-mechanical fields associated with the fundamental particles that permeate space. You can see this at this point in one of Krauss's lectures on A Universe from Nothing. He defines "everything" as all tied up in the $T_{\mu \nu}$ (which corresponds to my, less formal, QM fields) in the Einstein euqation, and thus the cosmological term is the "energy of nothing" (his term). So then, what is nothing: the absence of the QM fields and the associated space-time. I'd claim that this definition of nothing is consistent with dictionary (colloquial) definitions of nothing: the absence of all of the "stuff" that makes up our world. In multiverse theories universes containing ensembles of QM fields and space time must emerge in the multiverse structure which lacks these features, i.e. something from nothing. In one sense he's stretching the meanings of words (like nothing) for dramatic effect, however, in another sense when he says "nothing" he is referring to a specific limiting case of physical models and thus is being quite precise. I think that an argument can be made that this physicist's version of nothing, although precisely defined in and of itself, is not a philosopher's (metaphysical) nothing -- The exchange quoted in Mozibur's answer illustrates this in that Harris asked about something closer to metaphysical nothing and Krauss repiled, in effect "I don't know". Thus, I'd say with careful reading Krauss's claim of "something from nothing" is precise and accurate, although if you push hard enough on the concept of "nothing" it can seem misleading. 

Fallacy, shamallacy -- don't try to short circuit analysis by playing pin the fallacy on the argument. Whether Alice's statement is an appeal to authority depends in detail on what her intended meaning is, and how Bob interprets it. If Alice intends (or Bob interprets) the statement as indicating that "we should defer to these people on this issue because of their [social|political|intellectual] standing" then it would be problematic. Note that Locke's original name for the fallacy is the "argumentum ad vericundiam" which I'll translate as "the argument to deference" -- i.e. an argument that in some moral/social sense you should defer to people of elevated status (c.f. this paper by J. Goodwin which includes an interpretation of Locke's formulation near the end). If instead, both Alice and Bob interpret this statement to be a quick way of stating something like "These experts have looked at topic X in detail (which we don't have the resources to do), and are reporting on what they found; thus we should give credence to what they say", then the findings of the experts need to be assessed subject to the same considerations as other testimonial evidence. This is why both sides point the the bulleted items in the OP: these types of factors are the kinds of things that can bias peoples' testimony and thus degrade its reliability. There is the same kind of breakdown in terms of the appeal to consensus: in one case you interpret the existence of consensus as "a thing" and thus should defer to it, which corresponds to the argument from consensus. The other interpretation is that the consensus is a summary of the conclusions of the group of experts involved. In which case it falls back to, collective, testimonial evidence. 

"The cat is on the mat" is only true for only one conceptually distinct "state of the world". "The cat is not on the window sill" is true for a large number of conceptually distinct states of the world: the cat could be on the mat, or the cat could be on the table, or the cat could be in the sink... Thus the "negative" fact is, in this sense, less specific; kind of, say, insubstantial. One aspect of this is that a multiplicity of negative facts flow from (are entailed from) one "positive" fact. If the cat is on the mat, then the cat is not on the window sill, and the cat is not on the counter and the cat is not on the table... (unless of course, we're talking about Schroedinger's cat). Although this is the logical case, most people, most of the time, don't think about any of these implied facts -- thus they are not "clearly seen", i.e. shadowy. A final note on "conceptually distinct": this is setup by the context and actual description of the fact. If you look at the details, "the cat is on the mat" can be satisfied by a large number of "states of the world": the cat could be sitting on the mat, or lying down down... But just from the conventions of normal English usage, by indicating that the relevant status is "on the mat" the speaker has implied that these details don't matter for the conversation at hand; hence the inclusion of "conceptually distinct". 

In some circumstances, there is a way to justify it in terms of utilitarian considerations (which is one of the issues of utilitarianism -- what is the goodness metric?): By prosecuting the war as effectively as possible, the soldier can reduce the overall time that the warfare lasts. This has benefits (or lack of badness) in terms of disruption of people's lives, number of people killed/injured on both sides (if your opponent surrenders earlier) and so on. Once the crisis of war has passed, there might be the opportunity to address the nation's corruption. One can make a plausible specific case by considering a case where atrocities are committed and significant reprisals can be expected: Countries A and B go to war, some people from country A commit atrocities, the citizens of country A are convinced that their opponent will exterminate all of them as reprisal if country B wins. Country A's soldiers have a utilitarian basis for trying to win the war -- to prevent the expected reprisal, despite the fact that they know that people from their country have committed atrocities.