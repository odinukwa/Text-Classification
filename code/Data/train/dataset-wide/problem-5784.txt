When an issue is debated in good faith, it is possible for both participants in the debate to come away with a better understanding of the issues than they entered with. When one or both participants debates in bad faith, the other participant is far less likely to benefit. Note that there is a difference between playing devil's advocate versus arguing in bad faith. The former hopes that by arguing a position contrary to his belief, he will cause the other person to better articulate his beliefs (and those of the devil's advocate) than either person would be able to do in the absence of the contrary argument. By contrast, one who argue in bad faith hope to make his victim believe things the bad-faith arguer knows to be false, in the hopes that the victim will engage in some action which is detrimental to the victim but beneficial to the bad-faith arguer. That fact that a person engages in hypocrisy does not prove that the person's arguments are not valid, however it a sign that the person may be arguing in bad faith. If someone has no interest in good-faith debate, arguing with them will be a waste of time. Although the validity of a good-faith argument will not be affected by the character of the person making it, the extent to which an argument is worth considering is fundamentally dependent upon whether it is made in good faith, and that will often correlate strongly with the character of the person arguing. 

What exactly is the vocabular meaning of "Will to power", as Nietzsche meant it? I think it means: Will: Noun, meaning desire, drive, desire, wish, determination. To: infinitive marker, indicating verb is in the infinitive form To Power: verb, meaning to impel, to force, to direct, to command or control Is that right? Alternatives meanings might be: To: Preposition, meaning towards, approaching Power: Noun meaning domination or ascendancy 

You will easily devastate poorly-founded justifications for the existence of God but you will always struggle to devastate arguments such as these. 

Heraclitus famously believed in the equality of opposites, as do I. Would the truth of the equality of opposites have any significant implications for reason and logic? 

To draw a boundary around a 'thing' and say 'that is a thing and is apart from the rest of the universe' is a deception. You cannot have table without wood and you cannot have wood without a tree and you cannot have tree without the Sun and you cannot have the Sun without the Milky Way. And so it is, with a person having free will, and for an AI. So to argue that one of these had no free will because the outcome of some exercise was predetermined, save for some unexpected external stimulus, is not a valid argument that the object has no free will. Since you can neither draw a boundary around some AI nor around a person and state 'this is the full extent of that object, and this is the full variety of its possible outcomes.' Who is to say that a fixed outcome for some AI is a single fixed outcome from the AI's point of view? 

...is pretty much my answer: Meaning is internally constructed from (or formulated into) external physical constructs or events, which are themselves meaningless but decidedly non-arbitrary. However, what counts as "meaningful stimuli" is not objectively determinable. Rather, it's in the eye of the beholder. If we agree that removing one's glasses means buy and scratching one's chin means sell, then those are meaningful signals to us, but no one else. Thus, whether patterns of ink on paper, or photons from a display, or transistor voltages constitute "legitimate semantic representations" is neither true nor false. It depends on the potential interpreters, their capabilities, and their contexts. 

the level-1 relationship: Searle-UTM to the English program symbols (#1), the level-1 relationship: Searle-UTM to Chinese symbols (#2), and the level-2 relationship: the program's computation to the Chinese symbols (#2). 

* Obviously, full blown self-conscious intentionality is not required for computers, but translating a program's symbolic references into physical entities, actions, and events is required. That goes beyond formal symbol manipulation into enacting non-formal associations. Ref (and see refs therein): Refuting Searle's "syntax is not semantics" argument. 

As you and others here have said, your CRA reply is essentially the most common one, the Systems Reply. But your statement misses some important aspects, such as Searle's point about formal symbol manipulation, which is the one thing his CRA gets right. To understand how both things can be right: lack of semantics at the Searle-computer level and the potential for understanding at the CR-system level, one should understand the relationships among the Searle-computer and its two kinds of input. The Chinese Room's heat source is the fact that it produces two levels of Turing computation, both of which are processing the Chinese symbols. Level-1 is Searle himself, acting as a UTM-computer (a universal Turing machine; like a CPU). Level-2 is "the system" whose computation of the Chinese is determined solely by the program and its execution configuration (memory, state, etc.). Note that the existence of the two computations is a fact, not as in "I'm stating my opinion as a fact", but as in "it is an objective mathematical fact, like the Pythagorean Theorem, which anyone can understand and verify for themself". Searle's self-consciousness is a kind of 3rd level of "information processing" (which might or might not be a computation). It allows him to introspect on his own level-1 universal computation. But he cannot similarly introspect on the level-2 computation. For level-2, the Searle-UTM is merely its physical substrate, analogous to a person's neuron-level, not their consciousness-level. Thus, the Searle-UTM never knows what his program is doing, whether it is doing a Turing Test or taxes or tic-tac-toe. Also note that the Searle-UTM is processing two classes of symbols: #1 the English symbols of the program, which people always ignore, and #2 the Chinese symbols, which captivate people like shiny objects. Thus, to correctly address "symbol manipulation in the CR", one must fully address the three symbol-processing relationships: 

There's a class of scientist (and non-scientist) that pursues the atheism argument religiously. It seems that their ears are closed to reasoned argument. They are typically, in all other spheres of thinking, high-intellect, scientifically-minded individuals, and sure, they have reasoned arguments for their side of the argument, but on this particular subject, when it comes to considering counterargument, they seem to set out with unquestionable faith that a theist's position cannot possibly be a result of superior argument, intellect or understanding. Presented with strong arguments, they may become emotional or hostile, rather than allowing evidence or strength of argument to decide the matter. I think of these people as "religiously atheist" which for me exposes the paradox of their state. Is this a fair or accurate description? By that, I am asking if, in your experience this is a fair stereotype of a significant number of people? 

If you permit things to exist in our imagination then the property of existence in the real world can be a predicate of these things. Irrespective of whether God actually exists, he nevertheless exists as a concept and has certain properties in people's imaginations. The God in our imaginations and the God which actually exists, if he does, are one and the same thing. Therefore the God which definitely exists in our imaginations, may or may not, depending on whether atheists or theists are right, possess the predicate property of existence in the real world beyond our imaginations. 

In the CRA, Searle only addresses the 2nd relationship: his own UTM processing of the Chinese (#2), which he correctly characterizes as formal symbol manipulation, i.e,. syntactic and meaningless or non-intentional to him. Your reply above does not account for this 2nd relationship. For when you speak of manipulating English symbols in your mind, the key difference is that your mind can interpret them, whereas the Searle-UTM cannot itself interpret the Chinese symbols. That's Searle's main point, and he is correct about that much of it. (His mistake lies in missing the other aspects of the two computations.) Virtually no one addresses the 1st relationship. However, clearly the Searle-UTM must process the program symbols with some level of semantic intentionality.* That is why they must be in English! This fact alone contradicts Searle's own CRA conclusions. Most importantly, the 3rd relationship is approximately the famous Systems Reply, as mentioned. Searle tries to dismiss the Systems Reply, and apparently people are left to decide for themselves whether they agree, disagree, or prefer to focus on some other aspect of the CRA or science fiction or philosophy, etc. But the key point about the Systems Reply is this: although Searle cannot discern it, the additional level-2 computation is not merely some philosophical assertion. It is a mathematical fact about how Turing computation works. A universal computation on its #1 program input and its #2 nominal input, instantiates the program's own distinct TM computation on the nominal input. Period. Trying to rebut this would be like trying to rebut the Pythagorean Theorem. The slight difference here with the usual Systems Reply is that one cannot further assume that the Turing Test is valid. The CR's external behavior does not prove that the program's algorithm is equivalent to a human's internal understanding of the Chinese. But the CRA does not disprove it, so it remains an open possibility. Presumably, that is why over the years Searle has evolved his critique to more properly address computation in general, rather than just the CRA's focus on universal programmability. 

A proper reductio ad absurdum argument relies upon the fact that if a premise is true, an absurd conclusion would unavoidably follow. The word "unavoidably" is key; if any step is not logically forced by the previous step, the entire argument falls apart. In the scenario at hand, the premise (that there is an illegitimate bias against "rich" defendants) could be true without the "absurd" statement (that no factors other than a defendant's wealth are even considered) being true. Consequently, the absurd statement does not follow from the premise, and the premise is in no way invalidated by the absurd statement. Indeed, the argument is so poor as to suggest the person making it might not be debating in good faith. 

In the course of debating many political issues, it is very common for both sides to claim that various things will have various effects, without either side being able to definitively prove its case. Over the years, I have found that in many cases when one side claims that one political action will cause some particular chain of effects and the other is arguing that such a chain of effects will not occur, the latter party in practice ends up deliberately instigating the very chain of events they claimed would not occur. In formal argument where there is fundamental agreement upon premises, the credibility of one's opponent doesn't matter. In politics, however, when arguments are predicated upon unproven claims, it is necessary to judge the credibility of the participants' claims, and such judgements may often be very reasonably based upon judgments of the participants themselves. The fact that a person is of bad character would not imply that they are incapable of making a valid argument, but should cause one to regard with extreme suspicion the claims upon which their argument would rest. 

When I read this, I understood it. How? For me, the objects being processed were photons from my computer screen impinging on cells in my retinas. Those photons contained zero "semantics". However, their physical properties and configuration were far from accidental. Primarily, the semantics in your head determined them (based on a human & technical foundation). That physical signal was sufficient to cause in my head (1) a symbolic representation followed by (2) a syntactic & semantic interpretation (all based on a similar foundation), which hopefully is reasonably close to the one that your head intended (although certainly not identical). Semantics does not lie in transmitted tokens (signals). It lies in the (more or less shared) structure, function, and content (memory) of the machines doing the formulating and interpreting. 

As you say, the difference between extrinsic (observer-based) and intrinsic (subjective) symbol-manipulation semantics is key to the Chinese Room argument (CRA) (cf. the symbol grounding problem). However, I don't see that the abstract-vs-physical distinction between computation theory and physical computing devices addresses this issue directly. Computation theory is just another mathematical model, like calculus or geometry. Finding logical "0, 1" symbols in a physical computer is no different than finding straight lines and 90-degree angles in buildings. If we believe that the abstract, mathematically based theories of engineering truly keep skyscrapers from falling and planes in the air, then the dancing voltages in my bank's computer also truly represent the logical "balance" of my logical "checking account". Physical computers "manipulate symbols" to the same degree that buildings "obey statics" and planes, "aerodynamics". Fortunately, the distinction between idealized math and the real world is not needed to fully understand the CRA. Because it is grounded by Turing machine (TM) theory, the CRA's analysis can be much less esoteric and much more precise and objective. The CRA expertly focuses everyone's attention on the wrong symbols: the Chinese inputs and outputs. Like a magician, Searle makes you ignore the elephant in the Chinese Room: the program. It, too, is a symbolic input to the Searle-computer. (He also hopes you'll miss the fact that it's in English!) The program (aka, the rule book) is the key symbolic input because it alone dictates how the Chinese symbols are processed. The only reason the Searle-computer can (and must) process the Chinese symbols purely formally is because he also has the program-rule symbols, which he can (and must) interpret non-formally. As a universal TM, the Searle-computer's main responsibility centers on the program itself. Searle directs everyone's attention solely to himself and the Chinese symbols, yet he is wholly superfluous to their computation! The Searle-computer and its program input could--and should--both be completely removed from consideration. Replace it by a direct, non-programmable implementation of the program and the room would function identically. Hence, Searle's claim that the room processes the Chinese symbols purely formally (as opposed to just its Searle-CPU) is totally unfounded because he fails to account for the program's own computation (whose existence is irrefutably explained by Turing machine theory). The degree to which the program's computation interprets the Chinese semantically (or not) remains undetermined. Hence, the CRA establishes absolutely nothing about the semantics in the room regarding the Chinese symbols. References: Syntax vs. semantics, chineseroom.info