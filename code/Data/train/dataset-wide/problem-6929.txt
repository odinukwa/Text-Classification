Your example is the classic Allais paradox. I think the best way to see how the preference pattern $L_1\succ L_2$ and $L_3\succ L_4$ violates independence is to visualize it geometrically. Consider the following figure: 

Converting my comments into an answer... In the infinitely repeated game, if the players want to collude on $(L,L)$, then there needs to be an incentive for each to stick to the plan, i.e. a punishment if one of them deviates from playing $L$. As you have figured out, this amounts comparing the discounted payoffs from playing $(L,L)$ with a one-shot deviation of playing $H$ against $L$, and then playing $(H,H)$ forever. 

The Journal of Economic Science Association, a companion journal to Experimental Economics is one outlet devoted to publishing, among other article types, replication of experiments. As said on the website of the Economic Science Association: 

Hint By colluding, presumably the two firms would like to figure out the least costly way to produce in order to maximize profit. Treat the two firms as two production plants of a single "parent company". The total cost of the cartel can then be found by solving \begin{equation} C_\text{cartel}(Q)=\min_{q_1,q_2}\;[C_1(q_1)+C_2(q_2)],\quad\text{s.t.}\quad q_1+q_2=Q. \end{equation} This will give you a the optimal way of distributing production across the two firms, $q_i^*(Q)$, as a function of aggregate output $Q$. Then the cartel's total cost is just the sum of the member firms' costs evaluated at the optimum: $C_\text{cartel}(Q)=\sum_i C_i(q_i^*(Q))$. 

First, you should note that there is a Revenue Equivalence Theorem that says under a set of conditions, the seller's revenue from using different forms of auctions will be the same. This same result holds also in the multi-object case. Thus, if you have $n$ identical objects, you can sell them using a ($n+1$)th price sealed bid auction, where 

Consider three different consumption bundles: $(3,10)$, $(10,10)$, and $(10,3)$. Verify that these three bundles yield the same utility to the consumer. In other words, they should lie on the same indifference curve. Then draw a curve through the three points. Verify that all points described by $(x,10)$ and $(10,y)$ for $x,y\le10$ should also be on this indifference curve. 

At the end of the day, the firm seeks to maximize profits, which is a one-dimensional object. So the firm simply solves \begin{equation} \max_{\mathbf x}\;\mathbf{p}\cdot\mathbf f(\mathbf x)-c(\mathbf x) \end{equation} where $\mathbf x\in\mathbb R_+^\ell$ is a vector of $\ell$ inputs, $\mathbf p\in\mathbb R_+^n$ is a vector of $n$ prices for the final output, $\mathbf f:\mathbb R_+^\ell\to\mathbb R_+^n$ is the production function mapping $\ell$ inputs to $n$ outputs, and $c:\mathbb R_+^\ell\to \mathbb R_+$ is the cost function. This is a standard unconstrained optimization exercise that any first year grad student in economics should know how to solve. The standard textbooks --- MWG, Jehle and Reny, Simon and Blume --- have sections that cover the techniques. 

Instead of calling the three strategies you named the "best possible replies", I would say that they are the most salient replies. As you mentioned, there are many other potential responses to a tit-for-tat strategy. It turns out that what best responds to a tit-for-tat strategy is also a tit-for-tat strategy. Every other strategy will produce a lower payoff than using the tit-for-tat. Consider the sequence of outcomes generated by each of the three strategies you mentioned (played by $i$ against the other player's tit-for-tat): 

Let's review the definitions of the two concepts. Let $\sigma$ be a profile of strategies and $\mu$ a system of beliefs. 

Game Theory Explorer The game theory explorer is developed by a few people at LSE. It allows users to input matrix-form games or build extensive form games through a GUI. It also seems capable of converting between normal and extensive form games. Additionally, the software comes with a solver that looks for Nash equilibria of the inputted game. 

Yes. Taxing consumers reduces their willingness to pay. Therefore demand curve shifts down. Taxing producers raises their cost of production. Hence the marginal cost curve shifts up. As long as it's the same amount of per unit tax, the tax creates the same wedge between MR and MC curves, regardless of whether it's on consumers or producers. So the tax incidence is the same. 

The bottom line is: you cannot talk about an equilibrium separately from the beliefs. By talking about a particular equilibrium, you also implicitly restrict the set of beliefs consistent with the said equilibrium. 

The general procedure to solve for a MSNE in a 3-by-3 (or larger) game is always a bit tricky and involves some trial and error 

Myerson (1991) Myerson's Game Theory: Analysis of Conflict similarly defines (on page 185) an extensive form game with perfect information as information sets being singletons within each information state. 

Let the set of players be $N=\{1,\dots,n\}$. According to my understand your description of the game, I take the following statements to be true: 

In other words, if $\succsim$ satisfies completeness and transitivity but violates continuity, can we still find a utility function to represent it? From known results, the answer does not seem obvious. 

The expression $p=\frac{c}{1-1/\epsilon}$ is derived on the assumption that an interior solution is feasible, i.e. FOC is set to equal zero. But inelastic demand curve may not yield an interior solution at all, i.e. it may be impossible to set FOC equal to zero. Perhaps this example will help. Consider a demand curve that features constant price elasticity: $q=p^{-\epsilon}$, or its inverse $p=q^{-1/\epsilon}$, where $\epsilon$ captures the price elasticity of demand. We set $\epsilon<1$, so that the demand is inelastic everywhere. Assuming constant MC at $c$, let's maximize the profit of a monopolist facing this demand: \begin{equation} \max_q\; pq-cq=q^{1-1/\epsilon}-cq. \end{equation} The FOC is \begin{equation} \left(1-\frac1\epsilon\right)q^{-1/\epsilon}-c<0. \end{equation} Note that since $\epsilon<1$, the entire LHS is negative, and therefore we cannot have an interior solution. On a more intuitive level, when a monopolist is operating at a point on the demand curve that is inelastic, it could always increase profit by raising price (or lowering quantity): 

1) External validity --- whether results obtained in the lab can be generalized to settings outside the lab --- has long been one of the main criticisms of experimental economics, and practitioners in this field are well aware of this. In light of this concern, one must therefore exercise caution in interpreting experimental results. Lab results should be extrapolated to an external environment only if the settings of the experiment sufficiently resemble those in that environment. (To some extent, the same can be said about generalizations of results obtained using field data.) In the experiment that you participated, decisions were labeled as "cooperate" and "cheat". However, the labels could very well be "A" and "B", or "Left" and "Right", or "Aspiring" and "Cautious". The point is that the labeling of the actions is arbitrary, and you shouldn't (over)interpret the results just because the experimenter happen to choose a non-neutral frame. 2) Judging by your very limited description of the experiment --- e.g. you didn't say what the control treatment was like, or whether the subject moving at stage 2 can observe what was chosen in stage 1 --- I suspect that the experiment was more for a pedagogical purpose than a research one. Generally speaking, experiments for research purposes should avoid recruiting subjects from the experimenter's own class, since there are strong outside incentives that may affect/dominate the salience of the payoff from within the experiment. Moreover, experiments should generally adopt neutral framing, since non-neutral frames tend to bias the results in a certain direction. Therefore, I think you are over-interpreting the results in an experiment that is not very rigorously conducted. 

Now, consider a pooling equilibrium, where both types choose $A$. Then, upon seeing action $A$, P2's belief is calculated as $$ \mu(\text{Type I}|A)=\frac{\Pr(A|\text{Type I})p}{\Pr(A|\text{Type I})p+\Pr(A|\text{Type II})(1-p)}=\frac{(1)p}{(1)p+(1)(1-p)}=p $$ which is the same as her prior. This makes sense because P1's action provides no additional information in a pooling equilibrium. (P2's off-equilibrium belief can be arbitrary, unless you want to apply refinements such as consistency of the sequential equilibrium). 

The quick answer is Yes. A Bayesian Nash equilibrium (BNE) is Nash equilibrium (NE) generalized to situations where there is uncertainty over players' payoffs; that is, games with incomplete information. For example, in the following zero-sum game, $t$ is a "state variable" that may take values $\epsilon>0$ or $-\epsilon$, each with probability $1/2$, say. Then the equilibrium you solve for would be a BNE. On the other hand, if $t$ is not a random variable (or a degenerate random variable, as the jargons would have it), e.g. $t=0$ with probability $1$, then the equilibrium would simply be a NE. In other words, a NE (of a complete information game) is a special case of a BNE (of a game of incomplete information, where there is only one payoff-relevant state, so to speak). $$ \begin{array}{|c|c|c|}\hline & H & T \\\hline H & 1+t,-1+t & -1+t, 1+t \\\hline T & -1,1 & 1,-1\\\hline \end{array} $$ Adding perfection to BNE puts more restrictions on the players' off equilibrium beliefs about their opponents' strategies. In the case of matching pennies (the game above with $t=0$), which I assume you have in mind when saying "zero-sum games", this consideration wouldn't matter. 

Consider $u(x,y)=2\sqrt x+y$, and the budget constraint is $x+y\le 0.5$. If non-negativity is imposed, i.e. $x,y\ge0$, then optimal solution to the utility maximization is $\bar x=0.5$ and $\bar y=0$. Note that under this solution, the FOC holds with strict inequality. So we need to discuss various complementary slackness conditions before arriving at the solution. If we allow $y$ to be negative, then the optimal solution is $x^*=1$ and $y^*=-0.5$. Under this solution, FOC holds with equality, and both $x^*$ and $y^*$ can be solved directly from the FOC (and the budget constraint). From the perspective of characterizing solutions, it is thus more convenient not to impose the non-negativity constraint(s). 

In signaling games, beliefs as well as strategies constitute an equilibrium. In other words, beliefs are a part of the equilibrium object. By deciding which equilibrium to focus on, you also (partially) determines the beliefs consistent with that equilibrium. The key restriction is that beliefs be derived from Bayes' rule using sender's strategy and the prior. Consider the following game, where P1 is the sender and the common prior is Type I realizes with probability $p$. Separating equilibrium 

I'm not sure what capacity allocation games you're applying QRE to. But here's a very stylized example where QRE is applied to an asymmetric game where the strategy spaces of the two players are (nominally) different: \begin{array}{c|cc} &L&R\\\hline T&1,0&0,9\\ D&0,1&1,0 \end{array} This game can be easily represented in the extensive form as well. In the standard formulation of QRE, each player $i$ plays a mixed strategy $\sigma_i$, where the probability of pure strategy $s_i$ being played is determined by the following formula: \begin{align} \sigma_i(s_i)&=\frac{\exp(\lambda u_i(s_i,\sigma_{-i}))}{\sum_{s_i'\in S_i}\exp(\lambda u_i(s_i',\sigma_{-i}))}, \end{align} where $\lambda\in[0,\infty)$ measures the precision of the response; the larger the $\lambda$ the more precise the response. Applying to the game above, let $p$ be the probability that player 1 chooses $T$, and $q$ the probability that player 2 chooses $L$. Note that $p$ and $q$ parameterize the two players' respective mixed strategy. Then, player 1's quantal response to any given mixed strategy by player 2 (parameterized by $q$) is to play $T$ with probability $p$ and $D$ with $1-p$, where \begin{equation} p=\frac{\exp(\lambda\cdot (1q+0(1-q)))}{\exp(\lambda\cdot(1q+0(1-q)))+\exp(\lambda\cdot(0q+1(1-q)))}.\tag{1} \end{equation} Similarly, player 2's quantal response to any given mixed strategy by player 1 (parameterized by $p$) is to play $L$ with probability $q$ and $R$ with $1-q$, where \begin{equation} q=\frac{\exp(\lambda\cdot(0p+1(1-p)))}{\exp(\lambda\cdot(0p+1(1-p)))+\exp(\lambda\cdot(9p+0(1-p)))}.\tag{2} \end{equation} In a quantal response equilibrium, $(\sigma_1,\sigma_2)$, the two player's strategies must be quantal responses to each other; that is, \begin{align} \sigma_1(T)&=\frac{\exp(\lambda \cdot \sigma_2(L))}{\exp(\lambda\cdot\sigma_2(L))+\exp(\lambda(1-\sigma_2(L)))}&\sigma_1(D)&=1-\sigma_1(T)\\[12pt] \sigma_2(L)&=\frac{\exp(\lambda\cdot(1-\sigma_1(T)))}{\exp(\lambda\cdot(1-\sigma_1(T)))+\exp(9\cdot\lambda\cdot\sigma_1(T))}&\sigma_2(R)&=1-\sigma_2(L) \end{align} In the following graphs, the dashed lines plot the best responses of each player; the solid curves represent the quantal responses under different levels of precision. That is, the solid curves plots equations $(1)$ and $(2)$ above. The intersection of the two solid curves is the quantal response equilibrium point, described by the last set of equations above. 

Let the profit functions of the two firms be $$ \begin{aligned} \pi_1(q_1,q_2)&=p(q_1,q_2)q_1-C_1(q_1)\\ \pi_2(q_1,q_2)&=p(q_1,q_2)q_2-C_2(q_2) \end{aligned} $$ where $p(q_1,q_2)$ is the inverse demand depending on the total output of the two firms $q_1+q_2$, and $C_i$ is the total cost function of firm $i\in\{1,2\}$. Thus $C_i'$ is the marginal cost (MC) of firm $i$, and we can impose the condition that $C_1'\ne C_2'$ on the cost functions so that the firms have different MCs. Now we can solve for the Nash equilibrium (NE). Profit maximization would yield the following first-order conditions for the two firms: $$ \begin{aligned} p'_1(q_1^*,q_2)q_1^*+p(q_1^*,q_2)-C_1'(q_1^*)&=0\qquad\qquad(1)\\ p'_2(q_1,q_2^*)q_2^*+p(q_1,q_2^*)-C_2'(q_2^*)&=0\qquad\qquad(2) \end{aligned} $$ These are the usual MR=MC condition (for each firm). Solving for $q_1^*(q_2)$ in $(1)$, we get the best response of Firm 1 as a function of Firm 2's output $q_2$. Likewise, from $(2)$ we get Firm 2's best response to Firm 1's output, $q_2^*(q_1)$. Recall the a NE in a two-player game is a pair of mutual best responses. Therefore the NE of this two-firm Cournot game with different MCs is the pair $(q_1^*(q_2^*),q_2^*(q_1^*))$, where each firm is best responding to the other firm's best response (to the former firm). Practically, this means to plug $q_2^*$ into $q_1^*(q_2)$ and solve for $q_1^*$, and then plug $q_1^*$ back into $q_2^*(q_1)$ and solve for $q_2^*$. 

I'm not sure what you're asking is possible. Start with the intuition from the case with 2 pure strategies. A player's mixed strategy is a 2-vector $\sigma_i(p)=(p,1-p)$, which can be visualized on a 1-dimensional simplex (or simply a line). Therefore, a profile of two mixed strategies can be represented as a point in a 2-dimentional plane, because this profile is controlled by two parameters (say $p$ for player 1 and $q$ for player 2) like the following 

Are there any empirical studies on political elections that focus on the "tightness" of the race and how much attention the election receives from the public (or perhaps voter turnout). By "tightness" I mean ex ante probabilities of winning the election are not too different among the candidates. I suspect that tight races should be able to garner more public attention, but I would like some evidence to back this up. 

There are many such utility functions. Most commonly: \begin{equation} u(x)=L-\mathrm e^{-ax},\tag{1} \end{equation} where typically $a>0$. Or \begin{equation} u(x)=L-(x-a)^2.\tag{2} \end{equation} Both of these are uniformly bounded below $L\in\mathbb R$ and both tend to $L$ as the functions approach their respective maximum. 

As long as a preference can be represented by a continuous utility function, it is rational (and continuous). So from the very fact that you're writing down a utility function that is continuous in both $x$ and $y$ (on $(0,\infty)^2$), it follows that the function represents a rational preference (provided that both $x$ and $y$ are positive). However, if you insist that $y=0$ is part of the feasible choice set, then the preference is not complete. The individual cannot compare a bundle $(1,1)$ with another bundle $(1,0)$ because the utility of the latter bundle is not defined. 

1- Backward induction solution is Nash equilibrium solution. TRUE 2- Not all Nash equilibria are sequentially rational. TRUE; NE allows for sequentially irrational behavior off equilibrium path. 3- All Backward induction solutions are sequentially rational. TRUE 4- SPNE solutions are Nash equilibria. TRUE 5- SPNE solutions are sequentially rational if game has at least one proper sub game. FALSE (Counterexample below: the game has one proper subgame; $(XC,L)$ is an SPNE but involves a sequentially irrational strategy $L$ by player 2). If only has improper sub game then it may not be sequentially rational. TRUE (Treat the subgame after $X$ as a game of its own.) 

Consider the game below. $$ \begin{array}{|r|c|c|} \hline &L&R\\\hline U&5,1&4,0\\\hline M&6,0&3,1\\\hline D&6,4&4,4\\\hline \end{array} $$ Both $U$ and $M$ are weakly dominated by $D$. If we start by deleting $U$. This would lead to the removal of $L$ in the next step. Then $M$ would be deleted. The solution would be $(D, R)$. However, if we start by removing $M$, then $R$ would be removed next, and then $U$. The solution from deleting in this order is $(D, L)$. 

Some institutes/departments (e.g. BFI, Columbia, Cowles Foundation) would have periodic but irregular theory workshops. However, presentations in these events are usually by invitation only. 

The inverse of some matrix $X$, $X^{-1}$, is defined for square matrices only (i.e. when $X$ has the same number of rows and columns). In the typical econometric applications, the data matrix $X$ usually has far more rows (observations) than columns (regressors). Formally speaking, the matrix $X$ in your definition of $M$ has dimension $n\times k$ but $n\ne k$ (actually $n\gg k$), and so it's not a square matrix. Therefore the second equality in your derivation is not valid; in particular, $(X'X)^{-1}\ne X^{-1}(X')^{-1}$, because $X^{-1}$ and $(X')^{-1}$ are not defined. 

According to the examples given in the paper, direct externality results from, among other things, unsolicited promotions, while the sources of indirect / consequential externality are price discrimination, etc. In this sense, the externality on the individuals (whose information is collected and used) is deemed direct if the information about them is used directly back at them (in the form of targeted advertising, for example). In contrast, indirect externality only occurs if the individuals choose to engage in transactions with the firm which has (collected or purchased) their information, and that these transactions make them vulnerable to price discrimination, etc. In other words, externality of this second kind occurs consequently.