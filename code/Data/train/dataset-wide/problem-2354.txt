You have an order by so running a basic commandline diff should quickly highlight differences. The pt-table-checksum tool is also handy for finding differences. 

The biggest downside is repetition of the PK. You pointed out an increase in disk space usage but to be clear the increased index size is your bigger concern. Since innodb is a clustered index every secondary index internally stores a copy of the PK which it uses to ultimately find matching records. You say are tables are expected to be "small" (20 rows indeed is very tiny). If you have enough RAM to set the innodb_buffer_pool_size equal to 

So in summary, the general approach of partitioning tables can offer many benefits. However it's not a magic bullet to be applied blindly without consideration to access patterns and how exactly you are partitioning. I could imagine situations where the desired partitioning is very application specific and would be better suited to have that logic sitting in the application layer. However given your straight modulus 10 description this does not seem like such a case. EDIT In writing up my description I forgot that you stated your table is 100K rows. With out the full schema of your table and it's average row length it's hard to say for certain, but in general that sounds medium sized even for modest hardware. At the same time, if it's not causing problems the way it is now or in the foreseeable future then don't spend time and introduce risk by changing it. 

I'm not aware of a specific term for this practice but you can specify different data and/or index dirs using the create table syntax. This only works for MyISAM tables and your OS must support symlinks. In my practice though, we generally just segment sets databases into their own LV. These are generally a segment per functional application. Having a single logical volume with all the tables actually in there it's easier to keep track of an manage disk space for each DB. Those LVs though, are generally in a RAID 10 config to help balance IO. 

If it's showing in your processlist then it's still running. In the future, for situations like this we're you're pruning 90%+ of the table consider this approach: 

You can't use null checks like that with indexes. Further individual single column indexes will cannot be "combined" with your type of query (e.g. a bunch of ANDs; there is some merge optimization that can be done for ORs though). Instead of null could that be represented by either a 0 or empty string as appropriate. (This of course requires those not be possible values for various columns). Creating a composite index like 

So to be clear the old slave (oldS) and the first new slave (newS1) share the same server ID. It's not circular replication so I'm hoping things will turn out okay. I wouldn't have expected the fallout though. Alarms started going off b/c oldS1 started falling farther and farther behind. Looking at the logdir it was making thousands and thousands of empty relay logs. I stopped slaving on newS1 and that seemed to clear things up in that oldS1 stopped making empty relay logs and caught back up. Both slaves seem to be in a consistent state up to the point I stopped slaving on newS1. 

You'll need to copy over ALL the contents of your old data dir to the new data dir. Specifically it sounds like you did not copy the mysql folder (read mysql database) over to the new data dir. 

We've encountered a couple use cases where having federated tables prove useful, despite their limitations and caveats. As best I can tell this must be enabled with a federated declaration in the .cnf upon startup. Our use cases are limited and certainly don't warrant restarting every instance just to have it. At the same time I'm thinking of adding it as a default to our standard config so it is available on instances as they get bounced during more pressing maintenance. Is there any reason not to have this option available unless decided absolutely necessary? For a final clarification: This question is not about the disadvantages of actually using a federated engine; rather it is just about just enabling as an available option. Perhaps to put it another way: Is there good reason it is disabled by default other than making sure you don't shoot yourself in the foot if you understand the consequences? 

So I had my screwup for the week today. I was adding another pair of slaves and set the same server ID on the new slave as an old slave. The layout kind of looks like 

Create table test1 (innodb) w/ an auto increment PK Insert a couple rows w/o specifying PK values, letting auto inc do its job Create table test2 like test1; Alter table test2 modify pk_col int(10) unsigned not null; -- no auto_inc Shutdown mysql backup test1.frm; cp test2.frm test1.frm Restart mysql select * shows all rows as expected, w/ previously auto_inc created PKs 1,2 and 3 Insert a row w/o a PK specified, gets created w/ PK value as 0 (the default value). Insert a row specifying PK of 5 Shutdown mysql restore original auto_increment test1.frm Restart; show create table lists auto_inc Test insert a row w/o specifying PK, generated auto_inc value of 6 (+1 the highest value even though the last one created by virtue of auto_inc was 3 

Copy your db.tgz over to your new server and uncompress it on your new servers datadir while it is shutdown 

This isn't directly related to ORDER BY, but be careful using the LIMIT N,M pattern. This is often used for paginating results, e.g. 

The ultimate solution looks to be migrating to 5.5 which supports UTF-8 > 3 bytes Unfortunately this wouldn't be as simple as bouncing the instances under newer binaries. Being a major version dump we'd need to do a full dump reload which will require some scheduled downtime. Has anyone else had to deal this situation before? Are there any good work arounds? The naive approach seems to be have the app search and replace multi-byte sequences with question marks or ï¿½ . This seems pretty hacky and not a very palatable option to me or the developers. 

I was wondering if anyone had any pointers on migrating MyIASM tables from mysql 5.5 to 5.6, specifically using Percona builds, via an rsync? Is this safe? I know we need to do a full mysqldump/reload for a migration for InnoDB tables but I didn't see any notes about significant changes to the MyISAM format between the two. It would make things a little nicer for a rather large MyISAM db that would take several days to complete with a mysqldump. 

Then do that and you'll probably be sitting pretty. As a general rule though you'd want to leave at least 30% - 40% of total system memory for other mysql overhead and dis cache. And that's assuming it's a dedicated DB server. If you have other things running on the system you'll need to take their requirements into consideration as well. 

Google attempts aren't very useful as I'm mostly running across pastes of this message for different contexts. Basically what I'm wanting to know is: Is this just simply the wording/error code Mysql uses when truncating a sequence of multibyte characters, or is there something more telling I should be gleening from this message? I was initially thinking it meant the byte sequence was getting split in such away it was resulting in malformed characters. Attempts to try and make it do this didn't work (e.g. mysql seemed good about recognizing proper byte boundaries for a character encoding). Edit: After relooking over it does look to be the char splitting I initially dismissed. I had an off by one brain fart looking at it initially. 

Does anyone know of any existing tools/products that accomplish what I'm trying to do? After searching around for a bit the only thing I could find surrounding what I'm trying to accomplish is someone else looking for the same thing $URL$ The idea is I'd like to capture all the traffic to my master to save for a replay log against a snapshot of the entire database taken when the monitoring started. Bin logs won't serve what I want since they only include writes. I want read activity to realistically view the effects of proposed changes with "real" production traffic. Real production traffic meaning everything from all applications that are hitting the database to be modified. If there's some application level change, tests running just that app don't account for other activity going on in the system at the time. Running all applications in a test environment aren't guaranteed to have the same state of the database. I could take a test snapshot as a starting point as I fire them up but the applications don't have the ability to do an exact replay of their own activity. I've use the tcpdump script from $URL$ to monitor activity but this doesn't tell me which queries are coming from which connections. Part of the playback I'm wanting is a multi threaded approach that replays the activity from the same number of threads that were actually in use. I can't afford to turn on general query logging b/c my production master wouldn't be able to handle the performance hit for that. The whole snapshot part of the process is to have a golden start point database to ensure everything is the same during the start of each test run. 

innodb is very very very unlikely to have any corruption caused by the storage engine. (corruption caused by applications isn't something mysql can help with). Upon each start up it will check it's log files and automatically recover any from any partially completed transactions in the event of a crash. That being said it is still very possible for a replication slave to become out of synch. For that reason, or even if you just want to be uber paranoid you can use the tool pt-table-checksum This will sometimes intelligently checksum your live tables in chunks so performing checks doesn't require downtime (either through explicitly taking the server down or having tables locked for a checksum table; query). These numbers as a one off don't really tell you much. As with any checksum you need something to compare it against to have any value. If you run periodic checksums you can compare against previous values to alert you of unexpected changes. Now, obvious you will be making changes in a database so this isn't a catchall. This could be a good method for checking archival tables were data is not updated once it is written. Note: I said it "sometimes intelligently" does checks in chunks. You might run into issues if you only have a PK/unique key that is multi column. 

I was looking around for a quick way to remove an auto increment from the definition of a primary key. As best I can tell the only way to do it is w/ an alter table or dumping all the data into a new schema sans auto_increment. Just for fun I tried the following to see if it would work. 

They didn't explicitly mention this, so I am only guessing here, but they are using some search index such as Lucene to perform the actual searches. They'll have a persistent database of some sort but their search index is periodically built from that data set. 

Optimizing tables with the most data_free will give you the biggest savings in disk space. However there are some caveats: 

(replica set and host names have been sanitized for public posting) To attempt the repair I shut down the mongod and started it up with 

Does anyone know of any good tools for cnf configuration management? It's often the case I have a group of machines that has a very similar config except for a few differences such as server id or buffer pools to match their specific hardware. I'm looking for something where I can setup a general template, tell it I want to generate some configs for that machine from that template, have it prompt me for the variables that need to be filled in and write out the .cnfs for me. 

I think I found my problem. My testing server install was an ubuntu mysql default; not percona. $URL$ 

However that intro paragraph is the only mention of LDAP in the entire post. I've read through that as well as the general Percona PAM installation post. Every setup instruction seems to be talking about authenticating against a local unix account. No mention of specifying an LDAP server or anything. I found one other SourceForge project and some other mentions of perhaps slapping mysql_proxy infront. Frankly that SF project doesn't feel very production ready. Am I missing something about this percona plugin being able to authenticate via LDAP? If I'm completely off base with that plugin perhaps my larger questions is "How can I get users authenticated via LDAP?" 

Your own profile showed the bulk of the execution time was "Sending data", which means transferring records from the server to the client. Selecting a single integer id column is going to be small, requiring less bandwith than reading all the columns of a the row, which is what 'select *' is short hand for. This can be especially noticeable if any of your columns are large text or blobs. 

You don't want your logs in you data directory. This will show a "mysql-bin" database when you start mysql. You'll probably get some unneeded errors in the error log on startup. Best to keep that as clean as possible so you can pay attention when something does show up there. It's general convention to put logs in /var/log anyway. Further, when possible it's nice to have the logging file system on a separate set of spindles than the data directory. While it doesn't sound like that would be possible there could still be some gains in keeping the data directory and logging on different file systems, even if still on the same underlying disks. Be aware that expire_logs_days will purge binary logs regardless of weather slaves are up to date. Granted if you have a broken slave that's been off for more than 14 days you have larger problems. In general you'll want to keep enough binlog buffer around so that you can easily spin up a new slave based on your backup schedule. You might consider having an archiving script that offloads the binlogs to a more permanent archive server and manages the purging.