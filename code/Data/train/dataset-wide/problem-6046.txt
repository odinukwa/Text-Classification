Series will generally converge but there is always a small probability that a serie does not converge after a finite number of trials, so there is no contradiction. If you already had 100 tails the whole serie will converge more slowly. The interpretation of probabilities (degree of credence? Objective propensity? Frequency?) is an independent matter. 

Reality is often cast in terms of mind independence. What is real is what exists independently of our representations of it. (Note that it doesn't mean that minds are not real: our minds can exist independently of our representations of it). 

Classical logic is reducible to math (it can be mathematically described). The problem is math implicitely presupposes logic. EDIT (precisions) it is possible to describe logic mathematically as rules operating on an abstract language (a set of symbols + a grammar for correctly formed sentences). This can be called a reduction of logic to mathematic. Mathematical reasonning, however, follows logical rules (set theory is expressed in a logical language) and the use of logical connectors is unavoidable. For example you'll need to say 'or' to define mathematically the disjunction operator (the logical or). So in place of reduction, we merely formalized logic inside a framework which is already based on logic. This formalization is not useless though: it serves meta-mathematical purposes, such as proving GÃ¶del's theorem. About reducing mathematics to logic: this project is known as logicism and was pursued by Frege Russell and others. Although large parts of mathematics have been formalised and we have a quasi-reduction, Russell's paradox proves it is impossible to have mathematics as only logic(+definitions of math symbols inside logic). You need specific axioms beyond logic to do mathematics (standardly, the axioms of set theory). 

As Jo Wehler says, the two notions apply to different realms. Truth applies to linguistic entities, whereas reality applies to things in the world. Something is real if it exists in the world independently of our observations or conceptions of it. For example, tigers are real if there is an objective group of objects in the world that forms a natural class that does not depend on our conceiving them as such (the classification is not "in our heads", it's not a mere conventional or practical way of grouping objects) and the objects and their class continue to exist even if not observed. Truth, for a realist, is correspondence of a statement to reality. This is why the two notions are tightly related: for example, "there are tigers" is true if tigers are real. However truth crucially depends on the meaning of our words whereas reality does not (there could be tigers even if we had no word for them). Note that there are other conceptions of truth available for anti-realists (coherence, ideal assertability...) that are less tightly related to reality. 

Models were quite neglected by philosophers of science and even scientists before the second half of 20th century: science was more thought of as in the business of producing statements about the world, but the view was criticised in particular by Suppes and Suppe in the 60's and 70's, who emphasised the central role of models in scientific representation and empirical confrontation. This has come to be called the semantic view of theories, according to which a scientific theory is just (or is better presented through, analysed as...) a collection of models, and it as been endorsed by many authors, realist or anti-realist alike (e.g. van Fraassen, French, Ladyman, ...). Models are conceived of by these authors as mathematical structures that represent features of the world, and the laws of a theory are just a way to describe this collection of structure. These authors think that this view has several vitues: it is close from scientific practice, where empirical confrontation is made through comparison of data models and theoretical models (e.g. van Fraassen "the scientific image"), mathematical structures are more or less language-independent which allows one to bypass semantic issues in science (ibid), it provides mathematical tools such as isomorphisms to analyse intertheoretical relations (reduction, theory change), etc. Not everyone agrees though: some think that theoretical laws are more than descriptions of collections of models (but represent natural laws, e.g. Maudlin in "metaphysics within physics"), or should be viewed as tools to produce contextual models (Cartwright, Suarez). Some think that language is still important to apply models (Chakravartty). But in any case, the importance of models in scientific activity is widely recognised today. For a review of this specific debate you can read Lutz "what was the syntax-semantic debate about?" Or SEP entry on the structure of scientific theories $URL$ Note however that "model"is a polysemic word. I only addressed one aspect here: models as mathematical structures built from theoretical laws. There are other types of models: scale models (a reproduction of DNA), analogies and metaphors (model of the mind as a computer) or thought experiments... And a large literature on their status and role. For a larger view on models in general you can read the dedicated SEP $URL$ or Bailer-Jones "scientific models in philosophy of science". 

The closest I can think of is dual aspect theories, where "informational" and "physical" would be two distinct aspects of reality. You also have this kind of distinction in continental philosophy, e.g. in Sartre's philosophy, between two modes of existence: "being in itself" (material objects) and "being for itself" (conscious beings). Also, quantum mechanics is sometimes thought of as a theory about information. This would undermine the distinction. 

A premise is not valid or invalid, it is either true or false. Validity only applies to deductions. Maybe the confusion comes from the fact that you're conflating the logical implication "->" and the deduction rule. Logical implication is a logical operator that says that either its antecedent is false or its consequence is true, but it does not say that B is deducible from A. For example if "p:=tigers are mammals" is true and "q:=it is raining" is true, "p->q" is true even though q cannot be deduced from p. In your example, the premise is not a syllogism, but a logical statement that can be true or false depending on what you mean by A and B. From this sentence and the other premises you can deduce the conclusion. The argument is valid. Whether the premise is true or not will depend on what you mean by A and B, but the premise is neither invalid or valid: it's not a deduction, but a statement. 

Determinism is usually defined as the view that the state of the universe at a time can be completely determined by its state at previous times and laws of nature. Every single event fall into the scope of determinism thus defined. What you have in mind is perhaps a supervenience of big events on small events: small events determine big events. Supervenience is a dependence relation that can be invoked in questions of reduction and emergence (for example: the beauty of a statue supervenes on--is fully determined by-- its physical constitution) but it's not called determinism. 

It depends on your moral theory. (Answer edited following virmaior's comments). Some consequentalists, such as utilitarians, would probably say that you must donate blood because it maximalizes hapiness (taking for granted that your lie will harm noone in these circumstances, while your blood will produce hapiness). However other consequentialists might take different criteria as desirable consequences. Some deontologist would say you must not lie. Kant famously argued that you should not even lie to a murderer to protect the life of innocent relatives, but this extreme claim is rarely accepted even by deontologists, so it might depend on which kind of deontologist you are. Some deontologists do not assert that you ought not to lie. A virtue ethicist would tell you to weigh the sort of character that lying develops in you against the sort of character that giving blood under those circumstances develops in you. If you think that lying to donate blood in these circumstances makes you a better person, then you should do it. 

I don't know if the objection was raised but I believe that naturalised epistemology proponents have the resources needed to answer the objection. The reason, I think, is that being willing to revise one's belief in front of contradictory experience is not the same as not having the belief outright, or being sceptical about it. It would have been inappropriate to raise the objection against someone who, a few centuries ago, would have said "I believe physical space is fundamentally euclidean but I will revise my belief if an alternative works better". Although it seemed obvious to many (and even, for authors like Kant, a priori true) that physical space was euclidean, it turned out that it is better conceived of as non euclidean. Such a person could have been sincere: no doubt she could have adopted relativity, as many did, in front of crucial experiences. The fact that she strongly believed that space is euclidean, and acted accordingly, does not alter her sincerity when she said she would revise this belief if necessary. One could argue "well, you're not really willing to revise beliefs such as 'red is a color' because if you did, you'd only change the meaning of 'red' or 'color', so you're not sincere when you say you would revise anything". This argument misses the point: it's not obvious whether we changed or not the meaning of 'space' when we switched to non-euclidean geometry, and the defender of NE will say that meaning is a dubious, or at least a flexible notion and that there is no fact of the matter whether it is the meaning of 'space' or our beliefs about space that we changed. If it turns out that our notion of color is not as appropriate as we think and that it must be redefined in such a way that red is no more a color (or perhaps only in certain widespread contexts), then why not switch to this new framework? Perhaps the closest to an insincerity objection I can think of is the charge that Quine claimed that even logic is revisable, and was at the same time among the most conservative about first order logic against alternative logics. I heard this objection quite often informally. It amounts to suggest that Quine was not really sincere when he said that he thought logic to be revisable. However Quine argued that logic is so central to our conceptual schemes that the evidence needed to revise it would be tremendous, so again, all this merely shows that being willing to revise a belief if an alternative turns out to be better (however unlikely the prospects) is different from being sceptical outright, and that it is not even incompatible with holding the belief very firmly (if the prospects of revision are very unlikely). If NE is sceptical about meaning, a more subtle objection could target the view that there are no meanings: after all, NE rests on a scepticism about a priori meaning and analyticity. The objection would go: "you say you don't believe in analyticity but you show otherwise". I'm not sure that kind of objection can get off the ground because analyticity is not a trivial, common sense concept that would be implicit in so many arguments. At least the burden is on the attacker to show that a NE defender is using the notion. Perhaps the notion of meaning is more common sense and often used implicitly, but the defender of NE can argue that she has an aposteriori conception of meaning as use, and that what she is sceptical about is the idea that meaning is a priori.