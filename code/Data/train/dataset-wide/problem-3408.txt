An edge router is simply a router that connects the network you control to a network that you don't. In most cases, it is the router that's connected directly to your internet connection. This is in opposition to a core router, which is a router that routes between multiple networks that are all under your control. An edge router is generally a lower-end router, as it tends not to do much beyond pass traffic, and generally to a circuit that has a relatively low bandwidth. Edge routers are sometimes combined with firewalls, NATs, and VPN endpoints, but I'm not really sure you'd still call it an edge router at that point. 

As I recall, Firefox on MacOS won't open .url files, right? And Web Location Converter is an application that should convert .url files to .webloc files, which I think Firefox will open. It says that it isn't 100% under Snow Leopard, but the only thing broken is the other direction, so you should be okay. Here's an AppleScript droplet that would work to simply open the files if Firefox hadn't broken its AppleScript support at some point. Either way, one you get them opened in Firefox, it should be trivial to then bookmark the lot of them. Alternately, .url files are pretty simplistic. You could throw some text processing at them to convert them into a simple html file pretty readily: 

I have an ISO image on my VMware ESX 3.5 host that I would like to mount in a guest OS. I cannot figure out how to do this. I can easily mount an ISO image with the VMware Infrastructure Client's "Connect CD/DVD" button (that also allows you to mount the local workstation's CD drives), but that button only allows you to reference files from the point of view of the client workstation, which means I'd be accessing that image over the network, which I don't want to do, and I want it to be independent of VIC because it constantly crashes. Update: I see now that if I edit the guest OS's settings where the CD drive itself is defined, I can mount a datastore-located ISO from there. Isn't there some way I can log into the host OS and mount/present the image to a guest OS without having to interact with a GUI? Update 2: I must be an idiot today. I've tried the vmware-cmd utility and I can't get it to work. 

The uplinks to my switches are on Gi1/0/8 on both of their switches. The uplink ports are configured with a single tagged VLAN. I am also using a number of other tagged VLANs in my switch infrastructure. And, to be clear, I am passing the tagged VLAN I'm receiving from the datacenter to other ports on other switches in my infrastructure. My question is: how do I configure my switches so that I can use a spanning tree protocol inside my switch infrastructure without breaking the datacenter's spanning tree that I cannot participate in? 

Turns out that an earlier attempt to set the expiration date of the data on the tapes accidentally set the volume expiration date, so all of those tapes were expired. Resetting the volume expiration to nil solved the problem. 

Also remember that the free version of Hyper-V has no GUI, and, thus, no way for your local users to actually access the system short of using a separate computer. 

If a user tries to schedule a meeting in the "far" future, where ""far" future" seems to mean "seven or more weeks into the future", no existing meetings show up, and resources (at least) frequently (if not always) show up with the white-with-black-hatching "No Information" indicator in the meeting creation window, but shows up fine if you look at the actual calendar from the main Outlook window. Is this expected behavior? If so, is there any way to extend how far out Exchange/Outlook will look? Edit:Okay, many people are saying that this is controlled by Outlook, or that it's a function of Outlook. My specific problem is that I have a conference room as a resource that automatically accepts meetings, and it has very limited future data. No one ever logs in as that user (except for debugging). So is it that Outlook controls Exchange's free/busy publication span, or does Outlook actually calculate free/busy time and upload that data to the Exchange server? If it's the former, I should be able to log in as those users and set the Free/Busy span once and have it be fine. If the latter, I'd have to log in as those resource users every once in a while to update that data. Which would raise the question of how Exchange has even a few weeks of such data considering no one has logged into those accounts for many months. Regardless, if it's the latter, is there a known way to automate updating the data? 

I have an Exchange 2003 server that has accounts for rooms/resources set to autoaccept meeting requests. When those meetings are canceled, however, the meeting remains in the resource's calendar as a canceled meeting. This makes the calendar untidy and hard to use. Is there any way to have meetings automatically deleted from the resource's calendar when it is canceled? Failing that, is there a way to set up permissions so that people can manually remove canceled meetings, but not modify non-canceled ones? 

The reason to use Gentoo is so that you can install packages with the features you want. What I mean by this is: if you get a RedHat/CentOS/Debian/Ubuntu package for, say, Apache, you're going to get the features that they decided that you needed. If you want an additional feature, your only recourse is to download the source and compile. There's nothing inherently wrong with that, but it can be a pain. For one thing, you're used to just typing "yum install apache" or whatever. For another, now you have an application that exists outside your package management tools. On the other hand, if you have Gentoo, you can define in your emerge configuration files the sorts of features that you want, and you're compiling it anyway; it's just automated. And if there's no flag to enable what you want, it's relatively trivial to modify the ebuild. This way you can use Gentoo's package management even when you want options that no one else considered building into the package. There are minor performance improvements involved with compiling only what you want, but they really are minor, and this notion is used as a red herring to dissuade people from using Gentoo. All that said, it is complicated, you will learn a lot (though not as much as from Linux From Scratch), and it may be total overkill for what you want. If it is, I would go with Ubuntu in a heartbeat, and stay away from RedHat/CentOS where possible. (I find the RedHat system configuration style to be difficult to work with from both an administration and a WTF-were-they-thinking point of view, and I find that it's much easier to find up-to-date packages for Ubuntu than any of the others.) If you do want a learning experience, there's nothing like the trial-by-fire of installing a production server that you know nothing about, but if you're interested in a less stressful learning experience, try Linux From Scratch on a virtual machine.) Also, your dad is the man. I'm sure my dad would be trying to convince me to downgrade to Windows 95. Heck, probably a chalkboard. 

I would do a packet sniff on the network to see where the delay is occurring. It should show you if it's taking a long time for a DNS response to come back, or if the LDAP response is slow, or if there's some other delay you haven't anticipated, like an LDAP referral as DAM suggests. 

If I understand correctly, your SMTP server is remote to your local network. Is your ISP blocking the SMTP submission port (port 587) defined by RFC2476? 

against both of your URLs. (It'll write timing output to 'trace.log', so either rename the file between runs or change the filename on the command line.) Then examine the log files' timestamps and see if you can find where the delays are occurring. 

I don't know how much money you're looking to spend, but I've been really happy with my Cisco 1130AG. I previously had a Linksys Draft-N AP that I ended up rebooting every night and still remained unstable. I have had zero problems with the Cisco. Of course, it cost like 8 times as much and doesn't support N. (They have some now that do, I think.) 

The top of what unit has holes? The cabinet? That's insufficient, really. If you can't vent, you can't cool. That heat has to go somewhere. You can't get rid of the thermal energy, you can only move it. If your only vent is outside the cabinet, then you're effectively just using your office's air as a really inefficient thermal heatsink and your building's A/C to cool the computers. If you do have somewhere you can vent the heat to, though, there are "portable" or "spot" air conditioners. (MovinCool is a manufacturer that I'm familiar with.) Effectively, they're like window-mounted air conditioners, except they're mounted in a chassis with wheels, and the heat venting is usually through a hose, like a dryer hose. However, air conditioners are dehumidifiers. It will "generate" water, which you'll have to find a way to dispose of. Most units have removable tanks that allow you to take the water and pour it down a drain somewhere. Some have automated pumps, but you still have to provide a drain. Or carpet you don't mind being wet all the time. 

I haven't tested that, so I may have something weird wrong. Also, assuming that it's been running as root so far, make sure that your pid and log files aren't owned by root and inaccessible to user rails. 

I occasionally find myself in a situation where an undermaintained system has an account that's been locked out. The problem is that there are a variety of ways in which an account can be locked out, each with their own method of being unlocked. It's not that the account is being locked improperly, just unexpectedly, but finding the correct lock to reset is difficult. My most recent attack of this problem was on a SUSE system, and it turned out that the password had expired (which wasn't initially known because the login attempts were not through a system that provided that sort of feedback), and then also locked due to failed login attempts. Is there a list somewhere of all of the different possible account locks and how to disable them? I'm intending for actual brokenness, such as home directory access problems, corrupt PAM libraries, etc., to be out of scope for this question. 

Turns out that I had accidentally set some tapes to expire (not the backups on them, the tapes themselves). This is the "expiration date" as listed in the output of or "Volume Expiration" in the GUI's "Change Volumes" dialog. I cleared this expiration and that solved the problem. 

currently shows 17617 zombie processes, all of which have a ppid of 1/init. init should be reaping these defunct processes, but isn't for some reason. The number of defunct processes is growing. Trying to force them to be reaped using fails with: 

I notice that one of the ports is connected at 1000Mbps and the others are connected at 100Mbps. Can you verify that this connectivity problem exists between two computers connected at the same speed? I'm thinking that there might be a problem with the built-in switch handling cross-speed connections that would be hidden when dealing with a separate interface that goes through the kernel. 

When you created /Users/HMTS01/BACKUP, how did you set its ownership and permissions? You may need to set the mount point's metainfo manually before mounting the filesystem. 

I am installing a Sun Grid Engine environment and I have a scheduler limit that I can't quite figure out how to implement. My users will create array jobs that have hundreds of sub-tasks. I would like to be able to limit those jobs to only running a set number of tasks at the same time, independent of other jobs. Like I might have one array job that I want to run 20 tasks at a time, and another I want to run 50 tasks at a time, and yet another that I'm fine running without limit. It seems like this ought to be doable, but I can't figure it out. There's a configuration option, but that appears to apply globally to all array jobs. I can't see any way to use consumable resources, as I'd need a "complex attribute" that is per-job, and that feature doesn't seem to exist. It didn't look like resource quotas would work, but now I'm not so sure of that. It says "A resource quota set defines a maximum resource quota for a particular job request", but it's unclear if an array job's sub-tasks' resource requests will be aggregated for the purposes of the resource quota. I'm going to play with this, but hopefully someone already knows outright. 

You say filenames have slashes in them, and those are … hard to support under Unix. But Mac OS X is Unix. But HFS delimits directories with colons and not slashes. So how does this all play together? On my SnowLeopard installation, I can create a file in the Finder that has a slash in the filename. When I look at that file from the command line, though, that slash has been transformed into a colon. If I create a file on the command line whose filename contains a colon, it gets transformed into a slash in the Finder. I cannot create a filename with a slash from the command line, and the Finder refuses to put a colon in a filename. If I create a filename on a Unix Samba server that contains a colon, when viewing that file mounted on my SnowLeopard machine, I get craziness. The file "1:2.txt" gets transformed into "14V9MB~M.TXT". If I create a file on that share from the Mac, the colon gets transformed into three unprintable bytes: 0xEF, 0x80, 0xA2. This would appear to be the UTF-8 encoding of U+F022, which is in the Unicode "private use area", which means it is not universally defined. If I do the same tests using a real Windows machine as the server, I get similar results, I think. Windows won't let me use either a colon or a slash in a filename. If I create a filename with a colon from the Mac side, Explorer shows me the file without any visible character in the colon's place at all. (That is "1:2.txt" shows in Explorer as "12.txt".) From the command line, a shows me "1?2.txt". I suspect that it knows how to interpret the UTF-8 encoding, but doesn't know what to show for that private-use character point. What I think this all comes down to is: you can make the transition as long as you can figure out how to translate slashes in filenames into 0xEF80A2. This is obviously testable.