This command is described here. If you want to understand the mechanics deeper, I wrote a blog post a few years ago that discusses transaction log growth. Proper management is best because then you won't have to worry about finding an automatic way to shrink it. 

Old question, I understand, but an answer in addition to the above answers exists since SQL Server 2016 SP1. SQL Server 2016 introduced "Always Encrypted" as well as other security features like Dynamic Data Masking and Row Level Security. These were features originally released in Enterprise Edition Only. They now exist as features available in any SQL Server 2016 SKU - Enterprise, Standard or even Express. Worth checking out and worth looking at the upgrade process now. You can read more about this on Microsoft's post about SP1 for SQL Server 2016.. 

(ED- Another note - I often don't have an "S" drive available. At the end of the day, having your system database files for Master, Model, MSDB and Resource db living on the same drive as some of your user database files, but in a separate folder for logical separation to keep things less confusing isn't the end of the world.) 

Log the sp_whoisactive data to a table (Kendra Little has an excellent blog post about this) (I wouldn't do this terribly frequently, and I would monitor your performance while it runs. The tool is well written but it isn't "free" to run from system resourecs perspective. If you were running this every 1 second I'd potentially be concerned. Every 15? 30? 60? It depends - you need to test. Periodically query this table in a SQL Agent job. Use the information presented in the query (Duration, query text, application, user) to determine if it is "alert worthy" and if it is alert worthy (Duration > set amount, user not in an "acceptable" list, text not in an acceptable list, etc.) either raise an error that an alert can fire off of, or generate an e-mail. Remember to keep that table pruned and really monitor the approach - it may be that your environment can't handle the load of doing this frequently enough. You can look at some of the tables underneath this procedure and capture less data. 

I suspect this is not a SQL Server 2000 database you are attempting to attach to SQL Server 2000. That appears to be a common cause of the error as indicated here also. Can you attach this to SQL Server 2005 or 2008 Express and see what error message you get? Do you have access to the underlying database that your files are from? I imagine if you attach this to SQL Server 2005 or 2008 you will be able to attach it unless there are other impediments to attach going on that that approach will reveal. 

You should modify the registerallprovidersip setting in conjunction with changing the time to live (TTL) for the records. Without modifying the default TTL, the registration lives too long. Sadly there is still a delay but dramatically reducing the TTL helps. Ideally you should see what you can do to get the client connections to specify multi subnet failover and not have to do this workaround. But with the TTL being lowered, you should be fine, I've done that with several clients and it all works out alright. It still won't instantaneous. You can see more about these settings working in conjunction with each other here. 

That is just one approach. It may not be the right or best approach - and enough time searching the web will show you at least a half dozen more. But if a client were to offer to pay me an hourly rate to create this for them, I'd suggest they really consider SQL Sentry or one of the tools like it. The price of most of these tools isn't a whole lot more than a couple days of SQL Server consulting help. 

From the comments I see you removed the default time limit like I mentioned but still the analysis didn't happen in enough time or ever complete as I feared. 18GB is definitely the largest trace I have ever heard of attempting to be analyzed by the Database Engine Tuning Advisor. I suggest you break your trc file up into smaller sizes. Either by looking at the data a bit more filtered or for a smaller window of time while still maintaining enough of a workload to capture both data modification and selects. Alternatively - I haven't been a big fan of the DETA and sometimes the results, even with a properly sized workload file, fly in the face of reality (most index suggestions are very wide covering index in a lot of cases, redundant indexes in overlapping column coverage at times, etc.) I would suggest a "Top 10" style tuning exercise may be a better approach. Find the worst performing queries by duration and/or reads and work on tuning them through query tuning and index tuning/design best practices. Edited: Added a couple more tips based on comment from OP I would also look to set an end time. DETA isn't supposed to be a "done in 5 minutes" deal. It is trying to be incredibly thorough and look at your database as deeply as it can and analyze the workload as long as it can to come up with the recommendations. Have you tried setting an end time for the analysis? I'd check out this link on MSDN for some other tips - $URL$ Bottom line though - This will be a slower operation. The larger the workload file and more complex the database, the slower it will be. If you are running on the same system that other work is going on then you are each competing for resources. 

Because of your code - Are you using TempDB a lot in your code purposefully? A lot of temp tables and table variables created and destroyed? Doing a lot of things in TempDB like this? That isn't bad or good necessarily, but you might look at that and understand your intentional TempDB usage pattern. TempDB is a shared workhorse - TempDB is one database that is used as a temporary space for user defined temporary objects and various work tables and operations used by your entire SQL instance. How many user DBs are there? What kind of workload do you see in general? TempDB is one resource for all things to share. Inefficient queries and insufficient memory - Perhaps there are queries that aren't using indexes tightly enough or are doing large scan and sort operations. Large hash operations, and the memory on the server isn't sufficient for these. These operations will "spill" to TempDB as worktables behind the scenes. Sometimes this can be avoided with looking at your query plans and indexing or query tuning. Sometimes it happens (more so on warehouse workloads, I find). If you have enough memory, this can help, but these queries can still spill at times. Look a this as well. Are you using Read Committed Snapshot Isolation level with a fair number of updates in your system? This can also result in increased TempDB activity. 

Pros - It is the natural key, it makes sense and it will likely be searched on, I presume? Cons - The default behavior (which is totally changeable) is for a primary key to be the clustered index. An alphanumeric doesn't make the best candidate because inserts can cause page splits because they aren't set on an ever increasing value like an identity column. The Int identity column will take less space (4bytes) compared to the character data (40+bytes for the unicode) . This makes your other indexes larger since the clustered key is part of them. If you ever change how you identify your customers and make customer codes, this all breaks - going with a surrogate insulates you from those type of changes. In this situation, I tend to optimize for the insert performance and go with an identity column more often than not for the clustered key and primary key. I really like integer clustered indexes. (Now I know your question was not about clustered index, it was about primary key... You could still choose some other column to be the clustered index and make this your primary key, you could also put a unique constraint on this and treat it as a natural key but not make it your primary key). I would at the very least index this with a unique constraint and treat it like a natural key. I just don't know if you really need to make it your primary key. Kimberly Tripp is a trusted resource who has a lot to say about primary keys and (more so) clustered keys on her blog - $URL$ This is all just my opinion - YMMV. 

Then the last question I hate to shove off on this one, but I'm kind of going to do that. There are a lot of great restore scripts out there on the internet for different scenarios. You haven't fully described yours so not sure I can comment on the efficiency/elegance but you are right to read the headers to determine what you do next. Some questions to ask yourself: Are you looking at things like the date to ensure you restore the latest? Are you looking at things like full/diff/log backups and accounting for them in the restore? What purpose is this for? Restoring a dev environment? Or for a production restore? If a dev restore, I like to go more automated. If a prod restore I like to have a script that eliminates some "oops" factor from a critical production restore but not automate so much of it that it makes it easy to forget to do a critical step or do something like backup the tail of the log. I'd search for restore scripts and see what others have done, ask yourself these questions and incorporate what you like. I also am not sure you need to know if the file is compressed or what the compressed size is. Those facts shouldn't be terribly necessary for a restore script since SQL just handles the restore of a compressed backup for you. You don't have to tell SQL it is compressed. So you may just drop those columns altogether and only take what you require from the header to perform you restore. 

Well you can see which indexes are not built online by looking at the requirements for online index rebuilds. It isn't that the maintenance plan or database engine will arbitrarily decide which are online and which are offline. To see which index is rebuild at what point, you'd have to profile the activity with something like sp_whoisactive, extended events or SQL Trace - but you should make sure you don't trace too much or cause too much load from your checking. Also I notice that you are sorting your results in TempDB - is there a reason you've selected that? Have you noticed any issues in TempDB size with that set? I know I've said this before in other answers to you so I apologize if this sounds like I'm hammering you here - but I would strongly suggest you look at a script like the Ola Hallengren maintenance solution. There are others - SQL Server MVP Michelle Ufford has also written one. These scripts do a few things that maintenance plans just don't do and the benefits seem to be exactly what you want: 

Well to answer your specific question, you should be able to see that in the existing connections and audit:login events in SQL Server Profiler/Tracing. I would actually start by trying to investigate who the blockers are and then dig in, however. You may have better luck in actually tracking down the blockers if they actively block and you see the blocking in action. You should be able to do that by either querying the dynamic management view - sys.dm_os_waiting_tasks (described here) or installing and using Adam Machanic's sp_whoisactive (a procedure I recommend you install anyway) 

Like Swasheck and Mark I started playing when this one came out. Please don't accept this answer, accept Mark's, in fact don't even give me points, I have no screenshots when I saw Swasheck post what I had started working on, but this is too long for a comment. So the short answer is: Yes, you are fine That said, I have heard of reports in past versions of SQL where people have seemed to think this was required. So I wanted to be sure and I did a test. I created a database, created some tables and then used Glenn's query to see how much of that database was in the buffer cache before the restore. Before I had about 50.2MB of data, after I had about 1.5MB - this is most likely because of something after the restore, not because of data hanging about. I also ran several queries before and included table aliases like "foo" so I could find them in the cache using the query below. I saw them all there, did the restore and they were gone. 

You could shrink it in smaller "chunks" using . Pros: No development really required, potentially less downtime than migration. Cons: You are still shrinking a database, you still have to deal with fragmented indexes, but you should do some index rebuilds anyway because you've removed a lot of data. You could build a new database and select data into it. Pros: You aren't shrinking. You are starting "fresh" and clean. You can use this as a time for other cleanup potentially. Cons: Probably more effort than just shrinking in chunks, may require a larger down window depending on how complex the environment is. Potential risk for missing something in the scripting. If you chose the shrink route, remember to rebuild your indexes and deal with the resulting fragmentation. 

The link that Thomas provided in his comment on the question is a good resource of some scenarios to test. Bob also provided some tests that are good, many of which are included in the blog post linked. I would say in addition to those great lists of "what" to check, you also want to look at various application scenarios to test failover during. I've seen a lot of clusters get built and then get tested from the server team/DBA team side - but the application teams were never involved. What happens to your applications during that failover? Now it really mostly looks like a restart to the application (effectively that is what the failover is.. Service goes down on Node A.. Service goes up on Node B.. SQL does what it does when SQL is shut down and restarted or when it crashes and comes back up.. DBs go through recovery on the other side of the restart, connections are all dropped where they are, etc.) So it may seem pointless to test, but it is good to see what kind of process the users will experience and to understand what processes the application owners and helpdesk folks, etc. need to do when that failover happens. You should ask questions like: 

Glenn Berry has written some great scripts to help you find your missing indexes. I suggest using his scripts which take some of the guess work out of the task for you. Those scripts aren't just looking for null or 0 user lookups/scans/seeks but also looking for indexes that have a large skew between read activity and write activity, possibly still resulting in better overall performance by dropping. I'd check his scripts out - you can get a start on this post of his. I wouldn't be worried about the system activity. That isn't something that will get worse if you remove the indexes, in fact it could be activity that only happens on that index because it exists. The main thing you care about is user read activity and user write activity and balancing that out.