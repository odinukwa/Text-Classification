In Japanese there are two morphemes which are used before certain nouns as part of the honorific system: 

So obviously there are always various features that make adjectives behave a bit differently from nouns or verbs, but are there languages where adjectives are morphosyntactically a very distinct category that cannot be related to either nouns or verbs? Maybe this question only makes sense for inflecting languages since the syntax seems to vary for all three and in languages with little inflection like English where there is not much inflection difference even between nouns and verbs. 

I've noticed a propensity for agglutinating languages to also permit quite long compound nouns. Finnish, Turkish and Hungarian certainly have them and I've been finding a few now that I'm trying to learn Georgian. Obviously not only agglutinating languages go in for long compound nouns though, since German is quite famous at least among English speakers for having some really long nouns. But are there languages which are of agglutinating typology but which don't have the tendency to permit long compound nouns? Is there a language universal that says something like: 

$URL$ -- Using Speech Synthesis to give Everyone their own Voice) -- This gives a high-level overview of the different techniques. $URL$ -- Speech Synthesis by Kim Silverman -- Note that he gives some inaccurate information (e.g. he criticizes a pronunciation dictionary for having different phonemes for the comma and roses[1]). $URL$ -- "Electronics - Digital Voice and Picture Communication" (NPTEL) -- This has various videos on Linear Predictive Coding. 

It is not really any given language that is hard to translate. The problem is contextual words or phrases that mean different things (either in English or in the language being spoken). This includes colloquial phrases, cultural differences (e.g. the boot or trunk of a car). There are also domain specific differences (e.g. "International Phonetic Alphabet" in linguistics and the navy). Consider the phrases: 

One approach would be to look at the volume (amplitude) of the audio signal at each point in time. If the signal falls below some configured level (accounting for any noise in the recording), treat it as silence. Then, if the silence occurs for at least a configured duration (e.g. 10ms) mark it as actual silence with the start and end times. That will not give you the start/end of each sentence, but of each utterance (i.e. when the speaker decided to pause). This will tend to correlate to phrase-terminal (comma, etc.) and sentence-terminal (full stop, etc.), but not necessarily. For example, a speaker may pause before a conjunction ("and", etc.). To provide better results, you need to perform full speech recognition on the audio with the text as a reference to match against. A simplistic approach here would be to match a few words around the sentence terminal, but you need to be careful to avoid word sets that could occur within the sentence itself. Speech recognition is complex, and is harder to do when you don't know what is being said. This is because of accent differences, like the don-dawn merger in some American English acccents, suprasegmental features changing phonemes between words such as with the linked r sound (e.g. in "China and Taiwan"), and changes due to normal/informal speech. Due to these problems, knowing what text is meant to be spoken can be used as a hint to the speech recognising algorithm to help guide its internal models (e.g. recognising 'atom' instead of 'Adam' for an American English speaker). This is still complex, because speakers may rephrase parts of the text, repeat some words or phrases, or introduce words such as 'er' and 'um'. I don't know what software is available to provide the above functionality. 

Tone sandhi is the process by which the nominal tones of syllables or words change based on the surrounding context. I know that Mandarin Chinese and Thai have tone sandhi - but is this process universal within tonal languages? 

Animacy has come up in a few recent questions, especially in comparison to gender. One interesting thing that turned up in the comments on those questions was whether or not animacy can sometimes be purely grammatical. Let me compare with gender which is more familiar. Natural gender and grammatical gender are two different things. Natural gender is not abstract or arbitrarily assigned. This is when language reflects the sex of things, mostly people and higher animals. English has natural gender in pronouns etc: "he", "she", "him", "her", "his". Some languages have only one third person pronoun regardless of the sex of the person etc referred to. Natural gender is not lexical. It refers directly to the sex of the thing referred to and not the word representing the thing. Grammatical gender is abstract or arbitrarily assigned. This is when every word is assigned a class such as "masculine", "feminine", "neuter", "common". These assignments are mostly not related to sex but may be related to the sound of the word or may be utterly arbitrary. Words for inanimate objects are very often assigned to the "masculine" or "feminine" class and animate objects are sometimes assigned to the "neuter" (sexless) class, for example German "Fräulein" is a neuter word for "girl", not feminine as would be expected under natural gender. Grammatical gender is lexical. It refers to the word representing the thing and not to the thing directly. Two synonyms referring to the same thing rrcan have different genders. For example there are two Spanish words for "star". "El astro" is masculine and "La estrella" is feminine. It helps to differentiate the words "gender" and "sex" when talking about this topic. "Gender" was originally a grammatical term only and came to become a synonym for sex later. There is another phenomenon often confused with grammatical gender. I might call it "semantic gender" but there's probably a real term for it. In English all ships tend to be referred to as "her", but this is not lexical, does not depend on the word used for the ship. Languages with grammatical gender may use different genders for "schooner", "destroyer", "carrier", and "battleship". So, is animacy ever in any language grammatical? That is to say does it have the properties of being a) abstract/arbitrarily assigned and b) lexical? 

Another factor is whether it uses specialist words in a given domain (including archaic words), or meanings for the words. The more of these there are, and the more obscure outside the given field they are (e.g. electricity vs quantum chromodynamics), the more complex the sentence is to understand. The same goes for abbreviations, slang, accentisms ("Aye, tha' be t'one ah war lookin' fer."), or even pulling in words from other languages ("That is no bueno."). Another factor is whether the sentence uses non-standard word ordering, either for poetic effect or for something like Yoda speak ("Go, you must."). Another factor is if the sentence uses the incorrect form of a word (its vs it's) or the wrong homophone (their vs they're vs there) or the wrong word (e.g. via spell checkers or predictive texting for technical or uncommon terms). Another factor is mixing or using a different spelling (British English, American English, text/SMS, leet (e.g. l33t), archaic, ...) to what the reader is used to. 

In short we need to be careful about confusing word categories and functions/grammatical relations. These two things are entirely different. 

This is often referred to as dealveolar assimilation, because the consonant is moving away from its normal alveolar position, to effectively become a different consonant. The Original poster's question: There will be no elision of the /d/ in this environemt. However we are likely to get dealveolar assimilation. Because this consonant will now be homorganic (made with the same parts of the mouth) with the following /p/, it will not be released and may be less easy to hear. There will also be some devoicing of the /d/ because of the following voiceless /p/, and so it may appear more /p/-like. 

Again, how you wished to measure the 'distance' of the dependency relationship would depend on what exactly you were trying to show. 

In traditional grammar the verb BE was considered as a main verb (or lexical verb) when used on its own in a sentence. It was only considered an auxiliary when it was used as part of a passive construction or a continuous construction. However, we now understand that auxiliaries are a grammatical class of words that have the same grammatical properties. Lexical or main verbs do not share these properties. But the verb BE usually does, even when it is the only verb in the sentence. Auxiliary verbs The important central properties which characterise auxiliary verbs are sometimes referred to as NICE properties. NICE is an acronym for: 

Are there some more solid references? Is this a linguistics concept? Do I have the right term but the wrong definition? 

In looking through Google Books's preview of A Grammar of Lao by N. J. Enfield, I came across these two terms, which I'm assuming are equivalent to one another (possibly one is even a typo) and some kind of variant of "SVO", representing the word order subject-object verb: 

First tone is just a high note with a flat contour. Pitch is steady. Second tone has a rising contour. Pitch starts lower and becomes higher. Third tone has a contour which falls, then rises. Pitch starts higher, goes lower, then higher again. Fourth tone has a falling contour. Pitch starts higher then goes lower. 

In Georgian most nouns in the nominative case end with "-ი" (-i), most other nouns end in another vowel. In cases other than the nominative this ending may be replaced with a different ending but the endings are not usually altogether omitted. However I am sure that I have occasionally seen some nouns without this final -ი and just ending with a bare consonant. Is this really possible or have I imagined it? Under which conditions can it occur? 

The sentences above are well-formed with or without the phrase at four o'clock. Notice that we can stick this type of phrase on the end of just about any sentence regardless of the verb in the clause. There is no special relationship between PUT and the preposition phrase at four o'clock. Very importantly for the discussion here, Adjuncts can take many different forms. For example, they can be adverb phrases, preposition phrases or noun phrases: 

The Original Poster's examples don't imply anything very different from each other. However, the general question of whether or why it matters where we put the negation in a sentence is quite interesting—especially in relation to certain verbs: It is a fact known to millions of hardworking English language students all over the world that native English speakers strongly prefer negating the verbs think, believe and want, amongst others, to negating the complement clauses that they license. So, for instance, all other things being equal, we prefer: 

Here, the number of vowel sounds (syllabic or not) in the last two examples does not match the syllable split. A () has been inserted between two of the consonants. Does this pronunciation pattern change the syllabification rules to align with the number of spoken vowel/syllabic consonant sounds, or is it more a pattern of speech to smooth over adjacent consonants that do not flow easily together (e.g. the pair in )? With , should this be considered a prefix like , and others are, and be considered a syllable on its own -- that is, should it follow the syllable pattern of ? If should be considered a syllable, is the the nucleus? If so, does that make the phoneme syllabic? 

Look at the associated references (e.g. in the Klatt program and the Festival documentation). These reference the different papers published on different text-to-speech topics. [1] John Wells' Lexical Sets only has a commma set. The roses lexical set is needed to differentiate accents where <-es> is pronounced as '[əz]' or '[ɪz]' in sibilant fricative contexts, and <-ed> is pronounced as '[əd]' or '[ɪd]'. 

In reality, with many of these constructions there are practicalities which make multiple embeddings difficult to process, for which reason sentences like (7) are relatively rare. So, if we wanted to somehow measure how long-distance the dependency between the gap and its antecedent was in a particular sentence, we would most likely want to quantify this in terms of the number of embeddings involved—in other words the number of clause boundaries intervening between the gap and it's antecedent +. The number of words is usually of less interest to us. If we did want to measure the intervening material though, we might want to measure it in terms of syllables, not letters, characters, words, or phrases. 

What exactly does the term nucleus refer to in syntax? (I'm not asking about the term in relation to phonetics or phonology). For example when syntacticians write about left dislocations and so forth they talk about the nucleus of the clause. Similarly in some grammars when talking about free relatives or fused relative constructions people sometime refer to the wh- word as the prenucleus. Whilst I have a vague intuitive understanding of this term, I don't actually know what it means and haven't been able to find out from the web. I'd like to know, for example, whether in English sentences with fronted negative adverbials, whether the negative word is occurring before the nucleus of the sentence. For example in the sentences: 

John Wells' Lexical Sets define a FOOT vowel /ʊ/ for words like 〈full〉, 〈look〉 and 〈could〉, and a STRUT vowel /ʌ/ for words like 〈cub〉, 〈rub〉 and 〈hum〉. However, I am from the North of England and do not have the FOOT-STRUT split and am having a hard time identifying and hearing the difference for words in each group. I can look up each word in a dictionary to find that e.g. 〈hundred〉 has the STRUT vowel, however I want to be able to identify the STRUT vowel when people are speaking it (e.g. on recordings of Public Domain books on LibriVox, or on TV). According to Geoff Lindsey, in Standard British English the STRUT vowel is actually [ə]. In his blog post on the STRUT vowel, he notes that old RP speakers (esp. Queen Elizabeth) use [ɐ] for the STRUT vowel. I can recognise the difference in the more pronounced examples, but not generally. Lindsey transcribes 〈governing〉 pronounced by Kasia Madera as [ˈgəvnɪŋ] and 〈up to〉 as [əp tə] on his STRUT vowel page. Here, I can recognise the [tə] in 〈to〉 but am having difficulty identifying the STRUT vowels as [ə]. Is this because they are actually shifted slightly toward the [ʊ] vowel and thus harder to identify as [ə] (e.g. when comparing COMMA and STRUT vowel pronunciations), or is it my brain being trained to think that 〈up〉 is pronounced [ʊp] so does not hear the [ə] as a [ə]? For the TRAP-BATH split I can identify when people exhibit this and use [ɑː] for BATH. Is this because the FOOT and STRUT vowels are closer together than TRAP and BATH, thus making the difference less noticeable? Is it because there isn't any (or marginal) free variation/difference in the BATH vowel sound, making it clearer and more consistent? How can I learn to recognise where people are using the STRUT vowel? 

Here the subscript (i)'s are there to show that our interpretation of the word it is co-indexed with the word elephant. They refer to the same thing. So now we can model our relative clause sentence like this: 

A double vertical bar is often used in transcriptions to indicate a major intonational phrase boundary, and a single one to indicate a minor one. 

Most transcription systems allow for white space between words. This is just to make the transcription easier to read. It is not for any kind of punctuation reason. When a group of scholars decide upon a convention for representing the phonemes of a particular language in language-specific, phonemic transcriptions, they may sometimes choose one symbol over another because it more closely resembles the orthography. So, whereas Southern Standard British English /e/ is in between [e] and [ɛ], most authorities use /e/ as opposed to /ɛ/ to represent the phoneme because this is how the phoneme is most often 'represented' in the orthography. This it is felt, will make life easier for learners of English, who will have to use these transcriptions in dictionaries and language learning materials. When used in written essays about phonetics or phonology, lists of phones or phonemes are often separated within their brackets by commas. The comma does not feature as an IPA diacritic and so serves to show that we are talking about a list of discrete phones or phonemes and not a string of sound or a string of phonemes. So people tend to write [p, t, k] or /p, t, k/, for example, as opposed to /p/, /t/, /k/ and so on.