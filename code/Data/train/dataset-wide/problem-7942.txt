The Berry-Essen bound stated that $$\sup _{{x\in {\mathbb R}}}\left|\widehat{F_{n}(x)}-\Phi (x)\right|\leq C_{0}\cdot \psi _{0}$$ where $\psi _{0}(n)={\Big (}{\textstyle \sum \limits _{{i=1}}^{n}\sigma _{i}^{2}}{\Big )}^{{-3/2}}\cdot \sum \limits _{{i=1}}^{n}\rho _{i}$ and $\sigma_i,\rho_i$ are second and third moments respectively. $\widehat{F_n(x)}$ is the cumulative cdf for $\frac{X_1+\cdots+X_n}{\sqrt{\sigma^2_1+\cdots \sigma^2_n}}$ The DKW bound stated that $$\Pr {\Bigl (}\sup _{{x\in {\mathbb{R}}}}|F_{n}(x)-F(x)|>\varepsilon {\Bigr )}\leq 2e^{{-2n\varepsilon ^{2}}}\qquad {\text{for every }}\varepsilon >0$$. Question. Is it possible to construct such an example $F(x)$ such that $$\sup _{{x\in {\mathbb R}}}\left|\widehat{F_{n}(x)}-\Phi (x)\right|\sim O(\psi_0(n))$$ and simultaneously $$\Pr {\Bigl (}\sup _{{x\in {\mathbb{R}}}}|F_{n}(x)-F(x)|>\varepsilon {\Bigr )}\sim O(e^{-2n\epsilon})$$ as $n\rightarrow \infty$. (Note: My motivation is to find such a distribution worse enough to attain these two bounds tightly asymptotically, not to prove "$F=\Phi$" as @Linden pointed out, this may be a possible confusion of motivation.) 

[Brill]Brill, Eric. "Automatic grammar induction and parsing free text: A transformation-based approach." Proceedings of the workshop on Human Language Technology. Association for Computational Linguistics, 1993. [Hong et.al]Wei, Hong, et al. "Heavy-tailed statistics in short-message communication." Chinese Physics Letters 26.2 (2009): 028902. 

Therefore I do believe there is a deeper motivation of the "conformal prediction" from complex analysis that I was not aware of. Thanks! Therefore my question is, (1)Given the name "Conformal prediction", is this method more or less associated with the concept of conformal mapping in (multivariate) complex analysis? Does it mean that the old sample can be mapped locally conformally to the new samples? Since most of CP are implemented using SVM, is this related to the shape of classifying hyperplane determined by the SVM? (2)(More like a opinion-based question) How is conformal predictor different from the existing robust predictors while they both come with a guarantee that the true value will fall into the confidence region with high probability? Reference [1]Lei, Jing, et al. "Distribution-free predictive inference for regression." Journal of the American Statistical Association just-accepted (2017). [2]Papadopoulos, Harris, Vladimir Vovk, and Alexander Gammerman. "Regression conformal prediction with nearest neighbours." Journal of Artificial Intelligence Research 40 (2011): 815-840. [3]Saunders, Craig, Alexander Gammerman, and Volodya Vovk. "Transduction with confidence and credibility." Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence (IJCAI'99). Vol. 2. 1999. [4]Shafer, Glenn, and Vladimir Vovk. "A tutorial on conformal prediction." Journal of Machine Learning Research 9.Mar (2008): 371-421. [5]Vovk, Vladimir, Alexander Gammerman, and Glenn Shafer. Algorithmic learning in a random world. Springer Science & Business Media, 2005. [6]$URL$ 

We have the equation \begin{equation} \left\{ \begin{array}{rrrr} u_{tt}-\Delta u=0,&\text{in} & \Omega \times ]0,T[ & \left( 1.1\right) \\ u=0, & \text{on } & \Gamma _{0}\times ]0,T[ & \left( 1.2\right) \\ u-w=0, & \text{on} & \Gamma _{1}\times ]0,T[ & \left( 1.3\right) \\ w_{tt}-\Delta _{T}w+\partial _{\nu }u+w_{t}=0, & \text{on} & \Gamma _{1}\times ]0,T[ & \left( 1.4\right) \\ w=0,& \text{on } & \partial \Gamma _{1}\times ]0,T[ & \left( 1.5\right) \\ u(.,0)=u_{0},\text{ \ }u_{t}(.,0)=u_{1} & \text{in} & \Omega & \left( 1.6\right) \\ w(.,0)=w_{0},\text{ \ }w_{t}(.,0)=w_{1}\text{\ } & \text{on} & \Gamma _{1} & \left( 1.7\right) \end{array}% \right. \label{E1} \end{equation} I have proved that this equation possesses a solution in some space with the condition $${u_0} \in V \cap {H^2}(\Omega )$$ where $$V = \left\{ {v \in {H^1}(\Omega ),v = 0{\text{ on }}{\Gamma _0}} \right\}$$. My quetion is : Have I $${\partial _\nu }{u_0} \in {L^2}({\Gamma _1})?$$ Thanks. 

I found in a math book $URL$ a formula which gives the asymptotic behavior of the Laplacian eigenvalues with Dirichlet boundary condition in a bounded domain of $R^n$, this formula is given by But when we compute explicitly the eigenvalues of the Laplacian in the unit square we find that ${\lambda _{n,m}} = - {\pi ^2}({n^2} + {m^2})$. I can not see where is the problem in the above formula of the book because for $j=2$ we don't have the same behavior, and there is not a regularity restriction on $\Omega$. Thanks. 

Please see p.282 of the following ref, it does not call it Feynman-Kac Formula but the whole section 5 is discussing it. It formalized the diffusion using a tensor field over a manifold which is the most general and in-depth treatment from stochastic equation perspective that I know of. 

In fact, [Karlin&Taylor] defined Brownian motion to be a stochastic process satisfying 1,2,3 axioms with an additional stipulation "4*.$W(t)$ is continuous at $t=0$" And they derived continuity of Brownian path as a result using Karhunen–Loève representation Theorem at Sec 7.4. A possible relevant clue is that we always require the characteristic function $E(e^{Xt})$ to be continuous around origin in order to determine a random variables in distribution via characteristic functions. So I guess axiom 4* is a guarantee that some transform exists? My question is that: If we only assume axiom 1,2,3 on a stochastic process as above, can we construct a stochastic process $W(t)$ that is not a Brownian motion (which is defined as a stochastic process with axiom 1,2,3,4 satisfied OR axiom 1,2,3,4* satisfied in [Karlin&Taylor])? OR Alternatively, is the continuity axiom redundant? (I do not think so but it does not seem very clear how I can construct a counter example to illustrate the point.) After looking at @Bjørn Kjos-Hanssen's answer, I felt a more appropriate question to ask is that if there is a stochastic process that is not càdlàg and satisfies axioms 1,2,3. [Karlin&Taylor]Karlin, S., and H. M. Taylor. "A first course in stochastic processes" Academic Press. New York (1975). 

I want to apply the semigroup approach of nonautonomous evolution equation for the following wave equation $$u'' - \Delta u + \int\limits_0^t {g(s)} \Delta u(s)ds = 0$$ This problem can be written under the standard form of Cauchy problem $$U' = A(t)U$$ where$$ A(t)=\left( \begin{array}{cc} 0 & 1 \\ \Delta -\int_{0}^{t}g(s)\Delta ds & 0% \end{array}% \right) $$ It is obvious that we can't apply the classical semigroups approach because the operator $A$ in this case depends on $t$. I tried to find some references which talk about these things but I didn't secceed. I want from you some advice or halp. Thank you. 

I want to prove the existence of the solution of this system by using the Faedo-Galerkin approximation method, I have to choose a basis for working on and I don't know how to do it in this case, I suggest the basis of the following spaces : \begin{equation} H_{\Gamma _{0}}^{1}(\Omega )=\left\{ u\in H^{1}(\Omega );\text{ }u=0\right\} , \end{equation} and $$H_0(\Gamma_1)$$ to deal with the internal and boudary termes. Is this write? thanx. \begin{equation} \left\{ \begin{array}{rrrr} u_{tt}-\Delta u=0,&\text{in} & \Omega \times ]0,T[ & \left( 1.1\right) \\ u=0, & \text{on } & \Gamma _{0}\times ]0,T[ & \left( 1.2\right) \\ u-w=0, & \text{on} & \Gamma _{1}\times ]0,T[ & \left( 1.3\right) \\ w_{tt}-\Delta _{T}w+\partial _{\nu }u+w_{t}=0, & \text{on} & \Gamma _{1}\times ]0,T[ & \left( 1.4\right) \\ w=0,& \text{on } & \partial \Gamma _{1}\times ]0,T[ & \left( 1.5\right) \\ u(.,0)=u_{0},\text{ \ }u_{t}(.,0)=u_{1} & \text{in} & \Omega & \left( 1.6\right) \\ w(.,0)=w_{0},\text{ \ }w_{t}(.,0)=w_{1}\text{\ } & \text{on} & \Gamma _{1} & \left( 1.7\right) \end{array}% \right. \label{E1} \end{equation} 

(1) If we put a uniform distribution over $\mathcal{S}_n$, i.e. $Pr(S=S_i)=\frac {1}{n}$ for $\forall i=1,2,\cdots n,S\in\mathcal{S}_n$ and let such a random permutation $S$ act on another fixed set $M\subset\mathbb{R}^{n\times n}$ of matrices of compatible dimensions. Is there existing result stating that by choosing $M$ appropriately, the resulting $S(M)$ will follow some kind of probability law? (2) Now if we put a uniform distribution over $\mathcal{S}_n(\beta )$ of the collection of $\beta$-avoiding permutations, with the same question in (1), is it possible to choose the set $M\subset\mathbb{R}^{n\times n}$ to make $S(M)$ follow some kind of probability law? (3)If the answer to (1)(2) are affirmative, what will such a probability law look like when $n\rightarrow\infty$? Will it break down? I primarily thought of (2) but later think (1) will be easier to illustrate. Reference [Fox]Fox, Jacob. "Stanley-Wilf limits are typically exponential." arXiv preprint arXiv:1310.8378 (2013). [Hoffman&Rizzolo]Hoffman, Christopher, Douglas Rizzolo, and Erik Slivken. "Pattern avoiding permutations and Brownian excursion." arXiv preprint arXiv:1406.5156 (2014). $URL$ [Marcus&Tardos]Marcus, Adam, and Gábor Tardos. "Excluded permutation matrices and the Stanley–Wilf conjecture." Journal of Combinatorial Theory, Series A 107.1 (2004): 153-160. 

(2) One of the benifits that I feel is that this gives an explicit way of constructing an extension of functional. RN Theorem can be proven by using Hahn-Banach Theorem[2], this insight might give you a constructive way of expressing the RN derivative in stochastic calculus. In statistics, the branching technique could be used to construct sample functions of many processes like Dirichlet process and Polya tree. For geometric analysis, the only tangential reference that I know of is [3]. If you think RN derivative as a vector field. If you regard the RN derivate as a stochastic process I think it is also natural to regard it as a flow as [4]. From the perspective of operator algebra, this construction allows us to see conditional expectation as sort of RN derivate, and hence a differential operator. [1]Karlin, S., and H. M. Taylor. "A first course in stochastic processes Academic." New York (1975). [2]Radon-Nikodym Theorem and Conditional Expectation $URL$ [3]Stroock, Daniel W. An introduction to the analysis of paths on a Riemannian manifold. No. 74. American Mathematical Soc., 2005. [4]Ambrosio, Luigi, Nicola Gigli, and Giuseppe Savaré. Gradient flows: in metric spaces and in the space of probability measures. Springer Science & Business Media, 2008.