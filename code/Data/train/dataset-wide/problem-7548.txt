Let $X,Y$ be positive random variables on some probability space $\Omega$ such that $\mathbb{P}(X>x)\leq \mathbb{P}(Y>x)$. Can one remove a set of measure zero (with respect to both distributions) from $\Omega$ so that in the new probability space we could couple $X,Y$ so that we would have $Y=X+Z$, where $Z$ is some positive random variable? 

Let $p_i\in (c,1-c)$ for some fixed $c\in(0,1)$ . Consider a sum $X=\varepsilon_{1}+\cdots+\varepsilon_{n}$ where $\varepsilon_{i}$ are independent Bernoulli random variables with parameters $p_{i}$. Let $Z$ be a normal random variable with the same mean and variance as $X$. I would like to approximate probabilities $\mathbb{P}(X=k)$, where $k$ is "not too far" from the mean. For which $k=k(n)$ can we approximate $\mathbb{P}(X=k)$ by the corresponding normal probability. That is, in which range for $k$ is it true that $$\mathbb{P}(X=k)=(1+o(1))\mathbb{P}(Z\in (k,k+1))$$ 

Let $V=\left\{-1,1\right\}^{n}$. Consider three vectors $v_1,v_2,v_3\in V$. I would like to know whether these vectors are linearly independent over $\mathbb{Z}$. To be more precise - I need a following quantitative statement: What is the smallest number of triples, say f(n), in $\mathbb{Z}^{3}$ such that if the vectors $v_1,v_2,v_3$ are linearly dependent, then for some triple $(k_1,k_2,k_3)\neq 0$ we have $$k_{1}v_{1}+k_{2}v_{2}+k_{3}v_{3}=0?$$ As there are exactly $2^n$ vectors and there are $N=\binom{2^n}{3}$ triples, then clearly $f(n)\leq N$. But this is very wasteful. Is there a way to significantly improve this trivial bound? Could one hope for a polynomial in $n$ number of triples? 

Let $Z_1,\ldots, Z_n$ be standardized Gaussian random variables and denote $\rho_{ij}=\mathbb{E}Z_iZ_j$. Can one give an asymptotically sharp bound for $$\mathbb{P}\,(\max_{1\leq i\leq n}Z_i>x), \quad x>0\,?$$ 

I am not sure how useful it will be, but have you looked at the work by Ibragimov and Maslova: $URL$ It seems that they can extend the results obtained by M. Kac to arbitrary distributions with reasonably mild assumptions on the moments. That asymptotically should even give the correct constant. 

I am interested in the following question. Consider $n$ independent standard normal random variables $g_i$. Cosider a linear combination $w_1g_1+\cdots+w_ng_n$. Can one give a "decent" upper bound for \begin{equation} \mathbb{E}\min_{w_i \in \left\{-1,1\right\}}|w_1g_1+\cdots+w_ng_n| \text{?} \end{equation} Basically, I am asking about the minimum expected absolute value of a family of correlated gaussian random variables. If a good bound can be obtained, what about the same question for more general linear combinations, such as $w_1a_1g_1+\cdots+w_na_ng_n$ in term of $n$ and some norm of $a_i$, say $l_{2}$? 

Let $k_1,\ldots,k_n$ be distinct integers. Let $s_n(t)=\cos (k_1t)+\cdots+\cos (k_nt)$ be a trigonometric sum. Consider any interval $I\subset [-\pi,\pi)$ of length $\delta=\delta(n)$. Let $\,U$ be a uniform distribution in the interval $I$. I am interested in the quantity $\mathbb{P}(s_n(U)>0)$. Questions: 1) (strong form) How large should $\delta(n)$ be so that we would have $\mathbb{P}(s_n(U)>0)\approx 1/2$? 2) (weak form) How large should $\delta$ be so that we would have $\mathbb{P}(s_n(U)>0)$ is bounded away from zero and one independently of $n$? Comment: If $s_n$ is the Dirichlet kernel, that is, $k_i=i$, it is easy to see that we must have $\delta_n>>n^{-1}$. I would be content if one of the latter statements was true with $\delta(n)=1/\log (n)$. 

Let $A$ be a finite set of non-negative integers and write $I_k$ for the set ${0,1,\ldots,k-1}$. Form all possible l-wise intersections $(A+k_1)\cap \ldots \cap (A+k_l)$, where each $k_i$ runs through all values of the set $I_k$ (thus giving us $k^l$ of such intersections). Given an integer $0<t<|A|$, I want to maximize the number of intersections with cardinality at least $t$. Is it true that the optimal set $A$ is $\{0,1,\ldots,|A|-1\}$? 

Let me state a standard result first. Let a $A\subset \mathbb{R}^d$ be a set of fixed volume. Define $A_t$ to be the set of all points at distance at most $t$ from $A$. Then the volume of $A_t$ is minimal if $A$ is a ball of the prescribed volume. Another way to define $A_t$ is by $A_t=A+B(0,t)$, where $B(0,t)$ is the centered ball of radius $t$. We shall think of it as the union of translates of $A$ by all vectors in $B(0,t)$. I am interested in extending such a result to the discrete setting. Say, we translate $A$ only in the $d$ orthogonal directions. That is, we look at the union $U(A)=\cup_v (A+v)$, where $v$ is either the zero vector or $\pm e_i$, where $e_i$ is an element of the standard orthonormal basis. Given that the volume of $A$ is fixed, which $A$ minimize the volume of $U(A)$? 

Let $V=\left\{-1,1\right\}^{n}$. Consider three vectors $v_1,v_2,v_3\in V$. I would like to know whether these vectors are linearly independent over $\mathbb{Z}$. To be more precise - I need a following quantitative statement: Is there a finite number of triples in $\mathbb{Z}^{3}$ such that if the vectors $v_1,v_2,v_3$ are linearly dependent, then for some triple $(k_1,k_2,k_3)\neq 0$ we have $$k_{1}v_{1}+k_{2}v_{2}+k_{3}v_{3}=0?$$ The important thing is that the collection should work for all triples of linearly dependent vectors under consideration. If the answer to this question is NO, can one then give a infinite collection of such "test" integer triples that would have a very small density in $\mathbb{Z}^{3}$? That is, we clearly do not need to consider all triples of integers - having considered (1,2,3), we do not need (2,4,6) in the collection etc. 

Let $p\in (0,1)$ be fixed and let $X$ be a binomial random variable with parameters n and p. Consider a related normal random variable $N$ with mean $np$ and variance $np(1-p)$. Is it true that for some $x=x(n)$ we have $P(X>np+x)=(1+o(1))P(N>np+x)$? That is, if true, I would like to know how large $x$ can be. Is it true that the natural borderline is $x=O(\sqrt{n})$? 

Let $X_1,\ldots,X_n$ be independent Bernoulli random variables such that $\mathbb{P}(X_i=\pm 1)=1/2$ and consider two collections of real numbers $a_1,\ldots,a_n, b_1,\ldots, b_n$. For the moment let us just take $a_i=1$ and $b_i=i$. Write $X=\sum_{i=1}^{n}a_iX_i$ and $Y=\sum_{i=1}^{n}b_iX_i$. Questions: 1) What is the simplest way to show (maybe a result to quote) that the vector $(X,Y)$, appropriately scaled, is asymptotically jointly Gaussian? 2) Can one show that for "decent" (smooth, bounded) functions $f,g$ we have $E f(X)g(Y)= (1+o(1))E f(Z_1)g(Z_2)$, where $Z_i$ are Gaussian variables such that $E Z_{1}^2=E X^2$, $E Z_{2}^2=E Y^2$ and $E Z_1Z_2=E XY$? I am sure this is fairly standard, but I would very much appreciate a useful reference. 

Let $X_1,\ldots,X_n$ be independent random elements of a normed space $X$. Suppose that $\sup_{x\in X}\mathbb{P}(X_i=x)=p_i$. What is the best known upper bound for $$\sup_{x\in X} \mathbb{P}(X_1+\cdots+X_n=x)?$$ Comments: 

Let $X_1,\ldots X_n$ be i.i.d. random variables and denote by $S_n$ their sum. Assuming that $\mathbb{E}S_n=0$, $\mathbb{E}S^2_n=1$ and that $\mathbb{E}|X_i|^3=b$, the Berry-Esseen Theorem (in the i.i.d. case) gives us the estimate $$|P(Z<x)-P(S_n<x)|\leq cb/\sqrt{n},$$ where $c$ is an absolute constant and $Z$ has the standard normal distribution. I wanted to know what happens if we do not assume finiteness of the $3-$rd or $(2+\varepsilon)$-th moments? Could it still be true that $$|P(Z<x)-P(S_n<x)|\leq c'/\sqrt{n},$$ where $c'$ depends only on the distribution of $X_1$? It is easy to construct examples of $2-3$ point distributions that would make $c'$ arbitrary large (for those examples). But once we fix the distribution, is it in general reasonable to assume that that the is a constant so that the aforementioned inequality holds? 

Let $X,Y$ be two centered Gaussian random variables each with variance at most $1$. Note that we do not assume independence. I would like to minimize $$\mathbb{P}(|X|\leq 1, |Y|\leq 1).$$ Is it true that the latter quantity is minimized when $X,Y$ are independent and both have variance $1$? 

I am searching for a result in the literature that I am sure must be known, but I just fail to find it. Let us starts with a simple example: Let $A, B\subset \mathbb{Z}$ be a finite sets of integers such that $|A|=|B|=2m+1$ and denote by $I$ the set $\{-m,...,m\}$. I want to show that for all $k,l \geq 0$ we have $$\sum_{|i|\leq k, |j|\leq l}|(A+i)\cap(B+j)|\leq \sum_{|i|\leq k, |j|\leq l}|(I+i)\cap(I+j)|.$$ And, more generally, for any finite collection of sets $A_1,\ldots,A_t$ of the same odd cardinality $2m+1$ and all numbers $i_1,\ldots, i_t\geq 0$ we have $$\sum_{|j_1|\leq i_1,\ldots, |j_t|\leq i_t}|(A_1+j_1)\cap\ldots \cap(A_t+j_t)|\leq \sum_{j_1|\leq i_1,\ldots, |j_t|\leq i_t}|(I+j_1)\cap\ldots \cap(I+j_t)|.$$ Thank you for your attention!