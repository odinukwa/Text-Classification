More technical note: you might notice that (1) and (2) do not seem very similar to each other: (2) is a compensated concept, keeping us on the same indifference curve, while (1) is not. This is a valid criticism, and indeed there is an alternative notion of "q-complements" that is compensated, and a notion of "p-complements" that is not. The compensated notion of q-complements, which is probably more relevant for most consumer theory applications than (1), asks whether the marginal return to $x$ increases as we increase $y$, while staying on the same indifference curve. (It's more relevant for consumer theory because it doesn't depend on the inherently ambiguous cardinality of $U$. Indeed, apparently Hicks introduced this as the consumer-theory definition of "q-complements" in his 1956 Revision of Demand Theory, though I don't have a copy of it myself.) This notion also has a mixed partial characterization, in terms of something called the distance function, which is a cool micro theory tool that no one learns anymore; the matrix of mixed partials of the distance function is called the Antonelli matrix, and it is a generalized inverse of the beloved Slutsky matrix. If we wanted to think about other versions of p-complements, there are several options. One way is to hold income constant, and say that $x$ and $y$ are complementary if a decrease in the price of $y$ increases Marshallian demand for $x$. This is a valid notion (called "gross" complementarity rather than "net"), but it's not very nice because it's not symmetric (due to income effects) and hence doesn't have a mixed partial characterization. Another, nicer way is to hold marginal utility of wealth constant (this is called "Frisch" demand, and is the consumer theory analog of profit maximization, which holds price of output constant), and then ask whether a decrease in the price of $y$ leads to an increase in the demand for $x$. This depends on entries in the inverse of the Hessian matrix of mixed partials of $U$, revealing an inverse relationship with (1) (which depends on the Hessian matrix itself) that parallels the inverse relationship noted above between the Antonelli and Slutsky matrices. 

At one extreme, country A may use the same currency as country B. Relevant cases include the Euro Area and dollarized Western Hemisphere countries like Panama and Ecuador. In this case, we might say that A and B have a "fixed" exchange rate (at one to one), but we probably wouldn't say that their rate is "pegged". A similar but less certain case would be, for instance, the CFA Franc in Africa, which is in principle distinct from the Euro but has a fixed Euro conversion rate and is guaranteed by the government of a country using the Euro (France). This might be called "fixed" or "pegged". A less extreme situation is a currency board, where country A has a different currency than country B but promises to always convert them at a certain rate, and has reserves denominated in country B's currency backing up every unit of its own currency so that (in principle) this promise can always be fulfilled. Examples include Argentina's defunct currency board (a good example of a case where this promise was ultimately not fulfilled in practice) and Hong Kong's current currency board. I've seen both "fixed" and "pegged" used to describe such arrangements; as mentioned above, my sense is that "peg" is more common as a descriptor when the arrangement is perceived as being less automatic, with its permanence less certain. Still weaker is the situation where country A sets a certain exchange rate with country B but doesn't have a formal arrangement like a currency board to back it up. This is extremely common; one rare example among developed countries is Denmark, which pegs to the Euro. This is the last case among (1)-(3) that can still often be called a "fixed" rate or a "peg". The line between this and a currency board in (2) is often blurry, since in this case too central banks often maintain large foreign reserves, perhaps enough to back up every unit of their currency outstanding; but usually this case involves a less universal guarantee of convertibility. Then there is a vast set of arrangements where the rate is not perceived as being truly fixed for the indefinite future, but instead is allowed to fluctuate within a moderate or large band, or is subject to a "crawling" peg that is adjusted by the central bank, or is pegged to a possibly malleable basket of currencies, etc. These arrangements are usually called "pegs" rather than "fixed", because (after all) they aren't that fixed! A conspicuous modern example is China. There are even looser arrangements where a central bank floats the currency but pays some attention to exchange rates and wants to avoid fluctuations that are too large (rather than exclusively hewing to some domestic objective like an inflation target), using both the tools of domestic monetary policy (interest rates) and intervention in foreign exchange markets to keep exchange rates in line. This is usually described as a "managed" float, "dirty" float, or something similar; it would rarely be described as a peg, but sometimes the line between (4) and (5) can be blurry. Then at the extreme other end, we have countries that float their currencies and do not routinely intervene in foreign exchange markets. These arrangements would never be called either "fixed" or "pegged". 

This depends on long-run economic and demographic trends that are very difficult to forecast. That said, the medium fertility scenario in the UN's 2012 World Population Prospects puts the population in 2080 of China at 1173 million, of Europe at 659 million, and of the US at 446 million. Since the combined population of Europe and the US, at 1105 million, would be only slightly below the population of China in this scenario, China's output per capita would have to be more-or-less completely caught up with the average in Europe and the US in order to exceed their combined GDP. Although this would be a very strong performance, it is certainly plausible given the experience of China's neighbors: Japan, South Korea, Taiwan, Hong Kong, and Singapore all have per capita GDP within the range of other developed countries, despite all starting far behind the US and Europe as recently as World War II. (Japan had already experienced breakneck development following the Meiji Restoration, but according to the Penn World Table it was far behind the US + Europe average after World War II, and according to Maddison this was not just a result of wartime destruction: Japan was still far behind even before the war, at maybe 40% of US GDP per capita. Its performance following the war was therefore quite remarkable. Of course, South Korea's performance - starting at roughly the same level as sub-Saharan Africa - was an order of magnitude more impressive still.) Large-scale economic and political changes will most likely be necessary for China to achieve convergence to Western output per capita, but 65 years is plenty of time for these to happen. 65 years ago, in 1950, the Communists were just wrapping up after victory in the Civil War; 65 years before that, in 1885, the Qing Dynasty was still sputtering along. One consideration that will likely not matter much in all of this is land area. First of all, China's population density is actually lower than that in many of the world's leading economies - Japan, South Korea, Taiwan, and Singapore are all far denser, and the UK, Germany, and Italy are somewhat denser as well. Second, very little of the output in advanced economies depends on land area and natural resources: for instance, in the US, agriculture, mining, and resource extraction combined are about 4% of GDP. 

Suppose $B$ is an $n\times n$ matrix of Poisson transition rates, where $B_{ij}\geq 0$ for $i\neq j$ denotes the rate at which state $i$ transitions to state $j$, and $B_{ii}\leq 0$ gives the rate at which state $i$ transitions to all other states. Each row of $B$ sums to 0. Then if $p(t)$ denotes the probability distribution at time $t$, by definition of $B$ we have the ODE $$\dot{p}(t) = Bp(t)$$ We know what the solution to this kind of ODE looks like: $p(t)=e^{Bt}p(0)$, where $e^{Bt}$ is the matrix exponential of $Bt$. So, if we want $B$ to generate the Markov transition matrix $A$ after $t=1$, we need to have $e^B=A$. In principle, to get $B$, we need to invert the matrix exponential, taking the matrix logarithm of $A$. The problem is that each matrix has many matrix logarithms - the logarithm in one-dimensional complex space has infinitely many branches, and this is compounded when we're talking about matrices in $n$-dimensional space. Most of these logarithms will not be satisfactory Poisson transition matrices: maybe they won't be real, or the entries won't have the right signs. Yet it is possible that more than one of them will be: in some cases there is more than one Poisson $B$ corresponding to a Markov $A$, just as in some cases there is no Poisson $B$ corresponding to $A$. It's messy. Fortunately, there is a situation where life is relatively simple, and it almost certainly includes your own case: when all the eigenvalues of $A$ are positive, distinct reals. In this case, there is only one logarithm of $A$ that will be real, and it's easy to compute: you just diagonalize the matrix as $A=V\Sigma V^{-1}$ and take the real logarithm of the eigenvalues, getting $B=V\Omega V^{-1}$, where $\omega_{ii} = \log(\sigma_{ii})$. Indeed, you don't need to do this yourself: if you use the command $\text{logm}(A)$ in Matlab (presumably Python too), it will give you precisely this $B$. Given this $B$, all you have to do is to verify that it's actually a Poisson matrix. The first requirement, that the rows all sum to zero, is satisfied automatically due to the construction of $B$.** The second requirement, that the diagonal elements are negative and the off-diagonal elements are positive, does not always hold (I think), but it's easy for you to check. To see this in action, I'll consider an $A$ for a 3-state Markov process that resembles a discretized AR(1). $$A = \begin{pmatrix}0.5 & 0.4 & 0.1 \\ 0.2 & 0.6 & 0.2 \\ 0.1 & 0.4 & 0.5\end{pmatrix}$$ Now, if I type $B=\text{logm}(A)$ into Matlab, I get $$B = \begin{pmatrix}-0.86 & 0.80 & 0.06 \\ 0.40 & -0.80 & 0.40 \\ 0.06 & 0.80 & -0.86\end{pmatrix}$$ This is indeed a valid Poisson transition matrix, as we can easily check that the rows sum to zero and have the right signs - so this is our answer. The case with positive eigenvalues is pretty important, since it spans all cases where there is not some kind of oscillatory behavior in the Markov chain (which would require negative or complex eigenvalues), presumably including your discretized AR(1). More generally, the $\text{logm}$ command on Matlab will give us the principal matrix logarithm, an analogue of the principal scalar logarithm that takes all eigenvalues to have imaginary part between $-\pi$ and $\pi$. The problem is that this is not necessarily the logarithm we want, and by looking at it we might miss a Poisson $B$ that does generate $A$. (That's why the positive eigenvalue case, where we didn't have to worry about this, was so nice.) Still, even in these other cases it can't hurt to try and see if it works. By the way, this problem of seeing whether there is a $B$ that generates some Markov matrix $A$ has been studied extensively. It is called the embeddability problem: see some overview and references in this excellent survey article by Davies. I'm not an expert on technical aspects of the problem, though; this answer is based more on my own hackish experience and intuition. I feel obligated to close by seconding ecksc's comment and saying that there might be better, more direct ways to convert a discretely fitted AR(1) into a finite-state continuous time process - rather than just taking the matrix obtained via the Tauchen method and making it continuous. But I don't personally know what that better way is!