Fall in investment, uncertainty about the future, trouble exporting, and facing the high probability of loss of at least a part of the banking sector will in the short term probably trigger at least a small recession in the UK, accompanied by consumer price inflation due to higher import prices due to a weakend pound. A looming Scottish independence referendum is also not beneficial in this situation. Since the British Government is likely forced to intervene with a stimulus program of some kind, they will have to finance it, which means more debts financed by QE. Expecting QE, investors and speculators will flee into "save" currencies, like the CHF or the JPY. The last part, while apparently not yet finished, has basically already happened. BrExit will shift vote majority inside of what remains of the EU from North to South. Which means countries like France, Portugal, Italy, Spain and Greece will push for a weaker currency (aka. more QE to buy government bonds) to finance their ever mounting debt burden. With BrExit, a lot of Eastern European workers currently working in Britain might, and eventually will, have to return to their respective homelands by the time their visas expire. Since job prospects and pay in Poland, Slovakia, Romania + Bulgaria are admittedly miserable and I would try to escape it, too, this "innovative specialists" will undoubtedly seek employment in the rest of the remaining EU, which might trigger the domino effect by being the spark that ignites an already more than full powder chamber, especially when it comes true that BrExit means less growth in an already troubled Euro-area - and there is little reason to believe that it won't. 2) in turn is bad for the northern European states, like Denmark, Sweden, Austria, the Netherlands, Germany, etc. as it means they are going to finance the South's debts against their will with their "assets", aka mostly future pensions. Also, Brexit will increase the remaining states contribution to the EU budget, for example the German contribution to the EU budget will rise by appx. USD 2*109 (half of which will flow into agricultural subsidies, not anything productive or innovative or growth-stimulating). This 2 billions will have to be cut somewhere else, where that money would also be needed, such as education - and where that money actually would boosts both, future industrial innovation and growth. This and popular pressure due to unemployment as a result of EU-inflicted migration might make Northern States push for an EU-exit as well, especially in Sweden, Germany and the Netherlands, where the EU is, despite the suggestions of some official polls, even less popular than in Britain. And with elections in Germany moving closer, and the "Euro-sceptical" AFD on there rise, the Merkel government is not going to stay there for all that much longer. Insecurity about the economic and political future, as well as perceived or actual political and/or economic instability is going to do the rest for the EUR. No sane investor likes these things. 

Hence, $$\begin{split} M &= 1 - \int_{0}^{7/11}\frac{2-a}{3}da - \int_{7/11}^{1}\frac{3a-1}{2}da\\ &= 1 - \frac{259}{726} - \frac{32}{121} = \frac{25}{66} \approx .3\bar{78} \end{split}$$ Finally, $$T=1-\frac{25}{66}-\frac{101}{264} = \frac{21}{88} \approx .238\bar{63}$$ Since $$\begin{split} \frac{101}{264} &> \frac{25}{66}\\ \frac{101}{264} &> \frac{21}{88} \end{split}$$ the result is shown. 

The answer from Dan is a good one, but I would like to add on the following criticism, which is apposite at least in the context of international trade. Dynamic concerns notwithstanding (again see Dan for commentary on those), free trade between countries is welfare increasing for the countries trading (it must be so because under free trade voluntary autarky is always an option). However, the efficiency gains within each countries are not equally spread and so there may be winners and losers, despite an overall economic improvement. In the US, the losers are typically those employed in manufacturing, and it is documented that as a result of trade this sector suffers significant job losses: $URL$ ``Our central estimates suggest job losses from rising Chinese import competition over 1999–2011 in the range of 2.0–2.4 million." See also, $URL$ In short, international trade is beneficial, but not to everyone. 

History $(D,D)$ (Yes, this is with some abuse of notation.): On Path: Each player gets an average payoff of $4$. Deviating: Say player $1$ deviates and instead chooses $H$. Then the resulting sequence of actions is the alternating sequence, $(H,D)$, $(D,H)$, $(H,D)$,... Accordingly, player $1$’s sequence of payoffs is $(8,0)$, $(0,8)$, $8,0$... Player $1$'s average payoff is $(1-\delta)\big(8 + 0 + \delta^{2}8 + 0 + \delta^{4}8 + \cdots\big)$, which is $$(1-\delta)\frac{8}{1-\delta^{2}}=(1-\delta)\frac{8}{(1-\delta)(1+\delta)}=\frac{8}{1+\delta}$$ Hence, there is no profitable deviation here iff $$\begin{split} 4 &\geq \frac{8}{1+\delta}\\ 4\delta &\geq 4\\ \delta &\geq 1 \end{split}$$ Thus, $\delta \geq 1$ is a necessary condition (not necessarily sufficient because we still need to check that following tit-for-tat is still optimal for the other histories. I'll leave that to you!) 

In your basic introduction to information economics, the two classic interpretations of screening with hidden information correspond to monopolistic screening or a principal agent problem. Viewing the situation through the lens of the principal agent problem; there is a firm who wants an agent to produce a good, and the agent has private information as to how costly it is to her to produce a good of a certain quality. That is there are multiple types of agents--if there is just one type, this is just the full information (first-best) case, and the screening problem is trivial. The producer's problem is to design a contract in order to maximize expected social value while minimizing the agent’s rent. The basic problem with moral hazard, on the other hand, need not concern an agent with multiple types. Instead, the agent has multiple choices of effort. Now, the principal's problem is to choose the optimal level of effort and the best contract with which to elicit that effort level. To sum up, in the hidden information (screening problem), there is an agent with a private type, and the principal designs a contract in order to maximize some objective, given this information asymmetry. In the moral hazard problem the principal chooses a contract in order to elicit the optimal level of effort. Finally, as a caveat, this distinction is only clear at the introductory level, where the problems are very basic. One can easily have more complicated mechanism design problems that incorporate elements of both. 

In different paper I offen encounter two types of CES production functions $y=\left[\left(1-\omega \right) x_{1}^{\frac{\sigma -1}{\sigma}}+ \omega x_{2}^{\frac{\sigma -1}{\sigma}} \right]^{\frac{\sigma}{\sigma -1}}$ or $y=\left[\left(1-\omega \right)^{\frac{1}{\sigma}} x_{1}^{\frac{\sigma -1}{\sigma}}+ \omega^{\frac{1}{\sigma}} x_{2}^{\frac{\sigma -1}{\sigma}} \right]^{\frac{\sigma}{\sigma -1}}$ the only difference being the exponents of the weights. What is the difference in meaning and interpretation of the two weights (on an intuitive and a theoretical level). Does it matter which version to use in a paper? 

To solve the problem you also need the equation: $Y_t=\left(\int_0^1 Y_t(j)^{1-\nu} \ dj \right)^{\frac{1}{1-\nu}}$ Now, the FOC is the same for every $Y_t(j)$, so we only have to differentiate once. Applying the chain rule we get: $\frac{\partial \Pi_t}{\partial Y_t(j)}=P_t \left(\int_0^1 Y_t(j)^{1-\nu} \ dj \right)^{\frac{\nu}{1-\nu}} Y_t(j)^{-\nu}-P_t(j)=0$ At this point, the trick of the trade is that $\left(\int_0^1 Y_t(j)^{1-\nu} \ dj \right)^{\frac{\nu}{1-\nu}}$ which is a part of the FOC, equals $Y_t^{\nu}$ (check the first equation) Setting $\left(\int_0^1 Y_t(j)^{1-\nu} \ dj \right)^{\frac{\nu}{1-\nu}}= Y_t^{\nu}$ in the FOC, and solving for $Y_t(j)$ will give the desired result. 

Even though your question does not allow a definite answer, I am pretty sure the author used a Taylor expansion around the logarithm of both sides of the equation. This process is called log-linearization, and is fairly common. We can approximate (logs of) growth rates as $x \approx log(1+x)$ when $x$ is small. (and by the rules of logarithm: $\log((1+x)^\sigma ) \approx\sigma x$ Rewriting your equation $1+(r_t-\delta)=(1+\eta)^{\sigma}(1+\theta)$ where $r_t=\alpha (k^{\# *})^{\alpha -1}$ and applying this rule gives $r_t-\delta=\theta+\sigma \eta$ which gives the desired result. 

The third line of p.45 denotes: $MC_{t+k|t}=\psi_{t+k|t}/P_{t+k}$ but this is probably not the answer you are looking for. Going from eq. (9) to (10), multipliy the right-hand side by $\frac{P_{t+k}}{P_{t+k}}=1$ (you can always multiply by one), the numerator goes into $\Pi_{t-1,t+k}$ (together with $P_{t-1}$), the denominator goes into $MC_{t+k|t}=\psi_{t+k|t}/P_{t+k}$. 

NO, it is not redundant. Controlling for nominal effects gives you a better picture, and makes more sense on a theoretical level. To transform assets into USD use $\textit{asset}_{USD}=\frac{s_t P_{t,JPY}}{P_{t,USD}} \textit{asset}_{JPY}$ where the fraction is the real exchange rate, $P_t$ is the respective price level and $s_t$ the nominal exchange rate. Alternatively, you can work with differences $\Delta rer =\frac{\Delta s_t \pi_{t,JPY}}{\pi_{t,USD}}$. Note that the real exchange rate is far from perfect, but it is common practice in macroeconomics. Also, it does not matter which transformation you do first, as its purely multiplicative. 

Nope, every pure strategy equilibrium can be characterized as a degenerate mixed strategy equilibrium. That is, it is a mixed strategy in which a pure strategy is played with probability $1$. 

I think your one mistake was writing $\Pr(v_{2} < \beta(v_{1})$ incorrectly. It should be: $$\begin{split} \pi_1(v_1,v_2)&=\Pr(v_2<\beta(v_1))(v_1-\beta(v_1))\\ &=F_{2}(v_2<\beta(v_1))(v_1-\beta(v_1))\\ &= \beta(v_1)(v_1-\beta(v_1))\\ \end{split}$$ $$\begin{split} \left.\frac{\partial \pi_1(w,v_{2})}{\partial w}\right|_{w=v_1} =v_1\beta'(v_1) - 2\beta(v_1)\beta'(v_1)&=0\\ \beta(v_1) &= \frac{v_{1}}{2}\end{split}$$ Loosely we can look at, say, type $1$ of player $1$. If he bids according to this strategy his expected payoff is $1/4$. Suppose he picks any other bid amount $a$. Then his expected payoff is $(1-a)F(a) = (1-a)a$. This is clearly maximized at $a = 1/2$. 

I agree with the comments that suggest that the question is almost indecipherable. However, it should be easy, given the cdf, to derive the bounds. Why? Well we know for a cdf $F$, we must have $F(\underline{S}) = 0$ and $F(\overline{S})=1$. We can use the latter to work backwards from the upper bound i.e. We guess that $F(s)$ is of the form $$F(s) = k\bigg(\frac{S-v_l}{v_h-S}\bigg)$$ We must have $F(\overline{S}) = 1$ and using your solution, we have $$\begin{split}F(\overline{S}) = F\bigg(\frac{7v_h+3v_l}{10}\bigg) = k\bigg(\frac{\big(\frac{7v_h+3v_l}{10}\big)-v_l}{v_h-\big(\frac{7v_h+3v_l}{10}\big)}\bigg) &= 1\\ k\bigg(\frac{7v_h+3v_l}{10}\bigg)-kv_l &= v_h-\bigg(\frac{7v_h+3v_l}{10}\bigg)\\ \frac{7kv_h - 7kv_l}{10} &= \frac{3v_h-3v_l}{10}\\ 7kv_h - 7kv_l &= 3v_h-3v_l\\ k &= \frac{3}{7}\end{split}$$ Thus, I suspect that your mixed strategy for the high type is given by the cdf $$F(s) = \frac{3}{7}\bigg(\frac{S-v_l}{v_h-S}\bigg)$$ 

We can solve for the area of this quadrilateral: $$\begin{split} B &= \int_{0}^{7/11}\frac{2-a}{3}da + \int_{7/11}^{3/4}(3-4a)da\\ &= \frac{259}{726} + \frac{25}{968} = \frac{101}{264} \approx .382\bar{57} \end{split}$$ Through similar analysis for $M$, we obtain $$\begin{split} a &> 7/11, b>\frac{3a-1}{2}\\ a &\leq 7/11, b>\frac{2-a}{3}\\ \end{split}$$ 

Say you have two distributions, $G$ and $H$ with equal means supported on (say) $[0,1]$ and $H$ is second-order stochastically dominated by $G$. Then, for any concave increasing $u$, we'll have $$\int udG \geq \int udH$$ This would correspond to Aigner and Cain, where the risk averse firm would prefer to hire an agent from distribution G. However, now suppose that $G$ and $H$ are distributions of talent (with the same stochastic ordering i.e. $H \succ_{C} G$). One equivalent notion to this idea is that distribution $G$ can be obtained by ``fusing" together part of the mass of $H$, i.e. by collapsing part of the mass to its respective barycenter. Given this, it is easy to see that there is always a cutoff $\eta \in [0,1]$ such that $H(\eta) \geq G(\eta)$. This corresponds to Heckman's result--if the job is sufficiently demanding, then it will be (at least weakly better) to be part of the high variance population. Moreover, note that this by no means depends on the expected quality of the agent. There are simply more of the highest quality people in the group with distribution $H$ than in the group with distribution $G$. They are not just more likely to exceed the cutoff, there are more of them that exceed the cutoff. Another way to think about the hiring problem is as follows: say a firm wants to hire one person but receives applications from $10$ applicants, $5$ from group $A$ and $5$ from group $B$. A candidate's quality is unknown and it it ranges from $[0,1]$ continuously. Suppose also for the sake of simplicity that the firm may observe the candidate's group (and so knows what distribution he/she is drawn from): the distribution of quality for group $A$ is given by $G$ and the distribution of quality for group $B$ is given by $H$. Interviewing a candidate fully reveals a candidate's type, but the firm has the budget to interview only $4$ candidates. Whom should they interview? The answer is simple: all four candidates interviewed should be from group $B$ (which has distribution $H$). Why? Because we can think about a candidate's quality as a random variable $X_{i}$ and thus the firm wants to maximize $\mathbb{E}[Z]$ where $$Z:=\max\big\{X_{1},X_{2},X_{3},X_{4}\big\}$$ Since $H \succ_{C} G$, $$\mathbb{E}_{H^{4}}[Z] \geq \mathbb{E}_{G^{4}}[Z]$$ Note also that $H \succ_{C} G$ $\Rightarrow$ $Var(H) \geq Var(G)$ but not $\Leftarrow$. In this sort of thing, I think it is stochastic dominance and not variance that is the apposite metric. 

No. There is a trade-off between lowering inflation and boosting exports. You can't have both. There is no magic bullet. Note that with fully flexible exchange rates, high inflation does not hurt the export sector as the real exchange rate stays the same. 

If I have, for instance, a Libor security with maturity of one month, with interest rate $r$. Is $r$ the amount to be paid after one month, or is it the annualized interest rate? (My gut tells me that it is the annual interest rate, but I have not found a source to confirm this.) And if it is the annualized rate, how is the (actual) interest payment that is due after one month calculated? Is it $1+r/12$ or is it of the form $e^{r/12}$ 

Thanks for the hint and the link! I think I now managed to find the solution. Putting the exponent on the LHS and replacing $C_t^{1-\gamma}$ with $C+(1-\gamma) C^{1-\gamma}C \tilde{c}$ and $C_t(i)^{1-\gamma}$ with $C(i)+(1-\gamma)C(i)^{1-\gamma}\tilde{c}_t(i)$ i get (subtracting Steady State values): $(1-\gamma) C^{1-\gamma}C \tilde{c}=\int_0^1 (1-\gamma)C(i)^{1-\gamma}\tilde{c}_t(i) \ di$ Assuming steady state values of $C(i)$ are constant across $i$, i can take all values out of the integral and simplify to get: $\tilde{c}=\int_0^1 \tilde{c}_t(i) \ di$ 

Other things being equal, the price of patties influences the price of buns. The theory says nothing about how the price change came about. You implicitly assume that something changing patty demand would change bun demand, also. In the model world, there are only explicit assumptions. 

The Taylor rule links the interest rate to other variables (usually inflation), which are determined by the model (hence, endogenous). Therfore, it is endogenous. Similarly government expenditure. If it is pinned down (partially) by factors determined in the model, it is endogenous. 

To simplify matters, let's call the right-hand side of your starting equation $X_t$ Then, I start just like you did with $1 = X_t$ The difference between your solution and Gali's is that you took the Taylor expansion around $\log(1)=0=log(X_t)$ which implies that also the steady state equals 0, so we can simply subtract it to get log-differences, whereas Gali used $1 = \exp(\log(X_t))$ with steady state $1=\exp(\log(X^*))$ Let's define $x_t=\log(X_t)$. By definition of the Taylor expansion this gives $T(1) = \exp(x^*)+\exp(x^*)(x_t-x^*)$ Note that the exponential function is identical to its derivative. We know that $\exp(x^*)=1$ from above, so we can simplify to $T(1)=1+(x_t-x^*)$ At this point, you are correct that the $\rho$ cancel out. Instead of defining $\hat{x}_t=x_t-x^*$ but Gali chooses to replace $\rho=\pi +\sigma \gamma-i$, which is the steady state condition, which is why $\rho$ stays on the paper. Note, however, that the "approximation error" from taking log differences instead of Gali's approach is tiny, i.e. for $\beta=0.99$ it is only $-\log(0.99)\approx 0.01$ Have a look at appendix 2.1 of Gali's book! It is quite complicated, but together with this post, I hope you get it!