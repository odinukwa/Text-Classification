It sounds like you have a custom event handler setup that is doing some validation on the document during upload. If you get this codeplex utility: $URL$ You can point it to your site/list and it will tell you about any event handlers that are setup on the list. From there you can determine if you need to delete the handler or fix the problem that is making the document get rejected. 

Typically cross-subnet issues like this are networking equipment related, not necessarily NLB. Take a look at this blog post from the Microsoft Enterprise Networking team, it goes into the problems and possible solutions. 

Here is the official Microsoft documentation on how to disable a specific SSL protocol. The openssl test is definitely the easiest. There are binary distributions of openssl available for Windows. 

You probably need to add the NIC as a emulated/legacy network adapter instead of as an synthetic network adapter. Installing the virtual guest services should allow a synthetic adapter to be recognized as well. 

This is due to you running on 64-bit Windows 2003. Basically - cmd.exe is running in 32-bit mode, and there are only 64-bit versions of shutdown.exe (and some other executables) available. Due to how Windows works behind the scenes, it doesn't let you view/run the 64-bit executables from a 32-bit process. Explorer is 64-bit and can therefore see them. There is a hotfix available for this: $URL$ Also, here is a really good blog post explaining the problem in detail, as well as some alternative workarounds (although they recommend the hotfix): $URL$ 

Close all instances of Reporting Services Configuration Manager or SQL Server Management Studio. Open a command prompt. Register the Reporting Services WMI provider. In the command prompt, run the following command: Run the WMI Tester again to see whether you can now connect to the namespace for the Reporting Services WMI provider and continue with the debugging process. 

Adding a list is not a built-in command for STSADM. You can get 3rd party STSADM extensions that will add this functionality. 

Maybe I am missing something, but can't you just go into the Tasks list associated with the workflow and delete the offending Tasks? To make this more automated, perhaps you can setup an Information Management Policy to automatically delete the Tasks after a certain number of days. I believe for a Task List you can setup the Expiration policy to occur a certain number of days/months/years after the Tasks scheduled Due Date. 

I know you specifically asked about IIS data - but have you looked at the SharePoint Usage Analysis reports? 

What service pack level of sharepoint are you on? mergecontentdbs was introduced in 2007 SP1 so if you aren't up to that level yet it won't exist. If this is the problem (you aren't upgraded to SP1 or higher yet) there is a hotfix that can be applied to add mergecontentdbs. 

This can be a problem if your UserInfo table in the database has corrupted SIDs in it. I could definitely see this happening if you attached an existing content db rather than doing backup/restore. The way to test/fix it is: 

You can then setup a trust relationship between the main farm and the 2 my site farms, where the main site would publish its services, and the my site farms would consume them. Within your main farm you can set up an audience for your staff, and another for your users based on whatever criteria separates them. After that, you setup 2 trusted My Sites locations and give them the appropriate URL and audience. 

I don't know of a definitive source for the Wake Source codes, but next time you see a 0, try running the following command at a prompt: 

I think you are misunderstanding pass through authentication. If pass through authentication is enabled, one of 2 things will happen: 

but you need to recompile nginx to get this support - it isn't enabled by default. See this blog post for more details. 

There is no way to apply a template (.STP) to an existing site. There isn't even an easy way (as far as I know) to apply a separate site definition template (the "site template" you choose on initial site setup) to an existing site. Even if you could do either, removing the existing site content would probably not be part of the process. The closest thing I can think of that would accomplish what you want would be to create a new SharePoint Feature that contains the lists/etc. that you want, and enable that on the sites. You can even staple the Feature to specific site definition templates so that any site created with that template always has the Feature enabled. I don't think you can have a Feature delete existing lists on a site though. 

and then bring the servers back up in the reverse order. When Forms Services (and possibly Excel services...I've seen conflicting documentation) are in use, they sometimes have sessions that go through multiple HTTP requests before committing a transaction to the database - this is where the quiesce farm command comes in. It allows session(s) to finish doing one of these multiple request transactions, but doesn't allow any new sessions. After all transactions are committed the Infopath (Excel?) services are offline and ready to be shut down as well. Here is a blog post that goes into a little detail about what Quiesce farm is doing: $URL$ You didn't talk about the end user experience part of this equation at all, but I will mention it for completeness. If you were to shut down a WFE in the middle of a user uploading a file or editing a list item - there wouldn't be any corruption of the WFE or database, but the end user is basically just dumped to an error page that doesn't really let them know what happened (or if there edit happened!). The way to deal with this would be to have something in front of SharePoint (a load balancer, even ARR on a separate server could do this) that would gracefully "drain" SharePoint of end user connections, and potentially redirect to a friendly error page until the site is back up. 

There is indeed a way - the assemblies are stored in the table in your database. Select everything from and find the , then run the following code (changing the and path first): 

There are a couple of options to do this. The first (Microsoft-approved) way of doing it is to just move the content databases, but leave the config database on the internal database. The technet documentation for doing that is here: $URL$ If you want to move the config database as well, you have 2 options. The first (probably less headache-inducing) method is to basically backup your content databases, remove the WIDB from the computer, create a new farm pointing to your SQL Server database, then attach your content databases to the new farm. 2 blog posts that talk about using this method are here: $URL$ $URL$ The second option is to actually try and move all the databases (including the configdb) to the new server. Microsoft has documentation on how to do this (not specific to WIDB->SQL Server migrations, but I don't see why it wouldn't work.) My understanding of this though is that moving the configdb is not always seamless, and could cause you some big problems. Regardless, here is the documentation for this approach: $URL$ 

From a capability standpoint, Hyper-V Server R2 is essentially the same as the Hyper-V role on a Windows Server 2008 R2 installation. From a "technical limitations" standpoint, going with Hyper-V server is actually better than going with Windows Server 2008 R2 Standard. Hyper-V Server R2 supports up to 1TB of memory and 8 (multi-core) CPUs. Windows Server 2008 Standard supports up to 32GB of memory and 4 (multi-core) CPUs. If you compare memory/CPUs to Windows Server 2008 Enterprise or Datacenter, then Hyper-V starts to fall a little short. Enterprise supports 2TB memory and 8 CPUs, Datacenter supports 2TB and 64 CPUs. I know you said to ignore licensing - but the other big factor is the included free guest licenses on Windows 2008 Server. Hyper-V Server includes none. Standard includes 1 free guest OS license, Enterprise includes 4, and Datacenter allows unlimited. You need to do the comparison between purchasing guest OS licenses or purchasing the "upgraded" host OS and using the included licenses. 

Mirroring is definitely not able to do this, it can only mirror the entire database. If SQL Server Replication is not an option, I think you will need to come up with a solution that is not built in to perform this task. How "connected" are the 2 servers? The next thing I could think of would be to setup the destination server as a "Linked Server" within SQL Server. You can then use a database trigger on the source server to update the destination server using the linked server. You need to be careful in your trigger to get the naming convention down though, it would have to be something like . I think the servers would need to be (network-wise) pretty close to each other as well for this to work with any sort of reliability.