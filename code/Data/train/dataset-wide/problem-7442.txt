I will follow the original paper as much as I can. So, let us consider the solution of the equation $$u_t-6uu_x+u_{xxx}=\epsilon u.$$ You will have a general solution $u=u(x,t;\epsilon)=\sum_{n=0}^\infty\epsilon^n u_n(x,t)$ after a power expansion on $\epsilon$. Now, turning your attention to the Schroedinger equation $$\psi_{xx}-[u(x,t,;\epsilon)-\lambda]\psi=0$$ you will notice that the problem is now $$\psi_{xx}-[u_0(x,t)+\epsilon u_1(x,t)+\ldots-\lambda]\psi=0$$ and this is amenable to standard Rayleigh-Schroedinger perturbation theory. This means that the first correction preserves the discrete nature of the spectrum and will be real yet. You can iterate this procedure going to higher orders in $\epsilon$ still preserving the inverse scattering method. This can be seen in the follwing way. From the given Schroedinger equation one has $$u(x,t;\epsilon)=\lambda+\frac{\psi_{xx}}{\psi}.$$ The condition granting that this solves KdV equation is $\lambda_t=0$ when $\psi\rightarrow 0$ given $|x|\rightarrow\infty$ and $u$ evolves by KdV equation. This must be true also for the approximate solution. So, from this equation we can evaluate the next-to-leading order correction by setting $$\lambda=\lambda_0+\epsilon\lambda_1+\ldots$$ $$\psi = \psi_0+\epsilon\psi_1+\ldots$$ and we get $$u(x,t;\epsilon)=\lambda_0+\epsilon\lambda_1+\frac{\psi_{0xx}}{\psi_0}-\epsilon\frac{\psi_1\psi_{0xx}-\psi_0\psi_{1xx}}{\psi_0^2}+\ldots$$ and so $$u_0(x,t)=\lambda_0+\frac{\psi_{0xx}}{\psi_0}$$ $$u_1(x,t)=\lambda_1-\frac{\psi_1\psi_{0xx}-\psi_0\psi_{1xx}}{\psi_0^2}$$ $$\vdots$$ Turning back to KdV equation for the leading order one has $$u_{0t}-6u_0u_{0x}+u_{0xxx}=0$$ and this is exactly the problem solved by inverse scattering method that we recover as it should. The next-to-leading order correction gives: $$u_{1t}+6(u_0u_{1x}+u_1u_{0x})+u_{1xxx}=u_0$$ that is a linear equation. We notice here that we are consistent with the condition $\psi_1\rightarrow 0$ when $|x|\rightarrow\infty$ provided this is true for $\psi_0$ and this grants also $u_1\rightarrow 0$ as it should. One can check at this point that this is equivalent on doing the same perturbation approach on the scattering problem for the inverse scattering method (see eq.(5) in the original paper by Miura et al.). 

There is a simple way to manage this equation using a Fourier series. We assume a boundary at $0$ and $L$ and that exists the Fourier series for the solution $$ u(x,t)=\sum_{n=-\infty}^{\infty}u_n(t)e^{i\frac{2\pi n}{L}x} $$ then you note that $$ D(t)=\int_{-L}^L u(s,t)ds=\int_{-L}^L\sum_{n=-\infty}^{\infty}u_n(t)e^{i\frac{2\pi n}{L}x}=2L u_0(t) $$ and you are left with the following set of ordinary equations $$ \partial_t u_n(t)=-4\pi^2n^2u_0(t)u_n(t). $$ This yields $\partial u_0(t)=0$ and so, $u_0=constant=D_0$ and so for $n\ne 0$, $$ u_n(t)=e^{-4\pi^2n^2D_0t}u_n(0). $$ 

The idea is to iterate on the integral equation starting with $z(s)=1$. This will give the integrals in a series $$ I_{n}=\int_{-\infty }^{\infty }ds_{1}\int_{-\infty }^{s_{1}}ds_{2}\cdots \int_{-\infty }^{s_{2n-1}}ds_{2n}\;\cos { (s_{1}^{2}-s_{2}^{2})}\;\cdots \cos {(s_{2n-1}^{2}-s_{2n}^{2})}. $$ The paper discussing them is this one. The general formula is $$ I_n=\frac{2}{n!}\left(\frac{\pi}{4}\right)^n $$ and you should take into account also powers of $\gamma$. These are the terms of the power series of the exponential multiplied by a factor 2. 

This problem is known in literature due to the Onsager's solution of the 2d Ising model. You can already find this on an old paper by Fisher and Ferdinand. Some more recent papers, available also from arxiv are the following: $URL$ $URL$ A paper just available with subscription is Partition function of a finite Ising model on a torus T Morita 1986 J. Phys. A: Math. Gen. 19 L1191. 

The equation $$h(\vec x)\cdot A(\vec x)=\sum_{i=1}^m A(\vec x - \vec e_i)$$ represents a general translation on the function $A(\vec x)$ and can be stated introducing the operator $$h(\vec x)=\exp\left(-\sum_{i=1}^m{\vec e_i}\partial_i\right)$$ so that $$\sum_{i=1}^m A(\vec x - \vec e_i)=\exp\left(-\sum_{i=1}^m{\vec e_i}\partial_i\right)A(\vec x).$$ You can always introduce a set of eigenvalues of the operators $-i\partial_i$ that we can call $p_i$. You have a bounded set and so what you will get is discrete set of eigenvalues $\{\vec p_n,n\in\mathbb{Z}\}$ and eigenfunctions $\{\phi_n^{(i)}(x_i),n\in\mathbb{Z}\land i\in[1\ldots m]\}$ for $\vec p$. Assuming you can expand $A(\vec x)$ using these eigenfunctions, you will get $$h(\vec x)\cdot A(\vec x)=\sum_{n\in\mathbb{Z}}e^{-i\sum_{l=1}^m{\vec p}_n\cdot ({\vec x}-{\vec e}_i) }\tilde A_n.$$ In this way, your problem is simply reduced to solving a set of algebraic equations involving the eigenvalues $\vec p_n$. Your equation states that a sum of translations on $A(\vec x)$ reduces to a multiplicative factor. I do not know if a general solution exists to this kind of problem. 

This is somewhat of a curiosity that can hide somewhat deeper. For a Green function of a nonlinear PDE I mean something like $$ \partial^2\phi+V(\phi)=\delta^D(x). $$ I do not know if a real meaning can be attached to something like this. But I can think to a gradient expansion. E.g., consider the nonlinear Klein-Gordon equation $$ \partial^2\phi+\lambda\phi^3=\delta^D(x). $$ We can rewrite this equation as $$ \partial_t^2\phi+\lambda\phi^3=\delta(t)\delta^{D-1}(x) + \epsilon\Delta\phi. $$ and to treat the Laplacian as a perturbation (for this aim I introduced an arbitrary $\epsilon$ that I will set to 1 at the end of computation). Then, I have a gradient expansion in term of powers $\epsilon$. This has for the leading order $$ \partial_t^2\phi_0+\lambda\phi_0=\delta^D(x) $$ and I know the exact solution to $\partial_t^2\phi'+\lambda\phi'=\delta(t)$. Can I attach a meaning to something like this from the exact solution of this latter equation maybe using Coulombeau functions? There is also a less singular approach. I just rescale time as $\tau=\sqrt{\lambda}t$ and I get $$ \lambda\partial_\tau^2\phi+\lambda\phi^3=\sqrt{\lambda}\delta(\tau)\delta^{D-1}(x) + \Delta\phi $$ that is $$ \partial_\tau^2\phi+\phi^3=\frac{1}{\sqrt{\lambda}}\delta(\tau)\delta^{D-1}(x) + \frac{1}{\lambda}\Delta\phi. $$ This is again a gradient expansion in powers of $\frac{1}{\sqrt{\lambda}}$ but the leading order has the form $$ \partial_\tau^2\phi_0+\phi_0^3=0 $$ that has a known exact solution. Next-to-leading order is no more singular giving a linear equation. This is more than an exercise as can have some applications in physics. But what I am really interested to is if all this can have a mathematical meaning. Thanks. 

The most direct way to get a small time expansion is using a gradient expansion. This can be worked out in the following way. Rescale your time variable as $t\rightarrow\lambda t$ being $\lambda$ a parameter taken to be arbitrary large and introduced to fix expansion order. Then, takes $\phi$ proportional to $\lambda$. You will get $$\lambda u_\tau=\alpha(x,\frac{\tau}{\lambda},u)u_{xx}+\beta(x,\frac{\tau}{\lambda},u)(u_x)^2+\gamma(x,\frac{\tau}{\lambda},u)u_x+\lambda\phi(x,\frac{\tau}{\lambda},u).$$ Then, expand $u$ as $$u(x,\tau)=\sum_{n=0}^\infty\frac{1}{\lambda^n}u_n(x,\tau).$$ At the end of the computation just put $\lambda=1$. Your solution will be given as polynomials in $t$. Now, let us consider your equation $$tu_t=Tr[\frac{u}{2}AD(\frac{x}{u})\otimes D(\frac{x}{u})]-t^2Tr[\frac{u^3}{8}ADu\otimes Du]+t&lt;\alpha,Du>$$ $$+t Tr[\frac{1}{2}AD^2u]-\frac{u}{2}.$$ We firstly note that $D(\frac{x}{u})=\frac{e_x}{u}-x\frac{Du}{u^2}$ and so we can write down this equation in the form $$tu_t=\frac{1}{2u}[A_{xx}+x^2Tr[A Du\otimes Du]]-t^2Tr[\frac{u^3}{8}ADu\otimes Du]+t<\alpha,Du>$$ $$+t Tr[\frac{1}{2}AD^2u]-\frac{u}{2}.$$ I hope I have interpreted correctly your notation. Now, multiply by $u$ both sides and you will get $$tuu_t=\frac{1}{2}[A_{xx}+x^2Tr[A Du\otimes Du]]-t^2uTr[\frac{u^3}{8}ADu\otimes Du]+t<\alpha,Du>$$ $$+t uTr[\frac{1}{2}AD^2u]-\frac{u^2}{2}.$$ Now, change the variable as $\tau=\lambda t$. You will get the new equation $$\tau uu_\tau=\frac{1}{2}[A_{xx}+x^2Tr[A Du\otimes Du]]-\frac{1}{\lambda^2}\tau^2uTr[\frac{u^3}{8}ADu\otimes Du]+\frac{1}{\lambda}\tau <\alpha,Du>$$ $$+\frac{1}{\lambda}\tau uTr[\frac{1}{2}AD^2u]-\frac{u^2}{2}.$$ From this you can read off immediately the leading order being $$\tau u_0u_{0\tau}=\frac{1}{2}[A_{xx}+x^2Tr[A Du_0\otimes Du_0]]-\frac{u_0^2}{2}.$$ This is a Hamilton-Jacobi equation that can be solved by the characteristic method. Higher orders can be obtained straightforwardly as an expansion in $\frac{1}{\lambda}$. We can spend a few words about the next-to-leading order by substituting into the scaled equation $$u=u_0+\frac{1}{\lambda}u_1+O\left(\frac{1}{\lambda^2}\right)$$ Then, the equation becomes $$\tau (u_0+\frac{1}{\lambda}u_1)(u_{0\tau}+\frac{1}{\lambda}u_{1\tau})=\frac{1}{2}[A_{xx}+x^2Tr[A D(u_0+\frac{1}{\lambda}u_1)\otimes D(u_0+\frac{1}{\lambda}u_1)]]-$$ $$\frac{1}{\lambda^2}\tau^2(u_0+\frac{1}{\lambda}u_1)Tr[\frac{(u_0+\frac{1}{\lambda}u_1)^3}{8}AD(u_0+\frac{1}{\lambda}u_1)\otimes D(u_0+\frac{1}{\lambda}u_1)]$$ $$+\frac{1}{\lambda}\tau <\alpha,D(u_0+\frac{1}{\lambda}u_1)>$$ $$+\frac{1}{\lambda}\tau (u_0+\frac{1}{\lambda}u_1)Tr[\frac{1}{2}AD^2(u_0+\frac{1}{\lambda}u_1)]-\frac{1}{2}\left(u_0+\frac{1}{\lambda}u_1\right)^2+O\left(\frac{1}{\lambda^2}\right).$$ So, the equation to compute $u_1$ is $$\tau (u_0u_{1\tau}+u_1u_{0\tau})=x^2Tr[A Du_0\otimes Du_1]$$ $$-\tau <\alpha,Du_0>+\tau u_0Tr[\frac{1}{2}AD^2u_0]-u_0u_1.$$ One can repeat this procedure at any order and, finally, gets the solution into the form given at the beginning of this post. 

There is a fundamental reference using Bessel functions in Fourier's works. This is "Théorie analytique de la chaleur" firstly published on 1822. You will find this series firstly given in chapter VI pag. 370. This chapter is about the propagation of the heat in a cylinder ("of course" let me add). The modern nomenclature was invented by Bessel himself on 1824, just two years after Fourier's work. This is proved in F. Bessel, "Untersuchung des Theils der planetarischen Störungen", Berlin Abhandlungen (1824). Here the functions I and J get their names. 

In this case $\Phi(x,t)$ is itself a stochastic process and this equation should be rewritten in a proper way. There is some literature as this and a more general theory of stochastic pde due to John Walsh (a tutorial can be found here). In this case, a general solution can be written down using the fundamental solution of the heat equation given by $$\Delta(x,t)=\frac{1}{\sqrt{4\pi k^2 t}}e^{-\frac{x^2}{4k^2 t}}$$ and then one has $$\Phi(x,t)=\int dx'\Phi_0(x')\Delta(x-x',t)+k^2\int dt'[\nu(t')+C]\Delta(x,t-t')$$ and we can easily compute $$\langle\Phi(x,t)\rangle = \int dx'\Phi_0(x')\Delta(x-x',t)+k^2C\int dt'\Delta(x,t-t')$$ $$\langle\Phi(x,t)\Phi(y,s)\rangle=\int dx'\Phi_0(x')\Delta(x-x',t)\int dy'\Phi_0(y')\Delta(y-y',s)+$$ $$k^2C\int dx'\Phi_0(x')\Delta(x-x',t)\int ds'\Delta(y,s-s')+$$ $$k^2C\int dt'\Delta(x,t-t')\int dy'\Phi_0(y')\Delta(y-y',s)+$$ $$k^4C^2\int dt'\Delta(x,t-t')\int ds'\Delta(x,s-s')+k^4\sigma^2_0\int dt'\Delta(x,t-t')\Delta(y,s-t')$$ where I used the fact that $\langle\nu(s)\nu(t)\rangle=\sigma^2_0\delta(t-s)$. It is interesting to note the simplest case $\Phi_0=0$ and $C=0$ producing immediately $$\langle\Phi(x,t)\rangle = 0$$ and $$\langle\Phi(x,t)\Phi(y,s)\rangle=k^4\sigma^2_0\int dt'\Delta(x,t-t')\Delta(y,s-t').$$ So, all higher order even correlation functions are given by products of the fundamental solution of the heat equation properly integrate in intermediate times. 

This problem can be approached by a series in $KR$ and assuming for $g$ a Gaussian distribution. So, we have to manage $$ 1=K\int_{-\frac{\pi}{2}}^{\frac{\pi}{2}}\cos^2\theta\frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{K^2R^2\sin^2\theta}{2\sigma^2}}d\theta. $$ The limit $R\rightarrow 0^+$ can be taken under the integrale but we prefer a series in $KR$ that yields $$ 1=K\frac{1}{\sqrt{2\pi}\sigma}\left(\frac{\pi}{2}-\frac{\pi}{2^4 \sigma ^2} K^2 R^2+\frac{\pi}{2^7 \sigma ^4}K^4 R^4+O(K^6R^6)\right). $$ The required limit provides $$ K=\sqrt{\frac{8}{\pi}}\sigma $$ 

The technique to solve this problem, as suggested by the formulation of the question, is perturbation theory. One writes the solution in the form $$ u(x,t)=\epsilon u_1(x,t)+ \epsilon^2 u_2(x,t)+\epsilon^3 u_3(x,t)+\ldots = \sum_{n=1}^\infty \epsilon^n u_n(x,t) $$ and put this into the equation and the initial and boundary conditions. In this case one gets the set of non-trivial equations $$ u_{1tt}=u_{1xx}+u_{1xxt} $$ with $u_1(0,t)=u_1(1,t)=0$, $u_1(x,0)=f(x)$ and $u_{1t}(x,0)=g(x)$. This equation is linear and can be solved with standard techniques. Then, at second order one has $$ u_{2tt}=u_{2xx}+u_{2xxt} $$ with $u_2(0,t)=u_2(1,t)=0$, $u_2(x,0)=f(x)$ and $u_{2t}(x,0)=g(x)$ and so, $u_2=0$ the trivial solution. At the third order one has a non-trivial equation $$ u_{3tt}=u_{3xx}+u_{3xxt}+(u_{1x}^3)_x $$ that has a non-null solution and the solution can be given using the Green function of the linear equation. From this, you can iterate to whatever order you want. 

There is no direct link in the way you write it down. In order to decompose the wave equation you will need a Clifford algebra of matrices $\gamma$, such that $\gamma_i\gamma_j + \gamma_j\gamma_i = 2\eta_{ij}$, and define the operator $D=i\gamma_k\partial^k$. Then you will have $D^2=\partial_{tt}-\Delta$. But note that this operator will not apply on ordinary scalar functions but on spinors. Finally, when you consider the "massive" operator $D-I$, you are able to recover in some limit the Schroedinger equation. 

This function is quite interesting as it reaches a maximum in 0. This can be seen without difficulty computing the first and second derivatives. It is $$B(a,r)=\frac{K_2(ar)I_2(a)-I_2(ar)K_2(a)}{I_2(a)}I_2(ar)$$ that gives $$B(0,r)=\frac{1}{4}(1-r^4)>0$$ $$B'(0,r)=0$$ $$B''(0,r)=-\frac{1}{12}r^2(1-r^2)^2<0$$ for the given interval. This means that this function is decreasing for $a>0$. The problem is if there are some other points where the first derivative can become zero changing the concavity of the curve. So, the first derivative has the following involved expression $$B'(a,r)=\frac{1}{2 I^2_2(a)}\left[I_2(ar)^2 (I_1(a)+I_3(a)) K_2(a)+\right.$$ $$I_2(a) I_2(ar) (-2 r (I_1(ar)+I_3(ar)) K_2(a)+$$ $$I_2(ar) (K_1(a)+K_3(a))+r I_2^2(a) ((I_1(ar)+I_3(ar)) K_2(ar)$$ $$\left.-I_2(ar) (K_1(ar)+K_3(ar)))\right]$$ Now we notice that $I_2$ is a monotonic increasing function that never becomes zero and $K_2$ is a monotonic decreasing function that never becomes zero for the given intervals and similarly is true for $I_1,\ I_3$ and $K_1,\ K_3$. All these functions are positive. So, it is not difficult to realize that the first derivative is a monotonic function and never hits zero again being just a balance of functions never reaching zero unless $a=0$ and having monotonic behavior, $K_i$ are decreasing functions and $I_i$ increasing functions. We also note that $$\lim_{a\rightarrow\infty}B'(a,r)=0$$ that can be proved using the asymptotic formula for these Bessel functions. Now, combining monotonicity and positivity of these Bessel functions, starting from 0 and reaching asymptotically 0 at increasing values of the argument, they can just reach an extremum and never cross zero again. This can also be seen with a simple plot Free Image Hosting At site $URL$ evaluated at $r=0.1,0.3,0.5,0.7,0.9$.