Yes, you can view this equation as a family of curves (cyclic covers of $\mathbb{P}^{1}$) , as you said we can move each three points to $0,1,\infty$ and hence your family in fact reduces to a point in the moduli space of curves (or $A_{g}$). Your curve will have genus $1$ and is smooth so is an elliptic curve. You can find alot about cyclic covers of $\mathbb{P}^{1}$ in the book "cyclic coverings, calabi-Yau manifolds and complex multiplication" by J.C.Rohde. The main stream of this book as the name suggests is something else, but the generalities on cyclic covers is treated quite nicely here. 

I think I just found my answer. The Jacobians in the family are equipped with an action of the group ring $\mathbb{Z}[\xi_{m}]$. So the action on $V_{\mathbb{Q}}$ is that of the group ring $\mathbb{Q}[\xi_{m}]=\prod_{d|m} K_{d}$. So it is a module over this group ring and not just a vector space. 

As was indicated above your question is the equivalent to the branching rules for $sl_{n-1} \to sl_n$. This is a well-known branching rule and it is given by the following formula: If the representation of $sl_n$ is given by the highest weight $(\lambda_1 \geq \cdots \geq\lambda_n)$ then it decomposes upon restricting to $sl_{n-1}$ to the direct sum of irreducible representations with highest weights $(\lambda^{\prime}_1 \geq \cdots \geq\lambda^{\prime}_{n-1})$ satisfying $\lambda_{i+1} \leq \lambda^{\prime}_i\leq \lambda_{i}$. This is equivalent to removing some boxes from the corresponding Young diagramm. 

Let $S$ be a Shimura surface i.e. a Shimura variety with $dimS=2$. Does $S$ necessarily contain a Shimura curve? I know that probably the answer is No, but do not have an explicit example. What is the best example of such a surface? 

Unless the morhism $f$ is etale, this exact sequence is not true in general. The problem is this: the differantial $df$ can be viewed as an injection $f^{*}K_{Y}\to \Omega^{1}_{X}$. One defines $\Omega^{1}_{X/Y}$ to be the cokernel of this injection, so that we have an exact sequence: $0\to f^{*}K_{Y}\to \Omega^{1}_{X} \to \Omega^{1}_{X/Y}\to 0$. So far is true, but when you dualize, you do not get the exact sequence $0\to T_{X/Y}\to T_{X}\to f^{*}T_{Y}\to 0$. Because $T_{X}\to f^{*}T_{Y}$ is not surjective in general. There is an $Ext^{1}$ which comes in after dualizing which is the cokernel of this non-surjective map. So as Piotr pointed out, there will only exist an exact sequence $0\to T_{X/Y}\to T_{X}\to f^{*}T_{Y}$. 

Let $\pi :C\rightarrow \mathbb{P}^{1}$ be a cyclic cover of degree $m$ of $\mathbb{P}^{1}$. So $C$ has an action of $\mathbb{Z}/m\mathbb{Z}$. Let $\xi$ be a primitive $m$-th root of unity. Consider the cohomology group $V_{\mathbb{Q}}=H^{1}(C,\mathbb{Q})$. In the book "Cylic covers, Calabi-Yau manifolds and complex multiplication" (by Jan Christian Rohde) page 80, we read: "In general there is no $\mathbb{Q}(\xi)$-structure on $H^{1}(C,\mathbb{Q})$ which turnes $H^{1}(C,\mathbb{Q})$ into a $\mathbb{Q}(\xi)$-vector space " and then he gives a direct sum decomposition with different $\mathbb{Q}(\xi^{r})$-structures. But in many books and articles on this subject it is just claimed that $V_{\mathbb{Q}}$ has an induced action of $\mathbb{Q}(\xi)$(Like: de Jong and Noot : "Jacobians with complex multiplication"). Which one is true? However, my second question is: even if there is an action of $\mathbb{Q}(\xi)$, I think we then must have two different $\mathbb{Q}$-vector space structures on $V_{\mathbb{Q}}$. The first one is the usual one and one coming from $\mathbb{Q}\hookrightarrow \mathbb{Q}(\xi)$. Since if $dim_{\mathbb{Q}}V_{\mathbb{Q}}=g$, then by the induced action from $\mathbb{Q}\hookrightarrow \mathbb{Q}(\xi)$, it's dimension should be $dim_{\mathbb{Q}}V_{\mathbb{Q}}=m dimV_{\mathbb{Q}(\xi)}$ ($V_{\mathbb{Q}(\xi)}$ means $V_{\mathbb{Q}}$ as a $\mathbb{Q}(\xi)$-vector space ). But this two in general do not agree ($2g=g (C)$ and in general is not even divisible by $m$). So the $\mathbb{Q}$-structures should be different. Is this true? Can one give a good explanation of this? 

The problem: We have a $n$-state Markov chain with arbitrary initial distribution and transition matrix $P$ that is arbitrary except that we know that $P$ has trace $n-1$. Of course $P$ is also a stochastic matrix. Let $b(n,k)$ denote the suprememum, over all such matrices $P$ and initial distributions, of the total variation distance between the distribution of this chain after $k$ and $k+1$ time steps. I am primarily interested in bounds for fixed $n$ as $k$ goes to infinity. In the remaining description of partial results I will therefore focus on the following question: what is the largest $\alpha \ge 0$ such that $b(n,k)=O(k^{-\alpha})$, where big-oh hides a function of $n$. For fixed $n$ all matrix norms are equivalent, so it suffices to bound some matrix norm of $P^{k+1} - P^k$ by $O(k^{-\alpha})$. In particular using the vector $\ell_p$ norm $|\cdot|_p$ and its induced matrix norm $||\cdot||_p$ it suffices to bound $|(P^{p+1}-P^k)v|_p$ for all vectors $v$ with $|v|_p \le 1$. I'm using terminology primarily from Horn and Johnson's Matrix Analysis book. Partial results and discussion: One can use Markov chain couplings to show that $||P^{k+1}-P^k||_1=O(1/\sqrt{k})$. (See Lemma 10 in $URL$ .) All eigenvalues of a stochastic matrix are at most 1 in absolute value and the trace of a matrix is equal to the sum of eigenvalues, so we conclude that all eigenvalues of $P$ have real part between 0 and 1. Consider the special case of $P$ symmetric. Then $P$ is symmetric then it is orthogonally diagonalizable with real eigenvalues. For any $0 \le \lambda \le 1$ it is easy to show that $|\lambda^{k+1} - \lambda^k| = O(1/k)$, so therefore for symmetric $P$ we have $||(P^{p+1}-P^k)||_2 = O(1/k)$. Consider the special case of circulant matrices, i.e. matrices $P$ where $P_{ij}$ is a function of $i - j \mod n$. The trace restriction implies that the diagonal entries of $P$ are $(n-1)/n$. By Gersgorin disks it follows that all eigenvalues are within $1/n$ of $1-1/n$ in the complex plane. If my calculations are right the maximum over that circle of $|\lambda^{k+1}-\lambda^k|$ is $\Theta(1/\sqrt{nk})$ for $k >> n$. Finally the eigenvectors for circulant matrices are orthogonal, so we conclude that $||(P^{p+1}-P^k)||_2 = \Theta(1/\sqrt{nk})$. It turns out that circulant matrices are diagonalized by discrete Fourier transform matrices, i.e eigenvector $v_i$ satisfies $(v_i)_j = \omega^{ij}$ where $\omega=e^{2 \pi i / n}$ is a root of unity. This allows us to sharpen the above bounds a bit. One can show that any eigenvalue of $P$ is of the form $1 - 1/n + (1/n)*\sum_i \alpha_i \omega^i$ where $\sum_i \alpha_i = 1$, $\alpha_i \ge 0$ (convex combination), and $\alpha_0 = 1 - 1/n$. For $k >> n$ one can show that $|\lambda^{k+1}-\lambda^k|$ is $O(n/k)$ for any $\lambda$ of this form. Given the above results I have a strong suspicion that for general stochastic $P$ with trace $n-1$ we have $||P^{k+1}-P^{k}|| = O(1/k)$. Of course you might say that a better conjecture would be limited to matrices $P$ that are unitarily diagonalizable (a.k.a. normal), but I haven't found examples where non-normality makes things worse so I'm conjecturing $O(1/k)$ holds for non-normal matrices as well. One simple example of a non-normal matrix $P$ with $||P^{k+1}-P^k||=\Theta(1/k)$ is $P=\left(\begin{array}{cc}1 - \epsilon & 0 \\ \epsilon & 1\end{array}\right)$. (This has trace strictly greater than $n-1$, but that's fine as the trace can be corrected be extended by adding two dummy states without significantly changing the problem.) Extending the above eigenvalue-based proofs to the general case runs into a huge roadblock: eigenvectors are not in general orthogonal. This is a problem because the initial distribution vector may in general have unboundedly large coefficients when translated into the eigenvector basis. The mixing time of these Markov chains can be unbounded, so techniques for bounding the mixing time are not obviously helpful. Edit: the following example shows that the eigenvectors can have an arbitrarily small angle. $$P=\left(\begin{array}{ccc}1-\epsilon & 0 & 0 \\ \epsilon & 1-\delta & 0 \\ 0 & \delta & 1\end{array}\right)$$ Its (right) eigenvectors are $(\delta-\epsilon,\epsilon,-\delta)^T$ , $(0,1,-1)^T$ and $(0,0,1)^T$. As $\delta$ approaches $\epsilon$ the first and second eigenvectors become arbitrarily close to parallel.