I'm assuming you mean block access for incoming users and not for YOUR users connecting to the site(external)? If the former: Look into apache mod_rewrite. That'll do what you want. If you're not using apache, you may need to consult with someone else. If the latter: Look into setting up a proxy server. It'll depend on what OS you're using. 

Without getting into too much detail, why not off-set that common IP to a load-balancer and then put your work-horses behind it? That'll help you scale a bit without losing that traffic. Let me know if you need more explanation. Edit: If your clients are always typing in that IP from memory, there won't be a lot you can do to switch them to a domain. As I mentioned, your best bet will to be to incorporate that IP into a load-balancer. Should be the 'easiest' way. 

For the hosting side, I'd recommend Linode or a micro EC2 instance(free tier). Wordpress can handle multiple sites with some plugins. That's probably the easiest one to setup. It's not ideal for static content, but it'll do the trick. 

We have a bunch of existing servers in EC2. Future servers are created with Cloudformation with Cloudwatch integration. However, I need to setup Cloudwatch for servers that weren't created with Cloudformation. I have been asked to create a Cloudwatch Cloudformation stack. Is it possible to just create alarms in Cloudformation? If so, how do I specify which servers to monitor? Thanks! 

You didn't specify your ssh key by the looks of it so it's assuming you want to use a password. Most AMIs are configured to NOT allow ssh access for root with a password. Fix your parameters to ensure the key is being specified. 

Restore test database from a backup in physical SQL Server environment Connect to database locally Run Script - this step takes less than 1 second 

The best solution I've found so far is to remove the existing backup destination (so that the new backup won't overwrite it) and create a new one in a new file, then create a differential backup to that new file with the "back up to a new media set" option selected. But I currently don't understand this solution or even know if it works for sure (I haven't done a lot of backing up and restoring lately). How does it know what the base backup looks like if I've removed that file from the destination set? I'm starting to think the best way to delete all my differential backups might actually be to skip all that and just restore to my base backup, then re-backup overwriting all existing backup sets. This method doesn't let me pick and choose which differential backups to delete, but at least I can understand what's going on and rely on it. 

I often like to create backups when testing the software I work on, and will sometimes create a differential backup if I want to be able to get back to multiple previous states. However, sometimes I realize that I forgot one thing I wanted to include in a differential backup, or I no longer need a previous differential backup. Sometimes I simply want to create a new scenario from the original base image and start working with a new series of differential backups. So I'd like to be able to delete some older differential backups so I don't get confused about which ones I'm using. But I can't find any way to delete just the differential backups, selectively or all at once. 

The cluster gives you a little more power and some redundancy(if it's feasible for your software). The big 'workstation' has the advantage of being simpler to deploy and won't be bottlenecked by your switch. I can't say for certain if the switch will bottleneck since it will depend on your transfer sizes, etc. 

I think you're going about this the wrong way. Look into tuning Apache first of all. Then, research Linux memory management. You WANT your server using the ram, otherwise why do you have it? 

I've setup IPSEC tunnels between 3 management VPCs in 3 distinct AWS regions. Each of those regions has additional VPCs (dev/prod) that are peered to the management VPCs. It's setup in a hub/spoke like this: 

I'd 'personally' recommend Debian i386. Its relatively simple to setup and has a great track record. Ubuntu is nice, but not ideal if you don't know how to tweak out some of the cruff that comes pre-installed. Once again, this is just my personal opinion. Edit: If you're willing to spend any money, you may want to check out a Micro EC2 instance from Amazon(aws.amazon.com) or a 512 Linode from linode.com. I've used both for dev work and they're both cheap options. 

I've seen this done before. It's only as insecure as your network/destination servers make it. Only you know that. Are you transmitting these over a secure network? If so, you SHOULD be fine. But we can't possibly guarantee that. Why not write a simple ssh script to distribute them? That's what I would recommend. Or write a script to download the cert from a central server and distribute the script via puppet. Just an idea. EDIT: Since there is some confusion. I'm NOT saying Puppet/SSH are anymore secure. But if you're worried about unauthorized access, ensure everything is secure. This is most easily done with a custom SSH script YOU distribute. 

I have run tests on a virtual system with Windows 2003 32-bit and SQL 2005 32-bit and on and a virtual system with Windows 2008 64-bit and SQL 2008 64-bit. I have run tests on a physical system with Windows 2003 and SQL 2005 and on a physical system with Windows 7 64-bit and SQL 2008 R2 64-bit. All the virtual systems I have tried exhibit this slowness and are hosted on the new ESXi environment. All the physical systems do not exhibit this slowness. Can anyone help me understand what's going on here? I fear that similar performance issues are affecting other areas and we should reconfigure something on the host or guest environments. The only thing we can think of so far is turning off hyperthreading in the BIOS of the host machine to match the configuration of another virtual environment and its host where we were not able to see the slow behavior (I didn't observe the test on the other virtual environment&host where it wasn't slow). Could that create such a large performance difference? Edit: After some review of my question and the first answer, I agree that what I managed to demonstrate is probably a difference in performance of I/O latency between our physical and virtual environments. I also realize that I should have provided some other details: these images are using thin provisioning and have two or three snapshots under them. Could this affect that statistic so significantly? The question now becomes, is it normal for this statistic to be so drastically different between virtual environments and physical environments? Should I be able to optimize that in the environment or in the SQL configuration, or is it up to the software itself to be written more optimally for virtual systems with extreme I/O latency? vSphere client reports that the write latency on the virtual disk is 11 to 40 ms with an average of 21 ms. Is that a useful statistic? Is that extreme? Edit: It appears that our hardware (DL380 G6) has performance problems as described at $URL$ and we just need to do some reconfiguration to get the performance up. I'll accept the answer that led us in the right direction of seeing that disk I/O latency was the issue. 

Why not run that same command again with the proper permissions then apply your desired permissions to sites/default? 

Check out webmin It should allow you to do a lot of this. There are some great guides on configuring it. 

You've really over complicated your configs. First of all. Look into $URL$ Then, trim down those files to the bare minimum. Make sure to activate the sites and ensure the directories exist. That should do the trick. Also, don't forget to reload apache after all of that. 

I wouldn't recommend it. There ARE still methods of cracking these quite easily. I personally recommend a Truecrypt volume that contains a Keepass database. It servers me well and is extremely portable. And I'm using it in an environment with thousands of passwords. EDIT: And Keepass is already well laid out for password management. With a nice GUI(i.e., easy to see what password is which type) and built-in password generators...can't go wrong. 

I'd like to simulate 1000 concurrent downloads of a single file from Cloudfront. I figured I'd setup ~10-20 xlarge EC2 instances for this. Is there an obvious way I'm missing to trigger this at the same time and get the average download time while ensuring the instances aren't the bottle-neck. We REALLY need to know how much outbound bandwidth we can sustain from Cloudfront. Thanks! 

There is DEFINITELY going to be some consequences of doing this. The primary one is going to be IO read/writes. Beyond that, it's just a very scary way of dealing with that type of data(at that scale). 

I have approximately 30 users on a box. Those users are in overlapping groups(about 6-10 groups). I need them to be able to land in a specific folder based on their group assignment when they FTP in. I.e., group1 -> /tmp/site1 group2 -> /tmp/site2 Is this at all possible with VSFTP on a SuSE box? Using SFTP isn't an option unfortunately. Thanks! EDIT: And in the event of a user being in several groups, just dumping them to the highest-level folder necessary to view the various folders they have access to. 

A VLAN is a layer 2 construct - generally an Ethernet broadcast domain mapped onto a set of ports on one or more switches. An IP subnet is a layer 3 construct and is a collection of hosts within a common address grouping with local reachability. An IP subnet can run on a VLAN, but it can also run on a wide variety of other media. It is possible for two or more IP subnets to run concurrently on a single VLAN as long as the subnets do not overlap. This often occurs in environments migrating from one addressing scheme to another or when port space / VLAN capacity are limited. Typically the mechanism in use is secondary IP addressing for one or more hosts - usually a router. A secondary address is equivalent to an IP alias and is essentially just a single network interface with addresses in multiple subnets. 

There's nothing -inherently- wrong with a large broadcast domain if it's appropriately (and safely) configured. Employing PVLAN's, for example, can allow for very large networks without too much drama as isolated hosts don't see traffic from one another. Similarly if the network is relatively static, the links very stable and controls are in place to block broadcast/multicast/unicast flooding then it can be made to work. That said, more often than not the sort of networks you're describing (2000+ hosts) are basically a crisis waiting to happen. Some of the issues/warning signs might include- Excessive broadcast traffic - Either app traffic being blasted everywhere (i.e. like old school Windows), excessive ARP traffic, etc. Think of this in terms of packets per second moreso than absolute bandwidth - hundreds of packets per second of background traffic is getting up there. Bear in mind that certain network events (switches coming up or down) may exacerbate this terribly. Network diameter / topological stability - Do transitory spanning tree loops occur under certain conditions (i.e. device reboot)? What volume of TCN's and so forth are you seeing? Is the root bridge moving around at all? Physically how many switches are cascaded together? How do link failures work? If a link drops, what happens? I've seen situations where things were badly broken to the point where the network topology would literally never stabilize when a redundant link came down. It required mass reboots - well, more properly, it required a complete redesign, but that's a separate issue. Interface drops on routers and switches? Buffer issues? These can also be hints. In general bridges that cross physical sites cause a disproportionate amount of trouble. Is there a compelling reason why your sites (or floors) couldn't be broken up into routed subnets? Best practice is certainly to route were possible and bridge where not... 

I have found that if I follow the following procedure in one of these virtual environments, running the script takes 9-12 seconds: Test Case #1 

Restore test database from a backup in virtual SQL Server environment Connect to database locally Add "BEGIN TRAN" at the beginning of the script Add "ROLLBACK TRAN" at the end of the script Run script - this step takes less than 1 second Execute only the portion of the script that does not include the transaction - this step takes 9 seconds. 

We recently set up a new machine with 8 dual-core CPUs, 20 GB RAM, and 3 1-TB drives set up in a RAID of some sort resulting in 2 1-TB drives we actually get to use (I'm not the hardware guy here). It is set up as an ESXi host and we have a number of test environments set up within it. The current tests are running on Windows 2003 64-bit with SQL Server 2005 Standard 64-bit SP3. From all reports, this system should host environments that perform better than our previous setup, and yet certain tasks are performing much worse. I have found one specific SQL script that reliably runs very slowly under certain conditions, which I can't understand. The SQL script is a simple series of 1700+ UPDATE statements that starts out like this: 

What I find interesting is that it still runs slowly even after I execute it in transaction once and roll it back Test Case #4 

Restore test database from a backup in virtual SQL Server environment Connect to database locally Add "BEGIN TRAN" at the beginning of the script Add "COMMIT TRAN" at the end of the script Run script - this step takes less than 1 second