In a footnote to the list of known Mersenne prime numbers which can be found here, we read that the "ranking" therein is a provisional one since not all possible exponents between $37 \, 156 \, 667$ and $77 \, 232 \, 917$ have been eliminated/tested. If we may infer from this that the individual(s) who recently found the largest known prime number had not previously discarded (quite understandably!) the possible compositeness of the $\pi(77 \, 232 \, 917)-\pi(74 \, 207 \, 281) - 1 \approx 166 \, 801$ members of the set $$\{M_{p} \colon p \in (74 \, 207 \, 281, 77 \, 232 \, 917), p \mbox{ is a prime number}\},$$ do we know what it was that prompted them to try their hand at establishing the primality of the very specific Mersenne number $M_{77 \, 232 \, 917}$ ? Clearly enough, an analogous question can be formulated regarding the discovery of the 46th, 47th, 48th, and 49th known Mersenne prime numbers. If you know the answer to any of those allied questions, do not hesitate to enter it below (it might shed light on the case of the 50th known Mersenne prime). Thanks in advance for your knowledgeable replies. 

Curiously enough, the Wikipedia article adscribes the first complete proof of the theorem to Pietro Abbati Marescotti. 

Hello, Is anyone here aware of a well-motivated exposition of the Bourgain-Glibichuk-Konyagin estimate for exponential sums (or Gauss sums) over multiplicative subgroups? If any of you has a write-up on the subject, I would be more than glad to have an opportunity to take a look at it. Thank you very much! 

Well, I think you have to accept that concentration compactness is concept rather than a result. The intro of the mentioned book starts with 

If you accept that there is no theorem that captures the concept and don't want a whole book, you should read the explanation on concentration compactness here (longer than a theorem, but shorter than a book). A theorem that may come close to what you want is Theorem 3.1 (page 62) of said book. The basic notion of space is "dislocation space" which is a Hilbert space together with a set of bounded linear operators with certain properties… 

I think monotone operators qualify for question 1: A mapping $T:X\to X^*$ from a Banach space to its dual is said to be monotone, if for all $u,v\in X$ it holds that $$ \langle Tu - Tv, u-v\rangle\geq 0.$$ This generalizes to relations from $X$ to $X^*$ (i.e. subsets of $X\times X^*$): $G\subset X\times X^*$ is said to be monotone of for all $(x,u),(y,v)\in G$ it holds that $$ \langle x-y,u-v\rangle \geq 0.$$ Relations (or multifunction) like this appear, e.g., as subgradients of convex functions on Banach spaces. If $f: X\to ]-\infty,\infty]$ is convex, its subgradient $$ \partial f(x) = \{x^*\in X^*\ :\ \forall y:\ f(y)\geq f(x) + \langle x^*,y-x\rangle\} $$ can be viewed either a set-valued mapping $\partial f: X \to 2^{X^*}$ or as a multifunction $\partial f:X\rightrightarrows X^*$ or, by identifying it with its graph $\mathrm{gph}(\partial f) = \{(x^*,x)\in X\times X^*\ : x^*\in\partial f(x)\}$, as subset of $X\times X^*$ (indeed, a monotone one). 

Last but not least, in several works of old (z.B., Perron's Die Lehre von den Kettenbrüchen, Knopp's Theory and Application of Infinite series, Khinchin's Continued Fractions), there appears the following notation for general continued fractions: $\underset{j=1}{\overset{\infty}{\LARGE\mathrm K}}\frac{a_j}{b_j}=\cfrac{a_1}{b_1+\cfrac{a_2}{b_2+\cfrac{a_3}{b_3+\ddots}}}.$ Guess what the $\mathrm{K}$ stands for... References [1] Lion Hunting & Other Mathematical Pursuits: A Collection of Mathematics, Verse and Stories by Ralph P. Boas Jr. 

There are only three terms of the Fibonacci sequence which are equal to a factorial: $$F_{1}= F_{2} = 0!=1! \quad \mbox{and} \quad F_{3}=2!$$ What is more, F. Luca proved in this paper (published in 1999) that the only nontrivial solutions of the diophantine equation $$F_{n} = m_{1}! \cdots m_{t}!$$ are $F_{3}=2!$, $F_{6}=(2!)^{3}$, and $F_{12} = (2!)^{2}(3!)^{2} = 3! 4!$. 

I consider that the following lines of Hardy might help the OP to form a definite idea as to the accuracy of such an asseveration: "... I must deal with a misconception. It is sometimes suggested that pure mathematicians glory in the uselessness of their work*, and make it a boast that it has no practical applications. The imputation is usually based on an incautious saying attributed to Gauss, to the effect that, if mathematics is the queen of the sciences, then the theory of numbers is, because of its supreme uselessness, the queen of mathematics—I have never been able to find an exact quotation. I am sure that Gauss’s saying (if indeed it be his) has been rather crudely misinterpreted. If the theory of numbers could be employed for any practical and obviously honourable purpose, if it could be turned directly to the furtherance of human happiness or the relief of human suffering, as physiology and even chemistry can, then surely neither Gauss nor any other mathematician would have been so foolish as to decry or regret such applications. But science works for evil as well as for good (and particularly, of course, in time of war); and both Gauss and less mathematicians may be justified in rejoicing that there is one science at any rate, and that their own, whose very remoteness from ordinary human activities should keep it gentle and clean. *I have been accused of taking this view myself. I once said that ‘a science is said to be useful if its development tends to accentuate the existing inequalities in the distribution of wealth, or more directly promotes the destruction of human life’, and this sentence, written in 1915, has been quoted (for or against me) several times. It was of course a conscious rhetorical flourish, though one perhaps excusable at the time when it was written. " P.S. a) The emphasis is mine. b) The excerpt comes from the last paragraph of section 21 of Hardy's Apology. 

Regarding your question below the answer of Tapio Rajala: Testing feasibility of $\rho$ simply amounts to checking that $$\mu_1(A) = \rho(A\times Y),\qquad\text{and}\qquad \mu_2(B) = \rho(X\times B)$$ but probably your problem is, that you have to do this for all sets $A$ and $B$. Alternatively, you could check the integrals (3) and (4) for all continuous functions. In the finite dimensional case your "measure space" has atoms, i.e. your sets $A$ and $B$ (sorry for the overload) have subsets with minimal mass (i.e. that one-element subsets) and hence, you can show what you want for the atoms and that's it. In the infinite dimensional case you need to work with all subsets since there are in general no atoms on which you can build. I think it should work if you check the measures for enough simple sets as all rectangles (which is a good point to start anyway since it will provide you with a feeling what is going on). In case you did not know already: The duality in the continuous case is also nicely explained in Villani's book "Optimal Transport - old and New", Chapter 5. 

If you square your equations to get $|\langle x,a_i\rangle|^2 = b_i^2$ your problem is the so-called phase retrieval problem (which was motivated by the problem of recovering a function (up to global phase) from the magnitude of its Fourier transform). There are several results here (besides the general NP-hardness). I would like to point out some blog posts by Dustin Mixon, e.g.: 

It is well-known that not only does the arithmetic progression $\{ak+b\}_{k \in \mathbb{Z}^{+}}$ contain infinitely many prime numbers, but also that the series of the reciprocals of those primes diverges. The answer to the OP's question can be obtained now from the following general result: If $\{a_{i}\}_{i \in \mathbb{N}}$ is a strictly increasing sequence of natural numbers such that the series $\sum_{i=1}^{\infty} \frac{1}{a_{i}}$ diverges, then the unending decimal fraction $\alpha$ formed by juxtaposing the successive terms of the sequence $\{a_{i}\}_{i \in \mathbb{N}}$ represents an irrational number. For a proof of this theorem, see D. J. Newman, R. Breusch, and F. Herzog. Solution to problem 4494. Amer. Math. Monthly 9 (60), Nov. 1953, pp. 632-633. or N. Hegyvári. On some irrational decimal fractions. Amer. Math. Monthly 8 (100), Oct. 1993, pp. 779-780. 

In point of fact, K. Mahler proved in this paper that, if $p(x)$ in a non-constant polynomial such that $p(n) \in \mathbb{N}$ for every $n\in \mathbb{N}$, then the number $$0.p(1)p(2)p(3)p(4)\ldots,$$ which is formed concatenating after the decimal point the values of $p(1), p(2), p(3), \ldots$ (in that order), is a transcendental and non-Liouville number. 

I guess you can find plenty of them in the Problem Department of the American Mathematical Monthly. For instance, here is a nice one by M. Hajja and P. Walker: Evaluate $\displaystyle \int_{0}^{1}\int_{0}^{1} \int_{0}^{1} (1+u^{2}+v^{2}+w^{2})^{-2} du dv dw $. Good thing about this one is that there may exist a CAS out there that does not give you the answer at once. 

My intuitive explanation that $TGV^2$ does lead to an equivalent norm on $BV$ is the following: You do not really have a higher derivative since setting $\psi = \phi^{(k-1)}$ shows that you really measure the pairing $\int u\psi' dx$ for $\|\psi\|_\infty\leq 1$. The "higher" derivatives are really lower derivatives: You only supremize the integral $\int u\psi' dx$ over some special bounded functions, namely ones that are themselves derivatives of bounded functions. To get more intuition about the $TGV$ seminorm I suggest to look at the proof of the estimates $c\|u\|_{BV}\leq \|u\|_1 + TGV^2(u) \leq C\|u\|_{BV}$ and check how large the constants are, on what they depend (e.g. the size or shape of the domain?) and check the actual value of the norms for special cases. There are recent papers on $TGV$ denoising in one dimension where actual minimizers are derived exactly: 

When I was introduced to measure theory, the professor chose to use the Choquet integral to obtain the Lebesgue integral. An this uses the "good old" Riemann integral to integrate the pseudo-inverse of the cumulative distriution function (I think, it was this book). As a student I enjoyed this approach because I really knew what the Riemann integral was about and also I had an understanding of the problems with it - but I was really confused by the way we had had the Lebesgue integral at the first place. 

I think Brendan McKay's paper on computing R(4,5) will describe one possible approach. It is at $URL$ for your downloading pleasure. 

No, there is a correspondence between certain strongly regular graphs and two-graphs but those strongly regular graphs have specific and restricted parameters. 

As the Petersen graph has no $1$-colourings and $2$-colourings, then it must be the case that $T(0,0) = 0$ and $T(-1,0) = 0$ and indeed we see this. My question is therefore: Question: Are there connections between the nature and/or location of the zero curves of the Tutte polynomial in the $xy$-plane and the structure of the graph? This seems such an obvious thing to do that I am sure it must have been done before, so perhaps the dearth of published results means "no, you can't tell anything from these plots except the obvious", but I thought I would check here. I also tried to find some literature on "zeros of bivariate polynomials" but I got lost in a maze of results about numerical computation of these curves. ADDITION As requested, here are the commands used to create this plot (in Sage): 

I am not sure why you would want to generate these objects, but you could use geng to generate connected graphs, then nauty to compute the automorphism group of each graph, find the orbits of the group and then take one representative from each orbit. Each different orbit representative $v$ of $\text{Aut}(G)$ then gives you one "pointed graph" $(G,v)$, which seems to be what you want. 

I am a little late to the question but wanted to add a low-tech answer which somehow complements JDH's answer: 

The reviewer is not d'accord with the editor's decision. This happened to me once - as author: the reviewer wrote some kind of open letter to the the editor and put me and my coauthor in the cc. Basically, the reviewer complained that the editor weighted some other (unqualified) review high enough to not accept the paper. The reviewer has ideas for further research based on the paper and thinks that a collaboration would be a very good idea. He could think about contacting the author directly but this would disclose his identity (in the case that the paper is not available as a preprint - which still happens sometimes). However, waiting until the paper would be published would be a waste of time. 

Here is how you make an inverse problem of this problem: Choose a space $X$ for the function $f$ you are looking for (e.g. $L^2(0,1)$ to work in Hilbert spaces, but other spaces may be more suitable, depending on your needs). Now let us denote your tuples as $(a_1,b_1),\dots (a_N,b_N)$. You forward operator is $$\newcommand{\RR}{\mathbb{R}} K:X\to\RR^N $$ mapping $f$ to the $N$-vector with components $\int_{a_i}^{b_i}f(x)\,dx$. So you are given a vector $g\in\RR^N$ and want some solution to $$ Kf = g. $$ Now you are in business with the standard theory for linear inverse problems. You have some of the usual problems coming with an inverse problem: Non-uniqueness (the operator is not injective) and probably instability in some sense (depending on you data and values $(a_i,b_i)$). (As far as I see, non-solvability should not be an issue as $K$ should be surjective for meaningful tupels $(a_i,b_i)$). To deal with non-uniqueness: You may view this as an advantage as you can choose among all solutions of $Kf=g$. To pick one, you can choose regularization functional $R:X\to [0,\infty]$ and define a minimum-$R$-solution as solution of $$ \min\{R(f)\mid f\in X,\ Kf=g\}. $$ From a computational point of view, convex functional $R$ are bebeficial and you can choose $R$ to impose some structure on your solution, e.g. $R(f) = \int_0^1 |f'(x)|^2\, dx$ imposes some smoothness (effectively this means that you constrain your solutions to the Sobolev space $H^1$). The most straight-forward choice would be $R(f) = \int_0^1 |f(x)|^2\, dx$ which should produce a linear equality as optimality condition (and you are effectively computing the Moore-Penrose pseudo-inverse). I could say more about regularizing functionals if needed. If your data vector $g$ is also uncertain, i.e. it may be given by measurement data with an error, you may want to relax your problem and look for solutions of $$ \min\{R(f)\mid d(Kf,g)\leq\delta\} $$ for some discrepancy functional $d$ and some value $\delta>0$. Both should be related to the error in your data. Note that this is in some way equivalent to (generalized) Tikhonov regularization which would be solving $$ \min_f d(Kf,g) + \lambda R(f) $$ for some regularization parameter $\lambda>0$. The most simple case of this would be standard Tikhonov regularization in Hilbert spaces: $$ \min_f \|Kf-g\|_{2}^2 + \lambda\|f\|_{L^2(0,1)}^2 $$ leading to the linear optimality condition $$ K^*(Kf-g) + \lambda f = 0. $$ The adjoint operator $K^*:\RR^N\to L^2(0,1)$ is given by $$ K^*g = \sum_{i=1}^N g_i\chi_{[a_i,b_i]} $$ (where $\chi_{[a_i,b_i]}$ is the characteristic function of $[a_i,b_i]$). So the optimality condition is actually $$ \sum_i \left[\langle f,\chi_{[a_i,b_i]}\rangle - g_i\right]\chi_{[a_i,b_i]} + \lambda f = 0. $$ This shows that the regularized solution is also a linear combination of the characteristic functions $\chi_{[a_i,b_i]}$ and thus, we still get a finite dimensional linear problem for the coefficients. If you want some smoothness, try $R(f) = \int_0^1 |f'(x)|^2\, dx$. This would give an optimality conditions like $$ \sum_i \left[\langle f,\chi_{[a_i,b_i]}\rangle - g_i\right]\chi_{[a_i,b_i]} - \lambda f'' = 0 $$ and thus the solution is piecewise quadratic.