For this question, you should look up the topic of realism vs anti-realism. There's far too much to cover in one SE answer. 

But then, you might ask, what about situations where there is an inevitable conflict of interest between different interests in one society? In particular, what about situations where the interests of a small group are inherently in conflict of those of the majority. How does one take into account such situations, yet still allow for a universal ethics of voting? An answer was provided by Harvard political philosopher John Rawls, with his concept of the veil of ignorance, also explained in his idea of the original position. As described in this blog: 

The straight forward answer to your question is Ethics: that is the field of philosophy which directly studies ethical dilemmas such as the one you mention. There are also higher level ways of studying the questions you mention: 

For a long time, this argument made sense to me. I have since started having doubts about it, for the following reason: Only so much evil can occur in the world before God becomes guilty by inaction. Consider the following example: 

Your question is interesting because many people tend to draw the opposite conclusion: If a paradox is shown to exist, then this supports the idea of the existence of God. Keep in mind that they don't claim that paradoxes are in themselves knockdown proofs of God's existence, just that they are arguments in favor of the idea. Their reasoning tends to follow the below pattern: 

In GEB (and later in "I am a Strange Loop"), Hostadter states that human consciousness is due to the fact that the human mind is capable of perceiving itself. This capacity for self reference is analogous to the way Gödel sentences refer to themselves. By the same logic, any dynamic system capable of processing symbols and complex enough to be able to refer to itself (i.e capable of representing and processing formal logic sentences up to and including Gödel sentences) can eventually develop self perception and consciousness. The mechanism he describes for consciousness and self perception is based purely on formal logic. There is no reason why this ability should be limited to biological brains. In chapter 17, he states that any symbol system isomorphic to the brain's higher symbolic levels should be able to implement (strong) AI. 

How would Hume classify computer generated proofs? On one hand they are relations of ideas par excellence, on the other hand they require a mechanical procedure to be generated, and some of them are too complex for a single human to grasp. 

I always assumed that Logical Positivism and reductionism went hand in hand, and that refutations of LP automatically made the case for reductionism weaker. My reasoning was: if only empirically verifiable statements are considered meaningful, then all meaningful statements can be reduced to physical measurements of some sort or another, and that somehow implied the reduction of all sciences to physics. I realize that there are serious gaps in that reasoning. So my questions: 

Functionalism and property dualism are both physicalist theories of the mind in that they don't admit any substances other than physical substance. Property dualism holds that mental states are non-reducible properties of physical brains. Functionalism says that mental states should be defined in terms of their functional roles as opposed to being identified with physical brain states. I can't see any difference between these positions other than they are looking at slightly different aspects of the mind-body problem: Property dualism is looking at it from an ontological point of view, while functionalism is addressing the issue of causal relationships between metal states, brain states and behavior. In fact, it seems to me that functionalism is just a refinement of property dualism: mental states are properties irreducible to brain states, and these properties can be described by their functional relationship to other brain mental states and to behavior. In both cases, the key point is: mental states can't be reduced to brain states and behavior, they are fundamentally anti-reductionist. Once ones dismisses reductive physicalism (i.e. identity theories of the mind), whether it is a dualist theory, a functionalist theory or some form of emergentism seems a matter of semantics. Yet in the literature, functionalism and property dualism are frequently described as being in opposition to each other: Daniel Dennett for example is described as functionalist who is opposed to dualism (presumably including property dualism). My questions: 

If Chomsky had to resort to something even more outdated than behaviorism, how is he considered to have decisively refuted Skinner? Are there any more recent arguments against Skinner's theory of language acquisition? 

To say that the randomness of quantum phenomena is coming from somewhere/something is to assert what physicists call a hidden variable theory. In such a theory, there would be apparent randomness, but there are hidden variables we are not yet aware of (for lack of better knowledge of physics, lack of better measurement equipment, etc...) which if known would provide a deterministic explanation of the apparent randomness. John Bell proved in his 1964 paper (Bell's theorem) that no local hidden variable theory can reproduce the results of quantum mechanics. His theorem was experimentally validated by Aspect et al in 1981 (and many subsequent teams), in the sense that the experimental results indicate that Quantum Mechanics holds. The key terms here are "local" and "hidden variable". "hidden variable" was already explained above. "local" theory means any theory that precludes instantaneous interaction at a distance. It is still possible for a non local hidden variable theory to reproduce the results of quantum mechanics. We would eliminate the quantum randomness, but at the cost of removing locality as well. You might say "well fine, locality is not essential". But the consequences of non locality for causality are seen by some as even more disturbing than quantum randomness. Keep in mind that what is meant by non-local here is fully instantaneous interaction, not just faster than the speed of light. This means that it would be possible in theory for you to push a button on earth and cause a cat to die on the other side of the galaxy without any signal having to travel from here to there. The implications of this spooky action at a distance for causality are significant, especially given the results of relativity (which are much more intuitive than people think they are). 

A theory is then in a progressive phase if the changes being made to the auxiliary hypotheses improve its predictive power and are being driven from within the theory. It is regressive (and hence in need of change) if the auxiliary changes are being made as responses to outside challenges which question the theory's validity. From what I see, Lakatos's hard core corresponds to a Kuhnian paradigm, and his progressive phase is just Kuhn's normal puzzle solving mode of science. A theory in the regressive phase is just the crisis phase that precedes Kuhn's revolutionary science phase. 

Edit: The original question used Grand Unification Theory (GUT) instead of Theory of Everything (TOE). I changed the wording per the first answer's comments and after going back to the book itself. 

Wittgenstein makes an interesting distinction (as a complement to Russell's analysis of the difference): Mystical truths are exactly the truths that cannot be explained by logic, “What can be shown cannot be said”. Mystical schools such of Sufism, often speak of mysteries that cannot be explained, instead the mystic has to "follow the path" to arrive at the truth, the teachers (gurus, saints, masters, etc...) can only show they way. 

Daniel Dennett gives a strong argument against brain in a vat experiments being possible in the real world at the beginning of "Consciousness Explained". Is is pretty simple: Simulating reality to the point that the subject can tell the difference between the simulation and real life is so computationally expensive that it is not practically feasible. A simulation that is capable of taking into account every single possible choice I can make in a given situation would have to be to handle and store a super-astromically large number of variables. The fact that it has to take into account all the possible choices an individual can make in its simulation is the key point. It is totally possible that a computer can simulate relatively stable scenarios with real world accuracy - to an extent that is what many video games do. But in video games the number of possible courses of action a player can take is always limited. For a brain in a vat scenario to be convincing, the player has to be able to choose whatever course of action is possible, and that's when the combinatorial explosion happens that no computer will be able to handle. 

There are many refutations of John Searle's Chinese Room argument against Strong AI. But they seem to be addressing the structure of the thought experiment itself, as opposed to the underlying epistemic principle that it is trying to illustrate. This principle is "syntax is not semantics" (See these lectures by John Searle): At the end of the day, computer software, even the most advanced AI conceivable, manipulates symbols according to a set of syntactic rules, regardless of their meaning. Anybody who has studied formal logic knows that rules like De Morgans laws or the laws of idempotency ( e.g. A ^ A = A ) are independent of the meaning of the symbols being processed. This idea, that syntax is independent of semantics, and therefore a computer can function perfectly without ever knowing the meaning of what it is computing seems like a much stronger argument against AI, and Mind-Body functionalism in general, than Searle's original Chinese Argument. What are the main refutations advanced by proponents of functionalism and strong AI specifically of the "syntax is not semantics" argument? 

So it is pretty straightforward for a utilitarian as well, that you should vote for the greater good, not the special good. I don't know enough about utilitarianism to see how to it develop further or how to put it in to practice (How to measure the good? What about inherent conflicts? etc...). In response to the comment about Marx: Marx wouldn't have much to say about this dilemma, as his thought concerns economy more so than political theory qua politics (although there is inevitable overlap). To put it another way, Marx's ideas would be the end result of the voting process, not guidelines on how to vote. 

See for example the following article, by Marko Vojinovic:"Reductionism, emergence, and burden of proof" — part I and part II , and the SEP article on Godel's incompleteness theorems - section 6.5 and the reference therein. 

Chapter 9 of Hawking's "A Brief History of Time" has an interesting discussion of entropy. Also the following "The Blackwell Guide to the Philosophy of Computing and Information" $URL$ Has some good discussions of the philosophical aspects of entropy (and the physics of information) when seen from a information point of view. 

Signals coming from an intelligent agent will contain more information than a signal coming from a non intelligent agent. 

The main problem with this is that it is very difficult to define "sufficiently generous" so as to cover what constitutes the basic needs of a worker. Marx mentioned that the worker is forced to do so in order to avoid starvation, back in his time a house with running water and electricity was considered a luxury. Nowadays, in the developed world, people don't starve (thanks to food stamps, soup kitchens, etc...), yet someone living without electricity or running water is still considered to be living in abject poverty. A worker forced to work to pay his electric and water bills would be considered exploited, and the slavery component persists. At which point exactly does a worker no longer "need" to offer their labor on the market? Provide enough food and shelter to everyone, and we simply move a level up in Maslow's hierarchy of needs: The working class is forced to work to find love and belonging while the bourgeois class enjoys esteem and self actualization. The UBI would have to be such that everyone can move to the top of Maslow's pyramid at will - Marx alluded to this in his famous quote from "The German Ideology":