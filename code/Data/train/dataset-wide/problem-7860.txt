Author's note: This question might be a little hopeless, but maybe someone has some form of good feedback. It's a long one because I tried to be very thorough. I tried to explained all the odds and ends I had at approaching this. It is a preliminary fact when studying modern analytic number theory that the reader has seen Euler's partition function. The partition function $p$, as review, can be expressed as $$\prod_{i=1}^\infty \frac{1}{1- x^{i}} = \sum_{k=0}^\infty p(k)x^k$$ Essentially, I want to analytically continue $p$ to some domain in $\mathbb{C}$. I'll be clear now as to what this question is not asking. It is a basic graduate exercise in complex analysis to construct a holomorphic entire function $f(z)$ such that $f(n) = p(n)$ for $n \in \mathbb{N}$. I am not asking for such a simple analytic continuation of the partition function. I am asking for something a bit more nuanced. To explain this, I'll require Euler's Pentagonal Theorem. To paraphase and for the readers' convenience: let us enforce the fact that $p(k) = 0$ for $k \in \mathbb{Z}$ and $k \le -1$. Then, if $g_i = \frac{1}{2}(3i^2 - i)$ it follows $$\sum_{i=0}^\infty (-1)^i p(k-g_i) = 1_{k=0}$$ (Where $1_{k=0}$ equals $1$ if $k=0$ and $0$ otherwise.) This can be rewritten for $k \neq 0$: $$\sum_{i=1}^\infty (-1)^{i+1} p(k - g_i) = p(k)$$ I want to abuse this relationship in complex analysis. And by abuse, I mean it in a similar sense to how Euler would talk of the 'half-factorial' without actually rigorously describing the 'half-factorial'. I want to do something similar to the invention of the Gamma function (there are trillions of functions that interpolate the factorial, but only one nice one that satisfies $z(z-1)! = z!$). Here comes the actual question. I want to find a function $\mathcal{P}$ that interpolates the values of $p :\mathbb{Z} \to \mathbb{Z}$, but it also satisfies the above functional equation. Essentially, I don't just want to interpolate the partition function, I want it to satisfy a nice equation. That equation being $$\mathcal{P}(z) = \sum_{i=1}^\infty (-1)^{i+1} \mathcal{P}(z-g_i)$$ This is simply a rewrite of Euler's pentagonal identity for the partition function, except we're letting the variable be complex. To make the question more concrete, we have to work around a few facts. First things first, we have to remove $0$ from the domain of $\mathcal{P}$ because $\sum_{i=1}^\infty (-1)^{i+1} \mathcal{P}(z-g_i)$ is a holomorphic function that equals $\mathcal{P}$ almost everywhere, except when $ z = 0$â€”this sum equals $0$ but $\mathcal{P}(0) = 1$. So it's hopeless for this function to be holomorphic at zero. Because of this, we must weaken the solution so that $\mathcal{P}$ is not analytic at $0$. Working from this we can't have $\mathcal{P}$ being analytic at $z=g_i$ as well, because then undefined values of $\mathcal{P}$ enter our sum ($z - g_i = 0$ at some point). Then continuing from this, just as well if $z= g_i + g_j$, we will get undefined values in our sum $z - g_i = g_j$. Similarly for $z = g_i + g_j + g_k$, so on and so forth. So $\mathcal{P}$ can't be holomorphic on $\mathbb{N}$ at all. So to be safe, we're just going to cut $\mathbb{R}$ entirely. This might seem like we've just lost the meat of the question, but I don't quite see it like that. We're going to only talk about $\mathcal{P}$ in the upper half plane $\mathbb{H}$ with a continuous extension to $\mathbb{R}$. Because of this, we don't get a nice interpolation of the partition function, we get something more wonky. The sum $$\mathcal{P}(z) = \sum_{i=1}^\infty (-1)^{i+1}\mathcal{P}(z-g_i)$$ cannot converge for $z \in \mathbb{R}$, excepting when $z \in \mathbb{N}$ where it converges trivially. This way, we can't pull the limit through the sum and produce a contradiction (in contrast to if the function was holomorphic in a neighborhood of $\mathbb{R}$). Namely, if it did converge, we could pull the limit through and $$1 = \mathcal{P}(0) = \lim_{z\to 0 } \sum_{i=1}^\infty (-1)^{i+1}\mathcal{P}(z-g_i) = \sum_{i=1}^\infty (-1)^{i+1}\lim_{z \to 0}\mathcal{P}(z-g_i) = \sum_{i=1}^\infty (-1)^{i+1}0=0$$ This would clearly muff everything up. Which better explains why $\mathcal{P}$ can't be holomorphic in a neighborhood of $\mathbb{R}$. So now I can ask my question. It looks a lot like a boundary value ODE problem in complex analysis, except it's discrete. We write $\mathcal{P}\Big{|}_{\mathbb{Z}}$ to mean $\{\lim_{z \to k}\mathcal{P}(z)\,\Big{|}\, k \in \mathbb{Z}\}$ 

Not sure if this is an answer but a good suggestion of how to show (1) and (2) (and perhaps an actual solution), and a good start for (3). Consider the Newton series formula for tetration. This series converges for all $\Re(z) > -2$, and is very similar to your formula $$^za = \sum_{n=0}^\infty \sum_{k=0}^n (-1)^{n-k} \binom{z}{n}\binom{n}{k}(^k a)$$ (The op claims this expression diverges, an alternate expression is $$\frac{1}{\Gamma(1-z)}\Big{(}\sum_{n=0}^\infty (^{n+1}a)\frac{(-1)^n}{n!(n+1-z)} + \int_1^\infty \big{(}\sum_{n=0}^\infty (^{n+1}a) \frac{(-x)^n}{n!}\big{)}x^{-z}\,dx\Big{)}$$ of which the rest of this discussion still applies.) Now, since this solution is bounded in the half plane $\Re(z) > 0$ it does have a uniqueness criterion--quite a good one at that too. It is the only solution to the functional equation to do such. In fact, if a solution $F$ exists where $F(z) = O(e^{\rho|\Re(z)| + \tau|\Im(z)|})$ for $\tau < \pi/2$ then $F$ is still the above solution. What you have presented is a q-analog of the Newton series I just put above. Sadly I cannot find a rigorous paper detailing these types of series; I don't remember where I have seen them, but I have seen them. This suggests to me, that really you are just interpolating $(^na)$ in the same manner the Newton series does, except you are using q-analogs. It is necessary though that $q$ be fixed to the value you put (explanation below). Consider the rather beautiful fact that your solution is bounded in the right half plane. Observe if $[z]_q = \frac{1-q^z}{1-q}$, $[z]_q$ is periodic in $z$. $${z \brack n}_q = \frac{[z]_q!}{[n]_q![z-n]_q!} = \frac{[z]_q[z-1]_q...[z-n+1]_q}{[1]_q[2]_q...[n]_q}$$ And each of these functions have a period, namely $2\pi i/\log(q)$.. Therefore your final expansion has an imaginary period, it tends to $-W(\log(a))/\log(a)$ as $\Re(z) \to \infty$; thus, it is bounded in the right half plane. From this it follows your function is the standard tetration function (If it converges). So $t$ is bounded. The first obvious fact is $t(n) = (^n a)$. Next consider the wondrous power of a little known identity theorem for functions bounded in the right half plane. Namely, if $F(z)$ and $G(z)$ are bounded in the right half plane and $F\Big{|}_{\mathbb{N}} = G\Big{|}_{\mathbb{N}}$ then $F = G$. This follows because of Ramanujan's master theorem. I'll explain the identity theorem for a second, and then explain how this applies to your case. If $F$ and $G$ are bounded, then surely $$f(x) = \sum_{n=0}^\infty F(n+1)\frac{(-x)^n}{n!}$$ $$g(x) = \sum_{n=0}^\infty G(n+1)\frac{(-x)^n}{n!}$$ are both entire functions, and by Ramanujan both satisfy $$\int_0^\infty f(x)x^{z-1}\,dx = \Gamma(z)F(1-z)$$ $$\int_0^\infty g(x)x^{z-1}\,dx = \Gamma(z)G(1-z)$$ But $f = g$ and therefore $F = G$. Look at $t(z+1)$ and $a^{t(z)}$, both of these functions are bounded and agree on the naturals ($t(n+1) = a^{t(n)}$), therefore they are equal everywhere. Now as to the fact that this function is completely monotone: On the tetration forum Sheldon made a great point. I'm not sure of this fact, but I'm betting it's true. If $0 < \lambda < 1$ then $f(z) = \lambda^z$ for $\Re(z) > 0$ is the only completely monotone function on $\mathbb{R}^+$ such that $\lambda f(z) = f(z+1)$. Another function would have to be $f(z+\theta(z))$ for $\theta$ a 1-periodic function, but this will most assuredly destroy the completely monotone structure. What's great about the standard solution (the one that is periodic, the one that is the Schroder iteration, the one that is bounded), is that it can be expanded in an exponential series for $\Re(z) > 0$. This is just Fourier series, essentially. $$^za = F(z) = \sum_{k=0}^\infty a_k \lambda^{kz}$$ $$F'(x) \sim C\lambda^x$$ Since another solution is just $F(z+\theta(z))$ for $\theta$ periodic, we can most likely form a contradiction by using our knowledge of the uniqueness of the exponential function under these conditions. All in all, I mostly just had to weigh in my two cents, but I think all the conjectures you put are true and that your solution is in fact the 'standard' solution, which is: the periodic one, the bounded one, the Schroder one, and hopefully, the completely monotone one. Hopefully the rough proof I gave of (1) and (2) is good enough for you. 

Only reason I ask is because we get a little trouble when $j \to \infty$ since $e^{\lambda^jw} \not \to 0$. We are also guaranteed that $\vartheta$ can be expressed like this for $|\xi| < \epsilon$ for small enough $\epsilon$. All the usual tools are hard to come by in this scenario (or as I've looked at it). 

Personally, if I was entering this subject blind I would feel cheated if not shown the extensive pure mathematical power of the fractional derivative. Being that it is more useful than just being used to solve differential equations or physical problems. The first thing is to look at Cauchy's integral formula which is most aptly $$\int_a^x \int_a^{x_{n-1}}...\int_a^{x_1}f(x_0)\,dx_0dx_1dx_2...dx_{n-1} = \frac{1}{n-1!}\int_a^x f(y)y^{n-1}\,dy$$ which is a strikingly powerful equation. The natural generalisation arises by considering the operator $I_a f = \int_a^x f(y)\,dy$ and simply writing $$I_a^n = I_a ... (n\,times)...I_a f = \frac{1}{n-1!}\int_a^x f(y)y^{n-1}\,dy$$ where a natural conclusion is to define $$I_{a}^z f = \frac{1}{\Gamma(z)}\int_a^x f(y)y^{z-1}\,dy$$ which through no obvious or simple method $$I_a^{z_0}I_a^{z_1} = I_a^{z_0 + z_1}$$ This gives not only one iterated "fractional" integral but infinitely many for each $a$. The perspective result, or canonical fact, is that each fractional integral satisfies $$I_a^z (x-a)^r = \frac{\Gamma(r+1)}{\Gamma(r+z+1)}(x-a)^{r+z}$$ and $I_a (x-b)^r$ when $b \neq a$ is defined using a binomial expansion. Defining $\frac{d}{dx}_a^z = I_a^{-z}$ for $\Re(z) < 0$ and $\frac{d}{dx}_a^z = \frac{d}{dx}^n I_a^{n-z}$ for $\Re(z) < n$ we arrive at a fractional derivative. This seemingly convenient and beautiful expression gives us something rather ugly though. Since $\frac{d}{dx} e^x = e^x$ we would like $\frac{d}{dx}^z e^x = e^x$, but this is not so. By uniform convergence and all that jazz $$\frac{d}{dx}_a^z e^x = \sum_{n=0}^\infty \frac{x^{n-z}}{\Gamma(n+1-z)}$$ which is not $e^x$. Therefore another fractional derivative is required. Taking $a = -\infty$ then we arrive at the commonly called "exponential differintegral" which can be written $$\frac{d}{dx}^{-z} f(x) = \frac{1}{\Gamma(z)}\int_0^\infty f(x-y)y^{z-1}\,dx$$ defined for $f$ satisfying specific decay conditions at negative infinity. As one can see this fractional derivative fixes $e^x$ but diverges for any polynomial. Now we can generalize this even further! Consider $f(w)$ entire on $\mathbb{C}$, and for convenience assume $f(w)w \to 0$ as $w \to \infty$ when $|\arg(w)| < \kappa$ and call this space of function $D_\kappa$ Then we have the disastrously large formula $$\frac{d^z}{dw^z} f(w) = \frac{e^{i\theta z}}{\Gamma(-z)}\Big{(}\sum_{n=0}^\infty f^{(n)}(w)\frac{(-e^{i\theta})^n}{n!(n-z)} + \int_1^\infty f(w-e^{i\theta}y)y^{-z-1}\,dy\Big{)}$$ which holds for all $|\theta| < \kappa$ and $\Re(z) > -1$. Now some people would rashly think what is the point of this? Some interesting things happen in this scenario, firstly the differintegral can be thought of as a modified Mellin transform. Giving us things like Ramanujan's master theorem in a slicker notation. It further emphasizes that this operator arises in a very natural sense (the Mellin transform being prominent in many areas of mathematics). It says $\frac{d^z}{dw^z}$ for $\Re(z) > 0$ takes $D_\kappa$ to itself. So we have a semigroup $\{\frac{d^z}{dw^z} | \Re(z) > 0\}$ acting on $D_\kappa$. Furthermore, when looking at the fourier transform definition of a fractional derivative, it is in fact this clunky looking exponential derivative that's really pulling the strings. Where it may seem cleaner in Fourier transforms, it is much more general in its Mellin form. All in all it is quite a mysterious object, and is underused in my opinion. 

Now this question is like looking through a keyhole at a bigger problem I have been faced with. I've worked around it for 2 years, but at this point I'm rather frustrated and would like my assumptions to be proven. I can no longer work around it in a manner that suffices. The way I will pose this question is using tetration, but the idea generalizes well. Especially in the vein that I am researching. First and foremost consider the the function $$f(\alpha, z) = \alpha^z$$ for $\alpha \in (1,e^{1/e})$ and $\Re(z) > 0$. This function is obviously analytic in both variables. To be explicit we are choosing the principal branch of $\log$ to define this function, so that $f(\alpha,z)$ is periodic in $z$ with period $2 \pi i /|\log(\alpha)|$. What is especially important about this function is that there is a fixed point $1 < \beta < e$ for each $\alpha$, call this $\beta_\alpha$; wherein $$f(\alpha, \beta_\alpha) = \beta_\alpha$$ and these numbers are related by the identity $$\alpha = \beta_\alpha^{\frac{1}{\beta_\alpha}}$$ This fixed point depends analytically on $\alpha$ as well, so that $\beta_\alpha$ is analytic in $\alpha$--if not apparently obvious to the reader. The multiplier of this fixed point, $\lambda_\alpha$, satisfies $$0<\lambda_\alpha = \frac{d}{dz}\Big{|}_{z=\beta_\alpha} f(\alpha,x) < 1$$ so that $f(\alpha,z)$ has a geometrically attracting fixed point at $\beta$. This allows us (through no trivial manner) to define a function for $\Re(z) > 0$ and $1 < \alpha < e^{1/e}$ $$F(\alpha, z) = \,^z\alpha$$ which is tetration for base $\alpha$. Satisfying $$\alpha^{^z\alpha} = \,^{z+1}\alpha$$ $$f(\alpha,F(\alpha,z)) = F(\alpha, z+1)$$ and $$F(\alpha,1) = \,^1\alpha = \alpha$$ Now $F(\alpha,z)$ is analytic in $\alpha$, holomorphic for $\Re(z) > 0$ and if $\ell_\alpha = \frac{2\pi i}{|\log(\lambda_\alpha)|}$ then $\ell_\alpha$ is the imaginary period of $F(\alpha,z)$. $F(\alpha,z)$ is also bounded in the right half plane. It takes real positive values to real positive values and has monotone growth. This produces another set of fixed points on the real positive line--let's call these $\tau_\alpha$ such that $$F(\alpha, \tau_\alpha) = \tau_\alpha$$ and quite trivially for all $x \in [0,\tau_\alpha)$ we have that $$F(\alpha,F(\alpha,...(n\,times)...F(\alpha, x) \to \tau_\alpha$$ implying that $$0 \le \mu_\alpha = \frac{d}{dz}\Big{|}_{z=\tau_\alpha}F(\alpha,z) \le 1$$ I want to show that in fact $0 < \mu_\alpha < 1$. We can trivially remove $\mu_\alpha = 0$ as a possibility, but $\mu_\alpha = 1$ is not so easy. I can't seem to show that the multiplier cannot be $1$. This is equivalent to showing that $\tau_\alpha$ is analytic for all $\alpha \in (1,e^{1/e})$. To me, this should be obvious-- just as $\beta_\alpha$ is analytic $\tau_\alpha$ should be analytic. But how to show this? I've tried everything I could think of. I know that $\tau_\alpha$ is necessarily continuous in $\alpha$, but the problem is if and only if $\mu_\alpha = 1$ does $\frac{d}{d\alpha}\tau_\alpha = \infty$. So showing that $\frac{d}{d\alpha}\tau_\alpha$ is continuous would show its analytic would show that $F(\alpha,z)$ has a geometrically attracting fixed point on the real positive line and vice versa. My question is therefore simple to state. Is $\tau_\alpha$ analytic for all $\alpha \in (1, e^{1/e})$?