With control verbs, a single Noun Phrase seems to function both as an argument of the matrix predicate, and as an argument of the embedded predicate. I.e. in (1) The speaker is the one who is doing the liking, and also the one who is doing the eating. This is modelled in generative grammar by positing a dependency between the Noun Phrase and a null pronominal category "PRO" in the non-finite clause: 

I'll attempt to go through the various analytical possibilities for your example sentence within the GB framework: 

Raising verbs are analysed in generative grammar as involving displacement of the subject of the embedded non-finite clause to the matrix subject position: 

With raising verbs, a Noun Phrase in the matrix clause functions as an argument of the embedded predicate. I.e. John is the one who is doing the leaving, in (2). Crucially, John does not function as the argument of the matrix predicate - John is not doing any seeming. Generally speaking with raising verbs, the subject can be replaced by an expletive and the non-finite with a finite clause: 

It's probably worth making the more general point here that not everyone agrees with a Bloomfieldian 'constructive' conception of morphology, in which words are built-up from sub-word units. There are a few morphologists working within an 'abstractive' word & paradigm based framework (Jim Blevins' terminology), where words, the basic units, are associated with paradigms, e.g. 'dogs' is a basic unit associated with the 'plural' cell of a paradigm. Formatives and inflection etc. are treated as epiphenomenal abstractions over the lexicon. See for example the work of Jim Blevins at Cambridge , and his 2006 paper 'word based morphology' (can find here: $URL$ for an intro to this kind of approach. So to answer your question: The reality of 'zero morphs' is controversial, in the sense that word and paradigm models (which do seem to be in the minority) do not even commit to the reality of any sub-word unit (other than as an abstraction), and this includes zero morphs. 

If i had to recommend just a couple of textbooks for syntax, semantics/pragmatics and phonology respectively, they'd be the following: Syntax 

In (6), the pronoun us functions as both an argument of the matrix predicate told, and as an argument of the embedded predicate start. Remember that we modelled this as a dependency between the 'controller', and a null pronominal: 

Recursion in phrase structure grammar is where an expression of some type contains an expression of that same type. Under this definition, chains of relative clauses count as an instance of recursion. We can see this more clearly by drawing a (simplified) Phrase Structure Tree of your example (note i'm abstracting away from irrelevant details, e.g. the syntax of relative clauses. The 't' in the subject position of each relative clause stands in for an empty category - every theory of relativisation has to assume something like this): 

I'm don't think that the two examples you mention should be grouped together linguistically as a single class (to the exclusion of other activity verbs). Levin (1993) classes teach as a verb of transfer of message, along with show, read, preach, etc.. verbs of transfer of message are notable in that they participate in the dative alternation: 

Since the subject is closer to interrogative C than the object, it counts as an intervener to wh-movement of the object, as attested by the ungrammaticality of (b). 

Robins & Waterson (1952) give an alternative, less compact (but perhaps more readable) set of rules: 

Counterfeeding is opaque in the sense that the surface form violates the generalisation that [ee] sequences are generally altered via the raising rule (B). If rule A destroys an environment that could have triggered rule B, then A bleeds B, e.g. 

Now we've reached the crucial part of the derivation. Interogative C possesses an uninterpretable wh-feature, which must be deleted before spell-out, or the derivation will crash. The [*u*Wh] feature 'probes' downwards for a matching 'goal' - since 'whom' posseses an interpretable [wh] it counts as a matching goal. Once the goal is found, movement of 'whom' to SpecCP is triggered, and [uWh] is deleted in a spec-head configuration under AGREE with 'whom'. 

As desired, the grammar only generates strings ww (w concatenated with itself), where w is an arbitrarily long sequence of a, b and c in any order. A small explanatory note: This grammar works crucially by defining the copying rule S[x] -> T[x]T[x]. This rewrite rule takes the stack of symbols on S, and duplicates the stack on two new non-terminals, which exist only to hold the duplicated stacks (they are ultimately deleted via T[] -> E). Once the stacks have been duplicated, the non-terminals in the stacks are 'popped off' one by one to generate strings of terminals. Because the stacks have previously been duplicated, the strings resulting from popping off non-terminals from the stacks of T are guaranteed to be identical. 

The most famous example of a phenomenon which seems to argue against the context-freeness of natural language is cross-serial dependencies in Swiss German (Schieber, '85) (cross-serial dependencies can also be found in Dutch). Two facts about Swiss German are relevant here: 

The < NP, V > pairs < the children, let > and < Hans, help > can both be iterated. The following homomorphism f seperates the iterated NPs and Vs in (b) from the surrounding material: f(the children) = a f(Hans) = b f(let) = c f(help) = d f(Jan said that we) = w f(house have wanted) = x f(painted) = y f(s) = z otherwise The images we are interested in under f are of the form wV1xV2y, where V1 contains as and bs, and V2 contains cs and ds, and if the kth element in V1 is an a (a b resp.), then the kth element in V2 is a c (a d resp.) - i.e., sentences involving cross-serial dependencies. All other sentences have a z somewhere in their image under f. To make sure we only concentrate on constructions involving cross-serial dependencies, we intersect f(L) with the reg. language wa*b*xc*d*y, giving us L'. If L is context free, then L' must be too. If this is so, then the image of L' under a homomorphism f' with f(w)=f'(x)=f'(y)= Ɛ, f'(a)=a, f'(b)=b, f'(c)=c, f'(d)=d will also be context free. This image is: f'(L') = L'' = { a^i b^j c^i d^j | i, j >= 0 } L'' should satisfy the pumping lemma for context free languages. Inspecting the word {a^k b^k c^k d^k}, where k is the constant from the pumping lemma however, this can be shown to lead to a contradiction. In conclusion L'' is not context free, and neither is L' nor L. The take-home message is that purely context-free grammars cannot handle cross-serial dependencies in natural languages - although examples of this are few and far between. This result has been used to argue that natural languages are properly described by mildly context-sensitive languages. 

The difference you've identified is between predicational and specificational copular clauses (terms coined by Higgins, 1979, i think). In a predicational copular sentence, the subject denotes an individual and the complement (which may be either a Noun Phrase, or an Adjectival Phrase) denotes a property. The subject is predicated of the complement. Your examples 1b (i) and 2a (ii) are predicational copular clauses. 

ECM constructions are different, in that the syntactic object of the matrix predicate does not function as a semantic argument of the matrix predicate, but as a semantic argument of the embedded predicate. In (5), it is not him that is being believed by Mary, but rather the proposition that he is a fine dancer. We model this in generative grammar as displacement of the Noun Phrase in question from the subject position of the non-finite clause to the matrix object position, similar to the analysis of raising verbs: 

Ross (1967) identifies conjuncts as syntactic islands, in order to rule out extraction of, e.g., a wh-word from a single conjunct, as in the following example: (ii) What did John buy t and Mary sold a car? Constituents can exceptionally be extracted from conjuncts just so long as parallel extraction takes place from out of all of the conjuncts. Hypothesis 2.2: VP co-ordination + VP-external subject