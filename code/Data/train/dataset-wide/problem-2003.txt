Whether you use a local index or a global index will have (practically) no impact on the amount of space required for the index. If you are running out of space to create the index, you'll need to allocate additional disk space to the tablespace (or tablespace(s) if you create a local index where the index partitions are stored in different tablespaces). If you are building an index that involves the column you are partitioning on, you would almost always want to create a local index-- there is no benefit to creating a global index in this case. Assuming that the column stores dates of birth and that the time component of that column is always set to midnight, you can probably reduce the space required for the index by making the column the leading column of the index and by using index compression. In your case, you probably want to specify since you would only want to compress the column, not the column assuming that has many fewer repeated values. 

This problem may happen if you have multi MySQL instances on the same machine. There was pre-installed MySQL when the OS was installed, or using auto installation methods like : in this case when you type mysql it will point to the pre-installed one since the environment variable point there. you can test it by going to use this should show you the exact version of MySQL. 

to skip external lock you need to comment or remove and to disable delay key write you need to add the following parameter 

I am using oracle 11g R2 on and created a lot of databases. At that time there was no problem. But currently I am seeing that in (Database Configuration Assistant) application some options are disabled as follows:- 1 Create a Database - ENABLED 2 Configure Database Options - DISABLED 3 Delete a Database - DISABLED 4 Manage Templates - ENABLED I don't understand why this happening but in starting all the options were enabled. EDIT : file content, inside ** 

Is there a shortcut? If you're using a recent version of Oracle, you can use the procedure to estimate the size of a table. There are a couple ways of doing this. The first option is to pass in the size of the row. Using our 56 byte estimate, that yields a table size estimate of 64 MB with 63.52 MB used which is pretty close 

Now, if you run the same query, you'll see that the column takes up to 21 bytes of storage and averages 7.69 bytes for the 200,000 rows. The is still using a fixed 4 bytes for every row. Depending on your data, you may find that one or the other approach uses more space. Of course, where there are substantial differences in space utilization, there is the potential for more substantial rounding issues when you move to floating point numbers. Note as well that the results may be version-dependent. I did my test on an 11.2 database where the documentation indicates that always takes 4 bytes of storage. In 10.2, the documentation indicates that took 5 bytes due to the inclusion of an extra length indicator. It's not obvious to me why a 32-bit value would ever need a length byte so I'm hard-pressed to understand why an earlier version of Oracle might have required the fifth byte, but the documentation is consistent that it did. 

in-order to change default value you need to edit you file and look for if the parameter exist then you need to edit the current value to 600 and restart the service, otherwise you need to add the parameter and restart the service. Demo: my.ini content (I am using windows here, but MySQL) configuration is the same 

increase memory for MySQL. at least by double memory value to test if the new memory that reserved to MySQL is enough. reformat the transaction to take less memory. 

the answer is there MySQL can not write to the directory you are pointing inside , and it dose not have the right permissions. to fix this problem make sure the user MySQL has owner privileges on the directory that is pointing for example lets say the is located under , is located under and the socket is located under in this example you need to make sure and are owned by MySQL user, for since its a default directory for Linux user MySQL should have read,write and execute privileges. also you need to make sure the partition that contain the is not full "contain enough free space" 

You may, however, want to do something else. Perhaps you want to the two result sets, for example, it order to get duplicate rows. 

Short of disabling the trigger before executing your statement (which would affect all sessions and would only be appropriate if you are doing an off-hours bulk delete), setting a package variable (or defining your own context and setting a context variable) that your trigger reads is likely the cleanest option without reworking the existing application. When you have an action that generally needs to be done when a row in Y is deleted but not when Y is deleted because of the cascade delete, that is probably not an action that should be in a trigger in the first place. It ought to be part of the stored procedure (or other API) that allows you do do "normal" deletes on Y. Of course, that sort of refactoring may not be possible with a legacy application so you may be stuck with some of the less elegant workarounds. 

I'm working on a "Bus stations" database. I want to design the next relationship: "A bus line has many stops (one stop belongs to one line) and one stop has many arrival times (one arrival time belongs to one stop)". So my design is like this: 

I'm a little bit confused because I think this design has redundancy: the relationship between and could not be reached by the intermediate relationships? 

I'm not sure if this design is right at all. I'm no looking for performance. I just want to know if I will have problems with this design in future time (For example: is easy to insert a new line station? Is easy to select the next arrival time for a bus station with specific line station? How I deal with different time frequencies? Because is different for weekdays and weekends. If my design is ok, then the example above will work fine with arrival times in weekdays but no for weekends. I need a second table or add a column in table indicating the type of the day? 

Depending on the tool (SQL*Plus, TOAD, iSQL*Plus, SQL Developer, and the APEX query tool may have slightly different syntax requirements), you could also add a '/' character after each INSERT statement 

Oracle will look in the current schema to see if there is an object named . Since there is no such object, it throws an error. You can fix that by telling Oracle what schema the object resides in by qualiying the table name 

You can create two tablespaces, put all the data files for one tablespace on one drive and all the data files for the other tablespace on the other side, and then create the tables in whichever tablespace you would like. It seems unlikely, however, that you would really want to do this. It is very unusual to run a database on a server without any sort of RAID configuration. And it is generally the case that any automatic I/O load balancing that you would implement would outperform your manual load balancing. 

References: $URL$ $URL$ $URL$ Edit: I found the following article regarding the performance: The performance is a matter of debate between these two methods for stored procedures. As its name suggests, is itself a stored procedure, which stores in the system database. must require passing SQL strings to it thus, excepted to showing higher chances of caching, consequently leading to perform better when run for the second or later on times. In other words, its parametrized dynamic T-SQL encourages its reuse. Moreover sp_execute is supposed having higher chances for avoiding unnecessary compilation while executing a dynamic query over . But some experts take it as misleading as they think for both methods a plan will be cached. In fact, for the non-parametrized queries of shows the same characteristics as the later one. $URL$ 

how to avoid this log file growing? 1) Convert the Recovery Model to Simple Recovery 2) Start Taking Transaction Log Backup 

Say I have a table . Users can see the prices of this table (I'm simplifying it). Users also can send prices to the server, so the server is going to collect these data in another table (). When the server detects that there are 50 prices or more, then the server calculates a median of those temporal prices and update the table with the calculated value (again, very simplified). The first idea that came to my mind was have two tables with the same schema but different names ( and ). I don't know if this is a good/common practice. I am missing something? Also, what mechanism should I use to trigger the server to inspect the table ? I think about but again, I don't know if there is something I'm missing (another tool or common practice for doing this kind of stuff). Thanks. 

You will get this error when you enter wrong password. To reset your root password: 1) if you have another Admin user login by using it then execute the following command: 

Lets say the database we will be using called test, then we have to connect to the database first then create schema, example below 

To understand the problem and try to fix it you need to check related logs: listener.log, alert log, trace file, etc possible causes and solutions: 

:This option is useful for dumping large tables. It forces to retrieve rows for a table from the server a row at a time rather than retrieving the entire row set and buffering it in memory before writing it out : This option sets the transaction isolation mode to REPEATABLE READ and sends a START TRANSACTION statement to the server before dumping data. It is useful only with transactional tables such as , because then it dumps the consistent state of the database at the time when START TRANSACTION was issued without blocking any applications. : option stops tables (if they exsit) being locked during the backup. 

But when I was testing it, I realized that I needed a FOREIGN KEY in table (because I could not distinguish between times of different bus lines). This transforms the diagram: 

In the first 7 rows, the line with line_id=100 stops at different times in the station with station_id=10 (The in indicates that there is no backward route that passes by station_id=20). My questions are: 

Hi I'm trying to figure out how to design a database for bus time schedule. There are several lines, each line have two routes (forward and back), each route have several stations (stops) and each station may belong to several routes. The main goal of the database is to easily select the next arrival time for a specific bus station with a specific line. I googled and came up with next database design: lines (id, name, ...) routes (id, name, line_id, ...) stations (id, location) route_station (id, route_id, station_id) times (id, station_id, line_id, time_forward, time_back) So, for instance