However, there is a problem with this design: a row should only be allowed to reference a connection when the education type matches. E.g. a row can only reference a row in the table that references a row in the table with type == master. Would it be possible to add a constraint which can check exactly that? If not, what other options are available? 

So basically I'll have to do a migrate a database live over the course of a few days, while simultaneously updating the application live such that it can handle the new application, without being able to search for the usage of each table. With all these handicaps taken into consideration I came up with the following plan: 

I'm attempting to get a listing of the users and roles they are associated with on a remote server to be input into a database on the local server. But when I use the linked server sys.database_principals only shows me information for the login that the linked server is using. How do I get a listing of users and roles by database to a central db location? 

My Boss requires that we keep up to date scripts of all database objects in svn. This results in constantly trying to find the object in the current script and copy and pasting the changes. Is there an easy way to set sql server to script database objects and write them to a file on the drive? If not then I've built the following sql script as a test run for creating a tables file but I'm not sure how to capture the output string that sp_executesql is creating. 

I try to create a good database design to represent this data, however there are quite a few difficulties. A design I came up with is as followed: 

I "inherited" a web application which is designed and implemented horribly (both the application and the database). For example, the main data is stored using a sort of emulated key-value storage in a Postgres 8.2 database, making it virtually impossible to extract useful data from it in a reasonable amount of time. Currently I'm working hard on replacing the entire application + database, however it will take a few months before the new application is finished. This is a problem since the website is really slow due to the extremely bad database design and even worse queries. Therefore I'm planning to fix the database design and the queries on the live site until the website has an acceptable load time as a temporary solution. I do however have a few limitations to work around, the most problematic ones are: 

I'm attempting to determine root cause for an issue that caused an outage for my company. Essentially the site connections to our database server were timing out after not receiving a response for 5 min. A check of perfmon counters showed that the database server was using about 10% of processor, memory was under utilized, and our hard disks were not being stressed. A check of long running queries using the following statement showed that there were a lot of queries queued up with a status of suspended the longest of which had been running for 50 minutes. 

The short answer would be when you have no set based way to get the information or have exhausted all other options and rejected them based on their performance being worse. The reason for avoiding scalar sub queries is that they force SQL Server to perform the scalar query once per every row that is returned. There is almost always ways to get the information back using a set operation that will perform and scale better. 

As far as I could find out many DBMSs (e.g. mysql, postgres, mssql) use fk and pk combinations only to constrain changes to data, but they are rarely natively used to automatically select columns to join (like natural join does with names). Why is that? If you've already defined a relationship between 2 tables with a pk/fk, why can't the database figure out that if I join those tables I want to join them on the pk/fk columns? EDIT: to clarify this a bit: suppose I have a table1 and a table2. table1 one has a foreign key on column a, which references to the primary key on table2, the column b. Now if I join these tables, I'll have to do something like this: 

In this case you dont need to update the records for people who havent returned a car. You only update the record to contain the date when they have returned the car. 

There were also several queries with a status of running but none of these had been running for a significant amount of time. SQL Server threw no alerts during the time frame and nothing looked out of the ordinary in the logs. There were also no alerts for Blocking processes at this time. Finally the decision was made to fail over the SQL Server cluster. This cleared up the issue. I've exhausted the places I can think of to look to come up with an explanation for the outage. Has anyone experienced similar behavior? Is there something I should be checking that I haven't mentioned? 

Create initially empty tables to store the data in a sane way. Create triggers on the old tables which can sync the data with the new ones. Export the data from the old tables to the new tables & enable the triggers. Replace the queries one by one. 

Using this strategy I will have 2 synced databases after step 3. Initially all queries will go to the old database, but while I'm updating the queries slowly the old database will be used less, and the new one more. Taking this "sub-optimal" situation in mind, is this a good strategy to fix some of the problems? What things should I take into consideration while doing this? Note that I fully understand that this is a very risky suicide mission. However, I'll have to do something in a short amount of time, otherwise the website becomes entirely unusable. 

I'm not certain about the service broker que but it is possible to setup a user without a login. This user will not be able to authenticate but you can still assign the user rights. The examples below are from the microsoft article for createing users $URL$ D. Creating and using a user without a login The following example creates a database user CustomApp that does not map to a SQL Server login. The example then grants a user adventure-works\tengiz0 permission to impersonate the CustomApp user. 

I was trying to connect to a secondary instance on the server. If I use the primary instance this appears to work. Is there a way to use the secondary instance? I have the secondary instance port open but it is not of course using 1433. 

I have a messages table in a database, which include a sender id and a message type (and of course many more columns not relevant for this question). I try to create a query which counts how many messages of each type a user have send. e.g. if I have the following table: 

So in fact I want to group by message_type and user_id, but instead of generating multiple rows per user, I want to create multiple columns, one for each message_type Can I achieve this without hardcoding the message types in my query? 

However, I already defined using my keys that table1.a references to table2.b, so it seems to me that it shouldn't be to hard to make a DBMS system automatically use table1.a and table2.b as the join columns, such that one can simply use: