$X(x,0)=(0,x)$ for all $x>0$. For $x\in (0,1)$, the trajectory starting at $(x,0)$ follows a vertical line until it passes through the point $(0,\frac 1{1-x})$, and then travels counter-clockwise around the origin until it returns to $(x,0)$. The trajectory starting at $(1,0)$ never leaves the vertical line $x=1$. The trajectory starting at $(x,0)$ for any $x>0$ is non-periodic. 

Let Σp={1,...,p}ℤ be the full shift on p symbols, and let X ⊂ Σp be a subshift -- that is, a closed σ-invariant subset, where $\sigma\colon \Sigma_p\to \Sigma_p$ is the left shift. Then σ is expansive, and hence there exists a measure of maximal entropy (an mme) for (X,σ). It is well known that if X is a subshift of finite type on which σ is topologically mixing, then there is a unique mme. (See, for example, Rufus Bowen, Equilibrium states and the ergodic theory of Anosov diffeomorphisms, 1975. In fact, Bowen proves uniqueness of equilibrium states for any Hölder continuous potential φ, but let's stick with the case φ≡0 for now.) If X is not a subshift of finite type, then less is known. For example, if X is a β-shift, then it has a unique mme, but it is not known if this holds for subshifts that are factors of a β-shift. Question: Does anybody know of a subshift that is topologically mixing but does not have a unique mme? (That is, a subshift that has multiple measures of maximal entropy despite being topologically mixing.) 

Hahn and Katznelson, "On entropy of uniquely ergodic transformations", Trans. AMS 126 (1967) 335-360 C. Grillenberger, "Construction of strictly ergodic systems I. Given entropy", Z. Wahrscheinlichkeitstheorie 25 (1972/1973) 323-334 

This is the pentagram map, about which much is known. Not by me, or I would give a nicer summary. But the Wikipedia article has plenty of references. In a quick scan of it I don't see a direct answer to your specific question about the limit after rescaling. It seems that usually the polygons are considered up to projective equivalence, and then the pentagram map is integrable. 

Here's my understanding of the intuition behind the Hilbert metric's utility for Perron-Frobenius. (I don't have access to Birhoff's paper handy so I'm not sure to what extent I'm just duplicating what's there.) (1) As Suvrit's comment pointed out, since studying eigenvectors of $A$ is really a projective question, it is completely natural to consider a metric on the projectivization of $\mathbb{R}_+^n$, so that we are considering lines $\ell$ through the origin into the positive orthant. (2) For our metric to be useful, we should be able to compute $d(\ell_1,\ell_2)$ in terms of $x_1,x_2$ for some (any) $x_i\in \ell_i$. This should be independent of the choice of $x_i$; replacing $x_i$ with another point on $\ell_i$ should not change the value of $d$. At the risk of being a little bit vague, this replacement is a kind of projective transformation, and so it is natural to ask our metric to be associated to a projective invariant. (3) The most fundamental projective invariant is the cross-ratio. Given four collinear points $x_1,x_2,x_3,x_4$, the cross-ratio is $$ (x_1,x_2;x_3,x_4) = \frac{|x_3 - x_1|}{|x_3-x_2|} \cdot \frac{|x_4-x_2|}{|x_4-x_1|}\qquad\qquad (*) $$ (4) A cross-ratio requires four points but a metric only has two points as input. So given $x_1,x_2\in \mathbb{R}_+^n$, we need to choose two other points that are collinear with $x_1,x_2$. Let $L$ be the line through $x_1,x_2$; the only other natural reference points to choose on $L$ are the points where it intersects the boundary of the positive orthant; that is, the two points $x_3,x_4\in L$ where one (or more) of the coordinates vanishes and the rest are positive. (5) With $x_i$ as above, note that $(x_1,x_2; x_3,x_4)$ is equal to 1 iff $x_1=x_2$ (since we always have $x_3\neq x_4$) and so to produce something with the right scaling for a metric we should put $d(x_1,x_2) = |\log(x_1,x_2;x_3,x_4)|$. This defines the Hilbert metric. (6) It remains to get some intuition for why the Hilbert metric is a natural choice for something that is contracted by $A$. First note that since the quantities $x_i-x_j$ in $(*)$ are all scalar multiples of each other, we have $(Ax_1,Ax_2;Ax_3,Ax_4) = (x_1,x_2;x_3,x_4)$. Let $x_3',x_4'$ be the boundary points for the line through $Ax_1,Ax_2$, so that we have the following picture; note that this is where we use positivity of $A$ to guarantee that boundary points of the positive orthant ($x_3,x_4$) are mapped into the interior. 

If a map $f$ is Lipschitz, then it is a standard result in dimension theory that $\dim_H f(Z) \leq \dim_H Z$ for all $Z$. More generally, if a map $f$ is Hölder with exponent $\alpha \in (0,1]$, then one has the inequality $$ \dim_H f(Z) \leq \frac 1\alpha \dim_H Z. \qquad \qquad (*) $$ The proof of this uses the same sorts of calculations as in Anton's answer. Now the function $f$ that you describe has the property that there is a Cantor set $C$ such that $f$ is locally constant on the complement of $C$. The complement of $C$ is open, and hence is a countable union of open intervals, so its image under $f$ is a countable set. In particular, this implies that $f(C)$ is the entire interval $[0,1]$ with an at most countable set removed. Thus $\dim_H f(C) = 1$, and if $f$ were Hölder continuous with exponent $\alpha>0$, the inequality in (*) would give $$ 1 = \dim_H f(C) \leq \frac 1\alpha \dim_H Z = 0, $$ a contradiction. 

Background and motivation: Consider the cone $C\subset \mathbb{R}^d$ of vectors with non-negative components, and let $\Delta\subset C$ be the simplex of probability vectors (those for which $\sum v_i = 1$). The cone (and hence the simplex) can be equipped with the Hilbert metric, which has applications to Perron-Frobenius theory, among other things. In these applications, the following step is important: given a $d\times d$ stochastic matrix $A$ with strictly positive entries, one has $A\Delta\subset \Delta$, and one wishes to estimate the diameter of $A\Delta$ in the Hilbert metric. Using some explicit formulas for the Hilbert metric, it can be shown that $$ (1)\qquad\qquad \mathrm{diam}(A\Delta) = \sup_{v,w\in\Delta} d(Av,Aw) = \max_{i,j} d(Ae_i,Ae_j), $$ where $e_i$ are the standard basis vectors. Geometrically, this can be stated as follows: the diameter of $A\Delta$ is achieved by considering only its extreme points. The proof of (1) that I know relies on some matrix computations and doesn't feel particularly geometrically informative. It uses the characterisation of the Hilbert metric in terms of a partial order -- there is also a characterisation of the Hilbert metric in terms of a cross-ratio. In the present case it boils down to fixing two points $x,y\in C$, letting $w,z$ be the points at which the line through $x,y$ intersects $\partial C$, and setting $d(x,y)$ to be the log of the cross-ratio of $w,x,y,z$. I wonder if there is a more geometric proof of (1) using this description of $d$. This motivates the following question, which can be stated without reference to the Hilbert metric but would (1). Question: (can be read independently of the above) Let $\Delta,\Delta'$ be simplices of the same dimension and suppose that $\Delta'\subset \Delta$. Let $\ell$ be a line that intersects $\Delta'$ in an interval. Let $x,y\in \Delta'$ be the endpoints of this interval, and let $w,z$ be the points where $\ell$ intersects $\partial \Delta$. Let $\Theta(\ell)$ be the cross-ratio of the points $w,x,y,z$. Compactness of $\Delta'$ implies that there exists $\ell$ maximising $\Theta$. (We assume that $\Delta'\cap\partial\Delta=0$ so that $\Theta<\infty$.) It can be shown that the supremum is attained when $\ell$ is one of the edges of $\Delta'$, but the proof I know is non-geometric. Is there a geometric proof of this fact? 

In the setting you describe, for each $\alpha \in (0,1)$ the $(1-\alpha,\alpha)$-Bernoulli measure is the unique measure achieving the maximum. The function $\alpha \mapsto \eta(\alpha)$ is the Legendre transform of the function $t\mapsto P(t\phi)$ where $\phi(x) = x_0$ and $P$ is topological pressure. This is all part of the "multifractal analysis" of the system: see this other question and my answer there for some references and some more explanation. As for the Hausdorff dimension of $K_\alpha'$, it's given by $\eta /\log 2$, since $\log 2$ is the Lyapunov exponent of the doubling map $f$, and binary expansions are codings of trajectories under $f$. Informally this follows from the relationship dimension = entropy / exponent; to make this a little more precise you can consider Bowen's equation, which gives Hausdorff dimension of a set $E$ as the unique root of $t\mapsto P_E(t\phi)$, where $P_E$ is topological pressure, but this time defined for sets that need not be compact or invariant, using the definition of Pesin-Pitskel (following Bowen's noncompact entropy definition); see this other question for some more details and references. 

Question. What is the broadest class of measures for which the inclusion $G_\mu \subset Z_\mu$ holds -- that is, for which genericity for Birkhoff averages of continuous functions implies genericity for local entropies? Does this hold for all ergodic measures? If it does not, is there a natural class of measures beyond the Gibbs measures (and various notions of weak Gibbs measures) for which it does hold? Related question. Gibbs measures (and weak Gibbs measures) have the property that there exists a function $\phi\in C(X)$ such that $h_\mu(x)$ is completely determined by $\frac 1n S_n \phi(x)$ for every $x\in X$. (Not just for a full measure set of $x$ -- this is true for all ergodic measures.) Is there an example of a measure $\mu$ such that there is no single function $\phi\in C(X)$ whose Birkhoff averages determine $h_\mu(x)$, but there exist two function $\phi_1, \phi_2\in C(X)$ such that $h_\mu(x)$ is completely determined by $\frac 1n S_n \phi_i(x)$ for $i=1,2$? 

As indicated in the comments, measurability alone is not enough, and there are easy counterexamples. As for a condition between continuity and measurability that still does the trick, I'm not sure if there's a natural one. Using Lusin's theorem one can prove that Condition (C) below is equivalent to existence of an invariant measure, but it's not a particularly pleasant condition, as you'll see. Here we assume that $\Omega$ is a complete separable metric space (not necessarily compact), and $f\colon \Omega\to \Omega$ is measurable (nothing more yet...) (C) There exist a sequence of points $x_k\in \Omega$ and times $n_k\in \mathbb{N}$ such that for every $\epsilon>0$ there is a compact set $K_\epsilon\subset \Omega$ satisfying: (1) $f|_K$ is continuous, and (2) $\#\{1\leq j\leq n_k \mid f^j(x_k) \in K_\epsilon\} \geq (1-\epsilon)k$ for all sufficiently large $k$. If you have an invariant measure, you can use the ergodic decomposition to get an ergodic measure, and then the Birkhoff ergodic theorem together with Lusin's theorem to show that (C) holds. On the other hand, if (C) holds then by considering the empirical measures $\mu_k = \frac 1{n_k} \sum_{j=0}^{n_k} \delta_{f^jx_k}$ one can observe the following: 

Numerical experiments suggest that the behaviour observed for one-dimensional maps -- namely, existence of chaotic behaviour for a positive measure set of parameters together with open sets of parameters with regular behaviour -- occurs more broadly than just in this setting. But rigorous results are quite hard to come by. One final remark: You don't need nonlinearity to get chaotic behaviour, but for a linear system you do need non-trivial topology. The doubling map $x\mapsto 2x \pmod 1$ has all the chaotic behaviour you could want, but relies on the non-trivial topology of the circle; similarly, the Arnold cat map $x\mapsto \begin{pmatrix} 2 & 1 \\ 1 & 1 \end{pmatrix}x \pmod {\mathbb{Z}^2}$ as a map on the two-torus is both linear and chaotic. 

The answer is very different depending on whether one considers the space of $C^1$ maps or the space of $C^2$ maps. I won't go into the reasons for this. Let's consider $C^2$ maps, which is where I know more - other people are more familiar with the $C^1$ case. There is a series of conjectures due to Jacob Palis which address the question in this general formulation (see "A global view of dynamics and a conjecture on the denseness of finitude of attractors", in Géométrie complexe et systèmes dynamiques (Orsay, 1995), Astérisque, 2000, pp. xiii-xiv, 335-347). These conjectures are very hard and not too much is known in full generality. Rather more can be said in specific classes of examples. In particular, one-dimensional maps are reasonably well-understood. If one considers the case where $M=[0,1]$ is an interval and $\{f_\lambda \mid \lambda\in [a,b]\}$ is a one-parameter family of smooth maps satisfying certain technical conditions -- in particular, the family of logistic maps $f_\lambda(x) = \lambda x(1-x)$ satisfies these with $\lambda\in [0,4]$ -- then the following is known. 

The most well-understood examples are the ones you mention: Axiom A diffeomorphisms and Markov maps of the interval, since these can be modeled by SFTs. Note that "Bernoulli" refers to a particular choice of invariant measure; the SRB measure for an Axiom A attractor (or the ACIP for a Markov interval map) is Bernoulli, but other invariant measures, such as periodic orbit measures, need not be. More generally, given a system modeled by an SFT, equilibrium states for Hölder continuous potentials are always Bernoulli. (Recall that these are invariant measures $\mu$ that maximize the quantity $h(\mu) + \int\phi\,d\mu$, where $h(\mu)$ is Kolmogorov-Sinai entropy and $\phi\colon X\to \mathbb{R}$ is the potential function.) Beyond this, I know of basically two classes of examples that are known to be Bernoulli; both are "non-uniformly hyperbolic" in some sense. The first class contains systems that can be modeled by a Young tower or a countable-state Markov shift, where the measure is an equilibrium state for some sufficiently regular potential function; this includes the case where the measure is SRB, in particular when the measure is smooth. For example, this includes any positive entropy equilibrium state for a Hölder continuous potential on a surface diffeomorphism, thanks to recent work of Omri Sarig (JAMS 2013, JMD 2011). In fact, if the measure is smooth and has non-zero Lyapunov exponents, then you don't need to build a Young tower or a countable-state Markov shift; for measures like this ("hyperbolic" measures), Bernoullicity was proved by Yakov Pesin in 1977. In particular, this includes Liouville measure for geodesic flow of a compact surface of genus at least two without focal points (of course this is continuous-time rather than discrete-time as you asked for). The result for smooth invariant measures was extended to SRB measures by Ledrappier in 1984 (he also did ACIPs for interval maps without any Markov assumption). 

Define a random variable $Y\in \{0,1\}^N$ by $P(y_i^{(n)}=1) = \epsilon$ for all $1\leq i\leq N$ and $n\in\mathbb{N}$ and observe that $x_i^{(n)} \geq y_i^{(n)}$ for all $i,n$ (as long as $X,Y$ are being driven by the same random process). With probability 1 there exists a time $n$ such that $y_i^{(n)}=1$ for all $i$ (since all the events are independent and the lattice is finite), and then from this time on $X$ is in the state where every $x_i=1$. 

Edit: As pointed out in the comments the references I gave above do not really answer the question directly. For the sake of notation let me write $K_\alpha$ for the level set above, and $T(\alpha) = \sup \{ h(\mu) \mid \int\phi\,d\mu=\alpha\}$. Then many of the main results in the references are of the form "$h(K_\alpha) = T(\alpha)$ under certain conditions". Which is not quite the same as describing how to compute the measure maximizing $T(\alpha)$, which is what you asked. The result in my Nonlinearity paper that I linked to describes a proof that $T(\alpha)$ is the Legendre transform of the pressure function $t\mapsto P(t\phi)$, which comes a little closer to the mark; the proof there contains a proof that there is some equilibrium state $\mu$ for some potential that achieves the maximum in $T(\alpha)$. But the way that it is written is opaque enough that I can't really claim it answers your question. So let me extract the relevant bits in the case when $\phi$ is Hölder. Then the function $S(t) := P(t\phi)$ is differentiable in $t$, and $S'(t) = \int\phi\,d\mu_t$, where $\mu_t$ is the unique equilibrium state for $t\phi$. Using convexity properties of $S$ one can argue that $S'(t)$ takes all values in the interior of $\{ \int\phi\,d\nu \mid \nu \text{ is invariant}\}$. In particular, there is $t$ such that $S'(t)=\alpha$, and then one can show that $h(\mu_t) = T(\alpha)$, so that $\mu_t$ is the measure you want. As long as your system is such that you can write down $S'(t)$ explicitly, solve for $t$, and then describe $\mu_t$, then this gives you a pretty concrete algorithm for finding the conditionally maximizing measure. My understanding is that the argument in the previous paragraph is implicit in a lot of work on multifractal formalism. But as illustrated by my earlier attempt at giving references, it's not always stated in a form that is readily useful for answering your specific question. 

Given some class of objects, a property P is called "hereditary" if it is such that whenever X has P and Y is a subobject of X, then Y has P as well. (At least, this is my understanding of the meaning of "hereditary" -- please correct me if I'm wrong.) Is there a word in common usage to describe a property that is passed to factors? That is, what word should we use to describe a property P such that whenever X has P and Y is a factor of X, then Y has P as well? Edit: By "Y is a factor of X" I mean that there is a surjective map $\pi\colon X\to Y$ that preserves the structure of the objects $X$ and $Y$ (whether the structure is that of a group, a topological space, a dynamical system, or whatever else you may be interested in). As pointed out in the comments, this may also be called a quotient in some contexts. In the setting I'm most interested in, $X$ and $Y$ are topological dynamical systems -- compact metric spaces with continuous maps $f\colon X\to X$ and $g\colon Y\to Y$ -- and $\pi$ preserves the dynamics in the sense that $\pi\circ f = g\circ \pi$.