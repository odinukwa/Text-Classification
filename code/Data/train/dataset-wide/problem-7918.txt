Another reason to avoid conflating equality with equivalence: whether two formulas are equal should only depend on the formulas themselves. But formulas can become equivalent after some other set of axioms has been assumed, and the equivalence can depend on exactly which other axioms are assumed. For an elementary example in the language of rings, let $\phi$ say "there are no zero divisors" and let $\psi$ say "every element has a multiplicative inverse". These are not the same formula, trivially. If we assume all the ring axioms and we also assume that there are no more than (say) 16 elements, the formulas become equivalent by Wedderburn's theorem. But if we do not assume the ring axioms, the formulas are not equivalent. For example, I could make a model with three elements {0,1,2} such that for all $x,y$ we have $xy = 2$, and this would satisfy $\phi$ but not $\psi$. Of course this is not a ring – that's the point. Or, we could assume the ring axioms but not assume there are only a finite number of elements, and again the formulas will be inequivalent. (The reason for picking 16 is to avoid a technicality with first-order logic. For each $n$ there is a sentence which says that there are no more than $n$ elements, but there is no single sentence which says there are only finitely many elements. One can try to work around this by switching to the language of set theory, but that complicates things in other ways.) 

The theory $T$ could be ZFC set theory, or it could be a weaker theory such as second-order arithmetic. The main point of the theory is to give some syntactical tools for manipulating the ordered field axioms and the statements of $P$ and $P'$. For example, if $P$ is the axiom of completeness (every nonempty bonded set has an supremum), the theory $T$ needs to guarantee some sets exist. To establish positive results of the quoted form, you simply write a proof in $T$ of the desired result. The more difficult thing is to establish negative results, and this is the first time you have to think about semantics. To prove the negation of the quoted statement, it suffices to have: 

If $\text{Hom}(S,S/2)$ refers to maps of degree zero, then that group is $\mathbb{Z}/2$. However, $\text{Hom}(S[2],S/2)$ is $\mathbb{Z}/4$, as is $\text{Hom}(S/2,S/2)$. (My sign convention for the shift is such that $S[n]$ is the sphere $S^n$.) On the other hand, $\text{Hom}(S/2,S/2[i])$ will be zero for $i>1$ but nonzero for most $i\leq 1$. 

One point that I don't think anyone has mentioned yet is that $\mathbb{C}_p$ is isomorphic (as an untopologised field) to $\mathbb{C}$. More generally, any two uncountable algebraically closed fields of the same characteristic and cardinality are isomorphic, if I remember correctly. Of course the proof is horrendously non-constructive, but the very definition of $\mathbb{C}_p$ is already horrendously non-constructive. So instead of worrying about what $\mathbb{C}_p$ is, you can instead worry about why $\mathbb{C}$ admits a $p$-adic metric with respect to which it is complete. I don't have anything to offer about that. [Corrected as per Johannes Hahn's comment] 

I have put some notes about operads at $URL$ They are not finished (in particular, very many references are missing), but sections 13 and 14 are in reasonable shape, and they should answer your questions. They are written in terms of symmetric operads, so my $K(n)$ consists of $n!$ copies of the Stasheff polytope. I have also put another note at $URL$ This one shows that various things I had hoped to do with the Stasheff operad are probably not possible. 

In the simply connected case, essentially everything is in principle computable, by some very early work of E.H. Brown: 

Surely this is formal? I have drawn the diagram but sadly I cannot get MathJax to display it. Update: Just to be clear about notation, I'll write $\mathcal{C}(X,Y)$ for morphism sets in $\mathcal{C}$, and $Hom(A,B)$ for morphism sets in $Ab(\mathcal{C})$. An object $A\in Ab(\mathcal{C})$ has a natural abelian group structure on $\mathcal{C}(T,A)$ for all $T\in\mathcal{C}$. Naturality means that $q\circ p+r\circ p=(q+r)\circ p$ for all $p:S\to T$ and $q,r:T\to A$. Now let $B$ be another object of $Ab(\mathcal{C})$. A morphism in $Ab(\mathcal{C})$ from $A$ to $B$ is just a morphism $f:A\to B$ in $\mathcal{C}$ with the property that $f\circ(p+q)=f\circ p+f\circ q$ for all $T$ and all $p,q\in\mathcal{C}(T,A)$. Now suppose we have such morphisms $f,g:A\to B$ and $h,k\:B\to C$. We then have $ (f+g)\circ(p+q) = f\circ(p+q) + g\circ(p+q) = f\circ p + g\circ p + f\circ q + g\circ q = $ $ (f+g)\circ p + (f+g)\circ q $ (using the naturality of addition, the homomorphism property of $f$ and $g$, and then naturality again). This shows that $f+g$ is again a homomorphism. A similar argument shows that $h\circ f$, $h\circ g$ and $h\circ(f+g)$ are homomorphisms. We have $h\circ(f+g)=h\circ f+h\circ g$ by the homomorphism property of $h$. We also have $(h+k)\circ f=h\circ f+k\circ f$ by the naturality of addition. 

Andrej Bauer points out that predicative constructions are more explicit, and give more useful computational information, than impredicative ones. This has two further consequences that are of interest. I want to point these out as an answer to the implicit question asked by "alephomega". 

(1) Many graduate programs have a relatively fixed curriculum for first year students. Some require courses to prepare you to pass exams, others require courses for exams you don't do well enough on when you arrive. So you may not have complete freedom when you arrive, and only an advisor at the school you are going to can help you with that. (2) If you are going into a PhD program, you should keep in mind that you will need to transition relatively quickly into a specialization (within a couple years at the longest). You have to write a dissertation for a PhD, and that means finding a thesis advisor and taking specialized courses to prepare. How quickly this transition happens depends, again, on what school you are going to. 

The fact that the second incompleteness theorem refers to consistency is important for several applications, both philosophical and mathematical. Philosophically, the second incompleteness theorem is what lets us know that we cannot, in general, prove the existence of a (set) model of ZFC within ZFC itself. This is a fundamental obstruction to naive methods of proving relative consistency results. We cannot show, for example, that the continuum hypothesis is unprovable in ZFC by constructing a set model of ZFC where CH fails using methods that themselves can be formalized in ZFC. Philosophically, this says we should not be surprised that the relative consistency results that we do have require methods that cannot be formalized within ZFC. Second, there are some theorems (perhaps less well known) that leverage the second incompleteness theorem to prove the existence of special kinds of models. These are mathematical results, not philosophical ones. Theorem (Harvey Friedman). Let $S$ be an effective theory of second-order arithmetic that contains the theory ACA0. If there is a countable ω-model of $S$, then there is a countable $\omega$-model of $S$ + "there is no countable $\omega$-model of $S$." The proof proceeds by showing that, if the conclusion fails, a certain effective theory obtained from $S$ is consistent and proves its own consistency. The type of model constructed by the theorem is useful for proving that certain systems of second-order arithmetic are not the same. 

For endomorphisms of $F_m$ one should consider the ring of numerical polynomials: $$ P = \{f(a)\in \mathbb{Q}[a]: f(\mathbb{Z})\subseteq\mathbb{Z}\} $$ The functions $b_i(a)=\left(\begin{array}{c}a\\ i\end{array}\right)$ give a basis for $P$ over $\mathbb{Z}$, with $$ b_ib_j = \sum_{m=\max(i,j)}^{i+j} \frac{m!}{(m-i)!(m-j)!(i+j-m)!} b_m. $$ We have a series $f(x)=\sum_{i>0}b_ix^i\in P[[x]]$ (which is morally "$(1+x)^a-1$") satisfying $$ f((1+x)(1+y)-1)=(1+f(x))(1+f(y))-1. $$ In other words, $f$ is an endomorphism of $F_m$. Any endomorphism of $F_m$ over any ring $R$ arises by applying some homomorphism $P\to R$ to the coefficients of $f(x)$. Now let $R$ be an algebra over $\mathbb{Z}/p$. Consider the map $\mathbb{Z}\to R[[x]]$ given by $a\mapsto (1+x)^a-1$. This is continuous for the $p$-adic topology on $\mathbb{Z}$ and the $x$-adic topology on $R[[x]]$. This allows us to define $(1+x)^a-1$ for all $a\in\mathbb{Z}_p$, and this is still an endomorphism of $F_m$. For a more complete story, we should consider $P/p$. One can identify this with the ring of continuous maps $\mathbb{Z}_p\to\mathbb{Z}/p$ (where $\mathbb{Z}_p$ has the $p$-adic topology, and $\mathbb{Z}/p$ has the discrete topology). To understand this, put $T=\{u\in\mathbb{Z}_p:u^p=u\}$. It is known that the reduction map $T\to\mathbb{Z}/p$ is bijective; the inverse map $\tau\colon\mathbb{Z}/p\to T$ is the Teichmuller lift map, given by $\tau(u)=\lim_ku_0^{p^k}$ for any lift $u_0$ of $u$. Given any element $a\in\mathbb{Z}_p$ there are unique elements $c_k(a)\in\mathbb{Z}/p$ such that $a=\sum_k\tau(c_k(a))p^k$. The functions $c_k$ are continuous, so they give elements of $P/p$. In fact, we find that $$ P/p = \mathbb{Z}/p[c_0,c_1,c_2,\dotsb]/(c_k^p-c_k). $$ Any homomorphism from this ring to $R$ will give an endomorphism of $F_m$ defined over $R$. All of the above can be extracted from the literature on operations and cooperations in complex $K$-theory and its $p$-adic completion. 

The original definition of operads involves maps $$ \gamma\colon C(n) \times \prod_{i=1}^n C(k_i) \to C(\sum_ik_i) $$ There is an alternative definition in terms of maps $$ \circ_i \colon C(n) \times C(m) \to C(n+m-1). $$ It is not hard to outline an argument that the two definitions are equivalent (subject to some assumptions about $C(0)$ and $C(1)$; various choices of details are possible). Have the details been spelled out carefully somewhere? I have seen this called an "observation", but that seems a little blasé to me. 

The axiom system PRA of "primitive-recursive arithmetic" is finitistic, but it has been known for a few decades that it has the same set of $\Pi^0_1$ consequences as the infinitistic theory $\text{WKL}_0$ of second-order arithmetic. In particular, there is a primitive recursive function $f$ that turns a formal proof of a $\Pi^0_1$ statement in $\text{WKL}_0$ into a proof in PRA. Roughly put, a $\Pi^0_1$ formula says that all natural numbers have some particular property, depending on the formula, where the property can be stated using a formula in the language of rings with no quantifiers. The advantage of working in $\text{WKL}_0$ is that the proofs can be much shorter. I think this was always suspected, but Caldon and Ignjatovic recently established (pdf) a formal superexponential lower bound for $f$, at least on an infinite set of formulas. Their result is phrased for a different infinitary system, $I\Sigma^0_1$, that lies between PRA and $\text{WKL}_0$. $I\Sigma^0_1$ is a fragment of Peano arithmetic, unlike $\text{WKL}_0$; its main difference from PRA is that $I\Sigma^0_1$ allows direct universal quantification over the set of natural numbers during the proof, while PRA does not. In their paper, the set of formulas for the lower bound is explicitly laid out. These may not be particularly concrete, because they relate to consistency statements. If we expand PRA to allow for existential quantification, we can get a slightly larger theory in which $\Pi^0_2$ statements can be expressed. It is known that $\text{WKL}_0$ is still conservative over this larger theory for $\Pi^0_2$ statements. In 1994, Kikuchi and Tanaka (pdf) gave a nice example of how this could be used to show that the second incompleteness theorem is provable in PRA, by using model-theoretic, infinitary methods in $\text{WKL}_0$ and relying on the conservation result. 

Here's a nice example for André's simplified question. Consider the interval $X=[-1,1]$ with $0$ as the basepoint. Suppose there was a continuous monoid structure $m:X^2\to X$ with $0$ as the identity element. Suppose that $u<0$ and $v>0$; then we can apply $m$ to the piecewise-linear path $(0,u)\to(v,u)\to(v,0)$ to get a path from $u$ to $v$, which must pass through $0$ by the intermediate value theorem. It follows that either $u$ or $v$ must be invertible. From this we deduce that either all positive numbers are invertible, or all negative numbers are invertible; wlog the former. Now for $0\leq t\leq 1$ the maps $m(t,-):X\to X$ are homeomorphisms, so they preserve the boundary $\{-1,1\}$. As $m(0,-)$ is the identity on the boundary, the same must be true of $m(t,-)$ (for $0\leq t\leq 1$). In particular we have $m(t,1)=1=m(0,1)$, but $1$ is invertible so $t=0$, which is a contradiction. Now let $X$ be an arbitrary tree with finitely many edges. If $a\in X$ is not a boundary point then $X\setminus\{a\}$ will be disconnected and we can run the same kind of argument with the different connected components to see that there is no monoid structure with $a$ as the identity element. If $a$ is a boundary point then there may be a monoid structure; for example, the set $X=\{z\in\mathbb{C}:z^n\in [0,1]\}$ is a tree which is a submonoid of $\mathbb{C}$ under multiplication. My guess is that for more general trees there is no monoid structure but I do not see a proof at the moment. 

I have a metric space with the following property (a bit like having unique geodesics): for any points $a,b,x,y$ with $d(a,b)=d(a,x)+d(x,b)=d(a,y)+d(y,b)$ and $d(a,x)=d(a,y)$, we have $x=y$. Is there an established name for this? (UPDATE: the condition $d(a,x)=d(a,y)$ was omitted by mistake in the original question.) 

What is any large branch of mathematics "really" about? In one sense the question is overly naive if it assumes all computability theorists are motivated by the same thing. Any large branch of mathematics must have numerous specialized areas of study, and several different motivations, if it is going to support a large research community. With that said, the list of topics for the CIE 2010 conference at [1] is so long that it's natural to be confused about what the topic actually is. There are a few threads that go across most of computability theory: 

Hindman's theorem is of interest as a purely combinatorial result, but also because it is so closely related to results of topological dynamics such as the Auslander--Ellis theorem. 

I'm not sure, but maybe the question is why a non-ω-model of ZFC must have infinite decreasing $\in$ chains. This follows from two facts: 

Simpson, Subsystems of Second-Order Arithmetic, states an analogue of the normal form theorem that is provable in $\mathsf{RCA}_0$: 

I was also going to point at the SEP article $URL$ , which does a good job of explaining the differences. Unfortunately, while Russell and Whitehead had a great influence on logic, their actual work in Principia did not. The system they used in that book is mostly of historical interest, is not covered in any contemporary texts, and as far as I can see is not well known to contemporary mathematical logicians. Here's a one-paragraph summary answer, though. The things we usually call types will now be called "unramified types." Ramified type theory splits each unramified type into a whole sequence of types, so that the "ramified type" of an object depends not just on the unramified type but also on how that object is defined. The closest thing to this in modern logic is the stratification of sets into the cumulative hierarchy, where each set is assigned an ordinal number based on how many iterations of powerset are required to construct it from the empty set. But set theory is very different from type theory, so this is an analogy at best. A similar ramification issue was present in Paul Cohen's original presentation of forcing in set theory, which is now called ramified forcing ( $URL$ ). However, this was quickly recast in unramified terms so that the ramified version is (again) of primarily historical interest.