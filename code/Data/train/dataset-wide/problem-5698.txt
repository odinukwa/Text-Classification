I'm probably not getting this. Doesn't it hinge entirely on whether "true" and "false" are determined by a independent physical correlation? In the case of "the room is dark" or "the room is light" the beliefs and responsive brain states can correlate T/F, even if negatively. But beliefs need not correlate to external physical states, and brain states cannot correlate to independent states. Beliefs can be overdetermined, underdetermined, or self-referencing, as in "I believe in God," which has nothing to do with any external, independent condition, yet can be "true." The external references can be physicalized, but the "self-references," that presumably indicate consciousness, cannot. On the other hand, I do not see how a brain state can be "false" without reference to an independent system, in which case there is presumably no physical causation... apart from spooky actions, say. 

Certainly. This can be expressed in many ways. Kant, for example, develops both reason and moral freedom around the idea that all human beings or rational beings must be treated as "ends in themselves" never as means only. Most theologies or philosophies with a moral dimension have something akin to this assumed "intrinsic value" of human life. Your question then becomes, does this also extend to all life? Buddhism, for example expressly extends this value to "all sentient beings," which probably does not include plants or bacteria. The Pythagoreans extended such value to some plants, beans for example. And here we simply run into the ecological interdependency of life and even the definition of "life." We cannot live without consuming other forms of life. Does that mean we "value" them or that they have "intrinsic value"? I think it must almost be an a priori assumption that life "values" life, since it depends on it, and that only living things can "value" things, both living and nonliving things. So anything we might call a value system does assume an "intrinsic value" of life, if only to avoid internal contradiction. But such a general, universal "value" is nearly empty of content. It would not tell you whether or not to kill eat beans or kill Persians. Perhaps a better way to approach the question is in reverse. What sort of value system might value something more highly than "life itself"? Can we imagine anything of such value that we would consider eliminating all life to preserve or advance it? The idea comes very close to absurdity. Nonetheless, it has been a source of some compelling thinking, as in Nihil Unbound by Ray Brassier. We might imagine some sort of God or otherworld or afterlife or even AI singularity that is of higher value than "this life." ISIL, for one, appears to doctrinally destroy "this life" in favor of another. Marxists might argue that Capitalism, if it can be said to have a philosophy, progressively transforms life itself or "species being" into nonliving goods, machinery, and waste. Thus self-accumulating Capital enmeshes us in a higher value than "life itself." But even these examples are not so much negating life itself, as imagining life in a more "valuable" form.The nihilist or even the Schopenhauerian pessimist may see no intrinsic value in this life or that life or even human life per se. But in my view to say "life itself has no intrinsic value" is simply nonsensical. So we might say that all philosophies, all forms of communication, presuppose an "intrinsic value of life" as the basis of any sort of evaluation or judgment whatsoever, philosophical or otherwise. 

One does not have to go as far as logical positivists or even to atheists to find "analytical dissolutions" of the problems of philosophy and religion. In his Third Antinomy, I believe, and elsewhere, Kant demonstrates that logic or "analytical" methods cannot prove the existence of God nor the opposite. He in effect "dissolves" the problem as a suitable object of dialectic. Of course, Kant himself did believe in God as a "necessary postulate" of practical reason and moral behavior. He simply placed the whole problem outside of analytical methods. 

While I see the question is programming territory and I defer to all answers above, here is an alternate perspective, for what it's worth. Being is axiomatic to whatever world or "system" is given. Specific beings can be "subtracted" and "remembered," shifting their ontological status to former beings. But no system, no matter how simple or complex, can introduce anything that does not "have" being. Kant, in some ways the father of systems, summarizes this by claiming: existence is not a predicate. I know nothing about programming, but this may be a problem if being or is-ness is confused with the distinction equals, (=). Quite obviously 1 + 1 is not identical to 2. Anyone can see the difference. Both exist, each one is and both are. Both are admitted into the system. Yet their equality (=) also differentiates them. To "the system," so to speak, that differentiation is all that matters. All predicates or sets of properties that things "have" differentiate, exclude, enclose identities. All properties "make a difference," to use Bateson's apt phrase. They are differences that "make a difference." One may say that things "have" being or existence. But within any universe or "system" this "makes no difference." So, when we shift between ontologies or "what can exist" we shift between incommensurable systems. We start anew. Sorry, this may appear as total nonsense from your perspective. But I thought it might add to the imaginative component. 

This is actually quite an interesting problem, unique to the modern problem of representative democracy itself. First, modern democratic societies generally hold individual subjects (and their individual "souls") morally and legally accountable. We rule out collective accountability of families, generations, races, as were common in premodern societies. This is why Trump's proposals to kill the families of terrorists or Israel's destruction of the family homes of Palestinians appear repugnant and regressive. Second, as Trump and Netanyahu might retort, this is the case only within nations and not between nation-states in conditions of war, which then brings in all the complexities of wartime conventions, which even the United States has begun to abandon...if only unilaterally. If, for example, Americans elect a president who kills some 200,000 Muslims in acts of war, then are jihadis justified in targeting American civilians as responsible voters? Conversely, in countries without representative democracy, are citizens less responsible for violent acts of their leaders and militaries? In the case of representative democracy, of course, voters are not entirely passive. There is an enfranchisement and "act" for which they could be held accountable. Yet they are not moral agents or "wills" continuous with those who represent them. Once power is invested in the representative, moral autonomy is dispersed. Even with powers of immediate censure or impeachment voters can only respond to moral acts already undertaken. There would seem to be a kind of limited and partial culpability. This might inevitably get "generalized" beyond individuals in states of war. Morality does not seem to fit well with modern statistical contexts. The question of class and revolution is somewhat different. A class may be defined as functioning more or less consciously in its own interests. In republics with serfdom, slavery, extreme property or gender inequality, or other practically limited franchises, a dominant class might well be held accountable for representatives acting in their own interests "legally" but immorally against members of their own nation. Though again with some limits to culpability. In most of the modern revolutions, from France to Russia, the elimination of a dominant, "enfranchised" class was driven more by political-military expediency than moral consideration. Apart from all these armchair considerations, there are the practical operations of modern capitalist, democratic societies, where the individual is the operative unit, the financial identity, the primary form of representation, and the legal subject. Except for oppribrium and future elections, how does one go about holding voters accountable? Presumably their bad decisions result in various forms of "blowback" or what the Greeks would call the forces of Nemesis. Unfortunately, modern news cycles, national borders, global economies, and media ideologies are such that voters rarely recognize any link between their own votes and later consequences. Where causality is so diffuse or statistical, so too is any sense of moral accountability. Note: I am not familiar with contemporary political and legal philosophy as it applies to these issues of "representation," so I apologize for the lack of references. I hope others can provide. 

The wording makes it a bit difficult to respond. In the first place, no brain, rock, quark, or eggplant can be isolated in a specimen jar and "understood completely." In the second place, you specify the material "brain" while the unavoidable issue of "mind" lurks in the term "understand." While a "mind" understanding itself may seem like a paradox of self-reference or a "halting" problem, there are ways around that. Churchland's eliminative materialism, for example, proposes that, yes, everything about mind can be reduced to neural states that can be mathematized, modeled, and replicated, but will require a different sort of nonlinguistic reference system. Many argue the reverse. It may be that "mind" can understand "brain" if we treat mind as immanent and continuous and "brains" as discontinuous. Thus "mind" cannot observe or understand itself, from the outside, so to speak. Nor, for that matter, can one brain physically inspect itself. But our collective "mind" can certainly inspect a series of "brains" and accumulate a scientific understanding of their operations. I see no reason why such brain science would have any unique limits, aside from the obvious ethical limits. If you mean "understand" according to Hobbes' definition of being able to reproduce something...well, people reproduce brains all the time. Cognitive scientists just want to see if they can reproduce them without sex. That's their problem. 

I'm not sure I grasp your question or the "rebuttal." First, "honesty" is not necessarily related to logical fallacies or truth. It is simple consistency between what people say and what they believe, rightly or wrongly. I would note, as an aside, that the author suggests that Kant's categorical imperative is rooted in the structure of language, which may be a modern interpretation posed by Habbermas and others, but is not exactly how Kant would put it. However, we can stick with the language analogy here, since it makes sense. Kant assumes that the way to judge moral behavior can be understood logically and abstractly by "universalizing" propositions, as we do when we say to a child: "What if everybody did that?" The case of lying makes this rather obvious. If everybody lied, then "lying itself" would not work, since a lie only works on the supposition that people are not lying. This is, again, readily seen in daily life, where those who constantly lie find themselves no longer believed, Trumpism notwithstanding. People can, of course, lie, utter fallacies or nonsense, make erroneous statements knowingly or otherwise. But the exceptions prove the rule. Language simply would not function if it were systematically inaccurate and inconsistent with beliefs. Or so Kant claims. While he is correct at one level, the focus on "language" does reveal the shortcomings of this view. For, as we now understand, language can "behave" in many ways, and the half-truths or emotional appeals of ideology or advertising, for example, can be effective without claims to truth. Since Kant's philosophy is not about language per se but about reason, it rests perhaps on firmer, if more abstract, grounds. 

I suppose this could be filed as an epistemic question, but has other implications as well. We certainly know that digital photos can be readily manipulated and that photos, such as Mathew Brady's "evidential" images, can be manipulatively staged. And we also use charts, graphs, police drawings, crime scene drawings, statistics, handwriting samples, recordings, models (as in Wittgenstein's example), and, above all, eyewitness testimony or "memory," which is generally considered the most reliable evidence. The reason we may accept a digital photo as evidence is rather straightforward, but instead of confirming your second point, actually tends to refute it. The machine process is assumed to be a fundamentally physical-mechanical process with a linear causality and without the intervention of "subjectivity." Its product is objective or intersubjectively stable. That is, without the intermediation of a subject with freedom, values, choices, and all sort of possibilities for lying, deception, misrepresentation, moods, fears, greed, forgetfulness, or other "inaccurate" data transfers, including typically poor drawing skills. The machine is simply "dumb" matter carrying out a predictable, "lawful" input-output transaction without the "ghostly," black-box operations of consciousness and memory. Machines don't lie. At least not without a human accomplice who "programs" or otherwise distorts their causal sequences. It is not the superior cognitive abilities, but precisely the inabilities of the machine that make it a "reliable" witness. 

Presumably, yes. But this is why Objectivism is not taken very seriously. It opposes such harm, yet also and more ardently, it would seem, opposes the sort of government apparatus that could restrict environmental harms. The whole philosophy starts off with a bundle of simple-minded Aristotelean principles and whenever it runs into conflicts or contradictions, simply defaults to the power structure of Capitalism. Hence, the trusts, patents, monopolies, and political influence that capitalist collectives generate are not considered "harmful" or even "collectivist." As in the recent exercise of "freedom" that uses state patents to extract ruinous prices for necessary medicines. The patient, after all, is perfectly "free" to become a billionaire or, failing that, perfectly "free" to die. There is no way to evaluate the obvious conflicts of interest that arise in actual history, hence the utterly abstract "individualism" and default to power. I suspect most Objectivists would similarly propose that anyone harmed by corporate environmental damage is perfectly "free" to go to some other environment or perfectly "free" to invent advanced technologies to undo the damage. Rand was a fantasist and screen writer and I, like many others, find her "philosophy" a thin "screen" for the adulation of a power fetish. 

I agree entirely with **@Conifold.* First, you are using "relativism" where you probably mean skepticism. To say something is "relative" is to say that its relational values are in fact related to some fixed "general equivalent," as in the "speed of light." It doesn't mean anything goes or nothing is true. Obviously, in any system or conceptual scheme where things are "related" to one another, as they must be, they are "relative" to something. The question then becomes, is this "something" absolutely reliable? What is this "something," to which everything is related? Well, it could be all sort of "absolutes." It could be "energy" in physics or "money" in economics or "god" in religion or "me" in relation to "the world" or "consciousness." Or, as you suggest, the arbitrary, mysterious consensus we call "language" that must be utilized in any positive or negative claim. So "relativism" is badly miscast in your scenario. As for the skeptic! The role of the skeptic is to continually attack whatever "center" or "absolute" or "general equivalent" has historically assumed the role of absolute "authority" or the "author" of our present world. Those who have held this throne include the Patriarch, the King, God, Money, Science, Language...etc. When the skeptic attacks this "heir apparent," as Socrates attacked "Common Knowledge" or Hume attacked "God" and "Causality," they tend to do so not out of nihilistic glee but because they see suffering and horrors arising out of this fixation on some absolute. When Hume attacked the "truths" and certainties of his day, he did so at a time when naive students could still be, and were occasionally, hung for opinions "casting doubt" on dogmas of the Presbyterian church. The relativist attempts to discover the present "center" to which particularities are relative. The skeptic is like a doctor who constantly tests these "centers" to see which are rotten or diseased. Be careful. Philosophy, and especially logic, invite you into an exciting world of "find the right absolute." Wisdom backs away from that excitement, with "early" and "late" Wittgenstein being the most moving example. To philosophize, I would say, is to discover the "absolute" towards which normal, daily things are "relative" and to then use all your powers to test that presumed absolutism. 

While connecting "information" and "intelligence" is an irresistible puzzle, I suspect it is largely an apple-oranges update of mind-body problems. Information is, as Shannon's insists, strictly physical. It reduces "uncertainty, thus relocating a "message" from one place and medium to another, within a predetermined context of "meanings." All syntax, no semantics. It has no more special relation to "mental capacities" than, say, the theory of gravity. Nonetheless, the allure remains, and there have been efforts to develop a physical semantics or theory of "meaning" extending the theory of information. One involves, I seem to recall, a second-tier complexity of "information" that contains keys to "self-interpretation." This may be towards the end of Gleick's book, but I have no references at hand and hazy recollection. Because "intelligence" remains a "ghostly" property, you may want to consider first expanding "information" to the social operations of "communication," as in the systems theory of N. Luhmann, who defines "meaning" as an interaction between "actual" and "possible." While this clearly echos the relation of "certainty" to "uncertainty" in information theory, it is also reminiscent of Hegel's "actualization of the rational" and "rationalization of the actual." Sorry this is a bit vague, but I am actually just digging into this myself. But again, some neat conversion function between quantifiable "information" and whatever quality or capacity is meant by "intelligence" seems to run aground for now on the same old antinomies hampering computational reductions of "mind." 

I would agree that, as is often the case, Kant is the best starting point for a modern philosophical idea of "knowledge," as opposed to existence or truth, for example. Unfortunately, getting to "know" Kant is extremely time consuming. I believe it was Hobbes (I may be wrong) who said that to "know" something is to be able to reproduce it. This is a very handy definition, and far more complex than it at first appears. The irreducible philosophical command to "know thyself" is utterly paradoxical for humans because we cannot reproduce ourselves without "knowing" another, in the biblical sense. Similarly, I have often argued that one test of AI should be its capacity to reproduce itself...as biological intelligence does. A far more difficult demand than it at first appears. Von Newman replicators illustrate the problem. One can bring Kant back in here, in a renegade interpretation. Kant could be said to argue that we indeed "know" the world precisely because we partially produce and reproduce it. It is because we synthesize or "con-struct" experience of an outer world according to categorical "in-structions" that we can "know" it. This is how concepts latch onto percepts. Let me toss in one more reference, this time from Shannon information theory. To know is to increase information, which is to eliminate uncertainty. One begins with uncertainty (or possibilities) between zero (0) and one (1) about (X) and eliminate this uncertainty by a process of statistical divisions, as in the game of 21 questions. To know is to eliminate relative uncertainty given certain assumptions. All forms of life must do this in some fashion and to varying degrees. Again, the idea that all knowledge begins in the Delphic maxim "know thyself" is, in my view, crucial to philosophy. It was Socrates who demonstrated the paradox of this command, that we can only know for certain "what we don't know." So the Socratic, dialectical motion towards knowledge is not unlike the endless "elimination of uncertainty" given a modern, mathematical form in information theory.