Successive cyclic wh-movement is motivated by theoretical principles of minimal computation, as well as empirical data. There's nothing inherently wrong with the 'one fell swoop' analysis, but cyclic wh-movement is preferable. Minimal computation: At any point in the derivation, the range of visible syntactic objects available for computations (e.g. Agreement) is restricted. Remember, SMT assumes that derivations form interface-interpretable objects as efficiently and lazily as possible. Thus, we assume visibility is restricted to phase (CP and vP) edges, which rules out one fell swoop movement. This is known as the Phase Impenetrability Condition. Data: The following data comes from McCloskey 2000. In a dialect of English spoken in Ulster, the quantifier all can attach to wh-pronouns. 

Thus, it is possible to strand the quantifier in intermediate Spec, CP. This lends support to the cyclicity of wh-movement shown here. Angled brackets indicate lower copies. 

Learn some formal language theory via Sipser's Intro to the Theory of Computation. Having the background will be useful when dealing with Minimalist Grammars and their parsers. 

So it would seem that after [DP where/who/what all] merges in its theta position, wh-extraction can target only the wh-pronoun. Turning to long-distance wh-extraction, the following are all grammatical. 

Your analysis is not correct. It is well known that wh-extraction out of adjuncts is impossible. See Huang 1982. Thankfully, the derivation of your sentence involves neither wh-extraction nor adjunction. Notice that it involves the passive construction The plot was discovered by the authorities, in which case the plot and the authorities are both assigned theta roles by discovered. Ignoring the technical details of passive constructions, the derivation involves building up [TP the plot was discovered by the authorities] And in the usual manner, we merge in an interrogative C bearing a wh-feature that needs checking [C [TP the plot was discovered by the authorities]] The subject inverts with the auxiliary, and then how gets merged into the tree to yield [how [[C+was] [TP the plot was discovered by the authorities]]] 

Assuming the copy theory of movement, cyclic wh-movement is further supported by languages in which multiple wh-copies are pronounced. Consider the following Afrikaans data from du Plessis 1977 

Many aspects of cognition lack neurobiological evidence - consciousness for instance. Now if Cartesian duality is correct (and given its formidable presence in the history of philosophy, it's not a totally insane possibility), it follows that human cognition will never be completely understood within any biological framework. The language faculty can then be one of the 'magical' aspects of cognition, in which case, biological inquiry will be useless. However, this does not preclude the notion that the language faculty employs computational mechanisms like Merge. In light of such possibilities, the computational approach to the language faculty, namely that sentences are formed via Merge, is correct to the extent that we can successfully account for natural language syntax with Merge along with the other assumptions of the minimalist program (e.g. The Strong Minimalist Thesis). I would say that Merge has been very successful in this regard. On the other hand, it's possible that neurolinguistic research will one day provide a more illuminating account of the language faculty. For instance, perhaps Merge can be localized to Broca's or Wernicke's area. Or as an extreme case, perhaps the language faculty doesn't exist at all, and by extension neither does Merge. That language is nothing more than the result of domain general cognitive processes is a view held by many (e.g. Lakoff and most functionalists). My personal view is that the current generative approach will be vindicated when generative ideas are used to solve the central problem of AI. Once we create robots that speak indistinguishably from humans, using such hated principles of Universal Grammar, generativism's detractors will be at a loss of words. 

In this example, the phrase "a wise king" is placed in apposition with Solomon. In your example, there is simply a series of independent noun phrases, separated by commas. None of them describe the other in any way. 

The phrase "ein wenig" is reminiscent of the English phrase "a little", but what is interesting about "ein wenig" is that it is not an adverb proper. It belongs to a different class called an adverbial. How would you classify the English phrase "a little"? Is it also an adverbial? And how would you classify the word "little" (in this usage) on its own? It does not seem to be an adverb here. 

If my suspicion is right, and each of these sentences contains a subordinate clause, then does it follow that a subordinating conjunction (that, who, whom, which) necessarily introduces a subordinate clause? (I am assuming that all relative clauses are also subordinate clauses, as indicated on this grammar website.) 

In spoken English, is there a clear preference for using contractions? Does it depend on the locale? I am mostly interested in Midwestern and Northeastern USA, but I would also care to know how it is in England and Great Britain. Even if there is a preference, does it sound awkward or stilted when people avoid using them? Or, on the contrary, does it signal a higher register? I'm talking about contractions like you're, they're, haven't, we'll, etc. 

In the exclamation That you be happy! what part of speech is the word that? Is it a conjunction via ellipsis, i.e. "(I wish) that you be happy!" If yes, then does this poke a hole in the idea that subordinating conjunctions necessarily introduce subordinate clauses? 

It is not good that man should be alone. (Gn 2:18) He said that it would rain today. I could not decide which pancake to order. I did not see who was shouting. I was shocked that he would be so gracious. 

What grammatical feature is being used, when we say something like, "I drink a cup of coffee"? In this sentence we have one noun modifying another noun, "coffee" modifying "cup". Would "cup" or even "a cup of" be an example of a determiner? If not, how would you describe these X of Y sentences in grammatical terms, where X and Y are nouns. As a very last question, would the grammatical terms used be the same in both English in German, where in German you would say, "Ich trinke eine Tassee Kaffee"? 

I would like to clear up some longstanding confusion of mine on subordinate clauses, especially since it is a rather simple grammatical topic and it is about time that I learn it. Which of the following sentences have a subordinate clause? I suspect that they all do, but I just want to make sure. 

The Wiktionary page on the English word "with" < *wi says that the meaning of "with" shifted in Middle English to denote association instead of opposition. The latter sense is still present in phrases like "He picked a fight with the older boy" (opposition), whereas we see the former sense everywhere, e.g. "I walked to school with my friends today." Do we have any more information on how or why this shift may have happened? Are there other descendants of *wi that reflect this shift as well, or only the preposition "with"? The alternative to "with" may well have been "mid" (< *me, cognate with German mit), still seen in words like "midwife". Any idea why this fell out of use? 

The French verb trouver (to find/think) can trace its ancestry back to the Greek word τρόπος, which means a turn, manner, style, or figure of speech. Is there any logic to this seemingly disconnected progression? I can perhaps see some kind of figurative relationship between the two. Each person's thinking is unique to them in the way that a style or manner can be. Is it this figurative description that explains the semantic shift? 

This is implemented using language files. To support a new language, you won't need to update your code, just add a new language file. For example, The DHTML Calendar has a set of language files already available, published under the terms of the GNU Lesser General Public License. For example, Calendar._SDN has the following values: 

Human speech is noisy, and speech recognition must be able to find patterns in the noise. Phones have a series of articulatory attributes: places and manners of articulation, tongue shape, etc.; which cause voice resonance and distortion. All of those variables are continuous, and a continuous change in one of these parameters produces a continuous change in the produced phone. There's a spectrum of sounds between [a] and [i], for example. Different languages make different distinctions between sounds, and some attributes are more important than others. For example, the distinction between voiced stops and voiced fricatives is significant in English but not in Spanish; similarly, the distinction between plain and aspirated among voiceless stops is significant in Hindi but not in English. So yes, it's a subjective distinction. Also, not every English speaker pronounces yes and no the same way. There's a general pattern that makes a yes or no word recognizable, and a system could be trained to recognize these distinctions. On its most basic form, you only need to be able to recognize "yes" and "no" from everything else, including ambient noise and other words. In fact, this might be a much easier problem to solve than a general speech recognition system, since you don't need to tell "no" from "know" (a context-dependent distinction) or lone "yes" from "YESterday". You still need to be able to recognize the "yes" and "no" said speakers other than yourself, and that will require training your system with a decent amount of speech recordings. 

However, র BENGALI LETTER RA doesn't appear in Unicode as precomposed with NUKTA, as RRA, RHA and YYA are. It could be that RA and ব BENGALI LETTER BA are independent letters. Edit: This table shows the evolution of the Bengali script since the 11th century. 

If you already know X-SAMPA, you could use my X-SAMPA ↔ IPA Converter. There, you can type in X-SAMPA, then convert to IPA. For example, if you type , and press , it yields . 

After a quick look to WALS, my initial impression is that the number of unusual features in world languages tends to increase with historical isolation. Geographical proximity and language contact may result in the formation of Sprachbünde, or areas of linguistic convergence, which favors the use of common features instead of unusual ones. Influential languages may become sources for loanwords and cause spelling irregularities and sound changes. Edit: Also, standardization, which occurs in advanced literate societies for languages with hundreds of thousands of speakers, also aims to remove much of the unwanted or redundant complexity, creating a prestige dialect that will be taught at schools and spoken by most people. Assuming that your sea-faring fictional culture has a rich merchant tradition and interacts with many other cultures, I think that it should have a fairly typical language. 5-6 vowels, not too many consonants, lack of complex consonant clusters. A quite typical syllable structure is (consonant)(glide)vowel(consonant). 

That “dot” symbol is called BENGALI SIGN NUKTA (U+09BC) in Unicode, and is used “for extending the alphabet to new letters”. Other Indic scripts also have nukta signs for the same purpose. The following are examples of its use. The last three are precomposed characters in Unicode. I'm using Unicode names. 

The goal of the Hepburn system is to provide a more or less regular, unified system for writing Japanese using the Roman alphabet. Though superficially similar to English, it doesn't have to follow the particular rules of a specific language. This is most visible regarding the vowel system. Japanese vowels あ, い, う, え, お are spelled a, i, u, e, o in Hepburn; long vowels are spelled aa/ā, ii, ū, ee/ē, ō; えい and おう are spelled ei and ō. In English, the closest vowels are those in the words bat, bit, put, bet, bot; bar, bee, boo, bay, go. In French, it would be a, i, ou, é, o, with the tréma used as in French. Neither English nor French spelling works for Japanese vowels. In most languages written with the Roman alphabet, they use Hepburn to spell Japanese words because they are spelling Japanese words, not loanwords of Japanese origin. There is a difference. In English, many words of Japanese origin are simple transliterations based on Hepburn (without macrons), though some have a more-or-less English-like spelling. Examples: bokeh, noh, tycoon, moxa (moxibustion), skosh, rickshaw. In Spanish, 東京 is written Tokio, and 屏風 has been loaned as biombo. Even in French there are such loanwords with French-like spelling: Aïnou, atémi, daïkon, daïmio, taïcoun. There's a choice to be made, between a standard romanization system that reflects the phonology of the source language (such as Hepburn for Japanese or Pinyin for Chinese) and a customary romanization system that adapts foreign words to the spelling system of the target language (which is what you're proposing). The latter is more prevalent between European languages (and also Arabic whose speakers are geographically and culturally close to Europe), possibly because of an earlier tradition of literary exchange that favored the development of customary systems. Those traditions didn't exist between Europe and the languages of East Asia, because geographical distance and isolation made cultural exchange difficult, so each book used ad-hoc romanization systems that didn't become widely adopted until rather recently, when global commerce created a need for standardized romanization systems.