I usually use MySQL Workbench to do the import but I wanted to use the parameter and I don't think does this. What's wrong with this syntax? I also tried: 

I've called Dell twice to try and clarify this basic (or so I thought) question, but I've had two different answers so far. We have a Dell R710, and a Dell R720. Does DRAC come installed by default on either? Dell said it comes build into the motherboard on the R720 but the second time I rang, they said we didn't have it. Can anyone tell me if DRAC comes as standard on the R720? I'm aware we'll need a license as well, I'm just interested in the physical capability on the server. I've never used DRAC before and know next to nothing about it, so apologies if this seems blindingly simple. Thanks 

Fingerprints (and other biometrics) on Windows are designed to replace the PIN on the machine and are keyed to the machine's TPM individually. The point is that if your fingerprint is stolen, it could not be used to access resources using a different machine. There might be some third party tools that would allow you to do what you want, but that's not by design with Windows/Active Directory. 

You are correct, in order to use Azure AD you must become a "tenant" within the system. So a tenant is basically just securing a .onmicrosoft.com sub-domain. At that point you would have one account registered in your Azure AD. From there, you can activate Office365, Intune or any of the Azure services. 

After doing all that I ran expecting to see the new version installed. cURL had updated to 7.30.0 as expected, but libcurl hadn't: 

How do I find out what these are actually doing? Can I see a list of files being accessed by each PID, or any more info? We're on . I tried but it's not giving me much useful info about what's actually going on. Edit - Additional stuff tried based on comments/answers: Doing on each of the PIDs shows the following: 

We have a Dell PowerEdge R720XD server and want to setup iDRAC, but this is a production server so we need to do it without a reboot if possible. We just need to set the IP address on the iDRAC but the servers do not have a front LCD panel so we cannot use this. The iDRAC will currently have the default 192.168.0.120 IP address but we are not on this IP range so cannot use this. We need to change it to 192.168.5.x. I've seen mentioned, but before I start messing around installing this on Ubuntu, is this what we need? and will we be able to set the IP address on the DRAC with this? Thanks Edit - The dedicated iDRAC port seems to be completely disabled until you enable the enterprise license, so I think we need to used a shared NIC for now. We don't know any way of enabling enterprise without first gaining access to it via the web GUI. The server is in production with bonded network interfaces, so we can't change the server IP to 192.168.0.x while we do this, or we might as well reboot into the BIOS and do it. 

You might want to take a look at Azure File storage, which will allow other Azure servers to access files via SMB, without needing a server to host the share - $URL$ 

You can now active domain services directly for IaaS VMs using the Azure Active Directory Domain Services (currently in preview). This can potentially replace the need to deploy full ADDS VMs in your Azure virtual network. $URL$ 

The ability to protect ARM VMs with Azure Backup is now in public preview, you can find more information at $URL$ 

Just because you are logged into the Windows 2008 machine, it doesn't mean that the focus of your ADUC tool is that server. You can be logged into one DC physically, but be connect to the directory located on another. Make sure to confirm which DC you are connected to before attempting the change. 

A few days ago we were getting errors when trying to access files on the large RAID 5 partition. We rebooted the server and got a message about . We've had this before, and just needed to use Dell's RAID configuration utility to on the RAID. Last time this worked, but this time, it started doing a disk check then we got this: 

However, if I run I get which is correct. Can anyone explain why there's a difference in version numbers? And how to get them all showing the correct 7.30.0? Does anyone have any tutorials / advice / any help at all on the proper way of upgrading everything cURL related to a later version. The topic seems to be incredibly lacking online, not sure why :/ Thanks Edit - Following one of the comments, here's some additional info: gives gives gives gives gives 

For a VM using Standard storage for the OS drive (C) you only pay for what you use. It's thin provisioned at 128 GB, but if you only use 10GB, then you only pay for 10GB. For Premium Storage, you pay for the full amount you reserve. You can create a VM with a standard OS drive and then connect premium storage for your data, if the VM support premium storage. 

Your spns need to be added the service accounts, not the local administrator. ADSIEdit can be really helpful in figuring out where they go. 

I'm trying to import a large 70GB+ database (all ) using . This is a development system on Windows using WAMP server. . I'm getting the following error: 

A is showing tons of activity between two of our servers, over nfs, but as far as I'm aware they shouldn't be. A lot of entries like: 

We noticed one of the drive lights was not lit at all, and thought this may have failed and be the problem. We replaced the drive with a spare, and tried "F" to repair it again, but we keep just getting the same error as above. In the RAID configuration utility, all drives show as "online" and "optimal". We do have this data on another replicated server, so we're not worried about "recovering" anything, we just want to get the system back online asap. The server has 64 or 32GB memory, can't remember off the top of my head, but either way, with a 14TB RAID, I think it may still not be enough. Thanks EDIT - I checked the memory usage while fsck was running as suggested and after 2 or 3 minutes, it looked like this, using up nearly all of our servers memory: 

You might want to look at the features of MS Intune. It does a lot of what you seek, particularly with the remote device management, VPN access and security. If you sync on-prem AD with Azure AD, it will help with the credential management too. 

You have the right idea with your diagram. DCs should point to other DCs for DNS, ideally in the same site (if you have multiple sites). Your workstations should then be pointing to a DC in their site for DNS resolution. You will see slow logons as a symptom of DNS issues. Just about every problem with AD tends to be DNS related, at least in my experience... it's always the first place to check! 

I previously had cURL 7.22.0 on Ubuntu 12.04 Server.. but I now need to upgrade to cURL 7.30.0. I've done the following to compile this version for Ubuntu: 

We have a MySQL database server running on an Dell PowerEdge R720 (PERC H710 Mini RAID controller) ( (Ubuntu 12.04). We're considering upgrading the 2 x 146GB 15k SAS drives to Samsung 840 Pro SSDs. The Dell ones are just far too expensive! (nearly 2k per drive), and with us putting them in RAID 10, we can just have spare drives standing by for if any fail? Does anyone have an identical setup, and are we likely to get problems with this configuration? I've read reports online of the Dell RAID controller deciding it doesn't like the drives and marking them as offline randomly, but then other reports of people running 100+ of these in RAID and having no problems at all. Should we just avoid this entirely for a pretty critical database server? 

If you are looking to run multiple websites using Azure, it's not necessary to use IaaS. You can run up to 10 web roles for free - $URL$ 

With the classic portal, only co-admins can access a subscription. The Azure Resource Manager features of the new portal, you'll be able to more finely control the access within a subscription. The official documentation is here - $URL$ 

I have used Azure-to-Azure site recovery, which is currently unsupported, in test and lab scenarios. It's totally doable, but you would be assuming some risk with the unsupported aspect of it. As of now, you can't "fall back" to the original region, it only replicates in the one direction. 

Turns out this was down to the domain being different on the NAS and the server! on the ReadyNAS came back blank, and on the Ubuntu server came back . I changed it with: and updated: to Rebooted with: and it all started working as expected (think I possibly remounted the share as well, but not 100%)! 

When it failed after 5 minutes or so with the error in my post, the memory immediately freed up again: 

All the commands etc work as expected but we need to be able to access the OpenManage web interface, however, it isn't starting up for some reason.