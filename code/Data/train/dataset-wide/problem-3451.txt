Ok was the error log was totally throwing me off, and had nothing to do with the underlying issue. The issue was caused by Magento & HHVM not working well together. In the end I solved it simply by adding the following to my /etc/hhvm/server.ini file. 

And then updating /etc/sudoers so that the ubuntu user must give their password when running a command. To edit this file you must run and add: 

Which CRT file should I reference for NGINX, what about the other one? 3. SSL 3.0 & SHA1 When I check our site on DigiCert's SSL checker it says: 

I discovered if I changed the name of this file to I stopped getting the 404 error on it, and when I removed the below block from NGINX it loaded fine with it's origional name, so it must of had something to do with the dots at the end of the file name. 

I'm a but of a newbie to systems admin & redis configuration and am trying to figure our how to optimize redis. We are running a Magento eCommerce app on an AWS m3.large EC2 instance with redis and the backend caching seems quote slow. Up to 15 seconds for TTFB on some pages. The Root device type of our ec2 instance is ebs. When I look at the info command output from the redis CLI I see: 

Should I update our webserver? Everything is running fine now so I do not wish to run the risk of breaking anything. Can I just update the security updates? Is this the correct process for updating? 

On our Magento store when we try to we go to the product page in the admin section to upload images, we see that the images which we already have there on the front end are missing and there is no option to add images as per usual. 

I suppose I could create an image of the webserver on AWS incase anything goes wrong. Is there a way I can check to see what the updates are, especially the security ones, so I can see how necessary they actually are? 

I had NGINX running fine on my local machine and tried to install the Google Page Speed module by first uninstalling nginx and following the re-installing from source as Google suggests. Now NGINX won't start, and I can't access any of the sites I have set up locally for development. There is nothing in my error logs, yet I can see I have the /etc/nginx/ directory with all the configuration files I had before. Any idea how I can get things working again? I tried re-installing but still no joy :( 

First of all , i started seed node while other nodes stopping. After a successfully start action i started other nodes(without any error messages in log files). Then when i run nodetool on seed node , i only see nodes S1 and S2 but not node S3. 

As explained above posts it is not about incoming firewall rules. The problem may be in your outgoing firewall/iptables. Is this complete of iptables-save command output? Try iptables -L OUTPUT or iptables-save | grep OUTPUT Check your network interface and /etc/resolv.conf file.Your server may not resolve smtp.google.com. Try to ping smtp.google.com or other tools. Check your exim configuration and logs for more details. /var/log/exim_mainlog 

How can i add openshift node to cluster? Does openshift support nodes which is a member of multiple data centers cluster? Must all nodes have same version of cassandra? 

I'am wondering that how can integrate my database,web,backup etc.. centos servers with Zimbra LDAP Server. Does it require more advanced configuration than standart ldap authentication ? My zimbra server version is 

There is no log about this problem in /var/log/maillog. I am wondering that how to send mail file to user's mail directory? 

As seen in the output of your "netstat -tulpn" , you have RHEL distros, Exim smtp and Apache web server so you should check /var/log/messages file for more information about your problem with tailf -f command. If you are trying to send mail through PHP you should also check your httpd log file(/var/log/httpd/error_log or for vhosts check your httpd.conf file to find path under the VirtualHost scope) 

My problem is INBOX file path was wrong. After changing mail_location from maildir to mbox and INBOX file to /var/spool/mail/%u it gave some permission errors. 

Sometimes selinux may block curl requests. You should check your selinux configuration that it is in permissive mode or disabled. 

But i am sure that username user exist on ldap server. EDIT : When i run ldapsearch command i got all result with credentials and dn. 

I use fail2ban to prevent brute force attacks on my production servers. Fail2ban bans an ip after 5 authentication failure and unbans it after 1 hour with my own configuration. I wonder that what is the optimum ban duration or do i really need to unban it again? Is banning an ip permanently the best solution? 

I'm not really sure what this block was doing or what means, I'm sure I just took it off someones blog who recommended it. Any idea what it is doing? Below is my full NGINX configuration file, thanks in advance for any help and advice you may have :) server { # Listen on port 80 as well as post 443 for SSL connections. listen 8080; #listen 443 default ssl; 

Which is odd as I'm not used to comments in public keys or line breaks? We've tried using her public key with & witout the comment & line breaks. I've added it to like this: 

Two things confused me about this, first off I don't understand why the server block would not be allowed, after checking online it seems that this can be caused if config files are not included in the block of my , but they are: 

Our webserver is on AWS running on Ubuntu 14.04.3 LTS. When I ssh into the server I see this message. 

I'm moving a site to a new server running on NGINX. The old site's Apache2 VirtualHost has configured that I want to replicate in the NGINX configuration. From what I've read on the NGINX Docs this seems to be simply achieved with . I just want to make sure what I have is correct. From APACHE2 

Secondly when I removed the sendy-newsletter configuration from and folders, as expected I could restart the nginx server successfully but strangely when I ran I get the same error message as before but the server works!? 

It's also strange as it does not begin with , also her private key is called mags_private.ppk, I think this is because she is using windows & putty. I'm used to adding keys which are called Is their a problem with her public key or do I need to add something to the authorised_keys file. Other devs have been able to ssh in before but they had a . 

I'm such a dope, forgot I had varnish running on the other application so port 80 was in use. That was the issue, the error logs pointed me in the right direction while the nginx -c just confused me. 

I thought it might be a PHP version issue but my local machine is running 5.4.10 and my server is running 5.4.14. 

It turns out this was an SSL/CURL issue. In the TwitterAPIExchange.php file, I had to add these two lines to the CURL options array: 

I have a PHP script that displays Tweets embedded in a site I built out on my local machine. When I uploaded the site to my IIS 8.0 server, the PHP script no longer works and I receive this error: Warning: Invalid argument supplied for foreach() in C:\inetpub\wwwroot\i360_new\footer.php on line 76 The script is: 

I am trying to set Amazon CloudFront up with Nginx using W3 Total Cache and WordPress multisite. CloudFront only works with http 1.0 so, I read that you need to change the http version in gzip to 1.0. I made the change but my headers are still using http 1.1. Here is gzip block: 

Is there something else I need to change? If I need to provide anymore details please let me know. Here are the headers. 

I have a website on IIS set to domain1.com. I also have a domain called domain2.com that is redirecting to domain1.com. I currently have this set up in the domain1.com bindings. I need to change this to where domain2.com is redirected to domain1.com/blog Would I do this through the web.config file or is there another way? 

I have several sites on a VPS server and one of the sites randomly went down earlier (500 error). The site is hosted on a subdomain of another website that is hosted elsewhere. So, the site that is hosted on my server is blog.example.com while example.com is hosted on another server. I think the issue is DNS related and possibly NS record related. Prior to the site going down, I had the subdomain website NS records set as my server NS records e.g. ns1.myserver.com and ns2.myserver.com. I thought I might need to change the NS records to the server that is hosting the main website example.com. I changed the NS records to ns1.example.com and ns2.example.com but the problem is still not fixed. Could there be a different problem or another solution?