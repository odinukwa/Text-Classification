More generally, if for a process $X_t$ we have $$ V(\delta) \sim c\ \delta^{-\kappa}$$ can we prove that $H = 1 - \kappa$ is the Hurst exponent of $X_t$ ? It seems to work when $X_t$ is a $C^\infty$ function ($H=1$, $\kappa = 0$), it works for Brownian motion ($1/2$ for both), it also works for White noise ($H=0$, $\kappa = 1$). 

Let $(X_n)$ be a martingale. What can be said about the distribution of its maximum over a window of fixed length: $$M_n = \max_{n-10 \leq k \leq n} X_k$$ or about the "range" over a window: $$R_n = \max_{n-10 \leq k \leq n} X_k - \min_{n-10 \leq k \leq n} X_k $$ I know Doob's inequality, but can we give more precise informations about $M_n$ or $R_n$ ? At least when $X_{n+1} - X_n$ has a normal distribution? 

A completely different approach I have (hence a different answer) is to maintain a private wiki... I keep lots of partially written notes on the subjects I'm learning about or on partial approaches in new directions. The advantage is being able to access them from anywhere, without worrying about having a hard copy or the right computer. I organize them in lots of ways (tags, categories, etc.), can search through them easily, and have a history of any changes made. (The site I use is www.wikidot.com) 

In the second case, it makes sense to talk about higher order derivatives, but in the first example the derivative provides a matrix from a scalar function, so you have to massage it a little bit to define a higher order derivative (e.g. take the trace of the resulting matrix). I was wondering what other notions of matrix differentiation might exist out there, particularly any notions that allow for higher-order differentiation. I am also interested in any connections between various forms of matrix derivatives. As this is related to an undergraduate research project, I am mostly looking for answers that include a minimum of advanced terminology, but a discussion of how more general concepts (e.g. differential forms, matrix exponentials, etc.) relate to matrix derivatives would also be helpful. 

Given a binary function $f: [1..n] \times [1..n] \to [1..n]$ how to check that this operation is a group operation on $[1..n]$? It's obvious that this can be done in $O(n^3)$ time just by checking all group properties. The most time-expensive property is associativity. Also it's clear that it could not be done faster than $O(n^2)$ time since you should at least examine all values $f(i,j)$. The question is if there is any algorithm to solve this problem in time faster than $O(n^3)$? 

Consider multiplication table for numbers $1,2,\cdots, n$. How many different numbers are there? That is how many different numbers of the form $ij$ with $1 \le i, j \le n$ are there? I'm interested in a formulae or an algorithm to calculate this number in time less than $O(n^2)$. 

Let $(B_t)$ be a brownian motion on [0,1]. For the following, let $\omega$ be fixed. Let's compute the total absolute variation when sampling period = $\delta$ is fixed: $$V(\delta) = \sum_{i=0}^{N-1} |B_{t_{i+1}}(\omega) - B_{t_i}(\omega)|. $$ (i.e. $0 = t_0 < t_1 < t_2 < ... < t_N = 1$ with a constant step $\delta = t_{i+1} - t_i$ for all $i$) I noticed experimentally that: $$ V(\delta) \sim c\ \delta^{-1/2}$$ It confirms the common-sense feeling that the smaller the sampling period (=the higher the sampling rate), the higher the total absolute variation. Is it a well-known result? If so, where could I find a proof? 

Let $P_k$ be the product of the $k$ first prime numbers, and for any integer $n$, we denote by $(d_i)_{1 \leq i \leq \tau(n)}$ the increasing sequence of its divisors. The set $\{n_1, ... n_N \}$ of square-free positive integers which are generated by the first $k$ primes that you are considering is nothing else than the set of the divisors of $P_k$. Thus we can use this notation: $$\delta_k = \min_{\ell_1<\ell_2} \left(\frac{n_{\ell_2}}{n_{\ell_1}} - 1\right) = \min_{\ell} \left(\frac{n_{\ell+1}}{n_\ell} - 1\right) = \min_{d_i | P_k,\ 1 \leq i < 2^k} \left(\frac{d_{i+1}}{d_i} - 1\right).$$ We have, for $ \epsilon > 0$, $$(2^k-1) \Bigg( \min_{d_i | P_k,\ 1 \leq i < 2^k} \left(\frac{d_{i+1}}{d_i} - 1\right)\Bigg)^{1+\epsilon} \leq \sum_{1 \leq i < 2^k} \left(\frac{d_{i+1}}{d_i} - 1\right)^{1+\epsilon} \leq C,$$ with an absolute constant $C$, uniformly for all $k$, by using Théorème 1 of Sur un problème extrémal en arithmétique, G. Tenenbaum, Ann. Inst. Fourier, Grenoble (1987). i.e. it is proved that, for every $\epsilon > 0$, $$\delta_k \ll 2^{-k(1-\epsilon)}$$ Note 1 : It doesn't give the lower bound you were looking for, but it confirms that $\delta_k$ has an upper bound of the order you expected, i.e. $e^{-c\ k}$. Note 2 : I have applied Théorème 1 with the function $h(u) = u^{1+\epsilon}$, but the article describes (see page 3) a wider class of function that could be used. Note 3 : For a lower bound, the best I can prove is (do you want me to post a proof for this?): $$\delta_k \gg e^{- \frac{1}{2} k \log k}$$ 

If we take $x_n = (-1)^n x$ then $x_n$ converges to $0$ in Cesaro sence. But no subsequence of $x_n$ converges weakly to $0$. $x_n$ is also a bounded sequence. Hence your statements seems wrong. 

If $n_1$ and $n_2$ are not too big you can use Eratosthenes sieve (see wikipedia for this). If they are big enought you can use sieve to cross out numbers which have small prime divisors and after that check every number that wasn't crossed out and check if it is prime using any primality test (see $URL$ 

Yes, there is such scheme. It was recently suggested by Craig Gentry. Reference: "Fully Homomorphic Encryption Using Ideal Lattices" by Craig Gentry. $URL$ 

Yes... I saw it first in Stedman's work (Diagram Techniques in Group Theory, G. E. Stedman, Cambridge University Press, 1990), but it may also exist elsewhere. The basic idea is to combine symmetrization and anti-symmetrization across different sets of strands, roughly in correspondence with the Young tableaux. The other place to look for more general diagrams for general Lie algebras is Cvitanovic (Group Theory: Birdtracks, Lie's, and Exceptional Groups, Predrag Cvitanović, Princeton University Press, 2008, $URL$ The text is available online and it is extremely impressive. 

It seems to me that frequently people will say this because they find mathematics intimidating. I don't think they're trying to be rude. I try to get the idea across that mathematics is not always as complicated as it seems. For instance, the average adult may not know the term "integration", but a child can easily count the number of squares underneath a curve. 

Consider a finite group where all elements have the same order $n$. What could be said about such groups? For $n=2$ it could be proved that such group is isomorphic to $(\mathbb{Z}/2\mathbb{Z})^k$. Could it be somehow generalized on case $n>2$? EDIT: Surely the identity has order 1, so we have to exclude it. 

Is it true that every positive rational number $r = \frac{n}{m}$ could be represented as sum of $\frac{1}{k}$ for different $k$'s: $$ r = \sum_{i=1}^{s} \frac{1}{c_i} $$ where all $c_i$ are different? If true, are there any bounds on number of summands $s$ based on $n$ and $m$? 

It's well known that there are no non-constant polynomials with integer coefficients whose values at integer points are primes. Could this result be generalized to the case of prime powers? The question is whether there exists a polynomial $p(x) \in \mathbb{Z}[x]$ with degree at least one such that for all $x \in \mathbb{Z}$ $|p(x)|$ is prime power. 

Sperner's Lemma comes to mind. It can be used to prove various results about fair division (being strongly related to the Brouwer Fixed Point Theorem). Ideas from homology can be used to simplify proofs of its generalized form. See Francis Su's papers ($URL$ 

Most math papers have few figures, if any, although sometimes a well-chosen figure can be a tremendous help in understanding mathematical concepts. Does anyone have any examples of notable uses of figures in mathematical writing and/or texts that make great use of figures/diagrams/illustrations? 

I recommend Frank Morgan's Real Analysis for its clarity, the concise chapters, and good exercises. It's much more accessible than Rudin... while I loved learning with Rudin, I don't think it's for everyone. 

There is the following formula: $$ x_{n+2} = \frac{x_{n+1}^3}{2 x_{n}^2} + \frac{5}{2} x_n^2 x_{n+1} $$ I'm not sure if this is a pure recurrence formulae. If you need, I may provide a proof. 

There is an example of a function that is unbounded on every open set. Just take $f(n/m) = m$ for coprime $n$ and $m$ and $f(irrational) = 0$. I want to generalize this in a way to get a function which is not just unbounded on every open set, but whose range is equal to $\mathbb{R}$ on every open set. The latter construction clearly doesn't work. I'm interested whether such function exists and if it exists is there any constructive way to define it? 

Social scientists have long looked at the connections between people and studied "social networks", e.g. the famous paper The Strength of Weak Ties. There is a huge push currently to infuse this area of social science with more mathematics, and there have been several recent articles in the Notices of the AMS about this "network science". 

The best resource I can point a beginner to is the first few chapters of Stedman's book "Group Theory". He focuses on the specific example of 3-vector diagrams, and does a good job of including lots of sample calculations. Unfortunately, it's not available online. I have found Cvitanovic' book fascinating but tough to internalize. You might also try looking at some of the work of Jim Blinn (a compilation of his work is at $URL$ which has a lot of examples worked out. Another text that I commonly referred to is "The classical and quantum 6j-symbols" ($URL$ although this is limited to a special case of the diagrams. As for learning about the diagrams themselves, I think the only way to really get comfortable with it is to work out lots of examples. I filled endless chalkboards at the University of Maryland with the doodles... it's one of the fun parts of the subject. :) The paper you mentioned is focused on the applications of diagrams to ideas in traditional linear algebra. I have not found any other source that focuses exclusively on this use of diagrams, although Cvitanovic' book (for example) mentions without proof that one of his equations corresponds to the Cayley-Hamilton Theorem. This is probably because many mathematicians do not see much use in reproving old results (particularly if one must learn new notation to do so). I personally feel that there is sufficient beauty and elegance (once the notation is understood) in diagrammatic proofs of these "old proofs" to make them interesting. I also think that a deeper understanding of diagrammatic techniques is a worthy goal in itself. Others have mentioned some of the existing applications. The term "trace diagrams" originated in my thesis, so you won't find it in many published papers. I use it to mean the particular class of diagrams that are labeled by matrices. There are many other names. I first learned about them in the special case of "spin networks" (a special case), and Penrose has the strongest claim to historical priority, hence "Penrose tensor diagrams". 

You can use dynamic programming as you suggest in the title. Let $w_{ij}$ be the max gain you can get putting $j$ balls into first $i$ buckets. Then $w_{ij}$ has the following recursive relation: $$ w_{i,j} = \max_{0 \le t \le \min(N-1, j)}(w_{i-1,j-t} + \Delta l_{i, t}) $$ There $t$ is the number of balls you put into $i$-th bucket. Hence you can calculate $w_{K, \lambda}$ (your answer) in time $O(K \lambda N)$. 

If you consider only simple cycles (every vertex visited at most once) then this problem is NP-complete, so no polynomial (in $|G|$ and $k$) algorithm is known. If non-polynomial algorithms are ok, you can use dynamic programming algorithm with complexity $O(\sum_{i=0}^{i\le k}\binom{n}{i}n^2)$. This algorithm calculates for every subset $S$ of at most $k$ vertices and every vertex $v \in S$ from this subset the number of paths that goes through all vertices from $S$ and has $v$ as the last vertex.