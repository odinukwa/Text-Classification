I have a file under linux and have been trying to find a way to change the volume id without having to recreate the file. Most of the authoring tools such as provide a switch for setting the volume for example. However I can't figure out how to change it on a pre-existing file. For clarification, the bit I'm trying to change is this string. Here's an example dump from the isoinfo command. 

This will only allow them to run one command I believe. If you need to allow them more you can use . It's a script that has a file where you can specify commands that a person is allowed to run. 

Is this ? If so I got burned by this one as well. Check out the official CentOS 6 FAQ. The issue is that is now responsible for the device and by default it's disabled. During installation you can configure so that it will start up automatically, but the default is that it doesn't. If you need to configure this after you've setup the system you can follow the steps in the FAQ which tell you exactly how to setup the . The nuts of the fix are that you need to edit this configuration file, , and make sure that the line is enabled, i.e., . Here's a couple of screenshots of where to configure this during the CentOS installation. I totally missed it the first couple of times. 

I try to connect to a Windows Server 2008; I can get to the login screen but any login attempt fails. I tried local and domain users, admin/not admin... Using 'PsExec', I am able to open a remote command line. I created a new user (in case I was wrong about every single credential I tried ), and added it to local administrators. Still can't connect. (wrong username or password) It has been rebooted. I even disabled the firewall. What could prevent me from login successfully ? 

Turns out the DNS Server wasn't one that could resolve the domain controler name. I managed to change DNS settings thanks to psexec and netsh, and now I can login successfully again. I don't really understand why it has to resolve domain controler name even when one tries a local account. Also, about using psexec to change DNS settings, I was stuck because my inteface name contains accents, so I had to use the interface position in the interface list, which I had to specify in a binary way: 

We have a 2 backup machines that we use to manage via Remote Dektop Connection; Suddenly one of them can not be reached anymore by RDC. The other one is still accessible. I can ping the first one, even managed to restart it with the shutdown /r /computer commandline, but no way to access it on RDC. Any idea about what could have happened? How else could I take control over these remote servers ? The inaccessible one runs Windows Server 2008, the other one runs Windows 7. EDIT: We got an operator to directly log on the machine at the datacenter, turns out that the firewall configuration wasn't allowing remote access. We have no idea what happened, maybe a windows Update set the firewall configuration back to a more secure one ? 

For what you're doing, you're probably fine running on regular hardware. But it's always worth learning about things. As mentioned, server hardware is really designed for reliability. You get things like ECC RAM, dual or quad CPU sockets, redundant power supplies and fans, RAID for your hard drives among other things. You can also generally build "bigger" boxes than you can with "standard" hardware which is beneficial for maintenance (fewer boxes) and solutions like Virtualization (pretends to be more boxes). Google doesn't do that sort of thing and takes the approach I think you'd be comfortable with, use cheaper hardware and replace it when it fails. Google's redundancy and scaling is horizontally (more boxes). The advantage here is it's cheaper to buy at the cost of complexity of overall architecture. Applications need to be designed differently and how the overall system functions can get more complicated. You need to add load balancers and such which may or may not be possible. Assuming downtime isn't a huge concern of yours, I'd say stick with the low cost hardware, backup things properly and replace stuff if/when you need to. 

You could also do this using virtual hosts and setup Apache as a reverse proxy. This is how I have it setup where I work. 

The key line in that output is the . That defines where Apache's directory is to start, in my case, when looking for config. files and modules. NOTE: This is not the same thing as . This is specific to how the daemon was compiled, the is for specifying where the daemon should start looking for actual web content (.html files and such). For my file I have the following Load lines: 

According to the documentation for the Domain XML format, is a supported command taking as an : $URL$ These links were helpful: 

It sounds like a switch failing to me. You can use the app to scan your network or a single device and it will show you some additional information about the manufacturer of the NICs you're scanning. 

Look in Apache's config files. The main file is located here: There should also be a bunch of files under here: . One of them in the 2nd location may even be called or some such. Look through these files and you'll see a section that is telling Apache to look in the . Probably something like this: 

In looking through the output of an against our GS724T Netgear switch I was surprised that it doesn't list what MAC address(es) are connected and/or using a given port on the switch. This would seem to be useful information. Is this just a limitation of the GS724T? I see it's labeled as a "Smart Switch" which would seem to indicate that it's subpar to a fully managed switch, yet something as basic as collecting the MACs would seem like something that should be included, even in a lower level switch such as this. When I run the the following command I only am getting back the MAC address of the switch on each port. 

We used to work with a local Apache instance (WAMP) as a development environment, but we installed recently a PRTG server on the same machine, so it listens to the same port, as it is a web-based tool. We are not able to reach our Apache server anymore as web requests on the server IP keep going to PRTG. I changed the PRTG listening port to 8080 so that we would have 2 web servers listening to 2 dfferent ports. It doesn't seems to work well: when I try to reach xxx.xxx.xxx.xxx:80 with a browser (Firefox, Chrome) it instantly changes to xxx.xxx.xxx.xxx:8080, and I get to PRTG home page. Why does it changes from what I requested ? Should I use a totally different non-standard port ? What solutions do I have ? 

I have 2 PC with the same configuration. I open an Excel File (~5M) on the network from both PC. The opening is not the fastest but that's ok. The problem is that on one PC, Excel is really slow. I mean if I hit the left arrow 10 times, I will have finished hitting like 3 seconds before the active cell is the next 10th one. The file contains graphics that takes time to initialize on the slowed computer. Both PC have the same graphic cards, same driver version; both remote access to the file on a local network. Both configured to perform calculations automatically. Both Excel 2007. Both Windows 32bit. On the other PC it runs really fast. I really don't know what to check next. Any suggestions ? 

See this tutorial for more details. EDIT #1 Another suggestion would be to try escaping double quotes rather than use single quotes: 

If you take a look at the rules that are included with you'll notice that they use these variables to make things neater and more parameterized. For example in the included they've used them to make general action rules that they can then use when defining the various jails. Example Here are some basic variables at the top. 

There are some potential solutions you could try in this AWS developers forum. $URL$ For example: potential fix #1 

You can use a tool such as kismet, $URL$ to scan for wireless networks. I believe it can show you all wireless devices in your vicinity without having to have the devices being actively connected to same network.    This post should give you a rough idea of how to accomplish the scanning of the network using Kismet. $URL$ Also as a side note you can use this tool, fing, $URL$ to find out all the addresses of the devices on your network. 

The order is based on the RaidDevice numbers. These are the numbers in the square brackets of the lines like this: 

Why did this happen? I've had these happen from time to time when one of the members gets out of sync. However if they continue to occur then it's likely a good indication that one of the members is starting to fail, and so you should heed the warning and fully diagnose all the members to make sure they're in good health and also identify which HDD (member) is failing and plan to replace it sooner rather than later. Some distributions may perform a check periodically so you might be getting your array in this state due to these scheduled checks. I believe Debian/Ubuntu may perform a check like this weekly, look for a entry in your system's crontab files or /etc/cron.d directories. Lastly you can manually trigger a check such as this by echoing the command "check" to the RAID's file under . Example As root: