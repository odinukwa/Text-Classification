Partial answer: It is consistent with ZF that Q has a non-deterministic winning strategy.$\newcommand{\R}{\mathbb{R}} \newcommand{\N}{\mathbb{N}}$ First note that if $C(n)$ is ever reduced to a countable set $\{x_i\ |\ i \in \N\}$, then Q can win just by going through the singletons $\{x_i\}$ one by one; A must reject each in turn to avoid making $C(n+i)$ a singleton, and so in the end $C(\infty)$ is empty. Now, suppose that the reals can be expressed as a countable union of countable sets, $\R = \bigcup_{i \in \N}R_i$. (This is consistent with ZF.) Then Q can start out by listing the sets $R_i$. If A ever chooses $A_i = R_i$, then $C(i)$ is reduced to a subset of $R_i$, so is countable, so by the first note above, Q can win. Otherwise, if A always chooses $A_i = R_i^c$, then since $\R = \bigcup_i R_i$, Q wins in the end as $C(\infty)$ is empty. Note, however, the non-determinism required: Q cannot choose a full deterministic strategy in advance, since that would require choosing an enumeration of each $R_i$; and this cannot exist, since it would render $\R$ countable. 

In my experience, Enderton’s definition is far more prevalent. Certainly in categorical logic and the areas of proof theory I’m familiar with, it’s almost always what’s intended. On the other hand, $\Gamma \vDash \varphi$ is most often used when $\Gamma$ is some theory, i.e. a set of closed formulas, in which case they are equivalent. The difference appears only when $\Gamma$ and $\varphi$ share free variables. Bilaniuk’s definition (universally closing the two sides separately) is certainly coherent in itself. But Enderton’s definition (universally closing over the whole relation) has various nice properties which Bilaniuk’s lacks: 

See e.g. Where in ordinary math do we need unbounded separation and replacement? for a similar question, about different axioms, and relevant discussion of what should be considered “ordinary mathematics”. 

Regarding the interpretation of logic in the sequence $V_\alpha$: The simplest approach is to assume an inaccessible cardinal $\kappa$ larger than $\P$, and cut off at $\kappa$ on both the topos-theoretic and set-theoretic sides. So the model on the topos-theoretic side is just $(V_\kappa,\in_\kappa)$, and the interpretation of (I)ZF in it is the standard interpretation of first-order logic in a structure in a topos using the Kripke–Joyal semantics. On the set-theoretic side, one then correspondingly restricts the Boolean-valued model to “hereditarily $\kappa$-small $\P$-names”, i.e. $V\P \cap H_\kappa$. Then there’s Fourman’s approach, which is to work with the full sequence $V_\alpha$ for $\alpha \in \mathrm{On}$, and define the interpretation of logic in it by hand, in a way which clearly follows the normal Kripke-Joyal semantics except that its quantifications quantify over the whole sequence. Finally, the modern viewpoint on Fourman’s interpretation is the categories of classes setting, developed for Algebraic Set Theory. One can embed the topos $\E$ into a super-large category of classes $\E'$, whose objects are to the objects of $\E$ what classes are to sets in (I)ZF. In general, $\E'$ can be taken to be a category of ideals on $\E$; when $\E$ is a topos of sheaves on a small site, $\E$ can be taken to be a topos of “large sheaves” on the same site. Either way, $\E'$ is a Heyting category, so one can interpret first-order logic in it, and under the “large sheaves” presentation of $\E'$, this interpretation looks exactly the usual Kripke–Joyal semantics of a topos. And then in $\E'$, we can take the colimit of the sequence $(V_\alpha,\in_\alpha)$, and use that as our model. 

I think in practice, most people would (if pressed) describe the definition they're using as something like the Mac Lane definition, plus being allowed to replace either category with another equivalent category [where "equivalent" means "with a chosen equivalence in mind"]. This is clearly not equivalent to the unmodified Mac Lane definition. (E.g. the "walking isomorphism" $I$ has a ML-subobject that is discrete on two objects, but $I$ is equivalent to to the terminal category $1$, which has no subcategory equivalent to a discrete cat. on two objects.) This is equivalent to the definition "a subobject is a faithful functor". Precisely, given a category $\mathcal{C}$, we can define two 2-categories, $\mathrm{SubCat}(\mathcal{C})$ and $(\mathrm{Cat}/C)_\mathrm{faithful}$, with objects respectively 

Consider the space $\mathbb{Z}^\mathbb{N}$ of integer sequences $(n_0,n_1,\ldots)$, and take $R$ to be its ring of endomorphisms. Then the ``left shift'' operator $$(n_0,n_1,\ldots) \mapsto (n_1,n_2,\ldots)$$ has plenty of right inverses: a right shift, with anything you want dropped in as the first co-ordinate, gives a right inverse. I recall finding this example quite helpful with the exercise ``two right inverses implies infinitely many'' — taking a couple of the most obvious right inverses in this case, and seeing how one can generate others from them. 

so together they say exactly that it’s an iso, which is what the usual definition says. * For a general colimit, we’d need to use “the equivalence relation generated by $\sim$” (which is still something finitary), but if the colimit is filtered, so a fortiori if it’s $\kappa$-filtered, then $\sim$ is already an equivalence relation. 

As I see it, these (and a few other such examples) are the intuitively natural seeds from which the various abstractions and generalisations of orientation grow, and whenever I have trouble seeing why some choice is made the way it is, chasing it back to something like this usually resolves the question. Looking outward: the ideas in 1 and 2 are the first steps down the path of combinatorial approaches to orientation, where the orientaion is on entire simplices, as seen in simplicial complexes like you sketch. No. 3 points down a different path, to more geometric notions of local orientation at a point, which can be expressed in terms of local homology groups, among other ways; Hatcher's excellent free book has a nice treatment of this, with really good examples/exercises, in Section 3.3 under "Orientations and Homology". 

Classical axiomatic set theories (eg ZFC, NGB) are formulated in first-order logic with equality, so any things you can quantify over (i.e. that you can talk about as actual objects of the language), you can talk about equality of, as a basic given of the language. In particular, in either ZFC or NGB, you can certainly talk about equality of vector spaces. In ZFC, you can’t talk about beasts as quantify-over-able objects (since they can only be represented as proper classes, not as sets); in NGB, you can, and so you get equality of them. Cardinality is a bit slipperier: it’s generally considered as a defined rather than a basic notion, and the exact definitions used vary in ways your question will be sensitive to. Most often, an object called the “cardinality” is only specifically defined for sets[1]; for classes, “C and D have the same cardinality” is considered syntactic sugar for “there is a class-bijection between C and D”. So it’s not quite clear what it means to ask if a class “has cardinality”, but whatever it is depends heavily on having an equality relation on it, to be able to talk about bijections to/from it. 

Here are two main ideas which I found helpful when I was learning this stuff (very basic and handwavy, but good starting points to see where more precise and sophisticated statements are going): 

This corresponds clearly to the direct product of the (non-strict) partial orders $\leq_X$, $\leq_Y$ corresponding to $<_X$, $<_Y$. However, it’s not their direct/cartesian product as strict partial orders — or at least, it would be misleading to call it either of those, since those have another more obvious meaning. But presumably many other people must have had cause to make use of this product at some point or another. Does it have a well-established name? 

An awfully simplistic answer: we work on two-dimensional paper, so two-dimensional matrices are very convenient to write down and compute with, while higher-dimensional hypermatrices are not. So while we could represent multilinear forms, tensors, etc. as hypermatrices, we often don’t, because doing so is not nearly as fruitful as representing linear maps, bilinear forms etc. as matrices. Instead, we usually use other notations when working with higher tensors by hand. In computer algebra, the dimension of the paper is not significant, while some kinds of abstraction are harder, so in this context, higher tensors are much more often represented as hypermatrices. 

As Kevin points out, one can't ask for a representing family of sections that are equal on every intersection. However, the description can certainly be restated pointlessly. For $f,g \in \mathcal{F}(U)$, define $f \approx g$ if there's a cover $U = \bigcup_i U_i$ such that for each $i$, $f|_{U_i} = g|_{U_i}$. Read this as “$f$ and $g$ are equal on a cover”. In pointy terms, $f \approx g$ iff all their germs are equal: for every $x \in U$, $f_x = g_x$. Now, every section $f \in \mathcal{F}^+(U)$ of the sheafification can be represented by a weakly matching family in $\mathcal{F}$: that is, a cover $U = \bigcup_i U_i$, and sections $f_i \in \mathcal{F}(U_i)$, such that for each $i,j$, we have $f_i|_{U_i \cap U_j} \approx f_j|_{U_i \cap U_j}$. (This is immediate from the representing families you exhibit in the question.) Similarly, two weakly matching families are $(f_i), (g_j)$ are equal as sections of the sheafification iff for each $i, j$, we have $f_i|_{U_i \cap V_j} \approx g_j|_{U_i \cap V_j}$. So the sections of $\mathcal{F}^+$ can be described exactly as equivalence classes of weak matching families from $\mathcal{F}$. This is a standard way of constructing sheafification on general sites, known as the “double plus-” or “$(-)^{++}$-construction”; see e.g. the Mac Lane and Moerdijk book Sheaves in Geometry and Logic for more context. 

Background: I’ve been playing around with implementing the algorithms from Ross Street’s “The Algebra of Oriented Simplices” (and related papers) in Haskell/Agda, and this ordering turns out to make a computationally convenient stand-in for his $\lhd$ order, in places. 

The earliest instance I’ve been able to find is in Paul Taylor’s diagrams package, from ≤1994, as mentioned in e.g. the changelog notes for v3.81 at $URL$ . But it seems more likely that this was to meet the demand for a notation that was already established, rather than being the origin? But looking at various well-known category theory textbooks from before 2000 (Mac Lane Categories for the Working Mathematician; Mac Lane and Moerdijk Sheaves in Geometry and Logic; Borceux Handbook of Categorical Algebra; Johnstone Topos Theory), none of them seem to use it, as far as I can find. 

No. Consider the set of all pairs $(x,n,i)$, where: $x$ is the code for a Turing machine $T_x$; $n$ is a natural number; and either $i=1$ and $T_x$ halts on input $n$, or $i=0$ and $T_x$ diverges on $n$. This set is certainly countable (it’s isomorphic to $\mathbb{N}^2$, just by forgetting the $i$-component). But if we had a Turing machine that enumerated it, then we’d have solved the halting problem: given any code $x$ and input $n$, to work out if it halts, just wait until the machine spits out either $(x,n,0)$ or $(x,n,1)$. (Formally: write a new Turing machine to simulate the running of the first one and “watch” for an appropriate value appearing.) Generally, subsets of $\mathbb{N}$ that can be given in the manner you describe are called computably enumerable, or recursively enumerable. It’s a fundamental concept of computability theory; it’s a much stronger notion than countability. Also note that countability is defined as a predicate on abstract sets; it’s not clear what computable enumerability of a set means in the abstract, only for subsets of $\mathbb{N}$ and similarly presented objects.