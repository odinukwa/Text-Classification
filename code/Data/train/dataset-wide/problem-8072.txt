The reasoning I have for thinking of this is because of field extensions. By defining the field $F = \{\mathbb{Q},\cdot,\oplus\}$ where $x \oplus y = q(q^{-1}(x) + q^{-1}(y))$. We can take the polynomial ring $F[X]$ and talk about $F[X]/p$ for some irreducible polynomial $p$--which is isomorphic to some field extension $F(\alpha)$. Now let's make the convention $p(\alpha) = 0$, then this can be thought of as $$0 = p(\alpha) = a_n\alpha^n \oplus a_{n-1}\alpha^{n-1} \oplus...\oplus a_0$$ $$p(\alpha) = q(q^{-1}(a_1)q^{-1}(\alpha)^n + q^{-1}(a_{n-1})q^{-1}(\alpha)^{n-1} +...+q^{-1}(a_0))$$ so that $$0 = q^{-1}(a_1)q^{-1}(\alpha)^n + q^{-1}(a_{n-1})q^{-1}(\alpha)^{n-1} +...+q^{-1}(a_0)$$ Therefore if $q^{-1}(\alpha) = \beta$ and $b_n = q^{-1}(a_n)$, then $\alpha = q(\beta)$ where $\beta$ satisfies $$b_n\beta^n + b_{n-1}\beta^{n-1} + ... + b_0 = 0$$ This definition is consistent with the taking roots version. If $\beta$ satisfies $\beta^2 - 2 = 0$, then $q(\beta) = \alpha$ where $\alpha^2 \ominus 3 = 0$, aka $q(\sqrt{2}) = \sqrt{3}$. (Where the meaning of $\ominus$ should be self evident). However, as you may have noticed, this does not "choose" which root of the polynomial corresponds to $\beta$. As in $q(\sqrt{2}) = \pm\sqrt{3}$. Nor does it explicitly give a manner of producing said $\alpha$. $\alpha$ just exists in the "isomorphic algebraic numbers" generated by the algebraic closure of $\{\mathbb{Q},\cdot,\oplus\}$ which coincides with roots. And for higher-order polynomials this becomes a serious problem. This led me to two different questions. 

Take the straight forward Fibonacci equation $$F_0 = F_1 = 1$$ $$F_{n-2} + F_{n-1} = F_n$$ Let's consider a holomorphic function $F: \mathbb{C} \to \mathbb{C}$ such that $$F(z)\Big{|}_{\mathbb{N}} = F_n$$ $$F(z-2) + F(z-1) = F(z)$$ Let's call such $F$, those that satisfy the Fibonacci equation in the complex plane. It is very easy to produce such functions. Taking the Binet identity $$F_n = \frac{\phi^{n} - \psi^n}{\phi - \psi}$$ where $$\phi = \frac{1 + \sqrt{5}}{2}$$ $$\psi = \frac{1 - \sqrt{5}}{2}$$ It follows for any $k,j \in \mathbb{Z}$, using the standard branch of $\phi^z$ and $\psi^z$ that the functions $$F_{jk}(z) = \frac{e^{2\pi i j z}\phi^z -e^{2 \pi i k z}\psi^z}{\phi - \psi}$$ are a solution of the Fibonacci equation in the complex plane. These can't be all solutions though. Namely if $F$ and $G$ are solutions where we've simply chosen different $k$ and $j$ for each one, then $$\frac{F}{2} + \frac{G}{2}$$ is equally a solution, which corresponds to no function from our list. This additionally implies that the infinite sum $$\mathcal{F} = \sum_{j=-\infty}^\infty \sum_{k=-\infty}^\infty a_{jk}F_{jk}(z)$$ is a solution to the Fibonacci equation in the complex plane if it converges everywhere and $$\sum_{j=-\infty}^\infty \sum_{k=-\infty}^\infty a_{jk} = 1$$ 

I'll state the theorem I am posing up front, and then explain why I think this theorem appears to be true. I am asking if anyone can prove it, or knows references to where it is proved. Please, forgive me if it is trivial, or if a counter example is trivial too. 

There is an obliquely difficult problem when iterating the sine function to fractional numbers, namely that it has a neutral multiplier about its fixed point at zero. The goal is to find a function $\sin^{\circ q}(x)$ where $$\sin^{\circ q}(x) : \mathbb{R}^+ \times \mathbb{R} \to \mathbb{R}$$ $$\sin^{\circ q_0}(\sin^{\circ q_1}(x)) = \sin^{\circ q_0 + q_1}(x)$$ But the $\sin$ function proves to have quite a few barriers, where in other cases (like with $\cos$) these barriers don't appear. To set the scene, I'll say what I can prove. Let there be a sequence of functions $\{f_n\}_{n=1}^\infty$ where $f_n(z) = (1-\frac{1}{n})\sin(z)$ and some preliminary facts are $$f_n(0) = 0$$ $$f'_n(0) = 1-\frac{1}{n}$$ There is an immediate basin $I_n$ about $0$, the maximal connected set about $0$ where $\lim_{k \to \infty} f_n^{\circ k}(z) \to 0$ for all $z \in I_n$. Using these functions we can take the exponential generating function of $f$'s iterates and we have $$\vartheta_n(t,z) : \mathbb{C} \times I_n \to \mathbb{C}$$ $$\vartheta_n(t,z) = \sum_{k=0}^\infty f_n^{\circ k + 1}(z)\frac{(-t)^k}{k!}$$ This function is holomorphic in both variables. By taking a modified Mellin transform we can construct $\phi_n(s,z):\mathbb{C}_{\Re(s) > 0} \times I_n \to I_n$ where $$\phi_n(s,z)\Gamma(1-s) = \sum_{k=0}^\infty f_n^{\circ k+1}(z)\frac{(-1)^k}{k!(k+1-s)} + \int_1^\infty\vartheta_n(t,z)t^{-s}\,dt$$ And $\phi_n(s_0,\phi_n(s_1,z)) = \phi_n(s_0+s_1,z)$. This implies that $\phi_n$ is a fractional iteration of $f_n$. When $z$ and $s$ are restricted to be real, so that $s = q \in \mathbb{R}^+$ and $z = x \in \mathbb{R}$, then we've constructed a fractional iteration of $f_n(x) = (1-\frac{1}{n})\sin(x)$ on the real line. Let's denote $\phi_n(q,x) = f_n^{\circ q}(x)$. The natural idea, to find a fractional iteration of $\sin$ is to take $$\lim_{n\to\infty} f_n^{\circ q}(x) = \sin^{\circ q}(x)$$ Since there is no set $I$, which is a connected open set about the point $0$, where $\sin^{\circ k}(z) \to 0$, we lose a lot of complex analytic ground, and it's hard to say whether $\sin^{\circ s}(z)$ exists because talking about where $z$ lies is a mess. This is simply because $\sin'(0) = 1$. Instead we're stuck talking about the real line $z = x \in \mathbb{R}$ and only real positive iterates $s = q \in \mathbb{R}^+$. I thought about exploiting the fact we're working with an integral transform. We can say that there exists $I$, a neighborhood of $\mathbb{R}_{\neq 0}$, where $\lim_{n\to\infty} \vartheta_n(t,z) = \vartheta(t,z)$ for all $z \in I$ uniformly in both variables (on compact subsets). And this is where I'm stuck. If I can prove that for all $\Omega \subset I$, with $\Omega$ compact, letting $z \in \Omega$, for any $\epsilon > 0$ and any $\sigma < 0$ there exists $N$ such when $n,m > N$ that $$\int_{1}^\infty |\vartheta_n(t,z) - \vartheta_m(t,z)|t^{\sigma}\,dt < \epsilon$$ then we can show that in fact $$\sin^{\circ q}(x) \Gamma(1-q) = \sum_{k=0}^\infty \sin^{\circ k+1}(x)\frac{(-1)^k}{k!(k+1-q)} + \int_1^\infty\vartheta(t,x)t^{-q}\,dt$$ is analytic in $x$ and analytic in $q$ and satisfies the required functional equations $$\sin^{\circ q}(x) : \mathbb{R}^+ \times \mathbb{R} \to \mathbb{R}$$ $$\sin^{\circ q_0}(\sin^{\circ q_1}(x)) = \sin^{\circ q_0 + q_1}(x)$$ So essentially my question is, what are some plausible manners of showing that $\vartheta_n \to \vartheta$ in this modified $L^1$ norm? 

A composite square root of a function $g$ is a function $f$ such that $f(f(z)) = g(z)$. Not surprisingly, for arbitrary $g$ a function like this is hard to find. Specifically I am looking at functions $g$ such that $g$ has finite nonzero order, so that $$0 < \limsup_{r\to\infty} \dfrac{\log\log M(r)}{\log r} = \rho < \infty$$ where $M(r)$ is the max of $g(z)$ on the disk of radius $r$. Now naturally $\cos(\cos(z))$ has a square root function $\cos$, or $e^{e^z}$ has one, but these functions are of infinite order. Similarly with polynomials, any polynomial $p(p(z))$ has a square root function, but these are of zero order. The special case of functions of finite order, is that a possible square root function is of zero order. Which is an argument simple enough (I'll provide it if asked). The evidence I am seeing piling is that there exists no entire composite square roots of functions $g$ of finite order. Now if $I$ is the immediate basin about a geometrically attracting fixed point of $g$ (and $I$ is simply connected) then there is an $f$; but $f$ only sends $I \to I$ and is not entire. I'm wondering if this is always the case; that a composite square root cannot be entire. Taking $g(z)=e^z$ for example, if there were such an $f$, then $f(f(z))$ can't equal zero, so that $f(z)$ misses $f^{-1}(0)$ but then $f(f(z))$ must miss $0$ and $f^{-1}(0)$ and must therefore be constant by Picard's theorem. If $f^{-1}(0)$ is empty than $f(f(z)) = e^z$ misses $0$ and $f(0)$. This argument generalizes for all $e^{P(z)}$ where $P$ is a polynomial. Therefore the only possible cases where there is an $f$ for arbitrary $g$ are when $g$ is surjective on $\mathbb{C}$. This doesn't work for $\cos$ though, because $\cos$ has all its zeroes in $I$, the immediate basin about $z_0 \in \mathbb{R}^+\,\,\, z_0 \approx 0.739085$. It can be shown that if $f$ were entire all it's zeroes are described by the sequence $\{f(\pi/2 + n\pi)\}_{n=-\infty}^\infty$, but $f$ is necessarily periodic (again an argument I will supply if asked) so that $f$ would only have two zeroes $\pi/2$ and $3\pi/2$ and thus by Hadamard's factorization theorem $f(z) = C(z-f(\pi/2))(z-f(3\pi/2))$ which is obviously wrong. Thus no entire square root of $\cos$. The same argument applies for $\sin$ just as well but is a bit more finicky. As much as I look, the only possible candidates are when we have an entire function $f$ of zero order and we compose it with itself $f(f(z)) = g$ and $g$ is of finite nonzero order. I've yet to come across an example of such a function though. Can anyone even name such a function? So all in all my question is rather simple. For an entire function $g$ of finite nonzero order, can there exist an entire function $f$ such that $f(f(z)) = g(z)$? 

I'm not 100% on this (forget where I read it) but fractional calculus can deal with this problem. This is too long to post as a comment but I think it might help. If we take the Riemann-Liouville operator $D^{a}$ that satisfies $D^a x^b = \frac{\Gamma(b+1)}{\Gamma(b-a+1)}x^{b-a}$ it gives $D^{\Delta_0}f(x)\Big{|}_{x=0} = \Gamma(\Delta_0 + 1)a_0$. To solve $a_1$ just take $D^{\Delta_1}(f(x) - a_0x^{\Delta_0}) \Big{|}_{x=0}$, and iterating $$\Gamma(\Delta_n + 1)a_n = D^{\Delta_n} (f(x) - \sum_{j=0}^{n-1} a_jx^{\Delta_j})\Big{|}_{x=0}$$ Now you have to know $\Delta_n$, and that the expansion exists, but this solution should work. To find the operator $D^a$ just google Riemann-Liouville Differintegral. 

I like this question so I thought I'd bump it and give my two cents. We'll denote $I$ as the immediate basin of the fixed point $x_0$ on the real positive line. This is the largest connected set about $x_0$ wherein $\lim_{n\to\infty} \cos^{\circ n}(x) \to x_0$. And we'll denote $\Psi$ as the Schroder function of $\cos$ about $x_0$--the function which linearizes $\cos$ i.e: $\Psi(\cos(x)) = -\sin(x_0)\Psi(x)$. Naturally in a neighborhood of $x_0$ there are two half iterates $$f_{01}(x) = \Psi^{-1}(\sqrt{-\sin(x_0)}\Psi(x))$$ for both branches of $\sqrt{}$ ($f_0$ and $f_1$ denoting different branches.). Now, these functions can be lifted to functions $f_{01} : I \to I$. The formula is a little cumbersome but essentially is the following (the proof is exhausting and my own so I'll leave it out). Define: $$\vartheta(x,t) = \sum_{n=0}^\infty \cos^{\circ 2(n+1)}(x)\frac{t^n}{n!}$$ and for $0 < \Re(z) < 1$ $$\phi(x,z) = \frac{1}{\Gamma(1-z)}\int_0^\infty \vartheta(x,-t)t^{-z}\,dt$$ which satisfies $\phi: I\times\mathbb{C}_{0 < \Re(z) < 1} \to I$ in $x$ and locally about $x_0$ looks like $$\phi(x,z) = \Psi^{-1}(\sin(x_0)^{2z}\Psi(x))$$ choose $z_0$ and $z_1$ so that $\sin(x_0)^{2z_{01}} = \sqrt{-\sin(x_0)}$ for each branch of $\sqrt{}$ and voila $\phi(z_0,x) = f_0(x)$ and $\phi(z_1,x) = f_1(x)$. We've analytically continued $f_0$ and $f_1$ to the immediate basin. These are also the only analytic solutions to the equation $$g : I \to I$$ $$g(g(x)) = \cos(x)$$ They are NOT real to real, which is all to do with the multiplier $-\sin(x_0)$ which is negative; there are no real square roots of negative numbers = there are no real composite square roots of functions with negative multipliers. Similarly for the function $h(h(h(x))) = \cos(x)$ there are 3 solutions, and only one of them is real to real (just like there are three cube roots of negative one and only one of them is real). Just as well, there are four solutions to $q(q(q(q(x)))) = \cos(x)$ and none are real to real (there are no real fourth roots of $(-1)$). So on and so forth. Now I don't have a rigorous proof of the following, but it seems obvious enough that $f_0$ and $f_1$ are defined on their maximal domain. $\partial I$ is part of the julia set, and the function $\vartheta(x,t)$ diverges on the julia set because $\cos^{\circ 2(n+1)}(x)$ grows super exponentially with $n$ and the factorial no longer does its job. I think this is good intuition in inferring that $f$ has no extension to a larger domain. I could be wrong though--it'd be nice to see $f_{01} : \mathbb{C} \to \mathbb{C}$. 

I'll post my comment here. If $f(x,y)=x\oplus y$ and $f(x,y)$ is differentiable in $x$ and $y$ then $f(x,y) = \log_b(b^x + b^y)$. (I'm ignoring that $x \oplus y$ has no identity element (which would be $-\infty$ ad hoc)). by def $f(x,y)+c=f(x+c,y+c)$. Taking $F(x,y)=e^{f(log(x),log(y))}$ then $F(x,y)⋅c=F(cx,cy)$. Taking associativity and commutivity in to consideration; if i'm not mistaken the only differentiable solution to $cF(x,y)=F(cx,cy)$, $F(x,y)=F(y,x)$ and $F(x,F(y,z))=F(F(x,y),z)$ is $F(x,y)=\sqrt[r ]{x^r+y^r}$, and therefore $x \oplus y = \log_b(b^x+b^y)$ with $r = \log(b)$. QED $r$ can then be found for arbitrary $\oplus$ by plugging in values. 

When learning the derivative and its various rules, the intuitive undergrad way of proving the product formula kind of does this. We add an $f(x+h)g(x) - f(x+h)g(x)$ and the product formula just pops out. Of course I've never seen this proof rigorously done. I've just seen it used as an ad hoc way to convince people not fluent in epsilon-delta. 

Secondly, if we consider $q:\mathbb{Q}\to\mathbb{Q}$ and we wish to extend it to $\mathbb{Q}(\alpha)$ then if $q:\mathbb{Q}(\alpha) \to F(\beta)$ there should exist multiple extensions (i.e: a $q_{-}$ and $q_{+}$ where $q_{+}(\sqrt{2}) = \sqrt{3}$ and $q_{-}(\sqrt{2}) = -\sqrt{3}$). If we were to add multiple field extensions, the intuition would say we would compound the amount of extensions of $q$. For instance, if $q = (1\,2)(3\,4)$ (swap 2 and 3, and swap 5 and 7) then the field extension $Q(\sqrt{2},\sqrt{7})$ has four possible $q$'s extending its definition $q_{ij}(\sqrt{2}) = (-1)^{i}\sqrt{3}$ and $q_{ij}(\sqrt{7}) = (-1)^j\sqrt{5}$ for $i,j = 0\,\text{or}\,1$. But are these definitions compatible when adding multiple field extensions? I was only able to really construct it with a Galois extension (I think I mean a Galois extension). Would this still continue to work if say, we took $\overline{\mathbb{Q}}$, we added all algebraic numbers to $\mathbb{Q}$. Therein, my gut says to ask: 

Assume that $f(z)$ is a holomorphic function that sends some open and connected set $G$ to itself. Assume $f$ has a single fixed point $z_0$. Assume $f(f(...(n\,times)...f(z))) = f^{\circ n}(z) \to z_0$ as $n \to \infty$ for all $G$. By consequence $|f'(z_0)| < 1$. Let us additionally assume $f'(z_0) \neq 0$. This allows us to conclude there is a Schröder function $\Psi : G \to \Psi(G)$ such that $$\Psi(f(z)) = f'(z_0)\Psi(z)$$ $$\Psi'(z_0) = 1$$ which also means $\Psi$ is injective in a small neighborhood about $z_0$. Let us take $g$ which satisfies the exact same criteria as $f$. It has a Schröder function too, say $\Phi:G \to \Phi(G)$.