I am using A Concise Dictionary of Old Icelandic and An Introduction to Old Norse (by E. V. Gordon) as my resoources. In An Introduction, it is said that: 

I'm reading the paper Constraints on Null Pronouns by Speas, in which the author defines two constraints for a cross-linguistic OT analysis of the occurrence of null pronouns across languages: 

The neuter noun kné follows a-stem declension. But it comes from Proto-Germanic *knewą. This seems to be a wa-stem. Then why does it follow a-stem declension? Did Scandinavians force it to, even though it was wa-stem noun? 

I don't understand the text in bold at all. Does it mean the gen. sg. ending might be either -s or -ar, or does it mean something else? Also, in A Dictionary, I find (-s, -ar) written right next to noun entries, like this: 

When you write down the semantic representation of a sentence (lambda calculus) you see that the determiner "consumes" the noun. Hence, it is the semantic head of a noun phrase. SEOP has a comprehensive overview of the phenomena that led to this, but Wikipedia is not bad either. In syntax, the noun is considered the head of the noun phrase because it is the more "contentful" part, in the way people understand sentences. In HPSG, the CAT derivation is somewhat like the regular phrase-structure derivation, with heads having a correspondence to phrase-structure (PS) heads. (Though, AFAIK, there is no need for the concept of "head" in PS.*) The CONT derivation is somewhat like the derivation in Montague semantics. These are not two different types of parsing in HPSG (or anywhere else, AFAIK), but two (of the many) aspects of parsing with a rich grammar like HPSG. Benefits: I don't think you can compare one with the other for benefits... if you go through the references I gave for quantifiers, you'll see that the mathematics would become very cumbersome and ugly (or maybe even impossible... I don't know) if you try to make the semantic heads correspond with PS heads. * Though some parsing techniques find it useful to have heads of a PS marked. 

Say we want to know whether his son or the product is the subject of this sentence. Relying solely on the fact that subjects can be clefted in English does not help us determine which of the two NPs is the subject. It is better to test with yet another syntactic construction until only one of the NPs is eligible to a construction, such as matrix-coding-as-object: 

Modern Icelandic maður is from Old Icelandic maðr. To relate the latter to the former, I would say "Old Icelandic maðr is the ___ of Modern Icelandic maður." What linguistic term goes in the blank? Is there another term for a meaning the other way round, i.e., that fits the blank in this sentence: "Modern Icelandic maður is the ___ of maðr." I thought about ancestor for the first blank and descendant for the second, but I am not sure if this is correct linguistic terminology. 

People had already given me the answer I was looking for, but as comments to the question. I'll just paste them here for posterity, and mark the question answered. jlawler: 'Receiver' is not a grammatical term; I assume you mean 'modify'; and what you call a 'complement' is called an 'object'. Prepositional phrases can modify other phrases or whole clauses, as well as nouns. With an umbrella modifies the woman, a noun phrase; it's identificational, describing the woman. With a telescope modifies saw the moon, a verb phrase; it's instrumental, describing the means used. He saw the woman with a telescope is ambiguous between these two meanings. Cerberus: Another useful term is scope, which more or less means "that which is modified", so the scope of the prepositional phrases is different between the two examples: in the first one, the scope of with an umbrella is (the) woman; in the second one, the scope of with a telescope is (John) saw the moon. Here is an interesting article about the scope of adverbial clauses, although it uses many technical terms at some point: Adverbial clauses, Functional Grammar, and the change from sentence grammar to discourse-text grammar. 

Since matrix-coding-as-object applies to his son but not to the product, now we are more confident that his son is the subject in (3). The above process is what I think is the utilization of syntactic phenomena that target subjects, which are observations that certain types of constructions only involve subjects (or potentially other grammatical relations as well), as tests for subjecthood in a sentence. By transforming a given sentence into constructions of one or more of these "certain types", we see if the resulting constructions are grammatical or not, and determine the subject based on such results. The more tests we apply, the more confident we are about our judgment. Is this process correct, or canonical in linguistics? From tests for subjecthood, can we possibly derive a cross-linguistic definition of subject? I personally don't consider this possible, since we are only "more confident" about a constituent being the subject of an examined sentence with increasing number of tests we apply; we are never 100% confident. 

You could go the BNF way too, if you prefer. (The NLP community prefers to call it CFG (Context Free Grammar)). You can find some online demos of these too. NLTK comes with an implementation you could play with. 

Are there other approaches... CCG is not the only logic-based grammar. There are others that closer to mathematics, in that, their derivation trees for sentences that look exactly like natural deduction proofs. I think the ACG guys have a working parser. I am not sure about the others like TLG, CVG, etc. 

Note that dependency graphs are (1) not a formalism and (2) not standardized, so each researcher may re-define what happens in dependencies. Some of those dependency graphs are not even trees. Refer Generating Typed Dependency Parses from Phrase Structure Parses. 

I assume by the "Binding Domain" of an α the author meant the Minimal Governing Category for α, which consists of: 

What books / resources about analysis on Esperanto (and English) are recommended to get me started on such comparison? 

I believe his soni _i to have stolen the product. *I believe the productj his son to have stolen _j. 

I know Esperanto is constructed on the basis of Romance languages; but what are the main differences and similarities between English and Esperanto? Especially from the following aspects: (how are words constructed and orderly connected? what classifications / parts of speech does English / Esperanto have?) vocabulary (from what languages does English / Esperanto borrow terms / derived words?) semantics (words in what languages share similar connotations and implications with English / Esperanto words?) 

I'll attempt an answer. The key issue is the contrast between lay intuition, and mathematical logic. Lay intuition tells us that nouns and verbs are the most 'contentful' parts of a sentence. Mathematical logic brings its rules for operators and their scopes. If we have the expression , we can't have the scoping wider than the outermost parentheses here. If an had some sort of a universal scope, for example, over too in , we'd soon have a formalism that only talks about constant terms in the universe. Such s would be useless as variables. Now, note that the logical terms that we introduce for describing sentences are based on the principle of compositionality. If we had used , and to derive , this would not correspond to what we understand of the phrase "some man". Instead, it would correspond to "there is a man". The proper expression for "some" would be . So, , and (after a bit of α-conversion to avoid name clashes) . Here are two more pieces of the puzzle: , and . We now have NPs that have become functions that accept Vs and VPs as arguments. Determiners, that play a subordinate role in Phrase Structures, play a key role here in controlling the scope of variables, and the order in which functions apply over arguments. Given this, if you were to apply the object over the verb, and then apply the subject over the resultant, you'd have the man and the woman each visiting a garden, that may or may not be the same garden. However, if you were to apply the subject over the verb, and then apply the object over the resultant, you'd have them both visiting the same garden. In all this, we haven't brought in (Neo-)Davidsonian Event semantics, so we have made no commitments at all about whether or not the visit(s) to the garden(s) happened at the same time. 

TL;DR: How can we use syntactic phenomena that target subject to design tests for subjecthood (or even possibly derive a cross-linguistic definition of subject)? I am reading Van Valin's An Introduction to Syntax. It has many interesting examples of "syntactic phenomena that target subject", for example, reflexivization, relativization, wh-question and cleft formation and so on. To my understanding, such phenomena often always target the subject but not necessarily exclusively so; they can sometimes target other grammatical relations, such as English cleft formation, which can certainly target direct objects as well as subjects, as demonstrated by the following sentences: 

My understanding is that the two constraints are close opposites to each other (one asks featureless pronouns to be bound, one asks pronouns to be unbound), and the important point of the author's argument is that different languages allow different occurrences of the null pronoun since they rank these two constraints (and 4 others she mention) differently. However the issue is whether this oppositeness always holds. I think that depends on whether the C-Domain of a null pronoun would always match with its Binding Domain, but I cannot answer my own question. Any thoughts? By the way, the author considers the null pronoun to be a featureless pronoun. Thus null pronouns are subject to both of the two above constraints. 

Code switching is common in India. So, even when writing to each other in English on facebook or IM, many Indians tend to insert phrases from one or more Indian languages. When people do that, they do not use one of the standard transliteration schemes. Most Sanskrit books, when printed for an English-speaking audience, use IAST. However, that's difficult to type on a computer. I prefer ITRANS, and that's what I'd recommend for you. "Is there a common way to phonetically transcribe Hindi?" In the "common way", people don't aim to be accurate; they just aim to be understood by a fluent speaker of Hindi. Since you're not a fluent speaker of Hindi, I advise against the common way.