records should not return records. Point your to the dynamic name and things should work. DNS tends to be cached so you may loose mail when your IP changes. Also use your ISPs relay server to send mail if your want reliable outbound delivery. EDIT: To fix the outbound addess: You should be authenticating to GMAIL to forward the email. Try using the GMAIL address in a header, and the desired address in the header. Alternatively, add a header with the desired reply address. Send yourself a message, and check the headers. The SMTP RFCs describe the headers which should be easy to understand. 

As other have noted, they are likely doing brute force scanning. If you are on a dynamic IP address they might be more likely to scan your address. (The following advice assumes Linux/UNIX, but most may be applied to Windows Servers.) The easiest ways to block them are: 

If you have control of the application, it should not matter if they could see other application paths. If the apps run with different UIDs, you only need to set permissions on the application directory to 700 so that other users can't see their files. Even if the user can enter paths to resources, you can sanitized the paths they enter. Limit the accepted paths to appropriate directories. There are a number of methods of providing configuration data securely. You may want to consider using a service repository/registry. If you have passwords or other sensitive data, it should be store in an encrypted format. 

is the likely the name KVM it chose when it created a bridge for you. It is difficult but not impossible to configure your own bridge. From my reading of the documentation on configuring bridges, you should have only one bridge connected to a physical device (eth0, bond0, etc). You could configure a second bridge and use IP forwarding to handle traffic routing. This is fairly easy to do. You should be able to tag multiple vlans on the same bridge. This is likely the simplest method. 

You may be able to get the internal addresses from an file. You will need to copy this to all servers. If you can't configure the file to have priority over the DNS servers, you could setup dnsmasq on a server and feed it the hosts file. Then configure the servers to refer to it. 

The application should use the domain from the request headers when reconstructing redirects, rather than the remote IP when creating a response If the redirects are send by your server, there are a couple of options, both of which can be used at the same time: 

Setup a server with the manager application and deploy the war there. The manager will show you what the URL path it deploys to. You can try that path on your real Tomcat server. For test deployments, I leave the manager application installed so that problems like this are easier to resolve. The application could also be deploying, but having other problems causing it problems binding to its context. 

I don't think you want to redirect in this case. The forms that they are posting from should post directly to www.mydomain.com, not mydomain.com. You can use a ServerAlias in the specification for the www.mydomain.com to include traffic addressed to mydomain.com. You may want to do limited redirects from pages on mydomain.com to www.mydomain.com. 

There are very strong performance reasons for first match. First match allows scanning to stop as soon as a packet matches. For this reason it is usual to put the ESTABLISHED,RELATED rules at the top of their chains. Without the first match rule each packet would need to matched against each rule in each applicable chain which becomes increasing expensive as the rule set grows. Busier firewalls are likely to to have larger rule sets, and could have performance problems with last match. Reading rule sets with a last match approach can be difficult as once you find the first match you don't know if you are done or not. Again this becomes more difficult as the rule set size grows. It is possible to add a rule after a previous rule, but have it appear ahead of the rule added earlier. This is done by using to add the rule rather than . Using the index of the rule you wish to bypass will keep the rules together in the chain. This approach may accomplish what you need to do if you are modifying a running set of rules. I would suggest ordering your rules so that they work with first match. I use Shorewall to build my rule sets and usually add my rules using the following order. 

Gateway redundancy is usually done by a backup gateway doing an IP takeover when the first gateway goes down. This usually involves actively monitoring the gateway to ensure it is up. You will redundancy on the other side of the gateway as well or the far side of the gateway will remain a single point of failure. Redundancy is still vulnerable to single points of failure if there is anything shared between the routes. This can be be a cable, fiber optic bundle, power source, or something else. I've lost connectivity on redundant links when a fiber optic cable was cut miles from our site. It was cut a few feet from where the fiber routes split. Given the reliability of current gateway equipment, I would rely on a single gateway in most cases. 

I use NUT (Network UPS Tool) for cases like this. You will need a Unix/Linux based server to monitor the UPS. Once the shutdowns start, it will ensure the UPS is power cycled. This will bring the servers back up if they restart on when power is restored. There is a client for Windows servers so they can be shut down cleanly. 

My first question I would ask is why you are announcing 2 prefixes. I am not sure how Windows built its stack, but I would expect it is looking for one route. The prefix should not be used for global (internet) routing. However, given the lifetimes, it appears to be the preferable network in terms of lifetime. Also it is closer to the desired /64 for a local routing block. Is there any reason for having a local identifier when the global identifier would work as well? The prefix is being advertised with the full /48 supposedly supplied by your ISP. Normally this would be broken down into /64 sub-nets with each router being assigned a sub-net. This would be good for 65536 routers in your organization. Try advertising a /64 subnet and see what happens. 

It looks like a poorly done hacking attempt. I've seen a few of them. I would recommend using to block the IP on multiple failures. You should verify the patterns as the default patterns don't always match. It handles multiple files and multiple services. Exim does have the ability to ratelimit traffic. There are two versions and the newer version is designed to be used in ACLs. This will only slow down people trying to crack your password, but it may encourage them to try a different server. If you set the rate too low you may cause problems for legitimate users. You could also limit auth to the Submission port. A line in the mail section like this should require both TLS encryption and the submission port before authentication is offered. 

Plug everything into the switch. Give the server an fixed addess which has apporpriate access to the Internet and an address on the 192.168.100.0/24 subnet. Set the default route on server to the Firewall. Block access the 192.168.100.0/24 subnet access to and from the Internet on the firewall. 

There are no logs for your interfaces. If you check soon enough, you can likely find them in the output of . You should find all that output in . If it has rotated you need to look in . Grep out the time range to a separate file that you can examine more easily. A command like should work. Look for references to in the file. You may also see a reference to repeated messages which may be close to the line that indicates the problem. Also look for references to the driver for your interface, or the manufacturer. Running the command should output error counts, and may give you a hint as to the problem in the counts the follow the errors.