In comments above you ask about a linguistics professor correcting spelling in written assignments. When I corrected my students' phonology assignments, I never cared if there were prescriptive grammar or spelling errors; I only wrote comments if there were errors having to do with the concepts being tested in the assignments. Think of a math teacher grading an assignment involving a geometric proof. Would that teacher take points off for an extraneous apostrophe in a sentence like "Because ABC is a right triangle, the square of it's hypotenuse is equal to the squares of the other sides"? Nope. But actually, whether or not a linguistics professor corrects spelling errors in a written assignment is (as people have mentioned above) irrelevant. You bring up the scenario of an advisor correcting a thesis draft. In that case, the professor might comment on a misspelling, but not in her capacity as a linguistic researcher! Such a comment would merely be in the interest of "playing by the rules" of the academic establishment at large. When my choir director in college took us on concert tours, he dutifully saw to it that the underage members of the group (the majority of us) didn't drink after performances, as that is the law in the U.S. But his personal political belief was that people should be allowed to drink from the age of 18. It would be silly to extrapolate from my music director's behavior that there must be a "musical reason" for maintaining the legal drinking age of 21. All that aside, I invite you to think about what you really mean when you lament the "bastardization of linguistic rules". The truth is, the way any individual uses language (written or spoken) can be seen as a "bastardization of linguistic rules" from the perspective of someone who lives in a different place or a different time. In my comment below your post I teased you about the dangling participle in your first sentence. Some people would consider that sentence construction to be a "bastardization" of English; as a linguist, I don't care one way or the other, especially since I had no trouble inferring your intended meaning. Even the spelling of bastardization that you use would be considered a bastardization of the written form of English by those in the UK who would spell it bastardisation (although their complaints would not be entirely founded from a historical standpoint--see this blurb on -ize and -ise)! 

As with most terminology, these terms are used in different ways by different authors. But judging from this particular passage, I gather that this author uses borrow for when the speaker only has an L1 version of a word and deliberately uses it as a suboptimal substitute for the target word. The author uses access when the speaker knows the target language (L2) version of the word but inadvertently uses the L1 word instead (presumably because L1 "rolls off the tongue" more easily). An analogy: The borrow case would be if you needed to hammer a nail but all you had in your toolbox was a screwdriver, so you deliberately grabbed the screwdriver and used it to bang on the nail (not its intended purpose). The access case would be if you had both a screwdriver and a hammer in your toolbox but you were working too quickly and so you accidentally grabbed the screwdriver. 

It seems that the answer lies in the source you cite in your own comment. Cuneiform at this stage was not purely logographic but rather a mixture of logographic signs and phonemic (or what the article refers to as "phonetic") signs, and the inventory of phonemic signs that existed was tailored to Sumerian, which had a very different morphology, phonology and phonetics from Akkadian. Note that the writer says that Sumerian "lived on as an imposed constraint on the expression (emphasis mine) of Akkadian...". By "expression" the author almost certainly is referring to the written expression of the language. Are you familiar with the Japanese writing system at all? It's like if in a parallel universe you had grown up speaking German but no one ever taught you how to write it, but then someone handed you an instructional manual for Japanese writing--Kanji, hiragana, and katakana--and you had to try to adapt it for use as an orthography for German. For some words and morphemes you could use already-existing kanji and just re-establish their pronunciations. But how would you deal with the inflectional morphology that German has and Japanese lacks? You'd be forced to choose among letting it be implied, coming up with a kluge for expressing it using kana, or re-appropriating certain kanji to represent inflections. And if kanji didn't exist for certain words, how would you adapt kana to "spell them out"? There obviously isn't a one-to-one correspondence between phonemes in German and kana in Japanese, so you'd sometimes have to go without expressing certain contrasts that exist in German, like /l/ vs. /r/ (or, again, invent a novel way of marking these contrasts) and you'd also sometimes be forced to express certain phonemic sequences in a roundabout way--consonant clusters, for example. Of course none of this would hamper your ability to express yourself orally in German, though. 

While what @Raizin says about [əɹ] is technically true--it is supposed to denote a sequence of two phones--I have seen [əɹ], [ɚ], [ɹ̩], and [ɝ] all used to refer to the same speech sound. The thing is, while schwa is given its own place in the vowel space chart, in practice its formants (other than the first formant) tend just to be transitions between the consonants surrounding it (unless it is phrase-initial or phrase-final), so it's more of a chameleon vowel, blending into its surroundings. Consequently, a schwa-r sequence is going to be virtually indistinguishable from an 'r-colored schwa'. Furthermore, one would be hard-pressed to distinguish between unstressed [ɝ] and [ɚ]. I think, more often than not, it's a matter of convention rather than of phonetic distinctions. For example, I know one phonologist who sticks to [ɝ] and [ɚ] for transcriptions of American English, and by convention she uses [ɝ] in stressed positions (as in 'sir') and [ɚ] in unstressed positions (as in 'ulcer'). It's true that the formants of the vowel in 'ulcer' are going to tend to be a bit less extreme (i.e., a bit more centralized) than those of the vowel in 'sir', especially at faster speech rates. But they aren't always, and yet she lets phonology, not phonetics, dictate which symbol she uses. This follows the convention of transcribing the vowel in the unstressed syllable of 'submit' as [ə] and that in the stressed vowel of 'substance' as [ʌ], even if instances of those respective words can be found in which the formant values of the vowel are identical in the two cases. 

It's Cantonese. The character is naming colors, but the colors he's naming are different from the ones that appear in English on the screen. First he says "green", then he says "purple", then "red", etc. 

In general, yes--the F0 (fundamental frequency) of the voicing during a stop closure is going to be lower than that of the following vowel. The fact that there is a full closure in the oral tract (for non-nasal stops) means that there is nowhere for the air coming out of the lungs to escape, making it difficult to maintain a high velocity of air through the glottis and thus slowing down vocal fold vibration. When the oral cavity is opened for the release of the stop, the built-up pressure causes the air to rush out initially, making for a higher rate of vocal fold vibration. I tried recording myself producing some voiced stops in various contexts, and the only time I observed a partial exception to the above generalization was when the voiced stop was between two vowels and the first vowel had a much higher F0 than the second vowel. In that case, the incoming F0 had enough "momentum" to give at least the earlier part of the stop voicing a higher F0 than the following vowel: However, even in that case, the vocal fold vibration toward the end of the stop appears to slow down to a rate that is slightly lower than the initial F0 of the following vowel. I would expect this effect to be a language-general one, since it has to do with the mechanics of airflow through the vocal tract. 

...we can see that there are 16 glottal pulses in 0.152 seconds. 16 divided by 0.152 is about 105, so the average F0 of the vowel is about 105 Hz. If we do the same for the second and third vowels, we get 91 Hz and 86 Hz, respectively. So, as expected for declarative intonation, the stressed vowel, which is also the first vowel in the word, has the highest average F0, and the F0 drops for the second vowel and then drops a bit more for the last vowel. Now, of course the F0 of a vowel does not usually stay exactly the same through the course of the vowel; if we wanted a more precise measurement we could measure the time between every two pulses and then divide 1 by that time to get the fundamental frequency for that part of the vowel. If we then plotted the results on a line graph we'd get a nice fundamental frequency contour. 

Moira Yip discusses this issue in Chapter 2 of her book Tone. The short answer: four, possibly five. HOWEVER, this question is not as straightforward to answer as one might think; tones can be defined in terms of phonological contrast--like phonemes--or phonetic contrasts--like phones. Just like segmental phonemes, tones are often analyzed as surfacing with contours that deviate from their true "underlying forms". For example, since the pitch contour of a syllable is directly affected by intonation as well as lexical tone, what might otherwise be a level tone might surface as falling in a declarative context and rising in an interrogative context. What's more, tones are often analyzed as undergoing phonological processes--known as tone sandhi--that are dependent on the identities of neighboring or nearby tones. Let's take Mandarin as a familiar example. You stated that the third tone falls then rises. This is true of a carefully articulated syllable spoken in isolation (or sometimes at the end of a phrase), but actually in practice the third tone almost never really surfaces this way. If it is followed by another third-toned syllable, the pitch will basically just rise steadily. In other environments it often simply surfaces with a low, relatively level contour. In fact, some phonologists analyze Mandarin as having two level tones--high and low--and two contour tones--falling and rising. In such analyses the fall-rise surface contour of tone three is just an "allotone" of that "toneme" that occurs in a predictable environment, i.e. phrase-finally. What about Cantonese? "Checked" syllables aside, Cantonese is usually analyzed by phonologists as having six contrastive tones. Three are usually considered level, two rising, and the last is either analyzed as "low-falling" or just very low level. I've made recordings of native speakers of Hong Kong Cantonese, and in that experimental context I found that that last tone usually surfaces (in a declarative context) with a contour that falls briefly but then plateaus and stays relatively level at the bottom of the speaker's pitch range. So is that a level tone? Who's to say?? Assuming one can decide which tones in an inventory are level, another challenge is deciding how many of them can be counted as contrastive. Imagine being out in the field with a new, unfamiliar language that appears to be tonal. You record a bunch of words, and there appear to be minimal pairs that suggest that whether a syllable is given a relatively high pitch or a relatively low pitch can affect the meaning of the word it's in. One straightforward analysis is to say that there are two contrastive tones in this language, "high" and "low". But another reasonable analysis is that some syllables are lexically marked for tone--we could call it "high"--and others aren't. All else being equal, syllables that are marked as "high" get realized with a higher pitch than those that aren't, which by default surface with a lower pitch. Likewise, a language that is observed as having three surface levels may be analyzed as having a "high" tone, a "mid" tone, and a "low" tone, but it may also be analyzed as having a "high" tone and a "low" tone, with unmarked syllables surfacing with a mid-range pitch. So, in theory, Yip notes, a system with n phonological tones can produce (n + 1) surface tones. To summarize what Yip says about the typological facts: "Underlying" three-tone systems are common: Huajuapan Mixtec, Nupe, Kunama, Punjabi. Most systems that are given "underlying" four-tone analyses--Grebo, Igede, Mambila, Mazateco, Chatino, Jianyang, Cantonese (?)--only display four surface tones. In theory, of course, the logical alternative is to assume "high", "mid", "low", and zero for these languages. Finally, there are languages that contrast five level tones on the surface, but "most are known only from fairly brief reports, with not enough detail to determine unequivocally whether there are actually five underlying level tones, or whether one or more are derived in some way." (Yip 27) These include Hei-Miao, Gaoba Dong, Dan, Trique, and Ngamambo Bamileke. If you are interested in this topic, I highly recommend obtaining a copy of Yip's book! 

Unfortunately, I doubt this is possible. Praat doesn't have such an object, as far as I am aware. If you think about it, if there were such an interface, it probably wouldn't make sense to show all of the images at once, since 33 ms is such a short interval of time (only encompassing a few glottal pulses) and unless the spectrogram and waveform are stretched out quite a bit there won't be room to place a bunch of image frames side-by-side without overlapping. Rather, you'd probably want a tool that displays a single window for a single image that keeps changing depending on where in the spectrogram/waveform you place the cursor (I'm thinking of something analogous to the function in Wavesurfer that allows you to hover over the spectrogram and see a snapshot of the spectrum that corresponds to the relevant point in time). As I said, though, I'm pretty sure there's nothing in Praat with this kind of functionality. The best alternative I can come up with is to write a script that allows you to select a point on the spectrogram/waveform and then find (in a specified directory) an image file whose name encodes time information that matches the time of the selection. The script would have to open the image file with some other program besides Praat, I think. Others might have other suggestions. If you're really stuck, you could even contact Paul Boersma directly. His contact info is on the Praat page. 

Generally, each presumed level in the prosodic hierarchy is motivated by the observation that certain phonological processes (some may be prosodic in nature and others may be segmental) are associated with that constituent. For example, in standard Japanese there is a prosodic constituent called the accentual phrase, in which only one accented syllable may occur. If multiple words that are lexically accented are combined into a single accentual phrase, all but one of the accents gets deleted. Often, presumed prosodic constituents are motivated by more phonetic-y phenomena. For example, in English it is common to observe the lengthening of word-final, phrase-final, and utterance-final syllables. In many languages there is also a pitch reset (where the downward trend of the overall pitch range—sometimes called declination—stops and starts again at a higher pitch) at phrase boundaries. The usage of the term prosody in the conlang grammar you linked to is a bit confusing and seems to conflate prosody and intonation. It's not really that languages "distinguish" between "sentence" and "phrase" prosody; rather, as described above, different phonological and phonetic processes are observed to occur at different prosodic levels (i.e. over different prosodic constituents). Often-cited references for the prosodic hierarchy include those by Selkirk, Pierrehumbert and Beckman, and Hayes. I'm not sure how technical you want to get, but if you search for "prosodic hierarchy" online, you'll find links to online course materials that are relevant for your question. 

In another study carried out by Jody Kreiman and Bruce R. Gerratt (UCLA), the results of which are presented in a PowerPoint presentation entitled Jitter, Shimmer, and Noise in Pathological Voice Quality Perception, two experiments were carried out. In the first experiment, subjects were presented with sample recordings of human voices with perceptual irregularities. For each stimulus, they were given the opportunity to control the settings for jitter, shimmer, and noise on a synthesized speech sample to match, as best as they could, the human sample. Their responses were highly variable when it came to jitter and shimmer, but more consistent when it came to noise. The experimenters posited two possible explanations: 

Well, yes and no. Vocal F0 range is mainly determined by the length and thickness of the vocal folds. Inasmuch as neck circumference correlates with the size of the vocal folds inside the neck, you could find a loose, indirect correlation between neck circumference and F0 range. For example, adults generally have thicker necks than children, and they generally have lower F0 ranges. But there are several factors that contribute to neck circumference, and not all of them are associated with larger internal organs. For example, someone with a relatively high body fat index could have a very thick neck but relatively small vocal folds. Similarly, people who take up body building and build up all of the muscles in the neck will see an increase in neck circumference but not a concomitant decrease in vocal range. If anything, neck length is going to be more reliable than neck circumference. The length of the neck is determined by skeletal structure, so it is more likely to be in proportion with the vocal folds. In the opera world, conventional wisdom says that the stereotypical tenor has a short neck and the stereotypical baritone has a long neck. But even that metric is not 100% reliable, since ultimately the growth of the vocal folds is independent from skeletal growth and can be influenced by such things as testosterone levels.