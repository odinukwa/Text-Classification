And since this is an exercise, I will leave to you the task of projecting over , and , and discovering how the natural join of the three relations differs from the original relation . Finally a terminological note: a relation instance is not an array! There is no order in the rows or the columns of a relation, while in an array the order is essential. 

In the relation , since is a candidate key of the original relation, a minimal cover of the dependencies is (there are no other non-trivial dependencies that hold in it). Then, what happened to the dependencies and ? Well, they are lost in this decomposition (and if you try decomposing starting with dependencies different from you can find that these or other dependencies are lost as well). From the practical point of view, this means that the constraints expressed by the lost dependencies cannot be enforced in the decomposed database. On the other hand, it is a well known fact that the classical decomposition algorithms for BCNF is not guaranteed to preserve the dependencies, differently from the synthesis algorithm for 3NF. 

and are exactly the same relation, since the order of the attributes does not matter. In general the synthesis algorithm requires that, after the first phase, you should remove all the relations contained in others. So, the answer to the first question is yes, and of course the relation has two dependencies and , and two candidate keys, and . On the other hand, and are different relations, which should not be merged together (and, moreover, they do not have the same keys, since has key , while has key (and no dependencies)). 

In this example the table maintains information about, student, courses and exams, and we want that this information be consistent. Without this is not possible. Note that however the foreign key is checked: 

In the terminology used to to talk about conceptual design of database, this is called inverse relationship. So you could say: 

This means that all the attributes are primes, so the relation is by definition already in Third Normal Form. For the BCNF, you have described the “analysis algorithm”, which is the algorithm presented in every good book on databases. But, with this example, you have also discovered that in normalizing, you can have different results, that can depend for instance on the order in which the dependencies that violates the normal form are chosen (not in this case, but possible in other cases with this same algorithm), or by using a different algorithm (there are others, not interesting from a practical point of view). In your example, the second decomposition, which is in BCNF as you correctly stated, cannot be produced by the analysis algorithm: there is nothing wrong about it, in general there is no guarantee that this algorithm will produce the “best” decomposition (for instance a decomposition with a minimum number of relations), and, if this is an exercise, you have done it correctly! What instead is interesting to note, also from a practical point of view, is if the decomposition satisfies all the important properties, i.e. if it preserves the dependencies of the original schema (since the decomposition produced by the algorithm is instead guarantee to be always a lossless decomposition). And you can see that both the decompositions fail under this aspect. The decomposition in does not preserve the dependency , while the decomposition does not preserve the dependency . This means that in practice both of them reduce the redundancies and other anomalies of the data, at the expense of losing an important contraint over them. So, knowing that the relation is already in 3NF, one could be satisfied by this result and leave the relation in this form. This means the preservation of the dependencies, together with a limited amount of redundancy, which in practice can be tolerated. 

This can be seen since there is a theorem that says that a simple criterion for checking whether a decomposition (R1,R2) is lossless-join is that either: 

A simple check to see if a relation schema is in Third Normal Form is to see if every left hand side of non-trivial functional dependencies is a superkey (and this test can be used also to check if a relation is in Boyce-Codd Normal Form), or, if this is not the case, if every attribute on the right part is a prime attribute (i.e. part of any candidate key). So in you case both the dependencies A → BCD and BC → A (and also BC → D) have a candidate key as left part, so the schema is in Third Normal Form (and in this case also in the more strict Boyce-Codd Normal Form). 

The answer is “yes”. Consider the above example: in the table the column is a foreign key for an table. If an employee can manage more than one project, then different rows in the table have the same value in the column . 

You are correct, the relation is in 2NF, 3NF, BCNF. The reason is that the relation has two keys, and . So the relation is in BCNF (which is a property stronger than 3NF and 2NF) since each determinant of the minimal conver of R1 is a key. Here is one minimal cover: 

Of course such definition should also exclude trivial dependencies or derived dependencies in which the left part contains superflous attributes. 

The first solution is clearly more efficient than the second one, because you don't need to do the join (every join slows down a query, more or less depending on the access plan generated by the system). More, I think the second solution has some problem, since from the schema it seems that you are using the column inside as foreign key referencing the table , while in that table you use as primary key the couple of columns and , which conflicts with the definition of the foreign key, from which one could assume that is already a primary key for . So, if, as it seems from the diagram, the relation between and is 1:1, you should opt for the first solution which is still normalized and more efficient. 

Both relations are in BCNF, and the final decomposition is given by R2, R3, and R4. Finally, note that sometimes the algorithm can produce different solutions, depending on the functional dependency chosen at each step. 

In other words, if a Functional Dependency holds in a relation schema R, then this implies that the binary Join Dependency holds, and viceversa. Note that this is equivalent to say that you can perform always a lossless decomposition of a relation with a functional dependency in , . So, for instance, in the previous example, since , the Join Dependency holds and is a lossless decomposition. 

This dependency is not redundant, since otherwise you do not know that is a key, and you lose an essential information. So you must include it in the set of functional dependencies. For phone, if each phone is uniquely associated to a person, and each person can have only one phone, then you have these functional dependencies: 

To bring a schema in 3NF, first you have to find a canonical cover of the dependencies. Then, you can apply either the “analysis” algorithm to find the Boyce-Codd Normal Form (which is more strict that the 3NF) or you can apply the “synthesis” algorithm to find the 3NF. In this case, both the algorithms gives the same results. Here is a canonical cover of the dependencies: 

This is certainly possible and even very reasonable in many situations. Think for instance to the classical Order and OrderLine tables, in which the OrderLine has as primary key the order number and the line number, with order number foreign key for the Order table. 

I think the best option is the first solution, since the field is a VARCHAR: this means that no significant amount of space is occupied if the value is NULL. On the other hand, with the second solution you have a table more to maintain, other indexes, need to join if you need the value, etc. Too much hassle for a problem that can be solved in a very simple way. 

The relation is actually in 3NF (so that it is also in 1NF and 2NF). The reason is that each attribute of the relation is prime, that is, it belongs to a (candidate) key (the are four keys in this relation: ). The definition of the 2NF (which has only an historical interest), is the following (Database System Concepts, 6th edition, Korth, Silberschatz, Sudharshan):