You would get much better results using puppet modules for apt, nodejs etc. take a look at puppet forge. Using exec is a bad idea, as you really need to take care of the idempotency on your own. For example instead of lines: 

You can use testdisk to recover your partition table. TestDisk is a free and open source data recovery utility it can: 

As far as I remember it is not possible to disable the ACL on ZFS. But you can try to remove any ACL config with "Removing all non-trivial ACEs from a file" Take a look at the ZFS ACL admin guide it's for Solaris but I guess that the ACL setup is the same. 

You have deleted the file but the file descriptor is still open and used by the running script. Stop the script and you should get the space back. It's a better idea to truncate the file with or 

This control is used to define how aggressive the kernel will swap memory pages. Higher values will increase agressiveness, lower values decrease the amount of swap. A value of 0 instructs the kernel not to initiate swap until the amount of free and file-backed pages is less than the high water mark in a zone. The default value is 60. You will find more information about the virtual memory subsystem in the kernel documentation 

I wouldn't worry at all about the small swap usage. It happens that kernel drops some data from memory to swap. You can control the behavior of kernel with the swappiness option: 

You can try to use to check which processes are using the network connections. List al network connections: List all the TCP or UDP connections: Processes listening on a particular port: List network files which are being used by a process: List the network files opened by the processes starting with ssh: 

No, they won't be securely removed. If you overwrite the disk with zero's then it still will be possible to recover the data. If you do it with random data (/dev/random) once, it still will be possible to recover the data. You need to overwrite the disk with dd at least couple of times. Which will take exactly the same time (or even longer) as with . So to sum up, it always takes a lot of time, there is no quick method. 

What could cause this to happen? Where should I start troubleshooting next? I did try on that interface with no success. 

In our network, we have a Cisco router acting as the core router, connecting all our sites to the main site. We also have a Linux firewall connecting us to the Internet. 

Windows 2003 domain controllers do not seem to utilize IPv6 fully. Exchange 2010 needs to see all subnets containing domain controllers in Active Directory. But then Exchange was trying to contact the 2003 domain controllers via IPv6 and failing. When I removed IPv6 from the 2003 domain controllers, things started working. A 2008 R2 domain controller worked fine with IPv6. 

Nowadays there's no difference between the 10/100 ports and the gigabit ports except speed. A lot of modern switches' "uplink" ports aren't even crossed. We used to do the same thing - connect the file server to the gigabit port. 

I have a brand new Dell VRTX box set up as a Failover Cluster running HA Hyper-V virtual machines. This is my first time setting up clustering, and my first time with one of these boxes, so I'm sure I've missed something. The virtual machines are experiencing high disk latency and bad performance when accessing their VHD(x) files located on a Cluster Shared Volume. The VRTX has 10 x 900 GB 10K SAS drives in RAID 6 configuration, and the VRTX has the redundant Shared PERC 8 controllers. Both blades have full access to the virtual disks. There are two M520 blades installed, each with 128 GB RAM. MPIO is configured for the PERC 8 controllers. Operating system on the blades is Server 2012 (NOT R2). The RAID 6 array is split into a small (8 GB) volume for cluster quorum witness and a large (6.5 TB) volume for a Cluster Shared Volume (mounted on the nodes as C:\ClusterStorage\Volume1) An example of slow disk access: logging into a Server 2012 VM and having Server Manager come up automatically. Disk access goes to 100%, with write speeds at 20 MB or so, read speeds of 500 KB or so, and Average Response Time of over 1000 ms, sometimes spiking at 4000-5000 ms or so. It's the latency that really worries me. Is there something specific I should look at in my configuration? It doesn't seem to matter whether I use VHD or VHDX, dynamic or static. 

This will give you the block count reserved for root user, multiply it by the block size and you will get the size of reserved space (in bytes). Second, most probably some file descriptors are still in use. That means that a file seems to be deleted but still it is in use and process writes to it. Although you don't see the file anymore on FS a process still is using the file. If you stop/kill the process or reboot the system, the used space will be released. You can look for deleted files with: 

The value is bigger than the integer number you can put in to field. The in mysql is 4 bytes long so the maximum values are -2147483648 and 2147483647. You need to use instead which is 8 bytes long. See mysql documentation 

This will create a kind of wildcard certificate accepting any hostname and the IP addresses mentioned it that file. Of course this is just a simple example and you wil need to adjust the settings to your needs. 

You need to modify the root directory for your virtual host. Otherwise you will have a subdomain which will show exactly the same data as your main domain. For subdomain.domain.com you should set the of the subdomain to and for subdomain2.domain.com to etc. Check out the examples 

In CentOS/RedHat you also to enable the SSL rsyslog port in SElinux. Something like should do the trick. You can check your current syslog port with Also you can try, to run rsyslog in debug mode, to see whats happening: Stop rsyslog daemon, then 

You don't need to update all of them. Basically you need to know your HW, for example if you don't use a FC storage, you have no need to update the qlogic driver (most probably it's not even installed on your system). The other way around if you have an Intel network card then you need to upgrade the e1000 driver. You can check your HW from OS level with also will give you the information about modules loaded(used) by kernel. This should give you some hints about any drivers to update before hot fix installation. 

This is a story old as Unix and Linux systems, if you search on stackexchange for "du and df" you will find a lot of answers. 

This should loop every 5 seconds until the postfix queues are empty. Adjust your path to postfix files accordingly. You might want to leave the part out of the command, otherwise any temp send errors that cause an email to be deferred will keep the modem connection open until it retries. 

According to the manual page for , the CPUs are specified as a bitmask. So CPU0 is 0x01, CPU1 is 0x02, CPU2 is 0x04, CPU3 is 0x08. You can add them together if you want a process to run on more than one cpu. (e.g. 0x03 is CPU0 and CPU1) 

In my experience, Test-Cluster never triggers a failover event. It is designed only to check hardware and software configurations to see if everything is compatible with failover clustering. As I understand it, Test-Cluster is also run when using the GUI "Validate Cluster" function from within Failover Cluster Manager. It doesn't actually "Test" the "Failover" function of the cluster. 

Changing the BOOTUP line to something like eliminates the formatting for all init scripts. If you just want to disable formatting on one of your scripts, add: 

In our network, we have several Cisco 1721 routers located at branch offices connected back to the main office via T-1 circuits. All the 1721s are running the same IOS and configured the same, with static global IPv6 addresses on the LAN interface. Here are the relevant configuration items: 

But I have one router where the FastEthernet0 interface is not initializing IPv6 properly. The IPv6 addresses stay at tentative status: 

It turns out that Windows 2003 Domain Controllers will not accept IPv6 subnets in Sites and Services. After adding a 2008 R2 domain controller, I was able to add IPv6 subnets. But I also found out that running IPv6 on Windows 2003 does not work out very well, especially with Exchange in the mix. 

It might be important to note that while Zanchey's answer is correct with regards to x::0 hosts, the example in the question does not describe a ::0 host. The example was A:B:C:D:E:F:0:0/64. A:B:C:D is the network portion, and the host address is actually E:F:0:0, not 0. 

I am trying to get Exchange 2010 to change the MessageClass (PR_MESSAGE_CLASS) of an incoming message to that of my custom form (IPM.Note.MyCustom) when the incoming message has a certain header set. () I have seen some information about setting another MIME header () that Exchange will use to set the MessageClass, but it doesn't seem to work for me. (I've seen examples that use and ) I've even looked into writing a transport agent with C#, and I did find a property on the class, but it's read-only. I also looked at added a MAPI property in a TNEF section, but the Exchange API does not offer a way to create a TNEF section if one does not already exist. (And most mail from the Internet doesn't.) There's got to be a way to do this. What am I missing? 

If you connect using an IP address then your certificate must contain a matching IP SAN to pass validation with Go 1.3 and higher. This is not (yet?) mentioned in any README file or documentation but there are some issues ( #226 , #221 ) open at the project github repo. To permit IP address as the server name, the SSL cert must include IP address as a field. To solve that you can use following procedure for the creation of the SSL cert and key: 

If you connect via host names, you can remove the IP SAN's, otherwise add your logstash server IP address. 

As it is mentioned in the Apache Common Misconfigurations wiki site "...Because of the nature of SSL, host information isn't used when establishing an SSL connection. Apache will always use the certificate of the default virtual host, which is the first defined virtual host for name-based virtual hosts. While this doesn't mean that you won't ever be able to access the second virtual host, it does mean your users will always get a certificate mismatch warning when trying to access some.domain2.com..." And from the apache docs: "...The reason is that the SSL protocol is a separate layer which encapsulates the HTTP protocol. So the SSL session is a separate transaction, that takes place before the HTTP session has begun. The server receives an SSL request on IP address X and port Y (usually 443). Since the SSL request did not contain any Host: field, the server had no way to decide which SSL virtual host to use. Usually, it just used the first one it found which matched the port and IP address specified. ..." It is possible to have multiple SSL certs with one IP address with SNI (Server Name Indication) but only in the most recent versions of Apache and OpenSSL (with Apache v2.2.12 and OpenSSL v0.9.8j). In short: If you want to use different SSL certs for virtual hosts then you need to provide a different IP address for each of them or use SNI. 

Check your Vagrant file and make sure you have setup the modules and manifests directory. Then search the puppet forge for the modules, for example apt, nodejs, ruby etc. Download them and install (unzip in the modules dir). Make sure to change the modules directory names. For example from to Take a look at the modules overview and usage guide it will tell you how to use a module. Also check out this tutorial about using vagrant with puppet. If you want to learn more about puppet take a look at the learning VM and the docs.