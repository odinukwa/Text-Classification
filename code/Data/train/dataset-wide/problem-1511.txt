Some stars are simply huge. Eventually, though, wouldn't there be simply too much pressure or mass for the star to sustain itself? Wouldn't it eventually collapse into a black hole? Is there a theoretical upper limit on the size of a star, and what is it based on? 

Basically, they decided that it isn't officially a planet anymore because it didn't match criteria (c): has cleared the neighbourhood around its orbit. It hasn't done this, because it 'resides within a zone of other similarly-sized objects'. Therefore, it hasn't cleared its neighborhood. Soo... what about the number of planets? 

Speed, as we know, doesn't exist without first having a reference point. We then say that the reference point isn't moving at all, and speed is then measured in relation to the reference point. What is the standard reference point when determining the speed of objects in astronomy? Earth? 

You may take a look at the lates parametrization file by JPL-NAIF for the precession, nutation and pole orientation of the largest known bodies. Although, for the large time scales you are asking, I expect you will need to propagate the data and make your own wild guess, or dig into appropiate literature about solar system physics. 

I find the manner in which the question is posed rather opinion-oriented. Nevertheless, I try to give a few objective add-ons. Both missions have been great technical successes, having very different mission requirements, spacecraft designs and concepts of operation. When looking at the scientific return, objectively Rosetta has blown it out (count it in number of Science/Nature/etc. publications and count the amount of new geophysical models for pristine solar system bodies. The comet has told us so much, that few weeks ago NASA has approved budget for supporting a mission concept to revisit the body. Rosetta was, at the very origin of the project, conceived as an ESA-NASA cooperation, where JPL will build the lander. However, politics aside, Congress cut the flow and ESA had to turn to DLR to build a lander with limited budget, limited mass and limited volume. Therefore, Philae's platform had no steering (active AOCS) in contrast to Hayabusa, which was a fully-equipped platform. The landing sequence for Philae was pre-planned. Philae didn't control its path, it was the comets inhomogeneous gravity at ~1m/s for several km. Propagate your uncertainties... Still, the landing was pin-point, damn the rebound on that hard rock. Hayabusa performed an inertial hovering followed by a touch-and-go sequence. The operation was rehearsed twice before. The sample was taken with the equivalent of a vacum cleaner on a dusty body with such low density you could put your arm through and come out on the opposite hemisphere. One important requirement in sample collection is to prevent contamination of the sample by the system and the environment. Specially during re-entry. For the small sample of Itokawian dust that was recovered, isolation conditions could not be proven. So most likely some material from spacecraft outgassing went in there. This could not be proven one way or the other. Nevetheless, technically speaking, this operation: sample capture, retrieval and re-entry was a breakthrough. And in fact, OSIRIS-REX is just going to try and repeat that on asteroid Bennu with a load of lessons learnt. I personally look forward to the science return and wish for a lot more data coming down this time. So if you ask, why such a big boom for Rosetta, the key is, the few hours of experiments on the surface helped give context to large set of extended science observations by the orbiter. Something that had never been done before on a small body (be it a comet or an asteroid), actually only on Mars. This got the whole community very excited, for a good reason. As an engineer, I understand the voices of "this wasn't a real landing", "this was luck", "it was a failure" etc. But you know, JPL redefined the landing gear of their next comet sample return proposal when Philae's harpoons didn't work. This is what erros are made for, to make it better the next chance. And this involves all agencies and all countries collaborating instead of competing to win a front page. It also involves the general public understanding the importance of each mission out there. Some prove technology, some bring a science storm. Let's leave politics to politians ... 

Let's look at them in detail: Continuum measurements are easily done using dishes of any size, but I'd start from 3m upwards to get more interesting results. Calibration of the backend receiver is not trivial, and you should plan a bit of time for it. Spectral measurements also benefit from larger collecting areas, but you'll also need to set up a suitable backend. They are, however, possible from 3m upwards if you are happy with a bit of mapping of intra-galactic velocities. Pulsars require a lot of collecting area and bandwidth, so they are mostly the domain of large instruments. We are currently observing several dozens of the brightest pulsars on our 25m dish. The 10m might be sufficient for some of the very brightest. And while there is a report of pulsar measurements using a 3m dish and an RTLSDR frontend, this is a feat that requires experience and dedication. So, I'd recommend this only for 8m and above dishes. Interferometry with 2x1m dishes (20 GHz) is rather interesting, but very involved in terms of analysis. Two receiving systems help mitigate local fluctuations, and with that setup, we can observe sources down to 2 Jy (with a looong integration time). This setup will give you access to one or two handful of interesting targets like M1, W51 or Cyg A. Finally, I'd like to recommend the EUCARA conference series (European Conference on Amateur Radio Astronomy) and the SARA group as great starting points. They have conference presentations available online that show what other amateurs are doing. 

(Imagine this turned sideways and you get the effect in your image) Basically, because Earth and Mars are orbiting the sun at different rates, our vantage point of Mars changes for each combination of points in the orbit of each planet. On this scale, the background of stars is pretty much stationary - any apparent movement of the stars due to this effect is going to be negligible. Thus, the stars are our point of reference. As our vantage point of Mars changes, it appears to shift directions on the stellar background, creating the effect you describe. 

The definition At the 2006 IAU General Assembly in Prague, the accepted definition of a planet was debated vigorously. The outcome of the meeting was the currently accepted definition of a planet: 

I am a member of Astropeiler Stockert e.V., and we are fortunate enough to be able to approach this problem coming from the "large side" :-) We have a 25m, 10m and 3m telescopes as well as an interferometer made from two 1m satellite dishes available. All these dishes can be used to do interesting things, but you'll need to match the instrument to your target (and, in a hobbyist setting, often also the target to your instrument). First of all, you should think about what frequency band you want to work on. 21cm (1420 MHz) is the classical hydrogen line, which lends itself well for mapping neutral hydrogen in the spiral arms of our galaxy. You can expect comparatively strong signals in a quiet frequency band there. Lower frequencies (and large bandwidths) are interesting for pulsars, higher frequencies give access to more interesting phenomena but will require a lot of work on the high frequency side. So my recommendation would be to start out with 21cm. Secondly, what to look for? In general, the following areas of observation are easily accessible for amateurs: 

The problem you are trying to solve is one generally known as spectral estimation. In addition to the practical references provided by jstarek, I suggest you also read some fundamentals. The book by S.M.Kay Modern Spectral Estimation, although almost 20 years old, is totally up to date and is a very well explained (easy to read) introduction. You will see that the folding algorithm is just a flavour of the Welch periodogram, and that your cross-correlation approach fits as an MLE estimation scheme (nowadays also known as signal subspace techniques). 

NASA's Navigation Ancillary Facility (NAIF) publishes planetary constants kernels (PCK) which are basically text files containing pole orientations for the largest known bodies. PCKs includes the parametric orientation of their prime meridian in agremeent with IAU standards (meaning datum is J2000.0). The latest PCK dates from 2011 and is actively used by most operational interplanetary flight projects across the world. Using the NAIF SPICE library (available in Fortran, C, Matlab and IDL) you can load this kernel and read the orientation of the prime meridian for your body and date of interest. Time offset between bodies can be reconstructed as angular offset between meridians. But you may find some time-related functions within SPICE which can make your task easier. 

In radio astronomy, many common objects are refered to by their designation from the 3rd Cambridge Catalogue of Radio Sources, e.g. 3C 353. For hobbyist purposes, I would like to create a catalogue for Cartes du Ciel that shows the location of the 3C objects. However, the catalogue exists in three versions, 3C from 1959 being the original, and 3CR (1962) and 3CRR (1983) updating the original. Later surveys at different frequency bands used similar designations, e.g. 4C, 5C and so on. Looking at the databases linked above, however, it seems that both only list the updates to the original catalogue (e.g. 3C 353 is listed in neither of them). Is there a digitized, comprehensive catalogue of all 3C objects? Or, even better, is there an archive where I could combine entries from several C surveys based on, say, 21cm flux?