Finger exercises (WiP), with much less than due commenting, QA (do as I say, don't do as I do…), many more casts than pretty (extensive type hierarchies without extensive method overriding), …: 

Follow up to Selection sort with reduced comparison count - semi-final Iteration? My goal (and excuse not to tag reinventing…) is to have presentable code to argue the viability of reducing the number of comparisons used by selection sort (for readers not necessarily versed in the implementation language chosen). In this iteration, that is prominently and from the methods , , and , including intrusive comparison accounting for emphasis (and the possible addition of for computing the number of operations of interest). Note to reviewers of previous iterations: finding suggestions not followed, be assured they were not ignored - feel free to chat (or flame) me, regardless. 

(Not touching direct use of the Dirichlet series or stopping summation on the first difference between successive partial sums that is "too small in relation".) The difference any given partial sum and the preceding one is the term just added. Given that the range is from about 1.6 to 1.0, I suggest to just define a constant lower bound for terms to consider: (syntax?) 

Code samples in this are approximate, I didn't test them. A couple thoughts: 1) You've currently called inside the body of your foreach loop. This is unnecessary, you only need to prepare your query once. You may reuse the that returns repeatedly in every iteration of your loop. This is actually very efficient, as the query will only have to be evaluated once. Once you're prepared, the preparation is done, no need to re-prepare for each loop iteration if your query structure is the same. (For the record, prepare is indeed the correct method to use in batch operations like this. In the future, if you only need to execute a single query, you could alternative use (if you need results) or (if you don't need results from the query -- it simply returns the number of rows affected by the query as an integer.)) The same goes for . You don't need to re-bind the params each loop iteration-- once bound, they're bound. binds by reference, the actual evaluation of the param happens every time is called. So let's do this minor refactor. We prepare the statement and bind the params before the loop begins, we the statement on every iteration of the loop, and we'll move the -ing of the PDOStatement to be after the loop. Your sample now looks like this, and will be a bit more performant: 

You noticed that just the last bit of the value of SimpleFunction is used in the described check, and implemented using an "early-out" encountering the largest common digit. Apparently, this uses O(N1 * N2) evaluations of SimpleFunction. (I failed to find an analytical approach promising to be much faster for just shy of a million pairs.) The evaluation of SimpleFunction better be fast - you seem to plan to cache function results, an do back-of-the-envelope calculations of the resources required. The impact of memoisation depends on the time taken to (re-)compute a result and to retrieve it, respectively - let's try to make computation fast. The signatures for the digit strings are the sets of digits used, in a normalised representation. As long as is no larger than the number of bits handled in a basic operation, this can be handled as a "bit set", allowing fast intersection (bitwise and), union (or), …. With nine digit values allowed, there are 29(-1) possible combinations: one could represent the baskets with 2*511 10-bit counts, one for each possible set of digits, instead of 2*1000 9-bit signatures. To check if SimpleFunction for a pair of signatures would be even, get "the and" representing digits common to both strings, find the highest common digit using or some such and map to even/odd. 

4 - User compiled queries where possible. If you know you might be performing a query multiple times, there is little sense in having the query provider generate the sql each time, you might as well take advantage of the type: 

Pagination should be done by the database server where applicable. There is really no point pushing data down the wire if it is not being used, so what you should think about doing, is passing in your page number and count variables to the query or preferable a stored procedure, and use SQL to select the subset of data you want. There are SQL constructs in most SQL language variants to do this. Here is an example using MySql: 

I know there are already many responses to this question, but here are a few other tweaks: 1 - Refactor the method to return a boolean result.. the method shouldn't really care about how you report errors, it should care about returning a simple result... , the password's match, , they don't: 

Along with @kingjv's suggestions, you can improve the performance of your jQuery selections by making some simply tweaks to the selectors. Consider if I have the following html: 

(For variants using arrays of precomputed elements in stead of "the setup-loop" (and a ), consult the edit history.) (*Phi³ coincidentally can be computed with just two summands (and no other power up to 2³² can).) 

(Getting late: the following code is work in progress; posting this to save the above, mainly (not quite trusting SE's autosave)(Never used C# - give me a break on documentation comments, const-correctness, commendable use of or some such.)) 

is on the long side. If you factor out recreate_node_array() (under a better name), you can return early from that avoiding the repetition of . Guess confused me - oho: following the pseudo code in the Fibonacci heap chapter of CLRS quite closely (consider referring to that near the top of the questions). 

The non-buffered didn't suffice, in the end: Sunsoft's encoder buffers. Trying to keep that from interfering messed things up. The from the question seems to have a correctness issue with the way it guesstimates byte count: it extends and accumulates "the length of s gotten from representations of ". It should rather 

I'd recommend NOT to use variable variables. They're generally considered a blight on the language, and people have pretty strong opinions on them. They tend to make code more confusing to read, debug, and lint; and they don't do much that you can't do in a simpler manner. 2.5) Actually, looking at your sample data array, your data doesn't look to be of arbitrary depth. It looks fixed-depth. Yes, there are number of per day, but the the structure is repetitive. It looks keyed per-day, each day has a few unique key/value sets. The only thing in the value array you seem to care about is the per-day dates and resting heart rates. You aren't using them yet, but I can also imagine maybe you want the heartRateZones, you can just grab those directly without iterating over all the other keys in the 'value' array. I'm not seeing a need for recursion at all. We can easily eliminate the variable variables and get rid of the unnecessary recursion all at once. I'd probably handle this with loops or nested loops instead of recursion. You don't appear to currently be using any of the heartRateZones. If you wanted to insert a record per zone, you could run in that inner foreach. Otherwise just delete that loop and run the in the days loop. I didn't see defined in the code sample you gave, or in the JSON data. I assume you already defined that elsewhere in your script. 

These are small performance improvements, you'll appreciate them more if you are doing a lot of DOM manipulation and lookup. More simplistic applications won't have such an apparent performance improvement. 

Other comments: 5 - Rename your data context type to something more applicable. I'm sure your app isn't called ? The naming of a type should be relevant, in terms of data contexts, you might want to name it after the database name. 6 - You're not storing the plain text password in the database are you? Only ever store the hash. Importantly the changes above allow you to logically separate out the concerns of the original method, now your validate function should be more streamlined: 

Regardless of how you do it, at some point in the execution of a method like that, there will be a enumeration. What you can do, is make the method more terse by using a LINQ method: 

2 - Throw an appropriate exception that represents the exceptional state. 3 - Separate out how you are creating your into its own method, so should this need to be changed, it is changed in one place: