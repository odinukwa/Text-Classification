"True randomness" and "exists" are two concepts that are notoriously hard to pin down, so it is hard to give a straight up answer, but here are two directions of thought. You can consider the idea that the digits of normal numbers conform to the formal results of probability theory; that's what it means to have proven that they exist mathematically. But now, what you've done is established that this one type of formal/conceptual objects stands in a particular relation to these other formal/conceptual objects. Is that existing? If you are a mathematical realist, then sure, they exist. But if you are a mathematical realist, you probably (ha!) don't have a problem with the existence of (formally defined) randomness in the first place. If you reject the "existence" of purely formal objects, then this formal relationship between concepts won't impress you much. Sticking to the real world. Given one of these numbers we could construct a seeming perfect random number generator -- a machine/program that can construct more and more of the digits of one of the numbers and provide it to you. But is this really random? Some people could argue that it's not really random since the particular sequence of digits constructed by this machine was fixed (determined) by the normal number that was used to "seed" it. Conversely, if you take a more empirical approach, you might contend that its output is random, since by any computable measure it "looks random". 

There are some misconceptions here. First, we do not know whether quantum computers are better at some stuff than classical computers. There are problems where we know quantum algorithms that are faster than all known classical algorithms, but so far noone has been able to prove that are no equally fast classical algorithms. Second, there are many computational tasks humans are very bad at, despite the tasks being very easy. A core aspect here is that for something like combinatorics calculations, we are using concious, higher level style reasoning. A "hardware" implementation in our brains might have been much better, but just never evolved (being good at combinatorics is probably not strongly selected for). So from us not being good at something we cannot conclude that the basic computational machinery of our brains is not suited for that task. 

Basically the title question: How can I tell if a term is a rigid designator? So far all I have is that proper names are (or can be, since there is a difference between "being named Barack Obama" and "being Barack Obama") rigid designators. For other things, indicatives for example, I'm not sure. Is there some test, or set of tests I can apply to a term to decide if it designates rigidly? 

These and related works are widely considered to be deathblows to logical positivism in the philosophical community. It's my impression that most philosophers view these results as invalidating the positivists' programme to "formalize science" in much that same way that Goedel's results invalidated Hilbert's programme to "formalize mathematics". 

There is a strict sense in which you can say that no computational process produces a (truly) new algorithm. I'd usually think of the process of one algorithm generating another as involving: 

Your argument shows that a naive implementation of utilitarianism that defines global utility as the sum of personal utilities would not work if utilities are allowed to include both positive and negative infinity. For this argument to have any bearing on utlitarianism at all, you would need to argue that both positive and negative infinity are indispensable as potential values of individual utilities, and you will find this to be very difficult. Note that we already run into big problems here simply by considering probabilitistic events: What would be the expected utility of tossing a coin to either receive $+\infty$ or $-\infty$? All formal approaches I am familiar with tend to demand that utility values are real numbers, and hence disallow infinite utility values. In particular in a context where we are going to aggregate different utility values, it may even be prudent to demand that utility values come from a bounded interval, to avoid running into this situation: SMBC comic 

To believe that "all animals, which want to live, have the right to live", is not the same as believing "For all X, if X wants to live, it has the right to live". The reason why there doesn't need to be a generalization is that animals have characteristics, e.g. an ability to feel pain, or other aspects of sentience, that plant do not (necessarily) share, even if you accept that "plants want to live" in some sense. More generally all you need is some feature that animals have, and plants et al. don't and claim that that feature is relevant for determining whether that class of living entities "has a right to live". 

Items 1 and 2 are somewhat wishy-washy in that the principle of continuity applies when we don't perturb the system (basically by definition); and when we don't don't perturb the system, the physical observables satisfy the principle of continuity (basically by definition). One of the nice things about the theory of QM is that it formalizes this notion: if the operator representing the observable commutes with the QM propagator, then the expected value of that operator doesn't change. And since, at least in a Logical Positivist's ideal world, QM is a formal theory built up on the basis of empirical observations, this idea of continuity is empirically based. 

Fundamentally, category theory does not seek to model "having a structure". It rather starts from the realization that the way how we use the structure is typically via the structure-preserving or reflecting maps; and that it is only the maps that really matter. For example, in topology the topology is just to define what continuous functions are. Everything else can be expressed in terms of continuous functions (not at least because we can recover the topology on X by looking at the continuous functions from X to Sierpisnki space). Sticking with topology, one can then see that for many results in topology, the precise nature of the continuous functions is irrelevant. Most theorems have natural counterparts in the setting of computable functions. This is because the relevant categories have very similar properties. 

If the creator, or the bot itself, were able to convince the relevant person/people at SE to make an exception or to amend the terms of service, then you wouldn't have a problem. If society were to change such that bots of whichever sort are generally considered persons (individuals) then there wouldn't be a problem since the normal and legal interpretation of the current TOS would admit them. In this context, the AI aspect is a red herring; what is important is that SE is providing its services with restrictions. If anybody/anything is not able to conform to those restrictions they are lying (falsely entering into a contract); a fact that has negative moral impacts. This answer addresses one facet of a bot autonomously participating in SE; there are certainly ways that a bot acting in coordination with a person, could fulfill the TOS but I don't interpret that as the thrust of the question. 

I read your question as Is computationalism falsifiable? In the comments, Not_Here argues that it is, because we would just need to demonstrate that minds can solve non-computable problems, e.g. the halting problem. However, to experimentally demonstrate that a mind solves the halting problem, we need to show that it correctly determines halting for all possible inputs. We immediately run into two problems: First, we have no general way of checking the answers - after all, the halting problem is non-computable. Second, any experiment can only deal with a finite number of inputs, and we would need to test them all. Essentially, the claim that a device (which always answers) solves the Halting problem is itself only falsifiable, but not decidable. We could find out that a given model of minds is able to solve the Halting problem, but that only tells us that this model and computationalism are inconsistent. It is not helpful in determining which one to let go. If you wish to avoid using theory for non-falsifiable stuff, I would recommend the word paradigm. 

I've responded to this question as though the creationists (et al.) were doing responsible scientific work. The Dover case has provided evidence that at least some practitioners in that camp intentionally ignored good scientific practices in order to produce what are, in effect, political propaganda to support their religious stance. Even if some practitioners are making good faith efforts to understand the world (scientifically), almost all of the time the quality of the work is dubious. For example, the mathematical modelling used to justify "irreducible complexity" was quickly shown to contain errors, and each of the the supposed biochemical examples of the same were shown to have less complex analogs in other species; the kinds of errors that erase a researcher's credibility. At some point, poor enough work, or continuing to pursue an idea despite disconfirming evidence, can be considered "not science"