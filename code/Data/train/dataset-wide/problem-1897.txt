Absolutely. Lithospheric flexure due to volcanic edifice emplacement is well-documented. Not only do you get isostatic depression near the volcano, but further afield you actually can have uplift due to a "hinging" sort of effect. Lithospheric flexure drives the growth of underwater coral atolls through subsidence at a recently emplaced volcano (coral forms at a fixed depth beneath sea level), but later can lift the same coral above sea level due to far-field volcanic emplacement, turning the underwater atoll into an island. See the seminal work on this by McNutt & Menard (1978). 

The Glen flow law for glaciers is a common relationship linking stress to strain. At its simplest, $\Sigma = k\tau^n$ where $\tau$ is stress, $\Sigma$ is strain, and $n$ is roughly 3. I understand that $k$ depends on temperature and material properties of the ice, and that it can vary over two or three orders of magnitude. I have been searching the literature to find some example values of $k$ (also called $B$ and $A$) but so far I've had a surprisingly hard time. Is there somewhere that has a compilation of $k$ values from various studies? 

21.7%, by my calculations (338 / 1556 holocene-active volcanoes). I calculated perennial snow by combining 6 weeks of MOD10A2 data from winter and summer weeks in 2014 to figure out which pixels had snow both in the summer and the winter. My source code for that is available as a gist (an older version accidentally classified cloud as snow; that's been fixed). Then I checked if these pixels fell within 10km of the volcanoes in the Smithsonian Institution's Global Volcanism Database. I also plotted the woefully incomplete Global Land Ice Measurements from Space glacier polygons. There are clearly a few false-positives on ocean islands... I think this is due to MOD10A2 marking choppy surf as snow. Looking into that. I intend to publish this and will put a reference here if it is published. Here's what the map looks like for part of Alaska: 

Looks like a chunk of quartz. Please re-write the question following A guide for asking "Identify this rock" questions? . 

Because of the Coriolis Effect, the prevailing winds on the earth between about the Tropic of Capricorn and the Tropic of Cancer go from the East to the West (knows as the Trade Winds). To get to the west coast of a continent within those latitudes, an air mass blowing from above an ocean must cross the entire continent. Along the way, the air mass causes precipitation (rain, snow, etc.) and loses water so by the time it reaches the west coast the air tends to be very dry and average annual precipitation will be very low. "Rain shadow" is a related effect in which the lee side of mountain ranges are dry because air masses experience orographic rainfall when they encounter the mountain range. This causes the Atacama desert to the west of the Andes, and the Mojave to the east of the Sierra Nevada. Note that the Mojave is east of the Sierra Nevada rather than west because the prevailing wind direction is westerly (from west to east) because it is north of Capricorn. Bear in mind that this explanation is extremely approximate and oversimplified, and that your assumption of deserts on the western side of a continent should be reversed north of about Capricorn and South of about Cancer, where the Trade Winds are replaced by the Westerlies. 

Together, these two claims seem to imply that if it's not thicker than 30m, it's not a glacier. Are either of these claims correct, and do they indeed imply my conclusion? N.B. The question arises because I've been working with some literature and databases that refer to things less than 30m thick as glaciers. Update: looking closer at GlaThiDa, I notice that it contains 490 glaciers listed with mean_depth less than 5m. However, all of these are from a single article (Cogley, 2008) and some of them are apparently only centimeters thick. Something must be wrong with this data; I'm looking into it. 

Neither displacement nor acceleration; most seismometers measure velocity. If you want displacement, you integrate the output over time, and if you want acceleration, you differentiate the output over time. Check the datasheet for the instrument you are interested in. For example, the Guralp 3T datasheet says that it outputs 1500V m/s, so for each meter per second of ground velocity the output increases by 1500V. (It also says it only outputs from +20V to -20V, so this means ground velocities greater than 20/1500 = 0.013 m/s will be "off the chart" i.e. saturate the instrument). Actually, the voltage output from a seismometer is not exactly proportional to displacement, velocity, OR acceleration. The actual output is the input displacement convolved with the impulse response of the seismometer. It's just that the impulse response is designed such that it will have an approximately linear response to ground velocity within the corner frequencies. In the 3T datasheet we were looking at, they say it's within -3 dB of linear as long as it's measuring ground that's not oscillating faster than 50Hz or slower than 0.0083Hz for one version of the instrument. Measuring displacement directly is known as geodesy (as opposed to seismometry) and the tools used for those measurements include GPS, lidar, and radar. To measure acceleration (strong motion), as Jay says, you can use an accelerometer. Or, precariously balanced rocks for the palaeo case! 

Assuming your question is about how much of the sun's radiation hits the Earth's surface rather than just reaching the edge of the atmosphere ... The amount of solar radiation that hit's the Earth's surface varies a lot, depending on weather conditions, time of day, day of the year, latitude, altitude, air quality ... It can be anywhere between 0 and ~$1200W/m^2$ There is a standard "full sun" solar intensity which is used as a benchmark for things like photovoltaics testing and calibration. That's $1000W/m^2$, with an atmospheric spectrum denoted by AM1.5 

Is it possible for there to be enough change such that climate change can reduce and soon come to a stable level? Yes, sort of. For some value of "soon". Of all the emissions released to date, it will take another thirty years for the first stage of impacts to make itself felt. So even if we went to net zero emissions tomorrow, we've got decades of seeing the first stage of impacts, and then centuries of seeing further consequences. (of course, the global climate will continue to change at the scale of tens of thousands of years, but I've understood your question to refer to human impacts, and human lifetimes) But we're not close to getting to net zero emissions. We may be close to the time when emissions stop rising. Then they've got to level off, and then fall to zero. And then probably we'll want them to be deeply negative for a while, to prevent further damage. So we have decades of future climate change already built into the system. And the longer we take to get to net zero emissions, the longer it will be before things stabilise at human timescales. And the higher the cumulative emissions before we reach peak atmospheric CO2 concentrations, the worse the consequences for humankind. If the political will was there, we could probably get to net negative emissions within 20 years. So, we could get to some kind of stability in, say 40-50 years. 

And then I'll have modelled on a 0.5° grid, and archived on a 2.5° grid Here, for illustration, is Britain in a 100km grid: source If I wanted to aggregate that to a 200km grid, then the four squares in the bottom-left corner, SQ, SR, SV, SW, would be combined into a single grid cell. And SS, ST, SX, SY would be combined into another grid cell. And so on. 

All models are wrong. That's important. All models are wrong. In any real-world system that we're interested in, the only accurate model of the system, is the system itself. Anything else, any simplification, gives wrong answers. Some models are useful. That's important, too. Some models help us structure our discussions of the uncertainties (H/T Prof Neil Strachan) Some models allow us to test "what if" scenarios, and look at what the relative changes might be. Now, in the real world, exogenous influences that the model can't account for, would mean that the actual outcomes would be different: but if the model gives a near-enough account of the scale of relative changes, we can still make informed judgements on the basis of the models. Even when it involves pesky things such as turbulence. Some models give us insights into emergent properties of systems: a lot of the really interesting problems are emergent properties that aren't necessarily obvious from just looking at the basic rules of the system, and any insights we can gain are valuable. Some models allow us to do experiments on systems that we couldn't possibly experiment on. And although we know the models are wrong, they can at least give us an indication of the range of possible outcomes. That's not to defend the use of bad models to do bad work. There's far too much of that in my field, and I do not like it. As Simon W says, it is possible to test models to see if they are suitable for a particular purpose. To continue using a model for a purpose where it is known to be inapplicable, is charlatanry, not academia. 

About 900 grammes of CO2 for each 1kWh of electricity. There is some variation: very modern super-critical coal plants can be lower. But 900g is a reasonable central estimate. Note that that's just CO2 from combustion. It can be higher, when we include CO2 and CH4 emissions from the rest of the coal supply chain too.