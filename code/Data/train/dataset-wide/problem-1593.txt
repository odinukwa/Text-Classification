Telescopes tend to have a fixed focal length. What changes is the size of the sensor in the instrument used. If a small sensor is used, then a smaller section of the field of view is exposed, resulting in a narrower field of view being imaged than the equipment is capable of. If a larger sensor is used, more of the field of view of the telescope is utilised. Additional optics in the light path that are associated with the specific instrument being used on the telescope will affect the field of view also. Telescopes do not offer the capability of 'zooming' as you understand it from your consumer digital camera. 

It depends, as you say, on the subject matter. For instance, images useful in variable star study can be provided to the AAVSO $URL$ and images relating to asteroids can be provided to the IAU Minor Planet Center. $URL$ Other subject matter will be accepted elsewhere. However, for the images to be useful in scientific fields, you will need to comply with the submission instructions, which a casual snap probably will not comply with. On the MPC guide for beginners there is a list of 44 technical suggestions for submitting scientific data: $URL$ The AAVSO has a tutorial in six chapters on photometry using a DSLR camera (and another for astro CCD cameras) $URL$ If you just want to get it out there and have people comment on what is in it, post it to Google+. 

I would say that your initial observation is flawed, so the question is moot. Huygens landing site, Titan: 

Well, at least you did some thinking and proposed a couple of personal thoughts instead of just asking for the answer to a homework question. Both observations you make are pertinent. Remember, a celestial sphere doesn't actually exist. It is an imaginary concept, a simplification based upon our perspective of the universe. A planetarium, whether it is an old-fashioned one that depicts an earth-bound perspective of the universe, or a modern digital projection system that can "fly" you through space to view the universe from a different place, is projecting a perspective of the view of the universe from a particular place, that is, you see the "celestial sphere" as it would appear from that place. In the case of a view from elsewhere in space, it would be a different celestial sphere from our celestial sphere. So yes, you would be at "the centre" of the celestial sphere. Maybe not the "very" centre in the case of old fashioned projectors with fixed star fields, as they wouldn't account for the 150 million kilometre imprecision caused by the movement of the earth around the sun. But, as this is an insignificant distance in astronomical terms, that doesn't matter a great deal, so "the centre" is probably a sufficient description. 

Pretty most all lunar eclipses will turn the moon red like that. The amount of redness does vary, and sometimes so little light gets to the sun it is almost completely dark. However the redness is so typical of a lunar eclipse that NASA describes it as a "characteristic orange-red color". That link has a neat table with a categorization of the colour ranges. Probably what triggered the media's "do a story on that!" bells was lots of chatter they noticed online, mostly from the loony fringe making more of it than it deserves. The reason for the extra attention was probably because this lunar eclipse (I can't bring myself to write 'blood moon' ick I've done it) is coincident with the Jewish Passover - not a surprising event, as Passover is always when the moon is full after the spring equinox. It happens that the Passover that was celebrated the evening before the day Jesus was executed was followed by a lunar eclipse, and the Bible makes mention of 'the moon being turned to blood.' Simple and straightforward, but then some people start going off on their own weird supposes and imagining that Jesus' second coming will occur on another lunar eclipse, as if a lunar eclipse after the spring equinox was the only time it is possible for him to visit. So you get lots of internet chatter, the media notices what is trending on twitter and does a half-baked story. Lunar eclipse will occur in other months too, but without this association, people don't seem to care as much. 

Firstly, the galaxy is only about 1000ly thick. We are fairly close to the galactic plane, maybe around 65 ly 'above' it if we call the direction we are moving away from 'down'. So on your assumption that visible objects are all within about 1000ly, we can suppose that we should see more stars in the plane than above and below the plane, as there is only about 500ly of stars in the galaxy above and below. We are perhaps 25kly from the galactic centre. Therefore there are about 25kly of stars outwards, and 75kly of stars inwards. If we could see all of them with the naked eye, we would see more stars to one side than the other. While many of the stars that we see are within 1000ly, that doesn't mean that the stars within this region of visibility are evenly distributed. Stars are packed closer together nearer the centre, which implies that we will see more towards one side than the other. I don't know where you get the idea you seek confirmation for that the density of stars is not higher in the galactic plane, because it isn't true. Density is greater toward the centre of the galaxy; and orthogonal to the galactic plane, density decreases as you move away from it. Plus, we see far more than merely dots of light from other stars. We see other objects that are aggregations of stars - clusters, and galaxies like Andromeda, the LMC and the SMC. We see nebulae, clouds of gas and dust. In fact, dust even obscures what we might otherwise see toward the galactic centre. So when you ask 'what is it we see?' the answer is: lots of things. Because there is more of that 'stuff' in the plane of the galaxy, we see the majority of that stuff as a ring around us. Because there is more of that stuff towards the centre of the galaxy, we see that the ring is brighter, fuller, more complex, and dominant on one side. 

Check out the Design Overview and the Antenna/Beamformer page on the MWA website. The basic idea is that the signal arriving at an antenna is delayed in the circuitry, which makes it seem to the processing engine like the tile is being tilted in a particular direction. 

It would be good if you referenced your sources, because you may be misunderstanding them. We'd be able to see what they actually say, and help you understand them. Nucleosynthesis of iron does not use more energy than it produces. It is, however often referred to as the heaviest element created in fusion that results in more energy produced than consumed. However, that isn't quite true. Heavier elements can be produced by fusion that produce more energy than is used, except these fusion reactions don't occur in stars. (Eg 40Ca + 40Ca) Also, it is possible for heavier nuclei to be fused in stars that result in more energy being produced than is used, but these are unstable isotopes and they decay quickly. So, more accurately, iron is the heaviest element produced in stellar nucleosynthesis in any significant quantity that produces more energy in fusion than the fusion consumes. This is called the alpha process ladder. Keep adding alpha particles to the newly generated nuclei, until you stop getting more energy out than you put in. The last step in the alpha process that does produce energy is 52Fe + 4He => 56Ni(excuse the rubbish notation; if this answer is considered helpful at all I will try to tidy up the notation) 56Ni + 4He => 60Zn uses more energy than it produces. 56Ni has a very short half-life of just 6 days, decaying to 56Co which has a half life of 77 days, which decays to 56Fe, which is stable. So when a star is on the limit of collapsing, it will be producing a lot of iron in it's final stages - some of it from decaying heavier radioactive isotopes. Why does the alpha process stop producing energy at this point? It is because that is where the peak binding energy is. More.