I don't feel we have enough context to judge the full argument, but going by what you've quoted, it seems that his line of argument is indeed that composing a symbol such that it has a compound meaning but no relationship to a compound pronunciation is problematic, because you dissociate the symbol from the pronunciation. You make it arbitrary and unpredictable. The implicit conclusion is that readers of such a writing system will have a harder time with literacy and (to go a step further that I will soon explain) with cognitive processes supposedly tied to literacy. I consider your counterexample from Chinese excellent. In reality this dissociation does not appear to be a hindrance to reading. However, the fear Seidenberg expresses is not a new one. It rests on the opposite premise: that there are writing systems where there is an association between symbol and pronunciation, and that the pronunciation is predictable. This of course refers to alphabetic or syllabic writing systems. Fundamentally, we can't escape the arbitrariness of the relationship. That the symbol < a > makes (in many languages) the sound we transcribe /a/ is an utterly contingent fact. However, we can combine these letters in more or less predictable ways and thereby make the pronunciation of new words predictable. In English this doesn't work so well, but if we take a spelling-reformed language like Spanish we can observe that an invented word like calabrenoda will be accurately pronounced by all speakers. I presume you know all this. What might be surprising is the importance that has been attached to this fact in the past. Keep in mind that language theorists have historically (before linguistics became more of a science) identified random features of their own language and argued for their being the key to the cultural superiority of speakers of their language. The argument generally runs along one of two lines: (a) The mysteriousness/power of the feature shows that the language is highly expressive and poetic ("see how many meanings arise out of one word; how subtle is the English mind!"); or (b) the regularity/sense of the feature shows that its speakers have a naturally logical mental bent. Such arguments, incidentally, are used first and foremost to further political or sociological ends; for example, such linguistic observations were used by medieval Christian critics to argue (along nonsensical lines) that Hebrew was an inherently backward language, aligning with their conviction that Judaism was an inherently backward religion. However, such arguments are not extinct in our day. One recent theorist who argues for the significance of the compositional quality is Kieran Egan, e.g. drawing from Vygotsky in The Educated Mind. For Egan, there is a succession of stages that humans and human cultures move through in terms of refinement of thought, and each succession requires that they have certain cognitive tools. He argues that having an alphabetic writing system lends itself to developing the cognitive tools to move on to the next stage. Therefore, for him, cultures whose language has a less phonologically transparent writing system are at a cognitive disadvantage. One example he cites is that of an indigenous people in Russia who were subjected to a logic test involving syllogisms: "Everywhere in the north is snowy; Siberia is in the north; is Siberia snowy?" They responded, "I don't know. I haven't been there." He claims that their inability to understand syllogisms (as he reads that exchange) can be attributed to the lack of what he considers a sophisticated, i.e. phonologically transparent, writing system.* So that's where Seidenberg's argument may be tending towards—I'm speculating. Now, is that view valid? I would tend to side with you and your objection, partly because of that history I referred to. Linguistic features have been tied to cultural superiority questions for a long, long time and rarely with any good reason. Is China exactly a backwards society? I think not. To address the question more head-on might require some good, hard data on literacy (% among population, age first learned, grade reading level, etc.) among Chinese students with comparable education to that of English students or students of other languages whose language is alphabetic. But intuitively I strongly suspect that there is not a significant discrepancy. Again, this whole answer rests on reading a lot into a short quotation from Seidenberg. :) * If I had my book with me I would cite the passage. I will try to remember to return to it when I'm home. 

Within the book itself, you have a perfect example on page 126 (maybe your 125 because the paragraph you quote is on my page 12). 

The Syntax of French by P.Rowlett (see here) would be a canonical answer for French. That said, I think it is worth pointing out that the project of writing a full grammar of a given language (identified presumably with the official language of some nation-state) or even of devising a complete account of some syntactic phenomenon peculiar to a certain language (say object agreement in French) is at least somewhat at cross-purpose with the minimalist entreprise in syntax, as the latter is interested in the syntactic phenomena that stem from the core human faculty of language and its interaction with interface properties and thus has almost by definition nothing to say about the former's apparent object of interest. Much more congenial to the minimalist framework is the project of writing a complete account of a cross-linguistically attested syntactic phenomenon (binding of pronouns, wh-movement, agreement, raising, DP-licensing, voice alternations, noun incorporation etc.) or even better of the correlations between those in the terms outline above. Of that variety of work, you'll find no shortage; the one you are apparently interested in, not so much. 

The paradox is how a word that means "head" came to mean "subdivision". We have to switch our point of view: Looking at a book, the chapters are subdivisions. But looking at the mass of words, each chapter heads a group of them. The chapters of an organization are branches of the whole, but in terms of the members a chapter collects them under a single head(ing). And again, the world has any number of things that are grouped into the "categories" of definition 2. And not just any sections, but the "main" sections of definition 1c. To start with, anyway. So a chapter is a "head" not looking from the top down, but from the bottom up. 

As jlliagre implies, not all these forms are derived directly from their Latin forms. Also, I don't know Latin, but as far as I'm aware the uses don't overlap perfectly. French cases are still used for the same purpose, though — to mark a noun's role in the sentence. For example, say I either send Marie across campus to Abdul's office, or Abdul to Marie's office. Those two scenarios could be expressed: 

makes no sense if used alone, modifies the grammatical (syntactic, if you will) function of the word it is attached to, does not modify the semantics of the word it is attached to, and can be used with at least an entire group of words (see below). 

A complement to the answers above: The alphabet used for transcribing and the level of transcription are frequently confused. IPA can, just as any other alphabet, be used for both phonetic and phonemic transcription (the difference has already been neatly explained), or anything in between. One might argue IPA is richer, poorer, more or less readable, flexible, regular, whatever, but in principle there is nothing in it, or any other alphabet, that forces you to use it at any particular level of abstraction. Alphabet and level of abstraction are two independent variables. 

I've never heard of any specific movement that would obligatorily accompany a specific word or phrase. However, especially if you count facial expression as movement, certain rhetoric strategies are, I believe, accompanied at least very often by movement. Sarcasm, mockery and such typically involve a specific intonation and facial expression. In that sense I can see how a certain phrase could begin to usually cooccur with a specific expression through being used primarily in an ironic sense. I suppose that this also accounts to a certain degree for the popularity of emoticons: without them it's often diffucult to decide if what one's reading is a joke or serious. I suppose yes and no might often come together with head movement but it's surely not a rule. On a theoretical ground, I can say this would be a relatively unlikely thing to happen, as being obviously redundant. The only scenario that comes to my mind that could lead to an obligatory cooccurrence, is with 'holy' or taboo words, where e.g. a certain movement could perhaps possibly be required in some culture when mentioning the name of a god, demon or something of the kind. 

where the verb きる which ordinarily means to cut has been appended to the verb to convey the idea that the action was brought to full completion. Just as one would normally not consider finish in 

It seems to me that with this question, you envision a much stronger thesis, one which is usually attributed to Kant, as user fdb correctly pointed out. The reason is that the current consensus view that basic mathematical concepts are hard-wired in our brains applies only to very basic mathematical concepts. In fact, I seem to remember reading studies suggesting that not only subtraction with large numbers was not hard-wired, the truth was that our brains are hard-wired to make mistakes while subtracting large numbers (at least when numbers are represented in the usual way). So beyond elementary concepts, the mathematical language developed through the patient working of mathematicians, sometimes (or even often) struggling against their intuitions. Such a struggle will inevitably be extremely sensitive to cultural norms and preconceptions. A famous example is the case of negative number, which were truly accepted in the West only 1500 years after the beginning of mathematics as a science, a clear indication (to me, at least) that there are not (in any self-evident way) a reflexive property of the way our brains are organized. 

As I'm sure you know, there are many ways to create neologisms. (Here are a few I summarized in a student paper as a bright-eyed, bushy-tailed undergrad.) It would be fair to speculate that borrowings using Latin roots are far outnumbered by some of the other means active today. The number of people with direct access to Latin has certainly declined over the last century. It is far from a given that a given person's higher education includes Latin. Moreover, the sort of people who do speak it are not often the movers and shakers in terms of neologisms (new words tend to come from popular, not esoteric, groups of people). Therefore, the chances are low of widespread neologisms entering English based on a direct firsthand borrowing from Latin. But there are many Latin roots that have essentially become English roots. That a morpheme can be traced to a Latin root is not a reason to say that new words formed using it are "using Latin". Take the relatively recent word metrosexual. The OED and etymonline.com agree that "metro" is from "metropolitan", a word that English has possessed for at least 500 years, and "sexual" is so ubiquitous in English that no one would say we had to look to Latin to use it in a neologism. Therefore, we can describe this as mere derivation. English is merely "borrowing" from English. If that's what you're referring to, then yes, I predict that those "Latin" roots will continue to be productive for a long, long time. Even if we're more likely to form new words by other means. 

is contingently ungrammatical if X is animate and specific. English relatives are another much studied case. 

It has been famously shown (by Emmanuel Dupoux, among others) that the ability to differentiate phonemes markedly decreases after the age of 2. Consequently, you presumably have less ability to distinguish the phonemes of English which are absent in Hungarian that someone who was born and raised in an English-speaking family. In that sense, you might not be a native speaker of English (and you wouldn't be even if you had stayed in the US). The experimental protocol is as follows: subjects listen to increasingly rapid random series of two phonemes X and Y which are distinct in language A but not in language B and are asked to distinguish them. At first the error rate is identical for both native speakers of language A and speakers who are native speakers of language B but grew up in a language A environment since the age of 2, namely linear with respect to the speed of the series . But after a certain threshold, which is independent of the languages A and B of the phonemes X and Y, non-native speakers lose the ability to distinguish X and Y and their answers become no more correct than random ones whereas the error rate of native speakers keeps following the linear rate for a much longer time. 

This is a good observation and a good question, and the comments below it make a valid point, as well. In short, I would say that there is no such thing as a solid cross-linguistic concept of 'proper nouns' -- or at least, none commonly accepted and adhered to. My own experience is that the term is primarily used to refer to what you could call prototypical proper nouns (Coca-Cola, Berlin, John Brown &c.), and rarely to not so clear cases. I suppose there might have been more than one attempt at a proper definition, but neither has gained enough following to be even known of by the majority of linguists. Here a long and passionate rant is in order on the attitude towards properly defined terms in linguistics, but instead I'll just say that you might not be able to even find a single term which every linguist understands the same way for every language. You will, however, have no difficulty finding a linguist who can't give a proper and cross-linguistically solid definition for virtually any term he or she's used while talking to you. Basing a definition on language-specific spelling is obviously not a great idea, although in some cases it might be the best we have. 'Whatever's written between spaces' remains the best definition of word I know. If you were to create a definition of your own, I suppose you should try to capture the common and distinctive features of the prototypical cases. You should not, however, get your hopes up about how many linguists will memorize it and adhere to it. It's a hopeless bunch in this regard. 

The NP Jean has no thematic relation to aime: it obviously does not fit anywhere in the thematic hierarchy outlined by Rowlett (and you can omit it and still get a perfectly well-formed sentence). Examples of thematic dependency abound in the sections 2.1.3 and 2.2.2. Note that within this perhaps seemingly innocuous paragraph is hidden (in plain sight) a very strong and very controversial theory of universal rigid mapping from syntax to semantics. 

Compared with the original, I was surprised that none mentioned either God or angels in their summary and interested by the fact that they, like me, find it especially hard to identify mood and modality (about half thought the son wanted to go in the forest see the beautiful things and the other half thought, correctly, that he had already seen them in the forest). 

I have troubles parsing the question unambiguously. My answer assumes the question means "Why are symmetrical c-commanding nodes not barriers to government whereas asymmetrically c-commanding nodes are (potentially) barriers to government?" but I encourage you to rewrite the question with more details in case I misunderstood. Under this assumption, the historically accurate answer was that this was a pure stipulation based on the fact that such an ad hoc fix gets the case assignment and binding properties right. The main problem with allowing symmetrical c-commanding nodes as barriers is the inherent ambiguity this involves: since binary trees have no ordering (so that their common drawing is deceptive), it would be impossible to define which node is a barrier for the other in the generic situation were symmetric c-commanding nodes to be allowed. However, such stipulations should always be regarded with great skepticism and accordingly a good deal of works in that branch of syntax in the last 30 years has been devoted to eliminate them (the impetus behind the so-called minimalist program). Within the framework of minimalist syntax, the answer to your question follows from the data structure of the syntactic objects constructed by Merge, as I encourage you to work out for yourself (or ask about).