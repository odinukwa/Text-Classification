One can hope that step 2 is doable with standard calculus tools, since there should be no other local maxima for interlaced points. But Step 1 seems to require a more imaginative approach. Why do I find this question interesting? There is a natural way to distribute N points on a circle (i.e., at equal distances), and this configuration is known to give the solution for many extremal problems, such as the Fekete problem, isoperimetric N-gon problem, etc. There is also a natural way to distribute two sets of N points -- namely, by formula (2), but I don't know of any nontrivial problem for which the optimality of such configuration has been established. 

It's sometimes convenient to have different notations for "$A$ is a subset of $B$" depending on what the inclusion map does: 

Maybe if you allow an exceptional set, as in "For every $x$ outside of some meagre set, there is a $\delta>0$ such that $B(x,\delta)$ is contained in one of the $\overline{A}_n$" (Indeed, the set of all $x$ where the above fails is a closed subset of $X$ with empty interior.) 

If it's non-surjective, $A\subsetneq B$ or $A\subset B$, depending on your religion If it's surjective, $A=B$ :) If the image is a precompact set, $A\Subset B$ 

Men'shov proved in 1936 that if $f\colon D\to\mathbb C$ is continuous and approximately differentiable outside of a countable set, then it is holomorphic in $D$ 1 (Russian original with French summary). In the same paper he gives an example, attributed to Lusin, which shows that continuity cannot be dropped entirely even if the function is approximately differentiable at every point. Let $\varphi\colon\mathbb C\to\mathbb C$ be an entire function that tends to $0$ as $z\to\infty$ within any sector $\{|\arg z|<\pi-\epsilon\}$ (approximation theory can be used to create such examples). Then $f(z)=z\varphi(1/z)$ has an approximate derivative everywhere in $\mathbb C$, but of course it is not differentiable or even continuous at $0$. Men'shov asked if continuity can be replaced with boundedness. This was answered affirmatively by Telyakovskii 50 years later 2. In fact, boundedness can be weakened to logarithmic integrability. Brodovich 3 proved that an injective function with an approximate derivative at every point is holomorphic. (MR review omits the injectivity assumption). A survey of results in this area was written by Dolzhenko 4, but it predates the work of Brodovich. 

Tung, S. H. Bernstein's theorem for the polydisc. Proc. Amer. Math. Soc. 85 (1982), no. 1, 73--76. MR0647901 (83h:32017) (from MR review): Let $P(z)$ be a polynomial of degree $N$ in $z=(z_1,\cdots,z_m)$; suppose that $|P(z)|\leq 1$ for $z\in U^m$; then $\|DP(z)\|\leq N$ for $z\in U^m$ where $\|DP(z)\|^2=\sum_{i=1}^m|\partial P/\partial z_i|^2$. Here $U^m$ is the polydisc. Same author proved Bernstein-type inequality for the ball, Tung, S. H. Extension of Bernšteĭn's theorem. Proc. Amer. Math. Soc. 83 (1981), no. 1, 103--106. MR0619992 (82k:32013) 

Another option is $\sum c_{mn}z^m \bar z^n$, which still keeps track of the complex structure. For instance, harmonic functions will have $c_{mn}=0$ unless $mn=0$. 

Have you tried the method of section 8.7, i.e., solving Abel's equation $\phi(P(x))-\phi(x)=1$? Here we expect $\phi(t)=t^{-1}+\sum_{n=1}^{\infty}c_n t^n$, and you can find the coefficients of $\phi$ one by one. For example, I took $P(x)=x-x^2+x^3+x^4$ and immediately found $c_1=-2$, $c_2=-5/2$, $c_3=-7/2$, $c_4=-17/4$... Not a general formula, but you can get as many terms as you want for a given $P$. 

It's not a problem to multiply the series: the product is $\sum_{(t,k)\in\mathbb Z^2} a_tb_k$. The question is how to sum the double series that we have. For series with nonnegative terms summation is not a problem either: we take the supremum of all finite sums. And since any finite sum is contained in a sufficiently large square, it follows that $\sum_{(t,k)\in\mathbb Z^2} |a_tb_k|$ is finite whenever $\sum_{t\in\mathbb Z} |a_t|$ and $\sum_{k\in\mathbb Z} |b_k|$ are. In general, $\sum_{(t,k)\in\mathbb Z^2} a_tb_k=S$ if for any $\epsilon>0$ there is a finite subset $A\subset \mathbb Z^2$ such that $|\sum_{(t,k)\in B}a_tb_k - S|<\epsilon$ whenever $B$ is finite and $B\supset A$. Now if both given series converge absolutely, then the contribution from outside of a large square is small, and it follows that $S$ is the product of two sums. 

An N-subset $\{x_1,\dots,x_N\}$ of a compact set $X\subset \mathbb R^d$ is called a set of Fekete points (named after Michael Fekete) if it maximizes the product $$\prod_{1\le k<j\le N}|x_k-x_j|\qquad (1)$$ among all such $N$-tuples. When $X\subset \mathbb C$, one can express this product in terms of the Vandermonde determinant. In this case Fekete points are of particular interest in approximation theory (as interpolation nodes). Generally, they have no explicit form and must be found numerically. But there are exceptions. When $X$ is a circle, Fekete points are equally spaced. This is well-known and can be proved like this: we may assume $x_k=\exp(i\theta_k)$ with $0=\theta_1<\theta_2<\dots <\theta_N<2\pi$. For a fixed integer $m$, $1\le m\le \lfloor N/2 \rfloor$, consider the product $\Pi(m)=\prod_{k=1}^N|x_{k+m}-x_{k}|$ with indices taken mod $N$. Since each point $x_k$ appears in just two terms of this product, it is not hard to see that $\Pi(m)$ is maximal when $x_k$ are equally spaced. (Indeed, $\log \sin$ is a concave function.) Now let $X$ be the union of two concentric circles of radii $r$ and $R$. Assume that $N=2n$ is even and that exactly $n$ of the points lie on each circle. With this additional assumption we are not quite in the Fekete problem anymore, but we have an obvious candidate for the maximum - 

Show that the maximum is attained by interlaced points, i.e., when ordered by the argument, the points alternate between the two circles. Show that for interlaced points, maximum of (1) is attained when they are equally spaced. 

The ultimate sparseness occurs when $Ax^*(\lambda)=0$, which is the case when the minimizer $x^*$ is the projection of $b$ onto $\ker A$. For this to happen, $\lambda$ must be small enough so that the restriction of $A$ to the orthogonal complement of its kernel is bounded from below by a constant greater than $2\lambda \mathrm{dist}(b,\ker A)$. Here the lower bound for operator is understood in the $\ell^2\to\ell^1$ norm. 

The minimizer $m$ is the nearest point projection of $X$ onto the subspace of $L^p$ formed by the constant functions ($p=3$ in your case). This $m$ is sometimes called the $p$-prediction or $p$-predictor of $X$. Apparently, this terminology began with Andô and Amemiya. Some of later papers are Landers and Rogge (who wrote a few other papers, e.g. this one), and Cuesta and Matrán. The term "generalized (conditional) expectation" also appeared. 

Pick $\lambda \in \mathbb{Z}_p \backslash \mathbb{Q}$ and define $H = \left\lbrace\begin{pmatrix} 1 & 0 & a \cr 0 & 1 & \lambda a \cr 0 & 0 & 1 \end{pmatrix} : a \in \mathbb{Z}_p\right\rbrace$. Then $H$ is a closed subgroup of $Tr_1(3,\mathbb{Q}_p)$ but $H \cap Tr_1(3,\mathbb{Q})$ is the trivial group, hence certainly not dense in $H$. 

I find it helpful to first work through the definition of multiplication on $\mathcal{D}^{(m)}$ when $m = \infty$, in which case it reduces to the "classical" ring of differential operators in the sense of Grothendieck; read sections 16.7 and 16.8 of EGA 4, Quatrième partie. So let $A$ be a commutative base ring, let $S = Spec(A)$ and let $X = \mathbb{A}^1_S$ so that $B = A[t] = \Gamma(X, \mathcal{O})$. We want to work out $\mathcal{D}^{(\infty)}(X)$. Let $Y = X \times_S X$ and $m = \infty$. Let $n \geq 0$. First we have to work out the global sections of the sheaf $\mathcal{P}^n_{Xm}(Y)$, considered as a $B$-module. This will turn out to be dual (as a $B$-module) to the $B$-module of all Grothendieck differential operators of order at most $n$. Now $\mathcal{O}(Y) = B \otimes_A B$ is isomorphic as an $A$-algebra to the polynomial ring $A[t,t']$ where $t \mapsto t \otimes 1$ and $t' \mapsto 1 \otimes t$. The diagonal immersion $X \hookrightarrow Y$ corresponds to the algebra surjection $B \otimes_A B \to B$ which is just the multiplication map. So the ideal of the diagonal, namely the kernel of this map, is generated as an ideal by the element $$\tau := t \otimes 1 - 1 \otimes t.$$ Let's view $\mathcal{O}(Y)$ as a $B$-algebra via the map $b \mapsto b \otimes 1$; then $\mathcal{O}(Y) \cong B[\tau]$. By definition (EGA IV, 16.7.1.1), the global sections of $\mathcal{P}^n_{X\infty}(Y)$ are just $$P^n := \mathcal{O}(Y) / (\tau^{n+1})$$ --- this is the algebra of functions on the $n$-th infinitesimal neighbourhood of the diagonal $\tau = 0$ inside $\mathcal{O}(Y)$ (hence the $n+1$ in the exponent). So in particular it is a free $B$-module of rank $n+1$ with generators (the images of) $\tau^i$ for $0 \leq i \leq n$. By definition, $$\mathcal{D}^{(\infty)}_n (X) := Hom_B(P_n, B) =: D_n $$ which is again a free $B$-module of rank $n+1$; let $\{ \partial^{[i]}, i=0, \ldots, n\}$ be the dual basis for this module. Now the multiplication map $D_r \times D_s \to D_{r+s}$ is the $B$-module dual of a map $\delta : P^{r+s} \to P^r \otimes P^s$ which is constructed in EGA IV, Lemma 16.8.9.1. Morally $\delta$ sends $a \otimes b$ to $a \otimes 1 \otimes 1 \otimes b$, as Gros/Le Stum/Quirros mention. This turns out to be a $B$-algebra homomorphism, and tts key property is that $$\delta( \overline{\tau} ) = \overline{ \tau} \otimes 1 + 1 \otimes \overline{\tau}$$ (it is a "primitive element" in an appropriate bialgebra --- see EGA IV.4, 16.8.9.4). Let's now work out how to multiply $\partial^{[i]}$ by $\partial^{[j]}$ (drop the bars for clarity): $$(\partial^{[i]} \cdot \partial^{[j]})(\tau^k) = (\partial^{[i]} \otimes \partial^{[j]})(\tau \otimes 1 + 1 \otimes \tau)^k = \sum_{a + b = k} \binom{k}{a} \partial^{[i]}(\tau^a) \partial^{[j]}(\tau^b)$$ which is just $\binom{i+j}{i}\delta_{k,i+j}$. Since $\binom{i+j}{i} \partial^{[i+j]}$ has the same effect on each $\tau^k$, we deduce that $$ \partial^{[i]} \cdot \partial^{[j]} = \binom{i+j}{i} \partial^{[i+j]}$$ which is hopefully the familiar rule for multiplying divided powers (morally $\partial^{[i]} = \partial^i/i!$). The point of the Berthelot construction is that it is possible to vary the divided-power structure on the diagonal, and thereby control just how many divided powers one gets in $\mathcal{D}^{(m)}$. For example, if $m = 0$ then you instead allow all divided powers on the ideal of the diagonal (algebraically this means you consider the divided power algebra of the ideal $(\tau)$ in $B[\tau]$ to get $\oplus_{n=0}^\infty B \tau^{[n]}$), and when you take the $B$-dual, these divided powers in $\tau$ "remove" the divided powers in $\partial$ and you end up with $\mathcal{D}^{(0)}(X) = B[\partial]$, the ring of crystalline differential operators (no divided powers). Now to answer your question, let the level $m \geq 0$ be fixed. Then as Gros/Le Stum/Quirros explain just before Definition 2.5, $$\Gamma(Y, \mathcal{P}^n_{Xm}(Y)) = \oplus_{a=0}^n B \tau^{ \{ a \} } $$ where $\tau^{ \{ a \} }$ is a symbol that "behaves like $\tau^a / q_a!$" (where $q_a$ is the integer part of $a / p^m$: thus $a = q_a p^m + r_a$ say). To understand the multiplication of the dual vectors to these $\tau^{ \{ a \} }$, namely the $\partial^{ \langle a \rangle }$, we need to understand how to comultiply the $\tau^{ \{ a \} }$. So we compute (again dropping bars for convenience) $$ \delta( \tau^{ \{ a \} }) = \frac{1}{q_a!} \delta(\tau)^a = \sum_{i+j = a} \frac{1}{q_a!} \binom{i+j}{i} \tau^i \otimes \tau^j = \sum_{i+j = a} \frac{q_i! q_j!}{q_{i+j}!} \binom{i+j}{i} \tau^{ \{ i \} } \otimes \tau^{ \{ j \} }$$ and the same computation as above in the case $m=\infty$ shows that $$ \partial^{\langle i \rangle} \cdot \partial^{\langle j \rangle} = \frac{q_i! q_j!}{q_{i+j}!} \binom{i+j}{i} \partial^{\langle i + j \rangle}.$$ The interesting thing is that this structure constant $\frac{q_i! q_j!}{q_{i+j}!} \binom{i+j}{i}$ is always a $p$-integral rational number (see Lemma 1.1.3(i) in Berthelot's paper), so it makes sense whenever $A$ is an algebra over $\mathbb{Z}_{(p)}$, say, and in particular if $A$ had characteristic $p$. Note that if $A$ was a $\mathbb{Q}$-algebra, then there would be a ring homomorphism from $\mathcal{D}^{(m)}$ to $A[t; \partial]$ which sends $$ \partial^{\langle i \rangle} \mapsto \frac{q_i!\partial^i}{i!} $$ since $$ \left(\frac{q_i! \partial^i}{i!}\right) \cdot \left(\frac{q_j! \partial^j}{j!}\right) = \frac{q_i! q_j!}{q_{i+j}!} \binom{i+j}{i} \left( \frac{q_{i+j}! \partial^{i+j}}{(i+j)!}\right).$$ Thus morally $\partial^{\langle i \rangle}$ should be thought of as "modified divided powers" $q_i! \partial^i / i!$. Finally, you don't need all of the $\partial^{\langle i \rangle}$ to generate $\mathcal{D}^{(m)}$. As is well-known, the full ring of Grothendieck differential operators in characteristic $p$ can be generated by the divided powers $\partial^{[p^a]}$ (for all $a \geq 0$). Since $q_i = 0$ for $i < p^m$ and $q_{p^m} = 1$, the modified divided powers $\partial^{\langle p^i \rangle}$ are equal to the "true" divided powers $\partial^{[p^i]}$ for $0 \leq i \leq m$. If $a > m$ then since $q_{p^a} = p^{a-m}$, $$\partial^{\langle p^a \rangle} = \frac{ p^{a-m}! }{ p^a! } \partial^{p^a} = \left(\frac{ p^{a-m}! (p^m!)^{p^{a-m}} }{p^a!} \right) (\partial^{\langle p^m \rangle})^{p^{a-m}}$$ shows that $\partial^{\langle p^a \rangle}$ is a $p$-adic unit times a power of $\partial^{\langle p^m \rangle}$ for $a \geq m$ since the $p$-adic valuation of that big fraction is $$\frac{p^{a-m}-1}{p-1} + p^{a-m} \frac{p^m-1}{p-1} - \frac{p^a-1}{p-1} = 0.$$ So we see that $\mathcal{D}^{(m)}(\mathbb{A}^1_S)$ in this case is the $A$-algebra generated by $t$ and the divided powers $\partial^{[p^0]}, \partial^{[p^1]}, \ldots, \partial^{[p^m]}$, subject to appropriate natural relations. Edit: To see what the map $X \to P_{Xm}(Y)$ looks like in the case $X = \mathbb{A}^1_S$, it is enough to describe the corresponding map $C := \mathcal{O}(P_{Xm}(Y)) \to B = \mathcal{O}(X)$ on functions, because everything in sight is affine. $C$ is a $B$-algebra, generated by symbols $\tau^{ \{a \} }$ for all $a \geq 1$ subject to the relations $$\tau^{ \{a \} } \cdot \tau^{ \{b \} } = \frac{q_{a+b}!}{q_a!q_b!} \tau^{ \{ a + b \} }$$ (note that the structure constant $\frac{q_{a+b}!}{q_a!q_b!}$ is actually an integer, this again follows from Lemma 1.1.3(i) in Berthelot's paper.) The map $C \to B$ sends all of the generators $\tau^{ \{a \} }$ to zero, and the map $C \to P^n$ which corresponds to the closed subscheme $P^n_{Xm}(Y)$ of $P_{Xm}(Y)$ sends all of the $\tau^{ \{ a \} }$ to zero for $a \geq n+1$. This description makes it easy to see that the algebra of functions $C$ on $P_{Xm}(Y)$ is isomorphic to the polynomial ring $B[\tau]$ when $m = \infty$ (since we can take $q_a$ to be always zero in this case), and to the "free" divided-power algebra $B[\tau^{[n]} : n\geq 1]$ that Gros/Le Stum/Quirros call $\Gamma_\bullet(B \tau)$ when $m = 0$. This is because $q_a = a$ in this case, so the defining relations between the $\tau^{ \{a \}}$ reduce to $$\tau^{ \{a \} } \cdot \tau^{ \{b \} } = \binom{a+b}{a} \tau^{ \{ a + b \} }.$$