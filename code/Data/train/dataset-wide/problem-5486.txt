I'm hunting through Plato quotes and I can't find this one. (But it sounds plausible.) My question is: Did Plato say "In order to argue, you must express your opponents argument better than they could?" 

Now I'm not making a judgment for or against supernatural claims in this - I'm just trying to understand (a) the assumptions in this observation; and (b) how we reason about such claims. As I understand it we have four general ways of knowing things (epistomology): 

Plato's rejection of the Sophists is reasoned by their rhetoric lacking justice (khairos) - and he says they need to move to 'Maintenance and Restoration'. $URL$ The broader point in this reference was that Plato was the originator of arguing with empathy by better understanding the opponents position first, rather than saying something appropriate to the situation. 

Truth by authority - this is true because a judge, a scientific authority, a person at the top of an organisation, or a well-recognised book/publication said it was true - and I don't need to question it further. Truth by reasoning (rationalism) - this is true because someone has given me a bunch of reasons, and I have weighed it in my head, and I can't come up with a competing set of reasons that knocks it down - so it is valid in my head. Truth by experiment (Empiricism) - this is true because I saw it or felt it. Further more I could repeat it, and if you repeat it, you will see the truth of it as well. Truth by message (testimonial evidence) - I heard this message from a person I trust, and I hold their observations of reality as true. You can choose to listen to their message as well. 

Although the argument offers the general fact that people have religious experiences, it ignores the specific fact that many people never have religious experiences. Of those who do have these experiences, many already hold a prior belief in God. The Ludic fallacy? Nassim Taleb coined this term in his book The Black Swan. He defines it as basing studies of chance on the narrow world of games and dice. The gynecologists example: 

Whilst your friend's ideas about beliefs have some merit, they are actually irrelevant to the argument at hand. Your argument could very well be wrong, but not for the reasons that he has presented. This is because he is attacking your beliefs instead of your argument. For your friend's argument to be successful, he needs to attack the notion of creatine helping soreness, rather than attacking the idea that you hold a belief in the utility of creatine with respect to soreness. Therefore, I would say that he is guilty of ad hominem. Nevertheless, I don't think that hunting fallacies and then accusing something of committing fallacy X is particularly useful. Rather, you should be able to explain where the reasoning has gone wrong, and you don't need to know the name of a fallacy in order to do that. P.S. What should be noted is that the impact of creatine on soreness is an empirical issue. If you guys intend to debate the notion that creatine reduces muscle soreness, you have to bring some empirical support to the table. 

Suppose S denotes the sentence "m is struck". Suppose L denotes the sentence "m will light". Suppose W denotes the sentence "m is wet". 

Suppose m is a dry match. Under most circumstances, if m is struck, it will light. But if somebody were to wet m, then we might stipulate that m would not light even if it were struck. 

Question: Is the conditional S > L true? My intuition is that S > L is not true. This is because S is not enough for us to guarantee that L is true. For example, suppose S & W is true. Then S is true. Yet L would be false. Hence S > L is false. The problem with this is argument is that if it is true, then almost every conditional we utter is false. When we assert conditionals like S > L, we are often conversationally implying S & ~W > L. And in fact this isn't even quite right. There could be other things besides just W that could prevent L from being true. So really, the antecedent of S > L would have to contain an infinite number of further conditions (for example, that the match isn't deprived of oxygen at the moment it is struck) to truly guarantee that L is the case. I'm temporarily calling this argument the "Underspecificiation of Conditional Antecedents Argument (UCAA)" for why many conditionals, as uttered, could be false. Is this a common thought, and has there been much written about this argument? 

However, what your friend seems to be doing is that he is highlighting a feature of your disposition (your beliefs), and then using this in order to refute your argument. In other words: 

is the explicandum and is the explicans. Generalisation Roughly speaking, this is a broad statement or an idea which is supposed to apply to a group of things. For example: 

It looks like a version of the classic omnipotence paradox to me. For instance, the paradox of the stone: 

Sorry for turning up so late to the party. The front door was locked so I had to climb through a window. Anyway, I've recently come across the following book: 

My answer It seems to me that a generalisation such as the above can be part of the explicandum but it shouldn't be part of the explicans because, ideally, it would require an explanation of its own. This is of course assuming that you want your explanation to be a good one. In this sense, a generalisation doesn't quite fit the explanation criteria. 

Under the previous definition of "being human", those who fall prey to the allure of answers which allow them to follow custom and set aside contemplation- are possibly living an unexamined life. An unexamined life of the above sort would be quite pleasant, where one can live a "conventional" rather than ethically examined, life. 

Part of what your friend is saying does have some truth to it. Just because someone believes that X is the case, it doesn't follow that X is actually the case. 

It seems that in most everyday cases, taking conditionals to have material truth conditions suffices for us to reason with them correctly (in the sense that using material truth conditions will most often uncontroversially take us from true premises to true conclusions, even if the actual material truth conditions for conditionals are, strictly speaking, incorrect in a generalized context). No doubt there are many cases where material truth conditions for indicative conditionals seem to be harmful to our ability to reason effectively. For example, if I uttered the conditional "If I had a counter-example to Fermat's Last Theorem, nobody would care", then material truth conditions would force this utterance to be true. There are many other examples in the literature. Fortunately, we don't often deal with bizarre conditionals like these (outside of the logical literature). On top of this, even when we are dealing with bizarre conditionals, we can use natural language to mitigate for ambiguity issues by specifying our own semantics. We could say something like "if, in an impossible world where I had a counter-example to Fermat's Last Theorem, people would definitely care, and not vacuously so." In a sense, we have used natural language to specify our own conditional semantics. Are there philosophical issues with doing this? Sure. Are there are practical issues (even within the context of philosophy minus logic)? It's not so clear me. My question then is the following: why should we care as philosophers what the true semantics for indicative conditionals are, especially given that we can always mitigate ambiguity/logical issues with natural language (in particular, by specifying our our own semantics for the conditionals we utter on a case by case basis)? I agree conditional semantics is an interesting topic in its own right, but there is only so much time in the day, and there are many other interesting philosophical questions to think about as well. So why this one above others? PS -- For the record, I've spent a great deal of time thinking about conditional semantics. I'm asking this question in good spirit (not a negative one). 

This conclusion is clearly contradictory. The argument is valid however, since it follows a valid form of reasoning (MP). If the premises were true, the conclusion would be true. Remember that validity isn't concerned with the actual truth of the premises. 

If the premise were true, then the conclusion would be true and the argument would be valid. But what if our premise was actually false? For example, what if X was actually a triangle? If is true, then the conclusion is also false. We would therefore have a false premise which leads to a false conclusion. We would need the premise to be true and the conclusion to be false for the argument to be invalid. But, this can't happen. If X is a triangle, then the conclusion is false. If X is a square, then the conclusion is true. Either way, we are stuck in a situation where the truth of the premise entails the truth of the conclusion. The argument is therefore valid. Let's define two terms, of which only one term is directly relevant to the question at hand: Tautology: something that is true in all possible worlds. Contradiction : something that is false in all possible worlds. So, if we have a conclusion that is false in all possible worlds, the argument would only be valid if we have premises that entail the truth of the conclusion if the premises were true. Here is an example (Modus Ponens): 

There's a good entry on SEP about Pre-Socratic Philosophy,where Cosmology is also mentioned. you might want to take a look over there.