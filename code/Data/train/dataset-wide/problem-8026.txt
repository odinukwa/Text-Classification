Here is part 1″ solved, but the answer is complex and too long for a comment or edit. Notation is similar but not identical to before: Let f be a separable, irreducible polynomial of degree d. Let B be the block-Toeplitz matrix whose diagonal blocks are the companion matrix of f, whose first super-diagonal blocks are the identity matrix, and whose other blocks are 0. Let b be the number of diagonal blocks. Let { vi : i = 1,...,b*d } be the standard basis. We wish to express each vi for i≥2 in terms of v1, f, and b. In terms of k[x]-modules, B is the action of x on the module M = k[x]/(f^b) in the basis where v1 = 1 + (f^b), and vi are unknown polynomials related to f and b. The matrix explicitly says that vi⋅B = vi+1 + vi+d when d does not divide i−1. This can be solved for: 

These are called Dedekind groups, and the non-abelian ones are called Hamiltonian groups. The finite ones were classified by Dedekind, and the classification extended to all groups by Baer. The non-abelian ones are a direct product of the quaternion group of order 8, an elementary abelian 2 group, and a periodic abelian group of odd order (or all of whose elements have odd order). Periodic abelian groups all of whose elements have odd order can be quite complicated, but the finite ones are direct products of cyclic groups. Your example does not have the property that all of its subgroups are normal when n ≥ 4. The subgroup generated by x1*x2*x3 is not normal, since (x1*x2*x3)^x4 = (a*x1)*(a*x2)*(a*x3) = a*x1*x2*x3, but x1*x2*x3 has order 2. For n = 3, your group is Q8 x 2, and so is Hamiltonian. The cyclic group of order 6 and the direct product Q8 x 3 are two groups of non-(prime power) order with every subgroup normal. 

Goursat's Lemma provides a complete characterization of subgroups of a direct product of two groups as fiber products. In the language I am used to: subgroups correspond to the graphs of isomorphisms between isomorphic sections of the two factors. Some subgroup embedding properties can be read from the embedding of the sections in the factors (for instance being normal in the factors, or being central in the factors), but there are no embedding properties required to use the lemma. Goursat's lemma appears in Roland Schmidt's Lattice of Subgroups book in chapter 1.6 (google books), and as an exercise in several textbooks. 

The answer to question #2 is yes, by Tim Dokchitser. $$ R = \mathbb{Z}[e]/(2,ee), (1,2,3,4) = \begin{pmatrix} 1+e & 1+e \\ e & 1 \end{pmatrix}, (1,2) = \begin{pmatrix} 1 & 0 \\ 1 & 1 \end{pmatrix} $$ His answer can be verified with GAP using the matrix representation of the algebra. Since Kevin asked about using more complicated algebras, I thought it might be useful to mention how easy it is to use matrix representations. 

(The infimum is non-zero, assuming $\tau\not=0$, as it's always larger than the injective tensor norm. But it's not obvious to me that you actually get a norm on $H\otimes E$ from this). If $E$ is a Hilbert space, then the norm is independent of the choice of $\mu$ and $\theta$; you just get the Hilbert space tensor product norm. But what if, say, $E$ is a finite-dimensional $\ell^\infty$ space? 

To start with, we use the Eberlein-Smulian Theorem to observe that a Banach space $F$ is reflexive if and only if every separable subspace of $F$ is reflexive. [Question: Do we need Eberlein-Smulian to show this?] Recall also that $\mc U$ being countably incomplete means that there is a nested sequence of sets $A_1 \supseteq A_2 \supseteq \cdots$ in $\mc U$ with $\cap_i A_i = \emptyset$. I think of this property as allowing us to embed sequential convergence into convergence along $\mc U$. Finally, let us recall Theorem 6.3 in Heinrich's paper: 

As my comment said, if $A$ is a $C^*$-algebra, then "yes". $\newcommand{\mc}{\mathcal}\newcommand{\ip}[2]{\langle #1,#2\rangle}$To show it's not always true, here's a counter-example. Let $E$ be a reflexive Banach space, and let $A = \mc A(E)$ be the algebra of approximable (norm-closure of finite-rank) operators. Then $A$ is Arens regular. Let $\mc U$ be a non-principle ultrafilter on $\mathbb N$ (for example) and consider the ultrapower $(A)_{\mc U}$ which, in the obvious way, can be considered as a closed subalgebra of $\mc B((E)_{\mc U})$. [The idea behind the following proof is that if $(E)_{\mc U}$ is not reflexive, then $\mc A( (E)_{\mc U} )$ is not Arens regular, and "morally" $\mc A( (E)_{\mc U} )$ is a subalgebra of $(A)_{\mc U}$, so $(A)_{\mc U}$ is not Arens regular. This is not true, so we work a bit harder.] I'll use Heinrich's wonderful paper Ultraproducts in Banach space theory Sadly not open access (WHY?) Namely, Corollary 7.5 which says: 

The answer to 1 is "yes", and 2 is not quite well-defined, to my mind. I'm going to follow Takesaki, Chapter III, Section 4, but this is all standard stuff. Given a C*-algebra $A$, a closed subspace $V$ of $A^*$ is left-invariant if $a\mu\in V$ for each $a\in A,\mu\in V$, where $(a\mu)(b) = \mu(ba)$ for $b\in A$. Then we have the following (Corollary~4.4 in the book): 

If I understand the question correctly, then maybe you are after special cases, as well as a general comment. So, as one of your examples suggests, one special case is to let G be a Banach space, considered as sitting inside its own bidual, and let $X=G^*$. Thus G induces the usual weak*-topology on X. So an example of a positive answer is furnished by the Kaplansky Density Theorem: here G would be the predual of a von Neumann algebra, X would be a von Neumann algebra, and we let Y be any self-adjoint subalgebra which is weak*-dense. Then Kaplansky Density tells us that indeed the unit ball of Y is weak*-dense in the unit ball of X. This is an incredibly useful tool in Operator Algebra theory. This then suggests that the result is unlikely to be true in general. Indeed, I think rpotrie's counter-example works! But here's an easier variant. Let $G=c_0$ and $X=\ell^1$, and let Y be the span of vectors $e_n+ne_{n+1}$. To see that this is weak*-dense, suppose that $\sum_k a_k e_k^* \in c_0$ annihilates all of Y. Then $a_n + na_{n+1}=0$ for all $n$, so $a_1 + a_2=0$ and $0 = a_2+2a_3 = 2a_3 - a_1$ and $0=a_3+3a_4 = (1/2)a_1+3a_4$, so $a_1 = -a_2 = a_3/2 = -a_4/3$ and an easy induction shows $a_1 = (-1)^{n-1}a_n/n$. Thus $|a_n| = n|a_1|$ for all $n$, but as $|a_n|\rightarrow 0$, it follows that $a_1=0$, and so actually $a_n=0$ for all $n$. Hence Y is weak*-dense. However, $e_1$ is in the closed unit ball of X, but it's pretty clear that we can't approximate it by norm one elements in Y (to do this without a tedious calculation defeats me right now). 

Frobenius's original turn-of-the-century perspective was the nonvanishing of a determinant. Brauer–Nesbitt–Nakayama studied some equivalent definitions in the late 30s and early 40s. For instance, an equivalence between the left and right regular representations is a rare and beautiful thing; this gives an equivalence between projectivity and injectivity that is explained in modern language in Lam's Lectures on Modules and Rings. This also gives a "perfect duality" studied by Dieudonné in the late 50s. I added the missing early sources to the wikipedia article, including the Brauer–Nesbitt announcement in PNAS which is pretty easy to read. 

One phrase is just "normal product", but people who use such a phrase usually don't pay attention K∩L, so I don't think it will help you very much. These normal products are much weirder than direct products with amalgamation though! For instance, any (finite) direct product of supersolvable groups is supersolvable, and any quotient of a supersolvable group is supersolvable, so any (finite) direct product with amalgamation of supersolvable groups is supersolvable. However, a normal product of supersolvable groups need not be supersolvable. While the groups may normalize each other, they may not normalize their chief series, and so the result may not be supersolvable. The key problem is that [K,L] ≤ K ∩ L only implies K and L commute when K ∩ L = 1. People do say very non-trivial things about normal products, but I've not heard anything that sounds relevant to your situation. 

These are called Hopfian modules. I didn't see any particularly exciting general characterization, but there are several special case characterizations (that show up easily in a google or mathscinet search). There are also several papers devoted to giving "interesting" examples. An exercise in Lam's Lectures on Modules and Rings asks one to prove that every finitely generated module over a commutative ring is Hopfian (so if the ring is not-noetherian, this is a generalization). 

Note that efficient is sometimes defined in terms of the rank of the Schur multiplier. So be careful that your usage may contradict some of the papers (which give "efficient" presentations for groups with non-trivial Schur multiplier; they are allowed to use one extra relation per independent generator of the Schur multiplier). A related concept is an asymptotic version that seeks to describe how complicated presentations of finite simple groups get. In fact it seems they are very, very simple: 

Subnormality is a pretty critical idea, and many of Bender's insights use subnormality, so I would not suggest avoiding subnormality. Other characterizations of the Fitting subgroup in terms of subnormality are given in Huppert's textbooks. In particular, the Fitting subgroup as the elements that centralize chief factors is a very important viewpoint. It generalizes to F-subnormality in the finite soluble world, and Bender's p*-nilpotency in the finite insoluble world. Kegel and Carter have a number of nice papers that explore subnormality in ways that have heavily influenced both the soluble and the insoluble worlds. Robinson's group theory textbook (and Lennox–Stonehewer MR902857) have a good description of subnormality in the infinite case. Wielandt's collected works contains several good textbook style presentations of subnormality that are not properly contained in any other works that I have found. They avoid assuming finiteness, and tend to have very interesting relationships between perfect subgroups and subnormality, that complement Bender's work. 

I think? So, here's a thought. I'm always of the opinion that you should give the maximal amount of detail where referencing something. Give the exact Theorem number in the paper you reference (not just ``by results of [12] it follows that...''). Explain carefully the hypotheses and conclusions. Of course, the more accepted a result is, the less detail you need to give. If, however, you actually want to reference the proof then I'd be very careful. E.g. you might observe that the paper shows X=>Y, but the proof works for the weaker X'. I'd be tempted to give a sketch, or outline exactly the changes needed. My guess is that a lot of subtle errors can be introduced by referencing proofs: I've heard it said that most mathematical results are true, but many proofs are subtly wrong. So it might be true that the proof in [12] shows that X'=>Y, but maybe the author stated it only for X because there is a subtle error in the proof, and really the stronger X is required. (This, of course, is also a good test of your own proofs, but I'm heading off topic...) 

I'll add a specific entry for Takesaki's books. I learnt what von Neumann theory I know from these books. Especially volume 2 is a very nice, and concise, guide to an awful lot of the theory around Tomita-Takesaki and Connes' theory of weights. If you are interested in Tomita-Takesaki, in a gentler fashion, then the old books by Stratila are nice. In particular, they explain the unbounded operator theory somewhat more than Takesaki does. But it really depends what the original interest is: if you want to get into modern C*-algebra theory, then Takesaki is not the way to go. Finally, for reference, the recent book by Blakadar is wonderful, and is a great place to look for something, before reading up in more detail somewhere else. 

Let's be more precise with an example which is close to my actual situation. Let $A$ be a $k$-algebra ($k=\mathbb C$ if you like) and let $U:A{\sf -mod} \rightarrow k{\sf -vect}$ the forgetful functor from left $A$-modules to $k$-vector spaces. This has a left adjoint $A \otimes \underline{\ \ }$; you have a natural bijection, for a vector space $V$ and a module $M$, 

Under this definition, it is not true that having non-empty resolvent set implies closed. For example, let $X=\ell^2$, let $D(T) = c_{00}$ be the space of eventually 0 sequences, and define $T((x_n)) = (nx_n)$. Set $\lambda=0$ and check the conditions: $T$ is bijective between $c_{00}$ and $c_{00}$; $T^{-1}((x_n)) = (n^{-1}x_n)$ is bounded; $c_{00}$ is dense in $\ell^2$. But $T$ is not closed; only closable. Let's be a bit more precise. For any $T:X\supseteq D(T)\rightarrow X$, if $T$ is injective then we may define $T^{-1}:D(T^{-1})\rightarrow X$ by setting $D(T^{-1})$ to be the image of $T$, and defining $T^{-1}(T(x)) = x$ for $x\in D(T)$. This is well-defined as $T$ is injective. Let's compare the graphs: $$ \mathcal{G}(T) = \{ (x,T(x)) : x \in D(T) \}, \quad \mathcal{G}(T^{-1}) = \{ (T(x),x) : x\in D(T) \}, $$ so clearly $T$ is closed if and only if $T^{-1}$ is. As Robert Israel observes, it is also true that $T$ is closed if and only if $T-\lambda I$ is closed, and hence $(T-\lambda I)^{-1}$ closed does imply that $T$ is closed. There are further definitions of "resolvent set". E.g. Engel, Nagel define $\lambda$ to be in the resolvent set if $T-\lambda I:D(T)\rightarrow X$ is bijective, that is, $T-\lambda I$ has range the whole of $X$. They also by definition already assume $T$ is closed, so that then $(T-\lambda I)^{-1}$ is closed and hence by the Closed Graph Theorem, bounded.