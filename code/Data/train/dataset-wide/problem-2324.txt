Don't put quotes around things that aren't strings! You have (with some newlines and one space-after-comma added): 

Server 2 is obliged by its duties under the 2PC to contact the coordinator for advice on the state of the transaction. Until it gets a Commit or Rollback from the coordinator, it must hold the transaction in the 'Ready to Commit' state, locks and all — even if it is restarted. This could go on indefinitely, of course, so in practice there are 'Presumed Fail' or 'Presumed Succeed' heuristics that can be applied, but it is not something to undertake lightly. If you get into a heuristic operation, then you probably do have an inconsistent set of databases — which is just one reason not to go 'heuristic' in a hurry. Of course, if the Coordinator or the network are out of commission for any extended period of time, you probably have other problems than just database consistency. You can find out a lot from reading Concurrency Control and Recovery in Database Systems by Philip A. Bernstein, Vassos Hadzilacos, Nathan Goodman (available for download). That is tough going, though. You could look in Date (Database Fundamentals, 8th Edn), but it is covered very briefly there, or Recovery Mechanisms in Database Systems by Kumar and Hsu, which has a substantial discussion of 2PC in chapter 13. 

Unfortunately, that looks like you're not allowed to use tab either. (Test: Informix 12.10.FC5 on Mac OS X 10.11.6.) Incidentally, I tried some alternatives: (alert, aka Control-G) and (backspace, aka Control-H) are both accepted, but none of (formfeed, aka Control-L), (vertical tab, aka Control-K), (carriage return, aka Control-M) of (newline, aka Control-J) are allowed. Any other control character from through (octal numbers, all except 9-13 decimal, 011-015 octal) seems to be OK (and NUL or 0 being OK did surprise me!). Do you have any tabs in your main data? If not, you could export with one of the acceptable alternative characters and then map that to tab. If you have tabs, life is harder because you'd need to protect any tabs that are in a data field with a backslash. DB-Access allows without problem and produces an unload file with tab delimiters, so the problem is not in the shell code I'm using. If you're certain you must have tabs, then investigate Art Kagel's which is part of his package from the IIUG Software Repository, which also uses my SQLCMD, available from the same source. Using (or , or various other twists of the command line) produces output in a tab-delimited format. (On its own, SQLCMD does not handle a full export; it will cheerfully unload single tables, though. It does not yet handle NUL as a field separator or line separator — a design decision or artefact that I need to review.) 

If you are looking at alternatives to using Maintenance Plans or are looking for something that is easy to customize, you should really look into the Ola Hallengren maintenance solution. $URL$ 

I need to remove records from this table that are older than 30 days. We only have 2 columns in this table. The first date after 'Printed_%' is what I will be using to determine if the record should be deleted. Notice some of the dates are in MM/DD/YYYY format while some appear in M/D/YYYY format in the string. How can extract the date so I can determine which rows are older than 30 days? 

The only server role it is a member of is PUBLIC. How can I find out what exactly is preventing me from revoking these permissions so I can drop the user? Thanks. 

It turns out this issue was due to a restore of a database from an incorrect media set. Since the databases were not exact copies, the package was performing differently on the second instance. After performing a backup with INIT and then restoring that database to the second instance, the package now performs the same on both instances. 

I know there are still some SQL Server 2000 installs that exist out there. With Microsoft no longer supporting these versions, how can I check to see what vulnerabilities remain unpatched? This website lists some of the vulnerabilities but I am unable to determine which have fixes/patches to address the vulnerabilities. $URL$ 

I am investigating a SSRS 2012 Report which used to return data from an Oracle database. However, recently it stopped returning data. The report will sit there and run forever until something times out. Our report catalog database is also on a separate server which does not show any issues in the logs or while monitoring the performance. I do not see any errors in the Event log, SQL Server Logs, Reporting Services logs or the Oracle database logs. If I strip out the query from the report it returns rows in a few minutes. Is there a method for monitoring what is happening with the communication between the report server and the oracle server? How can I troubleshoot this issue if none of the logs are reporting any problems? Looks like I am now getting Timeout errors in the report logs. 

Contract — holding the single-valued data about a contract, excluding receipts. It might record the latest receipt number for the contract, but that would be an optimization, storing derivable data. Primary Key: Contract Number (aka Lot Number). Contract Items — holding the 1-6 items for the contract. Primary Key: Lot Number, Lot Sequence Number. Lot Number is a Foreign Key reference to Contract. Receipts — holding information about receipts. Primary Key: Receipt Number. Foreign Key: Contract Number reference to Contract again. 

And so on. By default, (you can also use for that, and for ) will batch the loading into sub-transactions of 1024 rows, but you can configure that, of course. 

One is to try downloading the ILS — International Language Supplement. This has many extra locales in it; it might have (but no promises). Another is to try copying an existing locale (maybe or to . You'd probably want to edit the LANGUAGE and TERRITORY lines. However, be aware that the French and German locales are different; it will matter which you choose. Report a problem to IBM Informix Tech Support, requesting the file for . 

This is a mismatch between the list of column names and the list of values in one or the other of the two insert statements. I've tracked that down using careful layout so that I could see that each variable matches each column name. In the first INSERT, you list column in the list of columns but don't pass a value for . In fact, you don't accept a as a parameter, so it is easiest to remove the name. This code 'works' — you'll have to experiment from here: 

My main concern, regardless of the migration mechanism used, would be for the consistency of the migrated data. How are you going to ensure that you don't miss changes while the data is transferred. One of the classic Informix tools could be DB-Export, which (by default) locks the database so it isn't being changed while the export occurs. It gives you the schematic and unloaded (text) data files. Another option would be to make an archive of the existing system and then restore that into a new (temporary) instance, and you could then run your migration against the temporary instance without affecting the working instance. But you'd still have to worry about later changes. If your existing machine is not too woefully under-powered, you should be OK running the export as you suggested, but you still face the issue of ensuring consistency of the migrated data if users are changing the source system while you are migrating. 

ID 2 is currently set to the default but cycles after a max 5 files. This trace isn't the one filling up my hard drive. ID 1 path and trace file are the ones filling up. I've already turned off C2 auditing. What other troubleshooting can I do to see why the audittrace files are even being written to in the first place? EDIT: I've restarted the services. It would seem the correct solution would be to turn off this audit trace by using the sp_trace_setstatus 1,0 but when I run that command I get the error: 

What do I need in order to get around this error and make a successful connection to SSAS? Is there a better/easier way to extract DMV data from SSAS? 

I noticed in the last month one of my SQL Server instances is getting a daily SQL Dump saved off to the Log directory. Unfortunately the SQL Dump is getting large and is consuming the majority of disk space. I don't know exactly where to start investigating why I'm getting SQL Dumps. If I run a DBCC CheckDB against my databases it comes back without any errors. Where do I start investigating why I'm getting SQL Dumps into the log directory? What can cause the SQL Dumps? Will reading the SQL Dump help with my investigation? 

Unfortunately we have some parcel numbers that were converted to scientific notation. This means they are in the wrong format for Parcel Numbers and should be converted back to regular decimal or numeric format. I am encountering difficulty converting just those values that have the scientific notation. The column is of nvarchar(255) data type but these values need to be manipulated back into numeric or decimal data type. 

I'm still fairly new to PowerShell so I'm unsure of all the troubleshooting steps I can take to solve this problem. I would like to use the below command to determine if the replica is primary or not. I believe I have successfully loaded both the provider and smo. Intellisense appears to recognize the command. If I run the following command 

I have tried granting full control to the folder share to myself, the SQL Agent account, and the SQL Services account. Whether I run the package as myself or as a service account I receive the error messages. I'm not seeing any more details in the SQL Server error logs or the Windows Event logs.