Your solution using the native sort on the vector is a good one, and your subsequent relocate-and-sort are relatively fast too. There's no scalability problem here in terms of performance, because they are no worse than the sort, but I can't help but think that there's a better way to do this. Why have the same scalability complexity of the sort, when you can do better....? The ordering/sorting of the data is a bit of a red herring. Rather, it's not a red-herring, it's a minor complication. The sorting is the first part of a two part process, and the problem should be considered as two parts. You should be able to rearrange the even/odd indices of any input vector, whether it's sorted or not. You should be able to relocate the data regardless of the values, simply based on the index. To make this obvious, there should be two functions, a 'prepare' function that sets the vector up in the input order, and then the 'real' function which rearranges the values in the even/odd index order, and the second function should be indifferent to the type of data stored in the vector. So, consider a test function that looks like: 

is a fantastic commandline tool that validates and reformats your XML to be consistent. I recommend it to anyone using XML that has access to Linux 

Note that this runs in 67ms, and has the same latency as the tight spin-lock mechanism. The major difference is in the fact that it wastes no CPU cycles. It's much more efficient. That's the best algorithm. As an aside, I through it would be interesting to try a queue, where one thread feeds Fib numbers in to the queue, and the other threads read it out. It was significantly slower than the alternatives, more complicated, and just generally ugly... here's the code for your reference: 

With the above class, any constructed Response is automatically a fail... only the static instance is a success. Your use code then becomes: 

This block increments both the and the pointers, but it only adds the value to the merged set, which means the equal value at is 'lost'. There are two ways to solve this, but I prefer treating the equals values as if the one is larger than the other.... if you convert the one comparison check to be instead of just , you will successfully merge results.... then you can get rid of the whole last block entirely.... it also means you only need one check: 

Alright, at this point, I can see the algorithm more clearly in the code, time to move on..... Bug Having isolated the code like this, it is apparent that there is a big bug too. If you have a carry coming from the highest bit sum, you ignore the carry... So, for example, if you have the two values and , I would expect the sum , but you will not carry the last bit in to the next value... Performance With the refactored code, it is clear that there are two major performance hits. The first is that the sum is a BigInteger value that gets recreated multiple times each loop (once for each set bit). Each time you call: 

Please explain that to me? ;-) Throw it away! While we are throwing things away, throw out the as well, it's a distraction, and unnecessary. Talking about throwing things out..... did you throw out the method when it should actually be there? One small comment on this code segment: 

Dumping some SEDE experience in as well as a SQL review. SEDE Specific things first Parameters SEDE caches the results of a query if it is run with the current data set (caches are cleared when the data is refreshed). If you run the same query twice, the second time will return the cached data. If the query has not been run, then you need to be logged in to refresh the cache. If the query has been run, then you do not need to be logged in to SEDE to see the data. As a consequence, if you share links, you should pre-populate the cache too. Your query is parametrized, and as a result, you do not have any cached results... BUT.... SEDE parameters are of the form . Use this to your advantage. By supplying a default value your query will likely be 'prepopulated' So, set up your parameters like: 

Note, we use the set-based handling in python. Convert the alphabet to a set, and then get the difference between the password set, and the alphabet. With that, if there are any characters left, then the password is not a match (there are characters in the password that are not in the alphabet). Additionally, I found that your readFile method does not do decent end-of-line handling, so I had to create a file without a line-terminator to make the code work... is this intended? 

Without going in to too much detail, you can easily convert this algorithm to work at the same time as you process the user input.... there is no real reason why you have to first convert all the values to int first, and only then process them.... you can process them as they are entered. EDIT: I realize you may need to be smarter than I have suggested when setting up the variables initially... if the first values in the input are all the same then the algorithm above will assume the sequence is and will produce the wrong result. You need to find out the initial 'direction' of the sequence by looking for the first 'different' value 

Taking this from an algorithmic perspective, rather than a python perspective (I don't know python well enough to write something sensible in it). Your algorithm can be expressed as the logic: 

Your narrative is closer-to-home: "... seems un-necessary unless instead of an Interface it was some Abstract class" The factory is often a combination of static methods, and an interface. Sometimes the interface and the static methods are combined on to a single abstract class, and sometimes they are separate. What you are missing is the static methods for creating the Factory instance. Note: many factory-pattern implementations in Java do not use the word Factory in the name.... So, there are factories that separate the static methods in a different class from the interface, and factories that have the static methods and the interface methods in the same abstract class. Abstract Class way The Abstract class is the most recognizable way of doing this in Java. It is often most easily identified by having static methods like . The Abstract class has abstract methods which are the factory methods, but it also has factory-factory methods for creating the factory!!!! (yes, really). The factory-factory methods are normally implemented as static concrete methods. In your example code, the and parts of the would be merged as: 

Your code is neat, and, within the confines of the "Solution", you have solved things well. The algorithm you use is the right one, it's implemented well, and it's all clear. I like it. There's only one thing that concerns me. The interface of the class: 

Then, the above code changes the value of that variable, runs the expression, and returns the first Element. That last part is double-important. The call is much better than because the does two things: it stops searching when the first instance is found so it is faster; it also does not throw an exception if there is no result (instead it returns null). Other Otherwise, I can't see anything else that's 'off' with the JDOM usage. Using some short-cut methods will help, the evaluateFirst XPath method is important. I like how you have used the live-iterator code for manipulating the document. As an aside, I like using a for-loop with Iterators. Where you have: 

If that function returned a complete stream that represented a single sequence, then, you could simply have the code: 

This question makes assumptions which are not supported by the actual implementations of in Java (or most other languages). is a floating-point number format, which has a number of odd behaviours that simply do not support 'rounding' in a consistently accurate way. Consider the following code: 

you have not commented enough you have commented all the wrong things you have commented too much. your comments are in the wrong format you are missing the formal comments. 

but that would be simpler if you got rid of the variable completely, and have some shorter variable names, and had just: 

Note that you will likely need better error handling on the Scanner. The complexity in here is \$O(n \log n)\$ which is pretty decent. It has little overhead other than the data array. The error-handling for empty inputs, and non-existing results (where there are no unique values...) makes this answer incomplete. 

When you have cascading conditions like you have, it can become 'messy'. At some point the design-pattern 'Chain of responsibility' becomes useful.... Consider an interface: 

Nice question.... but, you're not doing a Radix Sort, but instead you're doing a Counting Sort As it happens, a counting sort is probably the best sort algorithm you could choose for this problem, so there's no problem in the basic code, just the name you have given it. There's a significant optimization you can do though, which will save a bunch of memory.... you don't need the array at all. The "counting" part of your code is great: 

Your friend is right, and there's ways to parameterize the code to make it more useful. Consider three things: 

Here the first A points to B, which points to a different A, which points to C, and so on. You would call your method with the pointer to the first A as the argument . There is no previous .... So your system starts off looking like: 

I was inspired to write a query that produced a graph mapping the perceived quality of your Stack Exchange answers over time.... in other words, "Are your answers getting better, or worse?" Because answer scores are very 'spiky', it seems natural to calculate a sliding average with a configurable window, to show trends. The result I have is: 

You need to be using a transaction for this... if the data end up failing part-way through your procedure you will have corrupt data. you can actually do the whole thing in a single update, with no messing around with temporary ID's, etc. (Assuming auto-commit, then this will not need a transaction) seriously, who had the bright idea of calling the column .... should be shot. 

I have had a long look through your code. I like that you have tried to make a generic, type-safe pool. It is a problem that I have solved a number of times in the past (sometimes well, sometimes not so well), and I like looking at other people's solution to the problem. The basic concept in your code looks like it will work, but it is just "by the skin of your teeth" working. First up, I am going to rattle off a long list of things that concern me, then I am going to suggest a few things that will significantly change the structure of the code, and, perhaps at the end I will put out an alternative solution that will maybe give you some ideas you can (re)use. -> Head-Scratchers 

The logic is the exact same as yours except I have big things I use a part of, whereas you build it up bit by bit. The important part is the Math.abs(...) statements are identical to the previous version.... they are the limit to the values we build. Here's a way to do it: 

The above variables should all be final too. Also, there's an uncomfortable mix of the "old" -based system, and the "new" based one. I recommend that you use , and stick to it. Simplifications This code is.... ugly. 

You know, it's not too bad, but I dislike the magic numbers you have added in place. The mask as is a problem. is not a standard size, so why have you set it as 32 bits? I think you are missing a simple trick here. You are setting the mask high, and decreasing till it's done, when instead, you should start at the low order bits, and increase until there's nothing left to do.... by using a bit-shift (and the mask which is int-size safe. You have forced the values to be unsigned, so you may do it really easily: 

Then, we have the 'worker' thread pool that processes the actual jobs, and a logger thread pool that awaits (and logs) the terminations.... 

You declare convenience variables which really are unnecessary.... You are working with the data 'backwards'.... you build up the byte, then set the value in to the output, instead of just shifting the bits in to the output.