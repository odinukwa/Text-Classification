With a few XML files to read you could have done something like this to address your concerns, where the files are only read at once, but all loaded into memory at the same time: 

But before doing that: Why do you need to convert the list items to data.frames, then bind? Could you instead rewrite so that it returns a data.frame? And better, could take a vector of cutoffs instead of a single value and return a data.frame with rows? 

First, let's download some data similar to yours (I assume). This csv available online has almost 7,000 airports: 

Have a look at the function. To use the jargon, your data is in "long" format and you want to turn it to a "wide" format. Before using , you will need to add a column of 1, 2, 1, 2, etc. so it can be used as the "time" column. You can do that on the fly using the function. In all: 

where is a super fast (internal C-compiled) function. Question 2 Is the argument handling OK? I wanted users of the function to be able supply either ppm or mz_tol, but not both. Am I using missing() correctly? There are two schools for this kind of situation: 

I'll give it a shot, as I read through from the top. I'll skip the comments but keep them, this is an excellent habit. You are doing well identifying your globals and leaving them at the top like you did: 

Now about performance, since you mentioned it. Know that and are vectorized functions so unless you are handling many millions of rows or doing some high frequency trading, you should be fine :-) Minor speed improvements might be made by replacing the with in-place replacements (), I let you decide if this is more readable: 

Note how I created the and function so as to not clobber the code with complex and repetitive function calls. Another advantage of this approach is that it is very simple to maintain. See how easy it would be to add more metrics to your summary, versus what it would take with your approach. To create the final data.frame with summary metrics for all people, you can do: 

Note that in R, matrices are stored using "Column Major", i.e. column by column. So it would be more natural to pick that the second row/col in corresponds to the item at row 2 and col 1 in . You chose the opposite (row 1 col 2) which forced me to start my code with . If you want to pick the more natural approach as I suggest, just replace that first line with . 

However, as pointed, an exhaustive search will not work well for large input vectors. A much faster approach is indeed to use dynamic programming. Here is a tentative implementation: 

Now that you have your weights, computing the weighted averages for all main stations and all days is done in one simple matrix multiplication: 

The use of in a loop is a common mistake. You'll probably agree that, by design, the code in the loop will be executed . Well, that's not exactly always the case. In particular, when is empty: . You would want the loop to be executed i.e. zero times. However, in this unfortunate case, would evaluate to i.e. . Instead of zero iteration, you'll have two and likely cause an error. Instead of , you should use or . Both and will do the right thing when their input is empty or zero respectively. The use of to dynamically create objects is, excuse my word, an abomination. I'll try to show you a couple reasons why. Via your loop, you have managed to create four objects: , , , which you later use in your code: 

to pre-allocate a vector of integers. Integers use less memory; you will also save time avoiding unnecessary conversions from integer to character. Second, is for regular expression matching. When you do , you are checking if contains an which is not the same as asking if is exactly . In your case, you want exact equality so having used in would have been more appropriate. Even better, there is the function. It is vectorized so you can avoid the loop and just do: 

the use of rather than looping over an unused argument the use of 's and arguments rather than the trick you used making an optional argument 

Without changing the interface too much, your code could use the following changes. Note that I am fixing three bugs regarding corner cases: 

Some explanation: After we have found the list of unique genes across all pathways in the first argument (, , , ), we turn both arguments into a matrix where if the pathway contains the gene , or 0 otherwise. For , this matrix is : 

Here are a few pointers. I should first say that I am more familiar with R; I know next to nothing about Fortran but I could read your code and guess about a few things that will likely improve your code: both in simplicity and speed. 1) Why the need for two inputs and ? You know that in the end you will have a total of simulations: could there just be a single input that will be split evenly among your ? This should get you rid of the loop inside so it could only call once. 2) You should make your slave () as simple as possible. IMO, it should not know about things like or if you just tell it how many simulations it needs to do. Let R do the math upstream and pass it down to the slave. I don't know much about random generators but maybe the same can apply with the random seeds: if you could let R compute a seed for each slave and pass it down as an (optional) argument to the slave, that would be best. (However, if knowing the and is crucial for seed selection and can only happen on the Fortran side, then disregard my comment...) 3) This one I feel is important: do not compute averages too early. They are costly and can make you lose precision. This line in your code () is particularly problematic: you are doing so many unnecessary multiplications and divisions... Instead, you should just be counting the number of darts, i.e. incrementing a counter. Your slave should just be returning an integer. Let R add all these integers together and do a single division by at the end. To summarize 1, 2, and 3, it would be great (if possible) if you could just tell your slave: here is your seed number ; now throw darts and tell me how many ended up in the circle. 4) Now looking at your R code. Yes, the use of in your code is not very elegant. That's because you are trying to use which may not be the best option from the package. Instead, or are better suited for functional programming. Your code could look like this, I let you figure out the rest: 

This way, there is no way you or your end-user can mess up with the inputs. I hope you find this useful and it encourages you to write better code. 

Using your 2D example, doing is the obvious solution, both elegant and fast. So your way of generalizing the use of via to handle any number of dimensions is what I would consider the optimal approach. The rewrite below won't make the code faster but maybe a little more simple and robust. The main improvement is the computation of the using rather than a loop. And I added a number of checks to verify all the assumptions you are making regarding your inputs. 

There are a few cons with writing code that uses at each step. You probably know that these functions are disguised loops so it is as-if you where running at each line of your code. This will likely be: 

So it will be up to you to decide based on your requirements. Note: I have added to all your functions in case, in the future, your functions allow differing arguments. As you mentioned, your functions currently all only require and so you can get rid of everywhere if you wish. 

However, this will not work in your more general case where there may be more than 2 duplicated households: 

One improvement is you can use the vectorized function rather than . This way, you can precompute all hexadecimal pairs and feed them directly into and which are also vectorized. This removes the need for (a disguised and slowish loop). You could also use as a shortcut for . has been around for what seems like a couple years. If you are concerned about compatibility with older versions of R, then yes, it is safer to stick with . I could be wrong but I see no reason not to output a vector of integers instead of numerics. That integers use less memory and are not subject to floating point errors are two strong reasons to prefer them over numerics. It is also a good idea to add input checks to test your assumptions. Here it seems that the input must be a character vector of length 1. This comment is more subjective. You have crammed a lot of operations into a single statement. I can count 8 functions including the anonymous one you created. That really makes your code hard to understand. In all, I would have written the function like this: 

is a data.frame (i.e. a list), so is also a data.frame (a sub-list). When you then do , the operator has to convert your one-column data.frame into a matrix before it can compare it to , which is very expensive. This is where the item at the top of your profile comes from. Instead, you meant to do: 

Not to discourage you from using recursion, I think there is a much simple approach to your problem. If you build two vectors of ids and parent ids: 

This will not be faster (which would require you move away from ) but could give you ideas about writing better/cleaner code. The code first: 

Question 1 How can I get rid of the for loop? It seems like a smart way of using apply or a similar function would obviate this loop. Use : 

First step is to compute the distances between the main stations and the local stations. I use the because it is fast (compiled in Fortran), at least a lot faster than the loop inside . 

How is that different from version 1? Here we are careful to read the file and process it line-by-line instead of reading the whole file in memory. Also, when processing each line, we are careful not to generate the vector in memory and pre-compute the output for all the values. Instead, we are counting from 1 to and processing each value one at a time. Because version 2 uses a loop in place of the vectorization happening in version 1, it will be slower. But it will use a lot less memory, especially if the file contains a large number of rows or large values for , both things could make version 1 fail. I hope this helps. Let me know if you have questions. 

Here is how you can completely vectorize your code, making use of matrix functions such as , , and . Without loops, your code will be more concise and faster to execute. The construction of was indeed a problem. Incrementally growing an object like you did is very memory intensive: each time you add a row, a new object is built from scratch. On the other hand, your comment that I've read that making a matrix of the correct size and filling it with NA only to fill in its values later is very memory-intensive is not accurate. Here the object is created once and filled in-place by the loops. To summarize: growing an object iteratively is the worst. Initializing an object to its final size and filling it in place via for loops is preferable. Using a vectorized function to create the object in one shot is the best. Hope it helps! 

Now that's a start... If you try with a large prime, e.g. , it will take a very long time to converge towards though. So you will have to get more creative to make it converge faster. At least, you should be fixed about why your original code was so slow. 

Thanks for providing the link, it helped a lot in understanding what you were after. I will provide two versions for you to consider. The first one is algorithmically similar to yours, except written a little more in the "R style". The second one will make a more efficient use of memory since that seems to be important too. I will also assume that the input file in is like the one in the link, i.e. contains lines like the two below: 

If it were not for these solutions, there are a few things that could be improved in your code. First, you could have used directly instead of the variable you created. Second, the last two lines of your code could have been merged into one: . Also, if you look at the doc for , you could have saved yourself some typing by doing 

You will notice another improvement: everywhere I am referring to columns using their name, for example, instead of their index like . It makes the code more readable and easier to maintain (Imagine what would happen if suddenly a column was inserted at the beginning of : you would have to modify all your indices...) 

It returns a vector containing for each distinct value of . In the event that the data has no value for a given index, you could overwrite the output-ed with a so as to not affect the upcoming roll sums: 

It's recommended to use spaces to make your code easier on the eyes. Spaces also avoid ambiguous situations for people who are not experts in R's syntax rules; for example, when someone sees , is it assigning to , or is it asking if is less than ? Maybe another way to convince you is to make you notice that R's compiled code does contain spaces (run for example); it shows that R's authors agreed that code readability was more important than compactness. Now about the choice of arguments. Why not use the same argument names (and order) as since it is the main function being called here? So I'd recommend . Or maybe if it really helps knowing these are prices. 

You can improve your code by using vectorization to speed up the computation of Euclidean distances in the inner loop. The code would be: 

Next, we map each value of to the "group number" it belongs to (here, belong to group #1 then belong to group #2): 

Next, think of the assumptions your code is making: must be a square matrix with each row being an increasing vector of positive values ending with . must be an integer vector of length . All of these assumptions can be checked at the top of the function's body; I am only implementing a few of them here: 

You can indeed use vectorization. Create two vectors of indices (or booleans like I did) to identify the rows of the that need to be updated. To find the corresponding row from the , you can use the function like I did. 

Edit: And to handle a vector of as input, make these slight changes. It will return a list of matrices. 

so we will be calling . All that is left is to write : a vectorized function that will take as inputs two vectors of airport names and return their distances. We could first put the important data in a matrix with airport names as row names for easy access: