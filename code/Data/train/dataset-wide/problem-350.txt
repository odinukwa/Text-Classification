Oh boy, was Al Gore wrong. In December 2016, Winter Came. At first, it was called the Snowpocalypse and other cutesy names. The TV presenters in the Northern Hemisphere soon stopped laughing however. Snow kept on falling, and it never melted. More and more. And more. And more. Scientists now reckon we are abruptly, in the span on a single winter, entering a new Ice Age. Mind you, the full glaciation onset may take a few years, it's not like kilometer tall glaciers can appear overnight. They think it will end up with a similar ice extent as the last maximum, shown below: 

Step 1: Use an exaggerated Hajnal line The idea is that your country would have women marrying late. Late marriage means that both partners go in with a relatively large resource endowment, and then distribute it across relatively few children. Having relatively few children would prevent a Malthusian catastrophe, where the popluation expands into a pauperized class living at the limits of what can be supported by the land and then falls due to war or disease. Step 2: Good property rights Have a early and wide-sweeping Magna Carta or an Icelandic-style Althing, which is to say political representation of all property holders. Bonus points if you include women, either as widows or as pre-marriage freeholders. Having a strong political voice by the plucky freeholders will serve to slow or even reverse the encroachment by the richer landholders against the commons or individual farms. Step 3: Early life insurance Widows and orphans rely on a social safety net based on insurance payments. This prevents people from slipping into poverty due to the unavoidable medical disasters of a pre-antibiotic world. There is literally nothing about this that could not have been done as far back as Sumeria, it's just that nobody thought about it before the 1700s in Europe. 

Partial dreamstate induced by carefully targeted magnetic fields. In humans whose brain is still insde their skull this is known as transcranial magnetic stimulation, and it can do fun things like induce out-of-body experiences or a sense of presence, or for that matter, decrease the activity levels of the critical parts of the brain (the stuff that allows you to sometimes realize you're dreaming when a particularly egregious break of logic happens in a dream). 

They were quite cunningly hidden, but I finally discovered the hidden Illuminati ploy to meet at the regular European Tax and Regulatory Compliance Group for the Cucumber Growers Association meetings, held once a month in a regular hotel in various small post-industrial towns in Western Europe. They will use code words like for world domination, for bribes and blackmail, and for massive terror events being planned. 

Depends on how greedy he is about it Nobody cares if some dude makes \$10k in a day trade, especially if each \$10k gain is spread over a few dozen accounts with a half dozen banks, perhaps even under different aliases. But when Joe makes a billion dollars by shorting BP on the day before a terror attack takes out their refinery in Nigeria, people tend to notice. You did not make it clear if getting shot ends the repeating cycle (I'll assume not), so perhaps this is a recoverable mistake, but if he ends up in Guantanamo on the non-repeating day, that would make for a very, very long sentence. 

The answer depends almost wholly on the rate of intelligence improvement of AIs. Why Artificial General Intelligence will be sought The reason is that the world is a complex place, and dumb machines do not do well in it. This is especially true of environments that contain intelligent strategic actors (humans and other smart machines) that can run future simulations to optimize their actions. In dealing with complex problems in changing environments and difficult multi-agent situations, economic, tactical and strategic advantage will lie with the organizations deploying more and more intelligence in their machine operations. They will be more efficient and profitable, making it an economic imperative to seek further improvement, unless legally prohibited from doing so by strictly enforced legislation. As an aside, I will note that there is no escape from this dilemma between competing sovereign states in a non-hegemonic situation. Context Imagine starting with a machine that has 1% of human intelligent work capabilities. That is still way above our current AI capabilities, in most ways one defines human intelligent work capabilities. Machines are already able to multiply, for instance, a gazillion times faster, but have a harder time telling lightly colored trucks from the sky background, for instance, something we generally do effortlessly when sober, and a myriad other things. So the term of art here is Artificial General Intelligence, an artificial mind capable of reacting in an optimized way in a broad range of environments and novel situations, up to and above the level humans are able to do the same. Scenario 1: Each incremental gain is harder than the next. It takes one billion dollars to get machines from 1% to 2%, two billion for 2% to 3%, four billion from 3% to 4%, etc. It soon becomes prohibitively expensive to make further gains. Your machine robots might end up with the intelligence level of an ape, or a dog, or maybe a human 2-year old. Useful for many purposes, but not a threat to our labor force. Scenario 2: Each incremental gain requires more effort, but effort scales polynomially rather than exponentially up to 100%. Gains past human level are impossible or very very hard. In this scenario, human level AI take over most jobs, and only a few human creative geniuses remain competitive. Huge drive towards human genetic enhancement. Scenario 3: AGI scales up nicely up to and beyond human level, but progress is slow (measured in decades). Human politicians and human institutions can react meaningfully, either by implementing a guaranteed minimum wage, banning further research, or some other adaptive response. Human unemployment 100%, which could be dystopian or utopian depending on resource sharing agreements reached with the AGI workforce. Scenario 4: AGI goes foom. "Foom" as in a rocket going foom as it ascends into the sky. AGI goes from dog-level intelligence to strong-super-human levels like a Japanese bullet train past a granny in a kimono with a walking stick. In this case, humanity loses all semblance of control, and its fate is solely decided by the seed goal-set of the "fooming" AGI. Let's hope the initial goal-set makes it benevolent (but what are the odds that idiot monkeys like ourselves will successfully bind the morality of an ascending god). 

In the vision of its creators, the Dr. Watson AI would gather multiple live feeds from its insurance buyers, overcoming privacy concerns through friendly advice () and ridiculously low insurance rates. Watson would keep an eye on your vitals and call 911 if needed. Watson would also keep track of your bone microfractures and predict when you'll need a rest from running, or keep tentative doctor's appointments automatically booked if you insist on doing something against its advice (and it can't compel you to do otherwise by shutting off your alarm, putting on a great show on TV, or something like that). Same for artery buildup and other preventable medical conditions. Watson has 3 primary incentives, with these 2 initial ones: 

Tunnels. Tunnels under tunnels, under tunnels, under tunnels. You can never have enough tunnels. And they're so handy. You can keep your water, gas masks, food, ammunition, anti-tank weapons, missiles, sleeping quarters, dig out behind enemy lines and attack them from the rear. Tunnels are great! Tunnels are awesome. Tunnels can have heavy doors to limit blast damage. Tunnels can be built in networks, so you can work around damaged sections while they're being fixed. Lusom has been one of the world's busiest reinforced concrete consumers in the world in the past few years (and we take construction quality seriously enough to execute contractors who skimp on the irons). Moreover, our long-tunnels are extending many kilometers outside the city to disguised single-use exits, so we can effectively bring supplies in or launch attacks out of nowhere at enemy concentrations from behind their lines. Mortars, and, uh, man-guided bombs will be launched at the enemy when they least expect. Cleared neighborhoods will suddenly have enemy fighters again. Victims. There is a tunnel entrance/exit under every hospital, creche, school and kindergarten. They're covered in teddy-bears, dolls and there are at least 3 hello kitty-tshirt-bearing young girls standing by every entrance. We have emergency generators everywhere, gas masks for the fighters, camera-enabled cell phones for everyone to record the tragic and needless deaths of civilian women and children (all strategically placed around military objectives) and we have built dedicated underground fiber-optic links to make it past any jamming. Every enemy strike will feature widows, orphans, lost kittens, the works. This will get blasted onto the enemy's TV screens 24/7 by the opposition channels. Snipers. We have 50,000 trained snipers and high-quality gear (stolen from our enemies, ironically). The poor high-tech fools don't stand a chance. 

And yes, I know the AIs and Uploads will probably take over, and that most intelligence in the universe in the future will likely be of the computronium rather then squishy fleshy brains variety, which would result in totally different mass requirements, I've read Age of Em too -- if it makes you happier, assume this is a pet-project of some trivial nostalgic fraction of the Uberminds. Let's just focus on the question at hand for now.