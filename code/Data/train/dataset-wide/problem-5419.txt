I believe that none of the answers understand Kant or Idealism in general. Please understand: Kant is NOT trying to disprove objective reality. A naive approach to idealism is to think that, and then to conclude that it tries to disprove all our dear science. For example when you say: 

So, look at your keyboard again. No, there’s no keyboard there. You are “looking” at a representation inside your head, like in a flat screen, where you only see the results of the analysis made by your mind. Please note that the question is not whether the keyboard exists or not, but what are you expecting as a keyboard outside your mind? 

First detach yourself emotionally from all your research and understanding, then see that Kant can not possible be trying to disprove that, because that assumes that Kant has a concept of "real existence". Kant is not assuming a well defined concept of objective reality, you are. If then you reply: " but his reasoning is not valid vs the reality of Science", then you still do not understand. Do not try to understand idealism / kant by comparing it to your realism. Open your mind: Start with OUT the concept of objective reality. I will make a futile experiment to try to explain what PLATO, DESCARTES or KANT said: Lets start with your concept of reality as it pertains to that keyboard under your hands. The problem you need to recognize is not in the keyboard, but in what you used to know it is there. Note that the keyboard didn’t pop in your mind as soon as it was built. It appeared in your mind after you saw it right ? a) THINGS are IDEAS The first problem with all these was noted by PLATO. He realized that things do not pop in our minds by themselves, they appear after a collection of perceptions: Rectangularness, number of keys, color, angles of the sides…. He called these: “IDEAS”. You agree that you cannot describe your keyboard with out using ideas right? b) IDEAS do not exist in the "real world" The problem with such “IDEAS” is that they don't exist. There aren't any perfect squares, circles, straight lines, or points in space in the experienced world. What do you mean with a points in empty space in the first place? What is a line between to points in space? A single point moving in space ?? See that those are not "real" things by themselves. c) IDEAS do not make things REAL For one thing, none of these “IDEAS” belong specifically to your keyboard, they are general. These “IDEAS” have no connection with the keyboard. You can think about the keyboard whether the keyboard still exists or not. IDEAS have nothing to do with it. Also they apply to other keyboards. I bet if I replace it behind your back with the same model, you will not notice that your "real" keyboard is not there. So if you use IDEAS to define your KEYBOARD, and IDEAS are not real, how come you say the KEYBOARD is real ?? d) IDEAS do not come from REALITY You will say: IDEAS are learned from reality. Thats why I use them to define reality and Einstein and Euclid had discovered the right ones. All observations attest to their veracity and if the are wrong, only Science can correct them. ... so if you think that keep reading... The problem with that is that it doesn’t take much to notice that, the result of 1 + 1 = 2 is not learned. The concept of parallel lines was not "discovered" by Euclid. These all started 2000 years ago precisely when Socrates noticed that even an illiterate understands that parallel lines do not cross at infinite. It’s obvious you will say. Well, again, perfect parallel lines do not exist. Where’s the obvious in that? No one has gone to infinity and verified that parallel lines do not cross. So, why do we see that they don’t so clearly? Why do illiterate people can understand that ? If geometry invented that it should be able to change it, but it can’t. We can’t just come and say: From today on, parallel lines cross at 100 meters, deal with that. No matter how many Euclidean geometries you find, or how many times the postulate is discredited. f) IDEAS make your mind So, the real problem is: Where did squareness, the number 3, parallel lines, and all those things came from, if they don’t exist in nature, they don’t belong to objects, and, at least some, we didn’t learn from experience or science? Kant is just saying that, as unbelievable as it might sound, our mind has these things "a priori" to be able to think. Those are like the alphabet, but not the story. At first glance it sounds ridiculous, but, at varying degrees, it’s undeniable: We could not have deduced many of these “IDEAS” from nature, simply because they are required to define nature in the first place. g) THE UNSOLVABLE? PROBLEM So here lies the problem: If your reason uses all these hard-coded ideas to present you the real world, we need to see the real world with no reason, to get the "real" thing. Now you see the problem? Now tell me again that : 

Logic, mathematics, science, musicology, and most systems of government and commerce are all examples of attempts to create rigor and consistency in our thinking to address the flaws of our built-in logic inherited from our mammalian ancestors. We are born using a form of Bayesian logic or abduction described in the Theory of Sufficient Reasoning. Immortalized in "Occum's Razor" we gravitate to the simplest explanation, drawn from no more than our personal history of experiences. We judge our experiences and form a collection beliefs in a world view that acts like a filter or paradigm through which we judge future events. Each belief carries with it a credence value or disposition regarding how strongly the belief is held. When an event is witnessed displaying evidence in favor of or against the belief, the rational person will then adjust the credences affected accordingly based on their judgement as conditioned by the prior credence values. $URL$ The strength of abductive logic is that we can make quick decisions without perfect or complete knowledge of the facts, a very valuable tool for survival. This survival skill, however, comes with obvious flaws. Quick decisions without sufficient data results in tragic errors. Also, chronic, traumatic or systematic conditioning can set credences so high that one may not be able to recognize new evidence let alone judge it. Lastly, a credence change cannot be made without maintaining consistency in one's world view. If changing one credence causes unacceptable changes in other, the original belief change may be set aside, thereby weakening the authenticity of one's world view. So, the logic systems found in scientific, mathematical, and philosophical systems do impose rules of engagement to ensure integrity and reliability and to avoid or mitigate the flaws in abduction. Ironically, when scientific or mathematical discoveries are offered, abduction takes full charge in judging its acceptability. Resistance to change that threatens the system underpinning will be vociferous, even though the logic and evidence are compelling. Logic systems are like scientific theories. If they consistently provide the right answers in their assigned domains, we accept and use them. But, what happens when a contradiction appears? Your final concern, whether our choice of logic affects our math and other pursuits is a resounding affirmative. Aristotle's logic based on the premise that a statement must be either true or false created the logical foundation for the industrial revolution and remain embedded in every institution even though it is patently and inhumanly wrong. (Any Charles Dickens novel) Ultimately, you may master these systems and still have doubt about their credibility because your world view objects regardless of the evidence. On the other hand, you may find, as you learn more, that your inherit logic system can serve you well with help from other logical points of view. I suggest that you suspend judgement for a while, and allow your natural curiosity to seek out the answers to your concerns with knowledge. 

Of course and above are , and above is a.k.a. . So it can be done. Although maybe the answer you were looking for is: only if you add in some mathematical axioms as well, as @Mauro's comment above also says. 

It seems to me that the simplest refutation goes like this: There exists at least one moral-centered religious-text religion in the world that asserts the morality of killing non-believers of that religion, including theists of other religions. You can't simply declare the entire religion immoral, as they do believe in God themselves, and are thus theists and not atheists. Therefore the problem of morality vs. immorality, and the problem of relative morality, are not problems of theism vs. atheism. Because differing moral-centered religious-text-based religions themselves have contradictory absolute moralities. 

I would say that "claiming misrepresentation" is a valid "rhetorical device" if supported (i.e. by pointing out where the opposite party has paraphrased wrongly (or outright falsely quoted)). The problem lies in "but Alice offers no additional clarification", which puts your hypothetical in the realm of "stonewalling" I think: $URL$ 

I would say you very probably have direct experience of a non-reductionist supervenience, unless you do actually perceive your own self as "nothing more than" the collection of cells, chemicals, electrical signals, etc. of which you consist. "Living being" supervenes non-reductively on those other collections. It seems to me in general that non-reductive supervenience just means that there are really two different sets of phenomena (being, collection of cells) that operate "in parallel" with each other, rather than one being a mere "illusory" phenomenal result of the actions of the other, only. 

The difference is that children at Halloween and in school plays can also get dogginess, and that simply "being brown" brings along no additional information. The whole nature of "natural kinds" is that 1) they cannot be obtained artificially and 2) they bring in a whole family of related traits also. 

The word "faith" is simply too loaded a term to use in any forum where the objective is open dialog because the term is identified more commonly by its misuse in a religious context as a term related to obedience to dogma. Nevertheless, your question's meaning is clear and the answer is fundamental to the use of rigorous systems of logic. A far better term intended for this topic is "credence". The fundamental decision making model in the animal brain is Bayesian logic. That is, we learn from our experiences our personal truth on a matter. We each have a world view that is a collection of beliefs about things called credences that can be expressed as probability beforehand that I will accept as true the next thing I see. The more consistent our experiences regarding a matter, the strong our belief in that truth becomes. One example of a new truth is seldom enough to change our minds; but, it should increase my credence on the matter, thus making it more likely I will accept it next time. This system of reasoning is called abduction, as opposed to induction or deduction. Now, man has known for a long time that abduction is fraught with pitfalls because of its very subjective and localized nature. So, early, most notably Aristotle and his contemporaries in the west, tried to develop "objective" systems of logic; in all cases, certain assumptions were necessary to proceed. Aristotle assumed that any logical and meaningful statement must either be true or false. Plane geometry assumes a well defines domain of an infinitely flat surface. Newton Physics assumes that time is a constant and proceeds forward in the same manner everywhere. Einstein assumed that light speed is constant in any frame of reference in order to derive Special Relatively. So, axioms play an important role in even the most rigorous investigation based on inductive and deductive reasoning, and setting these axioms uses abduction. It is a general rule of thumb for most investigative diciplines that we not debate the answer before first debating the assumptions. Therefore, yes, you are correct that any "proof" or conclusion is tied to the assumption used in the derivation. Therefore, the assumptions are the first place we look for a system's boundaries or domain of applicability. It is not, however, necessary for one to "believe" an assumption or axiom in order to play the game of "what if?". In fact, it is often the case that starting from an assumption is contrary to common belief results in a paradigm shift in man's understanding of nature and reality. 

You seem to be describing, possibly, simple emergence or emergentism? Your "meta property" is just an emergent property, from what you call "artifacts". The key characteristic seems to be just what you describe: once the phenomenon has emerged, it cannot be reduced back to what it came from. It "has a life of its own" now. $URL$ $URL$ 

You seem to have discovered the "regress argument". Here is a good explication of the argument and some answers to it: $URL$ Your professor was too dismissive of your concerns; this is not just wordplay, it is a known philosophical paradox. ETA: You may want to see also Lewis Carroll's more entertaining version of the argument: $URL$ 

After reading the section from which those quotes come (thanks @CooLeeo for the link in your answer!), I think I have a better idea of what Heidegger means. First, the "casting-toward of being" means something like "just existing without thinking". I am reminded of the humorous poster of an ape or orangutan with the caption "Sometimes I sits and thinks. And sometimes I just sits." The key to the "casting-away of being" is Heidegger's opening sentences of the section about how as soon as you start thinking or talking about what "being is", you are necessarily "casting away" (separating yourself) from being itself. I.e. you're no longer "just sitting" without thinking. As to both "being ... essential", the context suggests that by "essential" Heidegger merely means "part of the essence of our (human) universe", not "required" or "necessary" as the term means in English. (I suspect a translation issue.) Or in other words, "that's just the way it is". Likewise, by the second rhetorical question, Heidegger seems to just be tacking on the additional "why worry about it?", or even "regular people aren't distressed by the situation, why should philosophers be?", or "this is our (humans') natural state, so deal" :-).