Consider the random variable $S=(s_0, \dots ,s_{N-1})$, a sequence of signs uniformly distributed on the hypercube $\{-1,1\}^N$. With the Fourier transform we can define $N$ random walk variables $$ \hat{s}_q=\frac{1}{\sqrt{N}}\sum_{k=0}^{N-1} \zeta^{q k} s_k, \qquad q=0, \ldots, N-1, $$ where $\zeta=e^{2\pi i/N}$ and to keep things simple we take $N$ to be prime. As we take $N\to\infty$ all of these have normal distributions: $\hat{s}_0$ on the real line and the others in the complex plane. I would like to be able to claim that these random variables become independent as $N\to\infty$ in a certain qualified sense. First, since $\hat{s}_q$ and $\hat{s}_{-q}$ are complex conjugates we only consider $q\in\{1,\ldots,(N-1)/2\}$. Second, I am only interested in "fixed-information" counterparts of these. We define these random variables as $f(\hat{s}_q)$, where $f$ maps the complex plane to a finite set. For example (in fact the case that generated this question), $f$ might be take the magnitude of the complex number and round it to 7 significant digits, or to $\infty$ if the magnitude exceeds a certain bound (in order to keep the cardinality of the range of $f$ fixed as $N\to\infty$). Is it true, say for particular kinds of fixed-information maps, that $f(\hat{s}_q)$ and $f(\hat{s}_{q'})$, $q\ne q'$, are independent as $N\to\infty$? 

Of course a highly non-convex polygon may have equidissections none of which are star-like, and it is easy to see that this might be the case also for convex polygons: Take a regular hexagon of unit area and label the vertices A, B, C, D, E, F. If we replace the vertex at A by a vertex at a point A' on the line through A parallel to the line BF, then the new hexagon still admits an equidissection into six pieces by cutting along the triangle BFD (and dividing the middle piece into three). But there are only countably many choices of A' for which there is some point P such that the six triangles with vertices in P and two adjacent vertices of the hexagon all have rational area. So perhaps the answer to my question is the obvious "No, why should it?", and the reason I haven't found a counterexample is just that dissections into a small number of pieces tend to be star-like. There is a short comment on the second page of this article that shows that the spectrum of a trapezoid is closed under addition, but I don't see how that would generalize. 

I can't say I share Littlewood's sense of humor, but here is a formula that made me grin the first time I saw it ($A$ and $B$ are non-commuting square matrices): \begin{equation}\frac{d}{dt}e^{A+B t}=\int_0^1 e^{s(A+B t)}\ B\ e^{(1-s)(A+B t)} \ ds. \end{equation} 

A somewhat lengthy calculation, involving integrals, reveals that the probability an $n\times n$ Hermitian matrix, drawn from the Gaussian unitary ensemble, is positive definite, decays as $\left(\sqrt{3}\right)^{-n^2}$ for large $n$. I can’t say what decay constant I had expected, given the context, but it certainly wasn’t $\sqrt{3}$ ! Is there a deeper or more direct explanation for the appearance of this number? 

The quotient can get as close as we please to $\sqrt{n}$. Start by putting a red and a blue point distance $\sqrt{n}$ apart (let me use colors instead of "point in $X$"). Then put $n-1$ pairs of coinciding points (or extremely close if you don't want them to coincide), one red and one blue, as "stepping stones" between them, a unit distance apart, but along a large circular path. With true distances, a pair of coinciding points of opposite color should always be matched to each other, so $c_1(M_1)=\sqrt{n}$. But with squared distances, the cost of that matching is $n$, so it will be just as good to use the stepping stones and pay for $n$ edges of cost 1 (and strictly better with a slight perturbation of the points). Provided the stepping stones are arranged so that under squared distances no shortcut will pay, we get $c_1(M_2) = n$. Clearly $\sqrt{n}$ is the best we can do. If we take the distance $c_1(M_2)$ and chop it into $n$ pieces, then the sum of the squares of the pieces is minimized when they are equal, therefore $$\frac{c_1(M_2)^2}n\leq c_2(M_2) \leq c_2(M_1)\leq c_1(M_1)^2.$$ 

The central limit property of $h$ follows from the main result of: David Freedman and David Lane, "The Empirical Distribution of Fourier Coefficients", Ann. Statist. Volume 8, Number 6 (1980), 1244-1251. They show that all the Fourier coefficients (not trivially related as complex conjugates) are asymptotically independent. 

With help, offline, from P. Diaconis: I believe my "fixed information" map is really just a license to take the limit $N\to \infty$ before asking if the random variables are independent. Now, if I exercise this license, I notice that $\hat{s}_q$ and $\hat{s}_{q'}$ have a bivariate normal distribution (in the limit), and when I work out the covariance matrix, which I can do for finite $N$, I see that indeed the two variables are independent for $q\ne q'$ (taking the $N\to \infty$ limit of the covariance matrix). 

If I haven't missed something, this is the "ordinary" two-person zero-sum game, which is a linear programming problem, and solvable in polynomial time. Game theory is full of slight variations, and you might have read about one of those being NP-hard (for instance, there is a paper by Fortnow and Impagliazzo, $URL$ ) An excellent and concrete description of an algorithm for solving this sort of game is given in Section II 4 of Thomas S. Ferguson's electronic text on "Game Theory", $URL$ I don't know about the worst case complexity of that particular algorithm, but it probably works fine unless you cook up specifically hard games. And in the intermediate stages, the (sub-optimal) strategies of each player will give bounds on V(P) that successively improve. 

I'm interested in a family of properties of connected simple graphs that comes up in percolation theory. Let $G$ be a simple connected graph. Now consider the set of subgraphs of $G$ that I will call "cores". A core $C$ of $G$ is a connected subgraph of $G$ with the property that upon "removing" $C$ from $G$ the resulting graph has no edges. I define "removing" as deleting from $G$ all vertices and edges in $C$. Note that a core is not the same as the induced subgraph of a connected dominating set (which makes reference only to the vertices of $C$ and not its edges). For example, the triangle graph has 1 core which is the triangle graph itself, 3 cores that are chains of 3 vertices, and 3 cores that are chains of 2 vertices. The properties are defined by sums over all the cores: $f_k(G)=(-1)^{v(G)+1}\sum_{\mathrm{cores}\, C\in G} v(C)^k (-1)^{e(C)}$. Here $v(C)$ and $e(C)$ are respectively the number of vertices and edges in $C$, and $k$ is a non-negative integer. I've proved that $f_1(G)=0$ for every connected $G$ except for the 1-vertex graph, for which $f_1=1$. I therefore do not need a name for property $f_1$. What about $f_2$? Here are some special cases. When $G$ is a tree with $n>1$ vertices, then $f_2(G)=0$ unless it is a path; for that case $f_2(G)=2$. Now consider cycles of length $n$. For these the $f_2$ values are $n(n-1)$ . For the complete graphs $f_2(K_n)=n!$ . Perhaps these special cases will help someone make the connection with a known property. Addendum: I welcome suggestions for a better term for what I've called a graph "core". Here is a rewording of the definition, in case there is still confusion. A core $C$ of a connected graph $G$ is a subgraph of $G$ induced by a subset of the edges of $G$ and which has the following two properties: (1) $C$ is connected, and (2) every edge of $G$ is incident on a vertex of $C$. It's not obvious from the definition of $f_k(G)$ that these integers are always nonnegative, but I believe this is true for all positive $k$. Is $f_k(G)$ counting something in $G$? If so, then the definition in terms of cores (and the naming problem) can be avoided. 

Suppose we are given a sequence $a_1,\dots, a_n$ (input to a partition problem). It seems that this can be encoded as a cycle problem in $\mathbb{Z}^3$ by finding two large numbers $M$ and $N$ and taking the sequence to be $$a_1, M, N, a_2, M, N, \dots, a_n, (n-1)M, (n-1)N.$$ The numbers $M$ and $N$ should be chosen so that the two last terms cannot be canceled in any other way than the obvious one. Then by the orthogonality rule, the only remaining possibility is to let the terms $a_1,\dots,a_n$ go in the third direction, and we are back to the partition problem. This ought to work also for $d\geq 4$, although admittedly some details remain to be filled in. 

Consider the random variable $S=(s_0, \dots ,s_{N-1})$, a sequence of signs uniformly distributed on the hypercube $\{-1,1\}^N$. We are interested in $N$ large and prime. The Fourier transform $\hat{S}=(\hat{s}_0, \dots ,\hat{s}_{N-1})$, where $$ \hat{s}_q=\frac{1}{\sqrt{N}}\sum_{k=0}^{N-1} \zeta^{q k} s_k, \qquad \zeta=e^{2\pi i/N}, $$ defines a new multivariate random variable. Finally, consider the univariate random variable $$ h=\left(\prod_{q=1}^{N-1}\hat{s}_q\right)^\frac{1}{N-1}=\left(\prod_{q=1}^{(N-1)/2}|\hat{s}_q|^2\right)^\frac{1}{N-1}. $$ This variable is the scaled algebraic norm of the cyclotomic integer whose coefficients are $S$. I would like to prove that $h$ has the central limit property for $N\to \infty$, that is, its distribution becomes increasingly concentrated at one value. The plausibility argument goes like this. Consider a "baby" estimator of the variable given by the geometric mean of a fixed number $M$ of the $|\hat{s}_q|^2$, instead of all $(N-1)/2$. For this fixed number of Fourier transform components we have a multivariate central limit theorem, for $N\to \infty$. When we apply CLT and compute the covariance matrix, we find that these $|\hat{s}_q|^2$ are independent and identically distributed random variables. The baby estimators therefore have the central limit property for $M\to\infty$. Unfortunately, the $M\to\infty$ limit of the baby estimators may be a different random variable than the $N\to \infty$ limit of $h$. 

Sure, multiplication is commutative, but there is more to it than that. While being reasonably easy, this puzzle suggests variations in ways that the equation $x\cdot y = y\cdot x$ doesn't. In his wonderful paper Games People Don't Play, $URL$ Peter Winkler describes essentially the same game as ``Next card color betting'' (a bit of googling also turns up $URL$ and $URL$ But there the player, Victor, wants to end up as far to the right as possible (increasing his bankroll). It turns out that there is a strategy that guarantees him to end up with $2^{10}/\binom{10}{5} = 256/63$ times his initial bankroll, or about 406 steps to the right of the origin. This is a game that children can understand, but if we pursue the analysis, it doesn't stop until we have developed, besides insights into hedging strategies, a good deal of nontrivial mathematics including information theory (the amount of information Victor has about the red-black sequence dictates exactly how much money he will ideally make by betting), the Wallis product formula (showing that his final bankroll is asymptotically $\sqrt{\pi n}$ for a deck of $n$ red and $n$ black cards), and even the central limit theorem. 

Hadamard matrices may be characterized as $n\times n$ real orthogonal matrices $U$ that achieve the lowest possible "energy" as defined by the (scaled and shifted) entry-wise 1-norm: $$ E(U)=n^2 -\sqrt{n}\,\sum_{i=1}^n \sum_{j=1}^n |U_{i j}|. $$ We'll consider only those $n$ for which Hadamard matrices exist; their energy is zero. I'm interested in the minimum energy "barrier" between distinct Hadamard matrices. Let $U_0$ and $U_1$ be distinct Hadamard matrices and $U_t$ a continuous map from the unit interval to orthogonal matrices (a "curve") with these matrices as endpoints. The energy barrier, for this curve, is the maximum over $t$ of the energy: $$ \Delta E(U_t)=\max_t E(U_t). $$ Finally, define $\Delta E$ as the infimum of energy barriers over all curves that join any pair of distinct Hadamard matrices. $\Delta E$ is easily bounded above by $90^\circ$ Givens rotations (as curves) that have the effect of swapping two rows or columns of a Hadamard matrix; the maximum energy, at the halfway point, is $(2-\sqrt{2})n$. Is this bound sharp, or are there smaller barriers?