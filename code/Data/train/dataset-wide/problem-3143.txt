Broken Code There seems to be a great deal of confusion about the class. The class you posted does not compile against the class you later posted, on account of the node class not being generic whereas your sieve class contains code that assumes it is. The sieve class also does not compile against the linked version of the class (which is generic), on account of being in that version, but the sieve class attempting to modify that field. The posted Node class has similar form as the linked one, but also considerable differences -- primarily, the former has been made specific to elements of type instead of generic, but it has also been reformatted, been made , and its has been made non-. This review is based on the version you provided, assuming the aforementioned error in is fixed (which can easily be done). Naming My apologies, but your naming is overall terrible, and that makes your code much more difficult to understand than it needs to be. Field and local variable names for the most part are meaningless or simply reflect data type; few of them clearly reflect the the significance or intended use of their values. Even the meaning of the name of inner class is obscure, plus it appears to be a verb -- class names should be nouns. Some methods have obscure names, too. In addition to being unclear, the names and in particular are also non-apposite. As a pair, they should be either and or and . Code Layout I strongly recommend a more conventional layout with respect to placement of the inner class. In your code, it is placed between two methods of the main class, and that makes it harder than it needs to be to follow which method belongs to which class. If you're going to declare an inner class, then the best place for it is after all the containing class's fields and methods. Correctness The adaptations to the class make it possible to use it in a manner that is not thread safe, and it is in fact used in an unsafe manner because instances' fields being accessed and modified by different threads without synchronization. This can be rescued by making the field , but that substantially slows the program (as should be expected). Even if it were implemented in a thread-safe way, your "restriction" mechanism would still have a race condition, because your code lies. The check against the restrictions interprets the restriction values as representing the last numbers flagged as composite by each running task, but when you initially create each one, you set its value to the first composite the task intends to mark, and then queue the next task before that composite is actually marked. It is possible for threads to be scheduled such that the next task starts before the one that enqueued it actually marks the designated number as composite. Algorithmic Improvements The most work is required to sieve the smallest primes, and the most work of all is required to sieve 2. You can efficiently handle 2 as a special case by initializing all the chunks in your bit set to the bit pattern 0x5555555555555555L, thus striking out all the even numbers very efficiently, and then starting at 3 for the rest of the algorithm. This modification speeds your original code by more than 30% for me. That's in the same vein as your own suggested improvement. Yours is more comprehensive, and with the threshold for enabling the optimization set to 32, my variation on that approach cuts the elapsed time in half. The two can be combined, but using them together provides only a marginal additional improvement over yours alone, so that's probably not worth it. One important thing to glean from that, however, is that atomic operations and operations on volatile data are expensive. You can get another significant boost by getting rid of your "restrictions" and the associated Node objects altogether, along with the operations on its necessarily volatile . The objective of those is to ensure that each previous task has progressed far enough that a given one can correctly identify the next prime from the sieve. We can avoid the need for that by simply not enqueuing the next task until we are confident that it can immediately proceed. We cannot know the earliest time when that is possible, but we do know that it is possible if the current task has already processed all values up to at least the square root of the sieve size (recognizing that the current task did not start until the previous task proceeded that far, etc.). That's an easy criterion to check, and it leaves plenty of room for many concurrent tasks, because the square root of the sieve size forms a much smaller proportion of the total sieve size than 1/(# cores). That optimization cuts the runtime by about 20% relative to my variation on your optimization alone, for a total savings of about 65%. The code is much simplified, too. I have not tested this one, but I'm inclined to think that further speedup could be obtained by doing away with the altogether, and instead using an analog that relies on an ordinary array. To make that thread safe and still performant, you would implement coarse-grained locks protecting large sections of the array -- for example, blocks of elements. That could trivialize the previous optimization, and although there would be increased contention between threads, I anticipate that the replacement of millions of atomic operations with normal operations plus a (comparatively) few lock operations would be a big win. Additional Comments 

I've never been too bothered by the lack of (and thus ) support for Factor collections and other objects, but I've never needed to generate Factor programs from JSON until now. To that end, I use these methods to turn arrays, hashtables and assocs into roundtrippable strings: 

When I'm writing Python, I wanna be able to pull up an interpreter quickly, and import what I need easily. Previously, this involved: 

Compiler errors First of all, this code does not compile with the (IMO too lenient) command line of : 

This scalably-threaded server has endpoints at and . This is just an example of how to use antiCSRF and you should never ever keep reusable, long-living secrets in your users' browser history. In the real world, instead of negotiating over , use with JSON or URLEncoded data, like me. I'd especially appreciate guidance on improving the threadsafe aspect of the library, but of course all recommendations and criticisms are appreciated. Finally, I fully expect to be told this is an insecure and wrong implementation, so tell me how I can write it better from an internet security perspective. 

Let this be a lesson to ye -- listen to the C compiler, for it knows many things :) API When I write in C, I try to make my functions applicable to a wide variety of uses because C is verbose, simplistic and lacks polymorphism. Having said that, I'm not sure how I feel about the interface I find when I read your code. Because the point of this program is hardly an end unto itself, surely this has applications in other projects' s. To this end, it would likely be best and most testable if functions didn't have rather unrelated side effects, like printing, which could be handled by the caller. That is, however, quite subjective and your use-case may differ entirely. Organisation / Style I know you're using Windows because you call without an , or perhaps that was a typo and you meant (from ). So even though all the functions in are laughable with their , "idiomatic" C uses , not . Moreover, in "idiomatic" modern C: 

It's at least twice as costly as rearranging a min heap appropriately without removing the modified element could be made to be. You've given no basis or context for putting that on absolute grounds. 

Pandigital testing You are making a tremendous sacrifice of efficiency here to implement this in terms of . itself, although not terrible, is also not great. To even get there, however, you need to format your number as a String, which by itself is more expensive than one whole pandigital test needs to be. You could instead just pick off the digits one by one via the modulo and integer division operators, and keep track in an array, or even in bit-array form in a single (only 40 bits of the 64 are needed). General is a wider data type than you need for representing the numbers being tested. is wide enough to express all integers having nine or fewer digits in their decimal representations. You could, and probably should, use -- or even better, -- everywhere you currently use . Also, there is a space vs. speed tradeoff available here, where you have opted for using less space. It is possible to augment your sieve to efficiently fill an array with the actual primes it discovers, particularly if you're willing to declare a big-enough array at the beginning, and not worry about unused space. It would be more efficient to process the elements of that array that are in use than to iterate over the whole range, testing directly against the sieve. In fact, if you do this then some of the extra space need be consumed only transiently, because you can let the sieve itself go after you finish filling the array of primes. 

There are unit-tests, but I'll omit them for brevity. Most interesting to the reader is probably a usage example, so here you go: 

I've been working on a full stack web application for a school project, and I wrote antiCSRF without prior experience or example code to prevent Cross-Site Request Forgery attacks, and to differentiate users who have authenticated once from arbitrary anonymous requests. The original implementation (v0.0.1) was very short, and used a module-global token register, instead of a class, and reflected how little I understood threading and the GIL in Python. The second generation of antiCSRF (which I deem v0.1 because I think it's kinda stable) is about 400 lines with docstrings and comments in. The continued use of almost definitely continues to reflect how little I understand Python's threading, but it's in there just to be safe with threaded code, for which this is explicity intended. The implementation consists of 4 helper functions (of which only 1 is essential) and 1 class, , which is where it all goes down. One of the first pieces of code I've "designed" in a while, the keeps track of currently valid and recently expired CSRF tokens, as well as providing metadata and "lower-level" functions for more customisation of the API. Specify your own key function, key length and expiry time, or don't, and use the reasonable defaults. anticsrf.py 

Some sections are optional - more details regarding the sections I use below in the organization part. Blocks of code inside each section can be commented with something like this, in order to create a clear separation of the different parts of code, and also to provide useful comments for business logic, batch file techniques used to "make something work", etc: 

Finally, functions are documented in a similar way than blocks of code, but I decided to include parameter and return value definitions (inspired to some degree in Javadoc comments). Here is an example (take notice of the tag at the top of the comment): 

I use these two methods when running macros that do intensive work of reading/writing information to several sheets: 

Well, in case anyone is interested, here is what I've come up with: BASICS I like using the type of comments over comments, because I think they are easier to read (less clutter). Also, I use lower case text for everything inside the file (except for section headers, as you will see below). I understand that many people prefer to use upper case text for function names, labels, etc., but I think lower case text is easier to read, so that is what I am adopting for my files. COMMENTS Taking this into consideration, I use a header on each file like this: 

See also below. Flawed implementation Your code can easily be made to overrun the bounds of the array. In fact, that will happen if the number of usable key characters is smaller than the number of letters in the message. To (partially) fix this, you need to wrap around the end of the key inside the loop, rather than at the end of the loop where you now do that. That will, however, expose another flaw in your implementation: it does not handle the case where there are zero usable key characters. Your current implementation will just immediately run off the end of the array in that case; after the fix, it will loop infinitely. See below for a suggestion that will help. Error handling does a decent job of noticing when memory allocation fails or nothing is read from the input. It helpfully returns in those cases. , however, ignores those signals and unconditionally passes the result to . For its part, assumes that its argument is always valid. Either 's behavior or 's could be ok in isolation, but together they constitute a flaw producing undefined behavior under some circumstances. Similarly, returns in some failure conditions, but pays no attention, assuming that the return value is a valid pointer, in attempting to print it. Implementation improvement If you have (which is standardized by POSIX, not C itself) then it is a convenient alternative to + + . calls before prompting for the encoding key. This is useless. Move the flush after the prompt, or remove it altogether. Since the prompt ends with a newline, it is probably unnecessary to flush even after printing the prompt. I remarked above on problems with your key handling. I observe also that you handle your key inefficiently if it is short relative to the phrase to encode. You shouldn't need to check on each pass through the key which characters are usable. You shouldn't need to account for upper- vs. lowercase on each pass, either, if indeed you make them behave the same way. Instead, process the key once, before the encoding loop: remove characters other than letters, and convert all the letters to a standard case. Then it's also easy to validate result to ensure that there is at least one (or two, or whatever) key characters. It doesn't make sense to me that your encoding code is not parallel for upper- and lowercase key characters. The code for uppercase keys looks equally applicable to lowercase keys except the computation of , but you use a more complicated and difficult to follow scheme for lowercase key characters. Indeed, one of the alternatives for lowercase keys cannot even be exercised, because and cannot be true at the same time. Design improvement Your function modifies the input string in-place, but also returns a pointer to it. On the other hand, the function's name suggests that it will create a new phrase. I suggest changing that function's signature to 

The method was written rather haphazardly as I tried to find something that seemed robust. The way the elements are finally formatted, using and may seem sloppy but it looks better than an , and can't be used on non-constant values. The recursive nature allows it to be cleverly repurposed for other collection types and on arbitrarily deeply nested arrays. Moreover, string literals in arrays preserve their so they roundtrip too, which I initially struggled with. But, can it be improved? The goal is that any collection converts into a string and s back into its original value (called roundtripping), which it does: 

Upon correcting the errors mentioned by the compiler flags, however, the bugs appear to have disappeared! 

is not returned or modified, nor should it be. As such, it should be declared , so that the compiler may make optimizations and assumptions around the fact it will not change: 

Well, now the program aborts 100% of the time, and it will take you a couple minutes to figure out why because of the tricky indentation. If you had used braces, this would have been avoided: 

Fact: you cannot reliably compare floating point values with or . Instead, you need to use an epsilon and compare the difference, like: 

must be declared except if its return type is omitted, in which case it's inferred to be by the compiler. Compliant programs declare . Since C99, need not explicitly return -- if you omit a return value, the compiler will insert at the end. 

My first observation was the same as @EmilyL.'s: that you're performing unneeded string concatenations. Upon investigation, however, it turned out to be a loser to substitute two invocations of methods for a string concatenation plus one method invocation -- the result ran about 70% slower than the original code for me. It took a while for the lightbulb to turn on, but that slowdown is a key symptom of the underlying problem: is unbuffered, at least when it's not connected to a terminal. In a comment you described addressing the problem by building the output in a and then printing it all at once. That's a viable mechanism for buffering manually, but cleaner and easier to integrate into your original solution would have been to wrap a buffered stream around and print to that. In other words, at the top of add ... 

You can quickly compute the exact total number of grains that could be eaten over a given time span by multiplying the time separately by each consumption rate (== truncating division by seconds per grain) and adding up the results. Having such a function in hand, you can avoid simulating the entire course of the process by instead searching the space of possible times. For example: 

dumping the input string to a ; creating a separate of the reversed input string; based on those arrays, for each index strictly between 0 and the string length less one, finding and storing the odd-length palindromic substrings centered at that index (based on the forward and reverse arrays); for each index strictly between 0 and the string length less one, find and store the even-length palindromic substrings centered between that index and the previous (based on the forward and reverse arrays).