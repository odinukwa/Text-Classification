I need to set up an ESXi 5.1 box to run some pre-made VMs that will not run well under VMware Workstation. I have started testing this, but cannot figure out where the @#$% the control comes from other than vSphere Client, which runs only on Windows. I get strong hints that, at least under earlier versions of ESXi, you could do most of the necessary things (start and stop VMs, add files to the datastore, configure new VMs, and so on) from a command line. However, VMware's site is now so littered with related products, it is impossible to find whether this low-end scenario is supported. I would imagine that a lot of serverfaulters would rather not have some of their critical infrastucture running on Windows. Let us set up a hypervisor box, and we'll control it from SSH. If there is a guide for how to do this for ESXi 5.1, I'm not finding it. Clues appreciated. 

I have a small Python-based server program that runs fine, but I want launched each time the server is rebooted. What is the least that I need to put into an /etc/init.d script to work? I only care about "stop" and "start" (and thus probably the trivial "restart"). 

The "default" category is supposed to get all of the logging that doesn't happen in other categories. However, when I start named, I get a bunch of messages in /var/log/daemon.log, and then more in the named file. I would like them all to go into the named file so I don't have to look two places to figure out what might have gone wrong when starting. 

a) Yes, I have experience with this. b) The answers above about using hashes answer only the question you asked in the title of this thread, not in the body. To prove you had them before you got the CD-ROM, you will need to provide logs of when they were last touched, something you probably don't have because this kind of information is rarely kept. c) Having said that, your company probably does keep backups, and those backups have dates on them, and those backups can have files selectively restored from them for matching. If your company has a written backup policy, and the backups you kept match the policy, this will make it much easier to convince someone that you didn't fake the backups. If you don't have a policy but the backups are clearly marked, that might be sufficient (although the lawyer for the other side will question this up the wazoo). d) If your company didn't keep backups, and all you have is the described screen shots, forget about it. You will have a very hard time convincing anyone that you are in control of your data well enough to "prove" that you had those files first. 

If available, an alternative would be to stand up the database in a virtual recovery environment in New Hampshire where the backup data is being stored and route Austin traffic appropriately to the recovered SQL system. This would be much faster to achieve you Recovery Time Objective, however only feasible if you can route traffic appropriately. 

Perform the partial restore of all remaining filegroups one by one to restore the entire database. IMPORTANT NOTE: This cannot be done in parallel and must be done sequentially! 

This will start an immediate restore of the database files to the destination system selected and mount the database in an online state. Performing Partial (Piecemeal) Restore of a Database (Out-Of-Place) If the size of a filegroup in a database is large, the restore operation may take considerable time. In such case, you can restore the database in stages. Partial restores also known as Piecemeal Restore in SQL Server versions 2005 and later allows you to restore a database in stages. Follow the steps given below to restore a database in stages at filegroup level: 

From the CommCell Browser, navigate to Client Computers | Client | SQL Server. Right-click the Instance and then click All Tasks | Browse and Restore. In the Restore Options window, click the Advanced Options tab. Select File/File Group and then click View Content. In the left pane of the Browse window, navigate to the database that contains the filegroups you want to restore. Select the filegroups you want to restore in the right pane and click Recover All Selected. Select the Destination Server from the drop down. Rename the database under the Database column and change the path of the database and log files under the Physical Path column. Click Advanced. In the Advanced Restore Options window, click the Options tab. Select the Partial Restore check box. Click OK to start the restore. 

I know this is an old question, but it is the first question that shows up when searching "commvault" on serverfault. I have two years of experience with Commvault Simpana v9 and v10 as a support technician and a year as a systems engineer. First Question 

From the CommCell Browser, navigate to Client Computers | Client | SQL Server. Right-click the Instance and then click All Tasks | Browse and Restore. In the Restore Options window, click the Advanced Options tab. Select File/File Group and then click View Content. In the right pane of the Browse window, select the database you want to restore. Click Recover All Selected. Select the Destination Server from the drop down. Rename the database under the Database column and change the path of the database and log files under the Physical Path column. Select Unconditionally overwrite existing database or files checkbox. Click OK to start the restore 

EveryDNS used to have this, but I switched to DynDNS because I found out my router has support for DynDNS. 

Where can the pfsense log files be located and viewed? I have searched the documentation and it doesn't indicate the log files location for the various components of pfsense. 

So my understanding of one scenario that ZFS addresses is where a RAID5 drive fails, and then during a rebuild it encountered some corrupt blocks of data and thus cannot restore that data. From Googling around I don't see this failure scenario demonstrated; either articles on a disk failure, or articles on healing data corruption, but not both. 1) Is ZFS using 3 drive raidz1 susceptible to this problem? I.e. if one drive is lost, replaced, and data corruption is encountered when reading/rebuilding, then there is no redundancy to repair this data. My understanding is that the corrupted data will be lost, correct? (I do understand that periodic scrubbing will minimize the risk, but lets assume some tiny amount of corruption occurred on one disk since the last scrubbing, and a different disk also failed, and thus the corruption is detected during the rebuild) 2) Does raidz2 4 drive setup protect against this scenario? 3) Does a two drive mirrored setup with copies=2 would protect against this scenario? I.e. one drive fails, but the other drive contains 2 copies of all data, so if corruption is encountered during rebuild, there is a redundant copy on that disk to restore from? It's appealing to me because it uses half as many disks as the raidz2 setup, even though I'd need larger disks. I am not committed to ZFS, but it is what I've read the most about off and on for a couple years now. It would be really nice if there were something similar to par archive/reed-solomon that generates some amount of parity that protects up to 10% data corruption and only uses an amount of space proportional to how much x% corruption protection you want. Then I'd just use a mirror setup and each disk in the mirror would contain a copy of that parity, which would be relatively small when compared to option #3 above. Unfortunately I don't think reed-solomon fits this scenario very well. I've been reading an old NASA document on implementing reed-solomon(the only comprehensive explanation I could find that didn't require buying a journal articular) and as far as I my understanding goes, the set of parity data would need to be completely regenerated for each incremental change to the source data. I.e. there's not an easy way to do incremental changes to the reed-solomon parity data in response to small incremental changes to the source data. I'm wondering though if there's something similar in concept(proportionally small amount of parity data protecting X% corruption ANYWHERE in the source data) out there that someone is aware of, but I think that's probably a pipe dream. 

This will start an immediate restore of the database back to the system from which it was backed up from and the data will be overwritten. Database Restore (Out-Of-Place) A database can be restored to another system that also has the SQL Database Backup Agent installed. This restore mounts the database in an online state on the destination system once the data has been restored. 

There are a two ways that CommVault Simpana v9,v10, and v11 restore Microsoft SQL databases, Database Level Restore and Database File/FileGroup Level Restore. Each has variations depending on the desired outcome. See below for details: v10 Microsoft SQL Database Restore Documentation v11 Microsoft SQL Database Restore Documentation Here are some directions that apply to v9, v10, and v11. Default Database Restore (In-Place) By default, a database is restored in the same location from where it was backed up using the CommVault Simpana SQL backup agent and the existing database files are overwritten. This restore leaves the database in an online state. 

From the CommCell Browser, navigate to Client Computers | Client | SQL Server. Right-click the Instance and then click All Tasks | Browse and Restore. Click View Content. In the right pane of the Browse window, select a non-system database you want to restore and click Recover All Selected. Select Unconditionally overwrite existing database or files checkbox. Click OK to start the restore. 

This will start an immediate restore of the database(s) to the destination system selected and mount the database in an online state. Restore Database using File or FileGroup Level (Out-Of-Place) You can restore a database in its entirety by restoring all the files/filegroups that make up the database. This option does not allow for multiple database selection, however this is to your advantage as File Level restores of Databases are usually limited to a single stream per job. Using multiple Database File Restore jobs you can increase your overall restore throughput and reduce the time needed to restore the entire dataset. Note: If you're restoring a single large database to files it is preferable to break out the individual database files as separate jobs using Performing Partial (Piecemeal) Restore of a Database (Out-Of-Place) 

From the CommCell Browser, navigate to Client Computers | Client | SQL Server. Right-click the Instance and then click All Tasks | Browse and Restore. Click View Content. In the right pane of the Browse window, select a non-system database you want to restore and click Recover All Selected. Select the Destination Server from the drop down. Rename the database under the Database column and change the path of the database and log files under the Physical Path column. Select Unconditionally overwrite existing database or files checkbox. Click OK to start the restore. 

If I have a mirrored pair of 250GB drives in a pool, and I later buy two more drives and add another mirrored pair to the same pool, can that second mirrored pair be 500gb? Such that my total usable space would be 750GB? Or do all the mirrored pairs in a pool need to be the same size? 

Intel AMT is a motherboard feature found in certain chipsets such as Q67. So if you are looking for a superMicro board with this, then just find out which intel chipsets support Intel AMT, and then look for supermicro boards with that intel chipset. There are some various other requirements as far as what CPU you use, etc. In a nutshell the motherboard keeps one of the ram chips powered, the northbridge powered(which runs the management interface), the onboard ethernet connection, and an extra flash chip to store settings. So you can connect to the system over ethernet and access the remote managmeent features/power-on/power-off etc. I am not sure though if this is available in any chipsets targeting servers though, but it is really powerful and would seem to be well suited for servers. 

Scenario: Excel file, with a SSAS data source connection Pivot Table/Charts with filters and slicers Published to Sharepoint 2010, such that users can access the report as a Excel Web Access Web Part, such that they can't break/change the pivot table other than changing filters and slicers. Note that I am NOT talking about powerpivot. Rather just using a regular data source connection. As users access the report, I would like the most current data(within the last day) from SSAS to be reflected in the report. Assume that the SSAS database is refreshed daily already. 1) Does Excel Services and/or the webpart automatically refresh the data when the report is opened/viewed through the Web Access Web Part? And/or can it be configured to periodically refresh the data? 2) What are the server software requirements to support this? Does it require SQL Server Enterprise edition? Or is standard enough? Does it require Sharepoint 2010 Enterprise, or is standard enough? when I say "support this" I mean both the Excel Web Access Web Part as well as the refreshing of the data from SSAS into Excel. 3) Does the Web Part allow them to only interact with filters/slicers? Or will they be able to mess with/break the pivot table? If so, will changes/breakage they make only be persisted for their session and not effect future sessions or other users? I would test this myself but I have had difficulty getting the trial of Sharepoint setup on my home computer(ultimately I won't even be the person setting it up in production anyways) and I just want to know what edition will support these features. Thanks.