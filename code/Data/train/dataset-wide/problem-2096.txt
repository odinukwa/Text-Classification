2) This one is tricky. It helps to know what ascii character your line breaks actually are. Depending on how they were written, generally (but not always) they will be chr(10) or a combination of chr(10)chr(13). You can use the REPLACE function in your query to replace those with '', which should get rid of them. 3) If you want quotes, see my example #1 above. HTH. 

First, let me state that I think that running anything as the non-oracle user on your filesystem may result in significant database issues! (I'll explain why in a minute) Aside from the pathing issue, which you solved, I think that Colin is correct. You (or your admin) does need to give read on the binary: 

As someone who spent 4 years of his life dealing with converting CLOB type data from legacy systems into Oracle, I feel your pain. I highly recommend using an Oracle built function, such as to go through and scrub all of the garbage characters from CLOB type fields. Additionally, remember that most systems consider a "return" to be a new line and carriage return in unison, so you might have to scrub ascii characters below 33. IIRC the new line/carriage return combo was char(10)char(13). You can easily google a list of of the "invisible" ascii characters, and hunt down the ones you want removed. HTH. 

Oracle specifically split out the sysaux from the system, and IMO this was a good choice by them. Essentially, without going deeply into the documentation which you can read for yourself, SYSAUX stores things like statistics history, non-essential performance views, and other pieces of metadata that may or may not be in-use in a particular database, depending on what that database is used for. It is sort of a "separation of duties", and allows for easier manipulation of these non-critical objects w/o SYSTEM level downtime (I'm generalizing here, 11g isn't 100% perfect in that regard). I'd break it down like this, as-if the database was the human body: SYSTEM is your nervous and cardiovascular system. You cannot live without it. SYSAUX is all of the other systems of your body - you can survive without them but for optimal performance it's best to keep them in good working order. 

SQL*Developer is a decent tool for this, but can still take some time. If you're looking at SQL Plus, I'd recommend that you use spool, and make liberal use of SQL Plus's set command to format your output into flat files. For delimiting the flat files, you can make use of the concatenate feature to add in column headers. Here's an example: 

found here: $URL$ I think you may need to utilize the DBMS_LOB package. Documentation found here: $URL$ HTH. 

I have been tasked with allowing developers to kill their own sessions in the Development database. I've written a procedure, but for some reason I'm getting when trying to call . Here's the proc, being compiled as . Running on an 11.2.0.4.3, 2 node RAC database: 

But hey, what is life without a challenge? I'll work on that, then perhaps post another question to the forum if I can't resolve the issue myself. Thanks for the help. 

So here's the rub: every single developer logs in with the same user, so I can't really use . I don't want to open up blanket for every single user. This would allow a dev manager to pass in a username (i.e. jsmith) and kill that session, and would email us DBAs that this happened, so we can see if the devs are doing this a lot. Any thoughts as to why I'm seeing this: Errors for PROCEDURE KILL_DEV_SESSION: 

mmmmmpie offers you a very viable way to do it. However, especially if you want to get your test environment as close to possible as prod for testing purposes, I highly recommend you look into RMAN cloning. You will end up with a block-for-block recreation of your production environment, which IMO is worth its weight in gold in regard to performance tuning (assuming the underlying tech stack is similar). $URL$ There's a 10g version of the methodology. HTH. 

Here's how searching for any object works (this example assumes the user has appropriate permissions, and that you didn't make the call as "schema.table") 

It sounds like you're dumping 30 million rows into an existing table, then immediately trying to update those rows. I have a couple of thoughts, which may or may not work for you (since I can't see your code currently): 1) Is there a way to combine the inserts with the updates? It seems suspect to me that you're creating 30 million rows, then immediately updating them. Perhaps you need to look into insert using select statements to dynamically derive the full value, and then insert the rows in their final state. 2) By inserting 30 million rows, I suspect that you're altering your tables by a value > 10%. Oracle's automated jobs will reanalyze stats on any table with a change of 10% or greater; I make it a practice to do the same thing when I'm inserting/updating/deleting data. This is why you're seeing this behavior when you stop the 2nd procedure and analyze the table. 3) For the update statement, have you properly indexed the columns? 4) What is your expectation for the second procedure's run time? Does 1-2 hours to update 30 million rows sound too long? Only you can know that. For example, in the environment I work in, we can run our databases at 17,000 IOPS, but we force logging on everything because we run a data guard to a DR site, which adds some overhead on operations. So for me, 1-2 hours for a 30 million row update is right about where I normally am. Of course, this also depends on factors like row size (are you updating a single character, or a blob?), the where clause of the update (are you updating based on primary key, a foreign key, or based on an unindexed field?), and the overall load on your system at run time. HTH. 

is probably the best starting place. In that view, you can pass in the view you're looking for in the field. If you want to see who has permissions to more than one view, you could always use a sub-select on the view to then see what the on that view are. However, depending on how your database was implemented, you may also need to look at role information. Using may only show you the roles that have select on the view(s), from there you'll have to use the series of views to determine which physical users have been assigned those roles. 

However if you're not expecting duplicates in the table, the more accurate answer would be to hunt down why those duplicates are there, and work with any stakeholders to eliminate the duplicates. 

Make sure you're using SYSTEM to do exports, as sysdba privs are not recommended for running data pump (see Invoking Data Pump Export. I wonder if that might be the problem. 

This will create a compacted index of only the rows with a 1 value. As long as you keep this 1 value at 1-5% by aging out rows, you'll see great performance. Not that partitioning won't work, but it does cost extra, while function based indexes do not. For reference, $URL$ (9i version), scroll down to "When to Use Function-Based Indexes". Again, I know you already accepted an answer, but I wanted to throw this out since you seem open-minded about possible options. 

It looks to me like the string you're passing in is too long for the UTL_RAW procedure you're trying to call. From the Oracle documentation: 

However, without knowing more about the table, I don't know if the TIME column is simply an integer, or is a date/timestamp field. If it is date/timestamp, SUM won't really do what you need it to. One other word of caution, using rownum doesn't always return the same results between runs. Please take a look at $URL$ for a much more succinct explanation than I can provide. 

So if you create a public synonym, any user that has access to at least select on the underlying table can see it, without any further action on your part, even going forward for new users. If you create a private synonym, you'll have to create a private synonym for every single user that will have to access that specific object, and you'll have to do this for every object that you move (this applies to tables, sequences, and assorted other DDL like packages, functions, etc). Either option is acceptable, depending on the level of security necessary for that object. 

The graph is showing the number of sessions in wait. The colors represent a broad category of wait class, which assists in quickly identifying the primary type of wait faced by sessions in the database. The maximum CPU line simply gives you a marker to determine if the amount of CPU wait is reaching extremely critical levels. 

In your example, you have Autoextend on with 4M as the next extension, but you also have MAXSIZE set to 8G, which means that Oracle is being told that once a tablespace reaches 8G, it will no longer automatically add space. This is for safety purposes, as sometimes administrators want to know when a datafile is growing very large very quickly. In your case, you could issue , which would allow this tablespace to automatically extend to that maximum size, depending on how much space you have on your server! If you run out of actual physical disk, nothing in the Oracle database will protect you from this. Additionally, you'll still want to periodically monitor the size of this tablespace, as you will (theoretically) still eventually reach the maximum size of the autoextend. Even if you set the maxsize to unlimited, there are still factors that determine the maximum size of a tablespace that are out-of-scope for your particular question. Just know that there is always a maximum upper limit to a tablespace, and someone will have to monitor it to take appropriate action. 

Search the current schema for that object Search private synonyms for references to that object Search public synonyms for references to that object