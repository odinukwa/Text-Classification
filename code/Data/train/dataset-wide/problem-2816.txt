From this you can get the idea of what you should do.... I realize I kept the as an array, and you have it as a List. I kept it as an array because it is the input mechanism for the bulk methods of the API... but, in fairness, I think you should keep using the List format (the is useful). Then, convert the List to an array when you need it. Also, look in to the FetchProfile object/method, you can add any header fields you want to it... Also, you can filter out messages that do not meet certain criteria, and then fetch additional data for the next set of tests, and do it that way. Bottom line is that you want to access the server as few times as possible, and when you access it, you should get as little data as you need, but, group all similar requests in to a sigle operation..... 

Using STL algorithms If you want to advance an iterator by a certain number, you can use std::advance instead of a loop: 

First of all, as DarthGizka mentioned, your code is mostly easy to read and understand and except for the memory leak I mentioned in the comments I don't see any errors. I can't really contribute on the general question, of how effective skiplists are or what would be the best algorithm to determine the height of each node, however, I think there are still a few things that can be improved in your current implementation: General Interface I believe this is more of a proof-of-concept, but on if you go on with it, you should probably strive to make a interface more similar to STL-like associative containers. Meaning in particular: providing iterators, template the class on the member (and key type), providing the typical typedefs and functions (e.g. ) etc. As mentioned by others, this would also make it easier to compare it to other data structures. Making a nested class Skip_Node is an implementation detail that should not be visible outside of the class, so you can just make it an nested class of . Const correctness and static member functions You have a few member functions that should be specified const (, ) or even static (, ). Structure It seems that you assume, that you will never add an item to the container with the same key as the key. If that is the case, you should probably document and assert that. However, this also means, that there is no need to treat the node in a special way. More to the point: The main reason for using dedicated and nodes is so that your member functions don't have to care about empty lists, or whether a new node is the first or last node in the list. If you embrace this concept, then you can e.g. make a one liner that simply returns the size of the vector. Also, insert and erase seem a little long to me and share a nontrivial amount of code, so you might want to refactor the common functionality in a separate function. Finally, seems to be a pretty heavy member for the list nodes (due to the size overhead and the additional memory allocation). If the maximum level is a compiletime constant, you could try e.g. a member array instead (possibly using multiple different node classes of different sizes, as suggested by DarthGizka). Dead Code With the above in mind and when you carefully think, about what invariants hold at each line of code, you might see, that there is a lot of test that always evaluate to true or false and code that never gets executed. Comments Nice to see a thoroughly commented code. Personally I would write the function documentation at the point of declaration (in the class definition) and I also try to avoid to write comments basically repeat the code the code. After reviewing and refactoring your code, I ended up with the following (some of the changes are just personal style): 

but, since is immutable (oh, should be a final class? ... I think so...), it makes sense that the method can return the exact instance if it is valid.... why does it have to create a new instance each time? In a stream that can create a lot of GC churn.... I would write that method: 

Algorithm The solution you have for this problem appears to work. The algorithm relies on passing a token around, and relies on first walking the right-edge of the tree to create a 'stop-gate'. These two items detract from the solution. There are 'simpler' ways to do this recursive problem without the overheads you have. Consider the functions: 

The Stream API is more than enough when it comes to "fluent". Also, if you don't want to include the size in the top call, you can limit the stream too: 

You default construct all nodes upon construction of the stack and destruct them when stack is destructed, in which case is unnecessary. One can just use an array of nodes and pass it to the unique_ptr. In this case you also don't need a destructor for . Obviously that only works with default constructable 's and makes only sense, if T doesn't hold any resources after it has been moved from. You actually create and delete objects upon calls to push and pop, in which case you have to use placement new () and manually call the destructor (not ) 

There is no need for , just put the (inverted) check into the loop condition (this will then also enable you to process empty lists). You can write your outer loop as a simpler (semantically equivalent) for loop: 

This way we can store each result, instead of just counting it. There are a few things to go through here. Product This class looks awkward: 

I see that you start the BlockedQueue off in an 'unblocked' state, so the first thread in will immediately return. Only 'subsequent' threads will wait. There is a gap in your logic though.... (hate to be the bearer of bad news....)... It is possible for the queue to be empty when is called even though there are blocked threads. This is because you may be removing() items in your loop at the same time as when the wake-up is called. Also, I think that you should be more precise about what threads can re-awaken the queue. I like the try-finally concept which will assure that the same thread that calls will also call . Consider the following alteration. Instead of using an AtomicBoolean to lock the thread, use an AtomicReference (and I have renamed it to 'active' instead of 'lock'.... 

I also made the deliberate design choice, to not provide a virtual destructor due to the overhead it would incur and the fact that I don't see any use case, where I would want to destruct const_string via a pointer to . Still this goes against best practices and might be suprising for other people using that code - would you accept such a code in your codebase? I haven't finished documentation and the unit tests yet (I hope the code is readable enough), but here is some sample code to play around with: 

There are a few simplifications you can make: Unused variables The value of isn't used anywhere, so you can just get rid of it it. Simplifying outer loop: 

I don't think there is anything wrong with your general approach (or at least I don't have a better suggestion). On an implementation level I've a few suggestions 

Your faith in your input data is absolute... you do not do any validation. This is not a 'best practice'. You should at least be doing an input range check on the . Once you have the range-check done, you can avoid the whole switch statement, and skip to some simple math for the index lookup: 

Those poor knights.... what did they do to deserve that? But, there is a mathematical treat that allows this problem to be solved in O(1) time, and space. What does that mean? Well, it means that solving the problem for 1 knight takes just as long (and just as much memory) as solving it for 10, or 1000, or 1000000000000000 knights. How is this possible? There's a pattern that emerges when you study this problem. If there is 1 knight, then knight 1 survives. If there's 2, then knight 1 survives, and, if we map this out for say the first 32 knights, we get: 

Your code doesn't run in parallel at all! Locking the mutex at the beginning of means you are always only run one instance of at the same time. You are passing a copy of the same random number engine to each thread. As this is only a pseudo rando number generator, all threads will operate on the same sequence of numbers (you are doing the same work multiple times). 

On my 4 Core machine with VS2015U3, this reduced the execution time from 120 to 20 Seconds and reduced the error roughly by a factor of two. Small style tips: 

Whether that is easier to understand than your version is up for discussion, but it should be a little more efficient. can be simplified by using an STL algorithm: 

The only thing you share among the codes is just define it as an atomic (). Even Better: Don't share anything: Let each task use it's own hit counter and sum them up at the end (easiest way to do this would be to use std::async). Create and seed a separate random number engine for each thread 

I agree that your code runs in \$O(n)\$ time and \$O(1)\$ space complexity, but the issue I have is that you do in-place modification of the list..... and thus a "processed" list is no longer the same list as it started as. This makes the function useless for most practical purposes. A list that returns "true" on one call, will likely not return "true" on the second call. A compromise solution would be to restore the list linking after reversing the second half, but your method will still not be reentrant - even though it would be more convenient to use. In other words, you are using the list itself as a place to store temporary "state", and that list is not entirely contained in your function. This is as bad, or worse, than using global variables. In a real interview I would challenge the requirement to have the \$O(1)\$ space, and suggest that \$O(n)\$ space is an acceptable compromise - or that a double-linked list is a better data structure to contain this problem. 

A final remark: although, you said error checking is not necessary, I'd probably at least put an assert into place, that checks that the indices in p don't exceed the size of the list you want to print elements from. 

In response to the comment about multithreading: You can (more or less) trivially parallelize by letting each thread generate the new cells for a slice of the world (e.g. a quarter of the rows on a 4-Core machine). There are many parallel loop implementations out there that can make that Task even easier. Obviously this is only sensible for very large grids. 

For some time it has been bothering me that there is apparently no way to directly initialize variables from input streams (something like ) My solution is this: 

As mentioned before, I'd replace the class member with a local in and pass the array as a const ref parameter to . This gets rid of the mutable problem and might even increase performance. I'd write the function a little different: