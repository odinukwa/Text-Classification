If you are running a regression analysis I would say you should look first at p-values to check if the explanatory variables you added make sense. I mean if you have a hypothesis about a relationship among two variables and you find the explanatory one not significant (large p-value) I would check for possible mistakes or alternative explanations. It makes sense to have a look at $R^2$ if you are comparing two different specification, it does not really make sense looking at it alone. I have seen many papers, have a look at Nunn, Wantcheckon, (2011) as an example, which have been published on top journals (AER in this case) even with $R^2$ around 16%, not really an high value. 

In a New Keynesian model, under the assumption of sticky prices, we need to express the monetary policy through an equation in order to close the model made of New-Keynesian Phillips curve and dynamic IS curve. I've read that an easy choice is to use the so called Taylor rule, which express the interest rate as a function of inflation (and possibly a random component). But, I've read that it is a suboptimal choice because it is something exogenous, whereas if we endogenously compute the optimal monetary policy we can reach a better result. My question is why using a Taylor rule when we know it is not optimal to do that? 

Deciding on whether to use monthly,quarterly or yearly data depends on over what period you wish to investigate for potential policy intervention. The term costs and benefits solely depends on what type of data you are looking at. If you want to figure out if the crime rate that is currently being experienced by a given city is normal currently, yearly data is probably not the best for investigating such phenomenon. Quarterly or monthly data is probably better because controls for seasonality can be applied, however for yearly data you cant implement seasonal dummies because there is no rationale for doing so. On the other hand,recall the more often you sample macroeconomic data the "noisier" it gets, so sampling more often than a monthly basis can add unnecessary noise which can make your data more difficult to interpret. 

Im looking for some resources on product pricing and other pricing methods commonly applied by price analyst's. If anyone has a book or article to recommend i'd appreciate it. 

Hotelling's lemma is stated as: $$\frac{\partial \pi}{\partial p}=y$$ knowing however that on the more basic level, output $y$ is determined by the input(s) $x(p,w)$,let the profit function be defined as: $$\pi=py(x(p,w))-wx(p,w)$$ taking the derivative with respect to $p$ $$\frac{\partial\pi}{\partial p}=y(x(p,w))+p\frac{\partial y(x(p,w))}{\partial x(p,w)}\frac{\partial x(p,w)}{\partial p}-w \frac{\partial x(p,w)}{\partial p}$$ Wouldn't this be a more accurate definition of hotelling's lemma? I'm speculating considering some of the critsisim I read on hotelling's lemma in applied work. Namely: Duality, Optimization, and Microeconomic Theory: Pitfalls for the Applied Researcher 

While I was studying, I stuck into a great debate between what is called "modern macro" and Keynesian macro with a lot of interesting and actual insights. I have already read about "classical economics", I mean Smith, Ricardo and so on but I did not succeed in finding a book/paper talking about the actual debate and its roots. Can you please suggest me some references in order to better understand the evolution of economic thought in the XX century and to make my own idea about the actual debate going on? 

I am a bit confused about the concept of natural real interest rate. I've read that it is the level of real interest rate consistent with the output being at its potential or natural level and with the inflation being static. Is that true? Furthermore, I do not understand how natural real interest rate is able to affect output and natural level of output (then, the output gap) in the usual New Keynesian framework. I mean the dynamic is curve is defined as \begin{gather} x_t=E_t\{x_{t+1}\}-\frac{1}{\sigma}\{i_t-E_t\{\pi_{t+1}\}-r^n_{t}\} \end{gather} where $x_t=y_t-y^n_t$, i.e. the output gap and $r^n_{t}$ is the natural real interest rate. ($\frac{1}{\sigma}$ comes from a CRRA household utility with elasticity $\sigma$). Thus it seems that an increase in the natural real interest rate leads to an increase in current output gap, but how is this true? Does it mean that natural level of output increases more than output? 

Where the property of "rational expectations" is defined as the true expected value of $X_t$ is equal to the markets expected value of $X_t$. Mathematically written as: $$\mathbb{E}(X_{t}|\phi_{t-1})=\mathbb{E}_m(X_t|\phi_{t-1})$$ $$\mathbb{E}(X_{t}-\mathbb{E}_m(X_t)|\phi_{t-1})=0$$ If rational expectations hold, we should observe when expectations are taken: $$y_t=\tilde{y}_t$$ that is $y_t$ should always be in equilibrium/ be forecasted based on its equilibrium values/growth process (providing rationale for the use of Univariate models in economics). My Question: Are the use of expectations augmented models useful for forecasting or is it just a way to explain forecast error? 

In Microeconomics producer surplus is equivalent to profits. However getting a tangible definition of consumer surplus has been difficult for me to ponder. What is the practical use of knowing consumer surplus and what does it tell us? 

It seems like you are talking about the Volunteer sector . in the UK particularly NVCO reports in its 2012 almanac: 

In order to understand how use of ARIMA models in Econometrics is a valid way to forecast economic variables, we must understand models which considers the case of for rational expectations (other wise referred to as efficient markets). your standard efficient markets model is: $$y_t=\tilde{y}_t+\sum_{i=0}^N\beta_i(X_{t-i}-X_{t-i}^e)+\epsilon_t$$ where: 

Yes, I would say so. If there is a stable increase in technological progress and productivity over time, the efficiency of the work force would increase, leading to current goods being produced more efficiently. This opens up space for new, higher-quality goods and services to be introduced into the market, which would undoubtedly grow the economy and likely increase consumption per capita. It seems unlikely to me, however, that such an economy would be able to maintain a fixed population in the long run. There would likely be an increase in the standard of living and life expectancy of the population. 

I think you're misreading what Sala wrote. The first sentence in the image you linked is just saying that in the worlds where either Case 1 or Case 2 occurs, the response of $b_t$ to a shock in $s_t$ allows us to differentiate between Ricardian and non-Ricardian regimes since there are no identification issues. In other words, if either the Case 1 inequalities or the Case 2 inequalities hold, then we can be confident that we have identified a non-Ricardian regime from a Ricardian regime. According to Sala, it seems that we cannot as easily identify Ricardian regimes from non-Ricardian regimes in Case 3 due to identification issues related to co-movements in real debt. 

Most microeconomics problems follow this format: Though leaving out some minor details, if you do enough microeconomics practice sets the problems end up looking the same after a while. This is what I got to share. Production/Utility functions There are three main types of utility/production functions you will be exposed to in an intermediate microeconomics course1. They are: 

As for the second point $Q_d$ is $Q$ because we can only have a single quantity supplied and demanded in equilibrium. 

It would appear that a staff fridge is a capital expenditure based on the above criteria because it contributes to maintaining the firms scope of operations. 

Ive been doing some superficial reading on Feldman-Mahalanobis Model and have been wondering what other equations and "brand name" models that have been prodouced by marxist economists? What other mathematical Marxian models are out there? 

These questions are important because it allows you to build a demand curve using simple linear regression. $$p=\beta_0+\beta_1 q+\epsilon$$ where $p$ is price and $q$ is the amount of product X. Using this framework you can obtain appropriate data from your survey for calculating demand for a given product. Hope this helps. 

I am trying to study the effects of a policy on educational attainment of individuals (years of schooling, primary/secondary school completion, literacy). Since the policy starts in a specific year I decided to use an RDD using birth year as running variable. The problem is that my sample is made of 5 different countries in which the policy has been implemented in 5 different years. Am I able to pool the effect of the policy across countries? Because if I build a unique running variable as being 0 for each cutoff year I get individuals born in e.g. 1994 having running variable both 0, -2, +3 depending on the country of origin. How can I deal with this issue? Should I run a RD for each country alone? 

I am working in a New Keynesian context so that the Phillips curve is usually specified as follows \begin{gather} \pi_t=\beta E_t\pi_{t+1}+\kappa x_t \end{gather} where $\beta$ is the discount factor, $\kappa$ is the slope of the curve depending negatively on the degree of price stickiness in the economy and $x_t=y_t-y^N_t$, with $y^N_t$ is the natural (potential) level of output What is driving me crazy is if this curve, specified as above, still make sense when we assume prices are fully flexible. I would say no, because in a flexible price context, the output gap would be zero and the firms would optimize in a static fashion (no need of taking into account expectations of future inflation). But, I have no idea about how to "transform" the model in this direction. 

The classic formula for where a monopolist produces is where marginal revenue equals marginal cost. Is there a similar formula for a monsopsonist? 

In basic intertemporal models the general assumption is that the objective utility function does not change. mathematically it makes the model simple to compute, however it does not reflect the changes in preferences over time. However, if we do allow the individuals utility function to change over time in our model, does this not violate the requirements for a rational consumer ? How do we model an individual with changing preferences over time and is it economically sound to do so? 

I'm currently reading up on matching models in terms of their ability to describe frictional unemployment, they generally follow a cobb-douglas form. $$M(u,v)=m=\mu u^\alpha v^{1-\alpha}$$ Where $M(u,v)$ or $m$ is the number of employed, $u$ is the number of unemployed, $v$ is the number of job vacancies, $\mu$ is a constant and $0<\alpha<1$. moving around the formula we obtain vacancy rate. $$v=\left(\frac{m}{\mu u^\alpha}\right)^{\frac{1}{1-\alpha}}$$ Economterically estimating job vacancy would seem to be much more difficult for countries which do not have a history of report it.This is mainly due to omitted variable bais, which would skew our estimates for $\alpha$. How does one estimate job vacancy in countries that only report employment and unemployment? 

Assuming a firm is a perfect competitor in input markets, the long-run average cost curve, which traces out the minimums of short-run average cost curves, can be used to characterize economies and diseconomies of scale for a firm. This is definitely a practical concept in business and IO. In an industry where the long-run average cost curve is always decreasing, a natural monopoly will tend to emerge due to the increasing cost-efficiency of larger firms. In a monopsony, the employing firm's average labor cost curve is equal to the supply of labor in the labor market. The marginal cost curve lies above the supply curve in this market because the firm's market power allows it to expressly set wages as a function of the quantity of labor. One reason this is practical is that it offers a potential theoretical explanation of why we do not see significant disemployment effects, or may even see an increase in employment, from establishing minimum wages in particular labor markets. 

The question as posed doesn't make sense to me. An increase in the market interest rate will reduce the price of current bond holdings precisely because they become less attractive since there are now more profitable alternatives in the market. Market forces will lower the price of the bonds in response to the increase in expected future coupon streams from these alternatives. 

Assuming that $W$ is wage and $L$ is labor, I would say this is a labor supply-demand graph. TD stand for demand and S for supply. The graph shows a positive shift in labor supply, i.e. labor offered by workers, leading to an increase in $L$ and a decrease of $W$ due to the excess of supply. The shift in labor supply can be caused by a variety of shocks as a preference shock which values more labor, a change in non-labor income, etc (look here for explanations) 

Mere googling leads me to find a bunch of references about elasticity of marginal utility. Here Professor Acemoglu defines the elasticity of marginal utility as the inverse of the intertemporal elasticity of substitution (pagg. 17-18). Here you can find a question analogous to yours together with an answer explained in an easier way than Acemoglu's lecture. If you are interested in something more empirical, have a look here: it is a paper by David Evans about the empirical estimation of elasticity of marginal utility in OECD countries. Hope this is enough. If you have other questions, please ask 

There seems to be a lot of misconceptions regarding the use of technology in economics. Its important to remember a two points. 1. Modern economic theory is mostly, just a branch of Applied Math Sure there are lots of fundamental philosophical concepts underlying the economics as a social science, however most practical problems require some calculus or linear algebra. 2. Economists test theories all the time using statistics. Some people don't know how data driven economics is. The utilization of Vector Auto Regressive Models (VAR),Vector Error Correction Models (VECM) and Impulse Response Functions in Macroeconomics tests is common practice. Central Banks use these methods and are constantly testing economic theories all the time. Answering the question: "What level of fiscal stimulus is better for a specific country?" has already been considering these methods for a while and are not a result of the big data revolution. Hope this helps 

However I am yet to find an open source document which explains the derivation of such a law. If anyone knows of a source Id appreciate it. 

Price discrimination is when a firm charges different prices for a homogeneous product to different consumers. In this example we see no such discrimination among consumers. This is just a case where there is competition between two firms.