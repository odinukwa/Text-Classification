Why are you using a global? There seems to be no need for it, and in general it's something to avoid. Why not factor out the common stuff? In your main loop you have a bunch of if cases which all start in the same way and then all call methods which are very similar. If you start by checking that it's a valid input you could pull out the calls to and and even the loop . 

Why add mouse listeners after the game is over? As a corollary to Josay's comment about , you can rewrite as , which is more idiomatic. A point specifically on game implementation: your timing loop is slightly off. You're going to get a bit under 50fps, but without much consistency. If you want a smooth game you should time how long things take and then take that into account. Using nanosecond timing for accuracy, 

If the supplied username is such that is not a no-op, the check for an existing user and the insertion of the user use different usernames. This is an important bug. Quite how important depends on things you haven't shown us, in particular on the database schema. Given the current mix of database access techniques, you should ditch the one which requires you to escape things yourself (dangerous, because it's easy to forget when you change the code) and use prepared statements for everything. 

Good comments make code more maintainable. I had to reverse engineer what this code was doing, when a few comments could have made it clear. 

Here's one thing I don't understand because there isn't enough context given: why on Earth is the return type of the same as the argument type? If you have the parsed instance already, can't you just return it? If not, shouldn't the argument just be the ? 

I'm afraid that you are very wrong. The code is performing \$O(n)\$ arithmetical operations on s, but an arithmetical operation on a is not \$O(1)\$. The fundamental problem is this: 

Favour composition over inheritance. You don't necessarily need 15 classes to implement the 15 interfaces, but if you split them into logical groups and have one class per group it should make it easier to understand the overall structure, and given the number of empty methods I wouldn't be entirely surprised if one or two of the interfaces turn out to be unnecessary. 

is used once, so I personally would inline it. However, this is a matter of taste, and I wouldn't be surprised if someone else has previously given you the opposite feedback. What I can say is that the code is consistent about always pulling out these intermediate values, and consistency is good, so well done for that. 

One possible improvement would be to observe that you require to be non-null (otherwise throws a ) and so the constructor should enforce that: 

This takes \$O(n^2)\$ time. There are \$O(n \lg n)\$ algorithms to do it, so since you say that performance is a concern you probably want to revisit this method. 

In my opinion the overhead of pre-calculating a value which won't be returned until the next invocation of is a trivial cost to pay for the simplification. 

There's a lot of shared code between the five HTTP action methods. I would be tempted to factor out a private method 

Is that necessary? It might be (again, blind leading the blind), but the name suggests that's it's more intended for cases where you want to modify some of the current buffer without modifying it all. Given that you're updating every pixel, it may be unnecessary overhead. Something funny seems to have happened to the indentation here. This is a micro-optimisation which may be premature, but since the point of iterating over first is to get good cache locality, I would take advantage and remove the multiplication: 

Check out first , and then for ways to simplify the memoisation - although note that has a subtlety in that it doesn't like as an argument type. 

What other possibilities are there? Shouldn't that just be an ? Why instead of ? Pick a style for use of whitespace and stick with it. 

This doesn't do much, so if it's the bottleneck it must be because you're calling it a lot. The first thing to do is to look at the calling pattern. If there are lots of calls with the same value of then you may be able to calculate and once rather than each time; you may even be able to cache and share it between lots of calls with the same and . On the level of microoptimisation, is mathematically equal to and is mathematically equal to ; I don't see a numerical reason that pulling that out would hurt, and it might shave a couple of cycles off. Then is which is another common subexpression. There's potentially another algebraic tweak: could be refactored by including that extra product in the method: 

First things first: there's an out-by-one bug in your code, which made me suspect an out-by-one bug in mine until I tracked it down: 

I know nothing about Processing, but this looked suspicious to me, so I went looking for the maths functions in question. I presume it's e.g. 

Same comment as before - although it's because there's duplicated code, so arguably should be initialised as for DRYness. In addition, 

There are seven chunks of code dealing with seven values of token which are virtually identical. DRY: use a loop. 

What's going on here? My best guess would be that you're mixing tabs and spaces with a tabstop of 8. Be consistent: tabs or spaces. Changing the tabstop shouldn't break the formatting. Names 

This confused me. Normally if a loop has a guard condition which compares the loop variable to another value, changing the other value is a "clever" way of doing ; sometimes it's genuinely clever as a way of maintaining a complex invariant (and should typically have a comment explaining what the invariant is). But when I looked to see why changes inside the loop, I couldn't find a reason. In fact, I don't see a reason for calling more than once in the entire program. If you delete one digit from a prime with digits, you get a number with digits. 

occurs twice, and by pulling it out to a separate method you would both ensure consistency and reduce the noise which makes it harder to see the core of the insertion. (Also, the error message doesn't make sense to me: the SQL checks that the table exists, so why do you think that an exception would be caused by the table not existing?) The SQL lines are rather long. I would try using to split them over multiple lines with indentation, because I think that would make them more readable. They would probably also be better pulled out of the method as fields or s. 

Again, a linear removal could be replaced by a swap and a constant time removal. But I wonder whether this actually meets the spec. Rather than removing from the pool entirely, didn't you just want to guarantee that it won't be the first element picked after repopulating the pool? In fact, I'd be inclined to take this further. Suppose we refactor so that is backed by its own field rather than , and that we have an additional field (or field-backed property) . If we replace with then when gets to 0, the pool contains the entire play list in reverse order of when they were last played. Now 

If I supply no command-line arguments, or if I supply an invalid one, the output is That doesn't help me at all with figuring out my mistake. I'd rather have the ! 

However, is the correct type to represent a monetary amount. There's a case to be made for using to comply with the spec and then converting it to . There's also a case to be made that you should talk to the person who set the task and suggest improving the spec. 

I can't suggest concrete changes without rewriting the entire code, but I think it does need to be completely rewritten with a public API and eager enumerations. 

Wouldn't be more useful? You can print to stdout given , but you can't print to anything other than stdout given only . 

One of the great features of Python which I wish more languages had is parallel assignment. I would ditch the temporary variable and expose the parallels between and as 

Fixing the bottleneck Profiling with and an early abort showed that from sympy was accounting for less than 3% of the runtime. The big bottleneck was in itself. Armed with that and a hunch I made the simple change of 

I would be strongly inclined to implement rather than . It's rather ugly to end up with asymmetric , which is what you have here. Consider 

Is the number of rows or ? Yes, they're the same (because the spec says that the matrix is square), but the comments are actively confusing, and it matters because the direction of the antidiagonals depends on whether the first index is the row or the column. 

This can be simplified slightly with a simple algebraic rearrangement to factor out the from the two candidates, since we know that at least one candidate must exist. (Note that by using we also fix something which could be argued to be a bug, unless the spec clearly states that the triangle will never contain negative numbers). I agree with TarkaDaal that is slightly more readable. And I would also find it more readable with ternary operators. Bearing in mind the scope change mentioned above, I get: 

Higher level suggestions Looking at the filters it's become clear what the biggest speed improvement would be. There's a maximum permitted major axis; once you're looking for possible edge points, there's a constraint that every point must be inside the circle which has and as its diameter. Rather than scanning every single edge pixel to see whether it meets those criteria, you should find or implement a geometric lookup data structure. It doesn't necessarily have to support circular or semicircular lookups: bounding boxes should be good enough to reduce the points tested considerably. As a first implementation, unless there's suitable library support, I'd try a simple quadtree. 

then I think it would be more self-documenting, and you could change etc. without worrying about breaking it. 

then good IDEs would be able to offer you better auto-completion. This applies to most of the method definitions, and I've just taken that one as an example because it was the first. 

That's a scary magic number. How do you ensure that it's identical to the value used in the later test? How do you know it's big enough? Is there any reason not to use a self-documenting upper bound such as ? 

Note that if you take the final option, it might be worth generating the code with T4 so that you only have to edit one place in the .tt file to fix bugs rather than having to fix them method by method. Further note that although I said this was a tradeoff, strictly speaking your code is buggy: if the original image is in then the conversion to might turn an almost opaque pixel completely opaque. 

Error handling seems somewhat minimal. The delayed enqueue covers some error cases, but there's still potential for the same batch to be processed multiple times if there's an exception in the last page. Have you considered generating and persisting the GUIDs in one phase so that you can detect this case and avoid reprocessing the parts which were successful? 

Elsewhere it's , here it's . Be consistent. only ever contains values and . Ideally it would use a 1-bit integer type (and you could consider writing a basic bitset implementation if it's not in the library). It's certainly wasteful to use . Integer types in C are a mess, which is why was created. This might be controversial, but my opinion is that code written after the year 2000 should use , , , etc. only when required to do so for compatibility with older libraries. The primes will never be negative, so it makes more sense to use unsigned types than signed. Don't reinvent the wheel is unnecessary. With C-99 you could just initialise as to set them all to and reverse the meaning of the mark; with legacy versions of C you could use to set them all to . Check your edge conditions 

This would mean that would need to be reworked to use objects, so it might as well be refactored into . There's an additional opportunity there to use the same approach as in : instead of sticking everything in one array and having to do tests like 

I'm not really a Python programmer so I'm not sure how Pythonic it is, but to me this overloading is a code smell. I would prefer to split out one function which takes just the line and another which does the real work. Also, what is ? I managed to figure it out by reverse engineering, but a short comment would have helped a lot. 

You seem to have reverse engineered a very different spec to me. I'm pretty sure that there are inputs for which the subsets should have more than two elements. If my understanding of the spec is correct, there should be a phase which gathers the input strings into equivalence classes and then another phase which calculates a Cartesian product of all of the equivalence classes. 

The best way to do that from the point of view of 1) self-documenting code; 2) not accidentally breaking it in maintenance is 

This is the biggest problem, although for your typical use case it might be relatively minor because it doesn't sound like this iterator is going to be a bottleneck. Removing a random element from a list takes \$O(n)\$ time. But since you don't care about the order of the elements in the list, you could copy the last element to position and then delete the last element in \$O(1)\$ time. 

This is unnecessarily complicated, partly because of the scope issues mentioned already by user158037, but also because it doesn't take full advantage of the ability to initialise a variable, or of the available operators. 

seems like a specialisation. Is the reason that you haven't made a version which takes a general YAGNI? There are a number of options here: 

Why loop down? If you loop up then you get the platform-independence for free, and also you loop fewer times when is small. Obviously the loop invariant would change, but it would be closer to school long multiplication and so might also be more maintainable. 

When I compile this I get a warning. Generally the idea of a constructor is to construct, not to implement the logic of an entire program. 

The name is somewhat opaque: carrier?! The implementation is also somewhat hacky. As far as I can tell without executing to double-check, this is using a list comprehension purely to iterate and produce side effects. Ugh. 

Finally, some debatable points of style. I think it's quite unusual to use , , instead of the aliases , , . And it's fairly conventional that a method (or property) which tests a condition and returns a should have a name beginning : here . 

In terms of the previous , we have ; that can be simplified exactly to , and using integer arithmetic to just 

However, you're on the right lines. Assuming that you want (or at least don't mind) to return each combination in ascending order, the way that I find intuitive to think about it is as a set of nested loops: 

Once your code works, given that it's Python you should run it through an automated PEP8 checker. It should be easy to find one online. 

On the subject of names: tells me the type, but what I care about is the meaning. For Eratosthenes that's easy: a means that the index is a prime, and a means that it's a composite number, so is a good name. For Sundaram the exact interpretation is a bit trickier, but would still work. 

Again, this can be memoised. It's also possible to trade off memory for speed by splitting up the multinomial as $$\begin{eqnarray}T(\lambda) & = & \binom{m}{a_1, \ldots, a_k} r(1)^{a_1} \ldots r(k)^{a_k} \\ A(n, s) & = & \sum_{\lambda\vdash s} \binom{n}{m} T(\lambda)\end{eqnarray}$$ where the sum is over all partitions of \$s\$, \$\lambda = 1^{a_1} 2^{a_2} \ldots k^{a_k}\$ in the frequency representation, and \$m = \sum_i a_i\$. \$T(\lambda)\$ can be memoised, but also it can be calculated incrementally by using a more complicated object to store the partitions instead of just an array of the parts: 

You don't need to loop over four variables (\$N^4\$ tuples) to solve \$a^4 + b^4 + c^4 = d^4\$. As Loki Astari has already pointed out, given \$a,b,c\$ you just need to test \$a^4 + b^4 + c^4\$ to see whether it is a fourth power: so \$N^3\$ tuples times a lookup (binary chop is a reasonable suggestion). Combined with Dannnno's suggestion in a comment on the question that without loss of generality \$a \le b \le c\$ you can reduce that further to approximately \$\frac{1}{6}N^3\$ tuples. But actually you can take the loop reduction a step further: rewrite the equation as \$a^4 + b^4 = d^4 - c^4\$ (with \$c < d\$). Then (at an abstract level) you can write two parallel loops, one over \$(a, b)\$ and the other over \$(c, d)\$, processing a total of about \$N^2\$ tuples. The implementation detail is that \$N\$ is too large to store the tuples from one of the loops. A standard approach to get around that is to generate the two sequences in order using priority queues. To keep it simple, I would initialise the ab queue with \$(a, a)\$ for each \$1 \le a \le N\$, and the cd queue with \$(d-1, d)\$ for each \$2 \le d \le N\$. Then the main loop is (Pythonesque pseudocode):