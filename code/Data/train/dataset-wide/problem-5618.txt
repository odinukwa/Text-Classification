Can it be? Of course! Counting falls under the sphere of skills and knowledge that we typically call "mathematics". A number of animals have rudimentary skills of this sort (even pigeons; this is at least estimation-of-number if not counting-one-two-three, which if accurate falls under mathematics (cardinality of small sets)). You can even implement it with biochemistry (hence plants); you might not want it call that "intelligence" though just because it's not implemented with neurons but with cellular processes. Do we want to use the term mathematical intelligence this way? That's a more complex and subjective question. If you're interested in highly reflective and axomatized mathematics (e.g. ZFC), probably not. In that case you probably don't want to call it mathematical intelligence when people count, add, etc., either; abstract axomatic mathematics is rather different, in terms of the type of thinking required, than formulaic skills like counting or long division. 

Humans are the only animal (thus far) with the potential to enable life (as evolved on Earth anyway) to escape the death of our sun. 

There are objective things that look like ethics, such as "non-extinction-promoting social behaviors for Homo sapiens" and "generalization of intuitive morality to large-group behavior such that individual intuitive morality is maximally fulfilled". The problem is mostly not that there is a lack of things which can be said objectively, but that people want more than reality can support when it comes to ethics. (Free will is similar in this regard.) So if you want ethics to back up your revulsion at something that is supposed to be reviled in our society, it's rather hit or miss objectively. If you want it to make sure humans are around in another 10k or 100k years, and are reasonably content in the meantime, you've got objectivity galore to play with. (Not that we know the answers (yet), but we can ask the questions.) 

is apparently wrong, at least for some people. The phenomenon of lucid dreaming is a counterexample. Furthermore, it suggests that at least under some circumstances, both you-while-dreaming and you-while-awake can agree on what is a dream. (Anecdotally, I can also attest that it was very effective at letting me avoid recurring nightmares when I was a child.) 

The consolations of the atheist, according to Christian friends of mine, are self-importance (hubris) and freedom (from ultimate responsibility, from feeling the weight of sin). I had a rather lengthy conversation (about ten years ago) with a Protestant and a Catholic apologist and they both seemed to make this point, though the Protestant was much more forceful. I'm not sure whether this was personality or theology. To expand a little bit more: to admit that God exists is (they claimed) to admit that one should hold oneself inferior to Him; one's own self-worth, importance, glory, etc., is so utterly insignificant compared to His that atheists can be driven by their own vanity to declare that he must not exist. They also viewed atheism as the ultimate escape-from-responsibility move: since everyone sins, and any sin at all is punishable by death, the only way to escape the conclusion that one deserves death (aside from receiving Jesus' forgiveness) is to deny that God is there at all. But because God is the source of all morality (direct quote from someone else: "Why don't I steal or murder or all the rest--it's not because I love people so much, it's because God says it's wrong.") once you do away with him you never really need to feel or be responsible for anything--you can do whatever you can get away with and pretend to yourself that it's okay. These points are not universal consolations, as they are couched strongly in Christian theology, but I was impressed that they were agreed upon by Catholic and Protestant. (Fair warning, though: sample size was one each, and they were friends, so they may not have even been independent samples (though they did receive different training in apologetics).) Also, they seem to be plausible prima facie, and I have had some atheist friends essentially confirm at least the second (i.e. what they say is logically equivalent to "I like X and the Bible says it's wrong, so I can't believe in God"). 

What is wrong with counting only economic value? The error would be to assume that economic value is synonymous with what you can get people or corporations to pay for. There are many areas where there is great value but because of structure or timescale you can't get adequate (or any) payment--preserving a common resource or advanced education for all are two examples. For instance, quite a few Asian countries have targeted science and technology education as an engine for economic growth (Singapore, South Korea, Japan, China, etc.). Funding for public arts tends to increase the livability of places, attract better workers, etc., though I don't think this is as carefully studied. If you allow long-term economic impact and indirect effects, it's not so clear to me that these things are not: legitimately in the public good, measurably so, and thus poor decisions can be detected and those making them can be removed if necessary. There may be other ways around the problem, but are they needed? 

From what I have seen, deep within quantum mechanics lies the source of so much sloppy thinking and confusion among people who don't know quantum mechanics (and occasionally even among those who do), that I think it's a rich source of fallacies and misunderstandings that can distract philosophers from worthwhile inquiry. Most of this seems to arise from looking at quantum mechanics and thinking, "!@#$!#, that's weird and unintuitive!", and then looking at something else and thinking, "(*%!!%, that's weird and unintuitive!", and then making the unfounded jump "Hey, they must be the same thing!!" If your friend has a specific well-reasoned argument about how, for example, an assumption made in philosophy is contradicted by particular experiments in quantum mechanics, you could post it here and hope that some people who are well-versed in both physics and philosophy can evaluate his arguments. Otherwise, I think the default stance should be considerable skepticism. 

I'm not sure it was even in the primate lineage first, though you may wonder specifically about the primate lineage. In particular, magpies can pass the mirror test, something which only seems like it could be possible if they have self-awareness of a sort. It would not surprise me if, for instance, some species of dinosaur could have passed the mirror test in the Cretaceous. Also, there are plenty of anecdotes about dogs misbehaving and looking sheepish (or behaving and not looking sheepish) that suggest that "primal instinct" is too simplistic a way to view animal behavior. These sorts of self-awareness are not as deep as the self-consciousness you're describing (i.e. being aware that one is having one's own thoughts), but I don't see a difference in kind between that and recognizing self visually: it's the same kind of capacity, just via a different sensory modality (internal instead of external). The internal awareness is really hard to measure, though, so it's best to use external forms as a proxy for what is likely. Gaining self-consciousness was almost surely a gradual thing, given the scattering of self-aware behavior across all sorts of animals with complex brains. Probably self-awareness was something which in some animals was only very intermittently noticed and the consequences only dimly grasped, and over time some lineages (including ours) gathered a more continual and deeper perspective on it. As with any other trait, even an abrupt change here would not alone serve to generate a different biological species unless the self-aware animals refused to mate with non-self-aware ones. 

Are siblings' sex correlated to each other at all? What is the (uncorrelated) sex ratio in humans (males/females)? What is the rate of atypical physiological sexual morphology (hermaphrodite, etc.). 

This sort of thought experiment boils down to an empirical matter: whether all choices made by people are motivated by the same reward system that delivers feelings of happiness and/or regret, and whether there are any rational actions aside from going along (on some time scale) with whatever this reward system decides is right. Looking at it this way, there are two obvious ways that an X could act as you've described. (1) X is not motivated entirely by that reward system. Thus, depending on the weighting between that system and whatever other motivational state he has, it could be "rational" to go along with the other motivation. Note that this is not entirely implausible given the relative commonality of extraordinary actions like self-sacrifice for offspring, both among humans and other animals. (2) X has reason to believe (maybe he's read Hume) that just because said reward system is pulling his strings, it doesn't follow that he should blindly go along with it. Instead, he reasons that for whatever reason his emotional state is not aligned with what is rational, and somehow manages to opt for the latter. (You may need touches of (1) for this to even be possible.) This is also not entirely implausible: one might understand that murder is wrong and even when losing one's sanity and feeling desires to murder (with no sense that you'd feel remorse) nonetheless reason that it is rational to resist these urges. 

You've mixed a number of unrelated things together as "non-empirical phenomena", and the answers are different for each one, much like the answers would be different for how law deals with "non-larceny". When it comes to mathematical proofs, you start off knowing that you can't know empirically whether the Riemann hypothesis is true. So you can gather evidence about where it holds, and reason or experiment or analyze data based on that. But it's just science at that point--it's going the wrong way, in a sense, from a more reliable way to know things (in a very limited domain) to a less reliable one. Qualia are phenomena that require some sort of explanation, just as our ability to see blue does. Science can use normal evidence-based approaches (e.g. Popperian falsification). It's worked reasonably well for neuroscience so far, though we know that we don't know anywhere near enough about the workings of brains to nail down what qualia are and how they are caused. So there isn't anything to see there--but you can certainly do empirical studies to verify that the phenomenon (that people report qualia) is true! Counterfactuals are different yet again, having to do more with the relationship between models of reality and reality than any particular empirical study. It's not clear to me that the interesting cognitive science thing about counterfactuals is that they don't correspond to reality because nothing needs to correspond to reality in the brain (what is remarkable is that many things do!). And so it's not clear to me that there is even a phenomenon there that you're studying. The bottom line, though, is that there is no particularly good reason, either from first principles or empirically, that you can build a robust base of knowledge on top of non-reproducible, non-quantifiable phenomena. Even if we adopt the most radical interpretation of Feyerabend's "anything goes" approach to the philosophy of science, it was "anything goes that works", and we haven't any indication that it works. So while I am not sufficiently familiar with the tenets of naturalized epistemology to be sure about what they say, the answer from those fields where naturalized epistemology is supposed to draw inspiration is "no". 

All you need is a system that is not in thermal equilibrium (which is practically any macroscopic system), or equivalently a system into which you can inject a reasonable amount of entropy. This process is termed quantum decoherence. The mathematics is nontrivial, but the bottom line is that it's essentially a statistical property, and as such a single other particle is typically insufficient while lots of particles are typically sufficient. I'm not sure how to explain it in more detail than this without an assumption of way more knowledge of physics. (The Wikipedia article does a decent job (as usual), if you have adequate background.) 

The question is based on a mistaken assumption that scientific theories are "proven". They instead--to reach the level of "theory" rather than "hypothesis" or "speculation"--are heavily supported by relevant evidence. In particular, one expects both good direct evidence and a demonstration that every other somewhat plausible hypothesis fails to match at least some important fraction of that evidence. I recommend you read any decent account of the workings of the scientific method--Popper is perfectly fine for these purposes, for instance. Anyway, all you need to have a God-existence-theory is really good evidence that God exists. For example, if we had really good evidence that God is infallible, honest, is good at and does communicate clearly, and that God wrote (or caused to be written) a faithfully-transcribed book, then if we get our hands on that book and read: