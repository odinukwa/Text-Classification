I share your concern about the application of material implication. It is a useful connective in mathematics or other highly mathematical branches of science but it does little to capture what we mean by conditionals in natural languages. This is why there are so many so-called paradoxes of material implication, which are not really paradoxes at all, just examples of where material implication does not adequately account for ordinary usage. To take your three examples... 

To understand this, it helps to be clear about the terminology. The term "chances" is usually used to mean a physical interpretation of probabilities. The idea is that a symmetrical, unbiased coin has a physical chance of landing heads with a probability of 0.5, or that an urn containing 1 million red marbles, 1 million blue and 1 million green, has a physical probability that a marble drawn at random will have a probability of 1/3 of being red. The first thing to note here is that this is only one way of understanding probabilities: on an epistemic account there are no chances, and what we call probabilities are statements about how much information we possess. I'll leave that thought to one side for a moment and proceed with chances, since the author of the article you reference believes in them. The important question is, if I don't have any direct access to the physical chances, i.e. I can't test the symmetry of the coin or count all the marbles in the urn, and the only information I have is gleaned from performing sampling experiments and observing the frequencies in the sample, what inferential relationship is there between the physical chances and the observed frequencies of the samples? What Bernoulli showed is that one can draw an inference from the chances to the observed frequencies: this is the law of large numbers, and it implies that if you keep tossing the coin, the long run frequency of the sample result will converge to the physical chance. Or if you keep drawing marbles from the urn, the long run frequency of your sample will converge to the actual proportions of the marbles in the urn. Note that this is a convergence result only: it doesn't mean that your sample frequency must agree with the chances, only that it will tend towards doing so in the long run. What Bernoulli doesn't tell you is how to perform the inverse inference from information about the observed frequencies of the sample to information about the chances. This is a very common problem in real life: often we want to know something about a system or a population, perhaps because we want to make future predictions about it, but we only have access to samples of data. Solving this problem is much more problematic and there is no perfect way to do it, or even a general consensus about how to go about it. Fisher held that the best approach is to make hypotheses about the chances, design experiments to test them, and reject the hypotheses if the test results are significant. Neyman and Pearson used the approach of defining type 1 and type 2 errors and of approaching the values of chances in terms of false positive and false negative error rates. Bayesians use Bayes' rule by specifying prior probability distributions and using the data to update those distributions. Likelihoodists take two rival hypotheses and calculate a likelihood ratio that allows one to say which hypothesis is confirmed relative to the other. 

Logic and computability are indeed closely related. They are not identical however. At the least, computations take place over time and require a computing engine of some kind. Proofs are often thought of as abstract structures, though any instance of a proof will require some physical form. The idea that a logic should possess some computable apparatus to qualify as a logic is not as weird as it may sound. It would not exclude classical logic from qualifying. It is a strong requirement though, and might be contested by those who view the semantics of logic as taking primacy over the proof theory. 

In S4 modal logic, nested modalities of the same type collapse, so □□A ↔ □A and ◇◇A ↔ ◇A. In S5 modal logic, all nested modalities collapse to the rightmost one, so □◇A ↔ ◇A, and ◇□A ↔ □A. If you want to be able to say that it is possible for something to be impossible, i.e. ◇□ ¬A, without this collapsing to □¬A, you need to use a modal logic weaker than S5. 

The simplest logical relationships are those in which truth is preserved from premises to conclusion. Reasoning is usually concerned more with grounds, reasons or justification. These can easily part company. For example, any question-begging argument is logically valid because if the premises are true then the conclusion must also be true, but a question-begging argument is not a good way to reason because there is no flow of justification from the premises to the conclusion. Several logics, including classical logic, include the principle of explosion: any proposition is entailed by a contradiction. This is fine as a logical relation, but is hardly a good way to reason. If I discover I have inconsistent beliefs I will not take this as a license to infer anything I wish. In logic we commonly define a theory to be a class of sentences closed under the relation of logical consequence, i.e. it includes a bunch of sentences and every other sentence they entail. Such a thing would be unthinkable when describing a reasoning agent. No human being is logically omniscient. We cannot know all the logical consequences of what we know, and as a corollary we cannot expect to have no inconsistent beliefs. Most logics that are of interest to logicians are monotonic, which is to say that whenever a set of premises entails a given conclusion, adding another arbitrary premise entails the same conclusion. Real human reasoning is seldom like this. We reason all the time on the basis of rules of thumb that we take to work by default because they are usually correct, but which we know may allow for exceptions if some defeating condition arises. "If it looks like a duck, walks like a duck and quacks like a duck then it's a duck" is a pretty good way to reason, though not valid in classical logic. The conclusion does not follow if we add an additional premise that an ornithological expert assures us we are looking at a rare species of goose. Logic typically lacks any kind of epistemic context or background. Logical proofs stand alone and can often be verified by a computer. Reasoning on the other hand takes place against a huge background of knowledge, beliefs and experience. This is why people can agree on the logic of a situation but disagree about the conclusion. If Alice and Bob both believe A is true and you prove to both of them that A entails B, Alice might judge that the truth of B is more plausible than the falsity of A and so infer B, while Bob might judge that the falsity of A is more plausible than the truth of B and infer that A is false. When it comes to reasoning, one person's proof is another person's reductio. 

Well if you don't believe in actual infinities, such as infinite numbers, you are in good company. Gauss, Poincare and Kronecker, to name a few, thought of infinity is nothing more than a kind of useful fiction that allows us to do things with limits. Mathematicians who reject the Cantorian approach to the construction of transfinite numbers are sometimes called finitists. This is a minority view, however. Playing around with transfinite numbers is interesting and useful. There are, for example, more irrational numbers than rational numbers, even within a finite interval such as 0 to 1. How would you express this without recourse to transfinite number theory? 

Does the "may be" indicate an epistemic possibility? I.e. is it saying B may actually be true for all we know, but we're not certain? For example, "If Alice is not in her office, she may have gone home." If so, then the nearest formalism for the conditional is likely a statement of conditional probability such as "P(B | A) > 0" - where probability is interpreted in the Bayesian fashion as a degree of uncertain belief. I suspect that usually when we say "if A is true then B may be true" we mean that B has some significant degree of probability, and is not a mere possibility. So, the zero could be replaced by a larger, possibly non-specific number. This formalism has the major advantage over other formalisms of conditionals that it does a much better of job of capturing what is means for a conditional to be uncertain. "B | A" is not a truth function of A and B, and contrary to what some elementary logic texts suggest, most conditionals in ordinary English are not truth functions. Disproving a conditional of this kind would involve showing that it is in fact highly unlikely that B on the supposition A, or in simple cases, showing that A is true and B false. Does the conditional express a relationship? "If Alice is a smoker, she may get lung cancer" would normally be understood to mean that we think there is some causal connection between smoking and lung cancer. Proving or disproving causal connections is notoriously difficult and typically involves being able to demonstrate the mechanism. A relation may also be evidential rather than causal. Does the conditional express a simple logical possibility? "If Manchester United win their match on Saturday, they may become league champions", seems to express nothing more than that given the rules of the league and the current standing of the teams, a win will put the team in reach of the championship. This might be disproved if you could demonstrate that even with a win, the arithmetic shows they cannot catch the current leaders. Does the conditional express a habit or rule? Sometimes, conditionals are implicitly quantified. For example, "If it snows, the flight may be cancelled" suggests that whenever it snows sometimes the flight is cancelled and sometimes not. Disproving this would be difficult unless you could show that in fact flights are never cancelled during snow. Does the conditional express a physically indeterminate possibility? "If a photon hits this half-silvered mirror it may be reflected." Here we might want to say that even if the photon were not actually reflected, it might have been, i.e. there is (or was) a counterfactual possibility of it happening. Disproving this would require disproving the scientific theory behind the claim.