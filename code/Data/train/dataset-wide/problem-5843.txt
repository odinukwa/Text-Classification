Well, the idea of a directly programmed intelligence, one where each main function of the mind was implemented by a programmer, was common in the 1970's. But while it's nice as a goal to gain better understanding of how e.g. vision processing works, it's wholly impractical as a way to create an intelligence. As already Alan Turing (1)noted in 1948 or so, the most likely way a machine intelligence is created, is the way that a human intelligence is created, namely by growing up and learning – with some basic instincts and abilities in place, of course. So a first answer is that the question as posed doesn't make much sense, because it's very unlikely that a machine intelligence will be of the directly programmed variety, that there will be any programming (except of basic functions such as edge detection in vision processing): I'd guesstimate that it's about as likely as a crocodile emerging up through the asphalt in the street, deftly stealing your wallet, only to be hit by a giant iron hippopotamus accidentally dropped from an airplane passing above. However, running on a digital platform means the possibility of making copies, partly or completely. It means the possibility of trying out things in simulated environments. Not the least it means that explorations of possibilities can be really, really fast. Currently the electronics is some millions times faster than our brain stuff, and that difference increases exponentially, which it's kept on doing since 1965 or so, roughly a doubling every 2 years. So we can expect some really fast evolution as soon as machine intelligences start creating new ones. 

If you want an expression that involves P you can just choose any one before the first simplification where P disappears, or you can construct such as one. E.g. Q ≡ Q ∨ F ≡ Q ∨ P∧¬P. IF you want a symbol for it you'll have to define one, because there's no commonly used symbol. E.g. you can define PβQ ≡ Q, or whatever. 

where is an identifier to be defined if it isn't already, denotes assignment (which creates an identifier if it doesn't exist), on the right hand side evaluates to logical if it doesn't yet exist, denotes logical OR, and denotes a new object, which is the result of the OR-expression if evaluates to . It's also the basis of boolean short-circuit evaluation in a great many programming languages. 

Not quite arbitrary association 2: In pixel based graphics there is an operation that takes an area of one image, and an area of another, and applies an arbitrary bit-level combination specified as a truth table. It was a result of the Smalltalk project at Xerox Parc, where it was identified as one of the crucial elements required to implement a graphical user interface. At that time it was called “bitblt”, short for “bit block transfer”, and e.g. the Windows API has a function, plus a number of variations & extensions. 

The answer that violence is never the answer does have a rich literature behind it; pacifism is not foolish and it does have the virtues of both clarity and consistency. It is also a minority view. More common is the view that the proportional use of violence is justified in defence of self and of others. Consider two cases: 1) I am attempting to stab you in a circumstances where you cannot reasonably expect to be able to run away from the threat. 2) A police officer arrives at the scene of one of the lamentably common "school shootings" to see the perpetrator firing an automatic machine gun at a crowd of students. The perpetrator is over 100m from the police officer. On most views, in (1), you'd be justified in using a level of force against me that a reasonable person would think necessary to neutralize the threat I pose to you as it is reasonable for you to fear that I am attempting to cause you serious harm or death. If and when you have managed to effect a situation where a reasonable person would no longer perceive me to pose a threat (say you broke my arms or rendered me unconscious), no further use of force would be justifiable. On most views, in (2), the police officer would be justified in shooting the perpetrator. By hypothesis, the perpetrator is in the middle of killing other people and is too far away for any other means of stopping that killing to be available to the police officer. Even here, if the police officer has a choice between shooting to kill and shooting to incapacitate the perpetrator, most views would have it that the police officer ought to aim to incapacitate. Of course, in the nature of the circumstance, it might well be that a shot aimed to incapacitate does instead kill. Likewise, if a shot aimed to incapacitate does wound the perpetrator but does not succeed in stopping their efforts to fire into the crowd, most views would have it that the police officer then may shoot to kill, the lesser use of force having manifestly failed to preserve the lives of those the perpetrator is attempting to kill. Common features of both cases are that 1) there is a risk of serious harm to someone, 2) no non-violent method can be reasonably expected to prevent that harm, and 3) the harm threatened is threatened due to the actions of a bad actor. ((3) is intended to distinguish cases like (1) and (2) from ones where Pat's actions pose a serious risk of harm to Sam, but Pat could not have reasonably been expected to foresee that Pat's actions did pose a serious risk of harm.) 

Ten years after he wrote (or spake, it was the Presidential Address delivered before the Sixty-fourth Annual Pacific Division Meeting of the American Philosophical Association in Los Angeles): 

1) I don't recall exactly those experiments, sorry; I only remember reading about it, but no doubt they involve exponentially increasing effects (i.e. chaos, in its mathematical meaning, more informally the butterfly effect) and inspecting ever more fine details. 2) I almost used the acronym SDS, Heinlein's Super Duper Snooper, with a footnote explaining it, but then I thought better of it. 3) Can't leave this without mentioning Charles Stross' “Accelerando” universe and “Glasshouse” novel. 

This is called disjunctive normal form, because it's a disjunction of individual conjunctions of the possible combinations of terms. You do not have to define each such table separately. 

I happen to believe that this concrete instance of the argument form is valid. But I may be wrong – the conclusion is after all in line with my views on the matter, so I may tend to only see that which supports my views. 

In other news, … I find it noteworthy that the notion of practically irreducible complexity is not one of the "two positions" you list, namely (1) the supernatural and (2) the view that some things just can't be understood. If there ever was false dichotomy it must be this, with both branches just childish nonsense. Is it really true that modern adult philosophers in general think one has to choose between the childish nonsense options (1) and (2)? 

1) Mainly section 9 “The cortex as an unorganized machine” of his 1948 technical report “Intelligent Machinery” (the link is to my transcription of photocopies of the original manuscript). 

if it is rephrased as “challenged” then the Wikipedia quote above applies and the answer is a clear yes. However, if you mean whether there is still a challange going on, literally “challenges”, then that depends on what exactly you mean by logical positivism for the present, and I have no answer. Presumably, though, a continued challenge based on some evolution of the concept of logical positivism is not an issue, or else it would surely have been mentioned. 

In the above image the colors are an invention, not a discovery. Different people will maybe choose similar coloring here, but I think it's pretty much an artistic choice. The colors roughly reflect how fast a point in the complex plane will head off to infinity under a certain repeated square-and-add operation, but they depend on a lot of parameters (including how many iterations one deems sufficient to establish the wayward nature of a point), including, of course, some particular color palette. I think this illustrates nicely that the very same mathematical beast can have aspects that are discovered, and aspects that are invented. ;-) 

Let us suppose that a given text is indeed of divine origin and that the language in which it is expressed is a human creation. (Another answer points out that some religious traditions would reject that second assumption.) There seems to me to be no incompatibility in these two assumptions. Let me take your various points in turn: 

This list has a good deal of overlap, too. Metaethics arguably straddles all of the first 3; philosophy of mind overlaps with at least metaphysics, etc. Philosophy of language seems an odd man out, but given its importance in analytic philosophy and that it cannot be comfortably subsumed under any other branch on my list, I'm stuck with the oddity. 

A straw man is a scarecrow. On the false assumption that there is glory to be had in knocking down an adult human being, there is still none at all to be had in knocking down a scarecrow for a scarecrow has no means of fighting back. The straw man fallacy involves ascribing a position to your opponent distinct from and weaker than their actual position, demonstrating that the weak position you have ascribed is unsustainable, and then proceeding as though you had refuted your opponent's actual position. Having focused upon a position weaker than that that your opponent genuinely was advancing, you have attacked a view that has fewer resources to resist your attack than does the actual view on offer. The appropriate response to a straw man fallacy is to point out that the position being attacked is distinct from the position that is purportedly being attacked. 

If we start, as utilitarians do, from the idea that everyone is of equal moral importance, we do need a method of aggregating individual utilities that treats each person's utility outcome for a given action as having equal importance. The simplest mathematical function that achieves this is taking the arithmetical mean. While other procedures are available (for instance, taking the mean of the cubes of utility), the arithmetical mean as simplest has a default presumption in its favour. 

The heuristic that the burden of proof is on the affirmative side of a dispute is intended to be broader than just claims of existence and non-existence. It is also one of a number of different (sometimes conflicting) considerations that go into the determination of the burden of proof. I said 'heuristic' as there is no algorithmic way to determine where the burden of proof lies. Imagine that we observed some phenomenon for which cannot account, say the diminished bee populations. Were I to suggest that the population decline was caused by cell phone transmissions, you might well accept that this is the sort of thing which could conceivably be involved but might still reasonably demand to know why I think this. 'Well, why do you think it isn't cell phone transmissions?' would be a wholly inappropriate reply on my part. As I am offering the positive account, all else being equal, the burden is on me to establish that my account is correct, not upon you to impeach it. Another consideration is initial plausibility. Say that we were to arrive at my apartment and observe that the door frame was splintered, the door was open, all my electronics and other portable valuables were gone. You offer the theory that I have been robbed; I offer the theory that a highly localized meteorological phenomenon tore through my apartment. We both are offering affirmative claims, but since yours is quite plausible and mine is not at all plausible, the burden is on me rather than on you. Indeed, we would reasonably take the inability of proponents to mount a serious case for alternative explanations to count as a reason to accept your account. Neither of these are fool-proof. One can often reformulate a claim to change whether it seems affirmative or negative (often with a transformation that seems less like a cheap trick than the one your offer). And, erroneous beliefs will adversely affect the extent to which our judgments of plausibility are reliable. (It takes a fair bit of knowledge of 20th c. science to find it plausible that the chair on which I sit is made mainly of empty space.) Some conflict between these two considerations can help explain why "all else being equal" is needed. If you have the view that dogs exist and I've the view that they do not, the fact that your claim is affirmative hardly means that the burden of proof is on you; my claim is so implausible that that implausibility swamps the affirmative nature of your claim for purposes of finding where the burden of proof lies. A third consideration is the costs of error on each side. Consider two drugs developed by pharmaceutical firms, one intended to help with acne, the other to help patients with advance terminal cancer. The burden of proof to establish safety of the drugs is higher on the firm that developed the acne medication than it is on the firm with the drug targeting the cancer patient as the cost of error in the acne case is much higher. 

From what I gather, for realists who are especially fond of a good old-fashioned Mathematical Platonism incorporated in their ontology, there seem to be two ways of getting at it. The first seems to be the need for truth-makers for mathematical propositions/truths, hence the positing of mathematical objects as abstract objects which serve as truth-makers. The other route is to marshal the Quine-Putnam Indispensability Argument, or some contemporary variation, and deduce their existence (am I right in thinking this is a deductive argument, or is it an abductive argument? Perhaps their are versions of both) by noting that the existential quantifier is a device for ontological commitment. First of all, am I mistaken in thinking that these represent some of the motivations for adopting/positing Mathematical Platonism? Secondly, are there any other motivations for adopting/positing Mathematical Platonism? 

Lately, I have been reading some of Quine's works on modality. I can't help but feel that many of his pronouncements on modality are wrong/misguided, although pinpointing exactly where is goes wrong is proving rather difficult. For instance, in The Problem of Interpreting Modal Logic and Reference and Modality, he seems to defines necessity as follows: 

As the two other answers suggest (Frank Hubeny's and Elliot Svensson's), there is, perhaps, some slight ambiguity in using the word 'save'. If by save you mean preventing their suffering and death, then one response available to the Christian is countering with a free will defense, most notably elaborated by Alvin Plantinga, which Frank Hubeny alluded to. If instead you mean redeem or extend salvation to, which is the more plausible interpretation given your mention of sin and innocence, then one could deny the presupposition undergirding your question--namely, that God didn't save them. On this interpretation, the Christian might respond by saying, "Given the traditional conception of God as a perfect being which Christians endorse, God is wholly just or fair, so that not extending salvation to such innocent younglings would be unjust and therefore impossible for God to do." This might be deemed a more 'philosophical response', as it doesn't fully appeal to Christian scriptures (it appeals to scriptures insofar as scriptures affirm perfect being theology). Or a Christian might respond by appealing to scripture to explain how exactly one might receive salvation without knowledge of Christ, which Elliot Svensson has nicely outlined for us. 

I am reading Russell's second installment in the series On Meinong's Theory of Complexes and Assumption. Among many things, presentations are discussed a lot in these articles. What exactly do Russell and Meinong mean by presentation; and how does it differ from representation? I have read through most of the SEP article on Meinong, but I haven't yet found a clear explication of the two, leaving me in a more confused state. In fact, the author of the SEP article seems to use them interchangeably, while with Russell's article I got a sense that they were different. Something like: a representation is a type of presentation in which the object exists. Of course, this might be wrong; but, in any case, that still doesn't tell me what a presentation is. The article is pretty technical, introducing a lot of distinctions/concepts, and is very summary (as are most SEP entries that survey a philosopher's career). Meinong seems to imbue a lot of common words with a very technical sense, and the author of the SEP article doesn't give their technical definitions. But I'm just wondering about presentations and representations.