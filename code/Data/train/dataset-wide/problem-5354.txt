i.e. make a world that is indistinguishable in a descriptivist sense, but differ in terms of the identity of objects therein. As far as I can tell, there is nothing ruling this out, so there's nothing ruling out making more general permutations of rigid designators. 

People don't magically disappear from our imaginations when they die. If we valued their thoughts, beliefs, attitudes while they were alive (and even when not immediately present), we will still tend to do so even when they are deceased. We don't need them literally present for them to re-iterate their wisdom; we can remember it, or imagine what they would have said or done. As with most important mental phenomenon, this is a mix of rational and emotional responses -- the continuing feeling of attachment is what keeps our memories of the deceased accessible and salient to our lives. From this view of the phenomenon, we can extract a few things that an AI would need in order to mimic this type of effect: As a minimum requirement, it would need to be able to remember what the now deceased agent (it might be another AI!) did, even better would be a model of what the agent would do. The AI could then incorporate that information into its own cognitive (-ish? for people who deny strong AI) processing. If it has introspective capabilities, it might rate that keeping this information around is valuable (with respect to some goals/measures). Aside, even if the AI could upload the full state of some other agent, a similar effect could still arise due to resource constraints. If the AI is up against its resource constraints, it may not have the ability to have all of the it's "ancestors" knowledge fully loaded. A sensible thing to do would be to index the reasons why the AI would call on a particular ancestor (and use that index to decide when to load its "ancestors"); that index would comprise the analog of the salient memories. 

If standing up a military is ethical in the first place, then as long as the recruiter provides correct and complete information to/from the applicant and does not apply any coercive threats/rewards to the potential recruit, everything is on the up and up (irrespective of whether the recruiter would be able to serve). The other items point out conditions where the likelihood of ethical lapses increase, but don't in themselves make the activity unethical. Consider Unite States Army's oath of enlistment: 

In the context of the linked interview, both Chomsky and his interviewer have an understanding of the term "language" that excludes music from it. To put it as a syllogism: 

This is an answer based on a sensible mathematical formulation. We have some that describes the probability of hitting the target as a function of the size of the target , and bullet . Premise 1 is that the partial derivative of wrt is everywhere. Premise 2 is that the partial derivative of wrt is everywhere. We can express the "scaled down" form for as a parametric equation so now we have (a constant) as we vary . If you compute the total derivative of wrt using this, you'll find everywhere. Therefore, for the straightforward mathematical model, the conclusion follows from the premises. I believe that your the model/intuition mismatch is due to the our implicit idea of aiming inherent in the use of the term "gun" and "target". For example, imagine that the target is moved around between shots, and the shooter is blindfolded -- a situation that does match the constraints of the premises. 

If you're going to have a finite discussion, you'll need to agree on some unfounded assumptions. If this constitutes "having faith" then you're done -- essentially everything in life requires faith in this sense. You can construct an argument by working out from introspection: 

The concept of supervenience seems related to these considerations -- the thermodynamic (statistical) properties of a system supervene upon the microscopic details of the atoms and their interactions. 

therefore, for some levels of discussion, qualia exist. Elaboration There is empirical support for the existence of qualia: my own mental states usually include features like "perceiving red" etc. I suspect that you find the same to hold for your mental states. In addition people in general report about their mental states in a way that is consistent with all of them having qualia. Thus at the common-sense day to day (i.e. pre-theoretic) level, qualia exist. The main question is whether these apparent qualia are in some way fundamental, or otherwise irreducable to other mental or physical characteristics. (The idea that objects have an intrinsic tendency to slow down in Aristotles' physics seems like a rough analog. everybody sees that this is the case in their day to day lives, but it is not an irreducable feature of a more accurate theory) Another empirical fact is that our qualia are influenced by things other than what would seem to be the most obvious physical determinant: our perception of color depends on what is around a given object (numerous optical illusions depend on this), our perception of volume depends on pitch, memory can play a role (the "color-reversals after staring" type of optical illusions), people literally "seeing red" when angry etc. These features indicate that, at the very least, the connection between physical stimuli and the resulting qualia is very complex; perhaps so complex that it is worth identifying qualia as being conceptually distinct entities from the stimuli. This level of discussion does not pin down the features of qualia in sufficient detail to be considered a theory of the phenomenon, however, it indicates that qualia need to be addressed, in one way or another, in any complete theory of mind. Edit: Additional Reference Although he does not explicitly reference qualia, Thomas Nagel follows essentially this line of thought in What Is It Like to Be a Bat?: humans, and bats, and other organisms have subjective experiences, it's unclear how these relate to physical phenomena, thus there is a problem in reductionistic approaches to mind. Namely, they do not address this issue of qualia -- how qualia arise, what their connection to the physical is etc. His own proposal for addressing this is to more completely, and objectively, pin down the features/characteritics of qualia (my interpretation), in his words "we can pursue a more objective understanding of the mental in its own right", and only by doing so can we resolve questions about physicalism. As far as I can tell, David Chalmers takes it as self evident: e.g. "It is undeniable that some organisms are subjects of experience." (That is, I'm unaware of any explicit argument aimed at convincing someone who is skeptical of the idea of qualia). 

Beyond what Ransack indicated, there's another flaw in your presentation: you assert that people who have enough empathy for the victims will be deterred by that, but then dismiss this case by saying that there are many criminals who are not empathetic. But at least a plurality of those non-empathetic criminals are not deterred by the prospect of supernatural punishment, e.g. declared Christians who have stolen from someone else. Thus, in your own presentation you have indicated that (a) sufficient empathy for the victims will prevent someone from committing a crime, even in the absence of other punishments, (b) even supernatural promises of punishment is insufficient to deter all people from committing crimes. So my take away from your presentation is that ethics is hard. To more directly answer your question: I'm not convinced that secular morality is in ever in conflict with enlightened self interest. The enlightened aspect include features like, considering the long term consequences, considering what would happen if your actions were a general rule (akin to rule utilitarianism), considerations of others (e.g. the veil of ignorance) etc. 

Especially during the initial formation and development of QM, as far as what physicists write down in their notebooks as “measurements”, they are all classical outcomes. So having a theory that allows one to predict classical observations make sense. Several of the developers of the theory were in the thrall of logical positivism, and thus they were only concerned with constructing a theory that was empirically adequate for computing the results of the kinds of experiments that they could conceive of. More recently study of quantum decoherence and related phenomena are providing a more complete QM description of the types of interactions that yield essentially classical results. My impression is that from some people in that field you hear the problem as being more of "how does one get an effective classical theory given that the 'real world' is quantum mechanical"? 

Let's start with a fairly obvious fact: human computers are produced every day by the process of birth. I'm stating this just to emphasize that this question is really a question of "are human made artifacts different, in some fundamental way, from humans themselves, which are themselves produced by a process". For a materialist, the answer is an obvious no; and thus there are no obstacles in principle to making strong AI. For a dualist, the situation is open: if there is a mechanism by which we can induce a soul to inhabit a human constructed entity, then we could have strong AI. Only if we have souls, and there is something that prevents us from setting up the conditions whereby a soul would end up inhabiting a human made entity, would there be a fundamental limit. Usually, we think of strong AI as embodied in a computer. What if we were able to construct artificial life-forms biologically? We can currently construct whole viruses, move nuclei from cell to cell, make hybrids etc. To me, it's harder to argue that this type of artificial biological system would have a fundamental difference from a human, given that much of the process of its development would exactly mimic that of natural human (or other animal) development; thus these types of human made biological systems would exhibit almost all (all?) of the physical correlates of the soul, but would have be made by artifice. To deny the possibility of strong AI requires some sort of transcendent soul that is not strongly coupled to material, with all of the baggage that that entails (e.g. how/why do souls interact with matter at all)? Comment: I'm using soul to indicate whatever the non-material spiritual essence(s) arise in a dualistic theory. I'm not trying to indicate that it is necessarily a personal essence. 

Nir's short answer makes the point of why an electron is not just it's associated field configuration: electrons have other properties mass, spin, lepton number, probably others, that distinguish it from other things with equivalent fields (mu and tau leptons, or anti-protons if you don't look at them too closely). There was an idea put forward in the early 20th century (something along the lines of the classical electron radius -- this was the Abraham-Lorentz model) that the mass of an electron could defined due to the energy in the fields via the mass<->energy equivalence in relativity. This idea failed -- one prediction was that the electron would have a measurable radius that hasn't been seen, and in general doesn't mesh with current QFT. All of this is to say that an electron has more features than just it's EM field configuration. As to why the field is "associated" with the particle -- the post-hoc explaination is that there are different things (the other charged leptons) that have the same field configuation, but different intrinsic properties (like mass). The real reason is because "particle" is an idealization/extension of the everyday notion of a thing that we can pick up and move around, taken to the limit where any internal structure is irrelevant. Since most things that we deal with day-to-day don't have observable electric charge, people tend to see the electron's field as something extra attached to an otherwise uncharged particle. 

Thus, they are variously, (absence of) belief, a doctrine, and a code of duty. Secularism (as used by Secular Humanists) involves a whole series of beliefs about what should (and shouldn't) be considered when trying to identify moral goods. Thus, at many levels of discussion, it would be worth considering secularism as an aggregate belief system (as opposed to a more or less atomic belief). For materialism, the case that it is an aggregate belief system, as opposed to a single belief is harder to make. It's pretty much just that the material world is all that there is. Although one can poke at it to try to clarify what exactly any given materialist philosophy means by material, world, or examine any of the various consequences of adopting this belief, but the term materialism itself ends up referring to, essentially, a singular belief. Atheism is in the same boat as materialism: it is essentially, an atomic belief. Again, if you get into it, you might be able to identify aspects of it that are arguably component sub-beliefs, but at the level of general discussion, it fits nicely into the category of being a belief. In the absence of any context that indicates that you're going to drill into the details, the first two are individual beliefs, while the third is a network of inter-related beliefs. I keep hedging about context because I cannot rule out the possibility that there are situations where would would want, and be able to, break materialism or atheism into component sub-beliefs. However,I cannot think of a specific context where this is breaking down is necessary or useful, so the descriptions here should apply in general. It's also worth pointing out, that no one of these items, by itself, provides resolution to all (or even most of) the "disquieting" questions. 

No, all of the examples in "Is Justified True Belief Knowledge" are examples of the form where the proposition is a JTB, but fail to be (commonly percieved as) cases where the person had knowledge. One way of interpreting this is that Gettier showed that naive JTB (or anything like it, i.e. the three definitions indicated at the start of the paper) is at best a necessary, but not a sufficient, condition for knowledge. 

I think that the key gap behind this question is that for most people, most of the time, the degree of justification required for them to "hold a belief" is much lower than requiring a proof; rather all that is required is some sufficient level of external justification. Thus, believers are not "blindly" following their religion, they have justification (although there are probably many people whose justifications are not well thought-out). In some cases, people have real experiences that appear to be related to an external transcendent being/essence. These experiences are real experiences, theists interpret them as being sensory evidence of a god (or god(s) or spirits) as relevant as our sensory experience of tables, chairs etc. Thus, people who have had mystical/transcendent/life-altering experiences, have had an experience that serves as evidence. Other (maybe most) people don't have the direct experience but do have access to a community that re-iterates the stories of those who have -- e.g. people whose lives have "turned around" after finding god. This serves as testimony based evidence, which although it should be modulated by considerations of the reliability the person giving the testimony, can serve as evidentiary support for the belief. In some cases, there are claims of logical proof (justification) of the god(s) as well: the idea that the universe requires a creator (as a logical necessity) and then linking that to the god(s) can be made into a justification of this sort. However, in my experience most Christians, and possibly theists in general, do not rely on these kinds of logical arguments as the starting point, but rather rely on the other forms of evidentiary support and build outward from there. In the end, these justifications do not provide a strict proof of the validity of the religion, however for most people, most of the time the criterion for believing a given proposition is much lower than requiring a strict proof; and the external (evidence) support that they have is sufficient (for them) to hold the beliefs of their religion. 

Edit to add another (better?) phrasing I'm looking for information that addresses this question: All prescriptive ethical theories need to be descriptive to at least some degree(1). However, a completely descriptive ethical theory is just that -- descriptive. How do you judge (or what is a framework for judging) whether a set of cases where the ethical theory prescribes different moral judgement/behaviour than is typically observed constitutes a failure of the ethical theory? Who has explicitly addressed the problem as to when to decide to allow for a specific ethical theory to deviate from common-sense moral intuitions? (1) By descriptive I mean describing/reproducing what some people assess as the correct moral decision. If a purported ethical theory did not have any particular relationship to the common sense use of the word ethics, we'd hardly call it an ethical theory. Original Question Who has explicitly addressed the problem as to when to decide to allow for a specific ethical theory to deviate from common-sense moral intuitions? Suppose I set up a suitably elaborated theory of ethics, and I find that gratuitous murder is perfectly acceptable. This seems like a good reason to reject that theory of ethics, i.e. it seems that matching at least some basic moral intutions is a requirement of any ethical theory. Suppose I set up a suitably elaborated theory of ethics, but it fails to correspond with typical people's responses to the Trolley Problem(s). Should that be interpreted as a failure of the theory of ethics, or as a case where peoples' typical intuitions are morally suspect? Requiring that theories of ethics merely be able to reproduce typical moral intuitions seems unduly limiting -- it rules out the existence of prescriptive moral theories. [Note that arguments that all moral theories cannot/should-not be prescriptive would address this question.] In addition, this seems problematic in the moral test cases where there is no clear common intuition (I don't know of any such cases, but I can't rule out that they exist). I see similar delineation problems in terms of aesthetics and epistemology, and it might arise in other fields as well. Thus someone may have tackled this as a kind of general problem, if so that is of interest too.