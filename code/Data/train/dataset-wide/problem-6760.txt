You can find some information about the language boundary in the project "Digitaler Wenkeratlas" at $URL$ (not easy to navigate even with knowledge of German; the main Wenker map is under $URL$ but you cannot click through to the questionaires). Note that Wenker was primarily interested in dialectology, and German dialects specifically, but he also recoded other languages (in the area in question Polish and Czech dialects). Note also that there was probably no such thing as a language barrier: Mixed language villages, bilingual individuals and migration from Polish speaking areas to the industrial centres of upper Silesia complicate the picture. 

The terms encoding density, information, and entropy circumscribe the property you are aiming at. When you replace your p's and q's with zeroes and ones you are at the bits computer science deals with. Computing the entropy of the English writing system is a typical exercise in theoretical computer science (Note that not only the number of character but also their frequency counts). 

For those types there exist lot of different implementations. For the first type there is (besides CONLL that you already mentioned) the vrt format used by the Open Corpus Work Bench (see this tutorial) that allows additional XML annotation in the file. For the second type, there is, e.g., Tübingen Corpus Format (TCF) used by WebLicht. Both flavours have their pros and cons. The first type is geared for fast and efficient processing and can be used for online processing. The drawback is that one needs to add a lot of fillers (e.g., ) for sparse annotations. The second type is good when there are several layers of sparse annotation, but becomes unhandy when the files grow too large. One also has to load the whole file into memory before processing can start. 

Well, even a character based neural network (CNN) does not only take the letters of a text into account, but also the their order. So, a text is not just reduced to a bag of characters. However, a CNN is completely agnostic of morphemes, words, sentences, syntax trees and other linguistic representations, indeed. So it has some internal representation of the text, but this representation is probably very far from what we'd call a "linguistic representation" or a "representation of language". To your question 1. CNNs are a very hot research topic right now, and applications are sought for everywhere, but there is not much usable yet. To your question 2. The answer to this question is a plain no. The internal space of neural network (counting in hundreds of dimensions) is very hard to visualise, when it is visualisable at all. 

Due to the study of Buddhism and its scriptures in the source language (either Buddhist Hybrid Sanskrit or Pali) Japanese scholars were aware of the structure of the Indic scripts finally coming from the tradition of Sanskrit. When they created the Katakana they applied the ordering priciples of the Devanagari Script to it; the deviations (i.e., the ordering of the consonants s and h) can be explained by later sound shifts: The /h/ was a /p/ originally and developped via /ɸ/ to /h/, the /s/ was a /ts/ originally and thus closer to the Devanagari letter ca (च). EDIT: Incorporated information from the comments 

There is not much saving (of words, syllables, or phonemes) in simple sentences. Case endings allow for a pro-drop language saving one word in a simple sentence, and saving adpositions is also a minor thing. It becomes more interesting when one looks at more complex sentences; the case-heavy Latin language has compact constructions like ablativus absolutus, participium conjunctum or accusativus cum infintivo that often require a subordinate clause or a relative clause in an English translation (with a lot of additional words: A conjunction, some words for a finite verb form, some words to be repeated from the main clause). 

The service Grapheme2Phoneme at Bayerisches Archiv für Sprachsignale (BAS), a CLARIN-D centre, provides this kind of conversion for a bunch of languages. 

There is the pair of terms monocentric vs. pluricentric describing the situation whether only one cultural or economical centre is responsible for the definition of a standardised language or Hochsprache, or whether there are several centres (e.g. in the case of High German Germany (Berlin), Austria (Vienna) and Switzerland (Bern)). However, this does not necessarily matches political boundaries, A language still may be monocentric and be spoken in several countries, or one country may host more than one centre of langauge standardisation. Maybe one can borrow the term endemic for a language only occuring in one country from biology. 

Nothing, really nothing, can stop language change. It is best seen on the word level: Neologisms enter the language all the time, and other words become obsolete, archaic, and even completely unused. Also, on the level of grammar language change is working, e.g., for the English language there is a tendency to use the present continuous in more and more contexts, while other grammatical constructions (to name one: the passive) fall out of favour. Even sound shifts still occur, despite IPA in dictionaries and sound recordings and mass media. Formerly dialectal or sub-standard pronunciations become accepted or even a new standard. All this happens every day around us, the younger generation speaks a different language than their ancestors. 

The Open Corpus Workbench originally developed at IMS Stuttgart has such a tool, called cqp (Corpus Query Processor). There are other implementation of similar tools, to mention one, there is Poliqarp. The tool can do really amazing things when your corpus is annotated (e.g., for part-of-speech), you can issuer mixed queries for word forms and part-of-speech. 

You can extract adjectives (for many different languages, not only English) from the Wiktionary. Wiktionary has a higher coverage of the vocabulary than WordNet. 

In standard average European languages and also in classical Latin and Greek, there is no new part of speech for a modifier of an adjective or adverb, it is just an adverb. I don't know whether there are languages having "adadjectives" that are different from adverbs. 

It was spelled IVLIVS CAESAR originally (lowercase letters weren't there yet, and also U was not yet differentiated from V). For the development of the Latin script, see these questions on [latin.se]: 

It is still a very active branch of linguistics with conferences and journals and many linguists around the world participating. See, e.g., the 42nd International Systemic Functional Congress at RWTH Aachen ( $URL$ ) or the page of the International Systemic Functional Linguistics Association ( $URL$ ). The conference programs should give you an impression on current topics in SFL. 

At least, other Indogermanic languages have the ability to derive nouns from verbs, too. In Latin, there is a suffix -tio, -tionis that forms abstract nouns (like derivatio "derivation" from derivare), there is a suffix -or (applied to the supine stem) that derives agents (like actor "actor" from agere, ago, egi, actum). The process of derivation is part of the morphology of a language; but it is usually kept separate from the inflection part. Drawing the line between derivation and inflection is to some degree arbitrary and may by controversial for some boundary cases. 

In English, only verbs have a past tense but the other parts of speech (nouns, adjectives, adverbs, ...) don't have one. The fact that you can express a notion of past-ness for some of them (e.g., former president or ex-wife) does not form a past tense. Also now and yesterday aren't derivations from a common stem. While using common stems (or recognisably related stems) is not strictly necessary for a past tense (think of the past tense of the verb to be) it helps to have some morphological rules for forming a lot of past tense forms. Together with the semantic arguments formulated by @curiousdannii there is no reason to think of now and yesterday as one lexeme. 

The Wortschatz corpora at Leipzig University offer some Hindi corpora of different sizes and genres for download, go to this site $URL$ and click on "more" and than on "Hindi" (the page URL stays the same, but some javascript magic selects the Hindi language). 

Weblicht offers such a service for German and English to the academic community. In order to use it, you need an Academic Account for Fedarated login in a participating European country or you need to be enrolled in the CLARIN IdP. Note that the tools behind the service are often free tools and can be downloaded from their respective URLs (Search for Stanford Parser, Stuttgart Parser, or Berkeley Parser) and used from the command line. 

Let's give an example: You may be aware that all kinds of political scandals (especially in the US, like Iran-Contra-gate) are nowadays given names ending in -gate. From a morphological point of view, -gate is is a suffix denoting "scandal". From an etymological point of view, -"gate" is derived from the common English word gate (meaning, of course "gate") that is related to other Germanic words like Icelandic gat "hole" and that has outer-Germanic relations as well. It has acquired the meaning scandal rather recently due to the Watergate scandal in 1972 (that got its name from a place name). You see, that etymology takes much more dimensions of explanation into account: Historical stages of the language, relations to other languages. Morphology is just a description of the present stage of the language. 

Proven? In the sense of a mathematical proof: Definitely not. There are no axioms and definitions to build linguistics as a part of mathematics. And even if there were some axiomatisations of subsystems of linguistics: How do they relate to natural language? Is linguistics a science in the sense of Karl Popper? I.e., does it consist of hypotheses that can be falsified but observations on natural languages?—I'd say, partly. There is a branch of linguistics, sometimes called Language Science, that can be considered a science in this sense. But there are other parts of linguistics, that are more like Humanities. And than there is a large part of Linguistics that is simply descriptive (think of all the field workers documenting lesser known or completely unresourced languages). 

Of course, there are lots of "It depends", but in practically all part-of-speech tagsets I am aware of Cardinal Numbers are a class of their own (called cardinal number, cardinal, oder numeral) 

The pair größer/kleiner seems to contradict the intuition, but there a lots of non-comparative uses of the two words, specially of kleiner (e.g., ein kleiner Frechdachs). Testing with the comparison particle als restores the ranks: 

This trait is directly inherited from Latin. A verb like laudare has subjunctive forms with an e: laudem, laudes, laudet, lauemus, laudetis, laudent while other verbs form their subjunctive with an a, e.g. vivere has: vivas, vivas, vivat, vivamus, vivatis, vivant. 

The term for such kind of phrase is multiword expression. I am not aware of a special term for the process that creates multiword expression. I am also not aware of some special treatment of them; in corpus linguistics usually each word is tagged separately with a part-of-speech tag and syntax trees are built from the single words (as separated by spaces). 

In this special case, English usage might be influenced by German usage. For the German language, there are the following rules 

Vesanto et al., Applying BLAST to Text Reuse Detection in Finnish Newspapers and Journals, 1771-1910 successfully used BLAST, a computer program to compare proteins, for a similar task: They tracked the spread of news items in Finnish newspapers (ORCed, so many typical OCR errors were present in the electronically available texts). 

There are language resources called wordnets that represent graphs of hypernymy and hyponymy and synsets. The prototypical example of such a resource is the Princeton WordNet for the English language that is available under a free licence. There is another type of language resource called ontology. Typically, ontologies are constructed for particular domains of knowledge. 

In theory, yes, in practice no. The user base of written English is so large and dispersed that any changes to the English writing system (including even minor spelling reforms without touching the alphabet) are almost impossible to implement. There have always been tris to change the basis of English writing, e.g., the Shavian alphabet or the International Teaching Alphabet (ITA), but none of them are going to take off at a larger scale. 

The major piece of evidence is the mere existence of agglutinating and inflecting languages. If there were only evolutionary processes that make formerly inflecting or agglutinating languages isolating , there would be no inflecting or agglutinating languages (given the time language is around, all languages would have reached the isolating stage and stay there forever. Also, Pidgins and Creoles are typically isolating, so they do not provide a source of inflecting languages). It is of course theoretically possible that an isolating language becomes directly inflecting without and agglutinating intermediate step, but afaik this transition has not been observed yet. It is, of course, somewhat unsatisfactory to have only a "non-constructive" argument for the typological cycle, seeing all proposed transitions in action (and not seeing the transitions the other way round) would be more satisfactory. 

There is the following fun sentence in German with a fivefold repetition of the syllable "ni" (spelled "ni" or "nie", but with identical pronunciation): 

No. It is just the rule for English, other languages differ, e.g., Russian and Chinese don't have articles at all (neither definite nor indefinite ones). 

For the two quoted speakers of German, dialect is an explanation. Brecht is Born in Augsburg (Bavaria) in an area where r's are rolled, and Brecht used Süddeutsche Umgangssprache (Southern colloquial German) quite consciously. I am not so sure about Hitler who is born in Braunau (Austria) in an area where r's are rolled. But I suppose, he received some training on pronunciation. R's are still rolled in Bavaria, when you listen to German speakers from Bavaria and Austria today you will notice it. Rolling the r's is a requirement for professional speakers in the official Bavarian radio network (Bayerischer Rundfunk). 

Without historical data on the dialect, I'd think that the second hypothesis (Or might this be best explained as dropping the [u] by syncope and adding a [i] by prothesis?) sounds natural and plausible. But maybe, you can dig up historical records shedding more light on the evolution of the São Vicente dialect of Cape Verdean Creole. 

There are some principles when you ever attempt a spelling reform—one of them is keeping the tradition of reading and writing intact (in German, the term behutsam was used when the latest spelling reforms starting in 1998 were introduced). There was lots of outrage and resistance against those reforms much underestimated by the politicians driving it forwards. Well-established spellings cannot be arbitrarily normalised or even be recreated from first principles in an already literate society. This is the reason why the German orthography sticks to the ie spelling (which denoted a diphthong in Middle High German that is preserved in the Bavarian dialect where "lieb" is still pronounced liab). 

German acquired the /eɪ/ diphthong from English, e.g., in the word "Spray" that is pronounced /ʃpreɪ/ (note the initial /ʃp/—it is not just a foreign word in its original pronunciation). 

ISO639-3 is derived from The Ethnologue. The author of this work have a certain point of view on the definition of "language" (vs. "dialect") with a strong tendency to split languages into smaller units. Note that the authors of the Ethnologue have a open agenda that is different from doing science. Divide and Conquer. 

There are some examples of language merger in history. Note that such a merger is rarely a "merger of equals" where both languages contribute about the same amount to the resulting merged language. 

Standard Average European (SAE) is a Sprachbund centred around German and French and extending to almost all European languages. Haspelmath has examined Maltese for SAE features, but he did not examine Modern Hebrew (Ivrit). Since Modern Hebrew is not only a Semitic language, but is also heavily influenced by native speakers of SAE languages (like German, Yiddish, and Ladino) I am interested in the question whether some SAE features were adopted by Modern Hebrew. P.S. Related Questions: How Standard Average European is Esperanto, Can Modern Hebrew be considered as a Indo-European language? 

The word Meer¹ has as its original meaning something like "stagnating water", see also the related word Moor "swamp". Also the word See² originally had both meanings, and it was originally masculine. It stayed masculine in Southern Germany, where only lakes but no sea are known, but it changed to feminine in Low German where the sea is well known. In German it specialised meanings along that line: der See is now only the Lake, and die See is only the sea. ¹ Meer im deutschen Wörterbuch von Jacob und Wilhelm Grimm $URL$ ² See im deutschen Wörterbuch von Jacob und Wilhelm Grimm $URL$