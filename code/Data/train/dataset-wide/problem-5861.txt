I hope you don't mind me saying this, but you're question made me laugh. Gastrointestiphilosophy - now there's a course I want to take! But seriously, branches and sub-branches of philosophy aren't 'created' by a board of academic philosophers, and only then can everyone write papers about it and get published. The order of events is the opposite: people were asking questions, and eventually enough material accumulated on a particular subject that it warranted getting it's own tag, for practical reasons. For example, there was a time (in theory at least) that if you took a course on ethics, you could comprehensively all the important ideas that were being discussed at the time, until lots of people had many more ideas, and applied it to more categories, etc. so that today we have metaethics, normative ethics, etc. and branches of applied ethics, one of which is bioethics, and today there's even enough material on neuroethics. Neurophilosophy is a branch of philosophy because what we've learned about the nervous system is very relevant to certain philosophical questions, making it a subject that has given philosophers much to talk about. So the answer to your question is merely that there isn't enough philosophical material or questions about the lymphatic system and its philosophical implications as there are on the nervous system. But by all means, if you have philosophical questions about the lymphatic system, go ahead and ask them - talk to philosophers, get a discussion going, and maybe the day will come where I can take a class on gastrointestiphilosophy. 

This question gets to the heart of the issue of philosophy of mind: what is consciousness, and how did it get there? Once we know how consciousness works and how it's produced, we can answer the question if whether complexity is one of the necessary ingredients, so to speak, of consciousness. In general, we could take two approaches, either a materialistic approach or a dualistic approach. A materialistic (or monist) approach to the question of consciousness assumes that everything produced or experienced by a conscious mind can be explained by physical phenomena and natural processes. Instead of discussing the many theories on this context, I'd suggest to read what's written in the subject by John Searle and Daniel Dennett (or if your lazy just read the Wikipedia or SEP articles about their theories). As far as I know, anyone who believes that consciousness (or what we describe as consciousness) is a natural outgrowth of the brain's function, also believes that complexity is a necessary, but not sufficient, factor. Personally, I think that the 'complexity' necessary for consciousness isn't a simple matter of quantified how complex a system is, but requires a complexity arising from variation, in that there are a variety of different ways in which the brain interacts with the environment which all need to interact with each other (though even a complexity of that type may not sufficient, I believe that it is necessary). To answer your question fully of precisely what level of complexity, given a 'complexity quantification' would be theoretically possible but I doubt that, at the present time, anyone has a full enough understanding of consciousness to be able to answer that question. On the other hand, we have dualists, who believe in something aphysical, or metaphysical, which is the producer of consciousness, such as a 'soul'. In theory, or at least in the ancient understanding of a 'soul', since a soul is unrelated to physical phenomena it doesn't necessarily have to belong to a complex system, and an empty cardboard box could be just as conscious as a human. By mentioning a calculator, I imagine that you think that either computational ability or the ability to have an input/output system are minimal requirements for consciousness, but if we're going with the soul idea, even those relationships are artificial ones. (I should note that dualists have argued with me about this idea, but only usually by appealing to external factors, such as the idea that God wouldn't give a soul to inanimate objects) Probably the most interesting opinion in this context is that of philosopher David Chalmers, who is a dualist in the sense that he believes consciousness to be something other than physical properties, but doesn't believe in the ancient conception of the soul that I've assumed until now. He believes that it is indeed possible that all objects or systems have a form of consciousness, and that their level of self-awareness is in fact a reflection of their complexity. Thus, a minimally complex system (even just a simple circuit) does have a 'consciousness' to it, albeit a 'low-level' or simple one. The more complex a being/system is, the qualitatively more profound is it's feeling of consciousness. I think that he believes, therefore, that the universe itself has a 'great consciousness', as do solar systems, anthills, and the Internet. I'd suggest reading some of his works to understand his opinion better. (I personally find his theory fascinating but patently absurd, so I'll admit that I could be misrepresenting it) 

This question is a variant of the Boy or Girl Paradox, which Wikipedia attributes to Martin Gardner. Wikipedia also writes that "the paradox has frequently stimulated a great deal of controversy" Wikipedia calls this question a paradox, because: 

While this won't solve any real form of epistemological doubt, what you can do practically is a sort of reverse Pascal's Wager. Let's take your example, but expand it not only to whether God exists, but to the corollary question of what exactly is the nature/definition of this 'God', and would He have anything to do with morality or communicate with humanity, etc. Now, some of these conceptions of God are quite elaborate, such as depicting Him as repaying human adherence to complex rituals with eternal bliss. Let's also assume that instead of making your own decision on this questoin, you decide to leave it up to the 'experts', the brilliant theologians and philosophers who have debated and thought about this issue, but - to your great chagrin - you have found that there seems to be either equal 'epistemological weight' (likelihood of being correct, disregarding actual arguments), or, more likely, you're unable to determine which side is more correct. So... do you just flip a coin? Well, let's imagine that these many hundreds of theologies are equally plausible (or, practically equally plausible since you don't have any way of evaluating their relative correctness), but you need to do something about this question and so you spin your Wheel of Theology. If it hits 1, then you'll be living life as if there were no god. If 2, then you'll be living as a Catholic, requiring prayer and a few sacraments. If 3: Islam, which instead of scattered sacraments would require significantly more prayers, and more ritual laws, etc... Basically, some of these metaphysical beliefs will demand more from you. If you see the choices are truly being equal, than you might has well spin the wheel. But if you're resorting to spinning the wheel, stop, and think about the consequences/demands each theology would make on your life. Just as Pascal thought that the religious life provides 'nothing to lose and everything to gain', similarly, you would have 'gained' the same likelihood of being correct from any one of the options, but would have to 'lose' whatever lifestyle sacrifices that would have to be made in order to accommodate said theology. Thus, the least demanding would be the most practical. As I said, though, this doesn't resolve the actual doubt, just give a practical 'way out'. 

Usually discussions of practical/applied ethics (which this site really needs a tag for, by the way) discuss matters in which a person's actions will have an effect on others. However, is there ever a case where a person can act unethically towards themselves? Alternatively, is there ever a case where something can be unethical despite not being harmful to any person at all? An example of the former would be causing pain to oneself I guess, or similar self-harming (though perhaps not painful) actions, though there may be reasons why one could justify that (ethically). I can't think of a better example though. I don't think anyone would go to the extreme and say that eating unhealthily is unethical because it is self-harming, but perhaps more extreme cases would be. One place that the latter question comes up is in discussions of bestiality. Some have objected to the practice of bestiality (disregarding any effects to the animal in question) on the grounds that it violates 'human dignity'. While I can certainly see human dignity playing a factor in applied ethics (such as a case where prisoner is denied his/her basic dignity, etc.), should this be a consideration in cases such as bestiality, where the question of 'human dignity' isn't one afflicting another or the like? 

The actual solution? It depends how the question is asked, or how and when you discover that one of the children is a boy. From the manner quoted here, the question is ambiguous. If the stranger offered this information to you upfront, than from your perspective, is it as if the stranger is offering information regarding a random child, in which case the answer would be 1/2, or specifically the child that is not the stranger him/herself? In the latter case, the answer would be 1/3, because your original sample size is only the families of two children where one of them is a boy, (or, in another version, you specifically ask, "is one of them a boy", not picking a child at random) and we want to know, of those families, what is the probability that the other child is also a boy. Eliezer Yudkowsky (a relatively well-known AI researcher) has a lovely story about this problem where writes that an incorrect wording of it changed his life. He, and the linked Wikipedia article, both have good explanations to a Baysian analysis of the problem and its solution. Of course, the questioner probably should have also stipulated that it's a way of asking a probability puzzle, so that there wouldn't be any demographic or sociological factors to consider. That way, you can discuss this as a case where boy:girl ratio is 1:1 and that the sex one child doesn't affect the probability of the sex of a second child (which technically isn't true, partly because there's a possibility that the two children are twins), etc. because after all, that's not really the exciting part of the puzzle, is it? 

Looking for sourced answers or article references for this question, please. Why should someone believe another person's assertions? I would imagine that the answer is because most of the times when I have been able to verify other people's statements, I've found them to be true. This becomes more likely as more people corroborate on a particular thing. But can this be quantified in probabilistic terms (in other words, the probability that someone is telling the truth) in order to balance such a likelihood against other prior possibilities? Furthermore, there are whole disciplines where I know that I'm not qualified to validate _any_statements made by any of the experts in that field, such as that of quantum mechanics, but trust the 'establishment' of the scientific community. While sometimes claims of 'the scientific community' are verifiable, there are whole areas where, from my own perspective, they are not. How can I evaluate the claims of such 'experts'? Would I be more justified in believing in bosons than in cold fusion? What probability should the uninitiated give to scientific claims? 

Hilary Putnam, in "Reason, Truth And History", attempts to argue against Cartesian (or hyperbolic) doubt, by proving that a 'brain in a vat' cannot actually think that it is a brain in a vat. Part of the argument (if I understood it correctly, which is unlikely) hinges on the fact that in order to be a valid 'thought', an idea must be related to something in reality. Because the brain has a thought about itself, it must exist in reality. Writing it in this way, the argument seems so obviously incorrect that I'm sure I'm missing something. How does Putnam define 'thought' in a way that makes it necessary for a thinking thing to exist as it perceives itself? I found a summary of the argument here, in "Philosophers Explore The Matrix" (not that I'm recommending the book or the movie which is referenced in the title) but it appears similarly flawed: if I merely have an illusion of a hand, isn't my 'thought' or speech regarding my hand a valid reference to my illusory hand? The word 'hand' still is referencing something, even if it has no ontological existence. 

As Descartes himself noted, part of the argument is based on the existence (and therefore possibility) of a dream-state. Even the materialist cannot argue that the mind is capable of being fooled, by anything from optical illusions to dreams, and that whatever chemical signals are necessary for brain states, these chemical signals clearly don't require outside stimuli that correspond perfectly to the mind's perception of them. Even by appealing to evolution fails in an attempt to show that the mind necessarily perceives its environment correctly, and that a dream-state or similar reality-misrepresentation-state cannot be the mind's permanent state. One proposing to relieve Descartes of his doubt might say, "well, since the brain evolved by surviving, which depends on correct representation of the outside universe - the only way for a body-mind to get away from a bear or similar danger, is for it to be able to see the bear, and see a heavy stone to hit it with, etc." However, this isn't necessarily true - perhaps instead of the bear that the mind perceived, reality was that an object of a different nature were in front of this mind-body, and the only way to continue surviving would be to move towards this object. However, the mind-body evolved to perceive a bear and to think that it's acting in a particular manner, when in actuality it's acting in the opposite manner - but this is all beneficial to the mind-body, because the end result is that it does the action that allows its survival. Hence, evolution cannot help Descartes out of his doubt. The only reason to believe in materialism (or evolution, or anything for that matter) is to believe in the scientific findings/theories etc, which are based in turn on sensory observations. There's no reason to justify a materialistic conception of the mind-body problem, unless one already believes in the existence of a material environment.