Felipe's answer is much better, but what about this, just for fun: an automorphism f of X induces an automorphism of effective divisors of degree 2, i.e. of the symmetric square X^(2). This object contains exactly one copy of P^1, corresponding to the divisors of the g(1,2) and thus the automorphism f^(2) of X^(2) induces an automorphism of this P^1, which takes divisors of form 2.P to divisors of form 2.f(P). 

I support the previous suggestions, especially Ted Shifrin's fine notes. I am quite ignorant of differential geometry myself, hence am sympathetic to this proposal. I have recently realized, through my love of Euclidean geometry, what others probably all know, that there is a natural sequence of topics: euclidean geometry, spherical geometry, hyperbolic geometry (these all being surfaces of constant curvature), and then other surfaces of constant curvature, namely quotients of the previous ones. Next one naturally progresses to surfaces of varying curvature, i.e. the realm of differential geometry proper, Riemannian surfaces. Finally one raises the dimension. Thus the natural elementary course to teach seems to me to be spherical geometry, then.... The point is to teach curvature, and emphasize that euclidean geometry is the unique geometry of constant zero curvature, (with another hypothesis that lines are infinitely long). In particular we seem to miss an opportunity when we teach non euclidean, i.e. hyperbolic geometry, without a link to differential geometry via curvature, but this is normally done in non euclidean geometry courses. E.g. curvature is easily presented in the elementary way that Riemann (and Gauss) described it, as the defect of the angle sum of an infinitesimal triangle. Gauss Bonnet easily follows for the basic surfaces. In this regard, I suggest a first step in learning differential geometry is to discuss whether a cylinder is or is not curved, and why or why not. Along this line of reasoning, John Stillwell has a very nice book on surfaces of constant curvature that would impart a lot of useful concepts at the advanced undergraduate level.. $URL$ I even sketched out a plan form such a course to present to brilliant 10 year olds, assuming neither calculus, topology, linear algebra or even trig, which could be taught in the course For more general differential geometry, there is a book by David Henderson, which attempts to teach an intuitive understanding of the ideas, curvature, parallel transport, holonomy... $URL$ But the basis of this suggestion is the hypothesis that concepts are more fundamental than techniques for computing them. Since it seems that the most important concept in differential geometry is curvature, the first job is to convey an appreciation for curvature and its role in geometry. This can be done naturally in a very elementary setting. Only afterwards does it seem important to train someone in the means of computing it, i.e. tensor calculus and differential forms, chern classes, etc.... 

Here is a self contained answer to why Riemann's original theorem as he proved it, before Roch's refinement, is indeed an index statement. Traditionally, the “index” of a linear operator is the difference between the dimensions of its kernel and cokernel. Computing this difference is usually easier than computing either the kernel or cokernel dimensions alone, hence it is a helpful first step even where one of those dimensions is really wanted. Moreover the index gives an estimate of the kernel dimension. Riemann’s proof of his theorem was to calculate such an index as follows. Given a divisor D of r distinct points on a compact complex Riemann surface X of genus g, he constructed a basis of the g+r dimensional space W≈C^(r+g) of corresponding differentials of “second kind”, i.e. having at worst principal part const.dz/(z-p)^2 at each point p. Since the space L(D) of meromorphic functions with at worst simple poles at these points maps with one dimensional kernel into the space W, in order to compute the dimension of L(D) it suffices to compute the subspace of exact differentials in W, i.e. the kernel of the “period map”, obtained by integrating these differentials over a basis for the 1st homology of X. Thus he wants to compute the kernel of a linear map from C^(r+g) to C^2g, where C = complex numbers. It follows immediately from the rank/nullity theorem that the index of this period map is (r+g)-2g = r-g = deg(D)-g. Hence this is a lower bound for the kernel, so dimL(D) – 1 ≥ r-g, i.e. dimL(D) ≥ deg(D) + 1-g. This also implies the modern index form of the theorem as follows. Riemann knew the period map is injective on holomorphic differentials, so he could, and Roch did, replace it by a normalized period map from C^r to C^g ≈ H^1(X;C)/H^1(X;K) ≈ H^1(X;O). The cokernel of this map is now called H^1(X;D), so Riemann’s theorem can be phrased chi(D) = h^0(D)-h^1(D) = deg(D) + 1-g. Since it takes some work to compute chi(O) = h^0(O)-h^1(O) as 1-g, this is actually stronger than the modern sheaf theoretic result that chi(D) – chi(O) = deg(D), which follows immediately from the sheaf sequence 0-->O--O(D)-->O(D)|D-->0. Of course Riemann’s result should be stronger since it contains in addition to the trivial sheaf theoretic linear algebra, also the computation of both the holomorphic genus = h^0(X;K), and the topological genus = (1/2)h^0(X;C). Thus Riemann’s theorem combines the two modern results: chi(D)-chi(O) = deg(D), and chi(O) = 1-g. Roch’s refinement of the RRT is to compute the cokernel h^1(X;D) of Riemann’s period map, which he does of course by making a residue calculation. He obtains that h^1(X;D) = h^0(X;K(-D)), hence h^0(D)-h^0(K(-D)) = deg(D)+1-g, the full RRT. 

Not a fact but a philosophy: to me the most important way of thinking in algebraic geometry that would be useful in many areas is that of a moduli space. I.e. the idea that the set of isomorphism classes of certain objects should be viewed with structure of that same type, and its properties studied as a tool for understanding the original types of objects. This I believe is basic to the work of Chris Byrnes alluded to above. This philosophy is perhaps not due to or original with algebraic geometry, but is practiced systematically there. It may derive from algebraic topology, (classification of vector bundles, E.H. Brown's representability of cohomology,....), like many other things in AG. It might be of interest e.g. to some high school students to know that Euclid proved the set of congruence classes of circles is an open half line, and that the set of all triangles modulo similarity is parametrized by the interior of an isosceles right triangle, modulo the reflection in the altitude on the hypotenuse (via the unordered coordinates AA given by the two largest angles), hence also the interior of an isosceles right triangle, but with the interior of one edge added in. Then the set of congruence classes of triangles can be seen as the product of this triangular region with an infinite open half line, i.e. an infinite parallelpiped, (via the ASA theorem). They might then compare this with the realization of this same space by the coordinates SSS. 

I once taught a successful class to second graders, on euler's theorem for polyhedra by handing out colored cardboard models and letting them count the facets, etc... This would seem a suitable topic also for elementary school teachers. (When reading elementary presentations of triangle geometry for children one sometimes encounters false statements, such as the claim that the rigidity of a triangle made of straws implies SSS congruence. Of course rigidity implies the moduli space is discrete rather than that it is a singleton, i.e. a similar proof shows (the false theorem) "SSA congruence".) Another favorite topic, harder than euler, is modular arithmetic applied to computing what day of the week someone was born on. 

Twelve years after Atiyah's article classifying vector bundles on curves of genus one, Narasimhan and Ramanan published a lovely paper in the Annals, (89) no.2, 1969, p.14, where they solved the case of semi stable rank 2 vector bundles on genus two curves. This case is perhaps more typical of the higher genus situation. Basically, a rank two vector bundle is analyzed by producing a sub line bundle, whose quotient is also a line bundle, and then studying how the vector bundle is reconstructed as a twisted sum of those two line bundles. I cannot improve on the wonderful references given by Georges Elencwajg above, but I have a short 4 or 5 page set of notes from a lecture given by Daniele Arcara, in a graduate class of mine, summarizing the status of moduli of rank 2 bundles on curves in 2001, if there is some way to send it to you or attach it here as a pdf file.... I sent them to your email address at Princeton. 

This is one of the most fundamental questions possible. Hence although it is old and well answered, I venture to add something, hoping to make it seem as transparent as possible. I would suggest the way to understand this construction is to look at it backwards. I.e. by its very definition, projective space carries a tautological line bundle, whose dual bundle has as sections the linear coordinates. These sections have no common zeroes because the hyperplanes have no common points. Hence any subvariety of projective space also has by restriction a line bundle whose sections have no common zeroes. Moreover a point of projective space is determined by the set of hyperplanes through it, so any subvariety is determined by the restricted line bundle, since each point is recovered from the set of sections vanishing on it. Moreover the projective space it self is dual to the space of hyperplanes, hence to the space of global sections of the bundle. Hence the bundle on the subvariety determines both the ambient projective space and the embedding. Now one sees immediately that one can imitate this to give a map, not necessarily an embedding, from any variety with a line bundle whose sections have no common zeroes, to the dual projective space of its space of sections, by sending each point to the subset of its sections vanishing at that point, as Anton said. In a nutshell, since projective space has a line bundle whose sections have no common zeroes, and line bundles and sections pull back under maps, having such a line bundle is a necessary condition for a map to projective space. Then one asks whether it is also sufficient, and it is, as above. It is easy also to recover the properties that determine whether the map is an embedding. Looked at this way, there is nothing mysterious about this construction - it is in fact the defining property of projective space. 

The answers that this follows from Hodge theory and HRR are of course spot on. If what is meant is rather why those theorems are true, here is a short proof at least of HRR for curves: If two smooth plane curves have the same degree, hence the same topology, they are linearly equivalent, so by the exact sheaf sequence (of a divisor on a surface) also have the same chi(O). So chi(O) is a topological invariant for smooth plane curves. But why does it equal 1-genus? In degree one, both (1-genus) and chi(O) are equal to 1. Moreover when you add a general line L to raise the degree of a curve C from n to n+1, the topological genus of the (smoothed) curve goes up by n-1, so (1-genus) goes down by n-1. By the exact sequence relating the structure sheaf of the sum C+L of these divisors, to the sum of their structure sheaves, chi(O) also goes down by n-1. Thus both invariants are the same for degree one curves and change the same way when we raise degree, hence they agree. But all curves are at least nodal plane curves, and we can modify the argument to allow for the nodes. As to why there exist g holomorphic differentials, by taking real and imaginary parts this is equivalent to why there are 2g harmonic differentials. I.e. we are trying to understand why Hodge’s theorem is true. As mentioned, the maximum modulus principle implies a non zero harmonic form must have non zero period over some loop, and a harmonic form is uniquely determined by its periods over all homology cycles. Thus existence of harmonic forms means finding ones with prescribed periods. This is done in two steps. The first step is to find a smooth form with given periods. This is done by putting a collar around a non separating loop, forming a smooth function that climbs from 0 to 1 when crossing the collar, setting it equal to zero elsewhere, and taking d of it. Thus we see that topology does tell us how many smooth closed forms we can construct that are cohomologically independent. Then the deep part, i.e. the Hodge theory, says that each such smooth closed form can be written as a sum of a harmonic form and an exact form. For details see Springer chapters 7 and 8 page 207, lemma 8-1, especially using Weyl’s smoothing lemma 7.3 p. 199. To “see” why this occurs, one may view the flow diagrams in Springer’s chapter 1 (fig.1.27. p.27), taken from Klein’s lectures on Riemann surfaces. I.e. it seems a differential form, or covector field, is determined by its flow lines, and when these flow lines are of minimal length in some sense, then they satisfy the Laplace equation and hence are harmonic. So the intuitively plausible fact that these lines may be allowed to deform within a cohomology class until they are minimal (Dirichlet principle), suggests the existence of a harmonic form in each cohomology class (??? I just made this up, but maybe some expert will help out here.) It seems Riemann reduced this problem to the “Dirichlet problem” of existence of a harmonic function with prescribed boundary conditions, on the polygon of 4g sides obtained by dissecting the genus g Riemann surface by 2g transverse cuts. One constructs a harmonic function f which agrees on opposite pairs of sides except on one pair where it differs by a ≠ 0 constant on the two identified edges. Then taking df gives a harmonic differential with a non trivial period. Since there are 2g choices of such paired sides, and a harmonic form is determined by its periods, one can construct exactly 2g independent harmonic differentials this way, hence g holomorphic differentials. 

This is discussed in detail in chapter IV of the RRT notes on my web page (roy smith at math dept, university of georgia). Briefly, the index point of view is a valuable simplification, but the Riemann Roch theorem is more than an index statement in general. Moreover the content of the index statement depends on the definition of the "index". In the answer by Spinorbundle above, the analytic index is defined in such a way that stating it as he does gives a complete statement of the RRT theorem. I.e. his definition of the index includes the statement of Serre duality as well, which in the case of curves also implies Kodaira vanishing. Usually an index of a linear operator is the difference between the kernel and cokernel of that operator. In Riemann's original formulation of his theorem, that operator is a matrix of periods of integrals, and the RR problem is that of computing just its kernel. In the sheaf theoretic version of his approach, the index of the relevant operator associated to a divisor D is the difference chi(D) = h^0(D) - h^1(D). An easy long exact sheaf cohomology sequence implies immediately that chi(D) - chi(O) = deg(D). Then if one simply defines the genus to be 1-chi(O) as is sometimes done, the result is the formula chi(D) = 1-g + deg(D), a sort of "computation" of the index chi(D), sometimes called the Riemann Roch theorem. This however is not very useful unless one can also compute g, i.e. chi(O). The real RR theorem should thus relate chi(O) to some more illuminating definition of the genus, such as h^0(K) or the topological genus. I.e. the very weak formula in this paragraph does not reveal that the index chi(D) is a topological invariant. Finally conditions should be given when chi(D) = h^0(D), the actual Riemann Roch number. In dimension one, defining the index as Spinorbundle does, and computing it, does solve all these problems at once. But that computation is correspondingly more difficult. In higher dimensions even that computation does not give a criterion for the index to equal the Riemann Roch number. When the index chi(L) is defined as the alternating sum of the dimensions of sheaf cohomology groups of a line bundle L, as is more common in algebraic geometry, there are then several steps to the full RR theorem: 1) compute chi(L) - chi(O), the difference of the indices of L and of O, as a topological invariant. This is the relatively easy part, by sheaf theory. 2) compute chi(O), also a topological invariant. this is sometimes called the Noether formula (at least for surfaces). One then has a topological formula for the index chi(L). 3) relate chi(L) to h^0(L), and perhaps h^0(K-L). this involves the vanishing criteria of serre and kodaira and mumford, and duality. This is the hardest part. Moral: computing the index chi(L) is topological, hence relatively easy. Then one tries to go from chi(L) to h^0(L), using the deep results of Serre duality and Kodaira vanishing. Saying the RRT is (just) an index problem is like saying you can compute the number of vertices of a polyhedron just from knowing its Euler characteristic. But I confess to pretending otherwise at times. Indeed one of my t - shirts reads "Will explain Riemann Roch for gianduia: chi(D)-chi(O) = deg(D), and chi(O) = 1-g", which is merely the index statement. In the RRT notes on my webpage, pp.37-42 there is an easy proof of steps 1 and 2, for curves, inspired by the introduction to one of Fulton's papers. Basically, once you have identified a topological invariant, you can compute it by degeneration to a simpler case. These notes also discuss Riemann's original proof, as well as generalizations of the index point of view to the case of surfaces, and a little about the Hirzebruch RR theorem in higher dimensions. Serre's proof of the duality theorem is also sketched. Briefly Serre lumps all the relevant cohomology spaces for all divisors D together into two infinite dimensional complex vector spaces, which he then shows are both one dimensional over the larger field of rational functions. It is then easier to prove they are isomorphic over that field, by showing the natural map between them is non zero, hence all their individual components are isomorphic over the complex numbers.