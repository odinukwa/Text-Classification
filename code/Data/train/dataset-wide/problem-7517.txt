Your last recurrence relation indeed helps. That is: 1) Away from zero, once you consider $t>\epsilon$ and $n\ge 1$, you have $q_n$ bounded away from zero by a positive constant $c=\min_{[\epsilon,1]} q_1(t)$, and hence $r_n$ cannot jump over the fixed point of the map $r\mapsto t+(1-c) r$, which is $r=\frac{t}{c}$. 2) Now, you have to handle the neighborhood of zero. If you had the limit value $t$ or at least $\alpha t$ (with $\alpha$ a constant) instead of $q_n$ in your recurrence relation, the fixed point would be $\frac{t}{\alpha t}=\frac{1}{\alpha}$, and it would be done. 3) Now you handle different $t$'s separately. For each individual $t$, for the first $1/t$ iterations there is nothing to worry about: anyway you have $r_n<nt<1$. 4) On the other hand, it is not so difficult to see that at the $n=1/t$'s iteration you have $q_n>\alpha t$. Indeed, on every step $j$ you add $\frac{1}{2}(t^2-q_j^2)$. Either at some $j<n$ you already have $q_j>\frac{1}{2}t$, and then you are done. Or it does not happen, and then $q_n\ge n\cdot \frac{1}{2}(t^2-\frac{1}{4}t^2) = n\cdot \frac{3}{8}t^2 \sim \frac{3}{8}t$. So you have $\alpha=\frac{3}{8}$, and the proof is complete. 

I would say that no. Because even if you consider the subset of 0-1 matrices that are adjacency matrices of graphs, for this subset such a relation becomes simply the isomorphism of graphs. And the problem of isomorphism of graphs is complicated (for a first glance, see $URL$ ). If there were a good canonical representative and a good algorithm of reducing to it, one would be able to solve the graph isomorphism problem by reducing both graphs to their canonical representatives, and checking if these representatives coincide. 

Am I right that in fact, your question can be re-stated in the following way: if $q(z)$ is a holomorphic function in $D(1)$ such that the average of $|q|$ over this disc is equal to 1, then the average of $|q|$ over $D(r)$ is at most 1? If yes, the first idea that comes to my mind would be to use that $|q|$ is subharmonic. Then you can proceed in two ways: 1) For a subharmonic function, if you average it w.r.t. a measure and then diffuse this measure, the average changes non-decreasingly. So -- you can launch a Brownian motion with the initial condition chosen w.r.t. the uniform measure on $D(r)$, and stop it in a (Markovian) stopping time chosen in such a way that the new distribution is uniform on $D(1)$ (a Skorokhod-like problem). There is a way of doing so, but it could be overcomplicated to write down. 2) The previous part brings into attention that the family of averages on $D(r)$ should be non-decreasing in $r$. And to show this, it suffices to show that an average on the radius $r$ circle is non-decreasing in $r$. And to compare these two averages, the previous arguments work quite well: you launch a BM from any point of an inner circle, and let it stop once it intersects the outer one. The rotational symmetry implies that the exit points are also distributed uniformly; and whatever you gain during this random walk (that is, the integral of $\Delta |q|\ge 0$ w.r.t. the expectation of the occupation measure) is the difference between the two. 

I would say that an asymptotic expansion formula for H(n) would suffice. That is, one has $$ H(n)=\log n + \gamma + \frac{1}{2n}+... ., $$ and the error terms are quite controllable. Assuming all i,j,k of the same order of magnitude, you can rewrite the condition $H(k)>2H(j)-H(i)$ as $H(k)-H(j)>H(j)-H(i)$ and thus as $$ \log \frac{k}{j} + (\frac{1}{2k}-\frac{1}{2j})+ \dots > \log \frac{j}{i} + (\frac{1}{2j}-\frac{1}{2i})+ \dots $$ If there would be only the first terms, and no integer restriction, the equality in the above formula would correspond to the geometric sequence: $k/j=j/i$. Now, roughly speaking, you get the Fibonacci sequence, because it is so close to the geometric one (error at $F_n$ is of magnitude $\sim 1/F_n$). Well, you will need some fine analysis to check that for $i=F_{n-1}$ and $j=F_n$ the inequality holds at $k=F_{n+1}$ and does not at $k=F_{n+1}-1$, but the difference between the left hand sides are "quite large" (that is, $1/k$), and you control the error terms as precise as you'd like to (see formula (13) here -- $URL$ ). The rest should be pure (and not so difficult) technique: just check the $\sim 1/k$ terms for $k=F_{n+1}$ and for $k=F_{n+1}-1$, check that they are of opposite signs, and control the error terms. 

Fix the query point $X_q$, and take random variable $\xi=D(X,X_q)$ for $X$ being distributed w.r.t. your law, and let $F_{\xi}$ be its distribution function. Then, you are taking a sample of size $N$ of $\xi$, order them by increasing (obtaining $\xi_{(1)}<\dots<\xi_{(N)}$) and you evaluate $F(\xi_{(m)})$. But for any continuous distribution of $\xi$, the random variable $F(\xi)$ follows a uniform distribution on $[0,1]$. In the same way -- as here the only things you are using are the order and the distribution function, -- the result here does not change if you make an increasing change of variable, passing to $\xi'=g(\xi)$ (as the distribution function then becomes pre-composed with $g^{-1}$). In particular, the result here will be exactly the same as if you take $\xi$ to be uniformly distributed on $[0,1]$ (this corresponds to taking $g=F_{\xi}$). And then you are asking for the law of $\xi_{(m)}$ for $\xi\sim R([0,1])$, which is exactly the beta distribution. 

Due to what's written in the text of Benjamini, I would expect it to converge to a straight line, (unless, perhaps, if your law has too heavy log-tails, I'm not sure): see $URL$ section 2: «Large balls converge after rescaling to a convex centrally symmetric shape...» (If this shape in strictly convex, what seems to me more or less natural to expect, then the geodesic for the limit metric is unique, and is the straight line.) 

The answer is no, a counterexample is for $n=1$, $m=2$: let $h$ be zero on (0,0), (0,1), (1,0), and let $h(1,1)=1$. It is rather clear that you can get it for a convex $h$. Then, $g(p_1,p_2)=p_1 p_2$, which is not a convex function on the unit square. 

Yes, it is. Take a point P, and let us check if it belongs to Nth Brillouin zone. The Bragg planes (rather, lines, as we are in $R^2$) that we have to cross while going from the origin $O$ to $P$, correspond to the points $L$ of the lattice $\Gamma$ such that $P$ is closer to $L$ than to $O$. In other words, we are looking for the number of the points $L$ of the lattice $\Gamma$ that belong to the $P$-centered ball of radius $|OP|$. This number is approximately equal to $\pi \cdot |OP|^2/\mathop{\mathrm{covol}} \Gamma$. Hence, $N$th Brillouin zone is very close to a circle of radius $\sqrt{N/\pi \cdot \mathop{\mathrm{covol}} \Gamma}$. 

Well, I cannot call it a complete answer, but it seems an idea that can work. First: take any loop in the (s,t) coordinates, and consider its image on the complex plane under $\gamma(s)+\gamma'(t)$. Any point having nonzero index w.r.t. this loop is then contained in $\gamma+\gamma'$. Second: take the loop to be the boundary of a rectangle, $[s_1,s_2]\times [t_1,t_2]$, and assume that along the second coordinate it is very thin, $t_1$ is very close to $t_2$. Then, the boundary consists of two translated images $\gamma([s_1,s_2])+\gamma'(t_1)$ and $\gamma([s_1,s_2])+\gamma'(t_2)$, and two very small curves $\gamma(s_j)+\gamma'([t_1,t_2])$. Third: I would say that the two translated images should more or less coincide, up to what happens at the endpoints. As if they do not, there is a part of one "somewhere in the middle", where it is far away from the other one, and then, crossing the curve, we change the index -- so on one of two sides there will be an open set of points with nonzero index. Last: making $t_2$ go towards $t_1$, in the limit of the almost-translation-invariance above we get that $\gamma([s_1,s_2])$ is a straight line. And this allows to conclude easily, as $\lambda$ is not real. Well, as I've said, it's a sketch, but it has a good chance of working. Upd.: I'm now sure that this argument works. For "somewhere in the middle", I mean the following. Lemma. Let $\delta$ be the diameter of $\gamma'([t_1,t_2])$, and assume that there is no point with nonzero index w.r.t. the loop described in the "Second." step. Then, the sets $\gamma([s_1,s_2])+\gamma'(t_1)$ and $\gamma([s_1,s_2])+\gamma'(t_2)$ coincide outside $\delta$-neighborhoods of $\gamma'(t_{j})$. Sketch of the proof. Assume the contrary and let $z$ be a point of a curve $\gamma([s_1,s_2])+\gamma'(t_1)$ that lies outside the above neighborhoods and that does not belong to the $\gamma([s_1,s_2])+\gamma'(t_2)$. Due to the continuity, there is $\epsilon$-neighborhood of $z$ that the latter curve does not intersect. Now, in this neighborhood one can find two points "on different sides" with respect to the first curve (yes, this phrase should also be more formally stated with an appropriate reference to the Jordan curve theorem). Such two points have thus different index w.r.t. all the closed loop (image under $\gamma(s)+\gamma'(t)$ of the boundary of the rectangle $[s_1,s_2]\times [t_1,t_2]$). Hence, at least one of them in an internal point of the sum $\gamma+\gamma'$. $\square$ Passing to the limit as $t_2\to t_1$ says that the curve $\gamma([s_1,s_2])$ should admit (if there is no internal point) arbitrarily small translational symmetries outside arbitrarily small neighborhoods of its endpoints. Hence, it is a straight segment.