I'm looking for more information about the utility MKSTORE that can be used for creating and modifying a Wallet. I would like to know things like what the -createALO option is and what the difference is between -createSSO and CreateLSSO. A link to the information would be fine or a document number on MOS. My goal is to script the Wallet creation and am wondering if these options can help me in any way. 

A primary key using the leading column of a unique index would require non-unique index constraint logic on a unique index. This would require changes and/or additions to the logic. If id is unique/primary then (id,val) is inherently unique, and normally you would not need/want a unique constraint/index on (id,val). You might want a unique index on (id,val) if there were a query referencing (id,val) and you wanted to prevent a table look-up. If this is your situation, you may have to decided which is the lesser tradeoff between allowing the table look-up, increasing the primary key to (id,val) or having two unique indexes. For most situations I suspect the table look-up would be preferable. 

Prior to Oracle 11.2 I was using a custom aggregate function to concatenate a column into a row. 11.2 Added the LISTAGG function, so I am trying to use that instead. My problem is that I need to eliminate duplicates in the results and don't seem to be able to do that. Here is an example. 

If instead you want feedback when this occurs rather than just ignoring the duplicate, you can nest the INSERT into a BEGIN...EXCEPTION...END block that catches the constraint violation and handles it by doing a DBMS_OUTPUT. 

Interesting question. As far as I can tell, this is not possible, though it seems like it should be. Unless someone else can show how it can be done, a workaround would be to nest the code in a block: 

Your desire to make a generic solution for all part number generators comes at the expense of making a good one for the domain you are in. VALUES and VALUESET tables could be used to represent almost anything. The components of your part numbers (Fabric Backer, Stitching Type, Stitching Color, etc.) are good candidates for well-defined database tables and the resulting part numbers are also good candidates for being stored in the database. The part number generation itself, however, should probably be in code. This code can (should) be in the database and may come in the form of one or more functions depending on how many different types of part numbers need to be generated. Some of the difficulty in answering your question is that we don’t know the scope of your part numbers. If your part numbers will pull from mostly the same sets of data, then you might even consider referencing the source tables in the table with the generated part numbers. Not only would this enforce valid data, it would also allow joining to see things such as part numbers and their Fabric Color descriptions. The part number itself could then even be a computed column in the table itself. 

The syntax of your dynamic create trigger statement is invalid. The select from dual and definition of NAZWA_TABELI for ora_dict_obj_name is unnecessary. The outer trigger will fire for every table, though it only needs to for one. The dynamic SQL could be a constant but is not. An early return could be used but is not. The If statement could encompass the sq0 definition, but does not. The insert will break if a new column nullable column is added to pstepien. You are creating a trigger to do what normal code should do. You are creating a trigger inside a trigger. 

The phrase "but not use the JOIN ON syntax" may mean you should use the older 8i style of joins that doesn't use words "JOIN ON" at all, or it may mean you should use "JOIN USING" rather than "JOIN ON". Hopefully they meant the latter. 

To add just a bit to the correct answer from Vérace (+1), you should go further than separating different types into different columns, you should also define what your columns are and use them appropriately. This is called design and it is a necessary step for an understandable, scalable, good performing system. Just to hit on the understandable angle, compare this: 

Memory If the client application allocates memory using the maximum size, the application would allocate significantly more memory than is necessary. Special considerations would have to be done to avoid this. Documentation The size of the field provides another data point of documentation about the data. We could call all tables t1, t2, t3, etc. and all fields f1, f2, f3, etc., but by specifying meaningful names we better understand the data. For example, if an address table for a company with customers in the U.S. has a field called State that is two characters we expect the two character state abbreviation to go in it. On the other hand if the field is one hundred characters we might expect the full state name to go in the field. 

The code doesn't handle to presence of an existing column named XXX. You might consider at least making the name a bit more obscure. Perhaps a quoted string of 30 mixed case letters and numbers. Even better you could handle the name exception and try a different name. 

Gaius has the correct answer+1. You should consider virtualizing the server to run both the original and the clone in separate virtual machines. It makes the setup of the clone considerably simpler and can help with managing the priorities between the two instances. If that is not possible and you are on 11.2+ you should look at instance caging. 

SYSDBA and SYSOPER System Privileges SYSDBA and SYSOPER are administrative privileges required to perform high-level administrative operations such as creating, starting up, shutting down, backing up, or recovering the database. The SYSDBA system privilege is for fully empowered database administrators and the SYSOPER system privilege allows a user to perform basic operational tasks, but without the ability to look at user data. The SYSDBA and SYSOPER system privileges allow access to a database instance even when the database is not open. Control of these privileges is therefore completely outside of the database itself. This control enables an administrator who is granted one of these privileges to connect to the database instance to start the database. You can also think of the SYSDBA and SYSOPER privileges as types of connections that enable you to perform certain database operations for which privileges cannot be granted in any other way. For example, if you have the SYSDBA privilege, then you can connect to the database using AS SYSDBA. The SYS user is automatically granted the SYSDBA privilege upon installation. When you log in as user SYS, you must connect to the database as SYSDBA or SYSOPER. Connecting as a SYSDBA user invokes the SYSDBA privilege; connecting as SYSOPER invokes the SYSOPER privilege. Oracle Enterprise Manager Database Control does not permit you to log in as user SYS without connecting as SYSDBA or SYSOPER. When you connect with the SYSDBA or SYSOPER privilege, you connect with a default schema, not with the schema that is generally associated with your user name. For SYSDBA this schema is SYS; for SYSOPER the schema is PUBLIC. 

The problem is that when is changed to the Index_Stats view does not get populated. Is there an online way to determine the benefit of compressing an index and/or the number of columns that will produce optimal compression? Update: $URL$ indicates that if Distinct_Keys from DBA_Indexes is "a lot smaller" than num_rows then the index is a good candidate for compression. This helps some, but isn't definitive and doesn't help determine the number of columns. He does give some guidelines for that, but nothing that can be determined programatically without a bunch of dynamic SQL. 

Oracle support has been no help. After about a week of the jobs sometimes running they stopped running completely. Every single job got an initialization error every time it ran and every time it was retried. We are in the process of re-creating the repository and migrating to dbms_scheduler jobs. 

Justin inspired me to attempt a version using the clause. This is my first use of the clause, so I'm open to any constructive criticism. I created three CTEs to test negative numbers and zero. 

Just so there is some sort of answer to this, here is some information I have found. On MOS there is a document called "High Numbers of 'Asynch Descriptor Resize' Wait Events Seen" (Doc ID 1273748.1) This seems to indicate that the problem is really another wait event slowing the system down and in turn causing these, so they aren't really the source wait event. Oracle-L has a thread on the wait event, but no mention of it on Windows. OakTable has some interesting info on the problem, and says, 

To your specific question of (easily satisfied) plausibility, the answer is yes. Since you seem to be looking for a broader critique. You seem to be mostly on the right track, but a few things are making your description overly complex. It looks like your Classes table is more like what I would consider a course to be and your departments_teachers_and_classes is more of what I would expect a Classes table to be. A course would be Math, but a class would be the Math course taught by a particular teacher during a particular school term. A class is like an instance of a course. To carry this change through, your departments_teachers_classes_and_students could simply be ClassStudents. It seems as though you are using the department concept on several different levels. You should decide where the department belongs and stop referencing it everywhere else. You've said that a teacher can teach for multiple departments, so we can't put the department in the teachers table. This leaves Classes and Courses. Whichever you decide, it need only have a foreign key to the Departments table (unless you decide that one can be in multiple Departments). This eliminates the Departments_and_teachers table. Teachers_and_Students could be replaced with a teacher foreign key in the Classes table and students/classes foreign keys in a ClassStudents table. In short, for the portion of the design you have described, you probably need the following tables: