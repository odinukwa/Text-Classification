Let G be an algebraic group (or, since the question was tagged as differential geometry, a Lie group). Then if we're given a principal G-bundle $E_G$ and a representation V of G, we get a vector bundle out of this through the associated bundle construction: $(E_G \times V)/G$ is a vector bundle with generic fiber V. Here, G acts on $E_G \times V$ as $g(x,v) = (xg^{-1},gv).$ This shows that fixing a G-bundle determines an exact tensor functor from the category of representations of G to the category of vector bundles. There's a converse to this which says that giving an exact tensor functor from representations of G to vector bundles is equivalent to a G-bundle. 

I think the following should work for $\mu.$ If $F \in m^i,$ then both derivatives of $F$ live in $m^{i-1}.$ Denoting the ideal generated by the partial derivatives by $J_F,$ it follows that $J_F \subset m^{i-1}.$ Then $(\mathbb{C}[x,y]/J_F)/(m^{i-1}/J_F) \simeq \mathbb{C}[x,y]/m^{i-1}.$ This shows that $\mu = \frac{i(i-1)}{2} + \text{dim }m^{i-1}/J_F.$ I think (and this should probably be verified) that this latter dimension is minimized when the two generators of $J_F$ are two generators for $m^{i-1}.$ We could then assume, for example, that $J_F = (x^{i-1}, y^{i-1}).$ Then $\text{dim }m^{i-1}/J_F = i-2$ (with a basis given by $x^{i-2}y, \ldots, xy^{i-2}$). Putting this together gives a minimum $\mu$ value as $\frac{i(i-1)}{2} + i-2.$ I notice that this disagrees with Roy Smith's answer above when $i>2$ (my answer is smaller). Perhaps I've made a mistake somewhere? 

Highest weight theory is ideally suited to answer just this sort of question. Here's how to figure out your problem. 

You can use connectedness to prove that $\mathbb{R}$ is not homeomorphic to $\mathbb{R}^n$ for any n>1 by noting that $\mathbb{R} \backslash 0$ is not connected while $\mathbb{R}^n \backslash 0$ is connected. The students may not be very impressed by this as it is telling them something they probably already assumed was true. I suppose that if you wanted them to discover cohomology, you could challenge them to find a reason why Euclidean spaces of different dimensions are never homeomorphic (I realize that this probably isn't very reasonable). 

Suppose we have a finite group $G$ with subgroup $H$, a representation $\rho_V$ of $H$ on a finite-dimensional vector space $V$, and an $H$-invariant inner product on $V$: $$\forall x,y\in V, h\in H,\enspace \langle\rho_V(h)x, \rho_V(h)y\rangle = \langle x,y\rangle$$ We will write $V_I$ for the direct sum of $\lvert G:H \rvert$ copies of $V$: $$V_I = \oplus_{i=1}^{\lvert G:H \rvert} V$$ We define a map $L_i$ that lifts $V$ into the $i$th copy in the direct sum: $$L_i: V\to V_I\\ L_i v = 0 \oplus 0 \oplus ... \underbrace{v}_{i\text{th summand}} \oplus 0 + ...$$ We extend the inner product on $V$ to one on $V_I$: $$ \langle \sum_i L_i x_i, \sum_j L_j y_j \rangle = \sum_i \langle x_i, y_i \rangle$$ From each left coset $K_i$ of $H$ in $G$ we pick an element $k_i$, so $K_i=k_i H$. We then have an induced representation $\rho_I$ of the group $G$ on $V_I$: $$\rho_I(g) \sum_i L_i v_i = \sum_i L_{j(g,i)} \rho_V(k_{j(g,i)}^{-1} g k_i) v_i$$ where $j(g,i)$ is the index of the coset $K_i$ to which $g k_i$ belongs. Now, suppose we have an irreducible representation $\rho_W$ of $G$ on some finite vector space $W$. The Frobenius reciprocity theorem says that $Hom_H(W,V)$, the space of $H$-intertwiners from $W$ to $V$, i.e. the space of maps $S$ that satisfy: $$S: W\to V\\ \forall h\in H,\enspace S \rho_W(h) = \rho_V(h) S$$ is isomorphic to the space $Hom_G(W,V_I)$ of $G$-intertwiners from $W$ to $V_I$, i.e. the space of maps $T$ that satisfy: $$T: W\to V_I\\ \forall g\in G,\enspace T \rho_W(g) = \rho_I(g) T$$ Indeed, given an intertwiner $S\in Hom_H(W,V)$ we can easily construct an intertwiner $T_S\in Hom_G(W,V_I)$: $$T_S w = \sum_i L_i S \rho_W(k_i^{-1}) w$$ As we vary $S$ over any basis of $Hom_H(W,V)$, the associated map $T_S$ will map $W$ into distinct subspaces of $V_I$, each of which is invariant under the action of $\rho_I$, and each of which has the property that the restriction of $\rho_I$ to that subspace is equivalent to $\rho_W$. My question is: supposing the dimension of $Hom_H(W,V)$ is greater than 1, does there exist an "easy" strategy to choose a basis $\{S_1,S_2,...\}$ of $Hom_H(W,V)$ such that the subspaces $T_{S_1}(W), T_{S_2}(W), ...$ of $V_I$ will be mutually orthogonal? By "easy", I mean something less computationally demanding than simply finding all the subspaces by means of an arbitrary basis for $Hom_H(W,V)$, and then decomposing their direct sum into orthogonal invariant subspaces. In other words, I am seeking to leverage the fact that $Hom_H(W,V)$ is a lower-dimensional space than the direct sum of the $T_{S_i}(W)$ in order to carry out a less demanding procedure to achieve the same result. Edited to add: One easy way to get a basis of $Hom_H(W,V)$ is to take a sufficient number of linearly independent maps $S^{(0)}_i: W\to V$ and average over the subgroup $H$: $$S_i = \frac{1}{|H|}\sum_{h\in H} \rho_V(h) S^{(0)}_i \rho_W(h^{-1})$$ So by starting with a basis of (non-intertwining) maps from $W$ to $V$, you can project as many as required into $Hom_H(W,V)$ to obtain a basis. My (possibly naive) hope is that there might be some way of modifying this construction to lead directly to a basis with the property I'm seeking. 

The geometric Eisenstein series is quite complicated, see the paper by Gaitsgory and Braverman $URL$ As the authors point out, a naive guess for the geometric Eisenstein functor would be the functor from sheaves on T-Bundles to sheaves on G-Bundles (T is a maximal torus of G) given by pulling back to sheaves on B-Bundles and then pushing forward to sheaves on G-Bundles. However, they explain that the fact that the map from B-Bundles to G-Bundles is not proper introduces problems, making it so that the geometric Eisenstein series does not behave as expected. For this reason, they have to replace B-Bundles by their Drinfeld compactification and (for others reasons they explain) also tensor with the IC sheaf of the Drinfeld compactification to get the correct functor (note that the Drinfeld compactification is singular, so the IC sheaf is not just the constant sheaf). 

I think a good illustration of why torsion-free sheaves on singular curves are both interesting and difficult is given by the following. Consider the $GL_n$ case of the Hitchin fibration, i.e., the map from the moduli space of vector bundles of rank $n$ with a twisted endomorphism on a smooth, projective curve to the Hitchin base space of characteristic polynomials. Then a result of Beauville, Naramsihan, and Ramanan (see this paper $URL$ says that for a sufficiently nice characteristic polynomial $a$ in the Hitchin base, the stack of torsion-free coherent sheaves of rank one on the associated spectral curve is isomorphic to the Hitchin fiber associated to $a$. See, for example, the notes on the Hitchin fibration on Drinfeld's geometric Langlands page for a quick introduction to these ideas. In general, these spectral curves will be singular (which is why I couldn't simply say 'line bundle' in the above correspondence). Given that the Hitchin fibration and Hitchin fibers are some of the most interesting geometric objects currently being studied, I think this gives a flavor for how interesting torsion-free sheaves on singular curves (and these are just rank one) can be. Also, it's worth mentioning that the curves which arise as spectral curves aren't even that singular (nodal and cuspidal elliptic curves are a couple examples), in the sense that the dimension of the tangent space at any point is at most two. There's an old result (I think from 1979) of Altman, Iarrobino, and Kleiman proving that in this situation, the stack of line bundles is dense in the stack of torsion-free coherent sheaves of rank one. This result has since been generalized to arbitrary reductive groups by Ngo in his paper proving the Fundamental Lemma. 

I've found a somewhat nicer proof than the version on the Visual Insight blog. This new approach doesn't entail a huge conceptual breakthrough, but it does avoid having to deal with 3072 individual cases. We have some freedom in choosing $R$ and $S$, but this makes no difference to the resulting sets of axes. We will pick: $$\displaystyle{R = \frac{1}{4} \left( \begin{array}{ccc} 2 & 1-\sqrt{5} & -1-\sqrt{5} \\ 1-\sqrt{5} & 1+\sqrt{5} & -2 \\ 1+\sqrt{5} & 2 & -1+\sqrt{5} \end{array} \right)}$$ $$\displaystyle{S = \frac{1}{4} \left( \begin{array}{ccc} \sqrt{5}-1 & -2 & -1-\sqrt{5} \\ 2 & 1+\sqrt{5} & 1-\sqrt{5} \\ 1+\sqrt{5} & 1-\sqrt{5} & 2 \end{array}\right)}$$ All the powers of these matrices can again be written with a denominator of 4 and numerators taken from $\{\pm 2, \pm 1 \pm \sqrt{5}\}$. We can simplify things a bit by working with integer matrices in 6 dimensions. For each of the four powers of $R$ and $S$, we will multiply the matrix by 4 and then write it as a linear map between 6-dimensional spaces with separate components for the rational and irrational parts of each component of the original vector. For example, for the first power of $R$ we get: $$\displaystyle{R_6 = \left( \begin{array}{cccccc} 2 & 0 & 1 & -5 & -1 & -5 \\ 0 & 2 & -1 & 1 & -1 & -1 \\ 1 & -5 & 1 & 5 & -2 & 0 \\ -1 & 1 & 1 & 1 & 0 & -2 \\ 1 & 5 & 2 & 0 & -1 & 5 \\ 1 & 1 & 0 & 2 & 1 & -1 \end{array}\right)}$$ and for the first power of $S$ we get: $$\displaystyle{S_6 = \left( \begin{array}{cccccc} -1 & 5 & -2 & 0 & -1 & -5 \\ 1 & -1 & 0 & -2 & -1 & -1 \\ 2 & 0 & 1 & 5 & 1 & -5 \\ 0 & 2 & 1 & 1 & -1 & 1 \\ 1 & 5 & 1 & -5 & 2 & 0 \\ 1 & 1 & -1 & 1 & 0 & 2 \end{array}\right)}$$ Suppose we have some unit vector $v$ of the form: $$v = (a + b \sqrt{5}, c + d \sqrt{5}, e + f \sqrt{5}) / 2^{N+1}$$ where $a, b, c, d, e, f$ are integers, with at least one of them odd, and $N \ge 1$. We will work with the integer vector: $$w = (a, b, c, d, e, f)$$ Because $v$ is a unit vector, the components of $w$ will satisfy the conditions: $$a^2 + c^2 + e^2 + 5(b^2 + d^2 + f^2) = 4^{N+1}$$ and $$a b + c d + e f = 0$$ If we multiply any vector of this form by each of the eight $6 \times 6$ matrices corresponding to the four powers of $R$ and $S$, then it turns out that precisely one of those eight matrices will yield a result equal to the zero vector modulo 8, i.e. a 6-tuple of integers all divisible by 8. To prove this, we take the lattice of vectors in $\mathbb{Z}^6$ equal to the zero vector modulo 8, and multiply it by the inverse of each of the eight matrices in turn, to produce eight new lattices: lattices which yield 6-tuples of integers all divisible by 8 when multiplied by the appropriate matrix. In concrete terms, for a given matrix $M_i$, the basis for the associated lattice is given by the row vectors of $L_i = 8 (M_i^{-1})^T$. The original claim can now be restated as saying that every vector $w$ that meets the conditions described above will belong to the union of the eight lattices $L_i$, but no such vector will belong to the intersection of any two of the $L_i$. The first part is fairly easy to show. We can obtain a basis for the union of the eight lattices by forming a matrix whose rows are the union of all eight bases, and then reducing that $48 \times 6$ matrix to a $6 \times 6$ matrix by putting it in Hermite Normal Form (the equivalent of reduced row-echelon form for integer matrices), and discarding all rows containing only zeroes. We will call that matrix $L_U$. The test for the vector $w$ belonging to the lattice whose basis is given by the rows of $L_U$ is that the vector $(L_U^{-1})^T w$ has all integer coordinates. When we carry through these calculations, we find: $$(L_U^{-1})^T w = (2a, b-a, 2c, d-c, e-a-c, \frac{a-b+c-d+f-e}{2})$$ Since $a, b, c, d, e, f$ are integers, the only thing remaining to show is that $a-b+c-d+f-e$ will always be an even integer, given the conditions we've placed on $w$. We have the conditions: $$a^2 + c^2 + e^2 + 5(b^2 + d^2 + f^2) = 4^{N+1}$$ $$a b + c d + e f = 0$$ It follows that: $$a^2 + c^2 + e^2 + 5(b^2 + d^2 + f^2) = 0 \mod 4$$ $$a^2 + c^2 + e^2 + 5(b^2 + d^2 + f^2) - 4(b^2 + d^2 + f^2) - 2(a b + c d + e f)= 0 \mod 4$$ $$(a-b)^2 + (c-d)^2 + (e-f)^2 = 0 \mod 4$$ It's not hard to check that the sum of three squares can only be a multiple of 4 if all three of the numbers being squared are even. So we have $a-b, c-d$ and $e-f$ all individually even, so $a-b+c-d+f-e$ will be even, $w$ will belong to the lattice $L_U$, and at least one of the eight matrices multiplied by $w$ will yield a vector whose components are all divisible by 8. To prove that only one matrix yields such a result for a given $w$, we need to show that the intersection of any pair of distinct lattices $L_i$ and $L_j$ cannot contain any vector $w$ meeting the conditions we've imposed. There are 28 such pairs of lattices. Finding their bases is a bit more involved than finding the basis for a union. First, we need to construct the dual of each lattice. The dual of a lattice $L_i$ is the set of vectors $d$ such that for every $v \in L_i$, the dot product $d \cdot v$ is an integer. Its basis is given by the rows of the matrix: $$D_i = (L_i L_i^T)^{-1} L_i$$ We obtain a basis for the intersection of two lattices by forming their dual lattices, finding a basis for the union of those duals (by joining their matrices and reducing it to Hermite Normal Form), and then taking the dual of that union. If we do this for the 28 pairs of lattices, we find that in 16 cases the intersection of the lattices contains only vectors whose coordinates are all even integers. This violates the requirement that at least one coordinate be odd (which we impose in order that the corresponding vector divided by a power of 2 is in lowest terms). For the remaining 12 pairs of lattices, the requirement that at least one coordinate be odd can be satisfied if and only if one particular element of the lattice basis has an odd coefficient $\ell$ in the sum that decribes the vector $w$ with respect to that basis. But that in turn clashes with the requirement that: $$a^2 + c^2 + e^2 + 5(b^2 + d^2 + f^2) = 4^{N+1}$$ The contradiction appears if we require the equation to continue to hold modulo 8. In each case all but one of the lattice coefficients vanish, and what we end up with is: $$4 \ell^2 = 4^{N+1} \mod 8$$ which is impossible for $N\ge 1$ and odd $\ell$. Because $R$ and $S$ are rotations of order 5, the set of their first 4 powers can also be seen as the set of inverses of their first 4 powers. Because the corresponding integer matrices are multiplied by a factor of 4, a result that is a multiple of 8 corresponds to a factor of 2 in the original matrices. So what we have established is that, given any unit vector over the golden field with a denominator of $2^{N+1}$ for some $N \ge 1$, the inverse of precisely one of the powers of $R$ and $S$ will take us to another unit vector with a denominator of $2^N$. As we repeat this process, we will move back through the tree to ever smaller denominators, eventually terminating with the original cube. This means that we can reach every unit vector $v$ of this form as one of the cube axes or their opposites, and also that we can only reach it via a single path. 

(second edit: This second bullet point is still incorrect. See David Speyer's comments and Tyler Lawson's answer for a correct formulation.) 

Drinfeld and Simpson's B-Structures on G-Bundles and Local Triviality, Mathematical Research Letters 2, 823-829 (1995) comes in at under seven pages and has been quite important in all the work done on principal G-bundles (such as the geometric Langlands' program). In particular, it proved the double quotient description of G-bundles on curves (for reductive G) which had previously only been proved for $G = SL_n$ by Beauville and Laszlo. The paper can be found here. 

Edit: I now realize this is pretty much the same thing that Alberto said in the comments above. Remember that closed points of a stack $X$ correspond to the $Spec(K)$-valued points of $X$ where $K$ is an algebraically closed field. In Laumon-Moret-Bailley, they define the points of the stack to be all of the field-valued points of $X$ (including the non-algebraically closed fields). Hence specialization and generization still make sense in this context. 

Ben gave the general answer above. If you care specifically about the symplectic group and are interested in a "flag-like" description of its flag variety, then one exists. It is given by all half-flags of isotropic subspaces (this is just like for $SL_n$, the symplectic group acts transitively and the stabilizer of the standard half-flag will be the standard Borel). With this description, it's just as straightforward computing Springer fibers and the like as it is for the $SL_n$ case, which you're presumably familiar with. A reference for these flag-like descriptions can be found in the section of Fulton and Harris on "Homogeneous Spaces" (there's a similar description for the special orthogonal groups). 

This answer is an attempt to slightly rephrase Ilya's argument; I would have written it as a comment, but there's not enough room. Given a path $\gamma$ with endpoints $v_0$ and $v_n$, we have a 1-chain $c(\gamma)$, which is an integer-linear combination of edges of the graph. Let $E_{c(\gamma)}$ be the set of edges with non-zero coefficients in $c(\gamma)$; this need not include every edge that appears in the path, since some might cancel to zero in the 1-chain. If we think of these edges as decorated with the integer coefficients they inherit from the 1-chain $c(\gamma)$, we can associate a 1-chain with any subset of $E_{c(\gamma)}$. It's possible that $E_{c(\gamma)}$ as a subgraph of $\Gamma$ contains several connected components that share no vertices with each other, but since the boundary of $c(\gamma)$ is only non-zero on $v_0$ and $v_n$, and it's impossible for a 1-chain to have a single-point boundary, these components would need to include exactly one whose 1-chain's boundary was non-zero on $v_0$ and $v_n$, and all the rest would have to give 1-cycles. Since they're all disjoint, any one of the 1-cycles $\chi$ would satisfy $\langle c(\gamma), \chi \rangle = \langle \chi, \chi \rangle \gt 0$. Assuming now that $E_{c(\gamma)}$ is connected as a subgraph, we can build up a 1-chain $\sigma$ with a positive inner product with $c(\gamma)$ as follows. Starting at $v_0$, pick an edge $\epsilon_1$ incident on $v_0$, and put $\pm \epsilon_1$ in $\sigma$, with the sign chosen to be the same as the coefficient of $\epsilon_1$ in $c(\gamma)$. Then advance to the other vertex of $\epsilon_1$, and choose an edge $\epsilon_2$ such that $\epsilon_2 \ne \epsilon_1$, and $\pm \epsilon_2$ with the same sign as the coefficient of $\epsilon_2$ in $c(\gamma)$ gives a boundary for $\pm \epsilon_1 \pm \epsilon_2$ that is zero at the current vertex. This must be possible (assuming we haven't ended up at an endpoint of the path), since the boundary of $c(\gamma)$ is zero at the current vertex, so the signs of the edge coefficients in $c(\gamma)$ can't all give boundaries of the same sign here. We continue this process until we reach either $v_n$, the endpoint of the path, or a vertex we've visited before. If we reach a vertex we've visited before, we can drop any earlier edges from $\sigma$ and obtain a 1-cycle with a positive inner product with $c(\gamma)$. If we reach $v_n$, there are two possibilities. If $\sigma = c(\gamma)$ then $\sigma$ describes a simple path $\gamma'$ from $v_0$ to $v_n$ with the same 1-chain as our original path, and we can proceed to use that simple path in place of $\gamma$. If $\sigma \ne c(\gamma)$, it nonethless has the same boundary. Since $\sigma$ is supported on a subset of the same edges as $c(\gamma)$, and its coefficients are of the same sign but never greater in magnitude (and must be less on at least one edge), $\langle c(\gamma), \sigma \rangle$ will be strictly less than $\langle c(\gamma), c(\gamma) \rangle$. So we'll have a non-trivial 1-cycle $\ell = c(\gamma) - \sigma$, and: $$\langle c(\gamma), \ell \rangle = \langle c(\gamma), c(\gamma) \rangle - \langle c(\gamma), \sigma \rangle \gt 0$$ Finally, suppose we have a simple path $\gamma': v_0 \to v_1 \to \dots \to v_n$ with the same 1-chain as $\gamma$. (The following refinement of Ilya's argument is something that John described to me in correspondence.) Since the edge $e_n: v_{n-1} \to v_n$ cannot be a bridge, there must be a path joining $v_n$ to $v_0$ that does not include that $e_n$. If we follow that path only as far as the first of the $v_i$ it reaches, we will have a path $\rho: v_n \to v_i$ which uses no edges of the simple path $\gamma'$. We can then append the portion of $\gamma'$ that goes from $v_i$ to $v_n$, call it $\gamma'_i$, to obtain a 1-cycle $c(\rho) + c(\gamma'_i)$ that must have a positive inner product with $c(\gamma)$: $$\langle c(\gamma), c(\rho) + c(\gamma'_i) \rangle = \langle c(\gamma'_i), c(\gamma'_i) \rangle \gt 0$$ 

Yes, the square root of a line bundle $L$ is a line bundle $L'$ such that $(L')^{\otimes 2} \simeq L.$ I don't know of any general criteria for detecting the existence of a square root. A couple basic observations: 

No, a ring will always be free viewed as a module over itself, but its ideals certainly don't have to be free. For example, consider the ring $R = k[t]/t^2$ and consider the submodule $I = (t),$ the ideal generated by $t$. Then $R \to I$ by multiplication by $t$ and has kernel $I$. It's then easy to see that $\ldots \to R \to R \to I \to 0$ is an infinite free resolution of $I$ where each map is multiplication by $t$. 

First recall that $Sym^k(V)$ is the irreducible representation of highest weight $k$. So, it has weight spaces with weights $-k,-k+2,\ldots,k-2,k$ occurring with multiplicity one. In particular, $Sym^3(V)$ has weights $-3,-1,1,3$. Then the weights occurring in $Sym^k(Sym^3(V))$ correspond to all possible ways of adding $k$ of the weights $-3,-1,1,3$ together. For example, $3k$ will be a weight occurring, and in fact it will be the highest weight, corresponding to the fact that $Sym^{3k}(V)$ will always be a direct summand of $Sym^k(Sym^3(V))$. Having found all the weights, you know need to know the multiplicity with which they occur. For example, the reason that $Sym^3(Sym^2(V)) = Sym^6(V) \oplus Sym^2(V)$ is that the weights $-6,-4,\ldots,6$ all occur, but the weights $-2,0,2$ all occur with multiplicity two. 

This is not a complete answer, but should hopefully be a start. Given a point $x \in \mathcal{F}$, the dimension of $\mathcal{F}$ at $x$ is given by picking an atlas $X$ of $\mathcal{F}$, and then computing \begin{equation} dim_x(\mathcal{F}) = dim_x(X) - dim(Aut_{\mathcal{F}}(x)). \end{equation} The dimension of $\mathcal{F}$ is then the supremum of its dimension at all its points. Given surjective, representable $\phi:\mathcal{F} \to \mathcal{G}$, we obtain a surjective map of atlases $X \to Y$. Therefore $dim_x(X) \geq dim_{\phi(x)}(Y)$ for all points $x$. So, we're reduced to comparing $Aut_{\mathcal{F}}(x)$ to $Aut_{\mathcal{G}}(\phi(x))$. There is necessarily a surjection $Aut_{\mathcal{F}}(x) \to Aut_{\mathcal{G}}(\phi(x))$, so there is a question of how much larger the automorphisms of $x$ in $\mathcal{F}$ are compared to those of $\phi(x)$ in $\mathcal{G}$. That is, we would need to verify that \begin{equation} dim_x(X) - dim_{\phi(x)}(Y) \geq dim(Aut_{\mathcal{F}}(x)) - dim(Aut_{\mathcal{G}}(\phi(x))) \end{equation} holds for all points $x$. I feel like this should be true just because my possibly faulty intuition says that the relative dimension of the automorphisms of a surjective, representable map won't exceed the relative dimension of the atlases. However, I don't see how to prove it right now. Does anyone know how to prove this, or provide a counterexample?