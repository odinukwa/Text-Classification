At the heart of the problem of evil is the idea that God lets evil things happen, such as wars, and does nothing to stop them. So we are at odds with God as to what is good and what is evil. It can be argued that we do not have the knowledge or the foresight or the omnipotence to make such a judgement. It also could turn out that (for the sake of argument) we are fooled into thinking God is good simply when we experience his all encompassing love and feel good about ourselves. Have there been any theologians or philosophers in the history who have adressed these issues in this way? 

I believe its a deeply philosophical question, one that concerning Theology and the other concerning the philosophy of science : the ability for the process of scientific inquiry to yield accurate predictions, once a suitable theory is proposed and proven. Theological issues involve mainly relationship between extraterestrial life and God: do they have souls and related questions. But the relationship between the philosophy of science and extraterrestrial life is even more interesting: we assume the laws of physics are the same througout the universe. What about the laws of biology? The current problem seems to be that there has been no known theory of the evolution of life, but at the same time such a theory is the holy grail of evolutionary biology. Assuming then such a theory will one day exist, one will be able to predict the evolution of life in the same way Newton and Kepler helped us predict the orbit of planets with enough precision to land space probes on Mars for example. Once the mechanism is known, then it becomes easier to predict the outcome of life on other worlds the same way we can predict the existence of volcanoes and dust storms given the chemical composition of the atmosphere of other planets and the physics of climate modelling. There is, I believe, a great fear associated with the existence of a few bacteria outside of this Earth, and this fear is amenable to study by another science, the science of psychology. An interesting article here adresses this question: 

Yes, you can imagine new "colors", and there are physically meaningful complex colors that humans don't really see. Short version We see with our eyes, and those signals go back to our brains. We ascribe "color" to things that we see as colors are common patterns worth noting and exploiting, e.g. for communication. Since this question is about imagining a new color, sure, you can imagine a description that doesn't correspond to anything else that you've seen. In the absence of correspondence to physical reality, this would seem to be a pointless exercise, but there's no reason why you can't imagine it. Additionally, there're physically meaningful "colors" that we actually observe in science labs. However, you can't really "see" these colors directly as the human brain's visual processing center isn't wired to process them. Colors with more dimensions Another answer had mentioned the prospect of tetrachromacy which is sorta how animals with more sensory inputs can see things; they'd have a wider color space. However, this strikes me as a limited perspective because that seems to suggest that there's something special about seeing color in just 4 dimensions. You can perform a Fourier transform on a source of light waves to get infinitely many dimensions of color as opposed to just the 3 in human vision or the 4 in tetrachromacy. We've even built machines that do exactly this, i.e. Fourier transform spectrometers. It's somewhat difficult for a human mind to appreciate such complex "colors" in the same sense that we perceive normal colors though. For example, here's a very high dimensional color for a blue flame. Assuming that this plot uses 1 data point per /nm on the x-axis from 300/nm to 700/nm, then that's a 401-dimensional color. Even if you were to see the blue flame yourself, it'd look blue to your eyes, as your eyes don't have the spectrometer's mechanisms for seeing more. However, you can see the color through the spectrometer's eyes by observing the spectrum showed in the link. If you want to imagine it in your own eyes, it'll look like a blue flame, since that's what it is; but if you want to rewrite how your mind works, you might try to appreciate that it's a far more complex color than just "blue". Science note: The reason that we have such spectrometers is because more detailed colors can tell more about what you're looking at. In many labs, spectroscopy is the go-to method for identifying chemical compounds and other physical samples. Not much art When people talk about imagining new colors, I suspect that they're generally looking for something aesthetically pleasing. The problem here is that beauty is in the eye of the beholder; you can imagine a Fourier-transform-like visual apparatus, which would see in vastly more colors than humans normally do, but since imagining such complex colors would require a lot of work and rewiring one's own brain, it's doubtful that an observer would find aesthetic joy in it. Aesthetics seem to work best when an observer can relate to what they see on some level. Unheard of colors, such as high-dimensional colors from spectrometers, probably won't match up to this for most folks. Color blindness Some people can't perceive colors like normal, i.e. they're color-blind. At least in some cases, this results from the eyes lacking the physical hardware to pick up on some of the color signals. Looking through Google, it appears that some folks are claiming that they're getting close to a cure for some sorts of color blindness, presumably by fixing the eyes. Once a life-long color-blind person has their eyes fixed, will their brains be able to fully process and appreciate the color distinctions as though their eyes had picked up on the signals all along, or will their brains have pruned the unused informational channels? 

The word "faith" is simply too loaded a term to use in any forum where the objective is open dialog because the term is identified more commonly by its misuse in a religious context as a term related to obedience to dogma. Nevertheless, your question's meaning is clear and the answer is fundamental to the use of rigorous systems of logic. A far better term intended for this topic is "credence". The fundamental decision making model in the animal brain is Bayesian logic. That is, we learn from our experiences our personal truth on a matter. We each have a world view that is a collection of beliefs about things called credences that can be expressed as probability beforehand that I will accept as true the next thing I see. The more consistent our experiences regarding a matter, the strong our belief in that truth becomes. One example of a new truth is seldom enough to change our minds; but, it should increase my credence on the matter, thus making it more likely I will accept it next time. This system of reasoning is called abduction, as opposed to induction or deduction. Now, man has known for a long time that abduction is fraught with pitfalls because of its very subjective and localized nature. So, early, most notably Aristotle and his contemporaries in the west, tried to develop "objective" systems of logic; in all cases, certain assumptions were necessary to proceed. Aristotle assumed that any logical and meaningful statement must either be true or false. Plane geometry assumes a well defines domain of an infinitely flat surface. Newton Physics assumes that time is a constant and proceeds forward in the same manner everywhere. Einstein assumed that light speed is constant in any frame of reference in order to derive Special Relatively. So, axioms play an important role in even the most rigorous investigation based on inductive and deductive reasoning, and setting these axioms uses abduction. It is a general rule of thumb for most investigative diciplines that we not debate the answer before first debating the assumptions. Therefore, yes, you are correct that any "proof" or conclusion is tied to the assumption used in the derivation. Therefore, the assumptions are the first place we look for a system's boundaries or domain of applicability. It is not, however, necessary for one to "believe" an assumption or axiom in order to play the game of "what if?". In fact, it is often the case that starting from an assumption is contrary to common belief results in a paradigm shift in man's understanding of nature and reality. 

The fallacy isn't in that calling Bob smelly is rude; as far as logic goes, that's perfectly fine. The problem's that Bob's odor doesn't typically have anything to do with statements he might make, e.g. X. That said, it's still possible for this to not be a fallacy. For example, if it's: 

So, obviously, something must exist within a debate to be a fallacy within it. For example, someone can turn on a TV, but if that's not part of a debate, it can't be a fallacy or non-fallacy within it. The main point of this post is that folks might be confused due to the assumption that all words in an exchange in which a debate occurs are necessarily part of the debate. But, that's the basic mistake. Instead, people can exchange words, including having one-or-more debates, without all words being part of all of the on-going dialogs. This is like how a computer can play music from the internet while a user is checking their email; the email app and music app are both streaming info over the same serial line, but the music doesn't exist in the email app nor do the emails exist in the music app. 

Einstein was a proponent of hidden-variable theory. The gist is that, if something appears random, then it's really just chaotically dependent upon information we don't have. So, God (the universe) doesn't play dice. Subsets of it might, but Einstein held that a complete description of the universe would be fully deterministic. Any description reliant on randomness merely omits the hidden variables. 

Logic, mathematics, science, musicology, and most systems of government and commerce are all examples of attempts to create rigor and consistency in our thinking to address the flaws of our built-in logic inherited from our mammalian ancestors. We are born using a form of Bayesian logic or abduction described in the Theory of Sufficient Reasoning. Immortalized in "Occum's Razor" we gravitate to the simplest explanation, drawn from no more than our personal history of experiences. We judge our experiences and form a collection beliefs in a world view that acts like a filter or paradigm through which we judge future events. Each belief carries with it a credence value or disposition regarding how strongly the belief is held. When an event is witnessed displaying evidence in favor of or against the belief, the rational person will then adjust the credences affected accordingly based on their judgement as conditioned by the prior credence values. $URL$ The strength of abductive logic is that we can make quick decisions without perfect or complete knowledge of the facts, a very valuable tool for survival. This survival skill, however, comes with obvious flaws. Quick decisions without sufficient data results in tragic errors. Also, chronic, traumatic or systematic conditioning can set credences so high that one may not be able to recognize new evidence let alone judge it. Lastly, a credence change cannot be made without maintaining consistency in one's world view. If changing one credence causes unacceptable changes in other, the original belief change may be set aside, thereby weakening the authenticity of one's world view. So, the logic systems found in scientific, mathematical, and philosophical systems do impose rules of engagement to ensure integrity and reliability and to avoid or mitigate the flaws in abduction. Ironically, when scientific or mathematical discoveries are offered, abduction takes full charge in judging its acceptability. Resistance to change that threatens the system underpinning will be vociferous, even though the logic and evidence are compelling. Logic systems are like scientific theories. If they consistently provide the right answers in their assigned domains, we accept and use them. But, what happens when a contradiction appears? Your final concern, whether our choice of logic affects our math and other pursuits is a resounding affirmative. Aristotle's logic based on the premise that a statement must be either true or false created the logical foundation for the industrial revolution and remain embedded in every institution even though it is patently and inhumanly wrong. (Any Charles Dickens novel) Ultimately, you may master these systems and still have doubt about their credibility because your world view objects regardless of the evidence. On the other hand, you may find, as you learn more, that your inherit logic system can serve you well with help from other logical points of view. I suggest that you suspend judgement for a while, and allow your natural curiosity to seek out the answers to your concerns with knowledge. 

There has been much interest recently around the discovery of Earth- like planets. While thinking of the possibility of life on those planets, I came to the realization that assuming there is no life on those planets, given that they are Earth -like, seems to be an unwarranted assumption. A planet with Earth - like geophysical features but with no life will have to have: 

Is it reasonable to assume that the same processes that formed the Earth and other planets resulted in the creation of life on Earth but somehow did not result in creating life on other planets? For those who believe that God created the universe, isn't it limiting God to imagine that He created Earth -like planets but stopped short of creating plant and animal life on those planets except on Earth? This seems to me to be an artifical limitation place by us humans on how the universe develops. 

I believe that Theists are reluctant to agree that everything that happens is God's will, with the knowledge and consent of God, even planned in advance. This reluctance seems to stem from the reason that this will make all the evil things in this world (according to our estimation of what is good and evil) all seem that they were planned and orchestrated by God Himself, making God the creator of evil. The problem of good and evil is adressed by other answers on this site, however I am still no sure what the reason for the objection among theists for the belief I have stated in the question. Perhaps because it leads to fatalism? One possible answer is that everything is God's will, and God, is like a surgeon, permitting pain to warn us of a serious disease within our souls, performing painful operations to rid us of the disease of wickedness within us, and getting us ready for a pain free, blissful afterlife? This is one possibility but I have not seen this opinion clearly articulated anywhere yet. If this is the answer, then we can preserve the concept of God's goodness as well as the idea that everything that happens is according to a Divine plan. 

Within the context of the debate, it's essentially a non-statement. As discussed in @CortAmmon's answer, this contextual confusion. Analogy: Multiplexing serial communications Most computers can be said to have a single serial port through which they access the internet. All of the data that comes in is like a stream of 's and 's, then gets streamed to various endpoints through multiplexing:             . The above multiplexer description is flat, though in practice multiplexing tends to be a hierarchical process. Anyway, details aside, it's then important for the communication protocol to sort incoming data into the various endpoints that ought to receive it. With computers, multiplexing tends to require precise framing. Part of this is that ambiguities can be exploited, allowing hackers to get undesired effects:     . With humans, our language tends to be far less precise, so while we must still multiplex our communications, the routing process involves a lot more inference. As given in the question statement, doesn't intend for the string to be parsed within the context of the argument. Since that string should never be routed to the argument in the first place, it has no existence within the argument; it's neither a fallacy nor a non-fallacy. At most, can say (in awkwardly precise language): 

tl;dr- You're right, this is a common misunderstanding. While perhaps not particularly mature, calling someone a "bloody idiot" can be a comment outside of the context of a debate. Rather than being a fallacy or non-fallacy, such a statement doesn't exist within the context of the debate at all. 

Not to say that this is polite or acceptable in moderated venues, e.g. on StackExchange, however it'd be logically correct. On moderated venues, it may simply be easier to stop responding. This also has drawbacks in cases due to the public nature of such forums, though I guess various constraints limit how much can be effectively communicated anyway.