Isn't the condition you mention just saying that the $g_{\alpha\beta\gamma}$ depends only on the corresponding intersection and not on the order in which the three sets are listed in writing down that intersection, mod transposition of any two. It is thus a normalisation condition, like saying $g_{\alpha \beta}=g_{\beta\alpha}^{-1}$ or $g_{\alpha\alpha}=1$. Are you thinking it is more than that? If you know about Cech complexes and simplicial objects this is like a `compatibility with degeneracy' condition together with a symmetry condition. (I personally like the clarity that comes, for me, with using simplicial objects, although some people find the notation can get in the way.) It may help to compare Hitchin's treatment with that of Larry Breen in $URL$ or $URL$ Looking at several treatments will I am sure help resolve the difficulty. As an aside it is interesting / fun to look at case in which the order of intersection does influence the assignment, i.e. in which $g_{\alpha\beta}$ need not be $g_{\beta\alpha}^{-1}$, as that to a limited extent reflects a more 'quantum theoretic' viewpoint in that an `observation' corresponding to $U_{\alpha}$ followed by one corresponding to $U_\beta$ need not be the same as when the observations are done in the opposite order. 

For example, is there a sequent calculus giving linear proofs and being simultaneously complete (and sound, of course) for classical first order logic? Or, on the contrary, is there some result limiting similar ambitions? P.S.: I know about deep inference, so let us restrict to `standard' sequent calculi. 

I wish someone had told me about this book when I was younger: A.I. Mal'cev, Algorithms and Recursive Functions. The exposition is simple, thought provoking and rigorous. You are teased to delve into many strains when reading it. 

Background When faced with the task of formalizing sequent calculus on a set theoretical proof assistant (Mizar), I felt trees would have been not so easy to actually work with, so I devised alternative frameworks. It worked, in the sense that one can manage not to ever mention trees and still carry on a great deal of results; however, they are still morally there, hence the question arose naturally. 

Although I am not so good with philosophical subtleties, I have always found useful to make a distinction between an antinomy and a paradox. The first leads to a formal contradiction, i.e., a logical inconsistency in your theory (you can prove both a formula and its negation). The second `merely' defies human intuition, without being a (known) antinomy. Much less worrying (ask Frege :)). Many just use `paradox' for both things, but I find this highly confusing. 

There is another description of $H_2(G)$ due to Miller: Miller, Clair The second homology group of a group; relations among commutators. Proc. Amer. Math. Soc. 3, (1952). 588--595. In modern terminology, let $x,y\in G$ and denote ${}^xy=xyx^{-1}$. Let $G\wedge G$ be the group generated by the symbols $x\wedge y$, $x,y\in G$, subject to the following relations: $$ xy\wedge z = ({}^xy\wedge {}^xz)(x\wedge z),\quad x \wedge yz = (x\wedge y)({}^yx\wedge {}^yz),\quad x\wedge x = 1, $$ for all $x,y,z\in G$. The group $G\wedge G$ is also known as the nonabelian exterior square of $G$. There is a commutator homomorphism $\kappa :G\wedge G\to [G,G]$ given by $x\wedge y\mapsto [x,y]$. Miller essentially proved that $\ker \kappa$ is naturally isomorphic to $H_2(G)$. This is closely related to the answers of Henry Wilton and Richard Kent. Namely, $G\wedge G$ is isomorphic to the derived subgroup of a covering group $\hat{G}$ of $G$, and it is not difficult to find an isomorphism between $\ker\kappa$ and $(R\cap [F,F])/[F,R]$. 

There is a whole theory of functional equations (or functional identities) in algebras. It was used for instance to obtain solutions to some of Herstein's problems on Lie homomorphisms. An overview of the theory is given in the book Bresar, Chebotar, Martindale, Functional identities The area has its own entry in the 2010 MSC (16R60). 

You seem to be asking about computers formulating conjectures later proved by humans. As one not having had much exposure to the issue, I wonder how to teach a computer (maybe with some form of heuristics?) assessing it has found a plausible conjecture: in this case computer misses the comfort of knowing a result is true for it has proven it's true, while human mathematicians can use instinct or some kind of common sense. However, I found this: A Symbolic Finite-State Approach For Automated Proving of Theorems in Combinatorial Game Theory 

In Gentzen's sequent calculus, a formal proof is described by a tree, with each node representing the sequent obtained from the child(ren) by applying a given inference rule. If no inference rule has more than one premise, such a tree becomes a sequence: in a 1957 paper, Craig devised Linear Reasoning to pursue such an idea; an evolution of this approach (seemingly related to Craig's famous interpolation theorem, by the way) is exposed in the standard First-Order Logic textbook by Smullyan (chapter XVII in my edition). The corresponding theorems, however, pose various restrictions: for example, on the form of the sentences involved. 

Every group of exponent 3 is nilpotent of class at most 3, and this bound is best possible. The question whether finitely generated groups of exponent $n$ are finite is also known as the Burnside problem. There is an excellent historical overview of this problem, along with a list of relevant references. 

Lie algebras over rings (Lie rings) are important in group theory. For instance, to every group $G$ one can associate a Lie ring $$L(G)=\bigoplus _{i=1}^\infty \gamma _i(G)/\gamma _{i+1}(G),$$ where $\gamma _i(G)$ is the $i$-th term of the lower central series of $G$. The addition is defined by the additive structure of $\gamma _i{G}/\gamma _{i+1}(G)$, and the Lie product is defined on homogeneous elements by $[x\gamma _{i+1}(G),y\gamma _{j+1}(G)]=[x,y]\gamma _{i+j+1}(G)$, and then extended to L(G) by linearity. There are several other ways of constructing Lie rings associated to groups, and there are numerous applications of these. One of the most notorious ones is the solution of the Restricted Burnside Problem by Zelmanov, see the book M. R. Vaughan-Lee, "The Restricted Burnside Problem". There's other books related to these rings, for example, Kostrikin, "Around Burnside", Huppert, Blackburn, "Finite groups II", Dixon, du Sautoy, Mann, Segal, "Analytic pro-$p$ groups". 

Rather than to a book, I point you to real formalizations in a set theory: I deem this appropriate given the question itself. Otherwise, downvote me please :) I happen to have formalized in Mizar set theory (which is Tarski-Grothendieck, i.e. ZFC on steroids) the stuff you seem pointing to: language, wffs, interpretation, satisfaction relation, evaluation, sequent derivability, provability, etc... In FOMODEL1: $URL$ you get most syntax (up to definition of atomic formula, or 0wff). In FOMODEL2: $URL$ you will find the definition of satisfaction. That is a series of five subsequent articles starting from scratch and getting to completeness theorem (and Lowenheim-Skolem, the latter only on my homepage, not submitted to Mizar people yet). The links point to hypertextual, proof-pruned versions. For full formalizations, look for the same files with the extension .miz in that same server. Mizar formalizations are arguably among the most readable for the average mathematician (that's the factor that got myself started with it), that's why I thought you could find this stuff of some interest.