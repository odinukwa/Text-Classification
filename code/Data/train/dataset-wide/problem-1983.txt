STEP 07) run on M1 STEP 08) run on M1, S1, M2, M3 Where is 0 on all the servers... STEP 09) Point you application to other servers as desired Any questions ??? If none Give it a Try !!! Your mission, should you decide to accept this, is to practice this is a Dev/Staging Environment and make sure you trust this algorithm before doing this in Production. In the event your data is caught or killed, the DBA StackExchange and I will disavow any knowledge of your actions. 

For every table that uses INT and you want to switch to BIGINT, you must forecast how much additional space to expect. For example, for figure out how much space will increase when you shift all INT(10) columns to BIGINT, run this query 

Since you want to treat NOW() as deterministic rather than stochastic, you should create a table called and initialize it with whatever date and time you have determined for the test. 

Your syntax is just fine !!! Your error message has as the problem. Take a closer look at the message: 

As your link points out, can break a transaction In fact, according to Page 418 Paragraph 3 of MySQL 5.0 Certification Study Guide 

I can't tell if this involves Aurora, but here is something worth noting: There are occasions when InnoDB will leave lock lying around. How does this happen ? About six years ago, I answer this question : Are InnoDB Deadlocks exclusive to INSERT/UPDATE/DELETE?. In that post I mentioned the following from the MySQL Documentation: 

This is an oversimplified answer. If there is a row with PK=1, you find it. If not, a full table scan may ensue because of gameid not being indexed. You are better off splitting the query with a UNION. Perhaps, like this: 

Running OPTIMIZE TABLE (reduces table fragmentation and recreate indexes) may not be necessary unless you do heavy INSERTs, UPDATEs, DELETEs. I'll say it is optional. Give it a Try !!! 

Possible scenarios are endless !!! Remember, whatever you allocate for, leave enough RAM for DB Connections and the Operating System. 

Given this output, I would expect a shutdown to have these lines at the end of the error log. UPDATE 2015-01-09 14:47 EST I just ran this 

will perform a CHECKSUM TABLE against all tables on Master and Slave. You can configure it to do all databases on just specific ones. can be run on a Slave against any table. Using the --print and --sync-to-master options, you can see what SQL statements need to be executed on the Slave to have it perfectly match the Master. This tool does not work with table that lacks a PRIMARY KEY or UNIQUE KEY. I have used MAATKIT for years. I still do. I have not tried the Percona Toolkit yet, but I am sure it should be of the same quality as MAATKIT. 

Just replace the NOW() function calls with whatever datetime you like and you will have the week starting Thursday all the time for the give datetime you choose. Here is another example using the specific date '2011-01-01' 

If either one of these good things apply, then I have good news for you STEP01) Zap All Binary Logs on the Master (OPTIONAL) Run this command on the Master: 

If every value other that 1 works, it sounds like a problem with the sign of the number being autoconverted in your OS. You should just do and be done with. You could also do . I tried this in InnoDB and MyISAM on MySQL 5.5.12 on my PC 

has a section on binary log events (pages 223-227). Those events have unique codes that are being interpreted as follows: 

You dropped an index with a specific index name () and with a specific column list (just one column, ) and then said add a new index with the same name and the same column list but make it the index . The net effect is that the index was never really dropped and the attribute was simply attached to the already existing non-unique index. Then, under the hood, mysqld attempted to load data into the table which is already populated and an index that's still populated, thus creating a duplicate key error. Please note I am only asserting this. I would have to look at source code for 5.7.13 to see if this is indeed occurring. Notwithstanding, 5.7.12 and 5.7.14 cannot reproduce this problem. This indicates that this strange condition was addressed when making 5.7.14. In light of all my conjecture, here are my suggestions: SUGGESTIONS SUGGESTION #1 : Upgrade to 5.7.14 or above SUGGESTION #2 : Change the to use a different index name 

They all have seem to have one thing in common: MySQL for Windows. It was claimed that Bug 7403 (the second link) was fixed and patch implemented July 14, 2005: $URL$ The versions of MySQL that this fix should be in 4.0, 5.0.40, 5.1.42. Looking in the error log you posted, I see you are using MySQL 5.1.67. Apparently, no one knows how to fix this issue or wants to ($URL$ I also noted that the error messages indicate that you are using MySQL in Linux already. I have three(3) suggestions that range from the most passive to the most aggressive... SUGGESTION #1 Try setting log_warnings to 0, if you don't mind flying blind on warnings. SUGGESTION #2 Upgrade to MySQL 5.6.11. Hopefully, there is should be more updates and bug fixes for this. SUGGESTION #3 Move the Database to Linux. There should be more stability for this problem away on a better machine with the most updated kernel for the OS. Give it a Try !!! UPDATE 2013-04-30 11:20 EDT Here is the fastest way to check for table corruption 

In this example, Relay_Master_Log_File is mysql-bin.009590. All binary logs before this one can be removed from Master. You could run this on the Master: 

This will give the OS 2GB of RAM. Your VM will simply love you for it !!! Give it a Try !!! CAVEAT Running on InnoDB tables simply closes files against the files. This will not really push changes directly. The changes have to migrate its way through the pipes of InnoDB. This is why you see the spike in . The 4262 changed pages (66.59 MB) gets flushed when InnoDB's scheduless its flush. 

mechanically runs and . That may change the PRIMARY KEYs. Here is something else you can do. Suppose your table is called name_city and it looks like this: 

Since the ARCHIVE Storage Engine does not support indexes of any kind, your main problem is the presence of the . Simply drop the . Then, convert the Storage Engine. There are two approaches to this APPROACH #1 

If you want to see who issued shutdown from a Linux viewpoint and if you are real risk taker, I have a very dangerous but fun suggestion. You could create a special log file that records when is issued or if mysqld_safe decides to shutdown. Let's say you want the file to be called Run the following two lines 

The amount of data you want could be fast to send over a wire, but what is mysql doing to process it and prepare it for transamission ??? Let's first look at the original query 

Once you select the value you want, start up MySQL with it. Then, perform a mysqldump of all the data. Keep that mysqldump somewhere. 

You will either see or . The only way to see the SQL, you would have to set binlog_format to in and restart mysqld because the MySQL Documentation on Replication with Global Transaction Identifiers says in the first paragraph: 

and restarting mysql does not work either, you will have to start up mysql with something like this: 

SUGGESTION Run the one of the above scenarios on one PXC node at a time while redirecting reads and writes from the cluster. If the data is huge, remove the PXC node from the cluster, run at will, and add the PXC back into the cluster. 

Queries that return lots of rows If you have queries returning lots of rows, tune your queries to return less data, perhaps adding effective WHERE and LIMIT clauses to SELECTs. Lots of queries If you do not have queries returning lots of rows, then it must be lots of queries. You may find this surprising, but MONYog queries mysqld for the global status variables with either 

This cascading would be a little worse because the cascading for table access would now occur among three files instead of two. Here is one more scenario some have thought of: Instead of moving the ibdata1 to a different volume, how about enabling innodb_file_per_table and moving the .ibd files to one or more different data volumes ? The cascading effect would now be a factor of the number of InnoDB tables multiplied by three(3). Percona has expressed very good reasons for not doing this that you will find helpful. 

Then, retry your queries. I noticed you are using MySQL 5.1. There are many patches to the partition code (such as ALTER TABLE ... REPAIR PARTITION). I would suggest installing MySQL 5.6 on a test server, copying the data into it and try out your queries on. 

There is a much, much simpler way A Replication Slave relies on the Master's binary logs so as to ship SQL from them into the Slave's local relay logs. Just tell the Master not to record the SQL 

CAVEAT If you ever have a problem with taking forever and still not shutting down mysqld, this quickly indicates that the socket file is missing. PID file will be out of whack as well. In that happens, do a TCP/IP shutdown of MySQL First do this 

There are three(3) ways using file timestamps: InnoDB Buffer Pool If you have innodb_buffer_pool_dump_at_shutdown configured, look for the timestamp of the file that was written. The default filename is . Mentioned this back on (Control InnoDB buffer pool allocation in MySQL (5.7+) is usually written in folder set by , you can run the following after shutdown: 

If you have any TEXT/BLOB fields in your MyISAM tables, you may just have bloated fields. You verify this, go back to your older MyISAM tables and perform this: 

This is risky because this speeds up changes to indexes in favor of not having buffering to recover in the event of a crash or reboot. SUGGESTION #4 (RISKY) Another cavalier approach would be to disable the Double Write Buffer. Since a restart is required, do this: 

Excuse the mess I am about to create, but here it goes ... STEP 01 Create a file called which contains this 

Run CHECKSUM TABLE command against a table. There is a caveat for this. According to the MySQL Documentation on CHECKSUM TABLE: 

PROPOSED QUERY EXPLAINED In the subquery AA, I compute the number of seconds elapsed using UNIX_TIMESTAMP() by subtracting FROM . If the patient is still in the bed (as indicated by discharged being ), I assign the current time NOW(). Then, I do the subtract. This will give you an up-to-the-minute duration for any patient still in the ward. Then, I aggregate the sum of the seconds by . Finally, I take the seconds for each patient and use SEC_TO_TIME() to display hours, minutes, and seconds of the patient stay. GIVE IT A TRY !!! 

When it comes to MySQL 5.5, you did the most expedient way possible. Great !!! A more politically correct way would have been to do the following: 

ngram_key has 73 bytes 64 bytes for ngram (ROW_FORMAT=FIXED set varchar to char) 8 bytes for ngram_id 1 byte MyISAM internal delete flag 2 Index Entries for ngram_key = 64 bytes + 8 bytes = 72 bytes 47 million rows X 073 bytes per row = 3431 million bytes = 3.1954 GB 47 million rows X 072 bytes per row = 3384 million bytes = 3.1515 GB 47 million rows X 145 bytes per row = 6815 million bytes = 6.3469 GB 5 billion rows X 073 bytes per row = 365 billion bytes = 339.9327 GB 5 billion rows X 072 bytes per row = 360 billion bytes = 335.2761 GB 5 billion rows X 145 bytes per row = 725 billion bytes = 675.2088 GB 

This problem looks weird. It reminds me of a post I wrote 7 years ago : Problem with MySQL subquery Sometimes, values in subquery results may disappear intermittently while processing. This problem was usually associated with non-SELECT queries involving subqueries. This looks like something even worse. You should file a bug report on this one. 

After restarting mysqld, rerun mysqltuner and evaluate the resulting recommendations. Taking key_buffer_size out of the equation is enough in your instance. 

These are just skeleton scripts to detect changes. For option 1, you can do mysqlbinlog against the current binary log and see the SQL that was executed in whatever timeframe you need. For option 2, you can change the SQL to retrieve the datetime stamp of the last update for a given table. UPDATE 2011-06-29 06:30 EDT Option 3 : You Could Monitor the general log Interestingly, you could activate the general log. What's even more intriguing is that you can activate it a MySQL Table. The template to the general log as a table already exists in /var/lib/mysql/mysql as general_log.CSV. Here are the steps: Step 01) Add these to /etc/my.cnf