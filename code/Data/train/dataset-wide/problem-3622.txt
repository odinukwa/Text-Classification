Don't do that. Leave it as-is. The "convoluted" directory structure nevertheless ensures that when you build future PHP extensions (that aren't shipped with PHP) that the build system can find your existing PHP installation and will put them in the right place so that your existing PHP installation can find them. 

You're overthinking your regex. Since you're already checking whether the underlying file exists before the rewrite rule, you should be able to just match anything. 

Your firewall rules do not allow DNS traffic (UDP port 53). Thus your Django app cannot perform a DNS lookup to locate : 

The php.ini setting only affects the time zone of your running PHP scripts. It is separate from the server timezone, which is probably set to UTC (according to best practices). 

and should be exactly the same file, with one symlinked to the other (for backward compatibility). You seem to have two different files. From a live CentOS system as seen after installation: 

You're not going to get a gateway address inside the allocated /56 or whatever IPv6 block that's assigned to you and routed to your premises. If you somehow do, you politely ask the ISP to put someone on the phone who knows what they're doing. Or perhaps less than politely. Usually, you don't have to worry about the upstream IPv6 address at all, as it will be autoconfigured as soon as you plug in your router. Most ISPs seem to be doing this with DHCPv6 (with prefix delegation), though it could also be done with straight up SLAAC if you have a statically assigned prefix. Once the /56 comes into your network, you can subnet it however you like. An example, with one possible (only partially fleshed out, and probably not very useful as-is) network design appears below. In any case, the IPv6 address of your upstream connection to your ISP is provided by the ISP and is outside your assigned prefix. You generally only need to worry about the inside interfaces. This example supposes you have an edge router with an integrated 4-port switch, such as many small business or SOHO routers. 

The obvious problem is that you opened port 22, but put ssh listening on port 56988. This is what you need to change. 

MX Logic is now a McAfee SaaS service. As a cloud-based service, it should be updated for all of their subscribers as soon as McAfee makes the changes, give or take a few minutes. If you want an exact number, you can always contact McAfee and ask them. 

You're not actually receiving traffic on port 25, but on port 80, via your web server. This traffic is attempting to use your server as a proxy to disguise the origin of the traffic. We generally call such servers open proxies, and they're quite useful for delivering spam and conducting attacks on other sites. For some reason, some people seem to think your IP address has an open proxy server, but the log entries show that the requests are being refused. If the volume of requests is too high, I would suggest firewalling off the IP address blocks rather than simply denying them in nginx. For instance: 

Keep in mind that SELinux will never allow the web server to write in user home directories. If you need this, you will need to place your web content elsewhere and make the appropriate directories writable. 

Hopefully you've long since replaced the drive, but since no one has yet directly answered the question... You ran two tests, both of which failed to read the same logical sector of the disk, as indicated by and the same LBA in both tests. This does indeed indicate the disk has a defect, and you should be able to have it replaced under warranty. Attempting to store data in this sector may or may not cause the drive to notice it's defective during the write process and remap the sector, but if the drive doesn't notice, and can't read the data later on, you've lost it. 

Buy one of each and test them. I think that's about the only way you can be sure how your particular application will perform. I didn't find anything more in a quick Google search than you did. 

Looks to me like it's time to take it up with the network team, though since it happens on all the iSCSI initiators, it's probably a problem with or at the target. The KB article also lists other possible causes, but they seem very unlikely. You may wish to check for them anyway. 

You have one in one , but not the other. Therefore you can't access using in that directory or subdirectories thereof. 

You can only change the physical extent size of a volume group if no existing physical extents would need to be moved to complete the change. Otherwise you receive the error that you posted above. The only other option is to recreate the volume group with the correct size. To quote from the man page: 

Since this is apparently a virtual machine, you can mount its disk on another (working) virtual machine and manually remove the password from the file. Or use to work with the virtual machine image file from the host or from another machine. 

If you get something else, the repository will be identified, and you can then disable that repo, contact its maintainer, suspect malicious activity, etc. If you get identical output, then you should be able to continue with the system update. 

Your machine isn't accepting connections on port 443. That's why the http link works and the https link doesn't. This may be because you didn't reload nginx after making the configuration change, or because you didn't open port 443 in your firewall(s). 

The type you want to use is not . This is for static files that the web server is meant to serve to user agents. For a socket used for interprocess communication, the type you are looking for is . Though, please note that because you ran gunicorn unconfined, there may be additional issues communicating with it. 

I have never seen anyone try to use service names in that argument. Try using the equivalent numeric port numbers instead: 

This means... disk. A likely cause of this problem is the server your VPS runs on is having issues with the disk(s). Those issues include, but are not limited to: a failing disk; using non-enterprise-grade disks; your host trying to run a VPS business on creatively recycled hardware, etc. It could also be that you are running a process that's causing unusually high amounts of disk activity. Unfortunately that information isn't reported in your or listing, making me suspect you have a low-end OpenVZ based VPS. (Which, if true, puts you back at the previous paragraph.) As for resolving the problem, the first thing to do is to rule out any of your processes as causing high amounts of disk activity. The program, as mentioned by @Shi, is good for this. Though my bet is you'll find nothing. Once done, you then contact the host to report some issue with the server's disk that they will have to diagnose, since they're the host and you can't see that from within the container. (And later, when you're shopping for a new VPS provider, steer clear of any who use OpenVZ. It's been my experience that the vast majority of them are run pretty badly.) 

The OpenShift cron directories are meant to contain the actual scripts to be run, not traditional crontab-style entries. So you should instead write a simple script to call your PHP code. 

It looks like you compiled Apache yourself, but you didn't choose to use the mod_deflate module. You'll need to recompile it, and this time enable mod_deflate. 

You installed the EPEL repository for CentOS 6, but you are actually running CentOS 7. Remove the RPM, and reinstall the correct RPM. Once you have done so, run to clean out any old metadata relating to the wrong version of EPEL. 

First, you need to ensure that the system time is set correctly. And ensure that it stays set correctly by running the ntp daemon. Second, you need to follow the link given in the error message you posted and begin recovering the databases. 

The most common cause of this problem is trying to start MySQL when it is already running. To resolve it, kill off any running instances of MySQL and then restart it using your normal startup scripts, e.g. . Don't attempt to start MySQL manually when using distribution-packaged versions unless you are prepared for a world of hurt. 

For testing, it is probably fine to do this. But a real production system will likely behave in the manner you experienced, and your program needs to be able to deal with that. 

Which also eliminates the need to use an evil , and doesn't require you to have Rails serve static files (which is slow). 

Without some more in-depth testing (which I'm not going to do right now) it's hard to say exactly what is going on, but the general outline is: When you first start up an Ubuntu cloud instance on EC2, a script runs which customizes it a bit for the EC2 environment. One of the things that happens is that your is rewritten to point to Ubuntu mirrors which are themselves hosted in Amazon S3 (which means you pay no bandwidth costs for install/update software). My guess is that something is subtly different between the Amazon archives and the general archives which causes the strangeness you're seeing; with a bit more testing and poking around you'll probably find out exactly what it is. My suggestion to make your deployment script work would be to simply wait until all of Ubuntu's initialization stuff is complete before you run your own script. 

Looks like you get to do everything yourself; Ubuntu doesn't seem to have any support for this scenario. I suggest opening a feature request on Launchpad. 

The installation instructions you linked to gave two separate and distinct installation methods, one involving EPEL and the other involving OBS. You seem to have done both of them, but they are mutually exclusive. To resolve the problem, remove the x2go repo file that you installed and try again using only EPEL. 

Your script being run from cron is not accessing your own site on the same server via 127.0.0.1, but by its actual IP address. For instance, you are probably doing something like: 

The solution is to update the system. Red Hat did not ship virtio guest drivers until 5.3. At this point you're nine service packs behind. Simply having kept the system up to date would have resolved the problem before it ever happened. 

A third party input plugin for logstash that reads the systemd journal directly is available. Adding support directly to logstash remains an open issue. Logstash now includes a systemd journal input plugin. 

After a service stops (or fails to start), systemd waits for a short period of time before attempting to restart it. The amount of wait time is configurable by setting in the unit. 

As joeqwerty said in a comment, nginx is correctly returning 200 because you asked for a document that exists. You would only get a 404 if you requested a document that does not exist. Try doing that instead. (And whether such a document exists on some other server is completely irrelevant.) 

The wiki is out of date. As specified in the actual documentation, the default for is since nginx 1.3.4. If you omit the parameter, then nginx will only bind to IPv6. The OS settings are never used. 

You should only have the IP address for the host on the host bridge. The IP addresses for the guests should be assigned only in the guests. 

You have your dependencies backward. The package requires one of those four named packages to be installed, so you should ensure that one of them (e.g. ) is installed first. Since it could be any of the four, no choice is made for you automatically. 

In this case, the first hostname is what the mail server identified itself as in its . The second hostname is the reverse DNS recorded at the time the connection was made. RFC 5321 section 4.4 explains the format of the Received: line, with a formal grammar. In your case, no reverse DNS was recorded. Since your IP address has a PTR record, this may be because they didn't look it up, or there was a temporary DNS failure. 

Note that should be set here, even if you don't use UTC as your timezone. This refers to the server's hardware clock, which should always be UTC regardless of your chosen system timezone. Replace the file with a link to the selected timezone: 

Yes, you have to be redundant. Except in very limited circumstances, blocks are only parsed once, and the closest match wins. Though you can reduce the pain of this by removing the common configuration parameters to a separate file and then using to include it in both places. 

So you should run one opcode cache, and one only. And, this may surprise you, but you need to get rid of APC, and keep Zend OPcache. The reason is that APC is very, very crashy. It alone may well be the cause of your PHP crashes, as it was for me and many others. Unless your new commerce portal is truly bizarre, it should work fine with Zend OPcache. 

The problem is simple. You have a typo in your DNS record. Your IPv6 address is , but your AAAA record has . You may resolve the problem by correcting the AAAA record.