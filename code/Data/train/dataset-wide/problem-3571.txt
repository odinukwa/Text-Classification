How do cluster file systems avoid the myriad of possible race conditions? I'm trying to get a grip on using a cluster file system in a Master-Master architecture. I'm thinking specifically about GlusterFS, so implementation details for it are welcome, but I'm hoping for a general answer. 

Many servers have an internal USB port and can boot from the internal and external ports. Comments about how MLC flash is limited to 10k-100k write cycles and may not be reliable enough are sure to come. I'm not too concerned about this, but perhaps I should be. File servers don't write to the OS disk very often, only for logs and such. Super Talent's flash drives are rated for 100k write cycles. Having two in RAID 1 and perhaps replacing one of them 3 years after set-up is still cheaper than alternatives and I believe would be reliable enough. And with ZFS, write errors will be detected quickly. So why is this not more common? 

Nowadays there's no difference between the 10/100 ports and the gigabit ports except speed. A lot of modern switches' "uplink" ports aren't even crossed. We used to do the same thing - connect the file server to the gigabit port. 

It turns out that Windows 2003 Domain Controllers will not accept IPv6 subnets in Sites and Services. After adding a 2008 R2 domain controller, I was able to add IPv6 subnets. But I also found out that running IPv6 on Windows 2003 does not work out very well, especially with Exchange in the mix. 

I'm designing a file server based around ZFS and I'm considering using USB flash drives in RAID 1 as boot devices. It seems that few people do this, and I'm wondering why. From what I see, using USB flash drives have some benefits: 

It is my understanding that network address translation (NATing) goes away with IPv6. How do we isolate network resources to those that need them from the rest of the internet? I am specifically thinking about allowing access to internal network resources like file servers or VM hosts to remote users, such as those working from home. A similar scenario also comes up in IPv4 today. At many universities, including my own, each network device gets a publicly routable IP. I'd like to run a file server, but don't really want it publicly accessible. Ideally it too would have a public IP and VPN would not be necessary. Comments? 

What could cause this to happen? Where should I start troubleshooting next? I did try on that interface with no success. 

In our network, we have a Cisco router acting as the core router, connecting all our sites to the main site. We also have a Linux firewall connecting us to the Internet. 

In my experience, Test-Cluster never triggers a failover event. It is designed only to check hardware and software configurations to see if everything is compatible with failover clustering. As I understand it, Test-Cluster is also run when using the GUI "Validate Cluster" function from within Failover Cluster Manager. It doesn't actually "Test" the "Failover" function of the cluster. 

I figured this out with a little help from the guys over at Unicorn. The problem originated from a query that was being run as part of custom middleware. Which is why it didn't show up in any logs. Here's the offending code: 

Everything works except one type of request. The page is trying to save HTML to the database. As such it's a large request. The request is passed to unicorn and the HTML is saved to the database, but then the page shows a 502 error. I checked the nginx logs and this shows up: 

I have servers that I wish to control access to. I have a firewall running pfSense between them and the public internet, but all machines have public IPs. A remote client may or may not be on the same subnet as the servers and firewall. I wish to, based on authentication, allow the remote client full access to the servers behind the firewall. I believe the best way to do this is through VPN. Note that normally when people refer to VPN connecting the same subnet, they refer to two machines having the same private IP ranges. That is very different than what I am describing. I simply want to tunnel traffic for a subnet through VPN to bypass the firewall. What is the best way to go about this? If you suggest OpenVPN, tun or tap? Thank you! 

Windows 2003 domain controllers do not seem to utilize IPv6 fully. Exchange 2010 needs to see all subnets containing domain controllers in Active Directory. But then Exchange was trying to contact the 2003 domain controllers via IPv6 and failing. When I removed IPv6 from the 2003 domain controllers, things started working. A 2008 R2 domain controller worked fine with IPv6. 

Changing the BOOTUP line to something like eliminates the formatting for all init scripts. If you just want to disable formatting on one of your scripts, add: 

How can I run an rsync backup/replication script in a user other than root while preserving permissions? This is a multi-user fileserver, where each user has a *nix account for permissions. Running with the root user poses obvious security risk - especially when you are using passwordless ssh keys to do it automatically. But running in a user other than root (like a backup user with full group permissions to the data directories), has problems setting permissions because only the owner or root can change permissions. In a perfect world, the production server user would only have read-only access. Thanks! 

It might be important to note that while Zanchey's answer is correct with regards to x::0 hosts, the example in the question does not describe a ::0 host. The example was A:B:C:D:E:F:0:0/64. A:B:C:D is the network portion, and the host address is actually E:F:0:0, not 0. 

I am trying to get Exchange 2010 to change the MessageClass (PR_MESSAGE_CLASS) of an incoming message to that of my custom form (IPM.Note.MyCustom) when the incoming message has a certain header set. () I have seen some information about setting another MIME header () that Exchange will use to set the MessageClass, but it doesn't seem to work for me. (I've seen examples that use and ) I've even looked into writing a transport agent with C#, and I did find a property on the class, but it's read-only. I also looked at added a MAPI property in a TNEF section, but the Exchange API does not offer a way to create a TNEF section if one does not already exist. (And most mail from the Internet doesn't.) There's got to be a way to do this. What am I missing? 

So the server isn't running out of memory. Is there anything further I can do to debug this issue? or any insight into what's happening? 

As you can see, the request completed successfully with a 200 response status in just 10.3ms. However, the browser hangs for about 30 seconds and Unicorn kills the worker: 

Again. There's no load on the server at all. The only requests going through are my own and every 10 - 20 requests at random have this same problem. It doesn't look like unicorn is eating memory at all. I know this because I'm using and this is the result. 

This should loop every 5 seconds until the postfix queues are empty. Adjust your path to postfix files accordingly. You might want to leave the part out of the command, otherwise any temp send errors that cause an email to be deferred will keep the modem connection open until it retries. 

In our network, we have several Cisco 1721 routers located at branch offices connected back to the main office via T-1 circuits. All the 1721s are running the same IOS and configured the same, with static global IPv6 addresses on the LAN interface. Here are the relevant configuration items: