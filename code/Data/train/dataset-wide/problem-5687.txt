As should be obvious to anyone who genuinely thinks, and has any concern whatsoever for the thoughts of other people, not all ideas occur equally naturally to all minds. As noted by Plato, there is a degree to which any important idea is less formulated than recognized. He went so far as to believe all important knowledge must therefore already be in the mind. But the oversimplification does not make this common experience less true. To the degree Plato's observation is true, one cannot clearly communicate most important ideas directly, but can only lead people to states in which those ideas might be recognized. Often only once related ideas are integrated can truly new ones be addressed. This is going to be harder for certain people, and certain ideas. Most easily comprehensible philosophers are either not original, or not actually saying what they mean, but interpreting for others. Someone like Bertrand Russel can be clear in almost every line. But if you take his body of basic (solo) work as a whole, it thoroughly contradicts itself, because he takes up one, and then another stable position formed by others, lays it out and moves on. He knoweth as he listeth. This is a great introduction to how ideas evolve. But we are left not really knowing what Russel, himself, ultimately thought, except on very specific technical questions, or on ethical questions about which the was quite passionate. At the other extreme someone like Nietzsche, or the later Wittgenstein can be much clearer about all of he work he is contrasting himself with, than about his own position. Such original notions are hard to communicate for anyone, because they come as a response to very basic conflicts, and they contradict things we might all wish were true, and that we seem to depend upon the truth of. But they are, at root, right. So anyone who imagines all philosophers would be equally easily comprehended by any one person, even if expressed perfectly, is basically delusional, or has no perspective and no understanding of the variations in human personality. 

The only consistent answer is One shouldn't. To such a person, of course, God's assurances, not being a proof in ZF, don't matter. So, how can one presume they have been accepted? One need not doubt God, as there is no fact of the matter about whether God tells the truth. Continuing forward from there, by presuming the opposite answer from what is clearly intended, twice, is just ignoring the content of the given argument, and forcing bad faith on your opponent in bad faith. The only thing here that is infinite, is the number of times it is necessary to ask a meaningless question before it gets an answer. 

It is hard to argue that nested quantification is not natural. Quite early languages have articles and combinations of moods that serve the purpose of quantifying. We naturally say 'A dog is (by nature) four-legged', or, if we own Champ the amputee, 'Dogs are not necessarily four-legged'. There is not a thing that marks quantification, but as a consequence of mood ('by nature', 'necessarily') it is grammatically present. Since we have verb phrases that reference other verb phrases, then, successions of moods result in nested quantifications. "Should there be a distance delta given, a fraction epsilon must be found which..." or in a well inflected language "I give (subjunctive) delta, you find (imperative) epsilon within it to..." encodes equally well the constant nested quantification in analytics "For every distance delta there is a lesser epsilon such that...". Aristotle moves forward from here with his framing using pronouns of quantity. I think this was not natural to his language, as such things were still generally phrased by hypotheticals with protasis and apodosis in different moods. It can be argued that Aristotelian forms are not quantified, but it is clearer to say that his 'No', 'One' and 'Some' are in fact quantifiers, just less simple and more natural to human usage. And even if 'All' is in some way not identical to universal quantification, it captures the itent. But if you look at what proceeds from Aristotle's own language you easily get them nested "All the children of some mothers will be talented." Some forms of this in older Greek are literally nested in a form similar to "The(nominative) The(genitive) some mothers(genitive) [all] children(nominative) talented will-be." Our abstract Universal and Existential forms may therefore be less natural than other earlier forms of quantification. But parameterization of the form you propose comes into the argument much, much later, when people start trying to reify relations, and does not find natural forms in language even in English and French, where it was first injected. So it is hard to argue that it would be more natural than nesting. So, based on classical languages, I would claim that a very thorough form of modal logic would be the most natural way to think about quantification, even though it might be more complex syntactically than our two quantifiers, but that nesting is a natural artifact of any representation of quantification. It is hard to see how a system where "possibly (delta > 0) implies necessarily (epsilon in [0, delta] and...)" stands in for "for all delta > 0, there exists an epsilon in [0, delta] such that..." can be processed as smoothly, but it captures the idea of 'ask and answer' more naturally than the traditional form. 

It depends upon what you mean by 'evidence'. If two particles are entangled at some point, the future behavior of one of them is tied directly to the future effects upon the other. If you don't question the idea that a particle has its own properties, or that information can travel instantaneously across arbitrary distances, then both events, the cause and the effect, have to already have been determined while the particles were together. (Modern physical theories, therefore, have to question one of these two things, or accept a rigid determinism compatible with destiny.) 

This is an issue that arises often when discussing formal fallacies: Observations are often rational, but not logical. An argument may well be trustworthy but not valid: It may be true, and proven well enough for all practical purposes without being completely well-founded. One way of looking at it is that logic (the handling of words or meaning, in origin) is about form, and reason (the handling of considerations or concerns, in origin) is about content. You may not have done the statistics that turn the known facts into well-founded premises, and it may not be possible to do them given what you have at hand. But you can still be pretty sure about your sense of the matter, and that may be reasonable. So you may not be able to state in simple premises the exact basis upon which you trust your observations, or state the degree of your certainty. But to act on the basis of that certainty is still often rational. Fallacies arising from slippery slope arguments, cui bono attributions, or maintaining generalizations in the face of a counterexample are logical problems. But they often express a completely rational position. 

The problem with this framing, to my mind is that the behavior does not get simpler, but more complex, when the situation goes unobserved. To maintain the distribution of the electron interfering with itself requires more data than storing the resolved position and velocity it would have if we prematurely collapsed the wave function. The most parsimonious way to account for things that show interference patterns, given that this is what we find causing this most often, is interference, either between potential or actual copies of the electron existing in parallel worlds or potential alternate timelines. It seems to me that if you wanted to limit data use, you would collapse everything early for simplicity or wait until observation took place and then randomly determine the outcome. The observed behavior is ultimately 'lazy' in evaluation and yet deterministic upon demand, while non-deterministic in other settings. This seems like the simulation approach that allows for the least optimization, in a digital computer, rather than one that is meant to facilitate it. If we are considering a model where this is an analog simulation, then this interference can be accounted for by the idea that the data is represented by some signal for which interference is a natural form of noise. The this could represent a way of delaying resolution. But then, in what sense would an analog simulation be a simplification over just assuming matter is really made up of a field, governed by the wave equation and only really processing data at a given granularity? You would still need continuous space and medium of some sort and an encoding of one analog reality in another analog system with data held at the same precision at which quantum gaps already require it be encapsulated. Such a simulation just seems like extra baggage, that provides no explanatory power.