A common calibration for depreciation rates within RBC models is to assume 10% depreciation rate (based on NIPA stats, for instance). This implies a half-life of about 6.5 years. But this estimate seems a little low for advanced economies where capital is often in the form of computerized technology etc, which would seem to depreciate at a much faster rate (say 25% pa, implying a half-life of more like 2.5 yrs). Further, with technological advance you have the problem of obsolescence - the useful life of a capital good may end long before it depreciates away fully using the 10% pa rate. There is an element of unpredictability around obsolescence as well. How can this be accounted for within RBC and DSGE models? Would obsolescence pose a problem for calibrating a model assuming delta is approx. 10%? Thanks in advance, R. 

But debt is bonds, accounts payable refer to money owed to suppliers ($URL$ Is it under "Other Current Liabilities"?. How can I know? Anyone has experience looking at balance sheets? I'm learning this. 

I have a question. A company is worth 1 million dollars, in terms of present value of revenues, discounted at rate R. Can I borrow 1 million dollars from a bank and buy the company? If the bank charges me R, I am indifferent? Or, can I issue a bond for 1 million, with coupon R? Am I indifferent too? Do these things happen? Do businesses ask for credit or issue bonds in order to buy companies? 

No, because money can be destroyed and counterfeited. For example, I have a shop, and you buy something from me. I could burn the money. The number of goods have not changed, but money has. Similarly, evildoers can counterfait money, adding it to circulation, without changing the amount of goods available in the economy. 

Well, adjusted R2 has more merit than R2. R2 will always rise (or at least stay the same) as you add more variables (even if the variables are not statistically significant). Thus in theory you could achieve a very high R2 by just bunging a load of nonsense variables into your regression. Adjusted R2 compensates for this by adjusting the R2 by a penalization factor that increases as the number of variables rise - hence adding a new variable will always raise r2 but will raise adjusted r2 only based on its explanatory power. Information criteria such as the Bayesian information criterion (also called Schwarz criterion) or Akike information criterion can be used to choose between competing models. Intuitively, they measure explanatory power but penalize for "bigger" models which are more prone to overfitting and other problems. The BIC penalizes additional parameters more heavilly than the AIC, for example. You would prefer the model which minimizes the information criterion score. Note that, unlike R2, the values of information criteria are not inherently very meaningful - you cannot say "this is a good model because it has a BIC of -50", but you can use them to choose between. What matters more than either P values or measures of goodness of fit is that the model is theoretically sensible and that the Gauss-Markov assumptions hold. This is what makes a "good" model - ability to explain a high proportion of the variance is the icing on the cake, nothing more. If I regress rainfall in the UK on US GDP for instance, I will get a P-value of close to zero and an R2 of above 0.95 - yet obviously there is no genuine economic relationship here. So a sensible model with solid theoretical foundations which satisfies the OLS assumptions is a good model even if its explanatory power is limited. Conversely a model with high r2 / low p values which doesn't satisfy econometric assumptions or lacks theoretical credibility can never be a "good" model. 

As I understood from my lectures, a multiplicative function means that the marginal product of one factor increases when another factor increases, and decreases when another factor decreases. The extreme cases (leontieff or additive) don't have this property. At the moment the teacher explained this, it made sense to me. If one factor increases, it expands the capacity of the other to produce more. I think it makes sense. 

I am looking at the balance sheet of Coca-Cola ($URL$ but I cannot guess where loans with banks are. These liabilities accounts are: 

ST Debt & Current Portion LT Debt 25.23M 25.94M 6.45M 7.06M 7.53M Short Term Debt - - - - - Current Portion of Long Term Debt 25.23M 25.94M 6.45M 7.06M 7.53M Accounts Payable 79.48M 69.45M 109.87M 162M 251.98M Income Tax Payable - 2.52M - - - Other Current Liabilities 111.6M 110.91M 111.11M 157.49M 198.4M Dividends Payable - - - - - Accrued Payroll 49.42M 49.4M 51.19M 68.99M 84.74M Miscellaneous Current Liabilities 62.19M 61.52M 59.91M 88.49M 113.67M 

If you want to forecast it is common practice to split your sample up into two parts - the "estimation sample" and the "forecast sample". The estimation sample is used to, you guessed it, estimate your model, which you then use to forecast the data for which you already have true values contained in your forecast sample. You then compare your forecast predictions to known data and to those of other forecasts. You can do this using r2 or adjusted r2 over the forecast sample. We also commonly use measures like means squared error, mean absolute percentage error, Theil's U, etc. etc. 

I'm not sure I fully understand what you mean by computing it endogenously? The nominal interest rate would be endogenous in the NK framework because the output gap and inflation are endogenous. There'd be feedback between nominal interest rates and inflation, which both feed into each other for example. So in that sense I'd consider the approximation of interest rate policy using a Taylor rule as entailing that interest rate policy WAS endogenous wrt. the output gap and inflation. As for why we'd use the Taylor rule as opposed to some more complex but accurate approximation for interest rate policy... well I can only suppose that the Taylor rule is a sufficiently good approximation such that the marginal benefit of adding more complexity / accuracy is minimal and perhaps less than the computational cost of doing so. There comes a point where you start to prioritize parsimony more and more. Perhaps this is the motivation. 

Page 75 of document: $URL$ I see, as Alecos suggested, that debt includes both loans and bonds. Itwas my mistake to assume debt is only bonds. 

The "common man" conception of money is not helpful to think about these issues. Money is not ONLY currency and notes anymore. These are just a TOKEN used to distribute goods and provide exchanges. They are not the real stuff. For example, when you make a bank account transfer, you are not moving TOKENS. Why would you? Banks are given these tokens by the central bank in order to keep a smooth movement of payments. So Apple does not have 80% of all tokens of the US economy in a vault somewhere. Why would they? It's dangerous! They have such ownership of wealth, but in the form of a current account and other assets. So you need to think differently between a claim on wealth, WHICH CAN BE TURNED INTO TOKENS, and the TOKENS THEMSELVES. 

Is CPI accurate relative to... what? If you are asking whether CPI is accurate as a measure of the true cost of living, the answer is no. One reason for this is that the CPI is computed using a weighted Laspeyres index of prices of different goods and services, weighted by their share in consumption. Prices are continually updated but weights are not, and hence the headline CPI index neglects substitution effects. Let me present a highly simplified example; two goods in the economy, apples and oranges, both consumed equally (weights 0.5 / 0.5). At the start, the price index computed using CPI methodology will be 100. Now the price of apples rises 10% and the price of oranges stays the same. As a result, people substitute out of apples and into oranges - so apples' share of consumption falls from 50% to 25%. The consumer price index would now stand at 105, implying a 5% increase in the cost of living. However, the true increase in the cost of living is 2.5% - CPI has overstated inflation in the cost of living through failing to take account of substitution. Most countries reset their CPI weights yearly. Some, e.g. Japan I believe, reset once every decade only. Obviously the less frequently you reset your weights, the worse CPI will be as an accurate measure of the cost of living. 

I think this is because of liquidity. If I am a poor household, and I own stocks (maybe via my pension?), if the price of those stocks go up, I cannot consume such extra income. Actually, if the stock market crashes, my capital gains can be wiped out! So in a sense, this is not "actual purchasing power", as it is the case with direct income like wages or transfers. So, to the day to day interest of a household, capital gains should not be relevant for their wellbeing. 

Thank you Brian for the suggestion, and the others too. It took me a long time to find it in the Coca-Cola report, and it was under Current Liabilities: 

Risk is important. A bond (or even a credit) is backed up by the company's assets. Companies go bankrupt because of a mismatch between assets and liabilities maturities (e.g. cannot pay a bond of a loan), but not because they are unsustainable in the long run. If a company goes bankrupt, debtholders are the first on the list (after workers, in some countries) to receive compensation. Sometimes they do assume losses, when the debt is negotiated at a lower value. The shareholder is the last one to get any money out of the assets of the company. So being a shareholder is more risky than being a bondholder.