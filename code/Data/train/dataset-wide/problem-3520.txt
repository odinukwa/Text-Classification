We are a team of less than ten persons that need to quickly set up a git repository that supports active directory based authentication. The simplest solution seems to be to use a file share with a git repository and reaching it using a unc path, e.g. 

I connected to my NAS using windows explorer, by entering \\DS412 in windows explorer. It prompted me for a username and password. I entered them and then the DS412 showed up under Network in Explorer. Worked fine. The share was listed by NET USE and I used this command to disconnect: 

However, we are a bit worried about robustness. Are there no issues with concurrency when several people use the same git repository and there is no actual server component running? Clients are running windows 7, server is Windows Server 2008R2. Using msysgit 1.8.1.2 (I am well aware that there are many other git server solutions, but, especially given the requirement of AD authentication, they are not as simple to set up) 

But now, I would install the snmp agent of my RAID controller. I used the rpm and I convert it ina deb with alien : 

The box dialog seems to be the acceptation of the hostkey of the remote server. Putty asks to confirm the hostkey to store this key in the registry of the user who wants to connect to him. If you want to bypass this dialog, you can force the use of a specified hostkey with the option. Moreover, you can explain to putty to use a serie of commands stored in a text file with the option. All these options are explained here : putty 

If you want to have an idea of what happening on your server, you can use the Performance Analyser of Windows 2012. You can launch a record during 24h of all counters and with that, you will be able to see where come from your performance problem. It could be the processsors, the memory, the disks or one process. Be carefull, the report files generated by the analyser performances can be very big, think to split them during the analyse. 

And that worked fine. Once. I then reconnected using username and password, this time I checked the box to remember these credentials. Worked fine. Now I again want to connect as another user. So I would like to disconnect from \\DS412 and reconnect using different credentials. I tried using NET USE, but it no longer lists the \\DS412. Entering NET USE \\DS412\IPC$ /DELETE again results in The network connection could not be found. Restarting the computer does not help. The \\DS412 does not automatically show up under Network in Explorer, but if I do enter \\DS412 in the Explorer bar, it immediately reconnects using my old credentials without prompting. Note that I am not mapping this UNC path to any drive letter. I have found this advice, but as you can see it does not help. I have found suggestions to use regedit, but I do not find the exact keys suggested, and I would really prefer not to hack the registry. This should be doable using command line commands? I am running Windows 7. 

The NIC of your machine resend the STP-keepalive to his connected port. So the switch close this port. Maybe, the loop can come from two interfaces installed on your machine which can be plugged on your switch. The interfaces can be virtualized interfaces of a virtualization software and misconfigured. Or the interface of your machine can be configured in a specific mode which resend all his received traffic. It would be interesting to see your traffic with tcpdump or wireshark when you plug your NIC on the switch. 

It maybe related with the profile of the user which execute the script. When you execute it from ise, you implicitly use the profile of the current user and you do the screenshot of the current screen. But when your script is executed from task scheduler, it uses the profile mentioned in the conf of the task and may not have a opened session with a desktop. It for that you have a white image, there is not any desktop with this session. You can try to change the user who will executes with a user who have an opened session and see the result.the task can be launch manually for test. 

When I try to start up HHVM. It was working prior to a HHVM which I applied (yesterday) as part of the standard upgrade process. Rebuilding the pgsql.so fails with the bulk of the problem seeming to rest in the file 

I'm trying to set up an NTP timeserver for hosts on my internal network to synchronise against. I need to use authorisation in order to comply with PCI standards. I've created a set of keys using ntp-keygen -M and added the below snippet to my /etc/ntp.conf file on the server. 

I have used ntpdate from the client machine to set the date from the server so I'm pretty confident that the networking is up and running. I've actually disabled iptables on both servers while I'm busy trying to set this up. The key file is 600 on the server, like this: 

Looking at the server logs I can see that I'm getting a permission denied fault when trying to read the file, as below. 

To delete the oldest logs, you can go the Task tab and create a job for that. It's the default paramters of Windows : After all, you mus restart yours counters to apply yours modifications. good luck! 

You can test your check_snmp_int.pl directly in a console and see if you have datas after the pipe. Moreover, you must activate the perfdata in icinga.conf and declare your broker. 

You can prefix the name of your file and select his format like this example. And in the properties of your collector, you must select Restart the data set (sorry my interface is in french, you can see the image below) and select the duration of the task : 

If you can mount and open shared folders but you can't see any files, it's certainly permissions problems. Did you do modifcations on that ? 

If you want to deactivate the notifications to all yours deveices. You can modify directly yours templates with . And for yours hosts with notifications you put le propriety in his configuration or create a specific template. 

I'm using ssl-cert-check to track a list of my domains certificates. In my crontab I set it to run quietly and email me expiring domains, but the command that I'm using to debug is: 

It is correctly reading the file and retrieving the certificates for the entire list, but it does not appear to be getting the correct expiry date for certificates issued by LetsEncrypt.org Other certificate providers do not seem to be affected by this problem. For example a certificate that is expiring on 24 March 2017 when I inspect it in my browser is reported to be expiring on 15 Jan 2017. I'm serving with nginx. Why would the CLI tool be retrieving the wrong expiry date and how can I correct this? 

I'm unable to connect to the server from a client. When I run "ntpq -c as" on the client I can see that auth is "bad" for my server. I have copied the key file that was generated on the server to the client and added the trusted key lines to the client too, like this: 

I've just installed Bacula ans some clients on differents debians with differents versions of the FD. My director : 

1. Testing NRPE connection You can test your connection between your windows and Nagios via NRPE like this : 

Hopefully, your GPO has blocked the interactive sessions and could use these two solutions. good luck 

For dumping the memory of a process, you can try via the task manager with a right click on your process and Full memory Dump Moreover, if it always fails, you can do a dump of all your RAM. For that, you can use DumpIt, I regulary use it and it never fails. But, the size of the dump will be the size of your RAM. You will be able to work on it with volatility or other debugger 

You could see some commands which are already created in nsclient.ini in the form of alias. You could look at the help of each command to specify which options you want to see in your supervision. Finally, you can create your own script and add it in the nsclient.ini 

Strangely there are other projects that have very similar configuration that work just fine. They use the same build agents. We use Atlassian Stash as Git server. I have looked at all the logs there, and nothing at all happens when I force a run in team city. So, it would seem that TeamCity does not even reach the Git server. If I test the VCS connection in TeamCity it works. I have tested restarting Stash. It did not help. We are working with feature branches. But I have tested turning those off and it did not help. Today the builds have actually worked a couple of times, but the problem returns. We are using TeamCity Enterprise 7.1.4 (build 24331) and Atlassian Stash v2.1.2. Both the build agents and Stash run on windows servers. Any idea on what is wrong and how to solve it? I have posted this question on the jetbrains developer forum, but gotten no answers. 

Is there a patch for this, or how would I be able to revert to a version of HHVM that does support this postgres extension? 

I'm using a Ubuntu box to host my bare Git repositories for developers to work off. At the moment I'm creating a user account for each developer on the box because it doubles as a filestore and local testing server. When somebody pushes to the bare repository other developers are unable to work on the files which change in the objects folder as a result. The new files are created with the user of the developer who pushes. I have placed all the developers into a dev group but the umask doesn't allow the group to edit. I've never had to set up a Git repository so haven't had experience in working with the permissions. I do want each developer to have their own user account on the test server, and I would prefer them to do actions on the server using that account. I don't mind giving them sudo rights. Is setting the umask for each developer the way forward? 

So you can export this key, edit it and apply yours modifications. When you are ready, you can plan a scheluded task which will run a last robocopy and import yours new keys the sunday. Like this, the next monday, you will have yours files up to date with corrects share and NTFS permissions. 

You can specify the port number directly in the command but you will must create one command per tested port. Or you can create a custom variable to store the port number , with your example: 

Moreover, you can test locally your command if you write directly in this file with the following syntax : 

You can start a scheduled task when a event from windows event log appears. In Hyper-V-worker\admin you have a log which describe the start or the restauration of a VM (see event log ID: 18596) You can select "On event" in your scheduled task for launching the task and select the event log which corresponds with your need.