I answer my own question here for completeness I will select @RolandoMySQLDBA as the preferred answer because it gave me the most hints even though it didn't actually solve my problem. Below are the results of my investigation Conclusion MySQL on Windows just creates lots of temporary tables and tuning MySQL by modifying the content of the configuration files did not help. Details The table details the parameters I have modified in my.ini respectively before executing any queries. MySQL was re-started between each test. I used the my.ini found in the original question as a template and I then changed the value of the parameters one by one according to the table below. I used JMeter to generate 100 concurrent web requests (as that represented our usage) repeated 10 ten times. Each consisted thus of 1000 requests in total. This resulted in subsequent database calls. This showed that MySQL would create lots of temporary tables regardless of what configuration parameters we changed. 

Edit I enabled log and discovered that the query was logged as slow. A quick search revealed that I had allowed persistent connections in the PHP configuration (). I turned this off. This reduced the rate at which MySQL consumes memory.It is still creating temporary tables though. I also checked that the is large enough. I looked at the variable . This should be zero. If not, increase the .I have zero and zero so I assume that the is large enough. I increased the and to 1024M as an increase in created_tmp_disk_tables may indicate that the tables can't fit in memory. This didn't solve it. Ref: $URL$ Edit 2 If you see many per second in SHOW GLOBAL STATUS output, you can consider increasing the value. I had 2 in an hour so I consider the to be large enough. Ref: Mysql Manual on 

*Average of three runs The images below depict the amount of memory and CPU the database server required for the different configurations. The black lines indicate the minimum and maximum values and the blue bars indicate start and end values. The maximum memory was as indicated in the question. 

Edit 3 I have modified the sort and join buffers as suggested by @RolandoMySQLDBA. The result is displayed in the table below but I think the is still high. I restarted the mysql server after I changed the value and checked the after a day (8h) and calculated the average. Any other suggestions? It seems to me that there is something that doesn't fit inside some kind of container but I can't work out what it is. 

What should I change to stop MySQL from creating temporary tables on disk? Are there settings I need to change? Should I throw more memory at it? How can I stop MySQL from eating up my memory? 

This setup was given to me so I have limited control over it. The web server is using very little CPU and RAM so I have excluded that machine as a bottleneck. A majority of the MySQL settings originates from a config auto-generation tool. I have monitored the system using PerfMon over a few representative days. From that, I conclude that it is not the OS that is swapping to disk. 

We are running a site (Moodle) that the users currently find slow. I think I have tracked down the problem to MySQL creating temporary tables on disk. I watch the variable in Mysql Workbench server administration and the number increases with roughly 50 tables/s. After a days usage, is >100k. Also, the memory does not seem to be released. The usage keeps increasing until the system becomes pretty much unusable and we have to re-start MySQL. I need to re-start it almost every day and it begins with using about 30-35% of available memory and finishing the day with 80%. I have no blobs in the database and no control over the queries either so I can't attempt to optimise them. I have also used the Percona Confirguration Wizard to generate a configuration file but that my.ini didn't solve my problem either. Questions 

As Justin's said (and the links in his post prove), the cardinality rule is a myth. This aside, there's a good reason to use bitmap indexes on fact tables: separate bitmap indexes on can easily be combined by the optimizer to reduce the numbers of rows to access. This is very useful with fact tables with a large number of dimensions. While any single dimension may return a large percentage of the data, when combined with others this may fall dramatically. For example, you may have thousands of orders per day and thousands of customers (with hundreds of orders each), but a given customer is likely to only have 1-2 orders on any given day. This saves you having to create multi-column b-tree indexes. As (ignoring some skip-scan conditions), the leading column in an index must be referenced in the where clause to be used. So with three dimensions you need to create six multi-column b-tree indexes to ensure an index is available for every query your users may throw at you ( ind1: col1, col2, col3; ind2: col1, col3, col2; ind3: col2, col1, col3 etc.) With bitmaps, you just need three single column indexes and can leave the optimizer to decide whether it's beneficial to combine them or not. This example shows how the two single column bitmap indexes are combined, but the b-tree indexes aren't (note Oracle can convert b-tree indexes to bitmaps, but this is rare): 

The fundamentals of indexing etc. all work in exactly the same way, so strictly speaking the only difference is the cost of getting this wrong! That said, here's a (not necessarily complete) list of things worth bearing in mind: 

You could then have further child tables below hardware or clothing, if there's more specific details required or just add columns to these tables (which may be null for some clothing/hardware types). It's fine to have nullable columns, though if a large percentage of the columns will be null due to the product type most of the time, you should think about splitting the table into separate child tables, similar to above. If you need to say which products a vendor sells, you can link them via a table. 

However, to get these benefits you need tables where you (nearly) always include the leading column(s) of the primary key in queries and you're likely to be fetching several rows at once. Some common examples of such tables are: 

Two to the power eighty-six records?! This is about fifteen orders of magnitude larger than any table I've ever worked with - I doubt even Google or Facebook have tables close to this size! Based on this alone, I'd say that having a lookup table of all the possible values is a nonsense. Regarding normalization: I believe your table is already fully normalised (to 5NF), though I think you're missing from your (candidate) key. The co-ordinates of death are than all dependent on a given player and their time of death (). so you don't need to "normalize" these into another table. It can be useful to have lookup tables when you're fully normalized though to help with the following: 

The check constraint on the MV will only be invoked when it is refreshed, so for this to work successfully you need to ensure that this is done on COMMIT. This will add to your commit time processing, so you'll need to bear in mind the following: 

When choosing index column order, the overriding concern is: Are there (equality) predicates against this column in my queries? If a column never appears in a where clause, it's not worth indexing(1) OK, so you've got a table and queries against each column. Sometimes more than one. How do you decide what to index? Let's look at an example. Here's a table with three columns. One holds 10 values, another 1,000, the last 10,000: 

Note that just because an object is listed as a dependency, doesn't necessarily mean it'll be invalidated when you modify the base object. This becomes more likely in 11g with its finer-grained dependencies. So you'll need to extend this to check the field to check whether whether you have actually invalidated the dependencies, with checks as to whether it was already invalid. How far you need to extend depends upon why you need to know what the "invalidator" was. A word of warning - if you manage to (permanently) invalidate the (e.g. by dropping the table), you won't be able to run any DDL in the schema again! A suitably privileged other user will have to drop/recreate the trigger for you. 

I decided to change to LK_ + original table + column as it allows easier navigation when browsing all tables. 

Inside the import file each CREATE TABLE statement is suffixed by IF NOT EXISTS, so why is this being reported as an error? I have tried to take out the table reported from the sql file, but then the next table just throws up the error, and the next etc until we have a sql import with no tables left. I am using Windows XP with MySQL 5.5.37-win32, these versions could be different from the versions used when creating the backup, would this matter? Thanks in advance. Edit : Added SQL code. This is just a sample, the code is created by phpMyAdmin's export function 

Is there a naming convention for lookup tables? I cannot see any declaration by oracle or anything consistent on google. However I assume some of you professional DBAs follow a convention? Perhaps there is a convention which occurs the most when you are called to edit a project you didn't author? example table metals 

I am trying to upload a backup sql file through phpMyAdmin. I create the empty db with the same db name as in my import file in phpMyAdmin then use the import function selected from within this empty db. I get the following error message. 

I seem to have came to a problem which I am having trouble solving, possibly because I have misunderstood intersections properly(or perhaps I shouldn't even use intersections for the goal). If we have a year table and use its primary key id in our intersection table to link to one actors primary key id, How can we populate the actors_nickname table before hand using one primary key id (to group together the rows)? which we then use after to populate the intersection table? year 

This is the desired result above, However if I was to insert rows into actor_nicknames, we would actually get actors_id = 1,2,3,4, which is useless to us in the intersection table as we need these rows grouped by the same ID. Thanks in advance. 

Here I have highlighted three problems which can occur, how can we enforce integrity here. PS Is there a name for what I have described? I assume in maths there are some terms for this, I did some research around ordinal numbers but it doesn't fit exactly into this. Describing this as just a set wouldn't allow for the issues I raised to be assumed problematic. Thanks 

I must enforce uniqueness within my table, But I cannot seem to find anywhere online(mysql manual,forums,stack overflow) talk about two unique constraints within one table. Why you might ask I need two? example 

I managed to find a workaround for this but I am not very happy about it. I installed my previuos setup which was EasyPHP and copied my old MySQL *data* dir into the EasyPHP *MySQL* data directory. This time around the database was able to read the .ibd / .frm files correctly.(even though these files did not change at all) I then used phpMyAdmin to export the database(this time around all tables/data was stored in the sql file) I then disabled EasyPHP enviroment and started up my new enviroment and used phpMyAdmin->import with the new sql file which loaded the data correctly. Overall I think its pretty poor that MySQL cant simply output some type of notice stating that the .ini enviroment variables are not set corresponding to the .ibd / .frm files rather than just output incorrect information and leave the user in the dark with all sorts of angles to think about. After googling around it seems many people seem to believe that their data is corrupt when that's really not the case. 

In other words, car or serial can only be inserted once for any one pid. Thanks PS, Sorry if my explanation isnt so clear, I will have to re illustrate, possibly by finding a better example too. 

I have a table images, which I use to store a file name, file hash and date created. I also need the width, height and watermark overlay of each image, but only on very small occasions do I need to access/update this data, should I create another table and setup a foreign key relation to hold just these values, and when I do need this data, use a join? Should I just store the width, height and watermark overlay values inside the images table? Thanks