Putting your query into the function, cleaning your general query log for this kind of process require a bit of work Here a simple output of a "personal" file, like the above, with 9 query, 7 insert and 2 select, +2 BEGIN/COMMIT: 

Alternatively you can manage the delay of a replica using the MySQL Delayed Replication, note that this feature is available only on 5.6.x + MySQL version. I think that a good idea where to start (but there are many configuration for your scenario) is to have 2 node attached in replica, one standard replica and one delayed replica: 

Execute a statement or a command. Use to remove all use of indexes for the table. Insert data into the table with . This does not update any indexes and therefore is very fast. Re-create the indexes with . This creates the index tree in memory before writing it to disk, which is much faster that updating the index during LOAD DATA INFILE because it avoids lots of disk seeks. The resulting index tree is also perfectly balanced. Execute a statement or a command. 

This is only a trace not a complete solution, "your" solution is based on your fantasy (and some work) ;) I have done this kind of test capturing and cleaning query generated by the general query log and using sysbench 0.5 after writing my own file, you can find some samples in the official source code, on a mirror of my database(hw and schema/data -a snapshot so I can restore the original status of data immediately- ). Then you can run a command like this: 

UPDATE FOR FREE BLOCK EXPLAIN When you delete a row a free block can occur, if you have free blocks in the "middle" of your insert, for example if you replace deleted rows(index and/or primary key) with your load data, concurrent insert do not work, when free blocks are filled in future insert become concurrent again. 

You can take a look into MySQL Fabric (Official Doc) but it requires more db server I have tried this tool only in R&D env for testing a basic HA It supports some sharding scenarios Here some high level pros and cons Pros: 

Another test you can try... "probably" in your table the cardinality of 'domain_id_resource_type' index is lower than 'domain_id', you can try to skip the optimizer choice and declare the usage of 'domain_id_resource_type' instead of 'domain_id' 

I am build a web application (project management system) and I have been wondering about this when it come to performance. I have an Issues table an inside it there are 12 foreign keys linking to various other tables. of those, 8 of them I would need to join to get the title field from the other tables in order for the record to make any sense in a web application but then means doing 8 joins which seems really excessive especially since I am only pulling in 1 field for each of those joins. Now I have also been told to use a auto incrementing primary key (unless sharding is a concerns in which case I should use a GUID) for permanence reasons but how bad is it to use a varchar (max length 32) performance wise? I mean most of these table are probably not going to have at many records (most of them should be under 20). Also if I use the title as the primary key, I won't have to do joins 95% of the time so for 95% of the sql, I would even occur any performance hit (I think). The only downside I can think of is that I have is I will have higher disk space usage (but down a day is that really a big deal). The reason I am use lookup tables for a lot of this stuff instead of enums is because I need all of these values to be configurable by the end user through the application itself. What are the downsides of using a varchar as the primary key for a table not excepted to have many records? UPDATE - Some Tests So I decided to do some basic tests on this stuff. I have 100000 records and these are the base queries: Base VARCHAR FK Query 

Have Types and Statuses tables for each table that needs them. Have one Types and Statuses table that every table that needs them uses 

Now I don't know what configuration I could make to make one or the other (or both) faster but it seems like the VARCHAR FK see faster in queries for data (sometimes a lot faster). I guess I have to choice whether that speed improvement is worth the extra data/index size. 

Everything I am talking about relate to relational database, specific MySQL. I have a number of tables in a database and for a moderate number of them, I am going to want to store a history of the records values when it changes. I have seen this done in a couple of different ways: 

If your table is a MyISAM engine you can try to specify in your statement. Load data ref. Concurrent insert ref. 

Yes, using the MySQL User-Defined Function (see MySQL 5.5 FAQ: Triggers) and installing the lib_mysqludf_sys Then, for example, you can write your own trigger calling the sys_exec like this: 

A good starting point to make a decision in order to use or not this kind of value is the MySQL official manual. In short: Optimization 

Collect and graph your results, changing concurrency and requests, and monitor your database and HW status. My file contains about 80.000 query and it is composed by insert, update and delete UPDATE #1 A good starting point that you can try is to start (simply) writing your file like this: 

Currently I'm working frequently with the first one obtaining good results and saving time... keep in mind that you have to check the result before apply them to the destination database(there are some little bugs in some scenario with unique keys on multiple columns and other) You can start using these tools with two test database in order to become familiar. 

In short, no, your CALL is not replicated You can take a look into the FAQ starting from B.4.22 and the Binary Logging of Stored Programs B.4.23: Are stored procedures and functions created on a master server replicated to a slave? 

For MySQL and PostgreSQL you can use the Snapshot Backups in order to obtain full or incremental backups: Some file system implementations enable “snapshots” to be taken. These provide logical copies of the file system at a given point in time, without requiring a physical copy of the entire file system. (For example, the implementation may use copy-on-write techniques so that only parts of the file system modified after the snapshot time need be copied.) It is available through third-party solutions such as Veritas, LVM, or ZFS. 

In order to synchronize(check database, object and data) the dev database with the production env you can take a look into the MySQL Utilities on these tools: 

See the sql_log_bin to turn off logging for the current session This condition is true only if you are sure that there is a single point of insert/update (your software with the dynamic declaration of sql_log_bin), on the contrary this condition fails if there may also be interventions by third parties, such as manual insert direct on the table.