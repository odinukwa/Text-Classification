Several organized or semi-organized groups of people in the world have really horrendous ideas, and react disproportionally strongly to any critique. I think most readers can agree with that statement, although we might disagree about which groups constitute examples of this. My set of such groups currently include militant Islamists like ISIS, the far right and far left political fringes in the West, the fanatically pro-Israeli (who tend to label any criticism as anti-Semitic), the fanatic Palestinians, and, yes, the typical modern day philosophers who, according to highly respected philosopher John Searle, make a living producing a lot of (quote) (1)“nonsense”. Now my general approach to such groups is to not accept or bow to their rules. 

according to the Wikipedia quote above it was a mixed response. Some people, including Carl Hempel, “continued support of logicism”. Assuming that they didn't fail to understand the import of Gödel's work, one must conclude that these people did not see Carnap's “universal language” for reducing mathematics to logic, as essential to the logical positivism, whatever they then defined it as. 

There can be a zillion different unknown unknowns. E.g. suddenly a giant TV set might drop from the sky. One prepares by estimating probabilities for various kinds of unknowns, and concentrating the effort on the least unlikely. The dropping TV set is very unlikely, to the point that it would be counter-productive to waste time and resources on preparing for it. Unknowns of the kind "almost zero probability but almost infinite impact if occurs" are also best disregarded. Multiplying the near zero probability by the near infinite impact if occurs, to get an expected impact value, doesn't really work in this case. Very small differences in the numbers can produce very different expected values, so there's no real information about probability to be had. E.g. Blaise Pascal (contemporary of Descartes) used an expected impact value argument to apparently prove that one should better believe in a specific god. But it's in the nature of near-zero-probability things that there are zillions of in principle possible such things, so e.g. Pascal's argument failed when other possible gods were considered. For computer belief management dealing with unknowns involves representing both probability and support. For example, 50% chance of raining tomorrow with 100% support means that in half the cases, it will turn out to rain. But with 0% support it doesn't mean anything: no prediction is possible, and the probability must just be ignored. At least one theory that attempts to do this correctly, Dempster-Shafer evidence combination, suffers from combinatorial explosion, i.e. it's just impractical. Apparently one can not, in practice, get a completely correct picture of the world. Happily very rough approximations work well in practice. But that means that we in some cases will end up with doing the Wrong Thing, where if we but had infinite memory and processing capacity, would have enough info to do the Right Thing; hence the expression "20-20 hindsight". 

Muslims don't even believe that modern canonical Christianity fully represents the original revelation to Jesus and His true life account. Same goes for Islam's view of Judaism. Muslims argue that only Quran has the authority to say what Jesus really taught by the virtue of its verifiable authenticity as verbatim words of God. Muslims believe that all Abrahamic Prophets were inspired by a same one God and originally taught the same message with no contradiction. 

God is a central concept to all religions. Apart from that, it is an attractive philosophical question. It's been discussed by philosophers even before Christianity. Although I believe it was Abrahamic religions that originated the concept. 

You're right. If everyone can create "meaning" based on personal preference not some philosophical idea it will amount to contradiction. Because the concept of purpose on itself (as far as the pure abstract meaning denotes) refers to whatever we pursue in our life. In this sense getting answers can be counted as the purpose of writing questions in Stack, just as making money is for seeking employment, or every other end we seek in our daily decisions no matter how important or intelligent. However when raised in a philosophical discussion, purpose denotes an overarching ultimate end that guides and shapes all of our life decisions towards itself. In this sense purpose doesn't refer to our particular daily life sough-after goals, neither our personal whims and preferences. It will only make sense when rooted in a philosophy that logically argues for some universal truth. Otherwise the term purpose wouldn't bear any philosophical sense and would inevitably reduce to more petty things such as our arbitrary whims that are unqualified for the kind of universal validity that is presumed in a philosophical definition of the term. 

The question of whether our universe is deterministic can IMHO be rephrased as “how much does the current state of this universe constrain the state in T units of time”? If the constraint is absolute, if there is only one solution to the forward evolution of any state for T units of time, then the universe is deterministic in forward time. And conversely, if this universe is not deterministic, then the constraint in forward time can't be absolute for all states, and it's reasonable to guess not even for any single state. I will assume that. Now, consider backward time. Usually we think of that as deterministic, that the past is fixed. Could there be more than one state evolution that had led to the current state, i.e., can state evolutions converge? Given the smoothness of ordinary classical measured state differences that seems almost unthinkable, but given the discrete nature of some quantum effects it's not so unthinkable any more (even though highly unlikely). So while nobody's yet thought of any way to test this, our usual notion is that our universe is deterministic in backward time and in-deterministic in forward time. If that's correct then a copy of this universe would evolve just as this one, just that every infinitesimally short time interval yields an infinite number of slightly varying possible state evolutions. Things get more complicated by the fact that current theory deals with two entirely different abstraction levels for physicality. In a thought experiment now known as the EPR paradox, in 1935, Einstein, Podolsky and Rosen showed that two “entangled” fundamental particles were more correlated than the speed of light limit would allow. So assuming that the speed of light really is a limit at the abstraction level of particles and waves and such stuff, the inner lower level workings of our physicality can't be totally bound by that law. That stands to reason, e.g. the laws that a computer program operates under are not the laws for the hardware platform that it runs on; they're two totally different kinds of beasts, just slightly connected. And as far as I know nothing more is known about that, just a baffling inferred law-breaking in one particular context, almost like watching a professional illusionist and inferring that what's really going on can't be what appears to be going on. Another area where there is a very large unknown, is that of dark matter and dark energy. That all started with some observations in the 1960's I think it was, if I remember correctly, that galaxies in general were rotating too fast to be compatible with reasonable assumptions about them (e.g. holding on to their outer stars). The upshot of that is that currently there is a scientific consensus that, according to Wikipedia, "dark energy plus dark matter constitute 95.1% of the total mass–energy content of the universe", which we know essentially nothing about. So in addition to quantum mechanics being so complex and weird that it's tantamount to being unknowable, there is the hidden internal implementation of reality, that we know next to nothing about (except the EPR), and there is the hidden matter and energy, presumed to be absolutely most, more than nine tenths, of this universe, that we know next to nothing about. In short, two very large terra incognitas, and one big extremely-difficult-terrain. And I think that means that currently it's impossible to answer simply "yes" or "no" to the question of whether all this unknown, is deterministic. 

This thesis explains why humans can develop infinite ideas as well as why machines do not since they do not posses mind with which to think and find illumination. Machines can only perform a limited number of seemingly intelligent behavior to the extent of the possibilities afforded by the human design behind it which is always limited. 

Humans can invoke and recall mental concepts and images from distant past which would be impossible if they were somehow "stored" in human brain or any other physical organ, as the constantly changing feature of natural things undermines any ability to preserve mental concepts through time. The simple nature of abstract concepts negates the possibility of material basis for their preservation as a simple entity can't be ingrained in/on a composite entity. 

I advocate Mulla Sadra's definition of time. A Persian religious scholar of 17th century who was also a genius of the Islamic tradition of Peripatetic, Neo-platonic Philosophy. He introduced innovative theories of epistemology, ontology, theology, and human bodily and intellectual (spiritual) development. In short, Mulla Sadra defines time as an abstraction from instability and motion inherent to the material world, with no actual, independent existence. In other words, concept of time is a result of perception of change or motion in the world. Time has thus no actual existence. What actually exists is motion, and change/motion is an essential property of matter. Obviously concepts of time such as 'past', 'present' and 'future' don't have any actual referent in the external world. These concepts are rooted in our mind, i.e. how we mentally categorize and conceptually preserve the lasting impact of a constantly changing world on our memory. Hence, when we say a day passes, it actually means some realities no longer exist. They are "past" but the memory of that bygone reality enables us to recall it in our mind and categorize it as 'yesterday', 'past', or other adverbs or adjectives of time. One important implication of this theory for philosophy of mind is that it points to the extra-natural essence of human mind. If human mind was not immaterial and thus constantly had its substance changed through time (like material forms), then we could have never have a concept of time, because no perception of reality would be preserved to be recalled later, giving us the sense of time. This in turn reveals that mental entities unlike material entities are in essence static and immutable. Mulla Sadra therefore defines time as the fourth dimension of the material world. The material plane of existence is stretched in 3 dimensions of space and 1 dimension of time. Dimensions both suggest gradual, divisive and imperfect existence of the material beings as opposed to the static, inclusive and whole existence of supernatural beings that are never subject to change and thus time. Mulla Sadra's theory of time is a part of his greater theory of Substantial Motion which is the main cornerstone of his theory of human bodily and spiritual development among others. 

I happen to believe that this concrete instance of the argument form is valid. But I may be wrong – the conclusion is after all in line with my views on the matter, so I may tend to only see that which supports my views. 

Ten years after he wrote (or spake, it was the Presidential Address delivered before the Sixty-fourth Annual Pacific Division Meeting of the American Philosophical Association in Los Angeles): 

In the above image the colors are an invention, not a discovery. Different people will maybe choose similar coloring here, but I think it's pretty much an artistic choice. The colors roughly reflect how fast a point in the complex plane will head off to infinity under a certain repeated square-and-add operation, but they depend on a lot of parameters (including how many iterations one deems sufficient to establish the wayward nature of a point), including, of course, some particular color palette. I think this illustrates nicely that the very same mathematical beast can have aspects that are discovered, and aspects that are invented. ;-) 

Well, the idea of a directly programmed intelligence, one where each main function of the mind was implemented by a programmer, was common in the 1970's. But while it's nice as a goal to gain better understanding of how e.g. vision processing works, it's wholly impractical as a way to create an intelligence. As already Alan Turing (1)noted in 1948 or so, the most likely way a machine intelligence is created, is the way that a human intelligence is created, namely by growing up and learning – with some basic instincts and abilities in place, of course. So a first answer is that the question as posed doesn't make much sense, because it's very unlikely that a machine intelligence will be of the directly programmed variety, that there will be any programming (except of basic functions such as edge detection in vision processing): I'd guesstimate that it's about as likely as a crocodile emerging up through the asphalt in the street, deftly stealing your wallet, only to be hit by a giant iron hippopotamus accidentally dropped from an airplane passing above. However, running on a digital platform means the possibility of making copies, partly or completely. It means the possibility of trying out things in simulated environments. Not the least it means that explorations of possibilities can be really, really fast. Currently the electronics is some millions times faster than our brain stuff, and that difference increases exponentially, which it's kept on doing since 1965 or so, roughly a doubling every 2 years. So we can expect some really fast evolution as soon as machine intelligences start creating new ones. 

Centuries before Descartes made up that (maybe perceived) fallacy, Avicenna the persian muslim philosopher had already explained why it is a logical fallacy to argue from an issue of the self (in this case thinking) for the existence of the self. Because in any such argument the existence of the self is already presumed as it is impossible to experience any issue of the self (such as thinking) without having first experienced the self itself. The glaring fallacy is manifest even by looking at the apparent semantics of the English translation of the argument that starts with a presumed "I" in the premise ("I think, ") to prove the "I" in the conclusion ("therefore I am."). PS: Even if the famous statement is not meant to be a logical proof (as ChristopherE and Asphir Dom suggested in comments), but a reference to a human transcendental experience (which is supposed to be beyond proof and self-evident); it still holds true that the first object of transcendental experience is not any mental/psychological process (e.g. thoughts, feelings etc) associated with human self but rather the very direct experience of the self which precedes them all. Nowhere this is better explained than in the theory of "knowledge by presence" which was first proposed by Al-Farabi and later refined by Avicenna. In knowledge by presence, it is argued, the subject and object of knowledge are united -- either because of the identity of the two or one being the intimate part of the other --, therefore the subject can directly experience the object of knowledge without any medium. Such a knowledge is thus self-evident, infallible and needless of proof. Examples are human experience of one's very self, one's thoughts and feelings. The theory is very significant as it bridges the gap between philosophy and mysticism, as in the latter most statements of truth are based on direct experience rather than logical proof. This allows objects of knowledge by presence to serve as self-evident premises for philosophy. That's how muslim philosophers for the first time reconciled Aristotelian philosophy with Platonic. 

where is an identifier to be defined if it isn't already, denotes assignment (which creates an identifier if it doesn't exist), on the right hand side evaluates to logical if it doesn't yet exist, denotes logical OR, and denotes a new object, which is the result of the OR-expression if evaluates to . It's also the basis of boolean short-circuit evaluation in a great many programming languages. 

Apparently Searle changed his opinion in these ten years, since the statements appear to be directly mutually contradictory. Regarding that aspect I mailed Searle, but he didn't answer. A typical SO reader may think I'm unrealistic in expecting an answer, and indeed in my experience, limited to two cases though, philosophers do not answer critique or admit to errors, but e.g. in my own field of C++ programming the top people such as Bjarne Stroustrup and Andrew Koenig are more than willing to discuss things, admit errors (and collect them in errata lists), and so on, and that's also for a few cases been my experience in the field of physics (e.g. I once pointed out a problem with the description of something in Scientific American's "expert answers" column and they put John Baez on it who just fixed it). So I don't think I was unrealistic. But no answer so far. Hence I'm asking here: 

So there is no basis for the belief in contradiction between Muhammad and Jesus's religion at least from an Islamic point of view. 

The answer seems so immediately evident to me that it makes me wonder what has made the OP to have doubt in the first place. Just how can there be any language capability without consciousness? One has to be first conscious to use anything and language is no exception! Just look at the newborn and how it learns to associate symbols only after he becomes adequately conscious of the environment and also conscious of primitive communication methods (gesture, voice, etc). 

I don't think you need to compare qualities to feel them, i.e. to feel their effects. You only need to compare them when you want to distinguish them from other qualities. Therefore we can say the effects are felt, whereas the differences are thought! This is a key distinction. By the same token, we can say numbers are thoughts, therefore they are known via comparison. But all that is felt and thought is ultimately by reference to our own self (or soul I'd argue). It is the soul that both feels and thinks, hence the ultimate reference. Number one is first deduced from the intuitive unity of our self, and the other numbers from multiplying just that. 

can not entirely be understood this way, because of the word “hence”. I suspect that something’s been lost in translation here. 

1) John Searle: “I don’t read much philosophy, it upsets me when I read the nonsense written by my contemporaries”, in an interview with New Philosopher Jan 25th 2014. 

Not quite arbitrary association 2: In pixel based graphics there is an operation that takes an area of one image, and an area of another, and applies an arbitrary bit-level combination specified as a truth table. It was a result of the Smalltalk project at Xerox Parc, where it was identified as one of the crucial elements required to implement a graphical user interface. At that time it was called “bitblt”, short for “bit block transfer”, and e.g. the Windows API has a function, plus a number of variations & extensions. 

In other news, … I find it noteworthy that the notion of practically irreducible complexity is not one of the "two positions" you list, namely (1) the supernatural and (2) the view that some things just can't be understood. If there ever was false dichotomy it must be this, with both branches just childish nonsense. Is it really true that modern adult philosophers in general think one has to choose between the childish nonsense options (1) and (2)? 

In purely formal logic Joe's and Alice's claims are invalid. In the real world, when the existence of something would very likely have caused evidence about it to be available, and no evidence is available, then that is a strong indicator of non-existence. This is what's implied by Bob's claim when it's interpreted as being about the real world. That's because you know that in the real world the existence of unicorns would likely have produced a lot of evidence about them. There would have been a whole industry providing unicorn pictures and stories etc. to fans of unicorns. I.e. the feeling of different strengths of arguments stem from interpreting the claims not as pure logic where the statements are all that is, but as real-world claims, with associated facts and inferences. To formalize this I think one would need to replace the word "evidence", which has different meanings in the real word and in pure logic, with e.g. "reports". Then one can say (P1) if unicorns exist then the probability of having seen at least one unicorn-existence-report would be >0.998, (P2) if unicorns don't exist the probability of having seen at least one unicorn-non-existence report would be <0.001. And with these (or other better) probabilities one can reason about the above Joe and Alice claims.