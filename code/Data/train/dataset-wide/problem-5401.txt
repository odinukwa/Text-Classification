I don't think there is any "reasonable expectation" in principle, just a lot of arbitrary choices. Privacy-seeking is a non-rational behavior that provides certain advantages in various social situations. It can provide protection from disease, allow behavior that is individually beneficial but not desired by the alpha individual, and so on. If you ask what constitutes a reasonable expectation of privacy for humans, then there may be an answer with a sound biological basis. But although different levels of privacy do have game-theoretic consequences for abstract (presumably rational) agents, there is no intrinsic reason to prefer one over another without knowing a lot more about the rest of the context. 

If rocks did this all the time, in apparent violation of basic laws of motion, then yes, the rocks are buying pies. Otherwise, no, this is just an amusing example that doesn't demonstrate anything except the danger of extrapolating complex properties (like agency) from isolated incidents. The point of agency is that you gain predictive power by considering the entity in question an agent with internal motivations which it uses to shape its actions. Whether there is something fundamental about agency or whether it's just an emergent property of sufficiently complex physical systems is perhaps debatable, but the rock example doesn't meet the minimum preconditions. 

Assuming you mean the problem of classification in general, i.e. placing entities with various qualities into meaningful relations or subgroups on the basis of those qualities: Extensive experience with machine learning has demonstrated pretty conclusively that we don't/didn't know from first principles what is necessary for useful classification. This is not to say that there is not work done on the philosophy of classification; there is, resulting in debates including, for instance, one about the periodic table of the elements. Unfortunately, when it comes to actually building a classifier, insight from philosophy has not proven adequate. Progress, such as there is, seems to be coming from statistics and mathematics (especially but not exclusively Bayesian statistics). I think the jury is still out on how to make a robust general classifier and thus how to draw meaningful and robust distinctions; once we've got something that actually works (and works well), I think we'll be in a good position to reason about the principles that make it work. (For reference, some good sounding frameworks that don't work alone include trees and other forms of hierarchical clustering (because every concept must have only one parent, while real objects like a bobble-head Obama toy fall squarely into multiple categories, and picking one as the "real" parent idea makes lookup and reasoning hard when you start with a different parent); tables of attributes (because it is difficult to restrict the number of attributes to a finite list which is nonetheless useful, and it's hard to work with such tables once you've got them); and networks of associations, oddly sometimes called rhizomes in philsophy despite the concept being around far longer in machine learning research (because we don't know how to build them in such a way that they're easy to work with yet capture all the subtleties and quantitative aspects of the world). All of these are surely relevant and useful in at least some subdomains.) 

Let's step back for a moment and ask a pragmatic question: do people need some level of satisfaction of wants? That is, one might not need a new smartphone, a sushi dinner, a visit with friends in a distant city, and a flavored latte made with exotic organic coffee; but does it work for people to never get any such things? It seems to me, put this way, that the answer is no, people need some level of satisfaction of wants to be motivated, productive, and psychologically healthy. If your morality insists that people not meet their need-of-wants at all, then it's not a very appropriate morality for humans. Therefore, we conclude that it is okay to some level to satisfy wants. Since this is an argument by contradiction it doesn't help us to know which wants are okay to satisfy, just that wanting something has some bearing on moral action. 

There are a wide variety of ways someone can end up calling themselves an Atheist, but what you've described is pretty common among researchers in the life sciences. You've put some things as premises that I don't think really are for these folks, though. I think it goes more like this: 

Such a theory can't be proven since it is not experimentally distinguishable from nonlocal hidden variables. Such a theory is extraordinarily unlikely because it completely fails to account for the apparent compactness of description (except, apparently, when trying to do quantum physics, whereupon complex rules unfold that prevent us from noticing that we're not operating in another regime). In this sense it is not that unlike Descartes' demon (and worthy of similar treatment). If such a theory were somehow proved to be true, however, it would still not invalidate science because science is mostly about finding what relationships allow predictive power about things that are to happen in the future; and those predictions have already worked quite well and will continue to work as well as they will work. We assume they will continue to work equally well, but there's no real reason why superdeteriminism would be more likely to make that break than any other theory. If everything suddenly stops working, it would be not because superdeterminism is true, but that superdeterminism is true and there's some bizarre change in causality at some point (assuming causality is still a sensible notion). We could also have fundamental stochasticity as indicated by conventional interpretations of QM and have some weird rule change at some point. Science isn't invalidated just because we can't control variables as well as we would like (e.g. we can't control what experiments we run). It already corrects for that: if you don't control your variables, your predictions aren't very good. Unless Descartes' demon gets involved, that's enough to allow progress even if the progress is less expansive than one might hope. 

Let's ask a different question: how do you know you're not twenty minutes old? That is, "you" didn't actually write the question, you just think you did because things were different in the past such that, well, somehow or other you exist now and have memories of writing a post, but there are parameters which changed and somehow spoiled stuff. Pretty silly, right? But, frustrating, you can't completely rule this out with logic or science or anything else. It's just a variant of Descartes' evil demon, albeit possibly a non-intelligent demon (maybe there's just some process that generates pretend histories, and a flag flipped saying, "okay, stop generating pretend histories now, plug them into beings and start doing stuff for real"). So if you really want to know absolutely for sure, it is logically possible that we could be almost arbitrarily badly confused about almost everything. This does an absolutely terrible job of explaining all the regularities we see, but it can't completely be ruled out. But if you're "just" doing science, you don't need absolute certainty. You ask: can we construct hypotheses that make predictions about what we observe, and do those hypotheses work on both observations we've already made and ones we haven't made yet? Can we find better hypotheses? And here, of course we can do science on stuff that's already past because it doesn't matter why you failed to make the observation before. It doesn't need to have not happened; you just need to have not cheated by plugging the answer into the hypothesis before "testing" it. You could get new observations by making new things happen, or looking at consequences of what has happened previously. Doesn't matter at all, as long as it's honestly independent from the generation of the hypothesis. Then the question is whether parameters can change in the past in a way that will confuse us. Possibly! The length of the day has, we think, changed throughout Earth's history. Based on physical effects we can observe now, it looks like the rotation of the earth is slowing slightly, and if we extrapolate the day should have been about 22 hours long during the Cambrian. If we check, by measuring relative changes in sedimentary patterns that occur on yearly, daily, and lunar-monthly cycles, it seems pretty much spot-on. Now, note what we did: we took multiple different predictions and they agreed with each other. We didn't take one and trust it, we checked. If some parameter changed in the past, it would somehow have to have affected these different factors by the same amount, so that they'd agree. Dating via radioisotopes is done much the same way. There are all sorts of radiogenic decay processes (for over a dozen, see Radiogenic Isotope Geology by Alan P. Dickin, Cambridge University Press (1995)) that agree with each other. So any "parameter change" would have to affect all radioactive decay the same way. Since decay of U235 and U238 is responsible for much of the internal heating of earth, if it had happened much much faster, the earth would have been a sphere of boiling lava unless thermal conductivity were also different. (And the sun wouldn't work properly either.) Furthermore, these methods agree with completely non-radioactive methods of relative time such as sediment accumulation, coral reef growth, sea-floor spreading, and so on. So not only can we perform scientific studies in the past, when it comes specifically to radioisotope dating, we can check and cross-check and cross-cross-check, and everything checks out. (To be perfectly clear: these are tests of the hypothesis!) Now, all measurements have some associated error, so if you want to tell to 0.1% how old something is, it can be quite a challenge. But if you want to tell if something is 5 million or 500 million years old it's really easy, and really robust (if you follow proper procedures and measure or avoid sources of error, as you will if you e.g. read Radiogenic Isotope Geology). So, in conclusion: while it is logically possible for evil demons to trick us, or for multiple models to give similar answers, in practice with radioisotope dating there are no competing models which make any sense at all, and tons of hypothesis-testing has been performed and the standard hypothesis has done really, really well.