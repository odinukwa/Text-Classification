I am interested in a class of $2n\times 2n$ unitary matrices with complex entries (if you prefer, we can replace "unitary" with "self-adjoint"). I know that all the eigenvalues of matrices in this class have (algebraic) multiplicity one or two. Some very interesting phenomena happens when all the eigenvalues have multiplicity two. Is there a way for me to tell when that happens based on the entries of the matrix, other than computing them by brute force? 

I will comment that it is easy to show this is true if $f$ is assumed to be analytic, but it seems rather difficult if I don't have this assumption. Through some basic PDE tricks (method of characteristics, etc) it is possible to show a local version of this result: that for a fixed $x$, there is a small $\epsilon(x)$ such that $f(x,t)=0$ for all $0<t<\epsilon(x)$, but this is not good enough for my purposes. 

We use the following definition of almost periodicity given in $URL$ Given a bounded function $f :\mathbb Z \to\mathbb R$ we denote the set of translates of $f$ by $U_0$. The function $f$ is said to be almost periodic if $U_0$ is precompact in $\ell_\infty(\mathbb Z)$. For instance, all periodic functions are almost periodic. If $\theta$ is an irrational angle, $f(n)=\cos(2\pi n\theta)$ is another example of an almost periodic function. Let $\Delta_n(x)=1+2+\ldots n$ be the $n$th triangular number and $\theta$ an irrational angle. Is $f(n)=\cos(2\pi\Delta_n\theta)$ almost periodic? 

May has carelessly made a typo in transcribing a proof in one of his books to another, and it has taken an impressive high school student in Korea to catch it. In his earlier book ``Classifying Spaces and Fibrations" --- the title is a joke: "classifying" here has two meanings --- ($URL$ there is a generalization of the cited result in "Concise". In its proof, but using the notation of "Concise", May remembers to normalize by setting $u_j = \sum_{i=1}^{j}\gamma_{T_i}(\beta) / \sum_{i=1}^{q}\gamma_{T_i}(\beta).$ With this correction (and correction of another typo, $s(e,\beta)= e$ should read $s(e,\beta)(0) = e$) the proof is correct, albeit miserably hard to read, way too concise. May should apologize to his readers. 

I don't have time to wade through terminology, but this seems to be an exercise in avoiding the use of simplicial homotopies, as defined for example in Definition 5.1 on page 12 of Simplicial Objects in Algebraic Topology. These homotopies make sense for simplicial objects in any ambient category $\mathcal{C}$ whatsoever, so that with this notion there is no such thing as a $\mathcal{C}$ "with insufficient structure to support homotopies''. Extra degeneracies give a particularly convenient way to construct just such a homotopy. If you have a terminal object, then you have a trivial map $\epsilon$ from any simplicial object $X$ to the constant simplicial object $\ast$ at the terminal object. A "base point'' is a map $\eta$ from $\ast$ to $X$ and is determined by a map in $\mathcal{C}$ from the terminal object to $X_0$. Then $\epsilon \circ \eta$ is the identity on $\ast$ and we say that $X$ is contractible if $\eta\circ \epsilon$ is homotopic to the identity. That makes sense in any $\mathcal{C}$, and it agrees with the usual notion in the usual examples. 

I am trying to understand this short paper and I am getting stuck right at the end. Let $V(x)$ be $C^\infty$ and 1-periodic (that is, $V(x)=V(x+1)$). We are considering the operator $$A=-\dfrac{d^2}{dx^2}+V$$ on $L^2([0,1],dx)$ where $A$ has periodic boundary condition $f'(1)=f'(0)$, $f(1)=f(0)$. Suppose that for some $n$ even, the $n+1$st eigenvalue of $A$ coincides with the $n$th eigenvalue of $A$. We call that eigenvalue $\hat E$. In other words, there is a multiplicity 2 eigenvalue of $A$ at $\hat E$. It is known that all solutions $u\in L^2 (\mathbb R, dx)$ to the Schrödinger equation $$-u''(x)+V(x)u(x)=\hat E u(x)$$ are periodic. Let $u_1(x)$ be the solution with initial conditions $u(0)=0, u'(0)=1$ and let $u_2(x)$ be the solution with initial conditions $u(0)=1, u'(0)=0$. It is easy to find a 1-periodic function $W(x)$ in $C^\infty$ that satisfies $$\int_0^1 W(x) u_1(x)^2 dx\neq \int_0^1 W(x) u_2(x)^2 dx.$$ Let $\lambda$ be a small constant. Supposedly, when we perturb $V$ by $\lambda W$ in the definition of $A$ (that is, replace $V$ with $V+\lambda W$) we can guarantee that for sufficiently small $\lambda$ the $n+1$st eigenvalue of $A$ no longer coincides with the $n$th eigenvalue. Why is that true? The paper cites Kato's Perturbation Theory for Linear Operators as justification, but I cannot find anything there that is directly relevant. 

I am searching for a comprehensive survey article (or more different articles) on the subject of isoperimetric problems from ancient Greece to modern mathematical physics. Could you point out some highlights? 

It is well-known that there is a relationship between music and mathematics, and there are many references that explore this topic (for example, Benson's book). However, I would like to ask if there is any current research going on between the relationship between mathematics and music which produced results significative to the development of mathematics (other than to the development of music theory). In case, where can I find a comprehensive survey paper of such results? 

Usually, during lectures Turing Machines are firstly introduced from an informal point of view (for example, in this way: $URL$ and then their definition is formalized (for example, in this way: $URL$ Is it possible to give another 'equivalent' definition that relies more precisely on algebraic concepts (i.e. algebraic structures: semigroups, monoids, etc; just like, for instance, regular languages are recognized by finite monoids and context-free languages are recognized by a product of a free group and a finite monoid)? 

I understand that the KdV equation, $$u_t(x,t)=-u_{xxx}(x,t)-6u(x,t)u_x(x,t)$$ is a compatibility condition of the two equations $$\psi_{xx}(x,t)=-(u(x,t)+\lambda)\psi(x,t),$$ $$\psi_t(x,t)=u_x(x,t)\psi(x,t)+(4\lambda-2u(x,t))\psi_x(x,t).$$ In other words, if these two equations are true it implies the KdV equation. These calculations are straightforward and available in these lecture notes. My goal is to understand why the KdV equation is an isospectral evolution of the Schrödinger operator $$H(\psi)=\psi_{xx}+u\psi$$ I can see why the evolution given by the KdV equation preserves the eigenvalues of $H$. But 

I asked the following question at Math Stackexchange a while ago here but did not get a correct answer. 

I am concerned about the Schrödinger equation $-x''(t)+q(t)x(t)=Ex(t).$ Here, the potential $q$ is real and quasiperiodic with frequency vector $\omega$. That is, we let $T^d$ be the $d$-dimensional torus and $\omega=(\omega_1,\ldots, \omega_d)\in T^d$ with the $\{\omega_j\}$ rationally independent, and $q(t)=f(\omega_1t,\omega_2t,\ldots,\omega_d t)$ for some continuous $f:T^d\to\mathbb R$, Equivalently, we may formulate this equation as a matrix equation instead, $X'(t)=\begin{pmatrix} 0&1\\ q(t)-E& 0 \end{pmatrix}X(t)$, where $X(t)=\begin{pmatrix} x_1(t)& x_2(t)\\ x_1'(t)& x_2'(t) \end{pmatrix}.$ There are two equivalent descriptions of a Floquet-Bloch solution, which I am having difficulty reconciling. First, we say a solution of the form $x(t)=e^{kt}(p_1(t)+tp_2(t))$ is a Floquet-Bloch solution, where $k$ is a constant and $p_1, p_2$ are quasiperiodic functions with frequency vector $\omega$ or $\omega/2$. Second, we say $X(t)=Y(\omega t/2)e^{At}$ is a Floquet-Bloch solution, where $A\in SL(2,R)$ and $Y:T^d\to GL(2,R)$. I don't see why these two are the same thing? 

Let's be precise about the question! I claim it is not meaningful until you choose basepoints in X and Y and restrict to based maps, since otherwise the suspension used to define the stable homotopy groups is ambiguous. And then you might well get different answers for different choices of basepoint: some might be degenerate, others nondegenerate, in the same space. Algebraic topologists tend to define away point-set horrors such as degenerate basepoints. Alternatively, growing a whisker on a bad basepoint gives a good one, and that is actually a cofibrant approximation for the h-model structure ("classical" or "Strom") on based spaces. The answer is yes for based maps between nondegenerately based spaces. I'm not even sure you have a suspension isomorphism for reduced homology if the basepoint is degenerate, but you certainly do if it is nondegenerate (e.g page 107 of "A concise course in algebraic topology"). Now suspend twice to get an isomorphism on homology between simply connected spaces, etc. 

The easiest starting point for equivariant stable homotopy theory is probably the paper with that title in The Handbook of Algebraic Topology, edited by I.M. James. The paper modern foundations for stable homotopy theory in the same volume is one of several possible starting points for spectrum level stuff. 

Context: this is a step to the proof of Claim 3.7 in this paper (if you have access to Comm Math Phys, the published version is here). In that paper, they used the "identity" $ \tan (\theta)\tan(\varphi)=\frac{1}{\Vert B \Vert^2},$ which I am pretty sure is false (you can choose $z$ to be in the most expanding direction, in which case we have $\varphi=0$ and so the LHS is $0$). 

I need to solve the following system of quasi-linear partial differential equations, where the unknowns $f(x,t), g(x,t)$ are smooth functions on $\mathbb R^2$, $$ \dfrac{\partial}{\partial t}f=\dfrac{\partial}{\partial x}((f^2+g)f),$$ $$ \dfrac{\partial}{\partial t} g=\dfrac{\partial}{\partial x}((f^2+g)g),$$ I think I am supposed to use the method of characteristics to find a characteristic surface, but I don't know how to do this. (I asked a more or less equivalent question on Math Stackexchange here, and got no answers) 

Consider a matrix $B\in \mathrm{SL}(2,\mathbb R)$. Let $s$ be a vector that is pointing in the most contracted direction of $B$, and let $u$ be the image under $B$ of a unit vector pointing in the most expanded direction of $B$. (The lengths of the vectors $s$ and $u$ don't really matter) Let $z$ be a nonzero vector not pointing in the most contracted direction. For some large positive parameter $r$ let $\theta\in (r^{-80},\frac{\pi}{2}]$ be the angle between $z$ and $s$, and let $\varphi\in [0,\frac{\pi}{2}]$ be the angle between $Bz$ and $u$. Let $\Vert B\Vert$ denote the norm of the largest eigenvalue of $B$. Assume that $\Vert B\Vert\geq e^{cr}$ for some constant $c$ and $r$ sufficiently large. How do we show that $\varphi<r^{-100}$?