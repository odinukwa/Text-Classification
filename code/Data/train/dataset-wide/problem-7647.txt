I've heard that Reshetikhin-Turaev (RT) is stronger than homotopy, and it can distinguish certain homotopy-equivalent, but non-homeomorphic Lens spaces (I think $L(7,1)$ and $L(7,2)$). Now the Turaev-Viro-Barrett-Westbury (TVBW) invariant for a spherical fusion category $\mathcal{C}$ is the Reshetikhin-Turaev invariant for $\mathcal{Z}(\mathcal{C})$, which is a restriction, so in principle, RT could be stronger than TVBW. Are there calculations that show explicitly how TVBW is stronger than homotopy? What category do you have to use to achieve this? Otherwise, I'm very happy to hear expert opinions stating that this is an open problem. 

In a sense, this is a follow-up to this question. By work of Freedman and Wall, it is known that if two simply-connected 4-manifolds $M$ and $N$ are homeomorphic, then there is $k \in \mathbb{N}$ such that $M \times \#^k (S^2 \times S^2)$ is diffeomorphic to $N \times \#^k (S^2 \times S^2)$. (By $\#^k$, we denote $k$-fold connected sum.) Can this statement be generalised to non-simply-connected manifolds, possibly including Whitehead torsion? 

A semisimple braided category with duals is called modular when a certain matrix $S$ is invertible. The components $S_{AB}$ are indexed by (isomorphism classes of) simple objects of the category and one computes $S_{AB}$ by colouring the Hopf link with (representants of) $A$ and $B$ and evaluates the resulting diagram. One can show that a category is modular iff there are no "transparent" objects (objects that braid trivially with every other object) besides the monoidal unit. Is being modular a specific property, say in the category of braided categories? Is being a modular category equivalent to being the limit of some diagram or satisfying some diagram? 

Putting these together, one might imagine that a good way to find factors of $n$ would be to compute $\gcd(n, x^k-1\mathrm{\ mod\ } n)$ with $k$ a product of distinct primes and $x>1$. This is equivalent to testing $\Phi_d(x)$ for a common factor with $n$ for each of the exponentially-many divisors $d|k$. So it might naively be hoped that one could thereby factorise $n$ in time $O(\log n)$ or thereabouts. Of course this does not actually work – one cannot thus factorise enormous numbers in the blink of an eye. I justify this claim on the non-mathematical grounds that a) if such a simple method worked then someone would have noticed by now; and the heuristic grounds that b) I tried it, and it didn’t. What I would like to know is why it doesn’t work. Presumably the problem is that the $2^b$ values $\Phi_d(x)$ are distributed in a sufficiently non-uniform way to stymie the procedure. What’s going on here? I can’t see much hint of this non-uniformity in examples that are small enough to compute all the $\Phi_d(x)$ explicitly in a reasonable amount of time. For example, if $n=61\times71=4331$ and $k=9699690$ is the product of the first eight primes, then the expression $\Phi_d(2)$ takes 244 different values as $d$ ranges over the $2^8=256$ divisors of $k$. (And as it happens, $\Phi_{35}(2)$ is a multiple of 71, and so computing $\gcd(4331, 2^{9699690}-1\mathrm{\ mod\ } 4331)$ reveals this factor.) 

Since handle decompositions and Morse functions are intimately related, I'm imagining that a given explicit handle decomposition allows for an explicit description of the cellular complex and thus of (co)homology, which is directly isomorphic to Morse (co)homology. More precisely, the $k$-th grade of the complex is generated by the $k$-handles. It is known how to compute the cup product $\smile\,\colon H^i(M) \otimes H^j(M) \to H^{i+j}(M)$ for the Morse cohomology $H^*$ of a smooth manifold $M$. One has to chose two different Morse functions and study certain Y-shaped Morse flow lines. The cap product should be related. Is there a way to translate this to handle decompositions, i.e. an algorithm to compute the cap product $\frown\,\colon H^i(M) \otimes H_j(M) \to H_{j-i}(M)$ for given handle decompositions? In particular, how do you compute it for Kirby diagrams? Edit: As far as I understand, the reason why this isn't trivial is because the diagonal map $\Delta\colon M \to M \times M$ is used in the cup product: The first part of the cup product is a special case of the Künneth isomorphism $H^*(M) \otimes H^*(M) \cong H^*(M \times M)$, and then we pull back along the diagonal, $\Delta^*\colon H^*(M \times M) \to H^*(M)$. But the diagonal is not a cellular map, so it doesn't have a straightforward description in terms of handles. 

I see no difference between working with the continuous time process and discrete-time process for this problem. Hence, to mitigate the unnecessary burden of notation, the rest of the work will be presented as the problem is posed for discrete time process. Denote that: 

From those, we deduce: $ \mathbb{P}_{\mu} (X^{N+t} =0) \ge p+(1-p) \mathbb{P}_{V} (X^{t} =0)$ (1) On the other hand, we have: 

From (1) and (2) , we get: $\mathbb{P}_{\mu} (X^{N+t} =0) \ge p+(1-p)( \sum_{i\ge 0 }^t m(t-i) \mathbb{P}_{V}( T_{C} =i)) $ Take the limit and do some calculations, $ \lim_{ t \rightarrow \infty} \mathbb{P}_{\mu} (X^{t} =0) \ge p+(1-p)( I ( \sum_{i\ge 0 }^t \mathbb{P}_{V}( T_{C} =i) )$ $ = p+(1-p)I (\mathbb{P}_{V}( T_C<\infty))$ $ = p+(1-p)(I \sum_{s \in S'} \mathbb{P}_{s}( T_C<\infty)\mathbb{P}_V ( X_0=s'))$ $ = p+(1-p)(I \sum_{s \in S'} \mathbb{P}_V ( X_0=s'))$ (first condition) $ = p+(1-p)I$ Then take the infimum. $\Rightarrow I \ge p+(1-p)I \Rightarrow I=1$ Therefore, $ \forall \mu \in \mathcal{D}(C) : \lim_{t \rightarrow \infty} \mathbb{P}_{\mu}(X^t = 0)=1$ Which gives $ \mathbb{P}_{\mu}( T_0 < \infty)=1$.()** Finally, $\forall x \in S'$, we have: $ \mathbb{P}_{x}( T_0 < \infty) \ge \sum_{i \ge 0 } \mathbb{P}_{x}( T_0 < \infty | T_C = i) \mathbb{P}_{x}( T_C=i) $ $ =^{**} \sum_{i \ge 0 } 1. \mathbb{P}_{x}( T_C=i) = \mathbb{P}_{x}( T_C< \infty)=1$ Q.E.D 

What a great question. I’m sure there will be many lovely examples. Here is one I stumbled on last year which seems to fit. I saw an online demonstration of a simulated annealing algorithm for the following problem: a digital photograph has been “shredded” by randomly shuffling the columns of pixels, and we wish to recover the original unshredded image. Here is such a shredded photograph. 

Added: Thanks to David E Speyer for a clear concise answer. Just to make it explicit, the “non-uniformity” at play here is that each prime factor of $\Phi_d(x)$ is congruent to 1 modulo $d$. 

Added: Since this question as written has no responses, let me explicitly widen the net to admit references to the 1-dimensional analogue of this observation, since the essential idea is the same in any number of dimensions, and 1-d paths have been better studied. (They’re usually described as NE/SE or N/E lattice paths in 2 dimensions, presumably because those representations map directly to readable diagrams). In a now-deleted answer, Mark Wildon pointed to Lemma 4 in this nice paper of his (2009), which is indeed essentially the same idea in 1d. Does anyone know an earlier reference to this idea? 

I have a braided monoidal, semisimple linear category $\mathcal{C}$. (Imagine representations of a semisimple quasitriangular Hopf algebra.) I also have a monad $(T,\mu,\eta)$ on it, however, $T$ is not necessarily monoidal. (Imagine left-tensoring with an algebra $A$ internal to $\mathcal{C}$, so $T = A \otimes -$.) Is there a general way to decide whether the Kleisli category or the Eilenberg-Moore category are braided monoidal? I already know from Wikipedia that if $T$ is lax monoidal and $\mu$ and $\eta$ are monoidal natural transformations, then the Kleisli category is monoidal as well, but what about the Eilenberg-Moore category? And do either have a braiding coming naturally from $\mathcal{C}$? Finally, when are Kleisli and Eilenberg-Moore categories semisimple? For my example, I guess the Kleisli category is not semisimple, but the Eilenberg-Moore category is, but I'm still a bit confused. 

Groups Let $G$ be a finite group. An involutive automorphism on $G$ is an automorphism $i\colon G \to G$ such that $i^2 = 1_G$. Question 1. What classifies involutive automorphisms on a given (non-abelian) finite group? In particular, is there any classification in terms of group cohomology? Note that the involutive automorphisms needn't form a group, just like the involutions (the "inner involutive automorphisms", if you wish) don't necessarily. Observe the following: Whenever $h = i(h)^{-1}$, then $j(g) = h^{-1}i(g)h$ is again involutive. Question 1.1. Is the set of involutive automorphisms a torsor for some group? Given two involutive automorphisms $i$ and $j$, then $ji$ is an automorphism of $G$, but I don't see any guarantee that it is inner, let alone conjugation by an element $h$ satisfying $i(h) = h^{-1}$. Now famously the number of involutions is given by a formula involving irreducible characters and Frobenius-Schur indicators, but I'm not aware of any such result for involutive automorphisms. Fusion rings Let $R$ be a unital ring with a finite basis $B$ containing the neutral element such that all structure constants are nonnegative. Such rings are called based rings. Morphisms of based rings are required to map basis elements onto basis elements. A fusion ring is a ring structure on $\mathbb{Z}^n$ with basis $\{(1,0,\dots), (0,1,0,\dots), \dots\}$, together with an anti-involution $i$ on $R$ such that for every basis element $b$, the multiplicity of the neutral element in $b \cdot i(b)$ is exactly $1$. (The Grothendieck ring of a fusion category is always a fusion ring, hence the name. The extra condition on the chosen anti-involution encodes the existence of duals in the category.) It is easy to check that every finite group gives rise to a fusion ring, where the chosen anti-involution is inversion. But there are also many fusion rings that don't come from groups, for example the Fibonacci ring with basis $\{1, \tau\}$ satisfying $\tau \cdot \tau = 1 + \tau$. Questions 2-2.1. What classifies involutive automorphisms on fusion rings? (And the same further questions as for groups.) 

Incidentally, the reason I was familiar with TSP-solving technology is that I had used it earlier to disprove a 20-year-old conjecture in combinatorics: another problem that doesn’t sound like graph theory at first blush. 

A historical example, in the sense that the conjectural equality has been refuted: A180632 (Minimum length of a string of letters that contains every permutation of $n$ letters as sub-strings) was conjectured equal to A007489 ($\sum_{k=1}^n k!$). The exact value of A180632 at $n=6$ is still unknown, but it must be less than the conjectured value of $1!+2!+\cdots+6!=873$, because the following string of length 872 contains every permutation of 123456 as a substring: 

The polynomial $x^k-1$ can be factorised over the integers as a product of (irreducible) cyclotomic polynomials: $$x^k-1 = \prod_{d|k}\Phi_d(x).$$ If we choose $k$ to be a number that has a lot of divisors, then $x^k-1$ will have a lot of factors. For example, if $k$ is a product of $b$ distinct primes then $x^k-1$ has $2^b$ factors. Suppose we are given some largeish natural number $n$, and we want to factorise it. One way to find a factor of $n$ would be to compute the product $a$ of lots of different numbers $a_i$, modulo $n,$ and then compute $\gcd(n, a)$. If we are lucky and some of the $a_i$ are factors of $n$ but $a$ is not a multiple of $n$, then the gcd will be a non-trivial factor of $n$. 

This may be more of a comment or opinion. A 2-Hilbert space is a Hilbert space on two levels: It's enriched in Hilbert spaces (morphisms) and it's a categorification of a Hilbert space in the sense of having biproducts for addition, Deligne-product with $\mathrm{Vect}$ for scalar multiplication and dual structure for the sesquilinear form. Which of those levels do you want to have infinite dimensional? The first one shouldn't be a big deal, you just allow for infinite dimensional Hilbert spaces as $\mathrm{hom}$-spaces. The second one is the harder one. I personally think that it is no big deal "formally", it just amounts to dropping the requirement that the 2-Hilbert space be finitely semisimple. The question is, will you find interesting examples that are actually any use? You have the same in vector spaces. I can cook up tons of infinite dimensional vector spaces, but how do they become interesting and tractable at the same time? By adding some extra structure, say as a Banach space, a $C^*$-algebra, an $\mathrm{L}^2$-space over some measurable space or so. In that sense, I'd say that there already is a theory of "dull" infinite dimensional 2-Hilbert spaces, but people are thinking about interesting ones with extra structure, such as having a measure on objects. As for your final question, I'd guess it will depend on the context of what you're doing. Are you considering some $n$-dimensional moduli space ($0 < n < \infty$)? Smooth groupoids? Then the approach with measurable categories may suffice. If your additional structure is different, a different variant might be needed. 

If the first square in row $i$ has side $1/{n_i}$, then $n_0=3$ and $n_{i+1}=\lfloor \frac{3}{2}n_i\rfloor$. But then the total height of the first seven rows is already $$\frac 13 + \frac 14 + \frac 16 + \frac 19 + \frac 1{13} + \frac 1{19} + \frac 1 {28} > 1.$$ On the other hand this arrangement is not optimal, since the sixth row has squares $\frac 1{19}, \dots, \frac 1{27}$ but we could fit up to $\frac 1{30}$. So perhaps the claim is still true, notwithstanding the unconvincing proof? 

I think Calkin and Wilf’s lovely short paper on what is now known as the Calkin-Wilf tree would be suitable. 

This is still a hard problem (#P-complete), so it almost certainly can’t be done in polynomial time. See Valiant, L. G. (1979). The Complexity of Enumeration and Reliability Problems. SIAM J. Comput., 8, 410-421. As for the other part of your question, I wonder if you’ve fallen prey to some terminological confusion. It seems clear that what you’re interested in is counting all the simple paths – paths that visit each node at most once – between two nodes. Multiplying adjacency matrices gives you something different: it counts all the paths, including non-simple ones that may double back on themselves or go round a loop. 

Before the demonstration of the problem, we start with some propositions Firstly with those concerning $m(t)$ Proposition 1: For all $t \in \mathbb{N}$ , $\begin{array}{lccl} m_t : & \mathcal{D}(C) & \rightarrow & \mathbb{R} \\ &V & \mapsto& m(t,V) \end{array} $ is an affine function. Demonstration 1 If each distribution represented as a stochastic row vector, $m(t,V) $ is indeed equal to $ VP^t\delta_0^T$ .QED Proposition 2: For each $t$, the infimum in the definition of $m(t)$ is achievable, ie. $ \exists \mu_t \in \mathcal{D}(C) : m(t) = m(t, \mu_t)$. Demonstration 2 Following from the previous proposition, in looking for the infimum of $m(t,V)$ over $\mathcal{D}(C)$, we are minimizing a continuous function over a compact set ( $ dim( \mathcal{D}(C) ) < \infty $ as $ |C| <\infty$ ). It therefore has a minimum. Remark 1: As $m_t$ is affine, it is reasonable to even suppose that $\mu_t = \delta_{d_t} $ for some $ d_t \in C$. Proposition 3: $( m(t) )_{t \in \mathbb{N}}$ is an increasing sequence. Demonstration 3 The proposition 2 and the fact that $0$ is an absorbing state imply : $m(t+1) = m(t+1, \mu_{t+1}) = \mathbb{P}_{\mu_{t+1}}( X^{t+1} =0)$ $ \ge \mathbb{P}_{\mu_{t+1}}( X^{t} =0) \ge \min_{\mu \in \mathcal{D}(C)} \mathbb{P}_{\mu}( X^{t} =0) =m(t)$ . QED Then, some proposition for estimation. Proposition 4: $ \exists p> 0 $ and $N \in \mathbb{N}$ such that : $ \mathbb{P}_{U}(X^N =0)>p $ for all $U \in \mathcal{D}(C)$ ,ie : $ m(N) >p$. Demonstration 4 The second condition of the problem shows that for each $ i \in \mathbb{1,n}$ , there is $p_i>0$ and $N_i>0$ such that : $\mathbb{P}_{c_i}( X^{N_i} =0 ) > p_i$ Choose $ p= \min( p_1,p_2,..,p_n); N=\max(N_1,N_2,..,N_n)$, using the fact that $0$ is an absorbing state, we deduce that: $\mathbb{P}_{c}( X^{N} =0 ) > p \forall c \in C$ Therefore, QED. And the last ingredient, Proposition 5: $\lim_{ t \rightarrow \infty} m(t) = \inf_{ \mu \in \mathcal{D}(C) } \lim_{t \rightarrow \infty} \mathcal{P}_{\mu}(X^t = 0)= I $ Demonstration 5: As $0$ is an absorbing state, for all $ \mu \in \mathcal{D}(C) $, $ ( \mathcal{P}_{\mu}(X^t = 0) )_{t \ge 0 }$ is an increasing state. Therefore, $ \lim_{t \rightarrow \infty} \mathcal{P}_{\mu}(X^t = 0) \ge \mathcal{P}_{\mu}(X^n = 0) \ge m(n) \forall n$ $\Rightarrow RHS \ge LHS$ On the other hand, following the remark 1 , and the fact that $|C| $ is finite, we deduce that : $\exists$ an strictly increasing sequence of natural numbers $(n_i)_{i \ge 0}$ and a state $c^* \in C$ such that: $ m(n_i) = m(n_i, \delta_{c^*} ) = \mathbb{P}_{\delta_{c^*} }( X^{n_i} =0)$ As $(m(t))_{t \ge 0}$ is an strictly increasing sequence, we also deduce: $\Rightarrow \lim_{t \rightarrow \infty} m(t) = \lim_{t \rightarrow \infty} \mathbb{P}_{\delta_{c^*} }( X^{t} =0) \ge \inf_{ \mu \in \mathcal{D}(C) } \lim_{t \rightarrow \infty} \mathcal{P}_{\mu}(X^t = 0) $ $\Rightarrow LHS \ge RHS$ QED. Let's begin the main demonstration Demonstration For all $t>0$ , $ \mu \in \mathcal{D}_{C}$ and the fact that $0$ is an absoribng state (*) , we have: