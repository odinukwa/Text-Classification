Does anyone has a good experience of setting a staging area in a remote data center? Should it be on a separate VLAN, or it can run in same LAN, by tight control of which servers are allowed to boot from DHCP? My idea in general is to allow something similar to our local staging area - but instead of bringing servers here, deploying then shipping to data center, they will be delivered directly to the data center and be deployed there. Regards. 

We ghosted our old Windows 2003 drive to a new 1TB one, and connected through new PCI SATA card. The x260m server fails to boot with error 1962: "Boot sector not found." When we connect the drive directly to motherboard, it boots fine, so the problem is probably in getting BIOS to boot from the SATA card. Has anyone encountered and solved such issue? EDIT: We tried disabling the on-board Sata controller (Hostraid/SAS?), but there is no such option - only enable, enhanced and compatible. Tried also to chance boot device priority to all possible choices - no luck. Thanks in advance! 

Has anyone tried the second option, and how it worked out? I'm especially interested in High-Availability performance under such environment. Thanks. 

Installed a fresh CentOS 5.10 installation on RAID5 provided by Perc H700 Integrated RAID, however the system fails to boot. Checked the system via recovery CD, and noticed that CentOS 5.10 now uses GPT instead of MBR. Updated H700 to latest firmware version, same result. Previous version of CentOS (5.x circa 2011) worked just fine on this server. Any idea how to make the RAID recognize the partition / boot record and start the system? 

Having failures to build RPM using some spec file which works great for other users, I found out that it for some reason changes the current directory to rpmbuild/BUILD: 

We have a really strange issue with recently installed DNS server. No matter which request submitted, it always returns 1.1.1.1, until the whole server is restarted. Restarting only the DNS service doesn't help. After the restart, the issue returns after some time. Has anyone encountered this, and can recommend how to resolve this? Thanks. 

I'm trying to figure out how $RPM_BUILD_ROOT relates to BuildRoot. It's clear that BuildRoot is the temporary path used during RPM construction. But here for example, they say buildroot is used during actual installation? $URL$ " RPM_BUILD_ROOT â€” This environment variable is used to hold the "build root", into which the newly built software will be installed. If no explicit build root has been specified (either by command line option, spec file tag line, or rpmrc file entry), this variable will be null. " So, does buildroot has any effect during actual installation? Or it's only needed for RPM building, and user always specifies the target path via --prefix? Also, during files and postun sections, any sense to use the buildroot? If not, what is the correct way to specify files and directories, taking into account the prefix set by user? Thanks. 

Can anyone recommend a good open-source inventory-agent, which would help enumerate both software and hardware on Linux servers? Thanks. 

The 29GB of primary disk coming up with Ubuntu 14.04 are not enough for our needs. Also (from what I understood), the attachable disks are not SSD. Is there an updated method of resizing the primary disk, rather then the one described in the somewhat outdated guide here? $URL$ 

Can anyone recommend a Linux specialized distribution (or appliance) which provides both Firewall and Load-balancer? Something similar to IPCop for example, but containing LB as well? Thanks in advance. 

Sorted it out with PowerBroker Identity Services Open Edition: $URL$ Worked out of box, without the complications of samba. 

I'm looking for desktop-grade drives to build a distributed storage cluster (chunks are replicated on software level). I don't mind their mission critical ability, which clearly impossible with their desktop designation instead of 24x7, but will appreciate a brand / model that will cause the least faults, while still being fast. Any ideas? 

Can someone provide cons and pros for having DHCP in a data center? I know this is usually a taboo, but maybe there were developments which alleviate the said issues? Thanks. 

I'm trying to prevent the search engines from crawling through SSL version of the site, to prevent content duplication and canonization issues. I found the following great article: $URL$ Problem is, that I'm using lighttpd, which doesn't seem to have the RewriteCond directive, to limit the rewriting only to SSL. Can anyone advice if this possible on lighttpd, and give a snippet? Thanks in advance! 

I have a CentOS server with 4 disks, each with 1TB that totals to 3.636 TB of usable space (according to $URL$ But the server df command shows the following status: 

We are buying new Dell R410 servers, and I'm trying to figure out the best RAM performance we can get. Dell offers the following choices: 

We trying a Xen server, and have a very strange issue, one that never happened to us on open-source Xen. The VM's created on Xen do not see the network outside the host. They do can ping each other and host, and the host can ping them, but that all. Any idea what causing this? I posted a question on Citrix forum but so far didn't receive a clear reply. Thanks in advance! 

To anyone with OpenShift Origin experience, is there any benefit in skipping any IaaS infrastructure (like OpenStack), and installing the PaaS layer right on top of hardware? What would be the upsides and downsides of such approach? Thanks. 

False alarm - apparently a new router we added wreaked havoc in network, possibly by intercepting the DNS queries. Removing the router sorted out this issue. 

Can anyone explain what is the major difference between Heartbeat and UCarp for IP fail-over scenarios? They both seem to provide this functionality, perhaps UCarp simpler to set-up? Thanks. 

So on overall, I'm about 900 GB short. Any idea where that space went, and how I can get it back? Thanks! 

I have some open-source Xen images (.img), that I want to convert to VirtualBox. Both the methods I tried (convertfromraw or to .xva via xva.py then to ova via XenConvert) produce FATAL: Fatal: No bootable medium found!. Any idea what the most reliable method is for performing this conversion? Thanks in advance. 

I have a quite big problem with customer's MS Exchange. The server got it's disk filled about 2 weeks ago, so it's currently offline. They plan to upgrade it, but not in hurry, as they use it mainly for OWA and back-up - the mails exchange is done via SMTP and POP3. Trying to diagnose some problem today, one of the users has (following the ISP instructions), removed the Exchange account from Outlook, which essentially left the OST orphaned. The user naturally didn't move the emails or any other data to the Archive / PST before, so these emails located on the OST only. So currently I'm trying to figure out how to restore them. There are 2 options: 1) Make the user buy some tool to convert them to PST, and import as archive / main Outlok file? 2) Reconnect the Outlook to Exchange (once it up), let it sync the old server content, then shutdown Outlook and replace the new OST with the old one, start Outlook again in offline mode and move these files to archive. 3) Any other method? Can someone advice what would be the best approach here? The used versions are Outlook 2007 and Exchange 2003. Thanks! 

I'm planning to migrate from MySQL to PostgreSQL, but worried about the apparent luck of replications solutions there. Are there any current replication techniques that can be used out of box? Heartbeat/DRBD would probably work, but I'm looking for approaches that are more integrated in PostgreSQL itself. 

Found it, apparently our router doesn't like the extra hope the virtual machine adds, works fine in another place. 

To anyone used Duplicity with Duply (wrapper script) on S3, what is the correct command to make duplicity purge old backups? I tried setting up the "MAX_AGE=7D" variable, and calling duply with backup_purge --force, but it still keeps all backups. Thanks for any idea. 

Have a strange issue on freshly installed CentOS 6, with Samba Windows 2008 R2 authentication. The login succeeds, and even the home directory created, but then I'm thrown back to the login scren again. The message log contain the following errors: 

with the message "sda not found". As the SSD is SATA3, shouldn't it be called via the standard sdX names? The machine is physical (Tyan AFAIR), and I'm trying to deploy latest CentOS 5.x via TheForeman, which includes DHCP/TFTP and Puppet. The disks are SanDisk Industrial/ Embedded SSD (32 GB), mounted via 2.5 to 3.5 adapter to server disk brackets and connected directly to the motherboard SATA ports 

I have multiple WSGI instances running each on it's own user account. I'm trying to give the users to reload their own HTTPD processes only on Python/DJango code update, without impacting the other users (as full Apache restart would do). Any way to accomplish this? 

We just installed Exchange 2010 for transition from 2003, and before continuing, wanted to upgrade to available SP1. Reading the forums, I seen a lot of complains about list of required hot-fixes and general in-compatibility. So question - is it worth hunting all these hot-fixes and install the SP1? Or it better skip this update and wait for SP2? Thanks. 

Is there any specific module/package in Linux responsible for initiating shut-down, once the power-off button was pressed? I installed a minimal version of CentOS Linux by removing the base package, and the power-off button stopped working. It does works fine in regular installation, so there must be some package missing? 

The solution suggested on Citrix forums was pretty simple - connect network cable to second NIC, and move all machines to it. Surprisingly, it helped. 

I moved my CentOS soft-RAID1 drives to another box, and now it fails to boot. When I launched the boot process from the grub menu, I get the following error: "Unable to access resume device /dev/md1". (I should notice that before that I got another error related to super-block, which was fixed by re-running the mkinitrd). Any idea? 

Trying to install web package in WebPI via Cygwin SSH (for automation) returns this error: There was an error reading IIS configuration schema from 'C:\Windows\system32\inetsrv\config\schema\'. When launched from the desktop Cygwin it works fine. Any idea what permissions might be missing, and how this can be solved? 

Is it possible for both Xen host and Xen guest to share same IP (albeit with different ports)? We have a single public IP, and want to have both the Xen host (as host only, no other role) and the Xen guest, to use it. Thanks. 

We have started using the DFS sharing functionality in Windows 2008 R2 (previously we used regular shares on Windows 2003), and noticed that for every office document we work on, it's work-file (filename starting with ~) is kept on the DFS-shared volume, so we have to erase them manually. Did this happen to anyone else, and is this a known issue? Searching online doesn't produce any meaningful results. Thanks. 

We are migrating to Server 20008R2 / Exchange 2010 SP1 (from server 2003, Exchange 2003), and as part of the process, have created a new forest with a different FQDN. Now we at the end of the migration after finishing with the ADMT tool, and trying to migrate from Exchange 2003 to 2010, and the part of the process is using the Prepare-MoveRequest.Ps1 to merge attributes from source domain to target domain accounts (-UseLocalObject -OverWriteLocalObject switches). The problem is that Prepare-MoveRequest.Ps1 script copies the source accounts as new ones, instead of merging them, as source and target account have different FQDN. There is also a message: WARNING: Cannot find corresponding object for XXX (source domain FQDN) in current forest. 'member' not updated. Any idea how to solve this issue, and merge the source attributes to new one? Thanks! 

I'm trying to clone an existing single disk (on Windows server) to RAID 1 via new ServeRAID M1015 / SAS9220-8I HBA card, but can't find in the card's bios options any way to do so. Can anyone advice about this particular controller, if it possible to clone an existing disk? The only other way I can think of, is making a new RAID-1 from scratch, then trying to clone the existing disk to it via disk cloning tools, but really prefer not to do this because of possible complications. Thanks. 

As I'm looking to take advantage of the SSD disks offering (D type in Azure), I understood that the only way to use them, is to copy the data to attached SSD disks from external storage like blob. I have customized an Ubuntu image, and now looking for a way to copy this data on VM's start-ups. What would be the best way to achieve this? Via standard Linux means (e.g. init script), or there is a better and faster measure provided by Azure? 

I noticed that using a dot (.) in Apache Location requires adding trailing slash in URL to work properly. Anyone knows why this happens, and how to enable it to work without the trailing slash? 

I need to keep ProxyPass configurations in separate files due to deployment system we use in following form: File 1: 

I'm trying to set-up a private git repo for code sharing, but found out that most of the implementations out there require use of SSH public keys, for example: $URL$ The only approach looking reasonable is the git-daemon, but it does not contain any authentication, and while it might be a good option for LAN, it is no go for remote working. Coming from SVN daemon, where all the access was conveniently controlled via single file, the SSH keys scheme quite a hurdle for me. Is there any way to securely share multiple Git repositories, without using SSH authentication? Thanks in advance! 

I'm running a FreeNX server on headless CentOS machine, and the resolution seems to be locked on 800 x 600. I tried editing the xorg.conf file, but without success so far. Has anyone succeed of running the FreeNX remote under 1280 x 1024 resolution, and can post a working configuration? Thanks! P.S.: Here is the pastebin of my current xorg.cof file: $URL$ 

I'm trying to make two physical interfaces visible to a Xen machine. I followed the guide ($URL$ and created two Xen bridges for two physical interfaces / updated the guest config file with the new bridge. The problem is that my guest machines are still unable to see the eth1. I'll appreciate anyone who had success with this posting any notes or checklist. The host (Dom0) is CentOS 5.5 64-bit, guest is CentOS 5.3 64-bit. The used Xen is version 3.0.3. Thanks! 

We have re-created RAID1 on our IBM X3400, with the 8K-l RAID card, and now the RAID1 is in status of Quick Initialized. I've read online that the performance of this status is might not be optimal, and some actions required to bring the operation paramters to optimal. Is this correct, and would the synchronize action (as I don't see anything else available) help? Thanks!