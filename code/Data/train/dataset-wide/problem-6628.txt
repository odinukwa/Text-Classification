HMM-based systems and concatenative waveform-based unit-selection systems are similar in that they both involve the use of a large database of recorded human speech, and they both involve concatenating stored units to construct something that results in a whole output utterance. However, whereas waveform-based unit-selection systems store actual waveforms from the database and concatenate those waveforms, HMM-based systems store HMMs that have been trained on the database and concatenate the HMMs. These HMM "units" are used to construct a single HMM for the desired output utterance. A set of parameter values is generated from that utterance HMM, and a synthesizer synthesizes the output based on those parameter values. You can find many resources for further reading by Googling speech synthesis based on hidden markov models. 

While others have provided informative answers to this question, I would argue that the premise of this question is not completely accurate. For example, in the traditional distinctive feature set, all phonemes (both vowels and consonants) are specified for the features [cons] and [son]. Further, it's true that there are additional features for which only vowels or only consonants are specified, but in a way this is an arbitrary distinction to single out. For example, in the same way that all vowels and sonorant consonants and glides are trivially [+son], all consonants besides /h/ and /ʔ/ are trivially considered [-spread] and [-constr], meaning those two features are not used to distinguish a vast majority of consonants. The resulting effect is that the minus value for those features on most consonants doesn't amount to much more than a placeholder. One could easily assign a minus values for those features on vowels and it would bear the same significance. It's true that some of the features used to distinguish vowels appear to have redundant analogues in the set used to distinguish consonants (e.g. [rounded] and [labial]), but really that is just a side effect of the fact that they are derived from similar articulatory properties. It is important to keep in mind that the distinctive features are just a convenient way to categorize phonemes at the phonological level (which is why I added the phonology tag to the post) and at the end of the day they are abstract labels derived mnemonically from articulatory (and in some cases acoustic) characteristics of the speech units with which they are associated. 

I think this question may be trickier to answer than you realize--it largely depends on your definition of vowel and consonant. If you take a structural phonological approach to defining those terms (i.e., if whether something is a vowel or a consonant depends on where it occurs in the syllable), then they are by definition in complementary distribution, so there's no way to prove that any vowel and any consonant aren't allophones of the same phoneme. We may say that [j] and [l] must be realizations of different phonemes, because we have minimal pairs like yes/less. Similarly, [oʊ] and [i] must be realizations of different phonemes because we have minimal pairs like boat/beat. But there can't be a minimal pair that contrasts in the inclusion of a vowel vs. the inclusion of a consonant in the same syllabic slot. Pairs like yon/eon and fro/furrow don't count, because in such cases both the segmental makeup and the syllabic structure is varying. (Note that the same is true for the French example in @cyco130's answer.) In such a model, one might look to distinctive features as a guide for identifying consonant vowel pairs that might be considered allophonic pairs. In particular, one might consider approximant/vowel pairs in French, English, etc. (of the type that @cyco130 describes) to be allophone pairs by virtue of the fact that their "features" (other than +/-syllabic) are the same. Of course this kind of criterion is entirely dependent on the feature set you use! If you have other criteria for vowel vs. consonant, like 'vowels must be voiced' and 'all fricatives are consonants' (regardless of whether they are syllabic or not), then it may be possible to find some other types of cases that would qualify. For example, it is well-known that in continuous speech in Japanese high vowels often get devoiced after voiceless consonants. It is even common for the vowel to "disappear" altogether and be replaced by a lengthened version of the consonant before it, effectively being realized as a fricative*. 

What you are referring to are prosodic word boundaries. Prosody deals with the relative prominence of linguistic units, but it also deals with the delineation of those units at different levels. Prosody can be encoded in the "ups and downs" of speech melody, but it also manifests itself in terms of duration (of speech units and of pauses) and intensity, among other things. All of these acoustic properties can be used by a speaker to cue prosodic boundaries, including word boundaries. Other prosodic boundaries include syllable boundaries and phrase boundaries. I added the phonetics tag to your question because phonetics is the field of linguistics that deals with how phonological units like words and phrases are delineated acoustically (acoustics is not a field of linguistics per se; one can study the acoustics of jet engines or the acoustics of a concert hall, but phonetics deals with the acoustics of speech) and how those acoustic cues are produced and perceived. As you noted, the prosodic word is not always equivalent to the morphological word or the orthographic word. For example, a prosodic word can often consist of a content word and a function word that cliticizes to it. One final note: the term phonotactics is not directly relevant for the discussion of the phonetic realization of prosodic boundaries. Phonotactics is the branch of phonology that deals with what combinations of phonemes are permitted in a language. Sometimes the phonotactics of a language can interact with its prosody such that, say, certain consonant clusters are only able to appear across syllable boundaries. 

This grouping of a noun and its particle into a single prosodic constituent is analogous to the determiner-noun grouping in English. To bring everything back around to the OP's hypothetical language, if li is a definite article, and it behaves like the determiner the in English or the particle -o in Japanese, it will form a single prosodic constituent together with stulu whether it is a prefix or a standalone morpheme. 

Just Googling, I found this: $URL$ I don't know anything about it, but they claim to be able to handle French, Spanish, and English. 

@jlawler pretty much answered this already in his comment, but I thought I'd post an official answer. In theory, yes--it's sensible to apply the concept of homorganic-ness (homorganism??) to things other than consonants. As you mention, one could consider the offglide in the diphthong [ɑɪ] to be homorganic with the vowel [ɪ], or the glide [w] to be homorganic with the vowel [u]. In my experience, however, the term is rarely used in this way. One possible reason is that vowels and approximants are more difficult to characterize in terms of "place of articulation". What is the "place of articulation" of [a], for example? or of [ɹ]? And as for the diphthong [ɑɪ], some people transcribe it as [aj]. Its pronunciation can be more like [ɑɪ] or more like [ai]/[aj] (i.e., with a more extreme high-front offglide) depending on the context or how carefully it's pronounced, even for the same speaker. Does that mean that the former is homorganic with [ɪ] and the latter is homorganic with [i] and [j]? What would such a distinction be useful for? Which brings up a more general point--a label like homorganic is meaningful in linguistics only inasmuch as it is useful for delineating certain properties of speech/language units or relationships between/among speech/language units. Phonologists started noticing that consonants often form natural classes along certain dimensions--one of them being "place of articulation". That is, they noticed that consonants whose oral constrictions are made in the same or similar place in the mouth tend to group together in terms of the phonological processes they undergo/trigger. And they also noticed that certain phonological processes are sensitive to sequences of consonants that have the same place of articulation, hence the usefulness of the term homorganic. (In phonetics it is also sometimes useful to identify homorganic relationships among consonants, as doing so may bring certain phonetic patterns to light.) When it comes to vowels, phonologists found it more useful to categorize them along several "place-related" dimensions, like height, backness, etc. As @jlawler pointed out, if two vowels are articulated at the exact same place, they are trivially the same vowel and trivially "homorganic"; but then in that context the label is not very useful. The exception I can think of is a nasalized/non-nasalized pair. I'd wager, however, that it's unlikely that you'll find a process involving sequences of nasalized/non-nasalized vowel pairs in a language that makes such a distinction phonemically!