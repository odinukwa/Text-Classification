Let $A$ and $B$ have the same rank and dimensions. If $P_A$ denotes the projection onto the range space of $A$, then $$ \|P_A - P_B\|_2 \leq \|A - B\| \cdot \min (\|A^\dagger\|_2, \|B^\dagger\|_2). $$ Here $A^\dagger$ denotes the pseudoinverse of a matrix. I believe that this result is established by Golub and Zha in the course of their proof of Theorem 3.6 in "Perturbation Analysis of the Canonical Correlations of Matrix Pairs," but in a manner that's too messy to point to and say "here it is." Unfortunately, this result also doesn't seem to follow readily from the results in Stewart's paper on perturbation theory for pseudoinverses and projections. Is this result clearly established somewhere in the literature? 

I'm looking at some statistical literature and trying to compare the results given there in probabilistic big-Oh notation with statements I'm more familiar with. In particular, I'm trying to interpret statements of the form $$ \|\Sigma_{n(p)} - \Sigma \| = O_P\left( \frac{\log p}{n(p)}\right). $$ As far as i can tell from the rather terse wikipedia page on $o_p$ notation, this means that there is some constant $C$ that is independent of $p$ for which $$ \lim_{p \rightarrow \infty} \mathbb{P}\left( \|\Sigma_{n(p)} - \Sigma \| > C \frac{\log p}{n(p)}\right) = 0. $$ Is that correct? 

I have $A^{1/2} B A^{1/2} \preceq I$ for two PSD matrices $A$ and $B$, and I'd like to know if that implies $\|AB\|_2 \leq 1.$ The argument I was using to show this is that for any two square matrices $A$ and $B,$ it is always the case that $\|AB\|_2 = \|BA\|_2.$ I thought I read that this equality does hold in a reputable source, but I don't have access to it right now and I was unsuccessful in reproducing a proof. I know the eigenvalues of $AB$ and $BA$ are the same modulo possibly having different numbers of zeros, so I'm worried that I might have ``remembered'' something that isn't true! Any references/counterexamples for either question? 

I'm looking for a reference for the following fact (which I believe to be true and should be easy for people who understand how spectral sequences arise from filtrations). 

If I understand the setup of the question correctly, the answer is yes. Using non separated schemes makes no difference. This is explained here. In brief, whether you do the Grothendieck ring of "integral, finite type, separated" or "finite type" or even "finite type algebraic spaces" it's the same. When you pass to stacks it's a whole other mess of course. 

The question might be a bit vague. Certainly there are excellent references online on stability conditions. The first which comes to mind is the most elementary and is by Arend Bayer. If you are already familiar with all of that, these notes by Daniel Huybrechts go deeper into the subject. These are notes from a lecture series delivered in Cambridge, which was recorded on video. Also, I find the original paper by Bridgeland quite readable. 

I don't know of a uniform way to prove it for all curves. For elliptic curves it follows from Hodge theory and for the rest it's a consequence of the Bondal-Orlov theorem. It's all explained in Huybrechts's excellent book on Fourier-Mukai transforms. 

Maybe Asher Auel's thesis? But maybe it's still schemes, not sure! (but that thesis is still awesome) $URL$ 

I am trying to understand Remark 11.3 in Huybrechts's amazing book on derived categories (FM transforms in AG). He starts with smooth projective varieties $j\colon Y \subset X$ and aims to describe the local ext groups $\underline{Ext}^i(j_*O_Y,j_*O_Y)$ in terms of $\wedge^i N$ where $N$ is the normal bundle of $Y$ in $X$. To describe this, he mentions a morphism $\wedge^k \underline{Ext}^1(j_*O_Y,j_*O_Y) \to \underline{Ext}^k(j_* O_Y, j_* O_Y)$ which he calls cup product (or composition). 

No; here's a counterexample: let $f = 0$ and consider the minimizer $y = 0.$ Then you can construct convex functions which converge to $0$ pointwise but whose minima are always moving away from $y =0,$ e.g. $f_n(x) = (x - n)^2/n^n.$ 

The constraints can be rewritten by replacing the squares with absolute values, then you have a program like $\operatorname{argmin}_{\mathbf{X}} \|\mathbf{D}\mathbf{X}\|_F^2 + \|\mathbf{X} - \mathbf{Z}\|_F^2$ $\text{s.t.}\quad \forall i,j \quad |\mathbf{d}_{01} \mathbf{X}_i| = |\mathbf{d}_{01} \mathbf{X}_j|, \text{ and } |\mathbf{d}_{34} \mathbf{X}_i| = |\mathbf{d}_{34} \mathbf{X}_j| $ where the $\mathbf{X}_i$ constitute the columns of $\mathbf{X},$ the matrix $\mathbf{D}$ takes the differences of the consecutive columns of $\mathbf{X},$ and $\mathbf{d}_{01}, \mathbf{d}_{34}$ are appropriately defined row vectors. Then you can use the standard trick of replacing $|x|$ with $x_{+} + x_{-}$ subject to $x = x_{+} - x_{-}$ and $x_{+}, x_{-} \geq 0$ to get the equivalent program $\operatorname{argmin}_{\mathbf{X}, \mathbf{e}^{+}, \mathbf{e}^{-},\mathbf{f}^{+}, \mathbf{f}^{-}} \|\mathbf{D}\mathbf{X}\|_F^2 + \|\mathbf{X} - \mathbf{Z}\|_F^2$ $\text{s.t.}\quad \forall i: \quad \mathbf{d}_{01} \mathbf{X}_i = e^{+}_i - e^{-}_i, \text{ and } \mathbf{d}_{34} \mathbf{X}_i = f^{+}_i - f^{-}_i,$ $\quad \quad \forall i \neq j: e^{+}_i + e^{-}_i = e^{+}_j + e^{-}_j, \text{ and } f^{+}_i + f^{-}_i = f^{+}_j + f^{-}_j,$ $\quad \quad \mathbf{e}^{+}, \mathbf{e}^{-}, \mathbf{f}^{+}, \mathbf{f}^{-} \succeq 0$ By considering the Lagrangian, you can see that for each i, at least one of the $e^{\pm}_i$ will be zero, and likewise for the $f^{\pm}_i,$ so this is indeed equivalent to the original program. Concisely: at a presumed optimal point you can always increase over the value $L(\mathbf{X}^\star, \mathbf{e}^{+,\star}, \mathbf{e}^{-,\star}, \mathbf{f}^{+,\star}, \mathbf{f}^{-,\star}, \boldsymbol{\lambda}, \boldsymbol{\nu})$ by moving all the mass onto exactly one of $\mathbf{e}^{\pm}$ and $\mathbf{f}^{\pm}.$ By vectorizing $\mathbf{X}$, you can write the objective as a convex quadratic in a vector $\mathbf{x}$, and a little massaging of the constraints gives you a convex quadratic program in standard form. In terms of actually solving the final QP, I'm not sure what the state of art is, especially since performance usually depends on the properties of your problem (sparsity or structure in the Hessian of your quadratic, whether you have only equality or inequality constraints, etc.). You'd need a subject matter expert to get a definitive answer on that one. I'd personally try TFOCS if you have access to Matlab, since it's a first order solver and looks relatively easy to use (I have not used it myself). 

I will start discussing the relationship between first and third definition. The key point to understand the different definitions of arithmetic Chow groups is to understand the equation $\partial \bar \partial g-\delta_Z=\omega$. In this equation appears the second order differential operator $\partial \bar \partial$. There is a cohomology theory, real Deligne-Beilinson cohomology, that contains information about the relationship between the real structure and the Hodge filtration of the cohomology of a complex manifold, where the operator $\partial \bar \partial$ appears naturally as the differential at certain degree. See "Burgos Gil, J. I.; Arithmetic Chow rings and Deligne-Beilinson cohomology. J. Algebraic Geom. 6, 2, (1997)" for a construction of a complex that computes Deligne Beilinson cohomology. It is related to the complex used by Goncharov. Thus we may write the previous equation as $d_D g -\delta_Z=\omega$ where $d_D$ is a differential in a exotic complex that computes Deligne-Beilinson cohomology. The next step is to notice that the current $g$ can always be represented by a differential form on $X\setminus |Z|$ that has logarithmic singularities along $Z$. This is proved in the original paper by Gillet and Soulé. Differential forms on $X$ with logarithmic singularities along $|Z|$ allow us to compute the cohomology of $X\setminus |Z|$ with its Hodge structure. Hence real Deligne Beilinson cohomology of $X\setminus |Z|$. From now on we assume that $g$ is the current associated to a differential form $g'$ with logarithmic singularities along $Z$. If $p$ is the codimension of $Z$, the cycle $Z$ defines a class in $H^{2p}_D(X,\mathbb{R}(p))$ (real Deligne Beilinson cohomolgy). But more preciselly defines a class in cohomology with support $H^{2p}_{|Z|,D}(X,\mathbb{R}(p))$. The class of $Z$ with support in $|Z|$ can be represented in two different ways. With the current $\delta_Z$ or with a pair of differential forms $(\omega,g')$, where $\omega$ is smooth on the whole $X$ and $g'$ is smooth on $X\setminus |Z|$ and has logarithmic singularities along $|Z|$. The condition $d_D g -\delta_Z=\omega$ is equivalent to the condition "$(\omega,g')$ represent the class of $Z$ in real Deligne-Beilinson cohomology with support on $|Z|$" A proof of this equivalence is given in Burgos Gil, J. I.; Green forms and their product. Duke Math. J. 75, 3, 529-574 (1994) Hence we have replaced a differential equation by a cohomological condition. As pointed out by Myshkin this opens the door to an abstract definition of arithmetic Chow groups: Let H be a cohomology theory that has classes with support for cycles and classes of rational functions with some compatibility conditions. Let $\mathcal{C}$ be a particular choice of complexes that compute said cohomology. Then we can define arithmetic Chow groups with values in $\mathcal{C}$. The properties of the obtained arithmetic groups will depend on the properties of the complex. This abstract point of view is worked out in Burgos Gil, J. I.; Kramer, J.; Kühn, U.; Cohomological arithmetic Chow rings. J. Inst. Math. Jussieu 6, 1, 1-172 (2007). Examples: 1) Usual complex of differential forms: The obtained groups are isomorphic to the ones defined by Gillet and Soulé. 2) Differential forms with logarithmic singularities at infinity: We obtain groups with better Hodge teoretical properties. 3) Currents: The obtained arithmetic groups are fully covariant. 4) Forms with log log singularities at infinity: We obtain groups that, on one hand receive characteristic classes from certain vector bundles with singular metrics, namely the ones appearing when studying Shimura varieties. On the other hand they have well defined arithmetic degree. Thus the main motivation of the third definition is "flexibility" With respect to the second definition it is a completely different beast. The classical Chow groups has been extended by Bloch to higher Chow groups. This is the analogue at the level of cycles of the extension from $K_0$ to higher $K$-theory. The aim of Goncharov is to construct an explicit regulator from the complex of higher cycles to a complex that defines Deligne Beilinson cohomology, and then use this map to define higher arithmetic Chow groups as the cohomology of the cone of this map. He proves that the degree zero part of his construction agrees with classical arithmetic Chow groups by writing explicitely the cohomology of the cone. There are two caveats in Goncharov's definition: first it is only defined for varieties over a field, not over an arithmetic ring limiting its usefulness. This is because the theory of higher Chow groups over a ring is not well developed yet. Second there is an error in the construction. In fact the map $\mathcal{P}(n)$ in Theorem-Construction 2.3 is not a morphism of complexes. This error is solved in $URL$ 

The series $$\sum_{k=0}^\infty \frac{\exp(c k \beta)}{(k!)^\beta} $$ has come up when I'm trying to apply the methodology in this paper ($URL$ to Poisson regression. When $\beta = 1,$ it is $e^{e^c}$ and when $\beta = 2,$ it is $I_0(2e^c),$ the modified Bessel function of the first kind, but have no idea what happens at other values, or how to approach the question. Does this series have either a closed form expression in terms of special functions, or an asymptotic expansion that is numerically useful for $\beta \in [1, 5]$ and $|c| < R$? 

The original problem I'm looking at is: given a bound on the operator norm of $\Lambda A \Lambda,$ where $\Lambda, A$ are positive definite matrices and $\Lambda$ is diagonal, what is the tightest bound on the operator norm of $A \Lambda^2.$ My starting point is the fact that these two matrices have the same eigenvalues, so the operator norm of $\Lambda A \Lambda$ upper bounds the spectral radius of $A \Lambda^2.$ For normal matrices, the numerical radius is the same as the spectral radius and the operator norm. While $A \Lambda^2$ is not normal, one might hope that it is nice enough that there is still some nontrivial connection between its numerical and spectral radii ( a bound on the former is a bound on the operator norm, up to a constant). Is this the case, or am I barking up the wrong tree? 

What are the standard methods of computing the rank-k truncated SVD of large dense matrices? My literature search yields results only for large sparse matrices. I assume for k small that you use a Krylov subspace method (this is what Matlab's svds does). But (empirically) how large can k get before these methods become impractical, and then what should one resort to? 

This is somewhat sad, but I think (part of) what we've learned from the whole triangulated-vs-dg story is the following pseudo-statement: the bare category of functors Fun(D(X),D(Y)) is the wrong thing to take -- it should be replaced the category D(X x Y). There is a nice example, due to the usual Bondal-Orlov-Bridgeland people (Example 6.5 in Caldararu's notes), which illustrates this perfectly. Thus, if you find something weird happening in Fun(D(X),D(Y)) you shouldn't be discouraged -- it's not your fault. Of course, there are big names in the field (Canonaco and Stellari to name two) who might disagree with my initial pseudo-statement. It really depends on what you care about. 

X and Y are proper and irreducible. As a double cover does not crush X to a point, it must be surjective. The fibres are then finite sets which implies that it is a finite morphism. Finite morphisms are affine. Affine morphisms do not have higher direct image (this is just the relative version of the theorem which says that affine schemes do not have higher cohomology with coefficients in quasi-coherent sheaves). 

I cannot seem to find stated the following fact, which is surely well known to experts. Let (S,L) be a polarized K3 surface. Then $M = L^{\otimes 3}$ is very ample and we can consider the embedding in the corresponding projective space $S \to P^N$. Question: is the image of $S$ in $P^N$ a complete intersection? I suspect the answer is no but I haven't seen it stated explicitly. (by the way, I am certainly allowing $S = H_1 \cap ... \cap H_k \cap D_1 \cap D_2$, where the $H_i$ are hyperplanes and $D_1, D_2$ or more interesting divisors. (information about other embeddings of S which are complete intersections, or statements about when one can know if S is a complete interesction would be highly appreciated as well)