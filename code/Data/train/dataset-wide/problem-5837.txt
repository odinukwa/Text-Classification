Definitions Learning: the acquisition of knowledge or skills through experience, study, or by being taught. Primary Argument Artificial intelligence is a field which attempts to mimic animal or human intelligence in software. One thing which differentiates AI from other types of algorithms is that AI learns. Other forms of algorithms do not. Because of this difference, AI is useful when we might not necessarily know all the details of the problem we are trying to address. There are two types of AI, basic machine learning and general artificial intelligence. When the field of AI started, AGI was essentially the kind of AI. These days, the focus is on basic machine learning, using methods like artificial neural networks. There are philosophical questions about whether or not we can produce true AGI, and there is a basic test, the Turing Test, which attempts to see whether or not we succeed. Regardless, the key difference between a general algorithm and an AI is that an AI is designed to learn. Rebuttal Basic linear regression techniques are not AI because they do not learn. You do not set a linear regression technique off on its own and have it learn as it goes. It is a pre-modeled system. Neural networks can do linear regression and do so only the fly and therefore do learn. TimB argues that "neural networks et al don't 'learn'; they collect data. They are then capable of using that data in the next 'iteration' of their algorithm." However, that is exactly what learning is: taking data and using it in the next iteration of the decision making process. TimB and others also seem to only accept AGI, but this question is at least partially a Computer Science question so the definition is largely based on the field of AI in computer science. The field distinguishes between weak and strong AI, or AGI vs AI as I described it above (Computer World). An AI does not have to act like a human. It just needs to be able to accomplish some kind of learning task that a human could. Animal Intelligence Moving on from the Computer Science argument, consider the following. It is true that we generally measure intelligence using our understanding of human intelligence as the paradigm, but we admit that many other creatures are intelligent, just in different ways. It is important to look at this point if we want to see what constitutes intelligence. If we using the Turing test to determine whether something is "AI" then even our close relatives would fail the Turing test. Does that mean that primates, other than humans, are not intelligent? 

For some reason I just had this question pop into my mind. It seems reasonable to treat Russel's teapot as an allegory. One definition that might indicate this is "the expression by means of symbolic fictional figures and actions of truths or generalizations about human existence a writer known for his use of allegory; also : an instance (as in a story or painting) of such expression The poem is an allegory of love and jealousy (Merriam-Webster)." 

First, and I know this is somewhat subjective, I dislike the distinction between "soft" and "hard" science. When it boils down to it, all science is "soft" because at best we can falsify our theories. The issue with many social sciences is that it is hard to construct formal experiments or repeat an experiment, but we can still collect data to build more robust theories and to knock down old ones. Now, as for application of hard sciences like physics and chemistry to "soft sciences" like psychology and sociology, the answer is fairly simple. It is because there is a sort of hierarchy from more foundational sciences to more derived sciences. Physics drives chemical reactions. The reasons why certain molecules form, energy is released or absorbed during reactions, etc is all a matter of the physics of atoms. Biology is driven by chemical reactions. Thought is a manifestation, as best as we can tell, of the brain, a biological component of the body. With humans, behavior of individuals, couples together in social interactions in a meaningful way, and so our psychology and biology drive culture, group behavior, and so on. Basically, while we might be able to understand the "what," such as "what do humans do when they interact" without these more foundational sciences, we cannot really understand the how or the why unless we look at the mechanisms which underlie them. So rather than being silly that "soft science" uses "hard science," it is necessary. Example This connection does not mean that one can easily throw any theory from physics at more derived fields of study. However, there are cases where there is a direct enough connection. For instance, evolution is essentially a stochastic process, modulated by environment and energy dynamics. There are fairly direct theories connecting thermodynamics to biology. Specifically, Jeremy England has proposed that looking at entropy within an open system (usually entropy is thought of in terms of closed systems) within an energy bath, it seems that "life" is really natural consequence of thermodynamics (Quantum Magazine). 

The answer to your question is "it depends" Different axiomatic systems can lead to different conclusions. The truth of a statement S can only be said to be true or false, within a given model. This issue is not really a problem if you are talking about reaching a conclusion in two different axiomatic systems. We usually only work in one axiomatic system at a time and there is usually some kind of justification for using that system. And in this case, H1 and H2, in OP's question would not be independent, as canifold points out. However, it is also possible for a single axiomatic system to lead to contradicting results. Such a system is said to be "inconsistent." We generally do not work with such systems and it is usually assumed that reality itself is logically consistent, but we do not have to make that assumption. There is a whole field of study involving inconsistent logical systems. They do have their benefits. For instance, in a consistent logical system, there are theorems which can never be proven true or false, while in an inconsistent logical system, we can always determine whether a theorem is true or false. Additionally, canifold's argument does not hold in a logically inconsistent system. Reductio ad absurdum, or proof by contradiction, is a form of valid proof, specifically because we have assumed that our logical system results in only true or false statements and that a statement cannot be both true and false. The link I provided discusses this concept in more detail and also explains some reasons why we might not be certain that our reality is logically consistent and also how we can take a current axiomatic system and add to it in such a way as to make it useful but not consistent. 

Is there a method, which is used, to write a philosophical argument so that each point and logical consequence is clearer than if the argument were written out in paragraph form, such as an outline or flow chart? 

It is indeed a biological imperative to survive and also to procreate, as SonOfThought mentioned, so our biology gives us meaning, but it is a complicated question. Your question is a fundamental question of nihilism. Answers are going to be a bit subjective. But in that subjectivity we can find an objective response: you can find your own meaning in life. Our lives can provide us with a level of subjective satisfaction, and that allows us to find meaning, even if the universe itself provides none. 

You are essentially asking for the probability of at least one alien planet having life, given an infinite number of planets. This question is basic probability question. Suppose the probability of a planet (currently) having life is p, where p is strictly greater than 0. According to current theories on how life forms, this assumption is reasonable. There is a basic formula for calculating the probability of at least one success (here a success is life forming on an alien planet). That formula is 1 - p(none). In cases where each trial is independent, that formula boils down to 1 - p^n where p is the probability of success and n is the number of trials. Since p is strictly greater than 0 and less than 1, the limit as n tends towards infinity for 1 - p^n is 1. We could say that the probability of life not forming anywhere else is infinitesimal, but we do not work with such concepts in probability theory. Probabilities are real numbers. In either case, the result implies that so long as we are correct in our assumption that p is strictly greater than 0, it is almost guaranteed that alien life exists on some other planet. Real Probabilities I am going to add a full section on probabilities. It is annoying, but 0 and 1 do not mean impossible and necessary, when we're talking about dealing with scenarios about infinity. They mean almost never and almost always. We cannot know if 0 means actually impossible or 1 means absolutely necessary, using current probability theory. The only option is to extend probability theory using hyperreals, which has been done. Regardless, it does not change the understanding of the result in this case, by too much. Is it absolutely certain that there is alien life? No. It is however almost certainly the case, again, assuming p > 0. 

Of course it depends on what you mean by seeing the object. I would say that we do not see objects. We do perceive these things, but only very indirectly, and we really wouldn't know one way or another if the sensory information was produced by a real object or is a product of something else. What we see is not even light. It is the processing of sensory information. What We See Light bounces off of an object, enters the retina, information is uptaken by the the optic nerve and processed in the visual cortex. The information is cross referenced against "forms" on which the brain has been trained and once identified, that registers as an object in the conscious mind. When Things Go Wrong Errors can also occur along the way, and so what we see and what is may not be the same. We can experience various forms of hallucinations, our brain may find a form that shouldn't really fit (like finding Jesus in our toast), etc. Or in more extreme examples, the machinery that our brain uses to match sensory information to categories or individual object types can be damaged. A great example is "The Man Who Mistook His Wife for a Hat." Likewise, if we are not trained to identify these forms (object classes), we might not see them at all. For example, significantly different trees may "look the same" to the untrained eye. Likewise you may look at something and your mind might be so preoccupied, that it does not register, such as the bottle of milk in the fridge that's right in front of you, even though you cannot find it. So again, we do not see objects. Our brain fits sensory information to forms or schema, and that is what we "see." If everything works as it should, then we do perceive the objects, but only through a series of pathways: light hits object -> eye detects light -> optic nerve sends raw information to the visual cortex -> cortex identifies objects in the raw data -> cortex relays that to conscious thought process. Perceiving the Nouminal Whether or not we perceive the nouminal is a matter of what we're willing to accept as perception. If only direct perception is perception at all, then we do not perceive the nouminal. But I think it is reasonable to say that we have perceived the nouminal, if we react to it through a properly functioning phenomenal reality. For instance, if I throw a ball at someone, and that person, through their sensory input and processing becomes aware of a ball heading towards them at high speed and as a result they duck out of the way, I would argue that they did perceive the nouminal reality, even if it was through a their phenomenal reality.