TL;DR: in a proper finite-state language, you only need finite memory to determine whether an arbitrary pattern is valid or not. This language requires you to remember how many s have been encountered, and that number is unbounded. Long version: There is a very nice intuitive "proof" that this is not a finite-state language, which can be made rigorous through some additional work. In true mathematical fashion, this additional work is left as an exercise for the reader. Let us say is a finite state language. This means that we can construct a finite state machine which takes in a series of characters as input, and outputs if that series of characters matches your language, or if it does not. So if we feed the finite state machine it will say ; if we feed it it will say ; if we feed it it will say . To match this language, our finite state machine needs to remember how many s it has seen, in order to make sure the number of s is the same. And the only way a finite state machine can remember anything is through its state. So the machine needs a state for "I have seen one so far", another state for "I have seen two s so far", and so on. But you're allowing any natural number of s. This would require the machine to have no fewer states than there are natural numbers, in order for it to remember accurately how many s it's seen. Since there are an infinite quantity of natural numbers, we need an infinite quantity of states. But this contradicts the definition of a finite state machine. So we have a contradiction. There cannot be such a finite state machine, and thus your language is not a finite state language. 

If you're interested in inflected forms, you could take data from Wiktionary's Latin section. Most verb entries have automatically-generated conjugation tables, and all of the content is CC-BY-SA. If you're interested in meanings, you can download data files for well-regarded dictionaries through the Perseus Project. Lewis and Short is my go-to resource; click XML at the bottom of the page to download a machine-readable form. But L&S is written for human eyes, not automated systems, and assumes the reader can fill in all regular inflected forms from the principal parts. 

While complicated, this is in some ways the most logical system. Since "Alice" is marked the same in both sentences, and "the window" is marked the same in both sentences. 

These sorts of coincidences happen quite often in comparative linguistics, just by random chance. For a famous example, German haben (~English "have") and Latin habēre mean the same thing, but come from totally separate roots; haben is instead cognate with Latin capere "seize", via Grimm's Law. The main similarity between all these words is the initial /v/, which goes back to PIE. It might be a coincidence that *wegh and *wel started with the same phoneme, or it might not (if one affected the other), but all the later similarities can be traced back to this. 

Some authors use c for kappa, kh for chi, ks for xi, or u for hypsilon, but readers will recognize any of these variants without difficulty (and none of them cause ambiguity). Any variant or archaic Greek letters should be mentioned specifically. Using ś for san, w for digamma, and q for qoppa is common, for example, but I would be very confused finding any of those in a transcription without them being explained. 

This is indeed a cross-linguistic phenomenon! Stephen Pinker named it the "Euphemism Treadmill" in his book The Blank Slate; the more general linguistic term is "pejoration", when a certain word or phrase becomes less polite over time. And it happens in pretty much every situation where a euphemism is used. The classic (SFW) example in English is the name of the room where one defecates: the terms "water closet" (closet with plumbing), "toilet" (place for doing makeup), "bathroom" (room with a bath in it), and "restroom" (room where one rests) all originated as euphemisms and then experienced pejoration. And even such a now-obscene word as "shit" originated as a euphemism; the original meaning was something like "to separate", cognate with "schism" and "scissors". (The opposite of this is "amelioration", where a word's meaning becomes more positive over time. This happened to "fine" and "nice" in English, which were originally neutral words but developed a positive connotation.) 

Translating isn't a one-to-one process. For a simple example, consider the French words si and oui, both of which can correspond to English "yes" in different contexts. Once you've translated them into English "yes", you need to choose which one to use when going back into French. A human translator could use context to figure this out, but even cutting-edge machine translators generally aren't smart enough to do that. Even if you got a human translator to translate to another language, and another to translate it back, the odds are close to zero for any non-trivial input that you'd get the exact same text back. Simply because there are so many different ways to express an idea in any given language. If you asked me to translate "the book was written" into Latin, I would say liber scriptus est. But if I were asked to translate that sentence back into English, I'd make it active: "someone wrote the book". Simply because the active voice is much more common in English than the passive. In this case, it seems that Chinese (like various other languages, including Ancient Greek) doesn't distinguish between "something" and "some thing" (= "a thing"). So when translating back to English, the translator has to guess which one you originally meant. 

I wouldn't say that modals are I': rather, I'd say that they're I. In other words, a modal verb is syntactically an inflection, not a full verb. (It's easy to see that modals don't act like Vs: they can't be put in non-finite contexts, like *to should.) In X-bar theory, the I is an inflection applied to the V. 

Roughly, 500 BCE - 200 CE. There's no firm date at which Proto-Germanic stops being Proto-Indo-European, or becomes other Germanic languages. These are all artificial divisions imposed on a continuous process of evolution. However, when people talk about Proto-Germanic, they generally mean the last common ancestor of the modern Germanic languages, which has been dated to somewhere around 500 BCE. To quote Ringe, the best authority I know on the subject: 

Oh yes, very much so! The IPA is constantly changing and expanding, and existing symbols are moved, repurposed, and deleted. Many linguists still use the "Americanist" system, for instance, which prefers diacritics to new symbols (/š/ instead of /ʃ/) and single symbols (like /č/) for affricates. To give a few other examples: 

This is a common phonological process called "lenition", from the Latin for "weakening". There are various causes posited for this, but the simplest can be summarized as language speakers are lazy: we will generally use the least amount of articulatory "effort" to make ourselves understood. Producing a [ɾ] takes less "effort" (tongue and mouth movement) than producing a [t], so that's what we tend to do. 

In English writing, often خ becomes "kh" and the others are combined into "h". For example, محمد → Muhammad (with "h" meaning ح), الله → Allah (with "h" meaning ه). In lossless Arabic transcription, ح is usually written "ħ" (h with bar) or "ḥ" (h with under-dot) to separate it from ه. But this is rare except in textbooks and scholarly works; I've never seen a news article refer to *Muħammad or *Muḥammad. Lossless transcription also needs to distinguish "kh" خ from "kh" كه . One approach is to spell كه as "k'h" (ALA-LC does this); another is to write خ as "x" (per ISO 233-2) or "ḫ" (h with under-breve). I personally prefer the second of these options. A handwritten apostrophe is too close to the symbols for ayn and hamza (ʿ and ʾ), while ḫ and ḥ tend to look very similar in print; writing the three as "h", "x", and "ħ" makes them much easier to tell apart. (In lossy transcription, of course, the distinction between the "kh"s can be ignored entirely.) 

Dividing up the audio As you mentioned, formant analysis can place vowels nicely on a chart. But first you have to cut the vowels from the surrounding sounds. Often their formants are changed by nearby consonants; the nice F1/F2 plots use vowels in isolation, or the middle part of the vowel without the messy edges. And when vowels are reduced, or too thoroughly colored by nearby phonemes (consider English "r-coloring"), this second option isn't always possible. Then consider the case of diphthongs: when does one vowel end and the other begin? If you take the Fourier transform of [ai], it'll average out the formants and give you results similar to [e]. Consonants are harder While vowels are easy to identify, consonants are harder. What differentiates a [p] from a [k], acoustically, isn't anything in the sound itself: that's just silence, and then raw noise. It's the distortion of the formants of the surrounding vowels; the same distortion that needs to be removed in order to identify the vowels. So you need to first know the baseline that the distortion happens relative to before you can figure out which plosive it is. Sibilants also tend to look like pure extended noise, and differentiating them based on their frequencies is more difficult. Everything is a gradient Despite its name, the IPA was designed for phonemic transcription, not phonetic: there's a symbol for the Swedish "sj-sound" /ɧ/, even though there is no such sound as *[ɧ]. And taps and flaps are unified, despite being acoustically different, because no known language distinguishes them. In acoustic reality, the cut-offs between different sounds—between a palatal [c] and a velar [k]—are much less distinct. They're divided because they're phonemic in some languages, rather than because there's a notable feature which separates one from the other. Given a sound in between pure [c] and [k], or a vowel in between pure [a] and [æ], the IPA isn't good at indicating that. 

Anunāsika is the Sanskrit name for what linguists call vowel nasalization. A vowel marked with a chandrabindu is pronounced with the soft palate lowered, allowing air to escape through your nose. It's difficult to describe nasalization in text, but it's characteristic of French: in standard Parisian French, a vowel followed by a (silent) n or m will be pronounced nasalized, e.g. un vin. You can also test if you're pronouncing a nasal vowel correctly by closing your mouth while saying it. If it turns into an /m/ sound, that's a nasal vowel. 

The first-person singular pronouns are also cognates, along with Latin and Greek egō, German ich, English I, French je, and so on: from Proto-Indo-European eǵoH. (Note: standard "model verbs" were chosen here, so more tables for them are easily found online.) 

It seems to be widely accepted that Proto-Niger-Congo had ten vowels, with ATR harmony: /i-ɪ e-ɛ ə-a o-ɔ u-ʊ/. Similarly, it seems widely accepted that Proto-Bantu lost three of these vowels and maintained seven. But sources differ on what those seven were: /i e ɛ a ɔ o u/, or /i ɪ e a o ʊ u/. (The phonetic details are lost to time, of course, but I'm interested in which Proto-Niger-Congo vowels were continued.) Wikipedia lists the second set, with /ɪ/ and /ʊ/, and that makes some sense: in Kiswahili, the "second highest" set frequently turned into semivowels, and ʊ → w, ɪ → j makes more sense than o → w, e → j. On the other hand, that "second highest" set did merge into /i u/, so even if it were originally /e o/ it might have passed through /ɪ ʊ/ on its way. On the other hand, I've found reconstructions of Proto-Bantu words written with /ɛ/ and /ɔ/, and this seven-vowel system is still found in Lingála. Furthermore, Lingála preserves vowel harmony with /ɛ a ɔ/ in one class and /e o/ in another, which would make sense as a remnant of the Proto-Niger-Congo system. (We know the PNC system survived into PB, because traces of harmony can also be found in the Kiswahili verbal modifiers.) But this new harmony could also have been a later development only in Lingála. What is the scholarly consensus on this? Where should I look to find more information? 

As far as the personal pronouns in Indo-European languages go, we don't really know where they come from. They already existed in Proto-Indo-European, which is the oldest stage we can reconstruct with any certainty. Some people try to reconstruct further back, but none of these theories are widely accepted, and all the proposals I've seen include personal pronouns in those earlier stages too. That aside, though, personal pronouns seem fairly common in the languages of the world. The Bantu languages of Africa have a person distinction that's very similar to the Indo-European one, for example, and I believe the Semitic languages do too. It's just plain useful to be able to talk about "me" versus "you" versus "them". One alternative, as found in e.g. Japanese and Vietnamese, involves having quite a lot of different words (or even an open class) that are usable as pronouns. But in practice, once a conversation is going, any individual speaker will tend to use a pronoun for "me" and another pronoun for "you". And it's easy to see how this system could get reduced to a straightforward first person, second person, third person distinction over time (potentially with different fossilized levels of formality, as in German). Another alternative is just using names everywhere. But this gets unwieldy, which is why pronouns were invented in the first place. As for where individual pronouns come from in any individual language: it depends! Sometimes they come from demonstratives: "that man" → "him", for instance (as in Latin is/ea/id). Sometimes they come from metonymy: the Japanese pronoun お宅 otaku comes from a respectful phrase for "your house". This is generally referred to as "semantic bleaching".