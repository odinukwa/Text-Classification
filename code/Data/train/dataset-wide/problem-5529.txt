Firstly, "waste of effort" may mean two different things to a human and to a God. Even more so, if a God really exists, who created the world and living creatures, and humans can appreciate the (natural) world for its beauty and not just for any material benefit, so also it is reasonable to expect a powerful creator to also be able to enjoy creating and his creation even if he knows how it will turn out. Secondly, the reasons for doing things usually are much more important than just to find out how things will turn out. We eat food not so that we can find out how they taste, but because we need food. On a higher level, we institute laws and live by them not to find out anything, but because we want to preserve peace and order (social stability). And we want to find out how the natural world works not for curiosity alone, but often also so that we can learn from it to be able to do things better, including feeding ourselves and those around us, and maintaining peace and order. Thirdly, by the previously mentioned considerations, it is not necessary that belief in a God entails believing in omnipotence or omniscience in the usual sense that people talk about. If for example we have limited omniscience and limited free will in the specific form mentioned above, it is reasonable for God to want to create the creation in order to allow people's choices to be played out, because then choices made would have real consequences that (usually) coincide with the intentions, because the laws governing the world are not chaotic but predictable. So far from predictability being useless, it is in fact extremely meaningful because it gives our choices meaning. Of course, in this view not everything is predictable, such as our choices and those of others. 

Choose an arbitrary collection of 100 pixels in a 100*100 square, and that collection forms a symbol. What meaning does it have? Well, you could tell people that you want to use it to denote something, in which case it has meaning to whoever accepts your decision. Likewise we can say that the answer to your question is "No." because given any symbol I can choose to interpret it to mean whatever I like, and it will have that meaning to me. Indeed, it is useless to ask whether a string of symbols has meaning (in itself), simply because any meaning can be given to it. What makes a particular interpretation useful is when it can be applied uniformly to a whole collection of strings (such as first-order semantics over a first-order structure applied to first-order sentences) and has non-trivial properties (like soundness and completeness). 

The current answer doesn't seem to mention that your proposed formal system is already flawed by definition. You say that "¬L" is a valid proposition, which you then label as "L". There is nothing wrong with arbitrarily stipulating such proposition formation rules for a formal system, but it simply doesn't correspond to anything meaningful. Why? Because a proposition is intended to represent a factual assertion, so the first part of your argument fails, because before you have labelled anything as "L", you need "L" to already refer to some factual assertion. But it doesn't, so it's meaningless to follow your argument. An analogy would be to say "Let n = n + 1. (where n is an integer)". It's meaningless, because you can't use "n" before you've defined it. In short, you cannot refer to something you have not defined. This is a principle that we hold to in any argument, not just in mathematics but also in philosophy. So the kind of formal system you propose doesn't make sense. However, there's an interesting variant which the other answer mentions, namely, is it possible to find some proposition P such that "P" is equivalent to "¬Prov(P)"? "Prov" here denotes the meta-theoretic function such that "Prov(P)" is an arithmetical formula in the formal system in question that is satisfied by N if and only if the formal system proves P. Indeed this is true for any formal system that extends first-order PA (Peano Arithmetic), and is called the fixed point theorem in logic. But "¬Prov(⊥)" cannot be proven by PA even though it is satisfied by N, which was the intended structure we wanted PA to axiomatize. In general Godel's incompleteness theorem shows that what we believe N is cannot be captured by any formal system with decidable proof validity. So one can say that analyzing the liar paradox properly gives rise to Godel's incompleteness theorem. Likewise analyzing Curry's paradox properly gives rise to Lob's theorem. Finally, note that natural language offers Quine's paradox that, unlike the liar paradox, is completely without any circularity (no reference to undefined terms)! 

In short: The so-called definition of natural numbers as those that can be obtained from 0 by adding 1 repeatedly is circular, but there is no viable alternative, which already makes it impossible to uniquely pin down natural numbers mathematically. Worse still, there does not seem to be ontological reason for believing in the existence of a perfect physical representation of any collection that satisfies PA under a suitable interpretation. 

One mathematical book that explains the motivations behind the logical notation is Introduction to Logic by Suppes. This is for classical logic of course, and is also logically rigorous. It explains that we build logic as a precise language by describing it using our imprecise human language, with the very purpose of using logic instead of our human language to perform our reasoning, so that there is no avenue for imprecision or illogical reasoning as long as we have accepted the language of logic and the method of translating natural language sentences into logic. 

This construction is essentially a quine. The difference is that if we assume that every well-defined sentence of the form "X is Y" has a truth value then this seems to be a robust counter-example. You can clearly see that the first half is a well-defined string, and that it preceded by the quotation of itself is another well-defined string, which the sentence asserts is a false sentence. The problem arises when one attempts to assign a truth value to this assertion. 

Further facts There are two curious facts related to this. Firstly, despite the fact that PA (Peano arithmetic) is based on the assumption of an infinite collection of natural numbers, which as explained above cannot have a perfect physical representation, PA still generates theorems that seem to be true at least at human scales. My favourite example is HTTPS, whose decryption process relies crucially on the correctness of Fermat's little theorem applied to natural numbers with length on the order of thousands of bits. So there is some truth in PA at human scales. This may even suggest one way to escape the incompleteness theorems, because they only apply to deterministic formal systems that roughly speaking have certain unbounded closure properties (see this paper about self-verifying theories for sharp results regarding the incompleteness phenomenon). Perhaps the physical 'fuzziness' due to quantum mechanics or the spacetime limitations may permit the real world to be governed by some kind of system that does is syntactically complete, but anyway such systems will not have arithmetic in full as we know it! Secondly, any meta-system MS that can reason about finite strings and sets of finite strings can prove the incompleteness theorems about itself, which immediately implies that if MS is consistent then MS' = MS + ¬ Con(MS) is consistent but Σ1-unsound (from the perspective of MS). But think about it: How do you know that MS is not already Σ1-unsound? The unsoundness could be buried deeper as well. MS'' = MS + ¬ ω-Con(MS) is ω-consistent but of course not arithmetically sound. The thing is that we don't have any way to decide whether or not our preferred meta-system (whether ZFC or something nice and predicative like ACA) is in fact arithmetically sound, until we actually find a proof of say "⬜..⬜(0=1)" for some number (possibly zero) of "⬜"s. We cannot just say that if nobody has found such a proof then it is good enough evidence that they do not exist, since Godel's speed-up theorem and elegant examples by Harvey Friedman show that it is possible for the shortest such proof to be so long as to be impossible for humans to discover by trial and error.