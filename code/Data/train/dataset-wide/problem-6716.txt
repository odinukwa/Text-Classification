A 1996 paper published in Language by Ladefoged and Everett treats this question, dealing with sounds which are unusual in terms of their phonetics. 

The link I have given is for an online implementation of the LinGO English Resource Grammar, which is a rather heavy-duty implementation of English grammar in HPSG. 

Made up words which are used in English will follow pluralization rules that hold for other English words. See the Wikipedia entry on Wug Test. The most reasonable plural of koopa is koopas, since most English nouns form their plurals by adding (orthographic) -s. If you want to take an affected air, you can call them koopae, by analogy with Latinate English words ending in -a which have a learned plural form with -ae (e.g., alumna, alumnae, which you might find in some brochures for women's colleges). You couldn't get koopa to have another type of irregular plural (and expect people to guess you are talking about more than one kooopa), unless the singular form has the right sound pattern that will let people pick up on your game. 

If the entries are sufficiently rich, it is certainly much possible. You will just have an algorithm for the regular cases, then annotations for different exception classes. The entry for Thomas would have a feature in it noting that the th is pronounced atypically, etc. Text-to-speech systems do something like this. 

Keeping in mind the caveat pointed out by @James C., I still think it is appropriate to ask whether there is a linguistic area that encompasses all of the Americas. Even though smaller linguistic areas involve a large set of shared features, there appear to be features that have the potential for being transmitted areally over very long distances. In his (1989) paper on the importance of large linguistic areas to typological studies, Dryer argues that there is likely a linguistic area as large as North America, and that there might be an area as large as the entire New World. While admitting that the evidence is "less convincing" (1989: 276), he gives possessive prefixes as an example of a feature that is common in the Americas and rare elsewhere 

Also tangentially relevant, and a good and quick read regardless of one's familiarity with phonetics is a 2005 interview with Gunnar Fant, who was very influential in the early development of digital speech transmission and speech synthesis. 

I am not familiar with the literature on machine learning, but some possible starting points: Work by Giorgio Magri, who works on computational models for the acquisition of OT grammars. Also work by Alexander Clark, e.g.: Clark, Alexander (2010). Efficient, correct, unsupervised learning of context-sensitive languages. Proceedings of the Fourteenth Conference on Computational Natural Language Learning, 28-37. Uppsala, Sweden: Association for Computational Linguistics. $URL$ Clark, Alexander, and Remi Eyraud (2007). Polynomial time identification in the limit of substitutable context-free languages. Journal of Machine Learning Research, 8, 1725–1745. Hopefully someone else can offer a more complete set of references. 

[Here is an answer whose substance was suggested to me by Diana Archangeli] The form of the OCP I was assuming was a somewhat classical one, more or less like Goldsmith's (1976:272) formulation: 

This leaves, finally, the vowel plot based on acoustic characteristics of vowels. Most vowel plots you will see published today are constructed by measuring the first and second formant values of vowels, and either using these values directly or using some kind of transformation of them (e.g., a derived perceptual scale or a normalized value) in making the plots. The main difference between the vowel plot and the kinds of plots you make in high school algebra is that the axis originates at the upper-right corner. Acoustic "backness" is a function of F2 (or F2-F1), and moving to the left corresponds to increasing F2. Acoustic "height" is a function of F1, and moving down corresponds to increasing F1. Software exists for tracking formants, but it is not completely reliable and its results need to be double-checked by a trained phonetician. Fortunately, it is much easier to learn approximate formant values for different vowels than it is to learn how to use the Cardinal Vowel method. David Abercrombie (1991). "Daniel Jones's teaching." Fifty Years in Phonetics: Selected Papers. Edinburgh University Press. pages 37–47. Victoria A Fromkin. Introduction. In Victoria A Fromkin, editor, Phonetic Linguistics: Essays in honor of Peter Ladefoged, pages 1–14. Academic Press, Orlando, 1985. Daniel Jones and Solomon Tshekisho Plaatje. A Sechuana Reader, in international Phonetic Orthography (with English Translations). The University of London Press, London, 1916 

Hale, Kenneth; Krauss, Michael; Watahomigie, Lucille J.; Yamamoto, Akira Y.; Craig, Colette; Jeanne, LaVerne M. et al. (1992). Endangered languages. Language, 68 (1), 1-42. Newmeyer and Emonds. 1971. "The Linguist in American Society." Papers from the Seventh Meeting of the Chicago Linguistic Society, 285-303. Chicago: Chicago Linguistic Society. 

(data is from Wetta 2011) In the sentence "Ich bin ein Berliner" there is only one verb, which is inflected, and so it must be in second position, after "Ich". In a true SOV language, either the finite verb must be clause final, or all of the verbs must appear at the end of the clause if there is more than one. Here is an example of a serial verb construction in Barai (Olson 1981, qtd, in Foley 2010), which is a strict verb-final language. 

But beyond the requirement that the finite verb be second, the word order is flexible. The following versions are also all acceptable. 

There was some kind of early state in prehistory at which no language had embedding, and where all languages had elaborate case systems. The advent of writing encouraged the development of embedding. Embedding developed at the expense of case-marking. All languages in the world are at some point in the continuum between having an elaborate case system and having recursive embedding. 

So derivations, subject to grammaticality constraints and global conditions, create pairs of representations. MP then models how sets of lexical items are converted to representations. If it were a model of comprehension, it would model how PF representations are converted to LF representations. If it were a model of production, it would be the other way around. Since it is neither, the answer must be "abstract enough to cover both." 

Ladefoged has also written in his (1967, p.86) "Three areas of experimental phonetics" something that I think is very useful to bear in mind as you start to track formants with a computer: 

I think that the main factors are going to be language external. Japanese people do not know English very well for reasons having to do with how English is used in Japan, and reasons having to do with the general language ecology in Japan. Scandinavians tend to have very good English, and there are language-internal reasons (their native language has a large number of vowels, there are many Germanic cognates, etc.) as well as external reasons (English has become established as a lingua Franca in Northern Europe, there is intensive English education and ample opportunities to practice, living in a multilingual society, they are comfortable communicating in a language that they don't master, etc.). So it could be debatable whether the language-internal or the language-external reasons are more important in determining the English skills of Scandinavians. But consider English in Nigeria. Roughly 400 languages are spoken in Nigeria, most of which are as different from English as Japanese is from English, but educated Nigerians tend to have a high success rate in learning English as a second language. In this case, there is nothing about their native languages that helps to explain their success in learning English. The status English has in government and business in that country, as well as the multilingual nature of the society, have to play a large role. My hunch then is that grammar is not the main barrier for Japanese people to learn English, because grammar is not a barrier for English learning in countries where the sociolinguistic situation is favorable for English learning; I think that all of the main barriers have to do with the sociolinguistic situation in Japan: that the society is basically monolingual, and that languages other than Japanese do not have an important status in any major public sphere. 

This type of construction seems to be found in quite a few Romance and Germanic languages, and also Basque. A quick check of the OED shows that the construction is found at least as early as the Old English period for English. One idea is that the construction has been maintained in Western Europe by areal pressures. 

These diacritics are listed in Unicode documentation as being particular to the Uralic Phonetic Alphabet. In the Uralic Phonetic Alphabet, the diacritics are documented on Wikipedia as indicating "retraction" and "advancement." It is not clear whether this should be tongue root or tongue body retraction/advancement, but I am guessing the former. 

In Role and Reference Grammar, gerund is used in the context of subordinating core juncture to refer to a subordinated core whose nucleus is a non-finite verb. This is of course a theory-dependent definition, and other theories will not grant any status to the term, but I imagine that if the RRG conception were applied to cases of gerunds in traditional grammar, most of them would also be analyzed as gerunds in the RRG sense, and some would get reanalyzed. Some general works on RRG: Van Valin 2005 "Exploring the syntax-Semantics Interface" Pavey 2010 "The structure of language" 

You'll find a decent overview of valency-changing processes, with some comments on the term middle in Dixon & Aikhenvald (2000: secs.3--5, esp. pp.11--12), and references therein. Those authors suggest that the term is used with a wide variety of senses, and recommend that it be avoided (almost) altogether because of its ambiguity. Rather than insert a long block quote, I'd encourage interested people to just click through to the PDF and read the passage on pp.11--12. Two works that Dixon and Aikhenvald cite that may be worth consulting are Kemmer (1993) and Keyser & Roeper (1984) 

In the Role and Reference grammar framework, clause chaining is usually analyzed as a type of cosubordination (a type of clause linkage where two non-finite clauses are both embedded in a matrix clause). Cosubordination exists alongside the more familiar clause-linking prototypes coordination and subordination. Complementization is a type of subordination construction where the verb of a finite matrix clause takes as one of its arguments a subordinate clause. Situating clause-chaining and complementization within the more general typology of clause-linkage, we see that these are instantiations of general clause-linkage strategies, all of which are well-attested cross-linguistically. For a language to have both clause-chaining and complementization then should not be unusual or surprising, then. Chechen (see Good 2003 for a thorough presentation) has both clause-chaining as well as subordination, so it will probably fit the bill. 

One point to add is that ability to produce a word in isolation does not translate into ability to produce that word faithfully in extemporaneous running speech. Fluency in speaking requires you to be able to pronounce words accurately without having to concentrate on pronunciation in itself. Your working memory will already be taxed by demands on forming ideas, selecting the appropriate grammatical constructions, lexical access, the emotional effect you are trying to impart, etc. Fluency requires correct pronunciation under pressure. A viable strategy for most L2 speakers is to settle on a bad pronunciation but an understandable message that is not delivered haltingly. The following reference may help to understand why trills are difficult to produce in certain contexts: Solé, M.J. 2002. Aerodynamic characteristics of trills and phonological patterning. Journal of Phonetics 30, 655-688. 

An auxiliary issue is the point that number is a property of morphologial subsystems, rather than of languages themselves. Most languages only distinguish number on nouns and noun-indexing inflectional morphemes, and do so in a consistent way. Some languages, especially Oceanic languages, have different number-marking systems for different morphological subsystems. In Wala, lexical nouns have only a two-way distinction between singular and non-singular (i.e. two or more), but possessive suffixes show a four-way distinction between singular, dual, paucal and plural. (data is from a sketch I am preparing) In Hiw it gets even more interesting. Subject pronouns can be singular, dual, or plural. Object suffixes can be only singular or non-singular, and non-human NP's show no number contrast at all. Hiw also has verbal number, and the contrast is between plural and non-plural (i.e. one or two). So the verb meaning 'kill' has two suppletive stems, not, meaning to kill one or two people, and qetnog, to kill three or more people. This is a rare case of a subsystem where there is no singular number. (Hiw data is from Francois 2009) 

See the approach of Sag et al (2001) on multi-word expressions, specifically the parts about light-verb constructions, which they model computationally with an HPSG-based grammar. See references in that paper for background, and also Copestake & Flickinger (2000). 

In most Grassfields Bantu languages of Cameroon, there is an associative morpheme which agrees with the possessed noun in a genitive construction. In the most minimal type of agreement, the associative marker is a floating low tone for noun classes 1 and 9, and a floating high tone otherwise. Noni, a Beboid language, has eighteen different genitive markers, depending on the noun class of the possessed noun (Hyman 1981: 19). A mixed case is Nkwen, of the Ngemba group of Grassfields, which has a segmental genitive marker for classes 2, 5, 6 and 19 (agreeing with the possessed), a floating low tone genitive marker for classes 1 and 9, and a floating high tone marker for other classes. (Ncheafor 2002) 

Not exactly the most orthodox source, but I find Johnson & Lappin's (1997) synopsis concise and easy to follow for non-practitioners. As they explain, 

To solve the problem you will want to consider one issue at a time. As a starting point, In your position I'd first see whether it is the vowel system of English that is a stumbling block. English could be considered special in that it has an unusually high number of vowel phonemes. Depending on the dialect, English vowels tend not to be pure vowels with a relatively steady formant trajectory, as are found in Spanish or Japanese. Instead, even the non-diphthongs tend to have a moving F1-F2 target. In some of the languages that I have studied that have large numbers of vowel phonemes, the target for producing the vowels tends to be more complex. I don't know, however, whether this is something that is of general significance. Languages such as Marshallese, which are reported to have very few vowel phonemes, can have complex rules for pronouncing them. So to see if the issue is the vowel inventories, you might try listening to songs in languages with large numbers of vowels, e.g., Cantonese, Norwegian, etc., and see if you have the same difficulty. 

Since the question is about determining the morphological profile of a language, the issue of determining word boundaries is quite central. However, I don't agree with @Dan Milway that native speaker intuitions are relevant here. Briefly, two arguments against native speaker intuition data on assessing wordhood: first, in practice morphologists do not support claims about wordhood on native speaker intuitions; instead, they offer language-internal evidence. Wordhood judgments have never served as a significant evidential base for morphological theory in the way grammaticality judgments have for syntactic theory. Second, (and not unrelated) native speaker judgments might somehow fail to reflect genuine linguistic intuitions (i.e. they may reflect spurious judgments) or may be inconsistent. In agglutinative languages, the grammatical word typically has a templatic structure: there is a fixed order of morphemes in the word, such that the word grammar can be described by a fininte state grammar. For example, the verbal word in Athabaskan languages can be schematized according to the following template (Hoijer 1971, qtd. in Good 2011) 

Corbett calls this (in Spanish) overlapping suppletion in his 2007 paper in Language. Stump is credited with the term heteroclisis (see Maiden (2009)). 

These two requirements will narrow down the set of candidate languages quite significantly. Looking at the languages that meet these criteria, the question is whether it is more common for non-finite verb forms of this type to have neither subject nor tense marking, or to have one or the other, and whether it is more common for non-finite verbs to be marked only for subject agreement or only for tense when they are marked for at least one category. So what is more common? Tensed forms without subject marking, as in present, future, past participles; OR Tenseless forms with subject marking, as in the Portuguese "personal infinitives." Some interesting possibly relevant data comes from Cristofaro (2007: 112), where a survey is made of marking on verbs in dependent clauses. What is found is that when subject or object agreement is not expressed on the verb, tense/aspect/mood tends not to be marked either. 

A word which is normally a noun is behaving as a verb. We can find more dramatic examples of this kind of behavior outside of English. Consider this pair of Tagalog sentences: