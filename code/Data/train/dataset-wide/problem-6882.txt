To answer the specific question, I believe the largest hf in the world is Bridgewater (assets under management of around 120bn USD). Assets of around 500m USD would be considered average and north of 1bn usd large. Bridgewater is an outlier. I do not know if one larger has ever existed but I doubt it. As to what effects they have on the economy well, funds can serve as catalysts for economic events (e.g. Soros' fund and others catalysing the UK exit from the ERM). They serve as vehicles for pooling and allocating capital and so act as intermediaries between those who wish to lend (investors in the hedge fund) and those who wish to borrow (firms issuing bonds etc. which the hf buys). This function only applies when the hedge fund is making a primary investment though - when it is buying something in the secondary market rather than a first issuance funds do not have this role. They largely determine things like commodity prices, exchange rates through the bulk of money they control together, although no hedge fund is large enough to control these markets directly. 

This is not true. A subset of a game can be any subset of nodes that (1) starts with a single initial node, (2) includes all subsequent nodes and (3) makes sure that the information set of any node in the subgame are completely included in the subgame. Since the actual game does meet all three conditions it is a subgame of itself. This being clarified, the definition of the Subgame Perfect Equilibrium (SPE) does make sense. An SPE must be a Nash Equilibrium (NE) in any subgame, including the whole game. Note, that it then logically follows that every SPE is a NE (but not vice versa). (Also, for further reference: The set of subgames excluding the complete is called the set of proper subgames. Note, that the definition of the SPE only refers to subgames without specifying that they have to be proper ones.) 

Well, adjusted R2 has more merit than R2. R2 will always rise (or at least stay the same) as you add more variables (even if the variables are not statistically significant). Thus in theory you could achieve a very high R2 by just bunging a load of nonsense variables into your regression. Adjusted R2 compensates for this by adjusting the R2 by a penalization factor that increases as the number of variables rise - hence adding a new variable will always raise r2 but will raise adjusted r2 only based on its explanatory power. Information criteria such as the Bayesian information criterion (also called Schwarz criterion) or Akike information criterion can be used to choose between competing models. Intuitively, they measure explanatory power but penalize for "bigger" models which are more prone to overfitting and other problems. The BIC penalizes additional parameters more heavilly than the AIC, for example. You would prefer the model which minimizes the information criterion score. Note that, unlike R2, the values of information criteria are not inherently very meaningful - you cannot say "this is a good model because it has a BIC of -50", but you can use them to choose between. What matters more than either P values or measures of goodness of fit is that the model is theoretically sensible and that the Gauss-Markov assumptions hold. This is what makes a "good" model - ability to explain a high proportion of the variance is the icing on the cake, nothing more. If I regress rainfall in the UK on US GDP for instance, I will get a P-value of close to zero and an R2 of above 0.95 - yet obviously there is no genuine economic relationship here. So a sensible model with solid theoretical foundations which satisfies the OLS assumptions is a good model even if its explanatory power is limited. Conversely a model with high r2 / low p values which doesn't satisfy econometric assumptions or lacks theoretical credibility can never be a "good" model. 

Historically, the distinction between GDP and GNW goes back (at least) to Adam Smith. Before Smith, it was quite common to measure a country's economic power by its wealth. For example, this was very characteristic of the Mercantilistic school in the 17th century. Following the motto "you are what you have", mercantilists suggested that countries should try to accumulate as much wealth (for them: gold) as possible. This was to be achieved by a combination of an export oriented economy and political measures to limit imports such as tariffs. Selling goods abroad and keeping one's currency (again, gold) they hoped would result in having more money and thus being more wealthy. This idea is reasonable for the middleages where the difference between having and not having money can decide about which country is able to hire more mercenaries and has the potential to decide wars. For more modern societies a country's wealth (read assets) becomes less important. Adam Smith was the first to realize that the "Wealth of Nations" is not so much about how much money they have but rather about how much economic welfare they can generate. This is measured in the number of goods and services produced in a given year, nowadays known as GDP. From today's perspective, why do we use GDP rather than GNW: 

I'm not sure I fully understand what you mean by computing it endogenously? The nominal interest rate would be endogenous in the NK framework because the output gap and inflation are endogenous. There'd be feedback between nominal interest rates and inflation, which both feed into each other for example. So in that sense I'd consider the approximation of interest rate policy using a Taylor rule as entailing that interest rate policy WAS endogenous wrt. the output gap and inflation. As for why we'd use the Taylor rule as opposed to some more complex but accurate approximation for interest rate policy... well I can only suppose that the Taylor rule is a sufficiently good approximation such that the marginal benefit of adding more complexity / accuracy is minimal and perhaps less than the computational cost of doing so. There comes a point where you start to prioritize parsimony more and more. Perhaps this is the motivation. 

This definition nicely summarizes much of the framework rational choice theory is embedded in. It contains instrumental rationality, in so far as that humans have goals (denoted as preferences) but only limited resources (constraints) and they choose so as to maximize their utility. It also hints at methodological individualism because it places human behaviour at the center of its investigation. Note, however, that Robbins again only summarized a research paradigm that was already well developed. (He says so himself on the same page.) Still, I guess it is fair to say that rational choice theory as we know it today took off after WW2. Here different names come to mind, depending on which focus you want to have. Arrow/Debreu for general equilibrium theory, von Neumann/Morgenstern if you want to stress expected utility (and game theory). A bit later, Becker is a good choice if you want to stress that rational choice theory is an approach that is driven by its methodology (rational behavior, methodological individualism) and need not investigate an economic topic at all. But yeah, asking for a single father of rational choice theory would really stress things a bit too far. 

If you want to forecast it is common practice to split your sample up into two parts - the "estimation sample" and the "forecast sample". The estimation sample is used to, you guessed it, estimate your model, which you then use to forecast the data for which you already have true values contained in your forecast sample. You then compare your forecast predictions to known data and to those of other forecasts. You can do this using r2 or adjusted r2 over the forecast sample. We also commonly use measures like means squared error, mean absolute percentage error, Theil's U, etc. etc. 

The answer is there is no single father of rational choice theory. The reason is that rational choice theory is not so much a theory but rather a coherent framework (others would call it a paradigm) resting on the key foundations of methodological individualism and instrumental rationality / self interest. Both of these aspects played important roles in the marginal revolution in the late 19th century. Important names here are, of course, Walras, Jevons, Menger and Marshall although none of them can be regarded single father of Economics in the modern sense. Some decades later, Robbins (1932, p. 15) famously defined Economics as 

A common calibration for depreciation rates within RBC models is to assume 10% depreciation rate (based on NIPA stats, for instance). This implies a half-life of about 6.5 years. But this estimate seems a little low for advanced economies where capital is often in the form of computerized technology etc, which would seem to depreciate at a much faster rate (say 25% pa, implying a half-life of more like 2.5 yrs). Further, with technological advance you have the problem of obsolescence - the useful life of a capital good may end long before it depreciates away fully using the 10% pa rate. There is an element of unpredictability around obsolescence as well. How can this be accounted for within RBC and DSGE models? Would obsolescence pose a problem for calibrating a model assuming delta is approx. 10%? Thanks in advance, R. 

Neither in the normal nor in the extensive game form. Different types of a player can be only be used if they are mutually exclusive. So suppose the citizens (one player!) can either be poor or rich and this may affect their pay-offs and thus actions. There is no possibility for the citizens to be poor and rich at the same time (while represented by the same player). Your only option is to follow Sub-Optimal's solution and model different types of citizens as different players. As Bayesian pointed out, you can then model simultaneous decisions by citizen 1, 2 and so forth by setting their information sets accordingly. 

I don't think cash could be described as a security... one of the characteristics of securities is that they have imperfect (if very high) liquidity and provide a return (be it fixed or variable). Cash is the definition of liquid and inherently provides no return - you could earn interest on cash by depositing it in a bank but then you are creating a debt obligation in effect - the cash inherently, as in cash in a physical safe, generates zero return nominal by definition. You could think of cash as a debt security where a debt is theoretically placed on the issuer. But: in practice the debt is impossible to pay. You cannot bring a bill into the fed and demand they honour it. So I suppose it would be a debt security in the theoretical sense but it lacks almost all properties of debt securities: cannot be repaid in practice, never intended to be repaid, perfectly liquid etc, and it has a value that cannot be expressed in terms of anything but itself.