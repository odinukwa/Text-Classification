To add to what dunxd said, you also do the A record because that's what directs requests for that (sub)domain to be handled by the service providers servers without the service provider having to take full control of the customers DNS. Once the request come into the service provider, there are several different ways that they can determine which customers data to display. The first is Virtual Hosts which allow you to set different configurations for each domain you're servicing. The second is Rewrite Rules which let you determine which data to return based on the requested URL. The third is to use Server Variables and then use what ever language you're coding the application in to processes requests based on the the http_host value. These aren't mutually exclusive you can use some combination of them to do what you want. I'm not sure what you mean by: 

FreeBSD*... Just saying... Seriously any of the ones listed as having packages are probably good candidates. *I know it's not Linux 

It wouldn't really be a different virtual host. But using something like mod_rewrite or mod_alias you can serve content out of any folder for which you have set the appropriate permissions. There's only one docroot, but you can effectively change that on the fly. One way to do it might be: 

It's easy to add extra headers to the request with curl. If the other side can modify their script they could just append the information you need. Since you're building an API just make the extra header part of the specification. 

What do you mean by local? If you have access to the file system of the server hosting the wordpress install through some other method(console, smb, ssh, RDP, etc) then you may not need FTP. FTP is just one common method gaining access to put files on the server. In my opinion SFTP is better than FTP or FTPS because it uses the SSH protocol, but it serves the same purpose. EDIT: Ok, if I follow what is going on, wordpress.org is going to use the FTP to do the update. So it's not you locally accessing the site, it's a remote 3rd party. This might answer some of your questions: $URL$ 

This might be of interest: $URL$ Also, .htaccess files would allow you to make changes without reloading the entire config. 

You'll probably need to tweak these because I don't understand all of what you're trying to accomplish. For example the RewriteCond below seemed redundent so I left it out. If you really are trying to rewrite everything under the guide directory you'll have to incorporate it back in. 

It's called a Reverse Proxy. You can do it with Apache as well as other web servers. There are also dedicated proxy servers that you could use as well. 

This will block everyone except 192.168.1.1 unless they enter a password. If you only want to make the one IP enter the password and allow everyone else with no restrictions then it would be: 

If all the first host is doing is email sending, then setting and to the second host is no problem. If the first host is also receiving email then this is what you use MX records for. The record will take care of routing the email while you point the main record to the web server. If the first host also has webservices or something for checking your email then I'd probably use a sub-domain for that such as . If you have different webservices on each server and want both under the namespace then you probably want to setup a reverse proxy on one of the hosts. Also it's no problem to create an record with both IP addresses. However this is probably not what you want for this situation. You would do that to do simple load balancing. 

A better way to accomplish what you want might be to, if possible, match the records in both name servers then switch the name servers first. That way no matter what name server the client gets it will give the same answer. Then when you're sure the new name servers are working you can lower the TTL there and switch the individual records. Also, since the fqdn of the name servers will likely be different, I think the time it takes for clients to make the switch will be affected more by the time it takes the registrar (GoDaddy) to make the change with the root name servers than the TTL of the NS records themselves. 

Note: the solution by David Zaslavsky above does more or less the same thing, but this way you don't have to do a separate VirtualHost section for each subdomain. 

It looks like your rule is getting you to a PHP file. I'm not sure what you mean by "downloading a php file" if you mean its downloading the code as plain text then you've likely got a problem with you php handler and not the routing. Otherwise it probably means that the PHP code is using the original URL to do routing and not your rewritten URL. What it sounds like you really want to do is have your final rule be a redirect. So your rules should be something like this. 

Another option is if you're willing to run your own DNS server, you can use includes to easily have the same config for all domains. I do this and then have my DNS Provider replicate the settings from there. Doing this adds a bit of overhead on the maintenance side though. 

You need to set the DNS for www.domain.com to point to your second IP address. Be aware that doing so will cause $URL$ to also answer on that IP address. I don't fully follow the description of your problem. Unless you're hosting more than one SSL domain you probably don't really need the second IP address. 

It looks like you've already changed your DNS, which is fine. But I wanted to mention that if you want to test your virtual host configuration before messing with the DNS settings (useful if you want to keep an old site live while you get everything ready on the new host) you can temporarily make the change in your hosts file on your local computer and the change will take effect immediately. 

See the Apache Documentation for descriptions of the flags and for the full list of server variables. 

EDIT: It should work without the RewriteCond as the first two conditions should cover it unless you're doing more rewrites in that directory or something. Are you using custom error pages? Something is changing the Request_URI so that it no longer matches any of the conditions. If you're not on a shared host or if your host supports it try setting up a rewrite log this will tell you exactly what is going on. 

Another way to do it would be to have a public folder inside each module. Then use alias' and/or rewrite rules to direct requests to the appropriate location. Using the directive you can set explicit permissions for folders outside of the document root. Doing it this way though would likely require you to reconfigure Apache every time you added a module. Something like this might work: 

With this configuration if the requested URI isn't an actual location it'll get routed to and from there to the backend. The part is there to prevent unauthorized code execution, so if the requested URI is which doesn't exist then a simple nginx is generated. What would be a better way to configure this (& remain 'secure') so that a request for a nonexistant php file also get passed to the backend via ? 

You'll probably also want to do a search on drupal and pretty or clean urls which will give you more info on this and will also let you drop the index.php. 

I use something like this for my zend framework projects. It tells index.php to handle every request for files that don't already exist. You can get creative with the regular expressions or add other RewriteConds to be more selective about when it sends the request to the index.php. 

What you probably want to do is a reverse proxy. Assuming the other websites on the linux server are running under Apache. Then using mod_proxy your config would be something like this: 

As mentioned in the comments, without another IP address you can't do this at the DNS/router/firewall level. You can do this at the http server level. You set this up using a reverse proxy. To do this using Apache you use mod_proxy. 

There are many other ways to configure a reverse proxy both with Apache and with other web or proxy server software. The only thing you need to configure on the Windows server is to make sure any URLs output by it use the external address. 

No it's not possible to do that with DNS. You must pick the one you want to be primary and that's where the mail will go. In DNS, you can have one server act as a backup for the other, but it would only actually deliver to one or the other. You could however have the primary mailserver forward the message to the secondary server. One other option is you may be able to have gmail act as a pop/imap client and connect to the outlook server to retrieve the messages. 

You really need to talk to the Network and/or Host Server administrator about this. If for example you're in a corporate environment they might not be too happy with you if you did something like this. That said, you could probably use an SSH Tunnel, though I don't know how practical that would end up being. 

Considering that DNS is how all those subdomains get pointed to the correct IP address then yes switching your DNS provider for the main domain will affect them. However as long as you put all the appropriate settings for them on the new DNS servers then they shouldn't really notice the change. 

It'll likely be easier to use an external SMTP server such as the one provided by your ISP. See the Zend Framework Manual for instructions on using the smtp transport. 

For a reverse proxy, fixing the links in your content output (as mentioned in the other answer) is the better way to go, however mod_proxy_html is another possibility. That said, if you're serving both applications out of the same Apache server why bother with the two virtual hosts? You should be able to serve two different languages from the same virtual host, that way you can skip the reverse proxy step completely. 

What you want to look into is mod_rewrite for Apache (often part of the default install). You will then rewrite your URLs. For example: 

If the only service you're worried about is http. You could use a single wildcard DNS entry pointing to the main webserver and then from there use redirects to point the user to the corrected domain. 

Finally when you "install" your module you could just copy the public files into the document root. You can still keep the separated. Something like this: 

If I'm following your setup correctly you have your SPF record set on the root, but you are sending email from the sub-domain if the 'envelope from' of the email is root@mail.myapp.com then you need to change the "@" txt record to "mail". if you were sending mail from root@myapp.com then your setup would be correct. So something like this 

Unison might work, I believe it meets all your criteria. It can work peer-to-peer, but if this is for more than 2 users it'll be easier to have a central location to sync to. 

Personal I've been happy with FreeBSD. For some reason it's always made a little more sense to me than other *nix OS (It has great documentation). The ports system is great for applying updates, and I've had little problem with updates breaking things. Pkg_updating especially helps. With any distro, if you're using packages that come with the os or even through 3rd party repo's, you're going to have to wait a least a little bit for them to build the latest version of the software you want, and sometimes that's a good thing because there may be stability or dependency issues you might not know about. Of course, you can always build directly from source, then you never have to wait. PS: Upgrading the base os is also quite easy and stable using freebsd-update even between major versions. 

Use Perl to evaluate the query_string and then use an statement to skip the rest if the parameter is not set. Perhaps something like this*: 

EDIT After doing some quick testing on my server I was able get these rules work but not in a per-directory context (ie. not in a .htaccess or inside a ). I didn't test this but you might be able to work around this by setting an evironrnment variable with the second rule and then testing for it on the first. 

I'm not sure why you're using the RewriteConds. It seems to me that you could put everything directly in the RewriteRules. It looks like your problem stems from the fact that you're redirecting everything that matches the Request_URI. If you do the matching in the RewriteRule itself the rewritten rule will no longer match the next rule. You might want to try something like: 

Does the URL acctually change in address bar when you visit the domain? If so, you're probably doing an http 301 redirect somewhere. You can still do that, but you would need to have the server rewrite the URL first so that you can still pass the account information. EDIT: I don't use nginx but I added some links that might be helpful. 

I'm assuming here that by "\u002f" you mean "/" and you mean the brackets "[]" to be part of the substitution and not in the actual URL. EDIT Ok, since you mean you want to rewrite the HTML output with mod_proxy_html. Then I think it would be something like this. 

It sounds like you want to setup a reverse proxy on the VM (or wherever). Then you will point all your domains to the reverse proxy which will then send the requests to their final destination. I linked to the Apache way of doing this, but nginx is also popular as a reverse proxy. Another option is any of the dedicated proxy software that will do this.