MEMORY_TARGET needs /dev/shm filesystem with required size. By default /dev/shm size is half of the system memory. So you have to change line in from: 

By "default" you can only select data from tables and views in your schema. To create different objects you need appropriate privileges granted. 

Also with such amount of memory you really really should use Huge Pages. Of course that means no more AMM and back to ASMM. But especially if you have many connections to Oracle the difference can be really big. You can read about configuring Huge Pages e.g. here: $URL$ 

Prepare transportable tablespaces metadata set. Copy expdp file to location accessible by impdp from destination database. datafiles to new location. Import TT metadata set. 

When renaming datafile you have to move it to the new place first. command does not move file. It just changes file record in control file. But destination file has to exist. Renaming and Relocating Datafiles 

impdp/expdp unlike imp/exp does not move the data. They only invoke DBMS_DATAPUMP package and actual data movement is done by the Oracle instance. So data pump can access external data the same way as all other Oracle procedures - loading files via directory object or SELECT data via dblink. 

CREATE LOGFILE GROUP and CREATE TABLESPACE accept only bytes as unit. $URL$ With MB converted to bytes logfile group was created successfully for me. 

In such way you can add several extents adjusting their sizes. After you'll check that corrupt blocks now longer belong to free space you can fill the table: 

Fuse-zip is available from RPMforge so one does not have to compile himself. Of course I would not use this for production database but just for restore - why not? 

As far as I know - it is impossible. Oracle is very strict about ACID. In general to reduce size of redo logs you can use: 

"Too many active scans" error means that at a given moment there are too many queries running which are scanning the tables while trying to get answers. Scanning means for example range scan queries (WHERE val > 20). And if I remember right scan also means fetch queries if index is not has. 

If that looks too simple - keep in mind that you will have to drop and later recreate foreign keys if you have any. :) 

You already got two answers about one database - multiple schemas approach. I will try to add some arguments when several databases may be better. If your applications are very different it may be better to have separate databases for them. Then you will be able: 

When you no longer need the data you can drop the tablespace and delete datafiles. This is basically the only way to release space back from Oracle to the operating system. When doing backups you can exclude tablespace from backup. E.g. if it contains non essential or easily recreatable data. When doing restore you can skip tablespace. E.g. if you need only specific table or you need to start as soon as possible you can skip index tablespaces and rebuild indexes online. Tablespace per user can be useful. Then when user is no longer needed you drop the user then drop tablespace and have disk space back. Also if user suddenly starts to generate lots of data only his tasks will break when tablespace becomes full. Other users will be unaffected. Data blocks corruption usually is contained within tablespace. In such cases only one tablespace is affected. You can store tablespaces (datafiles) on different types of disks. So you can manually manage which data goes on SSD and which on SATA. In really rare cases you may need different block size for the tablespace. 

Usual rules apply. Code changes should not be required but something will break if code is more complex. Also there will be some SQL plans regressions. Official documentation about deprecated features is there: Deprecated and Desupported Features for Oracle Database 12c Also you can check Metalink note 567171.1 about parameter. This parameter is used to enable or disable certain bugfixes which affect query behaviour. In 11.2.0.4 the view contains 854 rows which means that there are so many potential quirks while upgrading to the newer version of Oracle Database. I am sure that 12c contains much more rows. 

2nd step is to drop all the active connections and unfinished transactions so that node is free from user queries. And all the applications continued to work on the other SQL node. 

This means that you have to include Oracle instant client libraries into the database used by Linux dynamic linker when it has to resolve run time bindings. Instructions tells you to create new .conf file in /etc/ld.so.conf.d/ directory with the Oracle instant client libraries directory. And then you have to run with root permissions so that it will create new database with the Oracle instant client libraries included. Example from one of our servers: 

If your ASM diskgroup uses some storage device with several disks then you should be able to improve performance by copying several datafiles in parallel. 

With ALTER tables on NDB we noticed the funny thing. You can work with the data if you run the queries on the different SQL node from the one which is running actual ALTER TABLE command. Maybe not all the possible variants of ALTER TABLE but enough for our purposes. So we were doing the following on one SQL node: 

NOLOGGING. But as you noted not loged are only specific operations. So you have to plan and program around it. TEMPORARY TABLE. But in this case each session can only see and modify its own data. COMMIT WRITE BATCH NOWAIT. This feature was introduced in 10g and it affects redo size indirectly. Redo size is reduced because redo log buffer is not flushed immediately and less space is wasted in redo blocks. 

ORACLE_SID can be parsed from /etc/oratab file. ORACLE_HOSTNAME maybe from HOSTNAME environment variable. 

We were using the second method on 9i to compress export online. And I do not recall problems with this approach. We ran two sessions from the shell script: 

First step has to be run on all nodes of the cluster. Second step though - just on one node which will rebuild all the indexes. For foreign keys you can try to split first step into two: 

But with such amount of memory I would go with ASMM (SGA_TARGET) and huge pages. Especially if you will have many clients connected. Overhead to manage 48GB of 4kB pages will be quite big. 

It seems that for solving your problem you chose the wrong tool. MySQL Cluster is good when you do mostly key based lookups from multiple threads from memory based tables. Disk based tables may be useful when you have rarely read data. Or your work dataset is small portion of the table which should fit into memory cache whose size is defined by DiskPageBufferMemory config variable. If your queries need many range or full scans - MySQL Cluster is slow even on physical machines. That is because such queries need a lot of data exchanges between data nodes. Try pinging between your data nodes. And for range scan data nodes may need to exchange hundreds and thousands of such messages. Also MySQL previously stated that for data nodes your should use physical machines and have good interconnect for data node traffic. I doubt that this recommendation is no more valid nowadays. And I think you should try cleaning up your config. For testing most of those things hardly changes anything and some setting may be slowing down things. Try such simplified section: 

It calculates dates of next Sunday and 1st of next month and then returns the one which will be sooner. Just 'Sunday' in next_day is NLS dependent. That should give your required interval in call to DBMS_REFRESH.MAKE procedure: 

If large_data_table is really big (tens GB and more) then 1% or something like that may be needed. And do not believe that in dba_tables sample_size=num_rows. For big tables actual auto sample size is much much lower. I had the SR with Oracle about that. They found actual sample percentage only from session trace file. It was ~0.004% for 170GB table. 

Browse My Oracle Support for the possible causes. For example quick search revealed a bug about your Oracle internal SQL. Workaround for it is: 

Similar concept in Oracle is called Index-Organized Tables (IOT). Difference with PostgreSQL CLUSTER is that in PostgreSQL CLUSTER command reorganizes table once and later table still grows as it wants to. In Oracle IOT keeps its structure as ordered by index. Unlike Phil I'm seeing IOTs now and then. The most often they are used when you need to retrieve many (think hundreds) rows by index. 

Of course I forgot something. :) People will add more advantages in comments. While listing advantages I am not considering scenario when you have to preserve data between restarts. Database Concepts about Temporary Tables 

If you have split exactly in half brain situation MySQL Cluster resolves it designating one node as master. If you look into ndb_mgm output below you will notice asterisk at the end of node 10 line. It marks master. It means that if your cluster will be split in two equal parts the half which contains master will continue running. Nodes from the other half will be shut down. 

With any more complex data it is almost impossible to restore data in MySQL Cluster in one step. Usually one needs two steps: 

Certifications are just cherry on the top. But you have to bake the cake first. They mean nothing if you do not have any real life experience. But when you have - they give you a bit of an advantage in your job interview. Also do not concentrate just on Oracle. Most DBAs are qualified in several databases. Start with MySQL, PostgreSQL. They are simplier to start but still the core principles are the same. Also it should be much easier to find some real life practice with those databases. Then continue climbing the ladder. Good luck! 

First 2500*50kB ~= 128MB. Then if you will check CREATE TABLESPACE syntax default INITIAL_SIZE for the datafile is 128MB! So if you want to store more data you can either specify INITIAL_SIZE you need while creating tablespace or you can ALTER TABLESPACE ADD DATAFILE. By specifying in CREATE TABLE statement you stated that you want on disk table not in memory. With such tables shows nothing meaningful for that table. If you want "classic" NDB table which is stored in memory just skip modifiers and then will show you how much memory is used for the data and indexes. 

Also one small note for the multiple schemas approach - put different applications data into separate tablespaces. This will add just a few minutes while creating users but may save a lot of maintenance time later. Trust me. :) 

Also I assume this is development machine because in production MySQL Cluster with has little sense. 

Pushdown basically means that some part of the job is "pushed down" to data nodes. So performance gain is because: 

You will need some more space for row overhead and PK storage. More information you can find in MySQL Documentation. For the most detailed information you can use ndb_size.pl utility. 

You can. From backup (rman) perspective there is no difference between LOGGING and NOLOGGING tables. What you cannot do is restore through NOLOGGING operation. That means that if recover procedure will encounter such operation in archive log it is currently applying table will be marked as INVALID. 

It will find all the objects which consume some space in given tablespace and sorts the output by used space. TEMP objects are always related to user session. So you need to query another view: 

~50 million ~1kB records is ~50GB of data even not counting headers and possible indexes. And you have 3 machines with 8GB of RAM each. That means that Data node could use somewhere up to ~6GB of RAM. All the data records in MySQL Cluster has to be stored on two nodes. So in your Cluster you can store (3*6GB)/2=9GB of data. Actual amount is even less because of data records headers, possible indexes, other metadata. So to store 50GB of data in Cluster you have to use MySQL Cluster Disk Data Tables. And by the way with the default Cluster setting of you cannot have 3 Data nodes. Documentation says that . You have either to use 2 Data nodes and dedicate third server for SQL node or change to 1 and loose high availability.