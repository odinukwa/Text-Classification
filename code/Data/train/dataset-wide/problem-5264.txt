Although the practices in current ideas of mindfulness, such as breathing exercises and the particularly Eastern metaphysical ideas about the self (like in, for example, Reiki) wouldn't specifically have been invoked by anyone in ancient Greece, there are strong parallels with the theorising of the Stoics (SEP Article), and in their conception of Philosophy itself. Consider, for instance, the following cool quote from Cicero: 

(You'll also sometimes see that symbol used in the form "PREMISES |= conclusion"; this is shorthand for the Semantic Entailment relation: "all models that make PREMISES true also make conclusion true") What makes Logic interesting is that deductive systems and semantics can be given rigorous treatments that tell us about what we can do with formulae. For instance, in Classical Propositional Logic, True and False are understood as forming a two-valued Boolean Algebra - a mathematical structure described in set theory and category theory. This means we can talk about particular kinds of mathematical function that we know are described in that algebra - if you have a true sentence A and a false sentence B, then according to the algebra, we can evaluate A ^ B as a false sentence (interpreting ^ as a function that takes T and F to F), and A v B as a true sentence (interpreting v to take T and F to T). So in Classical Propositional Logic, rather than having to go through and manually specify values for every single formula, you can instead require that the interpretations assign values to all of the basic formulae (the Atomic propositions) and build up values for more complex sentences inductively. This structure means you can have a theory of deductive inference that "gets things right" on the level of interpreting sentences in line with their mathematical relationships. It is analogously possible to build logics over complicated logical calculi using more detailed mathematical models, such that we get very useful and productive deductive systems. In particular, the work in the late 19th-early 20th century by logicians such as Frege, Russell/Whitehead and Tarski gave rise to Predicate Calculus, which allows us to talk about Names, Functions, Properties and Relations of objects, and about variables that range over these things, in more detailed and general ways than just thinking of assigning truth values to sentences. What is generally now called Classical logic is the framework that is thought to encapsulate both the Predicate calculus formalism and the compositional aspect that a structured, two-valued algebra of logic gave us in the propositional case. Predicate logic works with the idea that our domain of objects is something that we refer to in the logical structure of making assertions - when I say that "That chair is green", the logical form of what I'm saying actually identifies something in the domain to be "that chair", and to attribute to it the property of "being green". The logical structure of language is such that what I say is true when it turns out that "being green" is, according to the interpretation we make, something that the object that is "that chair" satisfies. We can introduce first-order Variables and Quantifiers to make generalizations about whether properties apply to some object, every object, no object etc. And in the Classical framework, every property is understood to either determinately apply to a given object or to determinately fail to apply to that given object; the payoff being that we can use another (more complex) algebraic analysis to let us build up expressive and complete deductive systems for our logic. The power of deductive systems and the simplicity of the notion of ontology of this kind of framework is what makes it so widespread in the methodology of analytical philosophy, mathematics and science. It is by no means the only, or even necessarily the most appropriate, logic for use in formulating languages about particular subjects, and it is known to have several limitations and unusual consequences. Nonetheless, it is certainly a system that has become well established in a great many areas of study in the mathematical sciences. 

What you may be interested in is the idea that there is no thing in virtue of which one thing is what it is, and which is such that two referential descriptions that both have it are in fact pointing to the "same" object. This thesis does have a name: anti-haecceitism. This ties in with the metaphysical problem of persistent identity statements between different counterfactual states of affairs, which is discussed in some detail in a neat SEP article on Transworld Identity. 

The main philosophical objection to be levelled at your proposed conceptual analysis is that you're not matching your conditions on the left up with the range of concepts on the right, and this is introducing fuzzy boundaries for your concept. Not all rational numbers have "last digits". So if what you want is a concept that is determinate (that is, we get a yes or no answer as to the question of whether any given rational is even), we should really qualify our definition on the right so as to make the assertion on the right something that comes out as true or false given the range of things on the left. A simple existential qualifier usually does that particular trick - for example, we might re-construe your proposed analysis thus: 

Drawing a distinction between extensional and intensional meaning might help you puzzle through some of your thoughts about how perspectives and axiomatic identity relations might come into play here. How do we use our language, logic and conceptual technologies in making claims and assertions about a given frame of reference, and how do matters of good practice, convention, shared reasoning patterns or communication standards influence the ways in which we connect elements of our objective picture of the world together? Because I think you're right in many ways - on an extensional level, axiomatic specification of what it takes for something to be an identity relation doesn't tell you everything that might be psychologically or computationally interesting about what kinds of things are identical. It might be that without enough of a background framework about what kinds of things we want to include as modelling assumptions, conceptual tools, community conventions etc. for intensional descriptions, distinctions that we think should be obvious and rational just can't be drawn. And if we think that's okay, then what's the specific motivation of excluded middle or non-contradiction? If it's not prima-facie simply logical (in the classical Aristotlean sense) that there are referentially distinct things, or that all distinctions that we take to be logical occur strictly at the level of reference, then what does the idea of Negation amount to? Why should there be neat and clear distinctions between any given property and its lack, absence or exclusion? I think there are interesting proposed answers to those questions at least in as much as mathematics, culture, psychology or social structures are the domain of logical enquiry, though their methodologies are very much distinct, and in many ways significant (and potentially dangerous) issues emerge when we try to think of any framework as a dominating philosophical paradigm. The question that might be worth thinking about as a prerequisite for making progress here is what, or perhaps even who, your philosophy is ultimately for, and then to have a look at how they progress in their investigations and model building. 

I think the standard response here is to call upon two particular parts of the Frege/Russell tradition - the first being the concept of a Proposition (SEP) and the second being the concept of Logical Form (another SEP). Consider a simple question like "Is it raining outside?". One way to go about working out what it is that this question is asking is to try to determine under what conditions would this question receive an affirmative answer, and what would receive a negative answer. Naturally, we would say that it would be answered affirmatively if, and only if, it is raining outside, and negatively if, and only if, it is not raining outside. Now in one interpretation of the analytic philosophical project, what we're doing is constructing a theory of propositions (that we take to represent the bearers of semantic value) in a formal framework, and then using this theory to further interpret assertion more generally by saying that the logical form of a statement or argument reduces to the expression of either propositions or of relations featuring at least propositions and speakers as constitutive elements. The logical form of my question then will feature the proposition "It is raining outside" as a proper part. Is there something else that might be necessary here? Well, perhaps we might also add that in asking a question, I (the speaker) am addressing this question to you (a prospective answerer), in a manner which suggests that I do not know the answer but hope/believe that you do and want you to tell me if you do. So. Let's suppose we have a proposition-forming operator '' to form a proposition from the sentence . Perhaps a candidate for a correct logical form of "Is it raining outside?" asked by A to B would be something like this: 

I think what you're proposing is that for some explanations of descriptive phrases in common use, the only correct form of translation to a first order logical form would be an indefinite description, because there might be ambiguity involved in trying to specify a singular referent of the phrase. This certainly isn't alien to Russell's project, though others have taken and picked at the notion of ambiguity involved in indefinite descriptions in their own ways; see, for example, the SEP article on Descriptions. 

You've actually (perhaps unintentionally) asked a controversial question in the philosophy of logic. I don't think it's been given a lot of attention on the Phil SE, but it has definitely been danced around. The Explanation Classically, the two statements are equivalent. That's because in order for to be true, it is not the case that every x is B, which means there is some x that is not B, which means that . But what is the intuitive pull behind that middle equivalence? It's actually best to go right down to the semantics of classical logic to explain this, so let's do that. In a classical model in logic, we have a collection of objects called a Domain. When we use the universal quantifier in , what we are doing on the classical account is we're saying "any object in the domain, , is such that ". On this understanding, we assume that, in the language we're using to make statements like "every x is P" (as opposed to statements in our logical language like ), we have the resources we need to go through the objects of the domain and confirm that, indeed, all of them are P. (and this seems like not a major problem, since we're restricting ourselves to talking about things in a Domain, rather than talking about "everything there is" or something like that.) We also, when push comes to shove, have the resources we need to say, of any of those objects, when they are not P. And, of course, we know that any object either is P or is not P. So. The interpretation of why the two statements are equivalent comes together. It's because universal claims come out as true if, and only if, all of the objects in the domain are P. In our language where everything in the domain either is or is not P, we can tell that when not all of the objects in the domain are P (i.e. is true), that must be because at least one of them is not P (for some in the domain, ). And once we've established that, then we've established all we need to make true. The theory of classical models of logic is probably not suited to a first course in logic, but Ch.s 9-10 of Boolos, Burgess and Jeffrey's Computability and Logic is recognised as a good overview for an intermediate-undergraduate-level audience interested in delving into the rabbit-hole of metalogic. It should be available in most universities with a mathematical logic course, and I've seen it in quite a few public libraries too. The Problem But you're absolutely right that the latter proposition seems to have an existential commitment, where all we've done is negate a universally quantified proposition. It often seems natural to us to say that we have demonstrated that something is not universally the case without wanting to say that we have demonstrated that there is something for which the converse holds. Constructivists in the philosophy of mathematics will want to say that this is because there is more at stake in the existential quantifier than working within an accepted domain of objects, all of which behave perfectly classically and can be safely referred to and individuated. For a constructivist, when you want to logically assert that there is something that is P, you not only make a statement about an object abstractly, but commit yourself to being able to go out and actually present the object somehow. To explain this a little further, let's try out a mathematical technique of proving that something exists by contradiction (thanks to the wiki article on Constructive Proof for this one). I assert that "There exist irrational numbers a and b such that a^b is rational." In defense of this claim, I ask you to consider the number . Either it is rational or it is irrational. If it's rational, the assertion is true. If it's irrational, however, then let that be the first irrational number a and let be the second b. . So in this case, the assertion is also true, and therefore, it is always true. You can then respond by asking me "Okay, so maybe there are such irrational numbers, but so far I'm not sure what values a and b should take for your statement to be true. Can you tell me what they might be?". And on the classical account, I am entirely within logical authority (and perhaps, if I don't know, obliged) to say "No, and I don't have to in order to have logically proven my claim." The Constructivist will say that something is amiss wih the logic here. For a constructivist piece of reasoning to count as valid, it must in principle be possible to be able to provide examples or algorithms that serve to verify any conclusions that are drawn. This is a line that is quite common among verificationists or positivists, such as we find in abundance at the moment in a lot of popular science. That classical mathematical logic finds itself at such odds with this intuitive way of looking at what Logic is supposed to do (perhaps to reveal a conservative and transparent account of the way the world is) is something that many people find a pill too difficult to swallow. So don't worry if the classical way of thinking about logic doesn't seem natural or intuitive. That's a recognised issue people have had with the classical idiom. The trick to getting the feel for classical logic is understanding it in well-defined contexts and in the mathematical framework for its interpretation, which might be better thought of as the problem of presenting models of collections of objects and evaluating theories of inference concerning well-defined properties about them. You can worry about where and when this kind of model is suitable for wider application once you understand how the classical standard one works.