Wait for Dell to support it. Try the Server 2008 R2 drivers. They will probably work, though this is probably vendor-unsupported. 

If your package manager installed Ruby to begin with, then something on your system needs it. The easiest way to find out what needs it is to test an attempt to remove the package. For instance: 

That's one of a pair of routes that certain VPN software sets when you tell it to redirect all of your traffic through the VPN. The other route is: 

You send everything here which isn't a static resource from your , but the rewrite only matches the URL path . So again, you should expect to get 404s from everything except the home page. This can be trivially fixed by changing it to , which will match everything. It's also not clear why you don't just pass directly to FastCGI from this . The rest of them are redundant. 

The hashbang tells Linux to execute the script with rather than the default shell. And remember that the script must be executable before you check it in (but I think you've already done this). 

Or, more likely, along with a named to handle PHP scripts. This isn't something that should be done in isolation; it is an integral part of the entire block and you should not consider it separately. 

It looks like your files have the wrong SELinux security contexts. When I install the package (it appears to come from EPEL) and inspect those files, they all have the type, rather than . Try fixing the security labels: 

You can send a qemu monitor command to the VM's qemu process to cause it to recognize the new size of the block device. For example: 

Windows 2000? I'd just ban and forget about it. Nobody has any business running Windows 2000 anymore anyway. (Though I'm sure many of us know of one still running somewhere...) 

Zend OPcache is included with PHP 5.5 and later (and as from Remi) and is already installed on your system. You do not need to install the PECL package, which is only for PHP 5.5 or earlier. If for some reason OPcache is not installed, try installing the package from Remi. 

nginx makes a great reverse proxy, but is less than ideal as a forward proxy. It can be done, but since writing the rules you want will be rather hairy, you're almost certainly better off to use a purpose-built forward proxy, such as squid. Doing so also means your future self will have a much better chance of understanding what's going on when trying to maintain or debug the proxy. 

Use Active Directory to run a Windows domain for your cloud instances. Use sysprep to change the SID on your Windows cloud instances and join the domain when you start them for the first time. Use winbind on your Linux instances to join them to the Windows domain; set a unique hostname for each instance when you start it for the first time and before you join it to the domain. 

You appear to be running an old first-generation Rackspace Cloud virtual server. You have a couple of options: 

I'm going to say it's a 90% chance it's SELinux related. You can confirm it by looking for entries in . CentOS has SELinux enabled by default. When you run from your PHP script, it is most likely running under 's security context, which doesn't permit outgoing network connections. The quick fix is to allow to make outgoing network connections: 

You can throw in the GT 610 if you want, though in my experience it makes little difference. Unless you do something crazy like install Desktop Experience on your server and turn on all the 3D Aero Glass effects, the load on the video card from displaying console video will be so minimal that you won't even notice it. If you're really set on getting that last 0.5% of compute power out of the card, then by all means throw in the GT 610. Just remember to plug a monitor into it so Windows knows which card it should be using for the console display. 

In this case, we serve static files first, then go to the backend. If the backend returns one of the listed errors, then nginx will serve with a HTTP 503 response. The benefit of this method is that you don't have to manually add or remove the file. You leave it in place, and nginx will automatically serve it if the backend is actually down. 

KVM provides full hardware virtualization, but you can use paravirtualized disk and network drivers (virtio). Most current Linux distributions will use them by default provided you've configured them when setting up the VM. In full hardware virtualization, every component of the virtual PC appears to be a physical PC and the guest OS uses the same device drivers as it would if it were on a physical PC made of the same hardware. This can be slow because the hypervisor has to emulate common hardware for the benefit of the guest. In paravirtualization, guests can use specially written drivers for some performance-critical devices (like the disk and network drivers) to improve performance back to near bare-metal numbers. The paravirtualized driver, instead of talking to emulated hardware, talks (almost) directly to the native hardware. The disk and network drivers are generally the first to be paravirtualized, since they provide the greatest performance benefit. Other devices can be paravirtualized as well, though doing so doesn't provide quite as much actual real-world benefit. 

This comes out of the dim recesses of my memory, as I haven't had to script command line FTP in this way since, oh, the 90's... In an FTP protocol session, after sending the username to the FTP server, the server may then ask for a password, even if the username indicates that anonymous FTP should be used (i.e. the username sent is or ). In this case, the server requests the password but ignores it. So in a script that drives the command line FTP client, a blank line would be used to send an empty password. If the server doesn't ask for a password, the blank line does nothing and is harmless. 

The error you posted is returned by Django, because it cannot figure out the hostname part of the URL. When you proxy from a web server, you have to pass through this header explicitly. The critical line you are missing is: 

First, you need to create the guest's virtual network interface using the virtual MAC address that Hetzner assigned to you, and bridged to on your host system. For example (libvirt XML): 

The cache will then be bypassed for the IP address 192.0.2.81. You can add as many IP addresses or CIDR ranges as you wish in the block. 

You did open your firewall correctly. In order to "open" the port, you need to actually have a service running that listens on port 8080. 

Unset PHP's directive in . This will cause it to log to standard error, which nginx will then log to its own error log. Set in your php-fpm configuration , to ensure that the FPM SAPI doesn't discard standard error. 

Shellinabox is not an ssh client, it is a web application that emulates a plain Unix terminal. In particular, it has absolutely no security at all. In fact, using it is even worse than simply allowing insecure telnet! This is because all logins from shellinabox are logged in utmp as coming from 127.0.0.1 and thus attacks (of which you will get many) become diffcult or impossible to trace. This is not software you should ever run on the public Internet for any reason. 

Your code doesn't specify the extension name correctly, so of course it fails. The correct extension name, as we see, is . 

You named your server , the naked domain name. Thus many programs (sendmail included) take you at your word, and consider that the local server does everything related to that domain name. To resolve the problem, rename the host. For this and a variety of other reasons, no server should ever be named with only its naked domain name. 

You can try using - this is the method recommended in Rails' own guides - but the down side is that you will have to provide the unique ID yourself. The gem provides a much more compact, single-line log, and may be closer to what you're after. 

A Kubernetes persistent volume (or GCE persistent disk, which is approximately the same thing) can only be mounted to one point in your pod's directory structure. But once mounted, you can certainly create bind mounts or symbolic links to organize its files however you wish. You can also change the configuration of your applications to read and write to a subdirectory of wherever you mounted the persistent volume, but that would take more work. 

Where resolves to the same host. In this scenario, nginx repeatedly connects back to itself trying to serve the request, does so 1000 times, and runs out of workers. You have two possibilities to solve the problem: 

You are using gems with native extensions, but they were compiled against libraries on the source system that have different versions on the target system. So you need to rebuild your gems on the target system. 

Video streaming doesn't require that much RAM or CPU, but it does require fast storage. Let's say four 400GB SAS SSDs in RAID 10, for 800GB usable space, to store your videos. You may want to increase that, though, if you plan to have a lot more videos to serve in the next few years. Say, four 800GB SAS SSDs in RAID 10, for 1600GB usable space. Don't cheap out on the NIC. Your NIC should support, at minimum, TCP/IP offload (even if you end up not using it), receive side scaling and receive side coalescing. Some NICs such as those from Intel have further features to improve performance. You might spend a little time researching this. Though you do need to pay attention and make sure your server's networking is configured and tuned well, network throughput problems are sometimes the fault of the network infrastructure. If you're colocated and don't control this, be prepared to argue a lot with your datacenter. In particular, make sure that you aren't buying a network port which is throttled to some fraction of the link speed, and that the datacenter actually has more than enough bandwidth to accommodate you at peak times. The CPU doesn't matter a lot, but it does matter. The web server won't use much CPU, but processing interrupts from the NIC may use as much CPU as the web server does, and quite possibly more. You probably don't need something top of the line, but you shouldn't cheap out here either. You will have additional tuning work to do if you use a dual-CPU system. In such a system each CPU can access half the RAM quickly, and the other half more slowly, and vice versa for the other CPU. This is called NUMA, and you will need to watch out for bottlenecks related to your web server or interrupt handling running on one CPU and accessing memory from the other. Linux does include tools to help you deal with this. You don't need that much RAM to serve videos, but your server will make use of all the RAM you can give it, as a very fast disk cache. You aren't likely to hit a bottleneck here, I think, so I'd start small and upgrade the RAM if necessary. 32GB might make a good start; 192GB would be overkill unless you already knew you needed it. I would use the nginx web server. I always do, since it is much more capable of handling thousands of simultaneous connections than Apache, by default. You may need to increase the number of file descriptors on the system though. I would build this on Red Hat Enterprise Linux 7, and purchase and keep the subscription active for the life of the server. Besides Red Hat's comprehensive documentation on its distribution and on performance tuning, and its extensive knowledge base, Red Hat Support can help you identify and resolve bottlenecks when they appear, which is easily worth the price of admission. Be prepared to upgrade components if circumstances warrant. You might want to upgrade the NIC, RAM or the CPU based on actual issues discovered after you go into production. All of this assumes you are building multiple servers, and that requests are load balanced between them somehow. You should build the servers with more capacity than they need, so that in the event one fails or needs to be rebooted, upgraded, etc., the remainder can take up the slack.