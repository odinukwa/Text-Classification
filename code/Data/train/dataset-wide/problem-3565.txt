You want to reduce the resources used by find, ls and diff? Must be a huge amount of files for that becoming relevant I would guess... You can obviously save a lot of ls calls by using instead of . And you can consider getting rid of ls at all as it does nothing find cannot do itself. You may generate the file with find's printf values, creating more or less the same output. But: Neither ls nor find detect certain ACL and extended attribute changes. A completely different approach: FAM (File Alteration Monitor). You let the kernel tell you (via e.g. ) what has (possibly) changed. One more hint: Something like rdiff-backup should need less bandwidth than rsync because 

Beside the rather general approach with there is a nice device mapper target (ioband) which allows precise control over the bandwidth to a (DM) block device. Unfortunately it is not part of the standard kernel. Furthermore you can probably speed up tar by 

I don't know whether would tell you about misaligned partitions, though. So you should have a look at 

You probably have a LVM volume group (VG) of about 130 GiB size (with the very creative name "volume") in which just one logical volume (LV) has been created. Have a look at it: 

and replace with (or the with ). Or you rename it ( instead of ) in one of these ways and delete is manually afterwards. 

I think that is the expected behaviour - at least if both processes have an I/O share near 100%. There should be a small difference but 100% is the limit and if you are already at 96% then getting just half of the I/O results in 98%. No big deal. A serious difference should be discernible in the absolute transfer values. This difference may depend on the CPU priority, too. I/O prio idle doesn't mean that the system is not affected at all. If non-idle processes do not consume the whole available I/O then the prio idle process gets I/O bandwidth, too. Thus it may happen very often that a non-idle prio application demands I/O and does get the next slot but because there is an IOP just being executed for the idle prio process the lantency increases. The less I/O a process causes the bigger should be the idle prio process's impact on it. Thus it might help to reduce the CPU priority of the cron process (maybe even making it SCHED_IDLE). I have no idea about the swap problem though. 

You are asked just once. You can copy the respective entry from the file to the same file for other users. Or you put it into then it's valid for all users. 

If you want to avoid the situation that you are locked out for a moment (and avoid the risk that the firewall setup fails due to errors) a technical alternative is to avoid the table flush for INPUT. Replace or by 

Without saying that using an RAM disk is a good idea: I remember having read an article (unfortunately no URL at hand) about benchmarking the two kinds of RAM disks which surprisingly showed relevant differences (I have forgotten which was better). 

I don't know this Intel stuff but you could try this: Copy the whole content of the disk to be replaced to the new disk using dd (don't forget ). If your RAID solution does not store serial numbers and the like then there is a chance that the RAID continues working after changing the disks. I would expect this to work with software RAID. 

I noticed a difference between the two configurations which could in principle explain the reversed performance rankings for latency and throuput: 

You need to enable forwarding on the OpenVPN server in the kernel () and you have to globally or selectively allow forwarding in the firewall (iptables), e.g.: 

may be useful. Are the users configured on the new system? What does "to no avail" mean? Error message? Can you change any file's owner? 

You can do this with NAT. You make DNAT in the PREROUTING chain on B. You may forward port 23 on B to port 22 on A. This obviously requires that forwarding in enabled in general (in the kernel) and that this specific forwarding is allowed (in the firewall). 

Not really technical: Perhaps you can buy a working solution (hardware and software) from an ISP who is abandoning it? But I doubt that anyone has used Windows for that. 

If there is no Apache-internal solution and we are talking about Linux here there may be an option to do this with traffic shaping. All you need is a possibility to (quickly) communicate outside Apache that the respective process belongs to a certain user. Perhaps you can rewrite the URLs of your files so that Apache calls a PHP script instead. The script would determine the user and the process ID and write both to a small "daemon" (e.g. Python script) before it sends the requested data. This daemon would add an iptables rule with --pid-owner (doesn't work any more, see below: Edit) in the mangle table and mark the packet (one number for each (active) user). You would define an HTB class for each simultaneously active user. The tc filters would assign each packet one of these classes depending on the nfmark set by iptables. You can decide whether these classes have 200KiB/s as a hard limit or get the spare bandwith in addition. This way it does not matter how many connections a user has open, the limit is global over all of them. From time to time the "daemon" would have to check whether all processes still exist and delete the rules for those which have gone. Edit It seems that the option --pid-owner has been removed from iptables. The possibility to filter based on user or group does probably not help. But a PHP script knows the destination address so that it can call a script with these parameters which creates an respective rule. 

I would say that "jail" is a general term while "chroot" is not. chroot is just one of several possibilities to limit a process's accesses. I have never heard of "jail" in another context though. You may use AppArmor, SELinux and the like to reach similar results but "AppArmor jail" seems to be an uncommon term. On the other hand security is not the only reason for using chroot. Though the effect may be the same it may make little sense to speak of a "chroot jail" in certain situations when the aim is not security but a special configuration for a certain process. 

Not that I think it is a good idea to do that but for appending to a file a process needs write access to the file not to its directory. But I assume that Postfix is trying to do something different from what you expect... Edit 1: 

Check with tcpdump what the packets look like that reach the server. Maybe SNAT has been activated on the gateway. Edit 1 This refers to the case that the access is from outside the local net so that SNAT is possible but not necessary. 

You probably want to use the advantages of the newer version (security fixes) Usually during a kernel update the module tree of the old kernel is removed. Thus if you (or some script) unload a module then the system cannot load it again because it finds only the newer one on disk (if at all) and this is compiled for a different kernel and thus cannot be loaded (at least usually). 

You need not set routes on the server if just simple clients connect. If 172.16.20.1 connects as a gateway for the local network then you need a route for 172.16.20.0/24 but that is probably (and best) set in the OpenVPN config for 172.16.20.1. Edit 1 If you cannot configure the routing on certain systems and their routing would not send the traffic back the right way then you need NAT (more precise: SNAT): 

This may be a problem with your system, with the gateway, or with the connection itself. Can you reach other systems in that subnet? If they are reachable while the gateway is not this is a hint that something gets reloaded on the gateway (due to firewall / tc updates or whatever). Maybe reconfigurations of the switch (VLAN e.g.) can cause that, too, but then the connectivity to all systems should be affected. 

For testing you may disable the firewall on the VM (and on the host if that didn't solve the problem). 

Your only risk (if you got VMware from a safe source) are exploits in VMware. Not that hypervisors never got cracked in IT history... If you are paranoid about that, 

I don't see a possibility to force sockets to a certain port but you can prevent other ports being successfully used. This can be done by and its module. You can drop all replies from processes belonging to this user from disallowed addresses. If this is an option for you and you don't know how to do it let me know and I will deliver some code in addition. Edit 1 The solution is to block every packet from this user which belongs 

Perhaps it is useful to create a dedicated volume for MySQL, /tmp-mysql, and point MySQL to that path by setting TMP=/tmp-mysql for the start script. That way MySQL should keep operational even when /tmp fills up. 

If Group2 is not the primary GID of the users it may be useful to either do once or add to the setfacl -d. 

In "\ip" is the ID. That means the same like on the content level does not mean that both has to be syntactically equivalent. 

Edit 2 The approach with the table failed (for incoming connections because only the first packet of a connection is checked in and the first is the incoming one which hits only where the module is not available). Thus all checking and marking is done in the default table () now. The script: 

You can use any protocol, even unencrypted and without authentication. All you have to to is to sign and encrypt your data before you send it: 

It seems to me that you can solve this problem by creating another file in and abusing $CTIP and $DMZS. You just turn them around, making $DMZS the IP of the container and $CTIP the Internet: 

Updates are faster (less downtime) and less dangerous if you can do them with a copy of the VM while the VM is running. You can have a very simple host configuration (fast updates here, too). All configuration complexity is in the VM. So if you have to change the bare metal this is easier. You can easily put a second VM on the same host if that later turns out to be useful. Without the initial VM you would need a VM configuration in your application system where it doesn't belong. It's much less probable that the simple host (with hardly any changes to the OS) has a crash with boot problems. A crashed VM can be managed via virtual serial console (without fancy hardware or additional systems). 

What routing must look like depends on what you want to do. Probably you need an entry like this (if it's noth there yet; on the remote client): 

with the variables set accordingly. Assuming you can set the correct routing for targets in 172.16.20.0/24 only then you can do this easier this way: 

You can automate this by using keys without passphrase but interrupted SSH connections are not restarted automatically. Thus it would be useful to make the SSH call from a loop. OpenVPN would be more useful though. Edit 1 If you want to forward other remote addresses than localhost don't forget to both put 

You need in order to tell (and more or less all other GNU software) that all following parameters are file names even when beginning with "-". Otherwise (and in your case) the file name is confused with options. Another possibility is 

fuser shows you the PID of the process(es) which have opened the file output. The more elegant solution is using cgroups, though. You could use systemd for that. Just create a service file for your script and start it with 

Check with tcpdump on the LAN interface whether the Debian server routes the VPN traffic to the LAN. If it does then check whether the Debian server is the gateway for the LAN or whether the seperate gateway knows about the VPN address range and routes it to the Debian server. If that works check whether the LAN systems have firewall settings which prevent access from the VPN address range (probably from everywhere except the LAN scope). 

Depends on how you understand "some means". You can assign different gateways via DHCP configuration. You could offer an internal web page which the users can use for selecting the gateway. This page would trigger a script that makes the respective changes to the DHCP configuration file. Ask your favorite search engine for [dhcp multiple gateways]. 

Edit 1 (comment answering) It is possible to make the mail server see the original address (this is trivial, you just have to leave out the SNAT rule). The challenge is to get the reply packets back to the vserver. You need advanced routing for this. And I guess you also need the Netfilter connection mark. You mark all new connections from the vserver, copy the connection mark to the packet mark and use the packet mark for the routing decision. You need define an additional routing table in /etc/iproute2/rt_tables. You could name it to_vserver. The iptables block for each port, the others just once. 

a firewall problem on B (counter intuitive Netfilter blocks packets over a bridge, too) a firewall problem on C (not very probable) a routing problem on C 

neither to a connection which this user has opened (i.e. he is not listening on a port at all) nor sends from an allowed port. 

It is not possible to get this done with only one command per DNAT – unless... see below. But it is possible to enter the data just once. Let's define the mark range 1024–2047 for connections which get DNATted and forwarded. One line with each DNAT match condition in mangle: 

You may use tcpdump (-X) / wireshark to have a look at what Outlook is doing (not the packet metadata but the packet contents). 

All packets (connections) from that user are selected for special handling All packets are marked with 41 (disallowed). For allowed connections this is overwritten later. All connections with a locally generated first packet are allowed Everything left was not created locally. Drop everything not from lo Now allow all connections with an allowed source port (sorce of the reply i.e. local port) Last step: Drop all packets which are marked with 41. 

Your command tries to create an already existing directory. You should make this shell code more robust: 

If you have read access to a directory then you can see the entry names. The other metadata (type, size, owner, permissions and so on) is readable only to those users who have the execute right for the directory. If you had executed as root then you would have received a normal directory listing. In other words: The file system has not lost track of anything. It just denied you this information. 

The wording is misleading. The IP layer knows the maximum payload size of the link layer so it does the fragmentation. 

If your Apache does not happen to run as ekrem or root then you have to make the subdirectories readable and executable for the Apache user. Check also the access rights of the parent directories: You need a definition for so that access is allowed there. You also need a definition for which allows to follow symlinks. 

Just take ANY system, install e.g. OpenVPN, do SNAT, limit the outgoing traffic to the target to forwarded traffic coming from the VPNs and whitelist the SNAT IP. 

It's not one vnet for each guest but one vnet for each network adapter in a VM. You can configure the vnet numbers but usually they are not relevant. The vnet interfaces are bridged to either a physical or a logical (host-only) interface. 

This may work with the socked FD in , too. Furthermore socat supports FIFOs (named pipes). Edit 2: It does work with FIFOs, too: 

I think the easiest solution is to add another system (can be an old, slow one) in Network1. This system detects the breakdown of server1 (either by itself or it gets notified by server2 when it takes over) and takes over the floating IP. It also does NAT for this IP so that all traffic for server1 is forwarded to server2. I have no experience with heartbeat. This would work only if the apps don't care about the IP address. And if there is enough available bandwidth between the subnets. The address problem could be solved by having another NAT system in Network2. More points of failure, of course. 

"tlsv1 alert unknown ca" sounds pretty clear to me. stunnel cannot check the certificate of the other side because the configured CA does not match the one which signed the certificate. Or no CA is configured at all. You need an entry like this: