The setting does not create a PID file. That is still up to the service itself to do, the same as it has been for the last 40 years. Rather, this option tells systemd where to find an existing PID file (if any). In most cases it's not required at all, as systemd will keep services in their own cgroups and does not need a PID file to keep track of them. However, systemd will delete a PID file when the service exits, if the service fails to clean up after itself. From the documentation: 

If you think eAccelerator and XCache leak badly, try using APC, which just plain crashes PHP entirely. In the couple of years I've been using OPcache I've never seen a memory leak or crash. That said, you should update PHP anyway, as 5.4 will be end of life in just a few days. 

The errors say that Apache was looking for SSL certificate configuration for some virtual hosts, but didn't find it. You do indeed have three virtual hosts configured that are missing their SSL directives. Try adding them in. 

Don't just disable IPv6 entirely; this will cause you problems later when you roll out native IPv6 into your datacenter. 

It appears you've somehow installed your guest in a way that it considers the hardware clock to be in local time. KVM guests should always consider their hardware clock in UTC time, unless they're Windows guests (but even those can be set to UTC hardware clock)... Edit the file, and change to . Then reset your guest clock. 

The time recorded in the log is the time the request was initially received. However, the log entry is not actually written until the request is completed. Thus, requests can appear out of sequence, when some requests take more time to complete. 

The displayed uptime is that of the host. The kernel does not track uptime for individual containers in this way (though Docker does). 

Sounds like you might be able to use the (otherwise rarely seen) DNAME record. For instance, in the zone: 

These are not required if you're using HTTP authentication and you can get rid of them. (And Order breaks if there is whitespace after the comma.) BTW, it's a good idea to keep your htpasswd file outside the web documents directory. Since you've updated your question with additional information, I would say that you should also check the permissions in the directory with to check both the Unix permissions and the SELinux contexts. 

You should expect a service to have an SSAE 16 audit annually. While this isn't a strict requirement of the standard, regulatory requirements change, new technology is added to the environment, etc. An out of date report may not be useful. 

If you want to reach port 8000 from outside AWS, you must add it as a permitted port in your AWS security group. 

One's complement arithmetic was used because TCP was designed in the 1970s for 1970s computers, most of which used one's complement arithmetic. The rise of two's complement arithmetic, which modern computers use, didn't really begin in earnest until the personal computers of the late 1970s and 1980s. 

You appear to be using a Samba share to store your web content. If you want SELinux to allow your web server to read files on Samba shares, you need to set the appropriate boolean. For instance: 

Red Hat doesn't distribute MP3-enabled packages due to patent and licensing issues. You can find the necessary packages for CentOS and Fedora from the RPM Fusion free and nonfree repositories. 

Look in your security event log on the domain controller for event ID 628. If passwords were reset by someone other than the user himself, this event should have been recorded for each user whose password was reset. The details should tell you who changed the password. If passwords had simply expired, you would see event ID 535 logged when an affected user tries to log in. Also look for other events around the time period that you believe this happened. You may find other events logged that will give you a clue as to what happened. 

Postfix is not being particularly aggressive. It's trying to deliver mail in accordance with SMTP and various best practices. This is Yahoo's fault. Yahoo has extremely low limits on simultaneous recipients of a message from a single sender. I see this occur with a small 500-member list with only a couple of dozen Yahoo addresses on it. The contents of this particular list are extremely time-sensitive; if the message isn't received, read and acted on within two minutes, it loses much of its value. My "solution" is to warn Yahoo Mail users that Yahoo may delay receipt of their mail and that they may wish to consider a different provider. This may or may not work for you. Since Postfix retries the remaining recipients pretty quickly, this isn't usually a serious issue. Some other possible solutions are: 

Here is what's going on: The two major ISPs in UAE, Etisalat and du, use SmartFilter by Secure Computing (now McAfee) to block content. This works by transparently proxying all users' web traffic through the filters. What happens then: When a user requests a web site, the SmartFilter checks its local blacklist (for instance, in UAE, all sites ending in are blacklisted) then looks up its classification (e.g. politics, news, social media, games, etc.) to see if it's appropriate. What happens is that new sites which have never been seen before are unclassified until someone at McAfee visits and classifies the site. This can take a few days. Companies and ISPs which use tools like SmartFilter can choose to allow or block unclassified sites, and it seems that here, they are blocked. The other problem with proxies set up in this manner is that they must interfere with the end-to-end connection between a user and the remote site. This can and sometimes does result in performance problems which are difficult to resolve. You may have a lot of difficulty finding the responsible person at the ISP who can actually help to resolve these sorts of issues. Services other than web sites (HTTP) can be interfered with in other ways, as well. 

Set up "views" in Bind. The Internet has a very large number of tutorials on this; pick your favorite and run with it. 

Applications which were configured to use the old-style interface alias should instead be set up to use the corresponding IP address, or to listen to all addresses, as appropriate. 

In addition to CIDR ranges, you can specify single IP addresses or ipset names prefixed with . After this, all traffic from the specified addresses will be allowed on any port. Remember to make it permanent, either by repeating the command with appended, or by running . 

Your tests are not on similarly configured servers. Your Apache server served all its requests with keepalives enabled, but your nginx server served all its requests with keepalives disabled, which creates a significant reduction in performance as a new TCP connection must be opened for every request. By default, nginx has keepalives enabled, so you must have explicitly disabled them somehow. Inspect your nginx configuration carefully and remove any directives related to , so that nginx uses its default behavior. Then try your benchmark again. 

I see intermittent DNS failures when trying to resolve your domain name. So let's start at the beginning. I see in your whois record: 

Postfix directives that start with refer to when Postfix is acting as an SMTP server, receiving mail from other hosts. Postfix directives that start with refer to when Postfix is acting as an SMTP client, sending mail to other hosts. 

Your file is not readable by the PHP process. You can see that the permissions on the script permit only the user to read (or write) to the file, but PHP by default runs under a different user ID (e.g. or ). To resolve the issue, make the file world readable. You may also need to make the containing directory and its parent directories searchable. 

The directory doesn't exist or is unreadable by Apache. Check for its existence and permissions (it should be world readable/executable). 

Just run each version of php-fpm on a different port (or socket) and configure the appropriate port in your parameter in your nginx block. For instance, you might have 5.3 run on port 9000 and 5.4 run on port 9001. 

The extra addresses look to me like privacy addresses, which really should be disabled in any sort of business environment. Try disabling IPv6 privacy addresses: 

Upgrade to RHEL 7, which shipped with gcc 4.8.2. Use the Red Hat Developer Toolset, a software collection which supplies gcc 4.9.1 and updated versions of related tools, on either RHEL 6 or RHEL 7. This software collection is available with most RHEL subscriptions, but is in a separate subscription channel from Red Hat Software Collections. 

MySQL clients which link against libmysqlclient read global options from the section of . This is a typical behavior for such clients, and ProFTPD is such a client when you use its MySQL module. The SELinux boolean will allow this access, but it also effectively disables SELinux for the entire FTP daemon's operations, so it should not be used without extreme caution. If it were me, I would file a feature request against requesting that a boolean to allow this access be added, or perhaps to add it to the boolean. 

No. The tar "file" exists only in the pipeline; it's not written to disk in the intermediate stage, but only at the destination when you extracted it. 

Some notes on this: We use to ensure that IP addresses match exactly, and e.g. a given address that ends in doesn't match . The transform from to is done by in the loop. And we use to expand each rule into parameters. 

You don't necessarily know what the referring page is. And most likely there isn't one at all! Such attacks generally come from automata, not humans. 

Beginning with version 3.0, Postfix can also notify those same senders when delayed messages are finally delivered. This is also off by default, as it can result in a lot of notifications. But if you want this, enable in . 

The remote port number is available to your application in the environment variable . There's no corresponding string to log the remote port, but it can be logged in a standard Apache mod_log_config request log with in . 

The canonical answer to "how to deal with brute force attacks" like these is to use fail2ban. If you're using some sort of web hosting control panel, you may find options related to fail2ban already there. 

Remember that RAID 1 is a mirror, and that RAID 10 is a stripe of mirrors. The question is, on which disk in each mirror is the data valid? In a freshly created array, this cannot be known, as the disks may have different data. Remember also that RAID operates at a very low level; it knows nothing of filesystems or whatever data might be stored on the disk. There might not even be a filesystem in use. Thus, initialization in these arrays consists of the data from one disk in each mirror being copied as-is to the other disk. This also means that the array is safe to use from the moment of creation, and can be initialized in the background; most RAID controllers (and Linux mdraid) have an option for this, or do it automatically. 

On a Red Hat based system, there actually is no such package which will pull in everything necessary for a basic LAMP stack. A minute or so with is sufficient to demonstrate this. To install such a stack, you need at minimum: 

Your VPS runs on OpenVZ, a container based "virtualization" which has no support for SELinux. If you need SELinux, you will need to switch to another hypervisor which supports SELinux in guests, such as Hyper-V, VMware, KVM, Xen, and possibly others. 

Note that in 18.04 LTS the letsencrypt package has been (finally) renamed to certbot. It now includes a systemd timer which you can enable to schedule certbot renewals, with and . However, Ubuntu did not provide a way to specify hooks. You'll need to set up an override for to override with your desired command line, until Ubuntu fixes this. 

PCI passthrough requires CPU/motherboard features to be explicitly enabled in the system BIOS. AMD For AMD processors, you must enable IOMMU in the system BIOS. Intel For Intel processors, you must: 

You don't need to do any of this. As HBruijn mentioned in a comment, the file already contains your credentials and MySQL's command line tools will use them automatically without you needing to do anything special. So just do: 

Evaluate why this server has a custom kernel and consider whether it can be replaced with the supported kernel. Install the tape drive and driver on another server which runs the supported kernel. 

You don't need to be messing with . This is actually a rather dangerous setting when applied to KVM guests. I would remove that section immediately. 

You can match a rule for deletion by specifying it precisely and using () instead of . For instance: 

You can't really "fix" a user who mistypes an email address. So there's not much you can do about those bounces. As for the two greylisting examples you gave, just wait them out; postfix will resend the messages. 

It looks like is not allowed to login directly via ssh on an MLS system. You will need to ssh in as a user and then to root. 

In your https virtual host, you specified an IP address to listen for connections on. Thus, requests which connect to any other IP address on the host will never match that virtual host. If you really wanted to do this, you could add a second IP address to the declaration, or just make it a wildcard . 

You keep restarting everything periodically. The other option is to backport the fix from 3.x to your current version, but if you aren't allowed to upgrade, you probably won't be allowed to do this either. And it will almost certainly be much more work than upgrading, especially if the RabbitMQ code has been significantly refactored. Until you can change the politics of the situation, those are your options.