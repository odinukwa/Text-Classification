If you do mean to refer to Grice's Maxim of Relevance, and the examples suggest you do, then you must understand that, unlike other maxims, it's impossible to violate the Relevance Maxim. This is because Relevance is under the control of the addressee, not the speaker. No matter what the speaker may intend, the relevance of an utterance to a discourse is determined by the addressee who hears it in context and is the sole judge of its relevance. The speaker may try ever so hard to "say" one thing, but if the addressee "hears" another, that's just the way it is. And humans are always looking for contextual cues for interpreting relevance. The underlying truth that motivates Relevance Theory is that you can't get away from relevance; everything else conversational depends on it, and it's not under the speaker's control. 

Yes, but the term "ontology" is not always used; it's pretty general, after all, just the Greek for "words about things". In the case of philosophy or science, it means "questions about 'things' -- i.e what are "things"? and what properties do "things" have? Epistemology is usually studied (and cited) together with ontology, because epistemology tries to answer how we can know about reality, including "things", i.e, how do we know what a "thing" is? and how do we know what properties "things" have? Etc. Fillmore's linguistic work on Deixis, for instance, is clearly ontology, as is his concept of Frame, programmed as Framenet. And so is Berlin and Kay's work on color terms, which is squarely based on the structural differences between how humans perceive colors physiologically and how we talk about them. All of physical ontology -- real "things" -- is based on the human body and its sensory systems, since we need to perceive things in order to be sure they exist, and since the sensations of a human body -- like our experience of position, gravity, movement, and color -- are the only things humans have in common that everyone can depend on others' understanding, too. And that's why we take "things", and their properties, and their consequences, for granted in natural language; and why all this has to be spelled out in painstaking and pathetically detailed form for computers, which don't have bodies or experiences to refer to. And why we use body-part metaphors so often. Protagoras got it right: 

There are several different kinds of logical notation possible; few worry about RHS or LHS. Here are some different notational conventions for De Morgan's Laws, taken from this Logic Study Guide. It doesn't refer to RHS vs LHS, because logical equivalence is symmetric. 

A descriptive statement is a fairly abstract structure, pragmatically speaking, and as such seems likely to have appeared as a type quite late in human language evolution. Obviously it did not spring into existence full-blown. In other words, there was probably quite a lot of pre-evolution involved, but we don't have nearly enough data about what really happened to do more than speculate about the relative evolutionary advantages of speech act types. It is instructive, however, that mathematics, logic, and philosophy (and for that matter, science and theology) have seized on the descriptive statement as the communicational vehicle of choice. Descriptive statements have a lot of convenient features. 

The lexicalization of loans is a longer process, you have many words which are undiscernible from native words by a layperson because they have been so completely internalized. In English, you have words like ditty and because which can be traced back to stems of Latin origin, but which have been so completely adapted to the form of modern English that you need specialist knowledge to establish this. In Swedish, a lot of the old Norse vocabulary has been displaced with German loans which sometimes make little sense in Swedish. Everyday words like anhörig and begära are somewhat opaque (though some morphemes trace back to shared Germanic roots which were also present in older Norse) but make perfect sense in German. Some others which are outright peculiar in Swedish include fogsvans (literally "joint tail", where the German word means "fox tail" -- still a weird term for a saw). Later, French loans have entered the language in the 18th century, originally in forms like lavoir and manquements, but now have modernized spelling and native-like pronounciation lavoar, mankemang. Finnish is pecular because even more than Swedish, it has replaced much of the original Fenno-Ugric vocabulary with loans of Indo-European origin. A large number of words like pallo (ball) and ranta (beach, cf Swedish strand and German Strand) are clearly of Germanic or even earlier Indo-European origin, and there is a set of trisyllabic words like mehiläinen (bee) and kuningas (king) which are of somewhat later origin, and sometimes attest to forms which are no longer straightforwardly recognizable in the neighboring IE languages. In all of these languages, you can find recent loans which are used in a form which is much closer to the origin. With reading and writing skills approaching 100% of the population, the process for internalizing these is likely to look quite different -- it is not unlikely that résumé and coup d'état will remain in English in their French form for a very long time. Similarly, obviously English loans like jazz and policy may well have come to stay for the foreseeable future without any further adaptation to the host language. 

The tenth chapter of Geoffrey Sampson's Writing Systems: A Linguistic Introduction (1985) discusses English orthography, and by and large reaches a conclusion which somewhat resonates with yours; that logographic writing (such as Chinese) is efficient for the reader, somewhat at the expense of the writer, and that the quirks of English orthography push it in the direction of obtaining some benefits of a somewhat more logographic approach (so the different and sometimes decorative spellings of some homonym pairs in English accidentally but conveniently help the reader quickly distinguish between them). Sampson quotes many sources, some linguistic (e.g. Chomsky & Halle 1968) but many others from "the psychology of writing". I don't know if this is a proper subfield of psychology, or just Sampson's informal label for these studies. Notable references include Albrow 1972, P.T.Smith 1980, Wijk 1969, Frith 1979, 1980, and Bryant & Bradley 1980. 

feel, felt, felt; have, had, had; admit, admitted, admitted; ask, asked, asked. These three verb forms are called, in order, the Infinitive, the Past, and the Past Participle. 

To take the questions in order, ... Scope comes originally from a Greek word skopoi, 'a target to aim at'. The Greek root skop- is an ablaut variant of the verb σκέπτομαι skeptomai '(I) look at/examine/consider/think' (that's where both scope and skeptic come from). The earliest senses of scope in the OED have that same meaning -- a mark or target to aim at. In the context of logic, semantics, and syntax, however, scope has no exact meaning, except in a formal system in which such matters can be stated precisely, like Lambda Calculus. That is to say, logical scope is a metaphor, and a visual metaphor at that. The question is which operator can "see" the other one. Generally the metaphor talks about one Operator ( or ) being "outside the scope" of another, or of one being "higher" than the other. Note that whichever operator is "higher" or "outside" can "see" the "lower" or "inside" one, so linear logical notation is suitable for describing the inevitable ambiguity of multiple operators. 

If you have a set of phonetically similar phones in complementary distribution, with no contrasts, then you may assume they are allophones of the same phoneme. What you call the "underlying sound" is entirely your affair, like naming a species. It's just a name. Phonemes are simply named patterns of sound usage, and their phonological status may be very different from their phonetic status. For instance, English has a phoneme with at least a dozen different allophones, all voiceless vowels. The allophones include voiceless versions of every English vowel, immediately preceding that vowel. 

I'm afraid this is a rather poor question. However, instead of voting to close it because it's off-topic, I'll attempt to explain in an answer what's wrong with it. The question uses the terms Prescriptivist and Descriptivist without qualification, presupposing that they are well-known and well-defined terms, that they actually refer to two different real groups of real people, and that there are in opposition. None of this is true. That means that, whatever you're asking about, there's no answer to this question. There may be people who wish to define themselves as P or D, for all I know -- there are people who will do anything. But there are certainly no coherent groups of P or D people, and there is absolutely no coherent viewpoint represented by the terms. There are people who believe that there is only one correct way to speak or write a particular language (oddly enough, that always turns out to be the way they speak or write it). Some may call them prescriptive, since they prescribe behavior for others, like a doctor prescribing medicine; others use different terms, from different metaphors. Almost none of these people are linguists. Some of them may consider themselves P; others may not. Then there are people who believe that language is what people speak and write and that no bit of language is inherently "better" than any other. Some of these people are linguists. And some linguists do describe language and languages, so some might call them descriptive, like a biologist describing natural phenomena; but there are very few linguists in total, so real descriptivists are a very small part of this group, and very few of them besides linguists would consider themselves to be D. Then there are lots of other people, with lots of other opinions about language and correct behavior. They aren't either P or D. The result is that it's impossible to identify the two groups you mentioned, or to identify members of either group, so anybody can say anything they like about them. And they do. But there's no information in it. 

Let me post a slightly tongue-in-cheek answer, then perhaps expand on it in useful directions. If your corpus is 2.3 million words, the ideal gold standard is 2.3 million words. Now, to try to frame that, what I really mean is that you are approaching this from the wrong direction. You are not creating a corpus to satisfy your statistics teacher; you are creating a corpus for a particular purpose, and you want to maintain the highest quality you can with the available resources. Ideally it should be perfect, but we all live in reality - and if you can't make something perfect, at least strive to make it useful. That means, document what you have; explain to your prospective users what they can realistically expect. To approach this from a different direction, let's say you have a toy corpus - for example, written weather reports in English from a single weather station. What can we hope to do with this? Well, a linguist might look for variations in linguistic expression. In really formulaic (and these days, probably mostly automated) language, you will get bored after 5 or, if you are really patient and/or easily amused, maybe 20 reports. That's good. Now we don't need any more data because we have a reasonably representative - not to say exhaustive, even exhausting! - sample of the phenomenon we wanted to investigate. Maybe that's not the only linguistic inquiry we could think of for this example (aberrations in punctuation? Diachronic evolution, if you have reports from different decades?) but let's stop here. The point should hopefully be clear - you have enough data when a lot of it is redundant. Expand this to a real-world corpus and there will always be too little data for some of the hypotheses somebody will want to test - too few samples, of course, but also too few samples in some particular subcategory, and too little metadata (was this sample old or new? Produced by a native speaker? Produced by a member of some minority? From the Midwest? In a noisy environment? Under stressful conditions? Male or female? Young or old?) and there's only so much you can do to improve this. There are two obvious conditions I want to point out for your specific question. You want to make sure there is as little garbage as possible in the full 2.3M, and you want to take as much as possible of it into the golden set. The procedure I'd like to propose is iterative. If you decide to try to start with 0.5% for the golden set by random sampling, it is somewhat likely that some part of those samples are unsuitable for various reasons. That's good! Now you know what problems to look for in the rest of the corpus. Then maybe try to push it to 1%. By and by you will also get a feel for where there are problems which you can't solve by just discarding bad data. That's not so good, but definitely something you want to mention in the accompanying documentation. We really cannot tell if 0.5% is reasonable. If each sample is a single word then even 0.1% should be sufficient. On the other hand, if samples are sentences (on the order of 23 words) or paragraphs (on the order of 230 words) an off-the-cuff estimate of a good number of samples to review thoroughly for inclusion in a gold standard set would be higher. But again, this depends a lot on the types of samples, and the cost of processing and reviewing them. Without seeing your data or understanding your requirements, we can really only reason in very general terms. But a good rule of thumb at least to get you started is to assume that you have a logarithmic distribution -- if not exactly a Zipf distribution then at least a few phenomena with a lot of hits and a long tail of different types of outliers. And in the absence of any better data to guide you, remember the 80/20 rule -- 20% of the explanation will already cover 80% of the samples (so in your case, if you have a set of rules which capture 1/5 of the corpus, you can expect to put in roughly 4x this amount of rules to achieve reasonably full coverage). This also extends to error estimation -- when you start seeing mostly the same error over and over again, you have covered roughly 20% of the total errors. (Sorry if this is a bit rambling; I seem to have gotten a bit over-enthusiastic here.)