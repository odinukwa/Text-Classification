Note that and are reversed. That way, there is no need to traverse all rows for a given account_id that would separate enabled from disabled. Only enabled entries for account_id are read. SUGGESTION #2 : Refactor the Query Instead of 

That table, may have a broken data dictionary entry. Back in June/July of 2015, I answered 3 questions about a similar situation (where mysqld crashes accessing the table data). My condolences on this table's detachment. If you have a previous mysqldump of that table's data, you could load it into another database. Then, transfer all the good tables into that other database. Your current database with the corrupt table is called . Create a database with a similar name () and move the good stuff into it. 

NOTE: If you cut-and-paste the above query as is, it will generate the whole month for you You then LEFT JOIN this to your original query 

Once you make the disk and add , you should have more elbow room. DRAWBACK : Transferring of the temp tables contents from back to the home of for certain SQL commands (such as DDL). UPDATE 2013-05-21 00:10 EDT You simply don't have enough memory. All the cores in the world cannot help MyISAM. SUGGESTION #1 : Shorten your keys I can tell from the keys that you are trying to retrieve all data from the indexes and avoid touching the table. All well and good IF IT WEREN'T FOR THE BILLIONS OF ROWS. Here is something worth considering: Shorten the keys for each index 

Once I was certified, I was better respected by my peers and my boss. When I switched to my new career as a DBA, working for my past employer doing Managed Database Services, I was given the title of Senior MySQL DBA very quickly because I exercised my skills developed by the certification process. Other databases that give certifications may require certifying for the latest major releases. This cuts down having the big companies (like Oracle and Microsoft) do tons of support work by demanding DBAs keep up with the products. However, this just reinforces a DBA's drive to excel in Database Administration. Although I only certified for MySQL 5.0, I strive to keep up with MySQL 5.1, 5.5, 5.6, and Percona Server. In light of all this, the value of certification is directly proportional to the value you put into it. After all, certification is not graduation. Certification is really nothing more than a disciplined approach to being self-taught. The MySQL Certification served as my springboard in the direction of on-going self-education. 

There is no IF NOT EXISTS There is DROP TRIGGER IF EXISTS You must execute the trigger's creation as follows: 

SUGGESTION #1 You have no meaningful indexes. That can have a detrimental effect on execution since the MySQL Query Optimizer has no help in searching. You should all the following indexes 

The direct answer to your question is Yes, but it depends on the version of MySQL you are running. Before MySQL 5.5, replication would operate as follows: 

This will recommend the correct size for the MyISAM Key Cache. This maxs at 4GB for 32-bit. You can go higher on 64-bit machines. Yet, use common sense based on the amount of RAM the DB Server has. This should be a concern for you because only the pages from the .MYI are cached. Any thing from the .MYD must be read from disk over and over again. If the amount of RAM recommended from this query far exceeds the amount of RAM installed by orders of magnitude, just set key_buffer_size to 4G and call it a day on this perspective. PERSPECTIVE #2 : Leveraging Different Row Formats for MyISAM tables Altering MyISAM tables to use a FIXED row format can increases overall performance for SELECTs. Why ? Since CHAR fields require less string manipulation because of fixed field widths, index lookups against CHAR field are on average 20% faster than that of their VARCHAR counterparts. This is not any conjecture on my part. The book MySQL Database Design and Tuning performed something marvelous on a MyISAM table to prove this. The example in the book did something like the following: 

Step 13) on ServerA Step 14) Wait 5 seconds, then on ServerA If Slave_IO_Running=Yes and Slave_SQL_Running=Yes, replication is working Step 15) on ServerB Step 16) Wait 5 seconds, then on ServerB If Slave_IO_Running=Yes and Slave_SQL_Running=Yes, replication is working Step 17) on ServerC Step 18) Wait 5 seconds, then on ServerC If Slave_IO_Running=Yes and Slave_SQL_Running=Yes, replication is working UPDATE 2012-05-07 12:22 EDT The only reason to use auto_increment_offset/auto_increment_increment in this setup would be to do writes to all masters and reads from any master. There is only one scenrio with this setup where you are not obligated to use auto_increment_offset/auto_increment_increment: For any given database mydb - If you write to mydb on ServerA only, then read from mydb on ServerA - If you write to mydb on ServerB only, then read from mydb on ServerB - If you write to mydb on ServerC only, then read from mydb on ServerC 

Give it a Try !!! CAVEAT Notice that using MIN function helps keep the first pkey entered for fk. If you switch it to MAX function instead, the last pkey entered for fk is kept. 

I think you meant instead. Before you use it, you need to know the values allowed it. Here are the options from the MySQL Documentation on Forced Recovery 

OK, that makes the new DATA_ONE database. Now comes the adventurous part: Loading all those tables into DATA_ONE. Run these three queries to formulate the SQL needed for migration 

This will flush all the binlogs and relay logs. If the Slaves do not have binary logging enabled, then skip . Your steps look like this now: 

You cannot make an INSERT trigger DELETE the same row in just put it. For the record, it is possible to make the trigger with some special code to interrupt the trigger's progress in the event the zipcode was missing. But is this plausible? It would slow down the INSERT row by row. It would also disturb bulk inserts should anyone of the zipcodes be missing. Try constructing an INSERT that receives results from a SELECT that gives you all-or-nothing: 

and restart mysql UPDATE 2013-03-05 16:36 EST I don't know why this is still happening, but please try this: 

Here is the key thing to remember : Any instance of MySQL that works for your query in a specific environment is itself a corner case. Once you change one or more of the twelve(12) evaluation aspects, the corner case is due to break, especially given the first nine(9) aspects. 

Here is logical way to dump it: as SQL GRANT commands !!! SUGGESTION #1 If you already have Percona Toolkit installed, run pt-show-grants to a text file 

Don't specify upon reload. Those two lines will create (if it is not already there) and make the default database before loading the data. 

Migrating s single MyISAM table to another disk is only possible in Linux versions, not Windows, of MySQL with the DATA DIRECTORY and INDEX DIRECTORY clauses of ALTER TABLE on a MyISAM table. However, in Windows, you can manually move the .MYD and .MYI files to where you want. UPDATE 2012-01-03 22:03 EDT Interestinging, MySQL 5.5.15 on my Windows 7 machines says symlink support exists: 

GIVE IT A TRY !!! Bad News: Backing up will not scoop up mount volumes. You will have to resort to doing mysqldumps. That should not be an issue if you have 5GB mounts. 

Since this is db.m3.medium, I see two problems, maybe three PROBLEM #1 : Available RAM Since RDS is using 75% of the RAM for innodb_buffer_pool_size, this means you only have 960M for the OS. Not a lot of headroom. PROBLEM #2 : DB Connections Multiple DB Connections opening and closing can cause the OS to compete with the DB Connections for available RAM (See my old post : How costly is opening and closing of a DB connection?) PROBLEM #3 : Too many tables in the database Did you know memory is consumed when you have many tables and columns ? 

It will be handled immediately on mysql startup. You do not have to wait for a mysql restart. First, set to be 10 in /etc/my.cnf 

You can go to www.drbd.org to find out the latest version number and update the aforemtioned script Give it a Try !!! 

At the Client Response, there is crosscheck of capabilities between the client and the server. The CLIENT_COMPRESS flag (value 0x00000020) needs to be mutually exchanged before continuing authentication. To be honest with you, I have never heard of a MySQL question this deep. Good the thing all of this appears in the MySQL Internals Documentation. How on earth would you actually know where to intercept the CLIENT_COMPRESS ? I would suggest using tcpdump or snort to inspect packets. I will leave it to you to read up on the needed exchange packets 

does not give away the SUPER privilege. How do I know this ? SUPER is a global grant privilege. Global grants exist in the table 

upon every crash and restart of mysqld, you need to clean that entry out of ibdata1. I would not be fooled by 

There are some external DB Servers you should be looking into for cloud-based computing Amazon EC2 and XERound Both provide interfaces for creating New Database Instances on the fly As long as you are doing computation and you can settle for MyISAM only, either of those options are OK. However, keep in mind that XERound does not have InnoDB. 

In the context of MySQL, you cannot switch users. You can switch database and host. According to the MySQL Documentation on the MySQL Client 

Any queries attempting to read from or write to will fail immediately rather than hang on a lock from . Give it a Try !!! UPDATE 2013-08-26 15:24 EDT Look back at the code I suggested. Please note the line 

Move the DATA_ONE.sql file over to the new server and execute the script. That's it. Pure SQL solution. No PHP. If anything does not work, it is probably because I do not know the layout and current contents of the personal, account, & games tables and made assumptions on data. Please post the following in your question: 

then any database with any name can have a proper authentication setup. You can still run these two lines anytime. UPDATE 2012-02-24 15:20 EDT To openly demonstrate the danger of having anonymous users in , I would like to create a user that has only the usage privilege. I will be using MySQL 5.5.12 on my Desktop First, look at the mysql.db 

OBSERVATION #1 You need to look at what the Query Optimizer sees and what it is interpreting First, look carefully at the query 

Since Amazon RDS does not give away SUPER privilege, that's the only way to change a GLOBAL static option. UPDATE 2012-07-27 16:34 EDT Without SUPER Privilege, you can modify a DB Parameter Group for a given MySQL RDS Instance, and launch a reboot with one of the following: 

You should create the tree first and then fill in the ids to associate to each node. This is all based on a binary tree with AVL balancing but without the rebalancing. The math is very straightforward. Let's say you have N people. (Let's say N is 15) The formula gives the maximum tree height ( MTH ). Get the average of 1 and (). That becomes the root. Take half the distance and go forward and back (4 and 12) Repeat this until half the distance is less than one. Sorry, for the vague recursion but the end result is drawn for you. Now, go about assigning the user ids to each number starting from the root. 

Depending on the number of products, this will be a long query anyway. Approach #2 : DITCH JOINS ALTOGETHER 

Another major difference not as yet mentioned is how caching for each storage engine is done. MYISAM The main mechanism used is the key cache. It only caches index pages from .MYI files. To size your key cache, run the following query: 

This will close and reopen all tables. If you see your data, CONGRATULATIONS !!! STEP 06) If you get an Error If you get an error on , then one of the cells is not field enclosed with double quotes. Just re-export the data and try Step 04 again until you get it right For Those using MySQL for Windows If you have MySQL for Windows, you can drop in mydb\mytable.CSV becauswe of the way Windows locks files. You will have to run , copy the file in, and , skip the and just run Give it a Try !!! 

This why you should experiment with join_buffer_size. HOW TO EXPERIMENT TO join_buffer_size You can change the join_buffer_size one MB at a time. Then, run the and time it. STEP 01 : Set an initial size of 0 and initial runtime of 48 hours (172800 seconds) 

This will help the query optimizer retrieve your data ordered properly. SUGGESTION 02 : Display posTime as a Debug Step 

Google has many examples of using it and why many have stopped using it. To be honest with you, I haven't used column numbers for and since 1996 (I was doing Oracle PL/SQL Development at the time). Using column numbers is really for old-timers and backward compatibility allows such developers to use MySQL and other RDBMSs that still allow for it. 

If no rows disappear after this, then it was most likely the problem of open file handles agsint the MyISAM tables. MyISAm keeps tabs on how may file handles have been opened against the table. If mysql has been shutdown and you query the table for the first time since mysql startup and the MyISAM reports it already has open file handles when you are the first to access it, the table is marked as crashed. You can actaully run that repair on startup as follows: STEP 01) Make a one-line script to repair the table 

Then, go run the mysqldump. Setting these values very high forces the mysqldump DB Connection to wait a long time for data to be shipped over. In case you are wondering, The number is the number of seconds in a year (365 * 24 * 60 * 60). The mysqldump DB connection will just have to stay around and wait, even for your busy server, until data comes (eventually). Please see my post from : Client times out, while MySQL query remains running? GIVE IT A TRY !!! UPDATE 2018-01-04 09:53 EST I noticed your comment just now Please note the error message you got from the mysqldump: 

Now you have a temporary column at your disposal You could also build it as a separate table called mytablemyid 

The beauty of this is that creating a MERGE table takes milliseconds. Just make sure every table has an index on EmpName. Better to do 75 indexed lookups that 75 full table scans. If there is no index on EmpName, you need to do this: 

The mysql_upgrade program tries to realign the mysql.user table with latest grants for that MySQL Major Release. Since you only did a minor upgrade (5.1.30 -> 5.1.47) the mysql_upgrade was needless. The grant tables for the Slave have no bearing on Replication since the Slave has to authenticate back at the Master. Fixing MySQL Replication is just a case of repointing replication from the last know executable position and starting from there. Here is how you do this: Run and choose the following two fields 

mysqld is 32-bit and runs good; 32-bit client connects just fine mysqld is 64-bit and runs slow; 32-bit client connects just fine mysqld is 64-bit with the possibility of crashing if code for handling 64-bit addresses was not accounted for, 32-bit client connects fine until it mysql or mysqld crashes 

resembles a natural join where nothing matches on the cardinal table, so the count is correct. Your second query 

If these are too small, the tmptable goes to disk quickly. If these are too large, the tmp table goes to quickly when the limit is surpassed but creates intermittency due to moving the large in-memory tmptable to disk before completing the tmptable's usage. So, you need to perform a tight balancing act with these tmp table variables. These variables also have the same per-thread constraint that @DTest mentioned in this answer. BTW in theory a sort buffer is a tmptable in itself, though governed by a different session option (sort_buffer_size). Since you are sorting with a group-by column and not a pure table-established column, temptables are somewhat unavoidable.