I am reading MWG's explanation in Chapter 3 when showing continuous preference relation implies the existence of continuous utility function. First, the authors show $u(.)$ is continuous by using the definition that the image under $u(.)$ of a convergent sequence is convergent. Consider a sequences $x_n\rightarrow x$. They first claim that $u(x_n)$ must have a convergent subsequence. I understand the big picture: Since $x_n$ converges to x, for some large N, $u(x_n)$ must all lie in some compact set, and any infinite sequence in a compact set must have a convergent subsequence. The part I am having trouble is when they use monotonicity to show this compact set. The exact excerpt is: 

Consider a 2 player all-pay auction, bidding for $1. Each submits a bid that is a real number, thus $S_i=[0,\infty)$. The player with a higher bid wins $1, but both players must pay the submitted bid. Player $i$'s payoff function is: $v_i(s_i,s_{j})=$ $-s_i$ if $s_i<s_{j}$ ($\frac{1}{2}-s_i$) if $s_i=s_{j}$ ($1-s_i$) if $s_i>s_j$. Suppose player $j$ plays a mixed strategy in which she is uniformly choosing a bid between 0 and 1. I am only interested in the expected payoff from player $i$'s bidding less than 1, because if $s_i$>1, he would win, but also incur a negative payoff. My question: Why is Pr$(s_i=s_j)$=0 for any $s_i\in[0,1]$ if player $j$'s mixed strategy is U[0,1]? My confusion is: the PDF of player $j$ is 1 for any $s_j\in(0,1)$. So if I only consider $s_i<1$ and Pr$(s_i=s_j)$, how do I justify it becomes $0$? 

For pedagogical reason, if you are better at explaining these concepts, please share how you would go about this with an example both interor and corner solution in ECON 101 textbook situation. My strategy was from example to the graph and to show why the equality should hold leading to connecting the dots on the first order conditions of utility maximization... But this equality is hard to really spell it out on 101 level, that's my challenge. Thanks! 

I understand exactly as they sound by looking at the functional form of the object. But can someone provide why these structures or assumptions are sensible or unreasonable and why they are "convenient" or "useful"? The context can be anything consumer, producer, choice under uncertainty, game theory or GE. But trying to see why it is repeatedly coming up and why it is important or mathematically useful in many parts both in micro and macro. 

Here is my revised version/understanding why price vector is orthogonal to any vector from a bundle on the budget hyperplane to another bundle on the hyperplane: (see below for original question) 

Consider a simple static, incomplete-information entry game. Two players, $i=1,2$. where player $1$ is new entrant, and $2$ is incumbent. Player 2 can be two types: rational or belligerent, with common prior $(p,1-p)$ over her types. Action set: $A_1=\{Enter, Out\}$, $A_2=\{Fight, Accomodate\}$ When we turn this extensive form game into normal form, we compute the expected payoff for each pair of strategies $(x,zy)$ where $x$ refers to what player 1 chooses at the information set, and $zy$ refers to what player 2 chooses in case of each type. My question: When we make this incomplete information game into a complete-imperfect one, we introduce Nature and let her draw the type for player 2. However, she knows her type when she is called upon to move, so why do we calculate an expected payoff for player 2 when converting the game into an normal-form? Is this because when we collapse the extensive form into the normal-form, player 2's pure strategy set takes into account each type that she can be (rational or belligerent), thus she is also forced to calculate an expected pay off? I mean, for any pair of pure strategy set, you have to deal with two terminal nodes and their payoff, so it makes sense in this perspective, you need some sort of expected payoff calculation. But it seems odd that player 2 who supposedly knows her type also has to form expectation on her payoff. My guess is the way strategy is defined in incomplete information is that it prescribes each type of a player what she should do if this is the type Nature draws. So, as long as the cardinality of type space is greater 1, any pair of pure strategy will force each player to face more than 1 terminal nodes (eg. $(Enter, (Fight, Fight)$). It just sounds odd that all along, Harsanyi allows a player's type to be unknown only to other players, but in the end, no matter what, whether you have various types or not, the payoffs must be computed in expectation. 

Consider a game in static, complete information environment, and the following definition of a strategy never being a best response to a player: 

I want to understand the role of belief in this definition correctly. The definition of belief is given as: 

A quick response is that if the law of demand is violated, then the standard definition for substitutes and complements may or may not apply. 

Suppose a town is building a bridge, and it costs $B$. There are $n$ villagers. Each village's valuation of the bridge is private information, $v_i$. It is common knowledge that this valuation is drawn from a uniform distribution $[0,1]$. $B\in[0,1]$. Villager can only submit $0$ or $B$. If one villager submits $B$, then the bridge is built and every other villager pays their submission. If no bridge is built, everyone gets $0$. How do I construct an expected payoff a village $i$? What I got down to is having 2 scenarios: $v_i>B$ and $v_i\leq B$. But in each case, I have two possible payoffs. For the former case, 

When we look at a typical Walrasian budget set in $\mathbb{R^+_2}$, why is the price vector orthogonal to the consumption vector (e.g. any two on the slope) on the budget hyperplane? This goes back to Chapter 2 of MWG. I understand the analytical explanation using dot product. 

I had the same question few weeks ago. I attach the link below that may help you, but here is the approach I took to solidify the difference. When action and strategy differ in game theory Don't associate the distinction between action and strategy with whether the game is in normal form or extensive form or sequential or not. This can cause more confusion. When you want to define strategy, always think of "contingency". Action is a set of possible things you can do when you are called upon to move. For example, suppose you want to sell a used car as dealer. As seller, what is it that you CAN DO when you are "called upon to move"? Simple: offer high price or low price. But you immediately realize things can get complicated if, say, dealer has more information on the car's condition. You might suspect that car behind the dealer is a good used card or lemon. Although you still get to offer high price or low price at the end of the day, as player of the game, you must set a contingency plan when the car is good or lemon. Harsanyi introduces "nature" to do exactly this. The condition of car is simple: good or lemon. This is described as the state space of the game. Both players, seller and buyer, understand the ex-ante probability distribution over this state space, meaning you and potential buyer know the probability you get good car or lemon. Therefore, as dealer, you would have action space $A_1=\{H,L\}$ indicating offering high or low price. However, your strategy space would be $S_1=\{(H,h),(H,l),(L,h),(L,l)\}$ where first entry of the pair is your action when the car is good and second entry is your action when the car is lemon. It is a game plan laid out for you in every possible scenario. One good exercise may be to see if you can construct the strategy set for buyer if she doesn't observe the condition (i.e. state) of the car the nature draws. 

A great deal of time is spent distinguishing the big $U$ (von-Neumann-Morgenstern)v. small $u$ (Bernoulli Utility Function). The v.NM function maps from the space of lotteries to real number as it represents the preference defined on the lottery space while the Bernoulli is defined over sure amounts of money. Why is this distinction so important in the theory of expected utility? Also, what does this distinction enable us to achieve that is important in the expected utility theory? What is the most intuitive way to understand the expected utility theory is constructed in this way? 

I am reading the definition of a price equilibrium with transfer in MWG on page 548, 524-5. Consider two-consumer exchange economy. If social planner wants to transfer wealth, how does she achieve this? Two consumers are born with some apples and oranges. So, the social planner lets these consumers sell at the going market place of what they are endowed with. Then, does she collect taxes and transfer wealth in this way? It seems like this wealth transfer can be achieved also by directly reallocating the apples and oranges distributed among consumers. I am not exactly getting the terms like "there be some wealth distribution" or "equilibrium with transfers", "wealth transfers". What does it mean to say, "there is an assignment of wealth levels with ...."? 

This is just semantics, but MWG doesn't use the Weierstrass Theorem in its Math Appendix when using the fact that a continuous function always has a max value on any compact set. Some books appeal directly to the Weierstrass Theorm. Is there a right or wrong answer to this? Or is it more just, like I said, semantics?