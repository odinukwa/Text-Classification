Notice that using the dual basis with respect to the trace essentially seems to run into the same issues. I have looked into J.S.Milne's notes on Fields and Galois Theory and on Algebraic Number Theory as well as in Neukirch's Algebraic Number Theory, but in this regard they don't seem to go beyond calculating the discriminant. 

Bichteler - Integration Theory (with Special Attention to Vector Measures) (1973) Diestel, Uhl - Vector measures (1977) Dinculeanu - Vector Measures (1967) Xia Dao-Xing - Measure and integration theory on infinite-dimensional spaces (1972) 

Fr√∂licher, Kriegl - Linear Spaces and Differentiation Theory (1988) Gil - Norm Estimations for Operator-Valued Functions and Applications (1995) Yamamuro S.- Differential Calculus in Topological Linear Spaces (1974) Zelazko W.- Banach Algebras (1973) Barroso J.- Introduction to Holomorphy (1985) Buoni - Differentiability in Banach Algebras (1974) Coeure G.- Analytic Functions and Manifolds in Infinite-Dimensional Spaces (1974) Dineen S.- Complex Analysis in Locally Convex Spaces (1981) Mujica J.- Complex Analysis in Banach Spaces (1986) 

If $\gamma$ is smooth with $D\gamma$ of rank $1$ everywhere, then $\gamma(\mathbb{S}^1)$ is a submanifold ($\gamma$ is injective by definition and $\mathbb{S}^1$ is compact). In particular, it is a connected manifold, and we have a well-defined topological degree $\deg(\gamma)$ since it does not depend on a choice of a regular value of $\gamma$ on the image. This is one straight-forward generalization of the case $n=2$ for curves in higher dimensions. There are probably other approaches as well. Outerelo and Ruiz introduce $w(f,a)$ for continuous $f$ defined only on hypersurfaces $X:=\partial\bar{U}\subseteq\mathbb{R}^n$ (for some $U$ open and bounded). In particular, the construction does not seem to work for curves for $n\geq 3$. More generally, the topological degree appears to be defined only for maps whose domain and codomain are of equal dimension. (In this interpretation and modulo technical details, the winding number in the plane is the degree of a map defined on the unit disk which restricts on the boundary to our curve.) 

A vastly improved support for handwritten math (e.g. via digitizer pen) incl. its conversion to typeset math would be awesome! In a long run, ideally it should be able to replace LaTeX. Just think of how much of researchers' time is spent on inputting math. 

I would say, it depends on how much Differential Topology you are interested in. Generally speaking, Differential Topology makes use of Algebraic Topology at various places, but there are also books like Hirsch' that introduce Differential Topology without (almost) any references to Algebraic Topology. Having said that, topological theory built on differential forms needs background/experience in Algebraic Topology (and some Homological Algebra). In other words, for a proper study of Differential Topology, Algebraic Topology is a prerequisite. Addendum (book recommendations): 1) For a general introduction to Geometry and Topology: 

Is it already known that ${}_1F_1(a;b;x) \leq \Gamma(b)(1+|x|)^{-a}$ when $a$ is an integer, $a <0,$ and $b>0?$ If it is, what is a reference? my proof: Since the Kummer function can be written in terms of a generalized Laguerre polynomial, \begin{equation} \label{eqn:Kummer-Laguerre-equality} {}_1F_1(a;b;x) = \frac{\Gamma(1-a)\Gamma(b)}{\Gamma(b-a)} L_{-a}^{(b-1)}(x), \end{equation} when $a < 0,$ we proceed by bounding the generalized Laguerre polynomial on the right hand side. Let $n = -a$ and $\alpha = b - 1.$ Then $$ L_{n}^{(\alpha)}(x) = \sum_{\ell=0}^n \frac{\Gamma(\alpha + n + 1)}{\Gamma(\alpha + \ell +1)(n-\ell)!\ell!} (-x)^\ell. $$ Our constraints on $a$ and $b$ ensure that each $\Gamma(\cdot)$ term in the above sum is positive. Furthermore, for $\ell=0,1,\ldots,n,$ $$ \Gamma(\alpha + \ell +1) \geq \Gamma(b) \geq \min_{x > 0} \Gamma(x) > 0.88. $$ It follows that $$ L_{n}^{(\alpha)}(x) \leq 1.14 \cdot \Gamma(\alpha + n + 1) \sum_{\ell =0}^n \frac{|x|^\ell}{(n-\ell)!\ell!} = 1.14 \cdot \Gamma(b-a) \frac{1}{(-a)!}(1 + |x|)^{-a}. $$ The last equality is a consequence of the binomial theorem. The conclusion follows immediately when this estimate is used in the relation expressing ${}_1F_1$ in terms of the Laguerre polynomial. 

I evaluated an integral and obtained an expression with a Laguerre polynomial. I'd like something more explicit and useable. Are there any known simple (e.g. exponential) upper bounds on the generalized Laguerre polynomials $L_{n}^{(\alpha)}(x)$? So far I've only found some asymptotic expansions, but I'd like an actual upper bound. 

What are the standard methods of computing the rank-k truncated SVD of large dense matrices? My literature search yields results only for large sparse matrices. I assume for k small that you use a Krylov subspace method (this is what Matlab's svds does). But (empirically) how large can k get before these methods become impractical, and then what should one resort to? 

I have $A^{1/2} B A^{1/2} \preceq I$ for two PSD matrices $A$ and $B$, and I'd like to know if that implies $\|AB\|_2 \leq 1.$ The argument I was using to show this is that for any two square matrices $A$ and $B,$ it is always the case that $\|AB\|_2 = \|BA\|_2.$ I thought I read that this equality does hold in a reputable source, but I don't have access to it right now and I was unsuccessful in reproducing a proof. I know the eigenvalues of $AB$ and $BA$ are the same modulo possibly having different numbers of zeros, so I'm worried that I might have ``remembered'' something that isn't true! Any references/counterexamples for either question? 

In particular, it seems that implicitly $A_i$ are meant to be $\mathbb{R}$-subalgebras (without unit) and $A_{i+1}$ an ideal of $A_i$. On the other hand, not all $A_i$ are necessarily ideals of $A$ since in general the length of $A$ as an $A$-module need not equal $\dim_{\mathbb{R}}A$. Or perhaps $A_i$ are only vector spaces such that the quotient vector space $A_i/A_{i+1}$ still "magically" inherits multiplication from $A$? Or am I missing something entirely obvious? Thanks! 

Actually, matrix-valued differential forms are used a lot in hypercomplex analysis/hypercomplex geometry, which, as the name suggests, includes certain complex manifolds. There is a nice account of such differential forms in Rocha-Chavez, Shapiro, and Sommen "Integral Theorems for Functions and Differential Forms in $\mathbb{C}^m$" (2001) (~200 pages). The first chapter is a general introduction to (complex-valued) differential forms, the second chapter discusses differential forms with values in the 2x2-matrices, and then the book goes on into the realm of hyperholomorphy, including hyperholomorphic Hodge theory. 

I don't know about generally accepted, but $\log^{(n)}X$ seems pretty concise. It conforms to the usual notation for functional iterations and there is no room for confusion with either taking powers or using different bases, e.g. $(\log_2^{(n)}X)^k$. 

Depending on one's approach to Complex Analysis in One Variable, Cauchy's Integral Theorem is one of the first interesting results about holomorphic functions in any course. There are several related versions of it: 

Formally, the answer is "yes, of course, by simply translating all the winding number stuff in Artin's proof back to homology", but I hope it's clear by now it's not what I have in mind as reasonable. The motivation is to be able to present a general Cauchy Integral Theorem as early as Cauchy-Goursat, in particular before introducing $dz/(z-a)$. 

I am looking to learn a bit about (complex) ODEs and their interplay with algebraic geometry by some examples, but I couldn't find anything on this special case in Ilyashenko's survey on Hilbert 16 (I guess this case is too special and/or not very interesting as far as Hilbert 16 is concerned). Nontheless, it seems very natural. If we set $\gamma(t)=x(t)+iy(t)$, this amounts to the equation $$ \int_{\gamma_t}\frac{dz}{F(z)}=t $$ where $\gamma_t$ is the curve $\gamma$ "truncated" at $t$ and the RHS is in particular real. This can be taken further, for example by assuming $\gamma$ is closed and using the residue theorem to obtain constraints on (the coefficients of) $F$. 

The original problem I'm looking at is: given a bound on the operator norm of $\Lambda A \Lambda,$ where $\Lambda, A$ are positive definite matrices and $\Lambda$ is diagonal, what is the tightest bound on the operator norm of $A \Lambda^2.$ My starting point is the fact that these two matrices have the same eigenvalues, so the operator norm of $\Lambda A \Lambda$ upper bounds the spectral radius of $A \Lambda^2.$ For normal matrices, the numerical radius is the same as the spectral radius and the operator norm. While $A \Lambda^2$ is not normal, one might hope that it is nice enough that there is still some nontrivial connection between its numerical and spectral radii ( a bound on the former is a bound on the operator norm, up to a constant). Is this the case, or am I barking up the wrong tree? 

Let $n,p \in \mathbb{N}_+$ with $p \leq n.$ Let $\mathcal{P}$ denote the set of partitions of $\{1, \ldots, n\}$ into $p$ nonempty sets. How can I efficiently sample uniformly from $\mathcal{P}$? 

Let $Z \sim \mathcal{N}(0,\Sigma \otimes I)$ (so the columns of $Z$ are distributed $\mathcal{N}(0, \Sigma)$) and $A = Z'Z.$ Is there a name for the distribution on $A$? Is the density known? 

I'm looking at some statistical literature and trying to compare the results given there in probabilistic big-Oh notation with statements I'm more familiar with. In particular, I'm trying to interpret statements of the form $$ \|\Sigma_{n(p)} - \Sigma \| = O_P\left( \frac{\log p}{n(p)}\right). $$ As far as i can tell from the rather terse wikipedia page on $o_p$ notation, this means that there is some constant $C$ that is independent of $p$ for which $$ \lim_{p \rightarrow \infty} \mathbb{P}\left( \|\Sigma_{n(p)} - \Sigma \| > C \frac{\log p}{n(p)}\right) = 0. $$ Is that correct? 

The constraints can be rewritten by replacing the squares with absolute values, then you have a program like $\operatorname{argmin}_{\mathbf{X}} \|\mathbf{D}\mathbf{X}\|_F^2 + \|\mathbf{X} - \mathbf{Z}\|_F^2$ $\text{s.t.}\quad \forall i,j \quad |\mathbf{d}_{01} \mathbf{X}_i| = |\mathbf{d}_{01} \mathbf{X}_j|, \text{ and } |\mathbf{d}_{34} \mathbf{X}_i| = |\mathbf{d}_{34} \mathbf{X}_j| $ where the $\mathbf{X}_i$ constitute the columns of $\mathbf{X},$ the matrix $\mathbf{D}$ takes the differences of the consecutive columns of $\mathbf{X},$ and $\mathbf{d}_{01}, \mathbf{d}_{34}$ are appropriately defined row vectors. Then you can use the standard trick of replacing $|x|$ with $x_{+} + x_{-}$ subject to $x = x_{+} - x_{-}$ and $x_{+}, x_{-} \geq 0$ to get the equivalent program $\operatorname{argmin}_{\mathbf{X}, \mathbf{e}^{+}, \mathbf{e}^{-},\mathbf{f}^{+}, \mathbf{f}^{-}} \|\mathbf{D}\mathbf{X}\|_F^2 + \|\mathbf{X} - \mathbf{Z}\|_F^2$ $\text{s.t.}\quad \forall i: \quad \mathbf{d}_{01} \mathbf{X}_i = e^{+}_i - e^{-}_i, \text{ and } \mathbf{d}_{34} \mathbf{X}_i = f^{+}_i - f^{-}_i,$ $\quad \quad \forall i \neq j: e^{+}_i + e^{-}_i = e^{+}_j + e^{-}_j, \text{ and } f^{+}_i + f^{-}_i = f^{+}_j + f^{-}_j,$ $\quad \quad \mathbf{e}^{+}, \mathbf{e}^{-}, \mathbf{f}^{+}, \mathbf{f}^{-} \succeq 0$ By considering the Lagrangian, you can see that for each i, at least one of the $e^{\pm}_i$ will be zero, and likewise for the $f^{\pm}_i,$ so this is indeed equivalent to the original program. Concisely: at a presumed optimal point you can always increase over the value $L(\mathbf{X}^\star, \mathbf{e}^{+,\star}, \mathbf{e}^{-,\star}, \mathbf{f}^{+,\star}, \mathbf{f}^{-,\star}, \boldsymbol{\lambda}, \boldsymbol{\nu})$ by moving all the mass onto exactly one of $\mathbf{e}^{\pm}$ and $\mathbf{f}^{\pm}.$ By vectorizing $\mathbf{X}$, you can write the objective as a convex quadratic in a vector $\mathbf{x}$, and a little massaging of the constraints gives you a convex quadratic program in standard form. In terms of actually solving the final QP, I'm not sure what the state of art is, especially since performance usually depends on the properties of your problem (sparsity or structure in the Hessian of your quadratic, whether you have only equality or inequality constraints, etc.). You'd need a subject matter expert to get a definitive answer on that one. I'd personally try TFOCS if you have access to Matlab, since it's a first order solver and looks relatively easy to use (I have not used it myself).