A monistic theory of patterns can deal with facts by being many-sorted. This means that the theory has to have a proper definition of different sorts of things (i.e. types of things), but still uses the same operators to describe them. An example of this is 2nd order logic. While 1st order logic allows only for individual objects as variables, 2nd order logic allows for sets and relations of objects to be variables as well. 

Kant's proof of the existence of synthetic apriori knowledge was a response to Hume's fork and his views the problem of induction. Given the relevance of these two concepts to the philosophy of science in general and to the demarcation problem in particular, can it be said that Kant's synthetic apriori had any influence on the philosophy of science? Does it have any implications for the demarcation problem? Given Kant's pervasiveness in philosophy in general, has he had any impact on philosophy of science, not just due to the synthetic apriori result? 

Harvard philosopher Robert Nozick (who is a staunch libertarian) addresses this issue in his book "Anarchy, State, and Utopia": 

P.S: some people seem to think that emergentism necessarily implies some form of dualism or vitalism -- it doesn't, one can be a materialist physicalist and still subscribe to emergentism 

Per the OP's comments, part of the question was whether Self-fullfilling predictions are possible. This is already true of the world. Indeed the whole enterprise of modern technology and engineering is based on this premise: Science tells us that in the future we will be able to cure X disease or build Y device, so let us start working on how to cure this disease or build that device. More prosaically, forecasting in finance and in business analytics is based on the idea of predicting the most likely future values of some KPIs and then making business decisions (sales, purchases, stocks and inventory, etc...) based on those values. 

My understanding of Logical Positivists is that, following Wittgenstein, they accepted only 2 types of proposition as meaningful: 

So the argument of your radio host could be that: If materialists are justifying their position based on sense data, then they are already pre-supposing that mental (non-material) objects exist in order to be able to do so, ergo they are presupposing that materialism is false in order to justify materialism. To quote Berkeley: 

The Stack Exchange methodology is based on the original Stack Overflow, which is for CS and programming questions. For those types of questions, the answers are objective in the fact that they either solve the OP's problem or they don't. People are free to upvote for the wrong ones, and it does happen occasionally, but overall, there are enough people who know what they are talking about that the most accurate and informative replies "prevail". More often, what happens is whoever asked the question is actually going to go try out the different solutions provided, and will be able to empirically verify which one is best. They will then choose the correct answer, which helps future users in gleaning out relevant information. The Philosophy Stack Exchange and other humanities SE's are obviously more subjective and hence more susceptible to opinion/consensus biases. But ideally, we are dealing with philosophy (and other fields) as academic disciplines for which a certain amount of objectivity is possible. It is my experience that objective questions (Such as "Is Derrida considered an analytic philosopher?") tend to result in objective answers ("No, he isn't"). The onus in Stack Exchanges like the philosophy SE is really on the askers to ask the right questions, more so than on the users to upvote the right answers. 

The only sense data good enough to fool the brain in a vat would have to be real sense data, so that the brain will be living a sort of reality, it just won't be its own reality. 

However, with the exception of a few Western intellectuals who gravitated towards Buddhism, almost all scientifically minded/highly educated people who are also religious tend to subscribe to the faith corresponding to their family background: Gödel was Christian, Putnam was Jewish, scientists from Muslim communities tend to be Muslim, scientists from Hindu communities tend to be Hindu, etc....even Einstein, usually provided as the ultimate example of a renowned scientist who was also a theist, believed in Spinoza's God - and both of them came from Jewish backgrounds. If people who combine a modern scientific and rationalist (in the colloquial sense of the word) mindset with a religious outlook were objectively arriving at this reconciliation, then there wouldn't be such a strong correlation between their faith and their cultural background. It seems that there were would be more diversity and more crossovers. The fact that most people seem to fall back on the faith of their culture of origin seems to speak more to a psychological question of how hard it is to break away from cultural biases than about any coherence between a modern scientific worldview and various religious traditions. So to restate the question: Does the correlation between cultural background and religious views of those who are both scientifically minded and religious weaken the argument that modern science and a religious world view are compatible? Have philosophers of religion touched upon this question and the more general issue of how cultural backgrounds seem to be the biggest factor in determining which faith a person subscribes to? 

This is the most interesting question in this post. The other answers mention the Turing test. The Turing test is for intelligence (can a computer be as intelligent as a human), not consciousness. We do not know how to determine consciousness, and this problem has been described as the hard problem of consciousness. In fact the idea that on one hand consciousness exists, but on the other we cannot measure it or determine it using any empirical means, is used as an argument for dualism and against physicalism. The reasoning is the following: if something is physical then it can be determined using physical experiments. We know that consciousness exists, but we cannot determine its existence by any physical means, therefore it must be a non-physical phenomenon (See Frank Jackson's knowledge argument). For more details see the following posts: 

Without going into the details of Leibniz's philosophy, the general trend for that whole era (Descartes, Newton, etc...) was that science was just the elucidation of God's design. Taken in that context, the connection between Leibniz's physics and his attempt to solve the problem of evil is almost trivial. Moreover, the physics (and general scientific mindset) of the time were the precursors to the determinism that led Laplace to claim that everything that will every occur can be predicted based on the initial state of the universe. With that determinism in mind, one could argue that we are living in the best of all possible worlds, and the laws of physics along with the initial configuration of the world were specifically chosen such this world was the predetermined. My main point is that even if Leibniz didn't explicitly draw the connection between his physics and his theology, he thought that the connection would have been obvious enough that he didn't need to spell it out. 

How can one refute this argument? And how do materialists deal with perception as an event? (Not perception as qualia, but perception as the transition event from an object being just a material substance to being mental sense data?) 

Rationalism is the philosophical school of thought that the only way to reach the truth is through reason alone, since our senses (as you describe in your examples) are always fallible. Rationalism is usually contrasted with Empiricism, the position that our senses, despite being very error prone, are still the only reliable source we have. DesCartes cogito is a famous example of rationalist thinking: He imagines that an evil demon is trying to deceive us and everything is really just an illusion, even our very existence is an illusion. He then tries to prove through reason and logic alone that this is impossible, and that even though we may doubt everything else, we can at least be certain of our own existence. Similarly, Kant, who is halfway between being a rationalist and empiricist, tried to prove that some (but not all) truths about the world can be determined through reason alone. These types of truths he calls synthetic a priori. See the Rationalism vs. Empiricism debate for more details. 

You can't say anything: A hardened consequentialist might simply bite the proverbial bullet and say that, yes indeed, a small amount of slave labor is justified for the greater good. This for example was one of the justifications that pro-slavery "intellectuals" in the American South advanced in the lead up to the American Civil war. You can argue that in theory a consequentialist should accept a small amount of slavery if it benefits the greater good, but that in practice it is impossible to perform the necessary utility calculus that allows her/him to determine that the greater good achieved by the building is indeed higher than the harm inflicted on the slaves. Similarly, using probabilistic reasoning, you can argue that the harm coming from slavery is predictable and certain, while the benefit coming from the building is uncertain and liable to change (if for example a fire or an earthquake destroys the building right after it is built). Once you factor such probabilities/risk analysis into your utilities calculus, then slavery becomes an immoral choice. This what an Act Utilitarian would do (See IEP article on Utilitarianism, Act Utilitarianism vs Rule Utilitarianism) You can argue that the harm of slavery is incomparable to the harm caused by the lack of such a building, or that even if it was numerically comparable, it so much greater that it counts as infinitely greater harm, and therefore can never be justified. See Alastair Norcross, “Comparing Harms: Headaches and Human Lives”, Philosophy and Public Affairs, 1997. Sections I and II. You can argue that the long term harm of slavery due to its detrimental effects on society far outweigh any benefit coming out of the building. For example in a society where slavery is permitted, those who are enslaved or who fear enslavement might resort to violence and terrorism to avoid enslavement. Such a society would be living in constant fear of the violence that might erupt because of slavery, and this cancels any beneficial effects that cheap and efficient slave labor might provide. This would be a variation on Rule Utilitarianism, again see IEP. You can argue along the lines of G.E. Moore's ideal utilitarianism("Principia Ethica", 1903), that although a small amount of slave labor does allow us to achieve a greater good from constructing the building, there is a scenario of even greater good, where the same outcome is achieved without using slave labor. Per Moore, if such a scenario is possible, then using slave labor to complete the building is immoral. You can then argue that there will always be situations where the outcome is achievable without resorting to slave labor, hence the scenario you describe is immoral. 

Based on this statement from the authors, I would say that contemporary philosophers of mind would say that "Mario Lives!" doesn't experience emotions, since behaviorism has been pretty much refuted as a solution to the mind-body problem. In your title question you use the word "experience emotions". The way I read it is: Does the "Mario Live!" program have subjective first person experience. Closely related to the question of first person experience, and a topic that might help you more with your research, are the questions of Qualia and the hard problem of consciousness. 

First we need to know what our idea of natural intelligence is, and so far, there is no unified answer. The closest thing we have is the Turing test, but that has several holes in it and is disputed by many. Even using John Searle's definition of Strong AI, there is still a lot of room for interpretation. In short we don't know yet what exactly needs to be achieved for us to say that we have successful strong AI (Emotional intelligence? Creativity? The ability to see beyond Godel's theorem?). But we are making definite progress, even if we haven't completely defined the target. 

One of the most important defining mental features of mental states is that they are directly knowable. Indeed this is at the heart of the mind body problem: the mind is so special because mental states are knowable directly, while everything else we know about the world comes through indirect knowledge. 

David Chalmers described this as the "Hard Problem of Consciousness" (Chalmers, David (1995). "Facing Up to the Problem of Consciousness". Journal of Consciousness Studies 2 (3): 200–219.): 

Religious people regularly try to prove God's existence. However the whole point of religion is to have faith in God, i.e. to believe and trust in God without having any positive proof of his existence or actions. Their attempts to prove his existence or his miracles are useless, since that defeats the whole purpose (to believe without proof) of religion in the first place. Conversely, atheists regularly state that they reject religion because they don't believe in the super-natural. But how is the super-natural any different from the unseen or yet-to-be-discovered natural? A purely logical and empirical person from the ancient era or the middle ages would find electricity and the existence of other galaxies just as hard to swallow as angels and heavens. To say that I don't believe in the supernatural is to say that I don't believe in anything whose existence hasn't been proven yet, a view that even most scientists would find untenable. 

The problem of evaluating the truth of a proposition (including whether it leads to a contradiction or not) from a computational point of view amounts to evaluating the boolean expression corresponding to that proposition. Determining whether your proposition F would lead to a contradiction or not is the same as being able to determining whether the corresponding boolean expression is satisfiable or not. At the present time there is no known method for evaluating the truth of a general boolean expression without actually calculating the expression itself. This is known as the boolean satisfiability problem, and it is conjectured that there is no efficient algorithm for evaluating whether it has a truth value or not. The only guaranteed way of determining whether it is satisfiable or not, and determining the corresponding variable assignment, is to evaluate all possible combinations of the boolean expression. This fact that there is no known general efficient solution, and the conjecture that the can't be one, is known as the P vs NP problem. Here efficient means that it can be solved in (deterministic) polynomial time. Inefficient means that the problem is solvable in Non-deterministic polynomial time (The "NP" in NP-complete). For practical purposes this means the only way of finding a solution is to evaluate every possible input combination, which can take up to an exponential amount of time. The P vs NP problem first gained importance after Cook and Levin independently proved the NP-completness theorem in the 70s. In particular Cook was working on automated theorem proving procedures, and it was in this context that he ended up with his result regarding boolean satisfiability. There is a remote possibility that P=NP and that there is such an efficient procedure, but it is considered highly unlikely, and if it were true, the consequence would be significant for our understanding of computation and science in general. 

To compliment Conifold's answer, here's another way to look at it: Statements about number theory always end up being statements in number theory as well. Take any number theoretical theorem and replace the symbols with numbers using a suitable encoding, and you end up with an equation. Because of this, any system rich enough to encompass the arithmetic of natural numbers cannot avoid self-reference. And as Conifold points out self-reference makes the paradox at the heart of Godel's theorem inevitable. 

Dennett says in "The Intentional Stance" that: "first you decide to treat the object whose behavior is to be predicted as a rational agent; then you figure out what beliefs that agent ought to have, given its place in the world and its purpose." but can we treat an object as an agent with purpose if it doesn't have the autonomy that I described above?