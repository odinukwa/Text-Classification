ADDENDUM NOTES Long Explanation: Ontological realism is the view that physical objects exist independently of our own minds. Epistemological realism is the view that statements are true or false independently of whether we know or believe them to be true. Metaphysical realism is the view that what is real exists just as it is independently of the subjects that experience it. Realism in a general way is the thesis that science aims at truth and that acceptance of a theory includes believing that it is true. The main line of argument for realism is ‘‘explanationist’. This means, essentially, that the explanatory achievements of theories count favorably in their epistemic evaluation. If there were no truth to theory, one would be at a loss to explain, not just what is observed, but also the success of theory in explaining and predicting what is observed. Understanding why theories work as well as they do is necessary for improving them. A barrier to supposing that a realist explanation is needed is that the predictive result might also be predicted by rival theories. To generate the strong underdetermination problem for scientific rival theories, we start with a theory H, and generate another theory G, such that H and G have the same empirical consequences, not just for what we have observed so far, but also for any possible observations we could make. Quantum physics gives genuine examples of empirical equivalence. If there are always such strongly empirically equivalent alternatives to any given theory, then this might be a serious problem for scientific realism. There are non-empirical features (superempirical virtues) of theories such as simplicity, non-ad hocness, novel predictive power, elegance, and explanatory power, that give us a reason to chose one among the empirically equivalent rivals. The underdetermination problem motivate the conclusion that science can never give us knowledge of the unobservable world, and that our best scientific theories are empirically adequate rather than true. Realists argue that we need to explain the overall instrumental success of scientific methods across the history of science. But the realist demand for explanation of every regularity leads to infinite regress. Since there are many ontologically incompatible yet empirically equivalent theories, we have no reason to choose among them and identify one of them as true, thinks the non-realist. Inference to the best explanation is a rule of inference according to which, where we have a range of competing hypotheses, all of which are empirically adequate to the phenomena in some domain, we should infer the truth of the hypothesis which gives us the best explanation of those phenomena. But the non-realist thinks that some ‘principle of privilege’ is required from realists if we are to think that the collection of hypotheses that we have under consideration will include the true theory. The best explanatory hypothesis we have may just be the best of a bad lot, all of which are false. In other words this argument challenges the proponent of the realist's best explanation rule to show how we can know that none of the other possible explanations we have not considered is as good as the best that we have. Unless we know that we have included the best explanation in our set of rival hypotheses, even if it were the case that the best explanation is true, this would not make an acceptable rule of inference. The realist and the non-realist disagree about the purpose of the scientific enterprise: the former thinks that it aims at truth with respect to the unobservable processes and entities that explain the observable phenomena; the latter thinks that the aim is merely to tell the truth about what is observable, and rejects the demand for explanation of all regularities in what we observe. The non-realist thinks that empirical adequacy is the internal criterion of success for scientific activity, that acceptance of the best theories in modern science does not require belief in the entities postulated by them, and that success of modern science relative to its aims can be understood without invoking the existence of such entities. Non-realist-predictivists think that only successful predictions of previously unknown phenomena count as evidence, and realist-explanationists think that explanations of previously known about phenomena count as evidence, that the explanatory achievements of theories count favorably in their epistemic evaluation. There are many cases where the observation of one phenomenon allows us to predict the observation of another phenomenon but where the former does not explain the latter. For example, the fall of the needle on a barometer allows us to predict that there will be a storm but doesn’t explain it. There also seem to be theories that provide adequate explanations but that cannot make precise predictions. For example, evolutionary theory explains why organisms have the morphology that they do, but it cannot make specific predictions because evolutionary change is subject to random variations in environmental conditions and the genotype of organisms. Furthermore, there are cases of probabilistic explanations where the probability conferred by the explanans on the explanandum is low, so we cannot predict that the explanandum is even likely to happen although we can explain why it did if it does. Non-realists-predictivists think that explanatory power is a merely pragmatic virtue of theories and does not give us evidence for their truth, doesn't count favorably in their epistemic evaluation, explanations can be easily ad-hoc. The non-realist thinks that there is no evidence available in principle that can distinguish a theory’s truth from its utility and reliability in prediction. The realist contends that a theory’s predictive and explanatory success are evidence for it. According to the deflationary theory of truth, to assert that a statement is true is just to assert the statement itself. For example, to say that ‘snow is white’ is true, or that it is true that snow is white, is equivalent to saying simply that snow is white, and this, according to the deflationary theory, is all that can be said significantly about the truth of ‘snow is white’. Philosophers often make suggestions like the following: truth consists in correspondence to the facts; truth consists in coherence with a set of beliefs or propositions; truth is the ideal outcome of rational inquiry. According to the deflationist, however, such suggestions are mistaken, and, moreover, they all share a common mistake. The common mistake is to assume that truth has a nature of the kind that philosophers might find out about and develop theories of. For the deflationist, truth has no nature beyond what is captured in ordinary claims such as that ‘snow is white’ is true just in case snow is white. A central characteristic of truth – one that any adequate theory must explain – is that when a proposition satisfies its “conditions of proof (or verification)” it is regarded as true. It is often said that what is most obvious about truth is that truth consists in correspondence to the facts — for example, that the truth of the proposition that the earth revolves around the sun consists in its correspondence to the fact that the earth revolves around the sun. The so-called correspondence theory of truth is built around this intuition, and tries to explain the notion of truth by appeal to the notions of correspondence and fact. But it is far from clear that any significant gain in understanding is achieved by reducing “the belief that snow is white is true” to “the fact that snow is white exists”. Deflationists argue that truth is a shallow (sometimes “logical”) notion, a notion that has no serious explanatory role to play: as such it does not require a real theory, that would have to take the form of a genuine generalization. 

To prove that a "theory is a true theory" we cannot use the "falsifiability principle". Popper's does not seem to answer Hume's question. The theory that the sun rises every day may have survived falsification yesterday, but is this a reason for believing that it will survive falsification tomorrow? That was what Hume wanted to know. Popper retorts that induction is not justifiable. That a theory has been corroborated in the past "says nothing whatever about future performance." Popper wants to say that it is possible to avoid assuming that the future will, or probably will, be like the past, and this is why he has claimed to have solved the problem of induction. We do not have to make the assumption, he tells us, if we proceed by formulating conjectures and attempting to falsify them. He says that, as a basis for action, we should prefer "the best-tested theory." This can only mean the theory that has survived refutation in the past; but why, since Popper says that past corroboration has nothing to do with future performance, is it rational to prefer this? Fundamental is the question how, even in theory, we can possibly prefer one hypothesis to another, or take one as a nearer approximation to truth than the other, if past corroboration has no implications for the future. Without the inductive assumption, the fact that a theory was refuted yesterday is quite irrelevant to its truth-status today. So demising the inductive assumption makes nonsense of Popper's own theory of the growth of scientific knowledge. Theories or hypotheses can only be subjected to empirical testing in groups or collections, never in isolation. The idea here is that a single scientific hypothesis does not by itself carry any implications about what we should expect to observe in nature; rather, we can derive empirical consequences from an hypothesis only when it is conjoined with many other beliefs and hypotheses, including background assumptions about the world, beliefs about how measuring instruments operate, further hypotheses about the interactions between objects in the original hypothesis' field of study and the surrounding environment, etc. For this reason when an empirical prediction turns out to be falsified, we do not know whether the fault lies with the hypothesis we originally sought to test or with one of the many other beliefs and hypotheses that were also needed and used to generate the failed prediction. It forms a criticism of methodological falsificationism. Holist underdetermination ensures there cannot be any such thing as a “crucial experiment”: a single experiment whose outcome is predicted differently by two competing theories and which therefore serves to definitively confirm one and refute the other. Our response to the experimental or observational falsification of a theory is always underdetermined in this way. When the world does not live up to our theory-grounded expectations, we must give up something, but because no hypothesis is ever tested in isolation, no experiment ever tells us precisely which belief it is that we must revise or give up as mistaken. All of the beliefs we hold at any given time are linked in an interconnected web, which encounters our sensory experience only at its periphery. references: Peter Singer, Quine, Pierre Duhem 

Although not a topic that is the result of philosophy, the empirical study of happiness can have some consequence for philosophers who like generalizations about the human condition. There may be implications for the philosophical issues of free will, meaning of life, and the ethics of utilitarianism, but these are issues that are beyond the scope of the question. "Space must not be filled" with negative experience. The set point of happiness is more due to genetic characteristics of psychological adaptability to positive and negative events than objective occurrence of events. In general terms the feeling of well-being has a majority of genetic influence and not a decisive influence of the environment: 

After Lukas editing his question, and by his comments too, I realize it will be difficult to make him see what is accessory and what is the core in the criticism of Popper. I leave to others to do so. It is repeated too by many that this site is not a forum for debate. Therefore now I edit my answer and I will stick only to the main core question: 

Philosophical-zombie, the p-zombie, is a hypothetical being that is indistinguishable from a normal human being except in that it lacks conscious experience. When a p-zombie is poked with a sharp object, for example, it does not feel any pain though it behaves exactly as if it does feel pain. The possibility of something physically identical to a human but without subjective experience assumes the possibility that the physical characteristics of humans cannot be what produces those experiences. When concept of self is deemed to correspond to physical reality alone, philosophical zombies are denied by definition. P-zombies in an physical world would be indistinguishable from the observer, even hypothetically. The idea of the p-zombie in a physical world is meaningless: The zombie concept is self-contradictory in that, since zombies ex hypothesi behave just like regular humans, they will claim to be conscious. A zombie producing the same reaction as a person would be perceived as a person having complex thoughts and ideas in their head indicated by the ability to vocalize it. If zombies were without awareness of their perceptions the idea of uttering words could not occur to them. Therefore, if a zombie has the ability to speak, it is not a zombie. One is inclined to believe either that anyone including oneself might be a zombie, or that no one can be a zombie – following one's own conviction that being, or not being a zombie is just a product of the physical world or not. From Wikipedia 

The word philosophy is of Ancient Greek origin: meaning "love of wisdom." However, the etymology is not much help. The use and meaning of the word "philosophy" has changed throughout history. 

The question hinges on whether color is a product of the mind or an inherent property of objects. Another way to look at this question is whether blue must be blue for all people, or whether the perception of that particular color is assigned by the mind. For example, someone has learned to associate the word "blue" with what his mind sees as green, and so he calls the sky "blue", because for him the color green has the name "blue." This extends to all areas of the physical reality, where the outside world we perceive is merely a representation of what is impressed upon the senses. Why will never be known if the colors and forms experienced perfectly match between person to person? Color is representation, cannot to be intrinsic to object. Can we select one among perceptual variants that should be regarded as veridically representing the color of the object? There are analogies. Magnetoception is a sense which allows many animals to detect a magnetic field to perceive direction, altitude or location. How pigeons represent magnetic fields is not intrinsic to magnetic fields. We cannot know how does it feel to bees to see UV wavelengths representation and bat feel echolocation representation. Instead of a reductive physicalist account of color what we can do is to define in behavioral functional ways, comparative studies, so that it applies to honey bees, humans, pigeons, and so on. The question is akin with “Is there a world independent of human beliefs and representations? Is such a world empirically accessible, or would such a world be forever beyond the bounds of human sense and hence unknowable? Can human activity and agency change the objective structure of the world?” The question presupposes that it makes sense without a reference framework. If there are no mind independent properties that satisfy the requirements for being color, how did the ordinary concept develop? Through practical results of equivalence of representations. Some paraphrases from Stanford Encyclopedia of Philosophy and Wikipedia