To get the actual differences, you'd need to run and determine the changes by the SQL queries it generates. 

Drop the table on the 5.7 slave. Log out of mysql, run to recreate the dropped table. Log back in to mysql instance then / all should be good. The problem was when you source dump.sql it somehow changed the table definition in 5.7 hence the error you were getting. A simple test I tried was on a working 5.6 master to 5.7 slave repl, I dropped the table on 5.7 and recreated it with 5.6's table structure and got the same error when I started slave replication. 

If you want to backup database forum and all of its tables you should use this 'simplified' command: 

...and from the result deduce the subset of invalid gene names. Maybe it's just me, but I pick up some potent code smell from such huge SQL statements. Bottom line, I don't have an entirely satisfactory solution, but since the problem must be very common, I figure that there must be standard solutions for it. If this is correct, please let me know what they are. BTW, assume that access to the DB is read-only. In particular, please rule out any solution that involves creating temporary tables. Also, in case it matters, ours is a MySQL database. 

This "non-solution" consists of defining some distinct values of that can somehow be recognized as , and redefining to make use of this information. For example: 

Create a empty database with the same file layout, including names, filegroups, location, etc, everything but data Take the missing files offline Take the database offline Use the data files you have saved to overwrite the empty data files Bring the database online 

From the sample code I understand that #1 is what you want. In that case, do you really need a WHERE NOT EXISTS? Could you just do something like: 

I do not see this as the most desirable implementation. Using a Foreign Key constraint to enforce correctness is (in my opinion) much better than writing code to handle such issues. However, regarding your question, Yes, TableA can have both an trigger and an trigger. (In fact it can have several triggers.) $URL$ outlines some rules, including: 

...because there's no way to determine the appropriate value of for those rows where is . I'm looking for a normalized schema that would enforce the new set of constraints (and thus allow data like that shown in Listing 2). 

I'm looking for a way to enforce this constraint. (In case it matters, I'm particularly interested in solutions applicable to SQLite3 and PostgreSQL.) EDIT: Just to be clear, the description above does not preclude the existence of rows in table whose value of is not mentioned at all in table . For such values of there is no value of at all, principal or otherwise. It is only for those values of that appear in table that there must be one and only one row in table having . 

How your organization views your (person or businesses) will help you determine what is the best approach for your business. What would I do? I would tend would separate the from the more complex . When needed a summary of the totality of Orders, Subscriptions, and (returns, reshipments, etc) can be produced for your company and for your customer. 

Depending on your circumstances and how you feel about the overall process, you might want to rebuild the Materialized Views every night during a slow period. 

Then to grant access to the CustomConnection endpoint to the SQLSupport group (as an example), you could use something like this: 

SQL Server B-Tree indexes are not binary trees, but balanced trees. This structure allows a tree traversal which is much more shallow, and therefore likely results in a more rapid index search. This also affects the scope of updates to the indexes. See one explanation at: $URL$ 

...but it made no difference: the output of remains unchanged. Is there some other way to optimize this query? 

and detect the condition where the search fails. This means performing one such query for usually hundreds, often thousands, of genes. (BTW, most of these queries are usually performed by scripts written in Python, R, Perl, MATLAB, etc. using those language's DBI facilities.) Alternatively, one could concoct a (typically huge) SQL statement of the form 

My "non-solution" My "non-solution" to this problem is a hard-to-maintain hack. I post it here for three reasons: 

In the research group where I work, we must solve following problem hundreds, maybe thousands of times every day: given a set of putative gene names (typically a few hundred of them), flag those that are not in our (MySQL) database. This problem is solved in a number of ways by our various applications and scripts. I would like to optimize the process. The simplest approach, of course, is to iterate over the list of gene names (after removing any duplicates, of course), and for each gene name perform something like 

First of all, depending not just on the number of rows but also on the total size of your table (based on the average row size) , it may not be excessive to create a new Foreign Key. Especially if scheduled properly. However, it may well be too heavy a change. In that case, you could consider creating an Intersection Table like: 

The problem is, you should not be trying to create an ever-growing set of queries in this manner. Of course the first step in your example fails on the second run, since the column has already been dropped. There is nothing to restore and there is no error handling to cope with the missing column. I cannot fathom why you would want to build up your queries in such a manner. If your goal is to record every query that you run, then insert the code into a table that records the time and the code that you run. But do not expect to run all the commands without errors unless you have scripted the code to also deal with each exception that may arise. 

Well afaik you can't if you rely on mysqlsandbox to orchestrate it for you. But you can create a master-master for M1 <-> M2 and then create two standalone instance and configure each one to slave off of one master. It's pretty easy since you have all replication user created "rsandbox". 

Yes, of course. Standard replication configuration is master and single or multiple slaves. If you use MariaDB Galera cluster you can point your applications to a single node and the other two serves as slaves. 

Optionally, run ANALYZE TABLE on the affected table to re-calculate its statistics. Make sure you're aware of the effects of running ANALYZE TABLE on a busy server. 

with --no-check-binlog-format you would not be able to checksum from master to cascading slaves aside from master's immediate replicas, --no-check-binlog-format also sets the tool's session to STATEMENT format but does not change the global status. there should not be any issues when you use the option but we recommend you test them first. 

Overall, the database metadata and the user data that you insert/select/update/delete are in general protected by Transactions, Isolation Levels, Latches, and Locks. Since your question is about metadata, a simple example: 

Use your computer's mouse to move the cursor to the first character to be included. Next Hold down and continue holding down the key, then move the mouse to include the last character to be included. Continue holding the key, then press the key which will execute the highlighted text. 

If you need other file types, you will need to include them also in loading the table. One SQL Server example is ".ndf" used when adding files to the database beyond the primary .mdf. I included this in the dataset. For a server I tested with I got the following. Note that RLFJUNK is not really a database file, it is just named like one: 

no two rows may have the same -value but different -values; the -value is never empty; the -value is never emtpy; 

1 Another way to express the same constraint would be to say that the following two queries should always produce identical outputs: 

But such a listing would not be possible with the schema shown above. Even if the constraint were removed from the definition of the column, the closest we would get is Listing 3 

This definition misses one constraint that must satisfy. In English, this constraint could be described like this: 

to clarify the situation described in the question above; to provide table-initialization code that responders can use to test their proposals if they so wish (it's in fact the code I used to generate Listing 2); to give an example of the sort of hard-to-maintain hack that I'm trying to avoid. 

I understand your problem to be how to successfully convert the string into a DATE value. An undelimited string of integers is assumed to be Year-Month-Day order. (And, of course, I agree with the comments that dates should be stored in DATE data types in the database.) Reviewing the MSDN CONVERT documentation does not show a built-in conversion for your string, but it is easy to work around. $URL$ -- CAST and CONVERT I changed the month to 8 to make it easier to double check. Using the CONVERT style option 3, you can do the following: 

Reviewing your table definitions shows that you have indexes matching across the tables involved. This should cause the joins to happen as quickly as possible within the limits of join logic. However, sorting from multiple tables is more complex. In 2007 Sergey Petrunia described the 3 sorting algorithms in order of speed for at: $URL$