If a file named exists one level above the root, then the server will be in maintenance mode. (This is the test). Except that if there exist a cookie named with the value , the check described above will be bypassed and nginx will serve the data as if the server were not in maintenance mode. (This is the test.) 

Building a configuration using external tools is the way to go. I've used + . I use a custom Python script in one of my projects. The choices are plenty. 

The site is always started or stopped through Monit so as to avoid the possibility of race conditions, or Monit working against me. (e.g. I stop a service and Monit keeps starting it back.) The problem is that it takes much more time than necessary to bring the whole site up. If I instruct Monit to start the site, then once Monit has figured the dependencies, the sequence of actions on Monit's part is: 

(Emphasis added.) Going by this, unless is responsible for rotating the log, then will be ignored. I thought about maybe configuring logrotate to perform rotate operation that effectively does nothing but I'm not seeing anything among the configuration options that would easily allow that. 

Mostly sendmail.cf and rewriting rules are considered so geeky and arcane that very few people fiddle with them; the whole sendmail.mc/M4 mechanism provides a more "user-friendly" front end to sendmail configuration. Most folks should stick exclusively to the sendmail.mc/M4 mechanism and never directly modify sendmail.cf -including producing modified rewrite rules- at all. If the sendmail.mc/M4 mechanism won't quite work for you and you want to "tweak" a few rules in sendmail.cf, you may be able to do it with the LOCAL_NET_CONFIG and LOCAL_RULESETS capabilities of the sendmail.mc/M4 mechanism. If you want to make major mods directly to sendmail.cf, maybe even dispensing with the sendmail.mc/M4 mechanism altogether, you're beyond what 99.44% of admins need to do, and may need some custom editing of Makefiles and/or shell scripts to implement your desired scheme. (Beware that on some systems will invoke the Makefile which executes the sendmail.mc/M4 mechanism, so overwriting of sendmail.cf will occur more often than you may expect.) (To be brutally honest, I too sometimes find having this two-level indirect sort of front end interface a little awkward and frustrating: sometimes I know what I want, and I know how to make sendmail.cf do it ...but I can't figure out the "right" way to say it with the sendmail.mc/M4 mechanism. And advice for different versions of BIND is sometimes more misleading than helpful. What often works for me is using a few words from the desired sendmail.cf in a grep command to turn up the "right" sendmail.mc/M4 feature: .) Per the sendmail README (perhaps /usr/share/sendmail-cf/README) you can cause the M4 sendmail.mc->sendmail.cf mechanism to insert arbitrary additional rewrite rules literally by specifying LOCAL_NET_CONFIG and/or LOCAL_RULESET (and LOCAL_RULE_3, LOCAL_RULE_0, LOCAL_RULE_1, and LOCAL_RULE_2) in sendmail.mc. For example, to insert a delivery rewrite rule: 

Looking at my own monit logs, I see this happen if for some reason Monit is trying to start a service for which no method has been declared. Here's an example from the documentation: 

Since you have not mentioned anything about your cache configuration in Nginx, I'm going to assume you did not set a cache, and this would explain why your header has no effect for dynamic responses. When it comes to static resources, Nginx has a really easy way to determine how to handle : it compares the time in the field with the time the file was last modified. No problem there. When you want Nginx to do the same with dynamically generated responses, there's nothing for it to compare against, unless you turn on caching. By default, Nginx does not remember the responses it has served. When you turn caching on, Nginx has a way to compare an incoming request with a response previously given, and thus has a way to use . I've found this article really useful to learn the finer details of setting an Nginx cache. 

Starts . Sleeps for 2 minutes. Detects that is running, so start the two workers. Sleeps for 2 minutes. Detects that the workers and redis are running, so start . [Sleeps for 2 minutes] [Detects that is running.] 

Before I take any of these steps, does anyone have any ideas on anything else I can try to get these two servers talking again? 

We have a utility scheduled in Task Scheduler on Server 2008 R2 that just ran into an issue I haven't dealt with before. The utility hung up (no activity for a day), and selecting end did nothing to end it, so I had to manually kill the task through task manager. After I did, I tried running the task in debug mode from my machine, and it went through until a dialog box popped up. Once I cleared the dialog box, the utility completed its run and exited cleanly. The utility doesn't have any dialog boxes of its own, as it is designed to run under task scheduler, so the dialog box was a surprise to me. It came out of an API we are using, and I took care of the issue that it presented to me, but now I want to know if it is possible to have task scheduler detect and handle these dialog boxes, or if I need to add some extra code to handle the possibility of these dialogs appearing. 

We can use CTRL-ALT-DEL to get to the task manager, and from there run explorer and other programs to get into things to look, but this is really baffling me and our admin. Does anyone know what could cause all of this to happen at once on so many machines? Thanks. Edit: Seemed to be fine for a week, but it's back. Some machines have varying degrees of the above symptoms. 

(Emphasis added.) So it looks like your Django setup does not have caching turned on. I suggest you turn on per-site caching. If you do this, Django will generate in its response the headers that Nginx needs for caching. Another option would be to use the option in your Nginx configuration. I used a setup similar to yours and replicated the behavior you got, then I added which tells Nginx to cache responses that have any status code () for 5 minutes . Once, I did that, I got cache hits. 

I've bracketed the last 2 steps because they are practically moot since the site is effectively up and running before the last 2 minute interval. The 2 minute sleep is the default polling interval that Monit uses to check on services. I know that I could reduce this interval so that these services are always polled more frequently. For instance, I could do 

Here is an illustration of my prose description above. After removing things that are not pertinent to the issue, the Monit configuration is like this: 

I'm using Monit to monitor various processes that need to be up and running as a group for a web site to work properly. To bring up or bring down the site, there's a definite order by which the processes must be started or stopped. The dependencies are as follows. (The names have been changed to protect the innocent. I use more descriptive names in the real configuration.) 

We have a number of client machines on a domain that have decided to start exhibiting some strange problematic behavior this morning. All machines are Win XP SP3, fully up to date with patches and symantec av. Several different virus scanners have been tried (separately, of course), and nothing found. The symptoms of the issue are: 

So far nothing has worked, and the only other ideas that I have (but am not sure I want to try except at last resort) are 

I have a N-Tier system for our clients to access data, and we're finding that our current logging system (built into the server application) is insufficient for storing all the data we need. Now, I need to find a new solution for saving and storing logs, and was looking at two different options that I could find: using a remote syslog setup, and rolling my own system. The problem with a remote syslog system is the 1024 character limit, and a roll-my-own system is undesirable due to stability issues. Ideally, I'd like to have a system that I can just fire off the log entry from the server and forget about it. Does anyone know of any other options I have available? 

Splunk looked pretty good, but we couldn't justify the price compared to a roll-your-own, so I had to roll up a basic logging server using a UDP connection. Fortunately, a 64k size limit gives me the ability to send 99%+ of my log messages through with just one UDP datagram. 

The usual mantra: "what's changed?" By any chance have you fiddled with /etc/resolv.conf, maybe trying to tighten down the timeout a little? (Or is it possible the machine that's running BIND is quite a bit more heavily loaded and significantly slower than it was at first?) Only a network trace (wireshark?) would tell for sure, but it looks to me like the first request for isn't being returned fast enough, so the resolver is timing out and then trying (append "domain" to whatever ...even if it's a silly duplication). That second query probably never did work right even before (possibly because of the missing trailing dot mentioned in another response), but it didn't matter during your initial testing because the query never got sent anyway. Now the query is being sent, and tickling the incorrect behavior that was latent in your BIND configuration all along. Try turning the in /etc/resolv.conf way up and see if it stops happening. (Or turn the option way down so it tickles the problem all the time, then fix the root problem, then turn the option back up to a reasonable value.) 

However, this mechanism is for "tweaking" the existing rewrite-rule framework but not for making completely arbitrary changes to rewrite-rules. Rules using LOCAL_NET_CONFIG will always be inserted at the same place: halfway through ruleset 0. And they can't be wildly different from what was there before such that delivery no longer approximately matches the assumptions made by the existing "parse" functionality. New rulesets (subroutines) from LOCAL_RULESETS will either be called only by your inserted rules, or be called directly by the sendmail program itself depending on specific (and possibly obscure) subroutine names and sendmail.mc FEATURE specifications. And extensions to existing rulesets (subroutines) from LOCAL_RULESET can add new functionality, but probably cannot change existing functionality, as a match and "return" by an existing earlier rule will terminate execution of that ruleset before your additional rules are even reached. Nevertheless, this may be adequate for what you want. If you do this, use the test mechanism to make sure it's behaving the way you intend. Remember, your "style" should be to compose your new rules in such a way that they fit seamlessly into the existing ruleset framework (rather than making arbitrary changes with little consideration for the existing framework); it's rather like adding a new feature to existing code that was structured by somebody else. The distributed rewrite rules are very good at handling not only mainline behavior but also edge cases (MX for individual hosts? Masquerade exceptions? UUCP connectivity? aliases? etc.?); hopefully your added rules will be similarly comprehensive. 

I have a fairly simple server setup for which the configuration at the end of the answer will do the following: 

This service has the and method defined. You do not specify such methods for your service, so they are undefined and Monit cannot do anything if somehow it is requested to , , or (which is a third method) the service. You don't need to define them if Monit is not actually going to be tasked with starting or stoping the service. I have a disk space test where the methods are not defined, and it works just fine. 

It looks to me like the issue is that the upstream server is just not sending response that contain an expiration date () or a cache validator (for instance, ). (The cookie expiration time has nothing to do with caching.) The HTTP 1.1 spec says: 

I would also have to change the length of the polling cycle to something smaller so that a cycle is less than 2 minutes. However, I don't want Monit to always poll these services more frequently. I'd like Monit to only poll services more frequently when it is in the midst of waiting for a state change. Say, if Monit has started a service and another service depends on it, poll at a 5 second interval rather than 2 minutes. I'm not seeing any way to configure Monit to do this, but maybe I missed something.