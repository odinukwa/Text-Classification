You will need to install a fresh copy of MySQL and drop the raw data files into the new installation's Data Root, and then start the MySQL service. 

If you absolutely cannot add a column to your schedule or employee to reference the shift in question explicitly, you could make assumptions regarding the length of time between a log in and a shift start to determine this. 

To address the question of why test can from tables without a , it is because you have not explicitly run for the ability to connect to your database(s) from , and then explicitly run for your user: 

If you lack DBA access (and responsibility for tables you lack access to) Query ALL_TABLES checking if IOT_TYPE is not null, otherwise query DBA_TABLES where IOT_TYPE is not null. 

Once that is done, you would for your user within that database your tables and other items you wish to prevent the user from accessing, and then explicitly for the views. Note that user here could also be role, which multiple users could then be added to. 

EDIT: One additional point. You have to very precise while making us the if logic over here. As the same procedure needs to be called thrice, if may have an performance impact depending on what logic you are trying to implement. If possible make use of the same if block to incorporate all logic for the specific return scenario and keep the generic part in the head. 

You can make use of the procedure to get the logical foreign key information. But the limitation is you have to execute is by passing the table name as the input parameter. More info for the same can be found at below MSDN library. sp_fkeys Alternatively you can make use of below query to get all the tables from sys.tables and check if the same table object_id exists in the sys.foreign_key_columns. 

We had a SQL Server 2008R2 Enterprise edition for our database to support a front-end application. We never had any timeout issues before. Recently the company decided to upgrade the database in to SQL Server 2014 Enterprise edition with 2 node always on cluster setup. The new server has better CPU, Memory than the old server. After the upgrade I made all the necessary modifications, Checking Database consistency, run DBCC UPDATEUSAGE, update Statistics, index rebuilding, recompiling the stored procedures and so on. The database switching and migration all went well. However, our users start complaining about timeout issues. I have been reviewing different articles,blog posts and made some modification like changing the connection string and add MultiSubnetFailover = 'True', which seems helped a lot and minimize the frequency of timeout but still the issue is there. Does anyone know what can cause this issue and how to resolve it? I would highly appreciate your suggestions and recommendation to resolve this problem. 

Considering you have to create a single procedure to deal with three result sets, below is the solution. But as Aaron Bertrand have suggested in comments, if possible try having three different procedures for three different result set. If three different SPs is not accepted due to complex logic or architectural limitation, then 

I guess you can try something like below. This is combination of identity column primary key with the computed column. Hope this helps. 

I will suggest to have a table valued function. This function will accept your string as an input parameter and then return a table by splitting the inputs separated by ";" in different rows with an index ID. You can use this function internally with you logic and determine the MAX(Us) from mapping table. Below is the sample example for the function. 

You didn’t use compression on secondary and applied compression when you took the backup on primary server. As you already mentioned you were using Dell Lite Speed, which has different algorithm and compression level which also make a difference in your backup file size. 

That is normal. It is just indicates you that you are on the secondary server and the role is taking care of by the primary node (the one without the question mark). If it was a 3 node or more cluster you might see the question mark on all node expect the primary. When it failover you will see the reciprocal of this on the other server. 

For your first question, yes you can use the same environment (Windows: 2012 R2 Standard and SQL 2014 Enterprise Edition) but the configuration should be changed. During failover clustering, primary and secondary servers shares the same resources or drives, this didn’t work for Always on configuration, and both primary and secondary replicas has to have their own drives. For your second question, it depends on your preference and available resources, if you think that it’s easy just to reset drives on both servers and change configuration you could do that. If you have sufficient resources, space in SAN and feels more confident to start a fresh install you might chose the second option. Concerning about the licensing. Assuming you are planning to use secondary node only for disaster recovery or short maintenance time, you need licensing only for a primary node. However, if you are planning to query from secondary node, you are also required a license for the secondary node too. 

If you are just migrating the Schema itself, and not any of the data, Index Fragmentation of your user database tables should be irrelevant. The instructions in the migration script will come from system database tables holding the metadata for your user database/schema. 

One of our production systems has exhibited a problem with a single insertion statement into a temp table from our user database. When I comment out the insert/select, the stored proc in question runs in a timely fashion, so I am confident in my isolation of the problem. The series of stored procs invoked basically grinds to a halt when I un-comment the insert/select in question. I cannot see anything in Top Transactions by Age in tempdb or any of our user databases. I do not see anything in Activity Monitor that deviates from Activity Monitor's information when the database is "at rest", other than CPU being flatlined at ~20%. The behavior is as follows: when I setup and then execute the reproduction case, upon arrival at the insert/select in question, I see an SOS_SCHEDULER_YIELD and there is an ENCRYPTION_SCAN. About five hours later, I will see processing of our stored procedure resume and the activity will complete (I put quick and dirty log statements around every distinct operation). I also replaced the variables in the select portion of the insert with the values as executed, and ran the selection query itself, and it returned in five seconds. The user database in question has FALSE as its encryption enabled value, as does tempdb. The operation in question happens over about 65k rows of data, and I have tried it with only 1k rows, and the behavior persisted, although the time it took was far less. A single user database is the only instance of this behavior. I have reproduced it locally over a backup of that user databse. We have about 70 other users of the software that do not exhibit this problem. Given the above information, my question is, why is processing of our stored procedures stopping? As it is probably optimistic to expect a precise answer, what is the correct step to debugging this? Perhaps there is something in one of the DMVs like dm_tran_locks, dm_exec_requests, dm_tran_database_transactions, dm_os_schedulers, dm_exec_sessions that, while they have provided me with some information, I am not interpreting or understanding the output in a way that points toward a solution. Below is the insert/select in question: 

The size of the database is always exactly the same on both primary and secondary replicas. The difference you are noticing on the backup file size could be because one of the two reasons 

It depends on your company RPO and RTO. If it is ok or acceptable to lose some data you can just switch your database recovery mode to simple. But you have to know that you will no longer be able to perform a point in time restore. The second and safer option is to keep your database in a full recovery mode and take more transaction log backup 

You will have at some down time in you application or web (whatever accessing the database). You need to change the connection string. AOA group connection string uses the listener or AoAgroup. When you switch back, you need to use regular connection string FQDN of your server or IP of your address. You might also need to remove the server from the cluster. When you failover databases under your secondary server remain under no recovery state. Databases in your primary server will be online but sometimes (especially if you have really big database) if there is some transaction log left and during the failover, your database will hang up under suspect mode. 

What we have understood here is you want to migrate selective data from selective tables from SQL 2008 server into SQL express edition. Have you considered using the import/export data feature on the SQL management studio? Import/Export wizard can be accessed by logging into server using the SQL Management Studio. Here is the link to MSDN library. You can select the source as SQL 2008 server (production) and destination as SQL Express Edition (development). And then map the required tables and columns. If required, truncate the tables from the development environment first if you want to have a clean data. Once data is migrated, you can perform the update queries to remove/mask any personal or confidential data. Let me know if this serves the purpose else we will delete the answer later and will think something else. 

As the error indicates you, your secondary database is not ready for log shipping or it is online. Before you start the actual log shipping process, you need to make secondary database ready for the log shipping. Either you can leave the secondary database under restoring mode and then let SQL Server take snapshot of your primary database, or you can take a full and transnational backup of primary database and restore it on your secondary DB using no recovery mode then continue your log shipping process. 

That is normal. When you setup a database mirroring the mirror database is on no recovery/restoring mode and copies and run transaction executed on primary server. Then when you remove the database mirroring you just stopped those transaction to be transferred and nothing is happened to bring it back to recovery mode. If you want your secondary (mirror) database to be active you have to execute. 

As shown in Max Vernon's screenshot in his answer, you must allow TCP/IP connectivity for remote connections. Also, if you are not allowing traffic to the default instance (TCP 1433) that would also prevent connectivity. If you are trying to connect to a non-default (named) instance, you must have the port for that instance open as well. If your connection string for the non-default instance uses port number, that should suffice, however if you are using the name of the instance in the connection string, you must open UDP 1434 and ensure that the SQL Browser service is started. Disabling windows firewall and testing might help shortcut troubleshooting - if it works with firewall disabled, you know it's in port openings. 

I do not know of any tables or charts that document this. In general, MySQL Client is backwards compatible, and MySQL support indicates that 5.x clients can communicate with 4.x and 3.x servers. 

I finally find out the problem. After days of straggling I checked the SQL Server report and noticed that there were very large occasions of autogrowth on temp db database. The cause of the problem was, after the database migration to our new server the system database file size was not configured and tempdb had a way to less file size than what it supposed to have. It looks like whenever an autogrowth operation occurred on tempdb, the query is forced to roallback and cause the problem. I just change the file size as well as the file growth size. Now it is working like a charm and no issues since then. 

The performance issue could be because of different reasons. After you restore the database, make sure to check and if necessary to update the statistics, Index fragmentation level, and the query plan cache which usually has significant performance influence after a database restore.