Such simple adjustment is not possible. First, take the logarithm: consider new random variables $y_i=\log x_i$. Their ordering is the same, but correction is now additive rather than multiplicative: you change $y_i$ to $y_i+c_i$ where $c_i=\log k_i$. Assume that the distribution of each $y_i$ is normal. The natural choice is $c_i=-E(y_i)$, so that the adjusted distributions are centered at 0. By symmetry of the distributions, having the same mean is equivalent to the property that, for each pair $i,j$, the probability that $y_i+c_i\ge y_j+c_j$ equals 1/2. So setting $c_i=-E(y_i)$ is the only way to go if you want the uniformity of the minimum index for every subset of the variables. But this does not always work. For example, consider $N=3$ and assume that $y_1$ is concentrated near 0 (i.e. has very small dispersion) and $y_2$ and $y_3$ have identical distributions with very large dispersion. Then the events $y_2\ge y_1$ and $y_3\ge y_1$ are almost independent, so the probability that $\min\{y_i\}=y_1$ is approximately 1/4, not 1/3 as desired. For topological reasons, for every collection of distributions there exist adjustment constants such that the minimum index is distributed uniformly. But, as shown above, they depend in a strange way on the entire collection (i.e. you would need to recompute them if you remove one of the variables). And they are probably hard to compute. It is better to adjust $y_i$ both additively and multiplicatively so as to make all normal distributions identical. In terms of the original variables, you transform them by $x_i\mapsto k_ix_i^{p_i}$ where $k_i$ and $p_i$ are computed from $E$ and $\sigma $ of $\log x_i$. 

This is not true for $n=2$. Represent $\mathbb S^2$ as the cylinder $\mathbb S^1\times[-1,1]$ with two discs $D_+$ and $D_-$ attached to the boundary components $\mathbb S^1\times\{1\}$ and $\mathbb S^1\times\{-1\}$, resp. Denote by $\mathbb S^2_+$ and $\mathbb S^2_-$ the "positive" and "negative" hemispheres: $\mathbb S^2_+=(\mathbb S^1\times[0,1])\cup D_+$ and $\mathbb S^2_-$ is the opposite. First we define $g:\mathbb S^2\to\mathbb R^2$. Consider a smooth $\infty$-shaped loop $\gamma:\mathbb S^1\to\mathbb R^2$, namely $$ \gamma(t) = (\sin t,\tfrac12\sin2t) $$ (here $\mathbb S^1=\mathbb R/2\pi\mathbb Z$). Note that the velocity of $\gamma$ is separated away from the vertical vector $e_2=(0,1)$, namely $\angle(\dot\gamma(t),e_2)\ge\pi/4$ for all $t\in\mathbb S^1$. Choose $\varepsilon>0$ so small that $\angle (\gamma(t+\varepsilon)-\gamma(t),e_2)> \pi/5$ for all $t$. For $x=(t,s)$ from the cylinder, define $$ \begin{cases} g(x) =\gamma(t)+1000s\cdot\overrightarrow{(1,10)} , &\qquad s\ge 0 \cr g(x) =\gamma(t)+1000|s|\cdot\overrightarrow{(-1,10)} , &\qquad s\le 0 . \end{cases} $$ (its image of the cylinder consists of two almost vertical strips above the $\infty$-figure). Observe that the image of each boundary component $\mathbb S^1\times\{\pm 1\}$ is separated away from the image of the other half of the cylinder (by distance at least 100). Extend $g$ to $D_+$ and $D_-$ so as to fill these boundary components within their neighborhoods of radius 2. Then $g(D_+)\cap g(\mathbb S^2_-)=\emptyset$ and $g(D_-)\cap g(\mathbb S^2_+)=\emptyset$. Since $\gamma(t+\varepsilon)-\gamma(t)$ never forms a small angle with $e_2$, the construction guarantees that $g(t,s)\ne\gamma(t+\varepsilon)$ for all $t\in\mathbb S^1$, $s\in[-1,1]$. Now we define $f:\mathbb S^n\to\mathbb S^n$. For $x=(t,s)$ from the cylinder, define $f(x)=(t+\varepsilon,0)$, so the cylinder is projected to its equator and slightly rotated. Extend $f$ to $D_+$ and $D_-$ so that $f(D_+)\subset \mathbb S^2_-$ and $f(D^-)\subset \mathbb S^2_+$. For these $f$ and $g$, we have $g(x)\ne g(f(x))$ for all $x\in\mathbb S^2$. Indeed, if $x=(t,s)\in\mathbb S^1\times[-1,1]$, then $f(g(x))=\gamma(t+\varepsilon)\ne g(x)$ as noted above. For $x\in D^+$ this follows from the fact that $g(D^+)\cap g(f(D^+))=\emptyset$, and similarly for $D^-$. 

It is amazing how a fact that I was taught in a middle school can be proved using big theories where I don't understand half of the words. Let me add a straightforward proof (for $S_n$ and only $S_n$). For a permutation $\sigma:\{1,\dots,n\}\to\{1,\dots,n\}$, let $\lambda(\sigma)$ denote the number of inversions in $\sigma$, that is the number of pairs $(i,j)$ such that $i<j$ and $\sigma(i)>\sigma(j)$. Then $\lambda(\sigma)$ equals the length of $\sigma$ with respect to the generating set $\{s_i\}$. Indeed, left-multiplying $\sigma$ by $s_i$ only interchanges $\sigma(i)$ and $\sigma(i+1)$, and hence changes $\lambda(\sigma)$ by at most 1. Therefore the length is bounded below by $\lambda$. On the other hand, if $\sigma$ is not the identity, there exists $i$ such that $\sigma(i+1)<\sigma(i)$, then left-multiplying by $s_i$ decreases $\lambda(\sigma)$ by 1. Repeating this procedure, one reaches the identity from $\sigma$ by exactly $\lambda(\sigma)$ multiplications by generators. Now it is clear that the maximum length equals $n(n-1)/2$ and is attained only at the order reversing permutation (the one given by $\sigma(i)=n+1-i$ for all $i$). 

It is rarely possible. First of all, if the manifold is simply connected, then there are no nowhere vanishing closed 1-forms at all. Indeed, every closed 1-form on such a manifold is a derivative of a function and this function must attain a maximum where the derivative is zero. So, for example on $S^3$ there exist nonvanishing vector fields but no novaninshing closed 1-form. The same argument applies to any closed manifold $M$ with $H^1(M,\mathbb R)=0$ (so every closed 1-form has an antiderivative) and $\chi(M)=0$ (so there exists a nonzero vector field). On some manifolds, such as tori, there are nowhere zero closed 1-forms. But a vector field $X$ has to be very special to admit such a form $\alpha$. For example, if $X$ has a closed orbit, this orbit cannot be contractible (more generally, homological to 0 in $H_1(M;\mathbb R)$.) Because otherwise a closed form $\alpha$ would integrate to zero along this loop. And if two closed orbits are from the same homology class, then they must have the same period (because the integrals of $\alpha$ must be equal). A small perturbation of the coordinate vector field on the torus may fail this test. And if you have closed orbits in many homology classes, the period must depend linearly on the homology class. With these observation, you can prescribe $X$ on a tiny subset of the manifold and guarantee that no such $\alpha$ exists. Even one periodic orbit may present an obstruction. Indeed, a local antiderivative of $\alpha$ grows with unit rate along $X$. This implies that $L_X\alpha=0$ where $L_X$ is the Lie derivative. Now imagine that $X$ has a periodic orbit through $x_0$ with period $T$ and let $\Phi:M\to M$ be the $T$-shift along $X$. Since $L_X\alpha=0$, $\alpha$ is invariant under $\Phi$. On the other hand, $\Phi(x_0)=x_0$, so the kernel of $\alpha_{x_0}$ must be preserved by $d_{x_0}\Phi$. But it may easily happen that $d_{x_0}\Phi$ does not have any invariant subspaces transverse to $X$. Even without periodic orbits, there are problems. Having fixed $\alpha_{x_0}$ for some point $x_0$, the condition $L_X\alpha=0$ uniquely determines $\alpha$ along the orbit. It may happen that the orbit is dense, so $\alpha$ is determined everywhere by its value at $x_0$. But there is no reason for this uniquely determined extension to be continuous. There are examples (coming from hyperbolic dynamics) where the form exists and unique, is continuous, but not $C^1$. 

The integration of nonnegative functions deserves its own chapter, just like nonnegative measures. It has more features than the general case and there are cases when you need exactly these features and do not need negative numbers. And it is so elegant: every measurable function has an integral, and the integration is uniquely characterized by 3 properties: the integral of $1_A$ is the measure of $A$; the integration is additive and satisfies the monotone convergence theorem. For example, let $f:X\to Y$ be a map and $\mu$ a measure on $X$. Then one has a push-forward measure $\mu'$ on $Y$ defined by $\mu'(A)=\mu(f^{-1}(A))$. The integration against $\mu'$ is given by the formula $\int_Y hd\mu' =\int_X (h\circ f) d\mu$. Why? Because the r.h.s. satisfies the above 3 axioms. This is trivial to check, and going through any explicit definition of the integral would be painful. So essentially one proves the formula first for step functions, then for nonnegative functions via monotone limits, and then the general case follows. It is a standard type of an argument. And it looks natural and obvious to a student who learned the integration the traditional way. 

Update. This answer answers completely different question, see comments. Namely "positive" is substituted by "positive definite", norm is used instead of spectral radius, and quantifiers are different. Not true in general: take $S=T=-I$. Then the inequality boils down to $\frac{b}{b+1}<\frac{a}{a+1}$ which is always false for $b>a>1$. For positive symmetric matrices, yes. Fix $a$ and let $b\to+\infty$. The l.h.s equals to $\rho((I-\frac1bS)^{-1}T)$ which goes to $\rho(T)$. And the r.h.s. is greater than $\rho(T)$. Indeed, the matrix $S':=(I-\frac1aS)^{-1}$ satisfies $|S'(v)|>|v|$ for all $v\in\mathbb R^n\setminus 0$ (where $n$ is the size of the matrices). Let $v$ be an eigenvector of $T$ corresponding to the maximal eigenvalue $\lambda=\rho(T)$. Then $|S'T(v)|>|T(v)|=\lambda |v|$, hence $\rho(S'T)>\lambda$ by the minimax principle. 

I need this fact as a lemma in a paper on geometric analysis. The proof is more or less straightforward but it occupies some space when written down. And I suspect that the fact may be well-known to specialists. Is this indeed the case and what are relevant references? 

The discussion in the comments is getting too long, let me sum up the proof. This is community wiki; feel free to correct errors and fill in details. Let $H^*$ denote the Alexander-Spanier cohomology with $\mathbb Z_2$ coefficients. We need the following properties of a compact $n$-dimensional Alexandrov space $X$. 

This problem is one of the easiest applications of Frenet formulas for planar curves and can be found in differential geometry textbooks. Some minor corrections: First, $q$ is usually called "turning number" rather than "winding number". (The winding number is how many times a curve goes around a marked point; the turning number is how many times its velocity vector goes around the origin.) The turning number equals the integral of the curvature divided by $2\pi$. Second, as others noticed, $r$ should not be too large if the curvature attains negative values. More precisely, the result holds true for $r<1/\max(-\kappa)$ where $\kappa$ denotes the curvature. The proof goes as follows. Let $t\mapsto s(t)$ be an arc-length parametrization of the original curve and $V(t),N(t)$ its Frenet frame. Then the $r$-shifted curve is parametrized by $$ s_r(t) = s(t) - rN(t) . $$ Then the velocity of $s_r$ is given by $$ s_r'(t) = V(t) + r\kappa(t)V(t) = (1+r\kappa(t)) V(t) $$ because $s'=V$ and $N'=-\kappa V$ by Frenet formulas. Then $$ Length(s_r) = \int |s_r'| = \int |1+r\kappa| = \int (1+r\kappa) = Length(s) + r\int\kappa = Length(s) + 2\pi q r . $$ The area formula is obtained from the length one by integration. 

The answer is no, for any $n\ge 3$ and any $C^1$-smooth strictly convex norm on $\mathbb R^n$. (Here "strictly convex" means that the triangle inequality is strict for any two non-collinear vectors. This is equivalent to the following: the norm restricted to any affine subspace not containing 0 is a strictly convex function on that subspace.) The claim you are asking for is equivalent to the following: if $L$ is the intersection of the probability simplex and a hyperplane, then the norm restricted to $L$ cannot attain its minimum at a point of the relative boundary of $L$. To construct a counter-example, consider the set $F$ of points in the simplex where the coordinate $x_1$ is zero and all other coordinates are positive. (Thus $F$ is the relative interior of one of the $(n-2)$-dimensional faces of the simplex.) Consider the norm as a function on this $(n-2)$-dimensional convex set. Since this function is strictly convex, there is at most one point where its derivative vanishes. Choose $\mathbf x=(x_i)\in F$ so that this restricted derivative does not vanish at $\mathbf x$ (here I use the assumption that $n\ge 3$). Let $(a_i)$ be the vector of partial derivatives of the norm at $\mathbf x$ and let $b=\sum a_ix_i$. It is easy to see that $b\ne 0$. Consider the hyperplane $Y=\{\mathbf y=(y_i):\sum a_iy_i=b\}$ and let $L$ be the intersection of $Y$ and the simplex. By the choice of $\mathbf x$, this hyperplane intersects the relative interior of the simplex, so $L$ contains vectors all whose coordinates are nonzero and $\mathbf x$ belongs to the relative boundary of $L$. On the other hand, the norm restricted on $Y$ is a strictly convex function and by construction it has a critical point at $\mathbf x$. Therefore $\mathbf x$ is the minimum point of the norm on $Y$ and hence on $L$. 

No for general topological spaces, yes for metrizable ones (and I believe the argument can be generalized to all normal spaces). Bad example: $X=\{a,b,c\}$ with open sets $\emptyset$, $X$, $\{a\}$, $\{a,b\}$, $\{a,c\}$. Let $A=\{a\}$, then $\bar A=X$. The homotopy is given by $H_1=id$, $H_t\equiv a$ for $t<1$. The dimension of $A$ is 0 but the dimension of $\bar A$ is 1. On the positive side, let me begin with a quick and dirty proof in the case when $\bar A$ is a compact metric space. Let $\{U_i\}$ be an open covering of $\bar A$. We need to find a refined covering of multiplicity at most $N+1$ where $N=\dim A$. It suffices to find a continuous map $f:\bar A\to A$ and an open covering $\{V_j\}$ of $A$ such that $\{f^{-1}(V_j)\}$ is a refinement of $\{U_i\}$. Indeed, in this case we can find a refinement of $\{V_j\}$ of multiplicity at most $N+1$ and its $f$-preimage is the desired refinement of $\{U_i\}$. In the compact case, let $\{V_j\}$ be the covering by $(\rho/3)$-balls where $\rho$ is the Lebesgue number of the covering $\{U_i\}$. Then, for some $t$ sufficiently close to 1, the map $f=H_t$ satisfies the desired property: the preimage of every $V_j$ has diameter less than $\rho$ and hence is contained in some of the sets $U_i$. Indeed, suppose the contrary. Then there is a sequence $t_k\to 1$ and sequences $x_k,y_k\in \bar A$ such that $|x_ky_k|\ge\rho$ but $|H_{t_k}(x_k)H_{t_k}(y_k)|<2\rho/3$. Due to compactness we may assume that $x_k$ and $y_k$ converge to some $x,y\in\bar A$. Then $|xy|\ge\rho$ but $|H_1(x)H_1(y)|\le 2\rho/3$, a contradiction. In the general metric space case, let $\rho(x)$ denote the local Lebesgue number of $\{U_i\}$ at $x$, that is the supremum of $\rho$ such that the ball $B_\rho(x)$ is contained in one of the set $U_i$. Note that $x\mapsto\rho(x)$ is a positive 1-Lipschitz function on $\bar A$. It is easy to construct a continuous function $u:\bar A\to[0,1)$ such that the distance from $x$ to $H_t(x)$ is less that $\rho(x)/10$ for all $x\in\bar A$ and all $t>u(x)$. Then the map $f:\bar A\to A$ given by $f(x)=H_{u(x)}(x)$ and the covering of $A$ by the balls of the form $B_{\rho(x)/10}(x)$, $x\in A$, will do the job. 

The answer is no. Update. Here is an explicit example (which also preserves the $\mathbb Q$-span of the basis). Let $V=\ell_2$ over $\mathbb R$ and $(e_j)$ the standard basis. Define $T:V\to V$ by $$ \begin{aligned} (Tx)_1 &= x_1+3x_2+x_3 \\ (Tx)_2 &= 3x_1+10x_2+6x_3+x_4 \\ (Tx)_n &= x_{n-2}+6x_{n-1}+11x_n+6x_{n+1}+x_{n+2}, \qquad n>2 . \end{aligned} $$ Let $\alpha$ be the root of $p(x)=x^2+3x+1$ such that $|\alpha|<1$. Then the vector $v\in\ell_2$ defined by $v_n=\alpha^n$ satisfies $Tv=0$, so it is an eigenvector for $\lambda=0$. On the other hand, no nonzero rational vector $w$ satisfies $Tw=0$ because the relation $Tw=0$ implies the recurrence relation $$ w_{n+4}=-6w_{n+3}-11w_{n+2}-6w_{n+1}-w_n , $$ which does not have rational solutions tending to 0. Below is the original answer. Let $V=\ell_2$ over $\mathbb R$ and $(e_j)$ the standard basis, so that $\langle x,e_j\rangle=x_j$ for every $x\in\ell_2$. Let $v\in V$ be a unit vector with irrational ratios of coordinates (for definiteness, take a geometric progression like $(c\pi^{-n})_{n\in\mathbb N}$). Then there exist a continuous self-adjoint $T:V\to V$ with rational coordinates such that $\ker T=\langle v\rangle$. So we have $\lambda=0$ but no $\lambda$-eigenvector is rational. I represent $T$ by its (infinite) matrix $(t_{ij})_{i,j\in\mathbb N}$, $t_{ij}=\langle Te_i,e_j\rangle$. This matrix should be symmetric, and continuity of the resulting operator should be taken care of. Begin with a self-adjoint $A$ such that $\ker A=\langle v\rangle$ with irrational components $a_{ij}$. For example, let $A$ be the projection to the orthogonal complement of $v$, so $a_{ij}=\delta_{ij}-v_iv_j$. I am going to approximate the matrix $(a_{ij})$ by a rational matrix $(t_{ij})$ such that the kernel stays the same. Since $Av=0$, each row of our matrix is orthogonal to $v$. Approximate the first row $a_i=(a_{1i})$ by a rational vector $t_1=(t_{1i})$ such that $\langle t_1,v\rangle=0$ and $|t_{1i}-a_{1i}|$ is bounded by a rapidly decaying geometric progression (see below for details). Replace the first row and the first column of the matrix by this approximation. Then adjust the diagonal elements $a_{ii}$ so that the rows remain orthogonal to $v$, namely change $a_{ii}$ to $a_{ii}-(a_{1i}-t_{1i})v_1v_i^{-1}$. Recall that $v_i$ is a not-so-fast decaying geometric progression, so this adjustment is a small change. Now remove the first row and the first column from the matrix, and the first component from $v$. Apply the same procedure to the truncated data: namely approximate the first remaining row and the first remaining column by a rational vector whose scalar product with $v$ is the same as before, then adjust the diagonal elements so that the scalar products of all rows with $v$ are preserved. Repeat ad infinitum. Note that every element of the original matrix is changed only finitely many times, and $v$ belongs to the kernel of the matrix after each step. The approximations are controlled and the adjustments are bounded in terms of approximations, so the sum $\sum (a_{ij}-t_{ij})^2$ can be made arbitrarily small. This implies that $T$ is continuous and $\|T-A\|$ is small (say, less than 1/2), so we have $Tv=0$ and $\|Tw\|\ge\frac12\|w\|$ for all $w$ orthogonal to $w$. Therefore $\ker T=\langle v\rangle$. However $v$ cannot be rescaled to a rational vector. It remains to show that every vector $w\in\ell_2$ can be approximated by a rational vector $w'$ such that $\langle w',v\rangle=\langle w,v\rangle$ and $w'_i-w_i$ is bounded by a small, fast decaying progression. Let $w'_1=w_1+\varepsilon_1$ be a rational approximation of $w_1$, then let $w'_2=w_2-\varepsilon_1v_1v_2^{-1}+\varepsilon_2$ be a rational approximation of $w_2-\varepsilon_1v_1v_2^{-1}$, then let $w'_3=w_3-\varepsilon_2v_2v_3^{-1}+\varepsilon_3$ be a rational approximation of $w_3-\varepsilon_2v_2v_3^{-1}$, and so on. The $\varepsilon_i$ at each step can be chosen arbitrarily small, and the resulting vector $w'$ satisfies $\langle w'-w,v\rangle=0$.