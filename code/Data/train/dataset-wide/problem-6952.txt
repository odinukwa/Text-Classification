The best way to understand Friedman's and 1950s Chicago methodology is to consider it more an operation research outfit than an economics department. The group consolidated in the war-time SRG, an OR group studying the mathematics and statistics of weapon ordnance (check out Machine Dreams for a good history of it). As with all OR groups, the Chicago group put the priority on usefulness. What matters in economics to Friedman is that the models predict well. Even if the premise of the model sounds wrong, it's fine to act "as if" it was true as long as it predicts data well. This went against most of past (and future) economics. The predominant philosophy of science in economics hasn't changed since John Stuart Mill. In short the idea is that data and experience is misleading, that the job of the economist is to isolate causal mechanisms whose effect may be masked by countervailing forces when we look at data alone. This results in a science that spends more time thinking about first principles (assuming everyone is rational...) than data itself. Maki makes a good case for it. There is a nice blog-post about it on "a fine theorem". 

Hoping I don't confuse you any further. Variable cost is the cost that depends on how much you produce (hence, variable). So in your case that would be: $\text{VC}:25Q-5Q^2+Q^3$ Now the average cost is the cost divided by how much is produced. The average variable cost then is: $\text{AVC} = \frac{\text{VC}}{Q} =25 - 5Q + Q^2$ Now you want the minimum of the average cost. You find the minimum by deriving: $\frac{\partial \text{AVC}}{\partial Q} = 0; - 5 + 2Q = 0$ So you have that the minimum is at $Q=2.50$. Hurray. The AVC at the minimum is: $\text{AVC}(2.5) = 25-5*(2.5) + (2.5)^2$, that is 18.75. Now you also want the marginal cost, which is just: $\text{MC}:\frac{\partial \text{TC}}{\partial Q} = 25 - 10Q + 3 Q^2$ $\text{MC}(2.5)=25-10*(2.5)+3*(2.5)^2$. And look at that we get back 18.75. So apparently they are the same. Who would have thought. 

I'm not really sure what you're asking, but I'll try to answer what I think the question is. In an equity market, people trade certain financial assets. The first point is, trading these assets on a secondary market is not consumption, and it's not investment. If you buy a stock for 100 on NASDAQ, you basically give the previous owner of the stock 100, and you get a piece of paper in return. That piece of paper entitles you to a share of earnings of the company, and that's why you think it's worth something. You can either enjoy the earnings over time, or sell the thing later. So you had $100, and you could have consumed something, or you could have invested it, but you chose to trade that choice to someone else. Now he has to decide whether to consume or invest. In terms of the "real" economy, nothing happens. And nothing happens when you sell that stock. Money never "comes into" the market, and it never "leaves" the market. It just gets transferred between the buyers and sellers, and shares get transferred in the opposite direction. So we see the question of what happens if money can't come into the system doesn't really make any sense. So what do indices reflect? They reflect some kind of expectation of the aggregate value of the shares in an index. That value is the expected discounted streams of earnings of the companies in the index. When the expectations rise, the indices rise. When they fall, the indices fall. Obviously, if we expect inflation, we expect earnings in nominal terms to rise, so that will make the indices rise. But that shouldn't be thought of as "more dollars chasing the same number of stocks." It's purely an earnings effect. The only thing that can make a stock more valuable is if its earnings expectations rise. Supply and demand, as understood in consumer goods markets, do not have much of anything to do with secondary equity markets. Just because people have more money to buy stocks with does not mean anyone will spend 100 dollars to buy a stream of earnings worth 95 dollars. (I say "much of anything". It would make this post too long to go into details, but if there is a surplus of demand for financial assets, risk premiums will drop, and prices will rise. This is a long story for a relatively small effect.) I should mention another reason indices rise, because it's why we expect them to rise faster than economic growth. And that's because there's a selection bias in companies in indices: very poorly performing companies are booted, and more successful up-and-coming companies replace them. 

(i.e. not constant) then how does one determine where, on the MC curve, the equilibrium lies? If there are 5 Bertrand firms, then do I just find where MC intersects the Demand Curve and divide the quantity by 5, and then set price equal to MC at that quantity? Conceptually this sounds reasonable, but I'm not sure that this is correct. If these firms charge this price then it seems to me that one of them will under produce to charge a lower price until (if MC is 2Q for instance) price and quantity = 0. So that no firms will produce because if they do then someone will charge a cent less till we reach 0 again. 

The long-run in economics is a technical term. It means, roughly "without any short-run constraints". What are short-run constraints? Well they're fixed costs like any contracts you've signed (like, say, your lease, your employment contract) and any capital that you've accrued or lack would be short-run constraints. To give an illustrative example, a barbershop may want to increase profits and considers potential options. In the short-run he can increase the prices of haircuts or decrease his hours of operation. In the long-run he can move to another location where he'll have more room for additional chairs and such. For currency exchanges, I'd imagine fixed costs would include trade contracts and debt. At any rate hopefully this answers your question. edit: and "level" in this context just means the exchange rate itself. Since it is numeric, it can be said to have a level. You could change the word 'level' for 'rate' and it'd be the same meaning. 

I know that Bertrand Oligopolies will charge a price equal to marginal cost. But if marginal cost is, say, 

I'm reading a book about the economic development of South Korea during the 'miracle' period. One of the points the author makes is the following: 

I suppose I will suggest starting with Theory of Games and Economic Behavior by Neumman. If I recall it, believe it or not, assumes very little mathematical background from the reader. Maybe you should check it out and see if reading it increases your proficiency with other works. The reason that I think it will is that I'm not sure if the problem you're having is one of mathematics competency or one of comprehension. If it is the latter then you should know that authors tend to skip multiple steps in problem solving because they assume that you can figure things out on your own. If this is where you're struggling, then the seminal book I mentioned is a good choice; because the authors are more forgiving and offer many examples. Looking back on it it has a whole section dedicated to a review of very basic set theory. 

It's worth starting by noting that when we talk about what the stock market does, we're talking about something we believe, not something that's necessarily true. That said, we believe long term interest rates are correlated with economic growth. If the growth rate decreases, the P/E multiple of the market has to go down (because earnings growth is in the numerator of a discounted earnings stream, and earnings growth will be related, over the entire market, to overall economic growth). Also, when companies finance by borrowing, which they all do, earnings will be lower if interest rates are higher (for each non financial company, in this case). Finally, higher interest rates make financial assets other than equity more appealing, although I personally think that effect is far smaller than the earnings effect. 

I'm going to change a comment I made above to an answer, and claim the answer to the original question is that the original papers are correct. The authors of the 2015 paper throw out sequences which should logically be included in their analysis, as I describe in the comment, and therefore introduce a bias which supports their claims. The world works as it should. Addendum in response to comment: We look at table 1 in the paper. We see we're throwing out 4 values from the last column, so to get the expected difference we only average over 12 of the 16 sequences. If we look at these probabilities as frequencies, and we say, for the first line TTTT, what is the frequency at which a head follows a head, then logically it always happens, and we should put a 1 in the p(H, H) column, not a dash. We do that for the other three sequences we threw out, and we conclude the expected value of the difference is 0, not -.33. We can't just throw out data like that, when there is a clear logical interpretation of the data. Note that in order to make the drift vanish, we have to calculate the probabilities correctly, which isn't done in the paper. The probabilities in the table are claimed to be the "probability that a head follows a tail, in this given sequence of four tosses." And we see that for the row TTTH, we're supposed to believe that probability is 1/3. It's not. There are four tosses in the row, and one of the four tosses in that row is the event "a head follows a tail". The probability is 1/4. So calculate the probabilities correctly, and use all the rows, and you get the answer that's been accepted for 30 years.