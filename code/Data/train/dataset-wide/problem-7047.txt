The condition that unstable eigenvalues equal in number the control/decision/non-predetermined variables is equivalent to the requirement that a model possess the "saddle point property". Of more interest is why economists generally want their models to possess such a property, something that holds for the DSGE models. In Economics we call models with the saddle point property as "saddle path stable"; a mathematician would disagree. From a mathematical point of view these models are unstable, because there is a unique path to the fixed point/equilibrium. It should then be evident why such models are characterized as unstable: the slightest perturbation will push the dynamics off the unique path to equilibrium, never to return... enter human will and purposeful action by economic agents: we keep the model on the unique path on purpose, in order to fulfill the optimization conditions that describe our will and desires. In other words, going to the fixed point is the optimal thing to do from a utility-maximization point of view. And if a shock happens we forcefully "jump" back on the saddle path (that may have changed or stayed the same due to the shock), correcting the course of the economic system by will and decision. Consider now a model that is mathematically stable proper. It means that it does not matter where we start, and it does not matter what we do, we will end up in the long-term equilibrium. Hardly an appropriate model to reflect the observed human affairs, or decision-making. And decision-making is structurally an unstable phenomenon, mathematically speaking. This may help glean a bit more intuition: to possess "as much decision-making as needed" in order to have a unique way to go to the fixed point, we need the model to allow us to actually decide optimally on the number of variables the model premises say that we can decide upon, no less and no more: so, as many unstable roots as "unstable"(decision) variables. If the unstable roots are less than the unstable/decision variables, the model does not give us the "degrees of freedom" we need - it is "too stable", hence the many solutions: it is mathematically stable. Boring. If the unstable roots are more than the "unstable" variables, we cannot control the model through our decision making, and it will explode/implode. 

According to the Center for Disease Control and Prevention, approximately 35% of adults in the United States are obese. I have done much research on the topic of economic policies to reduce obesity (I did a fat tax simulation for my undergraduate capstone thesis). I have run into three proposals: 1) Fat Tax: A fat tax is a tax on fatty foods or on fats themselves. Various papers I read on the topic simulated a tax on certain fatty foods. However, one paper proposed an ad valorem tax on saturated fats which seems like the most effective way to target fats. The biggest problem found with fat taxes is that fatty foods are very inelastic. This means that a tax won't change consumption much, so this doesn't seem like an effective option. 2) Thin Subsidy: A thin subsidy is pretty much the opposite of a fat tax. It subsidizes foods that are considered healthy. In the literature, this option by itself doesn't change behavior much, but a thin subsidy can also be paired with a fat tax. Basically, the government would use all of the revenues from the fat tax to subsidize healthy foods. When paired together, they are more effective than they are separately, but they still are not very effective in reducing calorie intake. 3) Gym Membership Tax Credit: This is a tax credit you can receive if you have a gym membership. I have not seen as much literature on this topic. Intuitively, if the tax credit is equal to or close to being equal to the cost of the membership, then people may have more incentive to get a gym membership. However, if the credit isn't very close to the cost of the membership, it may not cause people to go get memberships. Another problem with this method is that someone may get a membership and simply not go to the gym. I know most gyms have scanners now, so one remedy could be that the tax credit amount could depend on how many days you scan in. Other than these three policies, are there any other policies being discussed to slow the trend of obesity? How effective can a policy be in reducing obesity rates? 

This is perhaps a good opportunity to point out that the "certainty equivalence" concept means one thing in microeconomics/choice under uncertainty theory, while it means something different in macroeconomics. Microeconomics/choice under uncertainty The Certainty Equivalent of a lottery/gamble, is the amount of wealth which, if given with certainty, provides the same utility as the lottery/gamble. See for example Jehle & Reny's "Advanced Microeconomic Theory" (2011, 3d ed.), p.113. Macroeconomics "Certainty Equivalence" is the situation in a stochastic model, where optimal decision rules prove to be identical to those that would have been derived in a deterministic framework (see for example Lungqvist & Sargent's "Recursive Macroeconomic Theory" 2004, 2nd ed, p. 113-115). Informally, this is sometimes described as "agents behave as if the stochastic processes are not stochastic", or "the decision rule is not affected by stochastic variability". It is a funny coincidence that both references treat the subject in the same page number... The concepts are evidently linked by the "as if there was no uncertainty" angle, but they are different in essential aspects: the micro-concept is a "buy-out" of uncertainty, providing a certain alternative towards which the agent that faces the gamble is indifferent in terms of utility, while the macro-concept emerges as a property of the solution (and only under restrictive model structures, or linear approximations thereof). 

You are describing a market where a "non-storable" (or "perishable") good is traded. This is the (in terms of historical precedent) model of a market, since in the old days, most goods were agricultural, and many amongst them were "non-storable". The argument behind "market clearing", i.e. that prices will adjust so that all quantity available will be sold, owes a lot to the goods being non-storable. You can observe this today in the so-called "farmer's markets", where if you monitor a day of trading, you will observe that prices go down as the day nears to an end, as suppliers attempt to sell all their quantity. Why some consumers nevertheless buy early on and so at higher prices, even though they know that later on prices will go down, has to do with a) constraints imposed on the consumer schedule (say, he has to buy early because he has to prepare lunch), and/or b) quality considerations: early on the suppliers may give you more room to "pick and choose" item per item, or they themselves will offer the better quality, to justify the higher price. It may be the case that some consumers have a lexicographic preference over a certain threshold of quality, which they expect it won't be around at the end of the day when prices will fall. On the other hand, some consumers will hold on, given their constraints/preferences. As you can see, the phenomenon of all consumers waiting till "the last minute" presuposes a situation were the consumers are perfectly "flexible", and the quality of the good does not deteriorate with time, but the good looses all its "good-properties", instantly, at the end of its "useful life". In reality quality erodes gradually, in almost all cases. 

Well, the name pretty much says it all. I have searched high and low, but I cannot find a concrete answer to the following question(s): How would one interpret the incidence rate ratio for a poisson regression with a non-binomial dependent variable? Also, can this be generalized? i.e. will the interpretation be the same for any count model or does it differ by model? 

I have been looking at quantile regression (since it is a much better method when trying to quantify welfare effects), and I am struggling with the following, standard model: $\textbf{Model:}$ $y=x'\beta(u)$ where $u|x\text{~}Uniform\,[0,1]$ and for any $x,\, x'\beta(\tau)$ is a strictly increasing function in $\tau$. For simplicity, assume $x=(1,x_1)$ meaning that we have one regressor and an intercept $\textbf{Question:}$ What is $Var(y|x)$? 

Government spending is the spending by the government on goods and services (non-capital goods). This means that the government buying physical capital would not be included in government spending, and would be included in investment spending. 

If this were to occur, there are three things we need to look at. 1) Will production occur? 2) Without wages, how will households make money? 3) What will be the welfare effects? $\textbf{1)}$ To answer the first question, if we assume that capital replaced all labor, we are assuming that capital and labor are substitutes which means that the production function will have the following form: $$F(k,l)=\alpha k+\beta l$$ What this means is that if $l=0$, $F(k,l)$ will still be greater than zero, so production will still occur. $\textbf{2)}$ To answer the second question, we can look at how households make money. Households make money from wages, and they make money from owning a fraction of firms (so they get that fraction of the profits the firm makes). All firms are owned by households (either through stocks or private ownership). The typical income of a household looks like the following: $$Y(\frac{}{})=wl+\theta\Pi$$ Where $w$ is wages, $l$ is labor hours, $\theta$ is the fraction of firms which the household owns, and $Pi$ is those firms' profits. If $l=0$, our income reduces to $Y(\frac{}{})=\theta\Pi$ One thing that immediately comes to mind is "without wages, won't all households' income decrease?" Well, we don't know for sure. According to economic theory, the reason the automation will have occurred is because it will cost less. What this means is that profit will increase, so $\theta\Pi$ will also increase. It really depends on whether $\Delta\theta\Pi$ is larger than, smaller than, or equal to $wl$. $\textbf{3)}$ The welfare effects are where we run into problems. When we look at the equation for income of a household, we can conduct a thought experiment: How does the fraction of income attributed to each term change when in different income groups? In the highest income groups, most of their income will come from $\theta\Pi$. An example of this would be the show SharkTank. In this show, companies come to the very wealthy "sharks" looking for capital, and in turn, they often offer a share of their company. Now, when we think about lower income groups, where does most of their income come from? Well, most of their income comes from wages because they cannot afford to save money (and therefore invest in stocks or entrepreneurship). What would happen as a result from full automation, we would theoretically see the income inequality grow to be even larger than it currently is. This is a very undesirable result. 

In the standard/canonical Ramsey model for discrete time, the Euler equation is of the form (notation is standard here, I won't write the whole model), $$\beta (1+r_{t+1})u'(c_{t+1}) = u'(c_{t})$$ To obtain a zero-change locus for consumption, we must satisfy $$c_{t+1} = c_t \implies u'(c_{t+1}) = u'(c_{t}) \implies \beta (1+r_{t+1}) = 1$$ $$ \implies r = (1/\beta)-1$$ -irrespective of the form of the utility function assumed (as long as it does not change, as a function, from period to period), and irrespective of the level of consumption. The locus therefore cannot have a slope in the consumption-capital space but it has to be vertical to the capital axis at a level of capital for which $r$ (which equals the marginal product of capital) equals the above constant. 

The preservation of ranking is over consumption bundles, not individual goods. So the one and only question is whether the ranking of bundles $(x_i,y_i),\; (x_k,y_k); \forall i,k$ is preserved or not. If preferences are rational (complete and transitive), and continuous, then they can be represented by a continuous utility function. So if these hold and $$(x_i,y_i)>_{pr}\; (x_k,y_k) \implies \exists \;U, U_i > U_k$$ The logarithm is a strictly monotonic transformation of any amenable to it function as a mathematical fact, irrespective of what we use the function for. So it follows that $$U_i > U_k \implies \ln U_i > \ln U_k ,\; \forall i,k$$ and the ranking of bundles is preserved. Whether due to the transformation we lose other information or not (that we may have wished we could have kept) does not concern the representation/transformation theorem. 

Well, one advantage to a sales tax is that it affects everyone (even those who don't pay income taxes). However, some people may see that same fact as a problem. This problem lies in analysis of the equity of the tax. When we consider every single person being taxed 30% on everything they buy, we need to think about how that affects different income groups. Lower income groups spend a much larger portion of their income on consumption, which means that they will be taxed relatively much more heavily than high income groups. This fact alone is enough to discourage this sort of action because the government tries to encourage saving in the lower income groups (so they can move up to higher income levels). This is one large reason why a tax like this may not be as fair as the name makes it seem. Another piece of information that must be considered is the incidence of the tax. As we know, the incidence of a sales tax depends upon the relative own-price elasticities of supply and demand. This means that in a market with very inelastic demand (such as cigarettes or oil), the buyer is paying most of the tax whereas in a market with elastic demand the sellers would pay most of the tax. This fact would make it so that different industries would end up paying a different amount of the sales tax compared to one-another. For example, an oil company would end up paying much less of the percentage of the tax than a company making a selfie stick. This, again, seems to be unfair. 

Angus Deaton is only the sixth economist to not share the "Economics Nobel" (the "Sveriges Riksbank Prize in Economic Sciences in Memory of Alfred Nobel") in the last 20 years (i.e. from 1996 onwards). The Press Release reads: 

Assume a company decides to "wind up". What would happen? Its competitors would want to get hold of its tangible and intangible assets (like customer base, patents etc). How is this different from "fighting to a buyout"? In this second scenario, the company has always available the option/threat of continuing competition (possibly harmful to the competitors), while in the "wind-up" scenario it does not -it has committed to leave the business. So "fighting to a buyout" gives the company better position in negotiations, and so chances to increase its selling price compared to the "wind up" scenario. You could spice this with theories about management, and how "management will not let go" etc, but the above provides an interpretation that appears more widely applicable. Compared to smaller companies, large companies have more market power and so the "threat" of continuing competition weighs more heavily with competitors. 

Some input: Kimball assumes a constant-returns-to-scale (CRS) production of the final good $Y$ from the intermediate goods (and no other inputs are involved in this function). Turn to discrete space for a moment, and this means that we would have something like $$Y = F(y_1,...,y_l,...,y_m)$$ Since this is a CRS function we have $$1 = F\left(\frac {y_1}{Y},...,\frac {y_l}{Y},...\frac {y_m}{Y}\right)$$ But also, from Euler's theorem for homogeneous functions we have $$Y = \sum_{i=1}^m \frac {\partial F}{\partial y_i}\cdot y_i \implies 1 = \sum_{i=1}^m \frac {\partial F}{\partial y_i}\cdot\frac{ y_i}{Y}$$ Combining and manipulating the index into $[0,1]$-continuity we get something like $$1 = F\left(\frac {y_1}{Y},...,\frac {y_l}{Y},...\frac {y_m}{Y}\right) =\sum_{i=1}^m \frac {\partial F}{\partial y_i}\cdot\frac{ y_i}{Y}\rightarrow \int_0^1\left[\frac {\partial F}{\partial y_l}\cdot\frac{ y_l}{Y}\right]{\rm d}l$$ In a sense, $G(y_l/Y)$ is the elasticity of final output with respect the the $l$-th intermediate good. Given the assumptions on $G()$, it rules out a Cobb-Douglas CRS production function, where the elasticities not only sum to unity but they are constant, and it looks, say, to a C.E.S. production function with constant returns to scale, where the elasticities are variable but always sum up to unity. 

Really, when considering whether importing a good is beneficial to a country we need only look at comparative advantage. For this concept however, we need information on another good which could be produced in each country. Consider the following example: Suppose we have country A and country B. Both countries can produce only two goods (for simplicity). These goods are gizmos and doodads. Each country has 100 labor hours to spend on production. It costs country A 10 hours to produce a gizmo and 5 hours to produce a doodad. It costs country B 15 hours to produce a gizmo and 6 hours to produce a doodad. Using this information, we can see that country A can produce both gizmos and doodads more efficiently than country B. This is what we call absolute advantage. A country has absolute advantage in producing a good if it takes less resources for that country to produce the good. Now, just because country A has an absolute advantage in producing both goods does not mean that they cannot benefit from trade. In order to see how they can benefit, we must look at the opportunity cost of producing each good for both countries. We will consider the case where opportunity costs are constant. $\textbf{For country A:}$ If they want to produce a gizmo, they must give up the opportunity to produce 2 doodads. Therefore the opportunity cost is 2 doodads. If country A wants to produce a doodad, they must give up the opportunity to produce 0.5 gizmos. Therefore the opportunity cost is 0.5 gizmos. $\textbf{For country B:}$ If they want to produce a gizmo, they must give up the opportunity to produce 2.5 doodads. If they want to produce a doodad, they must give up the opportunity to produce 0.4 gizmos. Now, we can see that the opportunity cost for producing gizmos is lower in country A, and the opportunity cost for producing doodas is lower in country B. This means that country A has a comparative advantage in producing gizmos and country B has a comparative advantage in producing doodads. On a side note, this situation will always be the case. If we are looking at a two-country-two-good world, each country will have comparative advantage in production of one good. What has all of this analysis told us? Well, it has told us that each country would be better off if they produced only the good for which they have comparative advantage in production and traded for the other good. This is, of course, a very simplified example, but the same basic concept applies when you start adding more countries and more goods. I hope this helps!