Another example is certain strong forms of Fubini's Theorem. If you have a real value function on the product of two closed intervals which is bounded, and which is measurable in either coordinate when you fix the other, are the two iterated integrals equal? (In the actual Fubini's theorem you care about joint measurability, not just measurability on either coordinate.) If you assume CH, it is easy to construct counterexamples. It turns it is also consistent to have models where it is true. I don't have a good reference on this, if you know of one please add it in to my answer. 

Let $A$ and $B$ be two models of size $\omega_1$. In both A and B, being in the same cycle is an equivalence relation. Each equivalence class has size $\omega$. So there are $\omega_1$ many equivalence classes in both A and B. Fix a bijection between the equivalence classes in A and B. You can use this to make an isomorphism between A and B because every single equivalence class in either A and B is isomorphic to every other. 

Q: How do you tell an extroverted mathematican from an introverted one? A: An extroverted mathematician stares at your shoes when talking to you. 

If your question is "Are there uncomputable functions which cannot compute Halt?" then the answer is yes. If you take all functions from ℕ to ℕ, "can compute each other" is a natural equivalence relation, and the equivalence classes are called Turing degrees. The computable functions form the minimal degree, 0. The Turing degree of Halt is called 0', pronounced zero jump. (For any degree A, the degree of Halt with A as an oracle is written A'). There are lots of degrees which are strictly between 0 and 0'. The question as phrased, suggests that logic constructions are unnatural or abnormal. This attitude is flatly wrong. Offhandedly rejecting such arguments is as quackish as claiming the real numbers are "morally countable". Computation, definability, and diagonalization are embedded deeply in a wide range of mathematical systems. (See Hilbert's 10th Problem or Gödel's Second Incompleteness Theorem) 20th century logic is a reality of mathematics. 

What tournaments can be obtained this way? Of course, if $k = 1$, only linearly ordered tournaments are possible. I am most interested in the case of small $k$. For example, is there an excluded-substructure characterization of these tournaments? What if we make the problem harder and ask whether a given directed graph $G$ can be extended to a tournament $T$ such that $T$ can be obtained in this way? Again, if $k = 1$, there are various simple characterizations, such as all digraphs that contain no directed cycles. What can be said about the computational problem of determining the smallest $k$ that can represent a given tournament or digraph? 

The following trick uses some relatively deep mathematics, namely cluster algebras. It will probably impress (some) mathematicians, but not very many laypeople. Draw a triangular grid and place 1s in some two rows, like the following except you may vary the distance between the 1s: 

Shall we try teamwork? Please feel free to edit this post if you have simplifications. The original sum may be re-expressed as $$ \frac{1}{2^{2m+1}} \sum_{k=0}^m (-1)^k \binom{m}{k} \binom{2(k+m)}{k+m} \frac{1}{2^{2k}} \sum_{j=0}^{k+m-1} \frac{2^{k+m-j}}{(k+m-j) \binom{2(k+m-j)}{k+m-j}}. $$ If we're trying to prove this is 0, we may drop the fraction out front. Also, change variables from $j$ to $\ell=k+m-j$: $$ \sum_{k=0}^m \left( -\frac14 \right)^k \binom{m}{k} \binom{2(k+m)}{k+m} \sum_{\ell=1}^{k+m} \frac{2^\ell}{\ell \binom{2\ell}{\ell}}. $$ At this point, my idea was to change the order of summation based on $$ \sum_{k=0}^m \sum_{\ell=1}^{k+m} \Diamond = \sum_{\ell=1}^m \sum_{k=0}^m \Diamond + \sum_{\ell=m+1}^{2m} \sum_{k=\ell-m}^m \Diamond, $$ but I can't get quite it to work out. The first sum simplifies, but the second sum I can't do much with. Any ideas? 

Gödel's Constructible Universe, L, is the fundamental example of inner model theory. L was the first inner model, and is the minimal one. One could argue that the point of inner model theory is to build L-like models that do things L cannot. 

The continuum can't be weak compact. The continuum can't be a strong limit (basically by definition of a strong limit) and weak compact cardinals are always strong limits. You could start with a weakly compact cardinal in the ground model and make it the continuum by your favorite way of changing the continuum, but by the above you'll destroy the weak compactness. (Under the assumption that weak compacts are consistent, of course.) If you are just interested in getting the continuum to have the tree property, this is done in Mitchell's Aronszajn trees and the independence of the transfer property by collapsing a weak compact to $\omega_2$. 

If you just want $\pi(n) = \Omega \left( \frac{n}{\log n} \right)$, good enough for many applications, here is a quick proof: The highest power of a prime $p$ dividing $2n \choose n$ is at most $2n$ -- you get at most one more factor of $p$ in the numerator than denominator for each power $p^i \leq 2n$. This tells you that ${2n \choose n} \leq (2n)^{\pi(2n)}$. So $\pi(2n) \geq \frac{\log_2 {2n \choose n}}{\log_2 (2n)} \geq \frac{n}{\log_2 (2n)}$. 

Yes. Here's a sketched example: Start in L. Let P be the forcing which adds ω1 many Cohen reals, and let G be an L-generic filter for P. Then L(ℝ)L[G] will model ZF, but will have no well ordering of the reals. The point is that if σ is an automorphism of P, then σ can be extended to an elementary map from L[G] to L[σ[G]], and this extension will fix L(ℝ)L[G]. So if there was a well ordering of ℝ in L(ℝ)L[G], it would give a well ordering of G which was fixed by σ. But σ can reorder the elements of G because of the homogeneity of P. 

A random $k$-coloring of the vertices of a graph $G$ is more likely to be proper than a random $(k-1)$-coloring of the same graph. (A vertex coloring is proper if no two adjacent vertices are colored identically. In this case, random means uniform among all colorings, or equivalently, that each vertex is i.i.d. colored uniformly from the space of colors.) 

If you are sometimes called upon directing a random walk in a directed graph, how should you direct it so as to maximize the probability it goes where you want? Formal statement More specifically, suppose you are given a directed graph $G$ with edge weights, two designated vertices $s$ and $t$, and a subset of the vertices $S$. The edges weights represent the transition probabilities of the random walk, the vertex $s$ the start, the vertex $t$ the target, and the set $S$ the set of switches. You are guaranteed that the weights on the out-edges of any node are non-negative and sum to one, that $t$ is absorbing (i.e., $t$ has one out-edge directed towards itself), and that the out-degree of any vertex in $S$ is exactly two. A random walk is taken on $G$, starting at $s$. For any given vertex not in $S$, the weight on an out-edge is the probability that the walk will travel in that direction. Every time that the walk reaches a switch (a vertex in $S$), you are allowed to choose which of the two edges the walk will travel along (and you are allowed probabilistic strategies). How should you direct the path if you want to maximize the probability that the walk ends up at your target $t$? Questions I am most interested in this as an algorithmic question. How fast can you find the optimal strategy with respect to the size of the graph? My specific application has about 100 switches among 200 vertices in a fairly sparse graph (say out-degree bounded above by 6). But we can also ask purely mathematical questions. For example, my intuition says (and I can hand-wave a proof) that there exists an optimal strategy that is deterministic in the sense that it always chooses the same direction for a given switch and this direction does not depend on the initial vertex $s$. Is this actually true? Also, is there a sense in which the optimal strategy needs to "coordinate" among the switches? That is, is there a local optimum that is not a global optimum? Notes A note on connectivity: we may assume that the graph is sufficiently connected. If not, we can identify all vertices that cannot be reached from the start node, as well as all of those that cannot reach the target node, into a single, absorbing fail state. We may assume the start node is not the fail node. 

I am learning about Quantum Homology which I have to use in my research, and I see that in many papers (For example in FOOO, "Spectral invariants with bulk, Quasimorphisms and Lagrangian Floer theory", $URL$ the homology ring being computed is given in terms of a Superpotential function. I understand that the relations in the homology ring are somehow encoded in its derivatives, and that it's critical point somehow correspond to Toric fibers with non vanishing homology, but nothing more than that and I have no clue about the details. What I am looking for is some exposition on the subject, some lecture notes, or somewhere where I can see a simple example being calculated completely from scratch. Can anyone please refer me so such sources? Thank you 

$\mathbb Z$ acts on the lattice $\mathbb Z \times \mathbb Z$ by adding an element to itself n times. I am studying some function arising from symplectic geometry which happens in my case to be naturally defined on $\mathbb Z \times \mathbb Z$ and is constant on each orbit of the $\mathbb Z$-action, thus it lives ob the orbit space. I am curious what kinds of algebraic/geometric/arithmetic structures does this set or orbits has, to compare with the behaviour of my function. Thanks 

Hello, I am looking for a source that discusses and teaches hyperbolic geometry from a synthetic approach (As opposed to the common analytinc approach in the poincare disk). I am looking for something more in spirit with eucld's elements or hilbert's geometry book. Thank you 

When defining the $A_\infty$ algebra of a Lagrangian (as done in the book by FOOO) it is done by "counting" (integrating over the moduli space or over the fiber of evaluation map) pseudoholomorphic discs with incidence conditions. To acheive a virtual fundemental class, a Kuranishi structure is built on these moduli spaces and then a virtual class is obtained by a (multi) section perturbation. I understand that each Kuranishi chart corresponds do the picture of the del-bar operator as a section in the corresponding banach bundle. But now (multi)section perturbations don't necessarily correspond to perturbing J or adding a Hamiltonian term. So in concrete terms what actually happens? It seems to me that after the perturbation what I am counting are no longer solutions to the $\bar\partial_J$ but something else. Can the equation they satisfy be described in some concrete way? Which propeties of J-holomorphic curves these solutions still satisfy? Thanks