According to the analysis of a previous question, case 1.a is an ergative use of the verb open, used transitively in 1.b. But then the sentences 2.a and 2.b should be analyzed in the same way, which implies that 2.a is an ergative use of the verb float. But then, sentence 2.c should also be ergative. Is that the case? And then, in successive variations, what of: 

The techniques for attaching other mathematical meaning to the strings (or trees, or graphs) may be considered as outside the mathematical domain of formal grammars. But basically, formal grammars are mathematical entities. Generative grammars is more a linguistic concept. In some looser sense (I guess) it is a set of rules that specify how linguistic elements can be combined to form linguistically acceptable construction, such as sentences (syntax) or simple words (morphology). As formal grammars usually have a generative reading, they are often used by linguists to specify formally generative grammars, often in conjonction with other mathematical tools attached to them. In a larger sense, generative grammar can also refer to a description of mechanisms by which the structure of syntactically correct linguistic constructions will emerge. Generative grammars are concerned with syntax only, with sentences that will respect structural rules of the language. According to such rules, and to Noam Chomsky, "Colorless green ideas sleep furiously" is syntactically an English sentence. Whether it means anything is for Salvador Dali to say. 

I do not know whether there is any sentence in the world that has a unique meaning. I am not sure I can identify all the things that contribute to the meaning of a sentence, since it depends on context, on the way it is stated or written, on the way people interpret various signs that go with it. Even single words seldom have a unique meaning. Meaning may also depend on the mood of whoever produces or receives the sentence. Regarding algorithms to determine grammatical structure, they are dependent on how you define the grammatical structure of a language, and that is very far from being standardized (or to put it differently, there are competing ones). It is that definition that matters, not whatever algorithm you may produce to recognize the structure. It is actually unlikely that any single description will explain all structures of a language. It is probably as unlikely that two people would agree on what belong or does not belong to a language. Furthermore, any language you consider is constantly evolving in time, and may vary geographically (and dead languages changed over time, so that remaining documents do not necessarily represent the same time or space variant). In other word, it is a lot fuzzier than chemistry, and even organic chemistry, because the human brain is a very big and complicated machine. This fuzzyness is somewhat underscored by the fact that a good part of the work on natural language processing is based on statistical techniques. For the time being, the best we can hope for is analyzing a variety of linguistic phenomena, and try to condense them into theories that will account for most, expecially the more frequent. Grammatical structures may be more complex than trees, depending on what you wish to include. But even ignoring that, I would not really see the point of considering together sentences with the same tree structure as a special class. What matters in the theoretical support that assign such structure to sentences. I would guess that most textbooks on natural language processing will have a chapter about describing the structure of sentences, though it may change some, depending on the book. This does not mean in any way that the knowledge is random, or totally disorganized. There are many bridges between the various approaches, and various ways to preserve coherence. As I said, the human brain is big and complicated. If you are interested in formalization (as you seem to be), there is a considerable amount of formal results in computational linguistics. But this does not mean it is able to accurately describe all aspects of natural language. 

But let's ignore this, since the rare form is understandable. Then, if you take the plural for the same examples, you get a single form: 

A reflexive use of a language A is the use of the language A to talk about itself, for example to analyze its own structure. Instead, one can use another language B to talk about A. Then B is a metalanguage for A. For example, if you define a mathematical formalism, say BNF, to express the syntax of languages, then BNF can be used (to some extent) to define the syntax of English, analyze it, talk about it, and do a variety of things. BNF is then a metalanguage for English, or more precisely for the syntax of English. But you could also use English to describe the syntax of English, as many grammarians did in the past. Then it is a reflexive use of English to describe its own syntax. An interesting note, not considered in the text you copied, is that a meta language like BNF can be used to define its own syntax. Then, it is a reflexive use of the metalanguage. What the part in red says is that, even when we do mathematics, we conduct the discussions in English, or whatever language we happen to speak (some people believe there is only one). This is only partly true as computer scientists and mathematicians are developping systems that can conduct mathematical work in a purely formal way. But we tend not to do that when exchanging between human beings, and rather use natural language. Applied to formal metalanguage, this means that even though we can have a specialized language B to express precisely some aspects of English, it is only used as a scaffolding to actually express our thinking more precisely in English, as we would do (with less precision) if we simply used English reflexively. So even the use of metalanguage ends up in reflexive use of the language, at least where natural language is concerned. This said, you can talk perfectly well about English in German or other natural languages. In this case, German becomes a metalanguage for English. And native German speakers do not have to resort to English to say whatever they have to say, thus contradicting in a way the statement in red. Nevertheless, this remark does not really weaken the argument of the author, since we use metalanguages for mathematical precision. German as a metalanguage is probably not much more precise than English used reflexively. The author is really using the word "English" to mean natural language (his responsibility). By the way, this was a reflexive use of English, as I was discussing the meaning of an English word in a sentence, and the current sentence is a reflexive sentence talking about itself. A problem is that metalanguages need also to be understood and precisely defined. So we could build a further metalanguage for the purpose, ... But this would not end. So at some point we cannot escape using reflection. This is precisely what is done when defining the syntax of BNF in BNF. (BNF is just a specific notation for context-free syntax). Further remarks I cannot explain this text much more, as he does not seem to me that the author justifies all his assertions in the available text fragment. And furthermore, I do not always agree with them, short of more developed arguments. To begin with the OP's question, I would definitely consider that a reflexive statement is a meta-linguitics statement about the language (here English) expressed in the language itself. The language is then its own metalanguage. If a language B has and expressive power that goes beyond the expressive power of a language A, while fully covering it, then one may expect that B would permit more general statements, or simply more statements about A than the reflexive use of A for itself. But that is somewhat a trivial remark. The point of view of the author seems however to be that reflexive statements in English can cover more ground than the use of a formal language, since, for lack of a constraining formalization, it will be adaptable to a wider range of concepts and situation. This may well be true, at the expense of precision, univocality of expressions, and possibly accuracy of reasonning and avoidance of paradoxes. Hence, it may indeed be undesirable to identify metalinguistic statements and reflexive statement as they do not serve the same purposes. Except maybe when the metalanguage is itself another natural language, hence having pretty much the same properties as English used reflexively. Still, it seems that the paragraph in red states that this identification necessarily occurs when using a formal metalanguage. I disagree with the last sentence of the first paragraph (which should have a question mark added). My view is that there is substance (semantics) and names (syntax) used to physically denote that substance. Whatever we do is syntactic. If I write "Socrates has eight letters", I am certainly using the word Socrates, but I am using it as substance, not as a name for another substance. And one never accesses substance directly, but only through a name, if only to always proceed consistently. But, the author says it is unreasonable. He may have reasons to think that, but I do not see that he is giving them. Furthermore, we remarked that using English reflexively, or German as a metalanguage for English, is about the same. Using German as metalanguage, would he oppose considering "'sesquipedalian'" as a name for an English word. I do not know. But that is what it is in formal metalanguages (programming languages for example). Would that say something about a possible difference between formal and natural languages, rather than about the concept of reflexivity. Regarding the sentence in red. I do agree with it on a first level. Usual discourse on English, even when based on a formal metalanguage, will make use of English itself (let's forget other languages), and will hence fall back on reflexive use of English. But, as I said, the formal metalanguage is still there as a scaffolding, possibly not very visible. And this scaffolding does structure discourse so that it will not wander beyond the limits set by the formal metalanguage. Hence there is not much that is changed by reflexive use of English, whathever "its richness, complexity and alleged inconsistencies". At best, you can get analogies and support for personnal intuition, but without really changing the end result. English is used reflexively in a formal sense, but it has little consequence ... unless the discourse starts bearing on the adequacy of the metalanguage. But this is yet another game, as English is then used as a metalanguage for the formal metalanguage. I would rather not comment the rest of the text, which encompasses too many things, And I do not understand the reason for preferring to talk "in terms of use and mention" rather than substance and name as I did. I made up this terminology to avoid the more formal syntax and semantics. My opinion is that the philosophers'view (according to the author) is a lot more limitative because it is absolute rather than relative. Recall that higher up I wrote «"'sesquipedalian'"» so has to have a name for the notation of the name of a concept. This allows recursive use of the concept of naming, while use and mention do not allow it, if I am not mistaken in my understanding of their intended meaning. If you reached this line without skipping, you won a coffee next time we meet. PS I thought "sesquipedalian" qualified a bicycle with a broken pedal. I was apparently wrong. 

I guess most signed languages are known to too few speaking people for such an occurrence to be likely. It is not so much a matter of prestige as a matter of population size and communication. However, there are also very limited signed languages used by speaking people when they have to communicate silently or from a distance. It would have a better chance for "word borrowing" from the signed to the spoken language. Thinking of that, I did think of one expression in English that seems to answer the question: "to give the finger" (sorry if that example may break some rules - this is linguistics here). There are probably some others examples. Maybe, "to wave someone goodbye" would qualify too. The interesting point about "to give the finger" is that it can be used in contexts where it is not actually describing a physical movement, but can be interpreted directly as meaning strong refusal. A similar analysis applies to "waving goodbye", meaning "aknowledging departure or loss". It can sometimes refer a description of the actual signed gesture, like "giving the finger". But it clearly only have the abstract acknowledgement meaning when applied to something other than a person. For example, in the sentence "if you trust bankers, you can wave your savings goodbye". There are also counter-examples. The expression "Back-scratching" refers to exchange of favor, not to actual physical scratching. However, it is irrelevant here because scratching someone's back is not considered a mean of communication. The expression "to nod approval" does refer to the signed gesture of approval, but (afaik) is only used to actually describe the signed gesture. One would not say "the man nodded" to mean that he expressed agreement by any mean, but only to mean that he expressed agreement by actually nodding. So the verb "to nod" cannot be considered as borrowed from the signed language, but only as a reference to it. 

A noun phrase is only what you (or the linguist you learn from) define it to be. Different understandings of a language could possibly lead to different definitions of what constitute a noun phrase. Given that you have some precise idea of what constitute a noun phrase, you then have to express that idea so that you can communicate it to others. To communicate it precisely, you need to express it with some kind of formal (mathematical ?) structure or notation. There are many ways to do that, a simple one being phrase structure grammars introduced by Chomsky half a century ago. Such a grammar is constituted of rules describing how phrases (a noun phrase for example) are built by putting together (sub-)phrases and parts of speech (words). So for example you could add to your lists of examples 

When looking on the web, wikipedia for example, at the concept of constituent, it is associated with the concept of phrase structure, and rather quickly with context-free languages (as the paradigmatic example), or more generally Linear Context Free Rewriting System (LFRS), which have standard, well analyzed formal definitions. When looking at the concept of dependency, things seem to fall more on the linguistic theory side, with much less mathematical formalization. My question is whether there are accepted reference versions of dependency grammars that are well defined and analyzed from a mathematical point of view. Is there a specific dependency formalism that could play for dependency the paradigmatic role played by CF grammars for constituency? When looking for example at the Wikipedia page for Dependency Grammars, there is no such formalisation that is suggested.