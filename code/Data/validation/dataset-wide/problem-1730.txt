I have done this with one printer and two different drivers (one PostScript, and one PCL). It should work about the same for using the same driver with the following caveat: Windows may not show both queues if it determines they are using the same port and driver (see the article below). You can sidestep this problem by creating another IP printer port on the server with the same address. I'm not sure if this caveat applies if the print server is a different server. It sounded like you were going to use the same server, but it should work fine either way. MSKB 2015694: Printers installed using the same driver and port on Windows are grouped as one when viewed within Devices and Printers 

You have installed the trust list. Now it's trying to grab the CA certificate. You're probably going to have to grab that certificate manually as well. It appears that this is the certificate chain it is trying to obtain: $URL$ Download it and import it into your computer's Trusted Root Certification Authorities. It is mentioned in this TechNet blog: $URL$ 

You can export the certificate authority database also. Here is the in-depth Microsoft Technet documentation for that. You will want to read it carefully. The table on the first page of the link indicates that migrating from 2008 32-bit to 2008 R2 64-bit is supported. 

I would venture to guess that the users who are affected have this update installed in their workstation or VM pool. If you have clients with this update, they will be unable to apply user settings if their workstation does not have Read (not necessarily Apply) permission to your printer assignment GPO. The default security settings include this, but if you customized the security and removed Authenticated Users from the security, you will experience problems. I have actually seen that practice recommended in some older books as a measure to optimize the GPO, but it's time to rip that page out now. The simplest thing to do is to grant Authenticated Users read permission to the GPO. If you have a lot of them to fix, Microsoft has a PowerShell script which can help you update them. As usual, weigh this information with your particular needs. If you aren't comfortable with adding this permission to all Authenticated Users, then you will need to find or make some other group to assign read permissions to the workstations. 

Both Ubuntu ($URL$ and Debian ($URL$ support upgrading. For Ubuntu, my personal preference is to upgrade from LTS to LTS every 2 years on servers, and if time permits upgrade to every new release on a desktop. People have mixed experiences upgrading both these systems, but with reading the release notes and planning carefully, upgrading never broke anything beyond repair for me (and often, nothing ended up broken at all). 

Are you sure there is a problem to solve? Do you experience low performance? Check for instance "Optimizing memory usage" AT $URL$ A lot of used swap space does not mean there actually is a problem. 

Did the varnish process maybe restart? There's an uptime counter in varnishstat. Under certain circumstances the varnish worker thread can die, but it gets restarted immediately. When everything is working fine, this might go unnoticed, but with (planned) backend down time it can be quite inconvient. 

Are you sure it's not cached at your client? Have you checked with a different browser or a cleared cache? I've found that at least firefox is pretty stubborn in caching the cpanel default redirect. 

Then you can go search the server with an empty but blinking network interface. This should also work for interfaces that are up and running (if they're all connected), but then you'd have to distinguish between the ethtool regular interval and the normal blinking that shows the interface activity :) 

Do you absolutely need to use varnishncsa? Varnishlog (with some extra command line options or shell piping magic) can give you the cookies (and their contents), and the XID, easily. I doubt the full content of the POST requests is available to log. 

This will not reorder them if they're in the wrong order, but it'll at least add them in the correct order right below the search statement (possibly listing 4 name servers which is more than 3 (MAXNS in resolv.h), but with just file_line resources avoiding this might be hard or impossible). Also, the parameter is specific to file_line resources, hinting where to insert the line, and is a general resource parameter talking about resource ordering. 

Your server most likely did not freeze, it was unreachable. The default rule for ipfw is to deny everything. You can recompile the kernel with " options IPFIREWALL_DEFAULT_TO_ACCEPT" set, or add ";ipfw add allow all " to your command (or build a script that flushes and adds your rules at once). 

I know it's an old question, but I encountered this today as well. Contrary to what was assumed, you actually can set up costs for a site that doesn't have a DC. I do this for some remote sites which are within our enterprise network, but not within my local control. In my case, site C includes our VPN users, and I was using it to steer them to a specific DFS server that has more bandwidth. 

DFS namespaces use some referral magic to find if it is on any of the domain controllers -- not just the ones where the namespace is specifically hosted. Non-DFS shares do not have this feature. Normally, you would make each DC a replica for the somecrap namespace by adding them to the Namespace Servers tab on your DFS Management for the namespace. This does not happen automatically when you add a new DC. Otherwise, it will appear to be blank if your computer happens to resolve \my.dom.com to \DC2, if only \DC1 has the namespace shares defined. Your DNS ordering or site setup may be such that it never defaults to the namespace server, so they would always be blank. 

You can force your client to only use one or the other to ensure that you're using Kerberos (or NTLM if you prefer that for some reason). Microsoft has a guide which you may find helpful. It tells how to assess and restrict NTLM usage. Auditing and restricting NTLM usage guide 

Is your DFS-R staging area on the same volume as the DFS-R folder? For performance reasons, it should be. If not, then DFS-R is having to copy the file from staging volume to the destination volume rather than doing a straight move. Here's where the speculation kicks in. It may be that during this copy operation, DFS-R is creating a sparse file, and then filling the blocks, and "unsparsing" it when complete. If something interrupts this process (like antivirus, Undelete, or some other file filter driver program scanning the DfsrPrivate folder), then you may end up with a temporary sparse file that doesn't get filled with its contents. You can test for this behavior by using Process Monitor on the files that are replicating properly and seeing if they are marked/unmarked as sparse at any point in the process. I'm not a fan of mixing 2008 and 2003 when it comes to DFS-R. I was soooo glad to get the last 2003 machine off our DFS tree. 

EDIT You have a certificate only for "master", but your client connects to "puppetmaster". So either the client needs to expect "master", or you need a certificate for "puppetmaster" on your master. A "certname=puppetmaster" in the [master] block in puppet.conf will change the CN on the server ($URL$ You may need to remove the old certificates, but I am not sure about this. Or, you can have the client connect to "master", either by adding it to /etc/hosts, or to your DNS zone if you're running one. 

There still is "example.com" in you config, is that correct? Also, the .net nameservers tell me that ns01.ispeed.it and ns02.ispeed.it are configured by the registrar as the nameservers for your domain. These nameservers respond for elfoip.net, but not with the data you show, these seem to be the nameservers of an Italian provider and not yours. Your registrar needs to change the NS records for your domain, or you need to start using their nameservers. 

$URL$ has an explanation. This command (re)sets the argument variables ($1, $2, $3, $4 and $5 in this case). gives you a line with some numbers, feeding the output to maps those numbers to the $N-variables. See for instance: 

If your out-of-band management does not allow you to flash the indicator, you could try ethtool if you have a spare/empty network interface 

Ubuntu-1004-lucid-64-minimal is not a valid global name, tell postfix to use your "real" domain name, using the myhostname setting: $URL$ 

In addition to the comment of BÃ²ss King, you can also simply specify several addresses seperated with a comma: 

Deleting a file does not actually delete the file, it reduces the number of names pointing to an inode. If both the number of names and the number of open file descriptors to the file reach 0, the data gets deleted. So if you delete a file that's still open by some application, that application can still happily use that file. Only when the last file descriptor gets closed, the file gets deleted (and then you'll see the used space is reclaimed again). 

NFS is from 1 client to 1 server, so the overall performance is limited by the performance of that 1 server. Adding more servers does not help. Lustre splits the data, the data gets requested from 1 server, but can be sent from one or more other servers. So adding more servers does help (which is why "Lustre scales"). This is an important bit from your first link: 

First off, I will assume that your printer is properly implementing DHCP and DDNS updates, but this is not always true. I am also assuming that the original lease it obtained has not expired yet. If you are getting this message after expiration, then you might be dealing with an improper DHCP implementation. Your printer obtained a lease of 192.168.0.20, and was told that it would be valid for X number of days. Some time before that, you changed the range to 10.10.10.0/24. The printer still has an address lease that is technically valid, although undesirable. During a lease, it is common for a device to request a lease renewal and/or a DDNS update. The lease renewal is obviously declined, since the original address is no longer valid for new leases, but that doesn't mean the printer will stop using it. It might not request a new address until the original lease has fully expired. This is not a bug. The name update seems to be what is triggering the error, though. Depending on your configuration, it could be the printer requesting the name renewal, or the DHCP server requesting the renewal on behalf of the printer. The name renewal is being rejected since the address it's tied to is no longer a valid address on the server. The server parts are smart enough to know this, but the device will hang on until the bitter end before trying again, and probably succeeding. The renewal process is basically the client or its agent asking if it may please continue using this name on that address. The server gets to answer "Yes," or "no," but does not get to say "No, but use this one instead." The shortcut is to get your printer to release its lease and get a new one. You can usually do this through the web interface, or sometimes a power cycle. 

This sounds like it could be related to a recent Microsoft update: MS16-072: Security update for Group Policy: June 14, 2016 This update fundamentally changes how GPOs are applied. The cause is summarized well in this snippet from the Microsoft Directory Services Team blog entry: 

This sets a preferred path for sites C and D. Wait for DFS changes to replicate, or speed things along with the appropriate and commands. 

I'm afraid that you're going to have to approach this from the client end. Changing the timeouts is only going to help clients the next time they check in, which is usually after half the existing lease time, or sometimes during boot. You can approach this by manually forcing the clients to check in. You might be able to do this by tweaking some group policy settings, or by running a script to bulk "ipconfig /registerdns" on a bunch of clients. If you insist on doing this from the server end of things, it should be possible to write a custom program to read the entries from a DHCP lease export, and register the addresses, but be sure to run it as the same account that DHCP uses for registrations, or else it may have trouble updating the entries in the future.