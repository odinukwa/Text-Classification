the script below will list all the primary keys, that have at least one or in their columns. You can filter further or tailor the query more but it should be a good starting point and hope it helps. 

these links below are interesting references regarding table partitioning: How to partition an existing non-partitioned table? What's the best way to archive all but current year and partition the table at the same time? Partition Key questions in SQL Server 2008 

where the has my varchar(max) in full. The question remains: How to save a varchar(max) to a file? Now running the following code I get the error message below: 

and this looks and works great! this is the way I call this procedure: MY_LINKED_SERVER is another server, where from I want to get the logins to apply to my current server. 

My complete implementation, working on my test environment is below. I have left everything there, select queries and procedures, to remind myself, where to go to get the data to be used as parameters to the sp_MSstartdistribution_agent and sp_MSstopdistribution_agent stored procedures. 

But that would not solve my query problem above. So I would like to have the following filtered index: 

A question came to my mind though: what sort of data analysis should I do, to identify which of these columns would be better in the index or in the part? Plus, the order of the columns in the index, is there any starting point as to find out, for this query in particular, or other queries that might hit this table, the best order of the columns? There are no other indexes on this table. I cannot change neither the table definition nor the update statement, but I can add indexes. the solution On this occasion though, even after adding the index as planned, while monitoring the execution and using the very helpful procedure sp_blitzcache that I contacted the third party company requesting them to alter the procedure accordingly ( and sort out the updates as described in the comments and the accepted answer) sp_blitzcache in action: 

This is the piece of code that I am mostly using to test the email sending. It shows how to send the result of a query by email, but in this case I made the query very simple because I need to get the email working first. 

I believe it is poorly documented (or at least for me) the fact that DatabaseMail needs .NET 3.5. SQL Server 2016 - Database Mail doesn't work without .NET 3.5 How can I see the current Database Mail configuration? 

I have a process run by a domain account that needs to execute a procedure but only when another specific procedure, called is not running. All this is within one specific database called How can I do for to check if the procedure is running ? What permissions should I grant to so that it can do this check? How can I test if this is working? 

I am using the procedure to find out what groups a user belongs to. I have created an AD group called , and added myself to it, then created a login and granted to the group. 

I have a procedure SP_MYPRO that updates data in MYDB1. 1) the performance of SP_MYPRO would be different if I place it in MYDB2 instead of MYDB1? 2) what if the procedure SP_MYPRO only read data, does not update anything? 

The Options at Database level on management studio you right-click on a database and you can see what are the defaults for a number of options: (in yellow on the picture below) 

Questions: How can we keep control of what is locked by who? how can I put a lock on a record using stored procedure and check if there is a lock on a record using stored procedure ? What would be the possible code of the and stored procedures? 

have you isolated or considered different filegroups for demainding objects\indexes? Have you checked the current available disk space in all drivers, specially those used in this DB creation? how big is the transaction log and why? Initially I like to set it 1.5 times the biggest clustered index. what are the autogrowth settings? what are the current permissions? 

to me it appears that there is something wrong as the way mirroring has been set up. you could use the query below, on the server where the principal databases are. this would give you some visibility as things have been set up. 

what is working for me at the moment, is copying and pasting the script into word then following this link: Special characters you can use with Find and Replace in Word I can put all the "@" in a new line and other similar tricks: Is there any way of doing this level of formatting using SSMS? 

there are still errors on this replication monitor, but they are unrelated to this subscriptions as they are on a different server. I would like to include a link to the question below because it might be useful when you have problems deleting a publication SQL Agent still attempting replication for deleted publication 

2) Suppose I do implement the merge in a package using the operation on question (1). What would be the internals of it? We are talking about 15 million rows between 2 different servers in different domains. Would it be performed in memory? Or where? 3) For performance reasons would it be better to use a in the ? 

Actually the procedure is my favourite in this regard. Now I would like to email the backup history for the day before (only full and differential backups) and I need to find out the profile name for each of those servers. I would like to get this done by saving the contents of the above procedure into a temp table or table variable and just query the info from it by the time that I have all the data I need and I am about to email them. How can I do that for those procedures, specially the sysmail_help_account_sp? I specifically need to find out the . I have used for the script below. this is the script I am using to generate the contents of my email: 

ON this occasion, on my current environment, I have a server that has 8 GB of RAM, I would ask management for more memory. I believe this is a memory bottleneck. what is using the RAM would be another investigation. is this email below valid to identify possible memory bottlenecks? 

Is there any other way to get this done? On this occasion this table is not big - about 500,000 records on the live system. the delete is part of a SSIS package, it runs daily and deletes about 10-15 records a day. there are problems in the way the data is structured, I just need one AccountCode for each customer but there could be duplicates and if they are not removed, they break the package on a later stage. It was not me who developed the package, and my scope is not to re-design anything. I am just after the best way to get rid of the duplicates, in the quickest possible way, without having to refer to index creation, or anything, just the T-SQL code. 

I don't know fully details of your environment, i.e. if the tables in question are mostly used for writing or reading. How often you do this delete? what is the primary key and clustered index of [sko].[stage_närvaro]? If I wanted to optimise this delete there are a few things I would consider: 1) an index on the underlying tables of the view ext.v_imp_närvaro with the columns used in the select (person_id, termin_fakta,[läsår_fakta]) you want an index seek there most likely (no need to include any columns because you are just going there for the EXISTS) 2) I have been using a lot filtered indexes and I would consider the following: 

I create a procedure in order to create random values to be added to MYXML column I want to add one million records to that table 

/------------------------------------------------------------\ Identifying How Often an Auto-growth Event has Occurred When SQL Server performs an auto-grow event, the transaction that triggered the auto-grow event will have to wait until the auto-grow event completes before the transaction can finish. These auto-growth events cause your performance to degrade a little when an auto-grow event is taking place. For this reason it is best if you can size your database appropriately so auto-growth events rarely occur. If you are interested in how often an auto-growth event occurs on your system you can capture those events using a trace. By knowing which databases are performing auto-growth events allows you to adjust those database file growth properties so they will perform auto-growth events less frequently. You can use the profiler “Data File Auto-grow” and/or the “Log File Auto-grow” events to track these database auto-growth events. If you are running SQL Server 2005 or above, both these auto-grow events are already being captured by the default trace. If you haven’t turned off the default trace then you can use the default trace file to find these auto-grow events. If you have turned off the default trace you can either enable it, or setup a new profiler trace to capture the “Data File Auto-grow” and “Log File Auto-grow” events. The default trace logs to a file. I have provided the code in Listing 4 to show you how to extract all the auto-growth events from the default trace files. If you create your own profiler trace session to capture these auto-grow events then you will need to modify this script to meet your profiler trace settings. $URL$ marcelo miorelli 11-mar-2014 

this view is just made up of different types of orders, that get different names as per the part of the process they are in. without getting into too much detail as every business has different rules and internal processes, the way I am about to test the tuning of this view (and wherever stored procedures it is used in joints ) is: I have created a table (see below), and added a non-unique clustered index to that table. I have been replacing the view with this new table, except for the beginning of the process when I use the view to populate the table. 

TITLE: Microsoft SQL Server Management Studio Either the 'mycompany\MMiorelli' user does not have permission to alter the 'myserver\instance' object, or the object does not exist. (Microsoft.AnalysisServices.AppLocal.Core) 

I have been working on a solution to synchronise logins (using T-SQL) between 2 servers, or between AlwaysOn nodes, inspired by sqlsoldier. It requires a linked Server. When run, this procedure outputs the following set of scripts that need to be applied in the current server for synchronising the logins (example): 

for my own records I have a table in one of my servers where I like to save my activities and scripts the table definition is: 

I could not yet figure it out why one of my transaction replication subscription is constantly coming out with the following annoying message: The process is running and is waiting for a response from the server. Query Timeout Expired. I have tried to increase the timeout on the Log Reader Agent Profile, but it is read-only. I have also tried to create another profile and associate it with the Log Reader Agent, but it is not applied. Questions: 1) How can I change the Log Reader Agent Profile via T-SQL? That would give me the proper error message. 2) How can I find out what is causing the timeout, where is it stuck? From my previous experience, this error message disappears with time, but in this case it is not going away, and I feel that I need to change some setting, but I would like first to see clear where it is stuck, in order to assess best what exactly to change and why. 

the problem is that I have to drop the primary key constraint and re-create it as clustered. this is what I would like to get done in the subscriber database: 

I have a table called which references a bunch of different tables. when I run the following script to check all the tables it references I get the result below. 

I have to grant permissions to a view. , however, this view joins many tables, and other views and synonyms. using the following script I can find all all the synonyms in my server: Script to list synonym contents 

this will show your credentials and if you execute as the login you are testing you can see how it looks like. 

I would like to log all these commands to a table before I apply them to my current server, but I understand these are sensitive information, and I would like to be able to encrypt it and be able to decrypt. What could I achieve this? I have already seen this: Is It Possible to Encrypt varbinary(max) Column Using Always Encrypted Feature? How could I achieve this, with minimal effort, and not affecting anything else on my systems? (I currently don't use always encrypted) 

something like the select above, I want to see all the jobs that have the database names in them and delete them, for example, like in the script below: 

Where can I find out (preferably using T-SQL) within a published databases, if it would replicate the schema changes? here is how to create a publication This topic describes how to create a publication in SQL Server 2014 by using SQL Server Management Studio, Transact-SQL, or Replication Management Objects (RMO). Replicate Schema Changes 

When talking about Partitioned Tables and Indexes for tables with less than 100 partitions, no nonaligned indexes: with that I mean: 

How can I find the code of the blocking session, in this case, the session 75 when the session's status is 'sleeping'? New version this new version shows also the blocking session, however, I could not find out how to get the database name and other data from a sleeping session.