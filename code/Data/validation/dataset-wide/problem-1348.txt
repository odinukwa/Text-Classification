you can write since returns the element removed. The s in the merge function are not properly aligned. Notice that the use of the method could alter algorithm complexity (because I think that is \$O(n)\$). It could be better to use two indices to keep track of the position in the two lists. 

You can move a window by increasing as long as the window does not contain all terms, then increasing as long the window contains all terms. This will find in linear time all possible windows containing all terms. Then take the shortest one. Here is an implementation: 

You are requested to implement a data structure which can implement the three commands: , , . What is the minimal information you have to hold? To respond to a command it is enough to store 216 possible answers, corresponding to 216 possible values of . That is enough. When you a number , just add 1 to the count of all such that . To a number just decrement the counter. So here is the core of a possible (not tested) implementation: 

so that in the case there is no need to access self_db and user_dbs. This is particularly convinient if the case count==2 is more frequent than count==0. 

why a class with static methods? Keep it simple, write global functions. You already have the module which encapsulates the functions. 

This makes it clear that is assigned one and only one value (while in your code this depends on the content of ). Notice also that the code is simpler and the is no longer necessary. The following code is ugly: 

in the main function you have a small repetition when checking argv to determine if the FILE should be closed or not. I would prefer checking which is telling the real reason for the check. Alternatively I would simply neglect closing the files... since you are in the main function, at the end all file descriptors are guaranteed to be closed anyway. i would prefer instead of . I see three reasons for this: it is shorter, you don't introduce the arbitrary constant 1, it is clear from the beginning that the loop has no termination condition. i would expect less invasive error checking. Since your and functions are perfect candidates to be reused in a library, you should not write errors to and should not terminate the execution with . A better approach would be to use return codes as signals for errors and let the main function write the messages and terminate. i would always enclose with braces the blocks of an statement even when there is a single line. This is to avoid the risk to forget the braces when a line is later added. As an alternative I would put the single line on the same line as the statement. 

Since you are interested in an OOP approach, I take the opportunity to show you a toy program I did during a programming course. The comments in the code are in italian (sorry) but I hope it is clear anyway. The code comprises: 

You can make the early stopping better (and maybe simpler) by checking that the current_sum plus the product of the remaining terms by the smallest term is larger that the target sum. You could also make the opposite check: if summing the larger possibile terms you cannot reach the target sum. 

what is the purpose of EntityManager? As long as it is nothing more than a container, you should use a container. Keep it simple! You can define the container with a typedef so that if later some more functionality is needed you can extend the functionality with a real custom class. Here I see a problem of ownership because has pointers which are owned by mEntityManager. If you plan to regenerate the whole in each update, then should be a local variable in the update function. If you plan to update mTree using its previous state, you must be very careful to handle deleted and added entities. This should be handled by the World object since it owns coordinate both mEntityManager and mTree. Hence the conclusion that World is the actual EntityManager (which, after all, sounds as a trivial truth). 

All these simplification do not change the algorithmic complexity of your code. PART TWO Your algorithm is \$O(n^2)\$ since you are iterating on all pairs of names in a huge list of length \$n\$. This can be terribly slow when \$n\$ is becoming very large... so you should try to find if it is possible to make a single iteration on the list. The key point, here, is that the computation on a pair of persons only depends on the number of occurence of the characters P,A,I,R,S in their names. So if two person share the same count of P,A,I,R,S occurences they share the same perfect pairs (if they have any). So you can start by construction a dictionary mapping "PAIRS count" to the number of people with such a count. Moreover every PAIRS count can be reduced modulo 9 (because we use modulo 9 arithmetic) hence the number of items in the dictionary is bounded by \$9^5\$ which gives constant time access and update of the dictionary. So the dictionary can be constructed by a linear sweep over the list of names in \$O(n)\$ time complexity and constant memory. Once the dictionary is constructed you can make the double iteration on the dictionary. Every match in the keys of the dictionary must be multiplied by the counts of both "PAIRS" to get the count of actual people matching. Since the dictionary has less than 100000 entries this counts as a constant time operation. Of course when \$n<100000\$ this could be not better than your algorithm (but also not worse) but I would predict that even for smaller numbers you have a gain, since real people names are not so long and contain very few occurence of five choosen letters (imagine any name with a (9,9,9,9,9) PAIRS count) hence I expect a lot of collisions in the hash dictionary which will sensibly reduce the runtime of the algorithm. Possible implementation: 

I think the code is very well written. But, as you suggest, it should be more object oriented. I see two objects which are calling to be extracted: a Tokenizer and the InfixToPostfixConverter(better name required). The Tokenizer should read its input from the scanner and have a method to get the next token as a string. The Converter could be feed with tokens and fill the outputQueue. This way you separate the two problems. Moreover you can put the tokenization process in parallel with the shuntingYard algorithm without the need of a buffer to keep the tokens. 

invert the two lines above, so that you can use size in the previous line. Why to use instead of ? The name of the variable is not very good for my taste: it is not "sorted" (maybe it is "sorting") and what does "indice" means? Maybe you mean "indices"? 

The explanation is not very clear. You describe what are the nodes of the tree but what are the children of a node? 

Here your code can be simplified and made more clear. You are checking if the character is alphabetical and then looking into your map to find the corresponding translation: 

use a single call to followed by a call to to get the same result. In the rest of the code I would suggest to take advantage of the fact that characters have consecutive ASCII codes. This would simplify (and speed up) the code significantly. In this case you would silently assume that alphabet is given by ascii codes from 'A' to 'Z' and to find the index of a character in the alphabet just compute . Of course this won't apply if you plan to differentiate frequency of lower/uppercase characters... but it would not be too bad to extend your frequency map to all 128 ASCII characters to anyway take advantage of this hint. 

There is no improvement which can be done on the code you show us. If the function really needs to be called for each combination of the parameters, there is nothing better you can do. You should try to optimizie the function, maybe it is possible to cache some part of the construction which is common if one of the parameters is fixed. For example you can pop the computation in the outer loop, so that you make it once for every Word (instead of once for every City). But I think this is a slight improvement. 

your pattern is always the same so you could cache the computation of the array . This would double the speed when you fill array you could stop whenever . This could speed up your algorithm a lot in some scenarios. For example you skip a position at once if the letter in the text is not in the pattern. you are making copies of strings just to add the null terminator. You can avoid this by adding the length of the string as a parameter to your first function. This would help point 2 to be quite fast in the scenario already mentioned. you can update the array incrementally. You decrease the count of character which exit the window and increment the count of characters entering it. 

there is a division by zero when the lines are vertical. You should moltiply both sides of equation by the denumerators to avoid this and to have a more stable condition. Anyway it is almost always wrong to check for equality of two floating point numbers, as already said. The function and are not used. Why did you include them? Anyway note that vertical lines have no slope defined. So the function is not very useful. The function also has the problem above (checking for equality of two floating point numbers). And due to the problem of it will not work if one of the two lines is vertical. 

you can easily replace this line with a for_each or an iteration. This would result to be more clear, since you are not really hiding anything in this method. EntityManager: as already said, I see nothing useful in this class. I read somewhere that whenever you name a class XxxxManager you should ask yourself if such class is really needed. And if it is needed you should be able to find a more explicit name which explain the purpose of the class. 

I always feel not comfortable when both operations and are computed separately, since the second one can be computed in terms of the first by means of sum and multiplication (which are much more efficient operations). Also this alternative "stream of thinking", i.e. modify the input values until they satisfy the requirements, requires less use of imagination to find the names of variables.