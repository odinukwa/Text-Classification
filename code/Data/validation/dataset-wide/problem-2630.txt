There are many intelligent people in the world who are not very good as programmers, or who don't have any interest in writing software. So if we created an Artificial Intelligence, what reason is there to think it would be a good, or decent, or at least not completely incompetent programmer? What reason is there to think it would be capable of being a programmer without growing up for close to 20 years, followed by some significant amount of training? What reason is there to think Artificial Intelligences capable of writing software would be able to do it in such huge amounts at a cost that making them replace all programmers would be cost effective? If I needed to pay a $1 million dollar bill a year for servers to run an "Artificial Intelligence" program that can replace a single programmer, why would anyone pay that money? There is a huge gap between an Artificial Intelligence, and an Artificial Intelligence capable of replacing a programmer cost effectively. Same as there is a huge gap between an Artificial Intelligence that can create a simple melody, and one that is better than Beethoven at composing music. At some point in 100 years or so, when a group of AIs goes through all the StackExchange questions and supplies perfect answers to all the questions, we'll get an answer that can express my thoughts on the subject much better than I can. 

Most suicides are committed due to mental health problems, and are not based on any rational decision. Since the victims are not thinking clear, they may have a plan to kill themselves, but no alternative plans. So you get a massive chance of saving someone's life without restricting them much by removing their intended means of committing suicide. Removing a gun or ammunition, or removing a stash of sleeping tablets, these are very helpful ways of helping a suicidal person. I hope you were looking for a practical way to help. Discussing the ethics of suicide out of curiosity and because it makes for an interesting subject would be deeply unethical. And after careful reading: Should I ever have the bad luck to be in a situation where suicide is a rational choice (which I seriously hope will never happen), what do you think would I do about it? 

As with many philosophy quandaries, you'll need to clearly define the term "chance" (or "randomness") in order to resolve this. I don't see any other way to ultimately define "chance" except for subjectively, i.e. I/we don't see a pattern or haven't identified a cause. (If someone has a candidate definition, please offer it.) Under such a subjective definition of "chance": 

Reasoning about it simply, Hume's position that causation is - at root - a regularity in events is indeed based on his first-person epistemology wherein all ideas are built out of impressions (what we might now call "sensations"). The reason is just a matter of definition: if all events are built out of impressions, "A causes B" boils down to "event A is regularly followed by event B," then "A causes B" fundamentally just means "my experiencing the set of impressions A is regularly followed my experiencing the set of impressions B." Consider a concrete example: you're playing Super Mario Brothers, something happens off-screen and you hear the sound of a 1-UP (a Humean impression) and see your status bar shows "4 lives" (another Humean impression), but you hadn't been paying attention to your number of lives so you don't know whether you just got an extra life (i.e., you just had 3 lives and now have 4) or if the sound just played but maybe you didn't get credit for the 1-UP because it happened off-screen. Nowhere does the game or instruction manual say as a rule that that sound necessarily means your lives got incremented, and since the event happened off-screen you don't get shown "1-UP" visually; it's just that you have experienced that every time you heard that sound before (regularity) it has meant that your lives got incremented as shown in the status bar (Humean causality). However, in another interpretation you may be asking whether you need the first-person epistemology in order to define causality in the Humean way. Like, would the definition of "A causes B" --> "event B regularly follows event A in time" still be tenable in, say, a physicalist view? I would say perhaps, but it depends upon your acceptance of the theory of relativity, because if you think that the timing of an event has no universally objective answer, you can't speak of universal ordering of events, then cannot speak of causality in the Humean sense. It in fact seems to me that it completely falls apart if you don't have a first-person perspective, as one person may say they experienced event B without experiencing event B, etc. 

Rules in a civil trial and a criminal trial are different. What I say should be only applied to criminal trial. When someone is accused of a crime, there isn't just "guilty" and "not guilty". Many actions could be different crimes depending on the circumstances - like theft, robbery or armed robbery, like manslaughter, second degree or first degree murder. So a lawyer might be very well aware that the client stole money or killed someone, but the client might be guilty of theft and not armed robbery, or manslaughter and not first degree murder, so even knowing that the client is guilty, the lawyer would still be expected to give his best defence. Many crimes can have mitigating circumstances. A person killing their spouse after ten years of being abused, and another person killing their spouse who dares defending themselves after ten years of being abused, should be treated differently, and the lawyer should do their best to make all mitigating circumstances for their client count. And there is the prosecutor. The prosecutor is not there to get a fair judgement, but will try to get the maximum punishment. Likewise, the lawyer is not there to get a fair judgement for their client, but the least possible punishment. The judge being between them is responsible for a fair judgement. The lawyer must do his best to represent the client, or the judgement will not be fair. Since I was asked: The case of Aaron Swartz and prosecutor Carmen Ortiz looks very much like a case where a prosecutor tried to get a maximum sentence, way beyond what looked to be justified. That is a case of "knowingly" looking for a sentence that exceeds the crime. But on the other hand, I didn't say that prosecutors generally "knowingly" ask for punishment that exceeds the crime, but it is obvious that in any single case where an innocent person appears in court, the prosecutor at least unknowingly asks for punishment that exceeds the non-existing crime.