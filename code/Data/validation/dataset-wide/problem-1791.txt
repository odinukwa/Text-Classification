Your upstream distribution (in this case Ubuntu) provides and supports a particular set of packages. It would be much more advantageous to upgrade your whole distribution to get a newer version of grep (or really any other package.) The way to do it, if you choose to go this route, is to create your own .deb package with the newer version. Place that package in your repo, enable your repo on the system. Then you can install that deb with apt. 

Setup a second server as a slave. You probably want a master/master setup so either host can take writes. Move the IP over to this second machine. Now you can do your maint on the first machine. This will minimize the downtime for the MySQL service. 

I have multiple Amazon EC2 instances which need to communicate using private IPs. However, so far I've been unable to ping one instance's private IP from another instance. I can ping external addresses, such as their Elastic IPs and other sites (yahoo, google, etc), so it seems there's nothing wrong with the instances' network configuration. Also, they are all in the same zone, so that shouldn't be an issue. Does anyone have any idea what I could be doing wrong? Could this related to the Security Group settings? 

I have several Amazon EC2 instances, running Ubuntu 10.04, with which I'd like to use Amazon's Route53. I setup a script as described in Shlomo Swidler's article, but I'm still missing something. When the script runs, it doesn't return any output, which I initially assumed meant it ran correctly. However, when I check the DNS records using MyR53DNS, there are no entries for my instances. Here's my script: 

The most secure PHP version is the one you keep updated. Which version (and associated libraries) are maintained by an upstream provider (your Linux distro, assuming you're running Linux.) Are you building the binaries yourself? If so, make sure that you allocate the time needed to keep up with all security patches, not just in PHP, but also in libraries required by your application. 

This seems wrong on so many levels. You are making it more difficult to maintain (by installing from source you lose all upstream QA and updates) and you are moving things around that don't need to move around. Is it valid? Yes. You can make it work. Should you so this? Probably not. 

I have several Amazon EC2 instances, running Ubuntu, which need to communicate (web servers and a MySQL server). I'd like to use OpenVPN to ensure their communication is secure and to reduce the number of open ports. I've been following this article, but I've run into a problem. Note: I'm using port 1194, not port 80, as shown in the article. I've installed and configured the OpenVPN server on the MySQL server and setup a web server to connect to it as a client. Running shows a tunnel has been created on both sides, but data doesn't appear to be being transferred over it. How do I change the default route to make it use the VPN tunnel? I'm assuming that's the problem, but I'm not positive. 

Just write a script to parse the output and have that output sent to your central monitoring host (or have it email you.) 

I would recommend any other configuration management system over puppet. Puppet will re-order the configuration steps on each run. Even on the same host. Proponents will tell you that you can setup your requires appropriately so that it works well. I'll tell you that I'm human and I make mistakes. If you have a puppet recipe of any complexity you'll want to test your work. When you do and it succeeds you'll assume that it works on all of your other hosts. This is not necessarily the case. Any system that assumes I'm perfect is, itself, not. 

I want to host my images on Amazon S3. So I created a bucket by the name and added a CNAME entry with the record host as and a record answer as . There is a file in the bucket named image.jpg, under a folder named images. which I can access at I cant access the same from I also changed the record answer to , but that also doesnt work. What am I missing? Thanks. EDIT, AFTER THE ANSWER: Just read these pages: $URL$ $URL$ 

I am facing a load average of > 3 since past 2 days. The CPU utilization is never above 40 % in all cases. Here are some screenshots of Server Density monitoring tool that I use. 

Currently there's only one Web server, but I've made an image of it, so once the project starts I can launch as many instances as I need and configure them individually. Everything has been going smoothly, but I've hit some snags. My problem is I'd like to run multiple web server instances, but with Amazon's restriction to 5 Elastic IP address, I know that won't be enough. I was researching how to host websites on multiple web servers from a single IP address and ran across mod_proxy for Apache. I haven't tried it yet, but I think that's what I need. I'd just like someone to confirm that I'm on the right track. 

I've had great experiences with 3ware controllers in situations like this. I've pulled full arrays from 6000 series controllers and used them on 7000 series controllers. I've intentionally jumbled the drives in an array and it picked up the changes without issue. The 3ware (tw_cli) utility is much more user friendly than either the HP (hpacucli) or the LSI (MegaMgr/MegaCLI) utility. (It should be noted that LSI bought 3ware last year. I hope they continue with the (almost) awesome 3ware utility.) 

You can setup a cronjob that runs at reboot. Just use the alias @reboot instead of the normal time specification. See for more info. 

Since I am charged I/O on an external EBS, am I correct in guessing that the EBS volumes are in a different location than the instances? 

I have a few key-pairs, that are used as authentication, to ssh into my servers on the Amazon cloud. I rotate those certificates weekly, manually. My question is, I need to share the certificates with some colleagues, a few on the LAN, and a few in another part of the country. What is the best practice to share the certificate? My initial thoughts were Dropbox and email. We dont host dedicated email servers with encryption and all, and dont have a VPN. Thanks. 

Below are my server.conf and client.conf files. I am using tun rather than tap, from what I've read, I think that's the best choice. I currently have compression turned off, just to eliminate that as the problem. server.conf 

I've setup two Amazon EC2 instances, both running Ubuntu Server. One is configured as a DNS server running bind9, which will be used to allow EC2 instances to communicate with each other based on hostname rather than IP, since their private IPs may change. I think I have the DNS server setup correctly. I want to use the second EC2 instance to test the DNS server. Using Webmin, I've added the DNS server's private IP to the client's DNS Servers list and added the domain to the Search Domains list. I did have to edit /etc/dhcp3/dhclint.conf to make my changes stick. After reboot, I expected I'd be able to ping or nslookup the DNS server from the test client, but it can't seem to find the server. Is there something I'm missing?