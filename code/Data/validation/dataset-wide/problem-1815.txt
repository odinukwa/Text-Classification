Is there a script that will show memory usage as a graph, for example as a pie-chart, with each process being being a separate slice? I'm not looking for something like Munin to graph memory usage over time, but rather show the memory usage per-process at a single point in time. To make my request even more obscure, it is for a headless server (so no X applications). The simplest way would be to write a PNG file, or possibly an HTML file (which could use Javascript to allow the filtering of processes, changing between graph-types and so on) 

The command on OS X is pretty crappy.. The one included with most Linux distros allows you to change the sort-by column using and , there is a coloured mode (by pressing the key), and a bunch of other useful options. Is there a replacement command line tool? Ideally I would like for OS X, but because it relies on the filesystem (see this thread) it has not been ported (and probably will never be) The obvious answer is "Activity Monitor", but I'm looking for a command line tool! 

You need to also remove the and directives from the virtual host's configuration, otherwise it'll be logged via the virtual host's log files. That said, how many virtual hosts are you running? You should be able to increase the fd limit to accommodate the number of virtual hosts you're running. Try apache's documentation example on this: 

But, for some reason, one of those providers, specifically , is indefinitely in a state. I can check it via CLI, like so: 

I left it in this state overnight and it's still in the same state. I tried unregistering, which left it hanging in the state. Then tried to register again and it has been like that for about 10 minutes. The other 3 providers registered almost instantaneously. 

You can configure it in the console, under the default realm -> configuration -> user lockout. Here's the documentation (I'm assuming wls 12c): $URL$ 

This error seems to be caused by . Check your central apache configuration and remove the directive for this directory and it should work. Source: $URL$ 

I'm just starting to look into Azure and AKS. In order to do this, I have to enable a bunch of resource providers. I did this using the Azure CLI, like so: 

I'm trying to get emails into a Python application. There is an exchange server that marks some emails with a BCC address for archive@somedomain.com. I do not control the Exchange server. The email volume may be high sometimes too. On the server that will be handling the mail send to the archive address, there is a Python application that parses the emails, inserts some header information to some databases, and stores the email in an object store. I'm not sure of the best way to receive the email and get it into the Python program. There are a few issues with a Postfix solution. 1) Postfix is a lot of moving parts for such a simple purpose. Not really a big deal if problem 2 can be dealt with. 2) There isn't a good way that I can find to get the emails from Postfix to a Python program. This is not a Python script that should be invoked each time using the pipe transport. I need a way to stream email contents into the Python application with some kind of deliminator. I'm also trying to avoid using Pythons smtpd library directly as it uses asyncore which should be avoided in favor of asyncio. Is there a good Postfix configuration or perhaps another mail SMTP server application that can do what I need? Or will I have to resort to using a Postfix pipe running a script that will insert the email into some kind of queue? I'm also find with some kind of deliminated rotating log file containing email body and attachment data. 

Err, if you left the monitor plugged in, would it have crashed? Pretty much any OS can run happily with no monitor attached. The only related problem I can think of is some motherboards refuse to boot if no video card is installed. There should be no performance difference between having a monitor connected, and not. There is a difference between running X11 and not (say to run Gnome, or KDE etc). The X server takes up memory and CPU cycles like any other process.. Disabling it is a good idea for a server, since most tasks can be done easily over SSH (or on the local terminal) 

Wouldn't a bootable Linux "live CD" (such as Knoppix, Ubuntu), or a BartPE disc be a better solution? If the system is "borked", surely it's going to struggle to run any VM software.. It also means you can access/edit/delete files that would otherwise be locked 

does have some additional features, like and things like holding packages (to stop them being upgraded) - nothing you couldn't achieve via other commands/methods, it's just more unified and nice to use. 

I have a Cisco branded Emulex LightPulse LPE12002 in a Cisco UCS server running Ubuntu 14.04, and I am trying to connect to about 15TB of remote storage configured for it. I don't know where to start, but here's what I have done. First, when I issue , I get a result like the following. 

This looks like it is the right target, since it's an "FCP Target" and I have confirmed that the port_name is indeed the WWN of the 15TB storage target I am trying to connect to. The issue is that Linux doesn't create a device in /dev that I can use. I have a sg0 device, but that's mapped to sda, which is from the raid controller for local disks. I have done the following to try and make linux recognize the storage. 

multiple reboots verified the lpfc driver is loaded None of these seem to work for creating a usable device. I am not using multipath currently, even though it is a 2 port FC card, I am just testing with one port connected and with exposed storage. Any ideas? 

Get a tcpdump, preferably filtering by their IP origin, and analyze it using a tool like Wireshark. You can see what's going on on the TCP level and better understand their issues, but if you have high load, analyzing it can be painful. Getting an end user experience monitoring solution. I realize telling you to spend money on a tool to solve an issue you have right now is not what you're looking for, but these are generally good value for the money in your kind of situation. 

I know it's been a while, but this usually has to do with SELinux. Try setting it to permissive and it'll probably work fine. 

WebLogic uses certicom as the SSL provider by default. On version 10.3.3, they've added JSSE support. I haven't seen this specific error you're seeing, but maybe enabling JSSE will resolve it for you. You configure it at the server level, under Server > Configuration > SSL tab > Advanced tab 

I'm not sure about setting a header, as that seems a little convoluted. But you could simply include the same URI in the Proxy, as in: 

Aside from providing a pretty console UI when you run with no arguments, it combines the various commands (and ) into one utility.. To search for a package and install it, using apt-get: 

Of course you should try and install everything via your package manager (so you get automatic updates and such), but I tend to keep old versions of Python around, and putting them in shouldn't interfere with at all. 

An alternative option - you can patch away the 10-inbound-connection limit, something commonly done by people using Bittorrent. $URL$ 

First, I would strongly suggest not doing this. As others have far more eloquently put, blocking a specific country doesn't fix the problem , it just defers it slightly. Also, when users from that country see you've blocked them specifically, it will only motivate them to cause you more problems. That said, if you really want to do this, IPinfoDB provide a free IP geolocation database, 

There is a Python 2.6 package for Ubuntu, $URL$ but only for the and releases. You could possibly grab the file and install it on previous versions, but things may break.. If fails you, compiling from source is trivial: 

Every guide to using SSSD for LDAP authentication I've found thus far shows you how to do more than just authenticate a user, such as provide their shell, groups, etc. I don't know how to remove those features without things breaking because there are several moving parts like SSSD, PAM, and NSS. Due to limitations on what information is provided via LDAP (it's not AD), only authentication of users can be done. There isn't even a uid available because the only id provided via LDAP are consistently formatted alpha-numeric strings (won't work on linux). Basically, how can SSSD be configured on Ubuntu to treat ldap as the "shadow" database, but get the uid, groups, and shell from your local system databases (passwd, group). This is currently done with libpam-ldap, but my understanding is there are better alternatives like libpam-ldapd and sssd, the latter of which RHEL has moved to. If I had to guess, it can be done similarly to how we currently do it, which is nss will check local databases first, and if the user doesn't have a shadow file entry, check ldap. As a summary, if I can use SSSD or, as a backup, libpam-ldapd, to authenticate the following way: uid -> /etc/passwd authenticate -> ldap shell -> /etc/passwd groups -> /etc/group Even better if it's possible to stop users from creating passwords locally that would end up in /etc/shadow thus causing it to check ldap at all in future login attempts. Also, all local and service accounts shouldn't be impacted, and ldap authenticated users can be determined with simple regex. I'll be very grateful for any good suggestions on how to handle this. Thanks! 

This probably has to do with the Managed Server's Listen Address. I haven't seen this error specifically, but if Listen Address is blank, WebLogic will bind to all IP addresses on the machine. When you enable DynamicServerList, these IP addresses would be sent to the Apache plugin. If there's an IP address that the Apache server can't connect to (e.g. a backup interface), you might have issues. This is not the error I would expect to see, but I have had issues with this before where everything in your scenario was exactly the same, except for the specific error message but I also wasn't using Apache 2.4. By the way, disabling DynamicServerList doesn't mean that Apache will keep sending requests to the downed server, thus making user experience very poor. Instead, whenever it detects that the server is down (e.g. via a series of Connection Refused errors), it will mark it as down and keep retrying from time to time. DynamicServerList is meant to avoid this and also to allow you to add Managed Servers to your Cluster without having to touch your plugin configuration.