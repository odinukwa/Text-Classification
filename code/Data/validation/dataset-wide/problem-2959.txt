The question is actually a fundamental and nuanced point of science. It goes from "this looks like it might be a good way to think about things" to "this is how things are." The way one thinks about that transition varies by time period. Because of the way you are phrasing the question, I have a feeling the modern scientific approach is the most meaningful, so I will do it first. Modern Scientific Approach In this scenario, we're going to need to define a few more propositions to properly capture the entire process, step by step. First, we are going to start with Pp, the "prevailing hypothesis." This is the presumed answer, based on what people knew at the time. It's also something we'll be overturning, so don't be surprised that you already know its false: 

The argument basically pre-supposes the conclusion in its second assumption. To make his argument work, his second assumption has to be rewordable to "material states are different than mental states," which is the conclusion. The only other possibility that I can think of for translating his second assumption is "two material brain states can be identical, but capture different facts," which is also a pre-suppositon of the conclusion. I think the thing he's getting at is that we do not have a rule for separating the brain states of true beliefs from those of false beliefs. However, the fact that we do not have them does not state that they do not exist. You cannot claim they are not different merely because you do not have a process for distinguishing them. His first assumption is tricky also. It sounds like a nice definition, and you are welcome to use it, but it is trivial to argue that beliefs are better modeled using modal logic because there are beliefs that are neither true nor false, such as the obvious paradox "I believe this sentence does not contain one of my beliefs." 

Do you want to be right? Or do you want to live a productive life? Validating every proof that comes across your table would quickly chain you down, verifying everything. Clearly there are points where we have to make judgement calls as to what to do with the proofs we don't have time to research. Do all arguments have to be accepted hook like and sinker? Perhaps there is something between "total hearsay" and "formally proven" which has some elements of both. If you can find one that works for you, you can attribute some level of confidence in an argument and work with it. Baysean inference is one which I have found useful, but I recommend you find what works best for you. If you're in the middle of an argument, and your opponent needs you to fully accept their claim on faith in order to continue, then the onus is on them to convince you that the argument can continue. The other approach, which I find highly productive, is to try to steer the argument in such a way that the veracity of the final result is no longer dependent on the claim being made. If I claim "blue is red," a highly tricky claim to make, but our eventual goal is to figure out what game to play tonight, you may be able to work around it so that we both agree that, regardless of whether blue is red, the game we'll choose is the same. If they wont take the time to work with you so you can understand the research behind their claim, and you can't nullify its importance towards the final result, then you're in a region of argument that is quite complex. There's myriad ways to go forward, at least one for every pair of people on the planet who disagree about something (which is quite a few!). However, I have found that, if you break up the problem enough, it often will fall into one of those two categories, and the problem can be solved accordingly. 

One philosophy I have found is that it matters not how much you give, but how you give it. My favorite wording for it is "a gift given freely." If you give gifts to charity freely, the result will always be more fortuitous. One existing argument along these lines shows up in a traditional method of teaching martial arts in oriental nations (and possibly other places as well). The "payment" paid to the teacher is treated as a "gift" rather than a "fee." The idea is that the money is treated as a gift; the teacher is under no obligation to teach you, and he has no obligation to teach you any specific thing you want to learn. Once it becomes a "fee" you are literally buying their time, and that has a fundamentally different flavor. I have seen this in reference to a Karate teacher who would give free lessons in the park to whomever came by. He had quite a following with many dedicated disciples. They sought to pay him for his time, but he always dodged it. Finally they cornered him, begging to pay him for his services. He looked them in the face and told them, "if you paid me for my time, you could not afford it." He then went right back to giving the lessons away for free. 

You are comparing two different cases. One is "the probability of landing heads on the next flip" and the other is "sum of the number of heads." The latter is governed by the Central Limit Theorem, which explains why the sum converges so rapidly (in many cases). Summing acts very differently than simply asking "what's the next result," and its the summing that causes the convergence. From the perspective of freeing ourselves from this "paradox" the key is that for every case where we have N tosses that landed heads, we also have a corresponding case where we have N tosses that landed tails. From the perspective of "sum of the number of heads," this matters. In the case where we discus "the coin has landed heads up 10 times in a row," it does not, because the fact that we have stated it has landed heads up 10 times precludes us from considering the case where it landed 10 times tails up. The 10 tails case doesn't have any effect on our discussion of the next coin flip because it simply didn't happen. We aren't interested in it. It's a bit easier to visualize the non-paradox if, instead of counting the number of heads and tails, we assign heads and tails numeric values (such as +1 and -1) and take the average. Most humans find it easy to intuit that the average of a sample will approach the average of the random variable as N gets large. This visualization can be done in many ways. One way is to look at all the different sequences of heads and tails that can occur. Clearly each sequence occurs with equal probability (with a fair coin). However, when you put these into "bins" based on how many heads you see, you find that there are many more sequences with an "average" number of heads than those which have extraordinary numbers of heads. This causes us to see average numbers more often than extraordinary numbers. To give a concrete example, the strings of length 3: 0 heads = 1 string ({T, T, T}), 1 heads = 3 strings ({H, T, T}, {T, H, T}, {T, T, H}), 2 heads = 3 strings ({H, H, T}, {H, T, H}, {T, H, H}), 3 heads = 1 string ({H, H, H}). 8 total strings, each with a probability of occurring of 1/8. Thus, by addition, probability of 0 heads = 1/8, 1 heads = 3/8, 2 heads = 3/8, 3 heads = 1/8 

If your premise was untrue, and in fact a holy book is a necessity for morality, then that would indicate that morality is fundamentally entwined with our language. This opens up a disturbing can of worms regarding language, reading, and several other learned concepts. While such an argument does not refute the possibility that a holy book is a necessity for morality, it does certainly provide several reasons to consider the possibility that such a book is not a necessity for morality. 

As we continued in comments, it was possible to get closer and closer to an answer that is more personalized. At the end of the discussion, you said something which spawned this answer. 

I would start from this question: are there thoughts that cannot occur without "ordinary language?" The dialogue regarding this question would form a framework for defining several words we are stumbling over, such as "ordinary language" "metathought" and arguably even "thought" itself. It might even have to define "impossible!" This sort of dialogue will be essential, because the answers are many. For instance, there is still a debate as to whether any thought can occur without language. A belief in that philosophy will quickly reduce your original question to triviality. 

Let's presume Mendel was a modern scientist, perhaps a grad student. His adviser had noticed that Pp just didn't feel right in a few interesting corner cases, so had Mendel do a quick screening test. Sure enough, Pp felt off. The proportions were off by a long shot. In fact, it looked like a 3:1 ratio in some situations, not a 1:1 ratio that Pp claimed would be found. Mendel then develops his new theory of genes (rules L, in your phrasing) which predicts a 3:1 ratio. Now he needs to "prove" it. To do so, he sets up an experiment and makes a hypothesis H1: 

This question is phrased as a legal question, which belongs on Law.SE. However, it seems as though the philosophical question you are getting at is whether you are responsible for your actions if someone else tells you to do it. Obviously there's many opinions in philosophy about this, but the current prevailing opinion would be "yes, you are responsible for any action you do under your own free will, even if you are being asked to do so by someone else." This opinion is maintained solidly by the result of the Nuremberg trials, which made it very clear that a solider could not simply claim they were "following orders" and get off for crimes against humanity. There is an exception for duress, which is when the person asking you to do something is sufficiently forceful that it is reasonable to say you had no freewill. For example, you are rarely considered responsible for actions done while a gun is held to your head, up to but not including murdering someone yourself. The person doing the forcing is responsible for their actions, of course, but not automatically responsible for yours. They become responsible when it becomes clear that they took responsibility away. This is the basis for arguments regarding statutory rape. The idea is that it is too easy for someone older to take over a situation thoroughly enough that a younger person cannot be deemed responsible for their actions, because they simply didn't know better. There are always grey areas. However, hopefully those cases will be enough to frame any future questions you might have about responsibility. 

Alfred Tarski worked on phrasings like that. However, he added some quotes to the phrasing to make it more grammatically correct. He defined his material adequacy condition: 

I would be wary generalizing all of mathematicians, but you make a valid point. When a person uses an English phrase in the form of "I seek X for the sake of itself," that phrase is used to state that that person believes X has intrinsic value. Thus people who study math "for the sake of itself" self identify as people who believe math has intrinsic value. Whether that extends to all mathematicians is a much more nuanced question. It seems entirely possible that an individual labeled as a mathematician could study math because it is a tool to achieve a goal. On the other hand, it is also possible to define "mathematician" to be "someone who believes math has intrinsic value" if you are comfortable with your definition potentially straying from the "mathematician" used by others who do not share your definition. 

One reason you may not see empiricism on Chinese thought is that you are looking for western style empiricism, with a clear cut boundary between "the truth" and "what we sense." In many Eastern philosophies (I know Chinese thinks this way, and I believe others do as well), the philosophy automatically blurs these because the language encourages it. Western language draws a very strong division between "us" and "the world." There is a thing called "the truth" that is out there, and ontology covers it. Then there are these things called "senses," that are frustratingly hard to define which lead us towards a mind-body division, and so forth. We divide to make sense of the problem. Eastern languages, especially those with a Chinese background, focus much more on the relationships between entities, rather than the entities themselves. This is often lost in translation, so sometimes you have to really look for it. The result is a very different way at look at the world. Western thought is primarily focused on "good" and "evil," "true" and "false." These are eternal opposites. What is true is never false. The fundamental Chinese duality, yin and yang, are constantly in motion as they describe an ever changing relationship between individuals. Because of this, much of what we look for in epistemology from a Western perspective is actually bundled into the language, so there is less of a need to explicitly talk that way. As an example, Chi is one of the most debated topics between Eastern and Western sciences. Western science claims it is not "real" because it cannot be measured. They clearly are making such a claim from an epistemological perspective. The Eastern teachers who are teaching "Chi" say it is real because you can feel it. They are clearly also coming from an epistemological perspective. However, that perspective is dramatically different from one of Western thought. Accordingly, they come to the belief that something is empirically validated along a very different path than we do when we seek to empirically validate something. Sometimes this helps, sometimes it hurts. As an example where their method has some benefit, consider the body-mind problem in Western philosophy. That issue has sparked tremendous debate over the centuries. From an Eastern perspective, it's a nonstarter. From their perspective, there is no reason to believe the two need to be treated as independent in the first place, for you only ever find them together. They have no need to figure out what a body is on its own, and what a mind is on its own, only how body and mind interact in harmony. (and, at some point, some philosophies shift to a claim that one half or the other is simply an illusion, and that they were just one piece the entire time) 

I think therefore I am - A definition of the Self is essential. Past performance predicts future success - A definition of Time or at least a time-like-illusion Actions matter - My Self can influence something (even if, in the most extreme worldviews, it can only influence itself) 

As an example in math, consider my favorite theorems: Godel's Incompleteness Theorems. They make some frighteningly deep claims about the abilities of mathematical proofs. They claim that many proofs we desperately wish could exist are, in fact, impossible. This would be a gigantic inductive reasoning leap, given that most people actually believed the contrary. His proof breaks that claim up into two parts. The first is an inductive step: he assumed the Peano axioms of arithmetic. For those who are not familiar, these are pretty benign axioms. Handwaving the exactness, they basically describe the ability to count to a number in a very formal manner. It is rare to disagree with the Peano axioms of arithmetic because they're just so natural. Godel then proceeded to attach a giant block of deductive reasoning that proved his claims about the limits of proofs. This bothered many mathematicians. Godel's results were not popular at the time, but he had succeeded as isolating the inductive portions of his theory to only the most basic of concepts no mathematician dared challenge. (As a result, many mathematicians have challenged the basic assumptions, and in doing so dodged Godel's claims. However, they have to continuously be cautious. If they accidentally accept his assumptions along the way, the deductive part of his proof comes back in full force)