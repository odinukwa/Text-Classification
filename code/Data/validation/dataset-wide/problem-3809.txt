For the commutative case. Take the set of all rational numbers whose denominators are coprime with a fixed integer $n$. Then the only prime ideals are generated by the prime divisors of $n$. More generally, take any PID and take its ring of fractions wrt all the elements coprime with some fixed element; you get a desired ring. 

Look at the graph with edge set $E'(T)=E(G)-E(H(T))$. It is a forest (since $E'(T)\subseteq E(T)$), and the set of its odd vertices coincides with the set $V_1$ of odd vertices of $G$. In particular, if $G$ is even then this forest should contain no edges (as domotorp has already showed). Next, I claim that each tree $T$ contains a unique subset $F(T)\subseteq E(T)$ such that $E(G)-F(T)$ is even. Indeed, one such set is $E'(T)$. On the other hand, the existence of the edge $uv$ in $F(T)$ is determined by the parity of the number of vertices from $V_1$ in (any) component of $T-\{uv\}$. This yields that $H(T)=H(T')$ if and only if $F(T)=F(T')$. This provides a fast algorithm of checking this property: $F(T)$ can be found pretty fast, and then one just needs to check whether $F(T)\subseteq E(T')$ (then necessarily $F(T')=F(T)$). Finally, take any forest $F$ such that $G-F$ is even. Then $F$ lies in some tree $T$, and $F(T)=E(F)$. Therefore, each even subgraph $K$ such that $E(G)-E(K)$ is a forest is realizable as $H(T)$. 

$\let\eps\varepsilon$It is easier to consider a function $f(x)=-\log g(e^{-x})$. Then $f\colon (0,\infty)\to(0,\infty)$ is still continuously differentiable and increasing (the bordering conditions are almost not in the game), and it satisfies $$ f((t+1)x)<f(tx)+f(x) \qquad (*) $$ for all $x\in(0,+\infty)$ and positive integer $t$ (I do not know why you set $t>1$...). Now let us consruct such an $f$ violating the desired condition. Firstly, we set $f(x)=x+\eps$ for a small $\eps>0$, so that it satisfies $(*)$. Next, we perturb $f$ in a small neighborhood of $x=5$ so that now $f(5)$ is slighly greater than $f(2)+f(3)$, thus violating the desired condition. Surely, now it also violates $(*)$, but this happens only for $x$ being in a small neighborhood of $5/2$, or for $x$ being almost in $(0,5/3)$ (or, recursively from $5/2$, for $x$ around $5/4$ and smaller ones). Thus, now it is easy to perturb $f$ in a neighborhood of $5/2$, and then simply to increase it on, say, $(0,\,1.9)$ so that it becomes, say, $1.1x+\eps$ on $(0,\,1.7)$. The details can be simply recovered. 

One can construct surfaces with mean curvature uniformly close to $1$, but look like collections of almost-touching spheres connected by perturbed catenoidal necks. The work of Ciraolo-Maggi (here) shows a certain stability result for these configurations. See the references therein for the constructions of these surfaces, and a discussion of other results (e.g. Hausdorff closeness to a single sphere with more hypotheses, like convexity or smallness of oscillation of mean curvature relative to the largest principal curvature). 

To do De Giorgi-Nash-Moser it is important that $f$ is in $L^q$ for $q$ larger than half the dimension. A heuristic is scaling: if $v$ solves $-\Delta v = f$, then the right side for the rescaling $v(\epsilon x)$ is $\epsilon^2 f(\epsilon x)$, whose $L^q$ norm is like $\epsilon^{2-n/q}$, so zooming in helps when $q > n/2$. When in dimension $4$ or higher, one can take e.g. $v = \sum h_k\varphi(2^k x)$ for some smooth $\varphi$ that is $1$ in $B_1$ and vanishes outside $B_2$. Taking $h_k = 1/k$ makes $v$ unbounded ($\log\log$ growth near the origin) while $f := -\Delta v$ is $L^2$ (the integral of $f^2$ is like $\sum h_k^2 2^{(4-n)k}$). It seems to me that for such a choice of $f$, the solution $u$ will immediately become unbounded since $u - v$ is unbounded initially and solves the heat equation. Note also that indeed, in Deane's computation, the (reciprocal) exponent on $f$ looks like $n/2$ for large $p$. It is important to use that $f \in L^q$ for $q > n/2$, for instance as follows (in the elliptic case for simplicity): Let $A_p = \left(\int u^{p\chi}\right)^{\frac{1}{p \chi}}$, with $\chi = n/(n-2)$. Applying Holder to the last term in the first line of Deane's computation gives an inequality like $$A_p \leq (pC(f,S))^{1/p} A_{\gamma p},$$ where $\gamma < 1$ depends on $q/(q-1) < \chi$, and $C(f,S)$ depends on $f$ and the Sobolev constant. Iteration gives $$A_{2\gamma^{-k}} \leq C(f,S)^{\sum j\gamma^j} \|u\|_{L^2(Q)}.$$ Taking $k \rightarrow \infty$ gives an $L^{\infty}$ bound in terms of the desired quantities and the Sobolev constant. I'm not sure how to remove dependence on the Sobolev constant. 

Well, by Cayley--Hamilton, each matrix $A\in {\rm GL}(n,p)$ generates an at most $n$-dimensional subalgebra ${\mathbb F}_p[A]\subseteq M(n,p)$ thus containing at most $p^n-1$ nonzero elements. Hence the order of $A$ cannot exceed $p^n-1$. On the other hand, consider a degree $n$ monic polynomial $P_n$ whose root is a generator $\xi$ of ${\mathbb F}_{p^n}^*$. Then a matrix with $P_n$ as its characteristic polynomial has order at least $p^n-1$ since $\xi$ is its eigenvalue. ADDENDUM. if you wish the order to be the power of $p$, then the answer is $d=p^{\lceil \log_p n\rceil}$. Since the order of $A$ is divisible by the multiplicative orders of its eigenvalues, all the eigenvalues should be $1$. Hence the characteristic polynomial is $(x-1)^n$, so $A^d-I=(A-I)^d=0$. On the other hand, if $A=I+J$ is the Jordan cell of size $n$ (with eigenvalue 1), then $A^{d/p}=I^{d/p}+J^{d/p}\neq I$, but $A^d=I+J^d=I$. NB. The subgroup of all (upper-)unitriangular matrices is a Sylow $p$-subgroup in ${\rm GL}(n,p)$. So you may concentrate on it when looking at the elements of this kind. ADDENDUM-2 (much later). This is to answer the question in the comments about the maximal order of an element $f\in AGL(n,q)$, where $q$ is a power of $p$. Write $f(x)=Ax+b$. If $1$ is not an eigenvalue of $A$, then $f$ has a fixed point (the equation $f(x)=x$ has a solution), so we may regard it as an element of $GL(n,q)$, and the maximal order of $f$ is again $q^n-1$. So we are concerned with the case when the minimal polynomial $\mu(x)$ of $A$ vanishes at $1$, say $\mu(x)=(x-1)^k\nu(x)$, where $\nu(1)\neq 0$. Then $A$ is similar to a block-diagonal matrix with blocks having minimal polynomials $(x-1)^k$ and $\nu(x)$ (in view of $\mathbb F_q^n=\mathop{\mathrm {Ker}}(A-I)^k\oplus\mathop{\rm Ker}\nu(A)$). So the order $d$ of $A$ does not exceed $p^{\lceil\log_p k\rceil}(q^{n-k}-1)$ if $n<k$, and $p^{\lceil\log_p n\rceil}$ otherwise. If $n>3$ (or $n=3$ and $q>2$), one may easily see that this bound does not exceed $q^{n-1}-1$. So $f^d$ is a translation, which yields that $f^{pd}=\mathord{\rm id}$, and $pd\leq p(q^{n-1}-1)<q^n-1$. Thus the maximal order of $f$ in these cases is still $q^n-1$. We are left with the cases $n=1$, $n=2$, or $n=3$, $p=2$. When $n=1$, the answer is obviously $\max(p,q-1)$. When $n=2$, the only case left is $d=p=q$ achieved when $A$ is similar to the Jordan cell $\begin{pmatrix}1&1\\0&1\end{pmatrix}$. In this case, $f^p(x)=x+(A^{p-1}+\dots+I)b=x$ unless $p=2$, when $f^2(x)=x+\begin{pmatrix}0&1\\0&0\end{pmatrix}b$. So the answer is still $q^2-1$ when $q>2$, and $4$ otherwise. Finally, if $n=3$ and $q=2$, then the order of $A$ having eigenvalue $1$ exceeds 3 only if $A$ is similar to $3\times 3$ Jordan cell (then $d=4$); but in this case $f^4=\mathord{\rm id}$. So this is not an exception. Summing up, the only cases when the order may be greater than $q^n-1$ are: (1) $n=1$, $q=p$ (the maximal order is $p$), and (2) $n=2$, $q=2$ (the maximal order is $4$). 

The constant $C_H$ must depend on $x$ and $r$. Consider for example $u = e^{\frac{1}{2}|x|^2}$, which satisfies $$\Delta u = (1+|x|^2)u.$$ Then $u$ has a minimum of $1$ at $0$, which clearly doesn't control the maximum of $u$ on $B_{\delta r}$ times any constant independent of $r$. Furthermore, $C_H$ must depend on $x$ because if we fix $r$ then the ratio $$\frac{u(x+r)}{u(x-r)}$$ blows up as $x \rightarrow \infty$. 

The answer to both questions is yes. The key is that being a viscosity subsolution is equivalent to satisfying the sub-mean value property $$u(x) \leq \frac{1}{|\partial B_r|}\int_{\partial B_r(x)} u \,dA$$ for all $r$ and $x$. Indeed, if $u$ is a viscosity subsolution then one can compare with the harmonic function with the same values on $\partial B_r(x)$. The other direction comes directly from the definition of viscosity subsolution. The statement (i) follows quickly by Fubini. For (ii), note that by integrating in $r$ one also has the sub-mean value property in solid balls. Let $(f)_r(x)$ denote the average of $f$ in $B_r(x)$. It follows that $(\alpha - u)_r(x) \leq 2^{2n}\inf_{B_r(x)}(\alpha - u)_{2r} \leq 2^{2n}\inf_{B_r(x)}(\alpha - u) \rightarrow 0$ as $r \rightarrow \infty$. As a consequence, $[\alpha - u]_r \rightarrow 0$ as $r \rightarrow \infty$. 

Yes, I think the estimate you propose is true. As a simple case take $f = 0$ and $M = B_1 \subset \mathbb{R}^n$. By adding a constant assume that $\inf_{B_1} u = 0$ and $\sup_{B_1}u = K,$ and note that these extrema are on the boundary. Note that $u(0)$ is closer to $0$ or $K$, say $u(0) > K/2$ without loss of generality. Then by the Harnack inequality we have $u > cK$ in $B_{1/2}$, so the function $$c(n)K(|x|^{2-n} - 1)$$ is a lower barrier in the annulus $B_1-B_{1/2}$. In particular, at the point where $u$ takes its minimum we have $|h| > c(n)K$ which gives the estimate. In a more general domain we can argue similarly; take an interior ball touching the point on the boundary where $u = 0$ and argue that $u$ is no larger than $C\sup|h|$ at its center, and similarly take a ball touching the point where $u = K$ and argue that $u$ is larger than $K - C\sup|h|$ at its center. If $K$ is much larger than $\sup|h|$ we contradict the Harnack inequality (with a constant depending on the geometry of $M$). Finally, if $f$ is nonzero similar arguments should work since we still have the Harnack inequality (now depending on $\sup|f|$) and for a barrier we can take $|x|^{-\alpha}$ for $\alpha$ large depending on $\sup|f|$. 

$\def\Hadw{\mathop{\rm Hadw}}$This is true for finite graphs, and false for (not necessarily connected) infinite graphs. Right now I do not know what happens for infinite connected graphs. 1. Each component $G_1\subseteq G$ corresponds to an isolated vertex $v_{G_1}$ in $\Hadw(G)$ and a component $\Hadw(G_1)\setminus \{v_{G_1}\}$; this component is empty if $G_1$ consists of an isolated vertex. For finite graphs, this means that we find the number of isolated vertices and the Hadwiger graphs of other components; so the problem reduces to the same problem for finite connected graphs. For infinite graphs, this leads to the counterexample. Let $G$ be a union of a countable number of components none of which is an isolated vertex, and let $H$ be $G$ augmented with an isolated vertex; then $G\not\cong H$ but $\Hadw(G)\cong \Hadw(H)$. The rest part is devoted to the reconstruction of a connected graph $G$ by its Hadwiger graph. 2. In this case, we will show a bit more, namely: Knowing $\Hadw(G)$, we can find all the vertices in $\Hadw(G)$ corresponding to the vertices of $G$ (then the induced graph is isomorphic to $G$). We proceed by the induction on $|V(G)|$. If $|V(G)|=1$ then the statement is obvious. Any vertex $P\in V(\Hadw(G))$ has degree 1 exactly if $P=V(G)\setminus \{v\}$, where $v\in V(G)$ is not a cut vertex; in this case $\{v\}$ is its only neighbor. Thus we may reconstruct all the vertices of $\Hadw(G)$ which correspond to non-cut vertices of $G$ (notice that there is at least one such vertex!). Let $T=\{v\}\in V(\Hadw(G))$ be one of such vertices. Denote by $N$ the set of all neighbors of $v$ in $G$; denote $$ L=\{X\in V(\Hadw(G)): (\{v\}\cup N)\subseteq X\}. $$ Notice that $L$ is nonempty. Consider now the distances $d(S,T)$ from every vertex $S\in V(\Hadw(G))$ (distinct from $T$ and $V(G)$) to $T$. (i) If $v\notin S$ but $S\cap N\neq\varnothing$ then $d(S,T)=1$. (ii) If $S\cap(\{v\}\cup N)=\varnothing$ then $d(S,T)=2$ due to a path in $G$ from $v$ to $S$; moreover, in this case $S$ has a neighbor in $L$. (iii) If $v\in S$ but $N\not\subseteq S$ (that is, $v\in S$ but $S\notin L$) then $d(S,T)=2$ due to any vertex in $N\setminus S$; but in this case $S$ has no neighbor in $L$. (iv) If $S\in L$ then $d(S,T)=3$ since the distance from every neighbor of $S$ to $T$ is 2. Thus we can reconstruct the set $L$ (due to the distance 3 from $T$), and then set of all $S$ such that $v\in S$ but $S\notin L$ (due to the distance 2 from $T$ and non-existence of a neighbor in $L$). Thus we have reconstructed all $S\in V(\Hadw(G))$ containing $v$. Now we can remove all these vertices obtaining the graph $\Hadw(G-\{v\})$ for which the induction assumption is applicable. 

The equation $F(D^2u) = g$ for $g \in C^{\alpha}$ should have a $C^{2,\alpha}$ estimate by perturbation theory. See for instance Caffarelli-Cabre, Ch. 8. The idea is that the constant-coefficient equation $F(D^2w) = f(x_0)$ has a $C^{2,\alpha}$ estimate (Evans-Krylov), so by using the quadratic approximation to $w$, ABP, rescaling and iteration we can produce a paraboloid approximating $u$ to order $O(|x-x_0|^{2+\alpha})$. (Since we use ABP I think that some Holder condition on the growth of the $L^n$ norm of $g$ should suffice). 

Also, in two dimensions (real case again) one has special techniques such as the partial Legendre transform (obtained by taking the Legendre transform along lines in some direction $e$). If $\det D^2u = 1$ then its transform $u^*$ is harmonic and $u^*_{ee} > 0$, and one can get an upper bound for $u_{ee}$ by using the Harnack inequality to get a positive lower bound for $u^*_{ee}$. 

Yes, this follows from Schauder theory for the Monge-Ampere equation and for linear equations. Subtracting the equations $\det D^2u_k = f_k$ and $\det D^2u = f$ gives, for $v_k = u_k - u$, the equation $$a_{ij}(x) (v_k)_{ij} = f_k - f$$ where $a_{ij}$ are coefficients depending on $D^2u_k$ and $D^2u$ (to see this observe that $f_k - f = \int_{0}^1 \frac{d}{dt} \det(tD^2u_k + (1-t)D^2u)\,dt$). By Caffarelli's Schauder estimates, the $a_{ij}$ are $C^{n,\beta}$ and uniformly elliptic when we step away from the boundary. Say $B_2 \subset \Omega_k,\,\Omega$ after an affine transformation. Linear Schauder theory gives (take $n = 0$ for simplicity) $$\|v_k\|_{C^{2,\beta}(B_{1/2})} < C(\|f_k-f\|_{C^{\beta}(B_1)} + \|v_k\|_{L^{\infty}(B_1)}).$$ By hypothesis, the first term on the right side goes to zero, and it is easy to see that the second term goes to zero using the maximum principle (e.g. apply the ABP maximum principle to $v_k$, which is small on the boundary of the common domain of definition for $u_k$ and $u$ by the Alexandrov maximum principle). 

For the sake of simplicity, let us assume that $[a,b]=[0,1]$. $C^k$ always means $C^k[0,1]$. We will even approximate $f$ in $C^n$-norm satisfying your additional condition. 

The answer is still No, but for not that obvious reason. To show that, let us start with a positive claim. 1. FIrst of all, an operator $T$ is semisimple iff all the factors in the prime expansion of its minimal annihilating polynomial $\mu$ are distinct. Actually, the algebra $K[T]$ is isomorphic to $K[X]/(\mu)$; so, if there are no multiple factors, then this algebra is a direct sum of fields, and each its finitely generated module is semisimple. Otherwise, if $\mu=p^2q$ with $p$ nonconstant, then the annihilator space of $p(T)$ has no complement. 2. Now assume that the extension of $K$ generated by all the roots of characteristic polynomials of $T_1$ and $T_2$ is separable. Then they should be diagonalizable over this extension by the reasons of the minimal polynomial. Since they commute, they are simultaneously diagonalizable. Hence their sum and product are also diagonalizable, and their minimal polynomials have no multiple roots (from separability!) and hence no multiple factors. So $T_1+T_2$ and $T_1T_2$ are both semisimple. 3. And here is a counterexample for non-separable case. Let $K=F_2(t)$ be the field of rational fractions over $F_2$. Set $T_1=\begin{pmatrix}0&0&1&0\cr 0&0&0&1\cr t&0&0&0\cr 0&t&0&0\end{pmatrix}$ and $T_2=\begin{pmatrix}0&1&0&0\cr t&0&0&0\cr 0&0&0&1\cr 0&0&t&0\end{pmatrix}$; their common minimal polynomial is $X^2-t$, so they are semisimple (this polynomial is irreducible although not separable). But their sum is $S=T_1+T_2=\begin{pmatrix}0&1&1&0\cr t&0&0&1\cr t&0&0&1\cr 0&t&t&0\end{pmatrix}$ with $S^2=0$, and their product is $P=T_1T_2=T_2T_1=\begin{pmatrix}0&0&0&1\cr 0&0&t&0\cr 0&t&0&0\cr t^2&0&0&0\end{pmatrix}$ with the minimal polynomial $(X+t)^2$. Hence both are not semisimple. One may present a direct example of a spaces that cannot be complemented as $\langle e_2+e_3,e_1+te_4\rangle$ in both cases. In fact, this example was obtained from the action of algebra $K[X,Y]/(X^2-t,Y^2-t)$ on its regular module; $T_1$ and $T_2$ correspond to $X$ and $Y$, respectively.