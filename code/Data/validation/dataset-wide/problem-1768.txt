I need to use a port that is already defined becasue I am upstream from a middlebox that only allows connections on ports allocated to specified services, and port 22 is blocked. 

I am trying to get a modern GCC to compile on Centos 6.4. The problem is that Centos does not have a modern glibc and GCC 4.8.x and 4.7.x keep giving me the following compile error: 

RHEL 7 includes in the official repository. However, this module does not install mod_php. I have tried all of the approaches for installing rh-php70-* and none of them installs and registers the appropriate php module. How does one do it? 

Is there a way to read the certificate in a consumer credit card EMV chip and use this to authenticate to an Apache web server using the client-side certificate support in SSL/TLS? 

What are the network protocols that can be used to measure the system clock (time) of a remote server? So far I have: 

We would like to have a network backup system with a user that can read any file on our servers but not write any file. Is there any way to do this under Linux (and specifically Fedora)? We would rather not have a remote that can erase any file... 

So the question is : Does anybody know of a way of tracking down the location of the module file and the conf file that loaded it Worth noting that these are not loaded from httpd.conf (/etc/httpd/conf/httpd.conf) or the conf.d/*.conf location that httpd.conf includes. However there are conf files here that include other locations and these include others and its all a bit rabbit hole. So if there is a command to get the info I need then all the better 

I am looking through the modules that my apache server has loaded. To get this list I am using the following command: 

When I perform the backup (initiated via a cron job) I set a .htaccess rule on my site to redirect any requests to a static "down for backup, back shortly" page. Once the backup completes I remove the rule and the site reopens. All well and good, it has been like this for years and as you can imagine this works perfectly well and I haven't had any issues. However... I would like to not have to close the site during the backup, so the question is can I do this with mysqldump? Is the tool capable of handling conditions where data changes after the backup initiates? If it does live backups can I guarantee that I won't get a corrupt backup? Is there a better way of doing a live backup? 

We wanted to block a specific directory from robots. We had a robots.txt entry but it's being ignored by many robots. So we added this snippit below to our apache configuration file; note that we uncommented the Wget because we wanted to allow that. It works by blocking based on the . The list comes (obviously) from $URL$ when we modify configuration files with information we get from the Web we always put the back-pointer so we know where it came from. 

The problem here is the is part of the modern and Centos 6.4 doesn't seem to have it. I've tried building my own but as soon as it gets installed and in my local I can't run any other programs, because all of the existing executables on the system try to link against it and they fail. I want to use the new compiler because it has dramatically better handling of C++ STL code, and because the optimizer in GCC 4.8 makes my code run in 1/2 the time as the GCC 4.4.7 compiler that comes with Centos. Any suggestions on how to do this? 

It appears that Hive, Impala, Pig, and others all provide SQL or SQL-like access to data stored on Hadoop clusters. They all seem to have support for HDFS, S3, and other forms. So why are there so many different ways for accessing Hadoop information by SQL, how are they different, and how does their performance compare? Do we have so many different versions because all of the projects were started at the same time for more or less the same reason? If so, is there an advantage to knowing more than one of them? I have found several articles that attempt to explain the differences (e.g. 10 ways to query hadoop with SQL and Selecting the right SQL on Hadoop, but mostly they just list features. 

Rather than copy the MDF files around, a better solution is to take a backup of the database and then restore that backup onto your target SQL instance. Assuming you are using SQL Management Studio, you can do this by right clicking on your database and choosing: 

As a possibly related issue, today I experience a server outage for reasons yet unknown. As part of the investigation into this I used Plesk to reboot the server. This action completed successfully and was the last action I performed in Plesk. Since the reboot I can access all services other than plesk itself. Having never encountered this issue before, and also being something of a newbie when it comes to administering a Linux based server, I have no idea where to go next? Is there are log file I can check for service start errors? Is the solution staring me in the face? Or maybe something else. Thanks in advance EDIT Something else that may or may not be relevant: After rebooting, and before attempting to access Plesk again I installed sysstat with yum in order to be able to use iostat. Other than that no other changes have been made to the server. EDIT 2 The last entry in the file is 

I have a Centos VM running with SELinux enabled. I wish to have sshd listen to another port --- says, 993. I've modified the sshd_config file to listen to another port, but SELinux is getting in the way. I don't want to disable SELinux. How do I tell SELinux that it's okay for sshd to be reading TCP connections on port 993? The correct command to use is but I cannot use that command because port 993 is already in use in another policy: 

An Amazon Machine Image contains an EBS volume. Is there a way to get the EBS volume out of the AMI without booting the AMI? 

We're currently using Mailman as a mailing list manager. Mailman modifies the content of mail messages. The problem is that some of our users are sending digitally signed messages and the modification makes the signature break. I've seen this behavior with Apple Mail, Outlook, and Thunderbird. The problem seems to be this: S/MIME signed messages are implemented with a MIME Content-Type. Mailman wraps this inside a MIME Content-Type. None of the mail readers look inside the outer for the inner . We won't be able to get the clients fixed. Is there anyway to modify Mailman so that it doesn't have this behavior? 

When using HTTPs/TLS/SSL site traffic is encrypted between your browser (or the application initiating the connection) and the web server that is serving pages to you. This means that if any intermediary attempts to "listen" to your requests/responses all they will see is encrypted traffic. This encryption model is the same regardless of whether you are using a VPN or a standard internet connection. 

I have been staring at this for a while not I can't fathom it, probably a wood for the trees scenario. I am attempting to use HTACCESS to block certain inputs to a web server, so I have added the following directives: 

It would seem that when I attempt to access my Plesk admin page this is unavailable. After doing some cursory checks I discovered that the server was not listening for incoming requests on port 8443 (verified remotely via telnet). I therefore assumed that the service was not running and therefore issued the following command via SSH under the root account: 

To be honest there are quite literally hundreds, maybe tens, of ways of doing this. Personally I would use a simple batch file that maps a network drive (net use) and then copies the files. Rather than copy or xcopy I would recommend using robocopy as this support functions such as mirroring. As for executing installers, thats a different question entirely. For this you could use remote command (rcmd) to execute the installer once you have copied it across. 

We are using Lustre in a cluster with approximately 200TB of storage, 12 Object Storage Targets (that connect to a DDN storage system using QDR Infiniband), and roughly 160 quad and 8-core compute notes. Most of the users of this system have no problems at all, but my tasks are I/O intensive. When I run an array job that has 250-500 processes that are simultaneously pounding the file system typically between 10 and 20 of my processes will fail. The log files indicate that the load on the OSTs are going over 2 and that the Lustre client is returning either bad data or failed function calls. Currently the only way we have of resolving my problem is to run fewer simultaneous jobs. This is unsatisfactory, because there is no way to know in advance if my workload will be CPU-heavy or I/O heavy. Besides, just turning down the load isn't the way to run a supercomptuer: we would like it to run slower when running under load, not produce incorrect answers. I'd like to know how to configure Lustre so that clients block when the load on the OSTs goes too high, rather than having the clients get bad data. How do I configure Lustre to make the clients block?