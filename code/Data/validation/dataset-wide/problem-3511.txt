This is at the same time 1) a little old and 2) provides a deeper and more general answer that what you might be looking for, but I would still encourage you to go through it. $URL$ with a preview in $URL$ (starting around 1'07) and a complete didactic overview at $URL$ and $URL$ Among other things, you will learn that -- for most purposes -- it does not matter that much how much or in which country Germany (or any other country for that sake) has debts, but that the whole network or obligations is really what matters. 

I might be repeating things which have been said before, but here is my take on this. I think we face a usual problem when comparing two different models. What an "equivalence" means is not completely obvious because the two definitions lie in different worlds, or different models. However, if "equivalence" is properly define, I think one can make sense of Osborne definition and show that it is indeed "equivalent" to a NE. The solution concept underlying the quoted section would be something like the following : 

I think this cannot happen with risk averse senders, risk neutral receiver, and $A$ rich enough. For example, and to stick to the canonical signaling model, suppose that $A$ is the positive real line and senders' utility $u$ is increasing in $a$ while receiver's have linear utility decreasing in $a$. (Admittedly, this is only a partial answer as the framework is much less general that the one in your question, so it might not be satisfactory to you. I still provide an argument in case you were ok with these assumptions) To derive a contradiction, suppose that at an equilibrium $\sigma^m_R(a') > 0$ and $\sigma^m_R(a'') > 0$ for some $a' \neq a'' \in A$. Let $$a''' \equiv \frac{\sigma^m_R(a')}{\sigma^m_R(a') + \sigma^m_R(a'') } a' + \frac{\sigma^m_R(a'')}{\sigma^m_R(a') + \sigma^m_R(a'') } a''.$$ By risk aversion $$ u[ a''' ] > \frac{\sigma^m_R(a')}{\sigma^m_R(a') + \sigma^m_R(a'') } u(a') + \frac{\sigma^m_R(a'')}{\sigma^m_R(a') + \sigma^m_R(a'') } u(a'').$$ $$ [\sigma^m_R(a') + \sigma^m_R(a'')] u( a''' ) > \sigma^m_R(a') u(a') + \sigma^m_R(a'') u(a'').$$ Under some continuity assumption, there must also exist $$ a '''' < a''' $$ such that $$ [\sigma^m_R(a') + \sigma^m_R(a'')] u( a'''' ) = \sigma^m_R(a') u(a') + \sigma^m_R(a'') u(a'').$$ So consider $\sigma^m_R{'}$ constructed in the following way 

Is this kind of behavior where people do not want to grab the last part of the pie (i.e., social endowment) documented in experimental economics? 

I don't have a specific paper for it (any intro to econ textbook would do), but I would also add the classical graphical measure of consumer and producer surpluses in ECON 101. (Especially for linear demand and consumer curves where is simplifies to measuring the area of a triangle. Can't do much more "measurement of land" than that) 

Arrow later corrected this mistake in the second edition of Social Choice and Individual Values (1963), and the formulation of Arrow's theorem using the Universal domain condition has now become standard. This being said, the initial error in the first edition of Arrow's book was rather minor, and the solution proposed by Blau does not reduce in any strong sense the importance of Arrow's result and approach. Intuitively, the conclusion remains that on a vast domain of relevant economic problems, no social welfare function satisfies a set of rather basic and reasonable conditions. So this might not be exactly the kind of errors you were looking for (definitely a seminal paper though!), but I like the example so much I could not resist posting it . If such brilliant people like Arrow make these kind of mistakes, I guess it takes a little pressure off for anyone else? 

In contract theory The first-best refers to the best you could do if you knew agents' preferences over labor an income (i.e., if you did not have to impose the incentive compatibility constraint), and the second-best is the best you can do if agents have to reveal their preferences themselves. In mechanism design A useful reference is Galichon, Alfred, Ex-Ante vs. Ex-Post Efficiency in Matching (May 21, 2011). Available at SSRN: $URL$ or $URL$ : 

Arrow's impossibility theorem was originally proven for an abstract set of alternative, allowing every possible preference profile over this set of alternatives. The question that Redekop (and others) asked was : is there an equivalent of Arrow's theorem when the alternatives are bundles of goods, and agent have "classical" preferences over those goods (monotonic, convex, continuous, selfish,...). More precisely, the question was whether there would exists a social welfare function satisfying the three Arrovian axioms (Independence of Irrelevant Alternative, Weak Pareto and Non-Dictatorship) on these Economic domains (see Le Breton, Michel, and John A. Weymark. "Chapter Seventeen-Arrovian Social Choice Theory on Economic Domains." Handbook of social choice and welfare 2 (2011): 191-299 for a great review, which this answer is based upon). Roughly, Redekop's work shows that, for some of those economic problems, if a domain of preferences admits an Arrovian social welfare function, the domain must be "small" in some topological sense. For instance, in Redekop (1991), he introduces an ingenious topology on sets of preferences he dubbed the questionnaire topology, and shows that, in a public goods economy, if a domain of preferences admits an Arrovian social welfare function, then the domain must be nowhere dense according to this topology (i.e. the closure of the domain contains no open set). 

the online appendix of which contains the complete STATA code of the statistical analysis. If the code is not available at the journal's webpage, other alternatives involve : 

The main economic journals are slowly starting to require authors to make their data and the code of their analysis available as part of the online appendix. When this is the case, it is easy to figure out which software was used. One example are recent publications in the American Economic Review. For instance, 

I found one implementation of TTC in at $URL$ However, it does not seem to include the two additional features I was mentionning. With of without these two features : I would still love to hear about more implementation of TTC, and about implementations of Boston. 

Patrick Prosser has some great java code at $URL$ which, among other things, can compute all the stable matchings in roommate problems. The code is for roommates problems, but Patrick's code allows preferences over roommates to include unacceptable roommates. To implement a two-sided market, just make sure any roommates on one side of the market views any other roommate on the same side of the market as unacceptable, and you're good to go. If (like myself) you are not used to java, you might struggle a little to get the code working. Here is a little tutorial for Mac OS, which worked for me as of today. 

The last condition is often referred to in the literature as the "cancelation" property. Now (Strong additivity) is not the most intuitive condition. In general, it can be hard to to check and navigate, which has spurred a large literature on alternative sufficient condition. I can send you a reading list if you are interested. Unfortunately, I don't remember of any paper directly tackling preferences over subsets of infinite sets, like your real interval. From my experience with these kinds of problems, changing the domain over which preferences are defined makes a huge difference in terms of the results that hold and the proof techniques you can use. If a result is not already out there in the literature, it is rarely easy to derive it from apparently similar results on different domains. 

I did not read the following paper, but it seems to be using fractals in a game theoretic context : Fractal Geometry of Equilibrium Payoﬀs in Discounted Supergames, by Kimmo Berg and Mitri Kitti 

I am a big supporter (and user of) LatexDraw. LaterDraw uses Pstricks which is the main alternative to Tikz to draw graphs in in LaTex. If you are not familiar with LaTex, one advantage of LatexDraw is that it allows you to generate pdf (and png, and jpeg, and tiff, and ...) versions of your graphs without having to paste the code of the picture in a Tex document and compile the document. 

Learn about axiomatic price index theory ( again see $URL$ as well as Afriat, S. (2014). The index number problem: construction theorems (1st ed). Oxford ; New York: Oxford University Press. and Diewert, W. (1988). The early history of price index research. Retrieved from $URL$ If you learn about an already existing theory of housing price indices, just pick the index you like best among the ones in the literature. Otherwise, try to see if you can adapt some of the general price indices in the literature to your housing case. In last resort, develop an axiomatic theory of your own. 

I can see some “intuitive” reason why a decline in population would be an issue for a country, mostly if it comes with a decline in the workforce (roughly decreased labor supply, decreased international competitveness and problems with funding pension system?). But I am interested in more careful and more general analysis. My questions are: 

In the literature Yet, in general, you are be more likely to find the first-best/second-best terminology in contract theory (random contracts are not that common in contract theory), and the ex-post/ex-ante efficiency in mechanism design (knowledge of the preferences is rarely assumed in a mechanism: the fact that we do not know agents preferences is the raison d'être of mechanism design). Thus you can expect to see 3. and 4. being discussed in the mechanism design literature, and 1. and 3. being discussed in contract theory. Beware This being said, the notions of second-best and first-best are often used outside of contract theory in a rather permissive way, which may be confusing. For some people, first-best simply means "if we do not impose some constraint $X$" and second-best means "if we do impose constraint $X$". Thus you may hear people talk about (beware this is where it gets confusing) 

I have a vague recollection I am unsuccessfully trying to find an exact reference for. I recall watching an interview of Jacques Attali about a new book of his (maybe 6 or 7 years ago) where he mentioned scholars who once (around 1700?) were convinced that economic growth would stop, not because of limits to technological progress, but because of satiation. As I recall it, the argument from these scholars was something like "we may be able to produce 10 times more food, but there's only so much food an individual can eat in a day, so we'll never get to such levels of production because of a lack of demand". Of course, we know that these scholars missed a number of important points, the main one being that growth occurs not only through producing more of the same old good, but by increasing the quality of these goods and by creating entirely new goods (which can easily break the satiation argument). I am not interested in a discussion of the argument per se. Rather, I am looking for precise references (if any) to people who actually argued (or maybe are still arguing) about the purported "satiation" limit to growth. Bonus points if someone can point me to Attali's interview or to the book where he mentions these people. 

By a "Demand", intro textbooks really mean a "Demand function" (but talk about "Demand" either for concision, or because they think the word "function" will scare intro students). Having shied away from calling a function a function, intro textbooks then cannot speak of "the demand at price $P$" (just like you would speak of the value of $f(\cdot)$ at $x$), and need to introduce the awkward terminology "quantity demanded at price $p$". 

It's been too long since I read those, so I don't exactly remember whether they answer your two specific questions, but if you are interested in the topic you should definitely have a look at: 

implied that there exists no social welfare function $S : \mathcal{D} \rightarrow \mathcal{R}$, where $\mathcal{R}$ is the set of all possible orderings (i.e. complete and transitive binary relations) over the set of alternatives $A$. This was later showed to be false by Blau (1957) The Existence of Social Welfare Functions" Econometrica Vol. 25, No. 2 (Apr., 1957), pp. 302-313 who provided a counter example. Blau also showed (among other things) that the theorem could be corrected by replacing the above domain condition by the following condition 

A classical conjecture by de Finetti's was that the following conditions should suffice (here I follows the presentation in Fishburn (1996)): 

I am reviewing Markov decision processes (MDP) and there is something I am missing with respect to the contraction argument. I am pretty sure it is a silly mistake somewhere (maybe computational), but anyways, I cannot figure it out. Here it goes. Consider a simple MDP with two states and two actions defined as follows. $$ r(s,a) = \begin{pmatrix} 1 & 1 \\ 1 & 1 \end{pmatrix},$$ $$ P(s,s',1) = \begin{pmatrix} 1 & 0 \\ 1 & 0 \end{pmatrix},$$ $$ P(s,s',2) = \begin{pmatrix} 0.5 & 0.5 \\ 0.5 & 0.5 \end{pmatrix},$$ $$ \beta \in (0,1). $$ Now suppose we start with two guesses for the value function $$ V_1 (s) = \begin{pmatrix} 100 \\ 0 \end{pmatrix}, $$ and $$ V_2 (s) = \begin{pmatrix} 0 \\ 1 \end{pmatrix}. $$ If we iterate on these approximate value functions using the Bellman operator we get $$ T(V_1) = \begin{pmatrix} \max_a \begin{cases} 1 + 100\beta, \qquad \text{ if } a = 1, \\ 1 + 50\beta, \qquad \text{ if } a = 2. \end{cases}\\ \max_a \begin{cases} 1 + 100\beta, \qquad \text{ if } a = 1, \\ 1 + 50\beta, \qquad \text{ if } a = 2. \end{cases} \end{pmatrix} = \begin{pmatrix} 1 + \beta 100 \\ 1+ \beta 100 \end{pmatrix}$$ and $$ T(V_2) = \begin{pmatrix} \max_a \begin{cases} 1 + 0\beta, \qquad \text{ if } a = 1, \\ 1 + 0.5\beta, \qquad \text{ if } a = 2. \end{cases}\\ \max_a \begin{cases} 1 + 0\beta, \qquad \text{ if } a = 1, \\ 1 + 0.5\beta, \qquad \text{ if } a = 2. \end{cases} \end{pmatrix} = \begin{pmatrix} 1 + \beta 0.5 \\ 1+ \beta 0.5 \end{pmatrix}$$ But then for $\beta$ close enough to $1$ and taking for instance the Manhattan norm, we have $$ d(V_1(s),V_2(s)) \approx 101,$$ and $$ d(T(V_1(s)),T(V_2(s))) \approx 199.$$ Now that sounds weird to me because I thought $T$ was supposed to be a contraction mapping. Where did I screw up? Is there a mistake in my computation? I am forgetting to apply an important hypothesis? Or am I misunderstanding something about contraction mappings? 

A disadvantage shared by both standards and Pigovian taxation is that in situations of imperfect information (about agent's preferences, firms' production technologies,...), it is difficult to find the optimal standard/tax. 

$$ \begin{align} f_1^*(HD) & = (1+\delta) \left[ 1 - \frac{1}{(1+\delta)} \right] \\ & = \delta \end{align} $$ Summing up the two deals, I still give you the dollar in $t=1$, but now you owe me an additional $\left[\delta - \frac{\delta}{1+\delta}\right]$ in $t=2$ which is strictly larger than zero for $\delta > 0$. Thus in a sense, I made money out of "nothing" (or some would say I made money out of your time-inconsistent preferences). Whether this is bothersome for the HD model depends on whether you believe that these kinds of money pumps are likely or unlikely to occur. ================== In the comments, the OP also asks whether HD would have any influence on risk behavior. I do not think it would. HD denotes a specific way to discount utility but does not impose restrictions on the form of the instantaneous utility function $u(\cdot)$ which determines risk aversion in uncertain environments.