How fast can an algorithm tell if an integer is square-free? I am interested in both deterministic and randomized algorithms. I also care about both unconditional results and ones conditional on GRH (or other reasonable number-theoretic conjectures). One reference I could find was on the Polymath4 wiki, where it states 

Finally, fill in all of the entries of the grid with a number such that for every 2 by 2 "subsquare" 

The "trick" is that every entry is an integer, and that the pattern of 1s quickly repeats, except upside-down. If you were to continue to the right (and left), then you would have an infinite repeating pattern. This should seem at least a bit surprising at first because you sometimes divide some fairly large numbers, e.g. $\frac{5\cdot 11+1}{8} = 7$ or $\frac{7\cdot 3+1}{11} = 2$ in the above picture. Of course, the larger the grid you made initially, the larger the numbers will be, and the more surprising the exact division will be. Incidentally, if anyone can provide a reference as to why this all works, I'd love to see it. I managed to prove that all of the entries are integers, and that they're bounded, and so there will eventually be repetition. However, the repetition distance is actually a simple function of the distance between the two rows of 1, which I can't prove. 

As you mention, this is related to the Hardy-Littlewood k-tuple conjecture. In particular, if their conjecture is true, then the primes are not translation-finite. Indeed, it is possible to find an increasing sequence n1 < n2 < n3 < ⋯ so that for every k, the first k nis form an admissible k-tuple. (For example, I think ni = (i+1)! works.) Then, by the k-tuple conjecture, infinitely many such prime constellations exist and so for all k, (X-n1) ∩ (X-n2) ∩ ⋯ ∩ (X-nk) is infinite. (Here and below, X is the set of primes.) However, maybe we can prove that the primes are not translation finite by some other means. Unfortunately, the technology is not quite good enough to do that. Proving that the primes are not translation finite would, in particular, prove that there exist n1 < n2 such that (X-n1) ∩ (X-n2) is infinite. In particular, this implies that the gap n2-n1 occurs infinitely often in primes, and so pn+1-pn is constant infinitely often. (The standard notation pn indicates the nth prime.) The best known upper bound for the size of small gaps in primes is that lim infn→∞ (pn+1-pn)/log pn = 0. This was established by Goldston and Yildirim around 2003 and the proof was later simplified. To the best of my knowledge, the best conditional result is by the same authors; they show that given the Elliott-Halberstam conjecture, the prime gap is infinitely often at most 20 or so. 

The Wendt binomial circulant determinant $W_n$ can be defined quite simply as a resultant: $$ W_n = \operatorname{res}(x^n-1, (x+1)^n-1). $$ Truer to its name, one may also define it as the determinant $\det(A)$ of the circulant matrix with entries $A_{i,j} = \binom{n}{\lvert i-j\rvert}$. The Wendt determinant was of interest historically to number theory because of its connection to Fermat's last theorem. The sequence is available on the OEIS as A048954, beginning as follows: $$1, -3, 28, -375, 3751, 0, 6835648, -1343091375, \dotsc$$ I have recently become interested in some of the prime factors of the Wendt determinant, a list of which is available online. Specifically, I am wondering: for which $n$, relatively prime to 6*, is $W_n$ divisible by $3$? I am interested in any result that gives a sufficient condition for $W_n$ to not be divisible by 3. The small $n$, relatively prime to $6$, for which $W_n$ is divisible by $3$ are multiples of 13, 121, 671, and 757 (note that $W_m$ divides $W_n$ if $m$ divides $n$). I was not successful in finding this sequence or any other related sequence in the OEIS. * I ask for relatively prime to $6$ for some technical reasons. Every sixth entry is zero, and also every even entry is known to be divisible by three. I am also interested in which of the even entries is twice divisible by $3$, ie divisible by $9$. 

I am told that finite groups have unique factorization under direct product. That is, call a nontrivial group "indivisible" if it is not isomorphic to a direct product of nontrivial groups. Then every finite group can be "factored" (by direct product) into a unique collection of indivisible groups. In particular, if $G$ and $H$ are finite groups so that $G\times G\cong H\times H$, then $G\cong H$. Can anyone provide a reference to a proof of these results? What is known in the infinite case? Thanks. 

Of course, the answers are this for some mathematical reason, not accidentally. Many of the problems are also elegant from a chess perspective. 

Fix an odd natural number $k$. Suppose we have $k$ total orders on the same (finite) set $X$. Define a tournament on the vertex set $X$ by putting a directed edge $x\rightarrow y$ if a majority of the total orders compare $x > y$. 

Dots and boxes is a pencil-and-paper game with a reasonably deep mathematical theory. The game is often played by schoolchildren. 

I came up with an explicit construction that showed that your problem was NP-hard, even on the real line, but then I realized there's an even simpler argument: Minimum dominating set is known to be NP-hard even for bipartite graphs, and those embed nicely. For example, you could send one part of the partition to $(0,0)$ and the other to $(1,0)$. (If you insist that distinct vertices be represented by distinct points, then you may choose different points like $(\varepsilon,0)$ and $(1-\varepsilon,0)$ instead.) 

I passed on your question to John H. Conway. Here is his response: (NB. Everything following this line is from Conway and is written from his point of view. Of course, in the comments and elsewhere on the site, I am not Conway.) I think it's wrong to focus on block designs in particular. This may not answer your question, but there are some interesting examples of theorems similar to Desargues's and Pappus's theorems. They aren't block designs, but they do have very nice symmetries. I call these "presque partout propositions" (p.p.p. for short) from the French "almost all". This used to be used commonly instead of "almost everywhere" (so one would write "p.p." instead of "a.e."). The common theme of the propositions is that there is some underlying graph, where vertices represent some objects (say, lines or points) and the edges represent some relation (say, incidence). Then the theorems say that if you have all but one edge of a certain graph, then you have the last edge, too. Here are five such examples: Desargues' theorem Graph: the Desargues graph = the bipartite double cover of the Petersen graph Vertices: represent either points or lines Edges: incidence Statement: If you have ten points and ten lines that are incident in all of the ways that the Desargues graph indicates except one incidence, then you have the last incidence as well. This can be seen to be equivalent to the usual statement of Desargues's theorem. Pappus's theorem Graph: the Pappus graph, a highly symmetric, bipartite, cubic graph on 18 vertices Vertices: points or lines Edges: incidence Statement: Same as in Desargues's theorem. "Right-angled hexagons theorem" Graph: the Petersen graph itself Vertices: lines in 3-space Edges: the two lines intersect at right angles Statement: Same as before, namely having all but one edge implies the existence of the latter. An equivalent version is the following: suppose you have a "right-angled hexagon" in 3-space, that is, six lines that cyclically meet at right angles. Suppose that they are otherwise in fairly generic position, e.g., opposite edges of the hexagon are skew lines. Then take these three pairs of opposite edges and draw their common perpendiculars (this is unique for skew lines). These three lines have a common perpendicular themselves. Roger Penrose's "conic cube" theorem Graph: the cube graph Q3 Vertices: conics in the plane Edges: two conics that are doubly tangent Statement: Same as before. Note that this theorem is not published anywhere. Standard algebraic examples Graph: this unfortunately isn't quite best seen as a graph Statement: Conics that go through 8 common points go through a 9th common point. Quadric surfaces through 7 points go through an 8th (or whatever the right number is). Anyway, I don't know of any more examples. Also, I don't know what more theorems one could really have about coordinatization. I mean, after you have a field, what more could you want other than, say, its characteristic? (Incidentally, the best reference I know for the coordinatization theorems is H. F. Baker's book "Principles of Geometry".) In any case, enjoy! 

Tic-tac-toe and Gomoku (five-in-a-row) are common games that have fairly mathematical rules. Players alternately choose points from some subset of a lattice and try to form a line segment of a certain length. The Hales–Jewett theorem is a result from Ramsey theory that essentially says that however long the lines must be, a draw is not possible in a sufficiently large dimension. Gomoku has been solved, constructively. (The first player wins.) The game of Connect Four adds the additional element of "gravity". It has also been solved. (The first player wins on the standard board size, but not on some boards of slightly different size.) 

I assume, perhaps naively, that this problem already occurs in the literature, perhaps in the theory of voting/social choice, so I would be happy with references instead of solutions if that's easier. 

Choose a point anywhere in the unit interval $[0, 1]$. Now choose a second point from the same interval so that there is one point in each half, $[0, \frac12]$ and $[\frac12, 1]$. Now choose a third point so that there is one point in each third of the interval, and so on. How long can you choose points like this? In other words, what is the largest $n$ so that there exists a (finite) sequence $(a_i)_{i=1}^n$ so that for all $k$, among the first $k$ points $(a_i)_{i=1}^k$, there is at least one in each interval $[0, \frac1k], [\frac1k, \frac2k], \ldots, [\frac{k-1}k,1]$? My question Is there a slick proof that $n$ is bounded? (Note that by compactness, the existence of such a sequence for all $n$ is equivalent to the existence of an infinite sequence with the same property.) Backstory I was recently re-reading old columns of Martin Gardner's, and he describes this problem in "Bulgarian solitaire and other seemingly endless tasks". (Original column 1983, available in his collections "The last recreations: ..." and "The colossal book of mathematics".) He says that the problem first appeared in "One hundred problems in elementary mathematics" by Hugo Steinhaus. There, he shows that there is a sequence of length 14, but there is none of length 75. The first published proof of the longest sequence, which has length 17, was by Elwyn Berlekamp and Ron Graham in their paper "Irregularities in the distributions of finite sequences" in the Journal of Number Theory. This was followed by a shorter proof by Mieczysƚaw Warmus in "A supplementary note on the irregularities of distributions" in the same journal. Now, these proofs mostly use case analysis to some degree or other. They are of varying complexities, oddly with Warmus's proof of the optimal $n$ being the shortest. It's also not too hard to write a computer check oneself that finds the optimal $n$. However, I feel that because of the elegant nature of the problem, there should be some "nice" proof -- not of optimality, but simply that such a sequence can't continue forever. Can anyone find one? Technical note: The problem is usually stated with half-open intervals. I made them closed so that compactness worked. (Edit: The possibility that this changes the answer did occur to me. I assume it doesn't, and I'll check by computer soon. I am fine with answers for any kind of intervals -- open, closed, half-open.) 

Sentences of this form would be inputs to a program, which decides if this statement is in fact true in ZFC (or your other favorite axiomatization of category theory). The point here is that I am restricting the sentences one can input into the program, but keeping ZFC or whatnot as my framework. I hoped (perhaps naively) that if I restricted the class of sentences, it might be decidable whether or not these statements were true. For example, I imagined that every such theorem is either proven by diagram chasing, or it is possible to find a concrete example of maps among, say, R-modules that contradict the result. 

the condition $ad-bc=1$ is satisfied, or equivalently, that $d=\frac{bc+1}{a}$. You can easily do this locally, filling in one forced entry after another. For example, one might get the following: 

This is a known open problem. See "Matchings extend to Hamiltonian cycles in hypercubes" over at the Open Problem Garden. 

There are a lot of theorems in basic homological algebra, such as the five lemma or the snake lemma, that seem like they'd be more easily proven by computer than by hand. This led me to consider the following question: is the theory of categories decidable? More specifically, I was wondering whether or not statements about abelian categories can be determined true or false in finite time. Also, if they can be determined to be false, is it possible to explicitly describe a counterexample? If it is known to be decidable, is anything known about the complexity? (Other decidable theories often have multiply-exponential time complexities.) If it is known to be undecidable, say by embedding the halting problem, then can I change my assumptions a bit and make it decidable? (For example, maybe I shouldn't be looking at abelian categories after all.) Thanks in advance. Edit: It appears a clarification is needed. My goal was to consider the minimal theory that could state things like the five lemma, but not necessarily prove them. For example, I want to say: 

I have a slight interest in both the inverse Galois problem and in the Monster group. I learned some time ago that all of the sporadic simple groups, with the exception of the Mathieu group $M_{23}$, have been proven to be Galois groups over $\mathbb{Q}$. In particular, the Monster group has been proven to be a Galois group over $\mathbb{Q}$. What techniques are used to prove such an assertion? Is proving that $M_{23}$ is also Galois over $\mathbb{Q}$ within reach? I assume that the same techniques do not apply, for it is a much more manageable group than the Monster. 

Actually, until very recently, Conway didn't even believe his problem had been solved. (This despite the fact that multiple solutions have been published, some years ago by now, and the solutions had even been exposited at seminars at Princeton.) Only a few months ago did a few graduate students at Princeton convince him that the problem was solved. He was particularly excited when he heard about the "nice devil" (who never kills a square that could have been visited before). I have checked with Conway: the bet has not yet been paid. However, it will be soon. I will update this answer if and when it has been paid.