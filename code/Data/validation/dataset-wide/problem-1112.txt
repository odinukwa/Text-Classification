I guess you are under a wrong impression that it is a OS related issue. Check your server bit if it is 32 bit and if you try to install 64bit package percona's xtrabackup . It would end up throwing such error messages. 

User accounts are again stored in tables in terms of rows and columns and also its respected permissions under mysql database wherein it has primary key as host and username. So, I don't think so you have any limitations. But you have something called max_connections that has to be set to a value, say it has 100000 as max that you can set. Then keeping each user connection in mind then we can go upto 99999 users connected to it parallely. My question to you is. 

First lets understand that to take an incremental backup you need to keep full backup on the server where you are taking incremental. Though you take a full backup on SERVER(A) you may push to AWSSERVER(B). It doesn't matter, but inorder to take an incremental you need to keep the full backup copy as source backup. UPDATE Below is the approach for incremental, you will be able to get your answers whether the idea you have is a feasible one or not. 

My ordering application uses Oracle 11g Database. This DB has a primary table ORDERS and multiple child tables like ORDER_DETAILS, PLAN etc. ORDERS table is LIST partitioned on STATUS column and all other tables are referenced partitioned with ORDERID as a foreign key. At peak load, when order status is changed and ORDERS table row is moved from one partition to another, Oracle performs row migration for all the child tables referenced partitioned by ORDERS table. Due to many tables that depend on ORDERS table, large number of row movements happen causing a deadlock in one of the child table. My question is, how to resolve a deadlock caused in the ORACLE's internal row migration step? Here is an example setup: ORDERS table: 

But If I break the query into 2 parts and rebuilt indexes with ONLINE option separately, DML queries DOES NOT get blocked while indexes are being rebuilt 

Have you tried mysqldump using --single-transaction ? In this way it doesn't lock the table for threads doing SQL,DML operations provided no DDL statements should be issued and you will get the backups for conistent states only. This will be efficient only for innodb tables. Below url might give some insights about the option. $URL$ 

Kill all processes for mysql in ps -ef | grep -i mysql If you see any any ibdata file generated under your default data directory you may remove them also iblogfile1,2 since its a fresh installation no need to safe backup them. chown -R mysql:root /var/lib/mysql chmod -R 775 /var/lib/mysql also the same permissions to /etc/my.cnf. Now try to start the instance by issuing /etc/init.d/mysql start and tail -f /var/log/mysqld.log. It should start without any issues if you get any error message . 

Restart mysqld. Every four hours let cron to exec a script by doing below steps one by one. 1). "flush logs" on the server. Get file names from binary logs generated from restart to latest - 1. (Make a note of latest - 1 file name for later reuse). 2). Convert those logs to .sql .ie., mysqlbinlog mysql.0000021 > mysql.0000021.sql ; mysqlbinlog mysql.0000022 > mysql.0000022.sql ... so on until latest - 1. 3). Now replace string "use A" to "use B" like. sed -i 's/use A/use B/g' mysql.0000021.sql 4). Now apply them to your DB instance. mysql -uwill -psmith << EOF source mysql.0000021.sql ; EOF 5). Capture errors in the below manner at the starting of the script. exec 7>&2 exec 2> ERR_FILENAME.txt 6). And now if [ -s ERR_FILENAME.txt ] then sendmail ; fi 7). For the next iteration use the binary log file that you took a note at step 1 as a starting file name. IMPORTANT 

So for some reason, ORACLE is not taking Index into consideration while running update query on PLAN table. Am I missing something? 

My primary goal (with this question) was to see if Oracle can give me some way to identify this expiration time trigger and initiate an activity rather than Application server initiating one. 

Can some one suggest some approach where Oracle some how notifies application server when lock expiration time is reached? Edit (To answer questions raised by Gil Shabtai) Its probably my bad that I tried leaving some of the points from the discussion which I thought were irrelevant to the question I was asking. Here are the answers to your issues / questions raised 

One solution could be to use DBMS_SCHEDULER package and create a scheduled job. But I could not find anywhere in the documentation, some way for the job to notify application server. It can send an email but that wont help me much. Second option could be to use "Database Change Notification feature" but this is triggered on a DML or DDL change on the DB object which is not happening in my case. 

You may give it a try using percona backup alpha version for Windows - Download_Link . Below are the steps after installation in Windows Bash. 

Doing by this way the SELECT statements are performed in a nonlocking fashion, but a possible earlier version of a row might be used. Thus, using this isolation level, such reads are not consistent.When you say not-consistent it means recently changing records i.e.. DML transactions that are currently in process will not be read. I assume which is in your case it is acceptable. This is also called a “dirty read.” Otherwise, this isolation level works like READ COMMITTED. If I were to be you, the below order is what I follow. 

I would like to understand the differences between innodb_autoinc_lock_mode options 0,1 and 2 when parallel load data infiles are given. I see in "0" option, it locks the entire table and does the First transaction requested for N number of records say TX1. So when next transaction say TX2 is raised in meantime when first transaction is still getting uploaded using "load data", then it has to wait in the queue for the first one TX1 to complete. And then it sets the max(AI_column)+1 value from the table and does upload for the next set of load data. In this case it doesn't jump the Auto Increment numbers. Also I see in "1" option, it locks the entire table and does the First transaction requested for N number of records say TX1. So when next transaction say TX2 is raised in meantime when first transaction is still getting uploaded using "load data", then it has to wait in the queue for the first one TX1 to complete. And then it sets the max(AI_column)+1 value from the table and does upload for the next set of load data. And then it sets the max(AI_column)+some_creepy_jump. But I see in "2" option, it doesn't lock the entire table. Instead it keeps inserts for each process simultaneously and inserting records for which ever request falls in randomly and ends all threads with average time around (1.21 sec for 7 parellel threads using load data having 1000000 record each). In this case it has multiple transactions in mixed order. And then it sets the max(AI_column)+some_creepy_jump atlast. I'm using mysql 5.1.61 . 

After 30 seconds a notification needs to be sent out to all clients that a lock has expired and this employee is available again for updates. Now to identify if LOCK_UNTIL duration has reached, application makes a SQL call to database every 2 seconds to see if 10:00:30AM has reached. Performance Issue: This call every 2 seconds is causing lot of overhead on the database and on the application server. I am looking for a better ways where Oracle itself initiates a notification to the server when lock expiration time has reached. Is there any way I can achieve this? Possible solutions: 

Now this SQL is internally generated by Oracle to perform row migration for child PLAN table. To resolve the issue I tried following changes: 

I am using Postgres 9.5 I have tables with date column. All tables are partitioned based on the date column. Table setup: Example of current partitioned tables are like below 

The second method is twice as fast as the first one. But the disadvantage is that after a few years the archive disk will contain a lof of folders/partitions containing the filestream data + database needs to be offline. As with the first method there is only 1 folder/partitions (or I can split that big partition by year). I hope my explanation is clear enough because it was hard to put all this in writing. What is the best method to accomplish the archiving or am I missing something? 

I've setup an AlwaysOn AG on SQL Server 2016 SP1 Standard. Then I created an AG and added a database with autoseeding (synchronous mode). I used SSMS 2017 to create my AG and to add the database. Everything works fine. But when I check the wait stats I get waits of type VDI_CLIENT_OTHER (80%) on the primary with an average resource time of 42 seconds. After some research I found out that the waits are generated by 4 sessions that execute the command VDI_CLIENT_WORKER. As I understand the wait means that a thread is waiting for work when seeding a new AG. But what I do not understand is why I have those waits because my AG is ready and why do I have 4 sessions that execute the VDI_CLIENT_WORKER command? I found out that each scheduler has one VDI_CLIENT_WORKER Can somebody try to explain what VDI_CLIENT_WORKER-command does and how can I solve the problem of the many VDI_CLIENT_OTHER waits? 

By this way DB performance will look good, quick recovery and data availability 24/7 and less time spent in-case of any maintenance activities. 

Table will be partitioned by RANGE weekly. On Master keep latest week's partition. And drop earlier partitions in below way. 

You may try reading the binlog events in 'mysql-binlog.000018' and see if there is any data corruption or the file didn't close properly. Anyway the better suggestion would be to rebuild the slave. But you might want to know what does the binlog events contain, for nailing the actual root cause and provide fix. I suspect probably there could be network glitch between Master and Slave Or Slave server would have failed its monitor health for a fraction of a second Or disk would have gone for failure and replaced if under EBS. Since you are in AWS and it is prone for such disasters. 

I have confirmed that OrderID column (Foreign Key column) in the PLAN table has index on it. Tried increasing PCTFREE parameter on the table. 

The down side of this approach is the time between the execution of drop partition and rebuilding index, those indexes will be unusable that might create performance problems. So my question is, is there any option where I can drop partition and rebuild index "online" in one query? Currently I dont think we have following option. 

My requirement is from the example below, can a new table have only partitions Part_2 and Part3. (Dropping partition Part_1 using WHERE clause) 

But havnt got success yet. How do I handle deadlock for this scenario? ------------------------- UPDATE ------------------------- As per suggestions suggested by Wernfried and Gandolf989, I verified if all my foreign keys have indexes on them by running query given in the Gandolf989 answer. Result was "No Rows Found". So it means, all the indexes seems to be in place. But while analyzing I realized, if I check an explain plan for a simple query like below, I see FULL table scan on the PLAN table even after having an index on ORDERID column. 

A while ago a consultant said that I should set processor affinity when I'm running SQL Server on VMWare. The advice was to disable CPU0 so it was free for the OS. When I read the "Architecting Microsoft SQL Server on VMware vSphere"-PDF on the site of VMWare I find following: 

We have a SQL Server 2016 SP1 CU7 Enterprise server where we enabled the query store on a database. This is a highly used database.The has been set to 200MB and is 1 day. I've used to check the properties of the query store and everything works perfect as long as stays under the 200MB. I've set to Auto but no cleanup happens, normally a cleanup should be triggered when the query store is 90% full. What happens next is that the query store goes into readonly mode because there is no available space left. I've tried changing to Auto but nothings changes.If I then change to 30 days the changes to READ_WRITE and the query store starts capturing again. The just becomes higher than the and after a while the goes back to READ_ONLY. Can anybody explain this behavior?