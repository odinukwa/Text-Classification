To my opinion, as long as a language is not insanely difficult, constructed languages will only be of a very limited range of complexity, since communication and languages are by themselves complex. This, and the fact that children seem to be able to perfectly well learn even the most puzzingly complex language, leads me to the assumption that all questions as to whether a language will be gaining widespread usage will not be dealing with intrinsic properties of that language, but much more with external factors. One can make a case that modern Hebrew is in a way a constructed language (even if it is not constructed from nothing) and it did gain widespread adoption; and for Esperanto there's nowadays native speakers as well. However, in most of the cases I believe people simply don't see the reason for learning a constructed language. Linguae francae are generally acquired from culturally dominant and prestigeous groups, but constructed languages simply have no such group of speakers that would inspire others to take their lead. In any way, what is certain, is that once a language - constructed or not - is spoken routinely by a sizeable number of speakers, it is inevitably going to change. 

Most languages (excluding highly polysynthetic ones) generally have a finite set of morphological word forms. From this, it follows that the language's morphology can in the worst case be described as a regular language simply by a disjunction of all possible forms; the question remains how elegant (and how explanatorily adequate) such an approach will be. Affixation can be very easily modeled via finite state automata without the need to explicitly enumerate each possible form, but full reduplication, stem alteration (like suppletion and ablaut) or templatic morphology (as in the semitic languages) require more work. A good book on the subject is Finite State Morphology by Beesley & Karttunen (see here). Although it makes reference to a proprietary software (the xfst tool), there are open source alternatives that work very analogously. 

This is almost certainly done with LaTeX, or one of its friends, and the tikz-qtree package. It is an improvement of the qtree package with nicer node placement. If you are not familiar with LaTeX, and want to learn more, this Wikibook might help (link is to the page about linguistics, but the book is in general about LaTeX). Both tikz-qtree and qtree have a quite extensive manual. Below is LaTeX code using the tikz-qtree package to draw your tree. The only difference with the original seems to be that the bar over the T and the v is less bold. Perhaps this was done with something like this, but I cannot get it to look exactly the same. 

A term often used synonymously to "generalisation" is bleaching. Joan Bybee in his Cambridge Textbook in Linguistics on Language Change defines it as "a meaning change in which specific features of meaning are lost" (p. 267). 

Although I haven't heard of the term "degrees of passive/active" before, they are almost certainly talking about the verbal stems. This is a concept indeed alien to Western European (or broader) but common to all Semitic languages. The core idea is that the stems differentiate voice and Aktionsart. In an earlier stage of the language (pre-1000 BCE) there must have been ten verbal stems, nine of which fit into a 3x3 grid of voice and Aktionsart: 

Note that from the definition follows that the distance between entirely unrelated sets is 1 (not ∞ as you may expect) which explains the many "perfect matches" with a distance measure of 1. A perfect match in fact has a distance of 0 (which only happens when the sets are identical). 

This system developed differently in different languages. I cannot comment on the situation in Arabic (which as far as I can see from Wikipedia must also have developed the new L stem) because I don't know enough about it. In (Biblical) Hebrew, there was the issue that Gt, Gp and N both indicate relatively rare non-active voice unmarked for Aktionsart. This leads to the dropping of Gt and to a large extent that of Gp as well, whereas N takes on passive meanings and Dt takes over reflexive voice unmarked for Aktionsart. Also, Ct is almost not attested in Biblical Hebrew and as far as I know does not exist in Modern Hebrew because reflexive causativity is so rare. Thus in Hebrew the situation has become far less symmetric than it once was. On the other hand, in Syriac, the function of the passives was taken over by participles and the N disappeared, leading to a highly symmetric system of only 6 stems (in fact, like the original table above). After this long detour I would still like to comment on the terminology of "degrees of passive/active". I'm sure that the author had his reasons for this term, but it doesn't seem to be accurate: it covers only one dimension of the system (voice) but neglects the other (Aktionsart). Thus, the verbal stems G, D and C all indicate active voice (the same "degree of passive/active"), whereas Gt/Dt/Ct all indicate reflexivity and Gp/Dp/Cp all indicate passive voice. (Only in Hebrew the system is more complicated, because N can indicate both middle and passive voice, thus being in between degrees). Lastly, for your convenience a table of the more common names of the stems in language-specific grammars: 

To be honest, generative notions of word classes don't seem any less whimsical to me than the classical ones, as they are no less biased. Of course, this will be a matter of hot debate, but I side with Haspelmath (and a lot of other typologists as well, see e.g. Bickel (2007)) who claims that there is no such thing as true cross-linguistic categories. To ask whether Japanese does have the same linguistic category that a completely unrelated language, English, has (maybe, if 'determiner' even is a valid category for English) seems absurd. The question would be easier to answer if we had a clear, operationalised definition of "determiner" that can be readily applied to all sorts of languages (but I doubt anybody could come up with that). 

Before answering this question one must agree upon a definition of parts of speech. I will assume that we define POS not semantically (which would give rise to an almost infinite number of categories), but structurally, i.e. by the way they behave morphosyntactically. It is nowadays evident that POS (as any construction) cannot be established cross-linguistically. Some languages do not even distinguish between nouns and verbs, at leat not in the way English does. But even if two languages seem to share the same POS category, despite the similarities it is almost never going to be the exact same. Verbs in Russian inflect for aspect, while German ones don’t, for example. When we talk about "verbs" or "nouns" we always have in mind some prototype category that we compare language-specific categories with. When we ask "does language X have category Y", we are actually looking for something similar to Y, so the answer doesn’t have to be "yes" or "no", it will often be "somewhat". To answer the question about "like" one must consider how it behaves. Of course, it doesn’t behave like an adverb (it takes a complement), so that is ruled out by any traditional notion of "adverb". It seems to behave more like a proposition in that regard; interestingly its complement is also in the oblique case ("like him", not "like he") very unlike German for example (note however that the oblique case has long spread to constructions like coordination as well). On the top of my head I cannot think of structural features that contradict the preposition theory, but it is possible there are some (I’ve never studied English grammar in detail). There is no a priori reason why the word couldn’t be in a category all of its own. Note also that I didn’t consider the uses of like as subordinator or discourse particle. These would be other lexemes. 

As others have answered, this question is based on a weird definition of what a "mother tongue" is. It also seems to presuppose that thought is always articulated in a language, which is far from true (I have no reference for that, but I know for a fact that I generally think directly in concepts rather than words, and I know other people who do as well. I think it's been studied before, but I cannot find a reference to that study at the moment. As far as I remember, there is a sizeable minority of people who think mostly in concepts rather than words). One thing I think I can add is that even if you take Alenanno's definition of a mother tongue (which is indeed the most common one), there is actually nothing special about one's mother tongue, besides the fact that it was the one learned chronologically first. It's for instance perfectly possible to completely lose command of one's mother tongue later in life. There are lots of examples of people migrating with their families at the age of 6 to 10 (or even later) to another country, completely cutting the link with their original country. By the age of 40 to 50, it's not uncommon for those people to not be able to speak their mother tongue any longer, except maybe for one or two heavily accented words. My personal experience also agrees with this: I am a French person who moved to the Netherlands 10 years ago. I speak Dutch and English fluently, and much more often than I speak French. And although I still use French regularly (if not that often) and it is my mother tongue, it is not the language I speak best any more! I often struggle trying to find my words when speaking French, and I've been told I developed a Dutch accent when speaking the language (I can't hear it myself). Dutch nowadays comes to me much more naturally than French, and I feel I can express myself far more easily even in English than in French! So although it is my mother tongue, nowadays French is only my third language in terms of fluency. So to answer your last questions, yes, it is perfectly possible to think spontaneously in another language than your mother tongue (if you think in a language at all!). There is no special technique to reach that point. As kaleissin pointed out, it's purely a matter of fluency: the more you actively use a language (passive use like reading and listening is not enough), the more naturally you'll be able to think in it. 

No. I have yet to meet structural categories in linguistics that have single, universally agreed upon definitions. Even "word" is not strictly defined in any way. You can compare terms only within the same framework. "Mediopassive" is a term used generally in historical linguistics for a certain kind of language-particular constructions/forms - anticausative is a term i know from typology. Unless given a precise definition of the terms, I don't think it is possible to answer your question. 

I disagree with the accepted answer. If there is a difference in inflection between mouse "device" and mouse "animal", the natural way to model this is with two different lexemes. Anything else seems like a poor model to me. Historical categories don't remain the same. Just because the etymology of "mouse" is still transparent, it doesn't mean it's still both the same lexeme. Of course, concepts such as "polysemy" and "homonymy" are made up by linguists; I don't expect them to have psychological reality. But that doesn't mean we can't use them to model semantics, just as we use terms such as antonyms, meronyms, etc. Be that as it may, there are certainly several competing defintions of homonymy and polysemy, so it's kind of wrong to argue which one is "right". 

Edit: Since I got a downvote, I reworded my question to better reflect my original intent. You are right in claiming that there is (very probably) no "pure" ergative language (although some, such as Dyirbal, come close). But then also consider that there is possibly no true accusative languages as well. While English certainly aligns fundamentally, accusatively, there are some constructions that are sensitive to other distinctions than subject/object. Past participles are one such example: 

WALS has a chapter on numeral bases. It appears most languages use either a decimal or a vigesimal (base 20) system (or some mixture thereof, as in Basque), with other patterns being relatively rare. There are also some language that cannot actually express all possible numbers but only a limited set. Pirahã is even claimed not to have any numerals at all (but every claim about Pirahã should be taken cum grano salis). 

G is called G for the German Grundstamme. D is called D because of Doubling of the middle radical (/qatal/ > /qittel/). C is called C for Causativity. It is also called Š sometimes which better reflects phonology (although in Hebrew the marking consonant became /h/). Dt is often called tD because the /t/ became a prefix rather than an infix elsewhere. Verbal plurality can be of subject, object or action, e.g. "they broke the glass" in G becomes "they shattered the glass (in many pieces) in D via object plurality, or "they repeatedly broke the glass" (action plurality) or "they all broke the glass" (subject plurality). Causativity is e.g. to cause to be seen, i.e. "to reveal". Thus you see that these distinctions are in English covered by lexicon rather than grammar (i.e., there are different verbs for different Aktionsarts, "broke"-"shattered" and "see"-"reveal"). Besides this nice symmetric system there was an N-stem, the original semantics of which are still debated but which probably had to do something with middle voice. In Central Semitic, "internal passives" are developed for the three core stems G, D and C. In Arabic grammar these are usually not treated as separate stems, but in Hebrew and other languages they are: 

It is a ב (beth). The thing above it that made you think of a lamed is a cholem (the vowel sign), and it has a dagesh in the middle. This is a masculine plural participle of the root בטח "to trust", i.e. "those who trust" (if used as a noun). This word is for instance used in Jeremiah 46:25: 

A good diachronic overview paper with many references is Gzella, H. 2009. 'Voice in Classical Hebrew against Its Semitic Background', Orientalia 78(3), pp. 292–325. 

I often hear people mention in passing that grammatical features are more reliable than lexical features in diachronic research, specifically when detecting pseudepigraphs, because it is relatively easy to fake old lexicon but difficult to fake old grammar (as is evidenced anecdotally by people imitating old English but mixing "thee", "thou" and "thy"). If I were to mention this in my paper, who should I cite? Where can I read more about this hypothesis? Has there been any statistical analysis on it? 

So, whether using the definite article with people's names is "bad style" or not could be said to depend on the prescriptivist's view of what the definite article's role is: if its role is to add definiteness to a noun, then it's more likely to be considered incorrect to add it to nouns that are already definite by meaning, like people's names. If its role, however, is merely to indicate that a noun is definite, then it is more likely to be acceptable to use it with nouns that are already semantically definite. 

As far as I know, in European Portuguese the use of the definite article with people's names is considered standard, and not using it is very formal. In Modern Greek (not a Romance or Germanic language, but still relevant) it is mandatory (except, naturally, in the vocative), and not using it would be considered ungrammatical. As for why it is considered "bad style" in languages that have it in dialects but not in the standard language, I think it's mostly a problem of the standard language being based on an older form than current vernaculars (Written French in particularly is quite archaising compared to Spoken French), a form where personal names cannot take the article. Since anything not part of the standard is considered "wrong" (the typical prescriptivist view), personal names with articles are considered "wrong" as well. The use of definite articles with personal names typically appears rather late in the evolution of definite articles. Definite articles typically originate from demonstrative determiners whose meaning gets eroded with time (from "this man" to "the man"). From anaphoric/cataphoric/spatial use to "simple" definition, the erosion of meaning carries on, and as it does the article's use becomes more and more mandatory, for more and more nouns (basically, it stops adding a specific meaning, and starts being seen as just something that must be used with nouns that are considered definite, even if they would still be considered definite without it). You can see this evolution by looking at how different languages use the definite article: