If you are prepared to accept that $G \to G/K$ is a principal $K$-bundle there is an easy proof. You have that $K$ acts on the homogeneous space $K/H$ so you have an associated fibre bundle $$ \frac{G \times K/H}{K} \to G/K $$ with fibre $K/H$. The total space is actually $G/H$. You can construct a fibre bundle isomorphism from this to $G/H$ by $$ gH \mapsto [g, H]_K $$ where $[g, H]_K $ is the orbit under the $K$ action $(g, H)k = (gk, k^{-1}H)$. Why is this well defined ? You can check that $$ ghH \mapsto [gh, H]_K = [g, hH]_K = [g, H]_K $$ as $H \subset K$. It has an inverse which is $$ [g, kH]_K \mapsto gkH $$ This is also well-defined as $$ [gk_1, k_1^{-1}kH]_K \mapsto gk_1 k_1^{-1} k H = gk H $$ 

Why are you not happy with using Grassmanians as in: $URL$ ? A related approach that might interest you is given in Dupont's book $URL$ using simplicial manifolds. A simplicial manifold $X$ is a sequence of manifolds $\lbrace X_n \rbrace$ and various maps between them. From a simplicial manifold you can construct a topological space called its realisation. This is how you define $EG \to BG$. Although it isn't a manifold you can realise its topology using the finite dimensional spaces $X_n$ which is how you tie things back to the statement of Chern-Weil theory given in the question. In this example the simplicial space is also the one arising in the bar construction and Milnor's join construction of $EG \to BG$. 

To be clear, although we have an embedding of $G$ in $\mathbb{R}^n$, I am not restricting the question to automorphisms that arise from homeomorphisms $\mathbb{R}^n \to \mathbb{R}^n$; any graph automorphism of $G$ counts. 

Let $M$ be any $n\times n$ matrix. We define the usual cofactors: $C_{i,j}$ is $(-1)^{i+j}$ times the determinant of the submatrix obtained by deleting row $i$ and column $j$ of $M$. We can write the determinant of $M$ using Laplace expansion along column $p$ as: $$\det M = \sum_{q=1}^n M_{q,p} C_{q,p}$$ Now, for any $k, p\in \{1,...,n\}$ consider the sum: $$W_{n,p}(k) = \sum_{q=1}^n {M_{q,p} C_{q,p}^2 \prod_{j\ne q}{C_{j,k}}}$$ Clearly $W_{n,p}(p)$ can always be factored, with $\det M$ as one factor: $$W_{n,p}(p) = \sum_{q=1}^n{M_{q,p} C_{q,p}^2 \prod_{j\ne q}{C_{j,p}}} = \sum_{q=1}^n{M_{q,p} C_{q,p} \prod_{j=1}^n{C_{j,p}}} = \left(\det M\right) \prod_{j=1}^n{C_{j,p}}$$ But in all the specific cases I've examined, $\det M$ appears as a factor of $W_{n,p}(k)$ even when $k\ne p$. For example, with $n=3$, $p=1$ and $k=2$: $$W_{3,1}(2)=\sum_{q=1}^3{M_{q,1} C_{q,1}^2 \prod_{j\ne q}{C_{j,2}}}=\\ \left(\det M\right)\left(M_{2,2} M_{2,3} M_{3,1}^2 M_{1,3}^2+M_{2,1} M_{2,3} M_{3,1} M_{3,2} M_{1,3}^2-M_{2,1} M_{2,2} M_{3,1} M_{3,3} M_{1,3}^2-M_{2,1}^2 M_{3,2} M_{3,3} M_{1,3}^2-M_{1,2} M_{2,3}^2 M_{3,1}^2 M_{1,3}+M_{1,2} M_{2,1}^2 M_{3,3}^2 M_{1,3}+M_{1,1} M_{2,1} M_{2,2} M_{3,3}^2 M_{1,3}-M_{1,1} M_{2,3}^2 M_{3,1} M_{3,2} M_{1,3}-M_{1,1} M_{1,2} M_{2,1} M_{2,3} M_{3,3}^2-M_{1,1}^2 M_{2,2} M_{2,3} M_{3,3}^2+M_{1,1} M_{1,2} M_{2,3}^2 M_{3,1} M_{3,3}+M_{1,1}^2 M_{2,3}^2 M_{3,2} M_{3,3}\right) $$ It might be worth noting that the second factor here cannot be written as a linear combination of products of the cofactors, with purely numeric coefficients. This is in stark contrast to the case $k=p$, when the quotient is simply a product of cofactors. I am seeking a proof that $\det M$ always divides $W_{n,p}(k)$, and a general formula for the quotient in the non-trivial case $k\ne p$. 

Elementary but still useful is the regular value theorem or the submersion theorem: Let $f \colon M \to N$ be smooth and $n \in N$. If $T(f)_m \colon T_m M \to T_{f(m)} N $ is onto for all $m \in f^{-1}(n)$ then $f^{-1}(n) \subset M$ is a submanifold of dimension $\text{dim}(N) - \text{dim}(M)$. 

The answer will depend on your realisation of a $k$-circle bundle. In the case of $i=2$ (second Chern class) there are results associating to any principal $G$-bundle a bundle $2$-gerbe. See: Bundle Gerbes for Chern-Simons and Wess-Zumino-Witten Theories. Alan L. Carey, Stuart Johnson, Michael K. Murray, Danny Stevenson and Bai-Ling Wang. Communications in Mathematical Physics, 159 (3) (2005), 577-613 math.DG/0410013 and the references there in to Danny Stevenson and Stuart Johnson's PhD theses and papers. Of course you have to be happy that a $3$-circle bundle is a $2$-gerbe. More generally you might find something useful in: P. Gajer Geometry of Deligne cohomology, Invent. Math. 127 (1997), 155-207. which gives a realisation of principal $B^k \mathbb{C}^*$ bundles which are another possible way of realising $(k+1)$-circle bundles or at least mathematical objects determined by a characteristic class in degree $H^{k+1}(M, \mathbb{Z})$. There is a nice inductive classifying theory and a simplicial realisation of these spaces. 

Maybe R.O. Wells' book ? $URL$ Sorry I'm not in the office so I can't check. I don't think it's particularly difficult. Certainly if the bundle is holomorphic you can construct the Dolbeault operator by just acting on the components of a section written as a linear combination of holomorphic sections. This patches to give a global Dolbeault operator because the clutching functions are holomorphic. To go the other way you need an integrability theorem such as Newlander-Nirenberg to show there are enough sections in the kernel of the Dolbeault operator to span the fibre of the bundle and trivialise it locally. 

This answer is an attempt to slightly rephrase Ilya's argument; I would have written it as a comment, but there's not enough room. Given a path $\gamma$ with endpoints $v_0$ and $v_n$, we have a 1-chain $c(\gamma)$, which is an integer-linear combination of edges of the graph. Let $E_{c(\gamma)}$ be the set of edges with non-zero coefficients in $c(\gamma)$; this need not include every edge that appears in the path, since some might cancel to zero in the 1-chain. If we think of these edges as decorated with the integer coefficients they inherit from the 1-chain $c(\gamma)$, we can associate a 1-chain with any subset of $E_{c(\gamma)}$. It's possible that $E_{c(\gamma)}$ as a subgraph of $\Gamma$ contains several connected components that share no vertices with each other, but since the boundary of $c(\gamma)$ is only non-zero on $v_0$ and $v_n$, and it's impossible for a 1-chain to have a single-point boundary, these components would need to include exactly one whose 1-chain's boundary was non-zero on $v_0$ and $v_n$, and all the rest would have to give 1-cycles. Since they're all disjoint, any one of the 1-cycles $\chi$ would satisfy $\langle c(\gamma), \chi \rangle = \langle \chi, \chi \rangle \gt 0$. Assuming now that $E_{c(\gamma)}$ is connected as a subgraph, we can build up a 1-chain $\sigma$ with a positive inner product with $c(\gamma)$ as follows. Starting at $v_0$, pick an edge $\epsilon_1$ incident on $v_0$, and put $\pm \epsilon_1$ in $\sigma$, with the sign chosen to be the same as the coefficient of $\epsilon_1$ in $c(\gamma)$. Then advance to the other vertex of $\epsilon_1$, and choose an edge $\epsilon_2$ such that $\epsilon_2 \ne \epsilon_1$, and $\pm \epsilon_2$ with the same sign as the coefficient of $\epsilon_2$ in $c(\gamma)$ gives a boundary for $\pm \epsilon_1 \pm \epsilon_2$ that is zero at the current vertex. This must be possible (assuming we haven't ended up at an endpoint of the path), since the boundary of $c(\gamma)$ is zero at the current vertex, so the signs of the edge coefficients in $c(\gamma)$ can't all give boundaries of the same sign here. We continue this process until we reach either $v_n$, the endpoint of the path, or a vertex we've visited before. If we reach a vertex we've visited before, we can drop any earlier edges from $\sigma$ and obtain a 1-cycle with a positive inner product with $c(\gamma)$. If we reach $v_n$, there are two possibilities. If $\sigma = c(\gamma)$ then $\sigma$ describes a simple path $\gamma'$ from $v_0$ to $v_n$ with the same 1-chain as our original path, and we can proceed to use that simple path in place of $\gamma$. If $\sigma \ne c(\gamma)$, it nonethless has the same boundary. Since $\sigma$ is supported on a subset of the same edges as $c(\gamma)$, and its coefficients are of the same sign but never greater in magnitude (and must be less on at least one edge), $\langle c(\gamma), \sigma \rangle$ will be strictly less than $\langle c(\gamma), c(\gamma) \rangle$. So we'll have a non-trivial 1-cycle $\ell = c(\gamma) - \sigma$, and: $$\langle c(\gamma), \ell \rangle = \langle c(\gamma), c(\gamma) \rangle - \langle c(\gamma), \sigma \rangle \gt 0$$ Finally, suppose we have a simple path $\gamma': v_0 \to v_1 \to \dots \to v_n$ with the same 1-chain as $\gamma$. (The following refinement of Ilya's argument is something that John described to me in correspondence.) Since the edge $e_n: v_{n-1} \to v_n$ cannot be a bridge, there must be a path joining $v_n$ to $v_0$ that does not include that $e_n$. If we follow that path only as far as the first of the $v_i$ it reaches, we will have a path $\rho: v_n \to v_i$ which uses no edges of the simple path $\gamma'$. We can then append the portion of $\gamma'$ that goes from $v_i$ to $v_n$, call it $\gamma'_i$, to obtain a 1-cycle $c(\rho) + c(\gamma'_i)$ that must have a positive inner product with $c(\gamma)$: $$\langle c(\gamma), c(\rho) + c(\gamma'_i) \rangle = \langle c(\gamma'_i), c(\gamma'_i) \rangle \gt 0$$ 

Has anyone tried one of these Logitech conference cameras with Skype $URL$ as a collaborative tool. I saw one report on-line of someone trying to use it to look at a whiteboard and claiming it didn't work because of reflections of the shiny surface. Thanks - Michael 

Maybe try first with $G=SL(2, \mathbb{C})$, $K = SU(2)$ and $T = U(1)$, the diagonal matrices with determinant $1$. Then $K/T = S^2$. Edit: I was thinking of a discrete lattice so this answer which I thought was a counter example isn't. 

Rummikub ? It encourages some logical thought and analysis. It seems to have at least one mathematical paper on it $URL$ and it's popular and fun. 

If this is your first time doing differential geometry you should do the calculation that ayanta is referring to in their comment. Let $X \colon C^\infty(M) \to \mathbb{R}$ be a linear map satisfying the Leibniz rule $$ X(fg) = X(f) g(x) + f(x) X(g) $$ for all $f, g, \in C^\infty(M)$. Show that if $\psi = (\psi^1, \dots, \psi^n)$ are co-ordinates in any neighbourhood of $x$ then there are real numbers $X^1, \dots, X^n$ such that for all $f \in C^\infty(M)$ we have $$ X(f) = \sum_{i=1}^n X^i \frac{\partial (f \circ \psi^{-1})}{\partial \psi^i} (\psi(x)) . $$ Also a good exercise to show that for the same $X$ there is a smooth function $\gamma \colon (-\epsilon, \epsilon) \to M$ such that $\gamma(0) = x$ and for any $f \in C^\infty(M)$ we have $$ X(f) = \frac{ d (f \circ \gamma) }{ dt}(0). $$ This connects you to tangent vectors thought of as equivalence classes of curves as Davidac897 discusses. 

I've found a somewhat nicer proof than the version on the Visual Insight blog. This new approach doesn't entail a huge conceptual breakthrough, but it does avoid having to deal with 3072 individual cases. We have some freedom in choosing $R$ and $S$, but this makes no difference to the resulting sets of axes. We will pick: $$\displaystyle{R = \frac{1}{4} \left( \begin{array}{ccc} 2 & 1-\sqrt{5} & -1-\sqrt{5} \\ 1-\sqrt{5} & 1+\sqrt{5} & -2 \\ 1+\sqrt{5} & 2 & -1+\sqrt{5} \end{array} \right)}$$ $$\displaystyle{S = \frac{1}{4} \left( \begin{array}{ccc} \sqrt{5}-1 & -2 & -1-\sqrt{5} \\ 2 & 1+\sqrt{5} & 1-\sqrt{5} \\ 1+\sqrt{5} & 1-\sqrt{5} & 2 \end{array}\right)}$$ All the powers of these matrices can again be written with a denominator of 4 and numerators taken from $\{\pm 2, \pm 1 \pm \sqrt{5}\}$. We can simplify things a bit by working with integer matrices in 6 dimensions. For each of the four powers of $R$ and $S$, we will multiply the matrix by 4 and then write it as a linear map between 6-dimensional spaces with separate components for the rational and irrational parts of each component of the original vector. For example, for the first power of $R$ we get: $$\displaystyle{R_6 = \left( \begin{array}{cccccc} 2 & 0 & 1 & -5 & -1 & -5 \\ 0 & 2 & -1 & 1 & -1 & -1 \\ 1 & -5 & 1 & 5 & -2 & 0 \\ -1 & 1 & 1 & 1 & 0 & -2 \\ 1 & 5 & 2 & 0 & -1 & 5 \\ 1 & 1 & 0 & 2 & 1 & -1 \end{array}\right)}$$ and for the first power of $S$ we get: $$\displaystyle{S_6 = \left( \begin{array}{cccccc} -1 & 5 & -2 & 0 & -1 & -5 \\ 1 & -1 & 0 & -2 & -1 & -1 \\ 2 & 0 & 1 & 5 & 1 & -5 \\ 0 & 2 & 1 & 1 & -1 & 1 \\ 1 & 5 & 1 & -5 & 2 & 0 \\ 1 & 1 & -1 & 1 & 0 & 2 \end{array}\right)}$$ Suppose we have some unit vector $v$ of the form: $$v = (a + b \sqrt{5}, c + d \sqrt{5}, e + f \sqrt{5}) / 2^{N+1}$$ where $a, b, c, d, e, f$ are integers, with at least one of them odd, and $N \ge 1$. We will work with the integer vector: $$w = (a, b, c, d, e, f)$$ Because $v$ is a unit vector, the components of $w$ will satisfy the conditions: $$a^2 + c^2 + e^2 + 5(b^2 + d^2 + f^2) = 4^{N+1}$$ and $$a b + c d + e f = 0$$ If we multiply any vector of this form by each of the eight $6 \times 6$ matrices corresponding to the four powers of $R$ and $S$, then it turns out that precisely one of those eight matrices will yield a result equal to the zero vector modulo 8, i.e. a 6-tuple of integers all divisible by 8. To prove this, we take the lattice of vectors in $\mathbb{Z}^6$ equal to the zero vector modulo 8, and multiply it by the inverse of each of the eight matrices in turn, to produce eight new lattices: lattices which yield 6-tuples of integers all divisible by 8 when multiplied by the appropriate matrix. In concrete terms, for a given matrix $M_i$, the basis for the associated lattice is given by the row vectors of $L_i = 8 (M_i^{-1})^T$. The original claim can now be restated as saying that every vector $w$ that meets the conditions described above will belong to the union of the eight lattices $L_i$, but no such vector will belong to the intersection of any two of the $L_i$. The first part is fairly easy to show. We can obtain a basis for the union of the eight lattices by forming a matrix whose rows are the union of all eight bases, and then reducing that $48 \times 6$ matrix to a $6 \times 6$ matrix by putting it in Hermite Normal Form (the equivalent of reduced row-echelon form for integer matrices), and discarding all rows containing only zeroes. We will call that matrix $L_U$. The test for the vector $w$ belonging to the lattice whose basis is given by the rows of $L_U$ is that the vector $(L_U^{-1})^T w$ has all integer coordinates. When we carry through these calculations, we find: $$(L_U^{-1})^T w = (2a, b-a, 2c, d-c, e-a-c, \frac{a-b+c-d+f-e}{2})$$ Since $a, b, c, d, e, f$ are integers, the only thing remaining to show is that $a-b+c-d+f-e$ will always be an even integer, given the conditions we've placed on $w$. We have the conditions: $$a^2 + c^2 + e^2 + 5(b^2 + d^2 + f^2) = 4^{N+1}$$ $$a b + c d + e f = 0$$ It follows that: $$a^2 + c^2 + e^2 + 5(b^2 + d^2 + f^2) = 0 \mod 4$$ $$a^2 + c^2 + e^2 + 5(b^2 + d^2 + f^2) - 4(b^2 + d^2 + f^2) - 2(a b + c d + e f)= 0 \mod 4$$ $$(a-b)^2 + (c-d)^2 + (e-f)^2 = 0 \mod 4$$ It's not hard to check that the sum of three squares can only be a multiple of 4 if all three of the numbers being squared are even. So we have $a-b, c-d$ and $e-f$ all individually even, so $a-b+c-d+f-e$ will be even, $w$ will belong to the lattice $L_U$, and at least one of the eight matrices multiplied by $w$ will yield a vector whose components are all divisible by 8. To prove that only one matrix yields such a result for a given $w$, we need to show that the intersection of any pair of distinct lattices $L_i$ and $L_j$ cannot contain any vector $w$ meeting the conditions we've imposed. There are 28 such pairs of lattices. Finding their bases is a bit more involved than finding the basis for a union. First, we need to construct the dual of each lattice. The dual of a lattice $L_i$ is the set of vectors $d$ such that for every $v \in L_i$, the dot product $d \cdot v$ is an integer. Its basis is given by the rows of the matrix: $$D_i = (L_i L_i^T)^{-1} L_i$$ We obtain a basis for the intersection of two lattices by forming their dual lattices, finding a basis for the union of those duals (by joining their matrices and reducing it to Hermite Normal Form), and then taking the dual of that union. If we do this for the 28 pairs of lattices, we find that in 16 cases the intersection of the lattices contains only vectors whose coordinates are all even integers. This violates the requirement that at least one coordinate be odd (which we impose in order that the corresponding vector divided by a power of 2 is in lowest terms). For the remaining 12 pairs of lattices, the requirement that at least one coordinate be odd can be satisfied if and only if one particular element of the lattice basis has an odd coefficient $\ell$ in the sum that decribes the vector $w$ with respect to that basis. But that in turn clashes with the requirement that: $$a^2 + c^2 + e^2 + 5(b^2 + d^2 + f^2) = 4^{N+1}$$ The contradiction appears if we require the equation to continue to hold modulo 8. In each case all but one of the lattice coefficients vanish, and what we end up with is: $$4 \ell^2 = 4^{N+1} \mod 8$$ which is impossible for $N\ge 1$ and odd $\ell$. Because $R$ and $S$ are rotations of order 5, the set of their first 4 powers can also be seen as the set of inverses of their first 4 powers. Because the corresponding integer matrices are multiplied by a factor of 4, a result that is a multiple of 8 corresponds to a factor of 2 in the original matrices. So what we have established is that, given any unit vector over the golden field with a denominator of $2^{N+1}$ for some $N \ge 1$, the inverse of precisely one of the powers of $R$ and $S$ will take us to another unit vector with a denominator of $2^N$. As we repeat this process, we will move back through the tree to ever smaller denominators, eventually terminating with the original cube. This means that we can reach every unit vector $v$ of this form as one of the cube axes or their opposites, and also that we can only reach it via a single path. 

If you work out how the circle group acts on the fibres then the connection form has to pull-back to the Maurer-Cartan form on the circle group. That will fix the multiple. 

In the case of differential geometry everything reduces to vector spaces. Let $x \in X$. Then at any point $(x, y) \in X \times X$ $$ T_{(x, y)} X \times X = T_x X \oplus T_y X . $$ Using this identification the tangent to the diagonal at a point $(x, x)$ is the subspace of $T_{(x, x)} X \times X$ given by $$ T_{(x, x)} (\Delta) = \lbrace (\xi, \xi ) \mid \xi \in T_x X \rbrace \subset T_{(x, x)} X \times X. $$ On the other hand the normal is the quotient $$ (T_{(x, x)} X \times X) / T_{(x, x)} \Delta $$ and we can identify this with $T_x X$ in at least two slightly different ways. Either $$ \iota_1 \colon \xi \mapsto (\xi , - \xi) + T_{(x, x)} \Delta $$ or $$ \iota_2 \colon \xi \mapsto (-\xi , \xi) + T_{(x, x)} \Delta . $$ We can of course also identify $T_x X$ and $T_{(x, x)} \Delta $ by $ \xi \mapsto (\xi, \xi)$. I guess one explanation for the two identifications of the normal bundle is that there is involution $\tau \colon X \times X \to X \times X $ given by $\tau(x, y) = (y, x)$ which fixes the diagonal pointwise and hence acts trivially on the tangent space to the diagonal. As a result it descends to an action on the normal bundle which interchanges the two identifications $\iota_1$ and $\iota_2$, that is $\tau \circ \iota_1 = \iota_2$ 

Suppose we have a finite group $G$ with subgroup $H$, a representation $\rho_V$ of $H$ on a finite-dimensional vector space $V$, and an $H$-invariant inner product on $V$: $$\forall x,y\in V, h\in H,\enspace \langle\rho_V(h)x, \rho_V(h)y\rangle = \langle x,y\rangle$$ We will write $V_I$ for the direct sum of $\lvert G:H \rvert$ copies of $V$: $$V_I = \oplus_{i=1}^{\lvert G:H \rvert} V$$ We define a map $L_i$ that lifts $V$ into the $i$th copy in the direct sum: $$L_i: V\to V_I\\ L_i v = 0 \oplus 0 \oplus ... \underbrace{v}_{i\text{th summand}} \oplus 0 + ...$$ We extend the inner product on $V$ to one on $V_I$: $$ \langle \sum_i L_i x_i, \sum_j L_j y_j \rangle = \sum_i \langle x_i, y_i \rangle$$ From each left coset $K_i$ of $H$ in $G$ we pick an element $k_i$, so $K_i=k_i H$. We then have an induced representation $\rho_I$ of the group $G$ on $V_I$: $$\rho_I(g) \sum_i L_i v_i = \sum_i L_{j(g,i)} \rho_V(k_{j(g,i)}^{-1} g k_i) v_i$$ where $j(g,i)$ is the index of the coset $K_i$ to which $g k_i$ belongs. Now, suppose we have an irreducible representation $\rho_W$ of $G$ on some finite vector space $W$. The Frobenius reciprocity theorem says that $Hom_H(W,V)$, the space of $H$-intertwiners from $W$ to $V$, i.e. the space of maps $S$ that satisfy: $$S: W\to V\\ \forall h\in H,\enspace S \rho_W(h) = \rho_V(h) S$$ is isomorphic to the space $Hom_G(W,V_I)$ of $G$-intertwiners from $W$ to $V_I$, i.e. the space of maps $T$ that satisfy: $$T: W\to V_I\\ \forall g\in G,\enspace T \rho_W(g) = \rho_I(g) T$$ Indeed, given an intertwiner $S\in Hom_H(W,V)$ we can easily construct an intertwiner $T_S\in Hom_G(W,V_I)$: $$T_S w = \sum_i L_i S \rho_W(k_i^{-1}) w$$ As we vary $S$ over any basis of $Hom_H(W,V)$, the associated map $T_S$ will map $W$ into distinct subspaces of $V_I$, each of which is invariant under the action of $\rho_I$, and each of which has the property that the restriction of $\rho_I$ to that subspace is equivalent to $\rho_W$. My question is: supposing the dimension of $Hom_H(W,V)$ is greater than 1, does there exist an "easy" strategy to choose a basis $\{S_1,S_2,...\}$ of $Hom_H(W,V)$ such that the subspaces $T_{S_1}(W), T_{S_2}(W), ...$ of $V_I$ will be mutually orthogonal? By "easy", I mean something less computationally demanding than simply finding all the subspaces by means of an arbitrary basis for $Hom_H(W,V)$, and then decomposing their direct sum into orthogonal invariant subspaces. In other words, I am seeking to leverage the fact that $Hom_H(W,V)$ is a lower-dimensional space than the direct sum of the $T_{S_i}(W)$ in order to carry out a less demanding procedure to achieve the same result. Edited to add: One easy way to get a basis of $Hom_H(W,V)$ is to take a sufficient number of linearly independent maps $S^{(0)}_i: W\to V$ and average over the subgroup $H$: $$S_i = \frac{1}{|H|}\sum_{h\in H} \rho_V(h) S^{(0)}_i \rho_W(h^{-1})$$ So by starting with a basis of (non-intertwining) maps from $W$ to $V$, you can project as many as required into $Hom_H(W,V)$ to obtain a basis. My (possibly naive) hope is that there might be some way of modifying this construction to lead directly to a basis with the property I'm seeking.