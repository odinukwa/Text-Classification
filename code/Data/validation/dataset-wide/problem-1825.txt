Looks to me like you'll need to make a script (shell or Perl or whatever, but personally I'd use Perl) to parse the output of an ls -laF command and then invoke a touch command. In pseudo-code, that would look loosey like this: 

I'm trying to get FreeBSD installed on a Dell R210 server with the H200 hard drive controller. I can boot with the 8.2-RELEASE ISO and the 8-STABLE-20110522 ISO. My problem is getting it to boot from the internal HDs. It seems that I need a driver in the 8-STABLE branch (not in 8.2-RELEASE) in order to use the disks as da0 and da1. It doesn't work with them in a RAID-1 configuration at all, unfortunately. So I booted from the 8-STABLE-20110522 disk and can install with it. However, I think that I can only install official releases, not from the stable branch. So... 1) Am I wrong? Is there a way to install 8-STABLE while booted from that DVD? 2) Is there a way to cvsup/makeworld the internal drive while booted from a DVD? Thanks in advance! 

This depends on what you're authenticating against. For example, I once got squid to authenticate against a Mac OS X Open Directory server (effectively LDAP). A few tips to get you started: 

Several ideas popp to mind. You'll have to research them to figure out which fits your situation the best, as I'm missing some information which would factor into it. CARP - Good if you're running FreeBSD or OpenBSD. I think that a variant is ported to Linux, but is implemented in userspace instead of at the OS level. I'm not positive. You can get some good details in the FreeBSD handbook, if you're running that. See also HAST for file synchronization. Reverse proxy - You can use this feature in apache or squid. Bsically, you have web server X and reverse proxies Y and Z. Then X has the authoritative data and requests to either Y or Z will cause them to ask X for the data. I use this to put a firewalled Mac mini on the Internet and have it dish out content from some proprietary/embedded Windows services. Then vulnerabilities in Windows become less of an issue. So in my case, it's more about security and my lesser skills are securing Windows. However, I've heard of some people using this to make "load balancing." IP - If you don't mind having to do this manually, you can always just reconfigure the IP of the second server to become the first. Not elegant or quick, but cheap and somewhat easy. CARP (see above) is effectively an automation of this. You may even be able to use a mix of cron, shell, and ping to vaguely simulate this. Load balancer hardware - I've heard of this from people with bigger systems than the one I administer. I don't know a lot about it, but it's out there. Hope that helps. 

I'm looking for hardware to run FreeBSD. I really like the chassis of the Dell R210, because two of them can stack up on a shelf in my wiring closet and take up the space of a single tower (laying on its side). However, after spending weeks trying to make it work, I'm seriously considering returning the thing. It's HD controller doesn't work with FreeBSD in RAID configuration and it doesn't even work with 8.2-RELEASE at all. (This is the H200, BTW.) Can you recommend any hardware that is sold now (can't buy used hardware at my job) that will run FreeBSD with RAID support and two ethernet interfaces? Thanks in advance! 

At the beginning of the day and on semi-random days, some of my Mac users are experiencing heavy lag. For example, 5-10 minutes to login, several minutes for Safari to load, visible delays while typing in a text field in Safari (e.g. the login form of a certain webapp). This doesn't happen with all users. The common element appears to be that these users all have their home directories on the same XServe. Users in the same building who have their homedir on either of two other servers do not appear to be effected. All three servers are in the same subnet and all users are in the same subnet. They all have the same Open Directory master. Yet the users on one server have this symptom at the same time that the users of the other two servers do not. Any suggestions? 

I need to find a way to give some telecommuters access to the office network. However, there is a high degree of confidentiality involved. So I am looking for a way to give them dedicated hardware (computers, thin clients, etc.) to bring home for the task. These devices must give access to file servers, printers, etc. in the office, but nothing else. Users must store files in the office server, etc. They should be prevented from storing items on the computer at their house, so something like a VPN isn't quite enough. I was thinking that a thin-client system would be great, but I don't know how to go about doing that. Any suggestions on products or techniques? I don't have any prior experience with thin clint systems. 

Are you sure that this is what they need? I don't mean to offend, but I've found that most of my teachers' needs were better addressed through other methods. For example, I set up a "Drop Box" share point. I then put a folder for each teacher in it. That folder is set to be world-writeable, but only readable by the teacher's account. Students can then hand in work by copying their files into the teacher's folder. They've come to call this "drop-boxing" it and really like it. Its easy to learn, its scaled well over many years and hundreds of students. The teachers even use it to send each other large files. If I had a better grasp of your needs, maybe I could see why the above doesn't work for you. Or even suggest a better method. 

Keep in mind that RAID-1 is a way to make 2 drives act like one. So when you write to "storage," you will be writing to both drives. When you read a file, it will read from whichever disk is available first. Theoretically, this makes a penalty on writes and a boost on reads. In reality, you might not notice a speed difference. The real reason that this is important is that it means that there is no such thing as a drive "taking over" when another drive fails. They're both in constant use. Case in point: I had a Mac Pro with two 500GB drives in a RAID-1 array at work. One day I randomly checked that server and discovered that one of the drives was actually dead for the last few months. No one noticed a difference. This computer was the file server for an entire elementary school. I'll answer question #3 by telling you what happened after finding the dead HD in the Mac Pro. I replaced the drive with only a few minutes of down-time. I replaced it AND added a third drive as a hot spare. So I now have 3 HDs acting like one storage device, i.e. a single "drive," of 500GB. Again, no one can tell the difference. As a side note: Please note that RAID is NOT a backup solution. I have had situations [plural] where I've lost data in a RAID array. My backups were well worth their expense those days. 

I'm assuming that "srvadmin" is the account that you created when the OS was installed and configured. If so, a few ideas: 

Again, that is pseudo-code. Its meant to demonstrate the idea that I'm thinking of within 5 minutes. Do not expect the above to be similar to the code you end up producing. Hope that helps. 

IIRC, ntpdate is used to set times, but ntpd is used to maintain the time on a system. Look in Server Admin --> --> Settings for the NTP on/off check box. Don't worry about the config files. If you can't get a solution from the GUI, then the following website might help: $URL$ Good luck. 

Is it possible that there are instructions in ~weirduser/.bash_profile that are causing it to logout? You don't offer any details about how it behaves (error messages, timing between steps, etc.) when you try to login from console or SSH. However, I noticed that it has bash for a shell. The man page states that ~/.bash_profile is only used for login shells, which I think means console and SSH but not su. Check other ~weirduser/.bash* files, while you're at it, too. Look in /etc/profile, too, but that is highly unlikely. Its just a guess, but its worth checking. If you provide more data about the way in which it fails, I'd be happy to try to come up with more ideas. Good luck. 

You can export and import JUST the workgroups (based on your purposes) via the menu bar -> Server -> Export (or Import). I definitely bow respectfully to the shell scripting in your follow-up post, but it might be more high end than you're comfortable using. Also, you can have remote-bulding server simply "Connect To" an Open Directory Master instead of making them Replicas. You get most of the same advantages. I've personally run both Connected and Replica servers for years. I've even done both of those over heavily utilized T-1 connections. (In fact, there are only two reasons to use a Replica instead of a Connected setting. One is for performance when in a remote, latency heavy site. The other is for redundancy -- the master can go down and users can still login.) Maybe that would give you your ideal solution? What kinds of problems did you have with Replicas? Maybe I could help, if you're interested. 

Use an MX record but NEVER EVER use a CNAME on a domain. It violates the structural basis of DNS. A CNAME, or Canonical Name, is like a synonym in DNS. And DNS is hierarchical. So saying foo.com is a CNAME to bar.com will invalidate all hosts such as xyzzy.foo.com and all MX records in foo.com. It effectively replaces foo.com with bar.com. This is what I was taught when I was working on DNS in the 90s, at least. The advise has served me well in the 12-13 years since I heard it. 

If this is at a school, give Apple support a call. They offer free support to public schools in the US at 800-800-2775. When asked for the product that you're calling about, say "XServe" or "Mac OS X Server" to get to the department that you want. 

I use FileWave to deploy files (e.g. "Google Chrome.app") and installers (e.g. "MacOSXCombo10.6.7.pkg") to over 600 Macs. Mixed with Deploy Studio (via a NetBoot server), I have a fully automated Mac workstation deployment system. I've also heard of (and been really fascinated by) RAdminD, Star Deploy, and Munki. Both of those are free systems that do parts of what FileWave can do, but aren't quite as robust. For example, they aren't as good at giving lists of what updates installed, didn't install, and why it didn't install. Also, FileWave can do roll-backs ("Geee.... That software has a bug. I'll just pull it back off the computers and replace it with this cached copy of the previous version for now.") and manage iOS (iPads, iPhones, iPod Touches) to a degree. Hope that helps. 

I'm having good luck with a Barracuda Backup appliance. Its not cheap (a few thousand at the beginning and a monthly cost for off-site storage), but it gives you a simple to use tool with lots of technical support. It will also send the data off-site. The least troublesome product that I've used so far. By comparison, I've directly been involved with Retrospect (versions 4 through 6), Time Navigator, NetVault, and Barracuda Backup Service. I've been indirectly involved with the built-in backup in Windows, Veritas, and Backup Exec. On Unix and Mac, I've used rsync (command line) and a few Mac-only products. Not sure if you have the budget or space for it, but thought I'd suggest it. 

Login as ANYONE and type "id srvadmin" to confirm that the account still exists. Put in the OS install disk, reboot from it, and use the password change tool. 

I've had this happen, too. In my case, it was a AFP (Mac file sharing) based home directory server and an Open Directory Replica. I ended up reinstalling the OS and re-binding it to the OD Master. Nothing else seemed to work. Not disk repair tools (fsck, diskutil, Disk Warrior), or re-binding to the OD Master, or software updates, or checking the logs, or calling Apple more than a half-dozen times. If this is your Open Directory Master, export all your users, user groups, computers, and computer groups via Workgroup Manager. Then demote all OD Replicas to Stand Alone and reboot them. Then re-import the Workgroup Manager data and re-bind the Replicas. (Note that all users' passwords will be lost. You can use the shareware program Passanger to read the users export and re-write it with known passwords. Then distribute the passwords to your users.) This process will cause the Open Directory data to rebuild, which should remove the corruption in an OD Master. Yes, I've had to do this a few times before. My users were... unhappy about the experience. They were glad that they could login again, though. If your server is at a school, don't forget that Apple provides free phone support. Good luck.