Did you see the value in the box before deciding whether to switch? If you did not see it: You are calculating the expectation wrong. You said there are two events, the second box containing $2v$ or $v/2$. But this conditions on a particular $v$ being in the first box. You did not see what's in the first box, so this is inadmissible. The correct pair of events is that either the second box contains $2n$ and the first box contains $n$, or else the second box contains $n$ and the first contains $2n$, with probability $0.5$ for each event. (Of course you are therefore indifferent to switching.) If you did see it: You are calculating the expectation wrong. Conditioned on opening the box and seeing $v$, there is a posterior probability that the other box contains $2v$ and a posterior probability that the other box contains $v/2$. These probabilities are determined via a Bayesian update from their prior probabilities, updating on the event that the first box contains $v$. In general these probabilities will not be $0.5$, but we cannot compute them because you did not tell us a prior distribution on the values in the boxes. Without a prior, the posterior is not defined and you cannot calculate the expected value of switching. For example, if you are told $n = 50$ in advance, i.e. guaranteed that one box contains $50$ and the other $100$, then of course you should switch if the first box contains $50$ but should not switch if the first box contains $100$. If you are told that $n$ is drawn uniformly from $[0,N]$, then you should not switch if you see $v > N$ because you must already have the larger box. Etc. 

See the bottom of p304 and top of p305 for a reiteration of this point. So it looks like to me that what's happening is that the same phenomenon -- i.e. a robot with a set of things it can sense and actions it can take -- is being modeled two different ways. These two ways have the same formalism but different meanings. The first, state-based way, explicitly tracks all possible states the world might be in, the set $Q$. The second, "diversity-based" way tracks the number of equivalence classes of "tests" that produce different results for the robot; this is modeled by $V$. Importantly, a particular state-based representation (your first definition) models the same phenomenon as a particular diversity-based representation (your second definition), but the mapping between these is NOT the identity! 

Now I am pretty happy with this definition, but the problem is (as has been noted) an arbitrary game tree can be phrased as a board game in this way. But I think we get closer with this restriction: 

Analysis: It helps to re-write the algorithm as follows. First delete from the graph all vertices with no edges. Now find a maximal matching between $L_0$ and $L_1$. Now delete from the graph all vertices in $L_0$, all matched vertices in $L_1$, and all edges incident to any deleted vertex. Repeat this entire process (note that the surviving vertices in $L_1$ become the "new" $L_0$ after the deletions) until the graph is empty. Note that this process eventually deletes all edges in the graph. We just have to show that at each round, at least $1/4$ the deleted edges are in the matching. Fix a round and suppose that $k$ edges were matched between $L_0$ and $L_1$. The deleted edges are exactly: (a) all edges between $L_0$ and $L_1$ plus (b) all out-edges from the matched vertices in $L_1$. The set (b) has size at most $2k$, as there are $k$ matched vertices in $L_1$ and each has at most $2$ out-edges. The key claim is that the set (a) also has size at most $2k$, or in other words, at least half of the edges between $L_0$ and $L_1$ are in the matching. Proof of key claim: Consider just the (undirected) bipartite graph between $L_0$ and $L_1$. Note all vertices have degree either $1$ or $2$. Take any $v$ with degree only $1$ and consider a maximal simple path starting at $v$. This path contains all the edges incident to all vertices on the path. At least half of the edges are in the matching by maximality (else we have an augmenting path). Find another vertex of degree $1$ and maximal simple path, etc. until no more vertices of degree $1$ remain. This decomposes the bipartite graph into disjoint paths of the above form and a "remaninder": a set of vertices all having degree exactly $2$. There must be the same number of vertices from $L_0$ and $L_1$ and they must have a perfect matching, e.g. because they are a disjoint union of even-length cycles, and the total number of edges is exactly twice the number of vertices, so exactly half the edges in this "remainder" are matched. P.S. Here is a graph where the bound is tight: For any $n \geq 4$, $L_0$ has $n$ vertices, $L_1$ has $n/2$ vertices, and $L_2$ has $n/2$ vertices. Each vertex in $L_0$ has out-degree $1$, each vertex in $L_1$ has in-degree $2$ and out-degree $2$, each vertex in $L_2$ has in-degree $2$. There are $2n$ edges in the graph, and a maximum matching cannot do better than including all $n/2$ vertices in $L_1$ (since every edge has an endpoint in $L_1$), so any maximum matching has size $n/2$. 

If $x$ is a root of our random polynomial $$ p(x) = a_nx^n + \dots + a_1 x + a_0, $$ then each of these vectors (including the $x^0$ vector not drawn) is multiplied by a random coefficient, and the sum is equal to the zero vector. I'm just thinking of i.i.d. positive bounded coefficients for this response. The key point is that this weighted sum of the vectors in any particular direction must cancel out to zero if $x$ is a root of the polynomial, yet each time $x^k$ goes "around the circle" the sizes $|x^k|$ of the vectors is geometrically larger --- unless $|x|$ is very close to $1$. Intuitivley, some randomness in the coefficients will not be enough to cancel out large growth of $|x^k|$ because the vectors must sum to zero in every direction simultaneously. For concreteness, choose the direction of the positive $x$-axis. Then the condition that $x$ be a root implies that, letting $\theta = \arg x$ be the angle of $x$ with the $x$-axis, \begin{align*} 0 &= \sum_k a_k Re(x^k) \\ &= \sum_k a_k |x|^k \cos (k \theta) . \end{align*} Heuristically, since $\cos(k \theta)$ is an oscillating term in $\theta$ and the $a_k$ are independently random, $|x|$ must be very close to one or else the large-$k$ terms "unbalance" the sum. And this condition must hold in all directions, not just the positive $x$-axis. I have drawn the case where $|x| > 1$, but the $|x| < 1$ case is exactly the same. (Edit: Maybe also interesting, in light of Francois' simulations, but this suggests that if the coefficients are all positive, or more likely to be positive, and the degree $k$ is relatively small, then we should see few roots with argument (angle to $x$-axis) close to $0$: In this case there is not enough oscillation to get cancellation. That is, the powers of $x$ don't go "around the cycle" and neither are they cancelled by negative coefficients.)