Strictly speaking (as far as I know), hydrostatic equilibrium applies whenever a fluid balances external body forces with the pressure gradient. From Wikipedia: 

I write this as a theorist who's never visited a modern observatory, so I will gladly defer to any true observers who do come along. But as far as I know, the best sites for astronomical observatories (certainly in optical or near-IR) combine a few common features. Above all, you want to be high and dry: above as much of that pesky atmosphere as possible. You don't want turbulent air distorting the image (related to what we usually call "twinkling"), nor do you want clouds to stop you from seeing the sky at all. Ideally, you also want to be reasonably close to the equator, so that you get access to different parts of the sky at different times of year. You also want to be far away from light pollution but the "high and dry" objective tends to bring that anyway. With just these few things in mind, the ideal locations for telescopes become quite clear. The summits of Mauna Loa and Mauna Kea on the Island of Hawaii (i.e. Big Island) are certainly up there. The top US telescopes are usually up there. For the Southern Hemisphere, the Atacama Desert in Chile also combines these features. For that reason, the European Southern Observatory, when it formed in the late 50s and early 60s, decided on the Chilean site, and they've been building many of their most advanced telescopes there ever since. The news stories you hear are probably based on telescopes at either the Paranal or La Silla Observatories. Edit: As pointed out in a comment below, there are other significant observatories in Chile. 

I think the concept happens to be most frequently used in areas where gravity is the external force, but it could in principle be anything else. So, though I stand to be corrected, I think a droplet isolated in space long enough could be said to be in hydrostatic equilibrium, even though the most relevant force is the surface tension, rather than gravity. 

You probably need someone better versed in the history of astronomy than me, but I'll give it a stab. As you've already noticed, the Wikipedia article on stars named after people has some entries, and that's probably about it. In terms of modern naming procedures, we tend to use catalogue names. Unlike, say, asteroids, there's no systematic way of naming stars after people or anything else, so stars usually continue to be referred to only by catalogue number. Those rare stars that are named after people (or something else) are usually because they are now somehow historically associated with that system. Unless, of course, the catalogue is named after someone! Another exception are those very bright stars with pre-telescope names, but those aren't named after people (e.g. many scientific papers refer to Betelgeuse as such). I guess in short, there's just no standard modern naming procedure by which a star can end up with a person's name, so few exist, and probably most are listed in the Wikipedia article. 

The effective temperature $T_\mathrm{eff}$ of a star, which is presumably what's been plotted, is defined through its relationship with the star's radius $R$ and luminosity $L$ by $$L=4\pi R^2\sigma T_\mathrm{eff}^4$$ This comes from the assumption that the star radiates like a black body at the photosphere. While this isn't strictly true, it's quite accurate, and regardless, that's how we define the effective temperature. The actual surface temperature will be slightly different but also behave roughly as plotted. So, even if $T_\mathrm{eff}$ is constant, the star expands if it grows brighter. Also, you can see that the sensitivity to temperature is steeper than radius, so a moderate change in luminosity can be absorbed by a relatively small change in effective temperature. While the luminosity is basically determined by the simple behaviour of the nuclear reactions in the core (in terms of temperature and density), the surface properties depend on how energy is being transported near the surface. For radiation, you have to consider what the opacity of the material is, which itself depends on ionization states and whatnot. It's easy enough to see why the luminosity grows (the core gets denser and also hotter, producing energy faster) but the determination of the surface properties is more complicated. For the Sun, it turns out the way shown in the plot after you solve all the equations with the relevant opacities. Also, as an extreme counterexample to "brighter means hotter and smaller", remember that red giants are much brighter but also much cooler! PS: I'm not sure the source of the data but I would guess the wiggle at the start is because of the star finishing its contraction onto the main sequence. That is, before the first minimum, energy is being released by gravitational contraction. After it, the energy from nuclear reactions starts to dominate. 

I personally use Astropy, specifically , although I'm not a seasoned user of FITS files and I don't really know their layout. As an example snippet of code, I often load data from FITS files using 

I'll try to add a bit of context to the Wikipedia article, though the major references are all available there. The article covers things like the potential formation mechanisms but I guess doesn't really put them into scientific perspective. Consider, for a moment, a red giant of one solar mass, far up the red giant branch. It has a deep convective envelope, at the bottom of which there is a shell of hydrogen fusing into helium, all surrounding an inert, highly degenerate helium core. The core at this point is much like an isolated white dwarf. So, back in the late 1970's, Kip Thorne and Anna Żytkow tried to model (Thorne & Żytkow 1977) what would happen if you replaced the white dwarf with a neutron star. Such hypothetical objects thus became known as Thorne-Żytkow objects (TZOs). TZOs have mostly remained theoretical exotica, at least in part because it's very difficult to distinguish them from "ordinary" red supergiants. The main giveaway would be the presence of unusual elements in the atmosphere, produced by the much hotter nuclear reactions happening in the fusion shell around the neutron star core. There have been just a handful of papers published about them, almost all by theoretical groups, in the intervening 40 years. The only candidate that I think anyone takes seriously is HV 2112. As far as I know, Levesque et al. (2014) found the object serendipitously as part of a survey of red supergiants in the SMC. PS, following comment: The consensus view is that a single star couldn't form a TZO because if the core collapses into a neutron star, models predict that the envelope will be ejected. That is, single star's only evolve into "naked" neutron stars. Under this assumption, the only way to form a TZO is to have a neutron star collide with or accrete enough material from another star. This could happen if two wandering stars collide. Alternatively, it could happen if one star in a binary collapses into a neutron star. In particular, it's known that the collapse process is probably not symmetric, so the neutron star gets a "kick" in some direction. If the neutron star is kicked into the companion, it will presumably undergo some viscous drag and settle into the centre. 

I'm no expert on stellar atmospheres, so I have a limited idea of how things like $\log g$ affect the lines. But I work with stellar models, so I can take a stab at that part. The overall principle is that computing stellar model ages is a kind of optimization problem. We model the structure of stellar interiors by constructing a system of differential equations based on a few simple assumptions. (When I teach stellar structure and evolution, I usually recommend the outstanding and free lecture notes by Onno Pols and Jørgen Christensen-Dalsgaard.) These models depend on many parameters. Some are familiar: the mass, composition, and age. Some less-so: there's usually at least one parameter for how convection is parametrized. e.g. the mixing length. Some are discrete: which opacity data is used, what solar abundances are chosen. And some are relatively inconsequential: there a dozens (or even hundreds!) of numerical parameters used in solving the equations. So let's just say we have a magical black box that takes five parameters—mass, initial metallicity, initial helium abundance, age and mixing length—and produces $T_\text{eff}$ and $\log g$. What we have to do is select values of the parameters to match the observations, which is a standard problem in optimization, inference, parameter estimation, or whatever you want to call it. Keep in mind that age is a special parameter. There are ways of measuring things like mass, radius or luminosity relatively directly. But choosing the sequence of models that produces the appropriate star is always depends on which stellar models you use in the first place. Ages are uncertain both because of the uncertainties in the observations, but also because of the intrinsic uncertainty in the models. Although something like interferometry can potentially give an independent radius, we can only get indirect measures of age, and converting these indirect measures to ages also introduces uncertainty. The trick now is how much data you have...