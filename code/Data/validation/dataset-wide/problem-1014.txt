I got a question if i create a login and database user for a database named TEST, and i have given permissions to user as db_datareader only. 1) Where does this permission evaluated when a user connects and runs a DML query? 2) If permission is checked during early stage of Relational engine will execution plan be created and stored in cache? 3) My answer is transaction manager in storage engine which controls the locks and permissions am i right? 

When i see my staring page number= FileID:PageNumber it is starting 1:285. Q 1). Why my page not starting from 1:0 or 1:001? Q 2).Will this page number have dependency from model database? Kindly find the below images 

I had a question on Log shipping Manual Fail over Let me explain about environment, Primary Server A (with Cluster setup A-P Mode) Secondary server B(DR server standalone). We had enabled Log Shipping on a database TEST from Primary Server and now we would like to test by doing a manual fail over and i had few questions. Log Shipping Jobs are disabled on both A and B Servers and Log shipping is not disabled or removed, Once the Server B is brought online by restoring the all the logs from Server A 

My search on the topic brought me here, so I'd just like to share my recent experience on the topic. I was running SQL 2014, so I figured that I would be safe from having to care about 4199 for a little bit... but it just wasn't true... How to Diagnose if you need 4199 If your query appears to run poorly, particularly when you feel it shouldn't, then try adding the following to the end of it too see if it fixes all your problems, as you might need 4199 ("Enable all Query Optimizer fixes.") 

Where -1 specifies the Global part in DBCC TRACEON. For more info see: $URL$ "Recompiling" Query Plans In my most recent attempt I had to enable 4199 globally, and then also remove existing cached query plans: 

In my situation, I had a top 10 clause blowing up a query that ran fine without, which is what made me think something fishy was happening, and that 4199 might help. About 4199 Any SQL Server Query Optimizer bug/performance fixes that are created after the new major version release actually get hidden and blocked. This is in case they might actually harm some other theoretically perfectly optimized program. So, install updates as you might, the actual query optimizer changes are not enabled by default. Therefore, once a single fix or enhancement has been done, 4199 becomes a necessity if you want to take advantage of it. As many fixes show up, you'll eventually find yourself turning this on when one of them affects you. These fixes usually are tied to their own trace flags, but 4199 is used as the master "Turn every fix on." If you know which fixes you need, you could enable them piece-meal instead of using 4199. If you want to enable all fixes, use 4199. Ok, So you want 4199 Globally... Just Create a SQL Agent Job which runs every morning with the following line to enable the trace flag globally. This ensures if anyone turned them off or etc, that they get turned back on. This job step has pretty simple sql: 

I have seen the 8KB (8192 = 96 Header + 36 Row Offset + 8060 Free space) page architecture in SQL Server. When it comes to storing a data record in Page i am confused. In Below table i have create Integer for column ID it should take 4 Bytes but each record size/length is showing in DBCC PAGE Command 11 Bytes. I have created a simple table as below: 

Q 1). Why a simple integer data is taking 4 actual bytes of data + 7 Bytes extra = 11 Bytes. Q 2). Can anybody explain how does a record store in a page. Kindly find the images below: 

I had checked the space of table Orders and Orders1 where i found the index size is of Orders Table is more than data size and in Orders1 Only i can find Data Size is less. Question 1:Is index size in orders table is cumulative of 9 indexes? or Its a single clustered index(as shown in below Fig.2) Question 2:Each index partition shown below in Fig.2 has 830 rows is that mean to have duplicate page data on disk or memory? Question 3:Does Non-Clustered index occupy space on disk or only Clustered Index? Question 4:How does fill factor effect on storage of these clustered and non-clustered indexes. How does index occupy size on disk(any references links/books/blog)? 

I might have solved my problem... I was afraid that 2 different killer threads could: (1) , (2) choose the same connection to kill, (3) then both would it. The first kill would trigger the execution of whatever I wanted, while the second kill could potentially blow things up. The easiest, and nearly obvious, solution that I missed is to look at the other side of the problem: instead of making the worker thread unkillable, the killer threads must cooperate: the killer threads would (1) , then only after acquiring the lock they would (2) , (3) the chosen threads and finally (4) . 

If you are not able to fine tune the filesystem (for instance, by using a smaller block size), and you really must use a database, I'd suggest the following readings: 

The first will explain the data structure most commonly used by indexes, the B-Tree. The second explains how MySQL uses the B-Tree. The third will tell you about the command , which is how MySQL describes the query plan (it will tell you which (if any) index it is using, if it is doing table scans -- which you must avoid at all costs). To create an optimized index, you should first think about the structure of the query (or queries) you will need. For example, it might be something like: . You should analyze the cardinality of each column (ie, how many different values can the column have). You chose the columns with highest cardinality to be the first in an index, leaving those with lower cardinality to the end. Example: suppose you have 2M rows and is a number between 1 and 1M, randomly distributed, and is the full name of the owner of the file. In such a situation, you want the index , in this very order, since the clause will leave you, in average, with only 2 rows. The cardinality of , on the other hand, is much lower: there are much less then 1M possibilities for people's names. Therefore, if your index is , the query will first look for every row in which begins with (which will be likely tens or hundreds of thousands), and only then it will look for the other condition. Also, note that the index is used from left to right. That is, if you have 3 columns, , and and you index , the index will be mostly useless in a query such as . It will likely be used to find rows matching , but after that every row will be checked for . If most of your queries are like that one (and some might specify B as well), than your index should be . Finally, note that can use an index, while (or ) cannot. This is, again, because the index is read from left to right. To match , it knows where to start looking; to match it must check every single row. All that said about indexes, I'd strongly suggest you to rework your criteria so that you have something more structured. As you said, you could try to precompute something. There are other considerations, such as the size of the content. If you can make it fit in under 8KB (which is like 3000 characters if you use UTF-8), then InnoDB will store the data in the same page as the primary key; otherwise, it will store the data elsewhere. If you query by primary key, in the first case you have a single read operation; if you query by another index, in the second case you have 3 read operations: one to find the primary key of matching row, one to find the row by primary key (to read the address of the data) and one to read the data. Oh, check the amount of RAM of your server. Ideally your data (or at the very least your indexes) should fit in the RAM. By considering all these points, you should have no problem at all: I don't know the hardware of your server, or its load (since you said it is shared), but 800k rows is close to nothing if you fine tune your indexes; I'm very far from expert and, by doing all the above things, I work daily with (very optimized) tables with 10M, some 100M rows, and the queries are ultra-fast. I hope that helps. Once you have your table(s), you could ask another question showing the statement and describing a bit about your data (sizes, cardinalities, etc) and the select queries you will use, so someone could help you to create an optimized index. 

$URL$ Where the recompile stored procedure finds any query plans relating to the database object (such as a table) and deletes those query plans, requiring the next attempt to run a similar query to compile them. So, in my case 4199 kept the bad query plans from being created, but I also had to remove those that were still cached via sp_recompile. Pick any table from the known query affected and you should be good to try that query again, assuming you have now enabled 4199 globally and cleared the offending cached query plan. In Conclusion on 4199 As you utilize indexes, a smart query plan optimization becomes important to actually using those indexes intelligently, and assuming that over time some fix to the query optimization process will be released, you're generally in safe water to just run with 4199 globally enabled, as long as you realize that some new fix might not actually play as nicely with a highly optimized database that was such optimized in the prior environment before said fix. But what does 4199 do? It just enables all fixes.