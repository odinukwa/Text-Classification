If a wrong certificate was to be presented (no SNI or wrong server selection), you would normally get a certificate warning since there would be a mismatch between the requested domain name and the one set for the certificate. This will display the protocol being used by the current connection: 

nginx is able to talk with any backend listening on a FastCGI socket. That includes PHP-FPM and HHVM, provided both frontend and backend are configured to find each other. Thus, it not efficiant to use 3 layers while you could only have 2 layers . You would need to decide which Web server you would prefer to use. I do not understand what might be unsafe, though, provided you use a setup suitable to be a server, up-to-date and properly configured. Security covers a wide range of different scopes, starting from network design, passing through OS configuration, up to individual Web server locations configuration. Provided you use stable software and an easy/automated method for maintenance/updates, I do not see why it would not be suitable for production. Anyway, the baseline is: you only install the bare minimum of stuff you need on a server. Security is helped by simplicity/cleanliness. 

As @Lukas explained it, forwarding the Authorization header to the backend will makes your client attempting to authenticate with it. As you probably have not defined any authentication in your backend, it will answer with a 401, as the RFC 2617 requires: 

Having several nginx process might be normal... or not. If you only have 2 processes, then you probably have the master process and 1 worker process, which is the way nginx works. Having several master processes, unless it is what you wish, is probably sign of trouble. If your PID file is empty, that is definitely a problem: it is used by the managing service to identify which process to check for and to send signals to. Empty PID file = service will try to send signals to the void... 

As a supplementary piece of advice, you might want to have a look at your regular expression to replace the generic catch-all characters by more specific classes or sets, so its behavior is better defined. 

Start by deleting the stanza from your file since that triggers the now unwanted behavior of including content at level. Now you could use some locations such as: 

Avoid at all costs automated tools which lack, by definition, the brains to properly convert rules. There is no simple 1-to-1 match between Apache and nginx ways. They have 2 different mindset. You thus need to understand what you are doing and use the nginx way of configurating it. That is IMHO a complex problem out of the reach of an automated tool. Concerning rules: 

then use in combination with 3. ?dct=portfolio_ -> ?dct=services_ Finally, to redirect old domains to new ones, it is the kind of arguments filtering explained on the link provided by @wurtel, although I would once again use a map instead of . 

Note the use of the variable, reproducing the scheme used to connect to the frontend with connection to the backend. I am unsure about SSL configuration on the backend. I guess you need to use the same on each of them and the same SSL certificate as on the frontend. I do not know if you can use different certificates on backends, each with a different and change SSL parameters for connections with the proxy module. 

According the official documentation, the only way to manipulate environment variables in nginx is through the use of the directive, only available in the context (ie not dependent on the protocol such as , thus not its inherent s). That means, the variables will be set for the whole nginx environment (even though it seems you can change it worker-based, which are independant processes). To do what you wish, I would suggest either: 

Once per log in a specific account, Windows XP is switching to 800x600 and 8 (looks like) bit color. It then after a few seconds switches back to the regular settings. This, so far, has only happened, once per log in session but it is becoming very annoying for the end user. :P Any ideas? I've tried turning off hardware acceleration as well as getting rid of her picture desktop wallpaper but nothing has made a difference. Thanks for any help! 

We have a bad problem of people forgetting/not caring enough to print handout versions of sometimes very large powerpoint presentations. Is there a way to force them to print handout versions of powerpoint slides that have 6 or 9 per page? It would save us a ton of both paper and money! Thanks! Edit: Maybe a good compromise would just be a message box that pops up everytime a powerpoint document is printed reminding them? I guess it would be probably good enough to have it just default to handouts and let them change it if they really want to waste all the money. 

I have an application that requires this older version of "MSSQL Server". Is there any chance I could seamlessly upgrade the DBMS to another (preferably free) product? It's having alot of "Out of hard drive space" messages and the application that uses it is crashing more and more. Thanks for the advice! 

Have the above server (got it for free) with the PERC 4e/Di raid controller inside (according to dell's site). I've downloaded the drivers to a floppy. The Windows Server 2003 Install disk recognizes the fact these disks exist and that the drivers on the floppy are newer. I select them to load, I see several screen flashes with "Windows is starting..." at the bottom of the screen and then I get the message saying no hard disks could be found. We've looked inside the machine and there is no IDE or SATA capability to speak of. Any ideas on what we should do? :) 

Is there a way to get 127.0.0.1 to route to the host computer (the one running the virtual machine, not the virtual machine itself)? I am supporting a web app that sometimes requires 127.0.0.1 to be the ip address, and NOT the 10.222.54.2 number I am getting for the host address at the moment. Thanks! 

No idea what's going on. New to Windows Server 2003. I can see the file in progress in Windows Explorer but then it disappears as soon as the file is finished downloading. What is going on? 0.o 

(Not sure on the model at the moment will update once I know) So we had a a RAID 5 that had two hard drives fail at the same time. Positions 0 and and 1 are labeled as "online". Positions 2 and 3 are labeled as "failed". We had a backup drive (of course) and put it in position 2. The drive is still telling us as position 2 as "failed". Is this usual behavior? Is won't let us rebuild of course since we lost two drives. (To make sure the controller wasn't just the thing that died, we tried switching the drives around. Switched 0 and 2 positions' cords. 0 went to failed while 2 went to online. The problems followed the drives) What should we do? EDIT: Put in the new drive and now on boot it's saying "unresolved configuration mismatch between disk(s) and NVRAM on the adapter" No idea what that means. xD 

Really need the ability (for backwards compatibility's sake ) to run Safar 4 on OS 10.6.4 instead of Safari 5. Would be sick to have both running at the same time. :D SOLVED: Found this website finally. :P $URL$ 

I'm going to assume that the -f argument expects an absolute path to the file and interprets the path as relative otherwise. Are you running those commands from in /etc/openldap? Does using work? Are you running the commands as a user that can read that file? 

Assuming you mean then yes, that should work. Check that the file has exactly two lines and that there aren't any extra spaces or anything in the key line for the second key. Also check that you have added the correct lines for each desired key. 

Installing an extra root certificate on the server is not going to help a browser trust the server certificate the server sends it. The browser needs the root certificate locally in order to construct the chain of trust when the server sends it the certificate. If you check the certificate dialogs in Chrome and Firefox I believe you will discover that Chrome has found the root CA installed locally and has constructed a correct valid chain whereas firefox has failed to do the same (because it does not have the necessary root CA locally). Installing root CA certificates in browsers is a fairly simple process once you have the appropriate certificate file. The certificate dialogs in the various browsers all have an 'import' button of some sort that you can use for this task. If your certificate requires intermediate certificates then those should, for best compatibility and correctness, be sent by the server during the SSL handshake process. That requires the intermediate certificates to be configured on the server the same way as the server certificate is (that is they must exist in a file and Apache must be pointed at that file with the SSLCertificateChainFile (or similar) directive). 

and tell you what sasl plugin types are available. I would assume those would return errors or empty lists if sasl support was not enabled at build time (though possibly not). You could also check the output of and see if it links to a sasl library or not (though it might be possible for postfix to be built with sasl and not link to a sasl library if it supports it via a plugin or something, I don't know whether it does or not). 

You need to find out if you are supposed to have an intermediate certificate or not. If you are then having your server supply it in the chain will help any clients that do not have it build a valid chain (assuming they have the StartSSL root certificate installed locally). That may not be the case and that will not help people who don't already have the StartSSL root certificate trusted locally. You can't help those people though they will have to install it to avoid the warning. 

You need to close the url.rewrite with a . That fcgi error seems to be referring to an fcgi script that I don't see mentioned in your configuration snippet. Is that the whole config? Is there anything in the conf.enabled directory? 

If you configure apache with no listening configuration on port 80 and ensure that you configure it to listen on port 443 with ssl correctly then yes, your server will not listen on any non-ssl ports. 

According to that documentation it looks like anywhere on the ISO you want as long as you point the path to it correctly in the preseed/url parameter. The example documentation puts it in the root of the ISO filesystem. That being said an ISO is a not a zip file and extracting and recreating one is not as simple as a similar operation for a zip file (though there are plenty of tools that should allow you to recreate the ISO as needed). It might be simpler, if you have an http/ftp server to stick the file on briefly, to just use that for this.