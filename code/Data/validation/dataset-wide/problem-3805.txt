If we ignore the trivial case of the affine line, then irreducible symmetric spaces come in pairs compact - non-compact. The compact ones are naturally projective varieties, while the non-compact ones are affine varieties. Thus question (4) is problematic, unless you mean "locally symmetric" or a more general notion of symmetric space than I understand here (i.e. "globally symmetric Riemannian symmetric space"). As far as non-compact symmetric spaces are concerned, they are Kähler if and only if they are biholomorphic to a bounded symmetric domain. Equivalently, there exists a compact quotient with non-trivial H^2 or, equivalently, the point stabilizer of the automorphism group has infinite center... I could give many more characterizations, but I do not quite see what you are after, so maybe you can provide more detailed information? 

See Montgomery's book, Ten Lectures on the Interface Between Analytic Number Theory and Harmonic Analysis, specifically the examples on p.55. He considers variants of your sum, namely $\sum_{n \leq N} e((n/3)^{3/2})$, and $\sum_{n \leq N} e((2n/3)^{3/2})$, and shows that they have very different asymptotic behavior. The former is asymptotically $c N^{3/4}$ while the latter is $O(N^{1/4})$. These examples illustrate why the hypothesis (3.3.3) in [GK] is assumed. 

While the answer to your question is negative in general, as pointed out before, the answer is positive for certain type of loop groups. This can be proved using topological twin buildings. See Linus Kramer, Loop Groups and Twin Building. (It is not stated very explicitly, but the topology used on the twin building and hence the algebraic loop group is meant to be the ind-topology coming from the Bruhat cell decomposition.) 

In some of my previous work on mean values of Dirichlet L-functions, I came upon the following identity for the Gamma function: \begin{equation} \frac{\Gamma(a) \Gamma(1-a-b)}{\Gamma(1-b)} + \frac{\Gamma(b) \Gamma(1-a-b)}{ \Gamma(1-a)} + \frac{\Gamma(a) \Gamma(b)}{ \Gamma(a+b)} = \pi^{\frac12} \frac{\Gamma\left(\frac{ 1-a-b}{2}\right) }{\Gamma\left(\frac{a+b}{2}\right)} \frac{\Gamma\left(\frac{a}{2}\right)}{\Gamma\left(\frac{1-a}{2}\right)} \frac{\Gamma\left(\frac{b}{2}\right)}{\Gamma\left(\frac{1-b}{2}\right)}. \end{equation} As is often the case, once one knows such a formula should be true then it is easy to prove it. I give my proof below. My questions are 1) Has this formula been observed before? I have no idea how to search the literature for such a thing. 2) Is there a better proof? (Of course this is totally subjective, but one thing that would please me would be to avoid trigonometric functions since they do not appear in the formula.) Proof. Using \begin{equation} \frac{\Gamma(\frac{s}{2})}{\Gamma(\frac{1-s}{2})} = \pi^{-\frac12} 2^{1-s} \cos({\textstyle \frac{\pi s}{2}}) \Gamma(s), \end{equation} the right hand side is \begin{equation} 2 \frac{\cos(\frac{\pi a}{2}) \cos(\frac{\pi b}{2}) \Gamma(a) \Gamma(b)}{\cos(\frac{\pi (a + b)}{2}) \Gamma(a+b)}. \end{equation} On the other hand, the left hand side is \begin{equation} \frac{\Gamma(a)\Gamma(b)}{\Gamma(a + b)} \left( \frac{\Gamma(a+b) \Gamma(1-a-b)}{\Gamma(b) \Gamma(1-b)} + \frac{\Gamma(a+b) \Gamma(1-a-b)}{\Gamma(a) \Gamma(1-a)} + 1 \right), \end{equation} which becomes after using $\Gamma(s) \Gamma(1-s) = \frac{\pi}{\sin(\pi s)}$, \begin{equation} \frac{\Gamma(a)\Gamma(b)}{\Gamma(a + b)} \left(\frac{\sin(\pi a) + \sin( \pi b) + \sin(\pi(a + b))}{\sin(\pi(a+b))} \right). \end{equation} Using trig formulas, we get that this is \begin{equation} 2 \frac{\Gamma(a)\Gamma(b)}{\Gamma(a + b)} \frac{\sin(\frac{\pi}{2}(a+b)) \cos(\frac{\pi}{2}(a-b)) + \sin(\frac{\pi}{2}(a+b)) \cos(\frac{\pi}{2}(a+b)) }{\sin(\pi(a+b))} \end{equation} I think I've run out of space? The rest is easy trig. 

Arbitrary Zariski-dense subgroups in a semisimple group can be very small from a real-analytic point of view. It seems that algebra cannot distinguish between "small" and "large" Zariski-dense subgroups, so most criteria to distinguish between the two have a strong non-algebraic flavour. (Of course one can also characterize arithmetic groups algebraically, but this has even less to do with the line of argument you seem to suggest.) From a dynamical point of view, the key difference between lattices and arbitrary Zariski-dense subgroups is that the former act transitively on the product of the Furstenberg boundary of the ambient Lie group with itself ("double ergodicity"). This is a sort of "largeness" property. There are various ways to capture this property, the most systematic way seems to me the concept of a generalized Weyl group due to Bader and Furman. 

These types of questions are pretty speculative. One should be aware firstly that there is no reason for there to be roughly equal numbers of rank 2 curves and rank 3 curves. Mark Watkins has a paper where he comes up with a conjecture, using random matrix theory, that the number of rank 2 elliptic curves with conductor up to $X$ is asymptotically $c X^{19/24} (\log X)^{3/8}$. The paper is: Mark Watkins, Some heuristics about elliptic curves. Experiment. Math. 17 (2008), no. 1, 105–125. At the end of section 4 of the paper, he remarks that possibly there are around $X^{\frac{21-r}{24}}$ elliptic curves of rank $r$, for each $r \geq 2$, compared to around $X^{5/6}$ total elliptic curves. 

Here is a complete answer: Every semigroup $S$ of invertible $2\times 2$*-matrices which is transitive on* $\mathbb R^2$ is either conjugate to $SO_2(\mathbb R) \times \mathbb R^+$ or $SO_2(\mathbb R) \times \mathbb R$ or it is a product of $SL_2(\mathbb R)$ and a multiplicative subgroup of $\mathbb R$*.* Proof: Let S be such a semigroup. Then the intersection $S_0$ with $SL_2(\mathbb R)$ is a subsemigroup of $SL_2(\mathbb R)$. By a theorem of Hilgert and Hofmann (see their beautiful paper on "Old and new on $SL_2$") there are only three choices for $S_0$: Either $S_0$ is all of $SL_2(\mathbb R)$, a circle group or contained in a conjugate of the elements of $SL_2(\mathbb R)$ with only positive entries. If $S_0$ is a circle group, then $S$ will be conjugate to $SO_2(\mathbb R) \times \mathbb R^+$ or $SO_2(\mathbb R) \times \mathbb R$. If $S_0$ happens to be all of $SL_2(\mathbb R)$, then we have $SL_2(\mathbb R)\subset S \subset GL_2(\mathbb R)$, so $S$ is a product of $SL_2(\mathbb R)$ and a multiplicative subgroup of $\mathbb R$. In the third case, we may assume that $S_0$ is actually contained in the semigroup described above. Then $S_0$ maps every vector with two positive entries to a vector with two posiitve entries, hence $S$ maps the upper right quadrant to a subset of itself and the lower left quadrant. In particular, $S$ cannot be transitive. 

The problem with using Euler-Maclaurin is that $e^{2\pi i \tau x}$ is oscillatory. The remainder term in the Euler-Maclaurin formula will involve the integral of the absolute value of the derivative of the summand. The oscillation of $e^{2 \pi i \tau x}$ means that this derivative will be roughly the same size as the summand itself so the remainder term is not helpful (unless $x$ is going to zero in some sense). This is in contrast to the case with $x=0$ where each differentiation gives an extra saving factor of $(\tau +a)^{-1}$. 

I am surprised to see that so many people suggest meta-mathematical articles, which try to explain how one should do good mathematics in one or the other form. Personally, I usually find it a waste of time to read these, and there a few statements to which I agree so wholeheartedly as the one of Borel: "I feel that what mathematics needs least are pundits who issue prescriptions or guidelines for presumably less enlightened mortals." The mere idea that you can learn how to do mathematics (or in fact anything useful) from reading a HowTo seems extremely weird to me. I would rather read any classical math article, and there are plenty of them. The subject does not really matter, you can learn good mathematical thinking from each of them, and in my opinion much easier than from any of the above guideline articles. Just to be constructive, take for example (in alphabetical order) 

I think the definition you want for $\phi|(M,X)$ is $(\phi |_{k,m} M) |_m X$.So your left hand side involving $\phi |(M,X) | (M',X')$ is the composition of four of these operators. Then the problem isn't too bad given your (i)-(iii). 

I will give an alternative expression for $f(x,y,t)$ that may be helpful for others trying to solve this problem. Initially suppose $|x|, |y|< 1$, and $0 < t < 1$. Then $t^{mn} = \exp(-mn \log(1/t))$, and so by the Mellin formula for $e^{-x}$, we have $$t^{mn} = \frac{1}{2\pi i} \int_{(\sigma)} \Gamma(s) (mn \log(1/t))^{-s} ds,$$ where $\sigma > 0$. By a simple rearrangement, we have $$f(x,y,t) = -1 + \frac{1}{1-x} + \frac{1}{1-y} + \sum_{m=1}^{\infty} \sum_{n=1}^{\infty} x^m y^n t^{mn}.$$ The infinite double sum above can then be expressed as $$\frac{1}{2 \pi i} \int_{(\sigma)} \Gamma(s) (\log(1/t))^{-s} Li_s(x) Li_s(y) ds,$$ where $Li_s(z) = \sum_{n=1}^{\infty} x^n n^{-s}$ is the polylogarithm. I haven't thought much about if this integral representation can lead to a meromorphic continuation. The polylogarithm does have analytic continuation but the above integral may not converge absolutely if $|x| > 1$ or $|y| > 1$. 

I am not suggesting that any mathematician should read all of them, but any one of them will do. In fact, the actual content of these papers does not matter so much. It is rather, that they give an insight how a new idea is born. So, if you want to give birth to new ideas yourself, look at them, not at some guideline.