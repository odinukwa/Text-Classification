I think you are best served by taking a look at Andrew Carnie's Constituent Structure (link to OUP). The focus in his book is less on comparing tree diagrams across different theoretical frameworks, but rather on tracing the notion "constituency" within the generative framework associated with the work of Chomsky. Changes of the concept "constituency" have at times resulted in changes in tree diagramming. Carnie addresses other theories (such Lexical Functional Grammar, Dependency Grammar, categorial, functional, construction, and cognitive grammars) in chapter 9. 

The examples (1-9) are all in the nominative masculine because the example in the question is, too. Other inflections are, of course, possible, depending on genus and case. The property the examples (2), (5), and (8) share with the example in the question is that a noun fails to appear with the article. As a result, I would view the syntactic heads of the partitive genitive expressions still as articles. The plural of these construction is, by the way, also an article, namely einige. However, other articles are possible, too, such as viele, or wenige, or constructions such as ein paar. These expressions are articles. Response Tim Osborne interprets my answer (above) as invoking noun ellipsis. Doing so is his prerogative, but that doesn't make it true. In fact, I do not claim that such a form of ellipsis is involved, rather I state that "a noun fails to appear with" forms such as einer. The attempt to construe that as the advocacy of noun ellipsis is far-fetched. Tim Osborne seems to view his example (3b) as evidence for his position. While (3b) is indeed ungrammatical, there is a grammatical alternative that Tim Osborne fails to mention: 

Thus we are forced into the assumption of exocentricity. B. One could assume the pronominal variations are morphologically simple in form, but complex in meaning. That means one could assume that the word/part of speech class is simply P, rather than X-Infl, but that assumption would not hold for semantics. One would then have to assume to different sets of these expressions, for instance einem as an article and as a pronoun, marking non-feminine dative singular. Thereby one would violate Occam's Razor: Pluralitas non est ponenda sine necessitate, i.e. 'A plurality is not to be posited without necessity'. It seems more parsimonous to assume that articles enact pronominal functions whenever they appear in the absence of a superordinated noun, regardless of this absence being caused by noun ellipsis or not. 2.The adverb so can precede German articles, but it cannot precede pronouns. 

Example (2a), where the right-dislocated expression appears in the nominative is now ungrammatical. If the case of the right-dislocated expression matches, as in (2b), the sentence is good. What principle could account for this asymmetry? 

The distinction is between arguments (sometimes also called complements) and adjuncts. In general, arguments are expressions that complete a predicate, and that are required by the predicate. Adjuncts, on the other hand, are not required by the predicate, but they do add (usually temporal or locative) information. Here are some examples: 

I don't think that constituency is necessary, although I acknowledge the notion of "constituent" (I just don't think it's the central notion on which language structure is built). Of course, I have to admit that many linguists seem to view the constituent as an indispensable tool. My impression is that rather than questioning the necessity of constituency, its suitability in producing coherent and accurate answers to linguistic phenomena should be in the focus. (Since it's the prerogative of the questioner to formulate their question, my contribution here is not really an answer.) My personal doubt about constituency stems from a solid conviction that the notion incurs bracketing paradoxes across the whole grammatical spectrum. Be it displacement, ellipsis, periphrasis, or morphosyntactical phenomena such as multiple auxiliaries, one always needs additional assumptions (movement, merge, etc.) in order to account for the fact that stuff that should go together doesn't do so. Constituents simply don't seem to be the conceptional units along which language is structured. 

The structure in (a) must be correct, because only mu-, but not kankei (b), allows the appearance of attributive -na. By the way, be careful with the data there, that's not correct. Rather take a look at "Rickmeyer, Jens. 1995. Japanische Morphosyntax. Groos, Heidelberg". Returning to the meaning of o- and go-: naming them as honorifics is not entirely correct. They can appear in constructions meaning 1. respect, 2. modesty, 3. eulogy (美化語 'bikago' from 美化 'bika' = "euphemism"): 

Dependencies are not restricted to verbs and their dependents, rather they exist between all types of nodes. On a conventional understanding, the root is the one node that is not dominated by one of the other nodes. In your example, then noun shit is the root, because holy, the only other node available, does not dominate it. Dependencies are typed, i.e. subclassified. For instance, attributive adjectives, such as white in white horses, depend on their nouns. Hence holy should depend on shit. The Stanford Dependencies take this to be an amod (adjectival modifier) dependency. (The 2008 paper "Stanford typed dependencies manual" lists common dependencies from section 2 on). Meaning-Text-Theory (MTT) labels branches between nodes with syntactic functions. For an example see Wikipedia: Dependency grammar: Syntactic functions. The dependency between an adjective and a noun is called attr(ibutive) in MTT. 

To my knowledge there is no specific term for the example of people not being able to understand foreigners because they believe that foreigners cannot understand the language. It seems to me to be the combination of several psychological biases. The first that comes to mind is the expectation (or experimenter's) bias. It basically says that we experience what we expect to experience. Since we expect foreigners not to understand our language, we're closing off the possible experience of foreigners communicating in our language. We thus develop a psychological blind spot. The entire situation also requires that we make the (unconscious) decision to treat foreigners more alike than we would people we know. This is called a representativeness heuristic based on similarity. If a foreigner speaks our language better than we expected, and we can't block it out, then we can make things harder for the foreigner by speaking faster, use more slang, etc. The foreigner will find it harder to cope, and thus fulfill our expectation. We thus create the "reasons" to deal with our cognitive dissonance. Concerning pronunciation, it is established that there is a tendency of native speakers to infer more than they should from the less than perfect pronunciation of foreigners. Native speakers often conclude that the foreigners they talk to are less intelligent, less educated, and of a lesser social status than they really are, all the while forgetting that most of the times, the native speakers are mostly less capable of speaking the foreigners' language, than the foreigners are of speaking the native speakers' language. However, this tendency seems to be countered to a great degree by how diverse a society is. 

the question word Wem is governed by geholfen, rather than by hat. A government-based dependency grammar will then connect Wem and "geholfen*, which results in a non-projective structure because the dependency edge connecting Wem and geholfen will cross the projection edge of hat (and that of er). A number of dependency grammarians regard the limitation on government as too restrictive, and they view the apparent non-projective dependent node (Wem in the above example) as somehow displaced. My own take on this phenomenon can be found here. That paper also contains references to other authors within the dependency grammar framework. In a projective dependency grammar, such as the one I prefer, the depicted structure is not possible. Rather the nodes Piet and Marie would attach, i.e. be connected via a dependency edge, to the highest verb node, namely zag. Such a constellation is licit under the following condition: Rising A node A may be immediately dependent to another B, even though B doesn't govern A, if B dominates the node C, the governor of A. In my example, Wem = A, hat = B, and geholfen = C. Since B hat dominates geholfen, Wem may rise in order to connect to hat. There are a number of constructions that elicit rising, but they have different syntactic properties. [I'd also like to emphasize that I believe that the depicted tree structure is inaccurate even on a purely non-projective approach. Piet is governed by zag, in a specific construction that requires an infinitive verb, here helpen. Hence Piet is not a dependent of helpen. The same holds for Marie, which must be a dependent of helpen, rather than of lezen. In non-projective systems, semantics sometimes occludes the appropriate syntactic relationships.] The answer to the second question, i.e. "What would be appropriate edge labels?", must first decide on whether the apparatus is projective or non-projective. If it is non-projective, standard (i.e. government) labels are in order. In the Dutch example, Marie would be the indirect object of helpen, and Piet the direct object of zag (rather than the subject of helpen). A projective account can choose whether it wants the labels to reflect the actual dependency connections, or the underlying government relationships (which for the most part are identical; only in examples as the ones used here does a difference appear). Yet another aspect is whether the grammar is mono- or multistratal. If the grammar is multistratal, i.e. employs more than one level of description, then labels may be transferred from one level to the next higher one. Or such a grammar may choose to use different sets of labels depending on the strata it uses at a specific moment. If the depicted tree structure were correct (which it isn't as I argued above), the labels for all three nominals, i.e. Jan, Piet, and Marie, would have to be [subject], and obviously that cannot be true because the verbs helpen and lezen are infinitive forms, and infinitives cannot command subjects. I hope that helps a bit. 

Yes. It's called the "out-of-africa" theory. It's a paleoanthropological hypothesis with substantial support from genetics, in particular studies on mitochondrial DNA. Much work has been done by Luigi Luca Cavalli-Sforza and others. See his book Genes, Peoples, and Languages. The linguist Merritt Ruhlen is one of the most important linguists to test Cavalli-Sforza's hypothesis, see the Santa Fe Institute website. No. But language superfamilies remain a problem. All the links provided above are relevant. A further term is diversity (but try to google more, the Wikipedia section is not that illuminating), see also language families. 

kono et.al. lack the expression of specification usually ascribed to determiners. kono et.al. lack the expression of genus usually ascribed to determiners. kono et.al. lack the regularity, the obligatory occurrence, and the word order specifics usually ascribed to determiners. They also behave differently in noun ellipsis. 

No, Japanese would not use について because the verb to be used would be あきる, see also here. The reason is that あきる requires the object to be marked with the case particle -ni: 

As requested by user3898238 in his comment to mine, I try to provide an answer: The verb review is, wrongly, labeled as a subordinating conjunction for the possible reason that in English conjunctions precede the clause they head. Since a subordinating conjunction is absent, the program simply chooses the next available option, i.e. the initial word. My explanation for the program apparently seeing a subordinating structure, instead of a coordinating one, would be that the presence of the coordinating conjunction and forces a two-clause analysis. And many computer linguists (i.e. the people who build taggers, etc.) view coordination as akin to subordination (cf. the treatment of coordination in MTT). According to my personal experience, computer "linguists" make terrible linguists. 

-er a derivational suffix because it changes the word class to which the entire expression belongs. That is what defines derivational affixes. bake is a verb, but bak-er is a noun. (I assume the stem bak because the final letter e is not pronounced.) Productivity is not a sufficient criterion for the distinction of inflection and derivation. English uses zero-conversion, i.e. the possibility that one expression belongs to more than one word class, e.g. The dog wants to run, and a run. That means that one must take care when looking at the verb/noun distinction in English.