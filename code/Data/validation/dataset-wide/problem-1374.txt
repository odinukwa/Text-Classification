From what you posted, I cannot tell whether you're sanitizing the data before saving it to the database. Hopefully you're not just inserting strings you received from the client into your DB queries (this would expose you to SQL Injection attacks), but are instead using parameterized queries. How do you handle a query not returning any result? For instance when I look at , you call on your results without checking whether there is such a result. I'm not familiar with Laravel so maybe it handles this for you? Be sure to test how your script handles getting a non-existent resource. In your class, you create a new instance of every time a method is called. This is a waste because you will have a lot of parallel connections to your database that you never close and all those objects must be kept in memory. A better approach would be to instantiate a in the constructor of , assign it to a class variable, and use it for all DB queries. Then in the function of , disconnect from the DB. 

If one entity is modified, the changes are reflected wherever the entity is referenced. Also, changes are unambiguous: there are no "equal" entities around having old values. (You're probably getting read-only data, so this may not affect you). Ability to perform operations that are based on referential equality. For example, in your case, grouping s by will produce groups having 1 item, because the language object aren't equal (sure, can be evaded by using , but still, it's a gotcha). EF can perform relationship fixup when it loads entities: loading Resources and Languages separately into one context will auto-populate the navigation properties. Your code won't ever do that. 

is so leaky, I wouldn't even call it an abstraction. Let's look at what you encounter if you want to implement for, say, NHibernate. 

... assuming that simply s the entity to the context. Now EF will see and as new objects and (try to) insert them on . So how to assign the and values? You could do that in a very generic way that will solve this for any you add, not only copied ones, even removing the need of this constructor. It's by overriding in your subclass: 

By returning an array you can still get the first unique by applying [0] to the result and indicate no unique entry with an empty array. It also does not change your complexity: avg. n+k with k being the count for different values, but still 2n tops. 

However, bear in mind, that "super" is also a foreign concept to JavaScript. You cannot type foreign syntax and expect it to behave identically with comparable performance. Additionally, you may emulate "super" as shown above, but you will have to use with great care, meaning 'ParanormalStudent.super' and 'this.super' may point to the same function, however, the latter will result in exceeding the call stack. This seems to me like a bad practice, since as a programmer you will have a tool which may either work or produce chaos. 

If you want fullName to be truly private, you would have recreate Getters and Setters for each object. 

OLD ANSWER: Seems to me, the more optimal concept is to remove multiple occurences once you can. Given the worst-case scenario, that the unique element is at the ende of the array, filter and find would have to loop over all elements. Then, if indexOf and lastIndexOf are supposed to be O(n), you would be stuck with O(n^2) 

To prevent these errors you'd want to ensure that whenever is to be executed is eagerly loaded (using ). Two options: 

Note that doesn't return but . This opens the opportunity to compose a LINQ statement involving multiple repositories and still translate the whole statement into one SQL statement. For example, if you need an occasional (because there is no navigation property), it would look like: 

... you would pull all records from the database before the actual join is made. By returning , this would turn into a SQL query containing a and (obviously) far less traffic. 

In short, this would mean that each step in a workflow would be represented by a service method. The UI just issues commands and reads results. It doesn't contain any business logic whatsoever. 

As a loose definition, repositories are supposed to expose the database tables as collection-like interfaces to the application code. So it's expected for them to have , , and methods. But what's the use of a method like ? Remember that consumers of the repo only see the outside. They'll wonder "am I going to insert a context? And into what?" This is bad, but the really bad thing is that the method has vastly unexpected side effects: it replaces the context's by . How can consumers even begin to expect that to happen? Together with the first point above I don't understand anything of these methods receiving as a parameter. No composability. OK, now if the above points wouldn't exist, you'd be left with a pretty regular repository. The only problem would then be that you can't use it to compose queries efficiently, because the "get" methods return , not . Take this example: 

Hint: If you find yourself doing something over and over and over, you probably need a loop. Since this is a login form and that you expect just 1 variable besides the password, don't have so many vars in your script: , , , , , , ... just use . If you really need to cycle through all possibilities build an array and loop until you find the one the user submitted: 

You're still vulnerable to SQL Injection. Take another look at . This function receives the parameter, sends its contents to the server which in turn puts it straight into an SQL query as the cat IDs: 

When your user comes to my evil site and I try to connect to , the browser will still send the cookie but it will not send the CSRF token, so before you grant access you would check for it: 

You are executing DB queries in a loop: . This means that for 4,000 urls, you will query the DB 4,000 times (assuming no unrecoverable error). This is expensive and will slow your script down considerably and lead to a lot of overhead. You're better off building and storing all the commands you will want to execute in an array. Once you've finished your cURL operations, the array into one big operations (look up how to insert multiple records with one query). The docs for mysql_query show that the default behavior is to store results in memory. I suspect that because you make so many queries without closing the connection, your memory is filling up (I'm unsure though since almost all your queries are rather than ). I suggest you change that behavior by passing a as the 3rd argument. This means that after you've processed the result with your script you must execute before making the next query. This has less to do with performance and more with maintainability and scalability; consider breaking out the functionality into several single purpose functions: could return your array, could make the cURL requests and add to the , and arrays (notice I passed them by reference). You would iterate over that function, re-inserting the again urls at the back of the line until you have processed all urls into just and array. Next, would implode all results into one big operation and a single request to the DB 

If returns you'll see that the s and s (all s) will be fetched into memory by two queries. Also, the is executed in memory, not translated into SQL. With , the whole statement is translated into SQL, making it far more efficient. (Assuming, of course, that both repos receive the same context instance). Finally There's always much discussion about the use of generic repo/UoW on top of EF's / that implement the same patterns. I wouldn't use them just because it's a "good pattern". In most cases they're only a thin wrapper around the EF objects. Maybe you have to reevaluate this. 

I don't understand why repositories insert, update and delete themselves. For example in the method, you have: 

You evidently want to clone mapped and scalar properties only. Your approach works (if you remember the error sources), but I'd prefer to use a method provided by EF itself: 

You may succeed in implementing the interface methods in a way that they display the same behavior as . This is hard enough. is far from trivial. affects an entire object graph. In fact, all methods affecting an entity's tracking state have nitty-gritty details when it comes to the adhered object graph. If you don't respect these details, saving will behave differently. If forces you to use LINQ-to-NHibernate. This in itself inevitably introduces differences. Both types of LINQ have their own set of supported methods. Both have their own bugs, or run-time issues (like generated queries that perform poorly). NHibernate has other powerful query APIs that you can't benefit from, at least not fully. NHibernate's workflow resembles that of EF. But there are important differences. For example NHibernate's auto flush (auto commit) feature. The standard implementation if , , has other important methods that are not part of the interface. For example, . An NHibernate implementation should also implement these to be even remotely interchangeable (which it never will be). 

Likewise when you're saving data that you want cached, cache it after you've successfully saved to the DB. I've been using Memcache as my PHP cache driver with no problem, but Memcached may be even more feature rich. Because I have a class as I described above, it wouldn't be too hard to switch. The rest of my scripts don't care because they interact with my class, never directly with the cache driver. 

At the start of each function, I set to null. If there is an error, I fill with the details. So the consuming code can check this variable after executing a query to check for errors: 

Then you can attempt to create the token with those credentials. Beware I've never used Laravel, but I wrote my answer after going over this helpful page on how to access requests. Quick sidenote: I notice that you have a check that can be true only if email has length < 6, and another that can be true only if email has length > 6. What if email has length===6 ? 

(1) Any opinion about this? Emulating language features/idioms which are not supported by the language itself (e.g. classes in JavaScript) does not seem to be a very good idea to me. JavaScript is not an classical OOP-Language (yet), but there are Prototypes: 

(2) Is this fast? Emulation is probably slower than using native methods - i suppose. However, it depends on the underlying engine. V8 is faster than Gecko. (3) What about correctness? Depends on how you understand correctness. JavaScript is powerful enough to emulate classical inheritance to some extend. (4) FYI If you want a more Java-like access to the parent-prototype with "super"-sugar, you can do something like this: 

(1) Usage of prototypes "from my understanding, prototype should be used when the particular behaviour/property is shared with all objects" Yes, this is more or less correct. Functions on prototype are shared with all objects, which inherit it. They are not recreated, but simpyl executed within a different context (this) for each object. However, it depends on your design, if this is desirable. For instance the Getters and Setters in your case can syimply be by-passed: 

By the way, this logic should be moved to a function that returns TRUE if the user is logged in, false otherwise. You can extend it with further checks. For instance you could record the IP address to which the session was granted, and if it doesn't match the IP of the request, deny access (to protect against an attacker stealing the session and CSRF token and trying to re-use it from another location). In login.php you have: 

You probably shouldn't be doing the work in this script. I'd have a or class that does nothing except receive the request, figure out what it's about and forward it to the appropriate service. I'd have one service for each task: add to conversation, send survey, unsubscribe... Because email addresses are case insensitive, I would make sure that all checks are case insensitive. 

There is a logic error here. Remember that the is evaluated at the end of the loop. So on first pass which means and are undefined. Change to This may not matter to your requirements since you use only with flattened arrays above, but it will return a false negative if you use it with arrays that contain non immutable members. Eg: 

This way, you have only n iterations for the first application of remove. Then you reduce the size of the remaining array to at least n-2 for the next recurrence, depending on the distribution of multiple occurences. This should sum up to O(n log n), but i'm not sure when it comes to the exact math. This solution might be worse space-compexity-wise. 

The proposed solution by the questioner is the fastest, 2n tops if i'm correct, so O(n). But error handling is problematic, consider the input [2,3,3,2,-1]. Is -1 the correct result or does it indicate an error? Maybe, instead of returning only the first unique element, just return all unique elements 

(2) Usage of undefined If your requirements state, it has to be undefined, then make it undefined. But whether that's useful, depends on the use-case. I would go with neutral elements of the desired type for each property. (3) Usage of this Also correct, this is the common usage of this. PS: Also bear in mind, this approach tries to emulate classes. However, JavaScript has no real concept of classes. Emulating foreign language features is not necessarily a good idea. $URL$