These videos are fun: $URL$ Although they do not explain what the proof is but they show some wonderful mathmatical ideas: Arnold's rouble problem, polyhedra, etc... Lots of interesting mechanisms too. I have seen children watch these movies, they get really excited. 

The answer to my question (provided by BS) is the following: We have to change the action by looking at the group $G=U(n, \mathbb{C})$ and its action by conjugacy on pairs of Hermitian matrices. The space of pairs of such matrices can be identified with $T^* (Lie U(n, \mathbb{C})^*)$ because $Lie U(n, \mathbb{C})$ consists of antihermitian matrices (so we should only divide by $i$ to obtain Hermitian matrices). The coadjoint orbit is an orbit of a matrix with ones everywhere except for the diagonal (where it has zeroes). Its orbit is all Hermitian matrices $T$ such that $rk (T+\mathrm{Id})=1$. Moment map is $J(X,Y)=-i[X,Y]$. This subtle change in moment map will permit us to change the entries in $Y$ matrix. And then a representative of each element in the orbit can be chosen in a form $(X,Y)$ where $X$ is a diagonal matrix and $Y_{j k }= \frac{i}{x_j-x_k}$. So the idea of AHusain to multiply by $i$ was a good one -- but one has to change the action... Note that this proof (for $H$) is quite the same as a proof for the potential $H^-$: it is related to the fact that they both come from the group $SL(n, \mathbb{C})$:this group has (among others) two real parts: $SL(n, \mathbb{R})$ and $SU(n, \mathbb{R})$. The first part corresponds to $H^-$ and the second to $H^+=H$. 

PS. I hope that this post could become a collection of the facts "known-by-now" on Zoll surfaces. I'm just getting lost in the abundance of information on the subject which is badly gathered. And I'm sorry that I do not have any picture in the post with the word "draw" in the subject. 

The answer is no. Here's an example --- which is based on an example I gave in my multivariable calculus discussion section recently!! :-) Let M be (0,pi) with coordinate t. Let N be R^2 with coordinates x and y. Define a map x(t)=sin(t), y(t)=sin(t) for t in (0,pi/2] and x(t)=2-cos(t-pi/2), y(t)=2-cos(t-pi/2) for t in (pi/2,pi). This map is smooth and injective on points but the derivative is zero at t=pi/2. Edit: Ok, I got a bit too excited about using multivariable calculus. As algori mentions, t^3 is a simpler example. Or just taking one of the coordinate functions in my original example works too. There's no need for multivariable calculus. 

See Atiyah-Bott, "Yang-Mills Equations over Riemann Surfaces" for the case of stable holomorphic vector bundles. See in particular section 9 and Theorem 9.11. They compute the Betti numbers of $N(n,k)$, the moduli space of stable holomorphic vector bundles of rank $n$ and first Chern class $k$, when $n$ and $k$ are relatively prime. They also find generators for the cohomology ring. These "Atiyah-Bott generators" are the KÃ¼nneth components of the Chern classes of the universal bundle. In this paper they don't compute the relations for these generators. The main tool in this paper is Morse theory. I think the reason for restricting to stable bundles is to get a moduli space (rather than some kind of stack or whatever). The reason for fixing the first Chern class is just because different Chern classes correspond to different connected components. I think the reason for the condition that $n$ and $k$ are relatively prime is just to ensure that the moduli space is a smooth manifold. Since these moduli spaces are also algebraic varieties, one can also compute their Betti numbers using the machinery of the Weil conjectures... There are some comments about this, as well as references, in the introduction of the paper and in section 11. EDIT: I just did a Google search and found this paper of Heinloth and Schmitt, which claims to compute the cohomology ring of the entire moduli stack: $URL$ This paper says that the Atiyah-Bott generators are in fact free generators... 

One of the ways of defining naturally a metric on the tangent bundle $TM$ is indeed (as Peter says above) a Sasaki metric defined in 1968. You can prove that $(TM, g_{\mathrm{Sas}})$ is flat if and only if $(M,g)$ is flat. The reference is for example the paper by Sigmundur Gudmundsson and Elias Kappos On the Geometry of Tangent Bundles. They give explicit calculations for Levi-Civita connection for this metric as well as curvature tensor. 

I will probably say a banal thing but the interesting degree of regularity depends on the problem you consider. In the theory of foliations, the foliations themselves are usually considered smooth although the transversal behaviour an be rather bad. In some theories the degree of regularity is already fixed but in most of the theories it really depends on the question. As a remark, I propose a problem that I find nice and for which I do not know the asnwer. Consider the map of the circle for which there exists an orbit which consists of all rational numbers. What degree of smoothness can this map have? 

I am not sure I can strictly define recreational mathematics. But we all feel what it is about: puzzles, problems you can ask your mathematical friends, problems that will bother them for a couple of hours, and then they will get them (or not?). Problems to distract yourself from research. Sometimes, however, these problems lead to some ideas and concepts connected to "serious mathematics". I adore this kind of problems and, with holidays approaching, I let myself surf on Internet for some new problems to distract myself a little near the Christmas tree. I usually look at some blogs but my search is very chaotic. I'll try to formulate more precisely what kind of problems I'm searching for: there are two kinds of them. First, good mathematical problems. So good that you can talk about the solution for an hour although the formulation could be really easy. Example: the old Arnold's question about the perimeter of a banknote. By folding up a banknote, we decrease the area of the polytope obtained. But can we increase the perimeter? The answer is yes, and we can increase it as much as we want. The proof is beautiful and doesn't need any knowledge of higher mathematics although it is not at all trivial. Second, problems giving some publicity for higher mathematics. I will give an example - hat puzzle. A sultan decides to give a test to his sages (a countable number of sages actually!). He has the sages stand in a line, one behind the other, so that the person in a line sees everybody before himself. Yes, the sages are clever but also they have a very good vision. He puts the hats on them: white or black. Then, the sages cry (all at one time) the color that they think they are wearing. Everybody who is wrong will be killed. The question is, can the sages achieve the result that only the finite number of them will be killed? I won't spoil you the pleasure giving the answer but this puzzle in some sort opens a path to some serious mathematics and can be a good pretext to explain it on the seminar for high-school student (or even to undergraduate). I search for problems that are easy to formulate and not trivial to solve, and that could give a nice pretext to talk about them for a couple of hours for undegraduates. In other words, I search for problems that could make a good advertisement of "serious" mathematics for high-school students that love puzzles. My question is -- are there any journals (I think, Mathematical Intelligencer can be one of the possible answers..) that publish some kind of research articles on the subject? Maybe some blogs I do not know? Any links or suggestions will be welcomed. 

After some work, I have come up with the following answer. In the general case, the following holds for any two multivariate normal densities: \begin{array}{rcl} f(\mathbf{x}|\mathbf{0},\mathbf{\Sigma}_{1}) & \geq & f(\mathbf{x}|\mathbf{0},\mathbf{\Sigma}_{2}) \\ &\Updownarrow & \\ -\frac{1}{2} x^{T} \mathbf{P}_{1}x + \frac{1}{2} log [|\mathbf{P}_{1}|] & \geq & -\frac{1}{2} x^{T} \mathbf{P}_{2}x + \frac{1}{2} log [|\mathbf{P}_{2}|] \\ & \Updownarrow & \\ x^{T}[ \mathbf{P}_{1}-\mathbf{P}_{2} ]x & \leq & log [|\mathbf{P}_{1}|] - log [|\mathbf{P}_{2}|] \end{array} The set $A:=\{x| f(x|\mathbf{0},\mathbf{\Sigma_{1}})\geq f(x|\mathbf{0},\mathbf{\Sigma}_{2})\}$ is a compact and convex set if $\mathbf{P}_{1}-\mathbf{P}_{2}$ is a positive definite matrix as in special cases (i). Moreover, if $\mathbf{P}_{1} = k \times \mathbf{P}_{2}$ for $k>1$ then $ \begin{array}{rcl} f(x|\mathbf{0},\mathbf{\Sigma}_{1}) & \geq & f(x|\mathbf{0},\mathbf{\Sigma}_{2}) \\ &\Updownarrow & \\ x^{T} \mathbf{P}_{1} x & \leq & \frac{k}{k-1} n \times log [k ] \\ &\Updownarrow & \\ x^{T} \mathbf{P}_{2} x & \leq & \frac{1}{k-1} n \times log [k ]. \end{array} $ In A Generalized Error Function in n-dimensions, M. Brown defines an n-dimensional generalized error function $erf_{n}(.): \mathbf{R}_{+} \rightarrow \mathbf{R}$ by $ erf_{n}(x) = \frac{\int_{0}^{x} e^{-u^{2}} u^{n-1} d u }{\int_{0}^{\infty} e^{-u^{2}} u^{n-1} d u} $ Equation [47] in the paper concerns diagonal variance-covariance matrices and states that $Prob[\sum_{i=1}^{n} \frac{x_{i}^{2}}{\sigma_{i}^{2}} \leq \beta^{2}] = erf_{n}(\frac{\beta}{\sqrt{2}}). $ If this equations extends to the general case so that $ Prob[ x^{T} \Sigma^{-1} x \leq \beta^{2}] = erf_{n}(\frac{\beta}{\sqrt{2}}) $ then the total variation distance under special case (ii) can be expressed as $\begin{array}{rcl} ||f(.|\mathbf{0},\mathbf{\Sigma}_{1}) - f(.|\mathbf{0},\mathbf{\Sigma}_{2})||_{TV} & = & erf_{n}(\frac{\sqrt{ \frac{k}{k-1} n \times \ln [k ]}}{\sqrt{2}}) - erf_{n}(\frac{\sqrt{ \frac{1}{k-1} n \times \ln [k ] }}{\sqrt{2}}). \end{array} $ As per the Brown paper, the error function is given specifically by $ erf_{2m}(x) = 1 -e^{-x^{2}}[1 + \frac{x^{2}}{1!} +\frac{x^{4}}{2!} + \ldots+\frac{x^{2(m-1)}}{(m-1)!}] $ if $n$ is of even dimensions and by $erf_{2m+1}(x) = erf_{1}(x) -\frac{e^{-x^{2}}}{\sqrt{\pi}}[\frac{(2x)0!}{1!} + \frac{(2x)^{3}1!}{3!} + \ldots+\frac{(2x)^{2m-1}(m-1)!}{(2m-1)!}] $ if $n$ is of odd dimension. Considering the one-dimensional case and letting $k=(1+\epsilon)^{2}$, we get $ \begin{array}{rcl} ||f(.|\mathbf{0},\mathbf{\Sigma}_{1}) - f(.|\mathbf{0},\mathbf{\Sigma}_{2})||_{TV} & = & erf_{1}(\frac{\sqrt{ \frac{k}{k-1} \times \ln [k ]}}{\sqrt{2}}) - erf_{1}(\frac{\sqrt{ \frac{1}{k-1} \times \ln [k ] }}{\sqrt{2}}) \\ & = & erf_{1}(\frac{\sqrt{ \frac{(1+\epsilon)^{2}}{(1+\epsilon)^{2}-1} \times \ln [(1+\epsilon)^{2} ]}}{\sqrt{2}}) \\ & & - erf_{1}(\frac{\sqrt{ \frac{1}{(1+\epsilon)^{2}-1} \times \ln [(1+\epsilon)^{2} ] }}{\sqrt{2}}) \\ & = & erf_{1}(\frac{(1+\epsilon) \sqrt{ \frac{1}{\epsilon(2+\epsilon)} \times 2\times \ln [(1+\epsilon) ]}}{\sqrt{2}}) \\ & & - erf_{1}(\frac{\sqrt{ \frac{1}{\epsilon(2+\epsilon)} \times 2 \times \ln [(1+\epsilon) ] }}{\sqrt{2}}) \\ & = & erf_{1}(\frac{(1+\epsilon) \sqrt{ \ln (1+\epsilon) }}{\sqrt{\epsilon(2+\epsilon)}}) \\ & & - erf_{1}(\frac{ \sqrt{ \ln (1+\epsilon) }}{\sqrt{\epsilon(2+\epsilon)}}) \end{array} $ which corresponds to one of the answers to a univariate version of this question. The above can be partially extended to all of special case (i) to provide a bound on the total variation distance in terms of error functions. Define a function $g_{1}(.): A \rightarrow \mathbf{R}_{+}$ by $g_{1}(x)=x^{T}P_{1}x$. Let $b_{1} =\max_{x\in A} g_{1}(x)$. Since $A$ is a compact convex set and the function $g(.)$ is continous, this maximum is well defined under the present assumptions. We we can hence define a set $A_{1}^{*}:=\{x \in \mathbf{R}^{n}| x^{T}P_{1} x \leq b_{1}\}$. Clearly, $A \subseteq A_{1}^{*}$. Similarly, define a function $g_{2}(.): A \rightarrow \mathbf{R}_{+}$ by $g_{2}(x)=x^{T}P_{2}x$ and define a parameterized family of sets $A_{2}(.) : g_{2}(A) \rightarrow \mathbf{R}_{+}^{n}$ by $A_{2}(b)=\{x \in \mathbf{R}^{n}| x^{T}P_{2} x \leq b\}$. Let $A_{2}^{*}= \{x \in A|A_{2}(g_{2}(x)) \subseteq A)\}$ and $b_{2}=\max_{x\in A_{2}^{*}} g_{2}(x)$. This maximum exists under the present assumptions since the set $A_{2}^{*}$ can be shown to the non-empty, convex, and compact. Clearly, $A_{2}^{*} \subseteq A$. We can now provide a bound for the total variation distance in terms of error functions that generalizes the expressions for the total variation in special case (ii): $ \begin{array}{rcl} ||f(.|\mathbf{0},\mathbf{\Sigma}_{1}) - f(.|\mathbf{0},\mathbf{\Sigma}_{2})||_{TV} & = & \int_{x \in A} f(x|\mathbf{0},\mathbf{\Sigma}_{1}) dx -\int_{x \in A} f(x|\mathbf{0},\mathbf{\Sigma}_{2}) dx \\ & \leq & \int_{x \in A_{1}^{*}} f(x|\mathbf{0},\mathbf{\Sigma}_{1}) dx -\int_{x \in A_{2}^{*}} f(x|\mathbf{0},\mathbf{\Sigma}_{2}) dx \\ & = & erf_{n}(\frac{\sqrt{ b_{1}}}{\sqrt{2}}) - erf_{n}(\frac{\sqrt{b_{2} }}{\sqrt{2}}). \end{array} $ In special case (ii), $b_{1}=\frac{k}{k-1} n \times \ln [k]$ and $b_{2}=\frac{1}{k-1} n \times \ln [k]$. While not generally available in closed form solution, increasingly good estimates for $b_{1}$ and $b_{2}$ can be generated through repeated simulation from centered multivariate normal densities with precision matrices $P_{1}-P_{2}$. To generate estimates for $b_{1}$ and $b_{2}$, let $B=\{x^{(i)}\}_{i=1}^{L}$ be a set of (non-zero) random draws from a mean centered multivariate normal with precision matrix $P_{1}-P_{2}$. For each $x^{(i)} \in B$, define $\begin{array}{rcccccl} t(x^{(i)}) &= & \sqrt{\frac{log [|\mathbf{P}_{1}|] - log [|\mathbf{P}_{2}|]}{(x^{(i)})^{T}[ \mathbf{P}_{1}-\mathbf{P}_{2} ]x^{(i)} }} & , & \tilde{x}(x^{(i)}) & = & t(x^{(i)}) \times x^{(i)} \\ \tilde{b}_{1}(x^{(i)}) &= & ( \tilde{x}(x^{(i)}))^{T} P_{1}\tilde{x}(x^{(i)}) & , & \tilde{b}_{2}(x^{(i)}) & = & ( \tilde{x}(x^{(i)}))^{T} P_{2}\tilde{x}(x^{(i)}) \end{array}$ and estimate $b_{1}$ and $b_{2}$ by $\hat{b}_{1} = \max_{x^{(i)} \in B}\tilde{b}_{1}(x^{(i)})$ and $\hat{b}_{2} = \min_{x^{(i)} \in B} \tilde{b}_{2}(x^{(i)}) $ respectively. As the number of draws from the multivariate normal density increase, $E[\hat{b}_{1}] \rightarrow b_{1}$ and $E[\hat{b}_{2}] \rightarrow b_{2}$ where the former convergence is from the below and the latter from above. 

Edit: I see that this topic has been closed. I agree that it is perhaps too philosophical for Math Overflow. But still, let me make a few more mathematical comments, and one philosophical comment. Consider the lambda calculus. This is a very simple model of computation; its functionality is essentially restricted to a notion of a function and a notion of evaluation of functions which allows for recursion. The interesting thing is that even with this seemingly very limited functionality, the lambda calculus is still Turing-equivalent. What this shows is that it is relatively easy for a "reasonable model of computation" to be at least as powerful as Turing machines; once it has a notion of functions and a notion of evaluation of functions, it will be at least as powerful as the lambda calculus, and thus Turing machines. The more philosophical question arises when we consider the converse situation, namely, why should we expect "reasonable models of computation" to not be strictly more powerful than Turing machines? There is (probably) no good mathematical answer to this, because there is (probably) no good mathematical definition of "reasonable". 

The Mumford conjecture states that for each integer $n$, we have: the map $\mathbb{Q}[x_1,x_2,\dots] \to H^\ast(M_g ; \mathbb{Q})$ sending $x_i$ to the kappa class $\kappa_i$, is an isomorphism in degrees less than $n$, for sufficiently large $g$. Here $M_g$ denotes the moduli of genus $g$ curves, and the degree of $x_i$ is the degree of the kappa class $\kappa_i$. This conjecture was proved by Madsen-Weiss a few years ago. 

Morse theory is another good example. Indeed it is the inspiration for Floer theory, which has already been mentioned. Atiyah-Bott's paper "Yang-Mills equations on a Riemann surface" and Hitchin's paper "Self-duality equations on a Riemann surface" both contain rather striking applications of Morse theory. The former paper contains for example many computations about cohomology rings of moduli spaces of holomorphic vector bundles over Riemann surfaces; the latter paper proves for instance that moduli spaces of Higgs bundles over Riemann surfaces are hyperkÃ¤hler. Note that these moduli spaces are algebraic varieties and can be (and are) studied purely from the viewpoint of algebraic geometry. But if we look at things from an analytic point of view, and we realize these moduli spaces as quotients of infinite dimensional spaces by infinite dimensional groups, and we use the tools of analysis and Morse theory, as well as ideas from physics(!!!), then we can discover perhaps more about these spaces than if we viewed them just algebraically, as simply being algebraic varieties.