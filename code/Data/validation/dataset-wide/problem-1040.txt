is not enabled by default. Normally, it should be enabled by placing in . But it does not work for all installations. In my experience, it worked for Debian 7, but not Debian 7 minimal, though both installations come from the same precompiled deb package. Both on OpenVZ VPS. How to debug why does not work for an installation, and how to safely activate ? 

I have a simple but big table (tens of millions of rows). The performance is quite good except when I need to order the table by the column with format . A simple query to fetch the last 10 updated rows takes tens of seconds. Is there a trick to order big table in a fast way? 

is a big table, and I want to make the only if has found something. In other words, I do not want to make the for . 

I want to concatenate the objects if the sum of frequencies reach a value. Currently I am doing this in as 

I want to assign folder number to rows but limiting the number of items in each folder (e.g. 100). Thus, increasing the folder number (next folder) if . The d folder should look like 

Here we have created a useless column, not to collect the data, but to repeat the for the . Obviously, it is not good from performance point of view, as we are running a useless action. 

Is it possible to do this with a native query of mysql instead of bringing the data into PHP and returning back to mysql? Since the process is simple, I think mysql has enough functions to do so, but I do not know how to do so. In fact, I want to group concatenate the entire column and split it when reaches the given value (i.e. 20). This needs a loop of s in which the reset to 0 upon reaching 20. UPDATE: The process with do as: table1: 

I want to search for the occurrence of each country in the column. I use multiple subqueries to do so 

It might be a naive question, but what is the difference of these two queries and which is preferred? 

In the following example, the is assumed the primary key, but obviously other orders or even clause can be added. My question is about comparison in performance of or a simple sub-query`. 

In an application, I am using 's . Since this application does not need permanent tables, I wonder if I can find an alternative RDMS designed for memory tables. I hope to find an in-memory database system, which is 

Is it still bad to use when we want to read the entire row, or even 90% of it? Isn't it benefitial when we read the whole row? In normal condition, the server needs to look for each cells in in order of the . But in , it simply reads in order of columns? The later should be easier and faster! 

The slow performance for using in large table has been widely discussed in various blogs, and the most efficient way is to use an as 

I need to build a table accepting one row for each minute. If I set the type of primary key to , 60 records can be added for each minute. Is there any trick to design a table to keep unique? 

as I want to update another table with these values, and with this row structure, I can update the country table row by row as I get from the above query. 

I have a few column with . In some queries, duplicates should be acceptable, in which a postfix should be added to the value. For example, if exits, we change it to . Is there a way to make a unique value upon ? 

There are many articles exaggerating (IMHO of course) the need for . I understand that with , there should be a better control over the individual tables; like backup each table separately. However, the claim for better performance is questionable. In my test, there is no difference in performance of and for a database of 60GB. Of course, it was a simple test with normal queries, and the situation can be different for complicated queries in real life (this is the reason that I asked this question). 64-bit linux with can effectively handle large files. With , more disk I/O operations are needed; and this is significant in complicated s and constraints. Tablespace is shared on single ; how dedicated tablespaces for separate tables can save disk space? Of course, it is easier to free table space for each table with , but it is still an expensive process (with table lock). QUESTION: Does has an effect on a better performance of mysql? If yes, why? 

This just a simple example with no significant difference, but when having heavy calculations, which one is preferred? 

Now I need to 1. fetch each sentence into PHP, 2. then split the string to words, 3. then catch the score for each word, 4. then calculate the sum of word_scores Is it possible to calculate the sentence score within mysql? 

each row includes the first value of and for each unique value of . How to select and for each value of . something like 

Since, make the calculation for the entire column, apparently, I need to reset the value/process of after reaching the maximum item in folder. 

is a many-to-many relationship between tables and . In this query, mysql will find all posts tagged by any of these words, and order them by PRIMARY KEY. How can we order the results by tag weight: 

Sorry, if my question is naive, but it has puzzled me, and cannot benchmark the performance. I want to use the newly introduced feature of innoDB for FULLTEXT index. I wonder what is the difference of 

For dropping a table in which a is used in other tables, it is necessary to drop all other tables having connection with the corresponding table. Is there a short way to drop a table, and its all child tables (in which they have to the parent table)? For example, 

and no special features is needed, just creating table and performing SQL queries. or other advanced features are not needed. 

is the in table1 and in table2. How to remove the clause to update each row of table1 by counting the number of rows in table2 with the same id? 

posts witch tagged with more words in the list (first posts with three tags from the list, then with two words, ...) posts witch tagged with first words (first posts tagged with tag1 then posts tagged with tag2). 

I want to SELECT or UPDATE to remove a row if the first or last (with id order) is (a given value). In other words, I want to skip the first and last row of a category IF . I cannot use as it is a table. 

and id is a in 5 child tables. Is it possible to drop TABLE , and force drop of all 5 child tables having ? instead of dropping child tables one by one? 

How to give a priority to get only one of the clauses? I mean getting rows with . Only if there is no row, get row with . In other words, do not use if there is a row for . 

How can I reduce the number of subqueries, and count all values in one subquery, then updating all columns? 

I have scheduled heavy queries at administrator level, and since they are heavy s with multiple s, consume a huge amount of resources. I do not want them to stop end users from basic tasks when performing such heavy tasks. Is for this purpose? or I should follow another strategy? 

Since external_id-number couple is unique, it will not update if the new value of number exists. How can I use something like to increase the value of by to reach an available value according to the UNIQUE Constraint and complete the task? 

I use to get the list of each , but I want to separate the concatenated column to multiple columns categorized by the column . It should be something like 

The easiest and straightforward method is to use sub-query (), but my concern is the performance, as this process should be conducted for a very long table and regularly (new data coming). Is there an efficient way to normalize this table with high speed? 

Now I want to introduce to my database instead of running the second query. Two for each column: one DELETE and one INSERT. Then, I will have 30 - 40 !!! Benchmarks show that using is about 50% faster than executing a second query. Apparently, it is reasonable to use the modern features of mysql. However, the reason that I am asking this question is that many programmers are strongly against , as it makes coding vague. Moreover, adding lots of may make messy. Am I on the right track? 

Every time reaching the value of in , I want to SET the and after that reset the to 0. In other words, I want to count the rows before the occurrence of rows ending to . EXAMPLE I want to as follows. In the above-mentioned query, rows for is simply for all . 

In a project, we need to frequently the tables to delete or add columns. I wonder if this weakens the database performance in long term. If it has a considerable negative impact, what is the approach to keep the database healthy and efficient? I was thinking of the following approaches: 

How can I two tables to have the month value (Value1 from table1) for each row of table2? The desirable result 

How can I run a query to sum the votes for each answer to get results for the list of answers in the poll? 

I use table for calculation of temporary data, but tables in has a big limitation, which made it useless for me. A table cannot be re-opened in a query. This mean I cannot the table with itself, and add sub-query. It is almost impossible to process data without and . Thus, I must give up table. A possible alternative is to create and delete a permanent table on each script run. However, I think it is not good from database administration point of view to and tables. Is there any practical alternative to tables with possibility of re-opening the table? 

Since, it is a temporary table, I cannot use . How can I from this table to have pairs of key/value in each row? 

How we can change two variables in one condition. For example, consider that when , we want to change not only , but also re-assign . In fact, regardless of the condition 2, we want to increase , if the first condition fails (the second part). Is it possible to re-assign two user-variable in a or we need to add another ? This will be equivalent to 

Is there a way to do this in one query? EDIT: The output should be the cells and the number of rows. In fact, after selecting the cells, it should walk over the table to count only. I know that it is not possible to merge these two queries, as the first return 1 row, but the second X rows. I am curious if there is a function in mysql to return the number of rows in the presence of . 

For each count, mysql needs to walk thoughout the table, and this is a big problem if having long table and numerous queries. I wonder if there is a way to make all counts in one query. In this case, when mysql walks over each row, it will process all counts, and no need to scanning the entire table over and over again. 

I need heavy arithmetic and string functions for processing the data captured from database. Which is preferred: functions or programming language (e.g., )? 

I want to SELECT rows in which there are duplicates against . For the example table, SELECT query should return 

but this does not work. I cannot the tables, as the is complicated to perform from different tables. 

I have many so-called summary columns throughout my database to count number of rows in other tables. For example, counting the number of comments by a user (a column in the user table). Currently, I update this column by an extra query: 

I have a global database, as I all users should have access to it. Is it possible to grant permission on a database to all users? something like 

I want to catch X rows, thus, I set ; but how can I simultaneously count the total number of rows too? Currently, I use two separate queries to do so as