SQL Server asks for a root snapshot folder path when you Configured Publishing and Distribution. After configuring publishing and distribution, all subsequent publications created will use that snapshot folder but will have their own sub-folder within that folder. If you wish to have your snapshot files for a particular publication be put into a different root snapshot folder, specify this by passing in the path to the @alt_snapshot_folder parameter of sp_addpublication or sp_addmergepublication when you create the publication. Alternatively, this can be done from the Publication Properties dialog after you have created your publication and before generating a snapshot on the Snapshot page, Location of snapshot files section, Put files in the following folder. 

The reason the round trip is not occurring is because your subscription from Server B to Server A has its @loopback_detection property set to TRUE, which is the default setting. As we can see from sp_addsubscription, @loopback_detection specifies if the Distribution Agent sends transactions that originated at the Subscriber back to the Subscriber. If set to true, the Distribution Agent does not send transactions that originated at the Subscriber back to the Subscriber. If set to false, the Distribution Agent sends transactions that originated at the Subscriber back to the Subscriber. I'm aware that the documentation states that this property is used with bidirectional transactional replication, however, I have reproduced your scenario and it appears to be being enforced with plain vanilla transactional replication as well. Dropping the subscription and adding it back with @loopback_detection set to FALSE alleviated the problem and allowed for the round trips to occur. Technically your topology can be considered Bidirectional Transactional Replication since both servers are publishing and subscribing to and from each other, even though the articles are different. Keep in mind that you will need to drop and add the subscription back with @loopback_detection set to FALSE since sp_changesubscription does not allow you to change the @loopback_detection property on the fly. I hope this helps. 

I need a DB that can capture instruments as reported by a bank and two accounting firms. Let's take Walmart stock as an example. The bank may have a instrument named "Wal-Mart Stock". One of the accounting firms may have it named as "Walmart Stock". The other accounting firm may have "Wal-mart common stock". Here's the diagram that I have so far: 

A product may be the same across sellers, but the productName, productDescription and productPrice can vary per seller. For example, consider the product TI-89. Seller A may have the the following information for the product: 

In SQL Server 2005 and 2008 R2, I'm calling into a stored procedure that has an out parameter defined as . The out parameter returns 10020 bytes according to . However, SQL Server errors if I try to define a varbinary with > 8000 bytes such as varbinary(10000). E.g. 

The problem with this approach is that it permits sellerProductId1 and sellerProductId2 to be from the same seller for a given row. That should not be allowed. How can I capture this many-to-many relationship while enforcing this constraint? 

Since your Subscriber is within two versions of your Publisher version, you are good here. However, this configuration is not supported if you are using Merge Replication since your Subscriber will be a later version than the Publisher: 

Yes, your publication database is your source database. There are some considerations when backing up the publication database, as well as other replicated databases, such as the distribution and subscription databases. This is covered in Strategies for Backing Up and Restoring Snapshot and Transactional Replication. 

You need to set the PollingInterval Merge Agent parameter in the replication agent profile after you create your subscription and your subscription agent. Have a look at Work with Replication Agent Profiles. 

This is a permissions issue, the Distribution Agent process account does not have rights on the distributor. Verify the Distribution Agent process account is a member of the PAL, has read permissions on the snapshot share, and is a member of the db_owner fixed database role in the subscription database. 

Just to add that restoring a database from an older version (e.g. SQL Server 2005) to a newer one (e.g. SQL Server 2012), i.e. upgrading is usually smooth. The issues are encountered when restoring SQL Server 2000 and older databases to SQL Server 2012 and newer. Downgrading - restoring a SQL Server 2012 database to a SQL Server 2005 instance is troublesome. 

Right-click the database (not the table!) Open Tasks | Generate Scripts On the Choose Objects tab, select the table to script 

Understanding Logging and Recovery in SQL Server An inactive VLF can and will be overwritten, but not immediately after the checkpoint, so the transactions will be there for a while. They will be gone when new transactions overwrite them. That can be in 5 minutes, or in 2 days. It depends on several factors Please note that 'truncate' doesn't mean 'deleted', just marked so it can be reused, i.e. overwritten. 

In future, you can also use the SQL Server Audit feature, just make sure you have specified all events you want to audit. Disclaimer: I work for ApexSQL as a support engineer 

What is happening here? How can SQL Server return more bytes than allowed in the data type? Is SQL Server using some other data type behind the scenes to hold > 8000 bytes? 

* Table contains five additional columns. These five column names are the same for and . The represents the bank, accounting firms, or any other entity that can provide data. The represents the instrument data as provided by the . is a version of the instrument specific to the application itself. So, in our example, it may contain "Walmart Common Stock" for the instrument name. It's different than b/c unlike , it is used extensively throughout the application and it must maintain a history of changes. The table provides a way to know that several different data sources are referring to the same instrument. and with the same are referring to the same instrument. ( is a surrogate key b/c some instruments do not have a natural key, and the s and a may need to be manually mapped as referring to the same instrument.) So, using the Walmart example, we can know that the bank, two accounting firms and the internal system are referring to the same Walmart instrument. The represents the issuer of the instrument such as "Wal-Mart Stores, Inc." Note: It only needs to be captured for s. I have a couple of doubts on this design: 

SQL Server recovery tools cannot help here, they can only recover lost information from database files (mdf, ldf, ndf, bak, trn). You should search for a way to recover overwritten files in Windows One of the solutions is to use the File History option in Windows. Your Windows version must support it and it had to be enabled at the time when the files were overwritten and "File History saves copies of your files so you can get them back if they are lost or damaged" Restore files or folders using File History 

You can find more useful info here: Auditing triggers in SQL Server databases Disclaimer: I work for ApexSQL as a Support engineer 

Besides sqlcmd, SQL Server provides the osql utility The same as sqlcmd, osql is stored in the SQL Server's installation Tools\Binn subfolder, and is used from the Command Prompt The syntax is 

There is a huge difference between the records logged in a transaction log file for a DELETE and for TRUNCATE TABLE statement A DELETE statement records what exactly has been deleted, i.e. the value of the deleted row e.g. 'JohnSmith', so you can read the transaction log content (you can use fn_dblog), see what was deleted and re-insert the deleted record if you want. With the TRUNCATE TABLE statement, you cannot do this, as the statement is 'minimally logged'. The exact deleted values are not logged in the transaction log, only the IDs of the pages that held the truncated records are logged. These pages are marked for overwriting in the database data file and the truncated data will be gone for good when the new transactions are written to these pages. Therefore, reading only the transaction log cannot provide the values that are lost due to the TRUNCATE TABLE statement. The only chance you have to recover the truncated records is to read the page ID in the transaction log and find it in the MDF file, in case it hasn't been overwritten 

Is it poor design to have a table (i.e. ) with only a single surrogate column? If this is a problem, how would it be designed differently? Are the various *Instrument table names confusing? If so, how could it be more clear? 

I have a SellerProduct table. Each row within the table represents product information as offered by a seller. The SellerProduct table has the following columns: 

Admin users will be required to identify that products are the same across various sellers. I need a way to capture this information (i.e. products are the same across sellers). I could create another table called SellerProductMapper as follows: 

Overall how should the design account for the need to capture multiple sources referring to the same instrument along with the need to capture an internal version of that instrument with history? Update The system's primary function / raison d'Ãªtre is reporting. It must report for a given date what the internal instrument (i.e. ) data was on that date. This is why I have as a history /temporal table and do not have the columns in .