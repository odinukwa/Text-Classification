I think you've essentially rediscovered the undecidability of the Halting Problem. This is the statement that it is impossible to write a program that can determine whether any program will terminate. The actual proof uses some rather involved logic, but the result can be summarized by the following counterexample: write a program that takes the output of a hypothetical Halting program when run on itself, and terminate if and only if the Halting program predicted that the program would not terminate. This contradicts the Halting program, therefore such a universal program cannot exist. Within the context of a model for the universe, my hypothetical explanation deals with how such a model would have to work. Suppose that we know a deterministic model for the universe, and from this construct a function called . This function takes any complete as input and returns , which is what is predicted to evolve to in ten seconds. 

If the definition of primitive could be the possession of all the attributes the image disowns (stress, bombs, etc.); If the natives truly do not have these attributes. 

If the answer is "yes," then God will have created something out of his own power to control, therefore no longer being omnipotent. If the answer is "no," then God is simply not omnipotent to begin with. The Wikipedia page on the Omnipotence Paradox explains this paradox and several approaches to it. It is apparent that the question itself is a matter of controversy. As far as I am aware, there is far from a universally accepted answer. However, I will present several responses in some detail: Logical Fallacy: Some believe that the question itself is logically flawed. Although "childish loophole" may not be the appropriate term, this is indeed an illogical product of the English language. It's not that an eternal God cannot destroy himself and therefore is not omnipotent, but that the proposition itself is logically impossible. Because your definition of God is one that must be eternal, it is logically absurd to ask if this God could destroy himself. It is akin to asking what the radius of a square is, or to apply the quadratic formula to a cubic function (as far as my education goes these are logically flawed). Absolute Omnipotence: Others believe that an absolutely omnipotent God is higher than the rules of logic and that such paradoxes are irrelevant. It does not matter what does or does not make sense to us, because our language simply cannot represent the idea of omnipotence. Thus, regardless of our logic and intuition, God simply can do whatever he wants, no exceptions. Impossibility of Premise: An entirely opposing approach taken by many is the idea that the paradox itself is unresolvable. This group sees the paradox as significant evidence against the existence of an omnipotent God; since the concept of omnipotence raises many contradictory situations, it is simply the case that an omnipotent entity cannot exist. To assert that it can is to allow for Omnipotence Paradox, an absurdity. These are the primary responses to your question, and it is important that you consider each against another in your further reflection. If I may add some subjectivity, I prefer the first response :) 

Your question heads in the right direction, but you're a little off in the religion itself. The invention of zero (or rather, its acceptance as more than just a placeholder) had a lot to do with Hinduism, not Buddhism (which, granted, came directly from Hinduism). The following explanation is entirely referenced from the excellent book Zero: The Biography of a Dangerous Idea by Charles Seife: 

Obviously, #2 is simply not true. I would appreciate an explanation of whether it is #1 or #3 (or possibly something else), and if it is #3, how the "free spirit" is only fooling himself and isn't really free. 

I would argue that Nietzsche certainly had a purpose in choosing "genealogy" over "history." Let's examine the meaning of each word (from Google): 

Our empirical evidence tells us nothing more than that we ourselves are conscious. There is no evidence convincing me that any of you have consciousness. How would you even go about empirically verifying something which is by definition purely subjective? The only thing I seem to know for sure is that I myself am conscious, and even this has been subject to skepticism over the years. To be clear, this is not some esoteric opinion I have, but the generally agreed upon view, and certainly much more logically rigorous than trying to argue that other things have consciousness. 

I'm going to tackle this more directly than I feel the other answers have done. Consider the following: broadly construed, harm in the ethical sense is something that can only happen to an agent - an entity with certain cognitive capacities (the ability to feel pleasure/pain, make decisions, etc. - incapacitated persons are a legal corner case I'm myself leery of). You can't, in an ethical sense, "hurt" a rock unless you believe the rock would experience something negative as a result of your actions. You can't declare it "wrong" to break a rock by virtue of it being a rock simpliciter. If it's wrong to break a rock, it's wrong because it infringes on somebody's property rights, it contributes to the destruction of a living habitat, et cetera. In the same way, we impose restrictions on the sorts of violence that are permitted with the intent to prevent harm; we want to minimize negative experiences, to make it so that thinking and feeling things are not inflicted with unpleasant qualia. Thus there's nothing wrong with acting violent to a rock, excepting the aforementioned cases. Thus, there's nothing wrong with shooting Nazi zombies in Call of Duty - because we have no reason to believe that the zombies "feel" anything, that they possess any sort of agency. But, this is not a claim which finds its philosophical origins in the mere fact that the zombies are "simulated". That, I will make explicit, is irrelevant. I will disclaim that the following is sourced on my studies into philosophy of mind - I'm not pulling this out of a magic hat. The Mind What are the kinds of things that "feel"? How does it happen that I, for example, am able to experience emotions and sensations? If I see a red apple, there's more happening than just optical processing of light being reflected by the apple's skin; there is additionally something it is like to see red, something it's like to be me seeing the apple. That's my "first person subjective experience", and it belongs to me alone. It's the existence of this first person subjective experience, I'd say, that motivates us to treat ourselves as agents. We want to minimize harm amongst humans because each human possesses an intricate, highly complex first person experience, and we consider these experiences valuable. Similarly, we want to minimize harm to "sufficiently cognitive" non-humans (with the boundary debated), because cats and dogs definitely feel pain and have their own experiences. But then, where do these varied experiences come from? What do we have in common with other animals, and potentially other non-biological structures which might have experiences - which might be conscious? I'm not going to dive into the colossal philosophy of mind debate. I'll just summarize the consensus position: unless you believe in souls as distinctly separate from and unrelated to physical bodies (and not many philosophers these days do) or are an idealist, you'd be rational to believe that consciousness is, one way or another (there are many ways) tied to/derived from our physical forms. That is, I am conscious because my bodies, and particularly my nervous system, behaves in such a way that it "generates" my conscious experience (the details are debated). Because my neurons are connected to one another in such-and-such a way, and because the electromagnetic configuration in the whole matrix is arranged in such-and-such a way, I am conscious. The puzzle then becomes to figure out what these "magical", consciousness-generating configurations are - and the best ideas we have right now simply suggest that a sufficiently complex organization of flowing information will generate some level of consciousness. Given how subjective consciousness inherently is, it's in practice more or less impossible to even be sure of what things might lead to consciousness. And hence, theory and practice collide. How can we, for example, know if a robot may ever be conscious if any hypothetical experience the robot has is totally private to it? The answer, of course, is that we do the same thing as we do for each other. I in fact have no way of knowing for certain that I'm not the only subjective experience in the world - you might all be philosophical zombies. But I trust that you're not, because things work out more easily that way with my ethics. I treat you like you feel, and you treat me the same - because we all demonstrate sufficiently complex behaviour that, as far as we can tell, we're probably conscious agents. The Simulation Now suppose we're all immersed in some higher-order simulation. Nothing changes. We still exhibit incredibly complex behaviour, we still possess (or appear to possess) our first person subjective experiences, and we still feel and act as agents. Being in a simulation has no bearing on our moral worth. We warrant treatment according to our established rules because of how we behave and demonstrate a capacity for agential behaviour. Return next to the Nazi zombies I've been shooting up. Watch how they scramble haplessly around the building and show minimal behavioural complexity. The most complicate decisions they make are "take this route or take that route?" They don't even have anything like a pain subroutine - they just charge at me until one of us is down. I'm allowed to be violent to them not because they're simulated, but because they're simple. They don't give me any reason to believe that they feel, so I'm under no pragmatic obligation to be nice to them. In short, we sanction violence in our video games because there's no reason to believe we're causing any pain, given how simple we create our characters. But, if we're in a simulation ourselves, that changes nothing about our own behavioural, functional, neurological complexity, all of which indicate that we each possess a subjective experience worth protecting. Sorry if that was a bit of a ramble. I get a bit excited about mind stuff. 

Alex, excellent question, here. I think Wigner's paper gives little defense to the Platonist case. It seems to me that he's merely saying "applying mathematics to physics is useful to us," but this doesn't quite lead us to believe that "mathematical entities are real," which is what the Platonists would want to say. This is why I think that: consider the possibility of stripping the theories of science of their mathematics. If we were able to do this, would we have any reason to think of numbers as still being real? I'm not sure that we would. Note that I'm not saying our theory would be better, or anything. It'd probably be much worse! You could definitely argue that keeping the numbers in the theory has value, that it's good; perhaps it's easier for humans to solve, or better yet, computers. Or maybe the theories are more compact with numbers. But if the theories don't actually depend on the mathematics, who cares, right? It's useful for me to think that I'm on just on a bus when I'm 35,000 feet in an airplane, because that helps me get through the flight without freaking out. But of course I have no reason to think that this useful thought has any bearing on what's real. This idea that I've introduced is called the indispensability argument, or the Quine-Putnam thesis. It basically says that we absolutely rely on mathematical entities to explain scientific entities, so we have just as much reason to believe in those mathematical entities as our scientific entities. A good thing about this theory that you don't even need to think that scientific entities are real to accept it. It just says that we should have the same confidence in mathematical entities as we have in scientific ones, whatever that amount of confidence might be (even if it's none). There are a vast number of criticisms about the original Quine-Putnam thesis, some of which you can read in that article or on the Wikipedia. One criticism was that some philosophers doubted that any scientific theory depended on math at all! However, just a few years ago, a paper was published where a brilliant philosopher, Alan Baker, found such a theory. You can read it in his paper here. So where do we go from here? If Baker is right, then we do rely on a mathematical property for a scientific explanation. Should we only place confidence in those mathematical entities (prime numbers?) Or all mathematical entities? Is that one example enough? Anyway, I just thought these sorts of thoughts and questions were relevant, so I decided to share them. I hope you find it interesting! 

Frank, you made a good observation about the similarities between traditional qualia and the flow of time. As I understand it, anything that we experience has all of the necessary properties of a quale. Since we experience the flow of time, surely we can find things that are similar in this experience to other quale, surely with it the problems that come up in discussions of other quale. Before I look into other similarities, let's first look at traditional quale, like color or taste. When I talk about the flavor of onions, it's difficult, maybe even impossible (for now, at least), to determine if that sensation is exactly the same as yours. And when I say blue, perhaps you're actually thinking of what I think of as red. As of yet, science hasn't given us the tools to compare these things. Personally, I think of this as the property of qualia that give them any weight, or philosophical meaning. If we could compare color, then who would about the quale of color, then, right? Sure, they'd still be experience just the same, but when I hear qualia I immediately think of the subjective, incomparable nature of experience. If we could compare things, calling them qualia would seem inappropriate. I almost define qualia as our experience that we can't compare. If we take this definition, then the ability to compare colors would exclude them from the class of things that are qualia. Anyway, back to time. When we the experience of time, it seems the only properties we could disagree on are the direction of flow and the rate of flow. Physics (in particular, thermodynamics and its irreversible processes) gives us reasons to think that time couldn't flow backwards. If you accept this as true (I don't think you need to, but you might be persuaded by physics), then you can only talk about the rate of flow. Could we disagree on the rate of flow? I think so. Perhaps what feels like an hour to me feels like a minute (how I experience it) to you. Allow me to take a break for a moment to discuss cause and effect. In the simplest form, cause and effect says nothing about rate of processes occurring. It refers solely to the direction of time flow. Accordingly, if you happen to be persuaded by physics that we physically could not experience time in the other way, then it seems that cause and effect loses that fundamental of quale: the inability to compare. If everyone experiences time in the same direction, and we know this, then who cares? It'd be like being able to compare colors above. Anyway, back to the flow of time. Up until now, there seems to be no reason to distinguish the experience of the flow of time from other qualia. But I'm wondering if it'd be possible for us to determine the rate of flow for an individual? Perhaps from something like brain waves or properties of your neurons? Might there be something which we can now observe that would lead us to think that someone is actually experiencing time faster. An example I'm thinking about would be someone who has faster reflexes than someone else. Now, there are at least two types of examples that could lead someone to have faster reflexes. The first is that they have simply have more neural connectivity that allows this person to perform a given activity faster. The other possibility would be two people who have identical neural structures, yet one is lacking myelin sheaths. Instances of the second sort seem more important to this discussion. In the first case, the electrons in the brain are traveling at the same speed, they just have further to go. In the second case, the electrons actually are moving slower. But the question remains as to whether or not we would experience time slower if the electrons in our brain were going slower. I'd like to think that it would. We have reason to believe that all our experiential processing happens in our brain, so surely if our brain was processing things slower that would lead to a sluggish experience of time? This hinges on electrons being the mediating particle in brain processing, which I'm not sure we have any strong reason to believe. But it seems possible. Maybe you disagree or are unconvinced. That is completely fine. I'm just writing some thoughts I found interesting and relevant to your question. I hope you at least find them interesting, if not convincing. =)