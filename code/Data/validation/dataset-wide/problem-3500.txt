The "production function" in economics and econometrics is not an engineering concept. It is a highly abstract construction where the myriads of inputs used are lumped together in very few categories: "capital" and "labor" being the most usual ones, while sometimes inputs critical to an industry like say "Energy" may be singled out and appear in the production-function formulation. At such an abstract level, it is easily implementable without the need to go into particulars of each firm. Moreover, in many if not most of the cases, what is modeled is the production of value added, not the total output (either in quantities or in values). Applied work commissioned by specific (usually very large) firms, and also, applied research into "adjustment costs" or what is called "insider econometrics", may go some steps towards creating much more complex production functions, that essentially try to take into account the actual physical relations and interactions between the various inputs. But these are very specialized areas -remember that the Economics discipline ultimately is about markets and economic systems -the "individual" (firm or person) level is researched mainly in order to have sound foundations for the aggregation that follows. 

Looking at a Profit & Loss statement of a company, Value Added = Personnel Costs (+) Depreciation Charges (+) Profits (or (-) Losses) It essentially is this concept that coincides exactly (in a narrow sense) to the fundamental production function with constant returns to scale, and factors of production only Capital and Labor, that moreover are being paid their marginal product: Due to homogeneity of degree $1$, we have the production function $$ Y = F(K,L) = \frac {\partial F(K,L)}{\partial K}K + \frac {\partial F(K,L)}{\partial L}L$$ So if the gross rate of return to capital equals its marginal product, and the wage equals labor's marginal product, $$r= \frac {\partial F(K,L)}{\partial K}, \;\; w=\frac {\partial F(K,L)}{\partial L}L$$ we get $$Y = rK + wL$$ So all of $Y$ goes to the factors of production that appear in the right-hand side. But $rK=$ Depreciation Charges + Profits (or minus Losses), and $wL=$ Personnel Costs. So in reality, $Y$ is Value Added rather than Gross Sales (and most econometric studies where production functions are estimated, regress Value Added on labor and capital, rather than Gross Sales). An issue here could be how one views interest costs, which are also returns to capital (irrespective of the fact that they do not belong to the shareholders -the company employs this capital and pays a fee for its use) Of course the concept of production function can be enhanced to include separately materials and energy for example, in which case the appropriate dependent variable becomes Gross Sales. 

The Laffer Curve is a theoretical argument that feels strongly true the moment one hears about it. The complexities around it once one wants to have a closer look are many (just for a taste the wikipedia article can be consulted). Even in the simplest econometric study, one has to make sure that what one does is consistent with the theory one wants to test (or the one on which one relies), otherwise it won't be an econometric study but an exercise in pure mathematical approximation devoid of economic content (after all any bounded continuous function can be approximated by polynomials as per Stone-Weierstrass theorem). So what does the Laffer Curve (very) basic theory (and in its strongest form) asserts? 1) That output is a negative function of the tax rate. 2) That a tax rate of $100\%=1$ should result in zero output, and so zero tax revenue. 3) Moreover, logic says that if the tax rate is zero, tax revenues should be zero. it appears then that we can start by an assumption that somewhere in between there is a point of maximum tax revenues (although one of the complexities mentioned earlier is that the curve may not be unimodal, i.e. it may also have a local maximum). Let's see which conditions should the simplest "quadratic regression" satisfy in order to be consistent with the theory. We have $$T(\tau, Y(\tau)) = \beta_0 + \beta_1\tau + \beta_2\tau^2 + u$$ where $Y$ is output (or sales), $\tau$ is the tax rate, $T(\tau, Y(\tau))$ is Total tax revenues, and $u$ is an error term, to account from deviations from the mean-value. We can deduce the following: A) In order to satisfy point 3) above on average, $T(0, Y(0)) = 0$, it must be the case that $\beta_0 =0$. B) This equation, in deterministic terms has derivatives $$\frac {{\rm d}T(\tau)}{{\rm d} \tau} = \beta_1 + 2\beta_2\tau, \;\; \frac {{\rm d^2}T(\tau)}{{\rm d} \tau^2} = 2\beta_2$$ and so it will have a maximum at the point $\tau^* = -\frac {\beta_1}{2\beta_2}$ if and only if $\beta_2 < 0$. C) Finally, in order for the equation to satisfy point 2) above, $T(1, Y(1)) = 0$, it must be the case that $\beta_1 = -\beta_2$. But then we also obtain that the maximizer will be $\tau^* = 0.5$. This last consequence is not good: our tool (a specific mathematical functional form that appears convenient for our purposes), forces on us a very specific conclusion that is not predicted by the theory, something that should be left for the data to decide, even in the case were the data do indeed exhibit "Laffer-curve" properties. In other words, the quadratic regression postulates not "general Laffer curve properties", but a very specific Laffer curve (this essentially comes from the fact that the independent variable $\tau$ is restricted to lie in $[0,1]$). But run the regression we must: so we found that for this specific "quadratic regression specification" to be valid, theory imposes three restrictions on the parameters, $$\beta_0 =0,\;\;\; \beta_2 < 0,\;\; \beta_1 = -\beta_2$$ Since one of the restrictions is an inequality, one could use Inequality-Constrained Least-squares which requires an iterated algorithm, but I won't go there. Otherwise, one should first run a regression with the coefficients unconstrained, and see whether at least, $\hat \beta_2 <0$. Then run the regression imposing the two equality constraints, hope that in this restricted regression $\hat \beta_2$ remains negative, and conduct an $F$-test on the two specifications to determine which fits the data better. Now assume that the restricted model does have a $\hat \beta_2 <0$ and that it outperforms the unrestricted model: one can then argue that this data set behaves like the Laffer-curve theory would predict, but also, that the tax revenue maximizer is around the value $0.5$. One cannot escape this last conclusion, if the restricted model prevails. If it does not prevail, other aspects of Laffer-curve theory are not supported by the data, so to mechanically calculate a tax revenue maximizer based on the estimates from the unrestricted model will be rather shaky. And there are also important statistical misspecification issues: 1) Can we argue that the sales and the tax rates of the various states come from the same distribution, and are independent? (this would be needed to have the "i.i.d. sample" framework) and especially (which I believe is what @FooBar 's answer focused upon) 2) Is the tax rate uncorrelated with the error term, or is it endogenous? Are there factors that affect directly output/sales and are also correlated with the tax rate (e.g.: if a productivity or other mid-term range shock affects output, is there pressure to change the tax rates also, and do they adjust?) In light of the above, I would say that the $R^2$ "fit criterion" is not the first thing to check, nor the primary method, in order to judge the quality of such a regression estimation. 

These are proper Marshallian demand functions, even though Income does not appear in them. This is due to specific form of the utility function (and the candidate solution of all goods being purchased at strictly positive quantities). It emerges that there is no income effect for goods $x_1$ and $x_2$ - optimal uncompensated demand does not depend after all on the level of income, but only on the relative prices. The reason why Marshallian demand is defined as it is, is to make clear that it does not include any kind of "income compensation" as Hicksian demand does. But this does not preclude a case like yours, which again, depends on the form of the utility function. Thinking economically, what goods can you think of whose demand may realistically not depend on the level of income but only on relative prices? Answering this question would be useful in order to map the mathematical expression of the utility function to real-world economic phenomena. Also, note that the specific utility function points to "quasi-linear" frameworks, where the good that enters additively, essentially functions as Income itself. 

The paper does not contain, even in print form, the actual data sample, so BKay's suggestion to contact the authors is your best shot. 

Just to complement @Bkay's answer, "measurement error" in the dependent variable is relatively "harmless" -what hurts is error in measurement in the regressors. If we have measurement error in the dependent variable, what we need to assume in addition, in order to preserve unbiasedness, is that this error is independent of the regressors. If we can reasonably assume that (and usually we can), then @BKay 's answer shows that the effect is just a transformation of the error term of the regression. It may affect the variance, but not the parameter estimates. On the contrary, if we have measurement error in the regressors, then they stop being strictly exogenous to the error term, and unbiasedness is lost. 

Separate the concepts "an increase in quantity demanded" from "shifting of the demand schedule". The second means that for some reason, say change in tastes, preferences, the whole demand curve shifts: now, quantity demanded for the product has increased for all price levels, compared to the previous situation, but of course the downward slope remains. Your economics textbook should have said 

Actual availability of regressors may be an issue here, but if all four mentioned variables are available, the situation is as @Michael mentioned in a comment: Since $X_2$ is correlated with $Y$, it should be included in the regression specification as a "control". $$Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + u$$ This is intuitive, but it also takes care of the technical aspect. Then since $X_2$ is endogenous, i.e we have ${\rm Cov}(X_2,u) \neq 0$, but we have an instrument that is not correlated with the error term $u$ since $X_2$ has been included in the specification, we end up with $$Y=\beta_0 + \beta_1Z + \beta_2X_2 + u$$ for which the OLS estimator will be asymptotically consistent, since (writing $\mathbf W = [1:Z:X_2]$) $$ \hat \beta = \beta + \left (\mathbf W'\mathbf W\right)^{-1}\mathbf W' \mathbf u$$ and its consistency will depend on the following probability limit being zero $${\rm plim}\mathbf W' \mathbf u ={\rm plim} \left[\begin{matrix} \frac 1n\sum u_i\\ \frac 1n\sum Z_iu_i\\ \frac 1n\sum X_{2i}u_i\\ \end{matrix}\right] \rightarrow {\rm plim} \left[\begin{matrix} \frac 1n\sum E(u_i)\\ \frac 1n\sum E(Z_iu_i)\\ \frac 1n\sum E(X_{2i}u_i)\\ \end{matrix}\right]= \left[\begin{matrix} 0\\ 0\\ 0\\ \end{matrix}\right]$$ holds because both $Z$ and $X_2$ are orthogonal/uncorrelated to the error term $u$. In other words, the fact that the regressors $X_2$ and $Z$ are correlated with each other does not create any problem (as long as of course the co-linearity between them is not near-perfect), on the contrary it more generally justifies including both in the regression specification, making it "multiple regression" -it exists exactly for such cases. 

Back to our problem. The first order condition is $$\frac {\partial L_{FJ}}{\partial \alpha} = \lambda_0\int u'[w+\alpha(z-1)]\cdot (z-1) dF(z) - \lambda_1 \leq 0$$ (note the "lower or equal to zero" which is the case when optimizing under inequality constraints, rather than just "equal"). First, we establish that $\alpha^* >0$. Due to $u'>0$ and the (strict) convexity of the utility function,$u''>0$, and the assumption that $E(z) >1$ we have (using Jensen's Inequality) $$E[u(w+\alpha(z-1))] > u(w+\alpha(E(z)-1))] > u(w + 0\cdot(E(z)-1))=u(w)$$ We turn now to examine cases. Since the two multipliers cannot be both zero, and $\lambda_0$ takes only two values, there are three possible combinations. Examine the case $\lambda_0 =1$. Then $\lambda_1$ can in principle be zero or positive. Examine the case where $\lambda_1 =0$, i.e. the constraint is not binding which implies that $\alpha^* < w$. With this candidate pair of multipliers, $\{\lambda_0=1,\lambda_1=0\}$, the first order condition would become $$\int u'[w+\alpha(z-1)]\cdot (z-1) dF(z) \leq 0 \Rightarrow E(zu') - E(u') \leq 0$$ Since $u'>0 \Rightarrow E(u') > 0$. Also, since $E(z)>1$ we have that $$E(u')< E(u')E(z) \Rightarrow E(zu') < E(u')E(z) \Rightarrow \text{Cov}(z, u')<0$$ But this cannot hold, because, since $\alpha^*>0$ and $u''>0$, we have that $u'$ will be strictly increasing in $z$. So the covariance of $z$ and $u'$ cannot be negative. But then the pair of multiplier values $\{\lambda_0=1,\lambda_1=0\}$ cannot be a solution, and this happens due to the assumption $u''>0$. We are left with the cases $\{\lambda_0=1,\lambda_1>0\}$, or $\{\lambda_0=0,\lambda_1>0\}$. In both these cases, $\lambda_1 >0$ i.e. the constraint is binding , i.e. we will have $\alpha^* = w$. QED. 

Energy consumption is a per capita variable, specifically "Kgr per capita" Real GDP is a per capita variable Trade Openness is a per capita variable Energy price is a unit price of "crude oil" 

This is wrong. I presume the Expected Utility Property holds here, so, if we denote the gamble by $G$, a discrete uniform random variable taking three values according to the setup, we have $$U(CE) \equiv \sum_{i=1}^3p_iU(g_i) = E[U(G)] < U[E(G)]$$ the inequality to the right due to Jensen's Inequality and the assumption that $U()$ is concave. This also gives us $$ CE < E(G)$$ which should be intuitive: a risk-neutral person would demand $E(G)$, the expected value of the gamble, in order not to take it. A risk-averse person would require less, to leave the gamble. Having cleared this, the OP asks: Is it possible that $CE < \min G$? The answer is : No. Assume that the gamble outcomes are ordered, so $\min G = g_1$. Ad absurdum, assume that $CE < g_1$ holds. Then we will have $$U(CE) < U(g_1)$$ Using the definition of $CE$ we replace the left-hand side $$\sum_{i=1}^3p_iU(g_i) < U(g_1) \implies p_2U(g_2) + p_3U(g_3) < (1-p_1) U(g_1)$$ $$\implies p_2U(g_2) + p_3U(g_3) < p_2U(g_1) + p_3U(g_1)$$ $$\implies p_2[U(g_2)-U(g_1)] + p_3[U(g_3)-U(g_1)] < 0$$ But this is impossible since $g_1 = \min\{g_1,g_2, g_3\}$ and so $U(g_2)-U(g_1) >0$ and $U(g_3)-U(g_1) >0$. So assuming $U(CE) < U(g_1)$ led us to an impossible situation, and therefore it cannot hold. Intuitively, the worst outcome of being in the gamble is to receive the minimum payoff -so for a rational agent, even if it is risk-averse, it would be irrational to accept less than the worst outcome, since then it would certainly do worse than being in the gamble. Note that "aversion to risk" does not mean "take away all risk at all costs".