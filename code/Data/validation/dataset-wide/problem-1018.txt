I created a user in SQL Server 2012 database and revoked all permissions given by the public role. Then i granted exec permission on a stored procedure. The user can execute the procedure but cannot get the data it returns. The procedure is in a schema1 and the tables from which it selects are in schema2. If I add the user to db_datareader role it can read all data from all the tables in the database. I tried WITH EXECUTE AS OWNER but it didn't work. How can I grant only the access to the given procedure and nothing else? 

I think it's a great news that Microsoft finally changed this default setting. The previous one was really bad - it caused problems with latch contention. Paul Randal's article on the topic 

Using different users will not reduce or increase the performance. It is clearly a security issue. Usually you don't want users from company A to be able to access company B data. I would recommend to create separate users for each application and grant them only the necessary permissions. If you run the application using a user with admin rights you risk a lot when the application gets compromised. 

I have recently upgraded a few SSRS projects and solutions created in Visual Studio 2010 to run correctly on VS 2017. I changed the target SQL Server version to 2012 (since this is the version that is used). One of the problems I face is whenever I upload any of the RDL files to the Report Server I get the rsInvalidReportDefinition error. This problem is further discussed here: Error while uploading a report I used the recommended solution and uploaded the rdl file from the bin folder instead. This time it works fine. The problem is that the files in the main folder still do not work correctly on the report server. I am wondering if I should maybe replace the files in the main catalogue with the files from the bin folder? Can you help me understand this issue better? 

This way the engine knows when you want to use Column from TableA and when from TableB. It is a good practice - you should always use aliases when writing SQL queries. The query you are looking for might be: 

A few notes about both of them. If a server crashes and you can't repair it what should you do? Set up a new server from scratch? In both physical and virtual environments it's gonna take a lot of time. When the database server is a VM should you recover it from a VM backup? This operation can last multiple hours for bigger machines. Or maybe one should keep a clean virtual machine with database software installed and in case of disaster: - restore databases on the clean VM - change the IP address and start using the new database server Any ideas? Or maybe you can submit some useful links or refer any books? 

I don't want to wait the estimated 2 months for the rollback to complete. The transaction isolation level of the database is READ COMMITED. Is it possible to kill this session? How should you act if you find such a query in one of the mission critical databases? 

Is anyone aware of a SSAS (tabular) 2016 in which the number of records in a table are not fully shown in Excel? 

The process outlined above basically copies all User DSN entries as System DSN entries. If you to have just one entry copied over, then you will need to delete their corresponding keys under .\ODBC.INI as well as their corresponding entries in .\ODBC.INI\ODBC Data Sources. 

I have an SSIS job that gets data from a SharePoint 2010 list that runs perfectly from Visual Studio and also if I trigger it manually from the SSIS store, but not when scheduled as a job in the SQL Server DB Engine instance. I am doing everything using just one super user account called "spadmin". 

As part of an ETL process, I need to copy a varchar field in table1 (staging table) which is meant to contain an integer value to a tinyint field in table2 (production table). However I am having some issues when trying to combine the following two business requirements: 

This only seems to happen with ONE table (all other tables are fine). So we tried recreating the table, but the same problem persists. Any idea of what might be causing this issue? 

(we ensure that Excel is connected to the deployed Tabular Model and not the user's workspace copy in Visual Studio) 

I am inserting values form a staging table in SQL Azure into a production table. Values in the staging table are varchar, while the target value in the production table is tinyint (it is an age field for humans, so I reckon that up to 255 will suffice ;) ) Problem is that due to a bug in the source system, we tend to get some values as -1 or -2 when they should be 0. This causes issues, since TINYINT only supports values form 0 to 255 (and also because this is factually wrong). I was wondering if there is some sort of case statement that I could use to convert values to 0 if they fall under 0, or perhaps if they fall outside the 0-255 range? 

I am having a real hard time trying to convert a TSQL statement (which be a store procedure) into a Dynamic SQL. Basically I must be able to pass the schema name as a parameter. Here is my code: 

Log in with the user that has the User DSN entries that you with to convert to System DSN Open the Registry Editor and navigate to HKEY_LOCAL_CURRENT\SOFTWARE\Microsoft\ODBC\ Right-click ODBC.INI and select export to save it as a file on the desktop (or anywhere else you fancy) Open the .reg file with a text editor such as Notepad Replace the text HKEY_CURRENT_USER with HKEY_LOCAL_MACHINE. Save your changes Double click the .reg file and proceed to import it into the registry. 

I am trying to create a contained user for a database in SQL Azure that only as read-only access. What I am doing is: 

I am trying to create a stored procedure that will allow us to duplicate values from the previous month into the current month -- BUT ONLY if there isn't a value for the current month already. 

Change to . Your soultion would work only if it was an instead. With it works different. The filter is applied for the join predicate and the result is different. 

I'm sorry if this question breaks the rules of DBA StackExchange. I'm not sure if it is allowed in here. I am planning to lead a basic SQL Server training for my coworkers. The course should include some basic information about relational databases and the SQL querying. This is why I'm looking for some training materials. Obciously I could prepare PowerPoint presentations, SQL tasks and all the other stuff myself but I think since it is a well researched topic I should not reinvent the wheel. Do you know of any training materials available that I could use? I have the training materials for the MS Exam 70-461 - Querying SQL Server but I'm not sure if I would be allowed to use it and also they are pretty big. Can you recommend something? 

I am designing a data warehouse using Azure Databases (not Azure Data Warehouse though), I have 2 databases: the main data warehouse and a staging database. As in a traditional ETL process, the raw data is stored in the staging, then transformed and finally loaded to the data warehouse/data marts. Since it is Azure SQL, cross database queries don't work and the only workaround I know is using external data sources and external tables, which is pretty problematic. Can you recommend the best solution to access both databases at the same time? My ideal solution would be cross database queries like in SQL Server on premise. 

I am looking for a better solution. I heard that SQL Server Integration Services have a MERGE JOIN and a LOOKUP transformations. I'm not sure if one of these provide the possibilities that I'm looking for. What tool can you recommend? I'm sure it can be done efficiently in SSIS but I just don't know the right solution. 

Note that it is the same table. This query causes serious blocking on one of my test databases (I wanted to drop it but couldn't and this made me investigate the issue). The lock type is LCK_M_X. I cannot kill the session - i get the following message: 

I am configuring transactional replication in SQL Server. The subscription is configured as push from 2008R2 publisher (distributor is the same server) to 2012 subscriber. The object I want to replicate is an indexed view. The base tables exist only on the publisher. The replication fails due to the following error: 

I have a query that collects customer data. I select a lot of correlated data from different tables. I want to have only ONE result row for each customer. The query looks like that: 

Share the execution plan, like @YperSillyCubeᵀᴹ said. I think you can improve the performance of this query by creating a nonclustered index on requestStatus, requestId. However: the fact that you are not specifying the column list (I'm guessing SELECT *) may change the plan by introducing Key Lookup or Clustered Index Scan (probably CIS on such a big table). If Clustered Index Scan is inserted to compensate for the lookup, the nonclustered index will not be helpful. I can answer the question more precisely if you update the question with the plan. 

To my surprise, I can create tables (!?!) I can also truncate them and drop them (?!?) Not sure what the heck is going on here. Am I missing something? I need the user to be contained in this database and not to exist outside of it. 

I have a table in my db that stored both successful and failed log-in attempts. I am creating a stored procedure that allow us to delete records which are older than X days old. So far so good, but I want to raise it a notch (or two) and allow us to specify whether to delete records on whether the [Success] column is true, false or both. I am having some issues with the concatenation of the script that needs to be executed, though. Here is what I did so far: 

If the value of the source varchar field is blank, then it will be set as NULL in the target tinyint field. For that I would normally use NULLIF. If the field contains anything that could not be cast as a tinyint value (e.g. punctuation, letters, or a value higher than 255) then the value will be set as 255 in the target tinyint field. The rationale behind this is that the tinyint field would never have a 255 value unless there is an error -- and it wouldn't be appropriate to have errors set as NULL or 0 because these are perfectly valid values and we wouldn't be able to differentiate between a valid entry and a mistake. 

Here is the answer. Even though the job was configured to run via a PROXY Account, the SQL Server Agent is still responsible for the job. I had a look and the SQL Server agent was configured to run under the Local System Account on that server. So what I did is to put the agent to run under the superuser admin account and it worked as expected. Now in this case the fact that the job no longer needs a proxy since the Server Agent itself is running under the ultimate account. However I appreciate that this is not the right way moving forward (even though this isn't my server and I hope I never get to touch it again!) I will be advising the customer to reconfigure SQL so every service runs under a dedicated domain account (i.e. created solely for this purpose), which is the way it should be! Now what I would love to understand is why the job would run as long as the proxy account used for scheduling the job was logged into the SQL server! 

If I connect to the SQL server's SSIS store (not the DB engine) via SQL Server Management Studio (SSMS) and I right click on the job in question that is stored under "Stored Packages\MSDB" and choose to execute it, the job will run without any issues. This happens whether I am using the local SSMS installed on the SQL Server in question, or if I am using a SSMS installation on a remote workstation. However if I schedule the job through the same SQL's server database engine, the job will fail -- both on a schedule and if I try to run the job manually. Now here is the puzzling bit: The job will not fail if I have on the background a remote desktop connection into the SQL server with that super user account (i.e. spadmin) while I run the job. By on the background I mean that I am not doing anything on this remote desktop connection except login in with the super user account. When the job fails, I get the following "Bad Gateway" error (see end of post) that suggests the problem is accessing SharePoint. However since I can run this job via the SSIS store with the same account for which the job has been scheduled, there is no doubt that this job is capable of running from the SQL Server. Server build: 10.50.1617 I am going mental here. Any ideas of what the problem might be? Here is the full error message for completeness sake: