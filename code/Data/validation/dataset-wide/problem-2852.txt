Sentience can not be aquired like a possession. It is an attribute that is either there or is absent. To be considered sentient there are several things that are required: 

Death penalty is a punishment, (in theory) reserved for the most heinous of crimes. While this is often done medically it does not have to be. Firing squads, hanging(thenyc.com has a NSFW Video i am not going to link from syria of mass hanging in last month), and electric chair are still common throughout the world. That said there is no moral difference when considering commandment "Thou shalt not kill". Taking a life is still taking a life. You can justify the execution but that should not be confused with making it morally better. The commandment is not thou shalt not kill unless you deem the crime heinous. So to support one but oppose the other would seem hipocritical. Hammurabi first proposed a set of laws that tried to set punishments that were equal to the crimes committed. Currently most advanced societies have moved to a policy that have lessened the punishment for some crimes, particularly violent crimes. The policies often involve the possiblity of release from prison, and often the potential for the death penalty in certian countries. One could argue that when committing the crime the perpetrator knew the potential penalty and thus committed a form of suicide. Albiet one that will be completed by agents of the government. 

I've been reading on the holism-reductionism continuum. Reductionism strikes me as compliant with general principles of the scientific approach and method because it seeks to explain complex phenomena by breaking them down into smaller units and building theories bottom up, focusing on specificity and detail. Holism is the opposite and seems to me it could easily serve as a seemingly respectable (who doesn't want to tie it all together in a big "theory of everything"?) curtain for poor, insufficient or downright misleading and sloppy research. This is not to say we shouldn't seek to explain relations among phenomena -- only that it should be preceded by a thorough understanding of individual parts. In modern scientific circles, is holism generally regarded as a conduit for pseudoscience? 

I am almost sure there is a name for the fallacy whereby its exponent tries to apply a very small sample of observation, usually anecdotal evidence, as representative of the population, of which that sample is part, at large. For example: 

I very much disagree with this premise. He did not free the slaves that existed in states that remained in the Union. He was responsible for the single greatest power grab by the federal government in history. And he was responsible for the deaths of hundreds of thousands of Americans much of which could have been avoided had Lincoln been willing to allow reunification once it was clear that the south was defeated. Instead he chose a path of conquest. Many people who were pro-Union and anti-slavery in the south suffered and lost as a result of the land they owned being in a slave state. 

It is kind of the reverse of the norm because we are infering: because it is true of some part of the whole, it is true of the whole. But it is still a compositional fallacy. 

You raise a few points. First ‘Sum of logic’ is the Wikipedia title. Don’t trust anything that Wikipedia says, or at least, be cautious. The book is generally known by its Latin title, Summa Logicae. ‘Summa’ is difficult to translate in English – it doesn’t really mean ‘summary’. The essay by Peter King that you link to is a short ‘summary’ of the work. You say: “But I can't find any scans or photos of the original handmade manuscript or the original (first) edition. Do you know any links or libraries or museims, where I can find it?” Until the 15th century, all such works were published in manuscript (i.e. handwritten) form, so there is no sense in which there was an ‘original first edition’. The concept of an ‘edition’ arrived with printing, when instead of writing a copy, you do a lot of work to set the type and get everything just right, then you publish with a large print run, and keep on printing until you decide on the need for a second edition. There is also the concept of a ‘critical edition’. Rather than rely on the old 15th century printed works and other editions copied from them, you go back to the original manuscript sources, and compare them together to look for copying errors, with the aim of finding out what the author ‘really’ said. The first critical edition of the Summa was published in 1974 as the first volume of Opera Philosophica (St. Bonaventure, N.Y. Editiones Instituti Franciscani Universitatis S. Bonaventurae, 1974. 899 p., eds Boehner, Philotheus, Gál, Gedeon, Brown, Stephen). I don’t have the full list of all the ms used for the critical edition, although two of them were: Bruges, Bibl. de la Ville 498 (1340); and Avignon, Bibl. Mun. 1086 (1343). I am not sure you would want these, however, as they will look something like this $URL$ I.e. not just in Latin but in a written form of Latin which is difficult to read without training. I hope that helps. Personally I would stick to the published translations in English – see below. Note that the whole work has never been fully translated into English, Ockham’s own language. Loux, Michael J. 1974. Ockham's Theory of Terms: Part I of the Summa Logicae. Notre Dame, Ind.: University of Notre Dame Press. Complete Translation. Freddoso, Alfred J., and Schuurman, Henry, trans. 1980. Ockham's Theory of Propositions: Part II of the Summa logicae. Notre Dame, Ind.: University of Notre Dame Press. Longeway, John Lee (2007), Demonstration and Scientific Knowledge in William of Ockham, University of Notre Dame Press, Notre Dame, IN. A translation of Summa Logicae III-II: De Syllogismo Demonstrativo, with selections from the Prologue to the Ordinatio. 

Well for one a being could have a non-physical existance and yet not even be in your mind. Your knowledge of that being may have no effect on it at all. Indeed even you knowledge may have no impact. Where a being that only exists in your mind relies on your mind for its existance. You have the power to completely shape and create its world. In a way you are its god. And if you do not retain a long term memory of it, or transfer that creature out of your mind in some way, then it is completely and utterly destroyed once you stop thinking about it. To the being it does not matter wether you can tell that it is real or imagined. It will either persist when you cease to think of it or it will not. This will happen wether you can tell the difference or not. Your knowledge only matters to you. 

Obviously you can't differentiate things that do not exist, given that there is nothing to differentiate. However you can differentiate descriptions. (1) "Ectoplasm" was supposed to be a substance or spiritual energy "exteriorized" by mediums. (2) "Phlogiston" was supposed to be a fire-like element called phlogiston, contained within combustible bodies and released during combustion, which has negative weight. Clearly if there were such things as ectoplasm and phlogiston, we could differentiate them. There aren't, but we can still differentiate their descriptions. 

"there are no facts, its our perception" is a very strange claim. For a start, is this claim a fact? If it is a fact, i.e. if it is true, then there are no facts. But if it is a fact, then there is at least one fact, namely this one, so it is not true to say 'there are no facts'. So it is not a fact. Generally, it's a logical fallacy to argue from (1) S perceives (or thinks, or believes) that p to (2) It is the case that p The truth or falsity of a belief report is nearly always logically independent of the truth or falsity of the reported belief. Note, however, that if we say 'S knows that p' then it does logically follow that p. However, this is in virtue of the meaning of the word 'know'. 

If it were written in a language not known by man on Earth but was easily comprehended despite not knowing or understanding the language by all. Such comprehension would be universal and the understanding of it consistant. The content should be such that it advances concepts previously unknown as any creation of an all powerful being is going to be for a purpose. Any demand that people not seek to understand or clarify would tend to steal credence for such demands are clearly signs of insecurity not of a creation of an all powerful being. 

Just because the Universe has a beginning does not mean that there had to be a god to create it. There could have been a cause that was not God. Perhaps there was a Universe that Predated our that no longer exists but was the roots of the creation of our universe. As we have no data upon which to evaluate this universe or any other competing or complementing universes there is no reason to think that the laws of this universe were identical or even similar to those of any previous universe. 

Many in the Frankfurt School, notably Adorno and Horkheimer, regarded rationality with criticism as, in their view, led to dehumanization and enslavement. But what did they offer as an alternative principle or ethos in guiding personal or social heuristics? I assume not religion/god, as they were mostly Marxist. 

I am looking for reference recommendation on the subject of analyzing responsibility in victim situations. I am curious which philosophers have written on that subject, ranging in scope from individual crimes all the way up to war crimes and genocide. E.g., the modern prevailing narrative, at least here in the West, frequently discourages culpability analysis any deeper than blaming the carrier of the crime itself. To clarify, I am not looking for some vindication of victim blaming but that mainstream encouraged scope is shallow for my intellectual standards. For example, to which degree can the victim be, not held legally responsible, but to some degree morally accountable for not doing enough to prevent what happened to them? In a fair and balanced analysis of different concrete scenarios. So I'm not satisfied with the general sentiment that any further dissection of an incident beyond obviously blaming the final executor of the act is "victim blaming" and should be discouraged. Therefore, I would like to research philosophical treatises on how each and every one of us, and we as a collective, can do our best to prevent catastrophes by avoiding prior exposure to it. If an angry dog bites a person who foolishly tried to play with it, with him, the usual moral imperatives are to blame the dog owner, which is fair. But shouldn't we assign at least some responsibility to the bitten person for not being prudent enough not to play with a strange dog? Which philosophers have delved in this topic, especially in a dialectical format? I'm not looking to have a discussion whether my motivating premises are crazy or not -- simply for reference to philosophers and their works who worked on that subject. 

For ease of use lets use Ayn Rand for example. The way Ayn Rand went about gaining acceptance showed a perceived intentional disrespect of the Academic community. In this way her ideology was not adopted more because of reaction to the method in which it was introduced, I believe. Assuming that logic above to be correct; in other-words, don't argue about the contents of Rand's work for this exercise. For the practical application here I believe I may have done this. But my lack of knowledge on the base may be lacking. If I have a way that re-scoped Objectivism in a way that did show promise, how can i best approach those people to gain acceptance in the community? The people who work in the world of philosophy and have the knowledge to expand upon my ideas are unlikely to notice my tool. I want them to take my tool and build a spaceship(or other metaphorically complex engine of transition). If I am right, I want educated and learned professionals to want to read and talk about my ideas because it changed their world. I think I have the tool to do that, and I want to find a road map of how I can get my idea there the most efficient way possible. So what is the most efficient path that a brilliant, but undereducated and incredibly modest thinker could take to get their ideas accepted. Caveat: For this question please assume my idea is everything I am saying, even though I am probably wrong. How can we get our ideas recognized and into mainstream, even if it means I lose any credit. To restate differently (feel free to edit to make this question more concise) How can I break it at a ground floor level and carry my idea to the levels that matter? 

"In fieri" (in becoming) was a phrase frequently used by the scholastic philosophers. E.g. here. "He [Aristotle] says that all of the foregoing senses have something in common inasmuch as that is said to be a principle which comes first (1) either with reference to a thing’s being (as the first part of a thing is said to be a principle) or (2) with reference to its coming to be [in fieri] (as the first mover is said to be a principle) or with reference to the knowing of it". 

Many of the thirteenth century scholastic philosophers and logicians developed interesting and original theories of modal logic, based on Aristotle’s account in the Prior Analytics. The analytics was unknown in the West until the middle of the 12th century, and serious work did not begin until the 13th century. Notable commentaries were by Robert Kilwardby (d.1279) and William of Ockham (1288-1347). Simo Knuuttila’s article in the SEP may be helpful $URL$ The arabic philosophers also had theories of modal logic, but I am not an expert. 

The brain develops in a fairly understood manner. At an early age children begin to reason that if they do not see it, then it does not exist. By 7 they can begin understand the concepts that object can be hidden behind each other, and by 10 should understand that the world outside of what they see and hear still goes on. But until their mind is able to comprehend that, they simply are not able to understand. I am sure that there is research into when a childs brain develops to understand the inputs of their taste buds. I would guess it is around 6 months as that is when I have observed babies begin to make faces at certian foods. But untl their brain can process the input from their taste buds, they are not going to get pleasure or pain from the taste of the milk. And Freud did not understand the actual physiological part of the development of the brain. While he had many contributions to psychology, today he would be considered worse than a quack. Today we have a much better understanding of the development of the human brain. And our memory creation at an early age is not suppressed, its just that what is memorable to a 1 or 2 year old is pretty mundane in just a few years. But young children (~6months+) do recognize people they come in contact with regularly. This shows some memory retention already.