If you are running a 3 or more node cluster with cman/corosync and you have some sort of shared block storage (SAN) connected only to some nodes in the cluster how can you enable CLVM on that storage device? In my example I'm running a 3 node cluster, there 2 nodes are "main workload" and 1 node are used for backups & archives. Main nodes are connected with FC HBA with multipath to a SAN. Everything works fine, I was able to initialize PV on that device and can see it on both nodes: 

As I can see now, from your detailed update, most likely it seems that you don't have those IP's assigned on your local network interface. You've only added 111.222.62.130 on your server. In order for linux S(ource)NAT to work, you must have every IP address you're NAT'ing to (--to-source) to be actually added on your network interface. Check on how to assign additional IPs to an interface. You must issue for every IP you want to have SNAT working for. It will be convenient to write a script to fill those values. Be aware, that once you'll add those IPs on your local interface, you will "expose" your server via them to the Internet. You might use iptables INPUT table to block unwanted local connections to those IPs. By local I mean only to your server. Those coming through NAT are subject to FORWARD table only. PS: If that it's not the case, also please check and post your . 

I created a ZFS pool on Ubuntu 14.04 without specifiying RAID or redundancy options, wrote some data to it, rebooted the machine and the pool is no longer available (UNAVAIL). I don't have the exact error to hand but it mentioned that there was not sufficient replication available. I created two datastores in the pool which consists of 2 3TB disks. ZFS was recommended to me for its deduplication abilities and I'm not concerned with redundancy at this point. I actually only want RAID0 so no mirroring or redundancy in the short term. Is there a way to do this with ZFS or would I be better off with LVM? 

But if I connect from NodeBB running on port 4567 via an importer plugin I get an access denied error: 

Limiting the ciphersuites is not the right method, as they could be negotiated by SSLv3 client as well, which will result in SSLv3. The best way is to follow the article Robert pointed to ($URL$ and set the proper registry keys. Anything other than that is prone to errors. 

The following two links have some detailed information on the SupportedEncryptionTypes configuration for Kerberos: $URL$ $URL$ In general, you need to have common algorithm between the KDC and your Windows machines. If you are running more recent version of MIT Kerberos, you should have AES support, but if your KDC is older one, you would need to use DES to interop. @tommed is correct that DES is disabled by default in Win7, but it should work fine on Vista. Alternatively, capture the network traffic between the KDC and your client machine and look at what the client is offering and look at the KDC config to ensure you have at least one of the crypto algorithms in common. 

Probably the best practice (if possible) would be to move your service from "Alpha" to another, separate network. And put 2 firewalls between this and Alpha & Gamma. This is a concept similar to DMZ. Consider a worst case scenario - what if your service gets compromised? That way a malicious user from Gamma network gained access to your whole Alpha network if you have service there. Even if you proxy it via HAProxy, he can still execute arbitrary commands on your server on Alpha network via HTTP(S) doorway. If you put the service in separate network even if it's compromised he still needs to penetrate your firewalls to reach other services. 

If you are getting a client certificate error, then you should look on the client side. Make sure your client has all the intermediate certificates in the chain present and is sending it to the server. If the server has no other network connectivity, ensure that the intermediates are also present on the server side, so it can build and validate the client certificate chain. I would suggest using Wireshark or other network tracing tool to capture the traffic and look at what is going on. If the client authentication is done through renegotiation (aka second handshake encrypted using the existing session), then look at the size the messages to judge whether the entire client chain is being sent over or just part of it. 

I want to enable rewrite logging so that I can debug a rewrite rule but adding the RewriteLog directives is causing a 500 error. Version information: 

I have a nodeBB install which relies on Redis as the data store. Its just a test install at the moment while I iron out any problems. The Redis instance stayed up for a few days but then fell over with the following errors in the logs: 

I have tried numerous methods to generate a password (e.g apache's ) but I am not able to log in at /Docs with the username and password specified in .htpasswd. I see the authentication dialog with 'Restricted Area' but the password is not accepted. I've tried the methods here: 

You will need to disable PCT 1.0 as well as SSLv2, as it is no longer used. If you follow the MS KB, then you should be fine. You can use ssllabs.com to test your server if it is reachable over the Internet. Also you could use the G-SEC tool for configuring SSL/TLS on Windows. 

SSL as already people pointed out is a protocol designed by Netscape in the past. At some point the IETF standards body decided to adopt the SSLv3 protocol as a standard one, so it got change very subtly and it was named TLSv1.0. So for most people, TLSv1.0 is almost equivalent to SSLv3. The reason people still call the family of protocols SSL is because of historical reasons - everyone is used to the name, so they keep on using it. It is quite possible for the VPN to be using TLS under the cover, but the marketing name still stays as SSL VPN. Since TLSv1.0, there have been two revisions of the standard and it is now at TLSv1.2, which while still compatible, has some significant changes. Because of the SSL/TLS design, both client and server can negotiate which version of the protocol they want to use, so clients using TLSv1.0 can still talk to servers implementing TLSv1.2 and vice versa. Considering the interoperability between all the versions of the protocol, there is no "making a switch", since they are the same family. It is a question of "do I need to use newer version?". As with any other area, the answer to this question will depend on whether the current version you are using has any limitations or not. Currently there are no problems with using SSLv3, but the majority of clients and servers out there work with TLSv1.0. I hope this clarifies the picture a bit. If not, let me know what is still confusing I will try to explain further. 

I don't really understand if you need to connect to 1.2.3.4 via VPN or directly. If you need to connect via VPN when I'm afraid it might be not possible if you don't have access to configure the VPN server and/or 1.2.3.4 server. Because you need to set up the reverse routing for this to work. Both VPN and 1.2.3.4 server need to know how to reach you back through VPN link. If your routes aren't symmetric most likely the packets are lost, because 1.2.3.4 doesn't knows how to route to 10.10.10.0/24 network. But if you are fine with direct connection (without VPN and encryption) to 1.2.3.4 you can add a route to connect directly via your Internet connection without VPN. Make sure to record your default gateway before connecting to VPN with command. Like this for example: 

You are correct that the Microsoft implementation does not include TLS-PSK. I am not aware of any way to accomplish this, since IIS relies on Schannel. Schannel has a pluggable model, but it is only for cryptographic functions. That does not allow introducing new handshaking mechanisms. 

You don't have a server certificate to use with LDAP. This is exactly what the event log is telling you. Installing Certificate Service will not create a certificate for you, this is an explicit step you need to do. How to get a certificate for your LDAP server will depend on whether you plan to deploy your own PKI (using Certificate Services) or just use a 3rd party certificate. If you are not familiar with this, you need to do some research and pick which way to go. The former is harder and more error prone, but most flexibe and the latter is easy to get going but not very flexible. 

Can anyone suggest what would be causing this and how best to resolve the issue? Where will Redis try and save temp files, which user would it use and which permissions would safely resolve this? Also of interest would be a free method of monitoring the Redis instance so I know if / when it falls over. 6359.conf: 

Is this because all requests containing in the name are passed to fcgi and so all rewrite rules are ignored? 

Turns out this was caused by a Squid caching proxy which was not passing authentication headers correctly. This was proved by running something similar to the following: 

Is it possible to set timeout directives within a location block to prevent nginx returning a 504 from a long running PHP script (PHP-FPM)? 

Most likely not, if your certificate is not wildcard one (has * in the host name). I assume your hosts are actually named differently, right? The only way I can think of will be able to use it is to terminate TLS on a load balancer put in front of the multiple sendmail hosts. Of course all of the above is predicated on the clients doing real verification on the certificate. If they ignore the name mismatch issue, then you can use it without a problem, but it will get you no real security, as MiTM can intercept such connections. 

You are listing a .csr file for SSLCertificateFile. .csr files usually contain the Certificate Signing Request, which is not your certificate. You likely have a .crt file which you need to put in that directive.