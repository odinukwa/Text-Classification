I'd like to follow-up on Hume's "complex of ideas" suggestion in @don-joe 's answer, and instead suggest Carnap's idea that "An 'object' is anything about which a 'statement' can be made", from the first page of his Aufbau. Then, depending on (your definition of) 'statement', an 'object' can be pretty much anything, including abstractions like love,hate,joy,sorrow,freedom.etc. But 'statement' is frequently taken as 'empirical statement', in which case your domain of discourse is constrained to more 'concrete objects'. So concrete is what I think the op's suggesting. But, a la Carnap, neither mathematics nor any discipline is necessarily constrained to such concrete objects. Mathematical axioms are frequently inspired by empirical observations, but also frequently inspired by more "abstract mathematical elegance" (or whatever you want to call it). And the latter kinds of axiomatizations give rise to more abstract kinds of objects. 

Maybe you have something in mind along the lines of Heyting semantics, e.g., $URL$ The aim, briefly, is to model not the denotations of statements, but their proofs, i.e., meaning=proofs. Then a proof of proposition P would simultaneously be a proof of .not.(opposite-P) And since, a la Heyting, meaning=proofs, P and opposite-P mean the same thing. There are a few unmentioned subtleties, e.g., incompleteness, whereby the fact that I can construct a proof of P doesn't necesarily mean I can construct a corresponding proof of .not.(opposite-P), i.e., even though it's true, I may not be able to prove it. Both-way-proofs correspond to what's called "recursive", one-way to "recursively enumerable". So I could have a P-proof but not a corresponding .not.(opposite-P)-proof. And then they wouldn't be "equal". 

Grant proposals frequently explicitly discuss "future research" (as suggested by DanielGoldman's answer). Is some such proposal where you read the phrase that prompted your question? Proposals will typically discuss in exhaustive detail (including personnel, equipment,etc) the research to be conducted and funded by the grant. And there's typically also a "future research" section, describing further research that may be proposed depending on the outcome(s) of the current research. That is, the full research programme is decomposed into several investigations. Moreover, the scope of that full programme can't be entirely known or understood beforehand. So the scope evolves as results from earlier investigations help to more clearly define the overall direction of the subsequent research. Nobody's suggesting they know anything about the future. Quite the opposite, "future research" is typically humbly suggesting ignorance about the outcome(s) of the immediately-funded investigation. But evaluating the current grant proposal also typically involves evaluating the principalÂ investigator's plans for follow-up research. So he has to submit some kind of "future research" ideas along with his current proposal. 

As you say in your preceding comment above, "because it works" is the sine qua non for scientific explanation (or, for that matter, for any conjectures that purport to be "explanations"). Beyond that, Occam's razor, whereby reductionism comprises the least complex scientific conjectures that "work". Moreover, reductionism is the only approach that works. Can you suggest any other? In the extreme, you could individually describe every observable phenomenon in complete detail. But that's just a description, not an explanation. Indeed, an explanation has to be simpler than a straightforward description of the phenomena it purports to explain. If not, what do you mean by "explanation"? And if explanations must be simpler, then why wouldn't even simpler be better, and simplest best? And that's all reductionism is saying, simpler=better. Maybe you can argue that's just a human intellectual bias, but then you still have to suggest an alternative definition of "explanation", and then come up with explanations that actually "work". Offhand, I see no reasonable way to do either, much less both. 

I'm not familiar with that quote or its context, but I'd be pretty sure Einstein didn't say that, per se. What he might have said (or have meant when expanded in more detail) is that the theory tells you what kind of preparation and test apparatus you can construct corresponding to the axiomatic elements of the theory, how to operate those apparatus, and then how to interpret the measurement outcomes resulting from their observed behavior. But not simply that the theory tells what you can observe, period. Heck, you can throw a tennis ball into the Large Hadron Collider and observe it bouncing around. But a theory's going to instead suggest you operate it by ionizing a puff of hydrogen, (pre-)accelerating the protons to a few MeV, injecting that beam into the LHC rather than some tennis balls, etc. So, no, I don't think you can interpret whatever it is Einstein actually said/meant the way you're trying to. But more generally, whether the world is compositional (whole made from parts) or decompositional (vice versa) might be an open question. 

At this time, nobody can say for sure what the physics/math difference is. That is, to what extent the foundational elements of physics can be entirely generated from purely logical/mathematical considerations, and to what (if any) extent there's an irreducible kernel of ad hoc empirical fact that has to be axiomatically introduced. So, you don't say exactly what your "investigating dimensionless physical constants" consists of. But your question strongly suggests you're trying to establish a mathematical relation between (some of) them that reduces (if not eliminates) the empirical input necessary to describe nature (e.g., gravity related to electromagnetism). That's not a new idea, e.g., Dirac's Large Number Hypothesis, $URL$ And Dirac's idea hasn't "been receiving lots of criticism", though it's never received lots of active investigation, either. So, describe exactly what you're doing, and perhaps its deserved or not-deserved criticism will be more apparent. 

Arguably "yes", there's a limit, as follows, based on two pretty reasonable premises. First, every (written) language consists of finite sequences of symbols taken from a finite alphabet, so every language contains at most a countably infinite number of wff's. Second, and maybe a bit shakier, suppose your semantic domain of "all knowledge" (whatever that is) is uncountable. Then all semantic functions mapping language syntax to domain semantics will be "into", but none can be "onto". Indeed, countable subsets of an uncountable set have "measure zero", e.g., like the rationals comprise only an infinitesimally small "amount" of all reals. So Wittgenstein's limit is rigorously correct -- any language comprised of sequences of symbols is very limited in the domains of knowledge it can completely represent. 

I believe (by which I mean 'think') your "common God perception" refers to macroscopic activities, i.e., good/evil/etc don't apply to individual atoms, per se. And, for example, the microscopic randomness of molecular motions/transitions/whatever doesn't affect the completely deterministic nature of thermodynamics, which describes the statistically-mechanically-averaged behavior of ginormous ensembles of such individually-random molecules. The probability that all the air molecules in your room will suddenly and randomly migrate to the half of the room you're not in, leaving you to suffocate in a vacuum, is ... zero. Likewise, the ginormous number of molecules in a single eukaryotic cell, like a neuron in your brain, completely overwhelms (like zillions of times overwhelms) any underlying molecular randomness. So your good/evil/etc intentions/decisions/actions/whatever can't be attributed to that kind of randomness. (Those Deepak-Chopra-like discussions conflating "quantum mechanics" and "brains" are utter foolishness, except that maybe he makes some money off of the utter fools who listen to that kind of cr*p. Don't drink the quantum Kool-Aid.) Nevertheless, there's still plenty of room for non-random/intentional free will, which I guess "common God perception" requires. But it has nothing to do with quantum randomness; rather, it arises from the fact that deterministic laws can still lead to unpredictable behavior due to emergent chaos (e.g., $URL$ And that kind of unpredictable-yet-deterministic chaotic behavior can emerge from extremely simple systems, much less brain complexity which is pretty much beyond any sensible comprehension. So quantum randomness doesn't "contradict common God perception" on the one hand, by preventing the formation of non-random personal intentions/actions/etc; and determinism doesn't contradict it on the other hand, by pre-determining them all. Common sense, however, may or may not contradict it, depending on your point of view.