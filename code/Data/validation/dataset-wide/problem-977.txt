The answer to most of your questions is: it depends. Is amplitude good for mapping channels? Amplitude maps can be great for finding and interpreting channel systems. It depends on the geology and on the seismic data's characteristics. Sometimes you can just see the channels, which might be qualitatively useful, and sometimes you can infer quantitative information, such as width, thickness, composition, porosity, or fluid content. It depends. Here's a workflow for any kind of attribute analysis. I'll try to add to it in the next day or two. When should I use RMS amplitude? Before confusing yourself with what others do (they are not necessarily a good guide), it's worth reading about different kinds of average. The main feature of the RMS average, for geophysicists anyway, is that it works on zero-mean data like seismic: 

This is not to say that things don't hit earth — they do, all the time. Just look at this map of recorded bolides over a recent 20 year period (Planetary Science, NASA, via Universe Today): 

References Machol, J. L., J. C. Green, R. J. Redmon, R. A. Viereck, and P. T. Newell (2012), Evaluation of OVATION Prime as a forecast model for visible aurorae, Space Weather, 10, S03005, doi:10.1029/2011SW000746. Newell, P. T., T. Sotirelis, and S. Wing (2010a), Seasonal variations in diffuse, monoenergetic, and broadband aurora, J. Geophys. Res., 115, A03216, doi:10.1029/2009JA014805. 

References Chao, Benjamin Fong, Richard S. Gross, Yan-Ben Han (1996). Seismic excitation of the polar motion, 1977–1993. Pure and Applied Geophysics, September 1996, Volume 146, Issue 3, pp 407-419. DOI 10.1007/BF00874727 Update: This article on some new research in this field is worth a read. 

Note that some properties, such as velocity, are scale-dependent. Be careful how you upscale them. Read up on Backus averaging, starting with Chris Liner's recent work. † How's that for a geoscientists's answer? 

In Scotland, the Caledonian Forest has been cut down by humans. According to an unsourced Wikipedia article the tree line in Scotland is at 500 metre (it does not indicate the tree line elevation difference between southeast and northwest Scotland, which should be considerable). That means considerable areas are naturally bare, and therefore arguably less unnatural than the areas where forests have been cleared. When I pass through Scotland, is there a way to tell whether the spot I stand on had a forest before that was cleared, or that it is a naturally bare area? 

A controlling factor is a factor that acts as a cause for others. A reactive factor is rather the consequence: that which reacts to the controlling factor. For example, the Sun is certainly a controlling factor. Nothing we do influences what happens on the Sun, but what happens on the Sun certainly influences us very strongly. Fortunately, its total power output is quite stable so as far as climate is concerned, we don't need to worry about it too much as far as the next couple of million years are concerned (although eventually, in hundreds of millions to billions of years, increasing power from the Sun will render the Earth uninhabitable). CO₂ is both a controlling and a reactive factor. We add CO₂ to the atmosphere, so the CO₂ concentration reacts to our emissions (reactive factor). But CO₂ levels are also a cause. If you were to make a simple climate model, you would put in the CO₂ concentration as a fixed value or perhaps an increasing value as a function of time: in such a model, it would be a boundary condition. If you instead made a model of a single factory or car and modelled how changes in the fuel cycle would affect CO₂ emissions, then those would instead be a reactive factor. It all depends on the context. For H₂O, however, it makes no sense to put in a fixed version as a boundary condition. Its concentration varies rapidly on short timescales: today may be dry and tomorrow a wet airmass may get in. Of course, physically, H₂O causes even more of the greenhouse effect than CO₂, but the increase of H₂O is not what is causing anthropogenic climate change; if anything, an increase in H₂O is one of the effects. So, think of it as a system: you add CO₂ (cause), many things happen, including an increase in H₂O in some places (effect). The cause is the controlling factor. The effect is the reactive factor, even though physically, both CO₂ and H₂O are strongly contributing greenhouse gases. 

One might expect that a large explosion could cause an earthquake, but there's no real evidence for that either. Here are Goldblatt & Cox (1988, Oxford) in Nuclear Weapon Tests: Prohibition or Limitation? 

It's not a healthy distinction, but in petroleum geoscience one can characterize the distinction around the sort of data people look at. Geophysicists are into seismic, sonic logs, gravity and magnetics data, electromagnetic (resistivity) data,... and anything to do with computers. Geologists meanwhile are into core, outcrop, gamma-ray and density logs, stratigraphy, tectonic reconstructions,... and anything to do with coloured pencils. Of course, they're both working towards the same thing: a model of the earth and its history. Your question also made me think of a couple of Twitter conversations, both started by Chris Rowan at Kent State: 

Yes, there are lots of other factors. Factors affecting sea levels are no different from other natural processes: there is a large number of coupled, non-linear effects, operating on every time scale, and at every length scale, and across many orders of magnitude. The Wikipedia page Current sea level rise lists many of the known processes. And I wrote a blog post, Scales of sea-level change, a couple of years ago with a long list, mostly drawn from Emery & Aubrey (1991). Here's the table from it: 

According to the International Commission on Stratigraphy (Cohen et al. 2013), this puts them firmly in the Eoarchaean era. References Cohen, K, et al. (2013). The ICS International Chronostratigraphic Chart. Episodes Journal of International Geoscience 36 (3). Link to PDF. Moorbath, S (2009). The discovery of the Earth's oldest rocks. Notes and Records 63 (4). DOI: 10.1098/rsnr.2009.0004 

Sound-like waves are routinely used to image the subsurface, but mostly well below the ultra-sound band. Several methods involve sound-like vibrations: 

What is a breadboard (retrieval) algorithm? Google Search yields precious few results, mostly from ESA. Another usage I found Albert, Preusker, and Fischer (2012), ENVISAT workshop: 

Does that mean we can say nothing? Well, it's not quite so pessimistic. There are many attempts to answer this question. The figure below shows estimates for the regional distribution of the shortwave and longwave cloud radiative effect, again from AR5 WG1: 

You can use simple logarithms to calculate the answer. The number of half-lives that have elapsed can be calculated with $$ - \frac{\log{f}}{\log{2}} $$ where $f$ is the fraction that remains. So plugging in the numbers gives $$ - \frac{\log(0.75)}{\log(2)} = 0.415 = 41.5\% $$ 

Clive D. Rodgers, Inverse methods for atmospheric sounding, Theory and Practice. ©2000 World Scientific Publishing Co., London, UK. 

A common layman explanation for why does it get colder to higher elevations (considering only the troposphere here) qualitatively boils down to The Sun heats the Earth's surface and the Earth's surface heats the atmosphere. I remember that, every time I heard or read this explanation as a child, I thought: then why is the Tibetan plateau still colder than lowlands at the same latitude? After all, the solar energy reaching the surface in Tibet is no less. Clearly there is more to it. Considering a remark from a quantum physics lecturer that you only really understand something after you've taught the subject twice, I'm phrasing my question as such: How does one explain, in layman terms, why the Tibetan plateau is colder than lowlands at similar latitudes? 

(I had the opposite problem, needing skin temperature, and being tempted to use 2 metre temperature instead, until I realised where the data were). If you encounter a model that really only has the full temperature profile, then I would contact the authors to inquire. Maybe it is a model that really only does well in the free atmosphere, and is not suitable for the extraction of (near-) surface temperatures. The boundary layer can be a hard thing to model! 

All of these logs are usually displayed on a linear scale. Indeed it wouldn't make sense to display them on a log scale, which is mainly for displaying resistivity logs, e.g. the induction log. Even if they were, it wouldn't make sense to show the usual 4 octaves (0.2 to 2000 for resistivity), given the range of the data and the scale of porosity values geologists are interested in. It's not clear if the data have actually been displayed on a log scale, or if it's just that the grid has been erroneously added. I would treat the data with suspicion. 

No, you can't stop an earthquake with a nuclear weapon. You can't even start one. You asked if you could "obliterate a plate" with a nuclear explosion. Definitely not. Plates are between about 10 and 100 km thick, and as you can see from this map, the earth's 15 large plates are very large indeed: 

So it's not really that "when using RMS amplitude one must integrate over a window", more that if you want to measure amplitude over a window, you must use RMS. Because the values are squared, RMS has two other features (or bugs, depending on your point of view): large values are emphasized, and noise may therefore be emphasized. An alternative is to use the envelope of the trace (sometimes also called 'energy' or 'absolute amplitude'), which is the magnitude of the Hilbert transform (also called 'complex trace'). It is always positive and has the added benefit of being phase-independent. Read more about envelope.. Which window to use? Let the expected geology and basic geophysics and statistics guide all of your decisions. Use a window that captures the interval of interest (look at the wells!) without too much non-interesting stratigraphy. But use a big enough window that you don't see a lot of artifacts from large amplitude values coming in and out of the window (this also depends on the quality of the horizons and smoothness of the geology). Windows don't have to be symmetrical about a horizon. It depends where the features you're interested in are. In my experience, stratigraphic windows are often useful — from one horizon to the next. If you're interested in the horizon itself, consider just using its amplitude directly. If it's too noisy, try improving the pick or smoothing the amplitude map, before confusing things by throwing more geology in there. What does that caption mean? Who knows what that caption means? Vague captions plague the geophysics literature. Don't be part of the problem! If only for the sake of your future self, record the exact statistic and its parameters on every image — even put it all in the filename. Remember what you're trying to do You're trying to relate the seismic to reservoir properties you care about. This means proving that the property is related to the seismic in as quantitative way as possible. A nice way to do this is to crossplot the property with the seismic attribute — that way you also know the error of the estimate. A map showing wiggly channels is interesting, but nowhere near enough. I tend not to believe attribute analyses that don't include a crossplot. 

Saturation vapour pressure of water. Source: Chemguide. See also the (not very good) Wikipedia article on Vapour pressure of water. 

(Source: NCEI) The detailed structure is somewhat different, which has to due with local climate and circulation, but the overall trend related to humidity and proximity to ocean shows up in both. We can also see the mountains, which I would guess to be a snow albedo feedback effect (ever notice how nights get colder when the ground is snow-covered?). At NCEI you will also find similar maps for the rest of the USA. 

Not a full answer as that is hard to give. But: This is a diagram by Kevin Trenberth picturing energy flows in the Earth climate system: 

Provide a monthly average in every grid cell, and describe how many measurements were used for each cell. There is no fixed rule for the minimum number of days for reporting a monthly average. A reasonable threshold will depend on the geophysical quantity of interest y, in particular on how much y varies on short and long timescales. If y varies from month to month, but does not vary a lot from day to day (example: sea surface temperature), you can probably get away with reporting a monthly average even when only one or two days have cloud-free measurements. On the other hand, if you're measuring precipitation, your signal will be relatively noisy even if you choose a threshold of 20 days. And any threshold is going to introduce a bias, because a lack of observation is typically due to clouds. Although you will get a bias in any case. In other words, if you only have one day per month you see a gap and in the clouds to observe whatever you want to know, it is a pity to throw it away. Therefore, personally I choose a minimum of 1 observation. Critically important though: when releasing the product, add a field that tells the user how many days worth of measurements make up the monthly average in any given cell! Like that, the user can decide which ones to use and which ones not to use. More broadly speaking: producers should document everything they do. For your specific examples: search for the ATBD and/or scientific papers describing the product. Hopefully, there is a field in the level-3 product that describes the number of measurements per cell. If the answer is not in there, write to the producers and tell them to redo the product... You will need this information to accurately calculate a yearly average! 

The boulder is a sculpture; the rock type is almost certainly conglomerate, a kind of sedimentary rock. Quoting here from an article about a geology walk, by Jean Gardner, in the winter 2014 newsletter of the Hertfordshire Geological Society: 

It is cristobalite, the main alteration product of obsidian. Obsidian, a siliceous glass, is only metastable — all known obsidian is younger than the Cretaceous. Over time, it devitrifies, forming cristobalite, a polymorph of silica. So there's no change in chemistry, just in the arrangement of atoms in the mineral. It's not an overgrowth or a deposition. Quoting Jim Miller at Oregon State: 

It's in the Aki–Richards equation This is the formulation from Avseth et al. (2006): $$ R(\theta) = \frac{1}{2} \frac{\Delta \rho}{\rho} - 2 \left( \! \frac{V_\mathrm{S}}{V_\mathrm{P1}} \! \right)^2 \frac{\Delta \rho}{\rho} \sin^2 \theta + \frac{1}{2} \frac{\Delta V^2_\mathrm{P}}{V^2_\mathrm{P}} \frac{1}{\cos^2 \theta_\mathrm{avg}} - 4 \left( \! \frac{V_\mathrm{S}}{V_\mathrm{P1}} \! \right)^2 \frac{\Delta V^2_\mathrm{S}}{V^2_\mathrm{S}} \sin^2 \theta $$ Refer to the book or SubSurfWiki for the symbol definitions etc. Hmm, none of these are reasons why $V_\text{P}/V_\text{S}$ prevails. This is starting to look like the $\pi$ vs $\tau$ debate... References 

As shown in the figure, GPS uses the World Geodetic System of 1984 for its measurements, so elevation is measured against its ellipsoid. So one must correct GPS elevations to this orthometric height (height above the geoid). If you want to read more, this tutorial on datums from NOAA is pretty fantastic. And here's a nice piece on the height of Everest, with respect to various datums. Image: Judson L. Ahern, University of Oklahoma, via Federal Geographic Data Committee. 

The area is experiencing post-glacial isostatic rebound. Much of Canada was covered in an extensive ice sheet in the last glacial period (the 'Ice Age'), from about 110 ka until 12 ka. The ice in the Hudson Bay area was among the last to melt: