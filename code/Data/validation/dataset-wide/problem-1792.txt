This is a warning, not an error. That's why it was prefaced with in the log. It means that the size of the uploaded file was larger than the in-memory buffer reserved for uploads. The directive controls the size of that buffer. If you can afford to have 1GB of RAM always reserved for the occasional file upload, then that's fine. It's a performance optimization to buffer the upload in RAM rather than in a temporary file on disk, though with such large uploads a couple of extra seconds probably doesn't matter much. If most of your uploads are small, then it's probably a waste. In the end, only you can really make the decision as to what the appropriate size is. 

You clean up the unprocessed orphan inode list by unmounting and remounting the filesystem. An extended discussion from the linux-ext4 mailing list has more information about what this message is and why it may appear. In short, one of two things has happened: Either you've run into a kernel bug, or much more likely, some filesystem corruption happened one of the previous times you remounted the filesystem readonly. Which is probably why the system thinks something is still using the filesystem when there isn't. If it's been a year and you still haven't rebooted the machine, just give up and schedule a maintenance window. 

This is how I would have gone about it: First, suppress ARP completely while the interface is being brought up. Then re-enable it after the interface is up. (You must re-enable ARP or the machine will not be able to communicate at all.) To suppress ARP during interface initialization, add to . This actually disables ARP at the kernel level, which should make any attempts to use fail. 

Notably, it doesn't try to do this to the LVM LV when the system is booting, but only when I take a snapshot. What is going on here? I really don't want device-mapper inspecting the contents of LVM snapshots to see if there's anything within them it can unhelpfully map for me. Can I suppress this behavior? Or do I need to create the snapshot via some other method? 

You don't need a "static" IP address to implement SSL; you do need a name in the DNS, for which the SSL certificate will be issued. The typical solution to this is to create a name in the DNS and then make it a CNAME for the DNS name given for the Elastic Load Balancer. 

The man page also states that you can add this into or as an option in (which may be overwritten by system tools, so you should avoid altering it when you can). Unfortunately the version of pam_pwquality shipped by Red Hat in EL 7 doesn't support the option. So your only real solution is to not use pam_pwquality at all. Note that commenting this out will also disable all of the other checks it performs, such as minimum password length and character complexity. 

Which just redirects back to the same URL. When you remove that, you should be fine. The redirect should only be in the block serving http on port 80, not in the block serving https on port 443. 

Later (post-RHEL 7) versions of firewalld do include a way to save the running configuration, and this is available now in Fedora and in RHEL 7.1. In this case the command is simply: 

It looks like a previous package update was interrupted. You should use to finish it, before attempting to do anything else. If that fails, you can try repairing things manually by removing the database entry for the partially updated package, then updating again. 

It looks like you actually are using firewalld. In this case is ignored, and firewalld is configured using . Just telling firewalld to add the services you want should be sufficient. 

The vast majority of things in the RHEL documentation will apply to CentOS without change. The main things that need adjustment are those that have to do with licensing and subscription, such as: 

You installed PHP from the remi repository, but you disabled the repository. So yum can't install additional packages from it. To resolve the problem, re-enable the remi repository. 

Virtual machines created on Hyper-V these days are almost always Generation 2 virtual machines. These boot with UEFI. In order to boot the VM on a different hypervisor, you must configure it to boot with UEFI. For instance, using virt-manager you would set UEFI (and Q35 chipset) while importing the virtual machine image. 

Block outgoing port 25 at your egress, except for traffic to/from your own mailserver, and business customers who request it to be unblocked. Then require customers to relay all their mail through it. 

By default (on Linux) the second directive binds to both IPv4 and IPv6, unless you explicitly request that it bind only to IPv6 with the option. There are two ways you can resolve this. Choose one (but not both): 

You appear to be running a Red Hat Software Collection. These are specially built software packages which exist outside the standard system and thus require special commands to use. For instance, the updated package's init script will be prefixed with the software collection's name: 

Sounds like you are on an OpenVZ based VPS. You cannot install modules on such a VPS. You have two options: 

HTTPS requests, which squid simply passes on to the remote site. Requests for ads, where it seems that the URLs are customized for each user. 

Did you check the permissions of all of the containing directories? One of those is likely where the trouble lies. 

This will give you the transaction ID, which you can then look up and find the dependencies which were installed, e.g. with . 

You need to include Google's SPF record in your own domain's SPF record, to indicate that Google's mail servers are valid senders for your domain. For instance: 

Did you run ? If was interrupted, it should have printed a warning telling you to do this. You should do so before attempting to do anything else. 

Which seems to argue against replacing existing moduli, though it doesn't really provide the actual reason for doing so. 

After the fragment reassembly timeout expires, the fragment is dropped; the other end would need to retransmit. This timeout is generally configurable. On Linux, it's 30 seconds by default and controlled via . 

There are none yet. Google has not yet expanded into Finland. When they do, the new region will be listed on their web site. 

The appliance is broken. RFC 5321 is crystal clear that after the DATA command all the state gets reset, regardless of whether the mail message was accepted or rejected. From section 4.1.1.4: 

Select a different port for the server, which is 1024 or higher. Run the server as the root user, e.g. with . (Not recommended) 

I wrote a simple script for this a long while back. It's less than perfect and has a few failure modes, but does well enough for casual inspection. I've never been bothered to improve it, but perhaps someone else will. 

You are trying to install the package, containing version 2.2 of Apache, but you already have , containing version 2.4 of Apache, installed. Before doing anything else, first decide which version you actually want. 

Unfortunately, you can't fully configure IPv6 (yet) from the installer or kickstart; you will need to make one change after installation. Edit the file and remove the line which was inserted by anaconda. Once you restart networking, () IPv6 will then be functional using the route advertised by OVH's on-link router(s). 

Actually that almost certainly is your problem. On a Linux system with PAM, attempting to login bypassing PAM is not guaranteed to work, and generally does not. Set and try again. 

libmcrypt is in the EPEL repository, which you don't seem to have installed. Install the EPEL repo and try again. 

It looks like you've taken some specific steps to harden OpenSSH. As a side effect of these changes, combined with running a relatively recent OpenSSH version, you will receive many more detailed log entries about connection failures. All of the preauth messages you are seeing fall into this category, and represent a client which failed to make a connection for some reason. For the most part, these connections fail before the client is able to attempt a username and password. The best thing to do with these log entries is to feed them to a log aggregator and make nice graphs for security researchers to look at. They do not need any individual human intervention. Of course, you should continue to intervene on messages which indicate a password was attempted and failed. Your existing tools such as fail2ban will serve you well here, though you'll find your ban lists far smaller than before, as most ssh brute force bots do not yet use modern crypto (which is the root cause of most of these messages). One other place where you may need to intervene is with authorized users who are no longer able to connect, because they are using old versions of ssh clients (e.g. an ancient version of PuTTY or FileZilla). Updating the client to the latest version fixes these issues. 

Your output shows that you don't have an SMTP server listening on ports 465 and 587. Reconfigure the SMTP server and try again. The same applies to your web server and port 443. 

If you shut down MySQL by killing it directly, then when systemd tries to run the script to stop MySQL, it returns failure because MySQL wasn't running. You can ignore this, but in normal circumstances you would never kill the MySQL process. You also would not use on a systemd-managed service. Use systemd to start and stop it instead. 

As far as I can tell from looking at the Apache source code, you can't do that with any Apache configuration option. You MUST send a Host: header matching what was sent via SNI for Apache to accept it. RFC 6066 section 11.1 specifies that web servers MUST check that the Host: header and host name sent via SNI match. As a practical matter, any software speaking HTTP that was produced in the last 15 years or so should be sending the Host: header with every request. If you actually have something that isn't, it's either too ancient to still be on the Internet, or broken. 

The problem with is that if you use one in a block (such as a ) then it overrides all of the higher-level statements. Therefore you have to repeat them all if you need to change even one of them. To get around this, you can make use of s, and put the headers which don't need to change at a lower level in an included file, then it in each . 

The easy way to do this is to run on your desktop and set it up with a remote ssh connection to the hypervisor, the server running your new virtual machine. The hard way to do this is by running on the server. This will give you VNC connection information. But, you may find this unusable as it may only be bound to 127.0.0.1, or firewalled. 

Yes, this is theoretically possible. There have been multiple proposals on how to locate HTTP sites with SRV records, the most well known of which is RFC 2782. Indeed, many other services already use SRV records in similar ways. An example SRV record that might locate an HTTP service for running on port 2673 might look like: 

This is supposed to be set to the name of the Datacenter object in vSphere. (And, as specified in the Ansible documentation, it should be set to if you're talking to a standalone ESXi host.) The minor problem is that you've used IP addresses rather than hostnames for connection information. What to do about this is obvious. 

Don't install the packages manually. You had to explicitly ignore a bunch of warnings telling you to not do what you just did or things would break, and that's why it isn't working. To fix the problem, follow the instructions to add dotdeb.org to your apt sources, and then use to install the desired packages. 

Next, it gets the actual uptime in seconds as reported by the kernel, and which would otherwise have been reported if you hadn't used . It then subtracts that number of seconds from the current time, rounding to the nearest second. Thus, if the system clock is adjusted, the output of will have a corresponding change. 

If you're writing your own NAT rules for your virtual machines, rather than allowing libvirt to manage them, then the virtual network to which the VMs are connected should be set up as a routed network, not a NAT network. You can fix this with and change: 

Don't. You could configure the guest to use a manually set IP address, but you can't be sure that it will work for every user, nor even for any of them. You can't predict what sort of network environment your appliance will be used in. It's even likely that most people who use your appliance won't use VirtualBox at all, since it's only suitable for consumer and (sometimes) developer use. 

The specification is needed to work around a bug in the EL5 backport where initcwnd would not be applied in all cases. (The bug is not present in the EL6 backport.) The example given is for WAN links; it should be much smaller (e.g. 100) for a LAN route. 

The utf8_german2_ci collation is only available in MySQL 5.6 or higher. Previous versions of MySQL do not contain it. 

Gives the user access to read files and traverse directories under , and applies the same ACL to any new files or directories created later. Once applied, user home directories no longer have to be world-executable, (e.g. ) thus users can no longer read each other's files, but nginx can. Note that if some directories need to be writable by the web server, you can set those up on a case by case basis by changing both instances of the permissions to . For example: 

Make a second and for the corresponding to . If that one is exceptionally large, though, you might have performance issues, and need to scrap this and do some scripting to obtain the redirect from a database. The s must be in your block, not within a block. If you are hosting multiple sites, the best place to put them, in my opinion, is immediately before the block that they correspond to.