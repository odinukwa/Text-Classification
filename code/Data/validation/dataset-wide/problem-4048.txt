Actually numerical computations show that if the sizes of the balls are comparable, namely, $\frac{1}{\ell} \leq \frac{r_{0}}{r_{1}} \leq \ell$ then the individual heat loss $Q_{j}$, $j=0,1$ is monotonically increasing, however, I was not able to prove this. Also based on numerical computations if $\frac{r_{0}}{r_{1}} > \ell$ then the nonzero distance that the big ball has to keep approximately equal to $r_{0}$. The heat loss of the small ball is always monotonically increasing. 

Here is an idea and I will leave details to you (it might be that I made a stupid mistake somewhere therefore these computations must be checked carefully). All functions below should be sufficiently nice so that all formulas make sense. First I will formulate a lemma. Lemma: Let $p>1$. If $\psi(0)=0, \psi' >0$ and $\psi(\infty)=\infty$ then for any $f\geq 0$ and any (nice) measures $d\mu(t)$ we have $$ \int_{0}^{\infty}\left(\int_{0}^{t}f(s)ds\right)^{p}d\mu(t)\leq \int_{0}^{\infty}f(y)^{p} \left[\frac{1}{(\psi'(y))^{p-1}}\int_{y}^{\infty}\psi^{p-1}(t)d\mu(t) \right]dy \quad (1) $$ Remarks: 1) We have a freedom of choosing $\psi$. One can optimize the quantity $\left[\frac{1}{(\psi'(y))^{p-1}}\int_{y}^{\infty}\psi^{p-1}(t)d\mu(t) \right]$ in the right hand side of (1) over all $\psi$ and find the best bounds (This becomes some ODE problem which should not be a difficult problem so that I will leave details to the readers). However, for our purposes we do not need to know the best $\psi$. One just needs to guess the right one to find some bound. Let me show you how it works on your example. In your case $d\mu(t)=e^{-t}dt$. Instead of $\psi$ take something like $\psi(t)=te^{\frac{t}{10(p-1)}}$. Then $\left[\frac{1}{(\psi'(y))^{p-1}}\int_{y}^{\infty}\psi^{p-1}(t)d\mu(t) \right] \leq C e^{-y}$. So the claim follows. Proof of Lemma: Let $\psi$ be a convex function, and let $w$ be some positive function (we will choose them later). Then Jensen's inequality together with Fubini's theorem implies: \begin{align*} &\int_{0}^{\infty} \varphi\left( \frac{1}{x}\int_{0}^{x} g(s)ds\right) w(x)dx\leq \int_{0}^{\infty}\frac{w(x)}{x}\int_{0}^{x}\varphi(g(s))dsdx=\\ &\int_{0}^{\infty} \varphi(g(s))\int_{s}^{\infty}\frac{w(x)}{x} dxds \end{align*} Let $\varphi=u^{p}$ and lets make a change of variables $s=\psi(y)$ and $x=\psi(t)$. Then the above inequality takes the form: \begin{align*} \int_{0}^{\infty} \left(\int_{0}^{t} g(\psi(y))\psi'(y) ds\right)^{p} \frac{w(\psi(t))}{\psi(t)^{p}}\psi'(t)dt\leq \int_{0}^{\infty} [g(\psi(y))\psi'(y)]^{p}\int_{y}^{\infty}\frac{w(\psi(t)) \psi'(t)}{\psi(t) (\psi'(y))^{p-1}} dtdy \end{align*} Now choose $g$ so that $g(\psi(y))\psi'(y)=f(y)$. And choose $\frac{w(\psi(t))}{\psi(t)^{p}}\psi'(t)dt = d\mu(t)$ (for example take $w(\psi(t))dt =\frac{\psi^{p}(t)d\mu(t)}{\psi'(t)}$ ). Then the lemma follows. 

The answer is No. If you consider only diagonal matrices then the question is equivalent to whether the function $B(x_{1},\ldots, x_{n})=\prod_{j=1}^{m}x_{j}^{-1}$ is convex function over $\mathbb{R}^{m}$ (for $1 \leq m \leq n-1$). For example the function $B(x,y)=\frac{1}{xy}$ is concave function in the domain $x \geq 0 $ and $y \leq 0$. However, the function $f$ might be convex for positive semidefinite matrices. 

This is a typical question about a convex envelope. I doubt that there is a nice answer for $M$ in high dimensions but let me tell you what that constant is going to be. Consider the function $B(x_{1},x_{2},\ldots, x_{n})=x_{1}^{1/p_{1}}x_{2}^{1/p_{2}}\cdots x_{n}^{1/p_{n}}$ on the parallelepiped $\Omega=[\ell_{1},r_{1}]\times [\ell_{2},r_{2}]\times\ldots\times[\ell_{n},r_{n}]$ such that $0<\ell_{i}\leq r_{i}$. Let $B^{convex}(x_{1},\ldots, x_{n})$ be a convex envelope of $B$ on $\Omega$. Since $B$ is a concave function the graph of $B^{convex}$ is the lower boundary of the convex hull of the points $(c_{i},B(c_{i}))$ where $c_{i}$ are the corners (extreme points) of the parallelepiped $\Omega$ (in total there are $2^{n}$ points). Then $M$ is the minimal number such that $M\cdot B^{convex} \geq B$ on $\Omega$. This follows from the observation that the the following function $$ H(u_{1},u_{2},\ldots,u_{n})=\inf_{f_{1},\ldots, f_{n}}\left\{\int_{0}^{1}B(f_{1}(x),\ldots, f_{n}(x)) dx, \; \int_{0}^{1} f_{i}=u_{i},\; \ell_{i}\leq f_{i}\leq r_{i}, \; i=1..n\right\} $$ is the maximal convex function on $\Omega$ with the obstacle $H\leq B$ on $\Omega$ (i.e., $H=B^{convex}$) Thus it follows that $$ M\cdot \int_{0}^{1}B(f_{1}(x),\ldots, f_{n}(x)) dx \geq M\cdot B^{convex}\left(\int_{0}^{1} f_{1},...,\int_{0}^{1} f_{n}\right) \geq B\left(\int_{0}^{1}f_{1},\ldots, \int_{0}^{1} f_{n}\right) $$ All these inequalities are sharp. In your case $A_{i} = \frac{r_{i}}{\ell_{i}}$.. 

This picture close to the boundary of $\Omega$ is true if the things are not degenerate (i.e., torsion of $\gamma$ does not vanish on any subinterval $I$) then the domains, where $B$ is linear, cannot touch $\partial\Omega$ on a thick interval. however they can touch $\partial \Omega$ at some finite number of points (or countable number of points if the torsion of $\gamma$ changes sign infinitely many times). In other words this means that the gradient of $B$ in $\Omega$ you can parametrize by one parameter $s$ i.e., $\nabla B = (t_{1}(s),t_{2}(s))$ where $s \in I$ So our equation $B_{1}f'_{1}+B_{2}f'_{2}=f'_{3}$ can be rewritten as follows $$ t_{1}(s)f'_{1}(s)+t_{2}(s)f'_{2}(s)=f'_{3}(s). $$ Of course this information is not enough to find $(t_{1}(s),t_{2}(s))$. But there is one more equation which you can also obtain, namely: $$ t_{1}'(s)\cos(\alpha(s))+t'_{2}(s)\sin(\alpha(s))=0, $$ where $(\cos(\alpha(s)),\sin(\alpha(s)))$ is the direction of the line segment starting at point $(f_{1}(s),f_{2}(s))$ i.e., unit vector, starting at point $(f_{1}(s),f_{2}(s))$ and going inside $\Omega$ along the line segment, along which $B$ is linear. These two equations $$ t_{1}(s)f'_{1}(s)+t_{2}(s)f'_{2}(s)=f'_{3}(s);\\ t_{1}'(s)\cos(\alpha(s))+t'_{2}(s)\sin(\alpha(s))=0, $$ allow you to find $(t_{1}(s),t_{2}(s))$ up to a constant $C$ which you still have to choose later in order to glue these local pieces and to get some global picture for $B$. Thus you find $B$ $$ B(x,y)=f_{3}(s)+t_{1}(s)(x-f_{1}(s))+t_{2}(s)(y-f_{2}(s)) \quad(*), $$ where $(x,y)$ belongs to the line segment starting at point $(f_{1}(s),f_{2}(s))$. For example if $\gamma(t)=(t,g(t),f(t))$ then $$ t_{2}(s)=C\exp\left(-\int_{s_{1}}^{s}\frac{g''(r)}{K(r)}\cos(\alpha(r))dr \right)+\frac{f''(r)}{g''(r)}-\int_{s_{1}}^{s}\left[ \frac{f''(y)}{g''(y)}\right]'\exp\left(-\int_{y}^{s}\frac{g''(r)}{K(r)}\cos(\alpha(r))dr \right)dy $$ where $K(s)=g'(s)\cos(\alpha(s))-\sin \alpha(s)$, and you can also notice that the expression $\left[ \frac{f''(y)}{g''(y)}\right]'$ coincides up to a curvature factor of $\gamma$ with the torsion of $\gamma$ which further plays a crucial role. By the way the equation $t_{1}'(s)\cos(\alpha(s))+t'_{2}(s)\sin(\alpha(s))$ also can be obtained by differentiating (*) with respect to $x$ and treating $s$ as a function of $s(x,y)$. Now there are lot of questions left: 

I will give partial answer in the following particular case: Assume you have only one closed space curve $\gamma(t)=(f_{1}(t),f_{2}(t),f_{3}(t)) \in C^{3}([0,1])$. Let $\tau$ be its torsion and let $k$ be its curvature. Assume that $k$ never vanishes, and $\tau$ is not identically zero on any subinterval of $[0,1]$. Assume also that the plane curve $(f_{1}(t),f_{2}(t))$ is convex. Let $n(\tau)$ be the number of sign changes of torsion $\tau$. Theorem If $n(\tau)\leq 4$ then $$ conv(\gamma)=\cup_{a,b\in \gamma}\{a\lambda+b(1-\lambda):0\leq \lambda \leq 1\}. $$ Remark: It is known fact that $n(\gamma)\geq 4$, therefore in the theorem one should think that $n(\gamma)=4$.The proof can be extracted from this paper, see Section 3 and 4. In fact, what you can actually extract is that \begin{align*} \partial[conv(\gamma)]=\cup_{a,b\in \gamma}\{a\lambda+b(1-\lambda):0\leq \lambda \leq 1\}. \end{align*} Here $\partial \Omega$ denotes boundary of the domain $\Omega$. Then it is not hard to show that this implies the theorem. I can sketch the idea: We are going to look to the boundary of $conv(\gamma)$. You can think that it has two boundaries: upper one and lower one. What does it mean? The upper one is a graph of a minimal concave function $B^{min}(x,y)$ defined in the plane domain bounded by $(f_{1}(t),f_{2}(t))$, and boundary of the graph $B$ is $\gamma$ i.e., $B^{min}(f_{1}(t),f_{2}(t))=f_{3}(t)$. Similarly the lower boundary is maximal convex function $B^{max}$ graph of which is attached to $\gamma$. Now by Caratheodory's theorem it is enough to show that the graph of $B^{min}$ does not contain domains of linearity (triangles!), and this will mean that it consists only by chords $\{a\lambda +b(1-\lambda), 0\leq \lambda\leq 1\}$ for some $a,b\in \gamma$. Suppose it contains triangles. Then let us consider any side of the triangle. Let it be the chord with endpoints $\gamma(a)$ and $\gamma(b)$ for some $a,b\in [0,1]$. Notice that this chord will be tangent to the curve $\gamma$ (this is not a difficult observation). In other words this means that there exists a plane containing the chord $[\gamma(a),\gamma(b)]$ and such that the curve $\gamma$ lies to one side of the plane. It is the same as to say that $$ \det(\gamma’(a), \gamma’(b), \gamma(b)-\gamma(a))=0 \quad (1) $$ Now if you play with this equation for a while, you will see that the torsion must change the sign from + to - on both of the side of its chord (moving counterclockwise). Since triangle has 3 sides in total you will have 3 times changing of signs of $\tau$ from + to - and this implies that $n(\tau)\geq 6$. In other words every time whenever you draw a such chord (bitangent line) torsion changes sign on its sides. And this finishes the proof. Now the question remains: what happens in theorem if we assume that $n(\tau)>4$. Of course theorem is not true anymore, the quantity $n(\tau)$ does not give you any information about the structure of the graph $B^{min}$. There is another object (smooth transformation of torsion) which we call force function which gives the answer: there exists a source such that coming force have full tails, but this is different story (some language was developed here) Roughly peaking at the point where the torsion changes sign from + to -, you can (locally) construct tangent chords (a cup) $[\gamma(a),\gamma(b)]$. Now take one of them an try to extend them through out the curve (I mean foliate the domain, bounded by the curve $(f_{1}(t),f_{2}(t))$, by chords so that they will not intersect each other but will fill out the domain). Intuitively it means that you take this closed space curve (say closed wire), drop it on the ground, and try to roll it, so that in the beginning ground touches the wire exactly at one point (where torsion changes sign) and then it can be completely rolled over the ground (so that wire will never touch the ground at triangle) and eventually it will finish touching again at only one point (and again torsion will change the sing at that final point as well). This is possible if and only if you can extend equation (1) say by implicit function theorem throughout the curve $\gamma$, and there is one simple answer to the question when is it possible, it is possible if and only if there exists a force function with full tails. And this should be true for both: for $B^{min}$ and for $B^{max}$. Update: To illustrate what I wrote above I am attaching this picture. On this picture torsion of the curve changes sign $n(\tau)= 8$ times (4 times from + to - minus), and on each point where it changes sign from + to - you see the cup : family of chords coming from there. And you see that there are two triangular domains (domains of linearity: places without any thread): one close to you and one from another side which is not completely exposed on the picture. By the way this is how the upper boundary of the convex hull ($B^{min}$) look like for this space curve (closed wire). 

There is a systematic approach to these type of problems which finds the best possible constants (when $n\to \infty$) but requires plenty (but easy) computations. I will mention the steps and if somebody is interested I can provide more details What are we looking for? $$ \sup_{x,y \in L^{p}}\{ \|x+y\|_{L^{p}} : \|x\| _{L^p}=1, \|y\| _{L^p}=1, \| x-y\| _{L^{p}}=1 \} $$ Let us consider the following extremal problem in $L^{p}([0,1])$ $$ B(u,v,w) = \sup_{f,g \in L^{p}} \{ \int_{0}^{1}|f+g|^{p} : \int_{0}^{1}|f|^{p}=u, \int_{0}^{1}|g|^{p}=v, \int_{0}^{1}|f-g|^{p}=w \} $$ Then clearly the best possible $C_{p}=(B(1,1,1))^{1/p}$. Properties of B Now the advantage of considering the function $B$ is that it satisfies the following properties 1) $B$ is given in the convex cone $\Omega$ such that $(u,v,w)\in \Omega$ iff $w^{1/p}\leq u^{1/p}+v^{1/p}$, $u^{1/p}\leq v^{1/p}+w^{1/p}$ and $v^{1/p}\leq u^{1/p}+w^{1/p}$. 2) $B$ is a concave function in $\Omega$. 3) $B$ has a boundary condition in $\Omega$ i.e, $B(|x|^{p}, |y|^{p}, |x-y|^{p})=|x+y|^{p}$ 4) $B$ is minimal among those who satisfy properties 1), 2) and 3). Now it is clear how to find $B$: $B$ is a minimal concave function in $\Omega$ with a given boundary conditions 3). Notice that $B$ is 1-homogeneous so it is enough to find $B$ just in any section of the convex cone $\Omega$ (say for example $w=1$). Your initial question reduced to a purely geometrical question: find the concave envelope of the boundary data. After you find $B$ you can use it for your finite dimensional problem: if $d\mu$ is the uniform counting measure with weights $1/n$ then by Jensen's inequality $$ \int |x+y|^{p} d\mu = \int B(|x|^{p},|y|^{p},|x-y|^{p})d\mu \leq B\left(\int |x|^{p} d\mu, \int |y|^{p}, \int |x-y|^{p} \right) $$ 1-homogeneity of $B$ and the right hand side gives you an upper bound. 

I will illustrate the Bellman function approach to prove Wirtinger's inequality which, of course, is simpler than the original problem. The advantage of the approach is that it does not use any Fourier analysis (which apparently is the best thing to do for this particular problem since $f$ is periodic), Cauchy--Schwarz, or variational calculus such as Euler--Lagrange equation. If somebody finds the approach interesting you can try to use it to prove the original problem (or maybe I will try to do it myself but later), and as Paul Bryan noticed, unfortunately it will only give you isoperimetric inequality for the sets whose boundary has a nice 1-1 parametrization in polar coordinate systems (for example, star shaped sets). Consider the function of 4 variables $$ M(t,x,y,z):=\frac{2tx^{2}(\cos(t)-1)-y^{2}\sin(t) +z^{2}(t\cos(t)-\sin(t))+2(1-\cos(t))(2xy+xzt-yz)}{2-2\cos(t)-t\sin(t)} $$ defined in the domain $(0,2\pi)\times \mathbb{R}^{3}$. In what follows $M_{t}, M_{x}, M_{y}, M_{z}$ denote partial derivatives of $M$. Claim 1: For any $v \in \mathbb{R}$ and all $(t,x,y,z)\in (0,2\pi)\times \mathbb{R}^{3}$ we have $$ x^{2}-v^{2}\leq M_{t}+v M_{x}+xM_{y}+vM_{z}. \qquad (*). $$ Proof: Optimize the inequality over all $v$. The optimal value is attained when $v=-\frac{M_{x}+M_{z}}{2}$. Therefore it is enough to have $$ x^{2}\leq -\left(\frac{M_{x}+M_{z}}{2}\right)^{2}+M_{t}+xM_{y}. \qquad (**) $$ After straightforward calculations one notices that the inequality $(**)$ is in fact equality! The details are left to the reader. Claim 2: For any $f\in C^{1}([0,2\pi])$ we have $$ \int_{0}^{2\pi} f^{2}-(f')^{2}\leq \limsup_{t\to 2\pi}\, M\left(t, f(t), \int_{0}^{t} f, \int_{0}^{t}f'\right) - \liminf_{t\to 0}\, M\left(t, f(t), \int_{0}^{t} f, \int_{0}^{t}f'\right). $$ Proof: Notice that $$ f^{2}(t)-(f'(t))^{2}\leq \frac{d}{dt} M\left(t, f(t), \int_{0}^{t}f, \int_{0}^{t}f' \right). \qquad (***) $$ Indeed, after taking the derivative the inequality $(***)$ simplifies to $$ f^{2}(t)-(f'(t))^{2}\leq M_{t}+M_{x}\, f'(t)+M_{y}\,f(t)+M_{z}\,f'(t). $$ The latter follows from $(*)$ where we take $v=f'(t), \;x=f(t), \;y=\int_{0}^{t} f$ and $z=\int_{0}^{t}f'$. Finally we just integrate $(***)$ in $t$ from $t_{1}$ to $t_{2}$ where $t_{1}, t_{2}\in (0,2\pi)$, and take the lower and upper limits $t_{1}\to 0$ and $t_{2} \to 2\pi$. Claim 3: Let $f\in C^{1}([0,2\pi])$ be such that $f(0)=f(2\pi)$ and $\int_{0}^{2\pi}f=0$. Then $$ \int_{0}^{2\pi} f^{2}-(f')^{2}\leq 0 $$ Proof: Indeed, using Claim 2 it will be enough to show that \begin{align*} &\limsup_{t\to 2\pi}\, M\left(t, f(t), \int_{0}^{t} f, \int_{0}^{t}f'\right)= \lim_{t\to 2\pi}\, M\left(t, f(t), \int_{0}^{t} f, \int_{0}^{t}f'\right) =0\\ &\liminf_{t\to 0}\, M\left(t, f(t), \int_{0}^{t} f, \int_{0}^{t}f'\right)=\lim_{t\to 0}\, M\left(t, f(t), \int_{0}^{t} f, \int_{0}^{t}f'\right)=0. \end{align*} These inequalities roughly speaking follow from the following observations \begin{align*} &\lim_{\delta \to 0}\; M(2\pi-\delta, f(0)-\delta f'(0),-\delta f(0), -\delta f'(0))=0\\ &\lim_{\varepsilon \to 0}\; M(\varepsilon, f(0)+\varepsilon f'(0), \varepsilon f(0), \varepsilon f'(0))=0 \end{align*} for any $f(0)$ and $f'(0)$. The end.