We need to first get up-to-date on the topic of sadness, therefore I would suggest this book: "The Anatomy of Melancholy, What it is: With all the Kinds, Causes, Symptomes, Prognostickes, and Several Cures of it. In Three Maine Partitions with their several Sections, Members, and Subsections. Philosophically, Medicinally, Historically, Opened and Cut Up)" by Robert Burton (1621). With later updates, revisions and reprints. (Usually just referred to as "The Anatomy of Melancholy", any good library will have it) After you read Burton's book, you will certainly know what it means to be sad. Then we would read a selection on existentialism. Maybe we could read Gyorgy Lukacs on Existentialism. Lukacs himself didn't think much of existentialism. You can find his essay on the internet. I don't think existentialism will help us much with our sadness, it may even make it worse!! However, there are some people who can truly commit to something so much that they rarely get sad. Then again, we may just be expecting too much from life. Everyone smiles in the advertisements on TV and on the net so we think everyone is happy all the time. But remember, the people smiling are actors, and a director is yelling at them to smile for the camera! This pretty much leaves us with the Buddha who said that this world is suffering, it is all about suffering, and then he laid out the eightfold path as the way to deal with the problem. But enlightenment requires us to let go of attachments. It is very, very hard for all people, much less for Westerners, to let go of attachments. Especially the attachment we have to our own ego. Nevertheless, the Buddha did some very profound thinking on this topic, and it is probably worth studying him. I don't mean to slight the other religions or belief systems. I mention Buddhism because it puts the issue front and center it seems to me. NB: The Wikipedia for The Anatomy of Melancholy quotes a literary critic as saying that the Anatomy "survives among the cognoscenti." And that is certainly true. Those in the know will have read this book. 

In philosophy, these are concepts of "modality" and still hotly disputed. You've provided a very nice example of how epistemology and metaphysics can lead to greater degrees of questioning... then (maybe) have applications in real life mathematics or scientific deduction. If you're looking for an amazing - yet wildly inaccessible to most readers - discussion about this look at Quinne. To summarize / bastardize: 

Stanford Reference Or, simply by saying "This company is stupid" you are actually just stating the thing that you are trying to prove. It's circular reasoning. The other propositions stated (such as "they blocked my TV show") don't lead to a conclusion of "this company is stupid" - that has to be assumed for the conversation to even make sense. People are casually, conversationally, question-beggers all the time and it's not normally a problem. They're either not saying what they actually mean (I hate this company for preventing me from watching what i want) or the remaining logic is assumed / implied / obvious. So, that's why I include the caveat of tragically bad in the context of philosophy. There's enough implied in the comment for you to assume it's someone's opinion. It's under circumstances where things are stated as facts that it becomes truly messy and where I feel like the term "fallacy" is appropriate. An example: 

Under the influence of Kripke's acute analysis, there has been a growing trend of modern essentialism, or in other words, the assertion that there are 'essential' descriptors (rigid designators) that 'stick' with the thing being described in all possible worlds. Most influentially Kripke identified that any set of descriptions could not be definite in the way Russell imagined, since it was possible that a given X with descriptions Y and Z could have been existent in another world where Y and Z were not applicable to X. Russell's descriptivist theory of names still holds a large degree of influence in analytical philosophy however. It is assumed especially in the way philosophers talk about existence. Existence is typically understood to be a general concept property which is instantiated in existent objects. This seems to largely hold only if we grant that existence cannot be attributed to singular things, which in turn typically only holds because singular things are held to be a collection of descriptions. If one were to rid of the last, grounding belief one would find new gates opened for conversation about what the nature of existence is. In any case, it seems clear that Kripke's criticism has very serious and far-reaching consequences. As such, it is important to understand the responses that have been given to such criticism. What is the current debate being had about Russell's theory vs. Kripke's? 

I think the artwork stays the same (is concrete). Then it is your mind plus the ambience of the room, or atomosphere of the place, that brings the particular experience of the work. A painting may look happy on one particular day, the same painting may look sinister that same evening (perhaps the darkness plus a ray of light strikes it in a certain way). The next day it may be different to you again. Again, the painting is exactly the same, but your brain reinterprets the work taking into account what we call the "atmospherics" of the place. A word about music. Music too can depend on the size and shape of the room (acoustics), if there are speakers, where are they placed and so on. Plus one should not have a heavy meal before listening to music. It dulls the music because it eventually dulls the brain, and we could fall asleep. But the music, the notes are the same (of course it's also possible to have a new arrangement of the score). If we are in a sad or dejected state of mind, all music might sound sad to us, it is our state of mind which has changed, not the music itself. When we first fall in love, all music sounds great to us; same score, different state of mind. The closest philosopher here might be Derrida. The "text" is fixed, but forever open to interpretation. However, that could just be my interpretation of Derrida. It's impossible to misinterpret Derrida, if you understand Derrida; if you understand (comprehend) what I'm saying. If you have not read Derrida, and you are enjoying paintings, prints, books, music, maybe plays, sculpture, whatever, good! Stop there and enjoy! Derrida might leave you pulling your hair out like he did me. It may not be worth reading him. My feeling is that you probably have the artistic temperament yourself. Which is good, not bad. Of course, there is no emotion here. No, no, none. Strictly the brain. But wait! Emotion is in our brain. The medical books said in the past it was in the heart, now they say the brain. Who knows? It must be somewhere inside of us! Enjoy. 

Or, using the example of self-defense, "that which is necessary, is legal/moral" could be restated as: 

Sneaky, factually stated, circular reasoning - completely inaccurate. Fallacies in philosophy are wolves in sheep's clothing. If we're too liberal with the term's usage we run the risk of conversationally pedantic. Hope this helps. Happy hunting. 

Just because something is false doesn't mean it's a "fallacy" - at least in a philosophical context. That word is reserved in philosophy, generally speaking, to mean logic that by virtue of it's deceptiveness is tragically bad. In this case - the "Stupid Assumption" - I would say this could possibly be a fallacy called "begging the question," which essentially means: 

James Ross has given several reasons as to why he believes thought (and formal thought especially) is determinate. Among these, and under a formulation put forward by the contemporary philosopher Edward Feser in "Kripke, Ross and the Immaterial Aspects of Thought", is the argument that a rejection of determinancy presupposes a conception of determinancy itself, so that in denying thought to be determinate one must understand what it is for thought to be determinate. However, to 'understand what it is for thought to be determinate' requires that such a thought is itself determinate (or so the argument goes). For the strength of the argument against determinancy of thought is in its actual denial of determinancy being attributed to thought. But if neither 'determinancy' nor 'thought' are determinately understood then it seems that no determinate argument can be made for the indedeterminancy of thought itself. Hence, there is no actual reason to accept any argument given for the indeterminancy of thought, or any argument period for that matter. But this is obviously a view that cannot be allowed, since it is itself arrived at through argument. Hence it is self-defeating, along with arguments given against the determinancy of thought. Therefore, by reductio ad absurdum, thought is indeed determinate. Is this analysis correct though? 

Well. We don't. We never know that. And we can't ever know that. But, does that matter? The question becomes whether that's a function of our language, understanding of the world around us, or something completely different. Russell provides a number of avenues to this end that sort of bridge the gap between math, language, knowledge, etc. And, he writes well. David Lewis is sort of a hallmark (for me anyway) in these discussions. You could summarize "degrees of truth" through the notion of "possible worlds" in which a statement like "I believe the moon is made of green cheese" means that you're committing to the actual existence of moon made of green cheese, just in another time and space. Something like a "square'd circle," couldnt possibly exist. 

Hume's Fork, which divides knowledge into 'relations of ideas' and 'matters of fact' has had an incredible influence on philosophy ever since its conception (though it is sometimes claimed that others before Hume, such as Leibniz, anticipated a version of the thesis). So influential is the thesis that it seems to have been a rather potent presumption in the minds of modern philosophers throughout time. For example, Hume's criticism of induction and the wedge he placed between what experience offers us and what we conclude about said experience was incorporated by Kant, who was a critic of Hume in many senses of the word. That same wedge could be argued to be a driving presumption in Kant's understandings of the terms apriori, aposteriori, analytic, and synthetic (even if Kant's famous synthetic apriori was a response to Hume's seeming attack upon the possibility of science). In more contemporary philosophy, such as in the works of Carnap, it is held that statements are either true by virtue of their form alone or are empirical statements. To what degree is Hume's Fork, in some sort of manifestation or another, present in philosophy in the analytical community (especially in the works of Wittgenstein, Ayer, Carnap and Quine)?