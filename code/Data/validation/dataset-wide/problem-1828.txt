I don't think it's possible to say: Buy X, install Y, and your problem will be instantly solved. This is going to take several iterations to get through, and you'll need to put more work into identifying the bottlenecks when they inevitably appear. For the most part I'm going to avoid recommending specific hardware, as that would be out of date by the time I click the submit button. So, since we don't have good data on what the bottlenecks were, let's just pretend this is a greenfield project. This is how I would approach it: 

None of those obsolete options you placed in have any effect anymore. And Google will prevent your IP from being spoofed; you don't have to worry about it. 

ISC DHCP certainly will request a prefix delegation from your ISP if you ask it to, but it won't actually do anything with it beyond logging it somewhere. Nor will any other DHCP client. If you really intend to build your own router, you'll have to write your own scripts to determine the prefix that was delegated, set up static routes, and configure your router advertisement daemon and/or DHCPv6 server on your LAN. If you want an example, OpenWrt beginning with Barrier Breaker has already done this and you may be able to reuse some of their work. For a home office I wouldn't really bother with this, and just use something off the shelf that has proper IPv6 support...like your Airport Extreme. 

Make something up, that is unique and won't match anything else. That field in is just a key, and it's used as a lookup in the specified . If you have a static key, then all the lookups will match the same, and the limit for that zone will be effectively global. For example: 

The problems with geographically distributing WordPress, as you'll see, all revolve around the MySQL database. There are basically two ways to architect this: Read replicas In this architecture, you run your LAMP frontend with WordPress in several geographic locations, each of which has a read-only replica (slave) of the master MySQL database. You will need to use something like MySQL Proxy to direct write operations back to the master, as WordPress doesn't natively support using a different database connection for reads versus writes. The big problem with this setup is that if your master goes down, you can't make changes (e.g. no new posts or comments). So the master should probably be clustered or otherwise protected (e.g. using Amazon RDS Multi-AZ). Database writes are also delayed slightly due to network latency between the LAMP frontend and the remote MySQL master. Multi-master In this architecture, you run your LAMP frontend with WordPress in several geographic locations, each of which has a multi-master replicated database, using something like MariaDB Galera or an equivalent MySQL solution (if you can find one). You need to have at least three masters if you go this route. As there's no single point of failure, it really doesn't matter if one master goes down (so long as they don't ALL go down at the same time; that situation requires manual intervention to recover). The problem with this is that writes take much longer, as they have to be replicated to all of the multiple masters. So people may notice a few seconds' delay when doing anything that writes to the DB, such as commenting or writing a new post. In practice, this delay isn't that significant, as users already expect delays when they submit information in these contexts. 

Later you should look at doing caching within your web app; if it writes generated HTML files to the disk, you could then have nginx serve those files directly out of its cache. 

When you reboot, the filesystem should automatically be resized for you by . If not, you can use to grow the filesystem manually. 

Have the mail sent directly to your server, or do the RBL checks on the other server. To send the mail directly to your server, just add appropriate MX records. For example: 

2 is ENOENT, or No such file or directory. This means the socket doesn't exist. And the cause of that is that MariaDB is not running. You need to start MariaDB before running . 

Here, you should double check that the AS number actually belongs to Hetzner. Many small hosting providers do not have their own AS and are simply customers of a larger network. You should also do this check if the above returns two or more AS numbers (which should never happen, but I have seen it once). 

Your consultant is blowing smoke. And probably getting very highly paid to do so. We're all in the wrong business... There are good reasons to limit the Apache modules that you install and use. Security and stability come to mind as the top reasons. But efficiency? Do they mean power savings? Unused code doesn't consume any electricity. I can't imagine what is supposed to be meant by this. You've spent more than a year's power savings from such "efficiency" just typing out your question. As for WordPress, its requirements are pretty minimal. You don't even need Apache... And advise the bean counters that they aren't getting their money's worth from that moron consultant. I'd ballpark the savings from this one at around 3 cents per year per server. You can use that as an example of the quality of recommendations you're receiving. 

Make sure the interface is configured correctly. Check and make sure it hasn't been altered. On my CentOS 6.5 system it appears as: 

This will let user do whatever they want to do with libvirtd without requiring a password. Second, non-root users need to specify the connection URL explicitly in order to access the system libvirtd. 

Among other things, you removed the system Python package; yum is looking for the package which provides Python to be installed, not merely a Python binary. Reinstall the package. And in the future, be very careful when removing packages. 

is a repair operation. So something is currently wrong with your system that this is intended to fix. My guess would be, if you haven't got a kernel installed now, that you really need to do this, as your system right now might not even be bootable! 

In both cases, the two iptables commands you are comparing have different semantics and behave differently to each other. It's not necessarily a matter of which is "best" but of what behavior you are trying to match or provide. First: 

If you don't have exactly six items between slashes, then this pattern won't match, and you'll get a 404. You can make five new rewrite rules containing one through five variables, respectively, (or someone who's better at regex than I am might suggest a single rule to cover all six cases, but that's above most people's heads) or just handle this in your application instead. 

If you ran yourself with the (verbose) flag then you would be able to see progress. But since you ran it in the background through a web app, you are stuck. You will just have to wait it out. In the meantime, you might want to spend some time learning how the system really works, rather than relying on the crutch of webmin. 

You may see a number of power-on hours on a new drive. It is normal for drive manufacturers to test their drives prior to shipping. For instance, WD RE drives are burn-in tested: 

As the documentation told you, if the images provided by Atlassian don't do that you want, then you should create a custom image. 

You're following a single TCP connection. FTP data transfers occur over a second connection. Stop following the connection (or filtering) and you should see the data transfer, assuming you didn't use capture filters and actually captured it. 

Ansible wasn't really meant to solve this sort of problem. It can do so, but it would be cumbersome at best. Something like Katello (the open source on which Red Hat Satellite 6 is based) can handle this sort of thing well. It maintains packages at the exact versions you've tested and allows you to promote them from development to staging to production, or define whatever workflow makes sense for you. Not to mention handles bare metal provisioning and many other things. Its only drawback in this scenario is it's well integrated with Puppet, so using it with Ansible may be a bit less automated in places than it otherwise could be. 

(The old name of Wireshark was Ethereal; this made the package update work properly when the software was renamed several years ago.) 

You mistyped the old password. doesn't have the proper permissions; it must be setuid root. Your local PAM setup is horribly broken; if this were the case, nobody would be able to log in. 

Your ssh private keys have likely been compromised, since someone had a valid private key for logging into your root account. The fact that someone didn't log in from a permitted IP address saved you from further compromise. Nevertheless, this is a significant compromise; it suggests that your workstation (or other machine you typically work from) was compromised. You should treat every workstation and server you touch as potentially compromised. Format and reinstall your workstation(s). Revoke/destroy all of your existing ssh keys and rekey everything. Change all passwords. Strongly consider wiping and reinstalling any servers on which you have access to log in with this key. 

Github looks for the shebang interpreter directive. This is the line at the top of the file which specifies what interpreter should be used to run the script. An example of such a directive is: 

Your hosting provider's advice is completely useless. Port 25 is the well-known port for receiving mail from other mail servers. If you want to deliver mail directly to a destination, that is what you use. Most such sites will not be attempting to receive mail on any other port, so attempting to deliver to port 26 will do nothing. You basically have two options: 

You're running an old OS on new hardware. Since you have an old release of RHEL, you have an old version of the PCI ID database which is used to look up device IDs and give textual descriptions for them. And since it's old, it can't possibly have descriptions for hardware that didn't exist when it was created (since time travel does not yet exist). This is not really an issue you need to worry about if you are updating to 6.4. It will have the latest PCI IDs and kernel drivers for any significant piece of hardware in that system. Anything that it might not have, such as HP management agents, you can obtain from HP. 

You're using an OpenVZ virtual machine. The hosting provider must specifically enable support for PPP for your virtual machine. Contact your service provider. 

For things that absolutely must be 100% working all the time, like network configuration scripts, you should include just to be sure. 

Security groups for regular EC2 instances can only have rules applied for TCP, UDP and ICMP. To resolve the problem, start your instance in a VPC. Security groups for VPC instances can be written for any protocol, though you may need to use the command line tool to create the rule. This should be sufficient to open up GRE for your VPC instances: 

The terminology surrounding remote access and RADIUS can be confusing the first time you run into it. In short: The user sends credentials to a remote access server (network access server). This is your wireless access point. (For wired networks, the access server is the switch and authentication is usually by MAC address.) The AP or switch then acts as a RADIUS client, and passes the credentials to the RADIUS server for authentication and authorization. (For wired networks, the switch serves as the RADIUS client.) Network Policy Server functions as a RADIUS server in Windows. Linux systems usually use FreeRADIUS. If the user is authenticated (their username and password match) and authorized (they're allowed to be talking to the network at all) then the RADIUS client also sends accounting information (when they logged in and for how long).