I have an anomaly in portion 3 of sheets 1 and 2 that might bear investigation. I should have displayed sheet name rather than sheet index. I leave that for you. If the fault is in your code, this should you enable to isolate the cause. 

That is followed by a boolean expression. Here I assert that the current sheet name is not BWTB. It this assertion is true, execution does not pause. But if it is false, execution stops on the assert statement. Place the assert statement at the top of the suspect code. When it pauses, use F8 (execute single statement) or use F9 (set/unset breakpoint) and F5 (execute until breakpoint) to step through the code until you have isolated the problem. I assume you have made all the improvements people have suggested although my experiments reveal these improvements will not make the difference we all believed. You start with Sheets("4020"). I seem to recall that you said it was important to start with this sheet. Is this because the other sheets depend on Sheets("4020") or because Sheets("4020") is Sheets(1)? I do not like the way you step through the sheets. Your code depends on Sheets("4020") being Sheets(1) and Sheets("BW TB") being Sheets(26). If Sheets("4020") is special you should make the body a subroutine with sheet name or index as a parameter. You then (1) call the subroutine for Sheets("4020") and (2) amend the loop to: 

Ok, I'm changing the answer now that I understand what you are doing. The main problem here is -- while Scala people, in general, don't mind special operators, they don't add operators just because they can either. You can replace with the existing just by adding to any one of the terms. Views aren't often used either, and it's important to have a very good understanding of how they work if you are going to use them, and it's not that easy to gain performance with them, since the machinery they use to support non-strictness is quite heavy, and not everything takes advantage of it. For example, will create a new collection before and are applied. Views can gain when you have many mapping/slicing steps, and few elements of it are ever used. Most of the time, iterators will gain you much more performance, at the cost of the mutability problems iterators have. If you want to reduce the number of times you iterate through the list of proportions, there's at least one place where you can simplify: 

and should be . You need to to use . You are defaulting the copy constructor and assignment operator, but not the move constructor and move assigment operator. That's fine because the defaults are generated anyway, but it is inconsistent, I think. What is the point of ? should be . You don't want to have users create s. does not actually own the pointer it holds. It is copyable and will just copy the pointer it holds. It also does not create anything or delete anything in the constructor/destructor. Nontheless you provide a member. That seems very wrong to me. You don't know how the memory you point to was aquired, it could be with static storage or an array. In both cases calling would cause undefined behavior. The object creating the pointer with should also be responsible for ing it. Calling on two copies of also causes undefined behavior. The fact that the pointer is not owned seems to be a major flaw here anyway. Currently the user of your class needs to gurantee that the object pointed to keeps in scope until all 's holding it are destroyed and then it has to take care of proper deletion. Using it outside of is not allowed. So why not move the responsibility of managing the pointer to ? The same holds true for the lock. Currently the user needs to provide a suitable lock and keep it live until no references it anymore. Why not create the lock/mutex inside the constructor from pointer? Though I realize if you do it like this you need to manage references to the lock and you end up with fully reimplementing . Therefore I will just assume that this wrapper is explicitly only about locking and not managing ressource lifetime and that the user is required to run the destructors properly. is fine if copy elision is performed (not required in C++11, but in C++17), but is not either way. The object you create in is destroyed before the function returns. That means that is called before the caller expression using the pointer ends. currently returns a copy. It should return a reference. At least that is the usual way this operator is interpreted. In general the approach with and has some limitations. You may not call either twice in one expression or you have deadlock. But you are also not allowed to save the pointer returned by or a pointer/reference to the object referred because these are not guarded any more by the lock. I guess it would be much better to let the caller call a which returns a . Access to the holding pointer is then only allowed via and of this . As soon as goes out of scope its destructor releases the lock, similar to . This still allows the user to misuse a saved reference/pointer to the raw object, but at least more than one usage can me made in the same lock aquisition. An implementation via C++11 standard library would be similar to this (not tested): 

In Scala, never use unless some API requires it of you; use instead. If you have to interface with an API that returns , convert the result into an . As long as you do that, you can ignore checks, for they'll always be errors: you got a from some code that shouldn't be producing it, or you forgot to convert some return value to , or else you didn't even know you had to. Use or -- seems better suited, but either will do with the proper conditionals. Also, do not use -- use . Yeah, it looks weird, but / is idiomatic, and faster. There's a function that is used for parameter validation. Either or will do. 

We'd usually make the solution more functional. That is, move the "fizzbuzz" logic into something that returns a string, and use that: 

This is longer, and handles nullness in two separate places, and doesn't protect against nullness, but I think it reads much better. To get more than this I need Scalaz: 

: There is no reason to use dynamic allocation, and are constant expressions!. Just use or better . That said you usually want to have dynamic sizes or your matrix may be larger than the stack limit. Then you should use . C-style arrays and dynamic allocation should always be limited as much as possible. Using proper class objects wrapping them is much safer. will take care of all memory management for you. If you are concerned that will layout rows non-continuously, then use instead and properly access the elements by . Also, in C++, you do not use and . Instead you use and . The difference is that not only allocates memory but also constructs the object in that memory. In most cases you would need to manually construct the object in the allocated space (although for double it is technically ok here). You should not declare a method, but rather everything freeing memory belongs in the destructor, which is automatically called as soon as the object itself goes out of scope or is destroyed: 

Note that doesn't know a thing about or -- it applies to the pattern. Well, anyway, take your pick. Sometimes a problem just isn't worth the trouble, but it is useful to know how to handle the trouble anyway. 

And, yes, was a good start, and for new comers to FP it is not obvious to implement something that will stop at the first incorrect size in functional style -- at least on a strict language like Scala. You'd either throw an exception or use recursion. 

This is a fold, not a scan. A scan produces something with the same number of elements, and change the elements. A fold produces something new. 

One good technique at eliminating vars is recursion -- it can certainly be used in this example. Alternatively, you can identify a common pattern, such as fold, traversal, etc. For example: 

Finally (unless I missed something), the inside can be avoided simply by using multiple , and statements like this: 

You could rearrange the boolean expression so the then-block is executed rather than the else-block but that sort of boolean expression hurts my head. If having a boolean expression I can understand means using the else-block then so be it. When I set up my workbook, my equivalent of Sheets("BW TB") ended up in the middle so I have had to change your code in this way. I have had to do the same to the code I am about to show you. You need to isolate the portion of your routine that is taking a long time. The secret to this is the Timer statement which returns seconds since midnight as a single. I have declared some new variables: 

I store timer values in TimerVal(1 To 5, 1 To 26). That is 5 times per loop for each of 26 worksheets. I use column 6 for worksheet totals. I use row 27 for loop portion totals. I used TimerVal(0,5) for the start time so TimerVal(N-1,5) is always the end time of the last loop. I use constants so if you decide you need 4 or 6 times per loop or you add more worksheets, you can change the constants rather than my code I placed before the Do statment. I placed immediately after the Do statment, with four other such statements placed throughout the loop. The effect of this is for the loop to record 125 times. The following code displays those times to the immediate window as durations: 

One could also keep a , then either use it alone when computing (instead of zipping stuff), or skip that altogether and put that computation on -- incurring the cost of computation O(nlogn) times instead of O(n) times. It would make the code shorter, but whether it would be faster or not is something I'd leave to a benchmark with a real application -- I'm guessing it would depend on actual sizes for . So, let's talk a bit about performance. Before Scala 2.10, if you want performance you should avoid methods added through implicits on critical paths. The code you wrote will probably get inlined by JIT. You can also reduce the number of computations by pre-computing , and if you make that , then you don't need . More specifically, views are not guarantees of speed, particularly if the computations are light, such as here. I'd not use them at all, unless I'm specifically optimizing the code. Doing a fixed size of multiple passes on small data structures is often not a problem. You are not changing the complexity, just losing memory locality. If the data is bigger, you can incur in gc overheads, which are more substantial. If maximum performance is required, just drop immutability and go to mutable arrays. Finally, is faster on than -- and, in this particular case, a would be way faster. Call it , however, since is a general method on traversables, while set's apply is a fundamental operation. If one of them is less than optimized, it will be . This is the most idiomatic beginner's code I have ever seen... do you come from another functional language? 

You forgot to in . There is no need for your limitation on integral types. You could just as well use the algorithm for any type with overloaded and or even only . You could follow the interface and make custom comparators available, too. However you would need to think about copy-constructibility and such. I think you cannot avoid limitation on copy-constructibility. I don't know why you write , is just fine in C++. It might even mask some errors, because will introduce as incomplete type, while will give an error if was not declared at that point. In C++11, which your code seems to be, you can easily offload memory management to in most cases. This makes the code shorter, clearer and safer, e.g. make and and leave the rest as . Then each node is owning its successor node and owns the first node. As soon as is destroyed, will be destoyed, which is owning the first node and it too will be destroyed, cascading down to the last node. There might be a problem with recursion for every node here if tail recursion optimization is not possible, though. In that case you can still use a custom destructor moving through nodes iteratively. You can spare a few lines of code, if you put and in the constructor of . Your code has undefined behavior if the input length is zero. You either need to check that this is not the case or change up your code a bit to work without handling the first node in a special way. It is unnecessary to repeat the node creation code so often. Just make a function which inserts a new node before the node pointed to by and updated to point to the new node. In fact I think this belongs into , rather than , so that will handle its own memory. I think holding the is unnecesary, as you can just get it from one indirection to . You are basically reimplementing a holding pairs of and . Maybe try using the standard library directly. I tried it out (I deleted the file accidentially though) and got your algorithm down in about 15 lines or so with and no performance impact on the test case and only about 10% additional time on the test case (but that might be improvable). If you used a tree () instead of a list to store your sorted values, then you can reduce the time to . I think this should also be possible while still keeping your behavior for smooth input. If you used a hash map () instead of a list to store your sorted values, then you can reduce the time to by counting all elements with the same key and ordering keys with afterwards. However the complexity for smooth data would not be better than that in this case, except if many consecutive values are identical.