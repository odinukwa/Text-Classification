Suppose I have a large thin disk of rotating gas in a galaxy -- the disk has a maximum inclination-corrected $V_{max}$ and a maximum radial extent of $R_{max}$ corresponding to that $V_{max}$ measurement. The virial theorem tells me that the total (aka dynamical) mass enclosed by that rotating disk (including stars, dark matter, etc.) is $V_{max}^2 R_{max} / G$, where $G$ is Newton's gravitational constant. Here I have assumed that the virial coefficient is 1, but the virial coefficient can vary widely based on the geometry of the problem. For example, it can be almost 10 for dwarf galaxies (an order of magnitude!), or a factor of $\sim3-5$ for dispersion-dominated rather than rotation-supported systems like elliptical galaxies where you're using the stars to probe the dynamical mass. My question is simple: for a simple rotating disk of gas as above (assume it is thin and obviously not dispersion-supported, which I think is one of the simplest possible geometries for a question like this), what is the virial coefficient? I have seen coefficients of both 1 and 2, but I have no idea which derivation is correct. Adding to the problem is that some derivations seem to be using the virial theorem to give an order of magnitude estimate which means they leave out discussion of the virial coefficient altogether. 

The Earth's gravity (call it the curvature of space) at the center of the Earth is approximately zero. Similarly, we assume a dense early universe was still infinite and homogeneous, so no worries, the gravity canceled out to approximately zero. There is no evidence that it was a lump of matter surrounded by an empty space, like a black hole usually is. Remember, the Big Bang happened right here where you are now, and all the matter became more and more distant from the point where you are. Simply all the distances increased all the time without matter accelerating or moving into some imagined "outer space". 

Singularity means "my theory doesn't work here". In other words, GR is unable to predict what happens at the point, so it calls this point a singularity. The most important thing is not to mistake map for the territory. GR is the map, a real black hole is the territory. GR is the map which allows us to predict what we will find in the territory. If the map says "don't really know about this point" you really shouldn't expect that when you go into the territory you will see an Unmeasurable Infinite Thing there. It's very much against our historical experience. To date, time after time we observed normal finite things in the territory, but we never have seen Unmeasurable Infinite Things. In every case when an old map said we would see infinity, we found that measurements of a territory were finite and so falsified that map (that theory). So it seems we should expect singularity as a word to only refer to the map. You really shouldn't expect to observe a singularity (a map thing) when your actual ship enters a black hole (a territory thing). It might turn out that GR is approximately right about an event horizon, but we already know it is not good enough to describe what is at the center. 

Suppose I have a wavelength array for a spectrum in units of Angstroms. Suppose further that the wavelength has "uniform logarithmic spacing" such that if I just take the difference in Angstroms between neighboring array elements i and i+1, this won't be the same as the difference in Angstroms between any other two neighboring elements j and j+1. However, if I first took the log10 of the wavelength array, then the difference between any two neighboring logarithmic array elements i and i+1 would be equal to the difference between any other logarithmic array elements j and j+1. Now, I know a priori that this wavelength array has a velocity offset of X km/s, which I basically want to remove. How do I apply a velocity shift of -X km/s to this wavelength array which has uniform logarithmic spacing? 

Suppose I have an astronomical image in some bandpass and I do photometry of an extended source (i.e., a galaxy). I measure an enclosed magnitude within my aperture or galaxy profile. What is a straightforward recipe for obtaining a realistic uncertainty on that magnitude? Can I just do something like 1/(S/N) or is that only for point source photometry? 

My question applies to gas falling in toward a galaxy from the circumgalactic or intergalactic medium, under the influence of gravity from the central galaxy itself as well as the overall dark matter halo. If there is diffuse gas uniformly distributed in a "circumgalactic halo" (assuming some mass density, temperature, and circular velocity distribution), how do I derive the timescale at which that gas will fall toward the central galaxy, as a function of galactocentric distance? Is this a simple classical mechanics gravity problem -- where you derive the "free fall" timescale of gas in different spherical/radial shells, assuming an overall external gravitational potential field? I guess this question could also apply to gas in clusters of galaxies too. Any references or textbook chapters would be greatly appreciated. 

Yes, as mentioned elsewhere, it is possibly possible. Dark matter particles may be intrinsically unstable (though having long lifetimes, which are at least significantly longer than Hubble time). Check for more info here: $URL$ 

It is believed that dark matter is made of particles, which interact with matter only weakly and gravitationally. One common candidate for dark matter are so called WIMPs. WIMPs, specifically, are heavy and may be their own antiparticles. And as any other particles dark matter particles can be produced at sufficiently high energies. The mass of dark matter particles is unknown, but is estimated to be of order $1$-$100 \textrm{GeV}$, which corresponds to temperatures of $T_{DM}\approx 10^{13}$-$10^{15}\textrm{K}$, at which these particles may be expected to be produced. Such enormous temperatures are barely attainable in any reasonable astrophysical processes, but say in core-collapse supernovae newly formed core has temperatures of $T_{SN,after}\approx 10^{11}\textrm{K}$, and probably more during the collapse phase. Then a crude estimate would suggest that the amount of dark matter produced is $M_{DM}\approx e^{-T_{DM}/T_{SN,max}}M_\odot$. Or, in number form $\log_{10}(M_{DM}/\textrm{kg})=30.3-0.43(T_{DM}/T_{SN})$. This means that at $T_{SN}=1.4\cdot 10^{-2}T_{DM}$ the amount of dark matter produced during a supernova will be around one kilogram. Such temperatures are fairly reachable for $1 \textrm{GeV}$ DM particles. So one can optimistically expect few kilograms of dark matter produced per supernova. Now the question. What is a typical dark matter production in core-collapse supernovae? A good answer, I imagine, would be a more robust expansion on the existing estimate. Any constructive comments are welcome.