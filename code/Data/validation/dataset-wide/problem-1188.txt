Ensure Mysql is stopped (the RPMs don't start it, but just be sure) Delete /var/lib/mysql/* run /usr/sbin/mysqld --initialize-insecure --datadir="/var/lib/mysql" --user=mysql (which is what the init.d script does, if /var/lib/mysql is empty, except we're using 'insecure' which means no root password is generated) Start mysql Use mysql client to log on with empty password and set the root password to whatever you want. I'm really not a fan of using Ansible or whatever to delete database data files. Even though this method has suitable checks to make sure it doesn't delete a live database, it still seems like you're creating a dangerous situation here. However, it's another possible approach. 

I have a Windows Server 2012 cluster with two nodes running SQL Server 2012 for production and a Windows 2012 single server with SQL Server 2012 for homologation. I just restored the production database backup on homologation and tried some queries. The queries on production are taking longer to execute than on homologation environment. This servers are all Hyper-V VMs, with 24GB RAM and two Intel Xeon 2.90GHz each. Why this different performance? Is it possible to run a query on a specific node without changing the current active node in the failover manager? 

As you may se in the tooltip image, the Clustered Index Scan with 75% of cost is using the table primary key instead of one of the following indexes. 

For constant scans there is an article here which may help explain Constant Scan in Execution Plans. The estimated number of rows is just that, an estimate. The Query Optimizer attempts to use past executions in order to guess how many rows are going to be returned by any given operation. If you're using something like a restore to practice query tuning then odds are that after your restore operation you did not perform any database maintenance. Statistics helps to determine things like estimated rows, and index maintenance will help to both intelligently query the data and provide better information for those statistics. If updating the statistics doesn't work, it's probably because there are not very many queries that have been executed against the database. Running that query a few times will give it some better information, but if the execution time is excessive other options need to be considered to help the optimizer. For making this query perform better you need look no farther than the worktable in the I/O statistics you've returned. IO Statistics is a great option for getting an idea of how much processing you're really doing on your data. The work table shown here means that the optimizer is saving the dataset then reviewing it multiple times. This can be reduced drastically by condensing the three subqueries shown here into one statement as follows. 

Check to see if /var/lib/mysqld exists. Remember this. Install Mysql RPMs (the post-installs automatically create /var/lib/mysql if it doesn't exist - you can't really stop this from happening) If (1) was "doesn't exist": 

This isn't much of a solution, but it's possible to put the data files in place on the system before installing the RPM packages. That is, on a dev system, install MySQL and set the root password as you want it. Shutdown Mysql and make a copy of the files/directories in /var/lib/mysql (maybe put them in a tar file or something). On a new system, before installing the MySQL RPM packages, take a look and see if /var/lib/mysql exists - if not, create it and untar your files into it. When the RPM installs it won't overwrite those files, and so will start up with your previously set root password. This seems like quite a cheesy option, and probably won't work when versions of the RPMs change (even dot release changes might break because they'll need an upgrade process on the archived data files). However, it's a possible way forward. Another (less than ideal) way forward is something like this: 

Note, I haven't tested the above because I don't have the schema or database so take it with a grain of salt (it might not even compile). 

SQL Server will always use all the available memory is given. As soon as something is read from disk into memory, it will stay there and never be released to optimize performance in case it needs to be read again. It is not uncommon in production environments to see SQL Server instances pegged at 95% memory utilization permanently. This is at odds with normal application use of memory which can cause some confusion. This behavior is regardless of any transaction use in your TSQL scripts and objects. EDIT: Here's an article from Brent Ozar on the topic which contains an absolutely fabulous quote: "SQL Server is using all of the memory. Period." - $URL$ More EDIT: If you want to limit the memory that it uses, the following article has instructions for updating the maximum memory setting which will place an upper limit on memory used. $URL$ 

I need to create a question and answer tables that will have millions (maybe billions) of rows. The current model is: Question Table id_question (PK, auto increment) id_user question_content question_date Answer Table id_answer (PK, auto increment) id_question id_user answer_content answer_date Is this a correct model (considering better query performance)? Should I add the id_question and id_user columns to the primary key? Thanks 

UPDATE Actually the servers are like this: Dev: 2 Xeon E5-2667 (15M Cache, 2.90 GHz) 16GB RAM SQL Server Min Memory: 4096 SQL Server Max Memory: 8192 Query Cost: 43,0161 Execution time: 16s Homolog: 2 Xeon E5-2667 (15M Cache, 2.90 GHz) 16GB RAM SQL Server Min Memory: 4096 SQL Server Max Memory: 8192 Query Cost: 42,6906 Execution time: 14s Production (1 cluster manager and 2 nodes): 2 Xeon E5-2667 (15M Cache, 2.90 GHz) 24GB RAM SQL Server Min Memory: 4096 SQL Server Max Memory: 16456 Query Cost: 45,5453 Execution time: 65s Previously, the dev and production servers were using Min Memory = 0 and Max Memory = 2147483647, but it seems that changing the Max Memory didn't make any difference. PS: I've executed the maintenance plan to rebuild the index and update the statistics after changing the Min and Max Memory. 

I've encountered this issue before and in previous cases for us the solution was to develop a system of ETL processes which bring the information over into the warehouse or reporting database. What we did was design the process to run near continuously and at the head of each iteration we would grab the current maximum datetime stamp of each table. We would then process each record that was generated or updated between the last timestamp and the current one we just retrieved then repeat this process constantly. There is a chance with this for partial data, but with the process running continuously any partial data would be resolved within a few minutes. 

I'm a long time user of MySQL, and have historically used Puppet or Ansible to install it onto boxes. I can automatically remove the test accounts/db, set a root password, add some application and monitoring users and databases and then hand the system over for application deployments, knowing everything's setup and ready to go for them. Since MySQL 5.7, I'm not sure how to approach this. On installation it generates a random root password which it writes into a log file. Obviously, getting that out and working with the restricted account to get it set to the required password is difficult with a script (or config management system). I've had a go at hacking the mysqld_pre_systemd script (on Centos 7) and have that create the data files, then start up mysql with a --init-file option, which I point to a bit of SQL that sets the password as I want. Once it's running, I then connect to it and run 'SHUTDOWN' to stop it, then let systemd carry on as it was to start it up normally. This all seems like a crazy amount of work (although quite possible with Ansible etc). As I've now got to get it going on Centos 6, is there a better way? One thought: Is there a way to specify the root password before installation? 

SQL Server will never ever ever give back any memory that it uses unless pressure is exerted on the service by the operating system. It's designed that way intentionally to do as much processing in memory as possible to prevent disk I/O. In the comments above there's a linked article to A Sysadminâ€™s Guide to Microsoft SQL Server Memory which contains some good information explaining the specific use cases and behavior that you can expect. Generally though it's best to remember that the structure of data held in the SQL buffer cache is based on performance, not resource conservation. Make sure your maximum memory is set appropriately for your environment and needs. If you are running SQL Server in a virtual environment where you are trying to reduce the amount of memory on an ongoing basis then you will need to use a balloon driver or other utility to exert memory pressure on the instance. For performance purposes if you are seeing a sudden flood of complaints it's possible that the SQL instance is running out of memory and is paging to disk, which will result in a very significant performance hit. There are multiple recommendations, but my personal preference is to not use a page file at all which will result in certain crash dumps not being returned in the event of a windows fault. 

I guess the last approach is to petition Oracle to allow setting a root password during installation (maybe via an environment variable that the RPM post-install picks up, or a magic file somewhere that contains the password that the post-install looks for. That would make life so much easier ;-) 

I'm getting a Postgres 9.3.3 install sorted out. My application is Drupal (so read/write), but low-traffic, so all application traffic is sent to the primary master. I have two sites (main and secondary) with two machines in each (again, main and secondary). let's say machines 1 and 2 are in the main site, with machines 3 and 4 in the secondary site. Right now, 1 is the master, and 2,3 and 4 are all hot_standby slaves of it (the master has a DNS CNAME, which is in the recovery.conf files). I've been told that if I wanted to flip between sites, I'd need to promote 3 as the master (by touching the /tmp file), and then can update the DNS to point to machine 3 instead of machine 1. I can then restart each of the slaves and they'll magically start replicating from 3 instead of 1. This sort of strategy absolutely won't work with MySQL, but can it work with Postgres? If needs be, I can stop Drupal from accessing the database while I do this sort of work, to avoid any writes being made. Could it work then? Is there another strategy I should be using to make changing sites (or machines in a site) relatively easy? Could cascading replication from 1 -> 2 -> 3 -> 4 maybe make more sense? I could then promote 3 (and have 4 as a slave of it), but then have to rebuild 1 and 2 to become slaves of 4.