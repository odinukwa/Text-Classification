Singling out Quine, in the context of Kant's synthetic apriori, seems to me out of place. There was nothing special about Quine's attitude towards Kant's synthetic apriori. Quine's specialty was his criticism of the analytic apriori, and this in turn has no special relation to Kant. Kant's synthetic apriori had some following during the 19th century. But by the dawn of the 20th century, practically nobody accepted the synthetic apriori. So Quine is really not special, and is therefore not the issue here. At least one aspect of Kant's epistemology has remained alive, however. It is the thesis that some parts of what we take to be knowledge are constitutive rather than merely descriptive. These parts make the form, and not merely the content, of what we seem to know. The constitution thesis can be separated from the apriority thesis (that is, absolute immunity to experience) which has become obsolete. One useful simile, provided by the later Wittgenstein in On Certainty, while discussing the epistemological status of logic, is the distinction between the water of a river, and the river bed. Constitutive knowledge is like the river bed. The river bed can, and does, change in time (and is therefore not strictly apriori). But it has a deeply different kind of dynamic than that of the river's water. 

From what I've heard personally I think that reincarnation theories usually involve the belief that past lives can be remembered, in principle, even though they usually aren't remembered. That is, if you are properly gifted, or properly trained, you will recall your past lives. There is a lot of internet material about reincarnation memories. See for example here. 

Putnam then concluded that the problem of meaning splits into two problems: first, the determination of extension, which pertains to meaning in the strict sense of the word, and which involves a social "division of labor". Second, the competence that is required from an individual in order to express meanings. This again involves social ingredients, how an individual hooks into a community in a way that enables one to use many words that, strictly speaking, one understands only superficially. 

There is a bit of confusion in the question, that needs to be cleared up first. You start by noting, correctly, that Hume argued that causation is based on habit, that is a subjective basis. Yet you end by attributing to him, incorrectly, the claim that causality is (merely) not valid a priori. Hume's conclusion was rather that causation judgments are not valid at all. That is, not having a rational justification of any kind. Hume was a skeptic. His assumptions were empiricist, but his conclusions were skeptical. Kant saw Hume as the best exemplar of an empiricist. Accordingly, Kant always identifies empiricism with skepticism. And this, I think, is the main reason why Kant "refused" to accept Hume's account of causation. The choice here was not between a priori and a posteriori justifications. The choice was between having and not having (and giving up on) justification at all. 

instantiates the (valid) form p, p->q => q but it also instantiates the (invalid) forms p, r => q p, p->r => q p, r->q => q For an argument to be formally valid, it doesn't have to instantiate only valid forms. This, in fact, seems impossible. It is enough for the argument to instantiate one valid form, for it to be formally valid. And that's how the above argument, in the example, is valid. 

The tension between the evidence of our moral and reasoning faculties and absurdist assumptions leads Camus to criticize existentialists for not remaining faithful to their “initial insight” as Ronald Aronson remarks: Stanford Encyclopedia of Philosophy 

It might not only be “thinking”, but choosing as well. Notice that Turing does not deny the existence of extrasensory perception although he does not find it intelligible or meaningful in terms of his theory. He faces the possibility that his approach may not be complete or even accurate. Haidt’s “The Righteous Mind” raises questions about our human rationality. His lecture, “The Rationalist Delusion” summarizes his position. If Dennett is trying to explain human beings as “rational agents”, he may not be explaining human reality as it really is although his explanations may work well for AI. Question 4: Similarly how does this tie into Chalmers notion of Philosophical Zombie? Why might imagine that such autonomy can serve to discriminate between philosophical zombies and humans, since zombies act like they are autonomous, but aren't being driven by an autonomous agent on the "inside" (See my previous post about "freewill zombies") Given the Conway-Kochen theorem, it is worthwhile separating freewill agency from other forms of subjectivity since there are results that pertain to free will alone. Consider a quantum particle that has free will. Such particles may be close approximations to what a freewill zombie might be. There are at least two objections to saying they are freewill zombies. (1) A freewill zombie is a p-zombie. A p-zombie is supposed to be a human being. A quantum particle is not a human being. (2) One needs to verify that there is nothing more to the subjectivity of quantum particles than freewill agency. 

Consider the following about the Chinese Room Argument. First, strong AI is a view that programs running on Turing machines (computers) not only produce correct results but also generate consciousness when run. Second, assume there exists a program that passes the Turing test for Chinese when run on any Turing machine no matter how advanced or primitive that computer may be. Third, let a human who does not understand Chinese simulate a Turing machine by following that successful program while being isolated from outside influence in a “room”. If strong AI is correct this should be a way for the human not only to give a correct answer but also to understand Chinese. This program would be a way for someone to learn Chinese. Fourth, Searle claims the human will not understand or learn Chinese, but the human will be able to pass the Turing test using the program since the program is assumed to be able to do so. Fifth, look at the program as the “mind”. Look at the computer as the “body”. The body runs the mind and this supposedly generates not only results, but also understanding of Chinese. It is this mind-body dualism that is the problem for a physicalist. Given the above, I will try to answer this question. 

One place to look for an answer to this is in Stephen E. Toulmin’s The Uses of Argument, last updated in 2003, Cambridge University Press. Toulmin recognizes that there has been a difference between logic and epistemology. Logic has been concerned with analytic issues where standards of entailment predominate while epistemology has a broader reach trying to justify substantial assertions using field-specific standards. His view of how things should be is pertinent to your question: (page 234) 

I think not. The characterization of "transcendental deduction" that you quoted from the SEP seems to me too liberal. Kant's sense of "transcendental deduction" is more specific than that. For Kant it is a kind of proof of right, a proof of legitimacy. The backdrop of Kant's deduction is David Hume's criticism of the concept of cause. Hume argued that the concept of cause, as it is traditionally conceived, is not derived from sense experience, and is therefore illusory and illegitimate. Kant agreed  that the traditional concept of cause is not derived from sense experience, but insisted that it is nevertheless legitimately applied to sense experience. It is to prove this legitimacy that was the task of the transcendental deduction. In addition, Kant observed that Hume's criticism applied not only to the concept of cause, but to the larger set of basic concepts that are being applied to the objects of sense experience - the categories. So it became the task of the transcendental deduction to prove the right, the legitimacy of applying the categories to the objects of sense experience. 

The answer lies in the Phaedo, not much after the passage on suicide, to which you referred. The issue of suicide arises in the context of the question, put to Socrates, why he seemed to favor death, rather than struggling to avoid it. And a part of his answer was, that the knowledge which the philosopher seeks all his life, seems to await him after death. Because the body is mainly an obstruction to true knowledge. Knowledge is, then, not merely possible after death. It seems to be more possible after death than during life. At least so for someone, like a philosopher, who has been preparing himself during life... 

Bergson's thesis was not that time is space-like, but that time understood "in the common way" is space-like. Bergson argued that practical reasons cause us to regard time as space, but that strictly speaking, the thesis that time is space-like is not merely wrong, but self contradictory. Influences from Aristotle and Kant can be detected in Bergson. For example, Bergson's reaction to Zeno's paradoxes is similar to Aristotle's: that motion is essentially continuous, and cannot be broken into separate moments. 

Socrates does not talk here about fear from personal harm, as when one fears that the gods will strike or punish her. Not at all. Socrates talks here about a fear from shame, and about a fear from ill reputation, in the eyes of the gods. That is, because the pious person admires the gods as unusually wise and virtous, she is afraid to disappoint them, to lose face in front of them, for not being virtuous enough. The same could very well have applied to Socrates's regard for Euthyphro. Supposing Socrates was sincere in calling Euthyphro a "revered friend", it is implied that Socrates would not want to disappoint Euthyphro, to lose his appreciation. This could well be, then, the sense in which Socrates feared (about) Euthyphro: a fear from being devalued, from not being respected by Euthyphro, for not being virtuous enough. 

The room is only a way to isolate the human from outside influence. It is not the computer. There is nothing for the room to learn. The human needs to learn or understand Chinese by running the program. Running the program is what counts not which computer is used to run the program. The program can be moved around to different computers or different humans and the results should be the same. The question is does running the program anywhere generate not only a correct result, but also understanding of Chinese? If it does, then this would be an alternate way for someone to learn a new language. Reference: John Searle, "Minds, Brains and Programs" 

It may be clearer to restrict the concern to Plantinga’s “naturalism” which implies a belief that there is nothing “God-like”, that is, there are no agents and everything is the result of event causation. See Plantinga’s Evolutionary Argument Against Naturalism (EAAN) in Where the Conflict Really Lies. The problem of evil may challenge not just a certain group of theists who believe in an omnipotent, omniscient and omnibenevolent God, but it also challenges this naturalism. The problem of evil has four premises assuming the concurrent existence of both a particular type of God and evil: 

The beam would be continuous, or rather a continuum, if that statement were true, but is it? Unlike Zeno’s arrow which we can watch going to the target, we can’t see the beam go to the measuring device. Is the reality surrounding the measurement of the beam also a “basic particle”? If it isn’t then the target photon and whatever that beam was prior to acting like a photon at the target are not the same. If the beam does not contain its limit point as a set of reality like itself, then it would be like the rational numbers lacking an irrational limit point and the beam would not be continuous. So to answer the question, Is anything truly continuous?, would require answering the question about what happens during a quantum collapse. 

It will not be possible for computers to understand language the way humans do. John Searle’s Chinese Room Argument (CRA) eliminates that path for strong AI by noting that human understanding cannot be reduced to a program instantiated on a computer. So, if by “machine” one means a Turing machine, the answer is “no”. For more information on this, see $URL$ The reason to eliminate this is so we don’t get bogged down with strong AI in spite of those who think there is a way around the CRA. Strong AI's reduction of mind to a program is simplistic. There are other potentially more powerful ways to reduce mind to something physical or perhaps even eliminate consciousness altogether if one uses something besides programs. However, the XKCD comic you referenced suggests in frame 5 that maybe even this is not possible. That frame notes that there are many ways to express something and each of these can still be interpreted by different humans differently. In other words this suggests that there may not be any deterministic way to link, one-to-one, a state of mind with some non-mental physical state. Although this suggests “chaos” what is really the issue is indeterminacy at least from the perspective of someone trying to make a reduction or elimination of mind. That is, given words, gestures, tonality, pauses, neurons, whatever a physicalist might accept as physically real, one may not be able to deterministically say how another human will understand a sentence. This would suggest that mind cannot be reduced to the objects physicalists have available. There may be no one-to-one deterministic function mapping these physical states to an individual’s understanding. This isn’t a proof that there is no such function. The comic though emphasizes the problem for someone who would like there to be such a function reducing or eliminating mind. If that deterministic function does not exist, not only is strong AI not a way to generate human understanding based on Searle’s CRA neither is anything physical that Searle might offer as an alternative to strong AI. None of this means that we cannot improve how machines store texts, deliver them to us, protect us by identifying friends and foes and many other things. All of that may involve using gestures, tones and pauses, even neurons. But machines are not winning a race against us. They are not even in a race with us. We use and improve machines to enhance and protect ourselves and if we are racing with anyone it is with other humans who are doing something similar.