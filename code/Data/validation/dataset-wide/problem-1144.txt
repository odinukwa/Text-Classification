From reading the documentation, it looks like DML on a synonym for a normal object will not be replicated. For example, you have a table called & a synonym called that points to . An into will succeed, but an into will not, as it is a synonym for another table & not a real base table. Test this in your dev environment to verify. 

The clause in the DDL statement causes the actual population to be deferred until the first refresh. While Oracle parses the actual SQL used to populate the view, it does not execute it & will therefore not pick up "runtime" problems. This is easily demonstrated. Parsing error, due to not being a datatype: 

This blog post shows you the required steps. I'd think long & hard before doing so, though as recreating control files is not something to betaken lightly. You don't need to do anything with the +ASM instance. 

You can create the database link using a full TNS connection descriptor, to workaround the requirement of needing tnsnames.ora entries on the DB box. For example: 

Basically your database has stalled because it has ran out of space to store archive logs, and needs to switch one. To remedy, delete the generated logs (assuming you don't need them for backup and recovery purposes), then execute (as SYSDBA): 

If you get a during any of this, then a different solution is needed. You might have to set the hidden parameter and/or recreate the control file to recover from this. 

The most common cause of this is virus scanning, as virus scanners tend to lock files. Try excluding the directory from scanning. 

There will be an easier way to do this, but I needed some practice and my brain hurt thinking about how to do the unpivoting and keeping the last record. SQL Fiddle. If you've never used before, my apologies. 

For completeness, whilst Jack's answer is technically true, it is possible to use Data Cartridges to expand on vanilla Oracle offerings. In fact, a company called CopperEye released a new indexing method (patented, now not available) utilizing this functionality. See this old press release. The patent makes for fascinating reading. 

I imagine the unescaped character in your password is causing problems in the shell. Escape it and you should be ok. 

I don't think there's much value in me copying what others have done so well in explaining in the past, so I'll just point you at a brilliant blog post: Reclaiming Unused Space in Datafiles. Essentially you just need to do: 

It's a bitwise and operator. See the documentation here. Wikipedia goes into lots of detail on bitwise operations. Logically, the query you give: 

Good question. I'll give a simplified answer. Oracle supports two character sets simultaneously, by way of different datatypes and parameters. A "normal" database-wide characterset and a "national" characterset. Now, the "normal" characterset affects the way that , and data is stored. The "national" characterset affects the way that , and data is stored. These are dictated at database creation time. For example: 

Running 4 instances on one machine is trivial, so I won't explain further. Consolidating to a single database is also easy if the separate databases don't have conflicting schema names. If they do, it may not be an issue as long as the applications/interfaces/packages don't have hard-coded schema names - it's easy to export data from one schema in a database & import it into a different schema on another database. 

Basically, is causing this, because . One of the columns in your self-joined table will be all s. Here's a little test case that shows why this can happen. Naughty equality and the way works, picking column names to join on for you. Setup: 

sqlplus is not in your path. Use instead of , as that will read the users ~/.bash* files & set the environment accordingly. 

Without using quotes, MySQL is essentially inserting the integer 1980 ( which is ) as a date, as it treats it as mathematics: 

... can use the functional index to select the pre-calculated value(s) of without having to call the function for each row in the table. Essentially, the query can look like this in pseudo-code: 

Either create the table manually beforehand, or specify the column names an NULLability in the CTAS statement: 

Make sure you to get the output from . Change the query in the to alter the table list it generates queries for. Note: Doesn't do anything for 'CLOB'/'BLOB' columns. Example output: 

... where is the name of the listener that is listening on port 1531. You can get this name from your file. For example: 

... which can then be inserted directly into an Oracle column. All a bit of a long way round, to be honest. Use in your statements instead. 

What you are experiencing is called caching. The database doesn't have to go to disk the 2nd time because it can either get the data from its own buffer cache, or the operating system/disk array can also provide the data faster from its own cache. In order to see whether Oracle fetched the data from disk, or used its cache you can enable autotrace in SQL Developer. You'll get something like the following: 

Or, you can create the equivalent of a Unix dot file. Create a file called and place it in , then add this to it: 

Amazon Athena uses Presto, so you can use any date functions that Presto provides. You'll be wanting to use , or similar. 

Unfortunately in Oracle 11.2 only supports SHA1 (documentation link), which is 160-bit. . in Oracle 12.1 supports SHA2 (documentation link), which does what you require. There are some free implementations of SHA2 just a google away. This blog post, for example. As for decrypting a hashed password? I don't think you understand hashing. Hashing is 1-way, unless you brute-force it, or use Rainbow Tables. To check if a password is correct, you would hash it and compare it to the stored hash. 

Consider using de-duplication if you have lots of identical XML - documentation link. I wrote a huge unit test, but it turns out that SecureFile LOBs are always stored in a Lob Segment outside the row! 

What you are asking is impossible, unless you brute-force the password hash for the user. How do you expect a system to be secure if passwords are stored in plain text? 

I have a table with an column called . I have a second string, let's call it (a ) that needs placing inside a given string after the word . Casting to truncates the string, so I cannot use the likes of (. I have used to check that there are a few thousand columns that are >8000 characters. An example of what I want to achieve (albeit with much longer strings): 

... will get you the next available ID. (You may be able to omit the parameter and have Oracle auto-generate the ID, but I can't remember off-hand if that'll work). 

You're have AMM enabled, so Oracle will manage it for you automatically. will be set to a non-zero value, which means: 

Obviously, this isn't incremental. There's no really easy way of doing it incrementally based on a query/the data. You'd have to roll your own tool to do it - flashback query could help. What data volume are you dealing with? If < a few million rows, just export the full data each time. 

You can also do this with Virtual Private Database, but I think it's an expensive extra licensed option. You use DBMS_RLS to configure the relevant security policies that you require. 

The ISO SQL 2008 Standard document ISO/IEC 9075-1:2008 Information technology -- Database languages -- SQL -- Part 1: Framework (SQL/Framework) is now freely available from the ISO website. 

Ok, minimal test case that reproduces the error, showing it's the intermediate table PK that is the problem: 

A operation is . When using , remember that any operations you execute will implicitly the current transaction. 

The release notes for MySQL 5.7 are here. "What's new in MySQL 5.7" can be found here. Changes of note: 

All releases belong in the table, all artwork in the table. The table joins the two, with the column enforcing the display order. Insert the covers with , then the rest (back cover, inlay etc) with 2, 3, 4... etc as needed - A simple will then deal with the ordering for you. If you want to doubly ensure the cover is first, you could always add a column to and set it to 1 for covers. 

... to Be aware that it will impact connection performance. To increase the logging level to be more verbose, you can also use the and options for the parameter. 

is for /, is for /. If your normal characterset is UTF%, you're generally safe staying away from the datatypes unless you have some strange internationalisation requirements. If so, feel free to edit your question! 

Yes, it's safe to delete them. If you're running on Linux, set up logrotate to compress & then delete after a set period of time. Examples of Oracle logrotate configuration can be found here. 

will be unless you have explicitly set it with . I realise that this isn't what you asked, but it's easier than messing with pools! 

Be aware that system stats can make a massive difference to database performance, and you're best gathering them first on a pre-production system with identical disk, just to make sure that there won't be an adverse impact on performance. To analyse the Oracle system tables, use: 

In case you were wondering, "" is a reference to the newly inserted row, and each column can be referenced individually. Test case: 

I think you'd be better off using the text version of the explain plan output rather than XML, as it gives you a pre-formatted readable ascii representation of the query plan. eg: 

The documentation for states that to shell-out you just have to use blackslash pling, followed by the command: 

An oracle database is the physical files that make up the database itself (control files, data files etc) - Documentation link. A database is associated with one or more instances, with multiple instances making a RAC setup - Documentation link. As far as your second question is concerned, multiple instances of a single database is a RAC setup. 

I'll do it in stages to make it easier to understand. I put your data into a table called - added a primary key as I assume you'll have one and it makes things a little easier: 

The view is populated when the server starts - it recursively reads the timezone files from and they are used to provide data for the view. Double check that the files exist (as they should in a full installation) and that the user you are running the database under has read permission on all of the directories and files under . You'll need to restart the RDBMS for changes to take effect. 

... the local time is 08:00:00, which is 16:00:00 UTC (08:00:00 + 8 hours, because it is 8 hours behind UTC). 

You can use 3 CTE expressions to generate the data, then cartesian product them together. Test table: 

Physical reads are pulled from disk. Another factor that makes the initial query slower is the fact that Oracle has to hard parse a query the first time it sees it - this involves finding the optimum (as far as the Oracle optimiser is concerned) execution plan for the query & is quite computationally (CPU) expensive, thus takes time. 

If you want me to expand further on all of the steps required to manually create a database, just ask (if you don't already know). 

The stored procedure takes an input, which is the start offset. Create another cursor, and use your concatenated ID in the clause. Why do you need to process 1000 records at a time? It'll be slower iterating this way. Often you can achieve the same thing using one or two lone SQL statements, which end up way more efficient. 

The easiest way to do this is to add another step prior to the end of the chain that changes the job to start execution of the chain at . Something like this: 

You'll see one process for each database that is up. For example , where is the instance name. You can also ask the listener which services it is serving connections for, with: 

The cursor is just used to demonstrate. I'll add that your question is poor, as you didn't even take the time to make sure that matched with itself on the next row - you used instead. If you expect random internet people to spend time writing quality answers, would it hurt to make sure your question was of sufficient quality? 

I'll answer this at a high level for you. The two backup methods work at different levels. An backup is a physical backup and a Data Pump backup is a logical backup. A database dump using is a 1-time export of one or more database schemas. It backs up DDL (table structures, views, synonyms, stored procedures, packages, etc), plus data. An backup is a point-in-time backup of an entire database (for the purposes of this question). It backs up the physical blocks that make up the database (data files, control file, archive logs etc) and, in combination with the database archive logs, allows point in time recovery options. In the event of a complete database loss an backup can be used to restore the complete database. However, a data dump taken using would need a new database creating before the data could be imported using . For a hobbyist Oracle XE database (that may not be in archivelog mode), backups using will probably suffice. The Oracle Documentation covers this far better than I could ever explain. Oracle® Database Concepts - Backup and Recovery 

Oracle's datatype behaves as both an ANSI and datatype. This was a design decision that only Oracle knows the reasoning for. I'll add that Oracle isn't the only RDBMS that doesn't follow ANSI SQL standards in this way. Obviously, you can remove the time portion with . 

Oracle 8.x.x has been out of support for some time. Apologies for the bad news, but your only option is to either recover the software from the dead disk, or ask Oracle (obviously with a valid support contract) for a copy of the software. Raise a ticket on My Oracle Support and they will help you.