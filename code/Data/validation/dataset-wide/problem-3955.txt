If $u$ is e.g. Lipschitz the desired inequality is true. Rewrite the original inequality as $$\frac{u(t)-u(t_0)}{t-t_0} \leq \frac{1}{t-t_0}\int_{t_0}^t u(\log v)'\,ds.$$ Taking $t$ to $t_0$ we get $$(\log u)' \leq (\log v)'.$$ Integrating gives the desired inequality. If $u$ is not continuous, note that $\limsup_{t \rightarrow t_0^+} u(t) \leq u(t_0)$ by the given inequality, so the same arguments as above lead to $$\frac{\overline{D}^+ u}{u} \leq (\log v)'.$$ (Here $\overline{D}^+w(x_0) = \limsup_{x \rightarrow x_0^+} (w(x)-w(x_0))/(x-x_0)$ and similarly for $\underline{D}^+$ with $\liminf$ instead). It is easy to verify that $$\overline{D}^+(\log u) \leq \frac{\overline{D}^+ u}{u},$$ so we have $$0 \leq \underline{D}^+(\log v) - \overline{D}^+(\log u) \leq \underline{D}^+(\log v - \log u),$$ and $\log(v) - \log(u)$ is thus increasing, giving the inequality. 

The only such functions are $0$. Compact support implies $$\int_{\Omega} \Delta u = 0.$$ This along with the subsolution hypothesis means that $\Delta u = 0$. Any compactly supported harmonic function is identically zero by analyticity. 

Functions in $F$ and $T$ are, at least around a level set where the gradient is nontrivial, the same up to "reparametrizations preserving level sets." To see this, assume that $f: \mathbb{R}^n \rightarrow \mathbb{R}$ is in $F$, that $0$ is a nontrivial level set of $f$, and that $g > 0$ in a neighborhood of $0$. If we take a function $h: \mathbb{R} \rightarrow \mathbb{R}$ with $h(0) = 0$ and $h'(z) = \frac{1}{g(z)}$ then the function $\tilde{f}(x) = h(f(x))$ has the same level sets of $f$, and furthermore $$|\nabla\tilde{f}| = h'(f)|\nabla f| = 1,$$ so $\tilde{f}$ is the signed distance from its $0$ level set nearby this set. Heuristically, we "adjusted the heights of horizontal slices of $f$" so that it becomes the distance function. As a simple example, take the simple example $f(x) = |x|^2$. Since $|\nabla f| = 2|x| = 2\sqrt{f}$ we have that $f \in F$. Then taking $h(z) = \sqrt{z}$ we transform this function to $|x|$, the distance from $0$. If we have any increasing radial function we can do the same. More generally, one can view the above discussion as saying that any $f \in F$ can, around "nondegenerate level sets," be written as some reparametrization of the distance function from this level set. 

The constant $C_H$ must depend on $x$ and $r$. Consider for example $u = e^{\frac{1}{2}|x|^2}$, which satisfies $$\Delta u = (1+|x|^2)u.$$ Then $u$ has a minimum of $1$ at $0$, which clearly doesn't control the maximum of $u$ on $B_{\delta r}$ times any constant independent of $r$. Furthermore, $C_H$ must depend on $x$ because if we fix $r$ then the ratio $$\frac{u(x+r)}{u(x-r)}$$ blows up as $x \rightarrow \infty$. 

Taking $r < \frac{1}{2C}$ should work. Indeed, if a circle of radius $r$ touches the graph of $f$ by below at two points, then the curvature $$\kappa(x) = \frac{f''(x)}{(1+(f'(x))^2)^{3/2}}$$ is larger than $-\frac{1}{r}$ at the touching points. Since $f$ lies above the circle, $\kappa \leq -\frac{1}{r}$ somewhere in between the touching points, hence $f'' \leq -\frac{1}{r}$ there. Semiconvexity completes the proof. 

It is a good exercise to show that for a function $u: \mathbb{R}^n \rightarrow \mathbb{R}$, $C^{1,\alpha}$ regularity is equivalent to the following: there exists a linear function $l_x$ such that $$\|u-l_x\|_{L^{\infty}(B_r(x))} \leq Cr^{1+\alpha}$$ where $C$ is uniform. The forward direction is clear; for the other direction, observe that for points distance $r$ apart, the linear approximations differ by $Cr^{1+\alpha}$ nearby these points, so (up to changing $C$ by constants depending only on $n$ and $\alpha$) their slopes can differ by at most $Cr^{\alpha}$. Actually, in the proof above I only needed that I can choose $C$ uniform on neighborhoods. This is crucial; as Pietro notes, we can get this property at a point (say 0) by taking an arbitrary bounded function and multiplying by $|x|^{1+\alpha}$, which clearly doesn't give $C^{1,\alpha}$ regularity away from $0$. The equivalence of "pointwise $C^{1,\alpha}$ regularity" with uniform constant and $C^{1,\alpha}$ is the basis of most approaches I know to proving $C^{1,\alpha}$ estimates in PDE. This is usually done by estimating a solution with a linear function, rescaling, and improving the estimate geometrically, i.e. finding $r_k \rightarrow 0$ and $l_k$ so that $$\|u-l_k\|_{L^{\infty}(B_r(x))} \leq r_k^{1+\alpha}.$$ One can analogously define "pointwise $C^{k,\alpha}$" by approximation with $k^{th}$ order polynomials to get Holder estimates on higher derivatives. 

It's well known that there are no non-constant polynomials with integer coefficients whose values at integer points are primes. Could this result be generalized to the case of prime powers? The question is whether there exists a polynomial $p(x) \in \mathbb{Z}[x]$ with degree at least one such that for all $x \in \mathbb{Z}$ $|p(x)|$ is prime power. 

Yes, there is a way to guess a number asking 14 questions in worst case. To do it you need a linear code with length 14, dimension 10 and distance at least 3. One such code can be built based on Hamming code (see $URL$ Here is the strategy. Let us denote bits of first player's number as $a_i$, $i \in [1..10]$. We start with asking values of all those bits. That is we ask the following questions: "is it true that i-th bit of your number is zero?" Let us denote answers on those questions as $b_i$, $i \in [1..10]$. Now we ask 4 additional questions: Is it true that $a_{1} \otimes a_{2} \otimes a_{4} \otimes a_{5} \otimes a_{7} \otimes a_{9}$ is equal to zero? ($\otimes$ is sumation modulo $2$). Is it true that $a_{1} \otimes a_{3} \otimes a_{4} \otimes a_{6} \otimes a_{7} \otimes a_{10}$ is equal to zero? Is it true that $a_{2} \otimes a_{3} \otimes a_{4} \otimes a_{8} \otimes a_{9} \otimes a_{10}$ is equal to zero? Is it true that $a_{5} \otimes a_{6} \otimes a_{7} \otimes a_{8} \otimes a_{9} \otimes a_{10}$ is equal to zero? Let $q_1$, $q_2$, $q_3$ and $q_4$ be answers on those additional questions. Now second player calculates $t_{i}$ ($i \in [1..4]$) --- answers on those questions based on bits $b_j$ which he previously got from first player. Now there are 16 ways how bits $q_i$ can differ from $t_i$. Let $d_i = q_i \otimes t_i$ (hence $d_i = 1$ iff $q_i \ne t_i$). Let us make table of all possible errors and corresponding values of $d_i$: position of error -> $(d_1, d_2, d_3, d_4)$ no error -> (0, 0, 0, 0) error in $b_1$ -> (1, 1, 0, 0) error in $b_2$ -> (1, 0, 1, 0) error in $b_3$ -> (0, 1, 1, 0) error in $b_4$ -> (1, 1, 1, 0) error in $b_5$ -> (1, 0, 0, 1) error in $b_6$ -> (0, 1, 0, 1) error in $b_7$ -> (1, 1, 0, 1) error in $b_8$ -> (0, 0, 1, 1) error in $b_9$ -> (1, 0, 1, 1) error in $b_{10}$ -> (0, 1, 1, 1) error in $q_1$ -> (1, 0, 0, 0) error in $q_2$ -> (0, 1, 0, 0) error in $q_3$ -> (0, 0, 1, 0) error in $q_4$ -> (0, 0, 0, 1) All the values of $(d_1, d_2, d_3, d_4)$ are different. Hence we can find where were an error and hence find all $a_i$. 

Is it true that every positive rational number $r = \frac{n}{m}$ could be represented as sum of $\frac{1}{k}$ for different $k$'s: $$ r = \sum_{i=1}^{s} \frac{1}{c_i} $$ where all $c_i$ are different? If true, are there any bounds on number of summands $s$ based on $n$ and $m$? 

Yes, I think it's true. Say we follow the line $(x,\alpha x)$ for $x > 0$ and $0 < \alpha < 1$. Both sides of the desired inequality have no linear part at $0$, so we examine the second derivatives. Keeping only dependence of the coefficients on $\alpha$, the second derivative of the LHS goes like $$(1-\alpha)(1+x)^{p-2}$$ and for the RHS goes like $$(1-\alpha)(1+x^{p-2}).$$ It is clear that the left is controlled by a constant independent of $\alpha$ times the right for all $x > 0$. The other regions can probably be taken care of similarly. 

This is actually pretty cool. Superharmonic functions bounded below in $\mathbb{R}^2$ are constant, while there are nonconstant superharmonic functions bounded below in $\mathbb{R}^n$ for $n \geq 3$. Here is a proof that doesn't use complex analysis, and only uses that the fundamental solution in $\mathbb{R}^2$ ($\log(|x|)$) is unbounded from above and below, and the maximum principle. Slide $u$ so that its minimum on $\partial B_1$ is $0$. Take the fundamental solution $f(x) = -\log|x|$, which is $0$ on $\partial B_1$. Since $u$ is bounded below and log is unbounded, $\epsilon f(x) < u(x)$ for $|x|$ sufficiently large (depending on $\epsilon$). By the maximum principle, $u(x) \geq \epsilon f(x)$ in $\mathbb{R}^2 - B_1$ for all $\epsilon$. Taking $\epsilon$ to $0$, we see that $u \geq 0$ outside $B_1$. But then, we see that $u$ takes its minimum in $\bar{B_1}$, and by the mean value inequality any superharmonic function with an interior minimum must be constant! This result is false in higher dimensions. For a counterexample, just take the fundamental solution $|x|^{2-n}$ and cap it off above in $B_1$ by a paraboloid and smooth it out. 

This inequality is not true. Here is a counterexample: Let ${\bf x},{\bf y} \in \mathbb{R}^2$ with ${\bf y} = 0$ and ${\bf x} = (1,\epsilon)$ for $\epsilon$ small positive. Let $g(x,y) = Cy^2$ with $C(\epsilon)$ very large, chosen say so that $${\bf x} - \nabla g({\bf x}) = (1, -M)$$ for some $M$ large. We now construct $f$ convex so that $\nabla(|x|^2/2 + f)(2,-10) = (1,-M)$ and $\nabla f(0) = 0$, which would violate the desired inequality. We rewrite this as $\nabla f(2,-10) = (-1,10-M)$, $\nabla f(0) = 0$. Take $$f(x,y) = \frac{1}{2}(C_1y^2 + C_2(x+y)^2)$$ for $C_1,C_2$ to be chosen momentarily. Then $$\nabla f(2,-10) = (-8C_2, -10C_1 - 8C_2), \quad \nabla f(0) = 0.$$ Taking $C_2 = 1/8$ and $C_1$ so that the second component is $10-M$ (if $M$ is large then $C_1$ can be chosen positive, making $f$ convex), we are done. The constants in this example are somewhat arbitrary; geometrically, the point is that we can make $g$ "very monotone" in one direction so that the non-expansivity of $(Id + \nabla f)^{-1}$ can't save us. 

I'll take a stab. In the following we consider the case $W^{1,n}$ in $\mathbb{R}^n$. My short answer is that under rescaling by factor $\lambda$, derivatives scale by $\lambda$ and volumes by $\lambda^{-n}$, so integrating derivatives to the $n$ won't change under rescaling. The following examples illustrate how this affects embeddings. As for no Holder continuity, look at a smooth bump function $\varphi$ supported on $B_1$ with $|\nabla \phi| < 2$. The rescalings $\varphi(x/\epsilon)$ have arbitrarily bad modulus of continuity, but bounded $W^{1,n}$ norm, since (key point) the derivative to the $n$ (~$\epsilon^{-n}$) grows exactly like the volume of support (~$\epsilon^{n}$) decays. This says that we cannot control the modulus of continuity by the $W^{1,n}$ norm. (As expected, these functions have unbounded $W^{1,p}$ norm for $p > n$.) As for not embedding into $L^{\infty}$, the way I would try to see how things could go wrong is take a function $\psi$ positive, supported on $B_2$, with $\psi \equiv 1$ on $B_1$ and $|\nabla \psi| < 2,$ and add dyadic rescalings together. Consider $$u(x) = \sum_{i} h_i\psi(2^{i}x)$$ for some $h_i$ we will choose to give bounded $W^{1,n}$ norm but unbounded height of $u$. Note that $|\nabla (h_{i}\psi(2^{i}x))|$ grows like $h_i2^{i}$ and they are supported on disjoint dyadic rings of volume going like $2^{-in}$. Thus, to get bounded $W^{1,n}$ norm we want $$\sum_{i} h_i^{n} < C.$$ Again, the key point is that volume decays with the same power that the derivatives of rescalings to the $n$ grows. To give unboundedness we just want $$\sum_{i} h_i = \infty.$$ The canonical example of such a sequence is $h_i = 1/i$. Ultimately this is just the same example as you gave since $\sum_{i=1}^k 1/i$ ~ $\log(k)$ ~ $\log\log(2^k)$ is the size of $u$ at $r = 2^{-k}$, but it shows how this example naturally arises. 

Hello, I am a PhD student who does not have extensive computational experience seeking advice from those experienced with computational modelling as to which method would be most appropriate for solving my particular problem. Background Physical Scenario The Salvinia is a small floating fern. Its leaves have upon them a forest-like structure of fronds, with a particular shape and particular regions of hydrophobia and hydrophilia. This structure, also found elsewhere in nature, allows the Salvinia to maintain a persistent, stable air layer on its surface due to the phenomenon of surface tension. For those familiar with the phenomenon of capillary action, this physical scenario is closely related, and involves many of the same considerations. Mathematics In brief, the interface between the air and the water is often constructed according to the method of Gauss. Operating on a variational principle, this method involves writing the free surface energy, the "wetting energy" due to contact with the solid boundaries (fronds) and gravitational potential (if desired) as action functionals to be minimised. It is also usually desirable to impose a condition on the volume bounded by the surface, specifying that it should not change under the variation, in order to fix a unique surface with respect to translations. Classical formulations have viewed the surface as a height function over a euclidean domain. This can cause problems when the surface curves back on itself, as in the case of some sessile drops, for example. Thus, I have written the action functionals in terms of functions $X^A$ (where $A=1,2,3$) which define the embedding of the surface into three-dimensional euclidean space. Why is this a problem? The difficulty I have encountered is that the solid boundaries (fronds) do not have a simple geometry. Take, for example, the case where the fronds are cylinders. It is then possible to define the surface as a function $u(x,y)$ over a domain $\Omega$. The functional is can then be decomposed into an interior term and a boundary term using the divergence theorem, and solved using a finite element method. Now consider the (still relatively simple) case where the frond is a cone, rather than a cylinder. Now, as the surface moves up and down vertically, the location and shape of the boundary as viewed in the $(x,y)$ plane changes, depending on the height and curvature of the surface. What I have already tried I have produced solutions for the cylinder case using FEMLAB, and replicated those results with COMSOL. However, I was unable to think of a way to incorporate more complicated boundary structures (even simple ones such as a cone). I have had slightly more success with the Surface Evolver, developed by Ken Brakke. This is also a finite-element-style scheme, which works by evolving an initial surface using a gradient descent method. The software is stable and well-written, and I have been able to produce results for a cylinder, a cone and hyperboloid. However, as the solid boundaries must be defined as level-set constraints, I assume that building more complex solid boundaries would require overlapping level-set constraints and some criteria for switching between them appropriately. Notes I am aware of several different methods which may be applicable, including: Volume-of-Fluid methods, Level-Set Methods (Osher & Sethian), Finite Element Methods for PDEs and the Dorfmeister-Pedit-Wu algorithm. I have been endeavouring to determine for myself whether any or all of these might be appropriate, but due to my limited computational experience, I am quite unsure as to what method might be appropriate. Important Comment I am not attempting, in any way, to avoid the long and possibly laborious process of learning the ins and outs of a computational method. If referred by consensus or expert advice to an appropriate method, I will most happily plow into every piece of material I can find on the subject until I am able to address my problem. At this stage, I simply do not have the breadth of knowledge necessary to investigate every possible method and assess each for its strengths and weaknesses with respect to my problem. Summary Is there a computational method, or already-existing software package, which is appropriate for modelling fluid-air interfaces with solid boundaries of complicated geometry? With thanks in anticipation, Christopher Laing