Sketch of proof of the weak bound: Suppose $W$ had dimension $d=o(\log k)$. By pigeonhole, there is narrow cone in $W$ such that the projections $w_i$ to $W$ of $\geq k/6^d > \sqrt{k}$ vectors $v_i$ lie in that cap. Any two vectors in that cap have inner product $\geq 1/2$ times the product of their norms. Hence $\langle w_i,w_j\rangle \geq |w_1|_2 |w_2|_2/2 \geq |\delta|^2/8$. Then the projections $u_i$ of those same vectors $v_i$ to the orthogonal complement $U$ of $W$ satisfy $\langle u_i,u_j\rangle \leq -|\delta|^2/8$ for all $i$, $j$ distinct. By a standard argument, this condition can be satisfied by at most $O(|\delta|^{-2})$ vectors. 

When exactly were $\ell_p$ norms first defined and used? (Here is what I know, or think I know: Lebesgue and/or Riesz had something to do with them, but in some sense they go back to Minkowski, since Minkowski's inequality is (in essence) the statement that an $\ell_p$ norm is a norm.) Here is what is really my main question: how were $\ell_p$ norms ($p\geq 1$ arbitrary) first used? What was their motivation? It is clear that $\ell_1$, $\ell_2$ and $\ell_\infty$ norms are very natural, and their use long predates the formal definition of "form". The $\ell_4$ norm also pops up on its own sometimes. In contrast, $\ell_p$ norms for other $p$ seem to arise most often in the course of a proof, as a tool, when one needs some notion of "size" that falls between an $\ell_1$ and an $\ell_2$ norm (for example). Did the first uses of $\ell_p$ norms fit this framework? Can you think of some interesting (and preferably early) instances that do not obey this pattern? 

Let $v_1,\dotsc,v_k \in \mathbb{R}^d$ be unit-length vectors such that $$\sum_{1\leq i,j\leq k} |\langle v_i,v_j\rangle|^2 \leq \epsilon k^2.$$ What sort of lower bound can we give on $d$ in terms of $k$ and $\epsilon$? Must it be the case that $d\gg \min(\log k,\epsilon^{-1})$, say, or anything of the sort? Is that tight? 

Given a group $G$ and a set of generators $A$, we can ask ourselves (and do ask ourselves all the time) to bound the diameter of $G$ with respect to $A$. The diameter, let us recall, is defined to be the least $k$ such that every element $g$ of $G$ can be written as a product $x_1 x_2 \dotsc x_k$, $x_i \in A \cup \{e\}$. We care not just about the diameter, but also about navigation: that is, given $A$ and $g$, we would like to actually find a product $g = x_1 x_2 \dotsc x_j$, $x_i \in A \cup \{e\}$, as quickly as possible. Now, a product is a very special kind of straight-line program. What is known (for different interesting groups $G$) on the following question: given $A$ and $g$, can we construct quickly a (short) straight-line program that, starting from the elements of $A$, outputs $g$ quickly? 

In what follows, $g:\lbrack 0,\infty)\to \mathbb{R}$ will be a continuous function obeying the following constraints: $g(x)=1$ for $x\leq 1-\delta$, $g(x)=0$ for $x\geq 1+\delta$, and $g(1-t)=1-g(1+t)$ for $0\leq t\leq \delta$. (Otherwise put: $g'(t)$ is a symmetric function around $1$ of support $\lbrack 1-\delta,1+\delta\rbrack$.) Other than that, we are free to choose $g$, and for that matter $0<\delta<1$ as well. Write $G(s)$ for the Mellin transform of $g$. Let $T>0$, $0<\sigma<1$ be given. Let $\epsilon = \max_{t\geq T} |\sigma+ i t| \left|G(\sigma+it)\right|$. How small can $$\frac{\int_{1}^{1+\delta} |g(t)|^2 dt}{(1-\epsilon)^2}$$ be? Is the minimum reached by a nice function $g$? (I take there has to be a non-zero infimum, by the uncertainty principle. It is also easy to get a crude upper bound, by choosing any particular $g$ (such as, say, $g(1+t) = \frac{1}{2} - \frac{t}{\delta}$ for $-\delta\leq t\leq \delta$).) 

I'm a little embarrassed to be asking this, but surely there is a simple argument that I didn't see? Let $(f_\lambda)$ be a net in $l^\infty$ which converges weak* to $f \in l^\infty$. We do not assume the net is bounded. Does the net $(f_\lambda^+)$ converge weak* to $f^+$, where $f^+ = \max(f,0)$ is the positive part of $f$? It's false in $L^\infty[0,1]$. 

I'm surprised no one mentioned C${}^*$-algebras and their Automorphism Groups by Pedersen. The later chapters get a little specialized, but no one does basic C*-algebra more elegantly than this book. 

I'm going to say the von Neumann algebra has to be either atomic abelian or finite dimensional for this to happen. If $M$ is nonatomic then I don't think any projection besides 0 is "way below" any other projection, because if $p$ is nonzero then we can write $p = \bigvee p_\alpha$ where the $p_\alpha$ are directed and all strictly less than $p$, so if $p \leq q$ we have $q = \bigvee (p_\alpha + q-p)$ and this shows that $p$ is not way below $q$. So you need minimal projections to even have a chance. But $B(H)$ fails for infinite dimensional $H$: take $H = l^2$, let $p_1$ be the rank one projection whose range is spanned by the vector $e_1$, and for $n \geq 2$ let $p_n$ be the rank one projection whose range is spanned by the vector $e_1 + \frac{1}{n}e_n$. Then $e_1$ is not contained in the span of $p_2 \vee \cdots \vee p_n$ because if it were then $e_j$ would be too for $2 \leq j \leq n$, but the span of $p_2 \vee \cdots \vee p_n$ only has dimension $n-1$. However, the range of $\bigvee p_n$ contains vectors arbitrarily close to $e_1$, hence it contains $e_1$, hence it contains $e_n$ for $n \geq 2$, hence it is everything. Thus $I$ is the join of the directed sequence $p_2$, $p_2 \vee p_3$, $p_2 \vee p_3 \vee p_4$, $\ldots$, but $p_1$ is not less than any of these projections. This shows that $p_1$ is not way below $I$, and by symmetry no nonzero projection is way below $I$. 

For the sake of readability, I am going to make this a separate answer. In response to my other answer, Bogdan points out that preservation under isometries need not determine the center. I suppose in most cases it wouldn't. What I want to say here is that it doesn't seem possible to have a good infinite dimensional generalization of the centroid in ${\bf R}^n$, even for norm compact convex sets, for the following reason: already in finite dimensions we can have convex sets $A \subset B$ such that $B$ is contained in the $\epsilon$-neighborhood of $A$ but the centroid of $B$ is far away from the centroid of $A$. For instance, let $A$ be the line segment $[0,1]$ in ${\bf R}^1$ cross a ball about the origin of radius $\epsilon^2$ in ${\bf R}^n$, and let $B$ be the convex hull of $A$ together with the ball about the origin of radius $\epsilon$ in ${\bf R}^{n+1}$. If $n >> 1/\epsilon$ then every point of $B$ is close to $A$, but because of the way volume scales in large dimensions (the volume of a ball goes like its radius to the $n$) almost all of the mass of $B$ is near the origin. But the centroid of $A$ is halfway along the line segment. We can use this phenomenon to construct a sequence of finite dimensional sets $A_1 \subset A_2 \subset \cdots$ in $l^2$ such that each $A_{n+1}$ is contained in the $2^{-n}$-neighborhood of $A_n$, but the centroid of $A_{n+1}$ is far from the centroid of $A_n$. We can make the centroid bounce back and forth on a line segment. So where should the centroid of ${\overline{\bigcup A_n}}$ be? It looks like we have to take the limit of a sequence that doesn't converge. There won't be any canonical way to do this. I could add that there is a simple procedure that will sometimes work. For each finite dimensional subspace $V$ let $x_V$ be the centroid of $S \cap V$. Then consider the net $(x_V)$ with the finite dimensional subspaces ordered by inclusion. If this net converges, that seems like a good definition for the centroid of $S$. 

(Note: this started as a different question that soon changed form, thanks to the answers.) Let $G = \mathbb{Z}/4\mathbb{Z} \ltimes H_4$, where $H_4$ is the Higman group and $\mathbb{Z}/4\mathbb{Z}$ acts on $H_4$ in the obvious way (permuting the four standard generators cyclicly). The group $G$ is generated by two elements, $a$ and $t$: here $t$ is a generator of $\mathbb{Z}/4\mathbb{Z}$, and $a$ is such that $t a t^{-1} \cdot a \cdot t a^{-1} t^{-1} = a^2$. As is well-known, $H_4$ has plenty of normal subgroups (though none of finite index). My question is about normal subgroups of $G$ other than $\{e\}$, $H_4$, $G$ and (thanks to a commenter for reminding me of this last one) $2\mathbb{Z}/4\mathbb{Z} \ltimes H_4$. (a) Can you prove that the normal closure in $G$ of any word of the form $a^{k_1} t a^{k_2} t a^{k_3} t a^{k_4} t$ ($k_1,\dotsc,k_4$ integers, not all $0$) necessarily contains $H_4$? (b) Can you prove that the normal closure in $G$ of any set consisting of two distinct words of the form $a^{k_1} t a^{k_2} t a^{k_3} t a^{k_4} t a^{k_5} t$ must contain $H_4$? Note: I am saying "can you prove this" on purpose; a few lines of GAP code (sent to me by Kate Juschenko) suggest that what I am asking you to prove is in fact true. Note 2: Playing around with the code a bit more suggests that, in fact, the normal closure of $(a^3 t)^4$ does not contain $H_4$. Anti-note 2: the normal closure of $(a^3 t)^4$ does contain $H_4$ (unless I've bungled). The proof I can give for this involves words with powers about 2^256 - no wonder GAP couldn't find the proof. The same argument should work for $(a^k t)^4$. (c) Can you prove that the normal closure in $G$ of $(a t)^5$ does not contain $H_4$? (GAP fails to prove that this is false, on KJ's computer and mine, at least. Any further information on the normal closure is welcome.) 

Was Vinogradov's first proof of the three-prime theorem effective? Reasons for my question: Vinogradov presented his proof in 1937 in a monograph; the English translation by K.F. Roth and A. Davenport is based on the second version of the monograph, from 1947. There is no doubt that the proof in the second version is effective - Vinogradov goes to great pains to prove a "nearly-log-free" result (as opposed to a bound worse by a factor of $(\log x)^c$, which he proves with much greater ease) because he allows himself to use Siegel-Walfisz only in Page's effective version (= primes are well distributed in arithmetic progressions up to modulus $m\leq (\log n)^{2-\epsilon}$, and exceptions after that in a moderate range would all have to occur for moduli that are multiples of a single modulus of size $> (\log n)^{2-\epsilon}$). However, I'm finding the 1937 original (in Russian) hard to get. Did he use the usual, ineffective version of Siegel-Walfisz there? Did he already have "nearly-log-free" estimates at the time? Two more historical questions. (a) It must have been realized at some point that one does not really need nearly-log-free results to get an effective result (= every odd integer larger than a constant $C$ is the sum of three primes, where $C$ is an enormous constant that can in principle be specified). This is so because there isn't really an exceptional modulus $q$, but, rather, there could be an exceptional character modulo $q$; the other characters modulo $q$ are fine. Thus, Vinogradov's simpler, non-log-free bound is enough for effectivity, even though it's far from optimal. When was this first remarked in the literature? (I can't find any awareness of this in Vinogradov's monograph (translation of 1947 version); he uses Siegel-Walfisz-Page as a black box.) (b) The first explicit value for $C$ was computed by Borozdkin, who was apparently an assistant and former student of Vinogradov's. The only reference I've got for this is what looks like a mention in the proceedings of a Soviet conference. Did the full version appear anywhere? Note: I can read Russian, but, like most people working outside Russian-speaking areas, I find many Russian-language historical materials to be hard to get. Links to electronic versions of the documents discussed above would be very welcome.