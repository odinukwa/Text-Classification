MY QUESTION IS: Is anything known about such "directed cages"? Specifically: how many nodes are needed for a directed cage when $r=2$, as a function of $g$? 

Let's call a function $f$ k-podal if, for every multipodal set $X$ of size $k$: $$\sum_{x\in X}f(x) = 0$$ In particular, a 2-podal function is just another name for an odd function: $f(-x)=-f(x)$. I am looking for information about these "multipodal points" and "$k$-podal" functions. In particular: 

$\newcommand{\abs}[1]{\left|#1\right|}$ There is a population $O$ with a countable (finite or infinite) number of subjects. The population is colored randomly: for each subject, an unbiased coin-toss is used to decide whether the subject is colored red or green. Then, a sub-population containing $t$ subjects are selected; denote this sub-population by $T$ (so $T\subseteq O$ and $|T|=t$). Denote by $T^R$ the set of red subjects in $T$ and by $T^G$ the set of green subjects. The difference $\abs{|T^R|-|T^G|}$ denotes the imbalance caused by the randomization process. What is high-probability upper bound on this imbalance, as a function of $t$? There are two extreme cases: 

the square is carved 3 times. The rectangle-numbers are written in each resulting polygon. The final rectangle-number is 6, since $P'$, which is a union of two polygons, can be partitioned to 6 pairwise-disjoint rectangles. Let $R(n)$ be the largest rectangle-number that you can achieve in $n$ carvings. The example above shows that $R(3)\geq 6$. What is an upper bound on $R(n)$? In the example above, each carving adds at most 2 to the rectangle-number. This hints that there may be an upper bound such as $R(n)\leq (2n+1)$, or maybe another linear upper-bound. EDIT: while there are scenarios in which a single carving can double the rectangle-number: 

Consider the following exact sequence $$ 0 \to L \to G(M) \to G(M/xM) \to 0 $$ where $L$ is the kernel of the map $G(M) \to G(M/xM)$. It is easy to see that $x^* G(M) \subseteq L$. Hence we have $$ 0 \to L / x^* G(M) \to G(M)/ x^* G(M) \to G(M/xM) \to 0 $$ exact. By the hypothesis the dimension of $G(M)/ x^* G(M)$ is at most $d-1$. This implies that $\dim G(M/xM)$ is at most $d-1$. Since $\dim G(M/xM) = \dim M/xM$, you can conclude $\dim M/xM = d-1$. Since $x$ avoids all the minimal primes ideal of $M$ and $M$ unmixed, $x$ is a non zerodivisor of $M$. I don't think I used the assumption of $G(M)$ being equidimensional. 

Also, Proposition 1.5.15 in Cohen-Macaulay rings by Bruns and Herzog might help you. This is a bit more general than what Karl mentioned above. 

I don't think the corollary is true without further assumptions. Take $R = k[x,y,z]$ and $I = (x(y-1), y,z(y-1)$. Since $x(y-1), y,z(y-1)$ is a regular sequence, hence depth $(I,R)$ = 3. But $x(y-1),z(y-1), y$ is not a regular sequence. I believe that the statement is that $I$ can be generated by an $M$-sequence. If $M = R$, then it is Exercise 16.9 in the same section in Matsumura's book. 

What exactly does your colleague need interpolation for? I guess he just needs to extend some inequalities to intermediate values of the parameters. Then he can use the black box approach and his problem is reduced to computing interpolation spaces between given couples of Banach spaces. Then, two possibilities: 1) The interpolation spaces have already been computed. There is a vast literature on this, and he would not need to really study it but just check the statements. Besides the books already mentioned I would add Bennett and Sharpley, Interpolation of Operators, and a few books by H.Triebel with a similar name (Interpolation is the keyword). 2) In the unlucky case his spaces have not been considered, then he has to delve into the theory a little, and try to compute the spaces himself. Bergh and Lofstrom is a strange book, full of results, but with several imprecisions which can cause the beginner a few nightmares. Better start with Bennett and Sharpley which is crystal clear and reliable, keeping BL on the side for a comparison. Lunardi's book is also quite good but less comprehensive (at least from the early version I have). 3) If all else fails, try real interpolation, Peetre style. The theory is much easier to grasp, and closer to approximation and convexity methods he might be familiar with. 

they still do not contradict the conjecture that $R(n)\leq (2n+1)$, since many carvings are needed in order to reach such a scenario (in that example: 16 carvings). Is there a way to formalize this argument? 

I just found this excellent blog-post: $URL$ It contains a poem on complexity classes, based on Dylan's song "Man gave names to all the animals", with the same tune but different lyrics: 

An addition chain for $n$ is a finite sequence of integers starting at 1 and ending at $n$, such that each element is a sum of two previous elements. A short addition chain for $n$ can be used, for example, to calculate $x^n$ quickly by multiplying previously-calculated values. Let $l(n)$ be the length of the shortest addition chain for $n$. I am looking for an upper bound on $l(n)$ of the form: $$l(n) \leq C \cdot \log_2(n)$$ where $C$ is a constant. The Wikipedia page cites the following bound from 1975: $$l(n) \leq \log_2(n) + \log_2(n)(1+o(1))/\log_2(\log_2(n)) < 2\log_2(n)$$ The OEIS page states several bounds, but without a clear reference: $$l(n) \leq (5/2) \log(n) = 1.73 \log_2(n)$$ $$l(n) \leq (4/3) \lfloor\log_2(n)\rfloor + 2$$ What is a reference for the best known upper bound of the form $l(n) \leq C \cdot \log_2(n)$ (the smallest value of $C$)? 

Personally, I prefer the notation $\int_{[a,b]}f(x)dx$ which is analogous to the usual notation for higher dimensional integrals. 

The meaning of your question is not completely clear to me. Anyway, the following remark might be useful: given a weak solution $u(t)$, the set of test functions $v(t)$ satisfying the identity against $u$ is a closed subset of $L^2(0,T;V)$, thus it is sufficient to use test functions belonging to $C([0,T];V)$ to check for a weak solution (at least when $V$ is Hilbert). This shows that the times where the identity does not hold depend only on the (representative chosen for the) function $u$ itself and not on the choice of the test function. 

Let me put it this way. Many natural objects in PDE theory are pseudodifferential operators. Just a few examples (besides, obviously, differential operators): 1) singular integral operators in the sense of harmonic analysis; 2) the spectral measure projectors associated to a s.a. constant coefficient differential operator, and hence all functions of that operator, in the sense of spectral theory; 3) the inverse of an elliptic operator; 4) solution operators to wave, Schrodinger, heat evolution equations. And this list is quite incomplete. Now, pseudodifferential calculus is essentially a framework which shows the underlying common structure of all the previous examples, unifies their properties, and shows that many computations from different theories are just special cases of general theorems. To accommodate more and more interesting examples, the theory has been tweaked and enlarged several times, while keeping the same abstract structure. Thus there does not exist a single calculus, but several calculi following similar guidelines. In addition, the procedure associating a symbol to an operator, which is at the heart of pseudodifferential calculus gives a mathematical framework for the quantization procedure in physics. 

If $H$ is a chain (each set of $H$ either contains or is contained in any other set of $H$) then $H$ is simple. Proof: Suppose $H\cap g$ contains the set $\{x\}$. Then some set $h\in H$ contains $x$ and not $y$. Every other set in $H$ either contains $h$ (so it also contains $x$), or is contained in $h$ (so it does not contain $y$). So, $H\cap g$ does not contain $\{y\}$. More generally, if $H$ is a collection of disjoint chains, then $H$ is simple. The proof is similar: if some set $h\in H$ contains $x$ and not $y$, then every other set in $H$ either contains $h$ (so it also contains $x$), or is contained in $h$ (so it does not contain $y$) or is disjoint from $h$ (so it contains neither $x$ nor $y$). In all cases $H\cap g$ does not contain $\{y\}$. More generally, suppose $H$ has the following tree structure: it contains the empty set as the "root"; this root has several children which are singletons; each singleton $\{z\}$ has as children several pairs that contain $z$; and so on. A set is a child of another set if it contains it; there are no intersections between sets except through the edges of the tree. Then, $H$ is simple. Proof: Suppose $H\cap g$ contains the set $\{x\}$. Then some set $h\in H$ contains $x$ and not $y$. If some other set $h'\in H$ contains $\{x,y\}$, then $h'$ must be a descendant of $h$ in the tree, so there is no other set which contains only $y$, so $H\cap g$ does not contain $\{y\}$. 

Since you talk about 'jump' discontinuities, I guess you are interested in a one dimensional Schroedinger equation, i.e., $x\in\mathbb{R}$. In this situation a nice theory can be developed under the sole assumption that $V\in L^1(\mathbb{R})$ (and real valued of course). By a nice theory I mean that the operator $-d^2/dx^2+V(x)$ is selfadjoint, with continuous spectrum the positive real axis, and (possibly) a sequence of negative eigenvalues accumulating at 0. Better behaviour can be produced by requiring that $(1+|x|)^a V(x)$ be integrable (e.g. for $a=1$ the negative eigenvalues are at most finite in number). If you are interested in this point of view, a nice starting point might be the classical paper by Deift and Trubowitz on Communications Pure Appl. Math. 1979. Notice that the solutions are at least $H^1_{loc}$ (hence continuous) and even something more. A theory for the case $V$ = Dirac delta (or combination of a finite number of deltas) was developed by Albeverio et al.; the definition of the Schroedinger operator must be tweaked a little to make sense of it. This is probably beyond your interests. Summing up, no differentiability at all is required on the potential to solve the equation in a meaningful way. However, I suspect that this point of view is too mathematical and you are actually more interested in the physical relevance of the assumptions. 

After a lot of playing around, I found this counter-example with $n=6$ points and only 4 squares. This link alone is not a sufficient proof because there might be a bug in my function that calculates the maximum disjoint set. So here is a formal description of the arrangement, and an attempt to prove that indeed no more than 4 squares are possible: 

A geometric separator is a line that separates a given set of shapes to two subsets of approximately the same size (up to a constant), while intersecting only a small number of shapes. When a geometric separator exists, it is very useful because it allows us to solve difficult computational geometry problems in a divide-and-conquer manner. Example: Given a set of $n$ disjoint axis-parallel squares in the plane, there is a rectangle such that at most $2n/3$ squares are inside it, at most $2n/3$ are outside it, and at most $O(\sqrt{n})$ are intersected by it. Smith and Wormald (1998) prove this theorem, as well as thousands of generalizations with various applications. However, there is one generalization I haven't found yet, and I really want to know whether it is true: Given $m$ sets, each with $n$ disjoint axis-parallel squares of various sizes, is there a rectangle such that, at most $2mn/3$ squares are inside it, at most $2mn/3$ are outside it, and at most $O(\sqrt{n})$ squares of each collection are intersected by it? Note that, because the shapes in each of the $m$ sets are disjoint, the union of all sets is $m$-thick. Therefore, by theorem 39 in the original paper, it is possible to partition the collections such that the total number of intersected squares is $O(m\sqrt{n})$. Therefore, when $m=O(1)$, the existence of a simultaneous separator is guaranteed. On the other hand, when $m \to \infty$, a simultaneous separator may not exist - see the comment by fedja. The interesting case is when $m=\Omega(\sqrt{n})$. In this case, the existing theorem allows $\Omega(n)$ intersected squares in a single collection. My question is, basically, whether it is possible to bound the number of intersected squares per collection. 

I don't think the conlusion right above Question 1 is correct. Let $S = k[x,y,z]$ and $I = (z^2,zy,zx^3-y^4)$. Then by the Hilbert-Burch theorem a graded minimal free resolution of $I$ is given by the following presentation matrix $$ \begin{pmatrix} y & -x^3 \\ z & y^3 \\ 0 & z. \end{pmatrix} $$ By analyzing the matrix you can see that the shifts are $-2,-2,-4$ and $-3, -5$. In particular $b^2_1 = 3$ and $b^1_3 = 4$. 

To support J.C. Ottem's answer, let me present one example. Let $R = \mathbb{C}[x,y]$ and $I = (x,y^2)R$. What is the minimal graded free resolution of $R/I$, equivalently $I$? That is, $0 \rightarrow R(-3) \stackrel{d_1}{\rightarrow} R(-1) \oplus R(-2) \stackrel{d_0}\rightarrow R \rightarrow R/I \rightarrow 0 $ where $d_1 = (-y^2 \;\; x)$ and $d_0 = (x \;\; y^2)$. Now, ask what are the graded Betti numbers and minimal number of generators for $R/I$. I agree with J.C. Ottem's opinion on reviewing the definitions. I hope this helps. 

I am pretty sure that you already know a result of Hochster-Huneke, Corollary 4.3 in "Tight Closure, Invariant Theory, and the Briancon-Skoda Theorem", Journal of the AMS, 1990, for regular local rings. I don't think it is true in general. Let $R = \mathbb{Z}/3[X,Y]_{(X,Y)}/(X^4)$. Let $x,y$ denote the images of $X,Y$ in $R$. Let $m = I = (x,y)$ and $y$ be a system of parameters of $R$. Then $$(y)^{[3]}: m^{[3]} = (y^3): (x^3,y^3) = (y^3) : x^3 = (x,y^3).$$ Since $(x,y^3) \subseteq m \setminus m^2$, the ideal $(x,y^3)$ can not be expressed as the 3rd bracket power of an ideal. -------- An example when $R$ is reduced I think this works. One can take $R= \mathbb{Z}/3[X,Y]_{(X,Y)}/ (X^2-Y^2)$, $I = (x,y)$, and $y$. Then we have $$(y^3) : (x^3,y^3) = (y^3) : x^3 = (y^3) : xy^2.$$ Therefore, $y$ is in the colon ideal. In fact, it is $(x,y)$. By the same reason as above it can not be expressed as the 3rd bracket power of an ideal. 

First of all, can you be more precise in your question? You are asking about boundary conditions at infinity, and this might make sense, but... for what purpose? do you need a set of conditions that imply existence and uniqueness of a global solution? or, do you need to classify solutions of the standard Cauchy problem (with data at t=0) according to their behaviour at infinity? Anyway, there are a couple general tools that might help you at least to clarify what you are looking for exactly: 1) If you need a tool to classify solutions according to their behaviour at infinity, then scattering theory (mentioned by Willie in his comment) might be helpful. However, its main purpose is to compare two different equations, i.e., use the solutions of a simpler equation to classify the solutions of a 'more difficult' equation. So I do not think this is what you actually need. 2) If you need to understand what might be reasonable 'data at infinity' for a Cauchy problem, then the Kelvin transform might be of use. This is a space-time change of coordinates that transforms a wave equation into a wave equation, and exchanges infinity with t=0. Playing with it might give you some insight into what kind of conditions you might impose at infinity on your solution. There is also a much more sofisticated transform with a similar effect, the Penrose transform, but this might be overkill in your case. 

Each vertex in a graph is randomly and independently colored either red or blue with equal probability. A coloring is called $r$-good, for some fraction $r\in[0,1]$, if at least a fraction $r$ of the edges touch at least one red vertex. Define $p(G,r)$ as the probability that a graph $G$ is $r$-good. Obviously $p(G,r)$ is decreasing with $r$. What is the largest $r$ such that $p(G,r)>1/2$ for all finite graphs $G$? There is an upper bound of $2/3$ (as noted by Kevin P. Costello) and a lower bound of $1/2$. 

This is an attempt to complement Nick Gill's answer. If it is correct (I am not sure), it should be merged into his answer. Proposition: In every hole-free polygon, there exists a corner square that lies in exactly one maximal subrectangle. Proof: Observe that as one moves clockwise around the perimeter of the polygon, one must go either left or right at various stages. One obtains a sequence: $R,R,L, R, L \cdots$ and it is clear that the number of $R$'s is 4 more than the number of $L$'s. Therefore there must be a pair of two adjacent $R$'s. Assume w.l.o.g. that there is such a pair such that the side between the corners faces west. Consider the maximal rectangle that covers the two $R$ corners (red in the pictures below). This rectangle must run into at least one eastern side. There are two cases: Case A: The eastern side is connected to an $R$ corner adjacent to the $RR$ pair at the north or south: