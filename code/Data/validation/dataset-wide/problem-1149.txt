If you only need to know that a row is distinct, and don't need the actual contents of col3, then perhaps returning the hash of col3 would speed up the query? You could even perhaps pre-compute the hash using a calculated column so that you aren't computing the hash on the fly. If you do need the contents of col3, but have a lot of duplicates of col1+col2+col3, then it still may be beneficial to work with the hash to remove duplicates as a sub-query, then only return the col3 contents for the distinct rows. 

I have Instant File Initialization enabled on our SQL Server, so the 'empty' part of the database file is not zeroed before being allocated. My understanding is that this means that the file could contain 'deleted' data. So now I want to send a copy of a database (probably a backup file) outside of the company. But there's all that potentially sensitive 'deleted' data sitting around inside the file. Now I would like to zero the unused portion of the file. Is that possible? I imagine I could create a new database and copy everything over, or perhaps restore a copy of the database to another server without Instant File Initialization enabled and then be aggressive with a ShrinkFile command to remove most or all of the unused portion of the database file, but is there a less manual and time consuming method? Ideally a command to tell SQL to zero the file as it would have done if Instant File Initialization was not enabled. 

I considered setting ONLINE=OFF for the alter index statement, but as the indexes start out disabled I wasn't sure that this setting would have any effect. I also considered setting SORT_IN_TEMPDB = ON, but as the tempdb files are on the same drive as the .mdf files of the databases I assumed that there was also no benefit to doing that. Whilst running the rebuild script I have noticed that I have a lot of CXPACKET wait types. I don't really understand why that would be or if it's a problem that I should be looking to address. One final point that may be relevant: my entire server is currently inactive other than this import of data into the database. There is no other user activity to consider or worry about; my only concern is importing the data into the database in the shortest possible time. 

I have a third party database in which a large number of the tables have a 'companyID' column, and most of the queries against those tables include in the where clause. [EDIT: In addition to the where clause, the companyID is generally also used in the order by clause of most queries: e.g. ] In our organisation the companyID column is always populated with 1 (though there is an outside chance that may change at some point in the future). Now I am looking at creating some indexes on these tables. SQL Server recommends some 'missing indexes' and all the recommendations contain the companyID field as the first column in the index. Going on the principle of specifying most selective column first I would think that I should put the companyID column last, or perhaps not even have it in the index at all. But then I'm wondering why SQL Server's missing indexes view always suggests putting it first - surely SQL Server is intelligent enough to know that every row contains the same value for that column? 

It's always possible that this table is populated by something external to the database instance that the table is situated on - from an application, via a linked server, from a script on the server. There are probably other possibilities but you get the idea. The best way I can think to track activity on the table is to run SQL Server Profiler (via the Tools menu of SSMS on the 2012 version). I'm not going to write a tutorial on that software here but you essentially want to filter the activity on the server by the name of the table that you are interested in. If anything updates that table then it should appear in the profiler results. 

Some of the mystery is solved - The reason that some sites could connect and some couldn't is that there was an additional connection string stored in the machine.config file that two of the sites were using. The site that worked when a port number was specified did not use this connection string, so worked. The other sites didn't work when port number was specified because I hadn't added the port number to this connection string in machine.config. Adding the port number to that connection string as well as the ones stored in web.config allowed all the sites to work. Additionally, the reason that iisreset had an effect is that once IIS knows the port number that SQL is using, it seems to 'remember' the port number, and so it no longer has to rely on using port 1434. Once I did an iisreset it 'forgot' what port number was used, so had to make a request on port 1434, which for some reason doesn't work. So my question has gone from a very confusing 'works sometimes' situation to a basic 'cannot communicate on port 1434' situation. 

With option 1 I worry that separating the Reporting Services from its databases will either impact the data warehouse server, or will impact the reports. With option 2 I worry that installing the database engine on the server will impact the Reporting Services server performance, and with option 3 I worry that I'm wasting resources creating a server that will hardly do anything, and also impacting the reports by separating the Reporting Services from its database. I think the key piece of information I need is to know which part of Reporting Services is the most resource intensive. If it's the Reporting Services application then I can leave the databases with the data warehouse. If it's the databases that are resource intensive then I need to either put them with the Reporting Services application or create a new server. Can anybody shed some light please? Thanks! 

I have a SQL Server 2008 R2 database server that hosts a data warehouse database. On this server is also installed SQL Server Reporting Services, and its two databases ReportServer and ReportServerTempDB. For performance reasons I want to separate the data warehouse database and the Reporting Services. I have another server that is available to install SSRS onto. Both servers are virtual and so their specifications are easily changed, or other servers could be 'created' if necessary. What I can't get my head around is where the best place would be to host the ReportServer and ReportServerTempDB. I can see three options: 

I'm looking to set up SQL Server 2012 installation with an Always On Availability Group, where the 'passive' replica will be hosted at another site on the WAN and using synchronous data commit - the idea being that we will have a hot standby with no loss of data in the event of a failure at our primary site. One potential problem that I foresee is that the secondary site has slower storage than our primary site. I don't care about that in the event of a failure, we can live with slow speeds for a period of time until the primary site is restored. My worry is that, because we are using synchronous commit, that the slower disk speed at the secondary site will affect performance at the primary site during normal operation. Is this a valid concern, or is it likely that the slower speed will be offset by, for example, the disk not having much read activity in comparison to the primary site? 

I've seen suggestions to set the "Use 32 bit runtime" option, but this had no effect. I've seen suggestions to set something similar in BIDS, but I didn't use BIDS to generate this package. I've seen options to use the 32-bit version of DTExec but I don't think the 32-bit version is installed on the server. SQL Agent Job definition: 

An alternative way that may be faster is to use the STIntersects and BufferWithTolerance methods to check if one point is within a certain distance of another. 

I've just installed SSMS 2012 and when I loaded it up I was presented with a nasty blue background - it looks so bad that I honestly thought something was broken, but apparently it's supposed to look like that! Short of sending the SQL Server Design Team a set of vouchers to have their eyesight tested, is there anything that I can do to change this? I've looked around and found a couple of other people whose sight has been similarly assaulted, but I cannot find a solution. 

In SQL Server 2008 when using database mirroring, it was possible to set up alerts when the oldest unsent transaction exceeded a certain threshold. We could check the state of any database mirroring using the Launch Database Mirroring Monitor menu command. In SQL Server 2012 we now have Availability Groups. It would seem to me that the same potential problem exists that if transactions cannot be sent to the secondary server then the mirroring will be suspended, and potentially the transaction logs will fill up all our disk space. However, the Database Mirroring Monitor tool does not seem to recognise databases in Availability Groups as being mirrored. Is there a way to set up an alert if the oldest unsent transaction exceeds a certain value? Is there a way to set that certain value?