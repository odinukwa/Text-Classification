"The rest, as they say, is history. Debreu and Arrow emerged from Nash’s seminar and in a few short months applied what they had heard to hammer out their own existence proof in the context of a multiple-sector model economy: one that effectively brought back from the dead Walras’ (fully neoclassical) idea of a General Equilibrium complete with determinate prices for everything, including labour input and capital goods (recall Chapter 6). This they accomplished by procuring General Equilibrium’s ultimate mathematical proof; an existence proof that showed under which conditions a set of relative prices exists such that all markets (including that for labour) are in equilibrium. This existence proof was to mark a new neoclassical turn in political economics; a turn that altered the discipline’s course and returned neoclassical obscurantism to the throne from which it had been removed by the combined forces of the fall of 1929, the analysis of John Maynard Keynes, the engineering brilliance of von Neumann and, last but not least, the experiences of economic policy during the New Deal and the Second World War." 

The odd couple of the title are value and growth. From the very start, political economics found it difficult to square the two; to create models or accounts of how the exchange value of things was determined in a growing economy. The chapter begins at the beginning, with the French Physiocrats, before moving to Adam Smith and David Ricardo’s attempts to tackle this conundrum. The Inherent Error makes its first fonnal appearance in these works, before it returns again and again in the following chapters. The essence of the Inherent Error is the impossibility of telling a credible story about how values and prices are formed in complex (multi-sector) economies that grow through time." 

How does US (its economy, banks, industry, "finance industry") profit from dollar being the "standard currency"? I am not seeking "ideological" explanations, but explanations of the mechanisms involved, of the kind of "how things work", better backed by actual numbers. Could one recommend some honest, preferably not ideologically coloured, accessible reference which discusses such mechanisms? 

Question Are there any simulated datasets that have been designed specifically to represent macroeconomic data? In particular, are there any such datasets that can be used in benchmark studies? Background To give an analogy, in optimization, one may be interested in assessing the quality of a given algorithm. To do this, there are a number of test functions for optimization, such as the well-known banana function, that can be used to evaluate the performance of an algorithm; for example, by analysing if and how fast the algorithm can find a global minimum. I am interested in working in this controlled experimental setting using simulated data that has a macroeconomic interpretation. With data simulated from a known data generating process (this would be my control), it would be possible to investigate, say, the performance of algorithms designed to detect structural breaks and to assess techniques/models used for forecasting. I would greatly appreciate if someone could help: either by pointing me to some simulated datasets that can be used for the above purposes or by providing some guidance on how to simulate data that carries a macroeconomic interpretation. It's possible for me to simulate a variety of ARMA processes (or VARMA model), but I am really interested in something that goes beyond that; the simulated data ought to have similar properties to observed macroeconomic data. Obviously, I am trying to avoid using actual data because my control (of knowing the data generating process) would be lost. Update For one of the purposes I had in mind, a quick read of Castle, Doornik, and Hendry (2013) suggests that it is, perhaps, not that difficult. Their "experimental design" is based on the following equations $$ y_{t} = \beta_{0} + \gamma y_{t-1} + \beta_{1}x_{1,t} + \cdots + \beta_{10} x_{10,t} + \epsilon_{t}\\ x_{i,t} = \rho x_{i,t-1} + v_{i,t}, v_{i,t} \sim IN[0,1], i=1,\ldots,10,\\ \epsilon_{t} \sim IN[0,1], t=1,\ldots ,10. $$ along with some further qualifications. So, it would appear that for one of my examples (the case of evaluating structural break algorithms), relatively simple (although by no means, "not tricky") DGPs are all that's required. Reference: Castle, Doornik, and Hendry (2013) Model Selection when there are Multiple Breaks 

This is why the phrase "market failure" is misleading and incorrect. The free market allocates efficiently, because goods go to the highest bidder. It is "forced market disturbance" that causes allocative inefficiency by disrupting the free market. Therefore, more forced market disturbance means less efficientcy, and less forced market disturbance means more efficiency, with maximum allocative efficiency when the market is free of all forced market disturbances (taxes, regulation, subsidies, red tape, etc.) 

Allocative inefficiency refers to a situation where good G was bought by buyer B1 ("allocated" to buyer B1) where it would have been more "efficient" if it had been bought by a different buyer B2 ("allocated" to B2 instead of B1). Good G could be producer goods like oil, lumber, plant equipment, or even consumer goods like sandwiches. In a free market, the only way buyer B1 gets to bid a good G away from buyer B2 is if B1 voluntarily pays more for G than B2 is willing to pay. This means that in a free market G is always allocated "efficiently", because it goes to the highest bidder, ie the bidder who is obtaining the highest "utility" from G at that point in time (that's why he bid highest). In other words, in a free market, goods are always allocated efficiently. A good G can be allocated inefficiently to B2 instead of B1 if the market is actively prevented by an external force from allowing B1 to bid G away from B2. There are many ways that this happens today: 

The tax burden falls on the ticket buyers, on the ticket sellers, on the hot dog vendors, on the cab drivers, on the children of the ticket buyers, and on a whole bunch of other people. Ticket buyer: Because he paid $5 extra to buy the ticket. Ticket seller: as @Mowzer said, if the event wasn't sold out, it is possible some tickets weren't sold that would have been sold at $5 less, so the seller lost on those. Hot dog vendors: some of the ticket buyers would have bought more from the vendors had they not paid the extra $5, so that cost fell on the vendors too. Cab drivers: some of the ticket buyers would have spent a few bucks on a cab after the game had they not paid the extra $5, so that cost fell on the cab drivers too. Children of ticket buyers: some of ticket buyers would have spend a few bucks on ice cream the next day for their kids had they not paid the extra $5, so that cost fell on the kids too. And so forth. And for those frugal buyers that would have saved the \$5 in their savings account, that is \$5 (times the number of such savers) that won't get lent out by the bank to a small business, hindering productivity increases and slowing down a growth in the standard of living that is brought about by such economic growth.