Generally the main difference is in the quality and features of the hardware, as well as the support offered by the vendor. Server hardware often has features to ensure uptime or easy maintenance in a data centre: 

I'd like to add a me-too to Mike Arthur's answer. I've used a Linux desktop since 1997 and have migrated my home directory along the way. Most apps just work. The only problems I've had was when I switched distributions. Upgrading from RedHat to newer RedHat or RedHat to Fedora or Fedora to newer Fedora is usually really easy. But when I switched from RedHat to Mandrake (now Mandriva) and Mandrake to Fedora it was not a pretty sight. Mandrake and Fedora both used a customized KDE directory structure that was incompatible with each other. As a consequence at that time I deleted most of my .kde directory to recreate the settings. But since then I've not really had problems. In any case, you can always just erase whatever's in your home directory that you don't want after a system update. I find it extremely convenient that my data is separate from my programs. Even if you have to blow away your whole home directory every two years, as a Fedora user that would save me about 2-3 backup-restore cycles (Fedora updates every 6 months). You can also set up a directory for use with programs. I typically have /usr/local as a separate partition. I install anything I compile from scratch there. This doesn't work as flawlessly as in the data case because many times the distros are not binary compatible with each other. But at least your programs are all there and you can assess them as needed. 

Try to pass then. will pass anything that follows onto the embedded MSI installer. The /qn is an msiexec switch indicating to run with no UI. The "wierd" format is required because that is how the InstallShield command-line parser is programmed to function. Likely, they built it this way to ensure msiexec switches/properties will be unambiguous on the command-line and within scripts. 

Your description read exactly like this KB: "Poor network performance on virtual machines on a Windows Server 2012 Hyper-V host if VMQ is enabled". VMQ must be disabled for your adapters. If that is not working, check the eventlog why. 

DHCP does not deny a IP address to a client; longer lease times or manual configuration ognore reservations. A reservation only kicks in when the client is reuqesting a address. 

The field shows the length of the time that it took for the request to be completely processed by HTTP.sys. The time stamp is initialized when HTTP.sys receives the first byte of the request (so network latency is included here). HTTP.sys is the kernel-mode component that is responsible for HTTP logging for IIS activity. The time stamp is initialized before HTTP.sys begins parsing the request. is stopped when the last (HTTP-) response occurs. So the answer is yes and no. Yes, it's the time when the request reaches HTTP.sys and no, it's not the time to measure if you want the time for IIS' reply. For example, a POST request with 2megs of payload will take a lot longer to reach your application (time-taken) than a short WebDAV keep-alive message. But both will have the same 'time' stamp. If you had subtractd one from the other, the long request would have "been there", even before it was sent. 

I have 2 webapps deployed in the same JBoss/Jetty server. In Jetty 5.1.14 I had the following jetty-web.xml which configured one of the apps to run as a virtual host (on the same port): 

Is it possible the VM has been hacked? Are the tools you're using to monitor the list of processes and memory from a known-good, read-only medium? You could have a rootkit installed which hides the leaky processes. 

The problem turned out to be that ALL webapps need the virtual hosts defined if they are running in the same container. For some reason deploying one WAR with virtual hosts and one without didn't work. This worked fine in Jetty 5 so I'm mystified, however defining virtual hosts files for all applications that need this isn't going to be a problem. 

I finally solved my problem. I suppose it was a Fedora problem all along but Fedora was not letting me edit system connections in NetworkManager. I changed NetworkManager's configuration so that it used its native connection information backend and edited the policy to allow my user account to edit the connection information; once I did that the "available to all users" checkbox finally started working. Thanks to all those who answered. 

The /T switch allows it to get subfolder permissions too. The /C switch allows it to continue even if errors are encountered. Errors will still be displayed. Use this command to restore them: 

There is a lot of authorisation, authentication and handshaking going on, even before any client data has been submitted. In the different versions of the protocol, things changed quite a lot. If you need a special behaviour, use the appropriate version. The good news: Your password is never sent through an unsecured connection nor is it used as a key for anything. This wouldn't be possible anyway, since the authenticating machine nevers has access to it. 

There is no (easy) auditing itself (except audit logs), but you can use to check regularly (usage here). 

No, and it shouldn't be. The header TTL is vital for the network, as it kills paket that travel for too long. Thats the same for all protocol types, including ICMP. 

My guess would be that some traffic on port TCP 443 (HTTPS) is allowed. OpenVPN uses UDP:1194 (and a properitary handshake) so it will not work. Try SSTP (like Microsoft does in its RRAS) or another SSL-Tunneling VPN. Otherwise follow ptman's answer. You don't have to root the app itself, just wireshark the WLANs traffic. 

It seems like, you do not have an automatic start script! Which is usual. OpenVPN does not install such a thing by it self, as far as i know... First of all try executing the server manually. This will need an own Terminalwindows to run. And for the time OPENVPN is running this way, the TerminalWindow will not be usable for other stuff. Try this (replace /etc/openvpn/config-files/ with your Path): 

Somehow the stuff i wrote in the crontab is now working as i wish. To be more exactly, i think it is not executing my commands. So now i would like to know if there is a way to get a plan what crontab, where it describes what he's going to do for today. But not by reading the /etc/crontab by myself, i would like to say to cron: *give me a report of your plan for today* So i can see if i'm just to retarded to load the stuff i write into his plan or if i have to look somewhere other for the reason. Of corse, if there is a better practice, you have my attention! When i do the commands by myself there is no problemo. 

I would recommend a (Hard-)RAID0/1 on this for better performance and availability. But this configuration will be slow anyway - get all the cache and BB you can find on the controller (nearly all DL3xx are capable of BBWC/BBFC). 

Insert another condition, like , before your RewriteCond. Or just use more conditional rewrites for HTTPS: 

Conversion happens at Layer 2, at the "MAC Layer". Thats one layer below IP - Routing happens just on Layer 3, where Packets do have IP-Adresses. In this case the MAC-Address of the Laptops wireless-interface would send the Request to the AP, the AP converts 1:1 it into a LAN-Packet on the cable and it would reach the server unchanged. No need to cache a pool of anything. 

If an external sender attempts to book the meeting room they will not receive an acceptance or rejection message, which may lead to confusion if the room is assumed to have been successfully booked (given that the ressource hat automatic processing anabled). To configure the room mailbox to process external requests: 

You want to ensure no unauthorized person can read it again (e.g. a stored credit card number: if you erase it an intruder can't get it) You want to ensure that the information can't be requested from you (e.g. through Freedom of Information Act requests) You want to keep the data size small for space or speed reasons (proper indexing and partitioning can help with the speed issue). You are required to delete it by law (e.g. privacy laws). 

There are lots of good VPN solutions out there, but sometimes you need something quick and dirty. You can set up a VPN using PPP over SSH. This solution has lots of drawbacks but the advantage is that it needs no special tools or programs, just standard ssh and ppp. It could probably work on Windows too with a little tweaking. 

The SSL traffic is decrypted by the SSL daughter-card in the CSM, and traffic is then routed by URL to the various servers based on the HTTP hostname. I'd like to add HTTPS support to the main site for non-ecom secure pages but my admin says the CSM isn't capable of routing the traffic in this way. Here is my planned config: 

Config problems will not go away with a service going away. You will still have to setup you vpn correctly, now including breakout rules for external DNS traffic. 

The physics is actually much easier than it seems at first glance: Power generators are engines just like the everyday ones we see all around in our cars, lawnmowers, snowblowers, etc. Except for new power sources like some wind and solar systems with electronic inverters, the vast majority of power is supplied by large rotating AC generators turning in synch with the frequency of the grid. The frequency of all these generators will be identical and is tied directly to the RPM of the generators themselves, generally 3600 RPM for gas turbines and 1800 RPM for nuclear plants. If there is sufficient power in the generators then the frequency can be maintained at the desired rate (i.e. 50Hz or 60Hz depending on the locale). The power from the individual generators will lead the grid in phase slightly by an amount roughly corresponding to the power they deliver to the grid. An increase (=defect) in the power load will cause this rotating frequency to drop. So a battery systems like this is designed to keep short-term fluctuations in power requirements from dropping the frequency because of lags in the governors and generators which require a finite time to adjust to the new power requirements. These "frequency regulator" power stations can supply very high power for short bursts to keep the power requirements even so that the other generators don't see too much load faster than they can respond due to mechanical limitations. If this does not happen somehow, your UPS will be killed. 

Some Information will appear in this Window. Now try to connect to the Server with a client. You can shut the openvpn down by hitting CTRL+C If this was the solution, do following for executing the OpenVPN-Server after your System has booted. Do this in the terminal: 

The magic Keyword in this case is Logical Volume Manager (short LVM). With this you can create volumes, and attach harddrives to this volume. Then you can mount this volume on /var/wwww It is possible to use this LVM with RAID system in Combination. So you can push speed or data-security(in case one drive breaks down). And i would reccomend you to use RAID 5 or RAID 6 if you have that many drives. Otherwise if one drive brokes down you might take it out of your lvm but you would leave a hole in you filesystem. And this will bring you in stressy troubles. I used to spend nearly to weeks to understand lvm, Raid and to set up a testing environment. But it's worth. It's like juggleing with data. 

Interesting phenomenon. Here is what I would try - I have no idea if this really helps. If it was my machine, I would extensively watch the SMB perfcounters. One of them will show the cause. More things to try Add more Worker Threads In case the SMB_RDR obens up one write I/O Request per line (what should not happen here), it may help to add some threads to the execution engine. Set "AdditionalCriticalWorkerThreads" to 2, then to 4. 

When an application loads a dynamic link library or executeable without specifying a fully qualified path, Windows tries to locate the binary by searching a well-defined set of directories. This includes the local path, active path and the PATH variable (speaking of applications respecting that, like CMD). If an attacker gains control of one of the directories, like on a website path in IIS, they can force the application to load a malicious copy of the file instead of that it was expecting. These attacks are known as "preloading attacks" and are common to all operating systems that support dynamically loading and/or shared libraries and binaries. The effect of such attacks could be that an attacker can execute code in the context of the user (process) who is running the application. When the application pool is being run as Administrator, this could lead to a local elevation of privilege. This is why a lot of system processes do not use or no longer use the PATH contents to search for their binaries. More on this: Secure loading of libraries to prevent preloading attacks 

In addition, you often get server-class hardware such as network cards, which may mean better performance (not guaranteed). If your needs are small or your budget really constrained, a non-server computer can act as a server. But you will likely pay for it down the road in maintenance costs. Also take note of the warranty and service contract differences. Does your workstation have the same on-site repair, with the same guarantees for response time from a technician? Etc. 

The problem might be the format of the data that is sent to the printer. Do you use native printer drivers on the windows workstation? If so, you might need to enable "raw" printing, that is, sending raw binary print codes from the workstation through to the printer. You might need to edit the cups configuration file and uncomment to enable raw printing. I'm not sure what the security ramifications of this are. The other thing that may or may not work for you is setting your printer up as a postscript printer, using a generic postscript driver on the Windows client. However, I've rarely gotten this to work properly.