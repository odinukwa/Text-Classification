Then clearly $ A^{\sim} $ is a sub-algebra of $ \mathbb{L}(A) $. Claim 1: $ L_{A} $ is complete w.r.t. the operator norm on $ \mathbb{L}(A) $. Proof of Claim 1 Let $ a \in A $. We already know that $ \| L_{a} \| \leq \| a \|_{A} $. However, $ \| e_{i} \|_{A} \leq 1 $ for all $ i \in I $ and $$ \lim_{i \in I} \| {L_{a}}(e_{i}) \|_{A} = \lim_{i \in I} \| a e_{i} \|_{A} = \| a \|_{A}, $$ so we actually have $ \| L_{a} \| = \| a \|_{A} $. The map $ x \mapsto L_{x} $ is therefore a bijective isometry from $ A $ to $ L_{A} $, so $ L_{A} $ is complete w.r.t. the operator norm on $ \mathbb{L}(A) $. $ \quad \blacksquare $ Define a (not a priori continuous) linear functional $ \phi $ on $ A^{\sim} $ by $$ \phi(L_{a} + \lambda \cdot \text{Id}_{A}) \stackrel{\text{df}}{=} \lambda. $$ To prove that $ \phi $ is well-defined, we must show that given $ (a,\lambda) \in A \times \mathbb{C} $, if $ L_{a} + \lambda \cdot \text{Id}_{A} = 0_{\mathbb{L}(A)} $, then it must follow that $ \lambda = 0 $. Assume the contrary. If we define $ e \stackrel{\text{df}}{=} - \dfrac{1}{\lambda} \cdot a $, then $ L_{e} = \text{Id}_{A} $, which means that $ e $ is a left identity of $ A $. Now, for all $ x \in A $, we have \begin{align} x e - x & = \lim_{i \in I} ~ (x e - x) e_{i} \qquad (\text{As $ (e_{i})_{i \in I} $ is an r.a.i..}) \\ & = \lim_{i \in I} ~ (x e e_{i} - x e_{i}) \\ & = \lim_{i \in I} ~ (x e_{i} - x e_{i}) \qquad (\text{As $ e $ is a left identity.}) \\ & = \lim_{i \in I} ~ 0_{A} \\ & = 0_{A}. \end{align} Hence, $ e $ is a right identity of $ A $ as well. This contradicts our assumption that $ A $ has no two-sided identity, so we indeed have $ \lambda = 0 $. Claim 2: $ A^{\sim} $ is complete w.r.t. the operator norm on $ \mathbb{L}(A) $. Proof of Claim 2 As $ L_{A} $ is a complete linear subspace of $ A^{\sim} $, it is automatically closed. The quotient vector space $ A^{\sim} / L_{A} $ can thus be given a norm, which then has to be complete because $ \ker(\phi) = L_{A} $ and so $$ A^{\sim} / L_{A} = A^{\sim} / \ker(\phi) \cong \mathbb{C}. $$ Exploiting the result that a normed vector space is complete if its quotient by a complete linear subspace is complete, we conclude that $ A^{\sim} $ is complete w.r.t. the operator norm on $ \mathbb{L}(A) $. $ \quad \blacksquare $ We now see that $ A^{\sim} $ is a unital Banach algebra w.r.t. the operator norm on $ \mathbb{L}(A) $. As $ \phi $ is a multiplicative linear functional on $ A^{\sim} $, it follows that $ \phi $ must be bounded with norm $ \leq 1 $ (this is an easy fact whose proof can be found in Rudin’s Real and Complex Analysis). The inequality is therefore established. 

My reason for this post is two-fold: (i) To give an answer for the case $ \alpha = 2 $. (ii) To attract attention to the other cases, which remain open. 

Using Pontryagin Duality, it is not hard to prove the existence of such an extension, but I would like to know if one can do so by furnishing an explicit formula in terms of $ \omega $. Thank you very much! 

Letting $ a = \alpha ~ f(\alpha^{*} \alpha) $ and $ b = \beta ~ g(\beta^{*} \beta) $, he then says that $ (a,b) $ is a generating pair for $ {\text{SU}_{0}}(2) $, i.e., \begin{align} a^{*} a + b^{*} b & = 1, \\ a a^{*} & = 1, \\ b^{*} b & = b b^{*}, \\ a b & = 0, \\ a b^{*} & = 0. \end{align} The problem is, none of this seems to work. For example, let us try to verify that $ a a^{*} = 1 $. Observe that \begin{align} a a^{*} & = [\alpha ~ f(\alpha^{*} \alpha)] [\alpha ~ f(\alpha^{*} \alpha)]^{*} \\ & = [\alpha ~ f(\alpha^{*} \alpha)] [f(\alpha^{*} \alpha)^{*} ~ \alpha^{*}] \\ & = [\alpha ~ f(\alpha^{*} \alpha)] \left[ \overline{f}(\alpha^{*} \alpha) ~ \alpha^{*} \right] \qquad (\text{By the continuous functional calculus.}) \\ & = [\alpha ~ f(\alpha^{*} \alpha)] [f(\alpha^{*} \alpha) ~ \alpha^{*}] \qquad \left( \text{As $ \overline{f} = f $.} \right) \\ & = [f(\alpha \alpha^{*}) ~ \alpha] [\alpha^{*} ~ f(\alpha \alpha^{*})] \qquad (\text{As $ \alpha ~ p(\alpha^{*} \alpha) = p(\alpha \alpha^{*}) ~ \alpha $ for every polynomial $ p $.}) \\ & = [f(\alpha \alpha^{*})] (\alpha \alpha^{*}) [f(\alpha \alpha^{*})] \\ & = h(\alpha \alpha^{*}), \end{align} where $ h: [0,1] \to \Bbb{R} $ is defined by $ h(t) \stackrel{\text{df}}{=} t [f(t)]^{2} $ for all $ t \in [0,1] $. However, $$ \sigma(\alpha \alpha^{*}) \cup \{ 0 \} = \sigma(\alpha^{*} \alpha) \cup \{ 0 \}, $$ so $ h|_{\sigma(\alpha \alpha^{*})} $ is the identity function on $ \sigma(\alpha \alpha^{*}) $, which yields $ h(\alpha \alpha^{*}) = \alpha \alpha^{*} $ instead of $ h(\alpha \alpha^{*}) = 1 $. 

This is in response to Yakov’s request to see a proof that does not rely on the continuous Hairy Ball Theorem. 

Let $ q \in [0,1) $. The compact quantum group $ {\text{SU}_{q}}(2) $ is defined to be the universal unital $ C^{*} $-algebra that is generated by two elements $ \alpha $ and $ \beta $ satisfying the following five relations: \begin{align} \alpha^{*} \alpha + \beta^{*} \beta & = 1, \\ \alpha \alpha^{*} + q^{2} \beta \beta^{*} & = 1, \\ \beta^{*} \beta & = \beta \beta^{*}, \\ \alpha \beta & = q \beta \alpha, \\ \alpha \beta^{*} & = q \beta^{*} \alpha. \end{align} In his paper Twisted $ \text{SU}(2) $ Group. An Example of a Non-Commutative Differential Calculus, Woronowicz proves that there is a $ * $-isomorphism between $ {\text{SU}_{q}}(2) $ and $ {\text{SU}_{0}}(2) $. Part of his proof proceeds as follows. He begins with the claim that \begin{align} \sigma(\alpha^{*} \alpha) & \subseteq \left\{ 0,1 - q^{2},1 - q^{4},1 - q^{6},\ldots,1 \right\} ~ \text{and} \\ \sigma(\beta^{*} \beta) & \subseteq \left\{ 0,\ldots,q^{6},q^{4},q^{2},1 \right\}. \end{align} Next, he chooses arbitrary continuous functions $ f,g: [0,1] \to \Bbb{R} $ such that: 

The reason why I say ‘almost complete’ is that it is not obvious at first sight that $ D_{T,\beta} \subseteq D $. Hence, here is my second question: 

To demonstrate the delicate nature of questions concerning the integrability of Lie-algebra representations, I would like to highlight a major error that I committed while I was formulating the OP. The last item in the hypothesis set for each theorem defines $ D $ to be the largest invariant domain of $ T[{\frak{g}}] $. This is absolute nonsense because it may no longer be true for $ X,Y \in {\frak{g}} $ and $ \alpha \in \mathbb{R} $ that $$ T(\alpha X + Y)|_{D} = \alpha \cdot T(X)|_{D} + T(Y)|_{D} \quad \text{or} \quad T([X,Y])|_{D} = \left[ T(X)|_{D},T(Y)|_{D} \right]. $$ These relations are only assumed to hold on the original invariant domain specified in the second-last item of the hypothesis set, so enlarging the domain while preserving the validity of the relations is not what we can get for free. What I should have said was: