Is the reason you can't use IDENTITY because there are already foreign key relationships between separate tables you are loading? And there is no other natural key for you to be able to link them up in an operation from a staging area to the production area? For that reason, I'd like to know a little more about how they are currently "linked" in the source system before you bulk copy? Do multiple source systems simply use their own sequences and have the possibility for conflicting sequences when brought into a shared database? The COMB ID/sequential GUID technique is one which I am familiar with, and it is workable any time you effectively need that global uniqueness assigned outside the database - it's effectively a usable row identity both inside and outside the database. For that reason, in highly-distributed environments or disconnected scenarios, it's an OK choice Except if you really don't need it, Because that extra width difference is significant when the size of the data grows and these keys are in every index and the working sets for a lot of queries. Also, with generation distributed, if the rows don't actually come in the order of the GUID column, the issues with using this for the clustered index key (narrow, static, increasing) potentially causing some fragmentation compared to clustering on an IDENTITY still remain. 

All work. Note that in the second case, you cannot add apples and oranges, and so the data is exceptionally easy to be subject to misinterpretation. Also note that conversions cannot be very safe and are susceptible to rounding error, overflows, etc. In addition, there are physical issues like the specific gravity and temperature. Converting 20 gallons of water to pounds would require you to know the density of water. But water's density changes with temperature, so you may need to either know the density contemporaneous to the measurement or the temperature similarly and use a volume correction factor. In the case of the Extended properties, that's only good for documentation - a good column name is better for documentation. The problem with the column implied as being in a fixed unit by name is that you end up putting yourself in a corner when you change measurement units - new client wants oil in barrels and not gallons - and that would be fine since their data is in its own database, but the column name is now misleading. Another option is to store canonical versions in fixed units (i.e. always kilograms and meters) in addition to the varying original measurements. Aggregate operations on the fixed units should be fine (except you wouldn't add temperatures, for instance), but you don't lose the original measurement. 

It seems like this is a symmetric relationship, however, in usage a symmetric relationship becomes a little problematic, since the table has to be joined both ways (effectively a UNION or OR) and indexed both ways. Sometimes it can be easier to have only asymmetric relationships and enforce that both exist with a trigger or something. 

Which of course doesn't work in Oracle (that syntax - apart from the INTO and the optional AS) would be fine in SQL Server $URL$ Is there an alternative to this (which requires me to put the aliasing inside) where the column aliasing is outside: 

Because relational databases are rarely used in isolation, in order to avoid confusion between other parts of systems, I always refer to tables and rows and columns. In a client applications, we typically have other constructs, including datareaders, datasets, datarows, datatables, etc - for instance "field" is often used for on-screen data entry and Pascal has a Record datatype which is similar to a struct in C. Sometimes in a system design, the idea of a "Record" might be used to mean something broader than a single row. It might be a row and it's history. Just as when we talk about a deleted row we might mean a row which is simply marked as deleted with a column or "moved" to a deleted table (and not simply the absence of a row which, by not existing, is rather hard to pin down). There just more varied usage of the term Record. Tables, rows, and columns are generally accepted terminology for referring to these entities in relational databases, including papers and work by Codd and Date, and the majority of database professionals prefer this terminology as it is more unambiguous. There is usually no ambiguity when one talks about rows and columns - other people understand you are talking about the underlying database physical design and not any other kind of artifacts from a logical design before the physical design or any later emergent system entities like fields on a screen. 

See how the DIM_Folder usage makes the set of dim ids small and then, we're assuming some kind of index on snapshot date and then folder dim id (or vice versa). See how you also now don't need to join on folder at all if you just want the data at a higher level. Since you usually know all this at ETL time, there is a different motivation than in OLTP systems where you want everything to move together when something is changed (leg bone connected to the thigh bone, etc.). In DW scenario, you really don't want anything to move. So, bam! - total Farm usage analysis: 

You haven't really indicated how this is called. Do you really have a string full of comma separated ints or is that just an artifact of some other aspect of your system? If the outer part of the environment around this requirement is changeable, then typically in SQL Server 2008 and up, I pass a table-valued parameter containing a list of IDs (perhaps from ADO.NET or whatever) and then just use it as a table inside the procedure - i.e. or 

1) IF PlayerId is assigned with NEWSEQUENTIALID, you could consider that as the clustered index. 2) Otherwise, you can add an IDENTITY and make that clustered (questionable benefit, since all access will be through the PK you have already established). 3) Or you can leave it as a heap - with appropriate non-clustered indexes. My order of preference would be 1, 3, 2 assuming you can't change the uniqueidentifier to an IDENTITY instead. Can you explain why you are using uniqueidentifier in the first place? - that may have some bearing on this. 

It can be very general, just a collection of data and structures. The system for managing a database can be as simple as a file system or as complex as a federated system like DNS. Generally in modern usage, when one says database, one does imply both the data storage and the structures and an accompanying database management system, and because so much theoretical work has been done on the foundations of relational databases, these are still the most popular so that often when one says database, one is often implying a relational database. With the rise of NoSQL/non-relational databases, the term database has returned to being more general, and potentially more ambiguous, since a shared model for understanding the data cannot be assumed. Prior to the foundation of relational theory, the modeling of data in other systems varied from system to system and did not have shared guiding principles as the relational model has - other kinds of databases such as hierarchical databases and network databases were used. 

No matter what, somewhere there is going to be type selection and some kind of branching going on. If you look at how you would do this in your option 1, it's similar but with either a CASE statement or LEFT JOINs and a COALESCE. As you expand your option 2 with more things being linked, you have to keep adding more LEFT JOINs where things are typically NOT being found (an object that is linked can only have one derived table which is valid). I don't think there is anything fundamentally wrong with your option 2, and you could actually make it look like this proposal with a use of views. In your option 1, I have some difficulty seeing why you opted for the tri-link table. 

Yes, it is a valid physical design modification to accommodate more flexible locking behavior. If you join the two tables and expose it to your ORM with a view, I don't think the ORM will know the difference (unless it attempts to look at the view metadata like looking for primary key or something during code generation). Your view should be updatable, and even if it isn't due to some peculiarity of updatable view limitations can always be made updatable using INSTEAD OF triggers. And yes, I would certainly consider it. Whether I would consider it before actually doing load testing on a single table design, I'm not sure. Here's an example in SQL Server: 

From my point of view, you need to be careful that you really are talking about only ITVFs. Inline table-valued functions are basically parameterized views, so they are better optimizable compared to multi-statement table-valued functions. However, this limits some of their functionality. I find it unlikely that all your logic for frontend #1 can be managed with ITVFs, but maybe. It's just as likely that they will duplicate logic in forms in Access unless all they are using is the linked tables and not trying to do any forms at all. It's an OK strategy, but I still expect you might have some duplication of code. As a strategy, it is probably sound because ITVFs are intrinsically pretty low on the complexity list - I tend to use the constructs in SQL in increasing order of complexity - trying to solve problems using the least complex structure possible: 

You can query the INFORMATION_SCHEMA: $URL$ In the INFORMATION_SCHEMA.COLUMNS table there is a IS_NULLABLE column. You could turn it into a function, I imagine, but I would probably put this logic in an outer part. 

Is there a simpler T-SQL construct for "all of these columns to be equal (NULLs ignored) on a row" - effective I want to say: 

This would obviously simply be used in your code as or similar Which helped the translator a bit. But .NET String.FOrmat doesn't support commenting within the format string, unfortunately. As you say, you would not want to handle that in your php with locale awareness or meta phrases. So what we had was a master phrase table: phraseid, english, supplemental info and a localized table: phraseid, localeid, translation You've also assumed with INNER JOINS that the localized versions exist - we tended to leave them out until they were translated, so that query of yours would end up returning nothing at first (not even the default) If a translation didn't exist, ours defaulted to English, then fellback to code-provided (in case the database didn't have the ID, and it was also clear from the code what phrase identifier "TXT_LNG_WRNNG_INV_LOW" was actually trying to get) - so the equivalent of this query is what we used: