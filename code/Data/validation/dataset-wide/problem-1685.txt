You installed a mysql-community repository for EL7, but you have EL6. Remove it and install the correct repository. 

If your script is called via CGI or FastCGI, it should find the document root in the environment variable. 

Most likely you have some old PHP packages hanging around from before you installed the remi repository. First, make sure everything is up to date: 

You have a very strange situation. It's really quite bizarre that any vendor would base a "network switch" on Fedora; with its very short 13-month lifecycle it would be very difficult to support. Unless, of course, they made it impossible to install or update anything, which they seem to have done. And that opens you up to security holes... So if you want to get to a point where you can install software on it, this is what I would recommend. First, the official Fedora archive site is . There you will find the old repositories you are looking for. What I would do is to download the RPM from Fedora 14, and apply that. Then you will have files in which you will have to manually update their s to point to the appropriate directories on archive.fedoraproject.org (and remove the or that might have been in there). This should get you to the point where you can install software and apply whatever updates were available for F14. Also keep in mind that after you do this, the vendor is probably going to tell you to get stuffed...if they're even still in business. Which seems doubtful, if they were making silly business decisions like this. I wouldn't even think about upgrading it past F14 unless you are prepared to sacrifice whatever functionality the vendor provided with this device. Binary compatibility with their custom software cannot be guaranteed if you upgrade to F15 or higher. 

You can use a proxy designed for MySQL, such as MySQL Proxy or MaxScale, to not only load balance your read queries, but also to ensure that writes are directed to the master. From the point of view of the clients, there is only one MySQL connection, which is useful for clients which can't make separate connections for reads and writes. 

If you want to access port 82 directly, you'll need to open the appropriate port in the server's firewall. You can do this with the command line tool. 

Well, they do sort of look like junk at first glance. Likely Gmail and Hotmail have seen so many of that sort of message that they automatically consider any similar messages junk. The first thing I would do is fix the mailing list software so that it's sending both HTML and plain text in the message. 

You can control which IP address Apache listens on using the directive. Just make sure that each server's configuration specifies only the IP addresses you want to use for that particular server. For instance: Server 1: 

Also, don't do development on your production (or even staging) systems. If you really must rebuild an RPM, use which builds it in a chroot and can clean up after itself. 

The problem is that you've put the tilde inside double quotes. When you do this, it is not expanded to the path of your home directory. Consider: 

You don't have enough RAM to run these 2000 processes. We can see here that you have used all of your 64GB of RAM, and are also using an additional 17GB of swap. Your server is thrashing, trying to swap data in and out, valiantly trying to let each of those 2000 processes do something. But of course it's not working. There are only two solutions here: 

You must update httpd to version 2.2.3-31 or later to mitigate this vulnerability. See RHSA 2009:1579 for details. (Note that the latest release as of this writing is 2.2.3-76.) 

Contact the host and request that they make the necessary kernel modules available to you. Use a VPS not based on containers but on full virtualization or paravirtualization, such as Xen, KVM or VMware. 

After adding new repositories, clear your yum cache and update your system before attempting to install any more packages. 

You can't do this with remote desktop, since connecting to the machine with remote desktop will log out the user on the console, and when it automatically logs in again, you get disconnected. Use another technology such as VNC, which does not have this limitation. 

Also, systemd can have instanced units, which start the same service but with a different configuration. An instanced unit has a name ending with , and the instance is the name following the . In the unit file, and are replaced with the instance name, which you can use to load specific configuration files. For example, in an instanced unit , you might specify: 

The quick and easy fix is to fix your web application so that it stops serving URLs that need to be redirected. This will also improve your site's overall performance and SEO ranking. For instance, if you redirect to then all of the URLs served by your web application should start with . 

You don't see these in firewalld because Docker opens the ports itself, outside of firewalld. To see what Docker is doing, run: 

On the next boot, the GUI should start up. If you need to start it immediately, you can also do that. 

If you're running this function as root, there's no need to call and then run several commands. Besides, that won't work anyway. You'll just get an interactive shell, and then the script will continue when you exit that shell. Just run the commands you need with directly: (and you don't need ; will do that for you) 

Yes, you have correctly determined what hardware is in your server. Windows Server really is not significantly different from the client OS. 

You have roughly one packet per second coming into your interface for the better part of a day. Best guess is that someone else on the same subnet as you was sending IPv6 multicast traffic of some sort (neighbor discovery, DHCPv6 requests, whatever). Someone on your subnet could also have been pinging you. You'll have to decide what that means, based on who and what else is on your subnet. 

Run to bring the system in sync with the package repository. It appears that whoever built this VPS template got something out of sync (and for the love of Gawd, it's "5.4"?!) and distro-sync will bring you current. 

As the Apache docs say, when no matches the hostname give in the web request, the first matching the given IP/port combination will be used. Thus, you merely need to give a default virtual host that serves no content, or content of your choosing, and it must be the first one parsed by Apache when it loads its configuration. If you don't want specific hosts to be accessible via https at all, place them on a separate IP address, on which you have configured Apache not to on port 443. 

In RHEL 7, the same SELinux policies that apply to Apache also apply to nginx. So you can use the same booleans: 

Your system has a copy of from the third party repository installed. Unfortunately someone didn't install it correctly and its dependency does not match the version of , because is still the one shipped by Red Hat. How you resolve this depends on whether you really intended to use the copy of , or whether it should be removed and replaced with the Red Hat distributed version. If you intend to use then enable its repository (which is either disabled or not present) and try your original command again. I do not recommend using this repository unless you know exactly what you are doing and can resolve the dependency issues which are certain to follow. (If you could, you wouldn't be here right now, so I strongly recommend against using this repo.) If you intend to use the Red Hat distributed software, remove the repository if it is present, and run . Note that in addition to replacing the third party package, this will also bring the system up to date. 

As a result, any virtual host in a block gets completely ignored for any requests coming in on the IP address you defined in your block, and it serves all requests. You fix this by consistently using either name-based or IP-based virtual hosting for all virtual hosts on a given IP address. 

BTW, I don't know what you mean by "inherited" a copy of the RHEL documentation. It is all available online for free and under a Creative Commons license. 

This is, as far as I can tell, one of the messier parts of Ansible. I've always thought that it should have a way to figure out what package manager is in use on its own, without requiring me to specify it. In the meantime, I have lots of roles with tasks looking like this: 

You got that error because your system still has the package installed. After you remove this, you can continue. As for webtatic, I would never recommend that. I always recommend you use the remi repository. He also builds the official Red Hat packages, and provides repos with newer versions of PHP for those who need them. 

Your web application is doing this, not the firewall. Because you're running OpenShift Origin behind NAT, you need to set to the address from which it can be reached on the outside. See the documentation for other variables you may need to set. 

RPM and dpkg are both perfectly capable of checking package signatures - and of course allowing you to sign the packages. Why reinvent the wheel? If you're building an embedded system, ipkg and its fork opkg supposedly also can deal with signed packages, though documentation is sparse since ipkg is dead and opkg refers to the dead ipkg website... 

Those are both telltale signs of a KVM virtual machine. It is almost certainly running on an Ubuntu host, based on the presence of the "Canonical" brand. 

How on earth did you get those bizarre SELinux contexts? Those are not the default contexts. Anyway, you should use to change the SELinux contexts back to the defaults, on all of your web content. For example: 

Beginning with Docker 1.10, set to be released in the next few days, you can specify a static IP address explicitly when starting your container, with the and options, to specify IPv4 and IPv6 addresses respectively. These can be used with and and persist as long as the container exists. 

I got similar results pinging your IP address from the US. When I pinged 81.212.77.58, the next hop upstream from you, which I presume is your ISP's equipment, I got back a TTL of 243 every time. This is obviously wrong. The next hop upstream from that acted reasonably, with a TTL of 54 every time. My strong suspicion based on these results is that your ISP is mangling the packets. 

No further sign of ULAs in neighbor solicitations, router advertisements or anywhere else, says Wireshark. 

Don't ever trust the string. It is ridiculously easy to fake. And if you haven't banned that IP address already, go do it now. 

You're getting the 405 error because you are passing all requests first to memcached, but it can only handle GET (and HEAD) requests. This upstream therefore returns 405 Method Not Allowed. You need to actually handle this, but at the moment you are ignoring it. I think the easiest way to do it would be to add 405 to the list of errors you handle in . 

In RHEL 6, the package is included with the distribution, but in RHEL 5 it is not. For RHEL 5 you can get it from the EPEL repository, which you don't seem to have installed. 

You should never touch anything in production unless there's a good reason to do so. Security updates are a very good reason. And as Iain mentions, testing beforehand helps you to ensure that nothing is likely to go wrong when you apply the updates to your production system. 

And as a bonus, TZ will be set correctly in the container as well. This is also distribution-agnostic, so it works with pretty much anything Linux. 

When you to a domain, the redirected domain becomes the target for all subsequent DNS lookups, such as those performed by . See RFC 7208 § 6.1: 

In the case you've described, the mails did not originate at your mail server, so they will not affect your mail server's reputation. The SPF record allows any mail server which is configured to check them to reject such messages or mark them as spam, but not all mail servers check SPF records, and some which do check them don't actually do anything with the results. The big providers like Gmail, Hotmail, etc., do check SPF records and use the results, so this is helping you to not receive a lot of bounces you would otherwise get. Not to mention killing a lot of this spam. 

You need to use the WordPress domain mapping plugin. Otherwise WordPress has no idea which blog to use to service the request. 

You have to use EAP/TLS. LEAP support was apparently removed from OS X with Lion. Follow the directions given by your network administrator. 

While you have a separate entry, it doesn't allow access. It seems to have the old Apache 2.2-style , and directives. These have no effect in Apache 2.4, and have been replaced with the directive. To resolve the issue, allow access to the directory. Remove the old directives and replace them with the new one: 

The functions you are asking about have been deprecated for years, and no longer exist in PHP 7. See the PHP documentation for information on choosing another MySQL API for your application. (Note that Magento uses PDO so you should have no issues with that aspect of it.) 

This error is about Unix permissions, and so that is what you need to check. It may also be caused by SELinux in some circumstances. In particular it means that Apache could not search a directory somewhere above the requested file, so you need to check the permissions on the entire path. Fortunately Linux has a tool to do this, called . Run and you can then inspect and fix the permissions on whichever directory is the problem. I bet it will look something like this: 

RFC 822 actually gives an example of this usage. It required (Section 4.4) that the Sender: header be present when it was used. 

As the message told you, the permissions of the file are wrong. You have probably made it group or world writable; if this is the case, it is a security risk and crond will refuse to run it. 

As has been noted by others, when you use and don't provide a network mask or CIDR range, is assumed, and so no routes are created for the subnet. To resolve the issue, you add the CIDR range as well: 

For NICs embedded on the motherboard, rather than in PCI/PCI-x/PCIe slots, the "consistent" network device names are actually obtained from information provided by the system BIOS. To quote Dell, who helped develop this feature: 

The ability to set SELinux contexts on files in GlusterFS volumes was added in GlusterFS 3.11.0. AFAIK Red Hat has not yet shipped this version or a later version of GlusterFS in RHEL or Red Hat Gluster Storage. However, it is available in Fedora, and in CentOS 7 by installing or depending on the desired version. 

The problem is that you used , which is not the HTTP hostname the browser requested, but the first defined in the block. To fix this, change it to , which is the hostname the browser requested. 

You can use to make images of the hard drives in these systems (or the individual partitions, if you want). can be used to read or write data to a plain file, as well, and you'll take advantage of this. Since the hard drives are likely much larger than the actual space used, I recommend compressing them as well. So the general idea would be something like this: 

This occurs when a client connects to the web server, but then fails to send a request before disconnecting. It also occurs when a client connects, sends a request with set, but disconnects before sending another request. In either case, they can be safely ignored. 

You're almost there. First, the WP Super Cache rules are very messy. They really need to be redesigned from the ground up, but that's a project for another day. To get this working, don't return immediately, instead set the as all of the other checks do. For instance: 

If you use the SURFboard, you'll merely have to stick a router behind it that's capable of routing your traffic in whatever manner you want. If you don't have static IPs then it really doesn't matter much from a technical standpoint which modem you go with, today. But the lack of IPv6 support is going to hurt you in the future. And, today, I have the SURFboard (and I'm still on Comcast). It does support IPv6, stays completely out of the way of routing and lets me do whatever I want with my internal network. BTW, NAT doesn't protect you from anything; the firewall does. NAT just causes all sorts of trouble, which is why IPv6. Either way you're going to end up with two boxes. (And I'm not really going to touch the office network design aspects here, since they really are separate questions and should be treated separately...)