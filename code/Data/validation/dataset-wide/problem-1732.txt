I have an Stunnel 4.29 on Red Hat Linux 6.8 that will not start and emits a 'No such file or directory' error: 

From the container, I can ping the default gateway but all name resolution fails. I noticed one weird thing in the log (Update #2 I now know that this is a red herring - see discussion below): 

Still no luck. I spent a whole day on this so pulling my hair out by now. Any thoughts on what else I could try or what else the problem might be much appreciated. Update #4 I performed some experiments using Netcat and I have proved that all UDP packets are not forwarded if sent from any container -> host. I tried using several ports including 53, 2115, and 50000. TCP packets are fine however. This is still true if I flush the iptables rules with . Furthermore, I can send UDP packets from one container to another - only UDP traffic from container -> host is not forwarded. To set up the test: On the host, which has IP 10.1.1.10: 

I tried unsuccessfully to fix the bad UDP checksums via this. I noted, however, that the bad UDP checksums are seen even during the successful transmission of UDP packets (host -> host) and container -> container. In summary, I now know: 

I have a docker container and I am unable to run DNS lookups from inside containers, although it works fine from the docker host. The configuration management code that builds the Docker host is known to work on a standard RHEL 7 image from the marketplace, therefore the problem is known to be something inside the SOE RHEL 7 image. RHEL 7.2 / Docker version 1.12.6, build 88a4867/1.12.6. Container is RHEL 7.3. SELinux in enabled/permissive mode. The Docker host is an Amazon EC2 instance. Some config: 

I've been running a data collector to identify possible causes and have isolated data for the outage windows, attached. $URL$ The one main concern is that during the outages, the % CPU for the asp_state.exe process jumps significantly higher. I had theorized mcaffee was a culprit, but there are other times when mcshield.exe spikes and there is no corresponding session outage. I bumped the timeout from 10 to 15 seconds this week as well, but just had an outage today. Does this data point to a culprit? What could the State Server be doing during these CPU spikes? Any other counters I should be tracking? 

Now, I am getting the role specific playbooks to run properly on my mac. The windows side is still unknown how to make it work. 

When provisioning with ansible in Vagrant, I am unable to get server/role specific playbooks to run. There is a common playbook run for all hosts, and that is working, but when trying to target a specific role, I'm missing something. Any ideas what piece is missing? The ansible output is: 

GitStack is the one I'm currently evaluating. As I'm beginning this process too (setting up Git server on Windows), and this discussion is over a year old, I thought I'd add that to the mix. 

There are many services that advertise themselves as providing multifactor authentication for Citrix. But, most seem to require the additional generated passcode every time. Are there any that can require the password once per device, like Google's 2 step verification? So that once a device is registered, it only needs username/password at that point. Components of this environment: 

I recently migrated an app from SQL Server backed sessions to the ASP.NET State Server. About once a week there is a brief failure of ASP.NET to connect to the state server. These last from 20 seconds to 2 minutes. 

I recommend reading the revision number from a file rather than reading from an environment variable. There isn't an easy way to ensure that your current environment is the same a the environment that Apache is running under. Also this ensures that the revision number in the php code survives reboots, etc. You should set Subversion to ignore the svn-revision file so you aren't checking it in. 

If the name for the reverse address does not match the forward address, it is likely that the name you see was the name assigned to your IP address when the IP was used by a different customer of your provider. If the name does match, you should talk to your provider and make sure something else isn't going on. If possible, please revise your question with some examples of what you're seeing. 

What do we need to do to make the disks be recognized? Any other things that we need to try? EDIT Here is the output of : 

Glancing at the Instagram post, I don't believe they're using Nginx for buffering or caching (although I could be wrong). I use something similar but with HAProxy instead of Nginx. Some of the reasons why we took this approach: 

We have a Sun 4140 running Linux (CentOS 5.5). A disk failed in a software RAID-1 array. We powered off the system and added a two new disks to empty slots in the chassis (we couldn't simply replace the failed disk due to some GRUB misconfiguration). Upon booting the system back up, we went to configure the new disks and add them to the array, but it wasn't found under the subsystem. The disk was found during booting (output of ): 

I have a virtual machine (Windows 2008 Server R2 64 bit running on vmware esxi 4) with 6 GB of installed RAM. It's reporting 95% memory usage and close to 0% CPU. This server hosts some WCF services on IIS and has AppFabric installed which installs its own SQL Server 2008 R2 Express. All in all, pretty low usage though. When looking at the memory tab of the resource monitor, there is no obvious process consuming very much memory. The sum of the commit column for all processes listed is around 1.5 GB. So, while the machine is reporting 95% usage (over 5 GB), I can't figure out what's using it. Looking at perform, I added several counters in the Process object and the biggest anomaly I found was that sqlserver had a virtual bytes count greater than 6 GB, yet it's private bytes count is 125 MB. Does that high virtual byte count prove sql is the source of the high memory use? What would cause that spike? Or should I be looking at something else to isolate the memory hog? 

But, the user is still unable to create a table within the target schema. It's not until I run this, hat the user can create a table: 

I'm trying to instrument ASP.NET cache behavior on a web cluster by accessing the counters in the WMI class, Win32_PerfFormattedData_ASPNET_ASPNETApplications. 2 of my servers have this class, but 1 does not. They all have the versioned class (Win32_PerfFormattedData_ASPNET4030319_ASPNETAppsv4030319), but not the general. How can I get WMI to expose the Win32_PerfFormattedData_ASPNET_ASPNETApplications class. It is visible in perfmon. 

In trying to lock down access to a web application too only users within a XenApp environment. Is it possible to send the clientname in the HTTP payload by customizing something in the XenApp server (registry, etc)? These users will be using Internet Explorer in the xenapp session. Similar in theory to how a proxy server passes a X-Forwarded-For header. We know WHO the end-user, since the have authenticated, but we also need to identify the end-user device distinctly from other users. 

You didn't explicitly state how Subversion is served, but based on your tags, I'm assuming Apache. Using Apache 2.2 to serve Subversion with authentication by AD is pretty simple. In your Apache config, you need to add the appropriate Auth parameters to the location block for the repository. For example (restricted read and write access): 

Basically you need to include all directories in the search, then add all files to the list, the exclude all other files. The option is handy to use as it excludes any directory that doesn't have a file. 

We are looking into using BtrFS on an array of SSD disks and I have been asked to verify that BtrFS does in fact perform TRIM operations upon deleting a file. So far I have been unable to verify that the TRIM command is sent to the disks. I know BtrFS is not considered production ready, but we like the bleeding edge, therefore I'm testing it. The server is Ubuntu 11.04 server 64-bit release (mkfs.btrfs version 0.19). I have installed the Linux 3.0.0 kernel as the BtrFS changelog states that bulk TRIM is not available in the kernel shipped with Ubuntu 11.04 (2.6.38). Here's my testing methodology (initially adopted from $URL$ with modifications to work with BtrFS): 

So after many days working on this, I was able to demonstrate that BtrFS does use TRIM. I was unable to successfully have TRIM work on the server that we will be deploying these SSDs to. However, when testing using the same drive plugged into a laptop, the tests succeed. Hardware used for all of this testing: 

From reading your answer it sounds like this is a client-side issue. Subversion does not support client-side hooks (from what I know) so I would recommend writing a small script similar to the following to perform your update and also update the revision number in a file.