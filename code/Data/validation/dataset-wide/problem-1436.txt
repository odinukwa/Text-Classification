I try to start from part dealing with removing of checked attachments. First, I can't find purpose of lines. Only if it used for debugging in development. Second, - every time updating single attachment, you need to go through all existing records. I think, that is what 'Codeclimate' "says". So, that structure must be simplified. Here is how I suggest to rewrite 'deletion' part: 

If you're using some kind of TDD all classes must be test-covered. Adding classes that are not mentioned in tests at least confusing, at most - leads to unnecessary complexity. What is the difference between , , and ? They are storing input/output methods but must be responsible for business logic, I think. They are acting like higher level of abstraction. BTW, - good "trick". Code is readable and easy to understand. When I looked through once again, I noticed that this part can be improved: 

This methods definitions can be removed from 's subclasses. My way (written in "least resistance way" with tests): 

In this code-snippet you've 1x and 2x statements. It's better to use ruby iterators (like , ). This way you're avoiding unnecessary variables and their "manual" incrementing ( in your case). Also try to avoid unexplained "hard-coded" integers(, ). Basically they're variables or constants. Next weird strings... it's hard to understand their purpose. Why use , not empty string? Everywhere in code string length is used, not content. Output lines can be easily organized with and be more informative. My variant of your code refactoring: 

Make the first object the centroid for the first cluster For the next object, calculate the similarity with each existing cluster centroid If the highest calculated similarity is over some threshold value then add the object to the relevant cluster and re-determine the centroid of that cluster, otherwise use the object to initiate a new cluster. If any object remains to be clustered then return to step 

I have a pretty simple problem. A large set of unique strings that are to various degrees not clean, and in reality they in fact represent the same underlying reality. They are not person names, but they could be. So for example Dr. John Holmes and Dr. Jon Holms are more than likely the same person. From the list of unqiue strings I want to cluster together those that possibly match the same underlying reality. There is no restrictions on the size of the cluster (i.e. I am not expecting only one match per string). I calculate the distance between strings using the Jaro-Distance with jellyfish in python. But then I wondered how I cluster them together? I was unable to figure out how to do this using scipy clusters as I am working with strings, not floats, so I decided to work according to the following algorithm. 

There would be little point using the code as presented if it didn't make life easy, and not escaping any of the properties would make it cumbersome and error-prone to use. E.g. you've got this in the Testing section 

I use gearman as an example - but you can implement it any way you wish. Just ensure your solution account for jobs that fail intermittently (job fails once, reschedule for later) and for jobs that fail consistently (something wrong, job fails 3 times - flag for action). 

Which is in fact set to four spaces. "\t" is easier and shorter to type. Minor Point: Whitespace Whitespace in html is insignificant, so doing this: 

Code separation What you have there is everything mixed together - just by moving the php logic to the top of the file, makes it easier to read. With some minor reformatting it becomes easier to read/maintain: 

I'm not particularly fond of the style of coding, not everything needs to be a class. But there is only one point that I feel warrants significant attention: Huge Point: Not escaping means not useful 

(Which, incidentally is the same as: - use dot notation where possible.) If you write it like that - seeing that you are passing (almost) the same argument in all use cases to your create_filter_input function - you can start to see/think that you don't need 2 local variables - just having "property_type" is enough. As one of the other answers says - don't serially append to the dom. each write is relatively expensive. it's better to build a dom fragment and append it to the dom in one go. 

Also, I decided to strip out generic components of the strings to improve the matches. In the name example above, this would give Dr. John Holmes, and J. Holmes a better chance of matching if 'Dr' is stripped out as a generic component. I created a Stripped Class that has an attribute that is the original unique string, and then attribute that is a stripped version (stripped of the generic components). This is becasue once stripped many of the strings could have exactly the same values, and I need to be able to identify which original string they identify. The code is posted below. It works well, except that the size/number of clusters is not independent of the order in which the strings are evaluated. So the results do differ. In the final function, the SLink fucntion is called inside another function I would specifically like to know if anyone knows of a better way to implement this type of clustering? If anyone has comments on how I could improve my code, and if anyone has any information about clustering strings in scipy. In an IPython notebook I go through in more detail how I could refine this system, including using another function to verify the clusters using alternate data points relating to each string (such as age). If anyone would like to view that and offer guidance, then please see the following link: $URL$ I think as the functions were somewhat trial and error and unplanned, they may have got a bit out of control. Any guidance appreciated. I am a researcher living in Bangladesh, a total programming data tripper sadly, but trying to get better every day.