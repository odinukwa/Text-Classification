Community wiki answer: The benefit here is that while you are loading your data in the staging tables (maybe it takes 8-10 hours), your destination tables are still accessible to your reporting queries and they are logically consistent (for example, contain data up to yesterday). As soon as you finish your data loading, it takes one second or less to switch in your staging table. Once completed, your reporting table has logically consistent data up to today. So the advantage is not only availability, it is consistency. If your ETL takes a long time, and you load your tables one by one, the overall state of your database during the loading process is not consistent; you have some tables with data up to yesterday and other tables up to today. Concerning performance: load the data using minimally logged operations like , and add nonclustered indexes only after the load is completed, and just before the switch to match the structure of destination tables. So there is also a performance gain. See The Data Loading Performance Guide for more details and techniques. 

We can create the database trigger on concrete schema event (ON SCOTT.SCHEMA) or on all schemas (ON SCHEMA). However, we can also use ON DATABASE when creating database trigger. What is the difference between them? Is it some legacy stuff? ON DATABASE should be used when using AFTER STARTUP or AFTER STARTUP because it's definitely related only to database but the same stuff that is done using ON SCHEMA might be done using ON DATABASE, so what's the difference? I can't find references in Oracle docs about that. 

You can create an index and define prefix length, so the index will store only first starting symbols from each of column value. It looks like this in MySQL: 

Hopefully, this last schema update will run quickly once all values are non-null and the default is in place. 

Community wiki answer originally based on a question comment by RDFozz. Please edit it to improve it if you can. 

Community wiki answer based on a comment originally left by the question author: Finally I solved this issue. The problem is in phpmyadmin: I can see those using MySQL query in command but still not in phpmyadmin. It's a bug in phpmyadmin as mentioned in How to support full Unicode in MySQL databases by Mathias Bynens. 

Community wiki answer: Even though writing T-SQL of such kind is a good mental exercise, I suggest that you move this business logic to server or client side, where you can process it with language that at least has arrays. For example, you can get all available seats from the databases to your web app and render them, and then highlight consecutive ones. It would be much more convenient either in this case, or if any changes are to be made to the location of seats and sections. 

The trigger does not contain autonomous transaction procedure with commit inside that, so who is commiting the insert? This triggger works like a charm and inserts new record into log table after user logon. It smells like hidden Oracle functionality and I can't find any reference in Oracle docs about that. I'm using Oracle11g. 

AFAIK there are three major structure types used for storing Oracle index data: B-tree, R-tree and Bitmap. All indexes use one of these structures. However, not sure about CONTEXT, CTXCAT and CTXRULE Oracle text indexes... 

Is it possible to monitor role and privilege grant/revoke using triggers? I' aware of doing that using Oracle audit tools however, it's interesting is it possible to do that using triggers. 

Community wiki answer: Parameters and local variables are different beasts. The plan with parameters is generated (if not already cached) using row count estimates gleaned from the actual values supplied and statistic histograms. The plan with local variables is generated based on unknown values so the average overall density () is used to estimate row counts. The plans may differ due to different row count estimates. Related: Understanding Performance Mysteries by Erland Sommarskog 

Community wiki answer: are binary data files used by the WiredTiger storage engine. Individual files are not usable as a standalone backup. If you want to take a file copy backup of a MongoDB you need to include all of the files using a Supported File Copy Backup Method. If you have a valid file backup you can use it as the for another instance. Aside from copying files, there is no restore special restore process for a file copy backup. Can you clarify what files you have in your backup? 

What is the difference between Oracle clusterware and Real Application Clusters? If we have 2 servers and want to join them into a cluster why there are two separate software products? 

Oracle has partitioning and clustering features. Partitioning enables to split table or indexes into multiple tablespaces and store on various servers. So it's done manually. Clustering enables several servers to make operate as one. This IMHO is handled transparently. However, it's possible to have several tables (in different server databases) and group them as one, and use it. From the perspective on table partitioning and table clustering, IMHO both ways implement shared everything because the data is split into the different locations. The theory about shared nothing architecture is that each database node is independent. But how this looks in practice? Both ways (partitioning and clustering) splits data into different sources and could be also described as horizontal partitioning. However, if we had for example, two different database servers we would need to synchronize the data between them... Anyway, any thoughts on that would be appreciated :) 

The MySQL documentation at 14.21.3Â Troubleshooting InnoDB Data Dictionary Operations has the official guidance. Aleksandr's alternative suggestion is: 

Community wiki answer: Try the latest SSMS version which is fully compatible with SQL Server 2016. It will install alongside your old version, not upgrade it, so make sure you then open the correct version. 

Community wiki answer: Your condition only eliminates about 50% of the rows in the table. In that case the Seq Scan will be faster than the Index Scan. See for example this Stack Overflow answer, where user a_horse_with_no_name says: 

Once that's complete, I plan to run the final schema adjustment to make that new bit column non-null: 

Suppose we have a server that has only 1 CPU with 1 core, so we need 1 Oracle database license for installing a database into it. Now, if we would need to add a second server, combine them into cluster and install database into it, then how many licenses do we need - 2 database licenses and 1 Clusterware licenses or 1 database license and 1 cluster license? I'm not sure, how Oracle treats joined into Oracle cluster servers - as one server or still as separate servers? Because we would need to buy expensive Oracle cluster software, then it would be logical for Oracle to treat joined servers as one. 

Community wiki answer: Did you really read chapter 23, where vertical/horizontal decomposition is described? I don't see any 'n/a' or 'd/k' anywhere there, even more in numeric columns. Figure 8 on page no 384 shows is what is "obtained" from the database, so a result set. Not what is being stored in the tables. As the previous pages describe, the suggestion is to decompose the table into smaller ones (fewer columns and/or rows) and each table stores the different info, i.e. one table for unknown, another for not applicable, etc.) The only place where 'n/a', 'd/k' are stored if you use a table with a column, and combine multiple missing-information tables into one. 

We can't COMMIT/ROLLBACK in DML triggers because transaction is handled manually after DML statement. However, database triggers seems to be an exception. For example, suppose there's a database trigger: 

I found there are special "Oracle Text" indexes that improve performance for wildcard queries. Such index construction requires a little bit more work but still is a way how to create prefix indexes: $URL$ 

Hash indexes are usefull when you have a large table with URLs and you need to query by them. So, a solution would be to have an additional column "url_crc32" that will be filled with hashed URL value via trigger on inserts. An index on url_crc32 would be definitely faster than index on URL column that is a type of text. It's not very common case to query data by URL. The more frequent case would be to query text data by fragment and hash indexes are useless in such case. So, I'm curious do you use such hash indexes, and if so then when do you use? IMHO Oracle does not have native hash indexes, so that must be done manually. 

Exclusive locks associated with those data modifications will be held until the transaction is complete. See the Deadlock Troubleshooting posts by Bart Duncan. 

Unchecking seemed to fix this immediate issue, but caused a new one. Now the 'me' user cannot expand any server nodes in SSMS. It looks like ultimately some of our logins were orphaned because we created the databases from backups from a different server. Community wiki answer based on comments left by the question author 

Indexes are good to reduce many rows to a few rows based on a condition in your query. Unless you have a very unequal distribution of values, a "not equals" condition will most probably not be considered for an index lookup. So, it all depends on how selective this index would be. Unless it eliminates much more than 50% of rows (usually 90%+ is desirable) it's probably no better than a sequential scan. See Use The Index, Luke