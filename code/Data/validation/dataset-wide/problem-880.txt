It goes on to claim that cometary meteoroids make up about 95% of observed meteors, 38% of observed fireballs, and 0% of fresh meteorites. (Since a hypothetical cometary-origin meteorite would weather faster than meteorites of asteroidal origin, they would be even less likely to be found later, and so it's not surprising that the page says 0% of all known meteorites are of cometary origin.) 

(Would this even be theoretically possible?) I very much doubt it. What you're suggesting would involve incredible changes in angular momentum over the course of one orbital period. In the scenario you suggest, the angular momentum vector for the planet (the direction of its north pole) starts off pointing in one direction. Six months later, it's now pointing in the opposite direction. Since angular momentum is a vector quantity, that would require an enormous amount of torque and energy to achieve. And then you have to do the same thing again for the second half of the orbit, and repeat the whole thing each orbit. 

You might take a look at this 2006 paper by Thomas et al. on centroiding algorithms for astronomical adaptive-optics (AO) systems, which includes a detailed discussion of error estimates for the centroid position using different algorithms. The approach you describe in your answer corresponds to what they call "simple centroid" (Section 3); they refer to a book chapter by Rousset (1999) for the detailed analysis (which I believe includes Poisson and readout-noise contributions, and so is not identical to your result). More generally, the "center-of-gravity" approach seems to be used in situations where one needs fast, computationally cheap estimates, such as in AO systems (where a stellar centroid needs to be determined many times a second), or as a crude first guess to provide a starting point for a more sophisticated analysis. Post-observing analysis of astronomical images generally uses more complex/sophisticated approaches, depending on whether the source is a star or other point sources versus an extended source, whether you have an accurate model of the point spread function (which may be non-circular), deblending of neighboring sources, what the noise characteristics of your data are, etc. In practice, I'd guess that most such analyses use some kind of nonlinear least-squares or maximum-likelihood analysis that involves fitting a model to the data. The errors in the fitted model parameters (including the centroid position) can be derived from simplistic assumptions about the fit landscape (e.g., Levenberg-Marquardt and other gradient-based minimization algorithms sometimes provide covariance matrices based on treating the local $\chi^{2}$ landscape as a parabola), from bootstrap resampling, or from Markov Chain Monte Carlo approaches. This may be supplemented by running simulations of the fitting process on artificial images of simple models of stars or galaxies, to get some quasi-empirical estimates or corrections for the centroid (and other parameter) uncertainties. 

If you're only trying to correct a small field, using a single guide star (or a single laser guide star), then the requirements aren't very arduous. The MACAO adaptive-optics module used on the Very Large Telescope at the European Southern Observatory dates from the early 2000s and is based around two 400 MHz PowerPC 604 chips (one for the "supervisory computer", the other for the "real time computer"). You can read more about it here (PDF file). For next-generation multi-conjugate adaptive optics, which tries to correct a larger field using multiple guide stars, the requirements are bit more stringent: my impression is that you need several GFLOPs in the real time computer (some of this may be handled by using specialized DSP chips instead of general CPUs), and additional processing power for external monitoring and analysis. So, crudely speaking, your smartphone could probably handle single-guide-star AO (except it would need to be re-engineered a bit and running a real-time operating system, and you'd need an extra computer for external monitoring); for multi-guide-star AO, you'd end up needing the equivalent of a powerful (multi-CPU) server or (small) cluster. 

The largest "robotic" (i.e., unmanned) telescope I'm aware of is the 2.4-meter Automated Planet Finder. Other large robotic telescopes include the 2.0-meter Liverpool Telescope and its copies (Faulkes Telescope North and Faulkes Telescope South). You can read about the automated control system of the Liverpool telescope here. These are all located at existing observatories (e.g., APF at Lick Observatory, Liverpool Telescope at Observatorio del Roque de los Muchachos, La Palma, Canary Islands, Spain), which means there are people on site for potential maintenance work, etc., though said staff are really devoted to working on other telescopes. The closest thing to an isolated, automatic telescope in an uninhabitable setting might be the small (0.5-m) Antarctic Survey Telescope at Dome A in Antarctica, which I believe is serviced annually by Chinese expeditions. It can apparently be remotely controlled via Iridium satellite communications, though actually retrieving the full data sets is part of what the annual expeditions are for. 

The short answer is that, as George notes in his answer, there is no naming system for supermassive black holes. I wouldn't say they're really "named" after their host galaxies; more that when one wants to refer one, you usually do it by using the name of the galaxy (e.g., "the SMBH in M31" or "M87's SMBH"). "Sgr A*" is actually the name of a radio source, a subcomponent of the radio source Sgr A which happens to be associated with the Galaxy's SMBH. The very early system for naming radio sources -- before better radio telescopes found so many that the system became unworkable -- was basically "name of constellation" + "decreasing brightness rank". So Sgr A was simply the brightest radio source in the constellation of Sagittarius. (In fact, the system was abandoned before most constellations even got to B.) Most such sources are not black holes; for example, Casiopeia A is a supernova remnant, as is Taurus A (the Crab Nebula). 

Your intuition is largely correct: the key is that the proto-bulge region had a deep enough potential well so that the supernovas couldn't expel the remaining gas, and so new stars could form out of the gas (enriched by the supernova ejecta) in a continuing cycle. In the low-mass, isolated protogalactic clouds which probably contributed to the halo, the initial round of supernovas ejected most of the gas (including the original gas that hadn't yet formed stars) -- thus, little opportunity to form more stars (out of higher-metallicity gas) on a continuing basis. It's really the total mass in a given region that matters. For example, the density of stars in the central regions of a globular cluster is pretty high, but the mass of the cluster as a whole isn't enough to keep most of the gas when its massive stars go supernova. (Side note: the traditional terms "Population I" and "Population II" aren't used all that much any more, since age and metallicity can vary continuously and aren't always strongly associated.) 

Dark matter is (thought to be) in halos which extend both to the centers of galaxies and outside most of the normal matter in galaxies (gas, stars, dust). So a black hole inside a galaxy could and undoubtedly will ingest some dark matter. However: Stellar-mass black holes form from the core-collapse of a massive star. Since stars are almost entirely of regular matter, the initially formed BH remnant would itself have been made almost entirely of regular matter. Such BHs might later grow by accreting gas (e.g., from a close binary companion star), in which case they're gaining mass in the form of regular matter. There would inevitably be some dark matter swallowed by the BH as it orbited within its parent galaxy -- just as the BH would swallow some interstellar dust, for example. But it would still be overwhelmingly formed out of regular matter. Supermassive black holes in galaxy centers would probably start out from some kind of early-universe collapse of a gas cloud or very massive star, which would again be mostly regular matter. Subsequent growth of supermassive BHs comes primarily from interstellar gas feeding an accretion disk around the BH, plus the occasional star that wanders too close -- so once again it's mostly regular matter that falls in the black hole. (The central regions of galaxies do have some dark matter, but they're dominated by regular matter. Plus, regular matter in the form of gas clouds can easily lose energy via cloud-cloud collisions and sink to the center of the galaxy, where it could feed a supermassive BH; dark matter can't do this.) (Of course, as user25972 points out, it's largely irrelevant to outsiders like us what kind of matter goes into making a BH. A black hole formed out of dark matter would behave identically to one formed out of regular matter.)