Now you need to remove the parameters : @CurrentDatabaseNameFS and UPPER(@CurrentBackupType). This will create all your backups to a single location as below 

We have multiple instances on single node of the AlwaysOn setup, all are configured as AOAG. Right now we are connecting using the Listener\InstanceName. The listeners for each AG is having a dedicated port designated. This is why we cannot connect just by using the Listener without the port or InstanceName. I wanted to configure in such a way that just giving the AG_Listener would be enough to connect without using the port explicitly. 

I was going through various articles on Missing indices and Unused Indices. Was wondering how having multiple indices which are un-used causes performance issues. 

You can build the "Export from SQL to Excel" part also via the SQL Server Import and Export Wizard in BIDS. Check this video for a demo. For the Send Mail Task, check this BOL article. If you want to automate and schedule it, you can use a SQL Agent scheduled job with an SSIS job step. A video demo is available here. If you automate it on a server, make sure Microsoft Access Database Engine 2010 Redistributable is installed (you do not need Excel there, just the "drivers"). 

First, are you sure the data growth won't happen again? If there's a realistic chance it will and the empty space doesn't hurt you, leave it, do NOT shrink the database. However, if you're positive you want to reduce the data file size, then you should be aware of the pitfalls of data file shrinking: 

As per Microsoft, having same service account is the prerequisite : All server instances that host an availability replica for the availability group must use the same SQL Server service account. The domain administrator needs to manually register a Service Principal Name (SPN) with Active Directory on the SQL Server service account for the virtual network name (VNN) of the availability group listener. If the SPN is registered on an account other than the SQL Server service account, authentication will fail. $URL$ 

This is the most frequently faced issue for almost all the DBAs where the logs grows and fills out the disk. 

It depends on what your needs are. Re-organize is a light weighed operation ,generated lesser logs and always an Online operation. While rebuild is online only for the Enterprise edition of SQL Server and is more heavy operation. 

The where condition is not applied at this part, as you can see from the whole query you posted. Looking at the predicates and outputs of the nested loop and the clustered index scan, I suggest you try to create a nonclustered index on . 

I can show you an example for SQL Server, but it should you help for your RDBMS aswell. I hope I understood the question. Suppose you want to get TOP users based on the number of same skills as the current user. Some sample data: 

It specifically mentions SQL 2012 at some point, but I guess the same would work for 2008 R2 aswell: 

Concerning clustering keys, here is a great resource by Kimberly L. Tripp (start with links at the start of the article): More considerations for the clustering key â€“ the clustered index debate continues! She gives detailed explanation of why a good clustering key should be unique, narrow, static, ever-increasing, non-nullable and fixed-width. The articles are about SQL Server, I'n not sure if the exact holds true for other RDMBSs aswell. 

Other than Logins,Agent Jobs,Triggers and already mentioned points by Max, these 2 can also be looked upon. 

Index maintenance is very vital when it comes to query performance. So it is very important to have it properly planned and implemented. Along with Index maintenance comes the ballooned log file which is the result of Index rebuild and re-organize. Now planning for Index maintenance is important as it might just trigger another issue of 'Transaction full' unless proper precautions are taken. It depends on you how you want to do the index maintenance, however the solution from Ola hellengren is the best and freely available. Link below : $URL$ With above solution you get multiple options and all can found in the website. Coming down to your queries: 

The main point has already been stated in answer by mendosi: the Columnstore Object Pool is located outside the Buffer Pool. See the blog he linked. The question is a bit unclear. Do you want the Buffer Pool to have the same memory available when you start using columnstore indexes? If yes, then: 

Run the first to see exactly which rows will be updated. If needed, adjust the clause to get the rows you want to target. Only then mark the sentence from the till the end and execute it. Much safer then running a "blind" update, as you did, forgetting the clause (I assume that was the problem). Even safer - do it on some test database first :). 

Since the recent patch where TLS 1.0 was disabled and 1.1, 1.2 Enabled , we are having issues where the SSRS in the server cannot make connections to the Database server. 

The above will backup all databases in AG except UserDb. For more information please go through the Databases parameter in the below link Ola hellengren 

Yes, that is how we need to roll out patches in the sql cluster with minimum downtime. The downtime will be during the failover part. Process: 

Try making the db to Multi-User from the GUI and not via script in query window.Also run sp_who2 and try to terminate the connection which is accessing the database now. Once the database is accessible to all users, it will not throw the error you have mentioned. 

Unless you have some kind of history table & trigger in place, to retain old values at every change, or you made a copy of the table before you ran the update, you will need to use the last backup that was taken before that update. Restore it (as some temp database) and extract the data. You do have a backup available, right? BTW, next time you're doing an update, I suggest you set it up like this: 

The query you posted is not valid for creating a view; running for this query will result in an error. Are you using a clause? A view, being a table expression (a set), can't have the order defined, since that would be against the principles of a relational model (there is no order for rows in a relational table - a set is an unordered collection of tuples). Same goes for other table expressions - derived tables, CTEs etc. From BOL article about the clause: 

All you have mentioned should be fine. Just remember to script out the replication before doing this as a backup. 

If you have already deleted the Imported Tables then you are fine. You will not be required to do anything else. This can happen and to get rid of this Use the Import/Export Wizard or Properly use the databasemame.Schema.Table. 

This is how SQL Server works and there are limitations to make it perform better as the Page limit is 8KB for all versions of sql server. Pasting something from msdn that will be helpful : $URL$ Row-Overflow Data Exceeding 8 KB A table can contain a maximum of 8,060 bytes per row. In SQL Server 2008, this restriction is relaxed for tables that contain varchar, nvarchar, varbinary, sql_variant, or CLR user-defined type columns. The length of each one of these columns must still fall within the limit of 8,000 bytes; however, their combined widths can exceed the 8,060-byte limit. This applies to varchar, nvarchar, varbinary, sql_variant, or CLR user-defined type columns when they are created and modified, and also to when data is updated or inserted. 

On the other hand, if you're fine with Buffer Pool getting less memory and/or you can't increase memory on the machine - decrease the MAX memory setting on the instance, since you'll need memory for the Columnstore Object Pool. In any case, I recommend monitoring memory usage and tuning machine memory and/or MAX memory setting accordingly. As a starting point, some DMVs: 

I refer to the advice of Paul Randal from his article "Why you should not shrink your data files" (read the whole article to get a clear picture what happens with index fragmentation): 

Long story short: Use the clause in the outer query that references the view. Do not use it in a view. Even using it with (or on SQL Server 2012, the equivalent) does not guarantee presentation order, it just means you'll get the top 100% of the rows, in any order.