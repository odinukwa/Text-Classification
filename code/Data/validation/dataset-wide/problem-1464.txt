I know that threading is a bit of a problem anyway here, but I would just like to comment on this specifically: by writing you are waiting on the thread to finish before starting the next iteration. This gets read of the threading all together, as there will only be two threads alive at a given time: 1 worker thread, and the main thread waiting on the worker to die. I'd suggest writing it as: 

Let's continue our focus on the nested . Now, for symmetry, we replace with . (I'm not showing the and anymore). 

Why do you even have the /? It adds nothing of value. Also, the parameter is now a list of , instead of a . Another thing I'd suggest doing is using the attributes of our class we just defined. 

It should be quite obvious that the only difference in these statements is the filename. "Easy" fix: 

You have a race condition! But not just the one you expected. Let's take out the 'beef' of the algorithm, and make something simpler: 

Another point of incorrectness In , you check that the length is > 2, but then you filter on . This should be the other way around. A tiny suggestion. Floating point arithmetic is challenging for problems like these. Maybe look into the fractions module? 

I'm doubtful of you using for this. But I don't see a better builtin for it either. But I see a lot of logic here which I'd like to separate a bit more: 

First of all, the could as well be written , but the point is: sometimes returns 1 (and other times 0 or 2). In that case, you'd call , which is basically a do-nothing operation. In fact, I'd hope that would throw an error in this case, but I can't check your code there, so I'll assume it will happily move whatever you tell it to. Unreachable conditional? One of the conditionals in your code is the following: 

This way, the code is just a bit more readable, because you're left with only the functional part of the code. Another thing that's worrisome is using blocks and manually closing the file. A block closes the file when the code leaves the block. Let's get rid of the explicit . 

The difference will be that this gives a list of tuples instead of a list of lists. That's hardly going to be a problem in the following. 

By using instead, everything is fine again. Subclassing list You're subclassing list, which causes to make a shallow copy of the supplied iterable. I myself would prefer composition: 

Please on your instance, so that it can be safely closed when your program terminates. Consider putting the calculation logic into its own method, so that you can call it by passing it two arguments (start and end). In fact, this can also return a of prime numbers for the caller to handle the results (print it out on console, display on a GUI, save to a file, etc.), so that the logic and the input/output of your program are properly separated. Do prompt your user by printing out a descriptive line before the input, e.g. 

Trim line. If length matches, count the line and print to . At the end, print the summary for valid/invalid lines. 

Using model classes It's not easy to manage a pair of values to determine if the timings they represent overlap. You have to: 

Unit testing As it currently stands, testing your class means having to feed it a filesystem-based input (even if it's using something in-memory like Jimfs). You should consider implementing your application logic such that the input is the form of , so that the source of that stream is independent of the processing here. splitting as 

is a convenient way of tokenizing a line as a stream, which in turn allows us to perform a by replacing each element of the source stream with the contents of the resulting stream. Convert each token as an integer within a certain range 

This is going to be subjective, but I'll just put in my two cents anyways... Looking at the statements above, I will roughly read them as 

I don't have much experience with Hibernate, and I'm rusty at JMS, so I'll review the other parts of your code... You have two inconsistent braces usage for your block: 

My take on modifiers on method arguments and variables these days is that they are largely redundant, as long as you can easily observe that they are not carelessly reassigned. If you happen to come from a (programming) culture where this is done way too often, and thus you are introducing to check such practices, then feel free to leave them in until such 'reminders' can be removed. Looping via iteration Another way of doing looping via iteration is to rely on the standard -loop as such: 

Let's get the basics right first... After attempting to understand your implementation, these are the gotchas I can spot (some repeated from @Robby Cornelissen's observations too) 

Since the method is only concerned up to days and the day of the week, I think you can opt for the "simpler" type for your testing. also has a static method that works directly on types, of which inherits. Therefore, you can replace: 

Also, in Dijkstra's algorithm, the key point is not the nodes, but the edges. An edge is a tuple (source, destination, weight). But let's first see what we can clean up before tackling that. Your takes a list of things. It claims to be a list of nodes, but it's actually a list of lists: edges. So maybe it would make sense to define a namedtuple : 

There are so many things going on, it is a bit worry-some. Also, you might want to add a space around the operator, causing the need for yet some more work. By using string formatting ($URL$ you can make it a bit simpler: 

Ideally, you'd want to just mirror the definition for , instead of re-using , as it more cleanly symbolises the symmetry 

(without the comment). The code is just as clear. Excessive commenting in general Another comment I'd just like to point out. Somewhere in the code I see 

as a method on the class If you follow my suggestion of turning the grid into a class, you can write 

The algorithm itself. Your algorithm is also far from optimal, calculating collatz(16) several times. First, when trying to add 3, it goes 

The trick is an optimization trick preventing a lookup to the global dictionary. Using compiled regular expressions also gains a bit of speed. (On the other hand: I don't see being used, so that's probably ok). Since it's not documented, I'm going to assume the calling convention will be 

weird function name Did you mean pythagoras? Oh, no, you meant . what does do? What are f,g? It looks like it returns two values based on , but it is not clear to me what the expressions signify. How did you get those expressions? It probably derives somehow from and its derivatives. Maybe it would help if you could show us what the code looks like for the arclength of the arc formed by between -1 and 1 (it should return 2). arc length algorithm Also, the arc-length runs the risk of running into a recursion-error. And it's slow due to function calls. Suggested implementation (typed on phone, untested): 

So, ideally, you'd want to make sure that contains as much as possible. One way to do that would be to add the following before the first loop above: 

Ok, so we do not get a string, but a list of characters. That's what is for. Finally, we need to convert it back to an integer, we can do that using . 

You load all files into memory at once. This is expansive. Rather not. Let's assume that there are no cross-file sentences going on (at least I hope not!). 

I am trying to write an algorithm that can find user-specified nearest neighbors. By user-specified, I mean that the user can specify whether it's a general nearest neighbor, a forward-nearest neighbor, or a backward-nearest neighbor. The idea for this code was inspired from this SO post. While it isn't ideal to search the entire array (perhaps use searchsorted as an alternative), I want to find all occurrences of the user-specified nearest value in the given data array. While there are other techniques that can be used to achieve the same goal (such as using the cumulative sum of differences of argsorted values), I feel the code below is easier to read/understand and is likely quicker since it performs less operations that require traversing the entire data array. That said, I would like to know if there are better approaches (in terms of speed) to achieve the same output, as this code will be applied to a dataset of at least ~70,000 data points. More than the value itself, I am concerned with the indices at which the values occur. 

Since the sum changes with each iteration through your dictionary values of , I don't know of a way to pre-compute the right-side sums before-hand. This would be a little easier if you could use external modules. That said, you might see a slight speed-up if you use more comprehensions. For example, you can get via . Also, use (not ) to check zero equality and use (not ) to check . Also, you are iterating through all possible combinations. In the case of using and , you know that and . So you know that your lower bound is cut-off at 76. Those are 76 permutations that you do not need to use. You can include a statement at the lower bound since you are incrementing downward (), but I would instead use this lower bound as the starting point and iterate by incrementing upward as you may find some other way to restrict the sums in the upper limit. Lastly, the use of globals and non-descriptive variable names makes it hard to edit the code. For example, instead of , instead of , etc. Also, you can pass into . I personally prefer iterating over lists instead of dictionaries since you can use zip. I don't have a full solution for your problem, but it may help as a start. 

Can the speed and/or accuracy of this algorithm be improved? Is it proper to use centered differences at interior points and one-sided differences at the boundaries? 

However, I've heard that it is good practice to modify the bins such that the observed counts are above a threshold (typically 5, sometimes less) as a large number of bin counts below such a threshold can result in a bad fit (assuming minimized chi-squared). If the observed bin count is less than this threshold, then the bin is merged with the next bin. Assuming a distribution (such as a Gaussian) with a central peak, the next bin would be the next-right bin (i to i+1 bin) when the bins are left of the central peak while the next bin would be the next-left bin (i to i-1 bin) when the bins are to the right of the central peak. I've created an algorithm that I believe works and covers all-edge cases (assuming a single central peak). I was wondering how it could be improved in terms of speed/efficiency. I also feel like I am duplicating code using similar approaches in two while-loops; can this be averted?