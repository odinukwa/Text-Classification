No. There would be no valid disproof. We generally hold that it is not possible to validly disprove something which is true. So if there are ten dimensions, any proof which concludes that there are not ten dimensions has a flaw somewhere in it. This is very different from some universes not being able to prove that there are ten dimensions. In some universes, I can imagine that an a-Ten-Dimensionalist could say: 

This statement is no longer self-defeating. But what is meant by 'truth'? Let's say "how reality works". We consider F = ma to be 'true', at least in certain domains. In others it's an alright approximation, and others it's a terrible one. It seems best to think of this kind of 'truth' as "true under these circumstances". Surely though, my inner thought-life is part of reality. Can science understand how it works? Somewhat. Can I say true things about it apart from doing science? Herein lies the rub. If we define 'truth' as "what science does", then we essentially say that a color is only 'red' if it has sufficient 'redness'. A claim is only true if it is sufficiently investigable such that science can be done on it. But these leaves huge swaths of life where science can't be done (many events in people's lives are nonrepeatable and not sufficiently similar to other events), or oughtn't be done (let's see what happens when infidelity is encouraged, under controlled settings). Do we really want to deprive ourselves of the concept 'truth' in these areas? I suggest a significant reframing: 

Damásio is a neuroscientist/neurobiologist who discovered that certain brain lesions would cause two simultaneous effects: 

It is not clear what precisely you mean by "would always happen"—why? There needs to be a mechanism for avoiding evil choices, no? That mechanism would ban all free creatures from being actualized in the first place, because such creatures would be transworld depraved. And so, precisely the world which is actualized would a priori contain no free creatures. You seem to be suggesting some world be actualized with creatures which are guaranteed to not make any evil choices, and then complain that, hey!, how can we say that those creatures aren't free creatures? But given transworld depravity, you can create only these two kinds of worlds:      (1) an all-good-choice world with no free creatures      (2) free creatures who inevitably make evil choices And so, your world-picking procedure has the freedom property smuggled into it, since transworld depravity logically combines freedom and your criterion for picking the world. 

And yet, when the link is clicked, one is redirected to WP: Property (philosophy). The very idea of 'property', at least to me, does not smell like 'relation'. This is but a noisy indicator that relations are still not dealt with head-on in philosophy. See also the Google search for "site:plato.stanford.edu relation", with really only one result which directly bears on relations: Medieval Theories of Relations. C. I think it is revealing to look at what a popularizer of science, Caltech's Sean Carroll, has to say at Post-Debate Reflections (the debate was with William Lane Craig): 

Without the statement of a purpose or telos, you don't have a standard with which you can judge your friend's position. Consider the following two purposes: 

This depends on how similar one mind is to another—at all levels of similarity. If there is sufficient similarity, then just as understanding a vast number of different types of rocks gives us additional knowledge about any one rock, understanding a vast number of different minds will give us additional knowledge about any one mind—including our own! 

Curiously enough, Mark Turner's argues in The Literary Mind: The Origins of Thought and Language that narrative—particularly what he calls 'parable'—may indeed precede language—contra Noam Chomsky and his universal grammar. Conclusion Science, if defined as the study of objects from the third person, is wonderful at understanding objects and how to manipulate them. However, if the goal is to enhance people, who necessarily have first-person perspectives, then this kind of 'science' is insufficient. Indeed, third-person science actively thwarts the pursuit of human thriving if used alone, as it 'finitizes' the inside of a person, instead of treating that inside as something which can grow, perhaps without known limit. 

Popper talks a bit about axiomatic systems (e.g. p53), but for now I'll stop short of providing full Popperian reasoning for the folks who would give a 'Yes' answer. 

One simple way to illustrate this is via the contradiction between predictions of general relativity and quantum field theory near the event horizons of black holes. These are two of our best scientific theories, and yet there is a contradiction. It is not 'logical'. But it is empirical. Of course we hope to ultimately resolve this contradiction, but putting a supreme value on being contradiction-free ("rationalistic") would appear to be extremely bad for doing more science. Were you to be properly empirical when it comes to what makes for the best scientists, you would be able to provide evidence to demonstrate at least one of the following propositions:      (1) upon becoming an atheist, a scientist does better science      (2) upon becoming religious, a scientist does worse science I have offered this challenge quite a few places on the internet over the past several years, in atheist-dominated domains, and never gotten a single peer-reviewed article demonstrating either (1) or (2). Instead, I got ad hoc hypotheses, in the manner of conspiracy theorists: they are absolutely sure their underlying "theory" is correct, and so any failure to produce expected evidence or explain unexpected evidence is rationalized away. For example, scientists are said to be able to "compartmentalize" away their religious beliefs while doing science. Curiously, the very attempt to squash religious belief in scientists is irrational if this compartmentalization produces no measurable ill effects. Never has evidence of ill effects been presented to me. What I suspect is going on is that you have a rationalistic idea of reality which predicts (1) and (2) so strongly that you have felt no need to actually go out into reality and check. Or, perhaps you have observed unscientifically and concluded that (1) and (2) are true, forgetting that in so doing, you have violated the principles of science in order to support science. Humans do this all the time and it's not clear they could wholly act in any other way. Nevertheless, it is self-defeating to bolster science through unscientific means. That is exceedingly illogical. 

All sense perception is "through a glass dimly". We know that our external senses—or extrospective senses—are pretty bad if and until we tune them. What some do not know is that we have good reason to think that our introspective senses are also pretty bad until we tune them; see Eric Schwitzgebel's 2008 The Unreliability of Naive Introspection: 

In my above answer, I basically rephrased your question: what allows a mind to become self-aware? An imperfect reality is our knowledge of atoms: we say we 'know' about them because we have A) identified many properties of them; B) predicated many thoughts and actions on those properties; the result being that we gained increased understanding about how to manipulate reality (which is the test that differentiates between 'just-so story' and 'theory'). When we make ourselves the subject of study, self-awareness comes when R sufficiently matches A ∪ T ∪ B. That is, when our introspective senses start reliably 'meshing' with our extrospective senses. 

Yes, pending a slight change to the question. (see A → B, below) I suggest we utilize Solomonoff induction (LW's narrative intro for those who don't know some basic theory of computation) in order to examine the issue. I will need one other tool: the concept of a non-recursively enumerable set of axioms. I claim that there are two kinds of infinite being: 

'faster': because many interesting problems in computation have exponential increase in time as the input size grows, they cannot in practice be solved, except by approximation; if we can find exponential speed-ups, like Shor's algorithm, we change what is physically possible to compute (in a finite universe) 'merely': there is nothing that BQP in theory can solve which BPP cannot solve 

Taylor spends the first part of Sources in critique of naturalism and reductionism; he contends they obscure our understanding of ourselves by depriving us of the ability to make important distinctions—chiefly, about what does and does not constitute a worthy life. Whether or not you agree with him, Taylor should help you see aspects of your question which lie in a blind spot of much modern, Western thinking. 

One option is to define 'better' to exactly that domain where science excels. For example, science has given us antibiotics and sanitation; what has religion provided in this category? Now, this approach ignores aspects such as our high valuation of egalitarianism, which is arguably required for scientific endeavor but was not itself a scientific result. However, that is irrelevant if it can be argued that no religion had appreciable positive impact on our high valuation of egalitarianism. Another option is to assert that 'religion' does not excel in the area it claims to. Given that there is empirical evidence that 'religion' can provide some benefits[1], one needs to somehow dismiss this. A common answer is that managing emotions has nothing to do with truth; here we need to say that managing emotions has nothing to do with better. That, or the kind of emotional management religion can provide is not superior to alternatives. As to our current theories possibly being wrong: all we actually need are approximations which suffice for the job. In control theory 101, a common example is cruise control for automobiles. As it turns out, one can have a rather terrible model of the vehicle dynamics and still get an acceptable system for controlling speed. Similarly, F = ma is still used in plenty of domains without relativistic correction. One area it does need correction is GPS; without relativity, errors would rapidly accumulate. 

I've taken to describing this as monocausation: there is one causal power in play, constituted by the laws of nature (not to be confused with scientific laws, which are understood to be approximations). And so, compatibilism is an attempt to achieve something that looks like free will without adopting a different metaphysics of causation. In other words: there is an implicit commitment to the denial of agent causation, where agents are irreducible sources of causation in addition to the laws of nature. Of course there are costs to abandoning monocausation: how exactly would two causal powers interact if there are no "global rules"? Every philosophy has to bite its bullets. You can find a fairly well-developed alternative to general causation/​determinism/​monocausation in Gregory Dawes' Theism and Explanation. There, he asks whether "God did it" could possibly suffice as an informative explanation. Let's not get too caught up in theology; what he's really asking is whether agent causation could possibly provide explanatory power over and above what you get with general causation. His answer is yes: a good explanation has to rule out possibilities, and there is a way to do that other than via scientific laws (e.g. [partial] differential equations): by rationality and what he calls the "optimality condition". I can predict the future based on cranking mathematical laws on state, and I can predict the future by knowing what courses of actions agents consider more optimal to achieve their goals. What you're really fighting here, is an "as if" method of explaining, exemplified by Daniel Dennett's intentional stance. Instead of teleology, you get the appearance of it, built on general causation: teleonomy. That which appears designed actually evolved. You may think you love your significant other, but it's just oxytocin. There are attempts to hide this reduction to general causation (e.g. Sean Carroll's Poetic Naturalism), but it's there. Libertarian free will, as I understand it, is an attempt to break out of the straight jacket that is general causation, but sometimes (often?) without understanding that the reaction is not to all forms of determinism, but only some of them. A great criticism of what is called 'determinism' can be found in mathematical biologist Robert Rosen's Life Itself. He looks at the specific mathematical forms to which all science was supposed to ultimately reduce—basically, differential and partial differential equations—and argued that it's not even possible to define 'life' with such spartan tools. There are simply more ways that causation can happened, he argued. Were the advocate of libertarian free will to avail himself/​herself of this critique, I suspect some interesting progress could be made. Then again, perhaps I am simply ignorant of the latest, best literature on free will. 

I've begun seeing Ockham's razor as being a statement about cognition and learning, and not about the construction of reality. Human understanding works best by successive approximation. Think about coming up with the coefficients in a Taylor series one at a time, vs. trying to figure out multiple at once. Trying to figure out multiple at once is computationally much harder. Having to fit multiple variables simultaneously is much harder than fitting them one at a time. Possible support for this comes from Grossberg 1999 The Link between Brain Learning, Attention, and Consciousness, in which we aren't even conscious of observations unless they sufficiently match a model we already have in our brain. We learn very well when the difference between what we know and what we're being presented with is not too large. Imagine Charles Darwin employing Ockham's razor to the cell, using it to say that the cell probably isn't very complex (details). That would have been a demonstrably wrong application of the razor. The razor doesn't address ontological complexity, despite it often being used that way. Instead, it says that the best way to understand the cell is by bits and pieces. An alternative, today, would be to cease all study of the cell until a computer simulation can be programmed which perfectly simulates cells. This would obviously never work. One could rephrase the razor: "Don't bite off more than you can chew." One property of successive approximation is that you stop when the next increment does not make things any better. Ockham's razor says that it is here that you stop. 

This is an excellent question. A. One way to motivate your question is to compare:      (1) laws of nature      (2) the things they act on (Essentialism?) These really do seem to be in different ontological categories. Without such a difference in categories, it seems that things would cause things and one would get an infinite regress. B. Another way to look at this is through the idea of relations; see D.M Armstrong's remark: 

Fortunately, neither of these claims need to be true in order for either answer to be plausible. This is because: 

The paradox is that 1. was supposed to lead to the opposite of 2. It was supposed to be possible to bring everything under a single system in an objective way which would remove all needs for that messy thing called 'interpretation'. For a very different perspective of what language could be, I turn to David Braine: