What you are creating is a third level domain. This should help a bit. DNS just converts the IP address computers talk into names humans can use easily. The reason you don't have to specify the NS server is pretty simple. You have already specified them for example.com. r.example.com is just pointing to a different IP address. 

It sounds like there is some security that your system administrator setup. I would talk to your IT/System Administrators before you go trying to bypass the security they have put into place. There are a number of different setups that could be "blocking" you. 

It sounds like SNI is not enabled. That would explain why they all go to the same page. If you are running Debian Lenny or Debian Squeeze I believe that it will work. Check out this page It describes how to enable SNI on your hosts. Note this is used with NameBased Virtual hosts. From your configuration it looks as though you are using Named virtual hosts. 

This has happened to me in the past. It Have you tried Different ports on the switch and a different Ethernet Cable. I've seen where a bad cable will give you link but not show you have a good enough connection to the pins to keep the signal of proper quality for higher then 10/Half. 

These three things alone would prevent 99% of the exploited systems I've seen in my 15 years of system administration. Don't get distracted by security theater until you've accomplished those three things and have made them a part of your daily sysadmin routine. After that, you can worry all you want about other stuff (but it probably won't make a big difference in the security of your server to worry about a bunch of other stuff). 

What are the permissions of /var/lib/bind and the hosts files within it? The likely problem is the files are owned by root:root, but need to be owned by bind:bind or named:named or similar. Check to see what user owns the BIND process, and make sure those files are owned by that user. BIND drops privileges after starting and claiming its ports, and so if the files are owned by root, it wouldn't be able to alter them. You can change file ownership with the command: 

John underestimates Webmin. Browse to the BIND DNS module in Webmin Select the zones you want to update in the "Existing DNS Zones" (check the boxes beside them) Click "Update Records in Selected" On the resulting form, set the following: Record type to update: Address (this is the default) Current value to change: address you want to alter New value: new IP address Click "Change Records" You may also need to click the Apply changes link in the top right corner of the BIND module home page in order to reload the BIND zone files after making the change. Additional documentation for the BIND module in Webmin can be found here: $URL$ 

This sounds like a Harddrive issue. Does this happen on all the laptops or just a few? Have you checked the Eventlog to see if there have been harddrive or hardware errors. One easy way to check and see if it's a hard drive issue would be to load up a Live-Linux CD and check for badblocks. Also I forgot to ask what type of hardware do you have for these laptops. That could be another factor to look at. 

I have been using Raid1 on linux with write's way over 15M/S. Those log messages are indicative of either a hardware issue with the drive, a bad Sata cable, or a bad connection on the motherboard. Does SMART reporting show any errors with the drive. I would check that and the SATA cable. Easy cheap solutions if it is a hard drive issue. 

This is what I think the best option would be. First Connect the ASA5550's in a HA pair. Connect HA1 Inside/DMZ interface to Switch1. Connect HA2 Inside/DMZ to Switch two. Have the Failover monitor ALL interfaces that are active. Between Switch one and Switch two setup a 3 or 4 port LACP. Now this is also assuming that your ISP has given you two distinct connections that are in the same IP address space. Also you didnt say what version of ASAOS you are running. The Release notes for 8.4(1) stats they did introduce EtherChannel. They may be worth looking in to as well. 

Disclosure: I am a developer on Webmin, Usermin, Virtualmin and Cloudmin, and work for Virtualmin, Inc. 

What you want is not actually a chroot. You want the DefaultRoot setting in ProFTPd. You can set that in Virtualmin by browsing to Webmin>Servers>ProFTPd Server>Files and Directories, and set the option labeled "Limit users to directories" to "Home directory". Save it, and click "Apply changes" in the upper right corner. 

Of course. SSL certificates are not really related to the OS or OS version, at all. The OS doesn't need to "accept" the SSL certificate. You would simply configure your new server with the SSL certificate in the places you're using it (presumable in Apache for web service, possibly in other services, like SMTP in Postfix or Sendmail or POP3S and IMAPS in Dovecot). There have been some changes to SSL that effect end users over the years, in terms of commonly used key sizes and the like, but it is a very slow-moving standard. Your certificates should be useful for years; we have some that have been in use unchanged for as much as five years. Oh, one other thing: If you were running a version of OpenSSL affected by the Heartbleed bug, you would need to get a new certificate, regardless of OS changes. If you use the standard package provided by CentOS 5, you will not be affected by this bug. It was introduced midway through the CentOS 6 lifecycle, and never appeared in a CentOS 5 OpenSSL version. 

arp -an will show what you you are looking for. There is a time out for how long the MAC will stay in the table. 

I'm using an asterisk VOIP server, and I'm able to make called though with my SIP client. The problem I get is one-way voice. I can hear the incoming voice but the caller can not hear me. I have no problems when using the X-Lite3 windows SIP client. I VOIP provider is broadvoice. Could it be something in the firewall rules that I need to fix? 

I just check to see if the Currently Active slave has changed or not. Also if you are just looking to see if link is lost on one of your NIC's, you can still do that though SNMP or other standard forms of monitoring. 

Is there a way I can convert an MBR partition setup to a GPT partitions with out having to destroy all my data? Thanks 

You can host multiple SSL based sites. You have to use SNI, and not all browsers support SNI, so you can have issues with an older web browser. Most modern browsers should support it. It's described in RFC-6066 This HOW-TO can walk you though how to do it. 

We have a guide for reducing memory usage here: $URL$ Edit: Also, I'm not sure what to make of the error you had in your configuration after install. The last test install I did on CentOS didn't have this problem, but if it is reproducible, please file a bug with the steps to reproduce it, so I can get it fixed. It's possible (maybe even probable) that it is caused by the same problem with your system that is causing all the other problems. Installation is pretty demanding of memory, because so many packages get installed and started up at once. 

There is nothing to "compile" in Webmin. It is written in Perl, with some client-side JavaScript and Java. setup.sh is an install script that puts the files in the right places, enables the webmin service on boot, etc. There is an uninstall script generated when you run setup.sh, which will reside in the Webmin directory (wherever you told Webmin to install itself when you ran setup.sh), called "uninstall.sh". But, if the install hung very early in the process this script may not have been generated (it has to be generated because the locations are not known until you tell it where to put things, and it'd be annoying to have to know where you installed it when you want to uninstall it). I suspect such a script exists, though. There isn't a lot that can go wrong during the install; you've not given us any clues about when in the process it hung. I just haven't seen a Webmin install fail in years, except in cases of pathological server problems (failing memory, failing disks, no disk space, not enough memory, etc.). I would recommend you install Webmin using the apt repository Jamie provides at $URL$ or if you're also using Virtualmin or Cloudmin, use the repositories at $URL$ Using native packages just makes more sense, and provides many additional tools for keeping up with what is installed on your server, and makes removing stuff easier and cleaner. It also makes your install more predictable; if I sit down at a Debian system where Webmin has been installed from our package, I know Webmin lives in /usr/share/webmin. If I sit down at a system installed from the tarball, I have to guess where it lives, or go dig into the initscript to see where it points to. I agree with sybreon...you're trying to solve the wrong problem here. The problem is you don't know why Webmin failed to install. Installing it again will just keep failing until you understand why it's failing and resolve that problem. Anyway, to answer your question, if you don't have an uninstall.sh script in the Webmin directory: Remove the Webmin directory. This is whatever you told it to use. Maybe /usr/local/webmin, maybe /opt/webmin, maybe /usr/share/webmin. Probably the first of those. Disable the Webmin service on boot using the Debian update-rc.sh script (I think that's how it's done on Debian, anyway) Remove the Webmin initscript (/etc/init.d/webmin) Remove any Webmin cronjobs; or, if you're going to reinstall Webmin, you can just leave them and double check to be sure there aren't any extraneous ones using the crontab editor in Webmin. I think it will skip adding cronjobs if they already exist, even if it doesn't know it's an upgrade. That's pretty much it. Webmin isn't compiled, doesn't touch any system directories except creating the startup script, and doesn't leave stuff lying around at random on your system. 

Official Support for the Debian distribution is not provided by Dell. However I have been running Dell Servers with various Debian versions for the past several years. They have been very good about supporting the Hardware. 

Time servers take a couple of samples to make sure they are reading the upstream servers properly and to set their own stratum correctly. It sometimes takes a while. Usually less then 10 minutes. When you get an error like that you should first check the stratum your NTP server is reporting. There is a limit on how low windows will go to set its time from a NTP server, but I dont recall off the top of my head. 

Depending on how you setup your Postfix you may be able to use an alias to forward all mail. edit Also you can setup a redirect that will do it for you easily. In /etc/postfix/main.cf add this: 

If you server is running some form of linux, try setting a ulimit on the user that generates the PDF's. 

It sounds like you system is doing what is called thrashing. What that means is your system is swapping pages in and out of memory for in use systems. That includes SSH. You actually have a couple of options. The first option is of course to reboot the server, but it sounds like that is not much of an option for you because it's not local to you. If it's at a datacenter then you may be able to get them to walk up to it and reboot it. You have to check with your DataCenter. Second option is also pretty simple. Your SSH session just hangs waiting for some stuff to be swapped out so it can allocate a tty for you. I have had this happen to me before, and you just have to wait for it to respond, it can take quite a while. Once you have a cli then you can kill or reboot the server. The reason you can PING the server is actually pretty simple, the kernel's IP stack (IIRC) does not get swapped out that is why ICMP is able to respond. A third option would require some setup before hand so I dont think it's a real option for you right now. You can setup a modem to allow you to dial in to a number and get a serial console. On the same note you can use IPMI Serial over LAN (SOL) to get a serial console. Also IPMI can allow you to reboot the server. Once again it sounds like those are not setup for you. 

And, if you ever find something that cannot be accomplished from the command line that is possible in the UI, it's probably a bug, and one that we'll address. You can file a ticket at Virtualmin.com for things like that. There are some things that aren't reasonable on the command line, like the system status graphs, but generally if it's something you could reasonably want to do from a script, we'd like to make it easy to do. I believe API coverage is very close to complete, but every once in a while new stuff comes up. The usage for this command is: 

Did you install Virtualmin using the install.sh auto-install script we provide at Virtualmin.com? Or did you install Virtualmin manually? The behavior you describe means your scripts are not being executed using suexec, but rather as the Apache user. If you used the install script, suexec should be configured, by default for all script types. If you installed manually, you'll need to set that up yourself, as well as recompile Apache (or, install the apache2-suexec-custom package, and configure it for /home, if you're using Debian/Ubuntu) to set the suexec docroot to /home. We have some documentation about manual installs on our website, but a manual install still requires pretty significant knowledge and a big time investment. We recommend using the install script on a freshly installed Grade A supported OS, as documented on our Download page. I don't know anything about gitweb, so I'll leave those questions unanswered. 

This is a bit of a hack but it will work for forwarding specific users from one domain to another. You also may want to look at this page for how to do some rewriting within Postfix it's self. 

I dont know of a web interface to manage squid blacklists, but you may want to look at DansGuarding. It has a very good blacklist and can be edited to suit your needs. 

Another service you can use is CAcert.org. They offer free SSL certs, you may want to look at them I use them for some of my certs. 

I use Bacula, its free and open and works on Windows and Linux, and has extensive documentation on the linux and windows ports. As for Duplicati, I have never used it so I cant really tell you what do on that, but you that is an alternative. 

What does show? Once you get the kernel names you can just Just make sure you do not purge your current kernel. The results can be unexpected. 

That line right there tells you the issue. Check your DMESG and see if it's detecting your other disk, also with software Raid I run smartmon on all my drives to make sure they are ok. You could have had your second disk go bad, and you didnt know it. Now to fix this you just need to run this command, assuming your second drive of your array is sdb. 

Re-Check Configuration will detect whether suexec is misconfigured in some way on your system, but since it works sometimes, it means you have some configuration over-riding Virtualmin's settings in the Apache configuration. suexec not being called for some domains or directories is the source of your trouble. That would indicate a few possibilities...mod_php doesn't work with suexec, so you'd need to use FCGId mode or CGI mode in order for suexec to work. My assumption would be you've got some custom PHP handlers in your httpd configuration that are leading to mod_php being used for some applications rather than CGI or FCGId. Virtualmin only controls that with domain-level specificity, so if it's really "sometimes" for a given domain, it has to be directory level or more specific. So, check your configuration file for custom handlers that lead to mod_php being used instead of FCGId or CGI. Also, MPM is incompatible with mod_php, as far as I know. So, if you're ever using MPM, you should even be loading mod_php, as you can't safely use it. 

Nothing is wrong with Postfix (or the Virtualmin install), as far as I can tell from the information provided. Your Postfix is being killed with SIGTERM; it doesn't look like it is crashing, it looks like it is being told to shut down. I would guess it is the OOM killer kicking it out because there's not enough memory on the system for everything you're trying to run. How much memory do you have? Is this system a VPS with so-called "burst RAM" and a much smaller amount of "guaranteed RAM". In a system with "burst RAM", it just means that you will never be able to count on your system to be stable...processes will be killed at random and there's nothing you can do about it, because processes and the kernel don't know what to do with RAM that suddenly disappears; but some hosts over-sell memory and advertise it this way. And, it may just be a VPS with oversold memory, without labeling it "burst RAM". You can usually find OOM errors (out of memory) errors in the kernel log (just run dmesg to see the recent kernel log entries). If you do find out of memory errors in the kernel log, you'd need to do one or more of the following: 

I was wondering who uses off site tape storage for their backups and their Positives and Negatives with each system. My basic requirements are secure storage, HIPPA certified, or SAS certified would be great. We rotate our tapes out every 6 months to offsite storage. I have looked briefly at Iron Mountain. 

The issue is displayed in your netstat output. Mysql is bound to the loopback address. Check your /etc/mysql/my.cnf (if you are running Debian, or ubuntu) and change the bind-address from bind-address = 127.0.0.1 to bind-address = 10.10.10.99 Also I would make sure you have proper security and firewall rules setup to protect your mysql server. 

It depends on what type of Load Balancing you are using, and what you mean by load balancing. If you have some kind of firewall disto such as pfSense, then there are build in clustering and failover solutions you can use. 

I'm running a couple of iSCSI Targets with OCFS2. I had to reboot my iSCSI Target (the physical iSCSI Target) due to some hardware changes and it caused all the initiators to reboot. I want to prevent that or at least make them wait a lot longer before they reboot. Is there some sysctl variables I can use to modify the targets? I have multiple iSCSI Targets on my main system, due to need to share them out with multiple systems I'm running OCFS2 as the Filesystems on the Initiators