Figuring out what is a 'basic colour term' (as opposed to a historical compound) is incredibly difficult, as is figuring out the order in which languages acquire them. Figuring out the order of colour term inclusion in a language is incredibly hard once you include more languages than Berlin and Kay original looked at. Even in their original data set they are incredibly flexible once they get beyond the basic few terms. This is a summary of chapter 2 of their book (of which they have a not-very readable summary on page 17): 

The linguistic feature you're talk about is the difference between an endonym and an exonym. An endonym is the name that an ethnic group gives to their own topographic space, while an exonym is that given to the group by an external group. These terms can also extend to the name of the cultural group, or the name of their language. It's pretty common around the world as you can see from all the examples above, given that groups generally have a different perspective on themselves than others external to them do. 

Although not a true test of mutual intelligibility, Blair's (1990: 26-34) is one way to quantify the lexical difference between two languages, so as to get a percentage of lexical similarity. The higher the similarity the greater likelihood of mutual intelligence. The test works by taking a word list, the bigger the better, although I have successfully used it on a mini-corpus of a 100 word Swadesh list before. Each item is gone though, with points assigned for features the same - identical are given full points, differences that are minimal are given less points, and there are no points for completely different items. The great thing about this is that it can be done across multiple languages/dialects at the same time. There are probably computer programs that can do this now, and more sophisticated analytical processes, but for a small list it's not that hard to do it be hand as long as you have a rudimentary knowledge of phonetics/phonology. Blair, F. (1990). Survey on a shoestring. Arlington, SIL International and The University of Texas. 

You can think of the language choices we make based on: a) the things we want to talk about in the world, and, b) the people we want to talk to. It is negotiating our relationships with people that we get all kinds of pragmatic effects (awful summary - language use in context). On of the most interesting works on this kind of effect is Brown and Levinson's book on Politeness (1987). They talk about these things in terms of face - saving your own face and threatening someone elses. They argue that this accounts for a great deal of the choices like 'I think' - which is a hedging strategy to weaken your assertiveness (or in some cases, strengthen it! Language is funny like that). Brown, Penelope and Stephen C. Levinson. 1987. Politeness: Some universals in language usage. Cambridge: Cambridge University Press. 

I don't know any off the top of my head, but Eugene S. L. Chan has a large number of languages for which he has collected basic numeral terms: $URL$ 

All languages contain terms for black and white. If a language contains three terms, then it contains a term for red. If a language contains four terms, then it contains a term for either green or yellow (but not both). If a language contains five terms, then it contains terms for both green and yellow. If a language contains six terms, then it contains a term for blue. If a language contains seven terms, then it contains a term for brown. If a language contains eight or more terms, then it contains a term for purple, pink, orange, and/or grey. 

I know we've already mentioned it a dozen times already - but I always find Wikipedia a good mix of basic definitions and indepth discussion. It usually doesn't seem to be too theoretically biased either. 

co-speech gesture is an area that has received lots of attention only in the last 20 years or so. You'll find lots of work being done on the importance of gestural information contributing to meaning. Adam Kendon and David McNeill have both done a lot of work on this. To summarise two of the more interesting pieces of work in relation to your question: Susan Golden-Meadows found that if the gestures accompanying the description of how to solve a maths puzzle contributed to the explanation of how to solve it then children were more likely to be able to solve to problem (see her 2003 book). By far my farvourite recent work on this is Jenny Green's 2010 thesis (University of Melbourne) on Arrandic story telling . In Arrandic languages of Australia story telling is always performed with speech, gesture and sand drawing. All three contribute meaning to the story. Although it's only one genre of speech some of this does carry over to general discourse. 

The best article I've found on this so far is: Anderson, Diane and Judy Reilly (2002) "The MacArthur communicative development inventory: Normative data for American sign language." Journalof Deaf Studies and Deaf Education, 7 (2): 83-106. This article is about the MacArthur report, which they created to allow parents to easily report their children's early signs in American Sign Language (ASL). With data from 69 children. The study only included deaf children with deaf parents. To skip to the pertinent information - children were documented as producing signs as early as 8 months, but until the age of 12 months they only produced concrete nouns. The study lists the first 35 words that signing children produce (averaged out across the sample - at least 50% of them had to be saying it before it was accepted) and compared it to a list of English speaking children from a similar study: The first seven items were identical and went daddy, mummy, bye, ball, baby, no, shoe. From there it's still very similar, lots of concrete nouns relating to clothing, food, animals and family members. So we see a similarity between English and Sign in terms of the content, even if it's not identical. For example English speaking children have words like moo, woof, yumyum and uh oh in their vocabulary whereas such sounds aren't so relevant to non-hearing children. In another study Petitto, L.A. (2000). On The Biological Foundations of Human Language. In K. Emmorey and H.Lane (Eds.) The signs of language revisted: An anthology in honor of Ursula Bellugi and Edward Klima. Mahway, N.J.: Lawrence Erlbaum Assoc. Inc (A PDF version of a similar paper can be found here $URL$ it is mentioned that children who grow up English/ASL bilingual and French/LSQ bilingual don't necessarily produce the same first words in both modalities. So a child's first spoken word might be more and their first sign might be DOG, but that's not to say that their first word might not overlap. Petitto gives the example of chapeau/CHAPEAU (hat) for the French/LSQ bilingual child. So although there has been very little cross-linguistic research done into children's first signs cross linguistically we can see from a comparison of ASL and spoken English that the exact words might not be the same, but that they generally fall into similar categories. 

Although it is a strong tendency it is still only a tendency. The prevalence of these two sounds in the names of parents is not surprising, given that they're two of the easiest sounds to make regardless of the sound system of your language. Think about English - we have 'mother' and 'father' but we'll accept 'mama' or 'dada' as a first word, because they're easy to make - open CV structure and basic stop sounds. Basically, across the world caregivers have an incentive to hear what they want to hear - and they want to hear their children say their names. Given that cross-linguistically mothers are generally caregivers, the easiest sound 'ma' usually is used first and the harder sound 'pa' or 'da' somewhere around second. Children are already very aware of who their caregivers are before they can articulate that, so as soon as they can articulate something, even something as simple as 'ma' this gets attributed as a name. So it's less that these words are a strong cross-linguistic tendency and more that parents are anxious to hear meaning in a child's early babbling-like word production! 

What you're referring to is the fact that we can interpret speech acts that don't look like questions as questions because of other features. So even though the phrase you gave doesn't look like a question (e.g. word order inversion or inclusion of wh- pronouns for English) people can still interpret it as a question though other means. The most common reason these are interpreted as questions (in English at least) is because they occur with high rising intonation, which makes them sound like questions. Another reason may be that the person asking the 'question' gestures at the other person, indicating they would like them to contribute the relevant information. Linguists and philosophers like to talk about 'speech acts' when discussing how people communicate. Sometimes a speech act will be doing something different in conversation to what the grammar looks like. For example "aren't you cold?" is a question grammatically, but in interaction it's a suggestion (that the other person put on more clothing). Therefore, even though some things don't look like questions on the surface, their speech act function may actually be to elicit information like a question would. For more on speech acts here is a nice summary: $URL$ The two most often cited papers in this area are Austin (1962) and Searle (1969), and it's also closely linked to Grice's (1989) theories about Implicature. Austin, J. L. (1962) How to Do Things with Words, Cambridge, Mass.: Harvard University Press. (Develops the distinction between performative and constative utterances into the first systematic account of speech acts.) Grice, H. P. (1989) Studies in the Way of Words, Cambridge, Mass.: Harvard University Press. (The essays on meaning and conversational implicature provide a framework for distinguishing speaker meaning from linguistic meaning and for explaining their relationship.) Searle, J. (1969) Speech Acts: An Essay in the Philosophy of Language, Cambridge, Eng.: Cambridge University Press. (Presents a theory of speech acts relying on the notion of constitutive rules.) 

This is something that bugged me before I studied linguists, and it still does - why is the word "orange" so often used for both the colour and the fruit cross-linguistically? Every language I've learned has these items as the same word, or at least very similar origins. English (orange), Polish (pomarańczowy), Italian (arancione/arancia) and Nepali (suntala). Granted, these are all Indo-European languages but they do cover quite a spread, and my sister tells me that Mandarin has the same feature with chéng referring to both the fruit and the colour. I'm assuming that languages have borrowed the work for the colour on the basis of the fruit, and not the other way around but I may be wrong. I know that oranges are a relatively recently introduced fruit to many places, but is this phenomenon as cross-linguistically common as it appears from my limited experience. And if so, why? 

I use ELAN as my annotation tool of choice - but this is appropriate for Audiovisual transcription (and, to a lesser extent, audio or video alone). The best thing about this is that it's time aligned, and allows you to "pull out" the written transcript for analysis in other programs. It sounds like you're transcribing and encoding text that is already written, in which case CLAN might be more appropriate for you. Although it was created for the massive CHILDES project, I know people use it for other written transcripts as it allows for good encoding and some analysis within the program. I haven't used it but other people might be able to tell you more about it. 

You also add a lot more languages with shared cognates to your list when you also consider that the Proto-Tibeto Burman negation is *ma- and the Proto-Sino-Tibetan root was probably also *ma- (James A. Matisoff (2003) Handbook of Proto-Tibeto-Burman. System and philosophy of Sino-Tibeto-Burman Reconstruction. Berkeley, Los Angeles, London: University of California Press.). There's no explanation for why the PST form should be a nasal and well as the PIE but it accounts for the possible nasal negative in the 500 ST languages. 

Your best bet is going to be to find typological works that give a general survey of the possibilities across known human languages, and then choose the less frequently found features (or those that aren't found at all, since this is a constructed language!). Thomas Payne's "Describing Morphosyntax" is a great beginners guide for those documenting language, but you could use it as a check list to make sure you've not forgotten to include anything in your language. It would also help you figure out what interesting features of language exist that we don't necessarily have in the languages you already know.