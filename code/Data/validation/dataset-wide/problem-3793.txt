The most comprehensive reference for this sort of thing seems to be Furstenberg, "Noncommuting random products", Trans. Amer. Math. Soc. 108 (1963), 377-428. I say this because I've seen it referenced in other places that consider similar questions; a quick glance through Furstenberg's paper suggests that some non-trivial study may be needed to answer your questions from his work. A more direct treatment of your question can be found in Marcelo Viana's recent book "Lectures on Lyapunov Exponents" (Cambridge University Press). I'm not sure if the entire book is available yet but at the moment the first chapter is available on Viana's website. That chapter describes the case when $d=2$ and the matrices are chosen i.i.d., and quotes Furstenberg's paper as implying that the top Lyapunov exponent is positive as long as the monoid generated by $S$ satisfies a certain "pinching and twisting" condition; the proof, and the general case, seem to come later on in the book, in Chapters 6 and 7, which are not available online. 

There are two pretty simple proofs. Both rely on studying the action $T_* \colon \mathcal{M} \to \mathcal{M}$, where $\mathcal{M}$ is the space of Borel probability measures on $X$ and the action is given by $(T_* \mu)(E) := \mu(T^{-1}(E))$. A measure $\mu$ is $T$-invariant if and only if $T_* \mu = \mu$. One proof is the one given by Michael Coffey in his answer: start with any measure $\mu$, not necessarily invariant, such as the $\delta$-measure sitting at an arbitrary point, and then consider the sequence of measures $\mu_n = \frac 1n \sum_{k=0}^{n-1} T^k_* \mu$. Because $\mathcal{M}$ is weak* compact, some subsequence $\mu_{n_j}$ converges to a measure $\nu\in \mathcal{M}$, and it's not hard to show that $\nu$ is invariant. An alternate proof is to observe that $\mathcal{M}$ is a compact convex subset of the locally convex vector space $C(X)^* $, and that $T_* $ acts continuously on $\mathcal{M}$, whence by the Schauder-Tychonoff fixed point theorem it has a fixed point $\nu=T_* \nu$. 

The graph of any Lipschitz function $f\colon [a,b]\to\mathbb{R}$ has Hausdorff dimension $1$ (this follows since Hausdorff dimension is invariant under bi-Lipschitz mappings). Your example of $f(x) = \sin(1/x)$ also has a graph with Hausdorff dimension $1$, since the graph can be decomposed into a countable union of curves that are graphs of Lipschitz functions, even though the function itself is not everywhere Lipschitz, and then you use the fact that Hausdorff dimension is stable under countable unions: $\dim_H \bigcup_n Z_n = \sup_n \dim_H Z_n$. I'm not sure exactly what other sorts of "elementary" functions you're interested in. Certainly if $f$ if piecewise $C^1$ with only countably many points of non-differentiability, then its graph has Hausdorff dimension $1$, by the argument above. 

Now one can ask: within the space of smooth maps, how large is the set of maps for which the above conditions hold? This at least gives a more precise formulation of the question. Here's what I know. 

The language of the proof given in the book you refer to is a little different from the language I'm accustomed to, but I'll give what I believe is the exact same argument using a slightly different language, and hopefully do it in such a manner that the issue you point out doesn't arise. (Since I'm not quite sure how to explain it away using a language that's less familiar to me.) Let $X = \{0,1\}^\mathbb{Z}$ with $\sigma\colon X\to X$ the shift map, and let $\mu$ be any $\sigma$-invariant probability measure on $X$. Given $n\in \mathbb{N}$, let $\nu_n$ be the Bernoulli measure for $\sigma^n$ that best approximates $\mu$, and let $\mu_n$ be the invariant measure generated by $\nu_n$. More precisely, $\nu_n$ is defined as follows. Let $Y = \{0,1,\dots,2^n-1\}^\mathbb{Z}$, with $\tau\colon Y\to Y$ the shift map, and define a homeomorphism $\pi\colon Y \to X$ by identifying symbols in the alphabet of $Y$ with $n$-words in $X$: if $\phi\colon \{0,1,\dots,2^n-1\}\to \{0,1\}^n$ is a bijection, then we put $\pi(y) = \dots \phi(y_{-1}).\phi(y_0)\phi(y_1)\dots$, where juxtaposition denotes concatenation. Note that $\pi$ conjugates $\tau$ to $\sigma^n$ via $\pi\circ \tau = \sigma^n\circ \pi$. Define a measure $\mu^\*$ on $Y$ by $\mu^\*(E) = \mu(\pi E)$. Now define a $\tau$-invariant measure $\nu$ on $Y$ by putting $\nu([y_1\dots y_k]) = \prod_{j=1}^k \mu^\*([y_j])$. This is the Bernoulli measure that best approximates $\mu^\*$. Define $\nu_n$ on $X$ by $\nu_n(E) = \nu(\pi^{-1}E)$. Then $\nu_n$ is a Bernoulli measure for $\sigma^n$ with the property that $\nu_n([x_1\dots x_n]) = \mu([x_1\dots x_n])$ for every $n$-cylinder, but $\nu_n$ is not $\sigma$-invariant. To rectify this, let $\mu_n = \frac 1n \sum_{k=0}^{n-1} \sigma_*^k \nu_n$. Then $\mu_n$ is $\sigma$-invariant, and moreover, since for every $n$-cylinder $C$ the $\sigma$-invariance of $\mu$ gives $(\sigma_*^k \nu_n)(C) = (\sigma_*^k \mu)(C) = \mu(C)$, we have $\mu_n(C) = \mu(C)$. I believe that this last set of equalities (the fact that $\nu_n$, $\mu_n$, and $\mu$ agree on $n$-cylinders) is the statement you wanted explained. It seems to me that agreement on $C_{\Lambda_n}$ (in the language of the book) corresponds to agreement on $n$-cylinders (in the language here). In any case, the measure $\mu_n$ is ergodic and $\sigma$-invariant, and approaches $\mu$ as $n\to\infty$, which shows that the space of $\sigma$-invariant measures is the Poulsen simplex. 

Even for Bernoulli shifts this property is not true, as the following example shows. Let $(X,\mu)$ be the $(\frac 12,\frac 12)$ Bernoulli shift on two symbols, 0 and 1. That is, $X = \{0,1\}^\mathbb{N}$ is the set of all one-sided infinite sequences of 0s and 1s, and $\mu$ gives weight $2^{-n}$ to every $n$-cylinder. Let $A=[1]$ be the set of sequences beginning with the symbol 1. Interpreting $x\in X$ as a series of coin flips, with 0 as heads and 1 as tails, $A$ corresponds to the event that the first flip is tails. Let $B$ be the set of sequences $x\in X$ with the property that for every $k=1,2,3,\dots$, there is some index $i\in [2^{k-1}, 2^k) \cap \mathbb{N}$ such that $x_i = 1$. Then $B$ corresponds to the event that the first flip is tails, then (at least) one of the next two flips is tails, then (at least) one of the next four is tails, and so on. Note that $[0] \cap B = \emptyset$ and so $\mu(B) \leq \frac 12$. On the other hand, $X \setminus B \subset [0] \cup \sigma^{-1}[00] \cup \sigma^{-3}[0000] \cup \cdots$, and so $\mu(X\setminus B) \leq \sum_{k=0}^\infty 2^{-2^k} < 1$. Thus $0 < \mu(B) < 1$. Now consider $B \cap \sigma^{-n}(A)$. This is the event that $B$ holds (first flip tails, one of next two tails, etc.), and also that the $n$th flip is tails. Let $k'$ be the unique integer with $n\in [2^{k'},2^{k'+1})$. Considering conditional probabilities, we have $$ \frac{\mu(B\cap \sigma^{-n}(A))}{\mu(A)} = \mathbb{P}(B \mid \sigma^{-n}(A)) = \prod_{k\neq k'} (1-2^{-2^k}) > \prod_{k} (1-2^{-2^k}) = \mathbb{P}(B) = \mu(B). $$ In particular, $$ \mu(B\cap \sigma^{-n}(A)) > \mu(A) \mu(B), $$ and this holds for every $n$. There may be simpler examples. I don't know how to generalise this to arbitrary measure-preserving transformations, but my expectation would be that for every mpt there are measurable sets $A,B$ such that you do not get equality in the mixing condition for any finite $n$. 

Start with a space $X$ and a map $f\colon X\to X$. Coarse-grain your space to a certain scale, so that orbit segments that are very close together are not distinguishable. Count how many mutually distinguishable orbit segments of length $n$ it takes to be "significant"; call this number $a_n$. Find the growth rate $\lim_{n\to\infty} \frac 1n \log a_n$; this is the entropy at the particular coarse scale you chose. Let the coarse scale become finer and finer and take a limit to get the entropy. 

Just as the $\beta$-shift arises as the coding space for the transformation $x\mapsto \beta x$ (mod 1), so the shifts you describe arise as coding spaces for $x\mapsto \alpha + \beta x$ (mod 1). The characteristic sequences $a,b$ correspond to the codings of 0 and 1, respectively. In particular, you can describe the subshift in terms of a graph -- this was done for arbitrary piecewise monotonic interval maps by Hofbauer, and the key references are: F. Hofbauer, "On intrinsic ergodicity of piecewise monotonic transformations with positive entropy", Israel J. Math. 34 (1979), no. 3, 213-237, MR 0570882, and part II (same title and journal), 38 (1981), no. 1-2, 107-115. There are also a couple papers by Hofbauer and Keller from 1982 that deal with these classes of transformations. Because the transformations they deal with are much more general than just $x\mapsto \alpha + \beta x$, it may take some work to extract the exact situation you want from what is shown there. I'll give a summary at the bottom of my understanding of the construction (without proofs). Another paper that may be relevant is B. Faller and C.-E. Pfister, "A point is normal for almost all maps $\beta x + \alpha$ mod 1 or generalized $\beta$-transformations", ETDS 29 (2009), no. 5, 1529-1547, MR2545016. I don't have the actual paper there in front of me at the moment, so I don't remember whether or not they go into details about the graph that codes the shift. Here's a quick summary of the construction that can be extracted from Hofbauer's work. Given a $\beta$-shift $\Sigma_\beta$, let $z$ be the $\beta$-expansion of $1$, so that the $\beta$-shift is all sequences for which every tail is lexicographically dominated by $z$. You build the graph for $\Sigma_\beta$ by putting a vertex at each $0,1,2,3,\dots$, labeling the edge from $n$ to $n+1$ with the symbol $z_n$, and labeling edges from $n$ to $0$ with the symbols $0,1,\dots,z_n -1$ (if $z_n>0$). Now given an infinite sequence $x$, the way that you test whether $x\in \Sigma_\beta$ is to see whether $x$ codes a path starting at the origin. Let $k(n)$ denote the vertex which this path has reached after following the labels $x_0,x_1,\dots, x_n$. This can be interpreted as follows: $x_{n-k}\cdots x_n$ matches the first $k$ symbols of the characteristic sequence $z$, and so the remainder of $x$ needs to be tested starting at the vertex $k$, not the vertex $0$. Now for $x\mapsto \alpha + \beta x$ mod 1, you can do the following. Take the vertex set $\mathbb{N}^2$ (instead of $\mathbb{N}$). As you follow a sequence $x$ to see whether it belongs to the shift space, we interpret "$x_1\cdots x_n$ ends at $(i,j)$" to mean that the last $i$ symbols of $x$ are the first $i$ symbols of $a$, and the last $j$ symbols of $x$ are the first $j$ symbols of $b$. Then you need to compare $x_{n+1}$ to $a_{i+1}$ and $b_{j+1}$. One of the following things happens. 

This doesn't directly answer your question, I fear, but it's at least tangentially related. Suppose we keep slightly more information than the combinatorics of $G_S$, and label each node as well with the area of the corresponding cell on the sphere. Let $A$ be the sum of the areas corresponding to nodes originally labeled "3" (where the projection is a triangle), and $T$ be the sum of the areas of all nodes. Then it's shown in "Angles as Probabilities" by David V. Feldman and Daniel A. Klain, American Mathematical Monthly, October 2009, that $2\pi A/T$ is the sum of the solid inner angles of the vertices of the original tetrahedron -- that is, you can interpret that angle sum as the probability that an orthogonal projection to a random plane is a triangle. 

Fix a set $J\subset \mathbb{N}$ and a number $\mu>0$ (this will eventually be large). Let $P(X=k) = C \gamma^k$ if $k\in J$ and $P(X=k)=0$ otherwise, where $C>0$ and $\gamma<1$ are chosen so that probabilities sum to $1$ and $E(X) = \mu$. 

For me the standard text is Peter Walters, "An Introduction to Ergodic Theory", Springer Graduate Texts in Mathematics. 

Yes. If $X$ is minimal (every orbit is dense) then the only subshift $Y\subset X$ is $X$ itself. The Jewett-Krieger theorem allows the construction of minimal subshifts with positive entropy, which therefore have the property you desire (albeit somewhat vacuously). Googling "minimal subshifts with positive entropy" brings up this paper by Henk Bruin, which includes such a construction and also gives two references to earlier constructions: 

A partial answer to Q1 -- apologies if this is obvious, but I don't see it written here yet, and this is the thing that made me sit up and take notice of the fact that there's some sort of connection between the boundary operator $\partial$ and differentiation. If $X$ and $Y$ are two topological spaces and $A \subset X$, $B\subset Y$ are closed, then they satisfy a product rule of sorts: $$ \partial(A\times B) = ((\partial A)\times B) \cup (A \times (\partial B)). $$ This also works without the assumption that $A$ and $B$ are closed if you're willing to weaken the analogy a bit by replacing the right-hand side with $\partial(A\times B) = ((\partial A)\times \overline{B}) \cup (\overline{A} \times (\partial B))$. 

To answer your questions about median and mode, one can take Alexandre's answer a little further and compute the exact distribution function for the overtake-times. Note that the overtake-time doesn't depend on $v_1,v_2$ directly, but only on their difference. Call the difference $v$. Now $v$ is the difference of two uniformly distributed random variables on $[0,1]$, so it is supported on $[-1,1]$ with probability density function $1-|v|$. Moreover, since $\theta$ is uniformly distributed we can without loss of generality identify the cases $(v,\theta)$ and $(-v,1-\theta)$ and reduce everything to the following set-up: 

Although it appears you've already settled matters with the information in Jon's answer, I'll offer a quick summary and elaboration. Let $(X,\mathcal{B},\mu)$ be a Lebesgue space (set + $\sigma$-algebra + probability measure) and $P$ the partition into orbits $\mathcal{O}(x) = \{T^n x \mid n\in \mathbb{Z}\}$ for an invertible measure-preserving transformation $T$. For (3), it's exactly as you say: $\mathcal{B}$ contains each orbit $\mathcal{O}(x)$, and since a set $A$ is $T$-invariant if and only if it is a union of complete $T$-orbits, we get that the $\sigma$-algebra generated by $P$ is precisely the collection of $T$-invariant sets. The completed $\sigma$-algebra generated by $P$ is the collection of sets that are $T$-invariant mod $0$. Consequently the answer to (1) is yes unless a single orbit carries full measure: ergodicity implies that every element of the $\sigma$-algebra generated by $P$ has measure $0$ or $1$, and consequently this $\sigma$-algebra is equivalent mod $0$ to the trivial $\sigma$-algebra. Thus for an ergodic transformation, $P$ is measurable if and only if a single partition element has full measure, which happens exactly when $\mu$ is supported on a single periodic orbit. Finally, for (2), you observe correctly that non-measurability of $P$ follows as soon as $\mu$ has an ergodic component that is not a periodic orbit. For a concrete example, one may consider the map $T\colon [0,1]\to[0,1]$ that takes $x$ to $2x \pmod 1$, and the measure $\mu = \frac 12(\delta_0 + \lambda)$, where $\delta_0$ is the point mass on the fixed point at $0$, and $\lambda$ is Lebesgue measure. In this case $\mu$ is non-ergodic but $P$ is non-measurable. Or, if you prefer a completely non-atomic example, you can let $\nu_p$ denote the $T$-invariant measure on $[0,1]$ that comes from the $(p,1-p)$-Bernoulli measure on the full two-shift (where $p\in (0,1)$) and let $\mu$ be any convex combination of $\nu_p$ and $\nu_q$ for $p\neq q$. 

The key words here are "large deviations"; large deviations theory addresses exactly this question. The answer depends quite a bit on the specific measure and system in question, but roughly speaking one may say the following: if the system displays a sufficient amount of hyperbolic behaviour (for example, an Axiom A system, or a system with the specification property, which is a sort of uniform topological mixing) and if the measure $\mu$ has some sort of Gibbs property relative to a potential function $\phi$, then the measure of the set you describe decays exponentially in $N$, and the rate of exponential decay depends in a precise manner on the topological pressure function. Let me state a concrete series of theorems to make the above more precise. Let $(X,T)$ be a transitive Axiom A system, and let $\phi\colon X\to \mathbb{R}$ be HÃ¶lder continuous. Then by a result of Bowen ("Some systems with unique equilibrium states", 1974/5, or if you prefer, "Equilibrium states and the ergodic theory of Axiom A diffeomorphisms"), there is a unique invariant measure $\mu$ that maximises the quantity $h_\mu(T) + \int\phi\,d\mu$. (This maximum value is the topological pressure $P(\phi)$.) Moreover, $\mu$ has the following Gibbs property: if $B(x,n,\delta)$ denotes the set of points $y$ such that $d(f^kx,f^ky)\leq \delta$ for all $0\leq k\leq n$, then there is a constant $K(\delta)$ such that $$ (*) \qquad \frac 1{K(\delta)} \leq \frac{\mu(B(x,n,\delta))}{e^{-nP(\phi) + S_n\phi(x)}} \leq K(\delta) $$ for every $(x,n)\in X\times \mathbb{N}$. Now a 1990 result of Lai-Sang Young on large deviations shows that for a system $(X,T)$ as above and a measure $\mu$ satisfying $(*)$, one has $$ \lim_{N\to\infty} \frac 1N \log \mu\{x\mid |\frac 1N S_N f(x) - \int f\,d\mu| \geq \epsilon\} = \sup \{ h_\nu(T) + \int \phi \,d\nu - P(\phi) \mid \nu\in \mathcal{M}_T(X), \left|\int f\,d\nu - \int f\,d\mu\right| \geq \epsilon\} < 0. $$ This behaviour is typical in the uniformly hyperbolic setting. In the non-uniformly hyperbolic setting, there are also examples where the rate of decay is slower than exponential. For example, this occurs in the case of the absolutely continuous invariant measure for the Manneville-Pomeau map.