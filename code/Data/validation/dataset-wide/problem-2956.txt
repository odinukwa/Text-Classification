You used the happiness version of utility in your question. There are other interpretations of utility which involve the greater good, regardless of happiness - remember that those two are not necessarily the same. To answer your question you would have to know is the public happy about the increased surveillance or not? If they are, then the increased surveillance is moral, if not then it isn't. If you had chosen the interpretation of utility which involves the greater good, then the answer would change. One could then argue that increased surveillance is moral regardless of whether the public is happy about it or not, since the public doesn't always know what is good for them. 

As you can see, John Rawls seems to agree with you that inequality is acceptable, as long as it works to the advantage of everybody, i.e. everyone ends better off in the arrangement (everyone gets more utility points than they would have in an equal distributions, but some more than others). There are also arguments for economic equality. Settings aside purely moral arguments for economic equality, one can provide the following pragmatic reasons for economic equality, which fall under the heading off everyone stands to benefit more from situations with greater equality, even the very rich (sorry for lack of sources, I will have to dig them up later): 

Do Turing undecidability and computational complexity considerations (NP-hardness, etc...) have consequences for epistemology? If X function or propostion is undecidable or requires an intractable amount of resources to be calculated, is it still considered knowable? 

I believe the last statement is at the heart of the question. Most people I know care less about the history of how ideas formed and the major contributors of the idea (Kant, Descartes, etc in this case). So I will cut to the chase and not talk about history of philosophy: 

In practice Laws come from traditions, politic, personal gain, maintenance of power, societal pressures, etc.. and rarely from well formed Ethical arguments of Philosophy to the great upset of many. This is for a number of reasons namely Philosophers have done a poor job making a compelling chain of reasoning going from Metaphysics -> Epistemology & Logic -> Axiology -> Ethics that has been widely accepted. There are a number of reasons for this, namely 

Lastly as you may be inferring, "Is it wrong to state something knowing it will hurt someones feelings?" Well for this I would say yes and no. When done in spite with intention to cause a harm without being sensitive to others, you can argue yes that is being a jerk. I would find it difficult to pin down a moral ought though, and it is not an effective way to get your point across. It can be useful to shock your audience into recognizing if there is a obvious pattern of lies you are trying to overcome. Stefan Molyneux, a modern philosopher, will occasionally take this position to get a point across about untrue things he believes is being frequently said by people even though he normally speaks with more empathy to strangers then people talk to their own children. Under that circumstance, I would consider that acceptable as opposed to strictly antagonizing people for the hell of it to bait them into committing violence which would be unethical. 

John Stuart Mill provides a group of methods which characterize an empirical approach to scientific discovery which he describes in his book "A System of Logic", see the SEP article on him, and references therein. Mill's approach is empiricist, meaning that for him we should start with the raw data, and then use various rules of inference, what he calls "“Methods of Experimental Inference” (System of Logic, Bk. 2, ch. 9), to discover laws and patterns. See also Mills methods. An opposing view comes from William Whewell, who saw that science has an a priori nature: One starts with a fundamental idea, and then reconciles it experimental data. From his work "The History of Scientific Ideas": 

So it is possible to "translate" continental ideas into analytic style prose, and presumably it has been done before many times (per the continuing demand). Have there been any such analytic expositions of Heidegger, and Derrida? I find Derrida hard to understand, and Heidegger outright impossible, and none of the lectures or sources I've looked at make any sense at all w/r to the latter. 

As a starting point, a system of AI morality would have to be deontological, because for it to be something you can implement as a program, it would have to be a clear cut set of rules, as opposed to a utility measure. Utilitarian ethics, even when applied to human situations, run into the difficulty of how to practically measure the utility of each situation. The problem of calculating such utilities would be impossible to implement in an AI system: It would be difficult to for an AI to have knowledge beforehand of all the variables that should go into such a calculation, and even if it did, such utility maximization/optimization problems are computationally very costly. This would make them impractical in real world situations. Using approximations or meta-heuristics to calculate probable values would be dangerous. On the other hand, straightforward deontological ethical rules would be relatively simple to implement, since the rules are categorical and would not be context dependent the way utilitarian rules are. Most importantly, in a utilitarian system, utilities would have to be assigned numerical values. To see why this is dangerous, consider the following situation: A utilitarian AI is faced with the scenario where it can increase the happiness of 1000 000 people each by 1%, but only at the cost of imprisoning an innocent orphan child for life, therefore reducing the happiness of that child by 100%. An AI using purely quantitative measures of utility is very likely to fall into such a scenario. The only way to avoid such a scenario is introduce some hard non-quantitative rules: "You can increase the happiness of everyone, but only as long as nobody is killed, no innocent is harmed, nobody is enslaved, etc..." - so deontological ethics are unavoidable. An example of AI ethics, taken from Sci-Fi, not philosophy are Asimov's 3 laws of robotics. Although Asimov doesn't mention Kant or the word deontological anywhere in his works, it is clear from their formulation that they are Kantian in spirit, in the sense that they are universal and context independent. 

The answer is Yes. To list a few: Evidentialism or some form of it such as Pragmatic Evidentialism is my go to. Evidentialism in a nut shell requires evidence for all claims. Pragmatic Evidentialism deals with the infinite regress by requiring evidence to a reasonable level based on the size of the claim, etc.. I belive this is the newest of the ones I am listing here. $URL$ Objectivism comes from Ayn Rand who has a different take on reality based Epistemology. $URL$ Materialism is notion that all that exists is matter and its movements and modifications. This one is the grand father of objectivism and evidentialism. 

This is not a commentary or valuation on which is better, but the observed "preference" for the two movements. Please correct me if you feel that I am being unfair or accidentally oversaw something. Classic Liberalism A little history: Mentioned by Greek Philosophers, although it is much older, the Classical Trivium was a secular method of learning from ancient Greece. It consisted of 7 principles, the first 3 called the Trivium, the final 4 the Quadrivium: 

Lies are a violation of most ethical systems. Usually statistics in books and the media are rarely fabricated (b), but very frequently they are out of context (a). This becomes very deadly when used as a premise to justify conclusions which would be an egregious premeditated lie with a false justification. Many authors and media commentators state a ton of facts to build a case and then jump to a conclusion without making any necessary links between the truck load of raw data that is taken out of context and the idea they are trying to promote. Plato talks about the Noble Lie. In essence his contention is that during a debate or similar circumstance you could perform a calculated lie in which your opponent in trying to dispute it would unravel the false basis of their position. I personally believe this was along the lines of agreeing with an opposing irrational view, and encourage taking the idea to the extreme. Manipulation The second ethical violation could be to purposely mislead people via Moving the Conversation to a red herring (reference). While not a direct lie, it can be seen as unethical to redirect the conversation purposely off track to avoid admission of the truth. Politicians frequently do this in debates, and a simple example could be as simple as citing a number of outlier events consuming the majority of the talk time, and claiming victory when not all of them are rebutted. This falls primary into the realm of intellectual dishonesty although many ethical systems may see this as unethical. Noble Lies An example of a Noble Lie could be(1): 

The difference between science and other fields of inquiry lays in science's predictive power. Many disciplines: Science, philosophy, history, sociology, etc...can explain things after they occur. Sociologists can explain to us why the hippies arose in the 1960s, and historians can explain to us why the Industrial Revolution happened in 19th century Europe. But science is the only field which allows to make accurate predictions about the future, not just the past. The text book case of a scientific theory with predictive power is Einstein's theory of relativity: Einstein predicted the existence of gravitational waves in 1916, and their existence was confirmed in 2016. This idea was formalized by philosopher of science Karl Popper in the idea of falsifiability. A theory or statement is scientific if we can perform an experiment which proves it wrong, i.e. it can be falsified. You need to be careful with the language used here: We don't want to prove it wrong, we want to show that we can prove it wrong. The reason is that some statements can't be proven wrong. Consider the following statement: "John fell sick because God hates him", you might try to answer by saying that "No John fell sick because he caught a dangerous virus", and your interlocutor will reply "That is true, but it was God who made him catch the virus". There is no way we can design an experiment that proves "John fell sick because God hates him" wrong, the evidence can always be interpreted to support that statement, and hence the statement isn't falsifiable. Compare that to the statement "John fell sick because he caught the flu virus": We can perform an experiment to confirm that John did indeed catch the flu virus, alternatively we could also perform an experiment and show that he didn't catch any virus, but that he got sick because he ingested a poisonous chemical instead. Hence the statement "John fell sick because he caught the flu virus" is falsifiable. Falsifiability also provides a measure of how successful a scientific theory is: A theory is good as long it hasn't been falsified. Once it has been falsified, then we know that new theory is needed, and that the domain of application of the old theory is limited. This is what happened with Newtonian mechanics: It is a good theory, but it is limited to a restricted domain, and these limits were proven by falsification. Relativity is a more successful theory because it covers a wider domain, and this was arrived by falsifying Newtonian mechanics. 

I would just grant Nietzsche charity here since the excerpt is a literary writing. If it was the case he was making a formal argument word choice based on the historical context of when and where it was written and defined terms of the author would come into play. This may lead to people naturally object since most writings from philosophers are not formalized arguments. While I agree most did not make abounding volumes of formal arguments it is not to say the literary works are without merit. Instead I would suggest non-formal arguments as much weaker when it comes to their philosophical value, yet much stronger when it comes to pop-culture persuasion of the general public. Both approaches have merit, though it is my expectation that modern philosophers do double duty through the exercise of writing both formal and informal arguments for the position for the two audiences to make the strongest case possible. 

I would say that we are much closer to having a rational chain of reasoning for laws based in Ethics today, but we are not there yet. 

This leads to Solipsism aka. how do you not know we are brains in a jar. From a pragmatic perspective this epistemology is unproductive since it doesn't get us anywhere. Some philosophers still regress to this state today. Although taking the questioning back this far is 'ok' as a thought experiment, living with this notion as being correct or using it as a defense against a claim or argument is intellectually dishonest since if they believe they are a brain in a jar they should not be participating in the discussion at all. Solipsism can be debunked as begging the question or being unfalsifible depending on the specific variation and the opponents epistemology.