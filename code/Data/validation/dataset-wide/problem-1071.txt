In the above code, filegroup [DATA_1995] would retain the values beyond the last partition boundary. So, if I elect to add new filegroups and split the function for additional boundaries in this fashion... 

A data warehouse ETL process is querying a read-only secondary in an availability group. The ETL process queries a single table incrementally using datetime range criteria of a minute and read committed isolation level. At the time of execution, 5 records that meet the criteria are committed on the primary, but another 3, with slightly earlier timestamps than the first 5 (but within the criteria range) are still in open transactions. Does the nature of availability groups require all transactions to be applied in LSN order (delaying the visibility of all 8 records until all are committed) or do the delayed 3 records get later LSNs and are applied as soon as they are committed, potentially after the ETL process has adjusted its date criteria? 

I'm restoring to an alternate server in a DR drill and have restored master but can't restart the instance, even with /f and /m switches. The log is indicating tempdb can't be created, probably looking for the paths from the source instance. How can I determine which path it's trying to create tempdb's DB files in? I was able to restore the master backup under an alternate name on a different instance so I can browse the system tables. Is there a spot where I can look for them? I have to go with the assumption that access to the source server is lost so I can only rely on the backups to determine the correct configuration. 

Can you confirm with a Profiler trace which credentials are attempting to execute sp_start_job? I'm curious if it's the credentials of the client using the browser or the underlying application pool. If the account in question has sysadmin, it should already have the permissions to execute jobs. 

I have a table with a PK based on a identity and will have a clustered index on a column. I've created a partition function based on calendar quarter and was planning on two partition schemes (one each for clustered and non-clustered indexes) to able to spread out I/O. However, if I plan to implement a sliding window to age out older data, do I need to keep all indexes in the same partition scheme or it doesn't matter as long as the partition function is the same and using the same key column? 

I think this is a pitfall. I recall SQL 2005 and older versions requires active nodes to be updated. SQL 2008 and later versions allow passive node updates like the walkthrough you described. A posting from Linchi Shea explains it well. 

What I learned on my own. Basically from each job I was hired for, I learned how each shop operated, listened to business requirements and learned on my own how to complete the assignments. A lot of reading the manual (now Googling) and trial-and-error is involved but it's ultimately how we all learn. What I learned from certifications. One time I picked a textbook for my favorite programming language and discovered that I was only using a fraction of the techniques described on the job. I wanted to learn as many aspects as I could. In the back of the book they had mentioned the certification program for my language (Microsoft Certified Professional in this case). It's a structured way to learn all the major features of the platform you're focusing on for your employment. There's a lot of studying and practice involved (My MCSD took four tests and my MCDBA and MCITP:DBA were comparable). You'll learn about features you might not end up using on a particular job site, but being aware of their existence helps shape you decisions on how to tackle a business requirement. What I learned from the community. This by far, is the most valuable. You learn firsthand that you're not alone in your profession. You also learn what your peers have learned on the job and through their own research, and it's great to share what you've learned. You'll find your mentors here as well. There's a large of community of masters, MVPs and fellow DBAs who share their knowledge in-person, in print and online. Search for them in Google, attend a local user group, have your employee fund a trip to your favorite products' annual convention. I've seen at SQL PASS twice and the knowledge shared there is amazing. 

The main errors I saw were: and - no need to use - no need for I included the line as this caused an error on my side otherwise. I believe this is related to replication, so depending on your set up you may not need it. 

(-sorry if I have misunderstood) (-assuming you are using binlog file and pos). The key things to make sure of are that your servers have unique (if you have replication running already then this should be ok). You also probably want to set: 

Has anyone found a way yet of circumventing MySQL 5.7s insistence that it's Master must have a . I currently have multiple instances of MySQL 5.5 over various sites, and want to look at upgrading to MySQL 5.7. To do this I was planning to set up a test-site using some MySQL 5.7 databases running as a set of master > slaves from my main site. But this failed at the first hurdle, as MySQL 5.7 insists that the Master must have a !! Depsite the official documentation telling us we should upgrade our slave databases before we upgrade the master. 

I'm trying to put together a function to convert a size from one type to another (e.g. bytes >> gigabytes). An extract is below 

1 & 2) You should look at and variables. This prevents the two masters from creating the same Primary Key (assuming you are using Values). 3) Not Natively, for this you would need to look at moving to one of the Galera Cluster variants. As it stands I wouldn't recommend an Active Active environment because you will almost certainly run into problems when the network drops out / replication stops on one or both sides. 

The config items you added in should have little to no impact on the situation. n.b. you will probably also want , (details) but leave that out until after you've imported the data, of you'll have 100's of GB's of binary logs created. I think the real question is whether your OS is happy with a single file that size, bearing in mind that it wont get smaller, but may get larger. If it's going to be an issue you may want to look at (details) which 'basically' splits the data between and a file for each table. (This involves reloading the dumpfile to take affect) (this is on by default from MySQL 5.6.6) There are pros and cons for both options. 

values so that the two Databases don't generate overlapping primary keys. $URL$ After that on your Slave DB (B), simply run . Use those details to issue the statement on DB A. What you should find is that anything executed on A is then replicated to B and vice versa. However anything executed on A shouldn't be replicated back from B to A. And as such, the only queries written back to A will be those that are executed directly on B. Finally, you will want to set B to read_only to prevent anyone accidentally writing to it, until such time as you want them to. 

What I would do is set it up with sufficient partitions so that your top (MAXVALUE) partition never gets used. In this way when the time comes to add the next partition, you are going to re-partition the 'empty' MAXVALUE partition which should be a lot quicker. So you would start by adding a partition for which replaces the MAXVALUE partition. Then when you get close to 2300000 entries, you would add a new partition for . And because you would be splitting the empty MAXVALUE partition it will be relatively quick. 

Is it possible to monitor role and privilege grant/revoke using triggers? I' aware of doing that using Oracle audit tools however, it's interesting is it possible to do that using triggers. 

Suppose we have a server that has only 1 CPU with 1 core, so we need 1 Oracle database license for installing a database into it. Now, if we would need to add a second server, combine them into cluster and install database into it, then how many licenses do we need - 2 database licenses and 1 Clusterware licenses or 1 database license and 1 cluster license? I'm not sure, how Oracle treats joined into Oracle cluster servers - as one server or still as separate servers? Because we would need to buy expensive Oracle cluster software, then it would be logical for Oracle to treat joined servers as one. 

What is the difference between Oracle clusterware and Real Application Clusters? If we have 2 servers and want to join them into a cluster why there are two separate software products? 

You can create an index and define prefix length, so the index will store only first starting symbols from each of column value. It looks like this in MySQL: 

I found there are special "Oracle Text" indexes that improve performance for wildcard queries. Such index construction requires a little bit more work but still is a way how to create prefix indexes: $URL$ 

AFAIK there are three major structure types used for storing Oracle index data: B-tree, R-tree and Bitmap. All indexes use one of these structures. However, not sure about CONTEXT, CTXCAT and CTXRULE Oracle text indexes... 

We can create the database trigger on concrete schema event (ON SCOTT.SCHEMA) or on all schemas (ON SCHEMA). However, we can also use ON DATABASE when creating database trigger. What is the difference between them? Is it some legacy stuff? ON DATABASE should be used when using AFTER STARTUP or AFTER STARTUP because it's definitely related only to database but the same stuff that is done using ON SCHEMA might be done using ON DATABASE, so what's the difference? I can't find references in Oracle docs about that. 

Oracle has partitioning and clustering features. Partitioning enables to split table or indexes into multiple tablespaces and store on various servers. So it's done manually. Clustering enables several servers to make operate as one. This IMHO is handled transparently. However, it's possible to have several tables (in different server databases) and group them as one, and use it. From the perspective on table partitioning and table clustering, IMHO both ways implement shared everything because the data is split into the different locations. The theory about shared nothing architecture is that each database node is independent. But how this looks in practice? Both ways (partitioning and clustering) splits data into different sources and could be also described as horizontal partitioning. However, if we had for example, two different database servers we would need to synchronize the data between them... Anyway, any thoughts on that would be appreciated :) 

The trigger does not contain autonomous transaction procedure with commit inside that, so who is commiting the insert? This triggger works like a charm and inserts new record into log table after user logon. It smells like hidden Oracle functionality and I can't find any reference in Oracle docs about that. I'm using Oracle11g. 

We can't COMMIT/ROLLBACK in DML triggers because transaction is handled manually after DML statement. However, database triggers seems to be an exception. For example, suppose there's a database trigger: