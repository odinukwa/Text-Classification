I have an Nginx/Gunicorn/Django web server and PostgreSQL database server that I only want to access using SSL. I've purchased, installed, and configured a certificate on my web server from a certificate authority and so now my users can only access my website via HTTPS and it's working fine. Now I'd like to implement secure two-way communications between my web server and database server over SSL. Since the only machine talking to my database server will be my web server, will it be OK from a security standpoint to generate my own private key and certificate using the openssl command ("self-signing") or should I get a free ones from somewhere like letsencrypt.org? 

Is this the right approach to take to change my worker log permissions and recreate the pid directories before the celery workers are restarted? If this is the right approach, why isn't it working? If it's not, what's the right approach? If I were using an init.d celeryd daemon script instead of Supervisor, there's a CELERY_CREATE_DIRS setting that will automatically create pid and log directories that are owned by the user/group. Is there a way to replicate this setting when using supervisord? 

I believe (but I can't really prove it) that this is an issue with upstream routing in some providers. I manage a large number of machines using apf, many of which are at one particular provider, and these machines have no problems. Other similarly configured machines at other providers have done in the past, and we never managed to find a cause on the servers apart from restarting iptables fixing the issue. It was always HTTPS on port 443 and never HTTP, so I think it must be either in an upstream firewall or router and is affected by a firewall being reloaded, which would suggest something to do with arp or other mechanisms at that level. 

You have built httpd correctly but the default directory for the version built from source is and if you have done as root it will be installed there. The usual approach is to symlink to for consistency. Looking at the initial install, moving and creating a symlink to should work with your init file, but you could also check that that matches your installation. If you need to do this again you could also consider building an RPM, the apache source comes with a build file that will do it, and it can be run on a VM running CentOS 5.11. 

They show the correct IP address for web02. I also disabled the log limit directive and check /var/log/syslog and /var/log/messages on fs02 and don't see anything pertinent. However, I checked /var/log/messages on web02 and I see this message: 

I figured it out. The solution is to set "user = root" in the project's Supervisor configuration file. The documentation says, "If supervisord runs as root, this UNIX user account will be used as the account which runs the program." Thus, setting user this way is equivalent to my running the script manually using "sudo." 

When running a Django application on a Debian server, should you create some sort of application user (e.g. "myappuser") and run the gunicorn process as that user or can/should gunicorn be run as root? Would running it as root create a security risk? I've installed gunicorn using APT rather than install it in a virtual environment. Running it as an application user seems to make the configuration more difficult as you have to give that user permission to write to the log files, the PID file, etc. It seems easier to run it as root. 

You would need a HTTPS to handle HTTPS requests and redirect them to HTTP. However, this VirtualHost would still need valid certificates to work correctly as the redirect happens after the SSL negotiation, so it's better consider creating new certificates using LetsEncrypt as it doesn't only provide increased security but improves search ranking. 

No, you are in control of what is sent from your server. Gmail's limitations are part of its service to prevent abuse. However, what you may find is that receiving servers (particularly Gmail) may limit your inbound mail if you are abusing it in any way. 

This is actually a software issue, not or , and if you are running the same software in two processes then it wouldn't be impossible to cause collisions. A quick look at the documentation suggests that while there is collision detection for a single application, two separate processes in different userspaces wouldn't do this. The simplest fix would be to configure differently for each pool. 

I've solved the problem. Here's what's going on. /etc/apache2/apache2.conf includes a call to any config files that have symlinks in /etc/apache2/sites-enabled. Since there was a symlink in that directory pointing to /etc/apache2/sites-available/000-default.conf, that latter config file was being loaded and it was over-riding the blocks and directives in my vhosts.conf file. Once I deleted that symlink, my vhosts.conf settings were able to take effect. The lesson for me was that any file that has a symlink in sites-enabled will be enabled. 

I'm developing a mobile web application using Django. Currently I can start the Django development server like this: 

How can I access this site from my phone? This appears to be a pretty common Apache error message that can be caused by any number of things. I've read many articles about it but haven't been able to resolve the problem. What am I doing wrong? Since I can access the site via my computer browser but not from my phone, I'm thinking perhaps it's an OS X firewall issue. Is there some way I can configure my OS X (Mavericks) firewall so that when I start the Django development webserver, my computer will automatically allow incoming connections and I won't get the pop-up window I described above? I've gone into System Preferences > Security & Privacy > Firewall Options and selected "Allow incoming connections" from the three "python" connections that are shown but I'm still getting the popup window. 

proxy_pass is probably the better way to do this as you are presumably updating links and moving images to the new server. A redirect should also return a status response of some kind which could cause problems for search. 

You can't resolve a URL such as with DNS or hosts, just the left hand side separated by the forward slash. All you can really do is configure a virtual host on your staging server to point at your project folder and use hosts or a local DNS server to resolve the domain. 

The issue with not being able to connect is probably because the restart process isn't killing httpd properly so it never actually shuts down, which is why you get the error about port 80 being in use. I also suspect there might be something about Pid changing, as it will when httpd is started or restarted. The logs should give more information as to why it's failing. However, httpd is usually solid as a daemon and I wouldn't force monit to restart it, just alert unless you have a critical state. 

Is there some other step I'm not aware of? UPDATE Here are the firewall rules if I run the command "sudo iptables -L -n -v": 

When I enter my website's non-SSL URL "cms00.example.com" into my browser, it won't redirect to $URL$ If I enter the HTTP address, I can see the site and if I enter the HTTPS address, I can see the site. I just can't get the redirect from http to https to work. I've read numerous articles on how to do this and tried all the suggestions but my configuration still isn't working. I'm running Apache 2.4.10 on Debian 8, and this is my first time working with Apache. I've run these two commands and verifed that the rewrite and ssl modules have been loaded: 

Also to listen over ssl you would need to enable ssl and have certificates installed or you will get a protocol error. You would at least need: 

MQTT needs the stream protocol so you need to separate your HTTPS and stream configurations. Something like this should do it: 

It's a fine solution and, assuming that the front end server isn't too far away from the backend servers, doesn't affect performance significantly. You can terminate your SSL certificates in nginx but you could have also SSL certificates on the backend to encrypt the connection between end and backend depending on where your systems are hosted. The general rule is to terminate SSL as far up the chain as you can. 

You can't give an address priority but you can disable the entry in . Presumably your server handles mail for your domain using as well as with virtual maps. The convention is to allow the virtual mapping to handle addresses found in in this case. To remove an entry from comment it out and run 

I have a Django 1.6.2 application that uses Celery 3.1.7 for asynchronous tasks. I'm starting my Celery workers using Supervisor. So far everything is working well except when I reboot my Debian 7.8 server. When that happens, my Celery workers won't restart because when the server reboots, it changes ownership of the celery log files from my "celery" user to "root". Also, the system deletes my /run/celery directory where I write my pid files. If I make these changes by hand and restart Celery, all my workers start normally. Since these changes need to occur before starting the workers, I thought the solution would be to write a shell script which, due to its higher priority, gets executed from my supervisor.conf script before the celery worker commands (See below). However, this setup script won't run. My supervisor log just says,