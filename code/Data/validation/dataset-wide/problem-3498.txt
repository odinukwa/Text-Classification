If you are running a regression analysis I would say you should look first at p-values to check if the explanatory variables you added make sense. I mean if you have a hypothesis about a relationship among two variables and you find the explanatory one not significant (large p-value) I would check for possible mistakes or alternative explanations. It makes sense to have a look at $R^2$ if you are comparing two different specification, it does not really make sense looking at it alone. I have seen many papers, have a look at Nunn, Wantcheckon, (2011) as an example, which have been published on top journals (AER in this case) even with $R^2$ around 16%, not really an high value. 

The problem is the maximization of profit of a firm that produces a differentiated good $i$ using labor $N_i$ as unique input, under the demand function of the consumers (or final goods producers) and the production function. The first three steps are computed by substituting the two constraints and the market clearing condition for goods market $Y_t=C_t$ into the objective function in order to have a free maximization problem in one unknown, $P_{it}$. The FOC for $P_{it}$ is right and the same is true for the next step, where the left hand side is positive because he has divided for $-(1-\epsilon)$, i.e. $(\epsilon-1)$ that you see at the denominator of $\epsilon$. The highlighted part is correct too: this is the derivative of the function nested in the square brackets; he added $\frac{1}{P_t}$ because he kept $\frac{P_{it}}{P_t}$ all elevated at $-\epsilon-1$, this means that $P_t^{-1}$ and $P_t$ goes away. You could also have written \begin{gather} \epsilon\frac{\frac{P_{it}^{-\epsilon-1}}{P_t^{-\epsilon}}C_t}{A_t}=\epsilon\frac{\big(\frac{P_{it}}{P_t}\big)^{-\epsilon-1}C_t}{A_t}\frac{1}{P_t} \end{gather} After the "Continue...", he just sum the two expressions in square brackets because they are exponentials with the same base and in the second step he notice that \begin{gather} \bigg[\frac{\frac{P_{it}}{P_t}^{-\epsilon}C_t}{A_t}\bigg]^{\frac{1}{1-\alpha}}=N_t \end{gather} using again the demand for $Y_{it}$, $Y_t=C_t$ and the production function. The last step is a rearrangement of the previous one (simple algebra) and it is still the FOC for $P_{it}$. If you rearrange it as in Gali, you obtain the optimal pricing condition for the monopolistic firm in flexible price setting. 

Mere googling leads me to find a bunch of references about elasticity of marginal utility. Here Professor Acemoglu defines the elasticity of marginal utility as the inverse of the intertemporal elasticity of substitution (pagg. 17-18). Here you can find a question analogous to yours together with an answer explained in an easier way than Acemoglu's lecture. If you are interested in something more empirical, have a look here: it is a paper by David Evans about the empirical estimation of elasticity of marginal utility in OECD countries. Hope this is enough. If you have other questions, please ask 

I would suggest you Ray, D. Development Economics. It received an endorsement by no less a person than Amyrta Sen, Nobel Prize Winner 1996. 

I am trying to study the effects of a policy on educational attainment of individuals (years of schooling, primary/secondary school completion, literacy). Since the policy starts in a specific year I decided to use an RDD using birth year as running variable. The problem is that my sample is made of 5 different countries in which the policy has been implemented in 5 different years. Am I able to pool the effect of the policy across countries? Because if I build a unique running variable as being 0 for each cutoff year I get individuals born in e.g. 1994 having running variable both 0, -2, +3 depending on the country of origin. How can I deal with this issue? Should I run a RD for each country alone? 

In a New Keynesian model, under the assumption of sticky prices, we need to express the monetary policy through an equation in order to close the model made of New-Keynesian Phillips curve and dynamic IS curve. I've read that an easy choice is to use the so called Taylor rule, which express the interest rate as a function of inflation (and possibly a random component). But, I've read that it is a suboptimal choice because it is something exogenous, whereas if we endogenously compute the optimal monetary policy we can reach a better result. My question is why using a Taylor rule when we know it is not optimal to do that? 

I am working in a New Keynesian context so that the Phillips curve is usually specified as follows \begin{gather} \pi_t=\beta E_t\pi_{t+1}+\kappa x_t \end{gather} where $\beta$ is the discount factor, $\kappa$ is the slope of the curve depending negatively on the degree of price stickiness in the economy and $x_t=y_t-y^N_t$, with $y^N_t$ is the natural (potential) level of output What is driving me crazy is if this curve, specified as above, still make sense when we assume prices are fully flexible. I would say no, because in a flexible price context, the output gap would be zero and the firms would optimize in a static fashion (no need of taking into account expectations of future inflation). But, I have no idea about how to "transform" the model in this direction. 

I was reading about the debate about income inequality and I would like to know your opinion on the matter. Basically, the positions are two: the classical one, which states that inequality is good for growth because it fosters innovation and investments and the most recent one, the one of IMF and OECD, which states that inequality causes a decrease in human capital investment among lower-income households, which prevent them to become earners or consumers in the future. I read that both are supported by empirical evidence but there is skepticism about them (e.g. Chris Giles on FT). What's your idea on the topic? Do you have any suggestion about literature/articles I can read about it? 

A share or stock is part of an individual company. Unit (Trusts) are a collection of different (and usually related) shares. For example, I am currently investing in a Singapore Equity Fund. And this is known as a Unit Trust. And within the Singapore Equity Fund, my investment is made up of different company shares, e.g. the local bank shares, telecommunication company and some other companies. And these Unit Trusts are usually managed by a Fund Manager who belong to a Fund Management Company (or known as Fund House). And there are many different Fund Management Companies in Singapore with their own expertise and knowledge. Source: here 

Kenny LJ and FooBar already did a great job of clarifying the broader conceptual issue here: in equilibrium, prices don't just increase or decrease without a cause (a shift in supply or demand), and any deviation from the equilibrium price will result in a surplus or deficit. But since you're talking about interest rates, I assume that you're interested in what happens when a central bank changes the interest rate. This is legitimately very confusing, because at first glance it doesn't seem like the central bank is affecting either the supply of savings or the demand for investment - and hence, by changing the interest rate, it seems like the central bank will break the equality of savings and investment. This isn't true. But it took me years to wrap my head around this, and I suspect that the vast majority of economists would get it wrong if asked to explain it (as evinced, perhaps, that someone as smart as FooBar misfired a little on this point). Indeed, John Taylor - an extremely well-known macroeconomist - recently fell victim to a fallacy here, as Miles Kimball pointed out (see point 7 here; as further proof of the difficulty of this topic, I'm not sure that Kimball got it quite right either!). To clarify, let's split into two cases. Case 1: flexible prices. Note that what really matters for savings and investment is the real interest rate, which is the nominal interest rate minus expected inflation, while the central bank sets the nominal interest rate. Suppose that the central bank increases interest rates, and at first suppose that inflation expectations remain constant. Then as you point out, desired savings will increase while desired investment falls. This means that there will be a glut in the economy: there will be more goods supplied than demanded. How is this resolved? In a world where prices are flexible, the price will fall until inflation expectations rise exactly enough to offset the central bank's increase in the nominal interest rate, leaving the real interest rate ultimately unchanged (so that desired savings and investment balance again). For instance, if we have a certain expectation of where prices will be next year, then when prices fall today, that fall creates more expected inflation over the next year. This is the neoclassical, flexible price case, and it resolves your paradox in the simplest possible way - by saying that expected inflation will adjust such that real interest rates, and hence the desire to save and invest, are unchanged. But as you can probably guess, this is fairly unrealistic: prices don't always adjust that quickly, and it's counterfactual to say that higher nominal interest rates result in an equal rise in expected inflation. Case 2: sticky prices. Let's suppose that prices are "sticky", meaning that they don't change in response to events very quickly. This is the kind of assumption made in "New Keynesian" models (and, to some extent, "Old Keynesian" and monetarist models before them). Indeed, for our purposes, let's suppose that prices are so sticky that expected inflation is a constant, so that a change in the nominal interest rate translates exactly one-for-one to a change in the real interest rate. (This is not a bad assumption empirically, according to Nakamura and Steinsson!) This means that we can't use the dodge from before: when the central bank pushes up the nominal interest rate, the real interest rate that matters for the savings/investment market rises too, and it seems like we should get some kind of disequilibrium. Indeed, if not all sides of the market react right away, something like this might happen. Suppose that in response to an interest rate hike, consumers quickly increase their savings, cutting back consumption, but producers are slow to respond and keep producing the same amount of goods. (Let's ignore the response of desired investment to interest rates, which complicates the story but doesn't change the basic lessons.) Then there will be a surplus of unsold goods, which will accumulate as inventories. This inventory accumulation is a form of investment (e.g. line 14 in the US national accounts here), so $S=I$ will continue to hold - but it will hold in a weird way, where consumers' saving is matched by producers' unintended inventory accumulation. Alternatively, suppose that producers react right away. Then when consumers try to save more and consume less, producers will produce less, and there will be less income earned by workers and capitalists. How will consumers deal with this fall in income? Partly, they'll save less - because it makes less sense to save when your earnings are low relative to their usual level. Partly, though, they'll consume even less - which means that producers make less and incomes fall again, and so on and so on. This is just the Keynesian multiplier, and the process ends when income $Y$ has fallen by $\Delta Y = \Delta S/MPS$, where $\Delta S$ is the initial increase in desired savings and $MPS$ is the marginal propensity to save out of income. At the point, the decrease $MPS\times \Delta Y$ in desired savings from the $\Delta Y$ fall in income precisely offsets the initial increase $\Delta S$ in desired savings arising from the higher interest rate. (If there is an initial fall $\Delta I$ in investment in response to the higher interest rate too, then this becomes $\Delta Y = (\Delta S - \Delta I)/MPS$; and it becomes more complicated still if investment changes in response to income, etc..) In short, $S=I$ continues to hold because desired savings depends on income - which you can't see from the simple, partial equilibrium diagram showing S and I relative to the interest rate. Consumption (and therefore income) will eventually fall enough to cause a decline in savings that restores equilibrium. 

Specifications of this form treat labor $h_t$ and leisure $1-h_t$ as two alternative ways of spending a total time endowment. Labor can be used as an input to the production function, while leisure enters directly into the utility function as a desirable end in its own right. In this environment, there are many equivalent normalizations. There is no need to say that the total time endowment is 1; instead, we could just as easily say it is 100, and by modifying the production function and utility function accordingly we'd get an isomorphic model. There's nothing special about any particular normalization. That said, given a particular functional form for utility $u$, it often does matter how we define the time endowment, and this issue has played an important and somewhat embarrassing role in the history of RBC. In particular, if we normalize the total "time endowment" to 1 and say that $h_t$ is the labor fraction of the time endowment, then it can matter greatly whether we define the time endowment to be 24 hours every day for all individuals, limit to non-sleeping time, limit to non-sleeping time of working age adults, etc. Why does this matter? The basic RBC model has typically assumed that intratemporal utility depends on a constant-returns-to-scale composite of consumption $c_t$ and leisure $l_t$. Given this, we can infer that this composite must have a constant elasticity of substitution of 1 from the fact that long-run labor supply seems roughly stable even as productivity and real wages have a strong upward trend. (See, for instance, pages 6 and 7 of Prescott 1986.) An elasticity of 1 means that the composite is Cobb-Douglas in consumption and leisure, taking the form $c_t^{1-\phi}l_t^\phi$ for some $\phi$. RBC models then generally assume a constant intertemporal elasticity of substitution $1/\gamma$ for this composite, giving us the period utility function found on page 6 of Prescott (1986): $$u(c_t,l_t) = \frac{[c_t^{1-\phi}l_t^\phi]^{1-\gamma}-1}{1-\gamma}$$ In the common special case with unitary intertemporal elasticity of substitution $1/\gamma=1$, the above reduces to simply $$u(c_t,l_t) = (1-\phi)\log c_t + \phi \log l_t\tag{1}$$ Now, one important feature of a dynamic macroeconomic model is the Frisch elasticity of labor supply, which is the elasticity of labor supply to real wages holding marginal utility of consumption constant. This is important because it determines how the household will intertemporally substitute labor in response to the intertemporal pattern of real wages and real interest rates. At an optimum the marginal utility of leisure must equal the real wage times the marginal utility of consumption, so for constant marginal utility of consumption $\lambda_t$ we have the condition $$\frac{\phi}{l_t} = w_t\lambda_t$$ It follows that the Frisch elasticity of leisure $l_t$ with respect to $w_t$ is $-1$; this is a more-or-less direct consequence of the assumption that consumption and leisure form a Cobb-Douglas aggregate. But since $l_t = 1-h_t$, the local Frisch elasticity of labor $h_t$ is $$\text{Frisch elasticity of labor}=\frac{dh_t/h_t}{dw_t/w_t}=\frac{-dl_t/h_t}{dw_t/w_t}\\ =-\frac{l_t}{h_t}\times \underbrace{\frac{dl_t/l_t}{dw_t/w_t}}_{\text{Frisch elasticity of leisure}} = \frac{1-h_t}{h_t}$$ From this, we can see that the definition of "time endowment" 1 matters greatly. For instance, from Table 1 of the most recent American Time Use Survey we see that average working hours per day are 3.14. If we take the time endowment to be all 24 hours, then $h=3.14/24 \approx .13$, and the implied local Frisch elasticity is about 6.6. If, on the other hand, we take out sleeping and other personal care activities, the remaining time endowment is 14.5 hours, in which case $h\approx.22$ and the implied Frisch elasticity is about 3.5. Both these values are far higher than most Frisch elasticities estimated using micro data, as discussed by Chetty et al. (2012). Moreover, it seems bizarre that something as deep and important as the Frisch elasticity should depend on a choice as arbitrary as the definition of "time endowment". This connection is ultimately attributable to the assumption that $c_t$ and $l_t$ form a constant-returns-to-scale composite; King, Plosser, and Rebelo (1988) show that if we discard this assumption, a more general "KPR" functional form is consistent with the stylized fact of stable long-term labor supply, and we can potentially calibrate this more general form to the (much lower) elasticities estimated in the labor supply literature rather than imposing an unrealistically high Frisch elasticity by fiat. For reasons that I do not completely understand, much of the RBC literature has followed Prescott (1986) and used the "log-log" utility parameterization (1) above, rather than calibrating the KPR functional form to match some externally estimated elasticity. This is probably due to a combination of inertia and convenience: the high Frisch elasticity guaranteed by the log-log parameterization helps to make labor volatile enough to match the macro data. And this is all connected to a lengthy and convoluted debate about the possible difference between "micro" and "macro" elasticities - see Chetty's slides or paper to read more about this.