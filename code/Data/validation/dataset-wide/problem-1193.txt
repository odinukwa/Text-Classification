First of all full text searches are often slower than searching on indexed columns. But full text searches offer some semantics that column searches do not. However, full text search is primarily valuable in larger sets of text, such as indexing documents, or when the likely order of the text is fluid. (e.g. John Johnson; Johnson, John; John, Johnson; etc) In this constrained task of matching names, I would choose the two columns, both indexed, as likely the better performing option. (But testing is the only way to know for sure.) If you are using standard indexed columns, then you can quickly search the fname column and/or the lname column and when needed join them on a matching identifier. This is more accurate than a full text search, because the search is very bounded. This does require that the search query be made knowing which name is the fname and the lname, of course, or adding additional conditions to check both ways. (Not always so simple in a multi-language world.) The full text search syntax will support "phrases" (words in a certain order) or the softer version of words in any order. In the latter case 'John Johnson' would be satisified by either or both of those names in any order. (Of course, for the exact search syntax options see the mySql documentation.) 

Run "cliconfg.exe" from a Windows run dialog to determine that you did not check "Force protocol encryption". 

This would allow you to incrementally batch the insert of rows into the intersection table a bit at a time, thus keeping the update transactions quite small. Perhaps insert one day at a time, 10,000 rows at a time, or some other batching method. Each batch should be a transaction that begins before the insert/update and commits when finished. That means that the updating of the batches of your choice would be many small transactions instead of one big one. That would limit the resources needed and, in many cases, would run faster that one big update. Perhaps having a included would help to filter the results more effectively. NULL keys are probably needed for the periods that are incomplete. What indexes do you currently have? SQL performance issues often depend on having the indexes properly defined. The columns in the intersection table likewise need to have indexes, as do the and tables. 

$URL$ Then you should have the SQL Server 2000 database upgraded to SQL Server 2014. Since you want Keys and Indices as well, you need the metadata. Another approach is to script out all the objects (tables, views, procedures, etc) from your SQL Server 2000 database. Then execute the create script on your 2014 server. (Fixing any problems that you find.) After that transfer the data via linked server (per Mark Sinkinson), SSIS packages, BCP, etc. 

The database owner_sid is not equal to the database's db_owner sid. You can compare this for database ABC by: SELECT owner_sid FROM sys.databases where name = 'ABC'; SELECT sid from ABC.sys.database_principals WHERE name = 'dbo'; Next you are getting a message saying that your proposed database owner_sid also exists as a user in sys.database_principals. We know this from the error message about mapping the proposed owner. 

Using wildcards for data that "they don't necessarily exactly match" seems likely to cause you a lot of grief. A search that begins with '%' will turn that into a table scan since no index can be used in searching the names. From your comments you apparently recognize that this is a thorny problem and you are unlikely to get perfect results. Since you are matching (roughly) on names, have you considered creating FULL TEXT indices for the tables and columns you are searching? Once the full text index is built and maintained, the likelihood of quickly finding candidate rows goes up. Here is a simple example of working on your problem from one of my earlier posts from a few years ago: $URL$ A sample script using the sys.dm_fts_keywords dynamic management function. 

I do not know how dynamic your queries are, but naturally each table needs a separate query for that table. Assuming that you are constantly querying this 4 table group, it might be worthwhile to create an indexed view that included the searchable fields you need from the 4 tables into a single view. This means the overhead of maintaining the indexed view, but may help in this case. Of course, if you have a widely varying array of tables that might be joined, you would need to consider whether this is a good idea for you or whether you should query each table separately as you are doing. 

You are correct that updating an non-indexed column will not cause changes to the indexes. In a simple case, there would also be no overall impact on the table. If a query can use the Index to look up data, it may speed up the lookup, but the exact behavior (depending on your SQL brand) may differ from other brands of SQL. (I use Microsoft SQL Server primarily.) Of course, updating a column with a significantly greater volume of data could cause some moving of rows to different pages, et cetera. 

It does not sound like your database and application would be very big in current terms. You could look into the freely available Microsoft tools for Visual Studio Express and SQL Server Express: $URL$ $URL$ Both of these are without charge and contain most features of the bigger products. The limit is in database size, amount of memory, and number of processors that can be used. 

The only way a login has rights to a server is if those rights have been granted. The question is likely: How did these rights get granted? If DOMAIN\USER_A is a member of some Windows group, then through the rights granted to the group the DOMAIN\USER_A login exists in the server. This is true even if there is no individual entry in sys.database_principals or sys.server_principals for that login. You can look for the permission paths used by a login as follows: 

Then load the data file on disk into a new temporary database (e.g. RepairRecovery). Once that is done you can compare the data between the original, now "repaired", database and the data that you were able to recover from the disk file. (There are tools to help you compare data, or you can just look for missing IDs or something similar.) 

A SQL Server BACKUP only backs up extents that are being used to hold data. The unused extents are left behind by the backup. When a page is used for data it will be formatted for use as needed, so that page would be free of old data. Therefore, all you should need to do is backup the database and restore it elsewhere. The restored files will be of the same size as the original database, but the unused extents will be created using the capabilities of the target server. This may be initialized fully or instantly initialized using the blocks of disk on the target server. However, because extents are the level at which backups happen the unused pages in the extent could still have potential to expose some data when restored on another server. Not as much as could be exposed on the source server, since the unused extents are not restored. 

was successful. In other words, can create NEW databases, but can only restore a database where it is already a user and still retain rights to that database. Hope that this helps you decide what to do. 

You might find the diagrams and explanation found in the SQL Server 2008 R2 documentation useful. (Nothing has fundamentally changed recently on Full Text processing.) $URL$ Quoting from that explanation: "The query processor compiles and executes SQL queries. If a SQL query includes a full-text search query, the query is sent to the Full-Text Engine, both during compilation and during execution. The query result is matched against the full-text index." So you might view the Full Text search as a 'function' that returns its portion of the query from the Full Text Engine, then joins with any operators from the Database Engine that may also be part of the overall SQL Server query. 

Most SQL Servers are configured for the non-system databases to exist apart from the system databases. That is what is normally meant by the default path. You can lookup some code for finding this at: $URL$ Also, Alex Aza has provided a popular post over at StackOverflow. The key is to get the data from the registry keys where they are stored. Here is a snippet from Alex's longer script: