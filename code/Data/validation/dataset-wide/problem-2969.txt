There are empiricist philosophers who have made an entire career out of applying the scientific method to their work, or at least arguing that it could be applied to their work. Bertrand Russell is a good one to investigate here, starting with his essay, On Scientific Method In Philosophy, which appears to be available online. In addition, David Hume's strong empiricist bent could be seen as strongly resembling a somewhat primitive "scientific method", and his ideas on deductive and inductive reasoning were actually quite influential in developing the modern notion of the scientific method. Also consider the subject of "natural philosophy" (which is the older name for what we now call merely "science") where the scientific method was surely applied rigorously. Before the development of modern science, philosophy and science were seen as one in the same. In fact, many long-established universities still appoint "Chairs of Natural Philosophy", commonly occupied by professors of physical science nowadays. There is also an entire division of philosophy known as the "philosophy of science" that's concerned with such things as the development of the scientific method. Perhaps they don't approach philosophical inquiry using the steps of the scientific method, but it must certainly play a role! In fact, the scientific method was itself developed as a direct result of philosophical inquiry. See the collective works of Francis Bacon and René Descartes, two of its most notable founding fathers. 

By all accounts, Gödel rarely uttered a word when he attended the logical positivist's meetings in Vienna. So it is not clear if Gödel was originally opposed to logical positivism even if his opposition became absolute as time passed. The refutation of logical positivism began when Russell pulled the rug out from under Frege with his famous paradox. We still have the polite but lethal letter Russell sent to Frege in 1902 : 

When considering questions such as this, it is useful to keep in mind Frege's ontology { concept, object, name }. Everything is considered as being in these three categories. We give an object a name (denotation), here P. In turn, the object has a concept (or sense). If you are familiar with modern computer languages (object-oriented programming), then this should be natural to you as the ontology { class, object, name }, where the object is a named instance of the class. On the other hand, in a different context both object and name are concepts which can be instantiated as an object with a name. So it is important to keep context in mind. 

None of the answers you're going to get to this question will be satisfying. Nor will any of them be correct. I could tell you that "postmodernist" thought is generally characterized by a "rejection of objective Truth", and a strong suspicion towards "totalizing meta-narratives", but that probably wouldn't tell you very much. And it wouldn't be strictly accurate, either. I could tell you that it argues that many of the things which we take for granted are merely "social constructions", not merely figments of our imagination, but things that we as a society have indeed created for ourselves. I could say that it aims to expose and destroy oppressive systems of classification, particularly those that emphasize sharp divisions between groups—gender, race, culture, etc. But one of those things might give you the idea that it's somehow "pluralism", which is so completely wrong that I'm not even sure where to begin. The reality is that "postmodernism" is not something that you can define, at least not as applied to philosophy. There were hardly any notable philosophers who accepted the label of "post-modernist", and many of those who are often considered to be anchors of the tradition actually strictly rejected the label. Part of the problem, of course, is highlighted by Jon Ericson's answer: thinking that is typically associated with the "postmodern" camp seeks to reject things like labels and totalizing meta-narratives. They wouldn't be too keen on allying themselves with any particular camp, or labeling their unique brand of thought as "postmodernist". There is a notable tendency among these thinkers to resist the homogenization and categorization that such labeling implies. About the only thing you can accurately say about "postmodernism" is that it's characterized by a rejection of modernism, the pseudo-scientific mentality of progressive objectivity established in the Enlightenment. Truly, one could argue that without the Enlightenment and the resulting movement that has become known as "modernism", there could never be such thing as "post-modernism". But whether that's actually a useful definition or merely a linguistic tautology is debatable. And even if you accept that definition, a couple of problems still remain. First, it's extremely difficult to define something in terms of what it is not. Several notable "postmodernist" thinkers have taken up this very notion, albeit in quite different contexts. As merely one example, consider Jacques Lacan and his notion of the "lack". Second, several of those who are apparently "postmodernist" thinkers have actually accepted "modernist" notions to varying degrees. Jürgen Habermas in particular is very much a "modernist", and he doesn't even reject the notions of "universality" and "Truth" that seem to characterize the thought of most other "postmodernists". It's hard to say whether "postmodernity" actually seeks to replace modernity, to render it obsolete, or whether it merely allied with it, continuing and reinvigorating the modernist project. Many, many, many "postmodernist" scholars vehemently disagree with one another. Somehow, this camp has grown to contain post-Marxists, feminists, deconstructionists, anarchists, post-Freudian psychoanalysts, and everything else outside and in between. Many people use it as a label of denigration, or at least a nicer way of saying "those people", the "different" ones, the ones "we" don't agree with. You see this in an unfortunate amount of academic literature, and in an even more unfortunate amount of colloquial rhetoric. See, for example, Paul Hartman's "What is 'Postmodernism'?" or the infamous Postmodernism Generator (refresh repeatedly for a real thrill!). In a truly postmodern sense, its accuracy lies in its appalling inaccuracy. So yes, of course it has a fuzzy definition, and of course the Wikipedia article seems to characterize it in terms of what it is not. There's not much else that it can do. In fact, reading the Wikipedia article now, it strikes me as possibly one of the best attempts to clarify and define the movement that I've ever seen. And I've read a whole lot of so-called "postmodernist" literature. Beyond that, the paragraph you mention concluding that postmodernism has influenced many other cultural fields is an important one. "Postmodernism" is not limited in scope to philosophy. In fact, when applied to other disciplines, an even more complicated web begins to emerge. From architecture to art to music, and dozens of other disciplines in between, "postmodernism" takes on very important meanings. Wikipedia links to a host of articles on "postmodern x", where x represents some particular artistic discipline. Again, what most of them have in common is the rejection of "modernism" "Postmodernists" would tell you that you're really asking the wrong question. Rather than trying to put a label on their critical project, to attempt to unite and thereby destabilize it from without, you should join in on the project and become part of the movement. If "postmodernism" implies anything at all, it implies problematization, the refusal to tacitly accept anything as objectively true, as objectively real, as objectively valuable. That doesn't, of course, mean that it embraces skepticism. That doesn't mean that it necessarily rejects all notions of objective truth. But it does mean that the goal is to problematize everything, to attempt to see everything from a different light, to root out problems at their source, to emphasize connections that haven't been previously observed or noted, to engage in relations with other cultures, values, practices, and systems of thought. It's a critical project, one in which nothing is taken as absolute, including the idea that nothing is an absolute. 

I think the problem is that randomness is a folk concept. Everyone believes that they understand what is meant by randomness and that their understanding applies to all cases of perceived randomness, including statistical randomness. For someone versed in finance, randomness is equated to unpredictability. The price movements of financial markets are perceived to be random since they are unpredictable. In a liquid market, such as treasury bonds, we expect successive trades to be initiated by a even distribution of buyers and sellers. If too many buyers flooded the market with orders, we would assume that there was some well define cause such as a change in interest rates. A financier would not see this as random, even if it still fell within the definition of statistical randomness from a purely transactional point of view. While it is true that certain areas of mathematics give precise definition of randomness, even here different areas of mathematics give different definitions. For example, statistical randomness is not necessarily the same as information-theoretic randomness even if information-theoretic randomness would necessarily contain some degree of statistical randomness. EDIT As per your request, I shall try to make my answer more clear. Everyone has a naive / folk idea of what they think constitutes randomness. In the case of the coin toss example, unless one is familiar with the concept of statistical randomness it is this folk concept that will be applied, or possibly some alternative definition of randomness such as that used by the information theorist. A typical folk notion would be "lacking pattern". When someone sees a "pattern" of what they consider too many heads or too many tales, either in consecutive sequence or in aggregate, they will automatically make the judgement that the sequence of coin tosses is not random. The coin toss example is an interesting example. The statistical distribution of the digits of the expansion of π is another. To make this analogous to the coin toss, let's consider the binary expansion of π. This is statistically random. However, it can be shown that sequences of consecutive zeros or consecutive ones of length n occur for any value n. Thus, for example, there exists a sequence of a trillion, trillion, trillion consecutive zeros in the binary expansion of π even though there is a statistically random distribution of 0's and 1's. If such a sequence occured near the beginning, the most non-mathematicans would assume non-randomness. 

And taking a slightly different angle, it's also a notable concept in existentialist literature. Heidegger himself picks up the topic of boredom a second time in his writings on "nothingness" and the meaning[lessness] of existence. To him, boredom reveals a lot about Dasein. In Being and Time, his most famous work, he writes: 

But beyond that, it appears that your confusion (and the confusion of whomever wrote the article you are quoting) stems mainly from the notion that atheism (or the rejection of organized religion) implies relativism, absent or beyond its humanist affiliations. That is also quite incorrect (albeit quite a common fallacy that religious scholars succumb to). The flaw lies in thinking that the only possible source for an objective morality is from [a] God. While that's certainly one possible source, and even a good source, it's far from the only possible source. Humanists, as I hinted above, would argue that human rationality, intuition, and logic are the sources for morality, and since all humans share these faculties, such a moral framework would be objectively shared across all humanity. There is an entire world of philosophers who don't necessarily believe in the existence of a supreme being, yet believe in objective morality. The one who makes this position most persuasively is probably Shelly Kagan, a contemporary moral philosopher. And other philosophers have even argued (this is Plato's famous Euthyphro dilemma) that objective morality cannot be based on God, even if both are granted to exist. 

I like Mauro's analogy, and Mozibur makes a good point about the nature of realism. I'm not sure this is entirely what you have in mind, but it may be of interest nonetheless. You ask : "How, then, can you 'think up' an equation or be presented one illusorily, that makes no sense to one's self, yet build on rules that you had previously known (or, rather, believed to have known) to determine that the original equation is true?" This is not uncommon in both mathematics and physical science. For example, the method of analytic continuation used to extend the domain of analytic functions in the complex plane is a well-defined, rigorous, rule-based method of complex analysis. It is a method that is well understood by mathematicians, though not necessarily by me. When this method is applied to the Reimann zeta function it yields : 

I believe that my comments on question 1 also answer this question. The example I have given is obviously an informal argument, but one which is easily formalised. 

When considering a mathematical result it is important to place all terms in the correct context. Cantor's diagonal argument is a method of proof, so it does not "conclude" anything. It is neither a paradox nor a theorem. The diagonal argument is used to prove a theorem that states R is not equinumerous with N. Diagonalization is a well-defined, mathematically sound procedure. The justification for concluding that |R| > |N| is that it has been thus proven in a mathematically rigorous way. Cantor's result can be proven in ways that employ neither diagonalization nor the reductio-ad-absurdum method. Diagonalization is the popular method of proof because it is the most elegant and intuitively clear. Cantor originally proved the result using an different reductio argument involving nested intervals. An example of a non-reductio proof is given by what is called The Measurement Argument. Aside : Russell's paradox is a logical (formal) paradox and one could say that it gives rise to a theorem, namely that the cumulative hierarchy (the collection of all sets) is not itself a set. This would not be a theorem of set theory since set theory only deals with sets, but it could be considered a theorem of mathematics in general. EDIT (Sep 11, '13): When I say that the diagonal argument is a method of proof and so does not conclude anything, I mean to point out that the diagonal argument is an argument used to prove dozens, if not hundreds of mathematical results in many areas of mathematics. Further, it may not be fair to say that the Measurement Argument is a non-reductio proof of Cantor's result. While the actual proof is non-reductio, it does rely on Measure Theory. Precisely, the proof shows that any countable set has zero measure. However, it may be that those measure-theoretic results which allow us to say that an uncountable set has non-zero measure may themselves currently have only reductio proofs. Finally, the context of Cantor's result is Set Theory. Set Theory uses classical logic. If you wish to apply a logic which rejects the Law of the Excluded Middle to argue the proof is not valid, fine. But this does not invalidate Cantor's result as a result from Set Theory. 

They would reject the idea (or at least the relevance of such an idea) that there are facts that are, in principle, unknowable. Talk of inaccessible Kantian "things-in-themselves", or the Nietzschean "True World" that is forever hidden behind the veil of phenomena is considered to be useless, merely idle chat. By contrast, utilitarianism is a moral philosophy. It holds that the utility of a particular action in providing the greatest amount of happiness or pleasure to sentient beings is both necessary and sufficient to establish its moral worth. It aims to measure the morality of an action, rather than merely assess its normative truth value. The conclusion of a utilitarian calculus is that the action is good or bad, right or wrong, moral or immoral. Pragmatists do not render the same type of judgment; it is not meant to guide moral evaluation or moral decision-making. The line probably begins to blur as you get into neo-pragmatism, those contemporary thinkers whose work has been widely held to be "pragmatist", like Jürgen Habermas, Hilary Putnam (although, "pragmatically"-speaking, it's awfully hard to nail down what his position actually is), etc. Some of them have drawn moral conclusions from pragmatist rationale. But in general, the distinction is still one of a moral-ethical system, as compared to a normative truth-based system. 

In recent years, a multiverse view of reality has become mainstream. Here, our universe is just one instance of many universes that make up a multiverse. In this vision, the multiverse is infinite in both directions. 

Schopenhauer begins by noting that when we view an object, the information that is impressed upon our retinas is upside down (since the light rays cross after entering the eye). He then notes that if seeing was simply the sensation resulting from the light rays entering our eyes and impressing their information upon our retinas, then we would expect our mind to model our surroundings exactly as this impression demands - i.e., we would perceive an upside down object. Thus, there must be a subsequent "intellectual process" which manipulates this information so that our mind models reality in the "correct" orientation. The italicised text justifies Schopenhauer's conclusion by noting that if we change our orientation, by, for example, lying downward on a hill, then our mind models our surroundings correctly - i.e., we still know what's up and what's down. This is because our intellectual processes include information about our orientation. This information cannot be from the light rays since the light rays cannot contain any information about our orientation. 

No, the scientific method is still the major way of assessing truth. It may not be as rigorously applied in the social sciences (the "soft" sciences, like philosophy, sociology, history, etc.) as it is in the natural sciences ("hard" sciences, like mathematics, physics, chemistry, etc.), but the underlying methodologies and motivations are all still there and all still intact. Perhaps you're wondering about logical proofs? Philosophical arguments are commonly made in this format, with the most common example being a syllogism. A syllogism presents two premises (or claims), and argues that the proposition (conclusion) must be logically inferred from those two premises. In other words, if you accept the premises, the conclusion must logically follow. For example: 

As far as a good contemporary of Rawls, you might look no further than Rawls himself! He has written several books following ATOJ  that aim to respond to some of his critics' writing in the interim (Nozick in particular). And I would strongly suggest reading the works of Thomas Nagel. He actually argues that Rawls's theory of justice doesn't go nearly far enough, as it merely seeks to redress the inequalities, rather than remove them altogether. He laments that a Rawlsian state would still permit intolerable inequalities and that we need to adopt an even more ambitious view of equality. For more on this, check out Equality and Partiality.