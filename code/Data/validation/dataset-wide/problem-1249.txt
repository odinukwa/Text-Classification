I think you can write a linear time solution borrowing ideas from this. The idea is to keep a stack of decreasing maxima (SDM). Let's consider first the problem without taking into account the circularity... Say your input was . When you are processing the third item (), you want your SDM to be , where he second item in the tuple is the 1-based index of that item in the original array, as per your problem's description. You search the SDM for the last entry larger than the item being processed, which in this case is , so the index of the first item larger than to its left is . You then discard all items in the SDM to the right of this one, and insert the current value in it's position, so the SDM now becomes . Rinse, repeat, and you have all your first items larger than to the left. For the symmetric item to the right, do the same scanning from right to left. At first this may seem as an \$O(n^2)\$ algorithm, since you have to search a list that could potentially be as large as the array (e.g. if the input is monotonically decreasing) for every item. Because the SDM is sorted, you could try to use binary search to make that bound \$O(n\log n)\$, but that would actually slow down the process! You have to keep in mind that, as the stack is being searched sequentially, entries that aren't larger than the one being processed are being removed from the stack! So the more work an item requires to find it's answer, the easier it makes it for the ones remaining. A careful analysis of this shows that, on average, each item takes constant time to process, so the resulting time complexity is \$O(n)\$, which is basically as good as it gets. You can factor in the circularity of the problem into the above approach, by first finding the maximum, and always starting your circular iteration, whether to the left or right, from it, so that you will always have the maximum in your SDM. But enough talking, here's an implementation: 

Note the use of and for yielding results. Using generators has a number of advantages including: you get to see results as they're created, you can stop iterating when you're happy with a result, rather than having to wait for the entire recursion to finish, you don't waste memory/time creating a list of all the results. Generators take a little bit of time to get used to, but they're well worth it, and should often be preferred to returning lists of results. Finally, one last neat trick; the general pattern of "make a change ... do stuff... undo the change" can be error prone; it can be easy to forget to undo the change, or an odd code path (e.g. an exception) skips the change. The other answers suggest making copies; however, backtracking algorithms like this can often suffer massive performance penalties from such a change, so it's worth knowing a pattern that mitigates this problem without introducing copies. We can use a context manager to do this automatically, such as below. (this post is not meant to be a tutorial on context managers) 

If you don't like global variables (which you really shouldn't!), you can create a static variable by making it an attribute of the function: 

If instead of raising an error you return without checking if the is indeed in the , things start getting interesting: 

The speed-up you are seeing is mostly from removing the calculation of the logarithm from inside the inner loop, and instead reusing the value. This performs only about 10% slower than your , and is infinitely more readable: 

While they stayed in the language, and are therefore fair game, reading Guido's 10 year old essay on how he planned to get rid of , , and for Python 3 will probably have you looking at those a little differently: I for one always try to come up with more Pythonic alternatives when tempted to use them. 

Your code doesn't actually work for some tricky corner cases. Take e.g. . It should be pretty obvious that is the proper answer, but your code returns . To build a working solution, let's leave the circularity out, you have already figured how to get the result for a circular array running twice over a linear array. As ususal with DP we will consider the array incrementally, and in an array we will store the value of the maximum donation from the first neighbors when the -th neighbor is one of the donors. It is relatively straightforward to see that then: 

would be better. In fact, you might consider doing something different: you could pass around by value rather than by pointer. Passing these objects around with move semantics may turn out to be more efficient. (you should probably explicitly deleting the copy constructor and copy assignment, to indicate that they shall not be used that way. Although this will automatically happen implicitly if you follow my advice and change to be a ) 

The usual way to implement the algorithm you're using (the sieve of Eratosthenes to find all primes up to a chosen bound) is to make an array of boolean values, so that means is in the list, and means that is not in the list. The point is that removing an element from the list only costs time, so it can be done much faster than erasing an element in the middle of the list. (and also, you don't even have to bother checking if the element is in the list before you remove it) 

Numpy has built in functions for most simple tasks like this one. In your case, should do the trick: 

If your list has items, and its max was , your original algorithm was doing operations, while this will keep that to . Putting the whole thing together for 2D arrays I would put all of the above in a function and then go with a dict comprehension that called it, so something like: 

If you look at that code, you don't really need to store the whole array, since you are only using the last value. So you can get the same time complexity, \$O(\log n)\$, but with constant space, by doing: 

Then all of a sudden your checks turn into a simple dictionary look-up, which is constant time, instead of having to scan all items in your dict every time: 

I'm pretty sure my 6 year old daughter could make sense of that last function with very little help. 

There may be other optimizations available, but this one alone should go a long way... When you do , the resulting is a dense matrix the same size as your . You later only use in your loop, so you are throwing away what probably are millions of computed values. If you simply replace that line with: 

One issue is that your function is four functions in one. The problem is that they are four unrelated functions — yes, they all have the job of displaying results, but: 

There is a fair amount of room for art and style in formatting, so don't take any particular suggestion as "you must do it this way" — in fact, I've mixed a couple different styles into the above example. The goal is to write code for which it is easy to see what the intention is, and without much clutter. You can improve readability further by realizing you don't need the , and can simplify to printing newline characters: 

Use the memory management tools the standard gives you In particular, should be of type , not . The memory management you are doing is a standard and common thing... and also well-known to be an extremely common place for programmer errors. Use the right tool for this job, so that it's easier to write code, less likely to have errors, and more obvious to the reader what your implicit intentions are. (and yes, you do have errors — for example, the way you wrote the code requires a destructor to deallocate the memory, and you don't have one!) You have a const correctness error is a const member, but it returns a pointer that would allow the user to modify the contents of the string! If you are going to have this function, you should have two variants 

You still have three nested loops, so this is unlikely to be very fast, but it should improve over your code, both in performance and memory use. 

This is only checking each position of the row once, rather than 4 times, so the algorithm is inherently more efficient. If rather than scanning row by row, you want to go with scanning from the last entered position, you could go with something like: 

It seems to me you could greatly benefit from storing your dictionary reversed. That is, if you create, just once, an auxiliary dictionary as: 

Slicing a Python list creates a copy of the list. This is not what you typically want in a merge sort. To avoid this, you can leave your original list unsliced, and pass around indices to the intervals being sorted and merged. Such an in-place merge sort could be written as: 

I think your method is unnecessarily cumbersome. It seems more straightforward to have a to which you append a reversed word whenever you find a space. And while I'm not an expert on Java internal workings, it will almost certainly be more efficient: 

and let manage the allocated memory, rather than managing it manually. Similarly, in , you have declared 

There is a better way to implement the design you seem to be using. Rather than generating numbers and storing them in a list, just generate the numbers: 

Generally speaking, buffering is good for performance, so it's better to write newline characters rather than inserting when you don't actually need flushes to happen. As a bonus, they're less typing and usually easier to read. Of course, I/O performance is basically irrelevant here because the human delay far outweighs any other concern — but it's good to get in the habit of writing what you mean early on. Thus, the above code snippet demonstrates the general pattern: I use newline characters to write newlines, and I do something to flush the stream at the point I want to ensure that all of the output has been written. Using to do the flush isn't an option here, if I want the flush to happen at the right place! 

As pointed out, top-down recursive approaches are almost never a good idea when it comes to Fibonacci numbers. Consider the alternative iterative approach: 

We can take the abstraction a step higher, to avoid repeating ourselves, and have a single function efficiently check for a win from a single location: 

Sometimes type checking makes for more readable code than duck typing, and this is probably one of those cases. What you shouldn't do is compare the types the way you are doing, it is better to use instead. You could check directly for the input being a string as: 

If you dig a little deeper in the math, it is very straightforward to realize that every third Fibonacci number can be computed with the formula: \$F_{n+6} = 4 F_{n+3} + F_{n}\$ You can reuse your function if you work the recursion backwards a couple of steps, and do something like: 

Note that the last timing means ~30 ns per item retrieved, right where you wanted to be. If you need to extract the boolean values one at a time, you are going to have to deal with the painful Python overhead. Notice that simply getting a single item from an array is terribly slow: 

In the source code, you can collapse a lot of the output statements to improve readability and so that they take up less vertical space. For example, 

You are using a reserved name due to the double underscore; you should adjust your naming convention for header guards (e.g. only use a single trailing underscore). The relevant passage from the C++11 standard, 17.6.4.3.2 , says 

This advice is likely to be somewhat controversial, but Explicitly flush when output should be available 

While some would advicate relying on the implicit flushes coming from being tied to , my own observations are that: 

There are times when it makes sense to have some sort of class whose instances are objects that can perform a bubble sort. This is typically when the algorithm might need access to some precomputed data, or maybe to acquire resources that will be reused through several invocations of the algorithm, or hold configuration options, or is keeping track of performance metrics, or other such things. (but this pattern has its own advantages and disadvantages and there are other patterns that can be used to achieve that effect) However, this implementation is very much not one of those times.