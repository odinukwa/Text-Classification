The premise of the question is not correct. Dwork's methods (and modern descendants of them) are a major part of modern arithmetic geometry over $p$-adic fields, and of $p$-adic analysis. You could look at the two volume collection Geometric aspects of Dwork theory to get some sense of these developments. Just to say a little bit here: Dwork's approach led to Monsky--Washnitzer cohomology, which in turn was combined with the theory of crystalline cohomology by Bertheolt to develop the modern theory of rigid cohomology. The $p$-adic analysis of Frobenius actions is also at the heart of the $p$-adic theory of modular and automorphic forms, and of much of the machinery underlying $p$-adic Hodge theory. The theory of $F$-isocrystals (the $p$-adic analogue of variations of Hodge structure) also grew (at least in part) out of Dworks ideas. To get a sense for some of Dwork's techniques, you can look at the Bourbaki report Travaux de Dwork, by Nick Katz, and also at Dwork's difficult masterpiece $p$-adic cycles, which has been a source of insipiration for many arithmetic geometers. In some sense the $p$-adic theory is more difficult than the $\ell$-adic theory, which is why it took longer to develop. (It is like Hodge theory as compared to singular cohomology. The latter is already a magnificent theory, but the former is more difficult in the sense that it has more elaborate foundations and a more elaborate formalism, and (related to this) has ties to analysis (elliptic operators, differential equations) that are not present in the same way in the latter.) [For the experts: I am alluding to $p$-adic Hodge theory, syntomic cohomology, $p$-adic regulators, Serre--Tate theory, and the like.] 

The idea for (2) is the following: the modular curve $Y(\ell^n)$ classifying elliptic curves over ${\mathbb C}$ together with an isomorphism $({\mathbb Z}/\ell^n)^2 \cong E[\ell^n]$ identifying the standard symplectic pairing on the left (i.e. $\langle (a_1,a_2),(b_1 ,b_2)\rangle = e^{2\pi i (a_1b_2-a_2b_1)/\ell^n}$) with the Weil pairing on the right, is irreducible. (It is isomorphic to $\mathcal H/\Gamma(\ell^n)$, where $\mathcal H$ is the complex upper half-plane and $\Gamma(\ell^n)$ is the congruence subgroup of full level $\ell^n$.) (3) follows from (2) and the irreducibility of cyclotomic polynomials over ${\mathbb Q}$. 

In my experience, mathematicians will frequently argue (in general, not just in mathematics) by passing to an extreme case at the beginning. Non-mathematicians (again in my experience) sometimes object to such a mode of argument as invalid or irrelevant because such extreme hypotheticals are clearly unrealistic. I think that the mathematical idea of first setting all the parameters to their maximal, or minimal, values, and understanding that case, before trying to tune them to a more realistic choice of values (and seeing how the solution/context changes with the parameters) can sometimes be valuable (even though it involves as a first step considering a situation that may be very unrealistic). 

Rather than thinking directly about "holes", I suggest you think about how a circle (in the guise of the boundary of a triangle) is obtained by gluing three intervals at their endpoints, or how a 2-sphere (in the guise of the surface of a tetrahedron) is obtained by gluing together four triangles along their edges. In general, the boundary of an $n+1$ simplex, which is topologically a sphere, is the sum of $n+1$ different $n$-simplices, and this sum is the non-trivial $n$-cycle giving the top homology of the sphere. If you have trouble connecting this picture with the definitions of singular homology, then try learning simplicial homology first. The computations are then much more explicit, and you can compute the homology of a sphere directly from the preceding triangulations, rather than from a diagram-chasing interpretation of Mayer--Vietoris. Once you are comfortable with computations in that context, return to the singular theory. 

Igusa uses Weil's language, in a modified/enhanced version that deals with reduction mod primes. (My memory is that there is a paper of Shimura from the 50s that develops this language.) It's not so easy to read it carefully, unfortunately. Chow's method for constructing Jacobians (explained in his paper in the American Journal from the 50s, again if memory serves) is, I think, as follows: take $Sym^d C$ for $d > 2g - 2$. The fibres of the map $Sym^d C \to Pic^d(C)$ are then projective space of uniform dimension (by Riemann--Roch), and so it is not so hard to quotient out by all of them to construct $Pic^d(C)$ (for $d > 2g - 2$), and hence to construct the Jacobian. (I hope that I'm remembering correctly here; if not, hopefully someone will correct me.) I think that this should be contrasted with the more traditional method of considering $Sym^g C$, which maps birationally to $Pic^g(C)$, i.e. with fibres that are generically points, but which has various exceptional fibres of varying dimensions, making it harder to form the quotient, thus inspiring in part Weil's "group chunk" method where he uses the group action to form the quotient (in an indirect sort of way), and consequently loses some control of the situation (e.g. he can't show that the Jacobian so constructed is projective). I should also say that it's been a long time since I looked at this old 1950s literature, and I'm not completely confident that I understand its thrust (i.e. I'm not sure what was considered easy and what was considered hard, and what was considered new and innovative in various papers as contrasted to what was considered routine), so take this as a very rough guide only. 

The introduction to Wiles's famous paper on Fermat's Last Theorem (from the Annals in the mid 1990s) gives an unusually detailed account of the process by which Wiles developed the arguments of the paper. 

If the base $S$ is Spec of a Dedekind domain, say $A$, and one restricts to finite flat groups schemes with etale generic fibres (which is no restriction if the fraction field of $A$ has char. 0), then one can form kernels and cokernels in the category of finite flat group schemes by taking scheme-theoretic closures of the corresponding notions on the generic fibre, and this can be useful. (Of course, one doesnt' get an abelian category: the map ${\mathbb Z}/2 {\mathbb Z} \rightarrow \mu_2$ has trivial kernel and cokernel, but is not an isomorhpism.) An illustration of how this method can be used is given in e.g. in my joint paper with Calegari On the ramification of Hecke algebras at Einstein primes. (The point of the restriction to a Dedekind base is that in this case, torsion free, which is what you get with scheme-theoretic closure from the generic fibre, coincides with flat.)