I have a table and a view that is a select of the contents of . If I deny on to a user, the user can still use the view . Is there a way that I can force the view to return an error when the user tries to use it? The real world case here is a database with about 20 tables and hundreds of views. User access is logically tied to the tables so we are hoping to stop folks from using the views based on those tables. 

I am a replication rookie. We have a very simple transactional replication set up in SQL Server. I am looking at the Replication Monitor on the subscriber and one of my subscriptions show Poor Current Average Performance. My understanding is this is derived from the latency threshold but when I look at the detail of the subscription, Performance is Excellent and Latency is 00:00:00. For what it's worth, Synchronization Status is fine. Why is this current average performance poor? Over what time period is this "average"? This subscription has had no noticeable issues and has been active for some time. (I am asking for my own knowledge as well as ensuring there is not something broken/sub-optimal that should be modified) 

I have a number of Oracle stored procedures whose activity I want to be able to audit, so I am having them INSERT some data into an auditing table. It would be swell if I could list the variables and their values as well. Is it possible to get this list in an automated way? I am already using to get my procedure name. 

I am creating a few dozen tables as CREATE TABLE AS SELECT (CTAS). The only difference in the SELECT statements is specifying a different value in the WHERE clause for TEAM_ID. I'm an Oracle newbie and thought I could use bind variables to speed up the process, but those are not allowed in DDL statements. My data is quite large - 500+ million rows. What is my best option for speed? Currently we are using on the CREATE TABLE statement. Would it be better to explicitly create the table and INSERT with the hint and bind variables? Or do the gains of outweigh the gains of bind variables? (I am sure this is an "it depends" scenario, but I don't even know what it depends on...) 

Addendum 3/26 - I like to think the lack of feedback means this is a fantastic idea, but I'd rather get some validation that I'm not treading in dangerous territory here. So let's try a rephrase: Is there any way a user can view the raw results of the query associated with a data driven subscription? 

I would like to set up an SSRS email subscription that attaches the report in PDF format to the email with a custom file name that changes daily. I was hopeful that I could to this via a data-driven subscription, but that does not seem possible. Does anyone have a handy work-around for this limitation? UPDATE: @swasheck provided a decent work-around, and one that we currently use. But I am hoping to remove the step of saving to a file-share. 

I would like to know more about the data-driven subscriptions on our ReportServer. I am specifically looking for what shared data sources are being used, but the connection string would also suffice. I have poked around the and tables, but nothing seems to give me the information I need. Any ideas? 

You can do this. You can create a single report that has multiple data sources (one per environment). Add the data sets required. Recreate the graphs (you may be able to leverage some cut-and-paste). In order to format them nicely, you will need to place the graphs into the cells of a matrix. You could also build a single report that links to other reports. I realize this is a high-level description of how to do it - if you need further details, let me know. 

I am looking for the most efficient way to solve this situation: We are an Oracle shop. I need to load data from one table to another. My source table, which contains 30 million rows, has a person identifier that is supposed to be unique, but it is not enforced so there are cases where it is not - about .1% of the time. There is logic I can use to resolve the non-unique cases. I want my target table to "enforce" the uniqueness of the identifier - so I have defined this identifier as my primary key. (Note that the data that is loaded isn't a straight source table -> target table; there are a few look-up tables that are used too) My goal: load this table as quickly as possible. It's a lot of rows, so efficiency is key. I have thought of a number of ways to address this, but I'm not sure what would be the most efficient. My ideas include: 

I am sure there are other methods that I haven't listed. So - what's the fastest way to accomplish this task? 

I would like to know if it is possible to verify that an SSRS subscription that was set up to send an email sent it to a real address. That is, if I put in an email address that is not valid, can I find out that an undeliverable message was sent back from the destination server? I tested this with an email address that does return an undeliverable message when I emailed to it from Outlook. After the subscription ran, its status simply said . OUR SOLUTION: We set up a shared Outlook account with a generic email address. Those of us who have access to create subscriptions have access to this email account. We then modified the file on the ReportServer to send emails from this new generic address. Now, any time a subscription is set up to send to an incorrect email address, we can see the delivery failure in the shared Outlook inbox. Woo hoo! 

You should format your label so that there is a background color of white (instead of default none). Right-click on one of the labels and select Series Label Properties. Select Fill. By default this is set to No Color. Change it to White. Click OK. That should take care of it! ADDITION: It may be possible to write an expression to change the distance between the label and the bar. When you select one of the labels, check out the properties window. You would need to play around with SmartLabels - specifically MaxMovingDistance and MinMovingDistance. You would need to have chart lines at specific intervals and then build the expression around the value being within one of those intervals. I know that is short on details, but hopefully the idea sketch gets you started in the right direction! 

I need to make a decision about deployment and security of some SSRS reports and would like some advice on what the most appropriate method is. We have 40+ sites that have access to information for only their site. Each site has access to a number of reports, say Report A, Report B, etc. For each site, the report name is Report A - Site 1, Report B - Site 1, etc. For each report (Report A), there is a Master report (Report A - Master). The Master report is the report itself - dataset and formatting - and includes a hidden parameter for site name. Each sites' report links to this Master report and passes in the site name. Thus if the report changes, the change is made in one place. Please note that limiting the reports to site-specific information on the database is not possible. Our data source uses a service account and all users access to the information is handled in the Web Portal. Now it is time to grant users access to these reports. Currently it is set up that all of the reports and the master reports are in a single folder. Access is controlled on each report individually and users must have access to the Master report as well as their site reports. I would strongly prefer to set up a folder for each site and control access that way. Obviously that would make it easier as site-specific reports are added, and it's superusers who will be controlling access. My concern is this will make deployment of reports incredibly difficult. Because of the linked mechanism, all 40+ versions (plus Master) are in the same BIDS project - and it seems like a nightmare to deploy to 40 different locations for every change. I would like to know if anyone else has had a similar challenge and found a good way to solve it. I have played around with linked reports, but then the site report can't "find" the Master report, even if a linked copy is placed in the same folder. EDIT: To clarify, and use the exact terminology, the Master report is a sub-report of each site report. 

I am fairly certain that it just looks at the third decimal digit... and that's 4 so it rounds down to 1.28. Clarify - it looks to the digit one greater than what you are rounding to... so it looks to the third because you are rounding to the second. 

That would be really fancy, but I don't think it's possible. You may be able to constrain the width of your bars of the chart and the width of your columns in your table as well as the placement of both to "fake it" though. 

Is it possible to set up an SSRS e-mail subscription, with an attachment, that is encrypted? POST ANSWER-ACCEPT UPDATE: Does the SMTPUseSSL switch in the RSReportServer.config file help me at all? ONE MORE UPDATE: No, the SMTPUseSSL switch does not get me there. I have validated the answer below here: 

I need to take some data from Table A, use some logic, and then insert one or more rows into Table B. I have a PLSQL block that brings in data from Table A with a cursor, performs all the logic required, and inserts the required rows. The problem is there are duplicate rows in Table B - it's the nature of the beast. But I need the final result to be a Table B with no duplicates. It's Oracle so temporary tables are bad form - what's the best way to accomplish this? 

I have a report in a BIDS project that has been deployed to our SSRS Web Portal. On the web, it renders within seconds. In BIDS, it takes upwards of seven minutes. I can see that the query runs against the database quickly - what in the world is BIDS doing that is taking so long? I have seen this happen in a number of different cases... 

I think only you can answer this question by testing out a few things. The SQL Server End recommendation you list are really just good query-writing practice. Whether or not you cache the reports depends on how live your data is and how live your reports must be. When I am trying to improve an SSRS report, I optimize the query (in SSMS) as much as I can (by limiting nested views and adding indexes when possible). 95% of the time, this does the trick. If it doesn't, I work with the user to come up with a caching strategy - or more specifically, we refresh the report execution snapshot overnight and just display that data all day long. This works well for reports we don't mind running overnight when the database load is low.