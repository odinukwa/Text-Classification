The problem could just be in the arithmetic. The two of you could both be utilitarians, even Utilitarians in the strongest sense of Mill's, but disagree on how important it is to an individual to be alive. To aim to maximize pleasure involves a theory of pleasure, and those can vary widely. You seem focused on social good, so you would attribute little utility to simply existing. An extreme form of this end of the scale would not even consider death to be harm, if it involves less suffering than the average death an individual could expect to encounter, since some death is a foregone conclusion and an improvement over average is a gain. Just existing has little or no value (or, in the 'Buddhist' case, may actually have negative value.) This measure of pleasure is very Aristotelian, and is partaken of actively. But many people look at the degree to which people are willing to sacrifice comfort or harm others for mere survival and assign a great deal of utility to simply being alive, perhaps accounting extra value for every person alive for every minute. Breathing is pleasant, and should continue. This measure of pleasure is very Epicurean, and is implicit in mere experience. Since nobody is psychic and we don't have a magic hedometer, we are free to have different theories of what pleasure is 'really like' and the notion of utility is rife with such problems. 

From this point of view my dog has intelligence and my computer doesn't, because the computer only defies me when it has been misinformed, and the dog defies me because he is of a species that has different basic agenda from mine, and on top of that, he makes decisions of his own. So there is an impasse between this kind of psychology and 'hard' cognitive science. People from a more mechanical orientation generally end up having a continual disconnect on vocabulary related to thought. They either have decided that all information processing is intelligence, or generated (to me) odd definitions that prevent computing from being thinking in ad-hoc ways. At the same time, this kind of thinking attributes intelligence to much more ambiguous objects like a group, a company, or a society, in that the individuals in an environment act as agents of the collective intelligence that only really exists in composite. (A group's members don't really individually believe the things the group decisively acts on, even in very conforming groups.) It also includes unconscious, 'primary process' thinking as thinking, in a way that is continually problematic, relative to those oriented toward neurology. (To me this is the Von Neumann question, and has been resolved -- virtual machines are real, and if we describe our hardware as software, no damage is done -- hardware, software and data are not truly separable to begin with. But it causes problems, nonetheless.) So both approaches kind of deviate from common sense. I also want to make clear that this is not a question about 'free will' vs determinism: In the extreme case, it seems that a species, or even the entire genetic process derives its own direction in a way that changes over time, and is not driven by another deciding force. Evolution solves problems, it communicates information (via DNA), and it directs itself. So, by my definition, it is intelligent, even though I can admit that I see it as completely determined. 

the kind of power one uses to control others as objects, regardless of their will; the kind of power one derives among people as subjects, in groups, through interdependence with others; and the kind of power one has whether or not others are present at all, through one's own capabilities and resources. 

Let's assume contrary to @shane that you have correctly expressed your real motivations. If your motivation is to be 'avant-garde' or to be contrarian, then you have a problem. Not everyone can be contrarian, and purposely flout the opinions of the majority for sport. Nor can everyone simultaneously 'push the boundaries' on purpose by constantly undermining popular opinion. We value those actions in a modern competitive society because they keep things evolving. But it seems clear that Kant would not. To play with expectations, with those motivations, is not universalizable. Knowingly disturbing people only for the sake of your own ego, or to improve some abstract process, is treating them as mere means. Especially because the people you are most likely to disturb are those who will not value the disruption, even if it does, in the end, improve their lives, or at least those of their progeny. If this is not a chosen motivation, and you like what you like in all honesty, there is no problem with being out of step by simply being yourself. Sentiments are not moral, according to Kant, so you are free to have what sentiments you have, as long as your motives and considerations are right. --- Here is a whole different framing for this argument, focussed on the questions raised in the comments. It is the same argument, just much, much pickier. It is called the categorical imperative to rule out arguments tied to contingencies. Theoretically, for Kant, every truly moral argument should be understood by any adequate intelligence, not just other humans, and he tried to analyze out the kinds of bases that an intelligence would have to have. If the intention cannot be put in terms of a certain sort, it is not 'categorical' and cannot describe a worthy maxim because it could not be translated into a usable form for a different kind of intelligence that recognized a different range of contingency. There are huge holes in his analysis of what is and is not a category, or how exactly categories should be combined into a maxim if other intelligences do not necessarily have languages. It is one of the primary weaknesses of the resulting ethics. But there is an idea that we should be able to develop an intuition for what is and is not adequately general, even if Kant's attempts to do so are either too hard to understand or too incompletely expressed for most of us to use them. It is clear that sentiments don't qualify, so yearnings, insecurities or other motivations for winning can't be an important part of a moral argument. Neither can natural human desire for a given outcome if it is just an emotional position contingent upon our humanity. But 'beauty' does qualify. Doing something with others well is a form of beauty, even if that thing is competition. So it is probably universalizable to say that if you join in a communal endeavor, you should intend to do as well as possible. Everyone can apply that to their own behavior. So to the degree that choosing beauty is done competitively, we are all still fine with most forms of competition. Cultivating and recognizing originality could also be an important aspect of beauty, especially if variety multiplies the opportunities for beauty itself. But in this case, the approach to finding originality stems from rebelling against the status quo. Were it universalized, the status quo against which one is rebelling would cease to exist. Like 'truth' in the classic Kantian argument against lying, defying standards dissolves the opportunity for standards to exist long enough to be defied. So we would lose the ability to follow our maxim if we agreed upon it. 

(First of all, at the risk of being a bit catty, to some degree isn't all of Nietzsche, Nietzsche on Nietzsche, especially in "The Gay Science"? Even when he is addressing global issues like the overall development of moral sentiment, or the nature of Greek drama, or how post-Classical music really ought to be, everything is introspection, or his insight is so quirky that his interpretation of otherwise objective facts is really about him.) As I read "The Gay Science" the most painful problem for him in a lot of places seems to be a wavering commitment to being outside the race and desperately wanting to work an effect upon it from within. (The pain is palpable... unless I am projecting it onto him.) To put it theoretically, there is an issue in his model of what the herd is, as to whether there is any possible continuity upward from the noble alpha leader of the herd to the independent creator free of human baggage. If there is one, Nietzsche is vying for it. And he hates himself for doing so, since he has gone so far as to say the herd-bond is something that must be overcome. If he gets what he wants, he is theoretically wrong. (His greatest dangers are in compassion.) He wants a transfiguration of values, but he seeks for such a thing in a natural history: The Genealogy of Morals, and leading forward from there would be choosing to be driven and shaped by social forces so as to be able to capture the intelligence of those around him. (What he loves in others are his own hopes.) But by his more raw logic a la Beyond Good and Evil, he should more highly value a deeply personal perspective that would uniquely express his distance from those same forces. ('You should become who you are.') (To address the issue with the word 'nobility': Nobility has a 'peerage', a standard that allows it to be respected in a social context by others who are similarly noble. This definition of heroism is personal and individual. This kind of hero may very well not be noble. He basically cannot be noble if his remapping of values is entirely unique. So Nietzsche has the Groucho-Marxism problem in reverse: He himself wants to be noble, whether or not he should be by the standards of any peerage he would choose to validate his nobility.) So there is a constant pain of pursuing the greatest calling he can tolerate, knowing there are theoretically greater challenges, which might even be easier to overcome, but those would not answer to his need. And of course, that pain is there only because of his own self-imposed morality, which may or may not have any real value, if he has to struggle both for and against it. Those two sides (continuity and jumping forward / nobility and freedom from the good) may very well represent Nietzsche's suffering, and his hope.