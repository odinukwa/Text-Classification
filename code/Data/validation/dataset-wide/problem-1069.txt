In this example, we identify a party which can either be a person or an organization. This is based on a single, fundamental, unchanging characteristic - if the entity is a single individual or a group of individuals. A person can make a donation. An organization can make a donation. A person can vote. An organization can never vote. These things never change. With respect to voting, it may seem to make sense to sub-type the Person based on if they are a voter or non voter. But being a voter or a non voter has nothing whatever to do with who the person is. Instead, it has everything to do with the district in which they live. Therefore, we model a district entity type which may be the home of one or more persons. Likewise, a person must be residing in one and only one district. This approach solves the need to know who have made donations and the need to know who is and who is not a voter via naturally occurring information - where the person resides - instead of information we invented by declaring them a voter or a non voter - or both. With respect to a person being both a voter or non-voter, that is mis-leading. They could be both over time, but could never be both at a moment in time. Therefore you must decide if you care about the history of their residence or not. If you do, then you would instead create an entity type - say residence - to associate the person to the district in which they reside for the period of time they resided there. I suspect you don't care however, and thus you would simply update the person's information to show their new district. Either way, the approach is more intuitive than using sub-typing. This is why I prefer the barker-ellis approach of limiting super and sub-typing to only fundamental classifications. Handling Missing Information One thing does remain however where specialization makes sense. You say you have additional information to store about a person if they live in your district and can thus vote for or against you. In the approach I have given that information would be characteristics of a person regardless of where they live. You are just choosing not to collect it if they don't live in your district, and to collect it if they do. Therefore, for persons not living in your district, this information will be missing. There are two approaches to this. First, you could simply include those attributes for the person and leave them missing. In mySQL you would make the columns NULLABLE. That approach is simple, but if you ever want to write a query where you use one of those attributes as a predicate you now have to deal with the complexities of three value logic (3VL), and the fact that SQL does not implement its 3VL consistently. If instead you want to avoid 3VL, you can use specialization to create an additional entity type to hold the extra information only when it is known. A row is placed there only for those persons for whom you've collected the data. Now this doesn't avoid NULLs altogether as you must deal with outer joins, but you can avoid nulls if you chose to via coalesce. Naming the Specialization I would not call the new specialization entity type voter. It is pure coincidence that at this moment you aren't collecting the additional information because you only need that information for persons living in your district who can vote for you. What if in the future you do want to collect that information for other reasons? What if you happen to know that information anyway for someone who doesn't live in your district and don't want to just toss it away? What will you do if someone for whom you have collected the information moves out of your district? Do you want to delete that good information you collected? If you do, what if they move back? You will have to collect it again! Instead, I would call the table something slightly different like voter profile. This denotes the information pertains to the person as a voter, and that information absolutely describes additional things about them regardless of whether or not they live in your district. Conclusion I hope this approach gives you some additional food for though. To learn more about the barker-ellis approach to business modeling you can check out David Hay's Enterprise Model Patterns, and also Richard Barker's CASE*Method Entity Relationship Modelling. With respect to missing information, I would recommend you check out Fabian Pascal's paper "The Final Null in the Coffin," part of his excellent Practical Database Foundation Series, and also Date and Darwen's The Third Manifesto site where they have some great resources on various approaches to handling missing information without nulls. 

Each department has a name, an unique number, keep track of the start date when the employee began managing the dept projects, each of which has a name, unique number, store each employee’s name, SSN, address, salary, sex, and DOB. keep track of the number of hours per week that an employee works for each project. keep each dependent’s first name sex, DOB, and relationship to the employee. 

Can partitioning the table help reduce the completion time? Yes - if you have sufficient CPU and IO resources to achieve query parallelism and partition the table on a key that will result in a set number of partitions having a roughly equal number of rows in them at all times. This approach uses a principle of spreading the workload across the partitions much like a MPP architecture. The drawback of the approach is you lose the ability to perform fast switching of partitions for deletion of data. We have used this approach in a DB2 z/OS based billing system for 15 years, where our "orders" table is partitioned by a random account number that hashes between the fixed number of partitions (200). Our batch billing process uses query parallelism to spread workload between up to 32 worker threads and thus completing the query to bill 1/20'th of the accounts in 1/32 the time it would take if a serialized process were used on a non-partitioned table. Almost all SQL Server advice focuses on partition elimination for query performance and fast switching to achieve quick purge of inactive data and in most cases that is appropriate. But your question is a good one as it shows that there are edge cases where a different approach to partitioning can be beneficial. 

Of these, you identified all but the first one. This, along with the supervisor I mentioned earlier, gets into a discussion of roles which we'll postpone to later. Right now we are just trying to identify the fundamentals and I'd say you were right on. Associative Entities Looking at the relationships we have a few that are many to many. The requirements state that an employee can work on many projects, which are not necessarily controlled by the same department. Given that most projects have more than one member, we can safely assume this is a many to many relationship. When you have such a relationship on an ERD, it is perfectly acceptable to show a many to many relationship line. I typically only use the many to many relationship though if I'm not showing attributes at all. Since we are showing them here, I prefer to resolve the many to many relationship with an associative entity. Even if there are no attributes for the entity now, we may uncover some as analysis proceeds. However, in the case of employees and projects, we have attributes - the hours worked - that must be added for that relationship and so it must be resolved by creating the associative entity to show them. Thus we will create an associate entity called Project Assignment. But we are still not done. The requirement calls for us to know the hours worked per week. When you think about it, you realize there would be many weeks in the life of the project, and we need to record the hours worked by that employee on that project each week. Thus another entity type is required which I called Hours Worked of which there will be many occurrences per project assignment. This entity type will hold the week ending date and the hours worked. Next, by creating a location entity type, the requirement that states a department may have several locations means we now have a relationship where one department can have many locations. It is safe to assume as well that one location will have many departments operating there. Therefore I added another associative entity called Operating Site to show this. Find the Attributes The attributes were listed pretty clearly in the requirements with statements like: 

No, for the same reason as this violates 1NF. Again that column contains 2 different values and each column must contain only a single value to be in 1NF. Fabian Pascal's Practical Database Foundation Series is a great reference to dive more deeply into these fundamentals. Paper #4 addresses keys specifically. 

When Codd defined the relational model he defined a set of operators which could be applied to relations. In specifying a relational algebra, much like specification of an integer algebra, we are able to use symbols in place of relations to solve queries. These operators are subject to the same algebraic properties that integer algebra operators (+, -, *, /) are. As a result, we can assume certain laws that always apply to a relation, any relation, undergoing that operation. For example, in integer algebra we know that addition and multiplication are associative in that we can change the grouping of operands and not change the result: 

Similarly, in relational algebra we know that natural join is associative and thus know that A join B join C can be executed in any order. These properties and laws create the power to re-write query formulations and be guaranteed to get the same results. The book Applied Mathematics for Database Professionals provides significant detail on the various re-write rules you can use to precisely formulate the same query in different ways. In a perfect world any formulation producing the same result would have the same performance. A modern optimizer, while an amazing piece of software, isn't perfect however. Thus if you have formulated a query one way and are getting poor performance, you have the skills to formulate it a different way and know it has the same semantics. Another practical advantage to this is in the specification of database constraints. First, understanding the relational algebra enables you to determine the simplest way to formulate the constraint. Second, by formulating the constraint in formal logic, you can immediately clarify any ambiguity in intent from the business subject matter experts who formulated the business rule in loose English and avoid bugs. It was Leonardo da Vinci who said: 

Employee manages Department Department controls Project Employee assigned to Department Employee works on Project Employee has Dependent 

The basic operators of the relational algebra are indeed closed and thus when applied on relations always yield relations. Keys are irrelevant as by definition each relation has no duplicate tuples. Any operation that would result in duplicate tuples (for example the projection of a single attribute over the relation) by definition eliminate those duplicate tuples when providing the result. As you know SQL does not properly implement this. Long Answer In order to really understand the short answer, and to understand the addtional nuances that "outer join" throws into the equation, we need to delve into the foundations of relational algebra in number algebra. Number Algebra Algebra is "the part of mathematics in which letters and other general symbols are used to represent numbers and quantities in formulae and equations" as defined by google. One algebraic property is operation, meaning there are actions that work to change numbers. For numbers these are addition, subtraction, multiplication, division, raising to a power, and taking of a root. There are many other algebraic properties as well such as the associative property which states that you can group numbers in any way without changing the result of the operations. These properties give algebra its unique power, in that with these properties we can use letters to represent numbers, manipulate them via the defined operators in equations, and know the transformation will be absolutely correct regardless of what actual number is eventually substituted for the letters. Closure is another of the algebraic properties which states that if an operator which works on numbers always produces numbers then numbers are closed under that operation. Real numbers we know are closed under addition for example. Add any two real numbers and the result will always be a real number. Real numbers are not closed under the square root operation as the square root of -1 is not a real number. All of this comes straight out of the property glossary of the Math Forum @ Drexel. Relational Algebra Chris Date says that Ted Codd was a genius. Codd's unique genius was the realization that mathematical relations, combined with set theory and logic, would be very practical when applied to data management. Fabian Pascal's Practical Database Foundation Series provides an excellent explanation of why this is so, and I'll briefly review a few of his insights. One of the primary database problem of the 1960's was one where a program had to be written for each "question" you would want to ask of the DBMS managing the data. Codd showed that by taking the concept of a relation and adapting it for databases a logical model of data input and output could be developed completely distinct from how data is physically stored. Part of that logical model was the set of operators that would apply to relations - the relational algebra. Just like number algebra allows us to exploit the algebraic properties to manipulate massively complex equations where letters stand for any potential number and guarantee correct results, the relational algebra can do the same for relations. Why is this important? Because with algebra, operations and their results do not depend of what the relations and their attributes actually mean. Then, by adapting logic, which like algebra proscribes valid forms which can be used to evaluate an argument to be true or false regardless of what the propositions mean, a generalized query language can be implemented that enables a user of the DBMS to ask a true question of the data - one of arbitrary complexity - and the DBMS can be programmed using the rules of relational algebra to give a provably correct answer! Now just like with number algebra, closure is the essential property that gives the algebra its power. Relations are closed under the basic operators and as such you can arbitrarily nest these operations at will, in any order, to declare practically any "question" you could ever think of. Once the DBMS is created that implements the relational algebra, unique programs no longer have to be written to find the answer to each question. The DBMS user simply declares the question using the relational algebra. Outer Join Thus far I have been saying basic operators. That is because the theory does not account for missing data. Each relation by definition contains tuples with a value for every attribute. But to adapt the mathematics to the practical realities of missing data some solution has to be developed for when an attribute value is unknown. SQL implemented the NULL and 3VL. Codd later proposed marks and 4VL. The join operator had to be extended to preserve un-matched tuples, and SQL implemented the extension by producing NULLs instead of values for the attributes of un-matched tuples. Date shows that by doing this outer join is: