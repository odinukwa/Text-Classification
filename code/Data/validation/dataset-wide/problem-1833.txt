That's one of the standard ways to specify the umask for Apache in CentOS. If your init script (/etc/rc.d/init.d/httpd) sources the /etc/sysconfig/httpd file, either the umask is not specified or something is overriding it. How are the files being created? 

It looks like you may have attempted to configure php to be executed as CGI. This would not be the ideal implementation for PHP. Do you have handlers specified? Is the module loaded? If you provide your full configuration file, we should be able to help you. 

Have you looked at LVS? It will meet most of those requirements. You might have a more difficult time finding a solution for tcp session failover but I've not sought that specific requirement before, as my application architecture could reasonably handle failover without it. 

Most positions centered around reviewing audit trails and logs are security analysts or administrators of various types. In IT, the responsibilities are security focused and it's usually entry to mid level positions. 

I'd recommend updating the revision control repository directly on the server itself. I keep most of my production configuration on an infrastructure repository. It sounds like you are attempting to over engineer the solution. Don't use symlinks, have them use SVN in the arbitrary locations. 

dnscache is literally that: a DNS cache. If you wanted to specify (forward resolution) records for a domain under your control, you would need to run a full-featured DNS such as BIND or djbdns. To respond with an IP when a NXDOMAIN response is sent, you would be breaking the RFC. NXDOMAIN rewriting is a controversial practice that is not recommended and generally not supported, as it breaks the RFC. Neither djbdns nor BIND have native support for this. From what I understand, there are only commercial solutions currently implementing this. This includes Barefruit and several others. This is an interesting post from a mailing list where someone who appears to be Keith Mitchell, the ISC Director of Engineering, states that he doesn't want to introduce support in BIND. If you have a legitimate need, we might be able to be able to offer you an alternative technical solution. 

I've found that using load balancing is my preferred solution for introducing high availability to Web servers. There's advantages for staging code deployments, not idling available resources, and introducing redundancy. LVS is my preferred solution there. Others seem to like Pound and I'm also intrigued by HAProxy. With LVS, configuring a ldirectord server and using arptables on the Web server can be a straight-forward implementation. You can prevent single point of failure with LVS by having an active/passive server implementation with failover using heartbeat. Now, if you're shared hosting selling accounts, introducing high availability with automatic failover is going to be more complicated. With this, you might have to consider a redundant storage solution that multiple servers can access and configure an active/passive server using heartbeat. DRBD seems like it could be useful here. You can implement complete high availability solutions with no single point of failure using entirely open source and commodity hardware. If you want additional recommendations, I would be happy to help. This is one of my favorite areas to focus in. 

Assuming your friend uses Windows, have them use WinSCP to access your server via SSH. Accessing user accounts via an unencrypted protocol is a security risk. If you do not know how to connect to the server, perhaps you should contact the administrator of the server or support department of the ISP providing it. Putty is a good Windows client and most UNIX based operating systems include SSH clients by default. to add an account. Read the manpage. to set his password. Read the manpage. to create a group. Read the manpage. to add your username and their username to the group. Read the manpage. to change group ownership on the web tree. You can use the commands below here instead of the next chmod commands and any other directory within that tree to make default ownership be groupname on permission, which will allow you both to work there. Then, make group writeable: 

Once you determine the query at fault, you can consider the best method of remedy be it simply tuning the query, creating an index or perhaps even pruning the data set. Architecture has a significant play on this type of scenario as well. OLAP queries are best done on secondary databases and not the OLTP database. 

If you want to review IT fundamentals best practices in detail, you may find the Practice of Systems and Network Administration to be a good reference. If you want to read further about change control, you will likely find ITIL to be a useful reference. I would be happy to go into further detail if there are particular areas that you are unclear about. 

I've yet to use cellular network solutions and have reasonable success with cellular e-Mail gateways, however I do plan on looking into implementing one of these solutions. They look to be really useful. 

I absolutely avoid cascaded switches whenever reasonably possible. Unless the clients are absolutely controlled, such as a thin client with limited functionality, it's only a matter of when it will be an issue. This is especially true within the core network or the network infrastructure that supports the servers. When working with purely workstations, you have a little more leeway. Many of the other points here are fantastic, as such I will not reiterate them any further but I do encourage you to consider them. 

I typically would use a CIFS share and a cronjob. Mount the SAMBA share on the UNIX server and put a bash script in cron to utilize it. 

Edit Check out /usr/src/linux/kernel/Documentation/kbuild/kconfig.txt (or appropriate path). You can use some of their recommendations to script a solution. I would use a combination of scripting and textutils to accomplish what you describe. Edit 2 As an additional note, this is a bad idea. What if optional hardware support unique to your environment changes but isn't default? What if a negatively impacting changes occurs? This really is something that should be interactive. You can make the config and automate the rest. "make silentoldconfig" is a little less verbose, which might be helpful. It is still interactive. 

If you do not know how to build one, you will need to purchase a network device (router) capable of load balancing between multiple ISPs. With inbound traffic, one solution would be to use a dynamic routing protocol such as BGP. With outbound traffic, a solution would be to failover a VIP between multiple devices using a protocol such as HSRP. If you do not have the knowledge or resources available to build a more robust solution, you could seek a router capable of handling multiple WAN connections. You will likely find affordable SOHO equipment able to serve your needs. It is important to realize this router is going to be a single point of failure unless you introduce redundancy. Another option would be with a single server, you could potentially introduce multiple routes with different metrics. 

The location where the MySQL named pipe is created can be specified in the with or via the flag on server start up. If your socket is not located in , which is the location that was specified for the client when MySQL was compiled, you can specify an alternate location with the flag. Otherwise, if is not specified in your , you can connect using TCP/IP instead of the named pipe by using the flag and then the IP address with the MySQL client. 

Basic troubleshooting. Eliminate equipment. Internet connection directly to PC. If reproducible, a different PC. Replace modem, try different ISPs (cell modem). Keep on going down the line until isolated then troubleshoot the equipment it's isolated to. 

Most modern distributions and processors support PAE, which is Intel's instruction set allowing memory addressing beyond the 32-bit limitation. PAE allows a maximum of 64GB of RAM to be accessed by the processor. PAE has additional CPU overhead. 32-bit Linux has a per process limit of 3GB addressable even with PAE. Typically, the kernel reserves approximately 1GB. MySQL is a single process daemon. As such, it will be unable to address outside of the 32-bit limitation even with PAE. Some useful references: 

You would be better off waiting for the official package, creating your own, or compiling from source. 

Here's a quick bash snippet that should do the trick for you. I'm making an assumption that everything in that is a directory and matches is a site where you want to replace and . If this logic is not suitable, you might have to make some modifications yourself. I have tested it within limited constraints. Make sure that the output in FreeBSD has the user in the third field and the group in the forth field. Also, is a GNUism. You might have to use or the BSD equivalent to force replacement of an existing file without interaction. 

Have you found the MySQL documentation? It's extensive and useful. When you run against InnoDB tables it outputs the message. From the documentation: 

Depending upon how you dumped the database(s), you might have to drop before sourcing the file. Be careful. 

Typically, Web servers would go in the DMZ unless for an unusual reason they contain restricted or confidential information. Databases typically contain that data, which go in a more restricted subnet. Often, modern DMZs are an internally reserved subnet. You would have a firewall on the edge network, which would provide NATing to that subnet. What I describe is a dual firewall configuration. SSL certificates would be acceptable on the network segment where the Web servers live. I typically lean towards encryption whenever reasonably possible unless there's another consideration at the time. I would use a CA signed SSL certificate in all cases that you describe. 

is a common location for the QMAIL logs. You want to look at the logs for qmail-send, which will display the reason Yahoo is rejecting your e-Mail. 

If you are looking to log output in case of a kernel panic with Linux, is the way to go. This is what Red Hat trains people to use and what I have known to be the standard approach. 

For client access, it's a great recommendation as opposed to sending plaintext database traffic via the Internet. You'd also risk the authentication data. The overhead is no more than any other SSH session. For application access, I'd recommend MySQL over SSL instead. 

I like Cisco managed switches. If cost is consideration, as it seems to be, you might even reconsider why you want a managed switch. You can have multiple physical Local Area Networks. For example, you buy or build a router and have it route the traffic between several switches. That's how everyone used to do it before VLANs. I have the hardware lying around to do this now, maybe you do too. 

Mounting the filesystem with specified in fstab would probably help. I suspect someone will have a recommendation better suited for your particular application. I begun initial research on filesystems used with flash storage, as I want to custom-build a home theater PC as an appliance. You may find a different storage solution better suited for your device. Unfortunately, I have yet to find something I prefer so I do not have a detailed recommendation there. Edit 1 According to the smb.conf(5) manpage, it supports immediate syncing within SAMBA: 

No Linux distribution has any distinct technical advantage for running a Java application stack. The two main issues are going to be your familiarity with the distribution as well as what the vendor officially supports. If you want official support for your Java application server and the vendor only officially support specific distributions, you want to choose from their list. 

You're going to have a hard time finding a distribution dedicated exclusively to e-Mail, as there's not much point when you can simply install the software on top of any distribution. QMAIL Toaster is a software collection meeting your specifications. 

This reply is primarily to espouse the benefits of properly maintaining access within your IT department. Your situation examples the benefit of an audit trail and proper access control. For example, all access would require an access request ticket with approval, without exception. Upon termination, you audit the ticket system. For common roles within your company, the access can be standardized and even easier to eliminate. For IT roles, we have a spreadsheet that we work out of for terminations. It lists everything to prevent oversight. We also audit our access request tickets and our work logging system, as all production changes are documented there. Administrators should also have individual user accounts, which they use to access administrative privileges. root and administrative accounts should not be authenticated to directly. While this is not technically infallible, it enables an audit trail as well as individual accountability. With this, locking all his accounts would be a first step and then you change all admin accounts. If you have not already, I would encourage you to implement some of these solutions if not all of them. I consider them integral and it reduces risk when an involuntary termination occurs. First, remove all external facing access. Any access the person could use without being on premise. Then, change all passwords. Every administrator password, every system password, every application password, every vendor account password, every support account password-- everything. If the risk for retaliation is great, you might expire all employees' passwords as well. Since you do not have the root passwords to the Linux servers, you can boot in single user mode and change it. With GRUB and LILO, you would simply append . The methods are similar. As others have recommended, audit all crontabs (located in /var/spool/cron), system users, running daemons, ssh keypairs, and the systems in general. While rebuilding is the only way to be certain, it should not be necessary in most cases. Any respectful professional would not risk their career on such a guttural reaction. It would also enable pursuit of both criminal and civil damages by your employer. Ultimately, I would suggest having a serious discussion regarding the risks with your manager after performing due diligence with removal.