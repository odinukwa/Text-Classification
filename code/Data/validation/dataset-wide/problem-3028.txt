This isn't true: there are several algorithms which use probabilities and randomness but achieve exact final results. See Monte Carlo methods and Las Vegas algorithms. Randomized algorithms have many applications. One example is Quicksort. More generally, optimization and search problems benefit from randomization and probabilistic approaches, since they are computationally hard, and the only deterministic algorithms to solve them are brute force searches which have to go through the whole solution space to find the answer. Most programming languages, Python, R, C++, etc... included random number generators, which can be used to insert randomness into and algorithm. 

The point he is trying to make is a subtle one. Since the beginning of the 20th century, philosophers of science have been trying to come up with a definitive way of separating science from pseudo-science and mysticism (See this post). This is know as the demarcation problem, and none of the solutions so far have been successful. Quine is arguing that it is not possible to do so, because no matter how scientific and empirical an explanation gets, it is still based on our language, which is a cultural artifact, not a brute fact of nature. Consider the following: An ancient Egyptian observes the sun's movement, and proposes a theory that its movement is due to the god Ra's Sun Boat. A modern scientist observes it and proposes a theory that it is moved by mysterious force called gravity. In both cases, the only thing that can be observed is the sun's movement, both the god Ra and the force are abstract entities which cannot be observed. Both the Ancient Egyptian and the modern day scientist have to resort to unobservable metaphysical objects for their theory to be meaningful, otherwise they don't have a theory, they just have a bunch of observations. The concept of force seems more "rational" to us only because we have gotten accustomed in Western culture to concept, but to a truly neutral and empirically minded observer, the idea of a mysterious unseen vector pulling the sun through the sky is just as outlandish as a god on a boat. Both are cultural artifacts. This is not to say that Greek, Egyptian, Nordic mythology are on the same footing as modern science, Quine is clear in that. Quine wasn't a mystically inclined person trying to bring mythology back to the same level as science. On the contrary he was a materialist, mathematically inclined logician. Modern science produces far better results than mythology in terms of being able to predict reality accurately, and one would be stupid to rely on mythology (or astrology, or faith healing, etc....) instead of the latest scientific theories in predicting reality. But that improvement in accuracy is the only difference, we have no other way of separating science from mythology. Quine's point is that we cannot separate theories into science and non-science, only into good science and bad science. 

No. Even if entanglement is proven, we can still have non-locality and non-determinism both at the same time. See this paper "An experimental test of non-local realism" . From the paper's abstract: 

I have read this book. Although dedicated to more than just the philosophy AI (it covers other topics in CS besides AI), the chapter on AI was very readable. $URL$ Given your background, you probably would like the whole book anyway. On the other hand in does get technical in places. It doesn't necessarily require any training, but it is not for the casual reader. 

Alvin Plantinga provided a solution (or what he called a defense) to the problem of evil based on the value of freewill. Assuming one believes in God, the problem is how to reconcile the apparent contradiction between the fact that God is omnipotent, omniscient and benevolent on one hand, and the existence of evil in the world on the other hand. Plantinga's defense (called a defense because he purports to show that there is no problem, as opposed to trying to solve the problem) is the following: 

Kuhn classfies science into two phases: periods of revolutionary science, where theories themselves are being challenged (for example when Newtonian mechanics was being supplanted by quantum mechanics), and a period of normal science, where researches accept a given theory and focus on confirming and working on its details (For example physicists subsequently fleshing out the details and consequences of QM). From the SEP article on demarcation: 

It might be that it is considered more the domain of psychology, sociology and anthropology, not philosophy. 

Philosophical Zombies are a thought experiment that is used to argue for dualism and against functionalism. The argument goes something like this: 

The processes are similar in principle, the only difference is the degree of accuracy, i.e. it is a quantitative difference. Yet they are considered to be entirely different qualities of evidence: The witness's reliability (even assuming good intentions) will be questioned and disputed by any prosecutor or lawyer. The digital photos will not be disputed in most cases, and would require an image processing specialist if they wanted to make the claim that it was digitally tampered with or photoshopped or something. 

The point here is that any set of true facts about the world can always be reconciled with a given theory, as long as you are willing to include additional hypotheses and assumptions to bridge the theory with the fact. So to answer your question: Yes, logic can be used to prove any belief, as long as a person is willing to add additional assumptions to support their belief. So then, how can one settle such arguments? 

More of an extended comment than a proper response: The original definition of thinking as information processing and symbol manipulation Ã  la Turing was fine until functionalism came along and people started to see the metaphysical and ethical implications that it implied. Then they started moving the goal posts just because they were uncomfortable with the fact that humans lost their privileged status as the only thinking beings. "so language and logic won't cut it anymore." is more an expression of people's fears and insecurities than of a better understanding of human mental processes. I would take your definition, and add a constraint that the data processing should at least partially involve symbolic representations which mirror the world in a way similar to Wittgenstein's Picture theory of meaning. This way a bacterium following chemical traces of nutrients isn't thinking, but a cheetah running after a gazelle is, giving that there is some homomorphism mapping the gazelle onto its neural patterns or memory states. This also allows us to say that advanced computers do some thinking but watches and light switches don't. 

Now my reasoning is the following: A weak agnostic can assign likely hood to each outcome (theism vs atheism), since her position regarding the question can change over time. It is conceivable that at some point Pascal's criteria doesn't hold, since although she still thinks it is possible that God exists, the likely hood is so small that that she stands to loose more by believing than by not believing. Implicit in the strong agnostic's point of view is that both outcomes are equally likely, since no information gain or loss on the question is ever possible. If both outcomes are equally likely, then Pascal's argument of loss vs gain stands, and a strong agnostic should live as if she believed in God. Does this reasoning make sense? Should a strong agnostic follow Pascal's advice? 

Qualia is the term to used describe actual subjective experience and sensation, as opposed to mere knowledge and information. The concept is best described by Frank Jackson's color blind scientist thought experiment: A scientist knows everything there is to know about the color red from physics, optics and neuroscience, but is color blind, and so she doesn't know what it's actually like to see the color red. If we then somehow repaired her vision so that she can now see colors, and let her see the color red, she would learn something new about red that she didn't know before, despite all of her previous knowledge about the physics and biology involved. This additional knowledge she gains is the qualia of seeing red. What I don't understand about qualia is that they are consistently presented in every philosophy of mind source I've come across as an argument for dualism and against materialism/physicalism. Somehow, the existence of qualia is seen as proof that there is a non physical dimension to the mind (i.e. dualism), since if the mind where purely physical, there would be no difference between knowing about the color red and seeing the color red. Frank Jackson, Thomas Nagel and many others argued that qualia is definite proof in favor of dualism. David Chalmers called this the "hard problem of consciousness", the fact that philosophers have not been able to explain qualia in terms of physical brain processes. I can see why the existence of qualia is an argument against functionalism or against the computational theory of mind: if the mind was just a fancy computer with functional states, it wouldn't matter whether knowledge of red came from other systems (learning about red through science) or direct sensation (seeing it with one's own eyes), the mental state "knowledge of red" would correspond to the same functional/computational state. The existence of qualia proves that the two states are different, and hence disproves functionalism. But I don't see why it is an argument against physicalism in general. If anything it seems to me like the existence of qualia is a solid argument for the type identity theory of mind, (which is a more radically physicalist position than functionalism since it denies mental states any independent existence at all): knowledge about red is different from actually seeing red not because of any dualist mental substance, but because they correspond to different neurons firing in different parts of the brain. This would confirm type identity theory exactly: knowledge of red corresponds to one brain state and the sensation of red corresponds to another brain state. The sensation of seeing red, the actual qualia, is not multiply relizable, hence qualia are an argument for type-identity, and against functionalism, not in support of dualism. My questions: 

The mind-body problem is essentially the question of whether mental states and events are fundamentally different from brain states and events (the way light and sound are different from each other, even if they go together sometimes) - or are mental states and events just different aspects of the same thing (the way musical notes and frequencies are different ways of describing sound waves). Mind-body interaction doesn't become part of the problem, unless you've answered the first question already with "mental states and brain states are different". "If so, then how can something non physical influence something physical?" The mind-body problem can be considered an issue for dualists only, because many dualists assume the answer to the first question and head straight to the second. 

Now for the answer: simply put, No. Your being, being in all space, is equivalent to saying that a Turing machine has infinite tape. Being in "all time" would be hard to define, but I am going to take as either meaning that the Turing machine is non-deterministic, or it is an Oracle machine. Either way, there will always be problems a given Turing machine cannot solve. Increasing the amount of tape available or allowing for non-deterministic processing allows for greater speed in solving problems, but doesn't increase the scope of which problems a given Turing machine can solve. Even assuming for a magical Oracle that can retrieve an answer with perfect accuracy, there will still be problems a Turing machine can't solve. This a result of the halting problem and the limits of Turing machines: For any given Turing machine, there will always be undecidable problems. Even If you take a Turing machine (deterministic or not) and add an Oracle to it to allow for it to answer questions immediately using that Oracle (for example by providing it with an Oracle for the halting problem), there will still be a class of problems that it cannot solve. If you add a super-Oracle for solving those problems as well, you will face a new set of problems that the new system (Turing machine + Oracle + Super-Oracle) problem cannot solve. This leads to a hierarchy of problems called the arithmetical hierarchy. There are those that argue that super-Turing computation might be possible, but that stance is not accepted by most computer scientists and mathematicians (see here and here). You will find many philosophers who might argue for the possibility of hyper-computation, but that usually leads to metaphysical proportions, which I said at the beginning of my answer make your question unanswerable. 

This is the same conclusion that Wittgenstein and others arrived at. Wittgenstein started out as holding views very similar to Carnap and the Logical Positivists: Logical statements and empirical statements are the only meaningful statements. But then he abandoned those views and in his later philosophy subscribed to the view that meaning is use: Statements derive their meaning not from the way correspond to empirical facts, but from the way we use them. The term "unlucky" is used in a certain way when we communicate and that is enough to give it meaning. See Ordinary Language Philosophy and Pragmatism. 

In the scenario you mention, the person is not justified in his/her belief, so the situation you are describing would count indeed as deception. Consider the following real world scenario: A sick person is sold a medicine that will cure him from his aliment. The medicine is indeed effective, but the person who sold him the medicine said that the medicine works using the Jedi Force. Clearly the sick patient is not justified in believing that he was cured by the Force, and the person who sold him the medicine unambiguously deceived him, by causing him to hold this false belief. A closely related issue you might want to examine, is Gettier's problem, which shows that in some cases, a belief can be justified and true, but still not count as knowledge. 

Positivism is a form of empiricism, and as such, is antithetical to rationalism and Plato's theory of forms, and eventually with any system that asserts the existence of a reality independent of and beyond the senses. More recently, in the 20th century, several schools, such as phenomenology, existentialism, sturcturalism, postmodernism, and (unsurprisingly) anti-positivism, were all seen as having positions in opposition to those of positivism in general and logical positivism in particular. 

Ship of theseus and the 4 rat brains experiment are different but related concepts that both challenge the concept of personal identity, especially in the context of the bundle theory. The 4 rat brains experiment might be seen as supporting the bundle theory of the mind. However, if one takes into account the idea that the brain is a computer and the mind is the software, there are limits to how one can divide and add mind and still always end up with new minds/personalities in the process.