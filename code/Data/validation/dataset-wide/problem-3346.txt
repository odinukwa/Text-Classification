References tell me that the term 'verb' originally means 'word'. This is easily understood by usages such as 'verbal abuse', 'verbal agreement', 'he's very verbal', etc. That said, of all the various parts of speech, the term 'verb' is reserved only for a single part of speech. Technically, other parts of speech such as 'noun', 'adjective', 'preposition' are all 'words', are they not? Then, why would you use this term 'verb' (originally meaning 'word') only for this particular part of speech that we now call 'verb'? I was just wondering if there has been any meaningful discussion about this issue in the linguistics community, and if so, could someone tell me the outcome of any such discussion and/or point me to any relevant literature? 

In this wiki on "Subjectâ€“verb inversion in English", there are two approaches suggested to dealing with subject-verb inversion. 

Which, according to the article, causes confusion as to what exactly the term predicate mean, and some grammarians came up with a new term "predicator" specifically for use (2), says the article. No problem thus far. What bothers me: The article in its explanation of (2) says, "Other function words -- e.g. auxiliary verbs, certain prepositions, phrasal particles, etc. -- are viewed as part of the predicate." (Emphasis mine.) Now, remember this definition of the predicate, i.e., (2) above, corresponds to the new term "predicator". I understand that auxiliary verbs are part of this definition of predicate, because an auxiliary verb can be part of a verb cluster. But so can certain prepositions and phrasal particles? The article has these example sentences (Words belonging to "predicate" (2) are boldfaced as in the article itself; My comments in parentheses.): 

In Dependency and/or Constituency Grammar, I think you get the same tree diagram for Sentence 1 comprising Subject - Verb - Object (I hit him.) and Sentence 2 comprising Subject - Verb - Predicative Complement (I am angry.). Am I right? If so, how come you end up with the same diagram for two different structures? For examples of tree diagrams in Dependency Grammar and Constituency Grammar, here's an image borrowed from this Wikipedia article: 

I'm no linguist and I'm unaware of the recent development in linguistics, let alone all the past developments, but I know some of the past developments at the very least, so I'm asking this question to anyone who is well versed in the current linguistic development. (So if you're not familiar with the recent development, please don't bother to downvote this post or answer my question simply because it doesn't make sense to your traditional linguistic knowledge. Not that I really care about this post being downvoted or even being cluttered with boring answers, but that I'd really like to know if there's anyone out there who can think outside the box without getting carried away with the box itself.) BACKGROUND As far as I know, there is a well-known distinction between a grammatical subject and a logical subject. The former concerns syntax, the latter semantics. The two subjects sometimes are the same as in: 

In the latter example of John went home, it seems, the predicate is went home whereas the predicator is went, home being an adjunct and thus not part of the predicator as defined. Now, I looked further in this wikipedia article to better understand the difference. The article recognizes two competing notions of the predicate in theories of grammar: 

In most grammars, an adjunct is differentiated from a complement in that the former modifies something whereas the latter complements something. But is it really the case that what an adjunct does is modify something? For example, here are a couple of sentences from CGEL (page 222): 

Machine learning equipped with artificial intelligence is looking very promising in the field of machines understanding various human languages including English and translating one into another. I'm no expert in the state-of-the-art machine learning algorithm or anything like that; all I know is that some kind of a statistical model is used in the process, and also that the current state-of-the-art technology is not perfect yet. So, my question is whether machine learning still could use a better linguistic theory to make some more breakthroughs that would eventually allow A.I. to perfect its language acquisition and translation expertise, or whether all that needs improving is more computing power and more sophisticated statistical models. 

Here, both the subjects are "I" and no other. But sometimes, depending on whether we want the former or the latter, we might get a different subject in the same sentence. Please see the following dialogue between A and B: 

As far as I know, the first auxiliary is normally treated as the head of a verb phrase (VP) in the X-Bar theory. 

QUESTION Except for the last one, which I suspect is a typo, I'd like to know whether the preposition in and the particle up belong to the predicate as presented in (2) and thus belong to the new term "predicator". 

But neither is perfect, says the wiki: In approach (1), "one has to assume movement (or copying) on a massive scale." In approach (2), "this analysis does not capture the obvious dependency between the main verb and the inverted subject." I'm not quite sure what the latter exactly means, but this sounds like a drawback of the second approach. (Please enlighten me on this as well in your answer.) Now, what if a verb phrase (VP) can be defined to include a subject? Then, I think we should be able to analyze subject-verb inversion without (1) assuming movement (or copying) on a massive scale or (2) failing to capture the obvious dependency between the main verb and the inverted subject -- whatever that means. 

For example, in these two sentences, "on the floor" is an adjunct of the verb "slept" whereas "on my mother" is a complement of the verb "relied". Now, is the tree diagram of (1) any different than that of (2)? 

In A's line, the grammatical subject is "There", as shown in a counterpart interrogative "Is there chaos?" (the subject-auxiliary inversion), whereas the logical subject is "chaos" because A is not talking about "there" but "chaos". Now moving on to B's line, both the grammatical and logical subject are "I" under the traditional definition of these terms. And they say that "That" is the object of the verb "know" and it is simply placed in front of the subject "I". Right? (If this is not what is normally accepted, please let me know.) QUESTION Is there any new development in linguistics that considers "That" in B's line the subject, be it the grammatical subject or the logical subject or some new kind of subject? Because, syntactically, "That" occupies the position of the subject, and semantically "That" is essentially what B is talking about. EDIT Oxford Dictionaries Online has this definition for "subject": 

In Constituency Grammar (CG), I guess that you would consider "Me" the subject and "too" the predicate. Hence, no problem drawing a tree diagram out of "Me too" in CG. On the other hand, Dependency Grammar (DG) assumes that there's at least a verb, with which it starts the parsing process. Then, how do you draw a DG tree diagram out of a verbless clause such as "Me too" when there's no verb to start the process with? EDIT I guess a more general question would be something like this: Perhaps the most important difference between CG and DG is that CG first divides the sentence into the subject and the predicate, where the latter may or may not contain a verb. So not having a verb is not a problem in CG. On the other hand, DG starts with a verb. So, if the sentence lacks the verb, where does DG starts its parsing process with? 

The 'function' of 'noun phrase' discussed by most dictionaries and grammars is its syntactic function, which, as is shown above, can be quite messy and therefore doesn't really help neatly define 'noun phrase'. Fortunately, there is another function of 'noun phrase' that is not syntactic. In any given sentence, 'noun phrase' refers to something, be it concrete or abstract or animate or inanimate. For example, in [6i] above, the doctor refers to a specific person who was a doctor and was being talked to by me. Similarly, in [6iii], the day before yesterday refers to a specific day when Fred arrived. And so on. In essence, what a noun phrase refers to in a given sentence can be any concrete object(s) or any abstract concept(s) or any animal(s) or any inanimate thing(s). If you're to use a single term to describe what a noun phrase can refer to in any given sentence, what can it be? Please note that that term should be able to encompass "any concrete object(s) or any abstract concept(s) or any animal(s) or any inanimate thing(s)". I was thinking about 'object' and 'thing', but the problem is, 'object' has the nuance of excluding abstract concepts, and 'thing' has the nuance of excluding animate objects. *The Cambridge Grammar of the English Language by Pullum (p 327) 

Here, the adverb phrase (AdvP) remarkably well is a complement of treated us in [i] and an adjunct of carried out all the duties in [ii]. But does the AdvP in [ii] really modify carried out all the duties in any way, shape or form? All it does is simply describe the manner in which she carried out all the duties. It doesn't modify even slightly the fact that she carried out all the duties. In fact, modify something is what the AdvP in [i] does to treated us, the meaning of which would be different without the AdvP in [i]. Therefore, I believe that the terms modify/modifier/modification should not be used to describe the function of an adjunct, because these terms actually describe the very function of a complement such as the AdvP in [i]. So, I was wondering why grammarians would even use these terms modify/modifier/modification when they describe the function of an adjunct. Am I missing something here? EDIT Thanks to StoneyB's comments, I've gotten to know that the word 'modify' used to mean 'limit, restrict' when first adopted as a grammar term, and that that meaning has been mostly bleached over time. Since 'modify' mainly means 'change or alter' in the present-day English, I think it'll inevitably lead to confusion when the same term is used in grammar not as 'change or alter,' which describes what complements do in grammar, but as 'limit, restrict', which describes what adjuncts do in grammar. Considering this confusion, why not abandon the term 'modify' altogether as a grammar term? Or am I the only one who thinks this is unnecessarily confusing? 

Applying this definition to B's sentence, "That" can be considered "a noun functioning one of the main components of a clause", and the rest of the clause "I know" predicated about "That". 

In this sentence, for example, the first auxiliary, was, is normally treated as the head of the VP, was writing a letter, in the X-Bar theory. In some respect, however, the first auxiliary, was, is merely indicating the tense and aspect of the following verb writing. Therefore, I wonder if the first auxiliary was can be treated as the specifier of the VP and the following lexical verb writing as the head of the VP in some variant of the X-Bar theory, or if this kind of treatment is a no go in any variant thereof. 

Is the prepositional phrase "at a public school" a complement or an adjunct in (1)? How about in (2)? EDIT This site shows this sentence: 

Both Dependency Grammar (DG) and Constituency Grammar (CG) are a tool to describe the syntax of any natural language in general. The language whose syntax is to be described in DG or CG doesn't have to be a specific language such as English or German or French or Japanese. That means that DG or CG doesn't incorporate a complete set of syntax rules for a particular language. Now, in order to present a theory of English syntax, whether you use DG or CG to describe the syntax, you need to be able to determine a finite number of English syntax rules -- the fewer rules, the better -- that can generate an infinite number of grammatical English sentences. Are there such English syntax theories out there? If so, what are they called? EDIT I'll try to show the difference between "explaining" and "describing" English. If you have a plurality of unrelated rules, each dictating how a particular English construction works, such unrelated rules are merely "describing" English. For example, in order to form a declarative in English, the subject comes first in a canonical construction, whereas, in order to form an interrogative, an auxiliary verb (e.g., do, is, can, have, etc.) needs to be fronted before the subject in a canonical construction. So, these are two "unrelated rules" for describing a canonical declarative construction and a canonical interrogative construction, respectively. There is no underlying principle whatsoever that explains why these different rules are applied to these different constructions. And if there is such a principle that can subsume the two apparently unrelated rules, that principle will be "explaining" English.