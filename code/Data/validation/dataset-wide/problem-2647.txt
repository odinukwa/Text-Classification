Many FOL treatments (I was raised on Schoenfield's) find the opening (x) pointless, presuming open quantification whenever a variable is free. But then you have to be very careful about combining statements with free variables. In marked quantification (x)(Ax) => (x)(Bx) does not mean the same thing as (x)(Ax => Bx), The latter is a much more powerful statement. But without explicit quantification, we are tempted to write them the same. What we really need to do with unmarked open quantification is to write the former as Ax => By, and the latter as Ax => Bx. (And we have to remember to do so every time.) Explicit quantification which must be removed and then reintroduced avoids this potential confusion, at the cost of additional explicit steps. The rules for removing the quantification prompts the step of keeping your variables separated when they would otherwise get confused. 

@virmaior asked for an example, and the examples are fun but really boring to describe. I will try to describe one from 'fully abstract semantics', a Chomskyian linguistics model that gets adopted by computing. I hope it somewhat appeals to human beings. One place deduction rules apply to something other than logical truth are in looking at abstract grammatical transformations (especially in computer languages, but also in human ones). The rules take us from one sentence to another, just as one might expect, and preserve meaning. Since this is not quite a logic, but only a deductive system, meaning has a broader sense than 'true, false or otherwise', and includes things we might really consider meaning. It can be true that meaning is preserved but rendered very hard to access. So you can make a subcategory of 'reasonably efficient' such transformations. (Where reasonably efficient has to not penalize the steps in the grammar itself, so Big-O or something similar.) It can be the fact that a transformation preserves meaning in way that sometimes is and sometimes isn't efficient, depending on the route through the transformation system. So important cases are characterized by the local equivalent of P & ~P. You can efficiently parse the statement as long as you don't take a certain detour, which will make you balk at it. In that sense the system both does and does not handle the situation. You can address these by tuning the rules, or you can use the cases in a given language to explain why people choose given grammatical transformations over others or why grammar changes in some ways and not others. Finding such situations is important when the language is artificial and the equivalent of determining equivalent meaning is that a given variable's type matches a function signature. (The theory arose in verifying the type system in 'ml' was not impossible to compile.) The compiler should not spend an inordinate quantity of time merely matching types and not actually compiling any code. (A real fear in the early entries in the class of languages that eventually led to Haskell.) It has also been used to prove whether a given optimization is helpful or not. (The optimized code computes the same thing, but should do so more efficiently and not less, but the compiler should not get lost in the weeds trying to figure that out.) (These examples are from lectures on abstract semantics by John Gray at the University of Illinois in the late 80's and early 90's, which may or may not have ever reached publication.) If you focus on the application to a real language, there are lots of more subtle ways of looking at meaning than logics allow. You might include considerations like the later Wittgenstein's, where meaning is focussed on given motives and segmented into 'games' in a way that does not allow all sentences to combine and reduce to truth-values, but only to 'moves' in the game. A lot of the power of arguments in the "Investigations" derives from determining when consistency does not apply and does not matter -- where P and not P is not relevant due to the sophisticated equivalent of a category error. And I would not even consider Wittgenstein and anti-realist. More pragmatically you can inject the idea that comprehensibility is contingent, and that incomprehensible statements still have 'best accessible meanings', so reality is constructed by your statements whether you are understood or not. Either of these remains a world where deduction matters, but does not constitute a logic, and where consistency is not necessarily important. Since both are reasonable, we might just live in such a world. 

One can accept the core of Wittgenstein's perspective and the notion of language as usage without rejecting the notion that there may be a proper domain for metaphysics. No one is correct about everything, and people are often most blind to the consequences of their own favorite observations. I would contend that within the theory of Wittgenstein itself there is a proper domain of metaphysical inquiry. The theory arranges language into a set of overlapping 'games', each of which is coped to best cover a given set of uses. But any concept has its meta-version. If there is a domain of games, there is a domain of studying games themselves, which for Wittgenstein was the domain of philosophy. Philosophers of Science, for instance are interested in the 'game' of science, and what its proper rules are. But there are questions about games themselves. First and foremost is the question of the boundaries between games, and how to negotiate them. When neurology and psychology both try to give interpretations of depression, there is a boundary dispute. Each considers the other's explanations true in their own domain, but somehow 'cheating'. If I drug you into being happy, have I really helped you improve your life, well, yes and no... If I talk you out of being depressed, but your physiology makes it likely you will fall back in within the next five years, have I really helped -- well yes and no... Yet, by and large, there is peace between these two cabals of cheaters, and each can incorporate the other's work despite its origin within a field with different standards. So to the extent different sciences are sub-games, there are boundaries between sub-games, and ways of negotiating those boundaries that respect both of the adjacent disciplines. The same thing obviously happens between top-level games, like religion and science, or logic and physics. Decisions about how one is to resolve those are going to lie in another game entirely, a meta-game that clearly has rules of its own. It seems to me, without forcing the perspective, that, other than the sheer volume of absolute nonsense that Wittgenstein was so appalled by, this is what metaphysicians have always done, and will need to continue doing, despite the dismissal of them. 

From that I would propose that I should be prevented from taking back the organ, but that I should be placed on whatever recipient list the individual stealing it would have occupied. I do have some right to recover the stolen goods, but not to kill in the process, and there is a way for this to happen. Since I think you should be prevented from threatening the holder's life, whatever his relationship to the threat, your follow-up question doesn't come into play. How recompensation for the organ itself should be managed is a really difficult call. If the person who needs the kidney bought it on the black market, for instance he has substantial money, and that could be used. But if the sufferer is really basically impoverished by his illness, he has a debt that he will not be able to pay. 

Special Relativity could be considered an eternalism that does not admit a B-Theory of time. Spacetime is a single 4-dimensional object. So this is an eternalism. But simultaneity is not the same across different locations, so there is no B-series. 

It seems to be a matter of high degree implying perfection rather than of anything specific to elapsed time. 

(Since it seems to have confused at least one person, Libertarianism per se is a political philosophy and not an ethics. Whether your ethics should override politics in any given situation is another point, for another time. If Libertarianism is the framing, this is a political philosophy question, and it is not so much about Person A's individual action, but about whether the social contract should allow for it as an approved option. I am adopting a notion of social contract, in which social contracts that make it difficult to be ethical should be avoided in principle as they are too hard on the populace psychologically.) You don't need anything that elaborate to defeat Libertarianism. The problem with Libertarianism is already captured in Nozick's concession that violence may be necessary to secure personal property. If the rest of us decide to adopt a different set of rights, which do not include absolute rights to personal property, the only way the Libertarian can have his absolute right to personal property is through violence. The violence required on his part is no more noble than the violence we would assert to enforce our chosen set of rights. But he seems to think that he has the sole right to determine the legal structure, by some gift of clairvoyance that makes his chosen set of minimal rights more trustworthy than any other. You need some more complex and humane method of negotiating the local social contract than absolute fiat based on what comes naturally to a toddler. It needs to somehow accommodate a majority opinion on various things, including deprivation and health. Most mature social contracts we have encountered do contain the equivalent of the legal standard of depraved indifference. If you keep water from someone dying of thirst, even if they manage not to die in spite of you, you are not welcome to be an American, because our social contract compels some actions, whether or not Libertarians think it should. We will declare you temporarily outside our contract, and we will imprison you and keep you from your private property. 

When all the things on the right are true, the thing on the left must be true. So this is a potential interpretation of a, b, c |= d 

From a Lacanian (or any less physicalist idealist) point of view, ideas are the only place knowledge can arise. Whether you are imagining the phone of the future, or guessing where your cat is hiding, you are imagining possible scenarios, and the two things are not really different except in their degree of 'futurity'. You will or will not succeed at making that phone or finding the cat. But the ideas about the cat will be tested more immediately and more completely than those about the phone, which will have to be combined with other imaginary criteria over the course of months or years before they are validated or abandoned. If an idea is validated by experience, it becomes an 'observation' and if it associates itself with existing observations it becomes a 'symbol', but the only thing that can be represented in thought is an idea arising from the imagination. This is a psychological elaboration of the older notions behind idealism as an epistemology. We have to build a model of the world out of imaginary projections validated by experience instead of being able to build it out of actual experiences. There is no actual experience except for a mere sense impression, and we know that our picture of the world does not consist primarily of raw sense impressions. It is made up of objects, people, actions, interpretations etc. Those things are representations that we have to have imagined and tested out as models. They capture sense impressions that validate or challenge them, but they are whole objects with identities in a way not directly determined by those impressions. 

Popper did not accept the delineation between normal and extraordinary science. He looked at it as one grand continuum of hypotheses from the most mundane of fine-tuning computations to highly confrontational propositions that audaciously challenge all the surrounding work. So he would see Kuhn's 'normal science' as a good thing, but not as the best thing. The best thing, for him would be for common scientific processes to mature through normal refinement, but occasionally contain highly audacious confrontational propositions. However, Kuhn showed that historically, what Popper expects to arise from a grand contradiction simply does not happen very often. If the confrontation is too great, the new hypothesis, even if well tested, is not integrated into the science. There is a shared, underlying set of unassailable propositions that constitute the paradigm of a productive science. To alter the paradigm, not only must there be available and compelling contradictions, but the existing normal science must be decreasing in its return on investment. Otherwise the contradiction sits there unintegrated, or gathers a small number of obsessive vindicators, until the rest of the science is ready for it. Having never accepted this argument, Popper would maintain that what he originally proposed would still be best. If science were consistent and fully rational, it should work that way, even if it historically doesn't. The parochialism that the idea of a stable paradigm implies seems inappropriate to a process that could otherwise be described by a simpler and more directly rational process. 

First, arguments from your opponents stated motivation are obviously flawed. He is using an inappropriate notion of cause, and therefore of solution: Follow the argument down to its logical closure: It is likely given the number of minor infraction for which, via this argument, would get you wounded or killed, that basically no one would want to live in such a world. The level of stress and fear would simply be too high. Following the proposed pattern, if no want wanted things this way, we would all just kill ourselves. Problem solved? No. This points up the fact that eliminating a problem is not solving it. Where does the distinction arise? Fairly early: If I decide to solve a mechanical problem in my car by disposing of the car, I am not solving the problem. The problem is that I do not have a functioning car, and after disposing of the car, I still do not have a functioning car. We need a definition of 'solved' that makes sense, and that involves discerning the functional failure of the system and addressing it. 

At that point, the question is answered, without needing a real definition of knowledge in terms of mental states. But looking deeper might help us consider the reason for the confusion. (The quote is clearly dealing with knowledge as a personal property, and not on knowledge as a transmissible currency. It is to that latter form that the notion of 'justified true belief' applies better. And it is the former form that I will seek to define.) We know (vaguely) when we come to know a proposition, and subjectively that point is a moment of belief. So there is motivation to consider knowledge to be the temporal trace of a past belief. But there are confusing difficulties with knowledge of propositions that other mental states also generally don't have, which give it a mechanical feel. I can both know X's phone number and not be able to retrieve it at the moment. To the degree that I am just re-entering a past mental state, this should not be possible. So the trace itself is not an image, it is more complex. I can also only vaguely know something I once more clearly knew. If knowing were just stored belief, this fuzziness of knowing should be the same level of indecision that the belief had when I initially held it, or should at least be related. And it does not seem to be. The fuzziness of time seems independent of the surety at learning. Beyond that, there are things we know that are not propositions. We know procedural things: driving a car, playing the piano, speaking... And we know impressionistic things: how to choose the right gift for the right person, when to use what rhetorical tone... A lot of that is clearly knowledge. But because of its form, we are seldom conscious of it. And we may not consider the decision we made to act in the way that constitutes the knowledge itself to be a belief in particular, but it does involve some assent of faith. Without some internal model of what memory and processing are and how memory modifies itself, the best you can honestly propose as a definition is that knowledge is the effect that faith in a past decision has upon your future thinking. The most clearly identified effect would be reuse of information captured in a past mental state by reflecting upon or partially reconstructing the times you have decided that information had value. And that is probably why we think of knowledge as a mental state itself. But it is hardly the most important one, much less the only one.