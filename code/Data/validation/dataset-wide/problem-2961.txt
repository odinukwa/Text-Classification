There's a problem with your argument. With our current knowledge of physics, it is physically impossible for any computer to enter more than 2^256 possible states. Each state change requires a minimum amount of energy, determined by quantum physics, and 2^256 state changes require more energy than is available in the whole universe. Trying to run through all possible proofs, 2^256 state changes doesn't get you very far. But what you describe isn't experimentation. What you describe is like trying to replace a mathematician with a primitive artificial intelligence. Just like you could try to replace a physicist with an artificial intelligence. That artificial intelligence would probably conduct physical experiments if it is intelligent enough. The Four Colour theorem wasn't proved in the way you suggest. Instead, mathematicians found a large set of graphs with the property that if each graph in this set could be four-coloured then every planar graph could be four-coloured. No computer program could have ever figured out this approach. The computer program was just used for the trivial, time consuming and boring task to check all these graphs. 

Well, in some cases. If a man is in court for running after a woman, catching her, and then beating her up, and the defense points out his bad misfortune of having lost both legs before that event took place, then this might make the defendant "not guilty". PS. It is exactly what the question asked about - can evidence about the defendant's unfortunate lot be a reason for the court to find him innocent. 

There are fallacies galore here. Number one: Appeal to authority. "The poor worry. The rich don't worry". Says who? This is totally contrary to everything I know about the behaviour of people. Number two: Not understanding causality. The claim is that there is a 100% correlation between poverty and worries. That doesn't mean that one of them can be changed at will. Actually, it makes it unlikely that one of them can be changed at will. If that correlation were 100% (which it isn't, see number one), we would all suspect that when you are rich, there is nothing that could make you worry, and when you are poor, there is nothing that can stop you from worrying. We wouldn't believe that you could stop worrying at will and become rich that way. We would instead believe that a rich person wasting their money would become poor and start worrying, and that a poor person starting a successful business or winning the lottery would become rich and stop worrying. Not the other way round. Number three (already pointed out), "affirming the consequent". If we had the two statements given, plus the statement "Everybody is either poor or rich, and everybody either worries or not", then the conclusion would actually be correct, but that isn't the case. But let me add a third statement that is probably more justified than the two original ones: "Dead people don't worry". Now the advice given can be literally fatal: Stop worrying, and you will either become rich or you will die. 

You wouldn't just evaluate an action for its moral value, you would then act on it. Maybe you would just act by admiring or hating the person depending on your evaluation, but you would act - otherwise the evaluation is pointless. Now you can choose to evaluate that action including or excluding any reward that was received. You will of course get different results. But also your action will start at a different baseline. Take the politician who did some excellent work. If you ignore that he got elected because of his good work, then you evaluate the action, assign it a very high moral value, and decide that he deserves a reward - which is very good, because that's what actually happened, he did get a reward! Or you include the fact that he got elected in your evaluation. The total is now of much less moral value because doing good and getting rewarded evens itself out (more or less). You decide that he doesn't deserve a reward, but that decision is taken from the point of view that he did already get elected and doesn't deserve any more. To answer the question directly: No, the reward doesn't destroy the moral value of an action. But if you evaluate not just the action, but the action plus any results of the action, then of course your evaluation of the sum will be different. You add a moral value for the action, you subtract a moral value for accepting the reward, and come to a total. Now if a reward was hidden (by the person we are looking at), and we find out about it, then we would subtract the moral issue of the person trying to seem more moral than they are, and trying to get more recognition for their morality than deserved. If someone hands out goods to people in need, that's a good thing to do. If that person received all the goods without having to pay for them and just donates their time, that's still a good thing, not quite as good as paying themselves. If their time is also paid for, then the moral value might be a total of zero, but not because the moral value of handing out goods was destroyed, but because the payment compensated for it. But if that person pretended that all the goods came out of their own pocket without any compensation, and fooled is into believing that they are a highly moral person, then the total would be a big negative. 

You gave three potential definitions for some kind of even number. The first one is the one that is used in mathematics. The second one "doesn't make sense". An integer doesn't have "a last digit". The digits of an integer are a concept that follows from representing integers using digits. We usually represent integers as decimal numbers, but we could use different bases, for example base 16 is quite commonly used, where the last digit could be 'A', 'B', 'C', 'D', 'E', or 'F' and isn't a digit at all (you might say that twenty-six = 1A in hexadecimal, so the last digit is 1). Or base 3 could be used. The integer four is written in base 3 as 11. That's the first thing in mathematics when you write down a definition: You check whether that definition makes sense at all. In the third definition, what is the last digit of a fraction supposed to be? That doesn't make any sense at all. Before you use this definition, you have to state what you actually mean by the terms in the definition. (The difference to the second definition is just gradual. In the second definition, one might think that it makes sense, but it doesn't when you look closer. In the third definition, it doesn't make any sense at all). That said, you can define whatever you want. The question is whether the result is useful in any way. For example, extending the definition of "even number" to fractions should be consistent with the original definition. That means 4 or 5 should have the same evenness or oddness independent of which definition you use. If your definition for rationals tells me that 4 = 4/1 and the last digit 1 in that fraction is odd, then the definition is inconsistent with the original definition. That is very likely to make it less useful. Another requirement for usefulness is that the definition helps you in any way. For example, for integers you can say "the sum of two integers is even if the integers are both even or both odd, and odd if one is even and one is odd". Or "the sum of four consecutive integers is always even". Expressing these without the definition would take a lot longer. If all your definition does is to allow you calling some rational numbers even and others odd, without any situations where this allows you to express some statement in an easier way, then the definition is useless. Paul Ross gave some excellent examples how you could make a definition for rational numbers that makes sense. However, even his examples only allow you to classify rational numbers into even and odd; you don't get anything useful out of it. For example stated above was a rule for the sum of odd and even integers: 0.14 and 0.26 are "even" and their sum 0.4 is "even", while 0.14 + 0.16 = 0.3 has a sum that is "odd" according to that definition. 

You said "A child psychologist, however, can be extremely biased about how kids should be raised, and have very strong opinions as well". But that's not what "biased" means. I have a very strong opinion that 2 + 2 = 4, and not 2 + 2 = 5. That doesn't make me biased (towards the number 4 or whatever). A good child psychologist will have some rather strong opinions about child psychology, but not out of any bias, but because of his or her education in the subject and their excellent knowledge. Of course a child psychologist could be biased, which would make them an awful child psychologist. 

There are two reasons why it might be impossible to create an Artificial Intelligence with a mind equal to or better than that of a human: One reason could be that the building blocks of the brain are in some way superior to silicon chips or anything else that humans could create as the substrate for intelligence. The other reason could be that creating Artificial Intelligence is just very difficult, and human scientists and software developers are not clever enough to do it. Substance dualism would be a subcategory of the first reason. But you could argue that the brain has about 10 to the eleventh power neurons, with each having on average 7,000 connections, and that is just a big number that beats current computer hardware. (On the other hand, the computer hardware runs a lot faster than the human brain's hardware). It is an argument for human-grade AI not being possible today, but not for the impossibility in the future. Substance dualism would be an argument for "impossible in principle". The other argument that creating an AI is just very difficult is also one that doesn't speak for "impossible in principle". It might be that creating a computer which spends 18 years learning like a human is needed to create an AI. That would mean "not impossible". (Note that once such a computer had learned for 18 years, it could easily be duplicated, unlike humans). So if there are claims that AI is in principle not possible, then attributing some mysterious quality to the human brain that humans can't reproduce would be one argument for such a claim. Just a note: It is well-known that there are certain mathematical problems that computers cannot solve. But humans can't solve them either. Humans can choose to ignore such problems. An artificial intelligence would necessarily need the ability to ignore such problems as well. 

A person who managed to become rich and therefore happy hasn't bought happiness. "Buying happiness" would mean giving away money in exchange for happiness. This person hasn't been giving away money in exchange for happiness. And a person who has only one goal in life wouldn't be automatically considered a happy person when that goal is achieved. They would be considered a person who achieved their goal, that's all. Quite the opposite, people who have only one goal in life may be very happy while they are working hard to achieve that goal, and when it is achieved, they have nothing to achieve, no goal, and may be unhappy because the goal in their life is gone. 

Since your question is "what am I doing wrong", you are making one of two possible mistakes: One is that you are committing an "appeal to authority" fallacy. You believe the statement because you found it in your textbook. However, the statement is false: "If P then Q" and "Q only if P" are not equivalent. The other and frankly more likely mistake is that you have misread what your textbook says. Maybe there was a section in the textbook titled "show which of the following statements are true and which are false". A simple example where the statements are not equivalent: "If a person is a man, then that person is a human being" vs. "A person is only a human being if that person is a man".