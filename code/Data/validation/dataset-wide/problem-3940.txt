One observation: $$A = I+L,$$ where $L$ is a lower triangular matrix with $0$ in the diagonals. This matrix $L$ can be seen to satisfy $L^n=0$, and $L^j\ne 0,\ 1\le j\le n-1$. Thus, one can write $$A^{-1}=(I+L)^{-1}=\sum_{j=0}^{n-1}(-1)^jL^j$$ 

Just an idea. I think the best way to start is to expand on the structure of the matrices $D, C$. For example, $D$ can be readily seen to be expressible in the form $$\alpha M_1\otimes I_2=\alpha\begin{bmatrix} 0 & \mathbf{0}^T\\ \mathbf{0} & J \end{bmatrix}\otimes I_2$$ where $J=diag(1,2,,\cdots)$. I think the structure of matrix $A$ can be expressed as $\beta M_2\otimes B$ where $$M_2=\begin{bmatrix}0 & 1 & 0 & 0 & \cdots\\ 1 & 0 & \sqrt{2} & 0 & \cdots\\ 0 & \sqrt{2} & 0 & \sqrt{3} & \cdots\\ 0& 0 & \sqrt{3} & 0 & \cdots\\ \vdots & \vdots & \vdots & \vdots & \ddots\end{bmatrix},\\B=\begin{bmatrix} 0 & 1\\ -1 & 0\end{bmatrix}$$ Now the problem becomes finding $(\epsilon\beta M_2\otimes B+\alpha M_1\otimes I_2 )^{-1}.$ 

Let $f:\mathbb{R}^n\to\mathbb{R}$ be a given function and let us consider the unconstrained problem, $$\min_{x\in\mathbb{R}^n}f(x)$$ The standard iterative method for this is the gradient descent technique, where one iteratively generates the following sequence of points, $$x^{n+1}=x^n-\mu_ng(x^n)$$ where $\mu_n,n\ge 0$ is a sequence of positive stepsizes, and $g(x)=\nabla f(x)$ is the gradient operator. My question is the following: 

David Mumford, a well known algebraic geometer, is responsible for the "Mumford-Shah segmentation" model in mathematical imaging. Besides being one of the most cited papers in this area, it also sparked in immense amount of work in geometric measure theory, "special functions of bounded variations", Gamma-convergent numerical approximations and calibration and functional lifting for numerical purposes. To get a glimpse, check the book Singular Sets of Minimizers for the Mumford-Shah Functional. 

I can confirm that there is no agreement of what "extragradient method" really means. I know the interpretation by Christian Clason but I also know the one that is linked in Carlo Beenakkers answer. Let me add my point of view: For simplicity consider a convex minimization problem $$ \min_{x\in C} F(x) $$ with a convex , lower semi-continuous function $F$ and a convex, closed set $C$. Optima $u^*$ of this problem are characterized by $$ u^* = P_C(u^* - \sigma\nabla F(u^*)) $$ where $P_C$ is the projection onto $C$ and $\sigma>0$. Doing a fixed point iteration for this equation gives $$ u^{n+1} = P_C(u^n - \sigma\nabla F(u^n)), $$ which is the standard projected gradient method. Now we introduce a new variable $\bar u$ in the optimality condition and write it as $$ u^* = P_c(u^* - \sigma\nabla F(\bar u)),\qquad u^* = \bar u. $$ This seems artificial but now we can devise a new iteration and decide on different update rules for the artificial variable $\bar u$. The projected gradient method just takes $\bar u^{n+1} = u^{n+1}$. The extragradient method uses another extra gradient step for the new variable and reads as $$ u^{n+1} = P_C(u^n - \sigma\nabla F(\bar u^n)),\qquad \bar u^{n+1} = P_C(u^{n+1} - \sigma \nabla F(\bar u^n)) $$ The benefit of this approach is that, although you make a new gradient step and usually have "better convergence", you have to evaluate the gradient of $F$ only once per iteration (but have to do two projections). If the cost for the evaluation of the gradient dominates the cost for the projection the, you may gain something. A similar motivation for extragradient methods can be done for methods for variational inequalities, monotone inclusions or saddle-point problems… 

So basically I am asking, is it always best to evaluate the gradient at the point $x^n$ itself, or there can be transformations $h$ which might depend on the structure of the function $f$, that may help in faster convergence of the method? Can anybody refer me to any result in the literature that might have a link with this question? Any help is appreciated. Thanks in advance. 

Let us consider a function $f\in C^2$, and convex such that the Hessian $H\le LI$. We consider following minimization problem: $$\min_{x\in \mathbb{R}^n }f(x)$$ Let us consider the following iterative process for estimating the minimizer, $$x^{k+1}=x^k-A \nabla f(x^k)$$ where the matrix $A$ can be singular. It is well known, that if $A=\mu I$, a suitable Lyapunov function to use for checking convergence, is the function $f$ itself, as in that setting we have $$f(x^{k+1})\le f(x^k)-(\mu-\mu^2L/2)\|\nabla f(x^k)\|_2^2 $$ which shows descent property for $0<\mu <2/L$. My question is, 

Let $\{X_k\}$ be an ergodic process. I know that if $f$ is a smooth real valued function then by Birkoff's ergodic theorem, $$\lim_{n\to \infty}\frac{1}{n}\sum_{k=1}^n f(X_k)=\mathbb{E}(f(X_1))\ a.s.$$ Is there any similar result for the $\limsup_n$ or $\liminf_n$ of the sequence $\{f(X_k)\}$, i.e. results which involve expectation? More specifically is there a way to find $$\limsup_n f(X_n),\ \liminf_n f(X_n)$$ almost surely? Though I have asked the question for the general ergodic processes, even results for stationary processes like Gaussian processes will be helpful to me. Also, if they are not available, it will be very kind if someone can give me some references that I can use to find methods to find these results. Thanks in advance. 

I am a little late to the question but wanted to add a low-tech answer which somehow complements JDH's answer: 

There is abundant literature about stuff like this but it can be hard to find the framework that is best suited for your case. For example there is quite general theory in "Incremental subgradients for constrained convex optimization: a unified framework and new methods", Elias Salomão Helou Neto, Álvaro Rodolfo De Pierro, SIAM Journal on Optimization 20 (3), 1547-1572 where "subgradient projections" are used. To use this, you can desribe your feasible set by inequalites of the form $g(x)\leq 0$ with convex (not necessarily smooth) functions $g$ and do "subgradient steps" for the functions $g$ if the constraint is not fulfilled. Note that you can have a number of these constraints and treat them sequentially/incrementally. So if you have a polytope as constraint, you can iteratively use subgradient projections (or even projections) onto the hyperplanes defining the polytope. This is just one possibility and it is not clear if this would be useful in your contexts (e.g., if the number of linear constraints is very large, convergence may be slow; but on the other hand, if the iteration become very quick you still may have some speedup). 

If you map the boundary of the unit circle conformally, then the image will not have kinks, but an optimal tour should have kinks. Probably I just did not get what you had in mind... 

You might want to (or not) think about putting a sensor on each knee, each foot, each toe, etc., and consider the paths traced out by each sensor. You could use the language of diffeomorphisms and elastic deformations to talk about "small" (or large) deviations. You could also invoke some functional analysis to be a bit more specific about how the paths can deform. There are a lot of other perspectives you could take--like what about the forces that come up through the heels/metatarsals/toes and travel through both bone and soft matter? Or, finally getting back to what you brought up: the Lie algebra of parameter space which all the angles of the joints. There you're interested in questions that might be answered—or perhaps they'll lead you toward new questions instead—in an introductory differential-geometry or algebraic-topology text. (Spivak DG v1 or Hatcher AT will do.) But really what you want, I think, are some practical measurements—science derived from kinesiology—rather than pure-mathematics stuff. Ball-and-socket joints move in like a deformed disk; elbows and knees allow motion in a unit interval; and all of this is tied together with a product that's more complicated than Cartesian (you can't put your hand through your chest, for example). Sort of boring, mathematically; that's the stuff I mentioned above that's covered in an introductory DG or AT text. The more relevant information for you, maybe, will be in empirical/scientific specifics of real bodies. 

Some background: I would like to state that in the above framework for some non-strictly convex $J$ there exist $x,y\in\dom J$ such that $\langle \nabla J(x),y-x\rangle = J(y)-J(x)$. It clear that one gets $x$ and $y$ such that for $\lambda\in]0,1]$ it holds that $$ \frac{J(\lambda y + (1-\lambda)x) - J(x)}{\lambda}=J(y) - J(x) $$ which implies $DJ(x,y-x) = J(y) - J(x)$. However, there exists a pathological convex function such that its subdifferential at some point is single values although it is not Gâteaux differentiable there (Example 4.2.6 in Borwein and Vanderwerffs "Convex Functions: Constructions, Characterizations and Counterexamples", see here). However, I assume a wee bit more, namely that the subdifferential is at most single valued everywhere (but probably this already rules out some pathological things…). 

Another shot at what could be an answer: If you have a matrix which is rank deficient or ill-conditioned, you can regularize the solution of $Ax=b$. The setup is as follows: Assume that $Ax=b$ is consistent, $A$ arbitrary and $b^\delta$ is a perturbation of the right hand side with $\|b-b^\delta\|\leq\delta$ (and $\delta>0$ is known). Also you need to assume some mechanism to single out one solution of $Ax=b$ in case of multiple solutions - let's take the minimum norm solution, i.e. the solution with minimal norm (which exists uniquely) - it's actually $x^\dagger = A^\dagger b$ (note that we do not assume that $x^\dagger$ is calculated in practice but only need it for theoretical purposes). The goal now is to approximate $x^\dagger$ from the knowledge of $A$ and $b^\delta$. Numerous methods exist - two are: 

Speaking of industrial applications, graph theory is quite popular among computer people. For example Facebook's determines who sees what in the news feed. And is a popular (or at least well-advertised) graph database, with a graph-traversal language. LinkedIn has a team devoted to "social network analysis" and graphs are hot as well in "complexity theory" including models of the brain. For example $URL$ gave me a flavour of how the web-programming crowd sees graphs. I don't know if any of the above interests you but at least outside of pure mathematics I believe quivers-as-directed-graphs have practical applications. 

In my opinion the barrier to overcome is dividing the world according to academic department labels. (eg, thinking that $\textrm{management} = \textrm{psychology} \oplus \textrm{business}$) It takes time, but in principle it's not hard to apply a functor that repositions the topology (and adds new objects) according to the goals and methods of commercial businesses, whether that's Altria, TimeWarner, VeriSign, Tesoro, Cargill, or Airbus. 

Roger Penrose's The Road to Reality. Needham says in VCA that Penrose taught him what good style is. 

According to this doctoral thesis $URL$ by Jesse Hughes (supervised by Steve Awodey), cogebras = coalgebras are the appropriate category to study non-wellfounded sets. 

There are many mathematical perspectives one could take on running, many of them I think are more interesting than the narrow question you posed. (Since it's a graphics question another SX site might have been better.) 

Whether or not the limit is singular (e.g. with respect to the Lebesgue measure), there are several notions of convergence for measures which can reflect this. Probably the most simple one is weak convergence of measures (I prefer the name "weak-* convergence", because I find the view that measures form the "dual space of continuous functions" very helpful). If you need to "quantify" the convergence in some way it could be helpful that the topology for weak convergence is metrizable is several cases and moreover, that there are different metrics which work, e.g. the Prokhorov metric or the Wasserstein metrics. 

If you consider general linear programming problems and the solution in dependence on changes in the right hand side, you want to look for sensitivity analysis in linear programming and more specifically changes in the right hand side. Most books on linear programming cover this, e.g. chapter 3 in "Applied Mathematical Programming". 

What Branimir Ćaćić writes is correct. Another way to see that your $\lambda$'s where not right is as follows: From $$\lambda\psi(x) = \int_0^x y\psi(y) dy + x\int_x^T \psi(y)dy$$ you get that $ $$\psi(0)=0.$$ Similarly, from $$\lambda\psi'(x) = \int_x^T \psi(y)dy$$ you get $$\psi'(T)=0.$$ Hence, you have two boundary conditions for the differential equation $\lambda\psi''(x) = -\psi(x)$. The first forces $C_2=0$, the second gives $$\lambda = \frac{T^2}{\pi^2(n+\tfrac{1}{2})^2}$$ ($T/\sqrt{\lambda}$ has to be a root of $\cos$) and no condition on $C_1$. Since you want an orthonormal basis, you have to normalize the functions in $L^2([0,T])$ which gives $C_1=\sqrt{2/T}$. What you are missing in your numerics is that the series starts with $n=0$ and hence, your result differs from $\min(x,y)$ by $\psi_0(x)\psi_0(y) = \sin(\tfrac{\pi x}{2T})\sin(\tfrac{\pi y}{2T})$.