Note how the methods are no longer static, and their implementation can have private access to the root instance (if any). DFS1 

You need to decide up-front whether the pivot value is going to be in the left partition, or the right partition. If the pivot is going to be in the left, then you need to return index, and the left partition is values the pivot. In my 'education', all the examples I looked at, and all the implementations I have done since then, have always returned the index.... and they have always included the pivot in the left side. There are a number of things that stand out to me in your code: 

I have taken the liberty of adding 5 cards (and their panels) to the system. It makes the logic for why things are done this way more sensible. I have messed around with a few things in your code, but here are the three classes I have. Note, each class chooses its own values, and manages its own state. The logic about what is selected and whether it wins or not is completely contained within . is purely a display tool. It does not contain any Bingo logic, but it changes the display state to match the . is the main method only (and some constants). I have put everything in the package 'bingo'. The BingoCard class is a logical place to start: 

This function takes the dimension of the board, the position (in one dimension), and which way we want to look for our buddy. So, consider we want to find the position of our 'left' buddy: 

Similar to Mat's answer, in stage 2, you are calculating a random value for each customer, and processing the customers one-at-a-time. It would be faster to process them all together, but, the rand() becomes hard to do because it changes value each time you call it, and you need to change the 'obvious' odds of things as you go. Your procedure (with a test SQLFiddle) can be reduced to: 

Note how the limit is not initialized here, but in the constructor. Hmm, why use when you can use the personality of ? It should be: 

Note how you can override the removeEldestEntry method? If you put this all together in an application, it looks like: 

The first method breaks the digits in to their 9 rows/lines. The second method runs through each digit and builds a single line for all the digits. The digits are separated by some spaces, and the lines are separated by newlines. Input to Digits The missing piece now, is how do you convert the input line to the available digits. Here's one way: 

Your code is a fairly good representation of a Stack, but has some issues. Some issues are in the technicalities of how your program is written, but others are in how you've used the tools available in Go. Technicals The exported value on the is OK, but it should be named or something - is an ambiguous name. There's no reason to have a capital . It's not an exported struct, so the field can't be exported either. Given that you have the , though, you should probably use that instead of the pointer dereferences to check for an empty list.... for example, this code: 

For the most part, this appears to be neat, and well structured. There is a significant bug, though: 

In the hashCode method, I suspect this is auto-generated code. It's OK, but I thought there would be a way to integrate but there may not be. AdjacencyList This code looks fine too. The one comment here is that I would prefer to see a more batch-oriented integer conversion of each line. I would have a method like: 

before you add the to . Also, I would avoid the array entirely until the button is complete.... Result 

This is the basic tool I can use for the MicroBench system: $URL$ Scanner option Let's start by comparing your function to the type system recommended in another answer... Here's the code I used for the : 

Validation Your OptionPanel blindly assumes the input will be a valid integer. This is not true, and you should build a validation sequence for it. You should also catch 'NumberFormatException' from the Performance & alternate The StringBuilder may make sense, but, if you use it, there are two things: 

it is not obvious why you loop 1-less time than you have characters in the code. Additionally, I am uncertain why the backward-direction loop is useful. Should be: 

Right, now for the actual implementation.... using JMapper. Unfortunately there are some real concerns I have in here. DestinationClazz Do you have an actual class called DestinationClazz? I imagine not. I think this is supposed to be a generic type, but then you are not treating it like a normal type. For example, your class definition is: 

Now, we're cooking. How much, though? Before we get there, I am going to suggest another change, which is to take the insides of the loop, and make it another function too, and also make some variables 'final', so the code looks like: 

you are casting the value to be an , but that value is a , and that is not an , so you will get ClassCastException. If you did it right .... Your generics should be worked correctly the whole way though. There is no need for , it should be , and instead of loading the executors as a you should be using the correct callable-nature of the , and submitting as: 

Here are the two interface declarations next to each other... there are some similarities (I have reformatted it to be clearer): 

ICMP does not appear to be an option for you... you say you are pinging 'servers', but I think what you mean is that you are pinging 'services' (actual applications running on the server). You connect to the host:port combination. You could even have multiple services running on a single server. A brief run-down of your code suggests: 

By sacrificing the per-field parsing from awk you instead gain the simplicity of bulk modifications of the comma values using sed, to expand them to quote their respective values. Combined with adding the surrounding structure for each line, it just works.... 

This is approximately how I would have written your function, given the above... I have compared it with yours using some input values to test with. 

The continuous testing of for each pixel is a horrible waste of time (also, it's not :). These values are not going to change part-way through a render, so just divide the method in three, and have: 

Code Style Read the Java Code-style guidelines. Java class names should start with a capital letter. 

If your question is 'When should I override the default toString() method and use create my own?' then there is one set of answers. If your question is 'when should I call the method (implicitly like or explicitly)?' then there is a different set of answers. So, when should you override the ? From the Javadoc for Object: 

Then, every operation knows the head and tail is not null, and becomes an insert/delete. The certainty this gives is useful. For example, your iterator becomes: 

... you return false if the link contains the replacement String, even if it also contains the to-replace string. Perhaps you should make the code just: 

Now, there are ways to improve that performance still, for example, lots of println statements could be grouped in to just one print... 

What is that saying? It's saying that I can make the code run more than twice as fast, without changing the algorithm.... Now, if you are running your code in about 10 hours for \$10^7\$ then my improvements will bring it to... maybe 3 hours? That's a big difference.... but, wait, there's more. Why does the 'split' function work so much faster than the single function? The reason is that the inside function gets called 10,000 times, and the outside function gets called once. A method that is called once is not 'compiled' by the Java compiler, but is run in more of an interpreted fashion. By putting the inner code in a function, the compiler sees it running many times, and it 'hotspot' compiles it.... with lots of optimization. We can use that to our advantage.... If I take lots of small datasets (say 1000 data sets between 1 and 1000 members large, and I run those functions for those data sets, and then I run it for bigger data sets, by the time the big data set is run, the methods are 'hot' and compiled, and the Java machine is said to be 'warmed up'. What sort of difference does it make? Well, for each of the three sorts above, let's see, first, your code: 

Let's introduce the Java7 try-with-resources system. This has a number of advantages, but, in this case it makes sure that, if there's a problem, the client side of the process knows immediately instead of hanging around waiting for a socket to die (get garbage collected). Note, never catch .... it will catch all sorts of things you don't want to, like ThreadKillError, etc. First up, we manage the input/output streams: 

Now, about those performance improving options.... Let's assume that the best way to solve this problem is to do a cross-product of the two tables. Compare each value in table a with all values in table b. Oracle ha a few options for doing this. I will list them in what I consider to be a worst-to-best order: 

Threshold Logic There is no apparent reason to have the weird logic in the for the 'scrape()` call. Something simple like: 

You have done this correctly in most places, so the places you have it wrong stand out.... There is no need, and it is now discouraged, for you to add the generic type to instance constructor calls. The generic type can be inferred from the target. i.e. your line: 

Each time you change a record, the block it is stored in is changed, and the difference is recorded in the redo log. The number of blocks you change is a key factor in determining the amount of redo-log work that you do. The number of blocks is closely related to the amount of data you are changing, and the way that the data is distributed. If you are deleting a bunch of records that are all stored really close to each other, then the chances are that the number of blocks that are affected will be small. If the records are scattered on many blocks, then the number of blocks affected is high. Based on the key you have specified for your data it appears to me that your data for a specific RUN_ID will be scattered all over the database. This means that, for each time you delete the data, you are actually inserting 400,000 redo-log entries, modifying 400,000 blocks of storage (let's say 8K each, so that's 3GB of IO), and generally processing the system quite hard. So, apart from the basic problem of deleting 400K records, and inserting 400K redo-entries, and writing all that data to disk, what else could it be? Locks will likely need to be escalated. Oracle will start by trying to lock the records one at a time, but will quickly find that the lock-management requires a bigger lock strategy, so it make replace the row-locks with block-locks, and then finally escalate the block locks to a full table lock. In itself, this is not a significant performance problem, but what is a problem is if anyone else is running anything against the table.... the lock escalation will have to wait until all other locks on the table are serviced. Only then will it gain exclusive access. Ways to improve the performance would be: 

Note that the is an and not a ... use the highest form of the instance where you can. Declare variables where they are used.... You declare the result variable outside the try-block. This is because of how you do the error handling and you may want to return it when it has an empty value. This is not the best solution though, I would have: 

would be sufficient to catch those people who inadvertently misunderstand the way your Runnable is supposed to work. The second problem I see in your code is the poor handling of the InterruptedException. At a minimum, you should re-set the interrupted flag when you log the message. Even if you don't know how to handle the exception, you should let someone who can handle it to do it. 

try to set up a system where you can sfp direct from the source to the destination without needing to process the file in between. You have ssh access to them both, so it should not be that hard to create a script on the source, and run that script with some parameters that copies the file to the destination. Use BlowFish encryption algorithm for the transfer. It is rumoured that blowfish is faster than the other algorithms, and, by the sounds of it, it should be fine for your use case. Wrap the InputStream you get from jsch in a BufferedInputStream spread the load of the decrypt/encrypt on multiple threads. 

Fundamentally, at some point, you have to do a cross-join to calculate your results. Performance will be a problem... but there are things that can be done. First though, why the ugly SQL? Formatting SQL to make it readable is not hard to do: 

Note: This review is based on the (apparently incorrect) assumption that the sequence in question is 'contiguous'. In other words, the 'right solutions' in the example: 

Your code is, in general well structured, and neat. You have a bunch of auto-generated content, like comments, and TODO items. You should remove those to indicate they are handled. As for the sax parsing, you have done pretty well, though there are some bugs and issues you have to address.... and it all boils down to the method. The characters method can be called multiple times inside any element. Typically the SAX parser reads chunks of data, and, if the chunk ends half-way through the text of an element, you may end up with one call for the last part of one chunk, and another for the first part of the next chunk. This makes it very hard to put decision logic inside the characters method like you have done. Instead, you should put the logic you want inside the and methods, and do simple String concatenation inside the method. Consider something like: 

Now, at this point, there is no need to perform an intersection on the maps... the values in we know ae not in , and visa versa. You can just print the contents of the two maps without any further processing... Putting all these suggestions together, your code would look something like: