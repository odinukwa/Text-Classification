By locally principal ring they mean a commutative ring such that its localization at any maximal ideal is a principal ideal ring. For euclidean ring $A$ this gives $K_1(\mathsf{C}_\ell,R)=0$. As a byproduct they also prove a stronger version of Suslin's theorem for $SL$ and a locally principal ring. They also have a version for Laurent polynomial rings and claim that by using stability theorems for $K_1$ as in M. Stein's papers one can prove the same results for classical simple algebraic groups of relative rank $\geqslant2$, but the latter has never been written in full details. 

Consider the root system $\mathsf{B}_n$ with the standard numbering of the fundamental roots (that is, $\alpha_n$ is short). Take $\alpha_{n-2}$ and $\alpha_n$ as a pair of orthogonal roots (indeed, $\alpha_{n-2}+\alpha_n$ is not a root), and take $\gamma=\alpha_{n-1}+\alpha_n$. Then $\beta_1=\alpha_{n-2}+\alpha_{n-1}+\alpha_n$, $\beta_2=\alpha_{n-1}+2\alpha_n$ and $\alpha_{n-2}+\alpha_{n-1}+2\alpha_n$ are all roots. But among the differences of the form $\beta_i-\alpha_j$ the only roots are $\beta_1-\alpha_{n-2}$, $\beta_1-\alpha_n$ and $\beta_2-\alpha_n$, so this gives a counter-example. The beautiful pictures of Hasse diagrams you refer to provide a good way to spot such examples, but for this one should draw them in a different way, which is easier to read. The keyword here is a weight diagram. For examples, see this collection of the diagrams along with a description of their various usages. Namely, Figure 14 on page 35 is the weight diagram of the adjoint representation of a group (or of a Lie algebra) of type $\mathsf{B}_n$, which also describes the structure of the root system (its vertices are the roots, plus the "zero weights" corresponding to the fundamental roots). One looks for a square which has non-consecutive label on its sides (say $i$ and $j$), such that the bonds joining its top or bottom vertex to something on the right are also labeled by either $i$ or $j$. Such a square is immediately found on the very bottom of the picture slightly to the left from the middle. By the way, the quick inspection of the weight diagrams shows that there is no counter-examples besides the one above (I'm not sure, but I haven't spotted any). 

Just a two cents worth here. :) Chess itself might perhaps not be too mathematical, but the chess evaluation functions of any chess-playing computer program seems like a mathematical object. After all, these are maps from the set of chess positions to $\mathbb{R}$ and they are bound to satisfy various properties. Given any two chess programs that are both strong and might be expected to be decent (in terms of current technology) approximations to objective truth, one might probably expect them to be "close" in some meaningful way that one could perhaps attempt to define. 

The density Hales-Jewett theorem implies that there cannot exist perfect magic hypercubes of fixed side length $k$ and arbitrarily high dimension $n$ whose cells are filled with the consecutive numbers $1,2,\dots,k^n$ and for which the numbers in cells along any geometric line sum to the magic constant $\frac{k(k^n+1)}{2}$. For, take the cells with numbers $ 1,2,\dots,\left\lfloor\frac{k^n}{2}\right\rfloor $. This always has density about $1/2$, and so by the density Hales-Jewett theorem, will contain a hyperline for sufficiently large $n$. But no $k$ numbers from this set of density about $1/2$ can ever sum to the magic constant. 

Hi there, If you're only interested in heuristics, then if you replace $89$ by $x$, fix $m$ and $n$, fix $\pm$ to be $+$ or $-$, fix one of $a,b$ to be $2$, and let the other variable range over primes less than $x$, then it is in the right form for the Bateman-Horn conjecture to be applied to. See for example, P. T. Bateman, R. A. Horn, A heuristic asymptotic formula concerning the distribution of prime numbers, Mathematics of Computation 16 (1962), 363--367. (Say $a=2$, $b$ ranges over primes less than $x$, $m$ and $n$ are fixed, and $\pm$ is $+$. Then one can use the case of Bateman-Horn for two polynomials simultaneously, one polynomial being $z$, the other one being $z^n+2^m$.) Then depending on which other variables you want to vary, you can apply Bateman-Horn to each case like this. Don't know how accurate it would be for $x=89$ ! But it should be more accurate for $x \rightarrow \infty$. The usual caveat about this still being a conjecture applies. 

For $T : R^n \to P({R^n})$ maximally monotone, the proximal point algorithm (step size $c>0$) $$ x^{k+1} = (I + c T)^{-1} x^k, $$ converges linearly with rate $\kappa = \frac{1}{1 + c \sigma}$ if $T$ is strongly monotone with parameter $\sigma > 0$. I'm interested in analyzing the linear convergence rate in case of matrix-valued step sizes, i.e., $C \succ 0$, $$ x^{k+1} = (I + C T)^{-1} x^k. $$ I could only manage to prove a bound depending on $\lambda_{\text{min}}(C)$, while in practice I numerically observe that the convergence rate depends on the whole spectrum of $C$. It seems like such a basic algorithm, so I am surprised that I could not find classic literature (e.g. by Rockafellar) on this topic. Background: many proximal algorithms for solving problems of the form $$ \min_x \max_y~G(x) - F(y) + \langle Kx,y \rangle $$ such as Douglas-Rachford, ADMM or Chambolle-Pock fit the above setting of proximal point algorithms given a special choice of $C$. In case $G$ and $F$ are both strongly convex, $T$ is strongly monotone and my goal is to connect the linear convergence rate to the choice of metric/step size. 

Consider the matrix $M = \begin{bmatrix} A & A B \end{bmatrix} \in R^{n \times (n+m)}$, with $A \in R^{n\times n}$, $B \in R^{n \times m}$, $m < n$, $m > 1$, $A$ symmetric positive definite. I'm interested in the finding an (good as possible) upper bound for the following expression $$ \sup \{ 1 / \sigma_{min}(C) ~:~ R^{n \times n}\ni C = \begin{bmatrix} A & AB \end{bmatrix}_I, C ~\text{invertible} \}, $$ where the supremum is taken over all column selections $[.]_I$ of $M$ such that the resulting square matrix $C$ is invertible. Basically I'm interested in the smallest singular value of all invertible $n \times n$ sub-matrices of $M$. Right now, I have no idea what are even the right tools to attack this problem. I'd be even interested in some numerical way to find an upper bound for this number for values of $n \approx 500$, $m \approx 200$ but an exhaustive search quickly becomes completely intractable. 

Hi! Not sure if this is exactly what you are asking for, but for non-linear equations in three variables you can fix a $b<1$ arbitrarily close to $1$ and then construct an equation so that $|A| > bN$ and there are no solutions to the equation in $A$, by using congruence conditions as was done for $x^2+y^2=z^2$. Take $x^2+y^2=p^2z^2$ for $p\equiv 3 \bmod 4$, $p$ sufficiently large, and form $A$ by deleting $p\mathbb{Z}$ from $\{1,\dots,N\}$. There are no solutions since $-1$ is not a square $\bmod p$. But if $p$ is fixed, then one wonders how much larger $b$ can be beyond size $\frac{p-1}{p}$. 

The following is for a finite board (the question actually assumes an infinite board). For an $N\times N \times N$ board, wouldn't $2N$ rooks suffice? The idea comes from adapting the checkmate with two rooks for the two dimensional case in which the two rooks alternate rows and force the king to the last rank. For the three dimensional case, for each $y$ with $1\leq y \leq N$, place one rook at $(1,y,k)$ and another at $(2,y,k+1)$. Then, for $y$ going from $1$ to $N$, move the rook at $(1,y,k)$ to the square $(1,y,k+2)$. Again, for $y$ going from $1$ to $N$, move the rook at $(2,y,k+1)$ to $(2,y,k+3)$. Each for loop over $y$ involves moving, alternately, the rooks with $x$ coordinate $1$ by increasing their $z$ coordinate by $2$ units, or the rooks with $x$ coordinate $2$ by increasing their $z$ coordinate by $2$ units. We alternate, so that a for loop in which the rooks with $x$ coordinate $1$ are moved is followed by a for loop in which the rooks with $x$ coordinate $2$ are moved, and vice versa. Eventually, either the rooks with $x$ coordinate $1$ or the rooks with $x$ coordinate $2$ will have $z$ coordinate $N$. The effect of this is that a subset of the squares guarded by the rooks form a "floor" of two layers that keeps moving upward. So if the black king is between this "floor" and the top of the $N\times N\times N$ cube, it gets pushed to the top face. The "floor" must be moved upward in such a way that it never becomes disconnected, so that the black king can never escape to beneath the "floor" through some gap. For an infinite board, @Noam Elkies has already mentioned $5N$, so the following is not an improvement: the "ceiling" (and the other walls of the $N\times N \times N$ cube) can be formed by placing $N$ more rooks at $(N,y,N)$, for each $y$ with $1\leq y\leq N$, and $N-1$ more rooks at $(x,1,N)$, for each $x$ with $1 \leq x \leq N-1$, and $N-1$ more rooks at $(x,N,N)$ for each $x$ with $1 \leq x \leq N-1$. 

Here $H$ is the maximal split torus of $G_2$, $\sigma$ is an automorphism of $K$ such that $\sigma^2\varphi=1$, $\varphi$ is the Frobenius, $U^1$ and $V^1$ are the subgroups of upper and lower unitriangular matrices stable under the exceptional automorphism of $G_2$ induced by $\sigma$ and the root length changing symmetry of the Dynkin diagram, the subgroup $G^1=\langle U^1, V^1\rangle$ and $H^1=H\cap G^1$. My question: is this still the case? 

Your question is essentially about surjective stability for relative symplectic $K_1$. The latter follows from the usual (absolute) surjective stability for $K_1$, which in symplectic case starts at $2n\geq \mathop{\mathrm{sr}}(R)$. To prove this, one can use so-called "Stein relativization", as described in M. Stein, "Relativizing Functors on Rings and Algebraic K-Theory", J.Algebra, 1971. See Corollary 1.7 therein or the remark after Theorem 4.2 in Stein's other paper, "Stability theorems for $K_1$, $K_2$ and related functors modelled on Chevalley groups", Japan J. Math, 1978. It is also possible to prove it directly under somewhat weaker assumprion on a ring by explicit calculations with generators, but since you are interested in Dedekind domains, the usual stable rank condition should suffice. 

This is an expansion of my comment. The Smith normal form is a normal form of a matrix with entries in any given PID (but this probably works for non-domains and for Bezout rings in general). It goes as follows: given an $m\times n$ matrix $A$, there exist invertible $m\times m$ and $n\times n$ matrices $B$ and $C$ such that $BAC=\operatorname{diag}(a_1,\ldots,a_r,0,\ldots,0)$. Moreover, the entries $a_i$ satisfy $a_i\mid a_{i+1}$ and are unique up to the multiplication by a unit. This decribes the representatives of $GL(m,R) \backslash M(m,n,R) / GL(n,R)$. From here you can obtain the decription for $SL(m,R) \backslash M(m,n,R) / SL(n,R)$ — no independent multiplication by a unit anymore, so the difference is the same as between $K_1$ and $SK_1$. When $R$ is a Euclidean ring, one has an algorith for computing the Smith normal form. This works for any PID, in fact, but the resulting matrices $B$ and $C$ are not necessary elementary in this case. For a Euclidean ring the algorithm gives you the chain of elementary transfromation for obtaining the SNF. As you mentioned, $E(n,R)=SL(n,R)$ when $R$ is Euclidean, but this is not the case for a PID. This equality fails, for example, for the ring $S^{-1}\mathbb{Z}[x]$, where $S$ is the multiplicative system generated by all cyclotomic polynomials. This is a result of D. R. Grayson — $SK_1$ of an interesting principal ideal domain. Here are two other links with examples: 

Here's an attempt to say something about your nice question. It surely follows from Igor Rivin's nice sketch and the Math Overflow question he linked to. Fix $r$. The quantity $E_r(x)$ in the edited question satisfies $$ E_r(x)\gg \sum_{\substack{m \leq x \\ \omega(m)=r\\ \mu(m)^2=1\\p|m \Rightarrow p \equiv 2 \bmod 3}}\sum_{\substack{n \leq x/m\\ \mu(n)^2=1\\p|n \Rightarrow p\equiv 1 \bmod 3}}1. $$ The inner sum in the above, by what you wrote about $E_0(x)$, satisfies $$ \sum_{\substack{n \leq x/m\\ \mu(n)^2=1\\p|n \Rightarrow p\equiv 1 \bmod 3}}1 \gg \frac{x}{m(\log x)^{1/2}}. $$ By induction on $r$, say, and using $\sum_{\substack{p \leq x\\p \equiv 2 \bmod 3}}\frac{1}{p}\gg \log\log x$, one has $$ \sum_{\substack{m \leq x \\ \omega(m)=r\\ \mu(m)^2=1\\p|m \Rightarrow p \equiv 2 \bmod 3}}\frac{1}{m}\gg (\log\log x)^r. $$ So one has $$ E_r(x) \gg \frac{x(\log\log x)^r}{(\log x)^{1/2}} $$ where the implied constant depends on $r$. 

I hope this could be relevant to your nice question. There is a paper by K. Williams where a Mertens' type theorem for arithmetic progressions was proved, K. Williams, Mertens' Theorem for Arithmetic Progressions, J. Number Theory 6 (1974) 353--359. In this paper, the relation $$ \sum_{\chi \bmod q}\chi(p)\bar{\chi}(a) = \begin{cases} \varphi(q), & p \equiv a \bmod q, \\ & \\ 0, & \mbox{otherwise.} \end{cases} $$ for Dirichlet characters is used to derive an expression for $$ \prod_{\substack{p \leq x\\p \equiv a \bmod q}}\left(1-\frac{1}{p}\right). $$ Letting $G$ be the Galois group of $K/\mathbb{Q}$, $C_G(g)$ be the centralizer of $g$ in $G$, $\mathcal{C}(g)$ the set of conjugates of $g$ in $G$, $\sigma_p$ the Frobenius element of $p$, the Schur orthogonality relations $$ \sum_{\chi}\chi(\sigma_p)\overline{\chi(g)} = \begin{cases} \left| C_G(\sigma_p)\right| = \frac{|G|}{|\mathcal{C}(\sigma_p)|}, & \sigma_p, g \mbox{ are conjugate}, \\ & \\ 0, & \mbox{otherwise} \end{cases} $$ where the sum is over all irreducible characters $\chi$ of $G$, can be used in a similar way to derive a formula for the partial Euler product in your nice question by writing, for some fixed $g\in G$, $$ \prod_{\substack{p\\\sigma_p \in \mathcal{C}(g)}}(1-p^{-s})^{-C_G(g)} = \prod_{\chi}\left(\prod_{p}\left(1-p^{-s}\right)^{-\chi(p)}\right)^{\overline{\chi(g)}} $$ where the $\chi$ are irreducible characters of $G$. In the mentioned paper, where the $\chi$ are Dirichlet characters, Williams wrote $$ \prod_{p \leq x}\left(1-\frac{1}{p}\right)^{\chi(p)} = \left(\frac{1}{L(1,\chi)}+O(1/\log x)\right)\left(K(1,\chi)+O(1/x)\right) $$ where $K(1,\chi)$ had some properties that could be stated in the paper. Hence in the case of the product in your nice question, maybe something can be worked out along such lines too. I guess it's more complicated as there are now Artin L-functions.