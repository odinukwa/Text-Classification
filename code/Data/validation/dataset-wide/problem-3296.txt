His notion of representing grammatical features "on" morphemes resolves the mystery in SPE as to which segment(s) underlyingly bear a diacritic feature – that is, if -akwo- is [+past], which segments underlyingly bear that specification? Although there is a convention that would distribute such a feature to all segments in the morpheme, nothing prevents underlying forms from having nonphonetic features contrastively located on segments within a morpheme. Leben's theory, with matrices "on" different things, resolves this matter: each morpheme has a single matrix of nonphonetic features (also tone). So, Leben's theory is the second kind of matrix that you ask about. SPE may have thought of having such a thing, but Leben embraced it, and planted the seeds of autosegmental phonology in that soil. Nothing in principle would preclude creating a number of different kinds of matrices and associated units, for example "word" or "syllable", and since morphemic phonetic features (tone) can migrate into the segmental matrix (via what he calls "tone mapping"), and since this can be language specific, then the floodgates are opened somewhat. I should add that understanding the history of these concepts is extremely difficult (was agonizing at the time) because of the unclarity of the original authors. This gave rise to many different interpretations, where I think Leben saw his analysis as being consistent with the SPE account and he only added a little change. The status of "matrices" and "segments" in SPE phonology is quite unclear, and became "clear" only subsequently, often made clear by critics. What is clearly understood is that in SPE phonology, there exists a "unit" (segment or boundary), and the phonetic features contained in that unit have no further structure -- there are as many instances of a feature as there are units. The term "matrix" is typically used to refer to "a unit", but the original canon (SPE) is quite murky. The appendix on formalism defines the objects for writing rules, but there is no corresponding formal definition of the objects that rules act on. The gesture in the direction of 2 special symbols (→, φ) and 3 classes of things (features, specifications, categories) as the primitives of rule theory, and it is completely unclear how parsing elements (brackets) fit into their theory. 

Double negation in languages follows math rules just fine, the better question is what set of math rules get followed, and that depends on the language. 

Standard English doesn't have negative concord, so having two negatives cancels things out. But Asturian (like many dialects of English) does, and so there is no cancelation. There's nothing wrong in Asturian saying, for instance (bold words in negative) 

I'm not very familiar with the history of Portuguese phonetics, but my guess is that when the palabra huracán was imported in Spanish (being then aspirated, unlike now), when it got to the Portuguese, they likely lacked the sound and so f was probably a pretty good substitute. 

Oftentimes we have documents that talk about how things were pronounced, especially when they criticize people for how they talk (the Romans were rather famous for that). Texts like poems are also very helpful for knowing where words would have similar pronunciations or stresses, and can even help demonstrate sound evolutions despite spelling being the same. On a similar note, inconsistent spellings that suddenly crop in after years of consistency may represent a sound in flux, especially if they later stabilize with the innovated form. Many of those sound changes are relatively consistent across languages, which help confirm those observations (in the sense that we know condition A has resulted in innovation B in unrelated languages due to some known principal C). Finally, we have documents where someone from one language reports on a word from another language and talks about how it sounds in relationship to their language, or more simply a word that gets imported and brings its pronunciation along with it. Taken together, there are generally enough pieces to put together to demonstrate how a language may have sounded with pretty high certainty. If there aren't enough pieces, though, there may be several pronunciations that are consistent with the evidence, and absent more evidence, it may be impossible to know which is the most accurate. 

It looks like Pierce & Karlin 1957 might be a good starting point. It came out almost a decade after the original Shannon (1948) entropy paper and a decade before Kolmogorov's 1968 paper on quantifying information. Here's the abstract: 

These are huge effects. This data has 2 degrees of freedom (df = the number of categories - 1) and so a chi-squared score above 4.605 has statistical significance. A score of 13.8 has a p-value of 0.001. So this is huge. But this was a very simplified test, and to really get at this problem, you'd probably want to take a more nuanced approach. You could collect data on several compounds that have hyphenated and spaced variations and look at the overall distribution to get a more realistic set of expected values (the argument in the function). Hypothesis #2 - Distributed similarly to fireplace, fire-place, fire place As a one-step-forward example, we could use the distribution of fireplace terms as our expected distribution for firefighter. 

(Diclaimer: I'm far from an expert in this area, but in my PhD coursework I took a computational linguistics course and a stats for linguistics course.) This seems like a case of a single categorical dependent variable. For this we used a Pearson chi-squared test to see if distribution differs from what is expected. This requires you to have an expectation. If you don't have one to start out with, equal distribution (or null hypothesis) is a good place to start. Hypothesis #1 - Equal distribution So let's hypothesize that these three orthographic forms are in free variation and we have no reason to assume any of them is more likely than the other. So we expect each variant form to account for 1/3 of all occurrences. It's easy to calculate the significance in R (with RStudio). For firefighter: 

It becomes obvious where to add fenceop's suggestion of (?: \w+\b)* in here (I'd also add on an extra otherwise if you have two que/qu' it will gobble up all but the last one), but first some things you can improve on: In the first group, notice that both of the initial two options include a group which is followed by (exactly 0 or 1 times). This means it can also match nothing at all. You can just put the at the end of the entire first capture group. Also, you have a space after each element in the nested options (for pronouns). You can just put this after all of them. Likewise, no need for parentheses. For for single letter options, character classes are much more readable and common, so you can change to . So can be trimmed down to . But since \w is just a default collect if not the ones you've specified, you can drop it even further to a single set of options rather than needing to nest it. But then again, since \w+ would match the others, you can just have \w+. I don't think that's what you want, though. In the the group with the verb conjugation, again, character classes are nice and the (ez) does nothing but add a capture group. Presuming you actually meant to include the word boundary after all of them, you can just use that after the options group. So can be trimmed down to . Also, some other improvements: using to try to match a sequence of letters will fail if there's any punctuation which I believe in French is quite rather common. You may wish to specify your own character as (adding in accented variants needed for French, hyphen must go at the very end or very beginning), or just use which is a non-white space character. For what you're doing, there's probably no harm in using in place of . With the number of non-capturing groups you have, you might want to instead use named capture groups and just ignore all other results, but that's me personally. Given my suggestions you will get using /x (again, spaces not fully escaped), I'd recommend something closer to this (using named captures pre, neg1, verb, pron, neg2, and extra — extra will contain the text you have in bold): 

There is some evidence indicating that back vowels are more sonorous than front vowels, although the relation could also be based on round (more sonorous) vs non-round, since the data comes from Modern Greek where back and round correlate in the typical way. This is discussed in E. Kaisse's Harvard dissertation. There is a general phenomenon of hiatus resolution whereby V#V sequences reduce to a single vowel by deleting one of the two vowels. Which vowel deletes depends on the properties of the vowels; there is also variation between dialects; there are multiple rules that implement this hiatus-resolution plan; and there are different syntactic conditions on the different rules. The general pattern (most pan-Greek) is that the "more sonorous" vowel is retained, and the hierarchy of vowels, in terms of sonority, is [a > o > u > e > i]. Examples of this here come from Peloponnesian (glosses are my construction based on available information from Kaisse). 

I would additionally suggest Hans Basbøll's monograph The Phonology of Danish. The ratio of chat to data is a bit high for my taste, but I think it would be helpful in getting a handle on the orthography to phonetics mapping. He provides detailed IPA phonetic transcriptions. Along with the Danish word index and forvo samples, this would help to concretize the spelling system. Recorded examples are especially important, since the conventional IPA transcription of Danish doesn't (didn't) match my expectations of what symbols should be used to indicate a given sound (especially with vowels). 

It certainly comes up occasionally, but mainly, I would think, across morpheme boundaries where one is a doubled letter and the other is that same letter but in its singular form (as in the new German orthography Schifffahrt, Balletttänzer, etc) or where a letter has both consonant and vowel values. Undoubtedly at some point uvula and any other words with uvu would in the past have been written identically until the separation of the v from u (if someone could find an old print reference to a vuvuzela then you'd have a quadruple u). But I would imagine most languages (happy to be corrected, of course) would start to simplify spelling if the extra letters don't change pronunciation, or add in punctuation to separate them (as in shell-less in English) 

There are a number of things that are often cited (and at times disputed) as influences that Basque has had on Castilian. 

Written language for the longest time tended in large part to be of literary or legal types. If you're going to take the time to write out something (or worse, carve it), after all, you might as well make it sound nice, pleasant, formal, and do it in some sort of standardized variant of the language. That said, we do have renmants of how people spoke more generally outside of these formal contexts that let us know that the flowery language isn't how most people spoke. Oftentimes I find evidence of it in my work when someone's moaning, complaining, or laughing about how some other person or group speaks (language pedantry, I'm sure, is as old as language itself). But those texts aren't the ones we normally are exposed to in Latin or Persian or other major literary languages of the past, so we often end up with a distorted view of how those languages worked at a quotidian level. 

Here the hyphenated and spaced forms are more frequent than expected. So what this test is showing us is that the hyphenated and spaced forms are much less marked for firefighter than comparable forms for fireplace are. Note about R I realize this is a lot of code, and if you're not used to working with R, it's not the most intuitive programming language to read. But Stefan TH. Gries has two good books on linguistics with R if you're interested: Quantitative Corpus Linguistics with R and Statistics for Linguistics with R. There are a lot of good Python resources out there too, if you'd like to work with a more human-readable programming language. But for statistics, R is really the best. 

So here too, the difference in distribution of the three variants is incredibly significant. What this test doesn't tell you is which form is marked. For that, you only need look at the raw frequencies compared to the expected frequencies. 

Also, I feel like Florian Jaeger has flirted with this unit of measurement when dealing with information density, but I can't remember an article name to save my life. 

In linguistics you can't really talk about "silent letters". Orthography is a step or two removed from phonetics in most languages, and orthographic spellings rarely have one-to-one correspondences with phonetic sounds. tl;dr: The closest term that comes to mind would be articulated. You could say the /h/ is elided (or omitted) by some speakers but articulated by others. Usually in phonology if you're talking about sounds not being produced, there's some phonological process involved in not producing them, and so the term used to describe them is usually a variation of the name of the process. E.g. elision of /h/ -> elided /h/, excrescence (or epenthesis) of /p/ -> exrescent (or epenthetic) /p/. But there aren't really terms for talking about why sounds are not omitted. One other potentially relevant term: when two different pronunciations are acceptable in the same speech community, as in your 'vehicle' example, it's called free variation. But this is not restricted to pairs where a particular sound is omitted in some varieties and articulated in others. /tə'meto/~/tə'mato/ is another example of free variation in which one vowel sound is different between the two varieties. 

In Spanish, derecho can mean either right (as in civil rights, derechos civiles “civil rights”) or straight (as in straight ahead, sigue el camino todo derecho “Follow the road straight along”). The feminine form derecha means right (as in not left, gira a la derecha “Turn right”) 

In English (and certainly in the Romance languages, and similar to what Tim Osborne mentions with older German), when you use the possessive adjective as a determiner, the noun is treated as definite: 

Also, a French questions I don't know the answer to. Does pas require ne? If so, and you wish to exclude ungrammatical phrases, you will need to set up a rather large alternate pattern. 

I'd imagine that most languages with a definite/indefinite distinction have the possessive adjectives imply definiteness, with any other forms (via pronouns, etc) allowing for idefiniteness determiners. 

The above is summarized from “La influencia del sustrato euskera en hispano-romance” (Mary C. Irtbarren-Argaiz). She goes into great detail evaluating the claims and sourcing them, some of which she doesn't necessarily agree with, but I've included some of the alternate views she mentions. 

The only way in English is to switch to an alternate structure. Ditto in the Romance languages, which language depending have different ways of adjusting structure so that the possessive adjective (if it stays as an adjective) loses its determinative prowess. 

It would really help you out if you write things out with /x which ignores whitespace. Using it allows you to document your regex which helps find inefficiencies in it and also ways to improve it. Here's what you have (I've not escaped the actual spaces you encoded, but it should give you an idea of how much easier it is to read).