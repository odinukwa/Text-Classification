That is the problem with Wordpress where the installation to Domain A would take over before you ever come to the DomainA,B Wordpress installation because of the Wordpress mod_rewrite rules inside the .htaccess file. Can you answer why would you use such setup, to have a Wordpress installation inside a Wordpress installation ? It would be far more logical to have separate installations, for example: public_html/domaina.com/ public_html/domainb.com/ Are you using cPanel for this installation? 

This would sound like there is a modified SSH binary set on your server, I would suggest running rkhunter and/or chkrootkit if there are any backdoors installed, if any are found I would suggest reading up on them and cleaning them up. Also check your root accounts history to see what is happened, if the attacker left any traces. You can also reinstall the SSH package ( or any other package that would be exploited )trough your package manager ( rpm/apt-get or any third package manager ) that would replace the binaries with the default binaries, rerun the rkhunter and see if there are still any matches. And lastly, you could do a check which packages have the files modified, an example for RPM based systems: Following command would list any changes to the RPM packages: 

I'm trying to build a customized version of a nginx package for Debian/Ubuntu which had a different set of modules opposed to the default version. What would be the fastest way to modify the debian/ structure (and which files) if I'd want to rename the package from 'nginx' to 'my-nginx' for example? I've got the source deb package unpacked and which files I'd need to modify in nginx-1.4.5/debian/ directory (holding the control, rules.. files) have buildpackage generate my-nginx-1.4.5.deb package instead of nginx-1.4.6.deb package. I appreciate your help! 

Try using http-vhosts.conf file for the Directory block to allow access to directory, place it in :80 and :443 vhost file: ``` 

How are the disks setup in the server, I would suppose that you aren't using any RAID implementation to speed up the disk read/write speeds (as disk usage shows 33TB for the LVM group) and this is your problem. As previous answers are correct, the 'wa' stands for disk I/O wait which is extremely high, practically locking up your server and placing any process that depends on disk I/O into uninterrupted sleep state (processes marked as "D" in top) - the problem is that you can not clear these processes by sending SIGKILL signal to them, they will not respond until they get what they wanted from the disk, and then they will exit. Processes in D state can be cleared either by reducing your disk I/O wait which will clear the processes or reboot the server, and rebooting is the last thing you want to do, if you run into a need for a filesystem check (fsck) it would take a long time to go trough 33TB of data on slow disks, it even takes too long on RAID setups. Look into getting a server with a quality RAID card and setup your disks in RAID6 if you're going with high number of disks per server, this way you'd get better speed and redundancy if you have a disk failure, since RAID6 can withstand two failed HDDs, where other RAID configuration can withstand 1 failed disk. Also when you have the new server setup, look into RAID array health monitoring, einarc would be helpful to determine the RAID array and display if there are any problems with your RAID array. With the RAID setup you would be sacrificing a bit of disk space but you would get better read/write speeds compared to the current setup. If you have 12 x 3TB drives and placing them into RAID 6 configuration, the formula to calulate the disk space you'd have is , so on 12 3TB disks you would have 30TB of free disk space: 

For ubuntu the apache and PHP user is www-data. Run and see if that fixes your issue. Also don't use 777 for the file permissions as Ignacio Vazquez-Abrams stated "0444 or 0664 for files, and 0555 or 0775 for directories" 

On two of our servers we have an Ubuntu LAMP setup with PHP code designed to allow large image and audio uploads. One of our clients is having an issue where they are unable to upload any files larger than ~4MB from any computer in their office. They get a "The connection was reset" this error in FireFox and in chrome they get "Error 101 (net::ERR_CONNECTION_RESET): Unknown error." In chrome I can watch the upload percentage and see the upload fail around the time ~4MB is reached (53%) on an 7.79MB file. It's not a speed issue as I've successfully uploaded files from slower networks. Apache is returning no errors in the logs, and is recording the start of the post in the access log. The PHP.ini is set to allow files up to 500MB and we have other clients doing this with no problems. I've upped the script timeouts of PHP as well. I've tested uploading from a number of other locations to the servers with no errors; and I've also tested uploading from the clients location to other services, also with no errors. I'm really at a loss i can't tell if it's a server error a client and I'm hoping someone might know of something I can use to test or perhapses possibly a setting I might have missed. 

Found the answer if anyone is interested, here it is. Turns out the instructions I received from my predecessor were missing a key command which needs to be run after the transport file is updated. 

I'm working with postfix on fedora 9 and I'm attempting to make some changes to a system setup by my predecessor. Currently the postfix server on [mail.ourdomain.com] is setup to forward mail sent to two addresses to another server for processing. The other server [www01.ourdomain.com] receives the email and sends it to a PHP script to be processed. Then that PHP script generates and sends a response to the user who sent the original email. We're adding more web servers to the system and as a result we've decided to move these processing scripts to our admin [admin.ourdomain.com] server to make them easier to keep track of. I've already setup and tested the processing scripts on [admin.ourdomain.com], and on the mail server doing the forwarding [mail.ourdomain.com] I added [admin.ourdomain.com] to /etc/hosts and also added another, aside from the one for [www01.ourdomain.com], entry to /etc/postfix/transport for [admin.ourdomain.com]. I also restarted postfix as well. I've tested the communication from [mail.ourdomain.com] to [admin.ourdomain.com] using telnet and the [admin.ourdomain.com] domain and everything runs correctly. But as soon as I change the forward address and attempt to send an email to the mail server I get a bounce message stating "Host or domain name not found. Name service error for name=admin.ourdomain.com type=A: Host not found". If I change the forward settings back to [www01.ourdomain.com] then everything works fine. Is there some setting I'm missing in Postfix? The server itself and telnet work fine it just seems to be postfix that's not able to discover the location of [admin.ourdomain.com]. 

Note: Running a similar index.php test against one of my servers(VPS hosted), I see the following: index.php load about 25-35ms consistently. There are some icons that attempt to load, which drives up the total page load time to around 200-300ms. 

Add the IP of the server to your client's /etc/hosts so that no DNS queries are involved. Run the test again and see if you have more consistent results. If the results are consistent, then the variability is due to DNS resolution. If switching to static IP doesn't help, try referencing the host via IP address in the addressbar when you test the page with your web browser. On the off chance the /etc/host change didn't take. If using fixed IP doesn't clear the variability, then try a local test from the server itself, to rule out network variability. If you still see the issue from a localhost test, then the issue is with your app stack on the server. :( 

If there are only 3 rows that are showing the problem, correct the key field for them, if possible, perform a dump and import of that instance and see if the error doesn't present itself again. I'm guessing, it should go away. 

Is the delay due to initial/pre-first index file load? If so, this could be due to DNS resolution. You can take out this factor in the following tests: 

Ah... good ol'Solaris and it's wonderful default policies. When you created the users on a new system install, there was an account expiration time set. This is in the /etc/shadow file, I believe. You will need to unlock the account and then set an expiration time far far into the future. I've tried the "never expires" flag in the past, but it's never worked as expected. You can fix it on a system you've been locked out of by vi'ing the /etc/passwd file after booting into recovery mode. Helps alot if you have a clean working Solaris box you can create a test account and set the expiration flag properly on, and transplant that. Yes, the above is a bit of a fudge. Edit: Corrected file from /etc/passwd to /etc/shadow. $URL$ and $URL$ What does one of the locked accounts look like? (A shadow line, but without the password hash)? 

First thing, check to see whether the rows in question exist in that state in the original database. Chances are, what happened is one of the following: 

VMware's server and vSphere products support some USB 1.1 functionality for the VM guest OS(s). If the dongle requires USB 2 features, you might have problems. You will need to explicitly configure the USB device to be assigned/allocated to the VM in question. If your Host OS takes hold of the device, then it will prevent proper operation with the Guest VM. Same story if you fire up a new VM and it includes the USB suport, it may also take the USB device. 

First thing that comes to mind is: are you using a FQDN/DNS to initiate a connection to your memcache server or are you using an IP address or local socket? If you are using a hostname, you might be losing some time in the name resolution. Try either putting the FQDN in the clients and servers' /etc/hosts and restart so that nothing gets cached, or change the reference to be IP address based, and see if you don't see an improvement.