where is the number of rows in each partition. Taking above into consideration, below will explain : 

From the client application side, your application connection string should use pointing to secondary or mirrored server. 

Log-shipping is not meant for this purpose. Its a warm / stand-by database that can be brought online by restoring the log-backups and the tail backup of the primary server (if possible) with minimum data loss. When you want to run reports against a database, I would suggest you to go for Transactional Replication (if reports are needed for near to real-time data) or database snapshot (if data can be a bit stale and you are using enterprise edition). Replication latency will depend on the amount of data you are replicating, the n/w bandwidth, number of articles and the amount of activity/transactions on the publisher database as well. 

Aaron has answered your question perfectly. I am just adding the full script that I wrote to test in my environment. Below is the script : 

Doing so, only the role reversal happens and mirroring direction is reversed - principal becomes mirror and vice-versa. Note that MIRRORING is not BROKEN. Now once you verify everything is OK, then you can break mirroring with below steps : Turn mirroring off (break mirroring) on the mirror DB. 

You can query to find out the read and write latency. You can use the script from here or here - this is snip from my project of designing a comprehensive SQL Server health checker (this is something internal for now, but planning to opensource the code soon - as a thank you to sql server community !). Also, read this blog post by Erin Stellato - What Virtual Filestats Do, and Do Not, Tell You About I/O Latency. This blog post has a script that you can use as well. 

This is a great question and someone will be in this situation and needs a rescue out of it .. All the credit goes to codykonior 

Whenever you do large updates/inserts to you tables, highly recommend to update stats and reorg/rebuild indexes. That way query optimizer does not select or produce bad plans on wrong estimates. 

I had issues setting the database in single user e.g. a sql agent connection might make it first and then you will struggle to take that database out of single_use. Instead, I prefer OFFLINE. 

Or you can use sql sentry's plan explorer tool and see the tab that will list the and for actual execution plan. If you cannot turn on the actual plan then you can look into plan cache as described below. 

Answering my own question that might be helpful to future visitors .. Aaron's comment made me thinking if we dump the data into temp table would it speed up ? Yes it indeed speed up as due to large number of Availablity groups 53 (I know thats a lot and we have plans to offload them soon), and selects were taking considerably long time. Below tsql runs in 1 min and 03 secs :-) 

You dont need to have them use . Only An intermediate will break the . What you can do is explicitly privilege to developers or developer group. Alternatively, just create a ROLE and deny backup log to that role. So all the users in that role will inherit the permissions. e.g. 

Below T-SQL will give you the log reader agent. You can use the agent name or job_id to drop/delete the log reader agent. 

Your best bet is to use : Discover, Diagnose, and Document ALL Your SQL Servers On Your Coffee Break using SQL Power Doc written by kendal vandyke This is written in Powershell. 

The reason might be because the full backup's wont be matching the Differential backup's ==> meaning if the values do not match, then you would need a full backup followed by a diff. 

Instead of relying on SSMS (its flakey sometimes - you might have to refresh, etc), always use T-SQL. Below script will provide you comprehensive result of what permissions you have set (filter out as per your need) 

All the above steps you can script out and automate. You can refer to the script that I wrote to rename the database - both logical and physical and adapt as per your needs. 

Script out the database SCHEMA_ONLY and recreate an empty database on the destination server. Below are the screenshots : 

For Documenting sql server, I highly recommend just recently released : SQL Server & Windows Documentation Using Windows PowerShell written by Kendal Van Dyke Brief description from the link : SQL Power Doc is a collection of Windows PowerShell scripts and modules that discover, document, and diagnose SQL Server instances and their underlying Windows OS & machine configurations. SQL Power Doc works with all versions of SQL Server from SQL Server 2000 through 2012, and all versions of Windows Server and consumer Windows Operating Systems from Windows 2000 and Windows XP through Windows Server 2012 and Windows 8. SQL Power Doc is also capable of documenting Windows Azure SQL Databases. 

It depends ! I have it every week on my prod servers with a maximum of 10 error logs ( setting in sql server log --> configure option) . This is official from Microsoft - How to manage the SQL Server error log ? 

For backup and restore you can use PowerShell (make sure you use backup and restore method) or tsql. You can completely automate the above pseudo code using sql agent job. 

The Blue (Current) will have the current version of the schema/build or product and will be your "LIVE" environment. At the same time Green will be your staging/testing environment wherein you will upgrade your schema/build or product to the NEXT release, do a full regression test and get signed off by your business users. Once happy, during a cut-over period, you will promote the Green to be your "LIVE" environment and demote the Blue to be a preprod/staging or testing for the next release. 

This is a really good idea to delete in small careful batches or chunks. I would add a small and depending on the recovery model of the database - if , then do a and if then do a to avoid bloating of transaction log - between batches. 

Since you want to use BPA, this PowerShell script will do the work for you. Another thing to be aware is that you can use below freely available excellent tools for checking health/best practices for SQL Server. 

You have to really read up on AlwaysON. AlwaysON ships only log blocks. So there is no fileshare concept. On the windows cluster, you can set a witness as fileshare. So, the witness (disk or fileshare) is not AlwaysOn specific. It is required by the Windows Server Failover Cluster to maintain quorum during node failures. Check What exactly is a File Share Witness and when should I use one? Some good references to get you started : 

SSIS code behind is actually a XML value and all components of package will be represented as XML node values within it.This XML can be parsed to identify if it has a reference for our searched table or column. Finding SSIS Packages having References to a Table or Column will help you. 

(you have lot of sub questions as part of main question .. will get straight to answering your questions ... ) 

The identity crisis in replication - by Hilary Cotter All about “Identity Range Management” - by Chris Skorlinski 

is a deprecated. You should use . If you change your server name after installing sql server then you have to make the entry in which can be done by and 

Configure Database Mail Create a sql agent job to run below t-sql (you dont need a stored procedure for what you are asking, but below code can be easily converted into a stored procedure --> I will leave that up to you - hint: just look for ) 

Below are general recommendations and your milage may vary depending on you workload running and your IO subsystem, server hardware configuration, etc. At SSIS level, you can look into below things to speed up data read and data load : 

You can even use below sql to create new blank table as the will always be false. Note that it wont create any indexes from old_table into new_table. 

I would not set the value to (limitless). I would instead find out the max datalength of your lob data and set it accordingly with a 10% buffer. This way you have more control of what and how much gets into distribution. I can see that in an unlikely situation, setting of can cause high network latency if the blob data to be replicated is of a much larger size. 

I would highly recommend you to ditch tsql and adapt PowerShell. It specifically adds more value to what you are doing .. Make sure you use Backup compression and instant file initialization on source and destination server instances. from dbatools.io e.g. Usage : 

There is no Buy in your table. You only have Sell and Purchase. Below is a good starting point for you to get (Purchase,Sell) combo : 

Since you are using Developer Edition (and is cheap as compared Standard or Enterprise), you are better off installing another instance with 5GB Max Memory. Put the databases that you need less memory on this instance. The rest of databases you can put on the instance with more memory. Read up Tibor's blog post on Restricting memory using Resource Governor which references the link that @shanky referenced. 

There are many system caches available in SQL Server. I am referring to SQL 2008R2 (as I tested on it). Below query will return all the caches available : 

Use T-sql to query sys.databases and backup your databases. one free solution is to use Ola's backup solution 

You can find that out using table. To automate that, you can use RestoreGene - TSQL or PowerShell version 

So to answer your question, a COPY_ONLY backup cannot be a part of a restore that involves T-log backups (doing a point-in-time restore). Its whole point is to have a backup set outside regular backup chain NOT impacting the restore sequence. A full backup must be performed on primary database (cant be a copy_only backup). Only T-log backup (as mentioned above) can be done on either primary or secondary with a CAVEAT that it wont mess up the LSNs on the PRIMARY i.e it will keep the LSNs consistent - regardless of where you take log backups in the availablity group. Best is to check the so the log backups will use the Availablity group backup preferences for Log backups. Refer to : Performing Transaction Log Backups using AlwaysOn Availability Group Read-Only Secondary Replicas - Part 1