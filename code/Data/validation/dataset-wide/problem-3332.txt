Let's say there are three people, Bob, John and Jane. There are also three languages, L1, L2 and L3. John is a fluent speaker of L1 and L2. Jane is a fluent speaker of L2 and L3. Bob only knows L1, but wants to learn L3. John, to help his friend Bob, translates a list of vocabulary from L1 to L2. Then he passes it on to Jane, who translates the words from L2 to L3. Thus, Bob has a dictionary of words between L1 and L3, as a tool for learning L3. The question is, given any set of three languages, is there likely to be significant "telephone game" or "chinese whispers" effect by doing this? Does Bob risk learning inaccurate or plain wrong definitions of words by working this way? Are there any good examples of this? Would this depend any on the language families of L1, L2 and L3? Would this be more, or less, complicated with full sentences, than with loose words? 

I'm creating a piece language learning software, which will include a component that lets the user read texts with a translation on the side. The texts will be chopped up into segments, and have the feature that, if you hold your mouse over a certain segment, the corresponding segment in the translation is highlighted, so that you can easily keep track of where in the text you are. The question is, how small can I make these chunks, before translation between different languages would be unnatural, stilted or impossible? The safest thing to do would be to simply cut the text in pieces at full stops. This however, would lead to certain really long sentences, in which the reader easily could lose track of where she is, thus making the program a lot less useful. The question then is, could I cut the sentences into smaller portions than complete sentences, and still expect every part to be translatable on its own into various languages? If so, where would I make the cut? For example: "He was a poor man who certainly would not be able to afford this car" Is it reasonable to expect that I here could cut this sentence in two, between man and who? Can I expect all languages to have the structure necessary to cut this sentence into two logical pieces like this? I mean, I'm thinking that, since for example in Spanish, the subject of a phrase is usually omitted (as it is expressed by the conjugation of the verb), I could not segment my sentences into phrase constituents without running into trouble if translating my program into Spanish. As there is a possibility that my language will be translated into languages whose structure I'm completely unaware of, I need to chope the sentences up in a way so that I'm sure not to get any unpleasant surprises during translation. So what I'm wondering is how I can chop up my sentences without avoiding trouble when trying to translate the individual parts into different languages. I hope I have phrased my issue clearly. Any insight on this matter is much appreciated! 

Full references: Carpenter, Bob (1997): Type-Logical Semantics. Cambridge, MA: MIT Press. Gamut, L.T.F. (1991a): Logic, Language, and Meaning. Vol. 1: Introduction to Logic. Chicago: University of Chicago Press. Gamut, L.T.F. (1991b): Logic, Language, and Meaning. Vol. 2: Intensional Logic and Logical Grammar. Chicago: University of Chicago Press. Heim, Irene & Angelika Kratzer (1998): Semantics in Generative Grammar. Oxford: Blackwell. Zimmermann, omas Ede & Wolfgang Sternefeld (2013): Introduction to Semantics. An Essential Guide to the Composition of Meaning. Berlin and New York: de Gruyter. 

The mechanism of Agree(ment) has been redefined since Chomsky 1995. Since Chomsky 2000, 2001, it does not rely on Spec-Head agreement anymore. Regarding the relation between the subject and V, if suggest to have a look at Pesetsky & Torrego 2007, who give important references and develop a slightly different, but influential departure from Chomsky's 2000, 2001 definition. Adger 2003 is a good book, but note that his version of agreement is non-standard (as it work up- and downwards). Literature Chomsky, Noam (2000): “Minimalist inquiries: e framework”. In: Roger Martin & David Michaels & Juan Uriagereka, eds.: Step by Step. Essays on Minimalist Syntax in Honor of Howard Lasnik. Cambridge, MA: MIT Press, 89–156. Chomsky, Noam (2001): “Derivation by phase”. In: Michael Kenstowicz, ed.: Ken Hale, a life in language. Cambridge, MA: MIT Press. Adger, David (2003): Core Syntax. A Minimalist Approach. Oxford: Oxford University Press. Pesetsky, David & Esther Torrego (2007): “Thee syntax of valuation and the interpretability of features”. In: Simin Karimi & Vida Samiian & Wendy K. Wilkins, eds.: Syntactic derivation and interpretation. In honor of Joseph E. Emonds. Amsterdam and Philadelphia: Benjamins, 262–294. doi: 10.1075/la.101.14pes. 

There are also languages that have more than singular, dual, plural. A good overview is provided by Corbett 2000, which is an really good overview over the category of Number in general. Here are some examples he gives (§ 2.2): 

I really depends on what you are after. Here is a list of my favorite text books, together with some short annotations. 

It is a controversial question if there is a true quadral (for “four) -- and some languages also have special encoding for “large numbers” though there is a lot of variation going on. The wikipedia article on grammatical number is also quite good. Literature Corbett, Greville G. 2000. Number. Cambridge: Cambridge University Press. 

Still the best overview over the historical development of the (technical) of presupposition is provided in the first part of Beaver 2001, which you can access here. A more concise overview (by Beaver & Geurts) can be found in the Stanford Encyclopedia of Philosophy. The Ohio State University also hosts an extensive bibliography on presuppositions. Some important references Beaver, David I. (2001): Presupposition and Assertion in Dynamic Semantics. Stanford: CSLI. $URL$ Beaver, David I. & Emiel Krahmer (2001): “A partial account of presupposition pro- jection”. Journal of Logic, Language and Information 10.2, 147–182. doi: 10.1023/a: 1008371413822. Beaver, David I. and Bart Geurts (2011): “Presupposition”. The Stanford Encyclopedia of Philosophy. Winter 2014. $URL$ Lewis, David (1979): “Scorekeeping in a language game”. Journal of Philosophical Logic 8, 339–359. Russell, Bertrand (1905): “On denoting”. Mind 14.56, 479–493. url: $URL$ org.ubproxy.ub.uni- frankfurt.de/stable/2248381. van der Sandt, Rob (1992): “Presupposition Projection as Anaphora Resolution”. Journal of Semanticsition projection as anaphora resolution 9.4, 333–377. doi: 10.1093/jos/9. 4.333. Strawson, Peter F. (1950): “On referring”. Mind 59, 320–44. Stalnaker, Robert (1978): “Assertion”. In: Peter Cole, ed.: Pragmatics. Syntax and Seman- tics 9. New York: Academic Press, 315–332. 

Ranging position. The syllable. This number tells you how often this syllable can be heard when one million words are spoken (which means, that frequent words are repeated many times and therefore theirs syllables are counted more often) Take a dictionary of all German words, where flexions of the same lexeme are distinct words (run, runs, ran and running would be listed as four different words). Count how often the syllable appears in this dictionary (the dictionary itself contains 365.530 different German words.) 

I'm not interested in the 4th column. English: $URL$ This list has only 3 columns, where #1 and #2 are identical with the first two columns of the German list. Columns #3 is the same as the German col#3, but in the German list you have counts per million, in the english you have percent, which is just another representation of the same thing. How would I use those lists to create an all-language-list? In the english list I would convert the numbers in column 3 into counts per million like in the German list. Then I need the number of native speakers per language. Such a list can be found here: $URL$ As you see, English had 360 million native speakers in 2010, and German had 89 million native speakers in the same year. So I multiply the (converted) english numbers by 360, and multiply the numbers in columns #3 of the German list with 89, and then merge both lists. If there are syllables used in english as well as in German (like [ɪn]), I add both wighted numbers. Then I sort this list again by those numbers. The result is a list of the most frequent syllables of the German and English spoken part of the world. And because I am interested in the most frequent syllables, it is safe to ignore rare languages, among which you will find all languages, that not have been studied. And to give you an example what I am not looking for: $URL$ There you find numbers of digrams and trigrams, but this are not phonetic syllables! 

This list is sorted by the 3rd column, and this is exactly what I want. This column answers this question: 

I am looking for a list of the most frequent syllables of all languages spoken on earth, sorted by frequency. I found such lists for english and for german, but I want to get a list across all languages. Suppose you can count every syllable that is spoken on earth within 24 hours. Syllables from languages with many speakers like Chinese (Mandarin), English or Hindi are more often used then syllables from rare languages like Esperanto or Klingon and so are ranked higher in the list. And within one language there are syllables that are more often used then others. I know, what I want will be hard to realize. So I also would be happy with separate lists of the languages with many speakers, lets say with the top-200 syllables. (I'm not interested in rare syllables, my focus is on common syllables. For the same reason I'm not interested in rare languages.) And I really want spoken syllables, not written di- and tri-graphs ("" is a trigraph, not a syllable. It can be the written representation of the syllable but also part of )