I have search online but not found what I am looking for. The problem/query is to my knowledge a database in SQL Server should have One .mdf file and maybe some .ndf files and One .log file. I have seen many database with one mdf and multiple ndf files. But recently I came across some database on a server where every database had multiple mdf files. I took a backup of some database moved them to another server and restored the Primary file as .mdf and all the other files as .ndf obviously except the log file it was restored as .log. Now my questions are: 

I have a table where 15,000 to 20,000 rows are being inserted every hour. Table Schema is something like 

As mentioned by Aaron in comments section that it can cause your insert statements to fail if someone passes a values longer than your column length (I would call this a bug in your code). Anyway, from performance's perspective, execution plan may look the same but SQL Server is having to do slightly more work when dealing with bigger data types as compare to smaller data types. If you switched on IO and Time statistics on before running these two inserts, you will notice that the insert with bigger variables are taking slightly longer than the smaller/correct size variables. Insert with large variables 

Even though you are looking for records with a string anywhere in there but you will benefit from the Index on column. 

for me details about the error message read this article I used the method suggested by but installed and wala it worked. Had to do a lot of reading and tried a lot of different methods to fix it, thought it will be nice to share it with you guys. cheers thank you. 

Hi I am trying to create a SQL Server Failover cluster. Windows Cluster is configured and working as expected but now when I try to install SQL Server it throws the following error: 

I have sql server 2008 R2 64bit Developer's Edition Installed on my machine. And Microsoft Office 2010 Professional 32bit. I have been trying to import some Excel data from an Excel sheet into a sql server database. I have used the following query to do this: Query 

I have been looking for any information online but couldn't find anything.... Any suggestions any solutions any pointers in the direct direction is much appreciated....... 

Note You are doing an Insert here, would have nothing in it and it will always return null. Delete is only useful when you are deleting or updating data, when deleting the delete values can be returned using delete.xxx and when updating the old values can be returned using the deleted.xxx. But you have no use for deleted in your case since you are only inserting, you should be using . 

This reduced the number of VLFs from to . The end-users has seen a sudden improvement in the application performance. Now one thing I am not sure about is, if 20 VLFs is the right number of VLFs for a 36GB log file. But it seems to have a good impact on the performance of the database. 

Another option that was suggested to me, was to create another table, Populate that table from this current table and index the living hell out of it to help all the possible select queries. Read data from this duplicated table. Keep the original table as it is with minimum indexing, for quick inserts. Since I am duplicating the data, I know this option violates the basic rules of normilazation, but this sounds like a good option for keeping inserts and reads as fast as possible. The problem is how can I maintain this near real time copy of this table inside the same database. I do not want to use any After Insert triggers as this will end up firing 15,000 to 20,000 times an hour. What other options I have to keep this near real time copy of table in the same database??? Or maybe another approach altogether, any suggestion or pointers in the right direction are much appreciated. 

Important Note The SQL Server has no external IP, it can only be seen from the reporting server. Could this be the reason that the connection is failing? I mean does the report builder try to obtain a direct connection to the SQL Server when launched? Or is there anything else that I have missed out? Any pointer any suggestions are much appreciated , Thank you. 

Finally found the a solution online which lead me to the actual solution of the problem. Apparently it is an issue with SQL Server 2008 and installing the Service Pack is the answer to this. How can we install a service pack while installing the application: See this article by . I tried to install the Service Pack 1 but it failed with a different error messages: 

which I think indicates that it was standard edition that was installed originally, yet after the installation was finished and the sql server service started for the first time the windows log show the following: 

Is there any wisdom in having multiple .mdf files for a database? Is there any drawbacks of having multiple .mdf files? 

Checked the Processor and Memory usage on the sql server (nothing is maxed out) plenty of free resources. Index fragmentation was minimum yet rebuilt the indexes and updated statistics. No changes has been made to the code in application (application code/sql server code) hence poor performance because of the poorly written code is unlikely to be the cause of overall poor performance of the application. Finally got Paul Randalâ€™s script . The result of the script shows that sql server has to wait a lot when writing to log file. The biggest wait type is WRITELOG. 

I have been given a server (SQL Server 2008R2 64 bit) where our application is running. There has been a gradual decrease in the performance of the application. Now it has come to a point where performance has become a serious concern. I started to investigate and went through the following steps. 

Let's say you are only interested in the rows where it has a value of and this the only value you always check for, then you can add another column (Computed) to the table, something like... 

To my knowledge, If these were all physical hard drives, having multiple drives for all these files (tempDB, Log file, backups, database files), would definitely benefit from parallel processing. But is there any drawbacks of having one massive Virtual Hard drive vs multiple Virtual Hard drives as in reality, when Sql Server is reading or writing , it will be all done from one Physical Hard disk? Is one method preferred over other? Any suggestions or pointers in the right direction is much appreciated. Thanks 

SQL server always append some random number in the end of a temp table name (behind the scenes), when the concurrent users create temp tables in their sessions with the same name, sql server will create multiple temp tables in the tempdb. I created 3 temp tables called in three different sessions in my SSMS, now if I go to the tempdb I can see the temp tables created there with a random (unique) string appended to each temp table's name. 

The above query returned the databasename and number of VLFs (1600) To reduce the number of VLFs this is what I did: 

I am trying to create a New Cluster for Always On Availability Groups. On when I try to add the cluster nodes I get the following error: . After some research on the internet I found out that it could be because the Nodes I am trying to add were previously members of another cluster, even though the cluster doesn't exist anymore but the nodes are still acting as node to an existing cluster. One solution that I saw on several places was to use powershell to forcibly remove the node; But when I execute the command it just sits there and doesn't do anything. 

After a lot of digging around I could get an answer and then eventually I got Microsoft involved to help me the problem. MS solution architect confirmed that the Report Builder requires a direct connection to SQL Server when launched hence the working with data sets in the report builder failed. Apparently this is BY DESIGN and it is not going to change. This was in SQL Server 2008 R2 but the same is true for SQL Server 2012, 2014 and 2016. Not sure about 2017 but I doubt it very much that this has changed in 2017. We ended up provided a client machine on the network to which end users connected remotely only to work with Report builder, it is a poor solution but it worked at that time and we needed a quick fix for it at that time. 

Keep indexing minimum, Primary key Clustered index and a Datetime index and keeping the inserts very fast and get a performance hit on selects. 

Error Message Yet every time I execute the select statement to get data from Excel sheet I get the following error. 

Since you have made sure that you have SQL Server installed on your machine all is left is to make sure that you follow the following steps to create a database. 1) Go to right click and Select 

Further investigation and "Googling" solved the issue, The issue was with drive, It was compressed and SQL Server did not like that. Solution Removed the compression from Drive and this time backup completed without any errors and much faster. 

A colleague of mine rang me today to told me that on one of our servers the SQL Server has stopped working. If he tries to run the management studio it throws and error saying 

The user must be a member of server role for user to have enough permissions to create a database. You can execute the following statement to make a user member of server role. 

to connect to local server and default instance just use any of these , , or . If you are trying to connect to a named instance on your local machine just use any of the above followed by . i.e , , or . Note If you want to connect to the default instance you just use the machine name, if you are trying to connect to a Named Instance then you have to use the machine name and the Instance Name.