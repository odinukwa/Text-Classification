The only language that has "hello", "please" and "thank you" is English. Other languages might have other words that they use in somewhat similar circumstances, but I don't think any language has an expression that is used in all of the places that we use "thank you". Indeed, Americans and Brits don't use "thank you" in exactly the same way (they say "Cheers" in a lot of contexts). Likewise with "hello" and "thank you", there isn't one fixed expression that is used on the phone and when encountering person on the street in any other culture that I know of, and useage of "hello" is not even uniform in US culture. 

There is a debate over whether the p/b distinction is based on voicing or aspiration, owing to the fact that the ostensively voiced stops are rather different from those of French or Hindi. Between voiced segments (especially vowels) they are voiced, but word-initially and finally they may be voiceless unaspirated stops and not voiced (this is speaker-dependent and also dependent on place). There is a complex set of factors that govern whether there will be vocal fold vibration. In "encouraged", the factors favoring devoicing are very high -- following a long period of obstruent closure, syllable final position, no following voiced segment. So it is quite likely that vocal fold vibration has been extinguished in this context. This is a non-neutralizing process, so even if vocal fold vibration has ceased in the final stop of "edged", it is still distinct from "etched". You would have to look at the phonetic details of a particular example recording to say what difference, if any, could be localized to [d] in this pair. 

There are recordings of Lithuanian at the UCLA phonetics archive, though you would have to do some work to determine what accent type a given word is (probably involves nothing more than a dictionary). The 1972 recording is lousy quality so not worth listening to. The last two (speaker from Kaunas) is probably not worth messing with because of uncontrolled list intonation that screws up pitch. There is some of that with the Illinois and Panevežys speakers especially with minimal pairs, but in just plain readings of words there seems to be a pitch distinction preserved. This is a good object lesson n how not to record data in a language with pitch distinctions. There is also a substantial body of Lithuanian samples on Forvo where again with some work you might find what you want, but at least you are getting pronunciations where the speaker just says the word and isn't doing it in a rise-fall alternating word-comparison fashion. Unfortunately, there is no FSI Lithuanian course. You could try this paper on acoustics of Lithuanian, which has 3 speaker icons implying recordings, though often PPT sound files get left behind or rendered unplayable. 

For the specific pronouns that you mention, the explanation is that those languages are Indo-European and have a common historical origin (*me, *tu). This happens to extend to Uralic, and the branches of what might be Altaic (if there is such a family). So there are conjectures that these language groups may also be historically related. This article gives reconstructed pronouns for various language groups. There is a fair amount of controversy over whether the similarities are coincidence, borrowings, or evidence of genetic relation. 

I don't understand the alternative question. But, Gricean maxims are not absolute rules about human language, they are defeasible assumptions about human social behavior which aid a person in getting from a grammar-based meaning to a probable actual communicative intention. The maxim of brevity does not say that the word "elephant" is somehow amiss because it's too long, nor does it criticize Sanskrit verb inflection because it is too obscure (not like Turkish). Grammatical features of a language are above reproach. There is a way in which Gricean analysis might be useful in thinking about reduplication, in the realm of the linguistic function of reduplication. It is reasonably common in productive and optional reduplications that the meaning is hard to pin down, so that 'cut-cut' might be used to talk about disorganized cutting, or multiple cuttings, or extended periods of cutting. Gricean analysis can help you discern the difference between cut-cutting an onion vs. cut-cutting a forest. At some point, the vague meaning conveyed by reduplication may be grammaticalized into "habitual action", "repeated action", or "insistent action". At an early stage in the development of reduplication, a hearer might be presented with an anomalous form "cut-cut", and have to wonder "what the heck does that mean". A communicative intent might be inferred from context, where reduplication becomes a meme, and eventually a hard grammatical property. 

I think the problem lies in the "on any practical definition" part. After decades in the field, I still don't know what the difference between agglutinative and polysynthetic is. Imbabura Quechua is an "agglutinative" language with a small morphology, and Sanskrit is an analytic language with a big morphology. Counting morphemes doesn't help, you have to have more sophisticated metrics of "combinability" and "functional uniqueness". Even if such notions were computationally defined, processing data from languages would require a lot of work, compared to what's required to determine if the dominant word order is SOV. 

The differences in presentation reflect the nature of how consonants vs. vowels are produced. The arrangement on the horizontal axis reflects location of the major constriction, but is mapped in terms of the entire vocal tract as a straightened tube for consonants, vs. just the tongue body for vowels. The vertical axis for vowels iconically represents degree of constriction, but for consonants that is only half-true (plosives and fricatives). Since there are separate symbols for nasal or phonatory differences in consonants (and not in vowels), the vertical dimension has to be recruited to also represent those consonant properties. There are more degrees of constriction for vowels compared to consonants. 

In the modern context, we can observe that Norwegian and Swedish are mutually intelligible, but Danish is not. Lacking the technology to do the experiment with historical speakers, the only way to figure this out is to see what writers of the time thought. A lot of the records are oral, and written down later, so there is a fair amount of plus-and-minus to such date calculations. It is said that in the Heimskringla, ca. 1230, there is evidence of significant dialect divergence: stirt var honum norrœnt mál, ok kylfdi mᴊǫk til orðanna, ok hǫfðu margir menn þat mᴊǫk at spotti ("the Norse language was hard for him, and he often fumbled for words, which amused people greatly"). The Wiki opines that "From the late 13th century, Old Icelandic and Old Norwegian started to diverge more"; it also reports the Grágás (apparently written down around 1260) as saying that "Swedes, Norwegians, Icelanders and Danes spoke the same language". Finally, "In the body of text that has come down to us from until c. 1300, Old West Norse had little dialect variation, and Old Icelandic does not diverge much more than the Old Norwegian dialects do from each other". (This video demonstrates perils of trying to make guesses about "mutual intelligibility" (a Danish and a Swedish speaker try to pronounce phrases in each other's languages, and the Danish speaker does much better than the Swedish speaker at getting the other language -- is that because of the languages, or the individuals?) 

It's hard to nail down a scientific difference between functionalist and formalist approaches, because the goals and domains of investigation are usually disjoint. If you want some opposite ends of the spectrum, you could compare David Stampe's dissertation on Natural Phonology with this paper. The main question is whether there is an autonomous computational "thing" that we call a grammar. A formalist will say yes, and studies the nature of that computational system. While generativists additionally claim that this computational object is an aspect of the mind, there are non-generativist formalists (certain HPSG practicioners, for example) who make no such claim about the mind, i.e. they just look at the system as a Platonic abstraction. A functionalist, on the other hand, cannot be a Platonist (of course, I may now learn that somehow that has actually happened). A functionalist focuses on why language behavior is the way it is, attempting to reduce language facts to being a result of more general cognitive properties. Some functionalists don't care if there is a small autonomous faculty for grammatical computation, they are just uninterested -- others (e.g. Robert Port, see his Language paper "Against Formal Phonology") are opposed to the concept. Formalists are less interested in functional (non-grammatical) aspects -- they don't deny that there are non-grammatical aspects to language, they are just focused on understanding the grammar part of language. So good formalists have to know how to weed out the functional chaff, and unfortunately, sometimes that doesn't happen and you end up with "formal" theories that basically reify functional expectations (for instance, SPE introduced a formal mechanism of "markedness" into phonology, which reifies various phonetically-based functional tendencies). Fritz Newmeyer is well-known for his investigations into formalism vs. functionalism, and one would be well-served by reading most of what he has written. 

There is no straightforward explanation for Germanic, but influence from "5" is suspected. There is an article (Patrick Stiles, 1986, NOWELE 8: 3-25) which addresses this but it's not available to me. 

Well, to answer the titular question, most languages don't have multiple genders. You could get away with saying that many languages have multiple genders, as long as you take 2 to be the lower bound on "multiple" (which in a certain sense, follows from what "multiple" means). A language can't have only one gender: the logic of gender means that nouns have to be split into kinds. If there aren't at least two, you don't have kinds. There are two kinds of kinds: natural, and arbitrary. The former refers to systems where nouns are classified according to some meaning property, and the latter is the situation where nouns are divided arbitrarily. It appears, from a historical analysis of gender systems, that arbitrary gender systems derive from natural gender systems which have gotten sufficiently complicated that nobody can figure out the natural system anymore, so instead you just memorize things. There are not any attested absolutely arbitrary gender systems, but western European languages come pretty close. So whether most languages with gender fall into the "more or less arbitrary" subset depends on how you draw the dividing line between "mostly arbitrary" vs. "kind of arbitrary". Languages have gender (which isn't just about sex) because it has (had) been useful to say things about the nature of objects. The most common and natural division is animate / inanimate (not masculine / feminine). And yet, there seems to be something attractive to having a male / female distinction. English has almost freed itself of gender distinctions, but we do still have differences in pronouns. Some Kurdish dialects likewise have eliminated noun gender except that it is sort of possible to distinguish male and female human 3rd person pronouns. Indicating male / female on 3rd person pronouns is the most functionally useful way of exploiting gender marking (it provides the most discourse-relevant information), as opposed to arbitrarily deeming "glass" to be masculine and "cup" to be feminine. We're moving towards getting rid of the pronoun distinction, so just be patient and in a few more centuries it will be gone. There seems to be some confusion over arbitrariness. In the architypical natural gender system, gender actually is assigned by rules that refer to semantic property. Since arbitrary gender systems derive from natural gender systems, there are often statistical traces of that rule system. With a sufficiently rich coding system and statistical software, you can always eke out some correlation between e.g. gender and real world properties. 

Questions about there being "many languages" with some property are basically unanswerable since there's no contextually reasonable number that constitutes "many". Anyhow, there are quite a number of languages with VV and VVV -- basically, you just need a language that doesn't particularly care about vowel sequences. You also find CV.VV in languages such as Ancient Greek and many Bantu languages. I don't know what it would mean for these languages to gravitate towards cardinal vowels. In these languages, there are no stress-related reductions so there are not many vowel neutralizations. Vowels are really easy to parse, so there's no inherent problem with long vowels sequences. The languages that you mentioned as having long consonant clusters actually have a decent supply of consonants (you can add Berber, Lushootseed and Bella Coola to the list), so I don't think you can say that they have a reduced set of consonants. Perhaps you mean that only a subset of the consonant inventory can appear in consonant clusters. This is fairly typical, and is observed in English where we don't allow stops after onset stops, obstruent clusters in onsets other that sC (and ʃC for some dialects), and so on. In fact, it might be the case that no language which allows onset or coda clusters up to length N allows all possible permutations of that length -- there is always some sequencing restriction. It is a theorem of the Clements & Keyser theory of syllabification that longer clusters are more restricted than shorter clusters (because cluster restrictions refer maximally to two consonants, and any three-C sequence has to pass all of the 2-C filters, and passing all the filters gets much harder as the sequence grows). 

David Lewis' account of the logic of imperatives is in terms of the possible worlds in which the imperative is obeyed. Here is a handout for a class which extensively deals with the formal semantics of questions. Anyhow, there is more to what linguists do than assign semantic interpretations to sentences. We use formalisms for all aspects of language, and at least for the non-quantitative, the interpretation of those formalisms requires the use of logic. Formal logic is important in interpreting these formalisms, since it provides a clear method of interpretation. Modal logic has proven useful in accounting for the meaning of sentences, and is of no use in interpreting phonological rules. Not every useful tool have to be useful for all problems. 

It is unclear what you are asking. You say that "Japanese has phonetic symbols that correspond to syllables", and I don't know what you mean by "correspond to syllables". I assume that by "phonetic symbol" you mean "a grapheme which represents sound units" (thus excluding logographic writing). There are a number of plausible interpretations of "correspond to", such as "every syllable is represented by a single, unique grapheme" or "each grapheme is interpreted as one or more syllables". Looking only at kana, there are symbols which do not represent syllables. For instance, the symbol ン is a coda nasal, not a syllable. Second, ガ [ga] is a syllable and is composed of two symbols, カ plus that other thing (dakuten) which I don't know how to type independently. There is also a symbol ッ (sokuon) which indicates gemination, and is not a syllable. チェンジ [tʃendʒi] has two syllables but 4 symbols. Perhaps you mean "are there languages where each autonomous symbol represents both a specific consonant plus a specific vowel?". If you are interested in the conventional terminology for classifying writing systems, I suggest reading Omniglot. It is possible that Eskayan and Yi script are the two "true syllabaries" where each grapheme represents an entire and unique syllable. "Syllabary" is the term generally applied to Japanese non-kanji writing, so you could read about "syllabaries" if that's what you're looking for. There are a number of books on the broad topic (Coulmas, Writing systems. An introduction., The Blackwell encyclopedia of writing systems; Daniels & Bright The World's Writing Systems; Rogers Writing Systems: A Linguistic Approach; Sampson Writing Systems).