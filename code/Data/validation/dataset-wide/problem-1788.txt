You started out with this configuration, which is otherwise correct but ESXi can't use a virtio NIC: 

Was it ever useful? Yes, and it still is, for exactly the sort of scenario shown in the ancient example. Messages with multiple authors are supposed to have all of them listed in the From: header, with the Sender: set to the person who actually hit Send in their email program. 

Modern web browsers do not follow the usual rules for IPv6 preference, because doing so would cause very lengthy delays if the client has broken IPv6 connectivity. Instead they use an algorithm called Happy Eyeballs, (RFC 6555) which tries both IPv6 and IPv4 almost simultaneously, with a brief delay between them, and then uses whichever connection it receives the response from first, dropping the other one. This algorithm was meant to work around situations in which the client has broken IPv6 connectivity. When Happy Eyeballs is in use, it is quite normal to see both IPv6 and IPv4 connections from the same host to your server. 

DO NOT symlink to or vice versa. These are treated separately and so you'll need to keep them separate. Ensure that both and have 1777 permissions. 

I would always recommend that new projects start out with the latest available OS version, unless there's some overriding need to not do so. The big stumbling block you may run into is that EL7 cut out a lot of drivers for older hardware, and since you propose to use some rather old hardware here, you may find that you can't install the operating system. In that case you would have to use EL6 (or upgrade the hardware). In particular, that G5 server probably has a SmartArray 400 in it, which used the old cciss driver, which was cut from EL7. You might be able to get it to work with the kernel boot command line option , but no guarantees. The G6 probably has a SmartArray 410, which should work with the current hpsa driver. The monitoring and management agents provided by HP and Dell also might not be available for EL7 for the particular hardware. If you can live without these, then it's not a big deal, but they do add sufficient value that you should use them when possible. 

Switch to the second ssh session that you should have opened, and fix it. The howto did explicitly warn you to do this, exactly because of the possibility of something like this happening. At this point the only way you can recover is via the system console. If you don't have remote access to the console, e.g. with DRAC, iLO, IPMI, etc., you will have to physically visit the server. 

They then take however long they take. With 60 copies running, that's probably quite a while, explaining why some requests finish hours later. If you really want it to run only once at exactly 4 am, then use: 

The Xserve Setup Guide states that all the DIMMs must be identical. Therefore, you cannot mix different sizes of DIMMs in the same Xserve. (Note that identical means that they must have the same specifications for size, speed, and timings. They don't necessarily have to be the same brand, but using RAM that Apple didn't sell you may invalidate the support contract you don't have anyway.) Also note that you need to install the DIMMs in specific slots depending on how many DIMMs you have and whether the server has one or two CPUs installed. The Xserve Setup Guide has an illustrated display showing which slots to use. 

You have a bunch of entries that don't have a port number defined. Thus, as your output showed, the definition is being applied to all listening ports. Define a port number for each of those s. 

You need to use to set the default file context for your non-standard location for the MySQL databases. 

You said that this IP address is the IP of the same server running snmpd, which means that only machines within that /23 will be allowed. This is almost certainly not what you want. To resolve the issue, use the IP address of the machine(s) which will be sending the SNMP requests. If you have multiple IP addresses you will need multiple lines here. Or you can just use and then use the firewall to control access. 

My current EL7 systems have roughly 200 MiB used in /boot, but I usually don't install kernel-debug packages. As the Linux kernel continues to grow over time, mostly due to adding hardware device drivers, this recommendation is likely to continue to grow as well. And again, as noted by others, a /boot partition isn't strictly required anymore for most installations. VMs generally do not need it, for instance, and UEFI booting systems also don't need it (though they have an EFI System partition which must exist and be large enough to hold various UEFI files). A /boot partition is required for some very old legacy systems and for using LUKS full-disk encryption. 

It sounds like you're overloading your Zimbra server, to the point that it can no longer handle incoming requests. You need to look at your Zimbra server and analyze it to see where the performance bottleneck is. You may also benefit from general performance tuning. 

Red Hat has not provided an updated package which provides this functionality, though there is a workaround available. Edit the file and add this line to it: 

Today, Microsoft Azure doesn't support nested virtualization, the technology required to run virtual machines inside other virtual machines. However, this technology is being rolled out with Server 2016 and Windows 10, so it may eventually become available. Keep in mind that nested virtualization has a performance penalty which on modern hardware isn't very large, but is larger than virtualizing on bare metal hardware. Your best bet is still to virtualize on physical servers when possible. Further, Azure limits the number of global IPv4 addresses you can use, and VMs you resell to customers will need their own separate global IPv4 addresses. Moreover, Azure doesn't support IPv6, which is a critically important feature in the market you are proposing to operate in. In short, Azure is a poor fit for what you want to do. 

Note that some of these attributes may indicate problems even if they are not marked as failed; so find an expert to examine them, or attach them to your question. 

First, is not necessary unless you're making this system a backup MX (you aren't) and therefore should be removed. Second, makes you an open relay. It also should be removed and replaced with something more sensible, such as . Finally, should specify the domains for which you want to receive email. You don't seem to have listed any domains here. Add in your domain names. Once you fix all three of these issues, you should have a functional mail server which isn't open relaying. 

You said that: "all the DNS part is done already." In fact, all the DNS part is not done already. We can clearly see: 

The same is true for each additional feature not present in the output there. Some time spent with should turn up packages for most of them. But you will need to enable the optional channel and EPEL to get some of them. Also keep in mind that an older version of GDAL is in EPEL, so if that is sufficient for your use, then perhaps you don't need to compile it yourself after all. 

The netmask is wrong on the enp4s1 (WAN) interface. This system has configured an IP address of 49.x.x.x and a netmask of 255.0.0.0 (prefix /8). But this is not the netmask that your ISP gave you. As a result, you will be unable to access almost all websites whose IP addresses also start with 49. To resolve the problem, fix the netmask or prefix declaration in your network configuration. I would expect the correct prefix to be somewhere in the vicinity of 27, 28 or 29, depending on the ISP. 

So I'll have a role which deploys the code. When I run this play, the nginx, mariadb and php-fpm prerequisites will be installed and configured first, if they haven't already been. In addition to calling , a play can also run arbitrary . Feel free to mix and match these if something is simple enough that a full role isn't called for. This play also goes into along with every other play, so that I can occasionally do . Remember that ansible doesn't guarantee idempotence like puppet tries to, so this is something you have to be careful of. 

At a minimum, you need to define , or in to specify the host to send SNMP traps to. You can also specify the community string and an alternate port number (if not using 162). You can also set a for a default community string to be used when sending traps. For sending v3 traps, use . See the man page for full details. See also the net-snmp snmptrap tutorial and snmptrap v3 tutorial. 

All you're doing is redirecting HTTP to HTTPS, so you don't need this regex at all. Instead, do something like this: 

Beware that the RPMs distributed by MySQL themselves are not binary compatible with your system and will break compatibility with other existing software, as well as breaking the dependency chain that yum maintains. (MySQL intends to fix its RPM packages in version 5.7.) For people needing an updated version of MySQL, I generally recommend using the remi repository, since he provides packages with maximum backward compatibility that will not break yum (or other things!). 

If you've already joined the server to the domain, then you'll need to reconfigure it to update DNS. Edit and enable dynamic DNS updates. You may also need to specify the NIC for which DNS updates will be sent. For example: 

It appears you've made a directory named and put all your key files in it. This is why it's not working. is meant to be a regular file, and you can put all your keys in . 

Edit the VPC to enable ClassicLink. Click your VPC in the list of VPCs, select Actions, then Enable ClassicLink. Attach the classic instance to the VPC. Click your old instance in the list of instances, select Actions, ClassicLink, Link to VPC. 

I suspect you have something corrupted somewhere in the RPM database or yum cache. I'd clear them all out and rebuild them. First the RPM db: 

This change takes effect when you shutdown all VMs using the network, stop the network (), restart the network (), and restart all VMs using the network. You will then also have to insert your own masquerading rules, if you want the virtual machines to access the Internet. For example, in the nat table section of : 

Create a blank and leave it there. The RPM packages will not overwrite it, since it's changed from the original distributed file; instead they'll create it as which Apache will ignore, and you can go clean up later at your leisure. 

This configuration requires that the host have a static IP address. For the expected use cases, it's likely that you have already planned for it to have a static IP address. And finally, the output! 

The domain colorpick.in doesn't exist. Did you let it expire? The domain darkfission.net has nameservers , , , and in the whois record. But the nameservers for aren't returning these NS records (as they should) or anything else about your domain. This indicates that something is wrong with Dreamhost's process. When you update your nameservers with them, they are supposed to send this update to , the DNS servers which serve the top level domain. This doesn't appear to be happening. If Dreamhost won't (or can't) fix it, transfer your domain to a registrar that has more competent staff. 

Create a new virtual network in virsh or virt-manager as an isolated network with the private IP range you wish. 

Well, the first obvious difference is that doesn't actually do anything on modern Linux systems. This kernel boot option is long obsolete, and was replaced with . Setting , where is the number of physical (non-HT) cores, now accomplishes the same thing. It's also possible to enable or disable individual CPU cores/hyperthreads via sysfs while the system is running. With that out of the way... There should be no difference in performance between disabling hyperthreading in the BIOS or disabling it in the operating system. The only real difference is, if you disable the cores/threads in the OS, then you can re-enable them again later without rebooting. You might want to do this if you run different compute jobs, some of which benefit from hyperthreading and some of which do not. 

By default VirtualBox guests will sync their time to the host. If you want to change this behavior, see the documentation. 

To be sure, you should use the EICAR test virus, and attach it to the email, rather than simply putting it in the body. 

One thing not mentioned is that most servers have maintenance tasks they perform on a daily, weekly or monthly basis. These are almost always scheduled for the middle of the night, when activity is expected to be at its lowest. On a Red Hat system, for instance, these activities start at 4:02 am server time. Depending on the server, these could run for a few seconds to an hour or more. If you turn on the server at 4:30, these maintenance tasks will start immediately (by anacron) and the earliest users to log in between then and 5-ish am would be impacted to some extent. 

If you're running email on the server, then the hostname should be set to one in a domain that you control, rather than one controlled by your service provider. You do not need to place it in , provided that the appropriate DNS entries exist for the name. 

Don't load the module. This, however, will disable the style functionality for the entire server, and is probably not what you want. 

Use or the older to maintain a terminal session on the remote server, to which you can attach and detach at will. Check the documentation for each command for specifics. 

means just what it says: the pages could not be shared because they're unique. indicates how many pages are actually in use and being shared. indicates how many pages the VMs think there are. If you didn't have KSM running, this is how many pages would actually be in use. So, in your example, 264281 pages have been found to be shareable, and so they were merged into 162221 pages, while 241483 pages were not shareable. KSM saved you about 398 MB of memory. 

Yes, that is the best practice, to serve a "nothing" page. Indeed, the default site on Ubuntu or Red Hat already does this, so you can just leave it in place and add your own virtual hosts.