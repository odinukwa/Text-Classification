Can you login to the server or sharepoint with the given username? First off, if you only used domain.com/admin as the installation user and nothing else, I don't think that is the cause of the problem. Then take a look for Failure Audit entries on your sharepoint server and your domain controller to see if there is an obvious reason for the "user not found" error. If that doesn't lead anywhere, take a look at all your Sharepoint service accounts, as these are the accounts that will be logging in here and there for Sharepoint. Given the "general" nature of the error, it seems likely to be the Central Admin app pool account, but it could be a Shared Service Provider pool account, or even a web application. Oh man - Sharepoint can have a lot of different accounts - it's a nightmare to keep track, even if only one of you set this up! You should check each application pool's identity tab in IIS for your Sharepoint server, and note down which pool uses which account. Also check the account used by SQL server, and any other accounts you may have used for crawling etc. Once you have this list, you can follow Microsoft's procedure for changing service accounts. If all your services/functions use the same account, you could try changing them to see if that fixes it. If worst comes to the worst and things aren't working, as long as you have your config and content databases intact, you can blow away the Sharepoint server, and start again with your accounts. If you do this, I recommend using different accounts for each function as suggested by Microsoft. It may seem like overkill, but if nothing else makes the errors a lot easier to deal with! 

If you truly suspect the server is hacked, you are best off setting up a new server, ensuring it is hardened for web hosting, restoring your data from a backup, and replacing the existing one with this. Knowing whether or not your server truly has been hacked may take some time, during which you absolutely want to have the server offline and isolated from the rest of your network. You say it is the presence of some extra database tables that makes you think the server has been hacked. What do these tables relate to? Web content? I guess you are using IIS (version?) and some database. You won't get much more help unless you provide more specific details. 

Ntop and Nagios are for different things. Ntop will help you analyse your network traffic in a variety of ways - e.g. what network devices are generating the most network traffic, what protocols are running across your network. Nagios is for monitoring lots of things (almost anything you can think of) across multiple devices, and then getting alerted when what is monitored reaches a threshold you specify. If you've read the ntop website and think this matches your needs, you don't need Nagios. Either product should be run on a dedicated server, unless your network is very small, in which case you might run it on another server that is used for management purposes. Don't put it on a server providing services (e.g. email, database) your users access. 

Followed the info at $URL$ paying particular attention to "rinse and repeat" in order to get the selinux policies in place. After a few attempts it all started working - uploading, and creation of new files. In short: 

With a little assistance from Cisco I did some deeper analysis of what was happening, and figured out the things that I needed to be checking for. The useful things that Cisco told me: 

When you need to edit your iptables in future, edit and use to do the update. See also iptables-howto which mentions as an alternative method for updating, which may be closer to what you tried to do already. However, I think having a separate file for making changes is better than editing iptables file directly. 

If you have a DNS server create an A record pointing your domain name at the ip address. If you don't have a DNS server, you can do this using Host files, but you will need to set this up on all your client machines, which is a drag. 

Normally you leave the nameservers alone, and just update the records that are relevant to you - in the case of websites that will be A and CNAME records, and maybe TXT if you need to prove ownership of a domain to some other service provider such as Google. Unless you know why you are doing it, leave the nameservers alone! 

I can't say I have done this, but I am sure if you follow the docs for generating a CSR from a windows box, then follow your CA docs for generating a .p7k cert from a CSR, then you should be fine. By the way - I would recommend you create your CA as a virtual machine for a popular hypervisor such as Hyper-V or VMware, rather than a boot disk, make sure you store it very securely somewhere your successor can find it, and spin it up offline periodically to make sure it runs, or transfer it to new media/technology. A root CA may have a life of 10 or 20 years... 

How do I get Windows 7 to automatically run dsac.exe as a specified user? I'm happy to fill in a password prompt for the specified user, but would be even happier if there was a solution that cached the password, so I didn't have to enter it more than once a day. Update The following worked, but feels a bit clunky: 

In some locations, the only option for an internet connection is to use some form of Satellite dish. Like any wireless medium these can be quite tricky to troubleshoot. What factors have you observed which have caused problems with a VSAT connection? What resolutions did you find? What measures have you taken to mitigate against these factors? 

I think you may find that for testing a new version of the site using a separate vhost for the new version of the site, and use a different ServerName directive (e.g. testing.yourdomain.com) will give you more flexibility than doing something clever with IP addresses. Then when ready to go live, you can just change the ServerName to the live servername. However, being able to serve different content for different IP addresses is a useful thing to do, especially if you want to test out the performance of different versions of the site with different visitors, or serve content based on geolocation derived from the IP address. If that is what you want, then you can ignore my answer. But if you only need to give a small number of people access to the test site until it is done, keep it as simple as you can. 

I have a video website running on a VPS under Apache2 that will soon start doing pay per view. Until it starts generating decent revenue, I don't want to invest in more servers, so to start with I need to provide a good enough service to the customers I get. I also host a couple of other websites, but these aren't expected to use a lot of bandwidth. I know that my major bottleneck is bandwidth - so I think the best thing to do is to prevent access to the video site to new connections once my bandwidth limit gets near. Anyone who is already viewing a movie should not be affected. Any ideas on the best way to achieve this? Update: The bandwidth limitation isn't my allocated bandwidth from the provider but rather the available bandwidth for my VPS through the network card. I found that once I hit about 250 simultaneous downloads things start to deteriorate. Assuming each download is at 1mbps I want to start throttling things once I hit 250mbps - in theory I can get 1000mbps, but it doesn't look like that really works. 

Ask the new guy what he thinks you should do. Maybe this should be a standard interview question for system administrators! 

What you are proposing is correct, and should work without disrupting mailflow to your existing mail server. I would suggest that you don't make your subdomain and the FQDN of your list server host the same - not because it won't work, but because it is confusing. 

Go with any Linux distro that VMWare have provided documentation for for your version of ESX, and whichever one you are most familiar with. If you aren't familiar with any, then just go with whatever version of Linux they were already running on. If that isn't consistent, then probably go with Ubuntu because it is quite well documented for a Linux newbie. 

The default configuration for those might not be appropriate. This was the case for me, and resulted in Apache using lots of memory when the server got hit more than usual. My issue was resolved by reducing the values of these. Make sure that you understand the configuration of your Production Apache - defaults are there for testing. 

I use PuTTY to SSH to my linux server. Today I noticed that when I enter a long command that goes beyond the right hand of the screen, instead of wrapping down to the next line, the text starts at the left of the screen on the same line, writing over the top of the characters. I can't figure out what might have changed to cause this. Can anyone give any pointers at what might cause this, and how to resolve? I have Auto wrap mode initially on ticked in PuTTY. I haven't made any changes to the PuTTY settings for this server, so at a loss why this stopped working correctly. 

You definitely need some static IPs (for your DHCP server for example), but you can do static allocation via DHCP using MAC addresses for servers. The benefit of that is that you have all your IP address configuration in one place - but you create a dependency on your DHCP server. Say you have a power outage, and for some reason your DHCP server is the last to come back up on recovery - you then end up with none of your servers having any IP address which wouldn't have happened if they were static. Some of them will "acquire" 169.254.x.x type addresses and may be able to talk to each other but not the outside world - others will not get anything. You turn up in the morning after this has happened, and you have a lot of work to do! So I think static for servers is good (keep decent records!), and dynamic via DHCP for clients. Maybe for printers and other non critical network devices, assignment by MAC address is worthwhile, since the interface for setting their IP addresses may be a bit obscure. You'd have to get pretty large for the admin benefits of assigning everything via DHCP to be of particular benefit IMHO. 

VMware recommend increasing the failuredetectiontime value when using more than one isolation address. After adding these settings I disabled and renabled HA, and the error is no longer displayed for my host. 

I believe that the most recent version of SCCM can do checks based on users, whereas SCCM 2007 is purely computer based. Given that, if you have some way, other than user, of organising your computers based on their use (which probably maps to users anyway) then you should be able to use SCCM Desired Configuration functions in SCCM to do all your checks. You should then be able to do some remediation based on results of your checks, or at least have a list of computers and problems to remediate. 

You can use to query a timeserver without adjusting the clock. Schedule that with cron, and write output to a logfile. 

It depends almost entirely on where the server is in relation to the developer. If both are behind the same firewall, and you trust your local network environment, then opening up MySQL locally wouldn't seem a particular risk. On the other hand, if your server is running on the Internet 24/7 with a public IP address, you want to lock it down as much as you can - cue another link to [Implementing network security on Centos/RHEL Servers] which goes through a number of things better than I could ever do1. In terms of the best way of securing a connection, it depends what you want to do. If just run SQL queries by hand, then SSH is all you need and the above link will get you there in a secure way. If you are wanting to use some GUI front end, then VPN access as mentioned by Linker3000, and succinctly detailed by adirau would be best bet. I wouldn't recommend putting phpmyadmin on as a publicly accessible service, unless you can secure it with more than a username password. If you need phpmyadmin, I'd only access through a VPN tunnel. Don't have a link like $URL$ - it will be probed within minutes, and any future exploits for phpmyadmin will be tried. I've seen my own server logs, and this is right at the top of failed http requests! 

xnet.exe available from a few locations (e.g. $URL$ can list all the services running - you can then use something else to search the output. Handlily xnet also reports the short name of a service, which can be used to manage it. 

I have applied the tcp-mss change, and removed the clear-df command on our HQ ASA and the site with the problems is able to work ok. This may be a better solution than clearing the df-bit, as that will lead to fragmentation which is not desirable. It is equivalent to setting the MTU on the ASA to 1340 (1300 + 20 bytes for the IP header and 20 bytes for the TCP header) but only affects TCP traffic. It also allows PMTUD to work, which isn't the case when clearing the Don't Fragment bit. Cisco discuss this option in detail in Resolve IP Fragmentation, MTU, MSS, and PMTUD Issues with GRE and IPSEC.