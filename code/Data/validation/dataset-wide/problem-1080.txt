A Final Word I'm not sure why you are using this table. I would suggest that you read up on each of the system functions above in books online. Some of them have notes of warning about various conditions where they can return incorrect data. For instance the note for talks about the data type and a warning that if it accumulates more than 49 days of time, it is no longer accurate or valid. Same with some of the other counters. I have actually never run on an instance of mine. It wasn't until this question that I dug deeper and learned about what it is and what it does. It looks interesting, it provides data on a host of counters (you can learn about each of those functions above here) that look to provide some useful data at first blush. But then when you look deeper, most of the information grabbed is probably best collected in other ways. For most of the information, I would look at a combination of perfmon counters, DMVs and virtual file stats. The counter is interesting but I can't really think of a useful case for the information presented that way. I want to get my disk write errors () and alerts as they happen and not worry about a cumulative count so much. Looking at total connections since a restart could be interesting and if you didn't want to track this information through perfmon or repeated queries at DMVs and adding it, that could be helpful. 

Have a smoke test / check to verify all came over well. Change compatibility mode to SQL Server 2016 on all databases if testing proved that out to work. I see this getting missed a lot. Make sure maintenance and backups are in place. Run a post migration DBCC CHECKDB on the databases. Make sure your jobs are running. Configure monitoring and alerting so you don't miss alerts about this server Once you are satisfied with a limited test, turn the old off and make a CNAME change. 

etc. There are quite a few database level and connection information level Dynamic Management Views exposed to you in Azure SQL DB. 

I think this may be less an ODBC challenge and more an Access challenge you are facing. The driver is more or less (with differences like when drivers like to introduce server-side cursors and break work up that way, etc) doing what the client tells it to. Access is really well known for doing some interesting things to decent databases and somewhat well designed DBs. Can you at least put your code into Oracle in stored packages/procedures and then just call those from the forms app? Are you 100% married to Access? 

Not sure if this should be an answer or a comment. But I've used the script here before for this type of question - $URL$ The last query Jamie uses shows the permission and if it is through a role, the role is specified. If it isn't, there is no role specified. This was written for SQL Server 2005, I've used it on SQL Server 2008 without issues. 

In your particular case though - you are moving from one special privileged account to another. As you have seen - you were safe and things worked. I would also take this time to question the choice of the service account. Are you on a domain? Why not use a domain user account per the best practices? The local accounts with special privileges are not the most secure or reliable service account choices. This article from Microsoft explains more there. 

You are misreading that document. In the document and image you are referring to - there are actually two distributed Availability Groups in the image you refer to. each one containing two Availability Groups. A distributed Availability Group is distributed between two (and as far as I now - only two) Availability Groups. You can have multiple secondaries in an Availability Group and they can span data centers, so depending on what you are trying to do, you may not need a Distributed Availability Group to do it. 

I'd echo @Mark Storey-Smith's comment - a competent DBA is the best way to go here. You can't really automate a well tuned SQL Server but a good DBA can setup various maintenance items to keep it running well. Sounds like you were asking a lot about maintenance so one great spot to look for some scripts to help setup a best of breed monitoring solution is Olla Hallengren's Maintenance Solution scripts explained on Olla's site here. That will help ensure you are at least doing the important maintenance items (Index rebuilding/reorganizing, statistics updating, backups, updating statistics, checking database integrity, etc.) As far as the ongoing optimization, I'd suggest picking up a copy of the Professional SQL Server 2008 Internals and Troubleshooting book. It has just the right amount of internals knowledge to help you understand the "why" behind best practices and contains plenty of practical examples for implementing the best practices. Or I'd recommend the same Internals & Troubleshooting book but for SQL Server 2012. Contains some great chapters just for your question. Like how to perform a SQL Server Health Check, by Glenn Berry. 

Ensure all services that connect to SQL Server are off/stoped (this includes services like SSIS, SQL VSS writer, etc) Restart SQL Server in single user mode using the -m startup parameter (described here) Connect as the single user and then do your CHECKDB with the TABLOCK specified. 

To the question you asked: I wouldn't rely on disk queue alone. In fact I rarely even ever look at disk queue lengths unless I'm getting in deep with a problem. It is best to look at your disk's latency. Those are the Avg. Disk Sec/Read (or /Write and /Transfer) counters. That tells you what your disk latency is from Windows' perspective. So the time that the request was taking after sent to the disk and brought back.. Disk Queuing nowadays doesn't tell you a lot because most IO subsystems are able to handle a disk queue depth and have multiple spindles doing work in your RAID group often. Finally - In this case - your disk queue length doesn't even look that bad. From here it looks like the max it was in the time of this screenshot (for the average length) was 1.377. That's nothing on most SQL Server systems. Look at your actual latency. Also I don't look at % Disk Time.. I look at the idle time instead. That is a more reliable counter and you just have to do a little math to read it.. The more idle, the less activity. To The General Question Behind Your Question I'll ask this one by starting with a question - Why did you go right to your IO? There could be any number of things causing your slowdown. And to answer that exhaustively here is tough but a high level of some things to look at/consider: