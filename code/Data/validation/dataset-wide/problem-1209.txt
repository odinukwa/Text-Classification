Here's a variation on how I have tackled this in the past. I have added a grp and seq columns to the @Geo to demonstrate how to build multiple lines and get the order of the points in the line correct. The seq could alternatively be datetime. 

I think the Point on the Geometry and Geography is flawed in not allowing NULLs to be input. Simply return a NULL as a result would be more correct in my opinion. If you wish I can put up my entire test script for this. 

Also note SQL Server let me build a spatial index over the geometry column that contains mixed SRIDs, but it is of limited use. Even if there was a lot more data, the index would be of limited use. I would suggest to make life easier that you pick a single projection to use across all you data and transform geometries to that. This can be done alongside the current geometries or replace them. Also if you choose a Lat/Lon projection, use the Geography data type. There is an open source project, SQL Server Spatial Tools, that has some tools that will allow you to do projections. You will however have to know the parameters for the projections you are using as it does not appear to have a list of projections to work with. I can't advise how good these are, as I haven't used them. 

No. This is normal. You are experiencing too many applications installed on your database server. Start migrating your database (SQL Server database engine) to its own server or start uninstalling all other applications in the database server. Currently your server have the following: , , , , installed. Not to mentioned if you have monitoring tools or anti-virus installed. When you login to the server, you also use memory. filter drivers also use memory. Check out this blog post by Jonathan. Let's say, you've a barebone database server (without the other application installed fighting for memory), you can at least have 27GB of memory for your SQL Server. 

Aside from what David already answered, I believe these are the most comprehensive guide to SQL Server Transaction Log Internals and Understanding How SQL Server Executes A Query that are free from the web. A must read blog. Thanks to Remus! 

You might be doing a large batch of transaction processing that could cause log reader agent to slowly read the t-log. Or NOT properly maintaining the t-log that could cause increasingly huge t-log. Ask around what's being process at that time. (watch out for index maintenance - Log Reader Agent will appear hung as it scans more log records.) Then check for VLF (Virtual Log File) by issuing on the publisher database. See if you have a lot of VLFs. Keep VLFs in check and t-log size at minimum. The key is to properly manage your transaction log when dealing with replication. Read on how to Optimize the Transaction Log. On your Log Reader Agent Profile, you can change the and to higher value. Be careful on these 2 parameters as it can cause Log Reader Agent to scan more transactions and could spend more time scanning and slowly delivering to distribution database. It's rarely you need to change parameters (even the ) on Log Reader Agent so use it with caution. 

Then to query for all points within a specified distance you can do a query similar to the following 

This is a pretty convoluted way to do it and I am sure there is likely to better ways, but it can be adapted to handle more columns. 

The spatial index, as with other objects, have their own menus and need to be done separately. This can be done to the clipboard and pasted to the query window generated by the command. I can't confirm at the moment, but I suspect that the primary key and other constraints come out in the options since the are an integral part of the table definition, whereas indexes are not. The wizard can also be used, but it is a lot of steps if you are just doing a few items. Technet, How to: Generate a Script 

I have struck similar issues with Geometry and Geography data types before. I think the issue is to do with where (and how) the optimizer decides to build the geometry in the plan. I was having an issue with insert statement that was basically 

I get 93ms, 4ms and 93ms respectively, removing the TOP 2000 from the queries causes the price filtered query to blow out to a minute or so. Are you able to give more details (execution plans, DDL, etc) to help us replicate your issue. My initial thought was that the was hiding the underlying problem. I think that may still be the case. 

Still on distribution agent job history. You can look at your stats on writer and reader thread of distribution agent. (eg.) 

You might be experiencing a network issue. The PAUSE and RESUME of mirroring should just be your workaround. Check with your network admin on your network bandwidth and latency (shared network with other apps? 1Mbps NIC?). This can build up your and can adversely impact performance of your database mirroring. 200GB is huge amount of data. You could loss 200GB data. You don't want that to happen. Consider setting up Threshold Alert for . If it reaches 1GB, send an email alert and take action. This way you can minimize your data loss. Read this KB Article on things to consider when setting up Database Mirroring in SQL Server. The 2 main important points about network: 

We need to step back a bit and apply basic SQL Server troubleshooting on subscriber db as well. Check for blocking, IO contention, network issue, check for wait stats, triggers, cursors, long running job/transactions, service broker, AGs redo queue, etc. From my experience, the silent killer of replication performance is... triggers. You wouldn't be able to catch it unless you're using profiler or you understand how the data flow works. These could quickly stock up the pending commands to be delivered. 

I've done this using a CTE query as I find it easier to follow and explain. The first CTE is just your data. The second CTE ranks each row of the data using based on the ordering of the . I have include the in the order so that if there are duplicate the first occurrence will be picked. In the final query we are using statements to pivot the data and aggregating the result for each with to create a single row for each . This query can be run over multiple 's 

You are correct in your interpretation of a SRID. It identifies the projection used to locate the Geometry or Geography. Even if the database in question (I'm assuming SQL Server) doesn't make use of the SRID directly, the point of it is to identify how to work with the coordinates in relationship to others. I suppose you could look at it like having a country code on a phone number. Not always necessary, but important none the less. Your understanding of Geometry vs Geography isn't correct. Geometry is used to store objects which are projected to a Cartesian or Planar coordinate system. They are not restricted to just 2 dimensions. They use distance units to (metres, feet, etc) to represent points. Geography is used to store objects that are projected on a Spherical coordinate system. These systems use degrees (Latitudes and Longitudes) to represent points. It is important to use the correct data type for your information. If your objects have Latitude and Longitude coordinates, store them in a Geography. This means when you use distance and area functions you will get a sensible result. While some systems (SQL Server) mostly ignore the SRID in geometries, it is still important metadata and should be set correctly. Other databases and software can and do use the SRID to determine how to treat the coordinates in the object, allowing for the coordinates to be reprojected to other coordinate systems and compared correctly to other objects that are projected differently. 

I would highly recommend you to capture a baseline on replication commands stats (Distribution Agent). We can use Perfmon to monitor the following: 

Apply the missing command on the subscriber db and let the command flow to subscriber Delete the command from distribution db (on table and make sure you specify and ). Apply the command manually in subsciber db. Skip the missing command. (not recommended) Change the and parameter to just to see if the command flows properly to subscriber db. This is also good for troubleshooting to isolate the issue. Then set it back to default or your desired paramater. 

You are right! I think this is a bug or by-design. I was able to repo the scenario. So basically when you run Ola's script with this: Or native: When you execute a new full backup or full backup or even differential backup, All your previous log backups will be deleted after you run another log backup (Ola's log backup script with param). Tested using Ola's script version: October 7, 2016. Based from Ola's website: 

It didn't mention about backups. For the meantime, you can change log backup param to as a workaround. Or consider moving to another backup tools (eg. Minion Backup or dbatools) or roll your own custom code because the last update of Ola's Maintenance Plan was on Oct 7, 2016. There's a github if you like to raise an issue/enhancement. 

The trick here is to not to get overwhelmed by the fact that there is a spatial datatype involved. Then it becomes a fairly simple aggregate query over a join between the pricing table and the catalog table where the join just happens to be a spatial intersection. 

Based on the previous question and this, the following should do what you want. As with Pieter's update it doesn't assume that the ID's are in sequential order, rather it uses the ReqTime to determine order. 

There is a couple of approaches that can be used here depending on the exact requirements. First of all you will need to create a spatial index on the Landmark table 

This is my interpretation of your requirement.As a simple query, this will return what you want, however you will probably want to try other options to make it perform. I don't use MySQL, but in SQL Server I would look at trying CROSS APPLIES or some sort of grouping option. This query will return all the dates on which the minimum or maximum occurred. You can of course then filter that to suit what you require. 

Don't wait for 10hrs or 200GB of unsent data, setup an alert and be proactive. Additionally, consider migrating/upgrade to SQL Server 2016/2017. Use Availability Groups (better than mirroring and faster) because Database Mirroring is now deprecated by Microsoft and you won't be able to get support or updates from them (except you paid for extended support). If you run into Database Mirroring bug it is unlikely Microsoft will patch it for you. You can read the SQL Server 2008 lifecycle support here. 

It could be someone or a process/apps deleted and inserted the data in subscriber db (while cmds are being applied). Review your subscriber security settings and check what process/apps are accessing the subscriber db. Multiple publications connected to subscriber db. pub1 (deleted the data first) then pub2 tried to UPDATE/DELETE the data which could cause an error 20598. Triggers on subscriber tables that could delete/insert/update the data. 

This will give us an idea on how long it will take to apply the commands in subscriber db. The before and after picture of commands stats is important as we can determine how slow is slow or what have changed since last baseline. 

The SRID does not appear to be an integral part of the spatial index nor can it be added. It is integral to the geometry even though there are no real tools for manipulating geometries based on the SRIDs in SQL Server. It does have a few rules about SRIDs. 

This gives a table of 1,000,000 random points with a 2 x 2 degree spread. After trying a few different options on it, the best performance I could get was forcing it to use the spatial index. There was a couple of ways to achieve this. Dropping the index on LegendTypeID or using a hint.You will need to decide which is best for your situation. Personally I don't like using index hints and would drop the other index if it is not required for other queries. The queries stacked up against each other 

Given the way this question has changed, it is difficult to determine exactly what you need. The current data and query in the question do not match the result you have posted. That said, assuming the data is the way I think it is, this should provide the result you want