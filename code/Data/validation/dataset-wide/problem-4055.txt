Here is one more approach, I think it is different from the others. Inside $\mathbb{P} \left( \bigwedge\nolimits^k V \right) \times \mathbb{P} V$, let $X$ denote $\{ (\omega, v) : \omega \wedge v = 0 \}$. This is clearly closed. Consider the projection $X \to \mathbb{P} \left( \bigwedge\nolimits^k V \right)$. Fiber dimension is upper semicontinuous, so let $d-1$ be the greatest fiber dimension and let $\Gamma$ be the closed locus in $\mathbb{P} \left( \bigwedge\nolimits^k V \right)$ where that greatest dimension is achieved. Looking at a rank one point of $\mathbb{P} \left( \bigwedge\nolimits^k V \right)$, $d \geq k$. For $x \in \Gamma$, let $V_x \subset V$ be the subspace for which $\mathbb{P}(V)$ is the fiber. So $d = \dim V_x$, choose a basis $v_1$, $v_2$, ..., $v_d$. Then $v_1 \wedge \cdots \wedge v_d$ divides $x$, as in several other proofs, so $d \leq k$. This shows that $d=k$ and that every point of $\Gamma$ is of rank $1$, conversely, it is obvious that the fiber above every rank one point is of dimension $k-1$. Basically, this is Qiaochu's answer/Lev Borsiov's comment, except using semicontinuity of fiber dimension instead of explicit equations. 

I claim that, if $g(x) \in k[[x]]$ is not a polynomial, then $g \circ c$ is a polynomial for at most $|F|^{k/2}$ polynomial $c$ of degree $\leq k$. We will always use the letter $c$ to represent a polynomial with $c(x)=0$. Case 1: $g$ is transcendental over the field $k(x)$. In this case, I claim that $g \circ c$ is a polynomial only when $c$ is $0$. Proof: Suppose that $g(c(x)) = h(x)$ for some polynomial $h$. Then there is a polynomial relation $F(c(x), h(x))=0$ for some polynomial $f$. Set $G(x) := F(x, g(x))$. By hypothesis, $G \neq 0$, but $G(c(x))=0$. The only way this can happen is if $c=0$. Case 2: $g$ is algebraic over $k(x)$. Let $F(x,g(x))=0$ be the minimal polynomial relation between $x$ and $g$. Let $A$ be the ring $k[x,y]/F(x,y)$. At this point I really, really want to use the language of algebraic geometry. If you aren't happy with this, I'll try to convert into commutative algebra, but it will be harder to write and, in my opinion, harder to read. My goal is the following claim: 

Quite the reverse is true: The probability that $n$ and $\phi(n)$ are relatively prime is zero! More precisely, the ratio $$\frac{1}{N} \cdot \# \{ n : \ n \leq N \ (n, \phi(n))=1 \}$$ goes to $0$ as $N$ goes to $\infty$. Proof: Fix a positive real number $\epsilon$, we will prove that this ratio is less than $\epsilon$ for $N$ sufficiently large. The product $(1-1/2)(1-1/3)(1-1/5)(1-1/7)(1-1/11) \cdots$ is zero (because $\sum 1/p$ diverges); choose $P$ such that $\prod_{p < P} (1-1/p) < \epsilon/2$. We claim that, for $N$ sufficiently large: 

Choose an arbitrary number $D_n$ and define $D_i = C_{in}+D_n$ for $i \neq n$. So $C_{ij} = D_i - D_j$. The identity we want to prove is $$\sum_{a=1}^n (-1)^{a+1} \prod_{\begin{matrix} 1 \leq b < c \leq n \\ b,c \neq a\end{matrix}} (D_b-D_c) = 0.$$ The product is the Vandermonde determinant $\det (D_j^k)_{ 1 \leq j \leq n,\ j \neq a}^{0 \leq k \leq n-2}$. So the sum is the row expansion of $$ \det \begin{pmatrix} 1 & 1 & 1 & \cdots & 1 \\ 1 & 1 & 1 & \cdots & 1 \\ D_1 & D_2 & D_3 & \cdots & D_n \\ D_1^2 & D_2^2 & D_3^2 & \cdots & D_n^2 \\ \vdots \\ D_1^{n-2} & D_2^{n-2} & D_3^{n-2} & \cdots & D_n^{n-2} \\ \end{pmatrix}.$$ Since this matrix has a duplicate row, its determinant is $0$. 

Combinatorial presentations of the cohomology rings of $G/P$'s. (And equivariant cohomology, and $K$-theory, and quantum cohomology ... Maybe this should be a second poster?) 

Since $\mathbb{Z}/12 \cong \mathbb{Z}/3 \times \mathbb{Z}/4$, it is enough to see how to build surjections $SL(2,\mathbb{Z}) \to \mathbb{Z}/3$ and $SL(2,\mathbb{Z}) \to \mathbb{Z}/4$. The former is easy: $SL(2,\mathbb{Z})$ acts on $\mathbb{P}^1(\mathbb{Z}/3)$. This is a permutation action on a four element set, and a bit of computation shows that the image is the alternating group $A_4$. We can compose $$SL(2, \mathbb{Z}) \to A_4 \to \mathbb{Z}/3.$$ I can't find an equally nice description of the map $SL(2, \mathbb{Z}) \to \mathbb{Z}/4$. It factors through $SL(2, \mathbb{Z}/4)$, but I can't see how to show that there is a map $SL(2, \mathbb{Z}/4) \to \mathbb{Z}/4$ in any way more elegant than writing it down. 

This seems extremely false to me: I can't think of any example of a positive dimensional Stein manifold $W$ and a compact subset $K$ such that $H^2(W) \to H^2(W \setminus K)$ has nontrivial kernel. That means there should be an abundance of counter-examples: Just take any Kahler form representing a nontrivial class in $H^2(W)$. In any case, here is a specific counter-example. Take $W = (\mathbb{C}^*)^2$ with coordinates $z_1$ and $z_2$. Take a $(1,1)$ form of the form: $$\omega := a \frac{dz_1 \wedge d\overline{z_1}}{z_1 \overline{z_1}} + b \frac{dz_1 \wedge d\overline{z_2}}{z_1 \overline{z_2}} + c \frac{dz_2 \wedge d\overline{z_1}}{z_2 \overline{z_1}} + d \frac{dz_2 \wedge d\overline{z_2}}{z_2 \overline{z_2}}$$ This is obviously closed. If I haven't dropped any signs, it is Kahler if and only if $\left( \begin{smallmatrix} a & b \\ c & d \end{smallmatrix} \right)$ is positive definite Hermitian. (It is easiest to do this computation after setting $z_i = e^{w_i}$, so $d z_i/z_i = d w_i$.) Now, let $T$ be the torus $|z_i|=r_i$. Irrespective of what $r_1$ and $r_2$ are, $\int_T \omega = (b-c) (4 \pi^2)$. (Again, if I haven't dropped any signs.) So, if we take $\left( \begin{smallmatrix} a & b \\ c & d \end{smallmatrix} \right)$ a positive definite Hermitian matrix with $b-c \neq 0$, then we will have a Kahler form $\omega$ for which $\int_T \omega \neq 0$. For example, $\left( \begin{smallmatrix} a & b \\ c & d \end{smallmatrix} \right) = \left( \begin{smallmatrix} 2 & i \\ -i & 2 \end{smallmatrix} \right)$ would do. Now, let $K$ be any compact set. For $(r_1, r_2)$ large enough, the torus $T$ is disjoint from $K$. So we have exhibited a Kahler form on $W$ such that, for any $K$, there is a $2$-cycle $T$ in $W \setminus K$ with $\int_{T} \omega \neq 0$. So $\omega$ is not exact on any $W \setminus K$. 

OK, let me try again. First, a general construction. Let V be an object in an abelian category, A = End(V) and J a finitely generated two-sided ideal of A, with generators (j_1, ..., j_r). Define V/JV to be the cokernel of V^{r} --> V, where the map is multiplication by j_i on the ith coordinate. We need to check that this depends only on J and not on the choice of generators; I haven't actually done this. Define JV to be the kernel of V --> V/JV. So we have a short exact sequence 0 --> JV --> V --> V/JV --> 0 I claim that the action of A on V passes to an action of A/J on V/JV. Also, A acts on JV. (One can say more than this, but we don't need to.) Using the action of A on JV, we can repeat this construction to get JV/J^2V, J^2 V/J^3 V, etcetera. All of these come with actions of A/J. Now, suppose that all of our Hom spaces are finite dimensional. A finite dimensional algebra is semi-simple if and only if it has no nontrivial nilpotent two-sided ideal. So, suppose for the sake of contradiction that there is some (V,A,J) as above with J nilpotent. Then J^k V is eventually zero. Trace is additive in short exact sequences, so Tr(f: V --> V) = \sum Tr(f: J^k V/J^{k+1} V --> J^k V/J^{k+1} V). If f is in J, the right hand side is 0. Also, if f is in J, so is fg for any g in A because J is an ideal. So J is in the kernel of the trace pairing, and we deduce that J=0. So all endomorphism rings are semi-simple and, by the lemma cited above, so is the category. 

I think you should first work out when there are characteristic class obstructions for the local problem. 

Sturmfels and Zworski have an unpublished conjecture, the "Chez Panisse conjecture", which I believe is meant to say that that adding one more $N_r$ to the list will determine $f$. I say "I believe" because the published restatements I can find (Hillar's NSA proposal, Hillar and Levine, Kedlaya) state the conjecture as saying that, if $f$ is reciprocal (meaning $f(x)=x^{2g} f(1/x)$) then $f$ can be recovered from its first $g+1$ cyclic resultants (meaning $\prod_{\zeta^r=1} f(\zeta)$). But $f$ for an abelian variety obeys $f(x)=x^{2g} q^{-g} f(q/x)$, not $f(x)=x^{2g} f(1/x)$ and, while we could make a change of variable to work with a reciprocal $f$, I believe we would then want $\prod_{\zeta^r=1} f(q^{-1/2} \zeta)$. Since I can't find a place where Sturmfels and Zworski themselves wrote this down, I can't say whether they missed this issue, whether everyone reporting on them did, or whether they for some reason wanted to state a conjecture which wasn't quite the right one for applications to number theory. 

You say that you are comfortable with morphisms of affine varieties. A map f: X --> Y between quasi-projective varieties is a morphism if and only if we can give open affine covers Ui and Vi of X and Y such that f takes Ui to Vi and f:Ui --> Vi is a morphism. Conceptually, I think of a morphism as anything I can write down in terms of polynomials without using limits or cases. The only case that used to trip me up is things involving normaliztion. For example, if Y is Spec k[x,y]/y^2-x^3 and X is Spec k[t], the map from Y --> X by (x,y) --> y/x is NOT a morphism, even though it has a well defined limit at (0,0). And writing it as (x,y) --> y/x if (x,y) \neq (0,0) and --> 0 if (x,y)==0 also doesn't work; because it uses cases. On the other hand, the map X --> Y by t --> (t^2, t^3) is perfectly good. Of course, this was an affine example. But a general morphism is just a map which is locally an affine morphism; so it is a map which I can locally write in terms of polynomials. In the particular case of projective varieties, if X \subset P^m and Y \subset P^n, and (f0,f1, ..., fn) are homogenous polynomials of the same degree, with no common zero on X, and such that these polynomials take X to Y, then these polynomials define a morphism. Note that this is not if and only if; this theorem is for writing down examples of morphisms, not defining them. I think there may be a way to make this if and only if, by allowing you to change the projective embeddings, but I'm not sure of the details. 

Let $X$, $Y$ and $Z$ be positive definite Hermitian matrices (you ask about the real symmetric case, the Hermitian one includes it). Let the eigenvalues of $(X^*)^{-1/2} Y X^{-1/2}$ be $e^{\alpha_i}$, those of $(Y^*)^{-1/2} Z Y^{-1/2}$ be $e^{\beta_i}$ and those of $(X^*)^{-1/2} Z X^{-1/2}$ be $e^{\gamma_i}$. Set $A=Y^{1/2} X^{-1/2}$, $B=Z^{1/2} Y^{-1/2}$ and $C=Z^{1/2} X^{-1/2}$. The singular values of $A$ are then $e^{\alpha_i/2}$, and so forth. Note that $AB=C$. By a result of Klyachko, there exist Hermitian matrices $\mathfrak{a}$, $\mathfrak{b}$ and $\mathfrak{c}$ such that $\mathfrak{a}+\mathfrak{b}=\mathfrak{c}$, the eigenvalues of $\mathfrak{a}$ are $\alpha_i/2$, those of $\mathfrak{b}$ are $\beta_i/2$ and those of $\mathfrak{c}$ are $\gamma_i/2$. This result can be thought of as saying that, although $\log A + \log B \neq \log C$, and although $\log A$, $\log B$ and $\log C$ are not Hermitian, we can find matrices which do have those properties and have the same eigenvalues. The inequality you want to prove is that $$\left( \sum \alpha_i^2 \right)^{1/2} + \left( \sum \beta_i^2 \right)^{1/2} \geq \left( \sum \gamma_i^2 \right)^{1/2}$$ But $\sum \alpha_i^2 = 4 \mathrm{Tr} \ \mathfrak{a}^* \mathfrak{a}$. So this turns into the (standard) fact that $\mathrm{Tr} \ \mathfrak{a}^* \mathfrak{a}$ is a positive definite norm on the Hermitian matrices. 

The following problem is homework of a sort -- but homework I can't do! The following problem is in Problem 1.F in Van Lint and Wilson: 

This question is borderline for appropriateness here, so I'll sketch how to proceed and omit the details. Let $f(p) = p(1-p)^t$. Notice that $$f''(p) = (1-p)^{t-2} (t(t-1) p + 2t (1-p))= t (1-p)^{t-2} ((1+t)p - 2) $$ So $f$ is concave on $[0,2/(1+t)]$ and convex on $[2/(1+t), 1]$. Take any $(p_1, \ldots, p_n)$. If two of the $p_i$ are in the interval $(2/(1+t), 1)$, then push them apart while maintaining their sum until one of them hits the boundary of the interval. This will increase $f(p_i)$, as $f$ is convex on this interval. Since their sum is $\leq 1$, the smaller $p_i$ will hit $2/(1+t)$ before the larger one hits $1$. Repeating this argument, we can continue to push $p_i$'s apart until at most one $p_i$ is in the interval $(2/(1+t), 1)$; call it $v$. Now, take all the other $p_i$ besides $v$ and replace them all by their common average. Since $f$ is concave on $[0,2/(1+t)]$, this will increase $\sum f(p_i)$. (This is Jensen's inequality.) So we have reduced to one of two cases: Either there is one $p_i$, called $v$ in $[2/(1+t), 1]$, and all the others are equal to $(1-v)/(n-1)$, or else all the $p_i$ are in $[0,2/(1+t)]$, and they have value $1/n$. You now have a single variable function to optimize, and also one other value to compare it to. I haven't done the work, but it should be tractable from here. I learned this approach from Kiran Kedlaya's notes on inequalities. It's really a shame that there is no course in the standard curriculum which teaches this. 

Here's something interesting that I couldn't get to work, but maybe will help someone else. Essentially by definition, this Kostka number is the dimension of the space of diagonal invariants in the representation of $SL_n$ associated to the partition $(n-1, n-2, \cdots, 2,1)$. And this vector space comes with a natural $S_n$-action, from the embedding of $S_n$ into $SL_n$. Unfortunately, they don't match! When $n=3$, there are two labeled tournaments. (Orient the triangle clockwise or counterclockwise.) So a permutation $\sigma$ in $S_3$ either preserves or switches the tournaments based on the sign of $\sigma$. The corresponding permutation representation of $S_3$ is the direct sum of the trivial and the sign rep. By way of contrast, the representation of $S_3$ on the diagonal invariants of $V_{21}$ is the $2$-dimensional irrep of $S_3$. Still, it would be really cool if we could find a deeper relation between these two representations of $S_n$ than simply the fact that they have the same dimension. In particular, remember that the number of orbits in a permutation representation is always the multiplicity of the trivial rep, so one could imagine counting isomorphism classes by representation theory if we can find a good alternate description of the tournament representation. 

Let $q(x)$ be the quadratic through the $(x_i, f(x_i))$. Set $g(x) = f(x) - q(x)$. Then $g(x_1) = g(x_2) = g(x_3) = 0$ and you want to show $g''(x)=0$ for some $x$. Apply Rolle's theorem to get that $g'$ has zeroes $y_1$ and $y_2$ in $(x_1, x_2)$ and $(x_2, x_3)$ respectively, then apply it again to get that $g''$ has a zero in $(y_1, y_2)$. 

I don't know a combinatorial interpretation, but here is a quick proof. Let $1 \leq a \leq b$. Write $$\sum_{0 \leq k \leq a} (-1)^k \frac{(a+b-k-1)!}{(a-k)! (b-k)! k!} = \frac{1}{a!} \sum_{0 \leq k \leq a} (-1)^k \frac{(a+b-k-1)!}{(b-k)!} \binom{a}{k}$$ $$= \frac{1}{a!} \sum_{0 \leq k \leq a} (-1)^k f(k) \binom{a}{k}$$ where $$f(k) = (a-1+b-k)(a-2+b-k) \cdots (2+b-k)(1+b-k).$$ Since $f(k)$ is a polynomial of degree $a-1$, its $a$-th difference is zero. (We used the assumption $0 \leq k \leq a \leq b$ to make sure that $(a+b-k-1)! / (b-k)!$ is never $0/0$.) A combinatorial interpretation may be difficult because the summands are not always integers. EG: $a=b=2$ gives $3/2 - 2+1/2=0$. 

Congratulations, you have asked one of the few questions of this type for which there is a positive answer. Such a formula is the main result (Theorem 2.1) of Remmel's paper "A formula for the Kronecker products of Schur functions of hook shapes". A few points of vocabulary to get you oriented: The irreducible representations of $S_n$ are indexed by the partitions of $n$. The partition $\bigwedge^k V$ corresponds to the partition $(n-k, 1,1,\ldots, 1)$ where there are $k$ $1$'s. These partitions are called "hooks". (Note the degenerate cases: $k=0$ is $(n)$ and gives the trivial representation; $k=n-1$ is $(1,1,\ldots,1)$ and gives the sign representation.) The tensor product of $S_n$ representations corresponds to the combinatorial operation known as Kronecker product. So the title of Remmel's paper tells you that it is answering your question, and googling on "Kronecker hook" will turn up more references. Remmel defines a double hook to be a partition of the form $(q,p, 2, \ldots, 2, 1,\ldots, 1)$ where there are $k$ occurrences of $2$ and $\ell$ occurrences of $1$. His result is that the only irreps that appear in $\bigwedge^i V \otimes \bigwedge^j V$ are hooks and double hooks, that the multiplicities with which they appear are $\leq 2$, and he gives an exact formula for which ones appear with which multiplicities.