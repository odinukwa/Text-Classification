Just found my old notes from grad school. It's not quite clear if your interest in telicity is historical (e.g. how did Dowty 19XX understand telicity?); obviously, a lot has been done since then. The following is based on Depraetere 1996. Tests to distinguish boundedness from unboundedness and telicity from atelicity (15a) John drank beer. (atelic, unbounded) (15b) John drank a glass of beer. (telic, bounded) 

There is no such "universal" definition - and if there were one, it would be useless. Every linguist decides whether they need a word as a concept in their analysis and if they choose to have words, they decide what a word is in that particular language they work with. For a very readable, recent and succinct discussion of wordhood see The Oxford Handbook of Word (2015), esp. Wray 2015. 

NB! by Scandinavian Durkin means "the ancestor varieties of both West Norse (Norwegian and Icelandic) and East Norse (Danish and Swedish), but at a time earlier than our earliest substantial surviving documents for any of the Scandinavian languages, and at a time when the differences between West and East Norse were still very slight" (p. 175). 

Bybee, Pagliuca and Perkins 1996 put it very nicely. Here's what they wrote. Iterative "signals that an action is repeated on a single occasion and differs from the habitual and frequentative, which both signal the repetition occurred on different occasions" (p. 160). Here are the two examples they use: He searched for his keys all morning. iterative He searched for his brother in every city he visited. frequentative Naturally, there is a lot of variation in linguistic terminology, esp. in aspect studies. Comrie 1976 argues for the importance of the iterative vs. habitual distinction; thus, the frequentative is viewed as a subclass of the habitual. Carslon 2012 does mention Van Geenhoven 2004, who views the frequentative as a subclass of the iterative; however, Carlson insists that Van Geenhoven 2004 terminology is not general usage. 

As Sihler puts it, [in Latin] "an s is lost before most voiced consonants" (para 225), cf. Meiser "(Konsonant+) s schwindet im Anlaut vor Nasal." Thus, in Anlaut (word-initial) clusters *sn, *sm, *sl the *s is lost. He admits that for *sm and *sl the evidence is "meagre." There is no written evidence coming from Latin; this is a reconstruction (i.e. educated guess) based on evidence coming from other IE languages and from the development of Latin Inlaut sn, sm, sl clusters - there is written evidence for the latter. Presumably, the change was s => z=> h (?) => 0 

As usual with terminology, what the term confix means depends on your theory of morphology. Some linguists used it in the sense of what we now call "circumfix." However, Igor Mel'cuk uses it in the sense of "an affix which neither divides the root not it is divided." In his theory of morphology, there are four types: confix, circumfix, infix, and transfix, see the screenshot below from Mugdan 1990: 

Yes, Basque (in the batua dialect) has ala "or (exclusive)" and edo "or (inclusive)", although ala can only be used in questions. You may also be interested in the WALS maps of languages with an Inclusive/Exclusive Distinction in Independent Pronouns and an Inclusive/Exclusive Distinction in Verbal Inflection. 

No, there is no specific term for how well an onomatopoeic word approximates the sound it refers to, because there is no way to measure how alike two sounds are. Remember that nearly every utterance made by the human vocal apparatus is a combination of several articulators sounding in unison (or phased relative to each other), making their output even more difficult to compare to any given sound in nature. 

My copy of A Course in Phonetics isn't on me at the moment, but if you're open to using software, I'd recommend Praat for its automatic formant tracking feature. 

Yes, the same answer that was provided in the previous question applies here. Several Slavic languages have an animate/inanimate distinction in addition to masculine/feminine/neuter. In some languages, only certain combinations are permissible - for example, Russian only distinguishes between animate and inanimate in the masculine. It's also been hypothesized that Proto-Indo-European possessed only an animacy distinction, with masculine/feminine developing out of the animate class of nouns and the inanimates becoming neuter. This idea appears to originate from Meillet (1926), and was further developed by Gamkrelidze and Ivanov (1973, 1984). Gamkrelidze, T.V. & Ivanov, V.V. (1973). "Sprachtypologie und die Rekonstruktion der gemeinindogermanischen Verschlüsse". Phonetica 27. 150-156. Gamkrelidze, T.V. & Ivanov, V.V. (1984). "Indoevropejskij jazyk i indoevropejcy". Rekonstrukcija i istoriko-tipologicheskij analiz prajazyka i protokul'tury. Tbilisi: IzdatePstvo Tbilisskogo Universiteta Meillet, A. (1926). Linguistique Historique et Linguistique Generale. Honore Champion, Paris. 

A diphthong is one sound segment created by a smooth transition between two targets within the same syllable. As a phonetic definition, this makes no theoretical claims about which phoneme(s) represent the articulation in the mind of the speaker. This statement is a bit vague, but is, as far as I can tell, true in some situations; see below. The number and character of underlying phonemes that a diphthong corresponds to varies by language and which researcher you talk to. Different kinds of evidence for a particular interpretation of field data are evaluated differently by each specialists, and mainstream phonology has yet to produce a theoretical framework that gives one clear answer to this question for each language. In English, for example, the diphthong [e͡ɪ] could be represented underlyingly as either the single phoneme /e͡ɪ/ or a sequence of two phonemes /ej/, where /j/ is the same segment that appears in /jɛs/ "yes". The latter analysis is tempting, since it would reduce the size of the phonemic inventory (all possible underlying segments) of English, but would have to explain the phonetic differences between the /j/ in "yes" and the /j/ in "made", which is much more like an [ɪ]. Of course, the addition of a transformation rule would be standard practice when faced with this situation, but we are then left with the basic question of which is simpler (and thus, more likely to be adopted as a strategy by native speakers): fewer phonemes, or fewer rules? 

I have parsed the following sentence in the Stanford CoreNLP demo page and the Stanford parser demo page. Although both result in a parse that can imply purpose semantics (hinging on the and the accordingly), clearly the parsers don't capture "in order to" as an expression whose meaning much transcends the relationships between its own word constituents (as in an idiom). 

What is called in pragmatics an utterance, and what is called a body gesture or a facial gesture, are all acts of communication. Is there any term in any context or discipline, that unites these different modalities of communication/expression under one umbrella term? 

Given a sentence from $URL$ From a layman's perspective, "by discussing" may link to either of two former phrases contained in this sentence. How does any school of parsing (e.g. popular ones like dependency parsing, constituency parsing, and others) preserve the ambiguous linkage of "by discussing two contexts" to both "describe" and "connecting"? Is preserving the ambiguity only possible by suggesting two separate parses, or is there a kind of parse that, inherently, preserves the ambiguity? 

Using verbnet to test whether a sentence matches a frame, how does one determine whether the semantic role specified in the verbnet frame is appearing in the sentence or not? e.g. on this verbnet class there is a frame . Is it somewhere specified how is it to be determined for a given sentence, whether it indeed has a role or not, whether or not it indeed has a Destination role or not, in the right location? how does one identify a v.s. a non-Destination? And likewise is defined anywhere? I am not sure I could locate this inside the otherwise definitive description of verbnet found here. 

In CFG we "simply" have production rules. Whereas in Combinatory Categorial Grammar (CCG) on the other hand, we have both composition rules over categories, and a mapping from syntax to semantics (from the categories to lambda expressions). Could we equivalently use such mappings to semantics, over a CFG framework, to obtain semantic representations? similarly to how we use such mappings in CCG? asked differently and perhaps more precisely, what would a combinatory formalism for semantics over CFG look like? would it just in fact be CCG, or would the production rules play any role? 

You have a list of expressions, some of which are a single word and some of which multi-word expressions. How do you call such a collection? actually mathematically speaking I mean the case of a set, not a list with possibly repeating expressions. Would you call it a dictionary? I assume not. A lexicon? 

What kind of parsing, or pre-processing stage, may yield "in order to" as a single unit of meaning, thus making it amenable to semantics derivation same as a preposition affords? e.g. "for" may commonly imply purpose semantics, and having "for" parse as a preposition assists in deriving purpose semantics. 

I have found most descriptions of these principles somewhat lacking in accessibility, something I can also say about discussions of why they are a good choice or trade-off in the limitations they impose. Can you propose a very self-contained explanation of these principles, drawing as little as possible from earlier terminology? 

This seems like a weak case. I'm sure there's a much more thorough rebuttal in the literature, but I'll give at least a few contrary remarks. The second point, that some words in the two languages seem to have some sounds in common, is the most frequent unscientific argument presented in linguistics circles for the existence of a language family. The problem is that between any two sufficiently large sets of data (language vocabularies have thousands of items), there will nearly always be a couple dozen pairs of words that can be extracted that are "similar enough" to be cognates. But that isn't how sound change works - to demonstrate shared ancestry, you must reconstruct words of the common ancestor language, and give a series of regular sound changes that output words in the daughter languages - Grimm's law is a model example of this. The late Basque linguist Larry Trask gave a quite readable defense against the ceaseless proposals attempting to connect Basque, a language isolate, with nearly every other language family, in "Origin and Relatives of the Basque Language" (1995), which I highly recommend for its applicability to this case. I also fail to see how a Proto-Semitic influence would have induced PIE to replace *[k] and *[t] with *[x] and *[θ] when both languages had *[k] and *[t]. Furthermore, PS doesn't even have an *[f] sound, so PIE could not have borrowed it. (You gave *[h], instead of *[x], as the reflex of PIE *[k] - this was a later development in English). Proto-Indo-European had only two tenses, present and past, on verbs in the imperfective aspect. Tense on other verbs was unmarked. The rich tense systems of its descendants are modern innovations. "Ablaut" refers to a morphological alternation already present in PIE - you're thinking of Germanic umlaut, a process which is uncontroversially understood as the product of fronting a stem vowel before a suffix containing [i] (the suffix is later dropped). A substrate influence is not needed to explain this. That being said, you're right that the loss of complexity in the case marking system and the large number of words unique to Proto-Germanic may indicate a pre-IE linguistic substrate. Unfortunately, barring a revolutionary discovery of a new trove of data, we will most likely never know. 

According to Twitter's new Terms of Service (see paragraph (I)(4)(A)), you may not export any data retrieved from Twitter, whether through its public API or by scraping. So you will probably never find a readily-available corpus of tweets - and if you do, it's in violation. Twitter has already taken a lot of flak for essentially shutting down academic research into a whole new frontier of linguistic data. However, if you'd like to publish your results after analysis, you may provide a database of tweet IDs and usernames, which other researchers can cross-reference with the official Twitter archive. I'd recommend the Streaming API to start aggregating data.