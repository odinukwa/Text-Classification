You probably want to consider using , as KPWINC says, but to answer your question directly, you want to use 's "skip" option. If your first command, as stated, is: 

I have a grid cluster. (It's running SGE, but I don't think that's relevant.) All the machines are intended to be able to drop out and come back at any time without any significant issue. However, my users need the ability to run cron jobs. Right now, they're just picking a server at random and plopping a cron job on it. I could assign a specific server, either in the grid or external, for them to run their jobs on, but that just seems wrong. Does anyone have a solution where crontabs are stored centrally, but run (potentially) elsewhere? Or am I just overthinking this? 

It has one optimization already, in that if a page contains only two colors, it marks it as B&W, even if one of the colors is nowhere near black, white, or grey. I also need to implement a filter to discard pages that have something like one pixel of another color, and also one to only mark the ones that are excessively color-y, to filter out things in color that happen on every page. (I figure that if someone is going to use this, they're intending to print at least some of the pages in black-and-white.) After that, I have to implement printing each of those sets through the appropriate queue. Hopefully I can figure out how to pull the Ghostscript and netpbm stuff back into the script, even if I have to change languages. 

I switched to TrendMicro OfficeScan recently, and I'm reasonably pleased with it. (Though I also switched from Symantec, so I would have been pleased with a kick in the teeth.) I do not believe that they charge for virus definition updates (you can download their pattern file for free, so I assume it's free for the software, too), it's client-server based, and they do have clients for 2k through Vista and '08, (Windows 7 isn't listed, but I would be surprised if it wasn't supported). I believe that it might also have the possibility of uninstalling SAV during installation, possibly even during remote installation. (I couldn't do it because the stupid Symantec firewall had been enabled and I had to touch each machine anyway.) 

Update Now that we know it's an MTU issue, and one that involves only your Ubuntu router, that would imply that your Ubuntu router is breaking packet fragmentation somehow. Is it running a firewall? Is it blocking ICMP? If so, try disabling that. (Obviously, move back to the standard MTU of 1500 first; otherwise you'll be debugging a problem that doesn't exist any more.) 

I'm not familiar with msysgit, but can it use PuTTY's ? If you don't know, is a simple command line ssh client, and it can use Pageant to authenticate. Update: Yes, you should provide different documentation to your Windows users. (Unless you think that the Windows users are going to be using OpenSSH for something other than git access.) I think you're trying to force an equivalence that does not exist. It seems to me that you're trying to "[make] ssh easier" by making it harder. 

I'm making assumptions about the network assigned by pptpd. Also, that route won't survive a reboot, so you probably want to add the route to a configuration file. Which file and what syntax depends on your distribution. 

Depends on how much access your administrator has given you via sudo. The simplest answer, assuming that you have permission to do so, is to run "sudo -s" to get a privileged shell and then just do your 

This sounds like it was able to connect via LDAP, but the thing that it was trying to do failed. But I don't quite follow what it was trying to do, much less how to reproduce it or resolve it. 2011-08-26 update: Using to try and make an LDAP connection directly to the DCs results in these errors: 

However, the memory metrics appear to just report the amount of memory used by the processes running inside the Cloud Foundry container. If you've dealt with monitoring Java apps, you're aware that JVMs will eventually, potentially, consume as much memory as you've told them they can have, even if the Java application is not using it. (In other words, it does its own memory management.) This means that the actual process might be consuming its full 1GB of memory, but that doesn't imply that it's about to run out of memory. In my experience, useful monitoring of Java app memory utilization depends on getting data from the JVM itself, via something like JMX (such as via ). However, Cloud Foundry does not seem to provide information about where the app is actually running. (In fact, I've found some people claiming that Cloud Foundry explicitly will not tell you that information.) And that means I have nowhere to connect a JMX client to. If I want to monitor the memory utilization of my Java apps inside Cloud Foundry, how should I do so? Feel free to rebut any of my claims if you know better. 

There are good books on specific topics, and good books on basic stuff (in both cases, check out O'Reilly books), but there's nothing that I'm aware of that is a comprehensive middle ground. IMO, your best bet is to learn by doing anyway. 

You at least need port 135 open as well. That said, I don't know that I would suggest putting a Windows machine on the Internet with all of those ports open. Can you at least have the firewall limit those open ports to your local system's IP? 

Outlook 2007 under Windows XP connecting to Exchange 2003 SP2: when started, it flips back and forth between "Connecting to Exchange Server" and "Disconnected" three or four times, then gives up and stays disconnected. I tried deleting the ost file (which was nearly 2GB), turning Cached mode on and off, recreating the account inside the Mail control panel, changing the account to use HTTP, and probably some other things. None of it seemed to make any difference, until … After fiddling with it for a while, I got this absurd error message dialog at startup, and it exits after I click OK: 

However, this assumes that your terminal is VT100-compliant, which, while a good bet, is not a certainty.‡ The more correct way to do it is to rely on your terminfo settings and run this command: 

Their current system is running sets of applications under Xvnc, and when they encounter a situation where they need to pass those applications off to another user, they hand off the whole Xvnc session and start a new one. Right now, this causes problems apparently due to multiple Gnome sessions walking on each others' feet, about which I have another question open. I should be able to resolve this by getting rid of Gnome, but something really tweaks me about this setup. Now that I'm thinking about it, I can't really figure out what, but it's still there. I want to move them into running their apps under xpra (or xmove or freenx or neatx) and then display them on whatever X server they want. This would give them the ability to move the applications around, they could use whatever X server they want (including Xvnc with Gnome, since they'll only need to run it once), and they could hand applications around. But I'm concerned that the interface for moving the applications around will be onerous. Has anyone had any similar situation that they've resolved well? Or have any ideas regardless of personal experience? 

Oh, and if you want to set the password at the same time, you have to pre-encrypt it. I continually rewrite this little program to do Unix-standard salt encryption: 

I have a Java application that I'm deploying inside a Cloud Foundry environment. I want to monitor the application's memory usage. Cloud Foundry provides the command that produces output about each instance of the specified application. Here you can see information about a particular application with two running instances (expurgated): 

Windows Server provides a certificate authority service. However, it's not clear from its documentation how (or if) the root certificate gets distributed to clients. 

In the Windows DHCP admin tool, right-click on the server and select Properties. Go to the DNS tab and "Enable DNS Dynamic Updates". This is the default setting, though (I'm pretty sure), and if it's turned off, it's likely that someone turned it off for a reason. And that reason is probably to prevent it from crapping all over your DNS server. The Windows DHCP server will register names and then forget to remove them. There's a lousy workaround embedded in the Windows DNS server called "Zone Aging/Scavenging", but it has been known to delete records that you are actually using. IMHO, the proper solution is to use a real DHCP server, like ISC DHCP, that won't forget to remove unused hostnames. 

What you're wanting to do fundamentally isn't the way GPG works. Let's say that something like this existed: you could distribute one public key that could be decrypted by multiple private keys. When the sender encrypts the message with the public key, it would then be decryptable by anyone with any of those private keys. Now you want to revoke one of the private keys. But decryption doesn't go through a third party; anyone who has a matching private key can decrypt the message. The only way to revoke a key is to let the sender know to use a different public key. Which is the same thing you'd do if there were only one private key. So, ultimately, there's not any particular advantage to having multiple private keys for one public key. 

Can you not just install a machine on the network with a static IP? You said you were in control of DHCP, so just reserve a specific IP for that machine. It doesn't need to get the address from the DHCP server as long as no one else takes it. Of course, you still have the possibility of the bogus DHCP server handing out that address. You could also log all DHCP offer and ack packets that come from systems other than your official DHCP servers. If you have login access to the switch (you say you don't own them, but you do say that you can "turn off the port"), you could even automate the disabling of the port. 

The xterm sequences work fine for gnome-terminal. What shell are you using and what did you put in your shell config file? 

Part of the problem, I think, is that there is an API. Under Unix, admins are largely scripting the automation of command-line utilities they already use. Under Windows, you have to use this API that is unfamiliar on every level. For example, what does "impersonate" mean? This is a trivial concept to a Unix admin, who is likely to use sudo and su and be familiar with setuid scripts already. But a Windows admin is unlikely to be familiar with any of that; they might know about "runas" (or the equivalent GUI option), but they are far more likely to log in as an administrator when they need to do something admin-y. And the documentation on scripting in Windows is miserable. For one thing, it's far more "interpreted language" than script, again because they are using an (unfamiliar) API and not commands that they're already familiar with. But I don't think I've ever found anything useful in Microsoft's documentation that wasn't led into by finding someone who was already doing something close to what I wanted that pointed me in the right direction. Nowhere does there seem to be a list of things-you-can-do. It's like you already have to be familiar with Windows internals in order to do the most basic things. Not that Unix scripts don't often look like line noise. But a Unix admin can start with a script that does nothing but run simple commands that he already knows. ("I always have to run these three commands in succession. If I just put them in a file together, I can do it in one command!") And then he can later progress as he gets comfortable with the situation. In contrast, there's no way for an admin to script "log into server as administrator; click on Start → Settings → Control Panel; double-click System; click on the Computer Name tab; etc." Yeah, whatever he was trying to get to is probably presented through an API somewhere, but there's no way for him to incrementally find that. So, to answer the question "how can we get Windows admins to do more scripting?", the answer is, make scripting less alien. How to do that, I don't know. Honestly, the answer is in Microsoft's hands. There's no reason that they can't have a command line utility to do everything that's done via GUI. (There are actually a lot of them out there now, but they're not advertised, they're poorly documented, and they're inconsistent.) There's also no reason that there couldn't be some hint in the GUI as to what that button actually does. Have a tooltip that shows the API object that's being modified. Or document it in the Help window. There's no problem in shielding users from the internals, but Windows seems to go out of its way to actively hide those internals, even from those who want to find them. 

It also looks like if there are no scheduled meetings "nearby" that Outlook also shows "No Information". I guess Outlook and/or Exchange don't really publish "Free/Busy" information, but just "Busy" information, so that there's no difference between "Free for a long time" and "No Information". Anyway, I scheduled a weekly meeting at 4AM on Sundays and that seems to have resolved that problem as well. 

I was able to find direct connections to the instances by querying Cloud Foundry's (Go)Router's URL. 

The poorly-named Console is a replacement terminal for cmd.exe (or powershell.exe or, really, any other cli shell). It's still running cmd.exe on the inside, so there are still problems with things like its confusing command history, but window resizing, selection, etc. all work much better. It also supports tabs, support for saving multiple configurations (so you can easily start different shells and different options, like startup directory and appearance settings), PageUp does something useful (I reconfigured mine to Shift-PgUp), etc. 

If you type in a hostname with no dots in it, DNS resolvers try to look up that hostname by first appending the configured search domains to it. For most resolvers, if you use a hostname with at least one dot in it, the resolver first tries the hostname on its own, and falls back to appending the configured search domains. Many resolvers have the ability to change their behavior so that they append the search domains for hostnames with dots. This is often through an option called "" that tells the resolver how many dots the hostname must have before it tries to look up the hostname on its own first. In order to make work, add this line to your :