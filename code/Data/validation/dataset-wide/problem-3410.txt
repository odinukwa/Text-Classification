This seems like a simple confusion of a polysemous concept: grammar. Grammar has several meanings when used both by specialists and non-specialists. 

a. Learning a language from texts and a dictionary. In that case, yes, it is possible for humans to learn a language in that way (at least the written part of it). b. Learning a language for an alien from texts and a dictionary. The problem here is that a dictionary would not be of any use aliens unless it was a bilingual dictionary between their language and the human language. If it's just the dictionary of (say) English, then that's simply another text in English. It would be possible to make sense of the texts for the aliens only if they could observe the context in which it is used. Simply seeing lots of texts is not enough without some external reference - as attested by the many undeciphered languages. This would be doubly hard since the Aliens would presumably not have the same script or maybe not even the same way of writing (phonetic vs syllabic vs ideographic). 

The responses so far have been that no language is "more evolved" than others. But in fact, no language needs more or less context than another. Context is essential in interpreting all language. What varies is what type of construction needs what type of context. All languages are redundant. They're just redundant in different places in different ways. A great example is plural marking. Strictly speaking, you almost never need the plural marking to get the plural meaning across. The context almost always provides enough information. And it always does in counting. Thus some languages (like Hungarian or Chinese) don't have plural marking on nouns preceded by numbers. But they may require some other redundant feature such as Chinese structural particles. Most often these contribute to some kind of overall cohesion (agreement, vowel harmony, etc.) You will find similar variation in gender or tense markings. Some languages always specify a time reference or a category reference, others very rarely do. Also, you should not that what is obligatory in written language could well not be required in spoken language. So the example you give, would be relatively plausible in certain types of English spoken discourse. 

Natural language does not "strongly distinguish between syntax and semantics". In fact, they are very closely interlinked. Syntactic constructions are used to express all kinds of meanings. Natural language is used to communicate much more than "to explain what something is or what is to be done". It's not even clear that communicating that kind of information is what language evolved to do (see e.g. Dunbar's thesis). Nevertheless, focusing on the kind of semantics that can be expressed by a programming language is what has been keeping the developments in semantics back. Natural and programming languages are compositional in very different ways. While you can define all the compositional rules in a programming language, a natural language is much freer - which is what makes language change possible. It also makes the expressive potential of a natural language significantly larger than that of a programming language. There's no irony in a programming language (that's not to say that programmers cannot express puns or even parody each other's code - but they're communicating those to other humans, not the computer). 

Is generative grammar difficult to incorporate into cognitive processing models? Not particularly. In fact, because generative grammar constraints what is meant by language. This makes it much easier to design experiments within the paradigm. However, you have to remember that, as originally formulated, generative grammar does not make any predictions about the online processing of language. It is exclusively concerned with 'competence' rather than 'performance'. But it is easily laid out into experimentally isolatable components, and a lot of psycholinguists have chosen to adopt its general approach as a sort of 'basic linguistic theory'. Unfortunately, this has led to a significant impoverishment of psycholinguistic research in the last forty years or so. Is the semantic component of generative grammar difficult to reconcile with psycholinguistic models? This makes the assumption that there is such as thing as a coherent semantic theory of generative grammar seeking cognitive plausibility. All the theories I've looked at are based on some version of formal logic. This is not too difficult to model experimentally but if you look at actual psycholinguistic research, nobody looks at this much (beyond some work in inference and presupposition). That's because natural language semantics is much more difficult to map onto generative linguistics than natural language syntax. So in practice, most psycholinguists rely on a sort of folk theory of meaning informed by various models. 

No maxim at all. The conversation was fully informative for both parties (as I have witnessed in real life many times). Maxim of quality. To help identify the hyperbole. Maxim of quantity. To account for the fact, that while the first speaker's hyperbole is understood, they are likely interested in more information to make their own decision. Maxim of relation - depending on the relationship of the two interlocutors. A parent may be less happy with this answer form a child than a partner with whom this may be an established conversational pattern. Maxim of manner. If the context does not make it clear whether this is a hyperbole or a literal statement. 

The problem with all grammatical labels used across languages is that they either lose or add some information. A further problem is that the terms are not used consistently by individual researchers or research paradigms. So the answer to this question is both yes and no. Yes, in the sense that perfect is generally applied to tense-related phenomena and perfective to aspect based phenomena (with the proviso that this is not often in the same language). So you're better off using perfect when talking about tenses and perfective when talking about aspects. No, in the sense, that tense and aspect are closely interlinked phenomena. In Slavic languages they mostly have independent morphology but in Germanic languages, they mostly don't. So the 'perfect' in 'present perfect' describes the same facet of the tense that 'perfective' describes independently. I once compared the English tense system with Czech to some interesting results. I found a lot of functional overlap but also many differences. Ultimately, using similar terminology was broadly helpful but also with a lot of potential for confusion: $URL$ 

As a proponent of construction grammar, I am perhaps the wrong person to answer this. But I can see at least two non-computational advantages of a constituency parsing: 

Re 1. The whole SOV/VSO/... thing is mostly an artefact of a linguistic theory that is concerned with the surface order of words in a sentence. It is clearly a remnant of the analytic nature of the languages spoken or focused on by the theoreticians. Not all traditions are at all concerned with word order nearly as much and will ask questions with a different bias. It may be worth keeping an eye on how the ordering of words is used to express certain meanings, but the order itself is really incidental. Of course, the whole subject/object deal is itself incidental to concerns of agent/patient relationship (experts on ergativity would do well to weigh in, here). Re 2. Given the revised emphasis and refocusing of our concern about word order from 1, we can ask why (with all the caveats in mind) do people tend to express the agent/patient relationship in a linear order going from agent to patient. The answer probably lies in what I would like to call (inspired by George Lakoff) 'motivated iconicity'. If time and action are conceptualized in space, then when that space is conceived as directional away from the actor, language may replicate that direction with word order. There are no universals here, just tendencies that may aggregate to very strong trends. There's some research on iconicity but not nearly enough to make this more than a supposition. But perhaps one worth further investigation. 

Yes and no. There are a number of well-known algorithms for determining a text's complexity. There are several generations of these and most of them are tied to educational attainment such as years of education, education level studied or age. They are very much replicable across populations but they do not do a very good job for determining suitability to an individual and/or very short texts. Most of the algorithms take proxies for semantic and syntactic complexities in the length of words and sentences. They do not look at phonic complexity - which may have to do with things like consonant clusters, etc. but would require more work. The Wikipedia entry on Readability does a good job of summarizing them. The first generation of these algorithms peaked in the 1960s and 70s and they have been built into many mainstream tools such as Microsoft Word and little free tools can be found online. Since the late 1990s, there have been some efforts in second generation products - see a review by Renlearn (which is a commercial actor in this field so keep that in mind). The lesson is that you cannot really just make up an algorithm without testing it against readers - and that adding factors to the measure does not necessarily improve reliability. Things get even more difficult when you try to personalize the measure. You need to know a lot about the user - with beginner or struggling readers, it's their phonic skills which is something we've tried to achieve in our work on the Phonics Engine but then you need a way to really understand the text at the phonic level. You also need to take into account the reader's interests because if they love dinosaurs a word like Pterodactyl may be actually easy for them. Ultimately, if you want to help individuals, you don't need a tool to help you categorize the texts but to help them access the texts or to help creators create more accessible texts. The tools for this are still not very good and looking at a single dimensional score for texts is more of a hindrance than a help. 

I agree with all the answers here. I would recommend Dixon's 'Rise and Fall of Languages' $URL$ where he explores some of these issues in depth. I particularly found his analogy with 'punctuated equilibria' very useful. But he also addresses questions of language boundaries and relatedness. Well worth a read, even if a bit controversial in places. 

WordNet is not a dictionary but a semantic lexical database. The key function of WordNet is to create a network of semantic relationships between words (synonyms, meronyms, etc.) So it makes sense it would only focus on content words and not function words (which is what stop words are). There are many free online dictionaries - depends on what you need one for. Wiktionary is really comprehensive and it has a machine-readable downloadable version. 

The etymology is fairly straightforward. The temporal meaning of before is secondary to the spatial meaning. This is very common across all prepositions of time: at (5am), in (5 mins), on (Wednesday), between (3 and 4), from - to, through. The Conceptual Metaphor theory posits a TIME IS SPACE metaphor that is present across many languages and many parts of the language. It is not limited to preposition. You will find it in adverbs as well as in things people say about time: 'time went by quickly', 'time slips away', 'we need to move the meeting back/forward', 'we need a chunk of time', 'give me space to figure things out'. This is bolstered by the associated metaphor of TIME IS AN OBJECT: 'give me time', 'take 5 minutes', 'employees steal time by going on Facebook', etc. This often explained by our experience of space and objects being somehow more physically and physiologically primary but I suspect that this is more of a reach. 

As always, 'why' questions are a really bad idea in linguistics. You can reasonably ask these three types of questions: 

I've written a post about 5 things people should know about language and another one with 17 things linguists know about language. Most of those will come as a surprise to non-linguists (and even some linguists raised in certain traditions). 

The only way of disambiguating satire or any figurative language (and most language is figurative) is shared knowledge of the world (and culture). The only way for Jim to know that Jane is speaking figuratively is that he knows she actually does not have a .45 or that she is extremely unlikely to have one. Or possibly, assuming Jane is on duty police, having a .45 is in no way relevant to the playground. You also have to start with the assumption that there is some real world context in which Jane could have interpreted Jim's statement as non-hyperbolic (e.g. the playground is a known place for drug dealing). The assumption that there is some universal procedure for identifying figurative language is behind much of the unjustified British conceit that Americans don't understand irony. But this is simply caused by a lack of shared cultural (world) knowledge. Both Americans and Brits use irony/satire in about equal measure but their usage spheres do not overlap perfectly. The misunderstanding goes both ways but the stereotype developed only in one direction for other reasons. However, this misunderstanding is not only cross-cultural. In any interpersonal relationship, the overlap in shared knowledge of the world (both general and immediate) is imperfect, thus leading to many possible confusions. Language (communication) has many conversation repair instruments such as 'just kidding' but that does not always prevent issues since figurative language (or which irony or satire are just one small part) often evokes very emotional responses.