The book you mention (Partee et al.) is the best one. If it's not an option for you, I'd recommend this one: Gamut 

In surface syntax it's "John - seemed". In deep syntax it depends on the theory. "John" would depend on "fall" but sometimes there are two heads and one would say that the subject of "seem" is athematic, i.e., it has no thematic role. XDG does it this way, for example. 

In the lexicon, ||loves||=λx.λy.love(x,y) and ||obviously||=λP.obviously(P). On this view, syntactic composition is function application (hence the name "functionism" for this approach). Some say that lambda calculus is unwieldy for implementing meaning assembly because it isn't monotonic. But it's a wrong approach to use lambda calculus at the level of surface syntax. (Linguistic) meaning is part of deep syntax, hence it should be assembled there. Deep syntax structures are unordered (or can be viewed as unordered for the purpose of semantic representation) and thus a λ-expression can refer to grammatical functions raher than the order in which syntactic structures are built up. In glue semantics (which uses linear logic) the meaning of "love" is taken to be 

As with the previous question, presupposition (as this writer is using it, but I think it's fairly general) is about what the participants in the conversation know, not about what the participants in the narrative know. 

None whatever. There are no "official" resources of any kind, for any aspect of the English language. There are dictionaries and grammars which are widely regarded as authoritative, but none of them have any kind of "official" standing, whatever that may mean. 

"How to prove" something that probably isn't true, is rather difficult. According to this site, the Thai word has a solid etymology pla.A in proto-Tai-Kadai. If this is true (and I have no idea how reliable the site is, but it looks plausible) then the word is not a loanword from Sanskrit, and has no connection with the PIE root (unless you subscribe to one of the controversial super-grouping theories). 

There is very little relationship between the structure and grammar of languages and how they are written. Bear in mind that most languages that have ever existed were unwritten, that some languages have been written in more than one writing system, and that native speakers of a language almost invariably learn to speak before they learn to read and write. Whatever might be their view for or against Chomsky's Universal Grammar, virtually all linguists agree that language "happened naturally" in some sense, whereas writing was an invented technology, that came along only in the last few thousand years. It is conceivable that the writing system of a language could have been devised with reference to the grammatical structure of a language, but I'm not aware of any examples. (Sanskrit is the only example we have, as far as I am aware, of a pre-literate tradition of grammatical analysis; and while the Devanagari script is ordered on phonetic principles - unlike the arbitrary arrangement of European alphabets - I don't believe there is anything particular to Sanskrit grammar in its construction and use). 

The term "agglutinative" refers to languages in which BOTH derivation and inflection are expressed by chained suffixes. The confusion might originate from the fact that both properties positively correlate in natural languages. Esperanto is an artificial language, and therefore atypical in this respect. 

The reference to future was inferred from the context, much like in today's German: Ich arbeite morgen nicht (I won't work tomorrow). The adverb "tomorrow" indicates that the speaker conveys a future event. Without a semantic clue in the sentence, the preceding discourse might be an indication. The go-periphrasis is a much later development. 

-asъ changed to -axъ in this context, it’s a pretty known fact in historical Slavonic linguistics. Note that -s- can still be found in modern Lithuanian in plural locatives. 

The principle of Economy of Expression applies to the general principle of how c-structures are built. In your example the I' node comes from I' -> (I) VP, i.e., this rule is required to create a well-formed f-structure of a sentence that may contain an auxiliary (as in Joan has written...). The same rules are applied to analyze both sentences and the f-structures are identical except for the value of the TENSE attribute. 

The verb they tabulate to illustrate is גלה 'reveal', which displays exactly the same patterns as you mention with תלה. They go on to say that 

There are instances where a word has been altered by folk-etymology, or by analogy with another word. For example, the English word admiral is ultimately a borrowing from Arabic amir al-bahr, but the 'd' is thought to have appeared by confusion with admirable. In that particular case one could say that the word has two sources. But such examples are the exception, not the rule. 

Wikipedia says "If a numeral is used with a noun, then the plural suffix is usually not used". (Unreferenced, unfortunately, but it agrees with my memory from when I studied Turkish.) So, no, neither the case nor the number of nouns changes with different numerals. I believe the use of the genitive singular for (numbers ending in) 2, 3 or 4, as opposed to the genitive plural for larger numbers in Slavonic languages is generally regarded as a paucal form, a generalisation of the dual. 

If you are lumping pronouns in with nouns (not usual, but I can see you might) then examples are rarer, but they exist. Besides the imperatives that jknappen mentions, in informal conversation you hear things like the following: 

Are you familiar with Sgall's Functional Generative Description (the theoretical framework used in the Prague Dependency Treebank)? He doesn't have synsemantic words in dependency trees and I think this is the right approach. He has the simple rule that in a phrase with an auxiliary or a preposition the autosemantic word is the head and whatever the auxiliary or preposition contributes to the syntactic structure is an attribute of the corresponding node in the tree. In other words, "I saw him" and "I have seen him" have the same dep. tree. Likewise, "Mary loves John" and "María ama a Juan" have the same dep. tree as far as structure is concerned. To sum up, only content words appear in syntax trees. If for some reason one would like to have function words in dependency trees they should be children of the nodes that represent content words (since they modify them, not vice versa). 

Yes, there are. Head-marking languages generally allow for free word order in case the language is caseless. Macedonian pops to mind, a language without cases on nouns but with free word order. Grammatical relations are indicated by clitics attached to the verb. Likewise, Northwest Caucasian languages have free word order and little morphology. In Circassian, only specific NPs are marked for case; Abkhaz lacks cases altogether. 

Because they are unaccusative verbs (ones where the subject may be seen as an experiencer rather than an active causer of something). 

There is no reasonable analysis under which "mcDon" is a syllable. It is two syllables, irrespective of whether you write an 'a' in it or not. "Kvit" (or "kvi") is one syllable except for those people who find it impossible to pronounce the cluster "kv", and for them it is two syllables. 

No. Your rule mostly works, but "in a row" fails to capture constructions like "He has definitely gone", where has is still an auxiliary. In fact, trying to analyse syntax just by considering the surface sequence is usually doomed to failure. Consider 

The existing of similar-sounding words in different languages tells you approximately nothing about any possible connection between the words. Unless you can show that they are part of a wider, regular, sound correspondence between the languages, or that there is a plausible route by which one might have been borrowed, there is no reason to believe that anything other than coincidence is involved. 

I don't think we ever know for sure how a sound change happens. We can deduce what changes have happened (and sometimes experience what changes are happening), and we can certainly conjecture about the phonetic processes involved, but we can never really answer how (or why) questions. Here, the obvious conjecture is that in that context, the fricative /s/ came to be replaced by a different fricative /f/. In other places the sequence became /ʃr/ or /str/, suggesting that it is often found to be awkward. I also notice that when I pronounce /sr/ I have a tendency to project my lower lip. If I happen to protrude my upper lip a bit, it can become /sfr/ (actually /sφr/, with a bilabial fricative). Notice that the other examples you give are difficult to understand unless you assume that they went through a fricative stage such as /β/, /ð/ or /ɣ/; then the probable process would again be substitution of the different fricative /f/. You can see a similar process at work currently in dialects of English where /θ/ (as in think) appears as /f/. 

Dependency parsing is constraint solving. I recommend you have a look at XDG, which is the only formally precise dependency grammar approach I'm aware of. 

You'll need a parser to identify objects automatically. There are a few online interfaces to natural language parsers. For example, you could use the Stanford parser (link) and look for "dobj" to find direct objects. 

Your intuition is correct, the parser is wrong in this case. Note that the argument structure for "lassen" taking an open complement is lassen⟨_,_,P⟨...⟩⟩ where P is the secondary predicator. This means that in a sentence like "er ließ sie ermorden" the causee depends on the finite verb. Reflexivisation unifies the subject with the argument in object position which in turn plays a role in the open complement's argument structure (this is referred to as argument fusion or coreference depending on the theory of dependency grammar used). For more on how argument structures interact with dependencies I'd recommend the PhD theses of Alsina and Manning. 

There is only stylistic difference. Attributes in Latin can precede or follow the head noun so both are well-formed and have the same meaning. 

Both have the same surface structure, but most analyses would consider am an auxiliary, but went not one: walking is a complement of the full verb went. 

You are using related in two different senses. When linguists refer to languages being related, they almost always mean "genetically related" - stemming ultimately from the same linguistic source. Most linguists today do not regard Hebrew and Greek as genetically related, but there is a respectable minority who believe that we can trace relationship further back than Afro-Asiatic and Indo-European to a superphylum, such as Nostratic, or Eurasiatic, depending on the particular theory. In those linguists' conception, Hebrew and Greek are related, but very distantly, in the way that a horse and a fly are very distantly related. Whatever kind of relationship the Jewish tradition talks about it is nothing like the linguistic conception of genetic relationship. It sounds from your account that it is something to do with suitability for use in particular contexts. Such a concept is purely a product of thinking about languages and not about their innate or historical properties, whereas the idea genetic relationship is predicated on there being an objective historical relationship, that of common descent. 

In Guarani, the derivational suffix -kue means former, ex-. It's also used in Jopara, the mix of Guarani and Spanish. 

There's no link between the principle of compositionality and (free) word order. Basque (and many other languages, such as most Indo-European and native American languages) use morphology to indicate grammatical functions whereas word order encodes topic-focus articulation. 

Arguments that are neither subject nor object nor adjunct are obliques. For example, indirect objects and causees are obliques. They are usually indexed by θ roles. 

The existence of a VP constituent is language specific. There are detailed constituency tests. One of the definitions of a language being configurational is the existence of a VP. The main evidence comes from sentence topology. In German, for example, no finite VP can be identified because the sentence splits into Vorfeld, Mittelfeld, etc., that is, it's organized along a completely different scheme. 

where e is an eventuality (also called situation, possible event, or state of affairs). Such logical forms can express everything one can encounter in language (such as quantification and logical connectives) so there's no reason not to use them if it helps elsewhere. And help it does a lot in pragmatically interpreting discourse. Meaning assembly that produces this kind of logical forms can be easily implemented (with or without lambda calculus) in both phrase-based and dependency-based grammar formalisms. 

Not readily, but I don't think it would take them too long to attune their ears either way. The obvious difference is all the consonants which have disappeared in modern French (mostly still represented in the spelling). The fact that many verbal endings have fallen together (-e, -es, -ent), and the fact that the passé simple has fallen out of use and replaced by a periphrastic tense, would I suspect make the Old French speakers think the moderns were talking a sort of pidgin. 

I don't think speakers do determine this, or need to. A word has (usually) a number of meanings, and we learn these in context (and sometimes a new meaning appears). It is only lexicographers and other analysts who have any need to identify which of the meanings are literal or basic and which are not. 

Yes. Biblical Hebrew has object suffixes which distinguish the person, gender and number of the object. Example (from the Shema:) 

I've never heard this, and don't know which accents it pertains to. But it appears to me to be a perfectly normal example of epenthesis (in fact it is mentioned in that article) I think /k/ in "espresso" is different: that is because of the influence of English words like "express". /aks/ is an example of metathesis, which is a different process.