Novikov complex is an extension of Morse theory to (closed) Morse 1-form $\omega$, which is not necessarily exact. Suppose for simplicity, $\omega$ is in the integer cohomology class and the universal covering is infinite cyclic. Then $\omega$ can be lifted to the universal cover $\hat M$, i.e., $\pi^\star \omega=d\hat f$, for some Morse function $\hat f$ on $\hat M$. The Morse 1-form $\omega$ generalizes the Morse function and the zeros of $\omega$ take the place of the critical points of a Morse function. Indices of the zeros (or critical points) of $\omega$ can be defined similarly and we have the stable and unstable manifolds of a critical point. The incidence number between a pair of critical points respectively of index $k$ and $k-1$ of $\omega$ can be defined for a Morse-Smale pair $(\omega, g)$, where $g$ is a Riemann metric on $M$. One can lift the stable and unstable manifolds to $\hat M$ and define the corresponding incidence number in $\hat M$ similarly. One can also define the Novikov complex. My question is: $\hat M$ is not compact and the unstable manifold (or the descending disc) of a critical point in $\hat M$ in general goes infinitely downwards. Also, for fixed $x$ in $\hat M$, it is possible that the incidence numbers between the critical points $x$ of index $k$ and $y$ of index $k-1$ in $\hat M$ are non-zero for infinitely many $y$. These are different from Morse theory on compact manifolds. Can someone give a (simple) example of an unstable manifold in $\hat M$ going infinitely downwards for some Morse 1-form? Maybe also an example of infinite number of non-zero incidence numbers? I am sorry that I pose the question rather imprecisely. 

Piggybacking on one of Pierre's answers, I once had to teach beginning linear algebra from a textbook wherein the authors at one point stated words to the effect that the the trivial vector space {0} has no basis, or that the notion of basis for the trivial vector space makes no sense. It is bad enough as a student to generate one's own false beliefs without having textbooks presenting falsehoods as facts. My personal belief is that the authors of this text actually know better, but they don't believe that their students can handle the truth, or perhaps that it is too much work or too time-consuming on the part of the instructor to explain such points. Whatever their motivation was, I cannot countenance such rationalizations. I told the students that the textbook was just plain wrong. 

I think the gap(s) outlined in the original post of this thread are inevitable since there is a limit to how many courses an undergraduate student can cram into his available time before graduating. Pertinent material for this discussion is the book "All the Mathematics You Missed But Need to Know for Graduate School" by Thomas Garrity. The goal of this book is ambitious, and so naturally it has its shortcomings. It has a number of errors, and one might dispute Garrity's particular selection of topics. But overall I like the book, and would recommend it to any undergraduate who is considering a professional career as a mathematician. The main body of the book is a series of short chapters, each a very brief introduction to a particular area of mathematics. This can be a useful read even for the mature mathematician who suspects that their mathematical experience may be a bit parochial. But one of the most useful parts of the book for me, which I read while working on my master's degree, and which I wish I had been exposed to as an undergraduate, is the introductory material that presents some of the broad patterns that are common across all branches of mathematics, and which form an outline for each of the following chapters. For example, he notes that every branch of mathematics is the study of some particular set of mathematical objects. This study includes questions such as how to tell when two objects of some class are essentially the same (isomorphic); when one is a sub-object of another; how new objects can be constructed from old ones; a notion of maps or morphisms between objects of a class that preserve the essential properties that the objects are supposed to capture; the notion of quotients; etc. As "muad" noted above, some teachers plan on students learning these principles more or less by induction, from having many concrete examples presented to them, and never mentioning them explicitly. While that may be an ideal way to learn the principles, there is no guarantee that a given student will learn them, regardless of the number of examples given. And I have met some mathematicians who, as far as I can tell, aren't aware of them. As an undergraduate, I came away with the sense that the various branches of mathematics were rather disjointed, with no real common patterns. Blame it on poor instruction, or more likely, my being dense. I think I would have benefitted a lot from someone pointing out these patterns to me in an explicit way. 

The (finite dimensional) Morse complex obtained from $f_\epsilon$ clearly is not a subcomplex of the Morse-Bott complex. If there is in question one no finite dimensional subcomplex of the Morse-Bott complex that computes the cohomology of $M$, then the Morse complex of $f_\epsilon$ may be viewed as a finite dimensional substitute. However, it maybe rather arbitrary, since it depends on the choice of $f_i$. Also, the dimensions of this complex maybe quite large, for instance, $f_i$ may have more critical points than the sum of the Betti numbers of $C_i$. That is, $f_i$ may not be a perfect Morse function. If the Morse complex of $f_\epsilon$ is a substitute, then how to choose a good one? Or are there other ways to construct a finite dimensional "Morse-Bott" complex that computes the cohomology of $M$? 

The above paper also gave a chain map from the Morse-Bott complex to a certain Morse complex pertaining to a Morse function $f_\epsilon$ obtained from a small perturbation of $f$. The chain map also induces isomorphism on cohomology (see p.147). The method is as follows: Let $C_i$ be all the critical submanifolds of $f$, $i=1, ...n$. Let $f_i$ be a Morse function on $C_i$. $f_i$ will have critical points on $C_i$. Let $\rho_i$ be some bump function that has support and value $1$ in some small neighbourhood of $C_i$. Define for $\epsilon$ small enough, $$f_\epsilon=f+\epsilon\sum\rho_i{{\pi_i}^{-1}}(f_i)$$ Then $f_\epsilon$ is a Morse function on $M$. (Here $\pi_i$ is projection of the normal bundle to $C_i$.) Here is my second question: 

I want to understand centralizers of semisimple elements in unitary groups. Let us begin with example of $GL_n(k)$. Centralizers of semisimple elememts are a product of smaller $GL_m(k)$ thus connected. Steinberg proved that for a connected, semisimple, simply connected algebraic group centralizers of semisimple elements are connected. However this need not be true in general. For example $-1$ in orthogonal group. I believe this is true that for unitary groups centralizers of semisimple elements are connected. I would also like to determine structure. Any help or reference will be helpful. 

Let $G$ be a Linear Algebraic Group (over algebraically closed field). We know that the connected component $G^o$ is a normal subgroup of finite index in $G$. Let $g$ be an element of $G$ which is not in $G^o$. I want to understand Jordan decomposition of $g$ as a product of semisimple and unipotent elements. Modification from earlier question: Can I choose representatives for $G/G^o$ consisting of semisimple elements alone? Of course the answer is 'no' in char p. But how bad is the scene. Thanks a lot. 

Is there a finite dimensional subcomplex of the Morse-Bott complex that also computes the cohomology of $M$? 

J. Bismut proved the asymptotic formula for the heat kernel of the Laplace-Beltrami operator $\Delta$ on a manifold $M$ in one of his well-known books. Later, in his paper on the index theorem, Bismut said that the result can be extended immediately to the heat equation semi-group for Hodge-Kodaira Laplacian or the Dirac Laplacian, since these (operators) are subordinated to the heat equation semi-group for $\Delta$. My question is: what is subordination or the subordination process in probability? If there is such subordination, how can one see that the result can be extended immediately? The proof of the asymptotic formula by Bismut in his book on Large Deviation is not easy to follow. Also Bismut mentioned that Malliavin has already used the subordination in his paper on vanishing theorem. 

In the paper Morse-Bott theory and equivariant cohomology, Austin and Braam built the Morse-Bott (geometric) complex which computes the de Rham cohomology of the manifold $M$ (this paper can be found in the Floer Memorial Volume). This is a generalization of the Morse complex in the case of a Morse-Bott function $f$ on $M$. However, unlike the Morse complex, the Morse-Bott complex is an infinite dimensional complex. The chains of the Morse-Bott complex are differential forms on the critical submanifolds of $f$ and the boundary map is defined in terms of the flow lines of the gradient vector fields. Only when $f$ is Morse is the complex finite dimensional. I have three related questions: 

I will second Thierry's reply. Of course, when I see the term "CV" I think of academic positions, whereas if one is seeking a job in industry one would instead produce a "resume". Different beasts, though in both cases the purpose is to some extent the same, namely to give an employer some idea why they should be interested in you to fill their opening. As Thierry said, a hiring manager in a corporation or industrial firm will have a very different set of things he is looking for in a resume compared to what a hiring committee in a math department at some college or university expects in a CV. 

Don't you need some strict inequality somewhere in your definitions? For example, a constant function meets your definitions of antimonotonic, submodular, and supermodular, but does not induce a metric (assuming your lattice has more than one element) since $d^s$ and $d_s$ would then always evaluate to zero. 

Alan, I have been in a situation very similar to yours. After getting my Bachelor's in math (also from a small, essentially no-name school), I spent 23 years in the software industry (Silicon Valley). Boredom and frustration with my work, and an ongoing interest in math since my undergraduate days all motivated me to consider returning graduate school. Being laid off during the recession in 2002 gave me the final nudge. I immediately entered a master's degree program in math at Cal State Hayward, full time. At first, I was thinking that the master's would be my terminal degree. It was only after I gained a mentor while in the program that I learned that it was feasible to go on to a PhD program, even at my age. In particular, the vast majority of PhD grad students in math have a teaching assistantship, which pays for tuition and supplies a (very modest) stipend. One bit of advice to me was to not go to any school which did not offer a TA-ship. Working on my master's provided me recent reference letters. (Some of my best undergraduate references were deceased.) I cannot say that working on a master's before the PhD program is required, or even recommended. Be aware that many schools have programs where a student enters under a master's degree program, and then before completing the master's the student can decide, together with faculty consultation, whether to continue on to a PhD program. (My PhD school, the University of Washington, offers such a program.) In fact a few schools require all their students to complete a master's before formally being accepted into their PhD program. These programs, where master's and PhD are both done at the same school, will save some time overall since all units are guaranteed to be transferable. (None of my master's degree work at CSUH transfered to UW, but it did equip me to pass one of the preliminary exams at UW.) I finished my PhD in 2009. I was hoping to enter academia, and I did a 2-year postdoc at UBC. But as everyone has noted, the academic market is dismal at this time, and I took a position in government. So it is good that you are aware of the job market conditions and planning accordingly. As David White noted, there are several industries that hire mathematicians. He also noted that the NSA and affiliated contractors hire a great number of mathematicians, doing interesting work. I would also note that there are other government labs and agencies that also hire some number of mathematicians. In any of these, I would suggest that while it's OK to seek "math-oriented" work, you should at the same time remain open to leveraging your industry experience, especially any software skills you may have acquired. All in all, I have no regrets for pursuing a PhD. Indeed, I would have had regrets had I not. Best to you in your pursuits. 

Let R be a "nice" ring with 1 (e.g. Euclidean domain). Then the subgroup E(n,R) generated by the elements $I+te_{i,j}$ is equal to $SL(n,R)$. My question is as follows: Instead of $SL(n,R)$ I look at left and right multiplication by elements of E(n,R) on elements of $M(n,R)$, set of all matrices, (i.e. it need not be even invertible). So equivalently, I want the coset representatives of double coset-decomposition. That is, I would like to determine : $E(n,R)\backslash M(n,R)/ E(n,R)$. In the case of $R$ a field, the coset representatives are diagonal matrices with either 1 or 0 on the diagonals. I believe that one can show the coset representatives are diagonals. It will be useful to have finer result that what appears on the diagonal, e.g., how many 1s and how many 0s etc. 

Jacobson-Morozov theorem for a semisimple algebraic group $G$ (presumably I am working over algebraically closed field) states that: given a unipotent u, there exists a homomorphism $\phi$ from $SL_2$ to $G$ such that the matrix $\begin{pmatrix} 1&1\\0&1\end{pmatrix}$ maps to $u$. What I want to understand is that when this map is injective and when it has kernel $\pm 1$? Do we know a criteria on $u$ which determines this? 

It seems that Joseph's approach would require computing the set of vertices from the standard form. I don't recall what the complexity of this is in the worst case, but I dimly remember it being pretty bad in the extreme case. In any case, I wonder whether that is in the spirit of the original question. Sad to say, I don't have an idea to propose. 

Yet another way in which people could use arXiv is as a repository for material which otherwise cannot find a home in a journal. Sometimes in the course of working on a project I wind up with some material which did not make it into the published article -- or perhaps some notes which record my growing understanding of articles already published by others -- which look like they could be useful to the community as expository or supplemental information, but which in my opinion are not otherwise significant enough to warrant submitting to a journal. I have sometimes wondered whether it would be appropriate to post such material on the arXiv. (I have not done so yet.) For that matter, I wonder whether others have done this very thing. One drawback of this use of the arXiv is that everyone knows that most arXiv articles have not been peer-reviewed at the time of first posting, so they must be taken with a grain of salt. If an article is never published in a journal, you must read the arXiv article with a more critical eye. But as I said, I do believe that there exist some notes that are perhaps worth sharing but not worth wasting the effort to peer review.