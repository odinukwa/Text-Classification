This way there is always an odd number of votes which is ideal. Even if this is used, there are still scenarios in WS2012R2 that could cause the cluster to shut down due to quorum - many of these have been addressed with WS2016. 

Then either change your edition or go without. You can write your own tracking using triggers, but it's going to make your application run extremely slow. You really need to look into items that do this, Golden Gate, CDC, CT, etc., and go from there. If you can't spend any money then you need to make a business justification case for it and if still nothing, you can write it using triggers. Note that using triggers is still spending money on development... so either way money is being used. 

To start off, NULL does not mean "no value" it means "Unknown value" in SQL Server. There is a session setting called ANSI_NULLS that could make your queries behave as you would like them to, however, it's deprecated and will be forced to ON (which you don't seem to like) in a future version: $URL$ I get what you're trying to do, and to make a counter point I would ask if you've seen any queries generated by reporting services or something like Cognos? If so, you'll see exactly what you're describing you don't want to do. Why? Well because with a schema that allows nulls, that's the way to do it. I'm not saying it's a super awesome and great idea but it works all of the time. What your designer could do is check to see if that column could even be null and if so the appropriate logic could step it and create the correct query. You could also have options such as "This column may be null, do you want those values?". I don't know the end-game per-se and writing your own dynamic querying tool is quite the deat when the logical consistencies are all factored in (such as this). I would continue to do explicit null checking on columns that could possibly be null, sure it doesn't look the best but it works all of the time. ANSI_NULL set option will work for now but NOT a good idea especially if you don't control the environment, plus it will be forced set ON later and cause errors where you'll need to re-write your application logic anyway. This is the way SQL Server works with NULLs. 

It looks as though you have a problem with your storage subsystem (somewhere from the drivers down to the actual disks, but it could be anywhere in that stack). The good news: 

That's an error you would get if the database wasn't readable (offline, etc) or if the connection string wasn't properly set (aka ApplicationIntent). That's not the error you would get attempting to write to a readonly database which would be 3906: 

I'm not sure why it would "lock up every single database" as we only see error messages and issues for a single database and I'd expect a long running shrinkfile holding an EX latch on the database file being shrunk to eventually cause issues given enough time. Unfortunately there isn't enough data to give a valid assumption as to what happened but at least this will give you some things to investigate/look into. 

That's definitely not going to work as the LSNs will definitely not sync up, nor would any of the information being applied to it in a transaction log (if SOMEHOW you could force it to restore [which you wouldn't be able to]) even be in the database to apply it to. It seems as though you're missing the fundamentals of how transaction log restores work, so I've included some links. Understanding How Restore and Recovery of Backups Work In SQL Server Restore and Recovery Overview Working With Transaction Log Backups Applying Transaction Log Backups 

Any log lower than the LSN currently requesting to be flushed will be flushed as well. Log records are put into the log buffer in order and all transactions are serialized to the log buffer for that database. Note that individual log records aren't flushed, they are put into log blocks and log blocks are flushed. 

Quorum will have most likely been lost - you'll need to force quorum on the server in the DC that is still up. This can be completed a variety of ways. Powershell: , services: , etc. Connect to SQL Server now that the cluster was forced quorum. Failover the Availability Group. This will bring the listener with it. Whether Synchronous or Asynchronous is set, this can be accomplished by executing Test connectivity. 

If you can't install SQL Server on your PC the only choice you have (if the database is already 2012) is to script out the databases objects, change anything that isn't compatible with 2005, and then run the scripts for your 2005 instance. Because there are many changes between 2005 and 2012, datatypes among other database objects may not align properly. This means the application(s) being used with the database if put into 2005 from 2012 may not function correctly or at all. Your best option is to get a waiver to install 2012 developer edition or some other test system for your 2012 needs. 

That's dynamic quorum kicking in with a 2 node cluster and no witness. I definitely wouldn't continue to run this way, either add another node or add a witness. 

The private key is what keeps everything safe, so no private key then no decryption. I can't think of any times when this would be useful. 

It is written to both, but it is written differently to each. The changes are made to the data pages in memory and are eventually flushed to disk via the checkpoint process. the changes are sent to a log buffer and hardened to disk at some point, though before the data file is written to disk to keep with the write ahead logging protocol. 

the overall issue with your endeavor, while I commend it, is that getting the log isn't the hard part. Reading the log is, as it isn't documented at all. There are 3rd party products that can help you, but you reading the log and asking these questions isn't going to work out very well. This wasn't written to put you off, merely to express that the log isn't very human readable, documented, or otherwise made for people to go slogging through it. With that, the below should help you: 

In this case, no they generally wouldn't be able to get to the decrypted data. There are, however, edge cases that won't stop someone with administrative access and a decent working knowledge of encryption from possibly getting the data. It's all about "reasonable protection" wherein you've given a reasonable enough protection to the data. If you wanted it to be extremely secure then you'd need to use an HSM, which another team owns and audits on an extremely frequent basis. No one would have administrative access to the server, and no one would have sysadmin access to SQL Server. That's probably not going to fly - so "reasonable" protection should be sufficed. 

The mitigation is not with the mode that the replicas run it, it's removing that replica from the AG. 

Between replicas, you mean? Again, you'll need to use PowerShell. There is an upcoming blog post [(placeholder)] blog post I wrote detailing this. When it is officially published, I'll update the answer with a link. In the interim, here is the basics of what you'll need to do this. You may want to re-think using clusters like this (workgroup) as this is just the tip of the administrative iceberg you'll be dealing with. 

The first two are fairly obvious as to why this would be an issue. The 3rd is not. Since secondary replicas automagically remap read-committed isolation level to the snapshot isolation level a few things need to kick in. One of those things is row versioning, since after all SI is an optimistic concurrency. Row versioning depends on the version store rows to be available on the secondary. If the low water for ghost cleanup is changed, then the secondary may need to cleanup records that are currently used for queries being satisfied by the version store which have a timestamp lower than the new ghost cleanup low watermark. When this is the case, those versions will be cleaned up and any SI datasets that required them will no longer be valid. That's when this error will surface for the session for that dataset.