I have a Windows 2008R2 print server hosting about 40 printers. For the longest time we had a Point and Print GPO that allowed the users to install the drivers for these printers without administrative interaction. Administrative Templates\Printers\Point and Print Restrictions: Disabled. This is still in place. Recently though that is no longer working. Take the "sales" printer for example. People have been connected to it for years now and in the last few days, when someone tries to print, their computers (All Windows 7) have been asking to install a print driver. Even new users that have not been attached to that printer before are being asked for admin rights to install the printer. This has affected about half of the printers on this printer server. So some printers users are able to install just fine. So when someone has the issue I hop on their machine and provide my rights so the print driver will install. I am sure I know of the catalyst that caused this but I have no idea how it directly relates. For inventory purposes, I updated the host names of the printers. To clarify I went on the web interface off all the printers and in each of their network IPv4 configurations I updated the host name from its generic Ricoh to be the same as the DNS record I made for the printer. So each printer has a share name, port name on the printer server which are both the same as the physical printers host name e.g. "sales". No changes have been made to the print server hosting these printers. I don't understand how that change would cause this. In the case of the "sales" users it is preventing them from printing. We have to allow the driver to update before they can print. That is how we knew there was an issue and was able to tie it to my inventory update. These users are not all in the same OU in AD and both have the same policies applied anyway. I am testing different GPOs as when you look up network printer driver GPOs there are more things people change than just the one I mentioned above. Any ideas why what I did is causing this issue? Perhaps I am chasing the wrong tail and something else is wrong? 

Worst case is I am hoping to get the of the Client List table so I can work with its contents. I can't seem to get any useful data no matter what page. I am not sure if the issue is working with Meraki or my PowerShell approach. I have only done simple scraping up until this point. I realize this is a very specific request but I am curious to know if someone that has Meraki is able or has been able to get this information using these means. 

A reboot will keep it's settings. If you bring up a new instance then you'll need some way to manage the IP's. A startup script is probably the way to go. Pull the instance metadata and update a config file (perhaps in S3) or DNS entry. You can also use an elastic IP and configure a cname which will resolve to the internal address within the EC2 environment. To do this, assign an elastic IP and note the public DNS string (there's a pattern but it's good to check) and create the cname record with it. The advantage with elastic IP cnames is you don't have to wait for DNS propagation. 

We've been moving servers to EC2 lately and I ran into an issue recently involving locales. We use a script to build an AMI from scratch that is largely based on a simplified RightScale script. However, we recently worked on an international project and I discovered that the locale was not set during the scripted install (issuing locale at the command line results in posix). It appear there is no i18n file by default. However, checking a development server that I installed locally (via GUI) the i18n file exists. What package(s) do I need to install and which program can I run (command line) to configure this during the scripted install? We're running the current version of CentOS. (5.4) 

Create or edit the vhosts.conf in your apache conf.d (or equivalent depending on OS). Use the NameVirtualHost directive to handle the DNS names. 

You can also add ports to the ProxyPass directive if you don't want your friend to change firewall rules, service setting etc. Or you can even be a reverse proxy for another external IP address too. 

Are there any ntpd messages in /var/log/messages? As I was dealing with my EC2 NTP issues I noticed that NTP didn't like being too far out of sync and wanted a manual update. Perhaps you're too far out for it to decide it will update for you. 

I've recently been moving our instances to EBS instances (CentOS) and still have a bit of confusion on what's happening when I "stop" and instance. I have some of my services with runlevels 345 on but when I start a stopped instance the services don't start. What's actually happening when I issue a stop command to the instance, and how do I get my services to start automatically when I start the instance up again? 

We've had a server (CentOS) running in EC2 for a few months. It had been going pretty smoothly until today when we got an alarm that the server was unavailable (HTTP service couldn't be reached). So I tried SSHing into the box but that timed out as well. I logged into the EC2 console and it said the instance was running and there wasn't anything in the system log. One odd thing I noticed is that even though we have an Elastic IP attached to it (which shows in the Elastic IP management area), the instance detail is not showing that there is an EIP associated with the instance. I looked through the message log and the last thing I see around the time we got our alert was the dhclient renewed the lease. I'm guessing there may have been some sort of issue with the networking. How might I check if that was the problem, or if there were any other issues that may have caused our instance to stop responding? 

Can a Windows OS that is automatically managing paging file size for all drives effectively use a drive that is dedicated for that purpose? 

So everything appears to be in check there as well. However in testing deleting both users and containers I am unable to find them in order to recover those objects. The only thing that ever shows up is the deleted container itself 

The windowsupdate.log corroborates this. I would like to try and include only what is required to try and keep the post length down. The client reaches out to the server and see that it has X available updates. However it fails to download those. The log shows entries like this: 

When I run that command I get some of the user accounts and groups that I was removing while testing. According to this page on TechNet forums though that means the the bin is enabled. 

I have a Windows Server 2008 R2 SP1 machine that is isolated in a DMZ. Historically it has not had issues but everything works before it breaks. The port 8530 is open on the firewall appliance and I can telnet from the client to the server which proves the site is ready and open. This machine is not attached to the domain so WSUS server is set in the registry. So under HKEY_LOCAL_MACHINE\SOFTWARE\Policies\Microsoft\Windows\WindowsUpdate I have 

There are two sections of the script that make updates to Active Directory. First updates their employeeID 

I am trying to automate a weekly process where I download a CSV copy from the Client page on the Meraki website. Before I lose you I am aware there is an API and it works very well. However there in a device attribute that is not exposed in the API. I got this from their support: 

I need the Owner as that is how I associate devices to people in our organization. Using PowerShell I am able to successfully log into the website and get a 200 response for a basic page. My problem comes when I try to use the same session to get to the data I want I keep getting a page with just breadcrumbs and no actual data. 

These are Windows Server 2008r2 machines in an AD environment. Some time in the past a DHCP server failed. An admin replaced it using a different host but the same address. Later on, when troubleshooting a rogue DHCP server, it was discovered that both the old and current servers were list as authorized DHCP servers. Once discovered it was de-authorized. That de-authorized our current productions DHCP server for a short period until that was reversed. Those two, with the same ip address, were listed for almost 6 months. Would that have been causing any issues or merely just an harmless entry in the authorized list? 

I'm wanting SNI on my CentOS 5.5 dev server and since it looks like I'm out of luck with the current repo versions of openssl and apache, before I go compiling custom RPMs I thought I'd see if I could get it working with gnutls. Anyone know how to do this? According to yum, gnutls is already installed but I don't see it in my apache modules directory. 

For what you're doing, you're probably fine running on regular hardware. But it's always worth learning about things. As mentioned, server hardware is really designed for reliability. You get things like ECC RAM, dual or quad CPU sockets, redundant power supplies and fans, RAID for your hard drives among other things. You can also generally build "bigger" boxes than you can with "standard" hardware which is beneficial for maintenance (fewer boxes) and solutions like Virtualization (pretends to be more boxes). Google doesn't do that sort of thing and takes the approach I think you'd be comfortable with, use cheaper hardware and replace it when it fails. Google's redundancy and scaling is horizontally (more boxes). The advantage here is it's cheaper to buy at the cost of complexity of overall architecture. Applications need to be designed differently and how the overall system functions can get more complicated. You need to add load balancers and such which may or may not be possible. Assuming downtime isn't a huge concern of yours, I'd say stick with the low cost hardware, backup things properly and replace stuff if/when you need to. 

I'm trying to write an install script for my Amazon servers and I'm getting stuck on some environment variable issues. I have a set of scripts to configure things and some of them depend on environment variables that I create in profile.d scripts. I create the profile.d script (or copy it over) and need to use the variables it sets in scripts that run later (without logging out and back in). Is there a way to load these (in a script) so future scripts take advantage of them? In the script after I create the file I tried: source /etc/profile.d/scriptname.sh and . /etc/profile.d/scriptname.sh but it only sets the environment variable for the duration of the currently running script, so any other script that gets run later can't use the values being set. How do I get them to get set for the session instead of the script? I have one master script that calls a series of small scripts to do all the configurations. 

Checkout the documentation for ProxyPass and ProxyPassReverse. If you just do a name based virtual host for both then you could add something like this to your virtual host definition (or replace localhost for your IP if your box will be hosting apache):