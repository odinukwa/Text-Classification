Physics never has implications for mathematics, only the other way around. Mathematics is not an experimental science, but an 'exact' one, and is only expanded, never altered, by the discoveries in other sciences. Surely there are productive extensions of Euclidean geometry that capture the newly discovered notions of space and of matter. (Back in the 80's I have seen folks define slight variations of topology that give open sets a quantum-logic penumbra, so that the resulting points are 'sort of fat' in a way that simplifies quantum and relativistic geometry, to the degree that quantum logic ever simplified anything.) But the old system captures something so natural to human beings that it will never cease to be our common reference point for what geometry means. From an intuitionist point of view, Euclidean geometry is part of our genetic inheritance, deeply embedded in our psychology, there to be discovered. This is why it was the perfect example of anamnesis for Plato. Folks who take a more functional or a more ideal approach to mathematics are also going to agree that this has the most immediate survival value, or that this occurs naturally so often that it must be part of underlying reality. None of them is going to expect it to change due to discoveries in physics. 

Some categories, like the notion of quantity that underlies space and time, have to be inborn, or the remainder could not possibly gain traction. We do not learn that time passes, we have already experienced it doing so before we leave the womb. An unborn child shifts in its sleep in response to its mother's posture, so it is already dealing with space and time and thus the category of quantity. A baby cries when you scare the breath into it, (to the extent that people still do that) so it has a notion of (pain, and therefore pleasure and therefore) beauty and the underlying category of quality. Something has to exist as a seed for meaning to accumulate around, and Kant has attempted to isolate the most minimal kernel for that seed. So the categories, and quite a bit of instinctive correlation around them clearly enter the mind before birth. Later: I do not mean to beg the question here, or to misleadingly affirm the consequent. Clearly that we are born with these things can be established without establishing that that phenomenon proceeds from our premise in any way. And I am only saying that a few of the categories Kant believes in need to exist for the very young. A category is that which can be asserted of any thing, regardless of what it is, regardless of what you are. From that definition, for me, the question hinges on the necessity of asserting things, when you are a foetus, or a baby. I am saying that things like 'I have fallen on my arm, and I would be more comfortable if it moved.' are in fact asserted by foetuses, if only unconsciously, as they do move their arms. And given that very minimalistic example, I am challenging whether anyone can imagine beginning to acquire knowledge from a position where nothing would ever need to be asserted in this sense. 

All three of these would be considered genuine definitions by almost any mathematician. So anything you say about all definitions must apply to all of them, or you need to go scold the entire field of math for not knowing what a definition is. Logical positivists like to imagine that all definitions really take the first form, at root, in some indirect way, and that all of language goes back to symbolic logic. But they are wrong: their enterprise fell apart under the weight of formal proof and observational data long ago. Even to the degree mathematics can be reduced to symbolic logic, the axioms of set theory are not strictly unique and therefore purely logical. Even if that were somehow true, it is not what the practitioners mean when they use the word 'definition'. They do not unwind every case into set theory. Instead, they prove the internal consistency and non-circularity of their definition as a statement, the same way they would prove any other theorem. In most higher mathematics, the very first thing you have to do after giving a definition is prove it is a definition. When these approaches are used in an experimental science, those proofs of applicability need not be formal mathematics, but are usually made on the basis of observations, instead. I know when I am defining a new species of bird, not because I have formally plumbed the separation criteria between animals and the equivalence classes created by enumerating traits, but because I can look at my clade diagram and see where the overlaps with other species are ruled out. But all of that on the chart is data, not math, and any part might easily have been misinterpreted. Then when the observation offered instead of formal proof is challenged by new data the definition is tested by experimental evidence. 

From a few different directions, there have been attempts to decouple value from behavior in recent religious or political philosophies. Such moves are often motivated by feminism or other kinds of inclusiveness, as they restore the value of being itself, or the inherent value in being valued. So they are often initially motivated by the inequality of the valuations of being vs doing. 

It is moderately ambiguous what 'not A' means. In the simplest formal systems (like the truth tables in @virmaior's answer) negation is just a convention of reversing truth values. But formalism is meant to reflect meaning, not dictate it. Informally, negation is about avoiding asserting two contradictory things at the same time in the same way. So it is common to define 'not A' to mean 'asserting A produces a contradiction with other things we know'. (Aside for the picky: This is even the formal definition in many systems that take various paradoxes and the 'groundedness' of deductions seriously, like intuitionism and paraconsistency, where we attempt to expand discovery out from what we know, instead of assuming the world itself is automatically consistent, like in the informal logic of mathematics. And it is equivalent in Classical logic to the simple flipping of truth values, because all true things are equivalent and we know some of them.) Then when A implies B and B produces a contradiction with other things we know, asserting A makes B true, which produces a contradiction with other things we know... So not B implies not A. And this rule of contraposition is true across a broad range of logics with a more formal, but more fragile semantics, including the Classical logic most of us use, though as @Bumble notes, not all sorts of logic. 

If the possible world in a philosophical sense can be constituted out of particles of matter and exchanges of energy, it is almost assuredly one of the multiple worlds of Quantum Mechanics. When you do the prediction integration over all possible Quantum worlds it is (theoretically) over every possible configuration of particles the universe could be in. Since the possibility curve for every particle extends through all of space, and the movement of particles could conceivably reshape space in pretty much any geometry humans have described, most alternative versions of the material world qualify. Given string theory and M-theory so do worlds with different physical constants, arbitrary numbers of dimensions and different characteristic particles. They may be incredibly unlikely, but none are ruled out. The computations are going to write them off, but they are in the range officially considered. Of course, in reality, such a computation is always staged over a very small area and a very short time limit with very few outside influences (like Feynman's examples), or is estimated over a huge area and time where a lot of other factors are assumed to cancel one another out (like Hawking's explanation of the lifespan of black holes), because anything else is pretty much beyond human scope. And very few people consider realms where the physical constants would be different, unless they are concerned about an entire abstract universe with almost no detail (like the stuff Green discusses at the end of 'The Elegant Universe'). But theoretically, there is a huge overlap. 

There is basically an answer included by reference in the comments. But I will lay it out for concreteness sake. I would agree with @Conifold and @Artem... that the most likely reference is to someone like Feyerabend, though indirectly (via Kuhn's abstraction of 'paradigm') the position is Neitsche's notion of 'creation'. So the same idea is widespread, if less clearly discerned elsewhere. The basic point is that everyone wants to place limits on what can be considered legitimate argument, but that the arguments made for doing so generally aren't legitimate in their own terms, and surely do not meet one-another's standards. They derive their power to ignore one another's standards sociologically, at some point, from the combined strength of personality of the actors drawn to them. It is not 'post-modernism' outright, but a strong lean in that direction -- either one needs to judge modernism by its own standards or question all limitations that don't meet standards that are equally strong. In Feyerabend's case, he is attacking the way in which theories of scientific evolution become prescriptive methods that allow us to write off earlier scientists as illegitimate even when they were correct, and Bowdlerizes the real thinking of those we canonize, by shoehorning them into a larger framework for our own intellectual comfort. We then accept their answer, and pretend we would have gotten there by our accepted means. But that weakens our collection of methods, forevermore (or at least until we lose the argument on methodology). Neitsche is on the same path turning away from choosing bases for morality, as arbitrary, in favor of addressing the genealogy of moral sentiments in a way that recognizes how moral bases get refolded over time or reframed totally by powerful personalities, and thereby declares them all wrong (and destined to remain wrong). That brings him back to simply considering morality personal. Basically, faith in the correctness of human enterprise is human and not rational. To pretend that we fully understand what it is to be human, or even rational, for all time is nonsense. So we need to leave a lot of leeway for taste and arbitration in our judgments of social or intellectual works.