The workers' income and how it changes as rates increase, the behavior of the workers as rates increase, (this is similar to but different than the first neglect), and the basis of the Laffer curve shape. 

So, I decided to first graph the behavior of the workers as the rate increases, which would then affect the amount of revenue the government took in (which, when graphed, is the Laffer curve), and then, just for fun, I included the disposable income. The x axis is the tax rate and the y axis is money amount-- in the United States, dollars. All y values are arbitrary. You could see the graph here: $URL$ Because the behavior of the workers is arbitrary, any depiction of their behavior would be sufficient for my purposes. Therefore, if you click on the link, you can see two different situations graphed, each situation for a different type of behavior. (For simplicity, I disabled the graphs for the second situation). Situation one: The orange curve is the total income of the economy before taxation, the purple curve is the tax revenue and the black curve is the disposable income. Situation two (not enabled): The green curve is the total income of the economy before taxation, the blue curve is the tax revenue and the red curve is the disposable income. The total income curves are shaped like they are because as the tax rate increases, society works less, (or is less motivated to make the same amount of money), and as a whole, has less total income. The tax revenue curves: Because, number one, as tax rates increase, workers are motivated to make less money, and, number two, the rate at which they make less money is increasing, the value of tax revenue does not increase at a constant rate. In fact, after a certain rate (changing depending on the behavior of the workers) tax revenues start to decrease. 80% of 60 dollars is more than 90% of 43 dollars. The tax revenue curves are, in essence, the Laffer curve. And lastly, the disposable income curves are simply, 

In short, not really. Prof. John Cochrane offers an astute example of Granger causality by stating that a weatherman Granger-causes the weather. We know that a weatherman has no measurable role in causing the weather, but there is indeed an intertemporal correlation between what the weatherman says today and what happens tomorrow. 

The first equation can be written as: $$ r_E(Levered) = \frac{E+D}{E}r_E(Unlevered) - \frac{D}{E}r_D $$ Then, isolating the unlevered return gives: $$ r_E(Unlevered) = \frac{E}{E+D}r_E(Levered) + \frac{D}{E+D}r_D$$ And this is the WACC. 

The division comes from the entities guiding these sets of policies. The austerity program falls under fiscal policy, which is controlled by Parliament. Quantitative easing falls under monetary policy, which is controlled by the Bank of England. The policies enacted by these two entities are not necessarily coordinated, and can sometimes work opposite each other's objective. 

One example of monetary policy is the Bank of Japan buying the Nikkei as part of its asset purchasing program. Typically, a substantial share of citizens' wealth is connected to returns of their national stock market. Hence, it is generally not a wise move for a fiscal authority to invest public funds (not tied to pension schemes) in broad baskets of stocks. You might try looking into sovereign wealth funds, these are typically gargantuan profit-maximizing investment vehicles wealthy nations use to acquire risky securities. 

The answer from Dan is a good one, but I would like to add on the following criticism, which is apposite at least in the context of international trade. Dynamic concerns notwithstanding (again see Dan for commentary on those), free trade between countries is welfare increasing for the countries trading (it must be so because under free trade voluntary autarky is always an option). However, the efficiency gains within each countries are not equally spread and so there may be winners and losers, despite an overall economic improvement. In the US, the losers are typically those employed in manufacturing, and it is documented that as a result of trade this sector suffers significant job losses: $URL$ ``Our central estimates suggest job losses from rising Chinese import competition over 1999–2011 in the range of 2.0–2.4 million." See also, $URL$ In short, international trade is beneficial, but not to everyone. 

Say you have two distributions, $G$ and $H$ with equal means supported on (say) $[0,1]$ and $H$ is second-order stochastically dominated by $G$. Then, for any concave increasing $u$, we'll have $$\int udG \geq \int udH$$ This would correspond to Aigner and Cain, where the risk averse firm would prefer to hire an agent from distribution G. However, now suppose that $G$ and $H$ are distributions of talent (with the same stochastic ordering i.e. $H \succ_{C} G$). One equivalent notion to this idea is that distribution $G$ can be obtained by ``fusing" together part of the mass of $H$, i.e. by collapsing part of the mass to its respective barycenter. Given this, it is easy to see that there is always a cutoff $\eta \in [0,1]$ such that $H(\eta) \geq G(\eta)$. This corresponds to Heckman's result--if the job is sufficiently demanding, then it will be (at least weakly better) to be part of the high variance population. Moreover, note that this by no means depends on the expected quality of the agent. There are simply more of the highest quality people in the group with distribution $H$ than in the group with distribution $G$. They are not just more likely to exceed the cutoff, there are more of them that exceed the cutoff. Another way to think about the hiring problem is as follows: say a firm wants to hire one person but receives applications from $10$ applicants, $5$ from group $A$ and $5$ from group $B$. A candidate's quality is unknown and it it ranges from $[0,1]$ continuously. Suppose also for the sake of simplicity that the firm may observe the candidate's group (and so knows what distribution he/she is drawn from): the distribution of quality for group $A$ is given by $G$ and the distribution of quality for group $B$ is given by $H$. Interviewing a candidate fully reveals a candidate's type, but the firm has the budget to interview only $4$ candidates. Whom should they interview? The answer is simple: all four candidates interviewed should be from group $B$ (which has distribution $H$). Why? Because we can think about a candidate's quality as a random variable $X_{i}$ and thus the firm wants to maximize $\mathbb{E}[Z]$ where $$Z:=\max\big\{X_{1},X_{2},X_{3},X_{4}\big\}$$ Since $H \succ_{C} G$, $$\mathbb{E}_{H^{4}}[Z] \geq \mathbb{E}_{G^{4}}[Z]$$ Note also that $H \succ_{C} G$ $\Rightarrow$ $Var(H) \geq Var(G)$ but not $\Leftarrow$. In this sort of thing, I think it is stochastic dominance and not variance that is the apposite metric. 

Check out the following: Jordi Gali; Monetary Policy, Inflation, and the Business Cycle: An Introduction to the New Keynesian Framework David Romer; Advanced Macroeconomics Michael Woodford; Interest and Prices: Foundations of a Theory of Monetary Policy The first two will ground you in the theory of nominal rigidities and the business cycle. Woodford's book is a good advanced text on the theory of monetary policy. I would not start with Woodford to understand the basic New Keynesian model. Practice problems with the first two books first, then move on to Woodford. 

Your question touches on seigniorage, which is the revenues a government receives from printing money. The issue is that, while the government may benefit (in the short run) from the additional revenues, the holders of money are penalized because their money becomes less valuable. While a low level of seigniorage is typically acceptable, if it becomes clear a government is going to finance the majority of its expenditures this way, then the government risks hyperinflation and a loss of confidence in the currency. Further, selling bonds can be beneficial for a few reasons. One, when a country participates in international capital markets, the act of paying off debt creates positive relationships with lenders and can lower borrowing costs. Two, it allows a government to smooth its expenditures over time. When the economy returns to healthy growth and is able to generate a surplus, the government will again be able to pay off debt it accumulated during leaner times. 

depicted the workers' income and how it changes as rates increase, depicted the behavior of the workers as rates increase, and I have proven that a bell like shape used to depict the relationship between tax rates and tax revenues is called for. 

And most importantly, doesn't it make more sense to say that the rate at which people are discouraged is not constant? 

Are my graphs accurate? And, if they are, are there preexisting graphs that describe the relationship between workers' income, workers' behavior and tax revenue? or is the Laffer graph the only one of the sort? 

Now, if one would argue that the Laffer curve should not be bell shaped, and rather should have constant slopes, we could deploy my graphs to show the absurdity of that assumption. The only society that can support a Laffer curve with constant slopes would be in a society where those taxed don't lose motivation to make money. This was, I believe, shown to be an impossibility during Communism in the USSR. Because it is a given that society becomes less and less motivated to make money the more they are taxed, using may graphs we can show that the Laffer curve must have changing slopes. I graphed a society with indifference to the tax rates using my equations. It can be found this link: $URL$ I was playing around with my graphs, creating different situations each depicting different worker behaviors and I noticed I was unable to choose a behavioral situation, (the orange curve in first situation above and green one in the second), where the tax revenue curve (the purple curve in first situation above and blue one in the second) would be a perfect bell shape like Laffer depicted in his curves. So, I decided I would work backwards. I would first draw the tax revenue curve and derive the formula for the associated behavioral curve. This requires simple algebra. 

Suppose we're talking about some bundle of consumables, $x$. If preferences are monotone, either weakly or strongly, the general idea is that more is better. With local non-satiation the idea is that, no matter what $x$ you have, there is always some small change in $x$ that would make you better off. Is your question, does there exist rational preferences where: 

It is generally not possible to make a sharp statement about the types of non-convex costs that Dynare can handle. Many different factors come into play about whether a model can be "solved" by Dynare or not. Is the steady-state correctly defined? Is the model stationary? Is the model differentiable everywhere in the ergodic set? Are the number of endogenous and exogenous variables equal to the number of equations? Is the model Blanchard-Kahn stable? But, to answer your question, can Dynare solve a model with a state-contingent fixed cost? Yes. This is not difficult, you should try to create one yourself. Try modifying a simple RBC model with capital and bonds. The trouble is not inducing the cost, but rather finding the steady state, which can be quite onerous if not done cleverly. Dynare, however, cannot solve Iacoviello and Pavan 2013 because of the min function found in a borrowing constraint. This min function induces a point in the ergodic set which is not differentiable. Dynare numerically approximates optimal policy functions about a steady state using perturbation methods. This requires employing the implicit function theorem to build out Taylor expansions of the optimal policies, hence you must be able to take derivatives everywhere within the ergodic set. 

I think your one mistake was writing $\Pr(v_{2} < \beta(v_{1})$ incorrectly. It should be: $$\begin{split} \pi_1(v_1,v_2)&=\Pr(v_2<\beta(v_1))(v_1-\beta(v_1))\\ &=F_{2}(v_2<\beta(v_1))(v_1-\beta(v_1))\\ &= \beta(v_1)(v_1-\beta(v_1))\\ \end{split}$$ $$\begin{split} \left.\frac{\partial \pi_1(w,v_{2})}{\partial w}\right|_{w=v_1} =v_1\beta'(v_1) - 2\beta(v_1)\beta'(v_1)&=0\\ \beta(v_1) &= \frac{v_{1}}{2}\end{split}$$ Loosely we can look at, say, type $1$ of player $1$. If he bids according to this strategy his expected payoff is $1/4$. Suppose he picks any other bid amount $a$. Then his expected payoff is $(1-a)F(a) = (1-a)a$. This is clearly maximized at $a = 1/2$. 

This is just @Sadem's argument formalized. Note that we do not need to use any utility function representations, we can use just the preference over lotteries in conjunction with the axiom of independence. The axiom of independence, formally stated is: $L'' \succeq L'$ $\Leftrightarrow$ $$\alpha L'' + (1-\alpha) L \succeq \alpha L' + (1-\alpha) L$$ $\forall L, L', L'' \in \mathcal{L}$ and $\forall \alpha \in (0,1)$. Define $L'' := L_{1}$, $L' := \big((0,1/11), (5,10/11)\big)$, $L := L_{1}$, and $\alpha = .11$. Thus, the first statement implies $$\alpha L'' + (1-\alpha) L \succ \alpha L' + (1-\alpha) L$$ Now, define $L''' := (0,1)$. Hence, the second statement implies $$\alpha L'' + (1-\alpha) L''' \prec \alpha L' + (1-\alpha) L'''$$ Thus the independence axiom is violated. 

Hence, $$\begin{split} M &= 1 - \int_{0}^{7/11}\frac{2-a}{3}da - \int_{7/11}^{1}\frac{3a-1}{2}da\\ &= 1 - \frac{259}{726} - \frac{32}{121} = \frac{25}{66} \approx .3\bar{78} \end{split}$$ Finally, $$T=1-\frac{25}{66}-\frac{101}{264} = \frac{21}{88} \approx .238\bar{63}$$ Since $$\begin{split} \frac{101}{264} &> \frac{25}{66}\\ \frac{101}{264} &> \frac{21}{88} \end{split}$$ the result is shown. 

Dynamic Programming & Optimal Control by Bertsekas Introduction to Modern Economic Growth by Acemoglu The Acemoglu book, even though it specializes in growth theory, does a very good job presenting continuous time dynamic programming. 

Try writing your equation explicitly with a conditional expectation operator: $$ \mathbb{E}_t f(\alpha_t, \beta_t, s_t, s_{t+1}) = 0$$ Hopefully this clarifies things. You can take the total derivative as you normally would with any function, however $s_{t+1}$ is a random variable since it is not predetermined. Ultimately you are considering all cases of $s_{t+1}$ weighted by their probability. Since $\mathbb{E}_t$ integrates over shocks, you can differentiate under the integral sign by Leibniz's integration rule. 

Consider the following example with a Cobb-Douglas production function having total factor productivity $A_t$, labor $L_t$, capital $K_t$, and effort $e_t$: $$ Y_t = A_t K_t^{\alpha} (e_tL_t)^{(1-\alpha)}$$ The intensive margin regards the level of effort $e_t$ (think intensity), and the extensive margin the quantity of labor supplied $L_t$. In a less abstract sense, think about output and hours worked. You can work for 2 hours at a normal pace and create one widget. Or, if you try very hard, you could make one widget in one hour. How do you get the same output from the same worker with different values of $L$? The intensive margin is the answer.