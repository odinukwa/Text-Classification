Up to now, PHPSERVER accesses LOCALSQL; I can only access REMOTESQL from a test Windows machine with SQL Server Management Studio, with the necessary firewall permission. Now, I would like to use sp_addlinkedserver to have PHPSERVER execute query involving tables from both servers. What should I do for the firewall? Should I allow connections: a) between LOCALSQL and REMOTESQL b) between PHPSERVER and REMOTESQL c) both of the above 

Question: how do I make sure that the combination action-reason is valid, i.e. exists in master_action_reasons? Since the action is in one table, and the reason in another, I cannot use a foreign key. 

I have made a script that, one at a time, deletes all the foreign keys from a database, just like this: 

Of course I could store an altered version of the title and search there. But is there any other solution? 

I would not expect the query to update any index, because last_read is not indexed in any way, and book_id is not changed. What am I missing? 

The column updated_on is updated by a trigger on insert/update; at every run of the Solr incremental indexer (every 10 minutes), many queries like the above get the latest modified records and reindexes them. This table, for instance, has about one million rows and at every time the query would return 10-20 rows maximum. These queries end up in the list of the most expensive queries run on the database, so I would like to optimize them. My questions: 1) Would a timestamp column perform better than a datetime column? 2) If I changed the query like this, would it be more efficient? 

I have to record a list of events made of action, reason (optional, may be multiple), user. I have a master table with all the valid action, and another with all the valid action-reason combination. All tables have a unique identity (not displayed in the example). 

The first query plan is the original one, the second is modified by me. The fact that the second plan asks for an index, and the first one doesn't, really suggests that the modified query can use an index, if present, and is therefore better. 

A server SERVER_C defines B as a linked server. I have full access to SERVER_C, I can ask for some changes to SERVER_B, but not to SERVER_A. All my applications will access server SERVER_C, and need the data from SERVER_A. The views on SERVER_B are quite complex, and they cause timeout before returning anything. I think that to improve the performance on these queries I need to turn the views on SERVER_B into "indexed views". To index a view, I must create a clustered index. Questions: 1) Where should I define the clustered index? Should it be at SERVER_B, or I can somehow define it on SERVER_C? 2) Will the use of an indexed view on SERVER_B affect in any way the performance of SERVER_A even when the view is not being used? 

I have logged the slowest queries on my database, and one surprises me, showing many times in the list, and taking often many seconds to execute. 

This helps me a lot because I immediately see all the tables and columns that have no description. Now, it would be really cool to be able to directly edit these descriptions. Is there a software that allows bulk editing of descriptions for tables and/or columns? 

For maximum file space I have set 1024 MB, more than enough. However, when from the SQL Server Management Studio I go to security/audits/audit_test/view audit logs it only displays exactly the latest 1.000 rows. On the other hand, the file produced by the audit is 317 MB, so I guess it has more than 1.000 rows. I even tried setting a filter, but it did not help: no line appear outside the latest 1.000. How do I read the audit log file? 

I regularly make a backup of my production database, then restore the same onto a test database, so developers can always have recent data for testing. The production database uses full recovery model, but the test database would be better off with a simple recovery model. So I thought to change the script, and after the database reload, running on the test database the commands: 

I always thought of TRUNCATE TABLE as an equivalent of DELETE, except that: 1) TRUNCATE can be used only in some cases (no FK referencing table, user must have ALTER permission etc) 2) TRUNCATE is faster to execute Apart from that, I expected them to have identical results. But from my experience, it seems that a TRUNCATE improves the performance of subsequent queries over a DELETE. I have a script that clears some tables, then fills them with millions of rows from another database on the same server, like: 

I have a big PHP application, developed by an external company, which is being completed right now; I cannot ask for changes to it. It uses a database Microsoft SQL Server 2016, which is accessed by some users via SSMS, including me, and by some scheduled tasks at specific times of day. Sometimes I find unexpected content in some tables, and it is frustrating because I don't know when it got there. I just discovered about temporal tables: knowing the exact date and time when a record changes would be extremely useful. Is it possible to add temporal tables to 2-3 key tables in the application, without changing the PHP code? Are there risks of compatibility or performances? 

I have a database table with a text column "title". New rows are inserted all the time, and every time I would like to check for potential duplicates on this column. I define duplicate by "having the same sequence of alpha characters". So, for example, if I already have the string "Lisa's Nights": 

In a question on StackOverflow I found this query, that displays table and column description for all the tables in current database: 

These commands come from my computer (DBA) and from a developer's. For the developer, it gives several permissions errors: 

SQL Server 2008R2 database server in my LAN and under my control (call it LOCALSQL) remote SQL Server, on which I have much less control (call it REMOTESQL), for which I only have IP, username, password Linux-Apache-PHP server, on my LAN, used to access LOCALSQL (call it PHPSERVER) 

I am DBA of server A (SQL Server 2008R2), linked to server B (SQL Server 2012SP1), linked to server C (not sure which version). I have no control on server C, and I cannot contact its DBA. On server B, I can contact the DBA and ask for a view on server C, example: 

This view gets a lot of data from server C, because the openquery gets all the content of the table, which is not acceptable. On the other hand, I know that this would extract only one row, and would be very efficient on server C: 

In my database error logs (produced as in this answer), I see many instances (hundreds per day) of the following query: 

What surprises me is that the script takes long time: on average, 20 seconds for each DROP FK. Now, I understand that creating a FK may be a big deal, because server has to go and check that the FK constraint is not infringed from the beginning, but dropping? What does a server do when dropping FKs that takes so long? This is both for my own curiosity, and to understand if there is a way to make things faster. Being able to remove FK (not just disable them) would allow me to be much faster during a migration, and therefore minimize downtime. 

I have an SQL Server 2016 Azure database in the cloud called XCLOUD, with many tables big and small, and a local SQL Server 2016 database with the same tables and data called XLOCAL. In all databases there are neither PK, nor FK. My goal is to keep XLOCAL updated with all the changes in XCLOUD, minimizing network traffic and keeping XLOCAL available all the time. Performances on Azure are not a problem: once XCLOUD is filled, the server does nothing else until the next day. A daily process on the Azure server truncates all the tables in XCLOUD and fills them again with almost the same data. I don't have control on this process: if I had, I would change it to only INSERT/UPDATE/DELETE and then I would use log shipping, but this is not possible. One idea I had is to create a new database from XCLOUD1 on the Azure server: when the process filling XCLOUD finishes, I would somehow compare the differences between XCLOUD and XCLOUD1, update XCLOUD1 with MERGE statetements as needed, then use log shipping from XCLOUD1 to XLOCAL. But I would need to code the MERGE statements one by one, unless you can recommend some tool for this task. What would you do?