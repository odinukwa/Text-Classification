It's roughly $2 - O(1/n^2)$. For an appropriate choice of $K$ evaluate $(D + P + P^{-1}) u$ for $$ u(k) = \begin{cases} 1 - \frac{|k|}{K} & |k| \leq K \\\ 0 & otherwise.\end{cases} $$ An application of the uncertainty principle shows that this is optimal up to constants. The main point why this works is that $2 \cos( 2 \pi \frac{k}{n})$ is almost constant in $k$. If you would instead take for some $\ell$ coprime to $n$ the potential $2 \cos(2 \pi \frac{\ell k}{n})$. The question is much harder. 

If you drop the locally connected assumption, the middle third Cantor set satisfies the desired properties. The proof can be given as in Nate Eldredge's answer, since it is homeomorphic to $\{0,1\}^{\mathbb{N}}$. 

Just so we have the silly example here. Consider $\ell^2([0,1])$ meaning the set of SEQUENCES $u_{x}$ indexed by a number $x\in [0,1]$. So the scalar product is $$ \langle u, v \rangle = \sum_{x \in [0,1]} \overline{u_x} v_x. $$ In order for $u \in \ell^2([0,1])$, we have that $u_x \neq 0$ for at most countably many $x$. So this is very different from $L^2([0,1])$. Now consider the operator $$ (Au)_x = u_x. $$ This operator is diagonal and it's eigenvalues are $[0,1]$. The eigenvector corresponding to $x \in [0,1]$ is $$ u_y = \begin{cases} 1, & x=y\\\ 0, & \text{otherwise}.\end{cases} $$ Of course the key to this example and the question is that $\ell^2([0,1])$ is a NON-separable Hilbert space. 

Not an answer, but maybe an useful reference: Your statement reminds me of Schiefermayr's theorem: If $p_n$ is a degree $n$ polynomial and $\Sigma\subseteq\mathbb{R}$. Then $$ \|p_n\|_{L^{\infty}(\Sigma)} \geq 2 Cap(\Sigma)^n $$ where $Cap(\Sigma)$ is the logarithmic capacity of $\Sigma$, e.g. $Cap([-2,2]) = 1$. This is Corollary~5.7.7. in Barry Simon's book: Szego's Theorem and its decendents. 

If $f$ is minimal, i.e. every orbit is dense, then $E$ is either empty or dense. So it remains to decide if your set is empty. Clearly it is non-empty for positive measure sets. If $\mu(E) = 0$. Then also $$ \mu(\bigcup_{n} f^{-n} E) =0 $$ and for this set the exceptional set is non-empty (and trivially dense). 

I am also curious if one should include some sort of source code in the paper, and if yes, in what form? Or what people have done in such a case... The simplified code is available at: $URL$ I have not put the real code online, because it requires external packages, and I am not sure how easy it is to install them... 

I think the following is another proof. It suffices to approximate a polynomial of degree n by an exponential polynomial of degree n + 1. Now, define $$ g_{\lambda}(x) = \frac{e^{\lambda x}}{\lambda} - 1. $$ It is easy to check that $\sup_{x\in [0,1]} |g_{\lambda} - x| \leq \frac{1}{2} \lambda$. Also $g_{\lambda}$ has order $2$. Furthermore, we can compute $$ |g_{\lambda}(x)^n - x^n| \leq |g_{\lambda}(x) -x| \cdot n \leq \frac{n}{2} \lambda. $$ And note that $g_{\lambda}(x)^n$ has order $n+1$. So a polynomial of degree $n$ given by $$ P_n(x) = \sum_{k=0}^{n} a_k x^k $$ can be approximated by $$ \sum_{k=0}^{n} a_k (g_{\lambda}(x))^k $$ up to order $n^2 \lambda$. Letting $\lambda \to 0$ implies the claim. 

Unfortunately, this does not apply in your case, since it requires the work with subsets of the real line. However, you are close to this situation, since you require the zeros of your polynomial to be on the unit circle. 

Let $f: \mathbb{R}^d \to \mathbb{R}$ be a continuous function. Let $t \in (\inf(f), \sup(f))$ and define $C = f^{-1} (t)$. Is it true that the Hausdorff dimension of C is $\geq d -1$? If no how does one construct a counter example? 

Old Post Let me rephrase the answer of Fabrizio Polo first: Consider all words $w$ in A, B of length $n$. Call this set $\mathcal{W}_n$. Now define $Af (x) = f(x+a)$ and $B f(x) = f(x+b)$. Then $T^n$ from the original post is equal to $$ \frac{1}{|\mathcal{W}_n|} \sum w, $$ where the sum is taken over all elements of $\mathcal{W}_n$. I am somehow unable to make that display properly. Here $w$ stands for the appropriate product of operators. E.g. for $n - 2$, we have $\mathcal{W}_n = \{AA, AB, BA, BB\}$ so that the expression above becomes $$ \frac{1}{4} (AA + AB + BA + BB), $$ which is the $T^2$ from the original post. Now if $a - b$ is irrational, I believe that $(\mathbb Z_+) \ast (\mathbb Z_+)$ action defined above is ergodic, so one should have almost sure convergence. However, I am not sure if this holds, since the group $(\mathbb Z_+)\ast(\mathbb Z_+)$ is not ameanable. So you will probably have to look into ergodic theorems for non ameanable actions to answer this question. Another hope could be to somehow resum the expression for $T^n$ and be able to use more classical ergodic theorems ... 

I am not sure of your math-background, so I am trying to keep it simple, without oversimplifying some ideas. First off polynomials are nice for various reasons, e.g. a polynomial of degree $n$ has at most $n$ zeros. However, there are still many polynomials and it makes sense to choose VERY nice ones: orthogonal polynomials. To choose orthogonal polynomials, one has a problem at hand, which comes with a way to measure functions $f: \Bbb R \to\Bbb R$ by an expression of the form $$ \mathcal{E}(f) = \int_{-\infty}^{\infty} f(x)^2 w(x) dx, $$ where $w(x) > 0$ is a weight that satisfy $\int w(x) dx = 1$. One should think of $\mathcal{E}$ as an energy. Now the orthogonal polynomial of degree $n$ can be defined as the polynomial $P_n(x) = x^n + a_{n-1} x^{n-1} + \dots + a_1 x + a_0$, where $a_{n-1}, \dots, a_0$ are real numbers, that minimizes $\mathcal{E}(P_n)$. It is this minimization property that is responsible for some of the power of orthogonal polynomials. At this point let me also say that it is through the weight $w$ that your problem enters the definition of orthogonal polynomials. And that one also has orthonormal polynomials, which satisfy $\mathcal{p_n} = 1$. These are given by $p_n = \frac{1}{\sqrt{\mathcal{E}(P_n)}} P_n$. 

AS for physical meaning of Hardy's inequality for p=2. Consider the Schroedinger operator $$ H = -\frac{d^2}{dx^2} - \frac{c}{x^2} $$ on $(0,\infty)$ with Dirichlet boundary condition at $0$. A natural question is: When is this operator positive on $L^2(0,\infty)$ and the answer is just Hardy's inequality, since $$ \langle \psi, H \psi \rangle \geq 0 $$ is equivalent to $$ \int_0^{\infty} |\psi'(x)|^2 dx \geq + c \int_0^{\infty} \left|\frac{\psi(x)}{x}\right|^2 dx $$ an inspection of Hardy's inequality now shows that $c = \frac{1}{4}$ is critical. One can actually use this reasoning to prove Hardy's inequality, since the ODE $-u''(x) = c u(x)/x^2$ is explicitly solvable. 

Ten Lectures on the interface of harmonic analysis and number theory by Hugh Montgomery covers these things (Chapters 2 and 3). 

Singular values of $A: X \to X$ are the eigenvalues of $A^{*} A$, which implies $$ A v = \sum_{n} s_n e_n(v) f_n $$ for some bases $e_n \in X^{*} $, $f_n \in X$. Independence on $p$ is then obvious. At least for reflexive Banach spaces. 

Just a comment if you choose coefficients $c_{k,n}$ such that $$ \lim_{n\to\infty} \left(\sum_{k=-n}^{n} c_{k,n} e^{2\pi i n x}\right) \to f (x) $$ in some sense, e.g. $L^1$, then these are not unique. It is even known that the obvious choice $c_{k,n} = \hat{f}(k) = \int e^{-2\pi i n x} f(x) dx$ is not the best. It's much better to choose $$ c_{k,n} = \left(1 - \frac{|k|}{n}\right) \hat{f}(k). $$ Then one Cesaro sums the Fourier series, and this is known to converge. As pointed out by Zen Harper below, I should mention that with the choice $c_{k,n} = \hat{f}(k)$ for $-n \leq k \leq n$, the Fourier series of a $L^1$ function must not converge. In fact it can diverge almost-everywhere. Having said these things, the obvious advantage of this is, that everything is explicit and does not rely on any abstract hocus pocus. I realized one more thing: Consider the case $f \in L^2$. Then the choice $c_{k,n} = \hat{f}(k)$ for $-n \leq k \leq n$ is optimal. This follows from easy Hilbert space theory!