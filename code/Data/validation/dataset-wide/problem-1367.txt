The code is readable, and appears to be correct. That's a pretty good starting point. It's shorter than what's presented here. I'm always skeptical of the word "Pythonic". The original code may be more Pythonic than that presented here because it is more explicitly procedural. Then again, someone could come along and claim that because Python has objects, true Pythonic code is object oriented. Down at the level of a single statement or expression, there are some dominant idioms. But up at the level of programs "Pythonic" is mostly part of a pejorative "Not Pythonic". The problem is such that there's no good way of avoiding the fact that there are four cases. Where the code in the question is weak is the level of abstraction at which the four cases are articulated. There's lots of fiddly-bits around columns and rows and limits up near the top-level of the function. Even though our top level abstraction is a diagonal. The mathematics works, but it's not obvious exactly why. One way of thinking about Remark 2 is that the code 'one level down' is reductionist rather than compositional. It expresses itself in terms a bit more like 'machine code' than 'business logic'...or perhaps the mathematical logic suggested when linear algebra was mentioned. 

The missing piece is a clearly defined interface between the View and the Controller. The controller should pass a value to the view. It could pass , , or directly from , but that's probably not a good idea for obvious reasons. An alternative is for the controller to pass the tuple of strings, i.e. something that would serialize to JSON as: 

Then all that's left to do is to make the diagonals for each quadrant. Clipping is applied first to reduce the number of calculations where possible. Translation is applied last because rotation produces negative values. 

The class maintains the nodes as a set in order to provide set semantics. It uses to maintain a bag of edges as recommended by the Python documentation. The implementation of undirectional edges is left as an exercise. 

An Ugly First Implementation The main code is reasonably clean. Improvements related to are described in other answers, but I've ignored them to focus on the algorithmic abstractions rather than performance related to language implementation. 

Sorting algorithms for an array are baked into most programming languages or can be found in a library [the kind with books if not the language's standard ones]. Sure they don't handle arbitrary objects directly, but they all handle integers appropriately for the purposes to which the language is usually put. These are off the shelf parts. There's a whole chapter in Knuth for anyone needing to take seriousness up a notch. Keeping the array sorted while changing it's values means concurrency semantics. That's the sort of hard problem that matters to a sensible interviewer. Presenting an unreliable answer in O(n log n) is often worse than a reliable one in O(n^2) even if a reliable answer in O(n log n) is preferable. 

It is important to consider and and the basic tree constructor because knowing their logic makes it possible to avoid walking the tree at every change to determine depth...or to know that the tree structure may be arbitrarily unbalanced and that it must be walked after each change. In any event, there is no reason to walk the more than once to determine its size, and there is some logic to having as a field of . This is essentially memoization and for any interestingly sized tree offers a huge performance improvement on repeated access for any data type as simple as an integer. 

A More Mathematical Approach Because, limitations of computer hardware aside, the chessboard can be arbitrarily large, looking at the solution for a bishop on an infinitely large chessboard might be a place to begin looking for a general solution. The first thing that popped out is that the choice of coordinate system origin point is important because an infinitely sized chessboard does not have any corners. Since the choice of origin point is arbitrary, maybe placing the Bishop at (0,0) might things easier to understand. It gives us a Cartesian grid: 

[Caveat: This review is premised on a rigorous technical interview context. It takes the specification literally.] High order bit To me, the code does not really meet the specification. 

That's just standard Scala. It's fast in the sense that many people will understand it as soon as they read it. The Clojure implementation, on the other hand, is really slow because the source code doesn't make the nature of state clear. A [more opinionated][more opinionated] approach might be: 

Abstractions As with Naming 1. the abstractions in the code don't closely follow the business logic of the problem statement. There's no reference to Easter Bunny Headquarters or Taxicab Distance in the code. If the specification changed from taxicab to crowflight distance, it's not immediately obvious how to change the code. 

[1] Clearly I have assumed that the author of the review code does not control the domain. My apologies if I am in error. The bases for this assumption were the standard parking content currently on the domain and the shape of the code relative to the shape of code expected when serving of area calculations from a website. 

The use of is a solid approach to functional programming. The names of the functions and variables are reasonable. 

Alternative For procedures that try to find a property of a list, folding is often a good place to start. This code uses . Usually I find rather than is what I want, for whatever that's worth. 

Decoupling Predators and prey are a different level of abstraction than anything in . Predators/prey respond to other predators/prey and move of their own volition. 2d grids are something else entirely. Predator/prey logical abstractions should work for whales and giant squid in the sea, leopards and chimps in the forest or lions and wildebeests on the savannah. The visualization methods should not leak into the simulation's abstractions. The simulation should be able to be run independently of any visualization. This allows running a million iterations, followed by statistical analysis using the Monte Carlo or similar methods. This means that the simulation portion of the program has its own methods and data structures. Likewise the display portion of the program should have its own. In between, the main loop reads the simulation data structures and translates them into a visualization data structure [i.e. the main loop draws a pretty picture]. 

Likewise, the ideal data structure for a sale may not be ideal for a receipt. So there is another interface that formats the sales data into a data structure suited for creating receipts. 

It depends on what operations will be performed on the graph and what the graph represents. If the graph represents something which might have redundant edges between vertices, then and don't capture the real world object and operations such as cannot be performed accurately. Similar issues arise if edges have variable costs. In the end, just as adjacency matrices are a good choice for dense graphs and maybe not so good for sparse graphs, other aspects of the procedural representation of mathematical graphs come with tradeoffs that should be dictated by the intended use. 

The Regex will validate some email addresses. Because the Domain Name System allows UniCode. the Regex does not match all valid characters in the Doman Name. Therefore it will not validate all valid email addresses. Alternatives: Validating over all allowable Unicode with Regex in a meaningful way is non-trivial. 

The specification says that a binary tree is "given". The code explicitly creates a separate implementation of a binary search tree without reference to the given. There is no method which takes a sorted list and returns a representation of the list. 

otherwise, 1 and 5 are magic numbers. Magic numbers make the code hard to understand and brittle when refactoring because each occurrence of each magic constant has to be manually changed. Even with just a single use, naming the values makes the code easier to read and helps the reader understand why 1 is one (and not some other value) and 5 is five. 

Using an internal function, recursion, and a trampoline is a good way to structure recursive procedures on a lists. The code fragment is the same as . The name suggests an accumulator, however, the value it stores is the maximum, so might be better. Because of the letter can be confused with , can be read as slang for 'first'. I prefer as the name for a list of 's. The nomenclature has become more common in Lisps over the past few decades due to the influence of other functional languages. No matter how it is dressed up, there's a procedure in the code somewhere. And it has to be written. It is better to be explicit about it than to try to hide by embedding it in some other function. 

Caveat: I'm taking the code seriously Background The abstractions are leaky. What is a Node? A node has two parts: the value it contains and pointers to other nodes. Either, both, or neither may be null. When the pointer part is null we have a terminal node. Depending on context a terminal node might be called a leaf or an atom. Graphs One or more nodes form a graph. A graph may be directed or non-directed. Some, all, or none of the nodes in a graph may point to other nodes within it. The way in which nodes point to each other is what distinguishes one type of graph from another. Whether a node contains null or some other value is a detail of a graph implementation not nodes. A node's pointers to other nodes are the edges of a graph. The value stored at the node is a record. The structure of a record is not a function of the graph or the node. It is an implementation detail of a particular program. That is to say that the record structure reflects business logic. The edges of a directed graph are directional. The directed edge is different from the directed edge . The edges of a non-directed graph are not directional. The non-directed edge is indistinguishable from the non-directed edge . Traversal is an operation on graphs. The order is not a property of the graph. It is a property of the business logic. The efficiency with which we traverse a graph often depends on the alignment between business logic and graph type. Trees Trees are a class of directed acyclic graphs. A graph consisting of a single node is a tree provided that it does not have an edge pointing to itself. A graph that consists of several trees is called a forest. A tree in which each node has two outgoing edges is a binary tree. Typically, one edge is labeled left, the other right. A binary tree may or may not store values at internal nodes depending on the business logic being implemented. Binary trees are of particular interest in computing due to their isomorphism with binary logic. Another important class of trees for computing is the b-tree. Code Improvements To a first approximation, the leaky abstractions can be removed by redefining and then using it in a definition of a . A Node Implementation Since the number of edges a node has is a function of both the graph type and a particular instantiation of that type, an iterable data structure makes sense. A list is probably the place to start. 

Down the road, the dependency on sorting by or ought to be made explicit so that a maintainer of the code is less likely to change it and thereby breaking code that depends on implementation details. 

Adding it's cost to a running total cost. Adding it's tax to a running total tax. Aggregating any where into a single line item. Mapping Each aggregate`` into a . 

Caveat: I am not a Matlab expert, nor am I competent at an advanced undergraduate level in mathematics. Efficiency Removing data structure impedance and redundant or unnecessary calculations is likely to improve the running time of the code under review. 

Search This is basically the case where we have a value and want to know if is a member of . Since is a permutation, must be a tuple. The comparison can boils down to: 

Nodes are necessarily properties of Edges. Edges are not properties of nodes. Edges are [ properties | fields | objects ] of a graph. The dependencies are: 

In my opinion, the biggest concern is that products are modelled with tax status as the most important property. This makes reusing the objects in different contexts, for example an inventory control system or an online storefront difficult. Furthermore, the tax status of a book is not a constant because in another jurisdiction, it may be taxable at the base rate and a book printed in Bolivia may be an imported book in Australia, but it is not in Bolivia. The code may meet the specification, but it is extremely brittle. It can not easily modified to address related circumstances or support making logically implied business decisions because it does not strive to fit into the bigger context of running a business. Code is a means to an end, not an end in itself. Modelling The key to designing a well-engineered solution is to have an appropriate model of the system. Sure there are times when quick and dirty is good enough, but a core business function such as sales transactions are usually not among them. Naive Model The naive model is specified in terms of computer input and output. We get an order and produce a receipt. 

Making these assumptions explicit allows those reading the code to reason about it more clearly. It makes it easier to extend the code to three or more dimensions [there's no reason a computer can't solve an maze] or to handle hexagonal grids in ways that make sense. 

Duck Typing QuickSorts Tony Hoare's QuickSort was considered quick in 1962. But it was not because it has 0(n log n) average performance. Merge sorting was already established [Knuth credits Von Neumann in 1945] and has better worst case performance than QuickSort. What made QuickSort a quick sort was it's space efficiency. Hoare's insight was in-place sorting. QuickSort was quicker because in-place sorting meant more blocks could be read from tape into fast memory on each IO cycle [and likewise written]. The speed improvement came from reduced latency. Because IO then as now was so much slower than fast memory, the practical performance improvement on non-trivial data was massive. It's common to illustrate functional programming using a double filter for the pivot and to call it a "quicksort". These necessarily avoid inplace mutations. Consider this page of examples in Python. If you consider the Python examples to be quicksorts, then clearly the code under review is a quicksort. If you don't then... Garbage Out Because the Java manages memory deallocation via garbage collection; because the JVM offers just-in-time compilation that may perform arbitrary optimizations of the bytecode, and different ones at different times based on how much time it has due to what else is running; and because modern CPU's utilize multiple levels of caching, simple definitions of "in place" become increasingly brittle the more absolute our definition of "true quicksort" becomes. Welcome to the effects of post modernism in computing. Practical Improvement Issues of truth aside, the performance of QuickSort degrades toward worst case 0(n^2) if the data is sorted in reverse order. Hoare advised selecting the pivot at random rather than sequentially. That is randomly selecting the pivot from the interval makes worst case performance statistically unlikely for any interestingly sized data. Of course, if the data source is known to be random then it's a waste of time. On the other hand, in the real world many data sources aren't random. Final Remarks There are many sound insights in the other code reviews, and there's no point in chewing the same ground. 

and placing - from the viewpoint of the stack - all the user interface code in . Whether the user interface logic all lives there or in it's own class/module is another question. But reusability and maintenance certainly offer suggestions. For example, breaking out the user interface and its logic and its content into modules allows handling nasty issues like multiple languages and the quirks of UniCode to be handled more gracefully. String output is the one of the places Your-Not-Gonna'-Need-It [YNGNI] fails and why it is a baked in module for so many development frameworks. Variable Names , , , and though perhaps conventional for C++ example code, don't really scale well because they lack information. Even in the original code: 

At this point, we are free to implement specific business logic such as that for modeling an HP11C calculator (I've had mine since 1988). 

Final thoughts The real scientific work is in simulating the behaviors of predators and prey. Getting the display code out of the way will allow you to focus on the core problem clearly. It will make the code more readable and prioritize bugs - it doesn't matter how right the visualization is if the underlying simulation is bad. 

For efficiency, there's no reason to be redundant. One walk of the tree can compute both height and size. A class can be used to hold the results of the walk: