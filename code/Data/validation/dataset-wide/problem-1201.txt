There are of course alternatives more intrinsically secure, like mysqldump and Xtrabackup. But I'll assume that you know how they work and you decided that a simple file copy is better for your use case (for example, because data are too big for mysqldump and most of your tables are not InnoDB). 

It doesn't mention TokuDB (despite it being distributed with MariaDB), so I would exclude that this engine is supported. 

So triggers are a fundamental part of the process (unless the table is readonly or you are definitely sure that no one is going to modify it now). The problem is that, before MySQL 5.8 and MariaDB 10.3, you can have only one triggers for each combination of table + timing + event. For example, your table can have only one trigger . One thing you can try is, turn your existing triggers to - unless you already have an trigger, this will do the trick. And do the same with INSERT and triggers. Or try to use from GitHub, as someone already suggested. This would work because this tool doesn't create any triggers: instead, it reads the binary log and applies the changes to the new table manually. 

I don't think that your approach is wrong, but I don't have much information. Your question is clear, but this space is limited compared to the complexity of your system. Definitely you shouldn't consider using Clickhouse for OLTP. Not only because and are not (yet) supported, but also because this database is designed to provide good performance for analytics. It lacks more or less everything is needed to optimize an OLTP workload. Kafka is a good idea? Maybe. But you won't have transactions, for example. I suggest to try to optimize your MySQL environment first. Some very generic points - sorry if they sound obvious to you, but of course I can't know your skills lever: 

Avoid a single database. My recommendaion is: start with separate databases on the same server - to reduce the costs, including maintenance costs. If workload increases, you can setup a new machine and move some databases. If only one application's workload increases, you can move only that one. To do this, it is important to monitor the workloads of different applications. So I recommend to install User Statistics plugin, from Percona. And yes, the good way to distribute the workload and face crashes is to use replication or a cluster (replication is much simpler). Nowadays, we need to have no single points of failure. With MySQL you will also have another way to reduce costs: if you have applications on 3 servers, you can replicate all those databases to 1 slave - this is called multisource replication. Other benefits of using multiple databases include: 

MariaDB doesn't have that variable, MySQL has. MariaDB is not a drop-in replacement for MySQL. The error you see makes me think that replication from 10.1 to 5.7 is not possible. One could investigate more, but take a look at this compatibility table: there is not an explicit incompatibility statement, but at least they don't guarantee that replicating from 10.1 to 5.7 is possible. Even if you choose to assume that such replication is possible and find a way to set it up, MySQL supports some syntax that MariaDB 10.1 does not support - not because it's more advanced, but because they took different directions. Such statements will break replication. 

As you probably know, the way to do this is a foreign key whith . But you don't want this, so I see 2 options (there may be more as I'm not a SQL Server expert): 

Yes, you can do it. Be sure to keep innodb_lock_wait_timeout readonably low, for example 2 seconds. Deadlock that last for 2 seconds are completely harmless, if they are rare (and usually they are very rare). Remind developers to avoid long transactions, and avoid foreign keys (because they propagate locks, making deadlocks more likely). Of course I am assuming that you can keep a very low value for those timeouts. But can you? I don't know your workload but, for example, a statement may lock some rows for 10 seconds every hour. In such cases, can you afford a low timeout? If not, then everything I wrote above does not apply to you. 

Just try to connect in a non-secure way and be sure it doesn't work. If you are not sure wether you are using SSL or not to connect, then yes, the simplest way is using the command line client: 

Logical data is how your applications see the data, and how they query data. In the case of a relational database, the design of tables, along with their columns and relationships, is the logical model. In other database models the logical level could be queues, collections, or any type of data structure used by applications. But how are those data structures written to disks (and to memory)? That is the physical layer. It is the set of files written to disk to contain data, and the format used to represent data in such files. So what is the independence between physical and logical layers? It is the principle that states that programs which query a database don't need to know how it stores data physically. For example, an SQL query mentions table and columns, not files and bytes from that file. 

I don't think that someone can give you magic numbers like the acceptable number of columns, or information too strictly related to your workload, like if it is a good idea to split the table. There are too many variables: number/types of existing columns and indexes, number of queries, how many columns you read per query, and so on. Proper tests will give you a good answer. All we can say is that, yes, common sense says that such a table should be split if possible. But then, every query will need to read from multiple partitions? Every new row will have matches in all partitions? This could slow down your application. Ideally, most of the queries should be able to read from only one partition. So the first suggestion would be to check with developers if some queries can be rewritten so that they will read less columns - possibly by rewriting some . You also ask about the best possible match condition. Here the answer is easy: join by primary key. All matching rows should have the same . It should be an columns on only one table. You first insert new rows into the table, then to the others, in this way: