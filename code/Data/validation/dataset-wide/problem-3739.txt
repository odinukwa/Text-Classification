Even worse, when you try to formalize these computations, you drown in rigor and entirely lose the spirit of the original computation. 

What if I changed the Euler number of the circle bundle over the torus? Does this have a matrix representation? $$ (x,y,z) (x,y,z) = (\,x+x \,,\, y+y+ {\color{#9FB825}n}\,xz \,,\, z+z\,) $$ There are lots of examples of these simply connected nilmanifolds coming from matrices, but it's not hard to find examples without an obvious matrix representation (e.g. changing the structure constants), or a reasonable-looking classifiction scheme (that will eventually fail). 

Have a look at Chapter 1 of Fourier Analysis by Elias Stein. You start with the wave equation $\frac{\partial^2 u}{\partial t^2} = \frac{\partial^2 u}{\partial x^2}$ one of the simplest solutions is $u(x,t) = \sin m x \sin m t$. Then you can try seeing if other solutions $u(x,t) = \phi(x)\psi(t)$ work and this is your separation of variables. If you solve the two differential equations $\phi'' - \lambda \phi = 0$ and $\psi'' - \lambda \psi = 0$ you should get a combination of sines and cosines, rederiving Fourier series. Checking the boundary conditions only sines or only cosines will work and $\lambda = - m^2$ necessarily. That's how I learned it but it was for a junior-level Fourier analysis class. 

I have been learning about Roth's theorem, trying to understand how Fourier series and dynamical systems (or even graph theory and binary sequences)are involved in counting arithmetic sequences in sets. 

However the papers have been hard to decipher, such as this one by Karlin and McGregor, or the first few pages in this paper by Fabrice Gullemin. The birth-death process on $$ 1 \rightleftharpoons 2 \rightleftharpoons 3 \rightleftharpoons 4 \rightleftharpoons \dots $$ where $\mathrm{Rate}(n \to n+1)=\lambda_n, \mathrm{Rate}(n+1 \to n)=\mu_n, \mathrm{Rate}(n \circlearrowleft)=-(\mu_n + \lambda_n)$ The Karlin and McGregor showed you can find orthogonal polynomials $Q_n(x)$ with respect to a measure $\mu(dx)$ that solve the transition probabilities (the odds of starting at m and winding up at n at time t) $$ \mathbb{P}(\Lambda(t) = n | \Lambda(0) = m) = \pi_n \int_0^\infty e^{-tx} Q_n(x)Q_m(x) \mu(dx)$$ They even figured out a way to construct the polynomials $$ Q_{-1}(x)=0, Q_0(x)=1, \lambda_n Q_{n+1}(x) +(x - \lambda_n - \mu_n) Q_n(x) + \mu_n Q_{n-1}(x) = 0 $$ And then one notices the 3-term relation is the "magic box" recurrence formula for continued fractions. 

I would recommend those from Simon's Center for Geometry and Physics. Here is a list of all workshops at SCGP. Videos from all of their workshops are available online. Here are all talks from Random Tilings Workshop last February. 

In a physics paper I found a very complicated Gaussian matrix model: $$ Z = \int \frac{d\mu}{(2\pi)^n} \frac{d\nu}{(2\pi)^n} \frac{ \prod_{i < j}\left[2 \sinh \frac{\mu_i - \mu_j}{2} \right]^2 \prod_{i < j}\left[2 \sinh \frac{\nu_i - \nu_j}{2} \right]^2 }{\prod_{i,j}\left[ 2 \cosh \frac{\mu_i - \nu_j}{2} \right]^2} e^{\frac{ik}{4\pi}\sum (\mu_i^2 - \nu_i^2)} $$ Such a formula looks vaguely like the formula for Haar measure on the grou of Unitary matrices - whose exact formula I forget. Let's derive several simplified versions of this measure: $$ Z = \int \frac{d\mu}{(2\pi)^n} \frac{d\nu}{(2\pi)^n} e^{\frac{ik}{4\pi}\sum (\mu_i^2 - \nu_i^2)} $$ One question is how to meaningfully ascribe a value to a Gaussian integral where the variance is a complex number. And actually $\mu^2 - \nu^2$ could be negative... so this could be like integrating over the maximual torus of a super-matrix model. $$ Z = \int \frac{d\mu}{(2\pi)^n} \frac{d\nu}{(2\pi)^n} \frac{ \prod_{i < j}\left[\mu_i - \mu_j \right]^2 \prod_{i < j}\left[\nu_i - \nu_j \right]^2 }{\prod_{i,j}\left[\mu_i - \nu_j \right]^2} e^{\frac{ik}{4\pi}\sum (\mu_i^2 - \nu_i^2)} $$ This could be like Haar measure on the unitary group $SU(N|N)$ except for the Gaussian. One more variant is if we use $\sin$ instaed of $\sinh$: $$ Z = \int \frac{d\mu}{(2\pi)^n} \frac{d\nu}{(2\pi)^n} \frac{ \prod_{i < j}\left[2 \sin \frac{\mu_i - \mu_j}{2} \right]^2 \prod_{i < j}\left[2 \sin \frac{\nu_i - \nu_j}{2} \right]^2 }{\prod_{i,j}\left[ 2 \cos \frac{\mu_i - \nu_j}{2} \right]^2} $$ This could be an integral over some matrix-like objects or over a Lie super algebra. Also there is something like the Cauchy-Binet formula. What are the appropriate Lie Groups for these setups? In physics these go under various names like Lens Space model or Chern-Simons theory 

There is an approach using half-integer weight forms that solved a few cases in 2014. And possibly a resolution of all cases where the genus has only 1 or 2 elements in 2017. 

This doesn't look very Abelian, and I sort of made things up as far as how $o(e)$ should behave: $$ o(e) = \text{neighborhood of the identity}$$ and hopefully $o(e)^2 \approx o(e)$. Sorry if this is too open-ended or unclear. In real math we deal with things which are not-quite symmetries and not-quite groups. How do we formalize such a situation, regarding $o(e)$? 

Mikhail Khovanov lists a bunch of materials for his course Representations of Finite Groups. Of course, he would be more interested in Hopf Algebras, their Representations, Applications, and Categorifications... 

Recently there was a proof of the Wallis Product using quantum mechanics on the arXiv. However, there are many proofs of the result, Wikipedia has 4. Fine Print the first proof has on Wikipedia, the Euler product as an input, $$\boxed{\sin \pi x = \pi x \prod_{n \in \mathbb{N}} \left(1 - \frac{x^2}{n^2}\right)}$$ and this follows from Weierstrass Factorization, which is a significant result. One proof by Oscar Ciaurri circumvents this. Another by Lars Holst. Quantum Mechanics This derivation starts with the Hydrogen atom SchrÃ¶dinger equation: $$ H \psi = \left( - \frac{\hbar}{2m}\nabla^2 - \frac{e^2}{r} \right) \psi = E \psi $$ Since this equation is radially symmetric there is an $SO(3)$ action on the solutions to this equation preserving the energies $E$. So these eigenspaces can be indexed by the representations of $SO(3)$, $E_{\ell, m}$ and $\psi_{\ell , m}$. Can we guess the values of $E$ ? A variational approach involves minimizing as best we can, using the point-to-line distance formula: $$ E_{\ell, 0} \leq \frac{\langle \psi | H | \psi \rangle }{\langle \psi| \psi \rangle} $$ This only works for the ground state energy. They have a guesstimate of $\langle H_\ell \rangle_{min} = \frac{1}{\ell + \frac{1}{2}}\left[ \frac{\ell!}{(\ell + \frac{1}{2})!}\right]$ while the exact answer is $E_{0, \ell} = \frac{1}{(\ell + 1)^2}$ Bohr correspondence principle How do we know for $\ell \gg 1$ these two values are the same? $$ \lim_{\ell \to \infty} \frac{\langle H_\ell \rangle_{min}}{E_{0, \ell}} = 1$$ This ultimately leads to the Wallis Product Formula using identities of the Gamma function 

Can anyone explain to me a little about this sheaf $\mathrm{ad}(E) \otimes K$ ? In light of comments, I've now learned $K$ is the canonical bundle of $\Sigma$. Can we just say $\Phi$ is a "matrix of $E$-valued 1-forms over $\Sigma$ transforming in the adjoint representations of $G$"? 

What are the odds two uniformly chosen elements of S_n span the whole group (or just the alternating group)? Mathematica experements suggest those odds approach 1 - this might have been proven a long time ago. How likely is it to get the alternating group or something much smaller? Also, how can you efficiently find the size of the subgroup $\langle a,b\rangle$ in S_n ? My crude tests consists of randomly multiplying the two permutations and seeing how many different elements you get. Maybe there's a more efficient way to generate all the elements spanned by two permutation. 

I have no idea what the above really means, but it sounds like we get really lucky. These results are due to Riemann -- long before Serre, Grothendieck, Hartshorne or Shafarevich. How could he have anything more complex in mind? The only ring mention in Klein's paper is $\mathbb{C}[x,y,z]/(x^3y + y^3z+z^3x)$ -- the one David Speyer wrote -- as well as $SL(2, \mathbb{F}_7)$ and $\mathbb{Z}(\frac{1 + \sqrt{-7}}{2})$. Which one is the canonical ring? Since $x, y, z$ are the coordinates of an equation $x^3 y + y^3 z + z^3 x = 0$, then $x, y, z$ can be thought of as parameterizing solutions to the set $$\{x^3 y + y^3 z + z^3 x = 0\}$$ So the coordinate ring might be the coordinate ring of $\mathbb{P}^N$ mod a single relation: $$ \mathbb{C}[x,y,z]/(x^3 y + y^3 z + z^3 x ) $$ In fact, $x, y, z$ are sections of the line bundle $\mathcal{O}_X$ and if $i+j+k = n$ then maybe we can multiply them to get sections of the other sheafs: $$ x^i y^j z^k \in H^0(X, n \mathcal{O}_C)$$ Looks like the coordinate ring is the direct sum of all of these possibilities excepting for the possibility that $x^3 y + y^3z + z^3 x = 0$. 

Whenever you write down an equation or do an approximations, polynomials have been the choice for describing these kind of relations. Therefore, algebraic geometry -- and algebraic varieties are always the main source of examples. e.g. a Lie group is a variety For me it's the fact that your theorem comes from a textbook, suggests the main geometers of the time knew your result under a different name. I am researching the name of the map $C \to SO(k)$ from your curve to the first $k$ derivative at that point. There must be an analogue of the Gauss map there. Just a bit from Wikipedia: 

Hugo Duminil-Copin, Stanislav Smirnov The connective constant of the honeycomb lattice equals $\sqrt{2+\sqrt{2}}$ 

If our game were played in normal play convention (player moving last wins), but real life Nim is played as a misere game. Probably the analysis is similar to normal-play Nim with some modification. Recently there was a theory of Misere quotients where each game has a commutative monoid assoicated with it. What does that monoid looks like here? Is it finitely generated? 

I interpret this as we are trying to approximate both $a, b \in \mathbb{R}$ with two fractions $\frac{x}{z},\frac{y}{z} \in \mathbb{Q}$ with the same denominator to $O(z^{-3/2})$. How to prove this result? Is $\sqrt{\frac{8}{19}}$ optimal? I will settle for worse constant just to see how geometry of numbers works here. 

How could a statement like this possible be proven geometrically? Minkowski's geometry of numbers is decidedly a Euclidean result and so the only possible completion that should be useful is $\mathbb{R}$. In the case of sum of 2-squares the role of the Hasse principle is even more obvious since we can use multiplication identities like: \begin{eqnarray} (a+bi)(c+id) &=& (ac-bd) + i(ad+bc) \\ (a^2 + b^2)(c^2 + d^2)&=& (ac-bd)^2 + (ad+bc)^2 \end{eqnarray} and check each time that $n = x_1^2 + x_2^2 \mod p$ and multiply the result. By Minkowski theorem this only works when $p = 4k+1$.