Suppose $f_n$ is a sequence of holomorphic functions taking $\mathbb{D} \to \mathbb{C}$ where $\mathbb{D}$ is the unit disk. Further, $f_n$ has a continuous extension to $\overline{\mathbb{D}}$. We can assume $\sum_{n=0}^\infty f_n$ converges normally on compact subsets of $\mathbb{D}$ to a holomorphic function $f$. Additionally, for each $f_n$ we know $\int_C |f_n| < \infty$ for any contour $C \subset \overline{\mathbb{D}}$. Less strictly, so we don't have enough to use the monotone convergence theorem, we know that $\sum_{n=0}^\infty |\int_C f_n| < \infty$. But additionally, for any closed contour $C^*$ in $\overline{\mathbb{D}}$ we know $\int_{C^*}f_n = 0$. Must it follow $$\int_C f = \sum_{n=0}^\infty \int_C f_n$$ I'm asking because all the naive instances where the monotone convergence theorem fail are exempt from these criterion. I think there's something more subtle in this instance. I've been able to strengthen the condition to a proof that $$\int_C f = \sum_{n=0}^\infty \int_C f_n \,\,\Leftrightarrow\,\, \sum_{n=0}^\infty \sup_{C\subset \overline{\mathbb{D}}}|\int_Cf_n| < \infty$$ Or rephrase it to $$\sum_{n=0}^\infty |\int_C f_n| < \infty\,\, \Leftrightarrow \,\,\,f \, \text{can be continuously extended to}\,\overline{\mathbb{D}}$$ Those are the two avenues I've taken. None have really given me an answer. Any suggestions, comments, questions are greatly appreciated. 

What are the continuous functions $f$ such that on $\mathbb{R}^{+*}$: $$f(x) - \frac{C}{x} \hat{f}(\frac{1}{x}) =x^{\alpha}$$ Where $\hat{f}$ is the Fourier transform of $f(|x|)$ and $C$ a constant. The functions $f(t)=t^{\alpha}$ with $-1<Re(\alpha)<0$ are solution, but can we find other solutions to this equation ? For example solutions which have asymptotics $t^{\alpha}$ near zero (with $-1<Re(\alpha)<0$) and decrease rapidly to zero at infinty have a chance to exist, as in this case we have $\frac{C}{x} \hat{f}(\frac{1}{x})$ which is asymptotic to $t^{\alpha}$ at infinity and decreases to zero in zero (providing $\int_0^{\infty} f(t) dt=0$) 

My question is on Mobius inversion formula convergence/properties when used with infinite sums of function. Lets consider (on $\mathbb{R}^{+}$): $$S(x)= \sum\limits_{n=1}^{\infty} f(nx)$$ We call $p_i$ the $i^{nth}$ prime number and we define operators $J_{p_i}$ such that: $$J_{p_i} (g(x))= g(x) - g(p_i x) $$ So if we apply successively $J_{p_1}$, $J_{p_2}$... to $S(x)$ we obtain: $$J_{p_j} ... J_{p_1} (S(x)) = S(x) - S(p_1 x) - S(p_2 x)-... + S(p_1 p_2 x)+... + (-1)^j S(p_1 p_2 ... p_jx) = \sum\limits_{n=1}^{p_j} \mu_n S(nx) + \sum\limits_{n=p_j+1}^{p_1 ... p_j} r_n \mu_n S(nx)$$ Where $\mu_n$ is the Mobius function and $r_n=1$ if n has only primes $p_1...p_j$ in its prime number decomposition. On the other side, using definition of $S(x)$ we see that applying $J_{p_i}$ operators removes the terms in the sum defining $S(x)$ (multiples of $p_1$ are removed then multiple of $p_2$ etc...) We see the inversion in progress as we apply the $J_p$ operators: $$J_{p_j} ... J_{p_1} (S(x)) = f(x) + \sum\limits_{n=p_j+1}^{\infty} a_n f(nx)$$ If we continue to infinity we obtain only $f(x)$ and this is due to the Mobius inversion property (Finally we have the inverison formula if everything converges nicely $\sum\limits_{n=1}^{\infty} \mu_n S(nx) = f(x)$). My question is on the behavior of $J_{p_j} ... J_{p_1} (S(x))$ as $j \to \infty$. For a "good" $f(x)$ can we have $J_{p_j} ... J_{p_1} (S(x))$ converging uniformly to $f(x)$ for $j\to \infty$ ? For example suppose that we chose $f(x)= x^2 e^{-x^2} - \alpha (x \alpha)^2 e^{-(\alpha x)^2}$, as here $\int\limits_{0}^{\infty} f(x) dx =0$ and $f(x)$ has a "nice" Fourier transform by Poisson formula we have $S(x) \to 0$ for $x \to 0$. In this case we have simple convergence for all $x$ when $j \to \infty$: $J_{p_j} ... J_{p_1} (S(x)) \to f(x)$ And for each function $J_{p_j} ... J_{p_1} (S(0))=0$ with also $f(0)=0$, but what is really happening in zero? Can I bound $J_{p_j} ... J_{p_1} (S(x)) - f(x)$ on $\mathbb{R}^{+}$ ? Any reference on this subject ? 

Look at Ramanujan Summation, also called indefinite summation. Ramanujan extended The Euler Mclaurin summation method using Bernoulli numbers and a whole stack of ideas. This is a well studied subject. In general, if your $g$ is defined in the right half plane and satisfies for $z = x + iy$ $$|g(z)| < C e^{\rho|x| + \kappa|y|}$$ where $\kappa < \pi$ and $\rho$ is arbitrary, then a unique solution exists, where $f(0) = 0$ and $f(z+1) - f(z) = g(z)$. Ramanujan's formula is rather simple $$f(z) = C + \int_0^zg(t)\,dt + \frac{1}{2}g(z) + \sum_{n=1}^\infty \dfrac{B_{2k}}{2k!}g^{(2k-1)}(z)$$ where $C$ is a constant making $f(0) =0$ and $B_{2k}$ are the bernoulli numbers. Since this is a linear operator on $g$ it is common to write $$\sum_z g = f$$ $$\sum_{j=1}^z g(j) = f(z)$$ $$\sum_1^z g(p)\Delta p = f(z)$$ where each draws the similarity between it and the integral. I can give you a formula for the more restrictive case $\kappa < \pi/2$, which is a modification of Ramanujan's method. $$f(z) = \frac{1}{\Gamma(1-z)}\Big{(}\sum_{n=0}^\infty \sum_{j=1}^{n+1}g(j)\frac{(-1)^n}{n!(n+1-z)} + \int_1^\infty\big{(}\sum_{n=0}^\infty \sum_{j=1}^{n+1}g(j)\frac{(-w)^n}{n!}\big{)}w^{-z}\,dw\Big{)}$$ which follows by Ramanujan's master theorem. All in all the subject has four names: Indefinite summation, continuum sums, Ramanujan summation, Euler-Mclaurin summation. I can't remember the names of the books, but there are some books on the calculus of finite differences that deal with this subject. The idea goes hand in hand with Newton series as well, where in such a case it is rather trivial to produce an indefinite sum if the function is expanded in a Newton series. I.e: if $$g(z) = \sum_{n=0}^\infty a_n\dbinom{z}{n}$$ In this case it's much easier to work with $g$ bounded in the right half plane, so it's more restrictive. Also, if $g(z)$ has nice decay properties we can always take the wondrous classical equation $$f(z) = \sum_{k=0}^\infty g(z-k) - g(-k)$$ or $$f(z) = \sum_{k=0}^\infty g(z+k) - g(k)$$ which was Ramanujan's motivation, but these are more volatile. 

Finding automorphisms is a hard problem in general, but I am studying some simple subgroups of automorphisms, which are easy to find. I have some r-ary relation R on a finite set U (if it was a binary relation, it would be a graph, but I am considering any general relation). Let A2 be automorphisms $(a/b)(c/d)$ consisting of exactly two disjoint transpositions, such that none of these transposition is an automorphism by itself. Let's call one transposition to be a witness of another one. There is a relation L2 on U, such that $L2(a,b)$ iff the transposition (a/b) is a part of some automorphism in A2. I need to represent the subgroup $G$ of automorphisms generated by A2. I am making an algorithm, which gets a relation R, then gets a permutation P and has to decide, if $P \in G$. We draw a transposition as a two-sided black arrow between two circles. A witness is a yellow line between two transpositions. I have proven two theorems: 

I mean to ask if $G(\xi(x,y))$ satisfies the Cauchy-Riemann equations for $(x,y) \in A \subset \mathbb{R}^2$ almost everywhere under the $\mathbb{R}^2$ Lebesgue measure, and if $\frac{\partial G}{\partial x} = \text{Constant}$ and $ \frac{\partial G}{\partial y} = \text{Constant}$ almost everywhere. This would imply that $G(\xi)$ is a weird triangle wave in its own right. Sadly though, comparing the situation to $\sin$ again, the discontinuities of the derivative of $T(x)$ are at the critical points of $\sin(x)$. This makes things a bit easier to classify. $T'(x)$ is discontinuous when $\sin'(x) = 0$. Unfortunately $f(x)$ has no critical points, $f'(x) \neq 0$, so we don't get something as simple. Forcing us to ask, if $G$ is continuous and differentiable outside a set of measure zero with no limit points, 

My question is really easy to state, but I'm having trouble hitting the final nail in the coffin in a proof of the result. The question concerns fractional iterations of holomorphic functions, for clarity I'll define what I mean. Suppose we have a holomorphic function $f(\xi)$ which takes the unit disk $D$ to itself. Further let us assume it fixes zero--where in addition $f^{\circ n}(\xi) \to 0$ for all $\xi$ in the unit disk as $n\to \infty$. A fractional iteration (defined in the sense I am concerned with) is a holomorphic function $f(z,\xi)$ (holomorphic in $z$ and $\xi$) such that $f(z,\xi) : S \times D \to D$ where $S$ is open and connected, and furthermore $S$ is closed under addition of its elements. Additionally we are given the semigroup property $$f(z_0,f(z_1,\xi)) = f(z_0 + z_1,\xi)$$ and the initial conditions $f(1,\xi) = f(\xi)$ and $f(z,0) = 0$. In the case where $f'(\xi_0) = \lambda$ and $0 < | \lambda| < 1$, it is possible to produce countably infinite versions of these complex iterations where $S$ is some half plane containing $\mathbb{R}^+$ and $S$ depends on our choice of which fractional iteration we are speaking of. But this is not the case I am concerned with. Instead I am concerned with the case where $\lambda = 0$, i.e: the case where $0$ is a super attracting fixed point. My intuition is telling me that no such fractional iteration exists in such a case. To explain my reasoning, simply consider $f(\xi) = \xi^2$ wherein a natural choice for an iteration is $f(z,\xi) = \xi^{2^z}$, however this function is no longer holomorphic in a neighbourhood of $0$ in $\xi$. We get branch cuts speaking simply. Extending this idea, let us assume without loss of generality the Taylor expansion of $f$ starts with $$f(\xi) = \xi^n + ...$$ so that $$f(f(...(k\,times)...f(\xi) = \xi^{n^k} + ...$$ giving the notion that a suitable $f(z,\xi)$ will probably start out $$f(z,\xi) = \xi^{n^z} +...$$ implying no fractional iteration exists. However this is far from a proof. I've boiled the question down into one single idea. Assume that such a fractional iteration exists and consider the BÃ¶ttcher function. For those who may not remember this, or know of it, it is defined by the following limit $$F(\xi) = \lim_{k\to\infty} \sqrt[n^k]{f^{\circ k}(\xi)}$$ wherein $F:D \to D$ and $$F(f(\xi)) = F(\xi)^n$$ Therein the final result will follow if we can show that our candidate fractional iteration $f(z,\xi)$ satisfies $$F(f(z,\xi)) = F(\xi)^{n^z}$$ for some branch of this multivalued function, therein showing that $f(z,\xi)$ cannot be holomorphic in a neighbourhood of zero. This reduces the question to something smaller, that there exists no fractional iteration of $\xi^n$--but even showing this is causing me grief. I feel like I'm missing something small, but I'm not sure what I am missing. All in all, I'm asking either for a proof or a reference or suggestions on where to look to solve this odd looking problem. It would also be really neat if someone could find a counter example to this statement--an example of a holomorphic function with a super attracting fixed point with a fractional iteration attached to it. 

What are the functions verifying: $$\int_0^{\infty} f(t) \cos(2\pi xt)=\lambda \frac{1}{x} f(\frac{1}{x})$$ With $\lambda$ a constant ? (Functions $x^{-\alpha}$ with $0<\alpha<1$ are solutions but can we find other solutions?) 

I would like to calculate the definite integral with K-Bessel funcitons and a and b complex (n and k integers): $$\int_{0}^{\infty} x \;K_{a}(nx) \; K_{b}(kx) \; dx$$ I could not find it in litterature with a and b complex (We have $Re(a)<1$ and $Re(b)<1$ for convergence in zero!). Any reference or help on this subject is welcome. 

Can we interchange the order of integration of following double integral ? $$I = \int_{0}^{1} \int_{0}^{\infty} F(x,y) \overline{R(x,y)} - R(x,y) \overline{F(x,y)} \; dx \; dy$$ Where $F(x,y)= \sum_{n=1}^{\infty} f(nx) e^{2 i \pi n y}$ and $R(x,y)= \sum_{n=1}^{\infty} x^2 n^2 f(nx) e^{2 i \pi n y}$ With $f(x)$ a function from $\mathbb{R^+}$ to $\mathbb{C}$, exponentially decreasing at infinity, such that near zero the asymptotic is $f(x)= a.x +O(x^2)$ ($a$ is a complex constant) and $\int_{0}^{\infty} f(x) dx=\int_{0}^{\infty} x^2 f(x) dx=0$ If we could interchange integration order we would have immediatly $I=0$: $$ I= \int_{0}^{\infty} \sum_{n=1}^{\infty} f(nx) \overline{x^2 n^2 f(nx)} - \sum_{k=1}^{\infty} x^2 k^2 f(kx) \overline{ f(kx)} \; dx =0 $$ The integral $I$ can also be written (for $n$ and $k$ strictly positive integers) : $$I= \int_{0}^{1} \int_{0}^{\infty} \sum_{n \ne k} f(nx)\overline{k^2 x^2 f(kx)} e^{2 i \pi (n-k) y} - n^2 x^2 f(nx)\overline{ f(kx)} e^{2 i \pi (n-k) y} dx\; dy$$ $$I= \int_{0}^{1} \int_{0}^{\infty} \sum_{n \ne k} (n^2-k^2) x^2 f(nx)\overline{f(kx)} e^{2 i \pi (n-k) y} dx\; dy$$ So showing we can interchange integration is equivalent to show that following integral is well defined: $$ \int_{0}^{1} \int_{0}^{\infty} | \sum_{n \ne k} (n^2-k^2) x^2 f(nx)\overline{f(kx)} e^{2 i \pi (n-k) y} | dx\; dy$$ But how can this be proved? I post a similar question here: Is this double integral of Fourier series always real? Note: $I$ is well-defined as $\sum_{n=1}^{\infty} f(nx) e^{2 i \pi n y} $ and $\sum_{n=1}^{\infty} n^2 x^2 f(nx) e^{2 i \pi n y}$ do not have any singularity for $x$ near zero (this can be shown using Poisson summation formula, even for $y=0$ there is no singularity as we have $\int_{0}^{\infty} f(x) dx=\int_{0}^{\infty} x^2 f(x) dx=0$). 

I thought of this in a more general setting though. I wondered if it happened for $e^{-y^2}$, does it work for other functions? It may be useful to explain the ad hoc arguments I had when I was younger. These arguments were a summation of identities which are satisfied by both expressions, which seems implausible if they weren't equal in some sense. I'll explain them in the obtuse language I used when I was a first year, as it is the best way I can think of framing it. Let $\mathcal{I}$ and $\mathcal{S}$ denote the following operators, $$\mathcal{I} \{f\} (x) = \int_{-\infty}^\infty f(y)\frac{x^y}{\Gamma(y+1)}\,dy$$ $$\mathcal{S} \{f\} (x) = \sum_{n=0}^\infty f(n) \frac{x^n}{n!}$$ Also, let $Qf(x) = xf(x)$ and $Tf(x) = f(x+1)$. Then $\mathcal{S}$ and $\mathcal{I}$ behave identically under actions of the two operators. The following similar identities present evidence as to why these two operators may be equivalent in a good enough scenario. $$\mathcal{I}\{Tf\}(x) = \frac{d}{dx}\mathcal{I} \{f\} (x)$$ $$\mathcal{S} \{Tf\} (x) = \frac{d}{dx}\mathcal{S} \{f\} (x)$$ $$\mathcal{I}\{Qf\}(x) = Q\mathcal{I}\{Tf\}(x) = Q\frac{d}{dx}\mathcal{I} \{f\} (x)$$ $$\mathcal{S} \{Qf\} (x) = Q\mathcal{S} \{Tf\} (x) = Q\frac{d}{dx}\mathcal{S} \{f\} (x)$$ From these we also get $$Q \mathcal{I}\{f\}(x) = \mathcal{I}\{QT^{-1}f\}(x)$$ $$Q \mathcal{S}\{f\}(x) = \mathcal{S}\{QT^{-1}f\}(x)$$ From all this the question is simple, 

Consider $f(x)$, a rapidly decreasing function, such that $\int_0^{\infty} f(x)=0$ and for $x$ near zero: $f(x)=O(x^a)$ (wit $a>0$). Can we interchange the sum and integral and write as below: $$\int_0^{\infty}\sum_{n=1}^{\infty} f(nx)= \sum_{n=1}^{\infty} \int_0^{\infty} f(nx) =0$$ Note that, as $\int_0^{\infty} f(x)=0$, the Poisson summation formula (thanks to the limit of $f(x)$ in zero) ensures that: $\sum_{n=1}^{\infty} f(nx)\sim O(x^a) \;\; (x \to 0)$ so the integral on the left in above expression is well defined. We cannot apply directly the classical interchange theorems as: $\sum_{n=1}^{\infty} |f(nx)| \sim O(\frac{1}{x})$ and even if we have simple convergence of the sum, the partial sum $|\sum_{n=1}^{N} f(nx)|$ cannot be bounded near zero for all N (even if the complete sum is absolutely integrable). So is there way to show we can interchange or two sums are different, and if it is the case how can we show it ? 

This function $G(x)$ is not periodic, even if the terms of the sum are the same. The fact to add a rational number $\frac{c}{d}$ changes the order of summation of the terms and finally the sum defining $G(x+\frac{c}{d})$ exists but is different from $G(x)$. Suppose $G(x)$ is $\mathbb{Q}$ periodic then as $G(x)$ is also equal to: $$ G(x)=\sum\limits_{q =1}^{\infty} \sum\limits_{m=1}^{\infty} q \; f(qm) e^{2 i \pi mqx} = \sum\limits_{n =1}^{\infty} A_n e^{2 i \pi nx} $$ (here we can change the order of summation as the sum is absolutely convergent!), with the $A_n$ such that $\sum\limits_{n =1}^{N} A_n $ converges (as $f$ has been chosen fast decreasing ). It means $\sum\limits_{n =1}^{\infty} A_n e^{2 i \pi nx} $ converges uniformly so that $G(x)$ is continuous. Therefore the function $G(x)$ should be constant and its Fourier coefficient should be zero except the constant term and this is not the case, so $G(x)$ cannot be periodic. 

L2 is transitive: Let L2(u1,u2), L2(u2,u3). Then L2(u1,u3). There are three ways such automorphisms can interact (with 1, 2 or 3 common values). Composing such automorphisms multiple times gives us new automorphisms of A2 containing (u1/u3). If $(a/b)(c/d), (c/d)(e/f)$ are automorphisms, then $(c/d)$ is an automorphism. 

The second theorem actually tells us, that each transposition can have at most one witness (otherwise a single transposition would be an automorphism, which violates the definition of A2). This means, that automorphisms of A2 can not interact as shown in a) - (u1/u3) is a second witness of (a/b), neither c) - (v1/v2) has two witnesses. They can interact only as shown in b). L2 splits U into equivalence classes. These classes group into pairs of the same size, such that every two elements of one class have some witness transposition in another class. To check, if $P \in G$, I first check, if P keeps each element inside its L2-equivalency class. I thought, that composing elements of A2 creates "ladders", that there is 1-to-1 mapping F between two L2-equivalence classes ($F(u1)=v1, F(u2)=v2, F(u3)=v3$) and it will be enough to check, that $P(a)=b \implies P(F(a)) = F(b)$, i.e. that automorphisms in $G$ can shuffle the elements in any way possible, as long as each element remains in its L2-equivalency class and the same shuffling is performed on the other side of the ladder. But what if there is $(u0/u1)(v0/v2) \in A2$, which will break the ladder structure, and then the map F makes no sense? I can not disprove it. Can you see any other useful properties, which can help me decide, if $P \in G$? Example: $R = \{(0,2,3), (1,3,2)\}$, the automorphism is $(0/1)(2/3)$, however, the map F is not unique (you can match 0 with 2, 1 with 3, or 0 with 3 and 1 with 2). But I think, that when L2-classes are larger than 2 (taller ladder), F will be unique. 

I want to calculate / simplify: $$\mathcal{F} (\ln(|x|)\mathcal{F(f)}(x))=\mathcal{F} (\ln(|x|)) \star f$$ where $\mathcal{F}$ is the Fourier transform ($\mathcal[f](\xi)=\int_{\mathbb R}f(x)e^{ix\xi}\,dx$) and where $f$ is an even function. Looking here: wiki, we find that $$\mathcal{F}[\log|x|](\xi)=-2\pi\gamma\delta(\xi)-\frac\pi{|\xi|},$$ so we should have: $$\mathcal{F} (\ln(|x|)) \star f = (-2\pi\gamma\delta(x)-\frac\pi{|x|}) \star f(x) $$ $$ = -2\pi\gamma f(x)- \pi \int_{-\infty}^{\infty} \frac{f(t)}{|x-t|} dt $$ but the integral of the second term does not converge... whereas the term $\mathcal{F} (\ln(x)\mathcal{F(f)}(x))$ is well defined providing the function $f$ is of rapide decrease near zero and infinity. So where is the problem ? and what is finally the "simplified expression" of $\mathcal{F} (\ln(x)\mathcal{F(f)}(x))$ ? We cannot use this distribution in a convolution product with a function? I already post this on Stackexchange but did not receive an answer. 

There is the conjecture that Selberg Class L-functions satisfy RH. So that an L-function needs to have its coefficient multiplicatives (plus other conditions: functional equation,...) in order to satisfy RH. But I would like to know if for a L-function of Selberg class it is possible to find another L-function having the same non trivial zeros (strictly in the critical strip) but having "the sum of its coefficient" bounded instead of "multiplicative coefficients". Meaning that for a L-function of Selberg class $L(s)= \sum a_n n^s$ with multiplicative coefficient $a_n$ there is another L-function $L_1$ (of Selberg class or not) having same non trivial zeros as $L(s)$ such that $L_1(s)= \sum b_n n^s$ with $\exists K, \forall N, |\sum_{n=1}^{n=N} b_n| \le K$ For primitive Dirichlet L-functions the function is itself satisfying the condition. But for the Zeta function we need to multiply it by $(1-2^{1-s})$ in order to obtain the Dirichlet Eta function which has the same zeros (strictly in the critical strip) as Zeta with the sum of its coefficient bounded. (And no more multiplicative property for its coefficients) Any existing results on this question ? May be it is obvious that such equivalence does not always exists?