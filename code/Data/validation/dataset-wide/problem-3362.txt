Hominis and agricolae are not in any way "less" fusional than andrôn — because singular is not an absence of number. They combine singularity and genitivity. As opposed to agglutinative examples such as the Turkish evde "in the house" where -de only carries the locative, and the singular is technically expressed by a null ending: ev.Ø.de, as demonstrated by ev.ler.de "in the houses". 

When listening to recordings of spoken Albanian, I sometimes note what sounds like a retroflex /r/; it's less pronounced than in American English, and seems to occur in syllable codas. Now Albanian phonology resources say the language does have two /r/s, but they're a flap and a trill like in Spanish (and reflected the same way in writing, as r vs. rr). Neither does the Wikipedia page for the sound list Albanian among the languages that have it. Is it a dialectal feature? Or am I hearing things? 

The question worth asking here is, how "instrumental" is the Slavic instrumental really? "Instrumental" is just a name that grammarians gave it, after its most common usage; but I don't think the pre-literate speakers of Proto-Slavic would think of it as a case for expressing instrumentality. To them, it just was what it was. The case for instruments and passive-sentence agents, as well as the case for times of day/year, as well as the case required by the prepositions for "behind" and "in front of", as well as the case for being or becoming, as well as the case for modes and manners (every -sky adverb in every Slavic language is historically an instrumental, plural, neuter adjective. По-русски is a technically ungrammatical contamination of rusьsky with po rusьsku.) And that latter meaning can probably elucidate how instrumental "felt" to speakers of Proto-Slavic — as a "modes and manners" case, which could equally be modes of doing — as in *maltomъ "with a hammer" or *slověnьsky "in Slavic", "the Slavic way" — or modes of being, as in *byti dobryjimъ "to be good". Or circumstantial modes such as *noktijǫ "at night". 

This is a sign with a straightforward relationship between signifier and signified. The arrangement of the hands is the signifier and the signified is that it's 3 o'clock. Signs like this, as the author says, are much more limited than language. The clock has a couple of possible meanings: perhaps it's 3 a.m. and not 3 p.m., and perhaps it's that time in Seoul rather than Los Angeles. But it can't do anything but tell you the time. Whereas (it is argued) language is a system of signs allowing you to express essentially any meaning. 

I don't feel we have enough context to judge the full argument, but going by what you've quoted, it seems that his line of argument is indeed that composing a symbol such that it has a compound meaning but no relationship to a compound pronunciation is problematic, because you dissociate the symbol from the pronunciation. You make it arbitrary and unpredictable. The implicit conclusion is that readers of such a writing system will have a harder time with literacy and (to go a step further that I will soon explain) with cognitive processes supposedly tied to literacy. I consider your counterexample from Chinese excellent. In reality this dissociation does not appear to be a hindrance to reading. However, the fear Seidenberg expresses is not a new one. It rests on the opposite premise: that there are writing systems where there is an association between symbol and pronunciation, and that the pronunciation is predictable. This of course refers to alphabetic or syllabic writing systems. Fundamentally, we can't escape the arbitrariness of the relationship. That the symbol < a > makes (in many languages) the sound we transcribe /a/ is an utterly contingent fact. However, we can combine these letters in more or less predictable ways and thereby make the pronunciation of new words predictable. In English this doesn't work so well, but if we take a spelling-reformed language like Spanish we can observe that an invented word like calabrenoda will be accurately pronounced by all speakers. I presume you know all this. What might be surprising is the importance that has been attached to this fact in the past. Keep in mind that language theorists have historically (before linguistics became more of a science) identified random features of their own language and argued for their being the key to the cultural superiority of speakers of their language. The argument generally runs along one of two lines: (a) The mysteriousness/power of the feature shows that the language is highly expressive and poetic ("see how many meanings arise out of one word; how subtle is the English mind!"); or (b) the regularity/sense of the feature shows that its speakers have a naturally logical mental bent. Such arguments, incidentally, are used first and foremost to further political or sociological ends; for example, such linguistic observations were used by medieval Christian critics to argue (along nonsensical lines) that Hebrew was an inherently backward language, aligning with their conviction that Judaism was an inherently backward religion. However, such arguments are not extinct in our day. One recent theorist who argues for the significance of the compositional quality is Kieran Egan, e.g. drawing from Vygotsky in The Educated Mind. For Egan, there is a succession of stages that humans and human cultures move through in terms of refinement of thought, and each succession requires that they have certain cognitive tools. He argues that having an alphabetic writing system lends itself to developing the cognitive tools to move on to the next stage. Therefore, for him, cultures whose language has a less phonologically transparent writing system are at a cognitive disadvantage. One example he cites is that of an indigenous people in Russia who were subjected to a logic test involving syllogisms: "Everywhere in the north is snowy; Siberia is in the north; is Siberia snowy?" They responded, "I don't know. I haven't been there." He claims that their inability to understand syllogisms (as he reads that exchange) can be attributed to the lack of what he considers a sophisticated, i.e. phonologically transparent, writing system.* So that's where Seidenberg's argument may be tending towards—I'm speculating. Now, is that view valid? I would tend to side with you and your objection, partly because of that history I referred to. Linguistic features have been tied to cultural superiority questions for a long, long time and rarely with any good reason. Is China exactly a backwards society? I think not. To address the question more head-on might require some good, hard data on literacy (% among population, age first learned, grade reading level, etc.) among Chinese students with comparable education to that of English students or students of other languages whose language is alphabetic. But intuitively I strongly suspect that there is not a significant discrepancy. Again, this whole answer rests on reading a lot into a short quotation from Seidenberg. :) * If I had my book with me I would cite the passage. I will try to remember to return to it when I'm home. 

-ben: after z, ž -pen: after unvoiced consonants and b, d, g, v -men: after vowels, sonorants and possessive forms (the latter is irrelevant here) Source (in Russian): $URL$ Consonant assimilation in suffixes is as typical of Turkic languages as vowel harmony. 

I'd venture this guess: both "wash" and "bear" stem from the same observation. Bears are part-time bipeds who occasionally use their forepaws as "arms"; raccoons appear similarly humanlike when engaged in their washing behaviour. A similarity in body shape and fur colour reinforced the association, but probably wasn't its starting point. 

It didn't. English used one prefix to derive this meaning from the more general root for taking; French used another. You can turn it around and ask, from a French speaker's perspective, how the English under "sous, sou-" evolved to mean "entre". While we're at it, Russian formed its word for undertaking by adding the equivalent of "fore-" or "pre-" to the equivalent of "receive" or "accept". The starting point may be more or less the same ("take"), the end point may also be the same ("undertake"), but individual languages simply took different paths to get from one to the other. I don't see a reason to use any specific version as a semantic standard. 

Many languages have such an ambiguity built in. It's very common that you can't tell the morphosyntactic properties of a word or even its phonological interactions just from its form, even given certain generalizations. 

Interestingly, you can actually hold those sounds, in a way. The nose is a second air channel. Try holding 'nnn' for a while. You'll find that what you're doing is putting your tongue where you make 'd', and letting air pass through the nose. These "nasal" sounds are almost as loud as vowels. 

Notice that the last one requires a few qualifying predicates; I can't even say Catholic or identify a single country they went to, at least by name. And it might still not be enough for you to realize that I mean the Jesuits. Even worse, we may not know the same things about them. You might think I mean some other set of missionaries because you don't happen to know how many continents the Jesuits have been to or in which century the society was founded. Moreover, we might not even agree on a predicate. You and I could talk about "the greatest English writer" and I could be talking about Shakespeare when you mean Ian McEwan. Those are the cases that would be harder to write. Incidentally, even proper nouns aren't always enough to do this job. If you address "Luke" now, we know you mean me. But if there are two people named Luke in the room, you have to say "Luke S." or "Luke A." But what if a person's full name isn't unique? Say there are two people named Luke Sawczak. Now you have to fall back to the same strategies shown above: "The Luke Sawczak who was born in Canada" or "That one there"... and in sentences like those, the name looks awfully like a common noun, not a proper noun. 

The "why" of it is essentially a question of whether the participle refers back to the subject. The être verbs all refer to a changed state of the subject — which is particularly obvious with naître, mourir, tomber and rester. Now you might ask: why just those thirteen verbs? Aren't there many more that can be construed to involve a change of the subject's state, and hence require "be" rather than "have"? Why is "I have grown up" J'ai grandi, not *Je suis grandi? That's a reasonable question. In fact, there are languages that are more consistent about be/have, such as Danish: Jeg er vokset op "I have ('am') grown up", as opposed to Jeg har set noget "I have seen something". It must have been the case with French at some point as well, before avoir began to take over, so that only thirteen être verbs remained in the end, most likely because they were common enough for their existing perfect forms to survive as set phrases. 

As a native speaker of Russian, where [k]/[kʲ] and [g]/[gʲ] are phonemically distinct, I've always been intrigued by the fact that several languages that don't have that distinction, and are in fact hardly "into" palatalisation at all, tend to favour what I'd describe as [kʲ] and [gʲ] realisations over "plain" [k] and [g], or at least go for something in between. This includes many varieties of English, as well as French, Swedish, Persian, and perhaps some others that I'm not aware of. In most if not all of these cases, the plain and palatalised versions co-exist as allophones, depending on position; [kʲ]/[gʲ] is especially frequent word-finally. On the other hand, this doesn't happen to any other consonants: the English take, depending on the speaker, is about equally likely to be pronounced as [teɪk] or as [teɪkʲ] (or close to it), while in no English accent does tape even remotely sound like [teɪpʲ]. Also, the phenomenon appears to be rather sporadic; it exists in French but not in Spanish, in Swedish but not in Danish. Have there been any studies or proposed explanations as to why and under what conditions these palatalised allophones develop? 

Several of the 20 or so articles that I checked have decent numbers of reads, downloads and citations for the field (ranging from a half-dozen to a few dozen). Tellingly, however, almost every abstract includes a line qualifying the phenomena as "not widely accepted", "contradictory to the principles of linguistics", or "not yet well understood or explained". The abstract of Nuckolls' 1999 review says this: 

Rhotics aren't a special case here. They will still either be deleted or be replaced with the sound that is perceptually (to speakers of the receiving language) closest to the original sound. English's /r/ [ɹ̠] is similar to /n/ and /l/ among others. For example, in the Algonquian language Innu, English /r/ tends to be replaced by /n/: 

The paradox is how a word that means "head" came to mean "subdivision". We have to switch our point of view: Looking at a book, the chapters are subdivisions. But looking at the mass of words, each chapter heads a group of them. The chapters of an organization are branches of the whole, but in terms of the members a chapter collects them under a single head(ing). And again, the world has any number of things that are grouped into the "categories" of definition 2. And not just any sections, but the "main" sections of definition 1c. To start with, anyway. So a chapter is a "head" not looking from the top down, but from the bottom up. 

Both you and your friend are framing in terms of "simplicity" vs. "complexity" what's really a slightly different issue, etymological transparency vs. etymological opacity. Or, in the most basic terms, native vs. borrowed. Most people speak a language that has a layer of "erudite" vocabulary borrowed from the language of a more influential, and usually "older", culture: depending on where you are in the world, it's usually one of Latin, Chinese, or Arabic. This means there are certain lexemes, and sometimes a certain amount of grammar, that you have to learn from scratch on top of your native language if you are to understand this "erudite" layer. For example, most speakers of English can break down the word "independence" as far as "depend", which is still a borrowed "erudite" word; speakers of Romance languages have it easier, since the Latin root is still transparent to them as meaning "hang", in the most everyday sense, and so indépendance or indipendenza still discernibly contain the metaphor of no longer "hanging off" of something (over a presumed cliff). So the solution — if you choose to think of this as a problem — is not in "pruning" the language, but in nativising its vocabulary. It's already been done in a lot of languages; the German Unabhängigkeit, or the Russian nezavisimost', are exact translations, or "calques", of the Latin independentia: "non-off-hang-ing-ness". That said, both Russian and German still contain a lot of Latin vocabulary, although much less that English. Very few languages have gone the way of near-complete nativisation, Icelandic being one famous example. It's hard to tell whether it did or did not lead to any greater political awareness, but it clearly involved no "pruning" of the language — if anything, it was the opposite, a massive infusion of new words. Another point must also be raised: political vocabulary is essentially jargon, no different in principle from the jargon of seafaring or video gaming. By which I mean, it developed as a form of communication between people with specific shared experiences, trading transparency of meaning for speed, efficiency, and not the least, the ability to identify with the group. The reason we have Latinate political terms such as "consensus" was that, a long time ago, it was part of a jargon shared by people who (1) knew Latin and (2) had political phenomena as part of their everyday experience; then it was handed down generations to people who didn't necessarily know Latin anymore, but for whom a certain amount of Latin vocabulary came with the job requirements (as well as general social status). It's understandable that they weren't in any way motivated to abandon this vocabulary in favour of something more transparent to the less educated populace — unless they were of a specific type of political creed, nationalist or "national revivalist". Movements of that sort in several different countries have in fact affected many languages, and in a generally positive way at that. But they were dedicated movements. By default, it's still up to the individual speaker whether they feel it necessary to expand their vocabulary with Latinate (or, say, Arabesque) political jargon. Not everyone has equal opportunities here, as regards time investment and the availability of knowledge (though that's less of an issue now that we have the internet). So your friend has a point. "Complex" speech isn't necessarily always inherenty valuable; often it exists just because a relatively small circle of people has found it convenient. However, you can't just decree a sweeping language reform, or manufacture the political will and popular support for it out of thin air. It's still mere reality of life that if you want to understand politicians, you might have to take time to learn new words. I'm not sure, however, that this is one of the "better" reasons, or that such better reasons even exist, beyond the most basic "knowing more is better than knowing less". 

Thoughts on inter- vs. intralinguistic patterns My own thoughts: I find the subject interesting as regards sounds' perceptual value. I always think of an anecdote of my mother's. She spent some time in India in her youth, and one day asked a man what he thought was the most beautiful word in Hindi. He immediately answered: "The word for 'lady': begum!" Savouring the word, he repeated: "Begum!" The usual response to this story is laughter. Why? Because to a North American English speaker, no word that sounds like begum could mean "lady". This tells us two things: One, that intuitions about which sounds have which meanings are not universally shared interlinguistically. Two, that there is nevertheless some intralinguistic consistency. To poke more holes in the interlinguistic hypothesis: Find someone who doesn't speak a language that you do. Ask them to guess the approximate meanings of ten words (not cognates of ones they know). The study on synesthesia I quoted mentions that people guess word meanings correctly at above-chance rates. My own anecdotal evidence suggests that they don't have a chance when the question is open-ended, testing between the utterly unrelated Hebrew and English. But I do believe in the effects within a language. Even if people don't have intuitions about the meanings of digraphs like gl- or sn- (at least I don't), speakers of the same language do share vague affective perceptions like those about begum — or about bouba and kiki, for that matter. And you can create new words with fairly reliable categorizations, at least if you make the categories as extreme as opposites. How many English speakers would fail to categorize Galadriel and Mordor correctly into good and evil?2 The Wikipedia article mentions that phonesthetic phenomena may be due to priming, which makes sense to me. Even if there's no reason why a woman should be called a begum or a lady, once a language settles on one or the other, speakers may make similar judgements about other words using the same sound configurations. The first connection is arbitrary, but later words can be derived from or influenced by it. Over time, perhaps that could even account for a tendency — far from a scientifically predictable rule — for phonological clusters to form semantic patterns. 2 When the categories are arbitrary, opinions become unreliable. I wonder how many of us would disagree with Monty Python's sorting into "tinny" and "woody" of gone, newspaper, litterbin, sausage, antelope, seemly, prodding, vacuum, caribou, leap, and bound? 

O is basically just a circle, so unlike with C/G, the visual similarity with Q is trivial. You could equally wonder if C being O with a chunk taken out has to do with anything. Q and O derive from two different Phoenician letters, qop and ayin; back then, they actually did have something in common since both were "throaty" consonants; however, since the shape of the letters is ultimately hieroglyphic, the similarity is either accidental or — if we credit the theory that the hieroglyphic meaning of qop was "eye of a needle" — based on a real-world visual similarity, since ayin/O represented a (literal) eye. 

I suppose "palatal" is a misnomer. In Slavic languages themselves, they are termed, literally, "soft consonants" (Czech: měkké souhlásky, Slovak: mäkké spoluhlásky). While palatalisation is sometimes called "softening", one doesn't customarily speak of "softened" consonants, but of soft/hard "pairs" or "counterparts". This Slavic choice of adjective referring, as it were, to being and not becoming, may have influenced the author's not-quite-correct choice of "palatal" instead of "palatalised". Also, I don't think it's correct to call palatalised, when it obviously has no non-palatalised counterpart. Also, if those quotes are complete, they fail to mention the Slovak-only . So I'd put this down to simple carelessness. 

As I'm sure you know, there are many ways to create neologisms. (Here are a few I summarized in a student paper as a bright-eyed, bushy-tailed undergrad.) It would be fair to speculate that borrowings using Latin roots are far outnumbered by some of the other means active today. The number of people with direct access to Latin has certainly declined over the last century. It is far from a given that a given person's higher education includes Latin. Moreover, the sort of people who do speak it are not often the movers and shakers in terms of neologisms (new words tend to come from popular, not esoteric, groups of people). Therefore, the chances are low of widespread neologisms entering English based on a direct firsthand borrowing from Latin. But there are many Latin roots that have essentially become English roots. That a morpheme can be traced to a Latin root is not a reason to say that new words formed using it are "using Latin". Take the relatively recent word metrosexual. The OED and etymonline.com agree that "metro" is from "metropolitan", a word that English has possessed for at least 500 years, and "sexual" is so ubiquitous in English that no one would say we had to look to Latin to use it in a neologism. Therefore, we can describe this as mere derivation. English is merely "borrowing" from English. If that's what you're referring to, then yes, I predict that those "Latin" roots will continue to be productive for a long, long time. Even if we're more likely to form new words by other means.