Following Eric Wofsey's point, you probably are interested in things that don't involve the pathologies of arbitrary uncountable objects. Some people have argued that the only things "ordinary mathematicians" care about are things that are representable in second-order arithmetic. (This gives you arbitrary real numbers, arbitrary complete separable metric spaces, Borel and analytic sets on all of those, and similarly interesting amounts of algebraic stuff.) The project of Steven Simpson's book Subsystems of Second-Order Arithmetic is to analyze just what axioms are needed to prove which results. All of the things considered there are far weaker than ZFC. But it's interesting to discover that beyond the axioms of Peano Arithmetic and the existence of arbitrary recursive sets of natural numbers, there are exactly five natural strengths. That is, there are five levels such that very large numbers of theorems from ordinary mathematics fall at exactly one of the levels, where any theorem at one level can be proved by assuming any theorem at that level or higher. Interestingly, things like the Heine-Borel theorem and the Bolzano-Weierstrass theorem, which are often thought of as equivalent, actually fall at different levels. Not everything falls exactly at these levels though. Some things do still depend on a version of the axiom of choice, which is above any of these five levels, and there are other results like Goodstein's theorem and Borel determinacy that are higher still (I believe). 

As John Goodrick is asking in a few places, you have to be careful in stating what you mean by "a model of the reals". If you're going to talk about sets of reals, then you need to have variables ranging over reals, and also variables ranging over sets of reals. You also of course want symbols in your language for the field operations and ordering, and possibly more. Three Options One way to do this is to use the language of second-order analysis, which is bi-interpretable with the language of third-order number theory. (It's straightforward to translate between real numbers and sets of natural numbers, and then between sets of real numbers and sets of sets of naturals.) Another way to do this is to use ZF, which talks about the reals and sets of reals, but also many many other things. (Far more than any mathematician who's not a logician (or perhaps category theorist?) ever uses.) There's also an intermediate strategy, which is basically what Russell and Whitehead did in Principia Mathematica, where you have some variables ranging over objects at the bottom (which might be real numbers, or anything else), and then variables ranging over sets of objects, and then variables ranging over sets of sets of objects, and so on to arbitrarily high levels. This is still far weaker than ZF, because you don't get sets that mix levels, and you also can't make sense of infinitely high levels. First-order and Higher-order logic If you take the first or third option, then you have two more choices, which correspond to what David Speyer was saying. You can require that variables that range over sets of things range over "honest subsets" of the collection of things they're supposed to be sets of. Or you can interpret the set variables in a "whacked model". (The technical term is a "Henkin model".) On this interpretation, the "sets" are just further objects in your domain, and "membership" is just interpreted as some arbitrary relation between the objects of one type and the objects of the "set" type, and you interpret all your axioms in first-order logic. The difference is that the honest interpretation uses second-order logic, while the Henkin interpretation just uses first-order logic. Second-order logic (and higher-order logic) is nice in that it lets you prove all sorts of uniqueness results - there is a unique model of honest second order Peano arithmetic, and if you require honest set-hood then this means there will be unique models at the third order level and higher, giving you one result that you remember. But first-order logic is nice because there's actually a proof system - that is, there is a set of rules for manipulating sentences such that any sentence true in every first-order model can actually be reached by doing these manipulations. That is, Gödel's Completeness Theorem applies. However, his Incompleteness Theorems also apply - thus, there are lots of models of first-order Peano arithmetic, and then there are even more Henkin models of "second-order" Peano arithmetic, and far far more Henkin models of "third-order" Peano arithmetic, which is the theory you're interested in. Unfortunately, I don't know what these Henkin models look like. It all depends on what set existence axioms you use. There's a lot of discussion of this stuff for "second-order" Peano arithmetic in Steven Simpson's book Subsystems of Second-Order Arithmetic, which is the canonical text of the field known as reverse mathematics. However, none of that talks about arbitrary sets of reals, which is what you're interested in. Solovay's results The other result you mention, which is cited in one of the other answers here, takes the other option from above. That is, we do everything in ZF and see what different models of ZF are like. (Note that I don't say ZFC - of course if you have choice, then you have non-measurable sets of reals.) Every model of ZF has a set it calls ω, which is the set it thinks of as "the natural numbers". Set theorists then talk about the powerset of this set as "the real numbers" - you might prefer to think of this set as "the Cantor set", and some other object in the model of ZF as its "real numbers", but there will be some nice translation between the Cantor set and your set, that gives the relevant topological and measure-theoretic properties. Of course, since we're just talking about models of ZF, none of this is going to be the real real numbers. After all, since ZF is a first-order theory, the Löwenheim-Skolem theorem guarantees that it has a countable model. This model thinks that its "real numbers" are uncountable, but that's just because the model doesn't know what uncountable really means. (This is called Skolem's Paradox - $URL$ $URL$ Encyclopedia of Philosophy.) What Solovay showed is that if you start with a countable model of ZFC that has an inaccessible cardinal (assuming that inaccessibles are consistent, then there is such a model, and we have almost as much reason to believe that inaccessibles are consistent as we do to believe that ZFC is consistent) then you can use Cohen's method of forcing to construct a different (countable) model of ZF where there are no unmeasurable sets of "reals". Of course, the first result you stated (that any two models of the reals are isomorphic) holds within any model of set theory, assuming you're talking about "honest" second-order models (that is, models of reals that are "honest" with respect to the notion of "subset" that you get from the ambient model of ZF). But the notion of "honest" second-order model doesn't even translate when you move from one model of set theory to another. So Solovay's model of ZF has the property that every "honest" model of second-order analysis (or third-order number theory) has no non-measurable sets, while any model of ZFC has the property that every "honest" model of second-order analysis (or third-order number theory) does have non-measurable sets. That's how your two results are consistent.