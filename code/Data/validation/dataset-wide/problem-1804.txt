This might already be what your doing but, here is a thought. If the contents of sample are only to be accessed via FTP then you can move that directory outside the web server's document root and use your 0775 with owner=user and group=nobody plan. The php script will be able to write, user will be able to use FTP and the outside world will not be able to get at sample through the web server. 

Be sure to try generating lots of different types of failed login attempts. Try from X (gdm or kdm or xdm), try from the console, try from ssh, try from sudo and try from su. Different subsystems can (and will) be configured different ways. It's not uncommon for ssh to be configured to use an internal login command that cuts around the /var/log/btmp business. Try the command as well. You might look in /var/log/secure to see if your failed login attempts are being stored there. But, I'm afraid I don't know the structure of the Debian log directory. Try on anything in the /var/log directory. It's quite likely that ssh is logging something someplace. 

You should try the Django work without any restarting of apache. Most sever side environments work fine while doing development work without any need for stopping and starting the web server over and over again. But, yes you can run any number of apace instances as long as you make sure your second server's config file is pointing at different resources. Like: 

I'm assuming, possibly incorrectly that your users are sitting in from of the windows boxes and need access to some linux gui applications. VNC works very nicely. Most Linux distributions have a the server sides vnc x-server included these days. Get a compatible windows vnc client and you should be good. If you need some additional security look for the ssl-enabled vnc stacks that are starting to crop up. Getting a windows side xserver like the one in cygwin will also works but is more complicated and will be much harder to explain to windows users. If your users are already linux savy this won't be to bad, otherwise go with vnc. 

About serving static files. Yes, you can use a lighter web server to do this. But, before you go to the effort be sure that it will do you any good. Is apache really using resources you need elsewhere? Maybe just configure apache to not start quite so many child processes. Be sure the added complication will pay for itself, because down the road it will almost assuredly confuse somebody when they try to figure out how everything is working. 

It isn't uncommon to find the device in each location that is making the VPN connection is also capable of acting as a DHCP server - e.g. Cisco ASA, Linux server, pfsense, m0n0wall. Depending on the capacity of the device and number of clients at the site, this might be worth taking advantage of. This is particularly useful where there may be site specific configuration you want to push out via DHCP. For example, you might want to include a public DNS server in the list of DNS servers assigned, so in case the VPN fails, but the Internet is up, people at the remote site can access public resources even if your central DNS is unreachable. It is also a lot easier to visualise/explain this way. 

The Cloud is lots of things. It basically means you don't care where your computing/storage/hosting is - just that it works as specified and can be accessed on the internet. Because you don't really care where it is, you can move it (whatever it is) anywhere else that offers better service/price/legal status. The supplier typically offers flexibility, expandability and hopefully comaptibility with competitors, and you don't worry at all about hardware or infrastructure issues (beyond assessing whether the supplier can do the job). So the Cloud could mean: You pay for Virtual Private Servers to host websites - as you need more processing power, you spawn extra virtual machines. When you need more bandwidth, you migrate all your VPS to a different supplier with lower bandwidth prices or a faster pipe. or You pay for 2Tb of storage accessible over the internet via tunneled iSCSI, which is used by your web servers. You then realise that the servers hosting this are in the US, but your data is from EU citizens, so you hastily move the storage to a EU based supplier - if you do it right, your site visitors don't notice. or You hire processing time on a botnet to carry out cracking attempts on a banking network. You don't care where the attacks come from as long as they can't be tracked back to you. There are many other examples that might be called cloud computing. Sure it is hyped and a buzz word, but there is a lot of it going on, and a specific example may be exactly what you need. 

SORB provide this information on their website. I'm surprised you didn't look there first, so perhaps you meant to ask something a bit less obvious? 

Use traceroute (tracert in windows) against Google. This effectively gives you the latency to each hop between you and Google, and will give you an idea if it is your router, or further upstream. 

Port 25 is the standard port SMTP traffic runs on. If you intend for you system to be an email server than those might be legit servers trying to send you or your users email. If you do not intend your system to be an email server, figure out how to get port 25 turned off. Historically email servers would be configured to politely send on email for other servers. Today this is bad, bad, bad. It's called being an open email relay. It would be wise for you to verify that you are not doing this. But, don't go to far and try to block port 25 traffic if you do mean to accept email from the outside world. 

You do not need to recompile anything. In fedora you can get the sqlite php module by installing the php-pdo module. The following should do the trick. 

I'd suggest using the expensive raid controller to do the bulk of the raid work. LSI cards and the software they come with works quite nicely. When properly configured, they will send you email when intereting things happen to the array. Like when disks fail. There is nothing wrong with either of the two linux software raid options, but you've gone out and purchased a somewhat fancy raid card. Let it do the work. Configure the disk array to expose one big device to Linux. If you would like to break up the final device into small volumes use lvm for that. One big physical volume, one big volume group and cut the volume group into whatever number of logical volumes you need. 

The reason your seeing php as having been built without sqlite is so fedora can split the php package and thus not force a big string of dependencies on people who don't want them. For instance you need sqlite and thus likely you do not need postgresql. If fedora was to build the main mod_php application with all --with's turned on you would end up installing postgresql without needing or wanting it. This helps people concerned with both security (only install exactly the software needed) and people concerned with package download bandwidth. 

Nothing requires that ping be possible between two hosts. It might be that somebody between you and google is dropping ICMP packets. If everything else is working I'd not worry much about this. If you are particularly worried check with whoever runs your networking equipment or firewall and see if they are letting ICMP traffic through. Also check to see if you can ping anybody else in the outside world other than google? 

If you have any resources at all, I would strongly consider setting up this server separately from your personal PC - if possible use some sort of hosting service outside of your home network, as suggested by Joe Internet in the comments above. You'll learn a lot about how these things are done in the real world, and will not be opening up a hole to your personal systems. 

CentOS 5 (and I guess Red Hat Enterprise Linux 5 too) doesn't have great support for PHP 5.3, at least in it absence of it in the official yum repos. Latest version available there is 5.1.6 which is pretty old... If you are just starting out on this path, and require PHP 5.3 you might want to use another distro that does officially support PHP 5.3. Ubuntu Server 10.10 has PHP 5.3 in its official apt packages. 

Another approach uses a different URL pointing to the directory. In Apache docs for Directory directive there is a comment saying: 

Sort of, though it depends how your Linux machine is configured. If it allows cached credentials, then the intial login while the machine is not connected to the network (I am assuming this is the scenario) should be sucessful. Then the wireless can connect. After this you are logged into the PC, and the credentials are used to access domain resources. Not exactly what you asked, but effectively the same. If the AD credentials had expired, after logging on you would likely need to re-authenticate when accessing a domain resource. 

If you want to use ssh to do any kind of automated procedure - I'm thinking specifically of Nagios checks - then you probably wouldn't want to use a passphrase. In this situation you probably wouldn't be using this outside of a LAN, and you would have the key stored securely on the server doing the procedure. Most tutorials discussing SSH will be anticipating a person logging in from an external network, possibly from an unsecure computer, in which case the advice is sound. Basically, unless you know there is a good reason not to, create a passphrase. Being too lazy to type in your password every time might be a good enough reason for you :-) 

You should be able to edit the defaults in the config file in the source code, then recompile and apply to your router. 

Do you really need an exact figure (whatever that means) to do this? Is knowing you currently use 100Mbps or 150.3528Mbps going to make a difference? Maybe you don't need to gather this data to get prices. What pipe/price options do they offer? If they don't offer these, ask for quotes in bands that make sense to you. You may get a better deal by not revealing up front how much you actually need, and instead get them to reveal their pricing structure. And the info may be useful in future when you need to upgrade. What does paying what you can afford get you? If it gets you way more than you expect to need now or in the next few months, then go down a level and ask again if you need that much pipe. Repeat till you are looking at a good price/pipe balance. Then look at the options to upgrade. How long will it take to upgrade? Are their additional costs to change later? How much will it cost you to have too small a pipe for the time it takes to realise and implement change? That might direct you to go for a bigger pipe. Answers to those questions will also be helpful in the happy circumstances of needing extra bandwidth because you are so successful in the future!