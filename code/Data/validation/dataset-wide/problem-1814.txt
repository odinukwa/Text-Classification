I was getting 403 & 404 errors on a Magento application I was working on I tracked down the issue to two blocks in the NGINX configuration, if I comment them out the issues are resolved but I would like to understand better what I'm commenting out. ISSUE 1 I was getting a 403 error on URLs such as 

I'm not really sure what this block was doing or what means, I'm sure I just took it off someones blog who recommended it. Any idea what it is doing? Below is my full NGINX configuration file, thanks in advance for any help and advice you may have :) server { # Listen on port 80 as well as post 443 for SSL connections. listen 8080; #listen 443 default ssl; 

Should I update our webserver? Everything is running fine now so I do not wish to run the risk of breaking anything. Can I just update the security updates? Is this the correct process for updating? 

I suppose I could create an image of the webserver on AWS incase anything goes wrong. Is there a way I can check to see what the updates are, especially the security ones, so I can see how necessary they actually are? 

I discovered if I changed the name of this file to I stopped getting the 404 error on it, and when I removed the below block from NGINX it loaded fine with it's origional name, so it must of had something to do with the dots at the end of the file name. 

Our staging server is on an Amazon EC2 instnace. When you ssh into it you can execute a command or without having to enter a password. Is there anyway I can require a password from a user when they try a command with ? I have a 3rd party dev who needs access and I want to restrict root privileges for them. I tried setting a password with but I still don't require a password. 

$URL$ I don't think I need to dump the full configs because obviously a lot is working: authentication, certs, compression, address pool, connection set-up generally. Does the Amazon VPC simply refuse to forward packets and I should really be on a somewhat-less-virtual cloud to do this? MORE EXPERIMENTS THE NEXT DAY: The VPC clearly isn't behaving like a true layer 2 subnet. In particular, ARP broadcasts don't actually broadcast! When I ping a non-existent IP (say .5) from .180, .58 doesn't see the request. The VPC is obviously optimizing away ARP broadcasts and sending it only to .5, if a .5 has been configured in the VPC via management console / API. Leaving on for a while only shows traffic between the host and the gateway, for all hosts. Further, pinging the broadcast address on the subnet doesn't work at all. This is backed up by the Amazon VPN FAQ. So the VPC is likely refusing to recognizing the unknown MAC address of .129, since it doesn't exist in its own "virtual ethernet switch". I'll probably shift this as the answer in a week or so. To extend the VPC with your own VPN, it must be via the formal "VPC gateway", which is only designed to work as an extension of a corporate intranet backed by a dedicated hardware router and static IP, not the roaming laptop scenario I'm aiming for. 

Not directly possible? I found it very simple and direct with no SQL, regular expressions, or policy mechanisms. In : 

Routing is obviously OK on the VPN server; I can SSH in, ping around, respond to the VPN request from the client: 

I can ping from both Windows & Mac clients to the VPN server's IP but not to any other IP's on the VPC subnet. (Those other IP's are OK; they are pingable from the VPN server.) When I on the bridge interface on the VPN server it sees the "ARP who-has" requests from the Windows client. However they aren't going onto the VPC subnet! on the destination IP does not see the ARP arrive. The Windows arp cache remains unfilled. (10.0.0.128 is the Windows client; 10.0.0.58 is the VPN server; 10.0.0.180 is the other IP on the subnet; the output below is from the VPN server.) 

Our site has been running slow recently and I've noticed that the RDS write IOPS can go as high as 80/sec and as low as 9/sec. Is this something that could be causing pages to load slowly? If so what could be causing it. Our RDS is a db.m3.large with 7.5 GiB memory and 100 GB SSD storage. On average we have about 2 people using our application at once, 5 max often just 1. Sorry if I'm not giving enough info, I'm very new to systems admin. 

We have a magento store which appends a query to our URL when you change Magento store views on the frontend. i.e. $URL$ Is there a way to remove the ?___store=uken with NGINX configuration? Say remove any query beginning with ?___store=. I'm very new to server config & nginx in particular. 

I'm trying to allow another developer to connect to a our ubuntu server and they are getting the below error in FileZilla. 

I thought, maybe I added the public key to the on the server incorrectly. She sent me a public key like this called 

I had NGINX running fine on my local machine and tried to install the Google Page Speed module by first uninstalling nginx and following the re-installing from source as Google suggests. Now NGINX won't start, and I can't access any of the sites I have set up locally for development. There is nothing in my error logs, yet I can see I have the /etc/nginx/ directory with all the configuration files I had before. Any idea how I can get things working again? I tried re-installing but still no joy :( 

I'm building a new Magento website on a Amazon ec2 instance and will need to point domain of their old OSCommerce site to the new ec2 instance's elastic IP address. Normally I would have though this a simple task of updating the record of their domain, but when I logged into the account with their register I see they have 90 records set up already, mostly & records. They have no IT guy to ask, but I'm almost 100% sure what I need to do but as I normally work with web dev stuff like php and javascript etc I just want to make sure I have it right. To give you a sample of their DNS records they have set up: 

I have a pool of virtual machines running in ESX that have their virtual hard drives set to Indenpendant/Non-Persistent mode. I won't go into the reasons for this other than to say it is working really well for us. Periodically I need to reset these settings back to the standard persistent mode and would like to automate that via a scheduled task for script. Does anyone know how to do this? 

It turns out this is a bug with Kerberos in Windows 2008. Microsoft has just released a hotfix for this (see link below). The hotfix completely resolved all my issues. $URL$ 

I have a SharePoint 2007 farm (w/ SP2, June cumulative update) hosting an Internet site and am seeing the nightly content deployment incremental job that moves content from our staging environment to production fail with the error below. When this happens the only way we know to resolve it is to manually run a full deployment. However the issue seems to come back again in a few days. Any advice on how to isolate the root cause of this problem and correct it? A duplicate name "9f2cdd1e-e4a5-433c-b4eb-f2baf9a46f0f" was found. at Microsoft.SharePoint.SPFieldCollection.AddFieldAsXmlInternal(String schemaXml, Boolean addToDefaultView, SPAddFieldOptions op) at Microsoft.SharePoint.Deployment.ListSerializer.CreateOrUpdateField(SPList list, String fieldName, XmlNode fieldNode) at Microsoft.SharePoint.Deployment.ListSerializer.UpdateListFields(SPList list, Dictionary`2 listMetaData) at Microsoft.SharePoint.Deployment.ListSerializer.SetObjectData(Object obj, SerializationInfo info, StreamingContext context, ISurrogateSelector selector) at Microsoft.SharePoint.Deployment.XmlFormatter.ParseObject(Type objectType, Boolean isChildObject) at Microsoft.SharePoint.Deployment.XmlFormatter.DeserializeObject(Type objectType, Boolean isChildObject, DeploymentObject envelope) at Microsoft.SharePoint.Deployment.XmlFormatter.Deserialize(Stream serializationStream) at Microsoft.SharePoint.Deployment.ObjectSerializer.Deserialize(Stream serializationStream) at Microsoft.SharePoint.Deployment.ImportObjectManager.ProcessObject(XmlReader xmlReader) at Microsoft.SharePoint.Deployment.SPImport.DeserializeObjects() at Microsoft.SharePoint.Deployment.SPImport.Run() 

I have a SharePoint 2007 farm (SP2, June Cumulative Update) where the User Profile Import job is now failing. The last log entry on the User Profile and Properties page shows the error message "The parameter is incorrect". This persists whether the job is run manually or via the defined schedule. What is interesting is that I see it working and running good in that I can see it successfully enumerating the AD profiles and the count goes up to the number I expect. But...it appears that this data is not persisted as I have old accounts still showing up in "Active Profiles" but are no longer on Active Directory. Also I can go to a test server and use the same settings for the import connection and user filter and it runs successfully. Any ideas on what the problem might be or how to troubleshoot? I have looked at all the logs but nothing has stood out so far and Google searches haven't turned up much on this topic. Ryan 

We're swicthing from an OSCommerce website to Magento and are also swicthing servers. The old server is on Apache and our new one is on NGINX. The SSL certificate we have seems to have been purchased from GODADDY. I've almost figured out how to switch our SSL certifcate from our old server to our new server. But have a few questions? 1. REKEY CERTIFICATE I've discovered three types of SSL files from the old OSCommerce site apache virtual host: 

Which is odd as I'm not used to comments in public keys or line breaks? We've tried using her public key with & witout the comment & line breaks. I've added it to like this: 

I stopped and started our Dev EC2 instance, I just wanted to test something. Now when I try to access our web app via the new AWS Public DNS I get an error. 

Secondly when I removed the sendy-newsletter configuration from and folders, as expected I could restart the nginx server successfully but strangely when I ran I get the same error message as before but the server works!? 

On our Magento store when we try to we go to the product page in the admin section to upload images, we see that the images which we already have there on the front end are missing and there is no option to add images as per usual. 

FINAL SOLUTION Just to clarify, my mistake was that I set the password for the wrong user, I tried to set it for root whereas I should have set it for ubuntu with: 

The issue with this now is that my file is now accessible. How can I rewrite this block better? What does mean? ISSUE 2 I was getting a 404 error on URLs such as: 

And then updating /etc/sudoers so that the ubuntu user must give their password when running a command. To edit this file you must run and add: