Modern spelling correction algorithms work independent of language. However, their statistical models have to be trained for each individual target language. This blog post by Peter Norvig is a good place to start exploring. 

Douglas Hofstadter's A Person Paper on Purity in Language is not exactly a "study", but I consider it a must-read. It is a satire on racism and sexism in language. I'll let Hofstadter himself summarize it for you. 

Code switching is common in India. So, even when writing to each other in English on facebook or IM, many Indians tend to insert phrases from one or more Indian languages. When people do that, they do not use one of the standard transliteration schemes. Most Sanskrit books, when printed for an English-speaking audience, use IAST. However, that's difficult to type on a computer. I prefer ITRANS, and that's what I'd recommend for you. "Is there a common way to phonetically transcribe Hindi?" In the "common way", people don't aim to be accurate; they just aim to be understood by a fluent speaker of Hindi. Since you're not a fluent speaker of Hindi, I advise against the common way. 

Standard Basque has a sort of ordering system for the Monday, Tuesday, and Wednesday: astelehena (week+first), asteartea (week+middle), asteazkena (week+last). The etymology of the standard names for the other weekdays is not transparent. One of several plausible etymologies for osteguna (Thursday) is bost + eguna = five+day. This implies a different numbering system (beginning with Sunday) than what is used for M-W. 

*This is of course soemething of a simplification of the literature on non-configurationality. **Full disclosure: a professor of mine. 

In non-finite contexts (which lack subject raising to Spec,IP) the verb moves past the VP-internal subject (ex. 17a): 

My understanding of the issues is as follows. Principles and Parameters is an almost-tautologous restatement of Chomskian UG: there are certain things that are not subject to cross-linguistic variation (principles) and other things that can vary but only in constrained ways (parameters). (The part about parameters is where the "almost" in "almost-tautological" comes in.) There are other things that can vary freely, of course â€“ e.g. vocabulary. All of Chomsky's syntactic theories fall under the P&P approach. In Government & Binding (the immediately previous generation), things like Conditions A, B, and C were principles; parameters were things like the EPP ("Extended Projection Principle;" originally this was the "subject movement to Spec,IP" parameter). Minimalism's principles are things like Merge (the operation) and the conditions on it (Last Resort, no lookahead, ...). One of the themes of Minimalist thought has been moving the locus of cross-linguistic variation to the lexicon. So the old EPP parameter, which in GB was true or false of a language, now can be specified independently for each functional head. In response to the observation/criticism that a small set of global parameters is not empirically adequate to describe the syntax of all natural languages, there has been research into lexical "micro-parameters" to fully describe languages (dialects) with small syntactic differences. 

When you write down the semantic representation of a sentence (lambda calculus) you see that the determiner "consumes" the noun. Hence, it is the semantic head of a noun phrase. SEOP has a comprehensive overview of the phenomena that led to this, but Wikipedia is not bad either. In syntax, the noun is considered the head of the noun phrase because it is the more "contentful" part, in the way people understand sentences. In HPSG, the CAT derivation is somewhat like the regular phrase-structure derivation, with heads having a correspondence to phrase-structure (PS) heads. (Though, AFAIK, there is no need for the concept of "head" in PS.*) The CONT derivation is somewhat like the derivation in Montague semantics. These are not two different types of parsing in HPSG (or anywhere else, AFAIK), but two (of the many) aspects of parsing with a rich grammar like HPSG. Benefits: I don't think you can compare one with the other for benefits... if you go through the references I gave for quantifiers, you'll see that the mathematics would become very cumbersome and ugly (or maybe even impossible... I don't know) if you try to make the semantic heads correspond with PS heads. * Though some parsing techniques find it useful to have heads of a PS marked. 

In many countries around the world, especially in Africa, the people natively speak both an indigenous language and French due to French colonization. The Norman conquest of England left us with many, many French words and grammatical structures, but England maintained only one language. What factors caused this difference? The French colonization of the world left many countries speaking French, but only left England with a vastly different language from what it started with. 

In terms on laminal consonants, the "flat" part specifically refers to the part of the tongue which contacts the roof of the mouth. So the body of the tongue is curled up, and the blade of the tongue is flat against the roof of the mouth. In practice, there is very little surface area actually in contact, but the point of contact sets the position of the whole tongue. 

The contrast between (1) and (2) shows that adverbs related to the speaker's perception of the event (luckily) must precede adverbs related to the subject's state of mind (mistakenly). And subject-oriented adverbs precede adverbs describing the event itself (tenderly), as (3) and (4) show. He has many, many more categories of adverbs than just these, and by pairwise comparisons he puts them all into an ordered sequence. He then argues that each adverb is associated with a functional head, and that the heads are also so ordered. Mark Baker proposed the mirror principle in this paper (JSTOR link). It says that, of two affixes, the one which is syntactically closer to the stem must be morphologically colser to the stem as well. So in a structure like the following, wherein Z is the root and X and Y are suffixes, we predict Z-Y-X and not Z-X-Y. 

Note that dependency graphs are (1) not a formalism and (2) not standardized, so each researcher may re-define what happens in dependencies. Some of those dependency graphs are not even trees. Refer Generating Typed Dependency Parses from Phrase Structure Parses. 

I don't think phonological rules are context-free. The earliest speech synthesis techniques like formant synthesis and diphone selection synthesis where either each phone or diphone could be run on a finite-state machine to either synthesize or select an appropriate sound to output. But these methods exhibited various kinds of unnaturalness that later techniques are aiming to overcome, by incorporating more and more coarticulatory effects. I'll quote from Syllable frequency effects in a context-sensitive segment production model, 2010, emphasis mine: 

English seems to have rules that are much more simple than its cousin German and its influencer French, as well as most of the languages that those are related to. What caused this? I suspect it's because there is so much influence on the language from two separate sources, but I could be wrong. EDIT: By this I mean when it comes to conjugation and compound words and number of phonemes, etc., etc., English has simplified very much. Alternative question that basically means the same thing: why has English simplified more than its cousins. PIE was much more complex, and I'm sure Proto-Germanic was much more complex as well; it's obvious that Latin is more complex than French, and I assume Proto-Germanic was much more complex than German. Why has English simplified one step further than these other two languages, in terms of grammatical complexity. 

The English word child once had plural childer (regularized from the original invariant plural child). Another pluralizer -en was then added, giving modern children In Proto-Germanic, there is a class of verbs called preterite presents. These were perfective in Proto Indo-European, but reanalyzed as presents in Germanic. The past tense was then formed by addition of a suffix (cognate with Mod. Engl. -ed). So, the past tense forms of verbs carried two "past" markers -- the original PIE ablaut and the Germanic suffix. 

I'm not quite sure what you mean by a "direct n-language creole." Creoles can and do draw their lexicon from many different sources; I would argue looking at aspects of syntax often doesn't let us identify any clear parents at all. (Berbice Dutch, a SVO language, developed from Ijo and Dutch, both SOV). So it seems that creoles from exactly two parents are not the norm, and furthermore considering different aspects of a creole's grammar/lexicon can give different answers as to what language(s) are the parents. Nonetheless, here's an attempt at answering your question from a couple points of view. Whinnom proposed a principle of "tertiary hybridization" which states that three language groups must be in contact for a creole to form. This is perhaps best illustrated by an example: in Papua New Guinea, Motu speakers were responsible for much coastal trade; they spoke pidgin Motu with their trading partners. The Hiri Motu ("Hiri" means trade) language arose when various of the trading partners began using their common pidgin Motu as a communication device among themselves. Motu could not form the basis of a creole (so the theory goes) when actual L1 speakers of Motu were in abundance, because they would perpetuate Motu grammatical norms as opposed to allowing a novel creole grammar to flourish. But I suspect that you are asking about creoles with a significant lexical contribution from many languages. Smith (1987, The genesis of the creole languages of Surinam, a Univ. of Amsterdam dissertation) speaks of a core of lexical material found in English-based Atlantic creoles which comes from various African languages. It was probably first amalgamated in a pidgin English spoken in African ports, then carried to the New World by slaves. There is also Saramaccan, which is among the most "mixed" creoles known, having drawn large portions of its core vocabulary from both English and Portugese. However, it also has other European and African influences.