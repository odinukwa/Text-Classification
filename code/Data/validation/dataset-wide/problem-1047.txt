Edit the precedence constraint between the Execute Script Task and the File System Task This precedence constraint will handle a missing DatabaseId. The DatabaseId would be missing if a connection to the SSAS server could not be established in the vbscript, or if the database is corrupted. You do not want to back up a corrupted database. It will bring the backup to a halt. 

Create an Execute Script Task Set the script to use Visual Basic. Set the ReadOnlyVariables and ReadWriteVariables as follows: 

I want to dynamically back up all the databases on a given SSAS instance using a SQL Agent job (which would most likely involve executing an SSIS package). It is imperative that this is a dynamic process - if users add databases or cubes, I want to set up a job one time that can automatically detect all existing SSAS metadata. Unfortunately, I don't see anything out there that tells me how I can automatically and dynamically back up all of the databases on an SSAS instance in a clean way. By "clean", I mean: 

Create the Foreach Container Here, you will create a Foreach based on the Catalogs schema rowset. This will get us the for each database in the instance and the will be put into its corresponding variable. 

SQL Server 2008R2 PowerShell 2.1 I am trying to create a SQL Agent job that dynamically backs up all non-corrupted SSAS databases on an instance without the use of SSIS. In my SQL Agent job, when I create a CmdExec step and point to a PowerShell script file (.ps1) like this: 

Create a credential Set up a proxy account Configure the SQL Server Agent step to use the proxy account 

Please replace 'insert FQDN here' and 'insert NetBIOS name here' with the actual FQDN and NetBIOS name keeping the double quotes. 

SQL Server will auto update the statistics if the default is left enabled. The problem with that are the thresholds (less of a problem with your SQL Server 2016). Statistics get updated when a certain amount of rows change (20% in older Versions of SQL Server). If you have large tables this can be a lot of changes before statistics get updated. See more info on thresholds here. Since you are doing CHECKDBs as far as I can tell you can keep doing them like before or you use the maintenance solution for that as well. For more information on index fragmentation and maintenance have a look at: SQL Server Index Fragmentation Overview Stop Worrying About SQL Server Fragmentation Considering you storage subsystem I would suggest no to fixate to much on "external fragmentation" because the data is not stored in order on your SAN anyway. Optimize your settings The sp_Blitz script gives you an excellent list to start. Priority 20: File Configuration - TempDB on C Drive: Talk to your storage admin. Ask them if your C drive is the fastest disk available for your SQL Server. If not, put your tempdb there... period. Then check how many temdb files you have. If the answer is one fix that. If they are not the same size fix that two. Priority 50: Server Info - Instant File Initialization Not Enabled: Follow the link the sp_Blitz script gives you and enable IFI. Priority 50: Reliability - Page Verification Not Optimal: You should set this back to the default (CHECKSUM). Follow the link the sp_Blitz script gives you and follow the instruction. Priority 100: Performance - Fill Factor Changed: Ask yourself why there are so many objects with fill factor set to 70. If you do not have an answer and no application vendor strictly demands it. Set it back to 100%. This basically means SQL Server will leave 30% empty space on these pages. So to get the same amount of data (compared to 100% full pages) your server has to read 30% more pages and they will take 30% more space in memory. The reason it is often done is to prevent index fragmentation. But again, your storage is saving those pages in different chunks anyway. So I would set it back to 100% and take it from there. What to do if everybody is happy: 

Connection Managers Use a real connection in design time so that the metadata plays nice. Creating the connection managers now isn't required, but it makes it easier for later. For each task in the process, you will have the appropriate connection manager available in the drop-down without the need to create any on-the-fly. ADO.NET 

Run the following query in the context of the database in question in order to get the Change Tracking table names used on the database. (Query via Kendra Little on BrentOzar.com) 

A SQL Agent job with a step for each instance that needs backed up (i.e. A step for the development server, the qa server, and for production). One dynamic SSIS package that is called in each step of the job. An that uses the Analysis Management Objects (AMO). 

Create a new OLEDB connection manager that uses the Microsoft OLE DB Provider for Analysis Service Using the Property Expressions Editor, set the ConnectionString property as follows: 

How can I determine when change tracking was enabled on a table in a SQL database? Assume that this table has a regular cleanup routine, which means that looking at the oldest record in the change tracking table won't provide the right answer. 

However, when executed with the embedded script, the job errors out quickly with the following response: 

This can in fact be done. There are probably a few ways to do it, and here is a fairly straightforward example. For this solution, you will use a combination of: 

Create a new ADO.NET connection manager that uses the Microsoft OLE DB Provider for Analysis Service Using the Property Expressions Editor, set the ConnectionString property as follows: 

You could be dealing with a delegation/impersonation problem as DimUser suggested. If your SSIS is just fetching data from one DB server and delivers it to the other the solution is much easier and should be to set up an SQL Server Agent Proxy. If you are executing the SSIS Package from Visual Studio or SSMS by hand the package will try your Windows credentials to log on to the SQL Server. If your account has the correct rights it will succeed. If you set up an SQL Server Agent Job to execute that package the service account running SQL Server Agent executes this package. He does not have your Windows credentials so he will try to use anonymous login resulting in this error message. To enable SQL Server Agent to execute a package using a different account you have to set up three things: 

It is provided by Tim Ford in his blogpost on mssqltips.com and he is also explaining why updating statistics matter. Please note that this is an CPU and IO intensive task that should not be done during buisiness hours. If this solves your problem, please do not stop there! Regular Maintenance: Have a look at Ola Hallengren Maintenance Solution and then set up at least this two jobs: 

You need to enclose CertStoreLocation, Subject, DnsName and FriendlyName with double quotes. There is no need to specify a location as it will default to "Local Computer/Personal/Certificates" where it needs to be in order to use it by SQL Server. This will generate a valid certificate on Windows Server 2016 that will be usable by SQL Server 2017: 

Sometimes certain SQL Server maintenance plan tasks can be problematic, like Shrink Database, Rebuild Index, Update Statistics, etc. I'd like to search for the use of one or more of these tasks on an instance of SQL server, for further review of whether they are necessary. Is there a way to query for maintenance plans that perform one or more specific tasks? (Not limited to the tasks that I mentioned.) 

Find the create_date for the change_tracking table(s) found in the first result set by querying sys.internal_tables in the context of the change tracking database. 

Create a new Analysis Services connection Using the Property Expressions Editor, set the ConnectionString property as follows: 

Add a step for each SSAS instance that will be backed up. Each step should be configured to execute the SSIS package. For each step, click the Set values tab and set the value of to the instance name for the step. 

The operator utilizes the operator. The specifications for the IN operator (screenshot below) indicate that both the (in this case, on the left of the ) and each (on the right side of the ) must be the same data type. Thanks to the transitive property of equality, each expression must be of the same data type as well. 

Why can't I reference the module from an embedded script, but doing so in a ps1 file works just fine? 

the job executes successfully (or at least gets far enough to only encounter logic or other syntax issues). This approach won't work for a final solution, because there is a requirement to keep the PowerShell script internal to SQL. So I have a different CmdExec step that embeds the PowerShell script like so: 

You gave us a long (and very detailed) question. Now you have to deal with a long answer. ;) There are several things I would suggest to change on your server. But lets start with the most pressing issue. One time emergency measures: The fact that the performance was satisfying after deploying the indexes on your system and the slowly degrading perfomance is a very strong hint that you need to start maintaining your statistics and (to a lesser degree) take care of index framentation. As an emergency measure I would suggest an one time manual stats update on all of your databases. You can get the nessecary TSQL by executing this script: 

Create a credential Connect to the SQL Server that should execute your package. Right-click Security and select "New Credential...". Enter a descriptive name (Credential name), select the Windows account you intend to use (Identity) and enter the password. Click OK. For initial testing, you can use your own Windows account. For production use, I would suggest creating a dedicated AD Service Account (with minimal permissions). Set up a proxy account Expand the SQL Server Agent folder. Open Proxies and right click on "SSIS Package Execution" selecting "New Proxy...". Enter a descriptive proxy name and use the credential you created earlier. Configure the SQL Server Agent step to use the proxy account Open your Agent Job, select the properties of your step executing the SSIS Package. Now you can select your proxy account in the "Run as:" drop-down list. Additional setup: If your package is deployed to the SSIS Catalog you need to grant the Windows login you used for the credential the "SSIS_Admin" role on SSISDB as well. For that, you need to create the account as a regular Windows login in SQL Server (Public) and map the user to SSISDB using the SSIS_Admin role.