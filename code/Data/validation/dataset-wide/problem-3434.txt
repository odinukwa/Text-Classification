Microeconomic theory is relevant to many topics in environmental economics, eg pollution control, valuation of environmental goods, economics of natural resources. A knowledge of more advanced theory would enable you to go more deeply into such topics and understand more of the literature. However, you can get quite a long way in environmental economics by applying basic microeconomic theory to situations with environmental features such as negative externalities (pollution), non-market environmental goods (many parks) public goods and "bads" (climate change), renewable resources (fish, forests) and non-renewable resources (minerals). If you are considering taking a graduate-level course in environmental economics, I suggest you look at the detailed content of particular courses to get an idea of what previous knowledge is assumed. I took an MSc in environmental economics several years ago which included a module on "economic principles" - essentially basic microeconomics, and obviously designed so that the course could be offered to those with backgrounds in related fields such as environmental science or agriculture but no previous study of economics. 

facilitate trade and specialisation, both within countries and internationally, by lowering transactions costs between people in circumstances where the informal constraints of village life do not apply; facilitate mobility of capital, by developing a legal framework for financial instruments and removing legal obstacles (eg usury laws); facilitate the spreading of risk, reducing the consequences of bad luck for individuals and firms. 

It's important to consider what exactly the population is about which an inference is being drawn. It's easy to overlook the time aspect in this context. Suppose for example that the aim is to forecast the next two years' GDP for each country in the world. Then the population of interest is a set of pairs of the form "country, year". It isn't simply "all countries", and even if a forecast model has been estimated by regression on current and past years' data for each country, that doesn't mean that the whole population of interest has been included. If one really does start from a complete dataset for the whole population of interest, then all one can do is calculate summary statistics. That could include standard deviations, but it would be inappropriate to call these standard errors, since that term relates to a sampling distribution whereas the only "sample" in this case is the whole population. 

One of the original statements of this kind were Kaldor's Stylized Facts on growth, Kaldor's Facts, the most important of which are that: 

Often people will first find a spread between the derivative products and the base one. This spread, is likely to be a reflection of the marginal cost of refining that last unit of the derivative product. Therefore it is likely to depend on demand relative to supply of refining capacity: If there's a new refinery for this product coming online, then you'd expect the spread to fall. If the demand for construction goods that use this refined product is increasing, then you'd expect and increase in the spread. Often several plastics and refined produces are substitutes of each other, like natural gas and gasoline are somewhat substitutable for each other. I would use the recent price of the other refined products to predict the price of polyethylene or polyurethane or its spread w/respect to crude oil. This wikipedia article has more on the spread and how people think it is determined. 

In principle the idea is that there are three sources of the 29.5 change: Lets assume we are taking period 1 as the 'baseline'. The first source of the 29.5 change is that the independent variables changed. To see the importance of this effect, you estimate education's effect on time for period 1. Then you apply the estimated model to the period 2 education and you get a predicted increase in time because the period 2 were more educated on average and the model predicts that higher education leads to more time. Suppose that estimate amounts to 22.78 minutes in this case. The second source of difference is found by estimating the model with period 2 data. Then you look at the different coefficients on education from the period 1 and period 2 models and apply the difference to the period 1 data. In other words, you see how much the function changed, as measured for the period 1 education levels. Suppose that in the second period, the effect of education seems to be larger. This difference in the coefficients explains 50.38 minutes of the difference between 1 and 2. Finally to interpret the interaction term, you have to imagine that you apply the difference in the models to the difference in the data. While the period 1 education using the period 2 model implies a high time and the period 1 model applied to period 2 education also implies a high time, it turns out that the period 2 model applied to the period 2 education yields a small time. This idea that when you interact the period 2 data with the period 2 model you get a different result than if you had just summed up the education change by the period 1 model and the model change by the period 1 data is what is at stake. In this case it turns out that the combination in yields a lower value than what is predicted by the sum of the differences. The interaction term is then difference between what you expected from the two individual differences and the result. In this case its a negative number, -43.66. Another way to see this is to imagine we are decomposing the difference between f(x1,x2) and f(x2,y2). As you go from x1,y1 to x2,y2, you will advance over the x axis. You expect the function to change Dx=(x2-x1)*df/dx(x1,y1).AS you go from x1,1 to x1,y2 you will advance over the y axis. You expect the function to change Dy=(y2-y1) *df/dy(x1,x2). Lastly you compare your results and realize that there's an error, xi, so that f(x2,y2)=f(x1,y1)+ Dx+Dy +xi. Dx here corresponds to the endowments effect, Dy to the coefficients effect, and xi to the interaction effect. 

A firm has received an order at time $0$ for $M$ units of product to be delivered by time $T$. It seeks a production schedule for filling this order at minimum cost. Let $x(t)$ denote inventory accumulated by time $t$, hence $x’(t)$ denotes the firm’s production at time $t$. There are two sources of cost: cost of production is $[x’(t)]^2$, the cost of holding $x(t)$ is $2x(t)$. Assume the firm discounts future costs with a discount rate $r > 0$. I am trying to formulate the Hamiltonian for this firm problem. However, I want to make sure my objective and constraints are correct: Is the problem of the form: $$min \int_{0}^{T} e^{-rt} [2x(t)+[x’(t)]^2]dt$$ i.e. $$-max \int_{0}^{T} e^{-rt} [2x(t)+[x’(t)]^2]dt$$ Is this the proper objective or am I completely off tanget? 

Just looking to see if anyone has any knowledge of original work for pareto refinement of NE under strategic form. I want to give credit to the refinement in a paper I am writing. I pulled the refinement from Nachbar's notes on "Topics in Advanced Game Theory", but obviously that is not a reliable source to cite. 

Im looking for some advice on I can solve my game below computationally because by hand it would take forever. 

Does anyone have any reference papers to modeling directional learning of rule sets for finite non-cooperative games? The only thing I can think of is to show disequilibrium due to some noisy process at early iterations of play, but is it easier to model these things with stochastic game theory or with evolutionary game theory? 

I have a game that I am trying to solve for here: My question is, due to the information set, can the game be solved with sub-perfect refinement? 

$(4)$ $(1)$ is combination of type $[a,c]$ $(2)$ is combination of type $[a,d]$ $(3)$ is combination of type $[b,c]$ $(4)$ is combination of type $[b,d]$. My reasoning for these four separate payoff tables is that that each player each has two types therefore there should be four possible combinations of types when modeling it from what Binmore would call an agent perspective Bayesian game. Type $a$ has a probability of $p=0.75$, type $b$ has a probability of $p=0.25$. Type $a$ and $b$ are represented as player 2's types. Type $c$ has a probability of $p=0.90$ and type $d$ has a probability of $p=0.10$. These types represent that of player 1. The probability distributions between player's types are independent so the combinations are, $[a,c] = 0.75(0.90)=0.675$ $[a,d] = 0.75(0.10)=0.075$ $[b,c] = 0.25(0.90)=0.225$ $[b,d] = 0.25(0.10)=0.025$ Obviously this sums to $1$. My question is is there anyone that knows some code that could allow me to compute Bayesian normal form's expected payoffs with ease? The Bayesian normal form for this game is quite large. Four possible combinations and 2 choices to choose between for each combination so we have $2^4=16$ profiles for each player which is a $16$x$16$ payoff table.