The universe is $[d]$. There are $m$ sets in the design, $S_1, \dots, S_m \subseteq [d]$. $(\forall i \in [m])\ |S_i| = n$. For every $t+1 \in [m]$, there exist $k$ disjoint subsets of $S_{t+1}$: $F_1, \dots, F_k$ such that 

The universe size $d = O(\ell)$. There are $\ell^2$ sets in the design, $S_1, \dots, S_{\ell^2} \subseteq [d]$. $(\forall i \in [\ell^2])\ |S_i| = \ell$. For every $t+1 \in [\ell^2]$, there exist $2$ disjoint subsets of $S_{t+1}$: $F_1, F_2$ (these are "forbidden" subsets), such that: 

Let $\ell$ be an integer parameter. I want to ask the existence of the following design: There is a universal constant $\beta < 1$ such that for all sufficiently large $\ell$, the following holds: 

btw. do we have a name for such block designs? Some motivations. If we do not insist on the size of each set, then one could choose all the $2$-subsets of $[d]$, and then order them in, for example, reverse lexicographic order. Then for $S_{t+1} = \{b_1 < b_2\}$, all the sets that are lexicographically larger than it can be divided into two chunks, one that does not have $b_1$, and one that does not have $b_2$. The question I have is whether such a phenomenon still exists once we enlarge the set size while keeping (asymptotically) the same number of sets in the design. Construction 1 with large universe. If $d = O(\ell^2)$, then there is an easy construction as well. Group $d$ into $O(\ell)$ blocks each with $\ell/2$ elements, then use the choose $2$ trick mentioned above, we have each set with $\ell$ elements, yet, the sets before any set can be split into two chunks that the first chunk does not know the first block of $\ell/2$ elements, and the second chunk that does not know the second block of $\ell/2$ elements. Construction 2 with smaller universe but more chunks. Let $d = O(\ell\log \ell)$. We could again group $d$ into $O(\log\ell)$ blocks each with $\ell$ elements. Therefore, by choosing all the $O(\log\ell)$-subsets, we can generate any $\ell^{O(1)}$ sets, each of $O(\log\ell)$ blocks (each block has $\ell$ elements). Sort these sets in reverse lexicographic order according to the block number, then for each $S_{t+1}$ its predecessors can be decomposed into at most $O(\log\ell)$ chunks, each not covered some $\ell$ elements. Note that this works for any polynomial number of sets. However, each subset has now $O(\ell\log\ell)$ elements and there are $O(\log\ell)$ chunks. Generalization. The tradeoff involves three things: (1) size of the universe, (2) number of elements in each set, (3) number of chunks we have. Let $k$ be another parameter which specify the number of chunks so that we have disjoint forbidden subsets $F_1, \dots, F_k$ each of size at least $\beta \cdot \ell$ and we allow to have $k$ consecutive chunks where chunk $j$ intersecting $F_j$ is empty. A more generalized definition is as follows: A $(d, m, n, k, a)$-design satisfies the following: 

Let $X_1,\ldots,X_n$ be independent random variables in $\mathbb{R}^d$ with $EX_i=0$ and $||X_i||_{2}\leq 1$. What is the best known exponential upper bound for $$P(||X_1+\cdots+X_n||_{2}>x)?$$ In particular, is it true, that the one dimensional case (Hoeffding's inequality) is the best? That is, is the latter probability at most $C_d\exp(-\frac{x^2}{2n})$? (the conctand $C=C_d$ is needed to account for the effects of the norm for $x$ small, that is, for $x<\sqrt{d}$ we can take all variables taking values $e_i$ and $-e_i$ with probability $1/2$, where $e_i$ stand for the usual basis of $\mathbb{R}^d$. 

Consider $m$ unit vectors in $\mathbb{R}^n$ with positive coordinates so that $m>n$. How does one pick the $m$ unit vectors so that the largest inner product of them is the smallest? 

Let $A\subset \mathbb{R^2}$ be a finite set such that $|A|=k^2$. Let $x_i\in \mathbb{R^2}$, $i=1,2,3,4$, be four points in the plane in general position (no three lie on any line). Let us form the multiset of cardinality $4k^2$ out of the four translates $A+x_i$ and call it $M$. Question: Can we partition $M$ into four sets (not multisets) $A_i$, $i=1,2,3,4$ with cardinalities $(k+1)^2$, $(k-1)(k+3)$, $(k-1)^2$, $(k-1)^2$, respectively? Question: Are there any good references for problems of this kind? 

For example, it is known that such designs exist for $a = \log m$, $\ell = C\log m$ and $d = O(C^2\log m)$. I am interested (in general) in such kind of settings of parameters: where you can generate a large number ($m$ in total) of small sets (each of size $O(\log m)$) over a small universe ($O(\log m)$ items in total), and with a small pairwise intersection ($\log m$). My question concerns with the behavior of intersections. Specifically, fix any $S_t$ in the system to consider. Consider the sets before it, $S_1,\dots,S_{t-1}$. Start with $S_1$ and find the maximal $i$ such that $|\left(\bigcup_{j=1}^i S_j\right) \cap S_t| \le a$. Let $S_1,\dots,S_i$ be the first chunk you find. Then you repeat this process starting at $S_{i+1}$ (find the second chunk). Let the total number of chunks you identify this way be $k$ (so $k$ is in general a function of $t$ and the set system). Now, do we know anything about upper bounding $k$? (over all choices of $t$, say). The intuition is that, at least on average, it should not be the case that $k$ can always reach ${\ell \choose a}$. Do we know anything about constructing an $(\ell, a)$-design (with the above settings of parameters in general) so that one can bound $k$ in the worst-case? UPDATE-1: To make the life easier, I want to know the behavior in the "average-case". That is, uniformly randomly pick a position $i \in [m]$, then try to bound $k$. Thanks in advance for any help! 

In the book "Cohomology Rings of Finite Groups", by Carlson- Townsley - Elizondo there is the following corollary 

Assume that $\mathcal{C}$ is a small category and that $\mathcal{F} \in \mathsf{ob(Ab^{\mathsf{C}})}$, is a covariant functor. When our category has finitely many objects then a classical theorem from Mitchell allows us to identify in that case the category of repesenations of $\mathsf{C}$, $\mathsf{Ab^{\mathsf{C}}}$ with $R\mathsf{C}-\mathsf{mod}$, where by $R\mathsf{C}$ is denoted the category algebra (defined as the free $R$-module, generated by the morphisms of $\mathsf{C}$). However, in the latter case we can define the $i$-th cohomology of $\mathsf{C}$, to be $H^{i}(\mathsf{C}, M) := {Ext^i_{R\mathsf{C}}}(\underline{R}, M)$, and exploit the intuition given by $R\mathsf{C}-\mathsf{mod}$, which is just a category of modules. However, the assumption of $\mathsf{C}$ being with finite objects is quite restrictive (mostly applied when the category is induced by a group $G$), hence I was thinking, is there any other definition with this assumption "chopped off"? A paper by Fei Xu - On the cohomology Rings of Small Categories, seems to be a standard source for this material, however I wasn't able to understand the definition he provides for the cohomology, since he uses the notion of $n$-th higher inverse limit $\varprojlim^n_{\mathsf{C}} \mathcal{F}$, which doesn't seem quite familiar to me. So, if someone wants to give an alternative (provided it exists) definition, or to give me a reference/definition of this higher inverse limit is more than welcome. P.S. I'm familiar with the notion of higher inverse limit in general, which by definition is the right derived functor of the left exact functor $\varprojlim$, but the above higher limit is something obscure to me and haven't confronted it before. Thank you! 

Let us say have a sequence of $n$ 2-$D$ random variables $X_i=(\varepsilon_i/\sqrt{n},i\varepsilon_{i}\sqrt{6}/n^{3/2})$, where $\varepsilon_{i}$ are independent random variables such that $\mathbb{P}(\varepsilon_i =\pm 1)=1/2$. Denote by $S_n$ their sum and take a $2$-dimensional Gaussian random variable $Z$ with the same covariance matrix as $S_n$. Any standard Berry-Esseen theorem (say by Gotze or Bhachattarya or Bentkus) gives us that for any convex set $C$ we have \begin{equation} |\mathbb{P}(S_n\in C)-\mathbb{P}(Z\in C)|\leq c\gamma, \end{equation} where gamma is the sum of third absolute moments of $X_i$, which in this case behaves like $n^{-1/2}$. Question: is there a standard way to pass from the distance between distribution functions to expectations of Lipschitz functions? That is, suppose $f$ is Lipschitz, can we still bound \begin{equation} |\mathbb{E}f(S_n)-\mathbb{E}f(Z)| \end{equation} in therms of $\gamma$? If so, does the same bound of magnitude $\gamma$ still apply? 

Let $G=(V,E)$ be a finite graph and let $f$ be any positive function defined on the vertices. Put weights on the vertices $v_{i}$, way $w_{i}$ so that $\sum_{i=1}^{n}w_{i}\leq 1$. Assume that every independent set of vertices, say $I$, satisfies $\sum_{v_i\in I}w_{i}\leq 1/2$. I would like to maximize over all choices of the weights the following expression (the average of f):$\\$ $$\sum_{i=1}^{n}f(v_i)w_{i}.\\$$ Question: is it true, that at least one global maximum is achieved by either i) putting weights $1/2$ on a pair of two neighboring vertices or ii) putting a weight $1/2$ on one vertex and $0$ on all of the others? Remark: the second situation can arise, for example, in the case $G$ is the empty graph and the value of $f$ at one vertex is strictly larger than on the other vertices.