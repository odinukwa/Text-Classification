Suppose $G$ is a finitely generated discrete group and that there is a subset $E$ of $G$ such that if $\mu$ is a finitely additive probability measure on $G$, then there is a $g$ in $G$ such that $\mu(E \cdot g) \ne \mu(E)$. Certainly $G$ is non amenable. Can more be said about $G$? Must $G$ contain $\mathbb{F}_2$? It should be noted that the above situation can happen: let $E$ be all elements of $\mathbb{F}_2$ which ``begin'' with $a$ or $a^{-1}$. Then both $E$ and its complement have infinitely many disjoint translates (by powers of $b$ and $a$, respectively). 

The answer is that $(a,b)$ must satisfy $a^2 = b^2 + 1$. It is possible to verify (see the preprint above) that for any $b$ and Borel $K \subseteq \mathbb{R}^{\mathbb{N}}$, that $$\gamma_\infty (K) = \int \gamma_\infty (\sqrt{1+b^2} K + b y) d \gamma_\infty (y).$$ By replacing $K$ by $(a/\sqrt{1+b^2})K$ in this equation, we obtain $$\gamma_\infty (\frac{a}{\sqrt{1+ b^2}}K) = \int \gamma_\infty (a K + b y) d \gamma_\infty (y).$$ Let $K$ be all $x$ in $\mathbb{R}^{\mathbb{N}}$ such that $$ \lim_{n \to \infty} \left(\frac{1}{n} \sum_{i< n} x_n^2 \right)^{\frac{1}{2}} = 1. $$ Then $\gamma_\infty(K) = 1$ and therefore $(a/\sqrt{1+b^2}) K$ has measure $0$ unless $a^2 = b^2 + 1$. Thus if $a^2 \ne b^2 + 1$, then $\int \gamma_\infty (a K + b y) d \gamma_\infty (y) = 0$ and hence the integrand vanishes for almost every $y$. 

The first place where the amenability problem for Thompson's group $F$ appears in the literature is, I believe, 1980 in a problems article by Ross Geoghegan. I have heard, however, vague comments to the effect that the problem was considered by other people before this. Does anyone have any knowledge about the existence of this problem prior to 1980? Edit: Following Mark's advice offline, I wrote Richard Thompson to verify the details of Mark's answer. He did confirm that he considered the problem. He first observed that his group $F$ did not contain $\mathbb{F}_2$. He then discovered the material on amenability in Hewitt and Ross's text on abstract harmonic analysis. He then observed that $F$ was not elementarily amenable. This occurred sometime prior to his 1973 visit to University of Illinois at Urbana-Champaign to visit Day. He did not, however, attend Greenleaf's series of lectures in 1967. Instead he read Greenleaf's 1969 text "Invariant Means on Topological Groups and Their Applications." It seems that the best date to attach to Thompson's consideration of the question is 1973. Of course Thompson never published his observations and they were not widely circulated. His observations mentioned above were rediscovered by others in the 1980s (the question itself by Geoghegan). I have invited Richard to post an answer, in which case I will delete this edit. 

As a set theorist, I feel some obligation to offer an answer here. First, the difficulties students may have in proving set theoretic containments like the one you mention above or in constructing $\epsilon$-$\delta$ proofs is not a matter of them struggling with set theory but rather of them struggling with something new: constructing a proof. In the case of $\epsilon$-$\delta$ proofs, a large part of this difficulty is in understanding quantifiers and how they work (for instance "for all ... exists ..." is not the same as "exists ... for all ...". This is because math is not a trivial subject to learn and some difficulty is required as the students minds stretch and grow. Surely there is no way around this. That really has nothing to do with set theory so far. In spite of a common misconception, set theorists do no actually care how it is that ordered pairs are defined. Or how exactly one codes the notion of a function. Set theory is not in competition with category theory, in spite of what category theory thinks. A very good analogy is provided by computer science: set theory is machine language (or maybe better: a low level language like C) and category theory is object oriented programming. While object oriented programming may provide a useful way of thinking about how to write a program, there still needs to be a machine language for the computer to run on. Moreover, there are occasionally things for which it is just better (or even necessary) to code in a low level language. Set theory provides an exact standard by which to discuss questions like "is there a subset of the real line which is uncountable but not of cardinality $|\mathbb{R}|$" (Hilbert's First Problem) or, maybe better, "is there an almost free, non free group?" (Whitehead's problem) or "If $h$ is a homomorphism a commutative Banach algebra into $C[0,1]$, is $h$ continuous?" (the negation being Kaplanski's conjecture). With the exception of the first question, these were asked, to my knowledge at least, without any thought that there was a foundational issue involved. Surely these are questions which could reasonably be asked regardless of how one sets up their foundations. To my knowledge category theory has never resolved these questions; set theory has in as satisfactory a manner possible (or at least until we adopt a more complete set of axioms). Now, one can argue at length about whether such questions are asked in poor taste or whether we should allow them to be asked at all. Readers interested in the question of "why care about set theory" should take a look at this (which might have been titled "why care about the uncountable"). 

My understanding is that the weaker form of square was initially needed to get a better lower bound on the consistency strength of PFA but that, with improvements in our understanding of the fine structure of the current inner models, the original form of square now suffices to give the best lower bounds. There are two versions of square (each with their associated ``weak square'' heierarchy): $\square_\kappa$ (formulated by Jensen) and $\square (\kappa)$ (formulated by Todorcevic). It is immediate from their definitions that $\square_\kappa$ implies $\square (\kappa^+)$ ($\square_\kappa$ and $\square (\kappa^+)$ are both statements about sequences of length $\kappa^+$ --- the apparent shift in indexing is purely notational). Todorcevic's theorem is that PFA implies the failure of $\square (\kappa)$ for every regular $\kappa > \omega_1$. It is often cited in the weaker form stated in item 1 of the question. Traditionally, lower bounds on PFA have been obtained through the failure of $\square_\kappa$ at a single singular strong limit cardinal. To my knowledge, there is currently no method for obtaining better lower bounds on PFA. It was somewhat of a breakthrough when it was realized that the failure of $\square (\kappa)$ at successive values of $\kappa$ was apparently more powerful than the failure of successive instances of $\square_\kappa$. That it took so long for this to be noticed may be due to the fact that Todorcevic's result was commonly cited in its weaker form. I don't believe, however, that this gives an improved lower bound on the consistency strength of PFA. It does, however, yield more strength from the failure of any form of square at cardinals below $\aleph_\omega$. It is at least my impression that it should be the case that the failure of square at all cardinals has a much higher strength than and individual failure of $\square (\kappa)$ or $\square_\kappa$. Whether the global failure of $\square_\kappa$, $\square (\kappa)$ or the weak forms of square mentioned above yield different consistency strengths is a matter which is completely open and for which there is only wild speculation. 

The following is an ``old question in analysis:'' Is it true that every perfectly normal compact convex subset of a locally convex topological vector space is metrizable? Here perfectly normal means Hausdorff plus all closed subsets are a countable intersection of open sets. Who first asked this question? The oldest reference I can locate is a 1972 paper by B. MacGibbon in the Journal of Functional Analysis but it is clear from what is written there that she is reporting progress on a known problem. Of course I am also interested in an answer to this question, but I'm really asking about reference information. I should note that Lopez-Abad and Todorcevic have recently demonstrated that it is consistent with ZFC that there is a counterexample to this problem. The question is whether a positive answer is consistent. 

I think it should be pointed out that, while many people working in set theory have a strong opinion about CH (with many feeling it is "false"), they generally do not have strong feelings against GCH above $\aleph_0$. That is, GCH is not such a controversial statement except that it implies CH. 

I'm addressing both the question and the comments, but possibly this question should be closed. First let's be clear what we mean by a model of set theory. A model is a set $M$ (or perhaps a class) with a binary relation $E$. $(M,E)$ satisfies Foundation if for every $x$ in $M$, there is an $E$-minimal $y$ in $M$ such that $y E x$. $M$ is well founded if for every $x \subseteq M$, there is an $E$-minimal $y$ in $M$ such that $y$ is in $x$. If $E$ is $\in$, then $M$ is transitive if every element of $M$ is a subset of $M$. Well foundedness is implicit in transitivity. The problem is that your model need not be well founded. The Axiom of Foundation only implies that the model of set theory you are working with does not have an element witnessing that it is ill founded. But certainly such a witness can exist outside. The Henkin Construction essentially never will result in a well founded model. A simpler example is given by a non standard model of PA. The model satisfies the induction scheme (which is the analog here of Foundation) but any well founded model of PA is isomorphic to the standard model. Furthermore, any well founded model $(M,E)$ of ZFC is isomorphic to a transitive set (or class) with the membership relation. This is the Mostowski collapse at work. So transitivity is not the issue here. The failure of finiteness to be absolute is tied up in the ill foundedness of the model in question. 

Is there a simple answer to the question "what happens to the continued fraction expansion of an irrational number when you add 1/2?" A closely related question is "what happens to such an expansion when you multiply by 2?" Remarks: I'm not sure what qualifies for an answer. The motivation comes from wanting to better understand the equivalence relation on integer sequences generated by tail equivalence (which is generated by adding integers and taking reciprocals) and closure under doubling/halving. It is known that this Borel equivalence relation is not hyperfinite, so the answer cannot be too simple. Edit: The answers are not really what I am asking for. It is clear there is some recursive procedure for doing this, just like there is a recursive procedure for taking a square root of a decimal expansion. I'm looking for something which one might call a "closed form". For instance, if you start with a periodic expansion, adding 1/2 produces a new periodic expansion. Is there a simple transformation on the initial and periodic parts which corresponds to adding 1/2? For instance, can this be done with a finite state automaton? An authoritative "there is no such nice answer" would actually be an acceptable answer. 

If $\kappa$ is a well orderable cardinal (i.e. an $\aleph_\alpha$) I don't think there is a need to involve determinacy. If all sets of reals are Lebesgue measurable (and DC holds), then Lebesgue measure is $\aleph_\alpha$ additive for every $\alpha$. This is sufficient (at least granting DC) since AD certainly implies all sets of reals are Lebesgue measurable. First argue that if $\kappa$ is a well orderable cardinal (i.e. an $\aleph_\alpha$) and Lebesgue measure is not $\kappa$ additive, then this can be witnessed in such a way that the sets in the union are all null sets (there is a countable subcollection whose union has measure equal to the sup in your equation). Without loss of generality, we may arrange that $$ \lambda ( \bigcup_{\xi \in \alpha} f(\xi) ) = 0 $$ for all $\alpha \in \kappa$. Define $Y = \bigcup_{\alpha \in \kappa} f(\alpha)$. Now define $$ X = \{(x,y) \in Y^2 : \alpha_x < \alpha_y\} $$ where $\alpha_x = \min\{\alpha \in \kappa : x \in f(\alpha)\}$. The set $X$ now violates Fubini's theorem: the set of all horizontal sections are the union of fewer than $\kappa$ many of the sets $f(\xi)$ and the vertical sections have their complement (in $Y$) being the union of fewer than $\kappa$ sets of the form $f(\xi)$. Thus by integrating in one direction, $X$ has measure 0, while in the other direction, its measure is $\lambda(Y)^2$. 

Suppose that $V$ is a locally convex topological vector space and $f:V^2 \to V$ is a bilinear map. Suppose that $C \subseteq V$ is compact and convex, $f$ maps $C^2$ into $C$ and $f \restriction C^2$ is separately continuous. Must $f \restriction C^2$ be jointly continuous? In the particular application I have in mind, $V = \ell_\infty^*$ with the weak* topology. Moreover the function $f$ is injective. I suspect even in this setting that this is false. I am also interested in a good reference for the optimal results of concerning separate and joint continuity of bilinear maps. Ideally this would be written for someone who is not a functional analyst. 

Is the property of not containing the free group on two generators invariant under quasi-isometry? Amenability is, so if there is a counterexample it is also a solution to the von Neumann-Day problem (which of course already has a solution). 

My favorite example of this is Stevo Todorcevic's paper "Compact subsets of the first Baire class" (JAMS, 1999). Fix a Polish space $X$ (for us it will be no loss of generality to take $X = \mathbb{N}^\mathbb{N}$). The Baire class 1 functions on $X$ are those functions which are the limit of a pointwise convergent sequence of continuous functions. A compact space which embeddable into the Baire class 1 functions with the pointwise topology is said to be Rosenthal compact. A typical example of a Rosenthal compacta is the set $\mathbb{H}$ of monotone increasing functions from $[0,1]$ to $[0,1]$. Two others are the ``split interval'' (which consists of those elements of $\mathbb{H}$ whose range is contained in $\{0,1\}$) and the one point compactification of a discrete set of cardinality at most continuum. The class of Rosenthal compacta is closed under countable products and closed subspaces. Todorcevic proved several ZFC results about Rosenthal compacta using forcing. Probably the best example in the paper (in terms of the use of forcing machinery) is the proof that any Rosenthal compacta contains a dense metrizable subspace. Before this it was an open problem whether there was a c.c.c. non-separable Rosenthal compacta. Todorcevic also proves in this paper that a Rosenthal compacta which does not contain an uncountable discrete subspace must map at most two-to-one into a metric space. Furthermore if such a space is non-metrizable, it must contain a homeomorphic copy of the split interval. Finally, he showed that any non $G_\delta$-point in a separable Rosenthal compacta is the unique accumulation point of a discrete subspace of cardinality continuum. One of the key lemmas of the paper is that the property of being a Rosenthal compacta is preserved when one appropriately reinterprets the compacta in any generic extension. 

First I'll say a few words about forcing axioms and then I'll answer your question. Forcing axioms were developed to provide a unified framework to establish the consistency of a number of combinatorial statements, particularly about the first uncountable cardinal. They began with Solovay and Tennenbaum's proof of the consistency of Souslin's Hypothesis (that every linear order in which there are no uncountable families of pairwise disjoint intervals is necessarily separable). Many of the consequences of forcing axioms, particularly the stronger Proper Forcing Axiom and Martin's Maximum, had the form of classification results: Baumgartner's classification of the isomorphism types of $\aleph_1$-dense sets of reals, Abraham and Shelah's classification of the Aronszajn trees up to club isomorphism, Todorcevic's classification of linear gaps in $\mathcal{P}(\mathbb{N})/\mathrm{fin}$, and Todorcevic's classification of transitive relations on $\omega_1$. A survey of these results (plus many references) can be found in both Stevo Todorcevic's ICM article and my own (the later can be found here). These are accessible to a general audience. What does all this have to do with the Continuum Problem? It was noticed early on that forcing axioms imply that the continuum is $\aleph_2$. The first proof of this is, I believe, in Foreman, Magidor, and Shelah's seminal paper in Martin's Maximum. Other quite different proofs were given by Caicedo, Todorcevic, Velickovic, and myself. An elementary proof which is purely Ramsey-theoretic in nature is in my article " Open colorings, the continuum, and the second uncountable cardinal" (PAMS, 2002). Since it is often the case that the combinatorial essence of the proofs of these classification results and that the continuum is $\aleph_2$ are similar, one is left to speculate that perhaps there may some day be a classification result concerning structures of cardinality $\aleph_1$ which already implies that the continuum is $\aleph_2$. There is a candidate for such a classification: the assertion that there are five uncountable linear orders such that every other contains an isomorphic copy of one of these five. Another related candidate for such a classification is the assertion that the Aronszajn lines are well quasi-ordered by embeddability (if $L_i$ $(i < \infty)$ is a sequence of Aronszajn lines, then there is an $i < j$ such that $L_i$ embeds into $L_j$). These are due to myself and Carlos Martinez, respectively. See a discussion of this (with references) in my ICM paper.