IMPORTANT: As with most properties of speech, the criteria described below are only going to be useful in relative terms--your script is going to do much better the more specifically it can be trained (either automatically or by you feeding it the appropriate parameters as arguments) for a specific individual in combination with a specific recording setup, since things like amplitude, duration, and formant values are all affected by a variety of factors. How breathing noises can be distinguished from linguistic speech noises: 

I'm a native speaker of American English, and none of the examples you have given strikes me as marked in any way. I don't know what the latest discourse-structure-based theories of focus would say about these examples, but my intuition is that they illustrate focus avoidance on "given" constituents. men, food, and guy are somehow "given" in their respective contexts. It's true that those words may not have literally been uttered yet at the time they appear in the discourse, but there is something generic about the entities to which they refer in those contexts, in a pragmatic sense. What is informative in the first discourse, for example, is the race of the men. Leading up to the mention of the men, the expectation is built up that St. Nicholas is accompanied by some perhaps unexpected entity. His being accompanied by men is not so remarkable (with the introduction of the phrase accompanied by one is biased to expect some category of human), but the fact that they are black is what the speaker expects to be novel and informative for the listener. It's true that one could think of black as being contrasted with other races, but I don't think this is contrastive focus in the usual sense, since the speaker isn't explicitly contrasting it with another specific race. If St. Nicholas were accompanied by six to eight black sheep, I would expect the prominence marking to shift to sheep, since people are not usually accompanied by sheep. In that case the focus would actually be ambiguous--it could be marking narrower focus on just sheep or broader focus on the entire constituent black sheep. In the second example, food is somewhat expected after We've ordered..., but the fact that it's Chinese is informative (and in this particular case enticing--it's a selling point to get the listener to help the speaker) to the listener. Again, had they ordered Chinese dancers, I would have expected dancers to be prominent. In the third example, the characters have all been talking about the person who has breached their security--the guy. Even more than in the previous two examples, the guy part of crazy guy is given explicitly in the discourse--he's the topic of their conversation. I should mention that, to my ears, the prominence pattern is actually not so clear in this example--I can convince myself that the speaker is putting prominence on crazy or that he's putting it on guy (it's not just about which has higher pitch--sometimes prominent syllables can get lower pitch in English). If he is placing prominence on guy, I would believe that he is contrasting it with the terrorists mentioned by the other character--"not a terrorist (or a group of terrorists)--just a guy". I don't have data on this, but my impression is that these focus phenomena are not unique to American English. I've definitely heard British speakers use similar patterns. The same holds for earlier generations of speakers. 

The "ripples on waves" (Bolinger 1964, Chao 1968) interaction that is observed in Mandarin is only one of several ways that lexical tone and utterance-level intonation may interact. I did a series of production experiments in which I elicited sets of utterances from native speakers of tone languages; the main two variables I manipulated were the tone on the final word or syllable and the intonation-type of the utterance (either declarative or echo question). The following summarizes what I found for echo question as opposed to declarative intonation in each language: Mandarin: The local contour of the lexical tone on the final syllable was largely preserved but shifted upward in the speaker's vocal range. So a falling lexical tone was still falling but from a higher starting pitch. Cantonese: The first half of the final syllable preserved information about the lexical tone on that syllable, but starting somewhere in the middle of the syllable the pitch shot upward with a steep incline. So a falling tone started falling but after the initial dip the pitch shot up in the second half of the syllable. There was no major lengthening of the syllable to accommodate both trajectories. Shiga Japanese: The tone and the intonation were expressed "in series", so that the fall associated with the lexical tone was completed and then the syllable was extended to accommodate the subsequent rise associated with the echo question intonation. In some cases this lengthening nearly tripled the duration of the final syllable. North Kyeongsang Korean: If the final word was monosyllabic, the falling contour observed in the declarative case was completely "overwritten" by a rising contour. If the final word was disyllabic (where the peak was on the first syllable and the fall carried through to the end of the second syllable in the declarative case) the fall was preserved but it started higher in the speaker's range on the first syllable (much like in Mandarin). In some instances there was a slight rise toward the end of the syllable (like in Cantonese, but nowhere near the magnitude observed in Cantonese or in the monosyllabic case). Interestingly, in each language there were lexical-tone-specific idiosyncrasies that made it impossible to formally characterize the mapping from the declarative version of a lexical tonal contour to the echo question version beyond the descriptive generalizations above. In other words, for a given language it was not possible to come up with an algorithm that could accurately predict the F0 contour of an echo question given only the F0 contour of its declarative counterpart. For example, There are three tones in Cantonese that are basically level in the declarative environment. In two out of the three cases (tone 3 and tone 6), the rising trajectory in the echo question environment was curved (i.e. more exponential-looking) but in the third case (tone 1) it was straight (i.e. more linear-looking). @jlawler's comment reminded me that there is also an interesting case in Shingazidja, a Bantu language spoken in the Comoros. Patin (2008) shows data suggesting that yes-no questions in Shingazidja are formed by the insertion of a "superhigh" tone on the penultimate syllable (phonetically the pitch on the syllable is higher than that on lexically H-toned syllables), overwriting whatever is there in the declarative version of the utterance (it gets realized at the same pitch regardless of the tone on that penultimate syllable in the declarative version). Interestingly, when the final syllable of the declarative version of the utterance bears a lexical H tone, the superhigh intonational tone is placed on the antepenultimate syllable! Bolinger, D. (1964). "Intonation: around the edge of language." Harvard Educational Review 34: 282-296. Chao, Y. R. (1968). A Grammar of Spoken Chinese. Berkeley, CA, University of California Press. Patin, C. (2008). Tone and Intonation's Waltz in Shingazidja Polar Questions. 3rd TIE Conference on Tone and Intonation (TIE3). Lisbonne. 

Here I am using Ls, Hs, and Ms to signify what phonologists think of as the phonologically important pitch events in these tunes (the symbols used in Ladd 2008 are couched within a more technical kind of notation used in autosegmental-metrical theory). As such, they should be thought of as residing in some level of phonological abstraction, and their acoustic realization may vary depending on the context. It is well established, for example, that the overall "tonal space" shifts downward over time during the course of an utterance, and so even if two syllables are specified for the same "tone" the later one will be realized as a slightly lower pitch*. In the above examples from English, some syllables are unmarked for tone, and the idea is that the tone level from the most recently specified syllable carries over (though the actual acoustic output may decline a bit in pitch). The approximate pitch level indicated by M above is very often about a minor third below that indicated by H. Indeed, the behavior of this contour (specifically, where the higher part of the tune and the later slightly lower part of the tune anchor themselves segmentally) in different languages has given us some insights into the typological differences among those languages when it comes to stress and intonation. If you Google Ladd's book, you can read some of his discussion on the calling contour via Google Books; just search the book for the term "calling contour". On a lighter note, if you listen to "Voicemail #4" from the Broadway musical RENT, you can hear the calling contour/vocative chant in action in English! Unfortunately the lyrics don't contain any words/phrases with antepenultimate (i.e. third-to-last) stress like the name Jonathan, but there are words/phrases with penultimate stress (like Anna) and those with final stress (like Louise), and you can hear that when the descending minor third happens indeed depends on the location of the lexical stress! *This also happens with lexical tones in tone languages. I have recordings of Cantonese speakers producing utterances composed solely of syllables with Tone 6 (the low level tone) on them, and the actual pitch gradually descends over the duration of the utterance in all cases. 

The vertical "stacks" correspond to frames; in other words, the pitch candidates are stacked vertically because Praat attempts to measure the "pitch" (actually fundamental frequency) at every frame. The horizontal placement of each stack corresponds to the occurrence of each successive frame over time, which is why they are equally spaced. The vertical placement of each candidate in the stack is dictated by its frequency (in Hz), as specified by the frequency axis on the right. The numbers at the very top are not pitch candidates, but rather measures of relative intensity of the sound in each frame. You can read more about the display of the PitchEditor on this Praat help page. 

Have you taken a look at Icelandic Online? It's a free online Icelandic language course created at the University of Iceland. It's been designed with an emphasis on immersion and trial-by-error, so you aren't spoonfed everything in every lesson. Pronunciation is no exception to this, so this may not be what you're looking for. That said, if you stick with it it might prove useful in the pronunciation arena. One of the tricky things about Icelandic is that there is a lot of lenition, contraction, etc. that happens in the context of full utterances, so that the pronunciation of a phrase may not be the literal "sum of its parts" (think going to --> gonna in English), but these pronunciation changes aren't indicated in any way in the orthography the way we sometimes use apostrophes or changes in spelling to express such phenomena in English. This is of course true for a lot of languages to varying degrees, but my anecdotal experience as a linguist and a native speaker of English is that Icelandic presents a more extreme case along this spectrum. What's useful about the Icelandic Online program is that it provides tons of recordings (by native speakers) of both full dialogues and individual words. By listening to the carefully articulated pronunciations of the individual words you start to build a sense of how the orthography--and therefore the phonology--works, especially if you supplement it with the Wikipedia article on Icelandic phonology, which gives you IPA information. Then, if you listen to the dialogue recordings you start to get a sense of how things get "slurred" and lenited in continuous speech. I hope that helps! 

Depending on how you analyze such cases, you could argue that these surface fricatives in Japanese are allophones of the underlying high vowels. Note that there is actually an articulatory and acoustic difference between the voiceless vowel [i̥] and the voiceless fricative [ç]. What is often described as the former is more accurately described as the latter. In the case of [i̥], the main constriction (and therefore the source of turbulent noise) is in the glottis; in [ç] it's between the tongue and the hard palate. I would argue that some realizations of /h/ in English are not voiceless vowels (as @jlawler claimed) but rather fricatives. Try pronouncing the beginning of the word huge and compare that sound to a whispered /i/ vowel. They are probably produced differently and sound different. But the /h/ in hot is pretty much realized the same as a whispered /a/ vowel. So one could make the argument that some allophones of /h/ are voiceless vowels and others (namely those before /i/ and /j/) are voiceless fricatives! 

This phenomenon is one of a family of phenomena known as Canadian Raising. "Traditional" Canadian raising involves the systematic vowel quality distinction made for the diphthongs /aɪ/ and /aʊ/ when they are followed by a voiced vs. a voiceless consonant. Generally they are realized as [ʌɪ] and [ʌʊ], respectively (or some similar variants), before a voiceless consonant. There are several varieties of this phenomenon, however, and the one to which you are referring happens to be the one that I speak. I was born and raised in New Jersey, USA, which is one of the regions where this variety is commonly found. I make the voiced/voiceless distinction for /aɪ/ but not for /aʊ/. I maintain the distinction even when the underlying voicing distinction is neutralized, as in the flapping examples you mentioned, like writer and rider. Those facts alone may not be that surprising, but there are certain seemingly exceptional examples in my dialect that make it less than straightforward to analyze from a phonological perspective. For example, in most cases the raising is only "triggered" when the voiceless consonant is in the same morpheme as the diphthong--so [ʌɪ] appears in ice cream but not I scream. But there are exceptions to this generalization--[ʌɪ] occurs in high school (when it refers to the institution of secondary education). Also, as you mentioned, the raised version of the diphthong occurs in some cases before voiced consonants! It appears in spider, idle, and cyber, for example. Finally, it can even appear before [nt], as in pint (as opposed to pined). Because of the exceptional examples in my dialect, a phonologist who believes in phonemes would have to concede that I actually have two separate phonemes, /aɪ/ and /ʌɪ/, in my inventory. There's no other way to explain minimal pairs like cider vs. sider and high school (the lexicalized compound) vs. high school (meaning 'a school that is high'). When I first mentioned all of these examples to a colleague of mine, she wouldn't believe me; she thought I was making them up. She finally came around when I pointed her to this Wikipedia article! In analyzing my dialect I would still posit a regular rule/constraint that keeps /aɪ/ from surfacing as [aɪ] before voiceless coda consonants, but such a rule would not be sufficient to cover all the cases. Just for fun, I'm listing some additional notable examples below: