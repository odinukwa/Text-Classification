The physical manifestation of triggers resides in database folder of the table that own the trigger. Trigger code resides in a file with the extension . For example, for a given MyISAM table mydb.mytable that has triggers, you will have 

but may not have an effect on the MySQL client pager. Since fails and you want to fail, here are your options OPTION #1 Try disabling the FILE privilege anyway on by doing this 

Above this output are histograms of these 20 top worst-performing queries Example of the first entry's histogram 

You could do things to speed up this whole process STEP 1 : Disable the double write buffer / increase log buffer size Go to the target server. Login o mysql as root and run 

Suggestions Workaround: use new InnoDB file format Barracuda and row_format=DYNAMIC This was added to the change log in MySQL 5.5.29 Perhaps an upgrade to the latest MySQL 5.5. is in order Give it a Try !!! 

You will see junkfolder as one of the databases. Knowing it is very vital for DBAs and Developers. Chapter 20 (developers) and Chapter 31 (DBAs) of the book MySQL 5.0 Certification Study Guide 

There does not exist a command nor is there a manual mechanism from the Master to stop Replication. You would have to go to each Slave and run on of the following: 

Then startup MySQL. If the MySQL Enterprise Monitor cannot be used to start MySQL then do . While you could move the whole folder over to Drive E:\ with 

you just created the database. The INFORMATION_SCHEMA database will dynamically register in the INFORMATION_SCHEMA.SCHEMATA table as a database. Since you want to create a volume for it, you can do this 

DISCLAIMER : Not an Oracle DBA Use , the grid control program that allows you to manipulate parts of the RAC Cluster 

Rather than try to guess, you should download Percona Tools. You should use the tool pt-duplicate-key-checker. It will compare all the indexes for you and give your the ALTER TABLE commands to drop the ones you do not need and still maintain fully compliance with all your index search needs. Here is the code to do it: 

InnoDB tablespace size for individual tables () can be reduced with and , but the system tablespace file can be never be shrunk. The source of ibdata1's growth in in the undo logs. I have written posts about this since July 2013. I first learned about this phenomenon from Percona's post Reasons for run-away main Innodb Tablespace. Suggestion #1 If you mysqldump the data into another server running mysql in a newly installed instance, you could setup replication to it, then failover and trash the old master. Suggestion #2 If you do not have another server, you'll have stop the application, mysqldump the data, drop all DBs, shutdown mysql, delete ibdata1, start mysql (which recreates ibdata1, reload the mysqldump). See my very old post Howto: Clean a mysql InnoDB storage engine? 

The confusion is caused by the double quotes you are using for the sudo and for the SQL GIVE IT A TRY !!! 

Please consult the MySQL Documentation on Temp Table Usage If you cannot set these values within your own session, contact your hosting provider to dynamically set them in your my.cnf. Give it a Try !!! 

So, as I stated, the user does not have a global privilege. The user has table privilege because has Y for create_priv. 

Based on this, your queries will have to use query100 instead of query in its WHERE clauses. Please let us all know if this worked !!! 

The usual rule of thumb for MySQL Query Optimizer is this: If the EXPLAIN plan has to read more than 5% of the table rows via the index, the index is dismissed (ruled out) and a full table scan is performed. In the case of the Slave, 156769 out of 32212292 rows are to be read. That's 0.4867%. Hence, the index is used. With regard to the Master, it is very disturbing that the MySQL Query Optimizer ruled out indexes. As @ypercube commented, perhaps there is no index. You should make sure by running on both Master and Slave. If they are different, please post both outputs in the question. Also, please run on both Master and Slave and post these counts 

You should only see just MyISAM. If you see other storage engines, you cannot just copy. If your root@localhost password is , here is all you need to to safely move all the tables regardless of storage engine: 

Within the query itself, trying separating the COUNT(*) from the retrieval by rewriting the query like this: 

That way, when you interrupt the mysqldump, everything prior to that interruption is committed. Give it a Try !!! 

First, look at the EXPLAIN plan again. The first line says that the Query Optimizer to do the following: 

If the character set's collation is case insensitive, then using the BINARY operator is not necessary. It would only appear to work fine in that instance. For more clarification on collations being case insensitive, please read the MySQL Documentation section "The _bin and binary Collations" 

Think about the amount of memory being allocated per DB Connection. What things must be allocated? According to MySQL 5.0 Certification Study Guide, page 357: 

If could speed up these steps by skipping the mysql shutdown of the DB server you are rsyncing from. That just requires a little extra cleanup on the DB target server. These steps are simply guides. You may find some of my steps a little paranoid. Feel free to use what you like. 

What really jumps at me is that 52% miss. It's possible your innodb_buffer_pool_size is just too small. Keep in mind that the InnoDB Buffer Pool caches data pages and index pages. How can you get a good size for it? Run this query: 

With this setup in mind, here is what you need to do: STEP 01) Use Query to Present Columns Ordered Per Database/Table Here is the Query: 

Database with all or some InnoDB Tables This is impossible to do with innodb_file_per_table disabled because all the files reside in a single system tablespace (). Besides data and index pages, there are other things written in the system tablespace: 

You need to stop replication, make the Slave have the same specs as the Master, then start replication. Make sure the Slave has no incoming connections. Otherwise, that will make the SQL thread on the Slave compete with incoming connections that are running queries against the same table you are running . If you cannot reroute the incoming connections, you will have to rerun the in chunks (perhaps 5000 rows at a time) on the Slave locally. As a last resort, rebuild the Slave (after scaling up the Slave's hardware and configs). 

Run those commands on master and server. This will ignore anonymous users. If the files are identical, grants are fine and replicated properly. Make sure you are using Statement-Based Replication and not Row-Based. Just a hunch... 

would keep the values for exactly the same. Nothing would change. Therefore, I recommend changing the query to the following 

It should run just fine. However, it is just like configuring Windows Updates. If you configure Windows Updates for 12:00 AM, shutting down the Windows Machine at 11:59 PM and starting it back at 12:01 AM prevents Windows from checking for Updates. When such a shutdown is occasional, leaving everything alone will cause the DB server to bring up the MySQL Event at midnight so long as mysqld is running at midnight. 

If you have no foreign key constraints, then yes this is correct. If you have foreign key constraints, some data may be inaccessible. You would have to fix it. 

I have decided to post a different answer in the spirit of your comment. Since MySQL is open source, YES, it is very possible to wedge in your own columns. However, I must present the facts in order for you to see the reality of such an undertaking. As I mentioned in my other answer, column order matters with . The actual source code responsible for managing grants is called sql/sql_acl.cc. You are free to look around and see it. What worries me is that the Book 

From this level, I only need three columns: , , in the outer most level Then, I append to the a hyphen and if is nonzero 

MySQL allows you to do with aliases (Problems with Column Aliases). This would be far better that doing with numbers. 

Subquery is essentially an array of types I would also index the table by blocked, location, and type to speed up Subquery 

At that point, MySQL is complaining that the data dictionary entry for the table in the database is still inside the system tablespace. Next, mysqld restarted and was ready for new connections 

I hope this information helps !!! UPDATE 2011-07-19 08:00 EDT From the last chat room session lovesh and I had, here is the example I ran to create the event on my PC running MySQL 5.5.12: 

If you get the mysql prompt, CONGRATULATIONS !!! You installed a password for root@localhost Go back to MySQL Workbench and user as the password Give it a Try !!! 

AFAIK MySQL Cluster has the ability to scale, but it is really a manual process to do so. In fact, it takes more planning and more hardware to do such scaling. Here is why: MySQL Cluster According to "Guide to Scaling Web Databases with MySQL Cluster" (October 2011 Whitepaper), page 5 paragraphs 4,5 under the subheading 'Auto-Sharding': 

That yields 16.03K per results. BUT WAIT ... Mathematically, we both figured out that 2.6 blocks per query was 20.8K. Since average space per query result (16.03K) is a few bytes above 2.0 blocks, fragmentation is all but guaranteed. SUGGESTION The Documentation says of query_alloc_block_size 

This is what happens when replication is off for 486330 seconds (5 days 15 hours 5 minutes 29 seconds) and you run Look at your . The IO Thread has been up for 66530 seconds (18 hours 28 minutes 50 seconds). This means someone or something started replication 18 hours 28 minutes 50 seconds ago. You stated in your question that you have set up replication for the production server. This means that you ran the mysqldump 5 days 15 hours 5 minutes 29 seconds ago and started replicating from the production master 18 hours 28 minutes 50 seconds ago. If you had setup the Slave the same day you got the mysqldump from the Master the replication load would be a lot less. Notwithstanding, replication is working normally provided and both say . 

This will list all users that have SUPER privilege. Most users that do application-related DB processing do not require this privilege. According to the MySQL Documentation, those with SUPER privilege can do the following: 

The biggest thing most people forget about TRUNCATE TABLE is that TRUNCATE TABLE is DDL and not DML. In InnoDB, the metadata within ibdata1 contains a numbered list of InnoDB tables. Using TRUNCATE TABLE causes the internal metadata id of the InnoDB table to shift. This happens because TRUNCATE TABLE effectively does the following: Example: To truncate an InnoDB Table called mydb.mytb 

In the event of a crash, just destroy the Slave and spin up a new one We'll call the Slaves S0 and S1 Here is something else: have this in /etc/my.cnf in S0 

Let's say you want to limit to the Latest Entry Per 10 seconds. You will first have to generate a ten-second interval boundary like this: 

Chances are, the number of PostalCodes with multiple records is probably so high that the MySQL (MariaDB) Query Optimizer does not like. At the very least, I would run and try these queries. 

Great, no complaints from mysqld. Of course, I arbitrarily chose 5 minutes. You can choose whatever schedule you prefer. Give it a Try !!! UPDATE 2011-08-25 11:22 EDT For everybody using release of MySQL prior to 5.1, I have a worthwhile suggestion: Write a perl script that keeps an open connection, making it heartbeat itself by retrieving something (i.e., uptime, aborted_connects, etc) and every 10 minutes kicking out FLUSH HOSTS. Whatever user you connect as, make sure it has RELOAD privilege. For example: run this command: 

The mysqldump file will extended INSERT commands importing 10,000-20,000 rows at a time. Now, just load the mysqldump 

Having taken a quick look at the Stored Procedure, I have three suggestions SUGGESTION #1 The table (lines 198-210) is MyISAM. Perhaps it should a MEMORY table. 

CAVEAT When running the download for MySQL 5.1.34, if the RPMs for the MySQL Binaries do not get retrieved, change this line 

I have a working theory (LaForge would say to Capt Picard)... Since you are using MySQL 5.1, you have access to the table INFORMATION_SCHEMA.PROCESSLIST. You also have access to the ID of the current process the trigger is running on. The function to get that process ID is CONNECTION_ID. You could try to fish out the query like this: 

Give it a Try !!! UPDATE 2014-09-22 15:07 EDT This will group by date and hour with a summary by date and an overall summary 

is really a JOIN clause due to having the two tables on opposite sides of the sign. The CONCAT on the right side would also trigger a full table scan. Adding the compound index on and seems to be the only option left. 

Give it a Try !!! UPDATE 2012-01-11 11:50 EDT To remove Jobs with no Posts, change the first LEFT JOIN into INNER JOIN: 

Unfortunately, you cannot force the ordering of columns in a mysqldump. You can, however, use the table . You will need the following: 

Good News, MySQL 5.x does not do that !!! If MySQL 5.x did this, I would be a PostgreSQL DBA today (No offense to PostgreSQL, it is an excellent RDBMS in its own right). UPDATE Oh my goodness, I read the post !!! That post came from me !!! I never thought someone would dig this post up. Please leave stuff like this dead and buried. Now I am having flashbacks !!! 

The second query would make the temp table from the subquery much larger and would take longer to scan for the outside WHERE clause. Go with the first query. Give it a Try !!! 

If you are looking for a running total for each row, you have to set up a user variable. The purpose of the user variable is to keep the total value after each row like a spreadsheet cell. PROPOSED CODE 

This will show total table count and how all (url,title) combinations that repeat twice and more than twice with the total for each at the bottom. If the sum of the repeats is more than 5% of the total: 

Whenever, you delete 70% or more of the table, do it like this. SMALL DELETEs If you are deleting smaller chunks, perhaps you can do it with a : 

Thus, you cannot run any of these and have a stable mysqldump SUGGESTION You badly need to create a MySQL Replication setup That way, the Master and stay up 24/7. On the Slave, you can do the following: 

PROBLEM #5: CPU db.m3.medium only 1 vCPU. That means InnoDB, Encryption, and the OS are all running on 1 vCPU. OUCH !!! PROBLEM 1 REVISITED According to your buffer statistics, you have 2664 MB for the InnoDB Buffer Pool 

UPDATE 2012-06-25 12:18 EDT AS pointed out by @yercube in his comments to my answer, you may want to attach the student-id from to degree_o and degree_id over to accedit. Perhaps something like this: 

There are three(3) ways to find out info on queries and its process ID Way #1 : Activate the General Log as a Text File If you add the following lines to my.cnf and restart mysql 

You want to turn innodb_stats_on_metadata on immediately after the so that metadata is used efficiently for Query Optimizer analysis when evaluating queries involving InnoDB. Leaving it off will provide more stable Query Execution plans, but the index statistics grow stale quickly in a heavy-write environment. Give it a Try !!! 

This show that a is just a secondary index. A secondary index would have a copy of the PRIMARY KEY attached to every index entry. My assertion is that a bug was introduced in 5.7.13 that did not exist in 5.7.12 when it comes to dropping and creating an index on the same column(s) at the same time. Look back at your command 

Since the InnoDB Storage Engine looks operational at the time mysql is restated, you should take the time to cleanup the InnoDB infrastructure 

In a separate script, load every table_name in mydb.TablesLeftToEnableKeys to bulk Step04 : For each table_name in Step03, do the 

STEP 03 : From here on, every restart of mysql will setup this private key cache for your table Give it a Try !!! 

There is a open bug report on this for MySQL 5.6.14 Bug #71520 Constantly increasing Innodb_row_lock_current_waits value From the bug report, note this entry 

When SQL statements are executed, gtid_executed is updated with the GTID Set value. MySQL Documentation says about gtid_executed 

I have some heartbreaking news for you that will solve your problem. If you are using MySQL 5.5/5.6, I can assume you are using innodb_file_per_table. There is some disk I/O going on when accessing the INFORMATION_SCHEMA to get information on InnoDB. What I am about to tell you I have personally eyewitnessed: I worked with a client that had a 2TB MySQL Instance with dozens of database and 10's of thousands of tables. Using MySQL 5.5, I was able to run these queries: QUERY #1 : Disk Usage by Storage Engine