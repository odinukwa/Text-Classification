This is old, but I had the same issue. My SQL logs and backup tables were indicating that backups were happening, but even when I used the vssadmin command above, I could not locate the backup files. I listed the writers, but none matched the long string in the SQL logs, so I tried some of the other "vssadmin list" commands: ---- Commands Supported ---- List Providers - List registered volume shadow copy providers List Shadows - List existing volume shadow copies List ShadowStorage - List volume shadow copy storage associations List Volumes - List volumes eligible for shadow copies List Writers - List subscribed volume shadow copy writers "List Providers" turned out to be the golden nugget. Although nothing was returned for existing copies or storage associations, the Providers listed the info I needed - it named my SAN provider. I looked in my storage tool and saw it was using Microsoft VSS, and the snapshot times correlated with what was in my SQL log. Three things of note: 

(change table names as appropriate for Hashtags and Words) Or, slightly more complicated, get the top 10 words for all tweets mentioning a specific hashtag: 

1: If the column you're changing is part of the clustered index definition, then yes. If not, no. Any non-clustered indexes involving that column will have to be rebuilt when you change the column type, also. 2: A heap just means no clustered index, so nothing to rebuild. Same as answer #1 for non-clustered indexes. 

Access is a perfectly fine database system for small scale individual-user apps. Here are some criteria for shifting: 

Example below is, for each column in the table that starts with either 'A' or 'B', return all rows in the table that have a non-null value in any of those columns. Note: I don't have a Sybase install handy to test this. Chances of it actually working are very low, but it should hopefully be enough to make you realise what a bad idea this is. 

ouch. reaching back into my memory - I remember that sometimes I had to put a return at the end of the format file. (SQL 7, maybe even 6.5?) So, maybe hit enter at the end of the format file, or optionally, make sure you didn't hit enter 

I could be wrong, (especially since I don't know German) but looking at the options on the second screen (Media Options), did you try doing "back up to a new media set", instead of an existing one? In 2014 there are additional options. Since it is a 2012 database you are trying to back up, there are probably defaults set in those options which are incompatible. 

You mention that the stored procedures should be done. My guess is that without any transaction marshaling the data is accumulated and then finally committed about 2 hours later. You mention you ran profiler, but I would look at Adam Machanic's sp_whoisactive at $URL$ It will give you all sorts of information. 

How often you need to run index maintenance/rebuild stats depends on your database load, specifically how often your data is modified (i.e. //). If you're modifying data all over the show (i.e. a staging table for a weekly batch process), you probably want to update stats/reorganize indexes nightly. If your data is rather more static you can probably make it a weekly or fortnightly schedule. 

I know I just spent this entire post detailing why EAV is a terrible idea in most cases - but there are a few cases where it's needed/unavoidable. however, most of the time (including the example above), it's going to be far more hassle than it's worth. If you have a requirement for wide support of EAV-type data input, you should look at storing them in a key-value system, e.g. Hadoop/HBase, CouchDB, MongoDB, Cassandra, BerkeleyDB. 

We have a purchased reporting application that executes a query that just recently is taking an extremely long time (>2 hours). A week ago, this same query completed in less than a minute. I've restored the DB from last week to confirm the end user's story, and sure enough, even with similar row counts with last weeks and yesterday's backup, the difference in query run time is there. Table1 contains 1.4 million rows. Table2 contains 16k rows. In this case, none of the records from Table2 exist in Table1, so when the query is actually allowed to complete, no records are returned. The table schemas are identical, with the exception that Table1 has a non-unique, non-clustered index on Field10. There are no other indexes that exist on either table. All fields in the join are (NVARCHAR(40), null) types. The query looks like this: 

It's called Entity-Attribute-Value (also sometimes 'name-value pairs') and it's a classic case of "a round peg in a square hole" when people use the EAV pattern in a relational database. Here's a list of why you shouldn't use EAV: 

Note that if you have a front-end built in Access and just want to shift the database away from JET (Access's internal DB engine) onto a "proper" RDBMS, you can do so by migrating the data across and setting up linked tables inside Access to the new data source. 

(* I'm aware this would probably fail any security audit going, but to my mind if we've let an intruder into the server room that knows to look in the third drawer down for the unlabelled 'sa' password post-it, then we're screwed anyway.) 

is a session-level command in Sybase ASE, it's not a server-level setting (if it was a server-level setting you'd be able to alter it via ). Can you run wireshark (or something similar) on the packets being sent from the JDBC client to see if it's setting showplan on as part of the session initialization? That said - showing the plan should not affect database CPU or memory usage, the plan is generated by the query optimiser anyway. However, showing the plan will increase network utilization. 

If I simply do a "SELECT * INTO Table3 FROM Table1" and "SELECT * INTO Table4 FROM Table2" and repeat the query about, substituting Table3 for Table1, and Table4 for Table2, the same query (against the new tables) takes 4 seconds. I'm not an expert at Execution plans, but it looks okay to me. No suggested indexes, index seek on Table1 (cost of 89%), and a table scan on Table2 (but cost is only 9%). Here's a link to the actual execution plan that has been anonymised. $URL$ There is no blocking that is taking place. When using sp_WhoIsActive, I can see that the Reads are sky-rocketing into the billions. Again, this is a boxed application, so I can't really change the query. Any ideas on what I'm missing here? It's driving me nuts that I can't figure this out. 

Short version: It depends. Generally spoken Sybase SQL Server is smart enough to do things the fastest way, though. Long version: Sybase's query processor is, at it's core, very similar to the one used in MS SQL Server. It will create worktables (internal temporary tables; not visible to the user) if the result set is sufficiently large to overflow available memory (similar to a table spill in SQL Server). Otherwise, it'll do a pair of index scans (you do have indexes on and in both tables, right?), then a join and output, all in memory. Caveats: 

First things first: MS Access was not designed for multi-user access. Every version of Access I've used had a disturbing habit of corrupting tables at a vastly increased frequency if there were >1 users using it. If the two users are connected to the Internet all the time, I'd recommend shifting your table storage to SQL Server and having the users connect to that (use a VPN or some other form of security! If they're on a company LAN it's even better, you shouldn't need a VPN then). It's a fairly straightforward process to convert to SQL Server. The users will still use the Access front end, but instead of having the tables stored inside the .accdb file and having to merge them, the Access tables are converted to linked tables to the SQL Server tables. This is possibly a bit more up-front work, but it'll save you hassle down the road (how often do you need to merge? who's going to do the merging?). Also, if the application ever gets more widely used, you can easily build another front end (in C#, Java, ASP.NET, whatever) and connect it to your SQL Server back end.