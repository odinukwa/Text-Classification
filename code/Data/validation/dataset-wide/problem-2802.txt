The idea that there is one fixed concept of either duty or obligation is probably in doubt, but there could probably be drawn a distinction in, say, Kantian philosophy. Kant in his Critique of Practical Reason states the following (in his typical, idiosyncratic way): 

The problem with this intuition is that in all of your suggested mathematical theories, we are already taking as background assumptions the full resources of first order classical predicate logic. The Proof theoretic resources following from Curry-Howard usually give us axiom schemes that we ought to already accept in that setting! What might be interesting though would be the effect of slightly more powerful machines corresponding to subtheories of Second or Higher Order logic. At a glance, it looks like there has been some fun stuff following from developments of Girard's System F calculus - here's a paper by Philip Wadler that discusses the idea that there is a representation in second order lambda calculus of a large class of arithmetical functions, regardless of the addition of explicitly arithmetical axioms. 

Both of these sentences have meanings such that we know where we would need to go and look, independently, in order to determine whether they came out true or false. However, since it turns out that they are in fact mutually dependent on one another for their truth value, it will turn out that they are both Ungrounded sentences when we theorise about them in a Kripkean theory of assigning truth values. 

Per se can be used sometimes as a sort of verbal um, but a more nuanced version of it is to highlight that the intension of the description of the item is in some way more crucial to the meaning of the referring phrase than the extension. The President of the United States does not per se have a political party or (say) a gender, even where Barack Obama is a male democrat. In your example then, "the literal meaning of the sentence per se" is used to emphasise that what is being introduced by the "but" leaves the meaning of sentence fragments in broad generality embedded with variable attitude statements to be in some sense transparently carried over to larger sentences with the relevant structural properties. The phenomenon is supposed to be general, with the "meaning as such" serving as a kind of generic element or parameter to facilitate discussion rather than specifically relating to a schema or class of contents of large numbers of individual sentences to be translated this way. 

Foucault argues that the move from torture and death to imprisonment and reform plays into the technologies of power that serve to influence the modern notion of the self. That is, that what is involved in present-day societal functions of discipline, the law and punishment is machinery designed to shape and influence your behaviour, in ways more subtle and influential than threats of harm, in order to make people en masse more ordered and less violent and chaotic. For Foucault, then, this is exactly the modern soul - something that has been specifically created, through the institutions and disciplinary techniques applied to you in childhood and continue to be at work in "civilized" society, to serve as your moral centre in the absence of direct individual coercion. Other theorists have called this "Conscience", the "Id" and various other labels. Typically then, debates about the "soul" are of less broad interest than debates about the mind, which certainly invites a lot of discussion: See for instance the introductory SEP article on Dualism and the Mind Body Problem. The Christian soul can be analysed in very similar terms, though they would be very hesitant to give a genealogical analysis. Your soul is something given to you by God, it is that in virtue of which you are what you are in the scheme of God's intention for the world, it is what is at stake in matters of adherence to religious doctrine and practice, and it is the source of your existence beyond your physical presence on the earth, for which you will experience either reward or punishment in the eyes of God. For a Christian, your soul is you, but specifically you within the context of a Christian perspective. Foucault might note that such a perspective is no accident, but is yours by virtue of various disciplinary and manipulative functions brought into practice upon you to write you into a docile Christian. Where Christians differ from Foucault of course is that they argue that your soul is something that is present within you certainly from the moment you are born to the moment you die (and beyond), and that is the creation of the Christian God regardless of whether or not you actually subscribe to the Christian faith or live in a world in which it exists. This might be read as a kind of claim for totalizing power over the right to dictate behaviour, which Christians will hold is God's (or from the analyst's perspective, Christianity's) by virtue of his power and benevolent will. It is difficult to challenge this position philosophically, because a primary issue as to the existence of their God or their souls is not a metaphysical or scientific one but rather a political one - specifically, what, exactly, does this particular series of behavioural manipulations through Churches, Christian doctrines about the family, about conduct in business and community engagement, about personal health and well-being and more, actually look like? How much of a difference have they made in the lives of others, what comfort and support have they offered the world, how is the world better for their being here than not? Maybe it really does work out for the best. I am firmly sceptical (and am regularly reassured as to that scepticism), but that's what it comes down to. The way to react to a Christian who relies upon their soul to justify their actions is just to look at their actions and challenge them independently if they are in need of challenging. That is their concept of "soul" at its most vulnerable. 

In Fashionable Nonsense, Sokal and Bricmont draw on quite a few different bits of Irigaray's work, but the one that is most extensively quoted is her This Sex Which Is Not One, specifically chapter 6 on "The Mechanics of Fluids". Irigaray is writing about the treatment of women and the feminine within the context of western philosophy, and in this chapter she's presenting a case that there is something masculine in the logic of the discrete solid object. Her idea is that the finite logic of syntax in the Frege/Russell tradition functions by first fixing upon a finite and discrete domain, which necessarily involves a process of extension. She thinks this process of extension is specifically psychological, depending upon a cognitive function of judging boundaries and exclusions and treating things as (solid) individuals. Finally, she argues that that function has been specifically coded as masculine, in contrast to how western culture has coded as feminine aspects of fluidity, which has sexualized connotations. Sokal (standing in for the authors against) is affirming firstly that mathematics takes the continuous very seriously and has proposed very particular theories of fluid mechanics without undermining the classical logic foundation, rather than ignoring it as "other". Secondly, he makes the case that the mathematics involved is used through formulating an idealized model rather than imposing that structure upon the world as a matter of "the Real"; that mathematics creates models and structures, rather than imposing itself upon the world as such. Finally, he criticises Irigaray on what he sees as an idea that mathematical reasoning might be somehow beyond the dispositions of women, who are perfectly adept themselves at understanding the tools of sets, probabilities and geometries that Maths has proposed. I think there is a lot to be said in defense of both parties here, but I think Irigaray's position is much less threatened by Sokal's response than might be concluded given the Wikipedia article. 

Sure. In certain modal logics, the concepts of necessity and possibility are taken as quantifications over those worlds that are accessible to a world, which allows us to say things like "necessarily, P, but not necessarily necessarily P". If we have a semantics in which there is a value assigned to a given world (let's say the number of cute fuzzy bunnies in that world), we can talk about the value of that measure in all of the accessible worlds (all of the possible ways things might be only have so many cute fuzzy bunnies). The choice function that says we can pick out an accessible world that maximises that value (we want "a world with the greatest number of fuzzy bunnies") follows from the semantics. Now what this line doesn't give you is an algorithm - it is just an existence property, rather than a generative procedure, as is common with most choice functions. To make this more palatable, you would need a more precise account of why some worlds are accessible and others are not. For instance, just what is it in virtue of which a certain number of fuzzy bunnies might exist? Arguably that's a matter of the science of the measured value, rather than pure philosophy. In my case ecology, presumably. For a more careful and considered notion of what it would mean to create a more Just world, say, you would really need to look at empirical political and social science, and what they tell you about how positive change can be brought about. (but more fuzzy bunnies would be a good start) 

The problem with doing this in a first-order theory is that the choices are what Saul Kripke, in his 1975 paper "Outline of a Theory of Truth" called Ungrounded sentences. Neither sentence says anything substantial except in reference to each other. 

The short answer is that Classical logic is about the idea that complete sentences can only take one of two Truth values: every grammatically well-formed sentence in a classical logic is either True or it is False. The longer answer... takes a while. The modern standard analysis of what Logic is can be described as its providing a framework with three different elements. 

Tarski's Convention T is not strictly speaking a definition principle for truth - it is an evaluation condition on whether a given axiomatically theorised predicate is a "Materially Adequate" definition to count as a Truth predicate. The work that Tarski did in showing how a truth predicate could be defined was not in presenting the T-Schema. That "snow is white" ought to be true if and only if snow is white is just something that Tarski reckoned anything that might be called "Truth" ought to satisfy, in the same kind of common-sense way that might meet your children's exacting standards. Tarski's work was presenting a way in which we might take our formulae of first order logic and understand what mathematical sense we might make of them. Tarski started by presenting the idea of a Model, as being an algebraic characterisation of a domain of objects, relations over and between those objects, for a class of names, constants and relation/property terms in our logical language, and a notion of an interpretation function that connects the various terms in our language to either objects or relations in our model. A model deems an atomic sentence (or ) true (or sometimes we say "value 1" to distinguish it from the question of the Truth predicate) if the interpretation of is an object in the domain that is a member of the relation interpreted by (that snow, being the interpretation of , is a member of the set of white things, being the interpretation of the predicate ). Then, the interesting aspect of Tarski's notion of a model is it matches the compositional structure of logical language, so we can add connectives like "and", "or", and quantifications like "every", "some" as part of how we mathematically model the domain of objects we're interested in, and build up more complex sentences from the basic cases. So thanks to using the maths of model theory, we can make sense of something Not being white, of what it would mean for everything to be white, or (given that there are other colours) how we might test whether something is "white and not some other colour" etc. By making mathematical sense of a logic in a model, Tarski showed that we could in principle define a Truth predicate over an interpreted language as a way of considering well-formed value 1 logical sentences as a class of "True sentences". He did this through a notion of what it takes for an object to satisfy an open formula. This is interesting, because it shows that there is not only a sensible and useful algebra for logical languages, but also a sensible and useful algebra for modelling logics and reasoning about how evaluated sentences might relate to one another. So if we want to be able to comparatively evaluate different logics or theories, we can use a Tarski-style definition to build mathematical models of their sentences and use mathematical tools to analyze them. As an example of how you might use this definition, suppose we might ask a sequence of logical questions, and want to test whether the resulting answers are all true. If Truth is well defined, there exists in principle a way of testing all of our sentences to show that they are all members of that class. Fortunately, for standard models, Tarski's construction satisfies the principle of the T-schema - a given sentence is a member of the class of True sentences just in case the sentence interpreted in the base model is given the value 1 through the model-theoretic semantics. So there is a fairly simple algorithm for evaluating all of some set of sentences for truth - namely, interpret them in the base model and evaluate them, continuing on if they get value 1 and returning if any gets value 0. This isn't going to be true of all sentences in all models (consider - the Liar sentence "this sentence is not true"), but the construction shows how we can characterise a truth predicate over some base model and thus treat it as itself an object for comparative evaluation. You can have a look at the SEP Article on Tarski's definitions for a more worked-through explanation of the mathematical project he was trying to build. A concrete instance of how this kind of reasoning sheds light on practical problems in mathematical logic is in the idea of reducing quantified logical sentences to a Skolem Normal Form, which massively simplifies the problem of automated theorem proving. We can do this because Skolemized sentences are "equisatisfiable" with their quantified counterparts. What we might say is that software specification and verification ought to be suitably founded in a semantics in just the same way that first order logic is founded in the model-theoretic programme following on from Tarski's initial discoveries. In formal computer science, this is studied in the field of Denotational Semantics and other related programmes, and some of the ideas about what kind of axiomatizations there are for correct software (and also hardware) behaviour are considered in Formal Specification and Verification logics such as Floyd-Hoare logic. 

The aim here is to find some sort of Diagonalisation procedure (the SEP article on Godel might be useful here) as applies to the domain of "powers"; we try to find some kind of power that can be defined in terms of the others but is somehow in contradiction with their universal closure. In this respect, your intention and technique in generating paradox is echoed in the paradoxicality of other notions such as naive versions of truth (the liar paradox), sets (Russell's Paradox) and computation (the Insolvability of the Halting Problem). It's reasonable to suggest that "powers" might not be sufficiently broad a notion to allow for definitions that might generate the contradicting notion you need - this would be an analogue to Asimov's response. But the converse is also a possibility; naive notions of "ability" might well be such that one could specify an ability that precludes the possibility of having every ability. At first, this seems likely. The ability to assemble a physical object that no-one could move and the ability to move any physical object seem like independently sensible notions, and we can easily show that I can't use both abilities simultaneously. Yet if our conception of what is possible is supposed to be predicatively restricted, you may find that these notions do not contradict one another. I can be able to move any currently or future existing object, and I can make an object that nobody is or will be able to move. I do not at any given time (or possible world) realize both of these potential properties at once, but that doesn't preclude me from either moving every rock that there is or will be, or building an unmovable artifice. Our intuitive reading of the abilities seems more in line with a more Impredicative interpretation of ability. Is Impredicative Definition a legitimate idea? This is a controversial point, and one current to much discussion in Mathematical Logic on the limits of abstraction. Perhaps the only legitimate sense we can put on our definition of Omnipotence is strictly tied to the set of powers that can be compositionally analysed. This would be an inferential weakening of the claims made by many proponents of the existence of an Omnipotent subject, but it may be one that gets them out of a lot of the more immediately threatening forms of paradoxicality in their position.