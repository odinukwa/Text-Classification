but as @greenlitmysql has mentioned you might see performance issues later on as the data grows (and length of column)... 

So there's tuner's logic, if the (Created_tmp_disk_tables/Created_tmp_tables)*100 is more than 25(%) then increase your tmp-table size (upto max 256M). Again, mysqltuner is for reference, if you don't see performance issues you don't need to blindly follow the suggestions. Also note that tmp table has nothing to do with InnoDB vs MyISAM (if you mean that in your last line). You might want to read about internal temporary tables. 

MySQL Installer provides an easy to use, wizard-based installation experience for all your MySQL software needs. Included in the product are the latest versions of: 

I donot think there is --ask-pass in xtrabackup! You might want to write a wrapper shell script which will 

So in anycase statement/row, you don't need to be worrying about the data on slave and it should match the master. but still if you want and can fit-the-logic on an event, this might be a possibility on slave at the risk of inconsistency!! As you said this is dw slave, would you consider a separate process to do the task you're looking to do, say a procedure? 

If you are the ONLY user connecting and manipulating data, I would suggest to download SQL Server 2016 DEVELOPER Edition (FREE) since it has tight integration with R. 

You can use sp_whoisactive to find out what is holding lock on the database or what SPID is rolling back. You can issue : 

As I mentioned earlier, Instant File Initialization will help with the restoring of full backup - cutting down the restore time. Setting up log-shipping won't involve a downtime on your primary server. It will only on your secondary server - if you are doing reporting and this is your case. It is by design, that during the restore - you cannot access the database. 

You are basically sending 1GB file from sql server which is max. You can reconfigure the default using 

However, if you configure an instance of SQL Server to use a static port, and you restart the instance of SQL Server, the registry values are set as follows: 

Note that the first query is able to do Index seek but has to do Implicit conversion while the second one does an Index scan which prove to be inefficient in terms of performance when it will scan large tables. Conclusion : 

Finally you can setup backup on this slave. (This is little complex than wht's written below) You may also have individual slaves for both masters and setup backups on them. You can later push those backup to remote location / network drive/ tape / upload to s3 to retain longer. 

As you already mentioned documentation that you cannot use table level filtering on replication. You might like to try another approach instead. Replicate whole database and change all tables except those you need to use to engine. 

(Consider backing up binary-logs if you want point in time restores.) For backups you can use traditional mysqldump or mydumper/loader. If your data size is large, it'd be better to go /w physical-backups, follow settingup xtrabackup for mysql with Holland framework. 

So yes as you have mentioned about SQL injection the other advantage is what you guessed. Quoting from documentation: 

You can generate these SQLs from information_schema database and source it to mysql to quick action. 

Because the flush to disk operation only occurs approximately once per second, you can lose up to a second of transactions in an operating system crash or a power outage. Well I just copied all of the above from documentation ;) Anyways, now about your points. 

This means that the dbs are decoupled or independent. I would say, club the dbs depending on the criticality and uptime SLAs and then distribute them between 2-3 servers (VM would be another option as well). This way, you dont put all your eggs in the same basket. Why ? 

The key here is which has a lot of information. Remember that triggers (whatsoever) cannot be used for backups. For backups, you have to tailor your own custom solution, but the idea remains the same. 

You have to create a login on the prod server as when you restore the backup to PROD server, you are having an orphaned user. So steps are : 

Rebuilding an index will update stats on the columns associated with that index. There can be a lot of variables which might be different between 2 servers (2014 vs 2016) 

It would be difficult to do that using Native tools or you will have to look for third party tools. Natively: 

Note: I have not tried the SQLDump, as I would personally prefer SSIS or T-SQL along with BCP and BULK INSERT - to move data out and in of sql server. 

Well you can review what mysqldump does on git and try working on it!! Though I'd not go this way... Few things to suggest: 

You have few options to consider but first I hope you're not troubling your production server but may be a slave of it to dump out things? (things may get bad there.) 

It is obvious to have better performance for the value of innodb_flush_log_at_trx_commit as 2 than 1. As commit operations are fairly dependent on underlying system even fooling-by-OS is an extra step one takes for every commit. For value of 1 flushing to disk operations are bound to happen every transaction while for 2 it happens once a second (depending on OS scheduling) 

When you cannot identify a primary key for a table you need to use surrogate key; auto_increment columns are most common surrogate keys which database internally provides and hence you should use them then. You may alternatively have sequences or programmatically handle uniqueness... 

Here is an old instructions for setting up master-master replication for windows but concept is same. Considering you already have a 3306 instance by default you can follow below steps to setup as well (if above doesn't help) 

Very feasible and supported by the vendors (e.g. Microsoft in-case of SQL Server). I have done plenty of SybaseASE to SQL Server migrations. Best is to use SQL Server Migration Assistant (SSMA) for migration. Refer to : 

I have written an extensive list of things you should check when you migrate from 2000 to higher versions 

Instead of reinventing the wheel (there is a cost associated to it), use SQL PowerDoc written by kendalvandyke. Its a powershell based solution. Documentation can be found here. 

If you want to audit on an ongoing basis then a server side trace will do the job. Below is how you will script out from Profiler 

To overcome the performance problems that might result from missing or stale stats, SQL Server team came up with temporary statistics in TempDB. Refer to : Making latest statistics available on Readable Secondary 

This is totally dependent on opinions. There is no right or wrong answer to this question. if you are using SQL Server, then the naming convention that I would follow is databasename.schema_nmae.tableName. So for storing changes made to table, it will be . Make sure you are in the right database when you create the table. For sql server 2005 and up, dbo is the default schema. 

Active-Passive master-master is a good setup but I have seen SUPER (humans)users writing on slave without setting sql_log_bin. (Though super_read_only in 5.7 will change things around this.) Anyways, following is possible and works. 

Before doing any changes and attempts, take complete backup of your databases. If you have physical backup of your database: 

"My current mysql backup strategy is replication." Replication cannot be a backup strategy but you can setup backups on slave! I guess you're talking about HA "if master fails then use slave"... Anyways... MySQL 5.7 comes with Multi-source replication. You can have single slave machine replicating from two different masters. You may write your own script to loop around CHANGE-MASTER-TO switching masters and replicate. Idea for you: 

Now, if you need slave's changes to be reflected on master, you need your master to be replicating from your slave as well. That's known as master-master replication. You can find plenty of posts around that. By default, all the databases are replicated. If you want to replicate only few of the objects (DB / tables) there are replication filters for that. 

Seperate spindles is the best recommendation. Read on When should you put data and logs on the same drive? 

Mirroring uses T-log to replay everything from principal server to mirror server. So Full recovery is only possible. check : recovery models. 

The above test proves that the method provides more benefit in terms of Transaction log generated as it is minimally logged operation + incurring less logical reads. Note: This is just scratching the surface, there can be more tests done to actually prove in terms of performance if WRITE method is performing better than the regular UPDATE especially when dealing with VARCHAR, NVARCHAR OR VARBINARY datatypes. 

Note: This will not limit what gets logged. It justs stops logging in Windows Event log. There are some stuff that you can prevent like - successful completion of log backups using Trace Flag 3226 Have a look at -n startup parameter. From Database Engine Service Startup Options : 

Once you gain access to sql server, then create a login and map that login to a database. Make sure to NOT delete it again :-) 

Oprn. is "slow" because you do ensure the data durability & consistency. Oprn. is "Fast" because you did less work (disk operations). Even for the "lies" mysqld goes an extra step. 

2TB restore from mysqldump?? How long do you have? mysqldump produces logical backup and it'd take longer to restore. Not scaring but I'd not dare to dump a 2TB database (unless you must)! I'd rather consider taking hotbackup. About your other questions: 

Yes, if your mysqldump is backing up all databases! If not, for future make sure you use with mysqldump. Alert but this will take your system to the state what it was earlier... If you know what your java programs are connecting using (user-name and host) then you can choose to fix the permissions for that!! 

No. Grants are not defined per database (as in mongodb 2.4). mysql database is a centralized system of records for authentication etc... (just like admin database in mongodb 2.6+). You might want to refer the document for mysql privilege system. 

Create windows login on ServerA Create user in database mapped to login Drop login on ServerA - (OPTIONAL -if you want to have that login intact then leave it, else drop it). Grant any required permissions to user in database Create login on log shipping ServerB 

Above all are described in this KB article How to grant users rights to manage services As a side note, you can use sysinternals tool - accesschk.exe. It will help you to find out - 

Yes, stats created on Primary replica will replicate to secondaries. The secondary is a strict replica (copy) of primary database. So, the stats are created in tempdb linked with the readonly database. SQL server will maintain statistics of read-only secondary databases in tempdb. Your secondary workload (readonly) will be different from the primary workload (will be mostly writes (more) and reads). From : AlwaysOn: Challenges with statistics on ReadOnly database 

Ideally, it should not take 60 mins , but again it depends on what you are doing. If you are pausing and then stopping sql server then it probably might. If your entire goal is to stop sql server, then I would suggest you to (in maintenance window) : 

mysql will write rollback to binary logs provided the transaction has mixture of engines (myisam and innodb tables). As the myisam can not be rollbacked. I guess you'd like this piece of documentation... 

This will let the slave catch-up with latest available changes from master. If your binary logs were not yet shipped (via replication) to slave, then you might want to ship them manually and play it on slave. (Provided they're available - as you say you have co-ordinates) 

I saw query then explain and then table definition and first question came into my mind. Why are you still on MyISAM @ 5.5? Let's just change this to InnoDB and you should get the results. This 0.1 to 2 range could be caused by locks or other reasons but let's avoid that issue first? Be-aware that below conversion will lock the tables and may cause downtime. 

So if you're setting 6 servers, you can set them as: auto_increment_offset=1,2,3,4,5,6 auto_increment_increment=6 so on each servers insertion series will be like: 1,7,13... 2,8,14... 3,9,15... 4,10,16... 5,11,17... 6,12,18... Idea here is just to generate unique auto-increment numbers. BUT WAIT!!!!! Before you begin, when you say 6 servers it will be pair of 3 master-master or are they slaves of original master? If they're slaves, are they going to accept writes (not good!)? Are you going to write on all nodes (in case of master-master? The architecture isn't clear enough and hence your solution of auto-increments might not be right / required as well. Anyways... I hope we fixed the confusion of auto-increment. Trust the documentation and don't get confused by too many articles.