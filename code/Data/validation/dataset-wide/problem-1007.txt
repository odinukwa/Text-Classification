It's reporting CPU usage and where I found it in the DMVs - the ring buffer. The ring buffer isn't CAUSING the high CPU use. To find queries doing high CPU use, use sp_BlitzCache @SortOrder = 'cpu'. For more details, check out this post from Microsoft's Premier Field Engineering team on using ring buffers to track CPU usage inside SQL Server. 

If you restore a database as a new database, the dbi_crdate field is the restore date/time. Here's how to reproduce it: 

I've seen this happen a lot when folks only have one set of network cables connecting their servers - meaning, a pair of 1Gb Ethernet cables in each node, at best, and they're using those for both regular networking as well as iSCSI storage connectivity. (The fact that you're using Equallogic is a clue - I've seen a lot of those with 1Gb implementations.) If you have any networking problems at all: 

These are big decisions that involve a lot of architecture work. For more detailed specifics, include the above details, and we'll be able to tell you more about how to configure it. Q: Isn't it just a matter of checking the box for Always On? Nope. 

If you can add columns to tables, you can try persisted computed columns, and index those. For example: 

"This table has the appropriate indecies but is becoming a major hangup when running queries" Partitioning alone doesn't help query performance unless SQL Server is able to eliminate partitions when running a query. Your WHERE clause needs to line up with the way you partition. We only get one field to use as a partitioning field, so if that field isn't included in your WHERE clause, you're still likely to scan the entire table despite having partitions. "and just because of its size." Partitioning can make certain maintenance operations easier, but there's still things we can't do on a partition-by-partition basis. If index maintenance and stats updates are causing you problems, you're better off splitting the design into an archive table and a live-updated table. When you need to periodically move data from the live table to the archive table, you do that, rebuild the indexes with 100% fill factor, update stats with full scan, and then set its filegroup to read-only. Partitioning can help with archive table loads - but partitioning the live table may not. (I'm tossing out several advanced concepts here as if it's quick and simple, but I'm just sketching out some background here.) "It appears that using the partitioning would require less code changes." Sorta kinda - it looks that way at first glance, but the more you get into it, you've got options like partitioned views. You can rename the existing table, put in a view in its place, and then you can make your own changes to the underlying tables (and add multiple tables) without changing your app. I've written more about the pitfalls of partitioning here: $URL$ 

Create a new database. Run DBCC CHECKDB() on it. Look at DBCC DBINFO() for the creation date and DBCC dates. Back up the database. Delete the database. Restore the database (if you want to get fancy, use a different database name.) Look at DBCC DBINFO() for the creation date and DBCC dates. The creation date will be the restore time, and the DBCC date will be earlier. 

You know what they say - premature optimization is the root of all evil. First, write the query to get the data you want, from the tables you have. Then, if it's not fast enough, post the execution plan here at DBA.se in order to get the best advice for you. What you call "large" may not be what other folks call large - I've seen people call a 1GB table "large," for example. The advice we give here for a 1GB table is very different from the 1TB table advice. 

That's why the coalesce has to be outside of the search operation: you need it to happen even when there's no rows in the result set. Now, let's look at your query. I'm going to take the subquery out on its own, and I'm going to hard-code values for one of the rows where you want the COALESCE to work, but it can't: 

Your comments note that you're specifically talking about full-text indexing. You can indeed query the database while a full-text index is being created. Full text indexes are created in the background on SQL Server 2005, 2008, and 2008R2. You can continue to query the database using the LIKE operator, although of course the queries won't be as fast as a full text index, and your database server's performance may be degraded while the index is being created. 

Beyond the Cost Threshold setting, SQL Server appears to treat parallelism differently for columnstore indexes depending on your SQL Server version (2012 vs 2014) and even the datatypes in your table. I'd start with Joe Chang's post benchmarking decimal vs float datatypes, and read the comments on that post as well. If you want to get exactly the right MAXDOP and Cost Threshold for Parallelism settings for your system, you'll need to perform the level of detailed testing that Joe does in his post, and that takes a lot of work. Because of that, I would focus on your system's primary bottleneck first - use wait stats to make sure parallelism or CPU pressure are problems for you, and then start by tuning the most CPU-intensive queries rather than making system settings changes. 

You're getting those errors because something is trying to connect to SQL Server via SSL, and you don't have a real (signed) certificate trusted by all parties involved. By setting "Force Encryption" to Yes, you won't make the errors go away - actually, the opposite. You'll make the errors happen everywhere, because you're not fixing the root problem. Right now, only a few things are trying to connect via SSL, but you're about to make EVERYTHING connect via SSL, which means everything will throw those errors. Bad idea. Instead, track down what's trying to connect via SSL. If it's happening at the same date/time every time, you can set up a trace, or figure out what servers are running batch jobs. Then, THAT server is the one that needs a real cert (as well as the SQL Server) - or just change that application's settings so that it's not trying to connect with SSL. 

Stop people from breaking the server When they do break the server, be able to identify exactly who did it 

Sure, some database platforms do handle read-only or mostly-read data differently. For example, in Oracle, you can choose to enable results caching, which lets the database engine save query results and reuse them when it sees the same query come in again. That's really useful for data that rarely changes. However, you wouldn't want to bother enabling that in scenarios where you know the data will change. Another example: in SQL Server, if you set the entire database as read-only, SQL Server handles locking differently. It doesn't need to worry about transactions when you can't modify the data. I know what you're thinking: "Why can't the database engine figure it out?" Because data access patterns can be complicated. For example, you might have a data warehouse that is loaded from scratch every night, and then is read-only all day long. You wouldn't want the engine to bother even trying to cache ETL query results overnight during the loads, so you'd want to turn that kind of thing off overnight to maximize load speeds. 

Depends on your database engine. For example, in Microsoft SQL Server, there are several database engine features that can track which rows have been changed, and then you can grab just those rows in your periodic query. Another technique I've seen is to add an UpdatedDateTime field on the tables you want to search. Use a default value of the current date/time, and add an update trigger so that whenever the record is updated, the UpdatedDateTime is reset to the current date/time. Keep in mind that you'll probably want to index that field since you'll be querying it frequently. Then, in your app, just poll for all records where UpdatedDateTime > the last time you updated. If you take the latter approach, you'll probably want to do full repopulations periodically to catch any goofups where the polling app failed for a while. 

Why would Microsoft build it? Well, if they want to let someone get a file list without running a RESTORE command. Could be a separation-of-duties thing, or could be making the automation plumbing easier for Azure Managed Instances. 

Update with sp_WhoIsActive - in the sp_WhoIsActive screenshot you posted, you've got a couple of queries that are waiting on ASYNC_NETWORK_IO. For those, refer to the above instructions. In the remainder of the queries, look at the "status" column of sp_WhoIsActive - the majority of them are "sleeping." That means they're not working at all - they're waiting for the apps on the other end of the pipe to send their next command. They have transactions open (see the "open_tran_count" column) but there's nothing SQL Server can do to speed up a sleeping transaction. These queries have been open for over forty minutes (the first column in sp_WhoIsActive. They're just not doing anything anymore. You've gotta get those folks to commit their transactions and close their connections. This isn't a performance tuning issue. Everything we're seeing here points to a scenario where we're waiting on the app. 

The easiest solution is actually free: Microsoft's Virtual Labs. You get access to SQL Servers in the cloud, plus step-by-step instructions on what to experiment with. (You aren't required to do their tutorials, either - you can use the VMs for anything you like.) Keep in mind that there's a few restrictions: you can't surf the web from there, and you can't copy/paste things in. Because of that, it's a little limited - but you can't beat free. If you're going to run your own SQL Server, I wouldn't recommend doing it in the cloud since you pay by the hour. You're better off using a free virtualization tool like Hyper-V, ESXi, or VirtualBox, and then installing the totally free SQL Server Developer Edition. Good luck on your learning journey! 

You posted a bug on this at Microsoft Connect: SQL Server 2016 SQLServer:Resource Pool Stats:CPU usage target % Always Returns Zero - by HunterX3 Given that Microsoft didn't respond there either, it's probably a bug. Open a support case with Microsoft, and if it turns out to be a bug, they refund your support fee. 

At first, it basically looks like sp_WhoIsActive, but here's some of the additional columns it shows: 

Put the distributor in a virtual machine, and use the hypervisor's high availability tools. This lets you survive host hardware failure. OS problems will still cause issues, though, so for an additional level of protection, you can run clusters inside virtualization. 

Try my free Learn to Query SQL Server with the Stack Overflow Database. You can either run the queries locally with the Stack Overflow SQL Server data export, or through your browser with Data.StackExchange.com. 

If that fails, you've got a communications issue between the principal and the mirror, and that's where the fun begins. It can be anything from IP connectivity to security on the mirroring endpoints to different encryption methods. I'd recommend Robert Davis's book Pro SQL Server 2008 Mirroring if you need to get into deep troubleshooting. 

Here's a couple of reasons when SQL Server will use the index rather than the clustered index. (I'm a SQL Server guy, so I'll leave this to a MySQL person to edit if there's slightly different syntax for MySQL.)