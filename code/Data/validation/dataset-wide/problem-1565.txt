This is small line of code might be critical to the performance of your algorithm. There are a thousand different ways to chose a pivot-element. Why did you choose this? Move it to it's on function . You might think about adding a comment why you chose this method. 

Gotten lazy at the end, hm? I can live with and . But what really bothers me is . Your describes the point at which the array is split. Lets call it like that: makes a lot more sense. (I am personally not very happy with the variable name as it may describe a keyword in another language, but I've seen it so often that I'm just going to leave it untouched.) 

What is the responsability of the -class? A board is supposed to hold some sort of players and objects for a game. In this case: The 'X's and 'O's. Hold them, keep them, no more, no less. Your class however does the following: 

Then calling the can be shortened up into just while your local class is called with just plain old . 

Which my tiny brain can't even begin to wrap around. I do see an awful lot of duplication here though. With the exception of (which should be by the way), the first coordinate in each of them is the same. Precalculate it and store it in a variable. 

There is no requirement in a *.csv file that there be a space after the comma between items. In fact, if there is a space, that space should be considered part of the item, not part of the delimiter. The next thing I notice is that comma separated files are not strictly separated by commas. Other delimiters are possible, and likely to be come across. Things such as pipes are common. I would consider supporting other delimiters. For example, Excel supports Tabs, Semicolons, Commas, and Spaces, along with an option for a custom defined delimiter. You might not want to fuss with supporting user defined delimiters, but certainly your class becomes more useful if you support the ones I've mentioned. The process of implementing this should clean up the string literal duplication you have here. 

I can also limit the amount of elements processed. That way I can visualize the first 10 million elements of . I find this visualization to be of limited use, but I guess it makes more sense to you? 

At this point we could start to tackle the loop, but it would start to get very micro optimized. One might consider aggregating the results in prob and then using and outside the loop, but that only nets like so it's more of a personal preference thing. 

Assuming is an okay thing to do you don't want to check after ing an element but rather before you insert it. It saves you the overhead of appending and popping visited nodes which can be quite substantial. Further, should be a (as stated in @Alex 's comment). It could also be a good idea to use an actual queue object, be that (for FIFO / LIFO) or a . The latter will slightly reduce performance (insert from O(1) to O(log(queue_size))), but offers a lot of added flexibility and easy scalability to graph search. Setting the priority to: is DFS, is BFS, (or ) is Dijkstra's search, is greedy search, is A*. I think that's a really cool property. 

Note that I use this method for serializing many different classes, so it requires that you tell it what type to save back to XML. You could modify it to be specific to your class, but I'm not sure there's a benefit there. And finally, the client code can load/save classes (and their state) to XML pretty simply. 

VB6 doesn't allow for short circuiting, so you might as well break this into two separate statements. Both conditions are always being checked anyway. This has an added benefit of giving a more specific error message to the end user as well. To keep the extra code from cluttering up your main function, I recommend creating a private that returns a boolean. 

It just occured to me that you might not want to repeat this code each time you need to pad to a different length, so you could wrap it in a function like this. (Even though I still hate passing in a number as a string.) 

further we can replace the strings and with a Boolean and stay in numpy for longer (down to 1.633 seconds): 

There is a steep gap after buildins.sum, i.e. you spend most time there. We can use instead (pushing it down to 3.457 seconds): 

You can safely remove this line. If you want to do functional testing, I would move such tests into a separate folder to not pollute the main code. Also this test case is not even remotely sufficient ;) 

will concatenate all sequences, despite them potentially belonging to different DNA Sequences. Here is Wikipedia (the best source to cite xD): 

Large Array There is multiple optimizations you could do, but only 1 that really makes sense here: Bin it. You don't need it. You pre-compute a lot of information that you reuse exactly once and that you can compute on-the-fly. There is no benefit in having this. In fact, you are making it worse by reading the once and then reading the array version of it, which is 40+ times bigger. Not cool :D The short version of it is that is wrapping python s which store 5-tupels worth 40 byte per entry. takes to represent in this format, whereas you can instead stick to a single character worth 1 byte and look-up the value as well as compute using the predecesor (which you know). This will save 40(!) times the disk/memory space (down to after optimization). Here is a version that uses , but saves only a character (worth 1 byte) instead of the tupel (40 byte): $URL$ I've also added as dependency and refactored your code (a lot) because I couldn't make heads and tails of it. Here is an even shorter version that no longer needs : $URL$ I also removed the timing comments, because that can be done more efficiently with or another profiler of your choice. In this scenario, I felt like the prints obstructed the code a lot; now it's easier to read. If a blinking cursor with no output irritates you, feel free to add more prints (at the cost of readability and a tiny bit of runtime). 

You're converting to a string outside of the block. Like I said, I'm not absolutely certain, but it at least looks potentially problematic. Are there any crazy edge cases where won't get cleaned up in the ? I don't know, but why take the chance? 

I was inspired by Processing a list to build an IP in String Format to reinvent the wheel a little bit and play around with explicit struct layouts. You see, an IP address is really made up of four, 1-byte numbers. Each Octet of an IP address is one byte. So, this means that an IP address can be represented by either 4 bytes, or a single 32 bit unsigned integer. In other words, this is why the "largest" IPv4 address is .