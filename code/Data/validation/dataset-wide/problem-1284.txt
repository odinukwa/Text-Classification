The big idea The idea behind these patterns and similarity measures is that given historical data we compute a pattern and a future price change with the idea that the pattern implies the future price change. Then given current data we compute the current pattern and search for a similar pattern in our database from which we can deduce the corresponding price change. The main problem is that the function is not symmetrical in its arguments, i.e. and may have wildly different values. Consider these examples: 

and it avoids having to return the object from the player object. Perhaps my implementation of isn't quite correct, but you can make it work. 

Use Here is a blog post containing an example: (link) Have a look at the language-python package. It's lexer is built using : (link) Purescript handles indentation via the , , and functions: (link) Grep the rest of the source code for these functions to see how they are used. Its lexer defines a token (link) but from what I can tell it is never returned, i.e. see (link). The indentation level is kept track of by the parser (link) via the function. 

The other thing which will help is to keep in mind that the type represents a a combinator which is able to memoize a function whose argument type is . So: 

The prediction algorithm then boils down to a nearest neighbor search in a high number of dimensions (e.g. the length of the pattern array.) 

is another potential expensive call. I would detect alphabetic characters using comparisons with the end points of the upper- and lowercase character ranges: 

These work like the and functions in other languages. Let's assume the first and last characters of the alphabet are the standard and . I've leave you to figure out exactly what the code should look like, but here are some hints: 

Notes A faster way to check if a file has been processed would be to add a character indicating that it has been processed, for example: 

What this means is that when the comparison fails, E is updated to the current value of X. If the comparison succeeds, X is updated with the value of N. Therefore, you don't need to update X again! That is the whole point of a compare/exchange operation; you're basically saying: "I was the last to modify X." Issue #1: Unsynchronized access to writer In your code, you perform a store to the atomic variable with a copy of a value you last obtained from the update performed in the compare/exchange operation, but this is not atomic. 

2.2. function_traits.h These are simple template class specializations that provide the required function traits for the implementation of . I realize that specializations for and functions are required. 

Welcome to Code Review. This queue implementation is not truly concurrent-ready. Arbitrary initial capacity 

3. Sample usage Here's some sample usage to show how a user can get the return values. Basically, the user would send in their function/functor to the dispatcher and would take care of the rest; the dispatcher would return the from its submit-a-function function. 3.1. Example 1 This example is pretty much just a test of the template deduction rules and shows how you can use a collection to erase types. The main feature is that you can have a collection of functions that all have different signatures and return types. 

Why have you decided that the default size should be 100? Different people have different needs; having default values like this isn't a good idea because there is no true advantage to having a default size of 100. While this is subjective, I suggest you remove that default size and just have users be required to specify the size that they want. Compare/exchange confusion There seems to be a misunderstanding in regards to the use of compare/exchange. The compare/exchange operations work as follows: 

A clique is just a set of Ints. You could use a linked list, or a bit set, or whatever you want. Here is part of a Haskell solution which might help you structure the problem in C++: 

Even though they are not needed, they aid in reading the code. Also, aligning the in the case patterns helps with readability. The type signatures on your calls are not needed due to Haskell's type inference. insert You should be getting this warning from ghc and ghci: 

Given these observations, why not just pass the first and last characters of the alphabet to , i.e.: 

This means that your code doesn't cover all of the possible cases. Append to your question an updated version of which doesn't produce any warnings, and then I might have some further comments about it. (Please append to your question instead of modifying it so it doesn't invalidate any existing comments.) Let me know if you are not seeing this warning from ghc / ghci so we can figure out what's going on with your environment. filterEmpty I don't think the logic is right here. What if you have this message: 

The key is to use with an increment of 1 starting from the previous computed config. Using this idea, here is a better definition of for a general : 

So build up the solution iteratively. If you have the placement how can it be extended to a valid placement ? Clearly r2 can't equal r1 and (0,r1) can't be on the same diagonal as (1,r2). And, of course, r2 has to be a valid row number. 

e.g. is all the ways of removing one element from the list . Also, using the polymorphic signature alerts the reader that the function isn't specific to Ints. I would also introduce a type alias: 

3.2. Example 2 This example displays a more "real-world" use. Instead of having the function call , that would be done by threads consuming from the data member. Since this is an example, I've provided a simple function that works only for free functions; overloads can easily be added to deal with functors and member functions. 

To indicate that the first three files have been processed. You would then only have to check the first character of every line you read, instead of the whole file name, to know which files have been processed. This is the technique I would personally use, as it doesn't require an extra file and it keeps the original file mostly intact while providing a much faster comparison. 

I've actually implemented the same functionality in the past, so here are my comments. Wrong behaviour? It depends on what you can consider wrong. Consider running your own example and inputting . The 2nd will be left in the stream buffer and will be automatically assigned to your 2nd variable. This clearly causes weird behaviour, but it is the same behaviour that occurs when normally using . Suggestions The following are what I consider to be useful features for such an utility function. Better interface In order to provide a nicer interface, you could instead read a single value from your stream and then discard anything else that's been left in the stream buffer; calls to will always return one single value and successive calls won't be forced to take what's left in the stream buffer. Example 

1. Description 1.1. Functionality The objective of these types is to provide type erasure for any function while maintaining the ability to provide a return value through a combination of and its associated . 1.2. Motivation This is useful for any sort of dispatch manager, a thread pool that you can submit tasks to being the actual target; where a task is any function with any parameters and return type. 2. Implementation 2.1. deferred_invoker.h This is the main functionality. Type erasure is provided through the base class, which simply has a virtual member function that is called when the function has to be invoked. The specializations will then know how to deal with the invocation and whether they have to save a result. They also take care of ensuring the correct initialization arguments required for the call are initialized and saved in a tuple. This applies for template parameter which is any function. A simple tag dispatch system takes care of return types. I've omitted a third implementation of for lambda and functor types to focus the review. It's basically the same style as the other two (possible design issue?), but it takes a copy of the lambda/functor and the arguments, instead of a pointer to the function. 

The idea is to keep track of the last node in the chain so you can update its field when you create a new node. 

The method is relative slow but indexing using is very quick. Instead of appending each wanted pattern and then calling to find it again, just append the index to : 

Define a variable which will hold all of the cliques found (of any size.) Initialize to just the empty clique. Consider the next node - call it . Let be all the new cliques you can form by adding to an existing clique in . Check for a solution. If no solution is found, add to and repeat from step 2. 

Then you have a list of primes and their exponents: (p1, e1), (p2, e2), etc. and the number of divisors is: 

where is the (infinite) list of primes and returns all of primes less than which can be combined with . 

How large are these files? My suggestion would be to load the entire compressed file into memory instead of using multiple calls. If you are storing the decompressed contents in memory, surely you can also store the compressed file in memory as well. Most of your run time is spent fetching bytes with , so being able to replace those calls with direct memory accesses should improve performance quite a bit. Another suggestion I have is to use instead of this loop: 

You've gotten rid of a lot of global variables, but you can do even better! Consider writing this function: 

First of all, the class describes a player in the game, so maybe reflect that in the name of the class, e.g. . In that respect the name name is good because it gives clues to the reader as to how the object is used. Secondly, if I read and correctly, you are just returning a copy of an object. Surely there must be a more idiomatic way to create a shallow copy of a JS object that doesn't require explicit looping? Or, how about just returning and hope that the caller doesn't modify it? Or, why do you do even need to expose ? I don't see where you call it. And for you don't need to expose the entire object - you just need to know if a player has a weakness for a specific user name. In the class , just expose this function: 

Imagine a first call to in thread A makes it inside the statement and gets stalled just before executing . Now another thread B calls and successfully gets past ; the writer now has a value different than reader because of the compare/exchange operation. However, the store of an element has not happened yet since thread A is still stalled. What is thread B going to pop? It's going to access whatever garbage memory is at that location. Issue #2: Malfunctioning empty function The load from and the load from followed by a comparison is not thread safe. 

Basic algorithm Since you have very large files, you should consider streaming the file one line at a time instead of loading them all once; your program would use a lot less memory. You would also not have to copy your , which is very large! In order to know which files you've already processed, you could create a new file that holds a list of all the files you've processed and write to it as you stream from the original file. This is of course, assuming you want to keep the original file intact. I will continue under this assumption as the other case (simply delete from the list as items are processed) is simpler. Check the Notes section for a better idea that you can implement with inspiration from the following section. Implementation The following is a sample implementation for the algorithm I described in the previous section. For brevity's sake, I did not include the items mentioned under the Form section, nor did I include exception checking; I will leave those things for you to figure out. It is also most likely not as optimal as it should be, but it's merely meant to show you streaming. Sample 

parseMessage The main problem here is that you are calling on the result of , and this doesn't preserve the original whitespace. For instance, the last case should just be: 

Note - my JS is a little rusty, but this should illustrate the idea. Update: Per our discussion in the notes, I am suggesting changing this code: 

partitions This is inefficient since once you have one person's items you know what the other person's items are - just take the complement. Also - does this condition really work if two items have the same value? 

The only drawback is that explicit bounds have to be determined for each level function. This approach computes in about half a second. 

returning a list of tokens? I'm not sure there is a lot of value in parsers which return except, perhaps, for testing purposes. Most of the time you want to run a token parser incrementally, but has to consume the entire file before it can return anything. There should be a function which just returns the next token. This will come in handy in conjunction with the next comment I have... handling dedents at eof I would find another way to handle implicit dedents at the end of the file. I'm sure this can be handled at the grammar level. The code to add them is extremely messy - don't you agree? Have a look at how the package does it: $URL$ The function returns just a single token. The lexer has state, so when it reaches EOF it checks the current indentation level. If the indentation level is > 1, it decrements it and returns a . Otherwise it returns an EOF token. 

Note that always assumes that is defined, and it doesn't have to return it since all invocations modify the same object.