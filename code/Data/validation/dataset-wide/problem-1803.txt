Thank you. PS: I basically want to replicate a Cpanel shared/reseller hosting environment, but with Plesk since Cpanel for Windows is not yet available and been delayed forever. 

How do I apply a MAC Address (of my choice, not random) to a VE (Virtuozzo powered) I tried this: [root@node root]# vzctl set VEID# --mac "actual mac address here" --save Invalid usage. Option --ifname not specified In order to license software for use for my client's company, the vendor needs the MAC Addresses setup for their vps' virtual enet interfaces. Tried various methods, not working. [root@node root]# vzctl set VEID# --mac --venet "mac-address" --save Bad parameter for --mac: --venet [root@node root]# vzctl set VEID# --mac --eth0 "mac-address" --save Bad parameter for --mac: --eth0 [root@node root]# vzctl set VEID# --venet --mac "mac-address" --save VEID#: unrecognized option `--venet' [root@node root]# vzctl set VEID# --mac "mac-address" --save Invalid usage. Option --ifname not specified [root@node root]# vzctl set VEID# --mac "mac-address" --venet --save VEID#: unrecognized option `--venet' Edit/Delete Message The Virtuozzo NODE uses Centos, as does the VPS container. 

Apache2: 192.168.2.139 Tomcat Node1: ajp://192.168.2.166:8010 (http connector also defined on port 8082) Tomcat Node2: ajp://192.168.2.166:8011 (http connector also defined on port 8083) 

I have a Java web application (using , and some other goodies), which is deployed using . Deployment works fine, and so does calling the application (using the Apache2 as the proxy, meaning ). The front-end shows up fine. 

So, when the button gets clicked it fires a sending a JSON object to the Java backend using the URL . 

I have set up keepalived on two Debian machines for high availability, but I've run into the maximum number of virtual IP's I can assign to my . How would I go about configuring and failing over 20+ virtual IP's? This is the, very simple, setup: 

Note that you should not run this on the domain controller, so if licensing allows it deploy a new machine for this purpose. 

I'm playing around with a test server, install Xen on a Centos 5 box. $URL$ I've tried two methods to create a vm. virt-install and virt-install -x "ip=xxx.xxx.70.212 gateway=xxx.xxx.70.211 subnet=255.255.255.248" If I do virt-install, it asks me this: $URL$ Automatic DHCP never works. If I try manual config, I have no idea what to put it. I did try this: IPv4 address: xxx.xxx.70.212__ / 255.255.255.248_ Gateway: xxx.xxx.70.211___________________________ Name Server: _________________________________________ note: only here in my post am I actually putting "xxx" in the IP for privacy reasons only. The 70.212 is the main server IP that I ssh into. See 2nd screenshot for error. Same thing with various valid mirrors I tried. $URL$ This is my ifcfg-eth0 info: DEVICE=eth0 BOOTPROTO=static IPADDR=xxx.xxx.70.212 NETMASK=255.255.255.248 ONBOOT=yes TYPE=Ethernet I've tried 2 different mirrors so far, same error. $URL$ $URL$ My resolvers are just fine too in /etc/resolv.conf Note, I did not do anything at all. I had a fresh Centos 5 64bit install and then followed that Xen install guideline. That's it. 

It's currently a litte tricky to get running, but worth it and looks great. Hopefully it'll become default GUI for Nagios someday. 

Thanks in advance. EDIT: @David Schwartz said it would make sense to add a route, so I tried adding a static route to the pfSense firewall, but that didn't work as I expected it would. pfSense route: 

Am I doing this wrong? I also removed all VIPs from the keepalived.conf so it only fails over 10.200.85.100. 

I have been asked to rebuild our load balancing infrastructure in the data center. The original request was to load balance FTP servers. I tried doing that using the current load balancer (), but didn't get it up and running. Not just because there's little to none documentation for this software. Since is considered deprecated, I went over to after a couple of days trying, which did the job in a fraction of time spent on . So I've got FTP load balancing (passive mode) in place. Now, I was asked to replace the whole Piranha Load Balancer in the data center. In the current Piranha configuration, we have several web servers, IIS servers....aaaand DNS. No here's the thing: seems to be a commonly used LB, but it is not capable of handling . This is a bummer, since I like how works. So I googled a lot and came across several things. Most people seem to use as a LB for DNS (TCP/UDP). Some use , some use , and some use . Since I would want to stick with for FTP, HTTP, IIS servers, I got confused on using it side by side with . Requirements: 2 LB instances with failover 2 DNS servers (already existent) with failover Multiple backend servers (http, application, etc...) Questions: Is this possible? Is UDP load balancing on DNS servers even necessary? Is there any kind of resource that might show me how to get started with that? Or is there a LB solution that is capable to not only handle TCP/HTTP, but also UDP load balancing? 

You should look into WSUS (Windows Server Update Service), free tool, that does exactly what you want. It runs on one server with Internet access, and takes care of updating other servers behind the firewall. 

It says in the first log. Try telnetting from your Openfire machine to the SQL server port and see if you can open a connection. If not then you might want to check the firewall rules and allow incoming connections. The second log is merely telling you that the connection string is invalid, and it doesn't know where or how to connect. 

Calling the application directly on one of the cluster nodes using the works fine as well. So, I assume this has something to do with my setup. 

When I run this locally from Eclipse, it just runs fine (and it comes back with the URL of the Tomcat instance). Running it in the Cluster gives me the following and coming back with the URL from the HTTP server: 

Each machine is also running Apache (later Nginx) binding on the virtual IPs for SSL client certificate termination and proxying to backend webservers. The reason I need so many VIP's is the inability to use VirtualHost on HTTPS. This is my keepalived.conf: 

An identical configuration is on the BACKUP machine, and it's working fine, but only up to the 20th IP. I have found a HOWTO discussing this problem. Basically, they suggest having just one VIP and routing all traffic "via" this one IP, and "all will be well". Is this a good approach? I'm running pfSense firewalls in front of the machines. Quote from the above link: 

EDIT#1: Yes, I have checked Apache and Tomcat logs, just Apache showing the 404. Application log doesn't show anything as well. 

I've been struggling around with this for 2 days now, and I can't seem to make it work. Any help is much appreciated! 

I have a Dell 2950 Gen III rack-mounted server sitting around here that I want to upgrade with SSDs. Since I haven't found anything related from Dell and just a few post that confirmed it'll work (and even more that say it won't!), I am getting curious what's right. I plan to put in Crucial MX100 128GB SSDs. I know PERC 5i is a 3GB/s controller supporting SATA drives and I know it does not support NCQ, but I am totally not sure about the support for SSDs. Is there a resource that may verify/disprove the SSD support for 3rd generation Dell 2950? Any help is much appreciated! 

I'm currently setting up a PKI for my company and while I have come up with a good layout and planned the overall policy of certificate issuance, I'm still puzzled by what role the CRL plays. By looking at other root CA certificates installed in browsers, we concluded that we could go without a revocation list for our root CA. We also based it on the fact that our certificate chain will be installed in strictly firewalled and closed environments on our customer sites, which means retrieving the CRL from our HTTP site won't work. Is it a bad idea not to include a CRL in the root? And would applications (IIS, IE, Firefox) behave badly or need additional configuration to work right? I'm aware that by not having CRL's, I lose the ability to revoke a certificate, but this is currently not an issue. The question concerns the root, the subordinate CA would, or could, have a CRL, depending on the Class (Class 1 = production, Class 3 = testing etc.) according to our CP.