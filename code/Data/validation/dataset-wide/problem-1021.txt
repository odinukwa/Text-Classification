Patch the passive node first. Move the resources to the passive node.(This will become active now) Patch the current passive node.(It was originally active). 

Now you need to remove the parameters : @CurrentDatabaseNameFS and UPPER(@CurrentBackupType). This will create all your backups to a single location as below 

I have a request to uninstall one of the test instance which is part of Always ON. I googled around for a clean decommission but did not find steps for Always ON Instance uninstallation. Would be great if Steps can be shared here or any link if you are aware of. As per me I would : 

So in fact I want to group by message_type and user_id, but instead of generating multiple rows per user, I want to create multiple columns, one for each message_type Can I achieve this without hardcoding the message types in my query? 

So basically I'll have to do a migrate a database live over the course of a few days, while simultaneously updating the application live such that it can handle the new application, without being able to search for the usage of each table. With all these handicaps taken into consideration I came up with the following plan: 

We have multiple instances on single node of the AlwaysOn setup, all are configured as AOAG. Right now we are connecting using the Listener\InstanceName. The listeners for each AG is having a dedicated port designated. This is why we cannot connect just by using the Listener without the port or InstanceName. I wanted to configure in such a way that just giving the AG_Listener would be enough to connect without using the port explicitly. 

Database is a vital part of any application and is active all the time.This is why databases are often hosted in dedicated servers where nothing else can hamper the resource utilization for the database. Now coming to your question, there is no problem at all and SQL Server is working as expected. SQL Server is smart enough and caches as much as possible to make operations faster. There is a setting called MAX MEMORY SETTING that can be set to a value at which you want SQL Server NOT to use any further RAM. This is done after keeping aside the memory usage for the OS processes. 

However, there is a problem with this design: a row should only be allowed to reference a connection when the education type matches. E.g. a row can only reference a row in the table that references a row in the table with type == master. Would it be possible to add a constraint which can check exactly that? If not, what other options are available? 

I "inherited" a web application which is designed and implemented horribly (both the application and the database). For example, the main data is stored using a sort of emulated key-value storage in a Postgres 8.2 database, making it virtually impossible to extract useful data from it in a reasonable amount of time. Currently I'm working hard on replacing the entire application + database, however it will take a few months before the new application is finished. This is a problem since the website is really slow due to the extremely bad database design and even worse queries. Therefore I'm planning to fix the database design and the queries on the live site until the website has an acceptable load time as a temporary solution. I do however have a few limitations to work around, the most problematic ones are: 

The above will backup all databases in AG except UserDb. For more information please go through the Databases parameter in the below link Ola hellengren 

It depends on what your needs are. Re-organize is a light weighed operation ,generated lesser logs and always an Online operation. While rebuild is online only for the Enterprise edition of SQL Server and is more heavy operation. 

Other than Logins,Agent Jobs,Triggers and already mentioned points by Max, these 2 can also be looked upon. 

The backup that you are taking is log backup and in addition to letting you restore the backed-up transactions, a log backup truncates the log to remove the backed up log records from the log file. This is very important to have a point in time recovery and has to be scheduled to run frequently. Please go through below link to understand how backups work : $URL$ 

I have a messages table in a database, which include a sender id and a message type (and of course many more columns not relevant for this question). I try to create a query which counts how many messages of each type a user have send. e.g. if I have the following table: 

I try to create a good database design to represent this data, however there are quite a few difficulties. A design I came up with is as followed: 

However, I already defined using my keys that table1.a references to table2.b, so it seems to me that it shouldn't be to hard to make a DBMS system automatically use table1.a and table2.b as the join columns, such that one can simply use: 

Yes, that is how we need to roll out patches in the sql cluster with minimum downtime. The downtime will be during the failover part. Process: 

I was going through various articles on Missing indices and Unused Indices. Was wondering how having multiple indices which are un-used causes performance issues. 

If you have already deleted the Imported Tables then you are fine. You will not be required to do anything else. This can happen and to get rid of this Use the Import/Export Wizard or Properly use the databasemame.Schema.Table. 

AFter days of scratching my head and google finally fixed with a vey simple setting. This was resolved by adding the url to the Compatibility View Settings in the IE browser settings. 

As far as I could find out many DBMSs (e.g. mysql, postgres, mssql) use fk and pk combinations only to constrain changes to data, but they are rarely natively used to automatically select columns to join (like natural join does with names). Why is that? If you've already defined a relationship between 2 tables with a pk/fk, why can't the database figure out that if I join those tables I want to join them on the pk/fk columns? EDIT: to clarify this a bit: suppose I have a table1 and a table2. table1 one has a foreign key on column a, which references to the primary key on table2, the column b. Now if I join these tables, I'll have to do something like this: 

Since the recent patch where TLS 1.0 was disabled and 1.1, 1.2 Enabled , we are having issues where the SSRS in the server cannot make connections to the Database server. 

The above answer from @kin is perfect. If at all you are looking for a script that you can use to backup your desired databases then use the below query. I have been using it to configure backup for Express Editions. Here is the query,i have edited the script accordingly, 

As per Microsoft, having same service account is the prerequisite : All server instances that host an availability replica for the availability group must use the same SQL Server service account. The domain administrator needs to manually register a Service Principal Name (SPN) with Active Directory on the SQL Server service account for the virtual network name (VNN) of the availability group listener. If the SPN is registered on an account other than the SQL Server service account, authentication will fail. $URL$ 

Using this strategy I will have 2 synced databases after step 3. Initially all queries will go to the old database, but while I'm updating the queries slowly the old database will be used less, and the new one more. Taking this "sub-optimal" situation in mind, is this a good strategy to fix some of the problems? What things should I take into consideration while doing this? Note that I fully understand that this is a very risky suicide mission. However, I'll have to do something in a short amount of time, otherwise the website becomes entirely unusable.