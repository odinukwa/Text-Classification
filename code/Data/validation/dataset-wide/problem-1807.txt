I have used external USB DVD drives to install DVD media, but the better answer is to pick up (or make) a netboot CD that the server can read, and use it to install over the network. 

No, there's no record keeping of who modified which file. To give you an idea, you might check the logs to see who was logged in at that time, and under ideal circumstances, history files can examined. 

NFS performance would be fine, but if the volume of files (and the delta) is that low, then an occasional sync would probably be the best way, particularly if they don't need to be stored on the web server. I only say that because NFS has issues with hanging due to network problems. You don't want your users to be unable to upload because the network is temporarily unavailable. By syncing, you eliminate that potential service loss. I've seen many cases where an hourly cronjob will sweep through and transfer everything to another server, and then it deletes anything over a day old. 

There is always the possibility that your admin has installed the equivalent of malware to watch you, but that's pretty draconian for most places unless someone has given them a reason. Generally speaking, when it comes to work PCs, the employer has a right to do whatever they want, because it's their hardware, their software, and their time. Your admin should be acting as the enforcement arm of management, so if he's monitoring your computer, your issue isn't with him, it's with the corporate decisionmakers who decided that it was necessary. Also, if your admin is monitoring you and you disable it, I can promise that he or she will be displeased and it won't earn you any brownie points. It'll probably just make your life more difficult. 

Have you tried setting up a machine that uses known PMTU ($URL$ and figuring it out from there? Worst case scenario, work your way up by hand. 

As womble said, you can't drop a disk and shrink a RAID. There are probably some things you should know about RAID. First, RAID 5 is no longer considered a good practice for large drives or large arrays. The reason is that the liklihood of a read error from one of the drives when replacing a failed drive becomes a lot closer to 1:1 with the larger / more numerous drives. Best practices are now RAID 6, which provides two parity drives, or RAID 10, which gives better performance, but slightly less fault tolerance (you can lose 2 drives in some circumstances). Also, when you're building decently-sized arrays, you might consider adding a hot spare that automatically swaps in for a failed member without your intervention. Of course, that doesn't get you your data. Assuming you've got a 5x500GB array, you've got around 2TB of usable space. If you have backups, then you really need to recover from those after recreating the array. Since it sounds like you don't have backups, first, good luck. Second, it's time to get some sort of secondary storage post haste. I would recommend an external 2TB drive. They're running around $160 on pricewatch.com. If for whatever reason you can't do that, try to logically break it up and dispatch it to several other machines while you rebuild the array. You probably want to hurry. 

You can see the benefit of VMs to yourself, but they don't see the benefits to them, so what you've got to do is translate the your benefits into their benefits. Lower power consumption for you equals lower recurring costs for them. Larger uptime for you equals more reliability for them. Easier administration for you equals more time for you to work on other projects. It's a pretty easy equation to understand after you simplify all the terms and break it down into things management can understand. 

Have you considered moving to virtualization? This would be a great time, because you're changing hardware, but you want to keep the actual installation. Any of the p2v (physical to virtual) converters should be able to handle that. 

and I get 10,000 responses. Every time. Then, I'll do the same thing, except to the IP address of the external interface (but still on the same device). It drops somewhere between 10 and 15 packets out of 10,000. I've done the same test on every other gateway in the company, and nothing else shows this behavior. I'm perplexed. I've talked with the support from the fiber company, and both of our interfaces are hard-coded to 100Mb with full duplex, if that could even cause the problem. Incidentally, when pinging the exterior interface from inside the router, I never lose a packet, which makes me think that it isn't the interface itself. And the local interface never loses a packet, so it isn't the switch. I'm honestly not sure where the problem could lie, except with the design of the hardware itself. I've watched the graphs, and even during the pingflood, I'm nowhere near maximizing the CPU or memory on the router. Any suggestions? Edit For Tom: The fiber is 13Mb/s, but when I ping the interface, it isn't crossing over to the fiber. The local LAN is running at 100Mb/s, and the internal interface responds to every packet. I'll have to see if I can borrow another piece of hardware, but I've got some older model Junipers (5GTs) at different sites that don't show the same symptoms. 

You could probably do it with your network ID, AAAA:BBBB:CCCC:DDDD:: or whatever it is for you. That would guarantee that only IPv6 interfaces would pick it up. I think. I'm no IPv6 master. 

Run strace -f apachectl start and see what the last dozen lines or so are trying to do. The output is a little bit crazy, so you might update your question with the output, and maybe someone can help. 

I've been a sysadmin for the better part of a decade, but only in the past few years have I really been interested in really bettering myself and the profession. To that end, I joined LOPSA (it was cheaper than USENIX or SAGE), but I don't have the time to attend either SCALE or LISA, so I don't feel like I'm really getting "the experience". I enjoy the fact that I support LOPSA, which I feel is a group with a very positive goal, and I want to get involved, but there's no way my company would pay the registration fee to the conference, and I can't afford a few thousand twice a year (plus airfare and accomodations). I'm wondering what you think of your professional memberships, if you have any, and what advice you could give to someone who wants to get more involved and improve the state of systems administration. Edit I marked Arclight's response as the answer, but just because his response is the sort that I was looking for. I'd still love to hear more people's input on this. I don't want the question ignored just because one person gave a really great answer. 

You are really asking two entirely different questions. Here are the answers I'd give: Will my VPS's performance be dependent on other VMs on the same physical server? To some extent, yes, although (unless the admins are incompetent) you will receive at least the performance you pay for. Many VPSes are setup so that you can draw more above your set resources, as long as no one else that has been promised the resources needs them. As an example, CPU usage is affected by this a lot. If there isn't a lot of load across all of the VPSes, you may be able to get better processor usage than you paid for. But the second that someone else starts to heavily use their processor, you're going to lose performance, because the VPS host has promised them a certain number of cycles, and you were using what was theirs. Your performance will decrease, but not below what you're paying for (again, in the right configuration). Will a VPS experience fewer downtimes? This is a harder question to answer. Statistically, I say no. A hosted account is one small piece of a complex puzzle, but (in most cases) the server (or servers, more likely) are administered by one group of people, and those people probably have a uniform set of procedures that is documented. One change affects many, many accounts, so they're (hopefully) very careful about what they do. There is a process, and administration is managed, as opposed to ad hoc. When you get a VPS, you introduce a new variable to the mix. Namely, you. Not only can physical issues and hypervisor issues cause problems, you yourself can introduce instability. If you've got years of experience administering servers, then this probably isn't an issue, but unless you're confident in your abilities and have the experience to back up that confidence, the end result is that your server is unavailable more than it would be in the hosted example. Generally speaking, more moving parts raises the likelihood of failure. $URL$ 

Are you absolutely certain that you don't want to reinstall that machine? If it were a personal desktop, that would be one thing, but I'm not sure I'd trust a machine without a fresh install. I may be paranoid here, though. 

Interesting. First, lets establish some specifics... You have an ESX host that is running multiple VMs, right? You have one of those VMs as a Windows 2003 server. You say when you run pings from a "remote" machine to that VM, you see 10-20 seconds of packet loss. OK, immediate questions: 1) Does the packet loss occur when pinging from one of the other VMs running on that host? 2) Do any of the other VMs on that host (or the host itself) display the same behavior when you ping them in an identical manner from an identical place on the network? 3) Are any of the other VMs running the same operating system as the VM displaying the behavior? 4) Is there any kind of timing pattern? Does it happen every 5 minutes? Is it every so many packets. Do you always lose the same amount of packets? 5) When you go into the vSphere console, do you see any kind of performance graph changes that match the timing of your ping loss? 6) Is VMware tools installed on the VM and up to date? 

Not really what you asked, but you might want to investigate running a Squid proxy internally there. It will at least cut back the duplicated traffic of everyone going to CNN, etc 

I can't find a lot of documentation on it, but it appears to be the vmware host/guest filesystem $URL$ 

Also, you can talk to a colo specialist like colotraq ($URL$ which is essentially a headhunter, but for colos. They'll find out what you're looking for and your range and they'll give you several contacts. I've used them and they were very effective. 

I keep some of my writing in a subversion repository, and I use tortoiseSVN as a subversion client on my Windows machine. Have you considered having them checkout the repository there, and maybe giving them a "laptop development" branch or something, into which they can merge changes and then folding them into their other development efforts? 

I've got an older Apple XRAID, and in order to administer it, I've had to rely on the Apple XRAID software utility that is native only on OSX. My only Mac laptop is going to be heading the way of the dinosaur soon, and I'd love to have another way to address this piece of hardware. Has anyone found, used, or even heard of a software solution for admining these things without a Mac? 

Alright, look. You're not going to find a server that has the sort of RAM footprint you're looking for, at least not one that doesn't require its own electrical grid. Why not take a scalable approach, and use memcached? You can spread the memory around to different machines across the network. The data never has to touch a disk drive, and with the sort of ultra-fast network you can buy with the money you're talking about, latency will hardly be a problem at all. Here's a memcached client for java: $URL$ And here's an intro to memcached in case you're not familiar: $URL$ Look into it. It's going to be way more cost effective than building a single monster machine with an insane amount of RAM. Besides, if you're doing something that has that kind of requirement, it's probably mission critical, and you don't need a single point of failure. 

Not being a puppet user, I'm sure others will chime in with more appropriate answers, but it sounds like a wrapper script could be implemented with relative ease that checks before starting the service. 

I've got an Avaya 4624 IP VoiP phone that I've ordered a power supply for, but it's still likely a week away, and I'd like to test now. I can't find the power requirements anywhere. I was hoping someone reading this might have a power brick to these things and be able to give me the stats. Thanks! 

I've only worked with these in Linux, and with Navisphere Light (or express, or whatever), but I have to either go into the navisphere web interface on the array and assign values to the properties of the server (in 'connections'), or run the /opt/Navisphere/bin/naviserverutilcli command, then scan and update the storage. That "registers" the server on the array for me. Since you're on Solaris, YMMV 

Do you mean to access documentation, or to create it? Or both? If you want to create it, then you might as well start your own wiki, internal or external. Externally means you could get knowledge from a lot of people. Internal means you could customize it to your infrastructure. I don't know of a wiki site like the one you described, but this one is the closest: $URL$ There are plenty of Mac Sysadmins out there, and lots of documentation in general, if not wiki form. Just google for Mac Sysadmin documentation and see what comes up. 

Password Safe with a centralized version control server should take care of this. I've used password safe for a couple of years now, and it's great. Highly recommended. 

(or wherever PHP is installed for you) That should print out diagnostics on what's going on. Also, it should be noted that if you just run php, it doesn't print anything, and it waits. Also, it won't print anything if your script doesn't have any output. Edit Check the code in the index.php script and make sure it's doing what you want it to be doing. If php is exiting immediately, treat this like a bug in your code. 

Have you verified that the name resolution is correct on the server for the client that is trying to connect (and is listed in the exports file)? 

It should probably be noted that RFC 1178 is devoted to this topic: $URL$ (even if I disagree with a lot of it, and much in there is out of date). 

On the other machine, cd to the .ssh directory, and edit a new file called "authorized_keys". Paste the contents of the .pub file into this (it's all one big line). 

Are you going for aesthetics or function? Unless I'm making something to show off, or for installers to put together right (they like pretty pictures), then I go for utility. For me, that means plain squares, with heights to match the size of the machine. The bonus is that the description of the machine can fill the box (if your diagram is sized such that it's possible, anyway). 

This runs the command at a nice level of 10. The $ indicates that it's a regular user. Here's what happens when you try to set a higher nice level: 

1) Data should be kept as long as necessary according to the legal limits imposed by your industry Meaning that if you are in the financial industry, you have different requirements than if you are in the private industry, or ISP industry, or what have you 2) legal implications are a function of #1 3) The easiest ways are to use known 3rd parties for archiving. I use Global Relay for communications archiving, because they have many, many services available in the event of an audit and so forth 4-... First you need to decide which industry you belong in, then which requirements and legal actions you fall under the jurisdiction o, then we may be able to help, but your corporate attorney would be a better person for advice. Once he gives you advice, ask a question related to what he tells you you have to archive. We can't decide that for you. 

You might look at just using apache authentication, and authenticating THAT with your centralized authentication scheme: $URL$ 

This is slightly offtopic, but VSFTP ships with the anonymous user enabled, just so you know. $URL$ Just letting you know in case you didn't test that.