I think that your example relies on a misunderstanding of the meaning of the choice function. $C(\{x,y,z\})$ does not contain the elements that the decision-maker would choose simultaneously if he could. He is only allowed to select one element at a time (otherwise, why not consuming all three items ?). Therefore $C(\{x,y,z\}=\{y,z\}$ does not mean that he selects both shoes. It means that, if you ask him to choose one element inside $\{x,y,z\}$, he might either pick $y$ or pick $z$, being indifferent between the two. In that case, your story would not make much sense, since the value of a single shoe would be the same in both choice sets. Regarding your question, there are some well-known violations of WARP that rely on behavioral biases, in particular the attraction effect and the compromise effect. These expressions describe situations where the comparison between two goods is affected by the nature of a third (unselected) good in the choice set. You can easily find some references (experimental evidence, models) on these phenomena. 

Here are a couple of suggestions. There are some PDEs in some recent continuous-time models, for instance in: 

I'll start from your last equation. \begin{align*} \int_{\underline{\theta}}^{\bar{\theta}}{u(\theta) dF(\theta)} & = \Big[ u(\theta)F(\theta) \Big]_{\underline{\theta}}^{\bar{\theta}} - \int_{\underline{\theta}}^{\bar{\theta}}{F(\theta) v_{\theta}(q(\theta),\theta) d\theta} \\ & = u(\bar{\theta})F(\bar{\theta})-u(\underline{\theta})F(\underline{\theta})-\int_{\underline{\theta}}^{\bar{\theta}}{F(\theta) v_{\theta}(q(\theta),\theta) d\theta} \\ & = u(\bar{\theta})-\int_{\underline{\theta}}^{\bar{\theta}}{F(\theta) v_{\theta}(q(\theta),\theta) d\theta} \text{ since } F(\bar{\theta})=1, F(\underline{\theta})=0\\ & = u(\underline{\theta})+(u(\bar{\theta})-u(\underline{\theta}))-\int_{\underline{\theta}}^{\bar{\theta}}{F(\theta) v_{\theta}(q(\theta),\theta) d\theta} \\ & = u(\underline{\theta})+\int_{\underline{\theta}}^{\bar{\theta}}{u'(\theta) d\theta}-\int_{\underline{\theta}}^{\bar{\theta}}{F(\theta) v_{\theta}(q(\theta),\theta) d\theta} \\ & = u(\underline{\theta})+\int_{\underline{\theta}}^{\bar{\theta}}{v_{\theta}(q(\theta),\theta) d\theta}-\int_{\underline{\theta}}^{\bar{\theta}}{F(\theta) v_{\theta}(q(\theta),\theta) d\theta} \text{ since } u'=v_{\theta}\\ & = u(\underline{\theta})+\int_{\underline{\theta}}^{\bar{\theta}}{(1-F(\theta)) v_{\theta}(q(\theta),\theta) d\theta} \\ & = u(\underline{\theta})+\int_{\underline{\theta}}^{\bar{\theta}}{\dfrac{1-F(\theta)}{f(\theta)} v_{\theta}(q(\theta),\theta) dF(\theta)} \\ & = \int_{\underline{\theta}}^{\bar{\theta}}{u(\underline{\theta})dF(\theta)}+\int_{\underline{\theta}}^{\bar{\theta}}{\dfrac{1-F(\theta)}{f(\theta)} v_{\theta}(q(\theta),\theta) dF(\theta)} \\ & = \int_{\underline{\theta}}^{\bar{\theta}}{\Big[u(\underline{\theta})+\dfrac{1-F(\theta)}{f(\theta)} v_{\theta}(q(\theta),\theta) \Big]dF(\theta)} \end{align*} 

Integrate the $f(t)$ (a primitive of which is $F(t)$) and differentiate the $t$. This yields \begin{align*} x(z) F(z) & = \int_{0}^{z}{t f(t)dt} \\ & = \big[ t F(t) \big ]_{t=0}^{t=z}-\int_{0}^{z}{F(t)dt} \\ & = z F(z)-\int_{0}^{z}{F(t)dt}. \end{align*} Dividing by $F(z)$ on both sides yields the result. 

Here is a decision-theoretic formalization of your definitions. The usual framework to talk about objective risk is the situation where a decision-maker expresses preferences over objective lotteries. Formally, if $X$ is a prize space, objective lotteries are defined as elements of the space $\Delta(X)$ of probability distributions (usually with finite support) over $X$. For instance, the decision-maker might be asked to form preferences between the lottery that offers her/him an apple with probability 0.3 and an orange with probability 0.7, and the lottery that offers her/him an apple with probability 0.5 and an orange with probability 0.5. The standard result in that area (von Neumann-Morgenstern theorem) delivers a representation that identifies the agent's attitude towards objective risk (her/his utility function), while the probabilities are given as a primitive of the model. The usual framework to talk about ambiguity is the situation where a decision-maker expresses preferences over uncertain acts. Formally, if $X$ is a prize space and $S$ is a state space, acts are mappings $f:S \rightarrow X$ from $S$ to $X$. For instance, the decision-maker might be asked to form preferences between the act that offers her/him an apple if Novak Djokovic wins the 2017 Australian Open and an orange otherwise, and the lottery that offers her/him an apple if Andy Murray wins the 2017 Australian Open and an orange otherwise. The standard result in that area (von Neumann-Morgenstern theorem) delivers a representation that identifies both the agent's probabilistic beliefs regarding the states and her/his attitude towards risk (her/his utility function). There is a third widely used concept, usually called Anscombe-Aumann acts or horse races, which associates both objective lotteries and uncertain acts. Formally, given a prize space $X$, an Anscombe-Aumann act is a mapping $f:S \rightarrow \Delta(X)$ that associates an objective lottery to any state in $S$. Notice that the definitions of objective risk and ambiguity are to some extent subjective. The fact that risk is called "objective" relies very much on the assumption that the decision-maker agrees with the underlying probability model. For instance, if you observe the outcome of a coin toss, you might believe that heads happen with an objective probability of 0.5. It is implicitly imposed in the theory that the decision-maker agrees with this statement. Regarding ambiguity, you might yourself believe that the act "receive an apple if Novak Djokovic wins the 2017 Australian Open" is very ambiguous because you have no idea on how to compute a subjective probability for this event. That said, another decision-maker might very confidently believe that Djokovic has a 74% chance of winning the tournament, in which case she/he does not perceive this act as ambiguous at all. Ambiguity is a subjective notion, which is given by people's preferences and behavior and not by the choice situation itself. 

I would not be surprised if Yuliy Sannikov used PDEs in some of his other papers (although I have nothing precise in mind). You can refer to the review by Achdou et al. (Partial differential equation models in macroeconomics, Philosophical Transactions of the Royal Society, 2014) for other references. 

Your first question was addressed in another answer. For the second question (why $\Phi(b) \ne 1$), you are confusing the cdf and the density. It is true that $\int_{a}^{b}{f(t)dt}=1$ but not that $\int_{a}^{b}{F(t)dt}=1$. Think for instance of $[a,b]=[0,1]$ and the uniform distribution ($f(t)=1,F(t)=t$ for all $t \in [0,1]$). 

As you requested, I will just give you a hint and let you proceed from there. The agent's choice variable is the number of working hours $w$ that he provides in a day. If he works $w$ hours, 

The set $\{\mathbb{p}:\exists \alpha \in (0,1), \mathbb{p}_1=\alpha b_i, \mathbb{p}_2=(1-\alpha)b_i\}$ coincides with the hyperplane $\{\mathbb{p}:p_1+p_2=b_i\}$, therefore you are not finding extra hyperplanes by doing this and varying $\alpha$. More generally, if you fix $x=(x_1,x_2)$ and $b_i$, you obtain one hyperplane characterized by the equation $\{\mathbb{p}:p_1 x_1+p_2 x_2=b_i\}$. Since there are finitely many such $x$ (and $b_i$ is given), there are finitely many such hyperplanes. 

Yes, it is correct. You can (for instance) write a Taylor expansion: \begin{align*} [1-(1-\frac{x}{un})^n]^x & = [1-e^{n ln(1-\frac{x}{un})}]^x \\ & = [1-e^{n (-\frac{x}{un} + o(\frac{1}{n}))}]^x \\ & = [1-e^{-\frac{x}{u} + o(1)}]^x \\ & \sim [1-e^{-\frac{x}{u}}]^x \text{ when } n \rightarrow +\infty \end{align*} 

The monotonicity result that they prove in their lemma 1 (p. 556) is stronger than you think: it states that whenever $q>q'$, the support of $R_1(q)$ is "uniformly below" the support of $R_1(q')$. In other words, it is impossible to find any realizations $(r,r')$ of $R_1(q)$ and $R_1(q')$, respectively such that $r>r'$. The proof of this result relies on the idea that firms decisions are strategic substitutes in the Cournot duopoly model: the more firm 2 produces, the less firm 1 wants to produce. Thus, if firm 1 finds it optimal to produce an amount $r'$ with positive probability when firm 2 produces $q'$, it cannot find it optimal to produce a larger amount ($r>r'$) when firm 2 itself produces more ($q>q')$. Consider therefore a production level $q$ by firm 2 such that $0$ is a realization of $R_1(q)$. Take $\epsilon>0$ and suppose that there exists $r>0$ that is a realization of $R_1(q+\epsilon)$. The condition \begin{equation*} r > 0 \text{ and } q<q+\epsilon \end{equation*} violates their lemma 1, since $r$ is a realization of $R_1(q+\epsilon)$ and $q$ is a realization of $R_1(q)$. This proves that $R_1(q+\epsilon)$ has all its weight on 0. 

Suppose first that the groups are not altruistic and care only about their own survival. It is not exactly a prisoner's dilemma since the outcome obtained by mutual cooperation (if both groups wait) is not Pareto-improving: everyone dies in that case. The only equilibrium is that one of the groups destroys the other boat as soon as possible; and any action played initially by the other group is possible in equilibrium, since this team is indifferent between waiting and triggering other the bomb (they will die one second later anyway). As @Alecos_Papadopoulos wrote, the game becomes more interesting if the groups have pro-social preferences. For instance, they might be reluctant to sacrifice the other group and prefer that everyone dies (including themselves). If there is no uncertainty, the outcome is trivial: the only equilibrium is that both groups wait until the Joker triggers the bombs. The most interesting scenario is the one in which the types of the groups are uncertain: each boat can be either selfish or altruistic. In that case, it seems reasonable (but other specifications are possible) to assume that cooperation is desirable only if the other group is also altruistic, but if the other group is selfish the individuals prefer to kill them first and survive. The equilibrium strategies are the following: 

I do not know about social choice, but for utility representations I think the two most cited books are "Convex analysis" by Rockafellar and "Infinite Dimensional Analysis: A Hitchhiker's Guide" by Alliprantis and Border. They contain most (if not all) results on convex analysis and functional analysis used by economists. 

We need indirect comparisons because looking at direct comparisons is not sufficient to detect all types of inconsistencies. Suppose for instance that we observe $C(x,z)=\{x\},C(z,y)=\{z\}$ and $C(x,y)=\{y\}$. $C(x,y)=\{y\}$ implies that $y$ is "directly" revealed preferred to $x$. The reason why GARP is violated is that $C(x,z)=\{x\}$ and $C(z,y)=\{z\}$ imply that $x$ is "indirectly" revealed preferred to $y$, an inference that wouldn't be possible by looking at direct comparisons.