Because less code is often easier to understand and might contain fewer bugs...at least those tend to be reasons given for using high level languages since the days when assembly was considered high level and compared to raw machine code it was. Trust and Verify(maybe) Idiomatic Scala will rely on library routines such as rather than reinventing them. Mainly because the odds of a random Scala programmer writing a better implementation are approximately zero. Even those who possibly could will not unless there is a verified performance issue and the bottleneck is in the sort. And then it's probably time to look at JVM Bytecode instead of trying to get more efficiency through the Scala compiler. Advice 

Minor Point Because , it may not be necessary to use ... depending on the implementation, of course. 

We can compare another value to . This would be a search operation. Note that this is distinct from comparison to . We can perform an operation on it mapping it to a new value [possibly, we could map with the identity function]. This would be an iteration. 

It looks like it will just return the nearest value when Dijkstra runs out of nodes. Ideally validation should be done in the code, even if it is via an external library call to a connected component module. This suggests that modularity would be improved if the general purpose Dijkstra's Algorithm lived in its own module. This would simplify and reduce the size of the code while abstracting away implementation details. 

Other answers show examples of how to use and it might be worth looking at them and trying "to see" them as recursive. It is probably worth using instead of recursion if you plan to share Python code with other people because in the context of Python's community, recursive code is harder to understand. Magic Numbers The Danish alphabet has 29 letters. Icelandic has 32. Russian, 33. The length of the Latin alphabet, 26, is hard coded into the functions. These languages use characters that are not directly representable in ASCII. The code assumes that they are and hard codes the offset . It may be the case that the Latin 26 character alphabet is hard coded into Google Sheets, now. If it is, that assumption should be made explicitly in one place so that maintenance will be easier if Google changes (or if there already is localization). Magic numbers are a "code smell". Sprinkling the same numbers throughout the code is another. A => 1 Python is zero indexed. Indexing the Latin alphabet from is fighting against the language. I can follow your rationales for wrestling the snake. But I have to think too much about your rationales in order to understand your code. If you had created a Domain Specific Language in Python and then were writing your functions in that, 1-indexing would make sense. But your code is in Python. The biggest advantage of Python is that people know what to expect. They don't expect 1-indexing. Data Architecture Zero-indexing versus one-indexing is mostly a matter of not conceptually separating the internal data representation of your application from the external interface of the Google API. The architecture of your application is: 

Down the road, the dependency on sorting by or ought to be made explicit so that a maintainer of the code is less likely to change it and thereby breaking code that depends on implementation details. 

Caveat Sometimes it's worth generalizing the implementation. The next level of this implementation would be a function that takes a and returns a animation. But sometimes it isn't worth doing because it's the road to type implementations. 

Create a higher order function that takes a structure and returns a function that can serve as the argument for . The returned function is a closure over a particular . 

Other Strategies An empty board has zero probability of being a solution. This is lower than a board with a queen randomly placed in each column. Though the probability of random placement producing a solution is slight, it is better than an empty board. Gradient Descent Starting with a randomly populated board, an estimate of the distance from a solution is made. [1] Next each alternative position for each queen is examined and an estimate of the distance from a solution is made for each resulting configuration. The one move that results in minimizing the distance from the solution is made and the process repeats. When no improvement is possible the solution may be abandoned [2] and a new random board generated. Generating and examining random boards is parallizable and typically done because the number of boards examined is often large. [1]: Choosing how to measure the distance is art informed by science, not pure science except in so far as recognizing that the problem of measuring is still in NP. [2]: More complex approaches may not always chose the configuration closest to a solution and/or backtrack when no improvement is possible. Again, optimization is based on understanding the particulars of the problem. 

Discussion of difficulty For me the alternative implementation was non-obvious and the result of many hours of trial and error and Googling Python syntax. I could never have white-boarded it. I wrote the implementation after writing "High Order Bit" and "Remarks on Code details" because I wanted to be sure that my interpretations of the specification were plausible. Though time is good, I have a hunch that may be possible because the list is already sorted. is the best possible sorting for random data and already sorted data suggests most of the work has been done. For example, the first value is always on the lowest level of the tree, the last value is on the second lowest level except when is an integer, and so on. In other words, the list comprehensions reflect a function that can be applied to the indexes. 

An Minimal Implementation This code does not attempt to be particularly Pythonic. It attempts to reflect the underlying mathematics in an object based manner. 

and placing - from the viewpoint of the stack - all the user interface code in . Whether the user interface logic all lives there or in it's own class/module is another question. But reusability and maintenance certainly offer suggestions. For example, breaking out the user interface and its logic and its content into modules allows handling nasty issues like multiple languages and the quirks of UniCode to be handled more gracefully. String output is the one of the places Your-Not-Gonna'-Need-It [YNGNI] fails and why it is a baked in module for so many development frameworks. Variable Names , , , and though perhaps conventional for C++ example code, don't really scale well because they lack information. Even in the original code: 

Since the specification states is between 0 and 10,001 exclusive. Either there's no reason to test the length of input is less than 10,0001 or it should be tested against the lower bound as well as the upper. does not specify a character encoding. The default may be fine, but since the requirements are underspecified (vowels in what language?, a string in what language?) make the programmer's assumptions explicit is worth the effort. This is a case where it might even be appropriate to comment the code to document the conundrum. 

The game "Rock Paper Scissors" can be specified in terms of states. Specification The game is played by two players, and . Each player selects from among a set of three options . is used to represent the state before a player has chosen. Using an ordered pair creates the possible game states: 

Nodes are necessarily properties of Edges. Edges are not properties of nodes. Edges are [ properties | fields | objects ] of a graph. The dependencies are: 

Nodes are necessarily properties of Edges. Edges are not properties of nodes. Edges are [ properties | fields | objects ] of a graph. The dependencies are: 

The use of is a solid approach to functional programming. The names of the functions and variables are reasonable. 

The business logic of graphs is mathematical in nature. As implemented the class does not directly reflect the underlying mathematics. Poor mapping between code and graph mathematics is not uncommon even for graph implementations in well regraded text books and online tutorials. Mathematics A graph is defined as a set of nodes or vertices and a bag of edges . The only relation between edges and vertices is that for each edge between vertices and both and must be members of . Dependencies Mathematically, a set of vertices is independent of the set of edges . Two different graphs and can be defined across the same set of vertices based solely on the difference between two sets of edges and . 

Further refactoring is possible, but not shown to make the high level structure read more clearly. Semantics In the review code there is a bit of disconnect between the form of the output and the execution path of the implementation: 

These programmer defined data types automatically provide functions like and that align with the business logic and require. During debugging, a programmer defined data type provides something explicit to inspect. As the code evolves it provides a single place to implement changes, a known type to pass among procedures, semantics for creating a list of easter bunny headquarters locations, or hash table to memoize intermediate locations. Formatting Racket also has a style guide. It is typical to limit line length to 102 characters. For example: 

An Ugly First Implementation The main code is reasonably clean. Improvements related to are described in other answers, but I've ignored them to focus on the algorithmic abstractions rather than performance related to language implementation. 

Computer Science In terms of functional programming, the use of recursion is a step in the right direction. However the recursive code calculating the Fibonacci values: 

Many of the states turn out to be equivalent and finding these equivalences would greatly reduce the search space and make for a more performant algorithm. For the purposes of Odersky's course [promoting Scala and functional programming] looking at algorithmic improvements is outside the mandate. For general code such as that under open review, it really isn't. 

Yes, it can be done more efficiently than 's O(n^2). And No. The limit of general comparison sorting algorithms is O(n log n). The Interview Question 

It depends on what operations will be performed on the graph and what the graph represents. If the graph represents something which might have redundant edges between vertices, then and don't capture the real world object and operations such as cannot be performed accurately. Similar issues arise if edges have variable costs. In the end, just as adjacency matrices are a good choice for dense graphs and maybe not so good for sparse graphs, other aspects of the procedural representation of mathematical graphs come with tradeoffs that should be dictated by the intended use. 

Tune the procedure for generating combinations for the problem domain. Tune the procedure for generating combination to those that are of interest to the specific question at hand. Tune the procedure for generating combinations to reflect structural properties of the data. Statistical analysis is a good place to start, try to avoid analysis that takes exponential time. 

Note that the locally scoped function takes no arguments and uses to create an executable block of code. 

Alternative Implementation The problem can be met using list comprehensions. Since this approach does not use a binary tree either, it may not meet the specification. 

Would improve the structure and probably improve readability. Naming Names such as mix game level logic of plays with an implementation detail of folding. This reflects a general intermingling of abstraction layers and that's probably related to the limited modularity in the code. Other 

The isomorphism is between the and the . This is consistent with the Naive Model of input output. The captures the business logic in regard to taxes. The is where the aggregate properties of a sale are captured as totals. We don't necessarily need cache these as part of the Sale because they are computable from the if someone else needs them. There are cases where they won't such as if there are early payment discounts that may modify the sale later. 

otherwise, 1 and 5 are magic numbers. Magic numbers make the code hard to understand and brittle when refactoring because each occurrence of each magic constant has to be manually changed. Even with just a single use, naming the values makes the code easier to read and helps the reader understand why 1 is one (and not some other value) and 5 is five. 

Maybe it's worth pointing out, that the starting point for writing the was wishful thinking where I wished I had . Then at the next lower level of abstraction down, I wrote it. Credit goes to Ableson and Sussman's SICP lectures. 

Using implies that the domain areacalculator.com is under the control of the programmer or the organization for whom the code was written[1]. The idea is to produce unique Java namespaces by leveraging the uniqueness of internet domain names. It's a convention designed for the age of the internet and a sound strategy for avoiding namespace conflicts. It makes assigning responsibility a more reasoned process: only one or none of the packages can be named correctly. 

From the README.md Introduction: The purpose of is to read all the lines from a text file and return the file's contents as a Clojure value in a standardized manner. Specification: Takes: 

Efficiency Because the graph is undirected, the adjacency matrix can be represented in space if there are no redundant edges, i.e. matrix is triangular. A one dimensional array with accessors could serve as simple data structure. As you probably know, if the typical graph is sparse, then an adjacency matrix may be space inefficient and an Representation 

Having as a property of a node feels a bit like a leaky abstraction because it embeds the needs of a particular tree operation into the more general abstraction of graphs and nodes. To me, a node is a data structure that has some pointers to zero or more children and perhaps stores a value - depending on the semantics of a particular graph. Consider an acyclic graph with all values at stored at leaves versus various cyclic graphs with values stored at each node. In the cyclic graph case depth first search is not directly applicable until an appropriate starting node has been selected and though the concept of may make sense for some cyclic graph algorithms, it wouldn't in the case of other algorithms such as Dijkstraâ€™s shortest path. To separate concerns, a depth first search algorithm might create it's own object consisting of a generalized node object and a field...or use any of many other data structure approaches. Without isolation algorithms operating on the graph must walk it a second time to clear the field. If there is concurrency, then graph algorithms must lock the entire data structure and the depth first search should have transaction semantics. 

Highlights Note the use in two places where a symbol bound to a function is passed as a parameter to another function: 

At an arbitrary iteration some may lead to states already visited and Odersky's approach trims those. What it doesn't do is capture the semantics of bags to trim the search space. Consider: 

The object hierarchy, instead of hiding the implementation details at the lower level of nodes and edges, exposes them at the higher level of the graph. Redundancy Redundancy occures in two forms, abstractions and data structures. 

Add tests to determine correctness of the implementation. Code review can uncover structural and syntactic issues, but given the abstractions it is near impossible to reason about the mathematics. Consider refactoring the code to reflect the mathematical dependencies rather than building up from nodes. Select a few data types: either Map or HashMap, either List or ArrayList, etc. This also means fewer object types. 

Review Style Scheme has formatting conventions. The code does better with indentation than with parenthesis. Logic The lack of a specification and tests based upon it leads to an incorrect implementation and poorly organized code. There is a branch which returns the same value on both paths: 

The other diagonals in the other quadrants can be generated from the worst case diagonal for Quadrant I (northeast). Technically, the transformation can be seen as either a four-fold rotation or two mirror planes. I thought that rotation seemed easier. 

Alternative For procedures that try to find a property of a list, folding is often a good place to start. This code uses . Usually I find rather than is what I want, for whatever that's worth. 

This is necessary within Emacs Lisp and one of the ways it varies from Common Lisp and various Schemes. Example Use Despite the difficulties that add complexity, provides a great deal of flexibility: 

and that distance is only likely to grow as a useful program adds features. Final Thought I cannot help but recommend McConnell's Code Complete as a guide to deepening one's understanding of the ways in which software can be organized. 

1: The name is as type agnostic as . I would have used but it is the name of a built in Python function. This can affect syntax highlighting in the editor. 2: I don't believe in self documenting code, but calling the output is an exception. 6: The short circuits. The slice covers all the logic of what to do when is matched in the source. 8: This bit of cleverness is why the absence of comments makes code harder to understand. Remarks: The code does not have a code path for a null/false pattern. Based on the specification, I consider it undefined behavior. There are some things I like about C. Practically speaking, in the context of an interview, "What happens with null pattern?" might be an interesting request for more information...then again, what happens if the pattern is not iterable suggests that treating it as undefined behavior might be reasonable in the context of a technical interview.