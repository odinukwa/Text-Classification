Two ways, basically. One's HDR. You adjust brightness of the image according to the brightness of the image (if that makes sense). It's somewhat hard to control and might not work exactly the way you want. The implementation is somewhat hard to do, too. The other one's a simple sprite that gets brighter when the camera is further away and looking from the right direction. A very simple approach: additive rendering, one simple equation to control brightness, sprite must fit in the scene (where all sprites are sorted according to distance from camera). You can find the performance of both techniques in different "parts" of Half-Life 2. The first can be found in "Lost Coast" while the second can be found in the original game, Half-Life 2 (the highway levels, to be specific), here's a video that displays this technique. 

Please note that even though you wish to dismiss a solution, it may still be valid. If you want quad's vertices to have Z=0, there's a scale matrix for that: 

Of course you should normalize it - it isn't the Lambert term if it isn't normalized. Lambert term = max(cos(angle between direction to light and surface normal),0) And (in HLSL-ish pseudocode): So to get , length of both vectors must be equal to 1 (which is what normalization does - divides a vector by its length). $URL$ 

You can interpolate tangents just like you would everything else, there should be no problems with that, as long as your mesh (morph target) count is low - I think there was a rather low limit on how many attribute slots you can use (GLES2.0 says there must be at least 8, Chrome seems to have 16). An alternative (if you can take the pressure on the pixel shader) is to try doing normal mapping without precomputed tangents: 

This shadow volume will include the polygon itself so as to avoid making it appear lit. It is also convex so there should be no problems rendering it. Rendering: for each light, clear shadow buffer, draw all volumes to buffer, use the buffer to draw the light. The buffer can be a z-buffer or a stencil buffer (creates pixel-perfect shadows) but it can also be a shadowmap, though in that case you'll also have to use the stencil to prevent the solid polygon from appearing lit. 

It is not possible to directly use a multisampled texture. You have to resolve it to another texture (same format, same size) first. You can do that by binding the non-multisampled texture and blitting the multisampled one to it with glBlitFramebuffer (you might need to append EXT to function name - use glBlitFramebufferEXT - if you use OpenGL 2). 

You found the right answer yourself - you will have to render things to an off-screen buffer and upscale it to any of the supported resolutions. This will be very easy since oldschool games didn't have anything better than nearest neighbor interpolation anyway. If you use GPU for this, it's possible to avoid a resolution switch (upscaling to large resolutions can cost quite a lot of CPU time otherwise). It would also allow the use of better upscaling algorithms, if you're interested. I'd highly suggest looking into these, at least for the people with bigger monitors than whatever laptops usually offer since nearest neighbor interpolation will look really bad for those people. They usually also have a good GPU so it isn't much of an implementation problem. 

You're going to have a class for the player and what you want to do is have that class inherit from a base class for objects in your game that need physics applied to them. 

I have an old phone, maybe 5-6 years old. It's not quite as powerful as it needs to be to run the OS I have running on it so everything just lags... it's pretty bad. I honestly don't think my phone could run a game with a fixed time-step particularly well. But I'm on an old android so you might be completely fine if you're targeting newer iPhones (much more homogeneous than androids). If you're thinking cross-platform I honestly wouldn't trust a fixed time-step, but I'm a very distrustful person. The bulk of the differences between the two are thinking about everything in unknown quantities vs rigid 1/60th of a second kind of thinking. But there's no reason you can't build everything fixed and switch over later if issues arise (and of course variable can become fixed at the drop of a hat). Just be careful how you code so if you need to make changes you know where they should go. 

I'd like to know the strengths and weaknesses of different progression methods through a game (or a part of a game), where they're suited best, and where they should never appear. I have several subsystems a player can progress through in a project I'm working on and I'd like to be able to work out if any of them would benefit from tallying xp. [Not sure why this is on hold, I'm asking about the concrete merits of things not simply asking everyone for their favourite??] At the moment the player's character becomes more powerful by equipping better and better gear as they progress through randgen levels however they like, but are given clear indication that going in a particular direction will increase difficulty and the quality of items. I'm not sure in what circumstances I would add in xp for fighting monsters, or which I'd have the monsters drop good gear, or parts to make good gear out of. On top of that I have a magic system and a crafting system that I'm considering progressing though with xp but I wouldn't want to implement it if the side effects don't suit the rest of the game. As far as I know games usually progress in the following ways, often in combination: 

Depends on what look you're going for. Usually you'd design for your target platform and then scale/rework art assets for secondary platforms. Make it look nice for the largest chunk of your players, essentially. 

If you modify 'a' in the equation above you can modify the height of the parabola while still hitting the x axis at 'contact'. a = 2 will be taller while a = 0.5 will be shorter. 

You're using Java so I'm going to assume off the bat that you're playing to Java's strong points and writing your game as Object Oriented as you possibly can. When you say you have a game loop I imagine you have a top level class with a main method that loops over your update and draw functions, something like the following (but yours will be far more detailed): 

I'd say you need all of them here, and some more. Bounding volume hierarchy (like BSP or octree), perhaps portal culling too for the static parts of the world, occluder volumes (antiportals in Unreal Engine) for terrains and a scene graph for compound objects (lamps, characters, doors etc.). 

I do not know how much this actually affects the development but as with any such changes, it's been told that they will let driver developers write better drivers. The complexity of GPU drivers is amazing but I'm not sure if this exact change will help much. In either case, it's possible to replace triangle fans for most of your needs (like convex polygon rendering) with strips, often with better results. 

What free / non-restrictive open-source solutions (not GPL) are available for decoding game videos? The requirements are simple: 

It appears to be a slightly misleading book. Offset does not change drawing order or even the 3D position of pixels. It simply adds some numbers to the Z value (the one that's going to the Z tests and Z-buffer) of a pixel (hence the term "offset"), making it appear above or below other triangles. This is generally used to prioritize visibility of triangles with (nearly) coincident surface planes. To find out, what exactly is it that the parameters change, refer to the Unity ShaderLab documentation. As for Z-fighting... in this case, offset would shift the odds of having more visible pixels towards your road plane. 

So, to sum up: rotate the quad, apply perspective transformation, divide by W (scale with 1/W) and flatten it along the Z axis in the end. 

Y values are locked to f(x). f(X) does not equal X therefore Y is not locked to X. You need a constant angular delta, which can be achieved by using a pair of sin/cos functions: 

This structure is pretty much the same as that of exception handlers in code. (And, in fact, something not told often enough - behavior trees are basically abstract syntax trees describing code that will be cooperatively executed in parallel - so they have lots of structural similarities with code). I implemented interrupt set as an integer where bits specify interrupts (not planning to have more than 32) but an unordered set should be fine for this as well. 

That would likely take even more pressure off your vertex shaders/attribute channels (no need to pass tangents or even normals) so you could blend even more meshes together. 

With this approach, components behave any way the entities want them to behave. Put logic into this the same way you'd put it into entities. There might appear to be some redundant glue code in this approach but all things considered, this one actually proves to require less work than any other system. All of the other approaches are mainly meant for data-driving the engine heavily (enabling entity composition in game editors), which is what most people don't actually need (most don't even have editors). Even GTA3 didn't need it. And I'd most probably be right if I said that you don't have a bigger game in development... 

Usually, in a database, you'd make a table of all the items in your game, make a table of all your players, and make another table, the Inventory table, that stores entries consisting of Player ID, Item ID, and Item Quantity. If you were using another structure to hold your data I'd probably be inclined to tell you to give each player their own separate inventory so you don't have to try to find items at the bottom of a long array (or something) but databases are kinda designed for querying so it wouldn't make a lot of sense to use a database like you'd use an OO class. 

I'd recommend against storing a huge image as a texture like that. SDL_Texture is stored in your video memory which only has so much space, usually a lot less than the main memory on your machine. Even if you're only drawing a screen sized portion of the texture you sill have 10000x * 10000y * 32px * 32bpp (almost 12Gb (I don't think they even sell cards with that much memory)) clogging up your vram. You'll want to stick with tiles is what I'm saying. Best approach is to put all your tiles on the one image and load that up as a texture and then draw each of the visible tiles each draw. That way you pack a much smaller texture into vram. Don't worry too much about asking your gpu to draw a lot of sprites per frame if they're made in succession on the one texture, gpus are designed to do just that! 

I'm trying to draw regular 2D tiles to the screen from a single texture but there are a few ways to accomplish this and I don't feel like I know enough about rendering to assess the trade-offs properly. First of all, I have potentially a lot of tiles to render. Each tile is 8-32px (depending on zoom factor) and on a Full HD monitor that's over half a million tiles (and over a million triangles) per layer, and I have two layers. While I'm not going to go out of my way to support massive screens that are zoomed all the way out, I do want a solid reliable experience for players with screens up to 2048x2048px at any zoom, which ends up being about a quarter of a million triangles (before non-tile sprites, effects, and HUD elements are added on top). I've been getting a lot of conflicting advice on what is good and what is bad to do with regard to tilemapping... What's been the nicest method so far to work with is instancing 6 points, two triangles in a square configuration, and giving each instance a position and texture position. But now I'm told instancing with less than 100 vertices creates a lot of overhead... Using a geometry shader to produce vertices is also crazy expensive and impracticable for hundreds of thousands of triangles, apparently. Sometimes I'm told triangle strips are the say to go, but you have to add in messy degenerate triangles when you have tilemap gaps. Other times triangles are said to be better. Do all roads lead back to a static baked in array of all corners of each tile for efficiency? Also, when you move left, right, up, down... you need to add in more tiles to the side... but how? Is there a way to do this that isn't messy and complicated?