There are several definitions of cryptographic protocols, each of which tries to capture some particular features of interest. I start with Goldwasser, Micali, and Rackoff definition (1985): They first defined interactive Turing machines (ITM), based of which they defined (two-party) interactive protocols. An ITM is a special TM equipped with one read-only and one write-only communication tape. A pair of ITMs constitutes an interactive protocol if the read-only communication tape of party A coincides with the write-only communication tape of party B, and vice versa. The power of parties and the adversary model is then defined accordingly (see the paper). The multi-party case was later defined by Goldreich, Micali, and Wigderson (1987). They modeled a secure multi-party game in an elegant way, though the paper (as Goldreich states himself) leaves a lot of doors open. For a more concrete discussion see: $URL$ Finally, a much stronger model was proposed by Canetti (2001). In his paper, he defines a framework called Universal Composability (UC), based on which he defines the cryptographic protocols and puts forward a notion of security for them. As far as I recall, the last paper cites a lot of other works which try to define and model security protocols. Therefore, I strongly advise you to take a look at it. 

Refers to another problem dating back to Gauss' Disquitiones Arithmeticae (1801): If the factorization of N is not known and $(\frac{q}{N})=1$, where $(\frac{q}{N})$ denotes the Jacobi symbol, then there is no known procedure for deciding whether q is a quadratic residue mod N. This decision problem is well known to be hard in Number Theory. It is one of the main four algorithmic problems discussed by Gauss in his "Disquisitiones Arithmeticae" (1801). A polynomial solution for it would imply a polynomial solution to other open problems in Number Theory, such as deciding whether a composite N, whose factorization is not known, is the product of 2 or 3 primes; see open problems 9 and 15 in Adleman. PS: By now, we know two of the four algorithmic problems: 

I would write this as a comment, but there was a limitation on the number of characters. So I'll put it here. The paper title is "Relativized Polynomial Hierarchies Extending Two Levels." When you do not have access to an article, your best bet is to search for books/articles that reference your indented paper. The best place, IMO, is Google Scholar and Google Books. The Complexity Zoo attributes the proof that "There exist oracles relative to which EXP = NP = ZPP" to this paper. Yet this is incomplete, since other references cite the following papers as well [off-topic: I updated Zoo to cover the new references as well]: 

Shoup then tries to pinpoint the flaw on a contrived version of a protocol called "DHKE-1" (designed by himself). However, the contrived version is too "non-standard" for me to understand. Specifically, it includes the operation (or attack) core dump, which is not compatible with the attacks listed in the BR95 model. 

Edit: Several natural relaxations are conceivable to the SRP: Instead of requiring that "there are no two participants x and y, each of whom prefers the other to his partner in M," one can require that: 

Background: In their 1995 paper, Bellare and Rogaway describe a formal model for authenticated key exchange in a tripartite setting. In this setting, each client has a shared key with a central server, which is willing to help in key distribution between any two mutually distrustful clients. This model is reminiscent of the security settings for Needham-Schroeder protocol, Kerberos and Active Directory. For brevity, let's denote the Bellare-Rogaway-1995 model by "BR95." The adversary in the BR95 model is a probabilistic polynomial-time algorithm, which has total control over the communication between each pair of parties. Moreover, the adversary can mount a number of attacks on any single party. The attacks include revealing the session key, corrupting a party, and a special "TEST" attack, which is described next. When the adversary has finished with experimenting different attacks on the parties, it makes a final TEST attack. The attack is restricted in several ways; for instance, the adversary cannot mount the TEST attack on a corrupted party, or on a party whose session key is already revealed. (Nor can the adversary mount the test attack on the partner of such party.) On issuing the TEST attack, the adversary is given either of the following, each with probability 1/2: 

I don't know whether you are asking an open problem, or whether it has already been resolved. Yet the following paper can shed some light on this problem: Kurtz, S. A. 1985. Sparse sets in NP-P: relativizations. SIAM J. Comput. 14, 1 (Feb. 1985), 113-119. DOI= $URL$ Basically, it states that, even assuming Pâ‰ NP, there is an oracle relative to which no sparse sets in NP-P exists. On the other hand, the following paper: T. Baker, J. Gill, and R. Solovay, "Relativizations of the P=?NP Question", SIAM J. Computing (1975), 431-442. DOI= $URL$ demonstrates an oracle relative to which sparse sets in NP-P exists. Since $NPI \subset NP-P$, this proves that, either way, the proof does not relativize. EDIT: In addition, there exist sparse sets in NP-P if and only if $E \neq NE$: Hartmanis, J., Sewelson, V., and Immerman, N. 1983. Sparse sets in NP-P: Exptime versus nexptime. In Proceedings of the Fifteenth Annual ACM Symposium on theory of Computing STOC '83. ACM, New York, NY, 382-391. DOI= $URL$ (Journal version available here: $URL$ 

Blum, Micali, and Feldman (BFM) put forward a new (cryptographic) model, in which all parties (honest or adversarial) have access to some string. The string is assumed to be selected according to some distribution (usually, uniform distribution) by a trusted party. It is called the reference string, and the model is aptly named the common reference string (CSR) model. The model allows us to perform many interesting interactive protocols non-interactively, replacing queries by bits from the reference string. In particular, zero-knowledge proofs for any NP language can be conducted non-interactively, giving rise to the notion of non-interactive zero-knowledge (NIZK). NIZK has a lot of applications, such as providing a method for realizing public-key cryptosystems secure against (adaptive) chosen-ciphertext attacks. BFM first proved the existence of a single-theorem version of NIZK for every NP language; that is, given a reference string $\rho$ and a language $L \in \bf{NP}$, one can prove only one single theorem of the form $x \in L$. In addition, the length of the theorem is bounded in $|\rho|$. If the prover attempts to reuse some bits of $\rho$ in later proofs, there's a danger of knowledge leakage (and the proof will no longer be NIZK). To remedy this, BFM used a multi-theorem version based on the single-theorem NIZK. To this end, they used a pseudo-random generator to expand $\rho$, and then used the expanded bits. There are some other details as well, but I'm not going to dig in. Feige, Lapidot, and Shamir (in the first footnote on the first page of their paper) stated: