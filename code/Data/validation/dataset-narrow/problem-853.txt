It appears some bits have been flipped in those files' names. Whether this was because of the trojan or not, it's difficult to say. But given the names of the files, it's very unlikely that they have any particular importance, or if they do, they are easily replaced. 

Your script being run from cron is not accessing your own site on the same server via 127.0.0.1, but by its actual IP address. For instance, you are probably doing something like: 

The other sysctl, , allows some extra time for existing connections using a temporary address to finish up. You can also reduce this, especially if you don't anticipate long running connections. Here I reduce it to 1 hour: 

Since that is the correct library, if it still complains, then you should have a chat with the packager. 

where is present. The problem is that by default the network is considered "up" if IPv4 configuration completes, even if IPv6 configuration does not complete. 

(Note that the ext4 driver is capable of mounting ext2 and ext3 filesystems, which is why your system is currently usable.) 

It sounds like you forgot to install the intermediate certificate bundle on your web server. Visit the certificate vendor's web site to download the intermediate bundle. For nginx, this must be concatenated with your certificate and placed in the directive, for instance: 

Go to eBay. Search for . Buy one, preferably one that includes a battery. This is an actual hardware RAID controller which is compatible with VMware vSphere. Do not get a 6/iR card. If the card didn't come with a drive cable, then search for and buy one of the cables listed. This cable allows you to connect up to four SAS or SATA drives to the 6/i. When they all arrive, install the 6/i in one of your computer's PCI Express slots and connect the drives to the 6/i with the cable. Use the 6/i RAID BIOS to create your RAID array. Install VMware vSphere Hypervisor. 

Your email client attempted to connect to Postfix port 25 and send mail. This is not allowed. You need to connect to port 587 and authenticate to the server (and probably also set up authentication, but you didn't discuss whether you did that). 

Your DNAT and MASQUERADE rules are missing an interface specification. Without these, they attempt to work on all traffic, in both directions, which is not what you want. A DNAT rule should specify the inbound interface (e.g. ) on which the connection arrives; generally this is the WAN/Internet facing interface. And an SNAT or MASQUERADE rule should specify the outbound interface (e.g. ) on which traffic departs; again this is usually the WAN/Internet facing interface. 

libmcrypt is in the EPEL repository, which you don't seem to have installed. Install the EPEL repo and try again. 

You set up a bridge to your existing Ethernet adapter, and then configure your guests' network interfaces to use the bridge. The guests can then use any IP addresses assigned to you. The Red Hat documentation has a step-by-step guide for setting up the bridge. 

From the remote console, bring the system to single-user mode ( as root, or reboot with added to the boot command line). Bring up the network manually, e.g. with the appropriate and commands. P2V it to the remote hypervisor (or a storage server): 

Your KVM-based virtual machine is reporting much more memory used than the running processes account for. I would guess the most likely cause of this is that the host is using memory ballooning to overcommit memory usage on the host. You won't have much control over this unless you also control the host. If you've leased this virtual server, check with the host regarding their memory overcommit policies. 

On March 4, 2013, Red Hat provided updated OpenSSL packages which address this issue. You can receive them through your normal update channels. The original answer was: 

You are trying to set the policy for a built-in chain to . But this is not working. From the man page: 

Finally, I'll do a traceroute and look at the actual network path taken to reach the IP address. In this case... 

Don't use unless your RAID array is battery-backed, or you risk losing data. (Of course, if losing data is OK, then feel free.) Third, some other things that may help include turning off barriers, and using the deadline scheduler in the guest. Finally, do some research. IBM made a very interesting presentation on KVM I/O performance at the 2010 Linux Plumbers Conference. In addition they have an extensive set of best practices on using KVM which will certainly be of interest. P.S. Lengthy sequential reads and writes are rarely representative of a real-world workload. Try doing benchmarks with other types of workloads, ideally the actual application(s) you intend to run in production. 

If you insist on using Apache, you'll have to set up Apache rewrite rules to send 404 errors to your application, rather than in nginx's configuration. 

Note that both of these fail if prelinking is in use, which is one reason why it's generally not enabled by default anymore on recent systems. 

The obvious use of VOLUME is to populate a new persistent volume with data supplied by your container. Regardless of what sort of application you are deploying, there's almost always some initial data you need to start with. The documentation makes clear that this copy only takes place when the volume is newly created. 

So it should either be absent (recommended), or contain 127.0.0.1 to accept only local connections, or the IP address of the local network interface. If you want to restrict what IP addresses can connect to MongoDB, you'll need to use the firewall. 

You don't want to capture everything, only text from the ID up to the next slash, if any. So won't do what you want, since it just captures everything. Rather, capture until the following slash (if it exists): 

Also note that MySQL keeps its own internal time zone tables, separate from the system timezone database. To update MySQL's internal time zone tables, run the script which came with MySQL. 

You pay Red Hat for Extended Update Support. This is the only supported way to avoid updating to the latest service pack, and is subject to availability. It's not offered for all point releases. 

So, conforming implementations of SPF will completely ignore everything after the first . This doesn't mean, however, that every implementation conforms to the spec. In particular, this was probably thought worthy of clarification precisely because one or more implementations did not conform. It's not at all clear why an online validation tool would not catch this misconfiguration, but if you intend for anything after the first to be used, you should correct the record, as proper implementations will ignore it. 

So we see their ASN really is AS24940. Now, we do a much more complex query at RADb to get all of the known routes for that ASN. 

Your code doesn't specify the extension name correctly, so of course it fails. The correct extension name, as we see, is . 

In future it's better if you just deploy your source code and let bundler handle the gems on the target system, rather than trying to copy your whole .rvm directory. 

MX Logic is now a McAfee SaaS service. As a cloud-based service, it should be updated for all of their subscribers as soon as McAfee makes the changes, give or take a few minutes. If you want an exact number, you can always contact McAfee and ask them. 

Nagios (as shipped with the EPEL repository) comes with a sample configuration which monitors localhost out of the box, as soon as you . If you've installed Nagios from EPEL on a RHEL (or clone) box, then it should already be giving you host and service status reports for localhost. 

Web apps can no longer deliver mail directly to remote SMTP servers, but must use the local mail spool or an authenticated mail service. 

Handshake would seem to suggest that the controller is having trouble talking to the drives. I'd suspect electrical interference, bad cables, or possibly a bad controller. In the latter case the motherboard would need to be replaced. You'll only find the culprit by a process of elimination, by testing each piece of hardware separately. 

As the error message said, you tried to install 64-bit software on a 32-bit Linux distribution. To resolve the issue, first reinstall with 64-bit Ubuntu. Then try installing Zimbra. 

This is a problem with your WordPress configuration, not your nginx configuration. If you really mean to run the server on port 81, then you have to modify the URL in your WordPress options. 

Note that this command is Linux-specific and may not exist on other operating systems. Also do not confuse it with the system call. 

Vixie-cron was replaced with Cronie in EL6. Likely it wasn't installed in your "minimal" installation; they really do strive to be minimal with it. 

Use a firewalld zone for this. Zones can be specified either by interface or by source IP address. In fact, by default, a zone which accepts all traffic already exists, and it is named . By default, though, nothing is in this zone. So, you don't even need to create a zone, just add the IP address to the zone. 

The usual solution for having global dynamic IPv6 addresses is to use unique local addresses (ULA) in your local network for resources on your local network. This puts you in complete control of the addresses you use on your network. Note that ULA addresses cannot be used to reach the global Internet; that's not their purpose. Depending on your local network setup it may be as simple as ticking one checkbox in your router's (not your ISP's router) configuration to get ULA addressing going. 

You're missing a directive in your block. So I don't expect your existing site to work without issues. As for adding more sites, just create more blocks. 

This configuration requires that the host have a static IP address. For the expected use cases, it's likely that you have already planned for it to have a static IP address. And finally, the output! 

What I think is going on here is that your older version of libvirt is not aware of the fact that Intel disabled TSX in Haswell chips in a microcode update which your processor has almost certainly received by now. Libvirt only became aware of and advertised a Haswell-noTSX CPU model in version 1.2.14. Because your CPU has had some features disabled that libvirt uses for CPU type detection, it mistakenly thinks it is a SandyBridge. On a current version of libvirt, it should be correctly detected as Haswell-noTSX. In practice, this should not really affect you at all, except for VMs being unable to use the other features introduced in Haswell and not present in SandyBridge, but you can manually add these to your VM definition XML if you can't upgrade libvirt and really want them. Keep in mind that you probably will also need to upgrade qemu. And at that point you should probably just use a more current hypervisor. Whatever you're running now is older than the hardware on which it's running, which is always a questionable idea... 

You've configured nginx in such a way that it is attempting to connect to itself as the upstream, rather than to Node.js. 

Most likely your Internet Service Provider is blocking outgoing connections on port 25. This is very common with residential cable and ADSL connections. 

Someone else will probably think of something complicated involving but I think I have a very simple solution for this. Your application caches files using the URL path, without query arguments, as the filename. If the requested URL has a query string, you don't want to use the cache. nginx has a variable which is empty if there is no query string, or contains a if there is a query string. You can simply incorporate this: 

Exit code 143 means that the program received a SIGTERM signal to instruct it to exit, but it did not handle the signal properly. This is almost always due to programming errors, and is pretty common with Java applications of all types. You should be able to suppress this by adding the exit code into the unit file as a "success" exit status: 

What happens depends on whether the trigger is set to fire once. If the trigger is set to fire once, then the changes get applied to database A and Streams faithfully replicates them to database B. This sounds like what you want. Otherwise, the trigger fires again on database B after Streams replicates the change that caused the trigger to fire on database A. Which method is appropriate for any particular case depends on what the trigger does. See Oracle's documentation for a fuller explanation and another example. 

OpenStack does indeed allow you to overcommit CPU resources, but the amount that you can overcommit can be limited by local configuration. By default the ratio is 16:1, meaning you can run a maximum of 16 virtual CPU cores for every physical CPU core across all running VMs. Since most workloads are not very CPU-intensive, overcommitting CPU usually makes sense. But some workloads can be very CPU-intensive, and for those you may want to limit overcommitting. Things run by university students often fall into this category... :) If the overcommit ratio was changed to 1:1 then you would not be able to overcommit CPU at all, and would be limited to running no more vCPUs than physical CPU cores. This seems the most likely explanation for your DevStack issue. Note also that a single VM cannot have more vCPUs than exist physical CPUs in a compute node. But there is no problem to run more VMs than physical CPU cores. 

The option does apply to the entire server, so in order to do this you will need to run two instances of OpenVPN (and they will have to run on different ports). If you're using EL7 or Fedora this is very easy to set up. Create and with your unique configurations, and then enable them both: 

One thing not mentioned is that most servers have maintenance tasks they perform on a daily, weekly or monthly basis. These are almost always scheduled for the middle of the night, when activity is expected to be at its lowest. On a Red Hat system, for instance, these activities start at 4:02 am server time. Depending on the server, these could run for a few seconds to an hour or more. If you turn on the server at 4:30, these maintenance tasks will start immediately (by anacron) and the earliest users to log in between then and 5-ish am would be impacted to some extent. 

As the message told you, 2001:41d0:e:4c8::1 has no reverse DNS entry set. To solve the problem, you need to set the reverse DNS for this to the proper hostname value, that also resolves to the same IP address. You can do this within your OVH management panel. 

Your domain gets added to the end of each of these, if you haven't terminated them with a period. To get it working, change them to: 

There's a subtle but important difference between and here. means "delete through newline". When you process your into a using (or possibly some frontend), the characters and everything following them, including the next newline, will be dropped. (And all of those lines end with to suppress extra blank lines in the output.) Nothing beginning with through end of line will make it out of and into . Anything that remains in the output, of course, will either be sendmail configuration, or a comment that begins with , which will be copied as-is into , where they will be ignored. Anything beginning with and not deleted above will make it into unmolested as a comment. In your example, someone meant for all of the commented features to be removed from , as well as the comments, since the comments would be meaningless without the features present. 

Aha, I see the problem. You have provided no way for nginx to actually serve static files such as , so it is trying to pass them upstream to your backend. The quick fix would be: 

Create a static page with your desired content, and then add something like this to your nginx configuration: 

(Errno 12 is "Cannot allocate memory") So we see that MySQL tried to allocate 128 MB and failed to do so. That means your instance doesn't have enough memory left. It could be you just have something running that's leaking memory, and rebooting the instance will get you up and running. But it's more likely that you need to go through all your processes and see what is using up memory, and tune them appropriately to run in a micro instance, or upgrade the instance size. 

You installed something from the IUS repo, which brought in an incompatible version of MySQL libraries. That repository is well known to distribute incompatible libraries that break dependencies in this manner, and I recommend against using it. To recover from this, you will need to: