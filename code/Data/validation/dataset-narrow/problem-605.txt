Additionally, I am interested in use-cases or usability factors that are of concern, or should be added. Background Arrays are a very convenient system for storing data based on a simple index. Their constraints though (in Java), are that: 

Every instance in an enum already has an ordinal (the 0-based position of the value in the declaration order of the enum). For example, your instance will return 2. See: . These are the same values as the ones you are assigning to . Is that a coincidence? Additionally, you're using a small range of 0-based values for the field, and as a consequence, an array will be a better storage option than a . Even if the array is as much as 80% empty it would still be more efficient (space and performance) than the Map. About the exception - yes, I would throw a if the user tries to get a value that does not exist. Enums are compile-time constants and any use of the enum that's not legal should be reported, and found as soon as possible. In a sense, it's for this reason that Enums exist - to give compile-time certainty that your code references meaningful constants. The very fact that you are mapping the enum values back to an int is itself a bit concerning. There is no need to make the a read-only map. The map is completely contained/encapsulated in the enum and no other write accesses exist, and no user can write to it, so it's redundant to make it read-only. If your values can span a (very) wide range I would keep your Map-based lookup, but change the code to be: 

no unnecessary List instances and String instances are created (the only strings created are actual result values) the recursion is clearly located, and the end-condition of the stack is first. the simple structure on the stack is very efficient. 

Is it thread-safe? Yes Is it going to do what you expect? Probably not Is there a better way? Yes. Safe Your code will correctly lock, and access the value each time, and this makes it thread safe.... but, you will not get the results you expect. Expectations I suspect that your plan is to start, say, 10 threads, each of them incrementing from 0 through 9, adding 1 each time. You would expect the end result for the to be 100. It may not be. This is because, while your code is thread-safe, it is not atomic. Atomic means that an operation starts and completes as a single logical step. You have the code: 

As for the data structure, since the code is a 'decorator' for an input list, you should just add the parent-node pointer and be done with it. It is something you know in your method so there is no extra work. Alternatively, just use stack, or use recursion. As for the complexity of the algorithm, it is only O(n2) if your input List is an ArrayList or some other O(1) access list. If the input is a LinkedList itself, then your complexity jumps to O(n3). You should find an O(1) way to step through the List in your method, probably using an Iterator instead of indexed lookups. An Iterator over the input is the safest way to do it, but, if you have no choice then in the method you should check to see whether the List implements , and if it does not, then you should copy the input in to an ArrayList, and index-get off the arraylist.... 

You are not supposed to add a to the multiple times. But, it is possible that two threads, each processing a page, both pages with a link to the same URL, will hit this code at the same time. Both threads may cal at 'the same time', and both threads will add the to the (even though the refs are different lists in each thread, the is not. Only one of the threads will successfully add the newUrl to the though. You can use this to your advantage with the return value: 

you are keeping track of the path-count in the static variable. This is a pattern that, although works, is not very 'pretty', there's a better way... I'll explain. you modify the source array. This can be OK, but, in general, when you want to modify the source data you should instead work off a copy of the data. all your other variables (the maze itself and the size of the maze) are static. 

As a general observation, your comments are very comprehensive, and this may sway people in different ways. I looked at them and thought "tl;dr", and read the code instead. I still have not read your comments. Algorithm This is likely what would be noticed the most. Your algorithm is both advanced, and also not ideal. For an interview, I really would not hold your answer against you, but, for your interest, if you sort the letters in the term, and then sort the letters in the same-length words, if the resulting strings are the same, they are anagrams. This is much simpler than the dictionary, and set approach. Note, I would not hold that against you in an interview, but others may. I would look at your implementation and think: huh, they've demonstrated good use of various data structures, and, if I suggested sorting the term/words I am pretty sure they could fix it in no time.... Good things To expand on the good things: 

Structure Functions..... you need more of them. Your large, monolithic main method makes your code hard to follow, and separating out functions would help a lot. Oh, and errors ... you need to handle them. For a start, take this block: 

Late answer to this question..... There are a few things which should be considered when implementing a solution like this, and best-practice comes in to play here. 

So, if we have a folding function, that takes a new row to solve, and a collection of partial solutions that have been solved so far, we could have a folding function like: 

loop over each character in the search word for each character, you check whether a Node exists matching the respective character a the respective level. if any character is impossible, you return false. If all characters are possible, you return true. 

You can then combine those in a on the DirectoryStream above to collect your data. Of course, the double-nesting of the data is odd. Each map in the lower level will have exactly one entry.... 

OK, so now we have a client that can process incoming messages, let's look at that code, but using a scanner now instead of a reader, and it does not need to do the or the related "publish" of the deletion. It also does not need to close the connection: 

Right, this interface is now a better representation of the work it is supposed to do. Now, here's a key feature I want you to consider.... at the moment, you may only have one 'action' you need to execute on the server, the part of translating a userid in to a JSOM response. But, I expect there is, or will be, more. Having to build a new implementation for your interface for every type of operation is a real PITA, especially when it requires building a new / instance.... so, what we do is we create a convenient abstract class, which will do all the synchronous/asynchronous work for us.... Note, it does not implement executeSynchronous(), and it is still fully generic. It uses an executor service that is passed in. One of the really huge advantages of reversing the logic (there is no Callable involved in the synchronous call) is that the work is done on the calling thread. In your implementation, you have two threads fully occupied, the calling thread waits for work to be done, and a thread in the ExecutorService is actually doing the work. By making the call the way I suggest, only one thread is occupied, and the thread that is busy is the same thread that calls