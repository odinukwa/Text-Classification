But this 16 byte pointer can be ignored in this case. Can anyone tell is there a way to determined how much space overhead values are going to cost if the option is true? I am planning to apply this option to a large table and want to calculated how the table size will be affected. Note, I know that the value is moved when it is inserted or updated only. 

I need to rebuild the clustered index of the table that has more then 1.6 millions rows, more then 20 non-clustered indexes and 80 columns in order to reclaim space after two columns were deleted. I have try using the following command: 

I have found this Why is GETUTCDATE earlier than SYSDATETIMEOFFSET? discussion about differences between old and new date time functions. Then build the following query: 

Additional Information With we have the availability to use functionality with the of the server. One is able to create a certificate in the and mapped this certificate to - then, use the to protect used for encrypting data in particular column. Using is handy: 

So, value for column and , and value for column because it is set in the first bit of the second byte. If I change the statement to it will check if columns and or column is/are updated? How can apply logic in the context of one byte? 

with space used - maximum 5-10% of it (a backup of the transaction log file is made every 15 minutes). So, the above settings are specific for each database but in common, the log file size is enough and not growing. After is made, the size of the transaction log file is increased with 1 or 2 or 3 GB. Since I do not need such big file for regular use of the database, I am shrinking them back like this: 

It seems when other data is extracted from the table (we are filtering by now) the engine is not able to use the spatial index and performs clustered index seek instead. 

Is there any message or error which will help me to understand when or why this is happening? Is there any other way to detect the event? As far as I read, I can only use but it will give me current transaction which is opened which is useless for me as I do not know when the event happened. 

So, it seems that really the first row is now occupying more space (8 KB exactly). So, I add one more row and do the test again: 

Maybe, the checks that the engine is making is doing something like this, comparing its current date with my newer date and this is causing the error - I have change the script like this and executed 1 000 times last night - no errors were generated. So, I believe I have fixed this particular issue, but I can't be sure. 

I have a databases that are regularly (monthly) updated. An update includes a lot of new or changed T-SQP procedures, functions, indexes creation, etc. A has transaction log file with the following settings: 

but it finds nothing. The code is executed via procedure. Could anyone tell what's wrong with my query or alternative way of detecting for specific query. 

I guess this should be SP1 issue, because I have checked that I had successfully install standard edition of SQL Server 2014 without SP1. 

I am renaming some unique constraints to match our database objects naming convention. Strangely, there are several multi-line table valued function which returned table has unique constraints as follows: 

Can I create a key vault in (let's say) and used the keys to protect keys in SQL instance running on machine hosted in ? 

- constantly (in 99% of the cases only data for the past 6 months) - rearly (in 99% of the cases only data for the past month) 

The problem is that the above statement does not use the index. If I replace the with a number the index is used, but when a variable is used, the clustered index is used instead the spatial one. I have try a lot of options and the only one that works is: 

Add column to the table called with default constraint and Rename the current column to Add new column called Add new computed column with the original column name which will return the if flag is , otherwise the By default a query will return encrypted data - in order to decrypt it, additional logic will be implemented 

I have primary key clustered index which is constantly modified (insert and update) and read (select). Now, in order to change one of the types of the columns from which it is composed I need to re-created them or: 

In , we can use module to simplify this hierarchy. For example, we can store the certificates in the and these certificates are protecting our encryption master keys. I am wondering, if I want to use not built-in encryption functionalities, can I use module to create and manage my symmetric keys (like it is shown on the diagram). In the CREATE SYMMETRIC KEY documentation we have option, but not enough information about possible providers and examples. I am interesting in storing the which is protecting the Symmetric keys or the Symmetric keys in external storage, because in such way the data is separated from the keys and in the database we are storing only references to the keys (like in always encrypted). Windows Certification Store will be best option for me, but Azure Key Vault or something else will work as well, I guess. 

I am not interested in the software . Could anyone tell if such optimization really exists and should I continue generated more data in order to see it? This is the set up: 

I am trying to check how the table size is going to be increased after adding new column with default values. I use the following default values: , (empty string) and (some random text)` but it seems the table size is not changed. I am using the following statements: 

Is each field stored or only the ones? If you are using the of the table to read the whole record, are fields that are stored out of the row read, too? 

I am going to rename all of the above objects in order to match our internal naming conventions but I want to write an automatic script for doing this (as there are thousands of constraints). The only issue I can think off is that if index is used with a in statement it will be broken. Could you tell any other reasons not to use the for such purpose? 

I have perform some test with relatively small tables and the encryption took a very long time (maybe because there are many SQL objects that are referring the target table). I am wondering(worrying) when a table is being encrypted, is it possible to read the encrypted data or query the table? I only found this: 

everything seems the same, except the operator - in the faster case 5 k rows are returned against 1.8 k rows for the the other case. I have compare the reads of the two queries and it seems the second one is performing a lot of LOB reads: 

If large amount of data is deleted from the first database and inserted into the second one, only the delete operation is logged in the transaction log file of the first database, right? If I have two linked servers with many databases like this: 

Of course, this is not working for the users who are members of the database role. Is there a list with security roles or cases showing when the is going to work? I have found a database engine permissions but it's too complicated and does not seem to show when data cannot be masked from a user.