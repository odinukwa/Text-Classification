Update: It seems calling for all sounds i want to play doesn't work. I'm still getting stuttering in various places in my game when i call . 

Render every to its own render target, then render them all to the backbuffer. Create some kind of RenderAction queue where a game screen (and anything else I guess) could queue something to be rendered to the back buffer. They'd render whatever they wanted to any render target as normal, but if they wanted to render to the backbuffer they'd stick that in a queue which would get processed once all rendertarget rendering was done. Abstract away from render targets and backbuffers and have some way of representing the way graphics flows and transforms between render targets and have something manage/work out the correct rendering order (and render targets) given what rendering process needs as input and what it produces as output. 

In my code I'm using and to play my sounds. On the xbox whenever I first play a cue I get lag of about about one second. How can I avoid this? I'm thinking I probably have to do something like call (without playing it) for every I'm going to use, however I don't have a central place where I list all cues I'll want to play, so is there an easy way to do that? 

I think I stumbled upon this link here on gamedev and I really found it enlighting. $URL$ It explains some basic methods of implementing tile based levels, but there are also some important parts about how certain mechanics work in 2d platformers. I think you should look into slopes, as they can solve many problems you come across in platformers. Good to know is, that most platformers don't even bother with implementing proper physics, but implement certain rules, that mimic some physical behavior (like gravity), but allow certain behaviors that wouldn't be allowed with proper physics (air control for example). 

At one place in your code, you create your game container. If you followed the tutorials, that part will look something like this: 

If you look at the code, you can see that two things were implemented. The update method changes the position of the GameObject according to the defined velocity. And the render method first simply calls the render method of the base class and then checks, if it has to draw the building material. Some comments to this. The entities do not manage their state themselves (besides the position), but you would handle all game objects in the game loop and depending on the state you would change the fields of the entity, for example like this: 

One way would be to start with a basic polygon, maybe your 2 circles approach. Firstly offset all points randomly, so doesn't look too much like a circle, then for every edge, split it in 2 and offset the middle point by some small random amount. Keep doing this until you have the required detail. This is similar to what's done when generating forks of lightning. 

The ContentSerializerRuntimeType attribute tells the pipeline what type this will represent at runtime. 

Get the length of the vector from the slingshot to the mouse/finger/whatever. If it's more than your allowed length then normalise the vector (to make its length 1) then multiply it by the maximum length. 

The above means if we have the angle and one length of a right-angled triangle we can work out the lengths of the other sides. Luckly your problem can be thought of as calculating the length of triangle sides: 

The easiest way to do this is to create a shader for it (See code below). Draw everything to a render target, then use the shader to draw that to your back buffer In your game code record when the player dies, then in subsequent renders interpolate a shader parameter between 1 (full colour) and 0 (full grey-scale) according to 

Basically this should be what you are looking for... You have to keep some things in mind, for example you can leave out the upper bounds check, if the screen size in that dimension is bigger than the map size ( viewport.width > map.width ). Also, if you have your map width in tiles instead of pixel, you would have to multiply the map sizes with the tile size. If your screen position marks the middle of the screen, you would need to change some of the calculations a bit, but the basic idea is the same. 

To make things a bit more interesting, we add the logic to spawn a static game object to the player object (this is maybe not the best solution, but it should do the work). So we add this code to the PlayerObject class: 

You should take a look at quad trees. Its a common datastructure to store spatial data in cells. When you do the collision testing, you simply test against the objects in the same cell... I use the same datastructure for rendering. I pass the rect that defines the viewport into a selection method of the tree and receive a list of cells. Now i just have to render all sprites from those nodes... When the object spans over multiple cells ,you can add it to both cells. Just make sure to remove the duplicates ,when you use the results from the selection method. I'm currently on my phone, so I have no code examples here ,but a quick google for quadtree should help. 

I suggest using the EasyStorage helper classes that encapsulates a lot of the setup of loading/saving. 

You don't need to load all content within the method, you could load it in a method called by that, or at pretty much any time after that (once the is set up). A very simple example might be having a list or similar structure in your game engine, then before loading the user of the engine would add the locations and types of content to load. Then you'd call your engine's method from your game's method. The engine would then loop through the added resources and load them for use in the engine. This is of course a simple example, you'd probably need some kind of resource manager to manage loading/unloading/making resources available to what needs them etc. 

The content pipeline cannot do that (without a bit of hacking about), it processes content as part of the project's build process. Just use regular .net functions for monitoring file changes, maybe and reading files . 

The problem is that or are being cleared somewhere (probably when they get set as a render target), so the only sprite that "survives" is the last one. Since you have all your sprites rendered to you only need to render onto once. 

In the first grid you see the terrain configuration. W stands for water, S for sand and G for grass. The second grid shows, how the blend tiles are applied. Like I mentioned earlier, the width and height of the blend tiles is the half of the terrain tiles. Here now the first render action happens. The lowest terrain type is water, so we fill all the cells (and all adjacent cells) with the water tiles. So allthough the water tiles only fill the first column of our definition, we have also to fill the second column. Now we draw the next layer, but we only draw the tiles, that won't be blended. Water is a lower terrain then sand, so we do not need to expand to that side. But because the grass is higher, we have to fill the adjacent tiles with sand, where the grass blend will be rendered over. Now based on some patterns, we render the blending parts of the sand. (Now you see, why we need to also fill the adjacent tiles). Here we have repeated steps 4 and 5 (allthough step 4 wouldn't produce any output, as all grass tiles in this examples will contain a blend). 

I'm trying to get my head around component based entity design. My first step was to create various components that could be added to an object. For every component type i had a manager, which would call every component's update function, passing in things like keyboard state etc. as required. The next thing i did was remove the object, and just have each component with an Id. So an object is defined by components having the same Ids. Now, i'm thinking that i don't need a manager for all my components, for example i have a , which just has a property). As a result the doesn't have an update method, and the manager's update method does nothing. My first thought was to have an class which components could query, instead of having them as properties of components. So an object would have a number of and . Components would have update logic that queries the object for properties. The manager would manage calling the component's update method. This seems like over-engineering to me, but i don't think i can get rid of the components, because i need a way for the managers to know what objects need what component logic to run (otherwise i'd just remove the component completely and push its update logic into the manager). 

As the engine is pretty well known and documented by the community I think you can will be able to find a lot of detailed information about that type of map rendering in the GemRB community. 

Like this, you do not have to care about multiple terrain types getting together, as they are rendered from lowest to highest terrain type and the transtitions only concern the higher type. I know that it is a bit complicated at first, but I currently don't have more graphics, because I'm in the middle of refactoring my source. I will add some graphics representing what I do as soon as possible (also better explaining every step). I hope this will help you. One small addition: My mapper is built, that there is a default blend texture. But you can define specific blend textures for every terrain type. So for example if you want to make smoth transitions for all mappings besides the beach to water transition, you put the smooth transition as default and only set the custom transtition for the beach tiles. Also, my mapper allows to define multiple transition tiles for each tile type (so if you have a straight edge, you can make multiple blends, so they will alternate). ** Appended ** Because I currently have no assets to show, I created a schematic drawing in paint.net. Keep in mind, I'm a programmer and not and 2d artist, so artistically it is very badly drawn, but it should show, how I tackle the problem with multiple terrain types (>2) coming together). I left out optimizations for simplicity and applying the blending is also not mentioned, as I concentrate on the problem with the multiple terrains. I will add an example with real textures and blends as soon as I find the time to do so, so this gfx is only temporary. 

I'm using the marching square algorithm (2D version of marching cubes) to generate vertices. I end up with vertices arranged in a grid. I want to enable destructible terrain, and the way i was planning on doing this was to start simple - have one vertex buffer with the whole map, and edit the bits that change. In cases where I need to remove vertices I was thinking about just making them transparent so I can still render the whole map in one go. Firstly, is this approach reasonable? Secondly, I want to design my VB so that if I need to change vertices in 3x3, 5x5 or 7x7 etc. grids the locations of the vertices in the VB are close together. Now, from university I vaguely remember an image compression algorithm that walked the image in an unusual way, which i think could apply. Basically it walked in a U / horseshoe direction. It would place a U over the image, large enough to cover the whole thing, then it would break the U up into 4 quadrants, and use a smaller U to walk those, and so on until it got down to the pixel level, or in my case it got down to a single grid unit. Does this sound feasible? What is that algorithm called? (I can't remember the name and haven't found via general searching).