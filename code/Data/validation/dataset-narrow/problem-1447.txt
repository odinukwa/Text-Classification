There are a number of techniques used to solve this problem. Generally speaking the technique is called Inverse Kinematics, whereby after the pose is complete, the pose is modified to fit to a specific point - hence being Inverse Kinematics - $URL$ This can be solved through various means - animation or algorithm. Here are some links to techniques, both of which I have seen used on projects I have worked on: In Mechwarrior, back in 2003, they used a blender to mix different animations to put the feet all in the right places: $URL$ In Zoo Tycoon, they used a PID algorithm to get the feed to line up with the terrain. Again, back in 2004 - search for Zoo Tycoon the the following PDF: $URL$ The actual path you need to follow will depend on performance limitations, and the aesthetics needed. PID, or blending, or serious IK solving - it's something you need to experiment with and decide. Here's links to more samples: $URL$ $URL$ Good luck! 

It isn't entirely clear what you are asking. Setting shader parameters IS a bottleneck - that's why engines batch by material - textures, parameters, lights, etc. While CPUs and GPUs are efficient, in order to get the most out of rendering performance you have to think about these things. 

You can accomplish this with a ram drive but at that point you might as well copy it to the host hard drive. 

Depending on which physics system you use it may be that rigid bodies can be disabled, removed from the world or destroyed and recreated. It depends entirely on the system you are using. Generally inactive or not yet spawned objects are not added to the world until needed. However as one person noted the hidden object won't get any collisions or simulation. As an aside I wonder are you creating all the bodies on top of each othet? Any engine will be slow if forced to evaluate many bodies overlapping at once. 

I'm incline to suggest there is no 'right way' to do this but I think there are 'better ways' and some considerations to make when implementing your own system. Should an object's transform be authoritatively a world-space matrix, or a local-space matrix? If you are going to have deep, complex hierarchies, storing a local-to-parent transform (or separate components) as the authority is preferable. The alternative requires transforming a child's world matrix by the inverse of the parent, which is a costly operation and can introduce additional, unnecessary floating point errors. Instead you can calculate the world matrix on demand, concatenating with the parent's world matrix as needed. Local space transformations are then simple enough, and world-space transformations are performed relative to the parent's matrix. Should an object's transform be a matrix, or the components of a matrix? It certainly is cheaper to have a matrix, but I would argue that keeping the components separate make more sense here because, again, once a matrix is built the components become effected by floating point errors, as well as interference with one another. Furthermore, when manipulating just a transform, you have to continually renormalize the matrix because the accumulated floating point error will denormalize your matrix, and it will stop being orthogonal. While you can extract scale from the matrices, it is easier to just keep it distinct. I didn't do that in my editor, and sometimes it frustrates me to no end. I extract the Translation, Rotation and Scale (TRS) components when the object is selected, and then manipulate those to build the matrix. Instead I think I would keep the data separate if I did it again. How to keep it all in sync? So I think the format of your matrix should look something like this: 

Given that the rooms are procedural built, portals created and then populated, I have a couple of ideas. A* works really well on navigation meshes, and works hierarchically as well. I would consider building a pathfinding system that works at two levels - first, the room by room level, and second within each room, from portal to portal. I think you can do this during generation at an affordable rate. You only need to path from room to room once you enter it, so it's very affordable from a memory/cpu cost. High level A* can be done by creating a graph of each portal and room - a room is the node, and the 'path' or edge is the portal to another room. The cost of traversal has some options - it can be from the centre point of the room to the centre point of the other room, for example. Or you might want to make specific edges from portal to portal with real distances, which is more useful, I suspect. This let's you do high level pathfinding from room A to room B. Doors can be opened and closed, enabling or disabling specific paths, which is nice for certain types of game. Because it's room/portal based it should be pretty easy and affordable to calculate - just distance calculations and graph book keeping. The great thing about this is it reduces the pathfinding memory costs dramatically in large environments since you are doing only the room-to-room finding. The harder part will be the low level A* because it should be polygonal navigation mesh. If each room is square, you can start with a polygon. When you place obstacles, subtract the area occupied from the polygon, making holes in it. When it's all finished you'll want to tesselate it into triangles again, building up the graph. I don't think this is as slow as you think. The difficult part is performing the polygon hole cutting, which requires a good amount of book keeping on that kind of stuff, but it is well documented within half-edge structures, and established computer science graphics books. You can also perform this generation lazily, in a background graph, as you don't actual need the A* results of this level until someone is in the room - the high level takes care of basic path planning for you. Someone may never even enter the room in a run, because the high level A* never leads them there. I know I have glossed over the low level navigation mesh generation, but I think it's one of those things you set your mind to and solve and then it's done. There are a bunch of libraries out there like CGAL ($URL$ and others that can do this stuff, but really to get it going fast you might need to write it yourself so you only have the things you need. Alternatively, you could make each room be a grid, and the obstacles fill up parts of the grid, and then do all the standard grid smoothing algorithms, but I like navmesh data as it is small and fast. Hope that makes some sense. 

Where each if case returns to prevent the following case from being called. While this is done often it is cumbersome to require it. You could use switch statements, but those don't work if unrelated conditional cases. Can you cite what debate you are talking about? 

It's possible to only send N vertices from a vertex buffer using the offset & size arguments in most APIs. 

Bullet does not allow the transform associated with a RigidBody to have any scale or shear in it. This is not uncommon; many other physics engines have this restriction as scale and shear can make the internal dynamics simulation very difficult to solve. Instead of scaling the rigid body you will need to instead scale the shape used for collision detection. This is done by calling btCollisionShape::setLocalScaling(). You may need to call btCollisionWorld::updateSingleAABB( rigidbody ) to get the new bounding box of the scale to take effect. 

You can see in the above diagram the black outlines of the skid mark. The points P0, P1, P2, P3, and P4 have been collected. Note that P4 has no further point so a forward vector cannot be calculated. I normally use the tire direction for the point, or simply use the same forward as the previous point. Here the blue line is the UP vector - assume that the red line lies on the X/Y plane and the Up vector is (0,0,1) - perspective is hard to show in a 2D image. Hopefully this helps - there are some additional operations to consider to make the pinching at corners work better, but you might not have to do it if you are not turning too quickly. You will also need to consider under what conditions you need to add skids, etc. 

While it's a btBvhTriangleMeshShape I expect the same (unsupported) results with btConvexTriangleMeshShape because the underlying colliders are very similar. 

Then PrimaryAction(), SecondaryAction() and TertiaryAction() would be called whenever i is zero. You might rewrite it as a function: 

Simply citing a language's need to allocate temporaries isn't fair when a language is designed around fast, generational allocations and garbage collectors, as you'll find in modern javascript implementations. I would go and profile where the bottlenecks are and be sure it is the allocations, first. 

Do you have edge connectivity? If so pick an edge you know to be on the boundary and add to your list. Working in a consistent winding order (clockwise or counter clockwise) pick a vertex of that esge. Look at all neighbouring edges that share that vertex. If an edge is on the boundary travel down it and add to your list. Rinse and repeat. Eventually you will return to the original edge. Now the contour is complete. For this to work you need dat on vertices and which edges of which tiles share them. As you traverse some edges will be on the same tile and some will take you to neigjbourinf tiles. In the end you have a polyline in the order of the boundary which would let you smooth it like civ does. 

You are blocking on pollEvent. window.PollEvent is for handing events, not your draw loop. Since you are looking at the keypresses every frame, you can't do it in the event handling - it is only trigger on the actual keypress events (which you are now ignoring, which is fine). Move it into the draw loop. Take a look at this sample: $URL$ Good luck! 

I would store the data in a graph to help with pathfinding - nodes are intersections and edges are streets (with one-way, no pedestrian, etc flags). Then for storing the data I would take a multi-layered approach Gather the Source Data First find some way to define (or import) the data. Likely a visual tool would help, but you could get away with something that supports real-world coordinates (latitude, longitude, etc). You will want to support connectivity at this stage, but also allow objects to be just 'placed' in the world (cinemas, etc), since writing the tedious connectivity code in XML, JSON or a non-visual tool will be cumbersome. File format of this might be useful to be somewhat human readable, so XML or JSON, as long as the format supports circular references and links. Nodes likely should be stored in a text-editor searchable format - GUID, or some such - to help authoring and debugging. Add Connections & Validate Now you need a tool that takes **all* of the world data and creates any game-specific connections, intersects roads and makes connections, annotates the world with one-way-streets. The data should be loaded all at once, in an offline tool, into some kind of verbose/fat format. It would have all the useful information in it so you can write validation steps. It should also allow debug pathfinding so you can run offline tests that you can truly get from the Eiffel Tower to the Louvre. Having a separate tool in an offline process for this is great because you can add as much cumbersome debugging information to it but you never have to feel like your game code is getting dirty. Plus the format you store this in memory will likely be vary different than in games - adjacent nodes will be in a dynamic list, whereas at runtime it will be in a fixed sized array, or a linked list, for example. Emit Data To make searches efficient you will want to store the data in some kind of efficient representation. That means your GUIDS will be compressed down to some kind of incrementing ID, and adjacency/edge information will be stored in flat arrays, or linked lists. All of this is really important to get your searches fast. Furthermore, specific entities (such as restaurants, or cinemas, would be stored in a separate data structure so you can quickly locate their positions in the world. That structure might be a database of restaurants, say, or it might be a uniform grid where each grid stores all of the buildings in it in order to make searches for 'nearest things' faster, or both. I suspect both. By making the emitting stage separate from the validate stage you can write code that compresses the data into game-ready format without worrying that you've broken the preprocessing or validation stage. Your writing code might be sharable with the reading code in the game, too. You might also want to chunk up the data into pieces to stream in, or implement a hierarchical path finding system on top of it so you don't need all of the fine-grained data loaded all the time. Load the data Now the game loads the data and starts working on it. Ideally the data is loaded with as little work possible. I always strive to make my data memory imaged so it loads in place without any allocations, but that's for my commercial production game environment. Good luck.