The answer to such question can have practical applications as well - e.g. it can help to define some kind of formal semantics of the "business rules" (declarative programming paradigm that is used more and more in business applications, e.g. IBM ILOG, JBoss Drools, Oracle Business Rules, PHP and Python also have their own rules engined) and going further - this can be useful for cognitive robotics as well. 

It is known that many logic problems (e.g. satisfiability problems of several modal logics) are not decidable. There are also many undecidable problems in algorithm theory, e.g. in combinatorial optimization. But in practice heuristcs and approximate algorithms works well for practical algorithms. So one can expect that approximate algorithms for logic problems can be suitable as well. However the only reseach trend along these lines I have managed to find is the max-SAT problem and its development was active in nineties. Are there some other active research trends, workshops, keywords, good references for the use and development of approximate methods for modal logics, logic programming and so on? If automated reasoning is expected to gain prominence in the future applications of computer science then one will have to be able to go beyond undecidability constraints of logics and approximate methods or heuristics can be natural path to follow, isn't it so? 

I'm especially interested in having either a specific example of such $V$ or a proof such $V$ doesn't exist under reasonable assumptions such as $\mathsf{P} \ne \mathsf{NP}$ The question might seem strange, so I'll briefly outline my motivation for it. I'm interested in AIXI-like models of aritifical intelligence. Here $L$ plays the role of the environment, which I assume to be efficiently computable, and $a$ plays the role of the actions of the agent itself. Given a positive answer for my question, it is possible to construct an agent efficiently computable relative to $V$ which optimizes a given efficiently computable utility function $u$ by choosing its future actions s.t. $u$ is maximized assuming the environment behaves according to the prediction of $V$ 

Consider a set of $n$ MDPs (Markov decision processes). An MDP $M$ is selected from this set according to some probability distribution $\xi$ and then interacts with a fixed policy $\pi$ for time $T$ yielding a total expected reward of $V_\pi$ (where the expectation value is w.r.t. $\xi$, the random transitions in $M$ and possibly random decisions by $\pi$). The problem of designing a policy such that $V_\pi$ is as high as possible is known as reinforcement learning (specifically, we only consider here the special case of model-based Bayesian reinforcement learning with a finite set of $n$ models). A policy $\pi$ for which $V_\pi$ equals the highest possible value $V^*$ is said to be Bayes optimal. It is often claimed that computing a Bayes optimal policy is intractable, therefore we need to use algorithms that are not Bayes optimal but still satisfy good performance bounds (e.g. PSRL or some UCB algorithm). However, I am not sure to which extent this intractability is backed by complexity theoretic hardness theorems? In fact, this kind of reinforcement learning can be regarded as a special case of solving a POMDP (partially observable Markov decision process). Namely, we can consider a POMDP $\hat{M}$ in which a random transition at the initial state samples $\xi$ in a manner which is unobservable, and the resulting MDP $M$ governs the following transitions. Now, Papadimitriou and Tsitsiklis proved in 1987 that solving POMDPs is PSPACE-hard. The proof works by reducing QSAT to computing the value of a POMDP. Moreover, examining the reduction shows that the POMDP they construct is exactly of the form $\hat{M}$! Specifically, the random unobservable transition in the beginning serves to select a clause in the formula of the given QSAT instance. Thus, Papadimitriou and Tsitsiklis's result indeed shows that finding a Bayes optimal policy is intractable (under standard complexity theoretic assumptions). However, notably, their proof only works when exact Bayes optimality is required. This is because the universal quantifiers in the QSAT instance are replaced by random transitions in the MDP, which means that it might be possible to achieve high reward even for unsatisfiable formulas. Now, Goldsmith, Lusena and Mundhenk proved in 2001 that even approximating the value of a POMDP is intractable. However, in their proof the POMDP is not of the form that interests us. More precisely, they start with a basic construction that is of the form $\hat{M}$, however they require a probability amplification that runs the basic POMDP many times, and each time it runs the unobservable part of the state is randomly reset. So, AFAIK, it seems possible to have e.g. a polynomial-time approximation scheme that accepts a set of MDPs and $\xi$ as above and produces an $\epsilon$-approximation of $V^*$. Such a scheme would be possible to use to compute a nearly Bayes optimal policy (with $V_\pi \geq V^* - T\epsilon$). Does such a scheme exist? Or is there another theorem that forbids it? 

The term “tight” has multiple uses, as is mentioned in a comment. However, you seem to be interested in a combinatorial context or on a combinatorial-type problem so I’m going to assume that contexts. Let’s say we are talking about a function, $f(n)$, that bounds $g(n)$. In your case, $g$ is the true number of vertices of the $n^{th}$ graph in your family and $f$ is your bound. 

This problem (when suitably rephrased) is NPC and I imagine that people have at some point wondered how Uber decides to pair drivers and passengers. 

My impression reading this question is that no suitable example of a problem that requires more than just PA (let alone ZF) has been given, and the excellent answer by Timothy Chow explains why it's so hard to find examples. However, there are some examples of TCS extending beyond the realm of arithmetic, so I thought I would give a theorem that requires strictly more than $ZF$. Although it doesn’t require the full axiom of choice, it does require a weaker version. The De Bruijin-Erdos Theorem in graph theory states that the chromatic number of a graph, $G$, is the sup of $\chi(H)$ as $H$ ranges over all finite subgraphs of $G$. Notice that the conclusion is trivially satisfied for finite $G$, so this is an interesting statement about infinite graphs. This theorem has many different proofs, but my favorite is to evoke Tychonov's Theorem. As mentioned in the Wikipedia article I linked to, this theorem really and truly requires more than $ZF$, however it doesn't go as far as requiring the "full axiom of choice." There's a horribly unreadable proof of this on the Wikipedia page, but basically the theorem falls in the Solovay Model due to a clever constructions involving measure theory. 

$\forall w \in V : |w|$ is even $\forall L \in \mathsf{P}, a \in {\lbrace 0, 1 \rbrace}^\omega \, \forall n>>0:s(L, a)_{2n}=\chi_V(s(L, a)_{<2n})$ 

It is well-known that the value of such a game can be computed in space polynomial in $l, m, n, N$ and the size of $C$ and $D$ (or even just the depth of $C$ and $D$, assuming appropriate representation). Now consider the same setting as above with additional parameters $k,j \in \mathbb{N}$ s.t. $k + j \leq l$. Consider the extensive-form game with imperfect information which is the same as above but positions are grouped into 1st player information sets by the first $k$ bits and into 2nd player information sets by the last $j$ bits. That is, the 1st player's pure strategies are functions $\{0,1\}^k \rightarrow \{0,1\}^m$ and the 2nd player's pure strategies are functions $\{0,1\}^j \rightarrow \{0,1\}^n$, which are evaluated on the first $k$ bits or the last $j$ bits of the position correspondingly. 

Hoare logic can be used for proving program correctness (e.g. for deriving correctness statements for the whole program from the statements for the individual commands or constructions; good summary is $URL$ The question is - is there any line of research where Hoare-style reasoning can be made for programs that creates and deletes objects. One thought can be that this reasoning can be simulated by defining large pool of objects which have (for the purposes of correctness analysis) additional state attribute with values from the enumeration {not-created, created, destroyed}. But I guess that better approach should exist. Are there any references or keywords for furher search into this matter. 

Recently such themes as semantic web, modal logics, business rules have seen increased interest as research topics in computer science (alhough many of then have more than 80 years of history), but are there any open source projects (even better if they are actively used in commercial applications as well) that use these technologies and where one can participate and get new challenges for research? I have found a lot of research projects (e.g. satisfiability solvers, logic programming environments) but at present I don't know many succesfull applied applications. There have been few reports on some of them in the jornal of "Theory and Practice of Logic Programming" - mostly about solving scheduling problems with logic programming methods. But maybe there is some open source projects as well? Sometimes it seems to me that modal logics (semantic web is part of them) and logic programming gives false impression about their power and their generality has few applications, e.g. the concrete algorithms of integer programming or scheduling are more powerfull and ready for applications than general methods suggested by the former ones. 

Consider any language $L$. Define $s(L) \in {\lbrace 0, 1 \rbrace}^\omega$ (an infinite sequence of bits) by the recursive formula $$s(L)_n=\chi_L(s(L)_{<n})$$ Here $\chi_L$ is the characteristic function of $L$ i.e. $\chi_L(w)=1$ for $w \in L$, $\chi_L(w)=0$ for $w \notin L$ A language $U$ is called a "universal predictor" when $$\forall L \in \mathsf{R} \, \forall n>>0:s(L)_n=\chi_U(s(L)_{<n})$$ A famous example is Solomonoff induction It is easy to see $U \notin \mathsf{R}$ by considering $L = U^c$. The question is 

Consider $X$ an $\mathsf{NP}$-complete language e.g. $3-SAT$. I'm looking for an algorithm $A$ for solving $X$ with the following property. Given $M \subset \lbrace 0, 1 \rbrace^*$ any set of words s.t. $X$ with promise $M$ is decidable in polynomial time, I require $A$ to decide $X$ with promise $M$ in polynomial time 

It is not hard to see that a positive answer would imply $\exists A \in \mathsf{TALLY}:\mathsf{R} \subset \mathsf{E}^A$ ($A$ is s.t. $U$ is Cook-reducible to $A$ and we have $\mathsf{R} \subset \mathsf{E}^A$ since it is possible to apply $U$ to the sequence $\chi_L(n)$ to decide $L$ in exponential time). This implication seems surprising but I don't see why it's necessarily false EDIT: Actually such $A$ exists: $\lbrace w | \exists i,j \in \mathbb{N} : i \in L_j$ and $|w| = f(i,j) \rbrace$ Here $f : \mathbb{N}^2 \rightarrow \mathbb{N}$ is a bijection computable in polynomial time and $L_j$ is the $j$-th recursive language (I'm using an arbitrary enumeration of the recursive languages) However a universal predictor in $\mathsf{P/poly}$ implies a stronger statement, namely, that there is $A \in \mathsf{TALLY}$ and some fixed polynomial $p(n)$ such that all languages in $\mathsf{TALLY} \cap \mathsf{R}$ can be computed in time $p(n)$ given an oracle for $A$ EDIT: The answer to the first question is positive. Showing this is equivalent to constructing a Turing machine with a special tape on which some fixed (input-independent) infinite string is written in the initial state s.t. this machine computes a universal predictor in polynomial time. To do this, imagine the special tape to be 2-dimensional. In row $i$ of the tape write infinite computable sequence number $i$ (i.e. computed by program $i$). The predictor then works as follows. Given an input of length $n$ it compares it to the first $n$ infinite computable sequences. The first sequence which matches the input is used for the prediction. If no sequence yields a match the predictor outputs $0$. 

I would agree with the commenter that this should be referred to as a cardinality constraint or a collection of cardinality constraints. I might also call it a "structural constraint," but I would specifically avoid calling it a "group carnality constraint" as "group" already has a meaning. In general, I would advocate for avoiding referring to a collection as a "group," "set," or "class" unless your object actually satisfies the required axioms. "Collection" is a good, general word that doesn't have a mathematical meaning. If you don't want to use the term "carnality constraint" you can always introduce a term to refer to this specific restriction in your context. This can be helpful because it allows you to highlight the context-sensitive meaning of the constraint in a way that a more general term doesn't. For example, I have a paper with a constraint of this form that I refer to as an "isolation condition" because, when $S$ satisfies it, $S$ is isolated from the structure of the rest of the graph in a relevant way. This gives me a simple and intuitive way to refer to the condition, while simultaneously telling the reader what is important about the condition every time it comes up. 

It is possible to restrict attention to functions $u:\lbrace 0,1 \rbrace^* \rightarrow [0,1]$ since any function satisfying the 2nd condition can be brought to this form by a linear redefinition Consider $u$, $v$ asymptotic optimization problems. $f: \lbrace 0,1 \rbrace^* \rightarrow \lbrace 0,1 \rbrace^*$ is a called a reduction of $u$ to $v$ when the following conditions hold: 

The motivation for the question comes from Levin search which would satisfy the above condition if we considered the candid search problem instead of the decision problem Is the answer affected by adding the assumption $M \in \mathsf{P}$? 

If the answer is positive, can $f$ be polynomial? What is the growth rate of $g$ (clearly at least exponential under ETH)? If the answer is negative, can polynomial $f$ exist if ETH is wrong but $P \neq NP$? 

Motivation Consider some $L \subseteq \{0,1\}^*$. Suppose Alice gives Bob a machine or oracle $M$ that purportedly decides $L$. If Bob has only polynomial time in their disposal, then they cannot directly test $M$ unless they already know a polynomial time algorithm for $L$. However, if $L \in \textsf{PSPACE}$ then Alice might be able to convince Bob via an interactive proof protocol. That is, Bob can generate random instances of the problem of size $n$, run $M$ and have Alice demonstrate the correctness of the answer. If they repeat the procedure sufficiently many times then Bob knows that, with high probability, $M$ gives the correct answer on most instances of size $n$, so it is at least "average-case" valid. Now, if Alice is also limited to polynomial-time, then in general they won't be able to supply an interactive proof. Indeed, if it is possible for both the verifier and the prover to be polynomial-time, it follows that $L \in \textsf{BPP}$. The motivation for the question is: what happens if $L$ is in $\textsf{BPP}$, but Bob doesn't know the algorithm for solving it? In this case, it is possible that Bob knows an interactive proof protocol for some class that is known to contain $L$ and Alice is able to fill in the role of prover. For example, if Alice tells Bob a polynomial-time algorithm for solving graph isomorphism then Bob can easily convince themselves of its validity (for given input size) because there is an interactive proof protocol where the prover can run in polynomial-time given oracle access to the problem. However, this example requires using a protocol specifically tailored to graph isomorphism, whereas I would like a protocol that can work for any problem in a large class (optimally all of $\textsf{PSPACE}$). I am interested in all results that are relevant to the above discussion, but to make the question concrete, I will suggest a specific hypothesis. Question Given a polynomial-time computable mapping $f: \{0,1\}^* \rightarrow \{0,1\}^*$, we can consider the language $f^{-1}(\textsf{TQBF}) \in \textsf{PSPACE}$. We say that such an $f$ is easy when there is a polynomial-time algorithm that implements an optimal strategy for the corresponding game. That is, given $x \in \{0,1\}^*$, $k \in \mathbb{N}$ and any assignment of the variables corresponding to the $k$ outermost quantifiers in the formula represented by $f(x)$, our algorithm can decide whether the resulting formula (with quantifiers over unassigned variables) is true. In particular, in this case $f^{-1}(\textsf{TQBF}) \in \textsf{P}$. 

I am trying to model domain in logic (first order logic or some of modal logics) and I have variable which is degree and not true-false variable. There can be different conclusions depending on the degree of this variable. How to model such variable? If v ir degree variable and n degrees are possible, then v can be modelled by introduction of n propositional variables v1=true <= v=1, v2=true <= v=2 and so on. Additional constraints (axioms) should be introducted - e.g. only one variable from v1, ..., vn can be true. Introduction of additional variables is not good, because: 1) it increases complexity; 2) it is not extendable in simple manner. The question is - maybe there is some syntactic sugar available for degrees, or maybe special logics are already available for handing degrees of even variables whose domain is set of natural numbers? Prolog and other logical programming environments has this feature, maybe this can be brought back to the theory as well. 

Notice that $f$ can be tight but still improvable. If you have that $g(n)=n-\epsilon\sin((n-1)/100)$ then $f(n)=n^2$ is a tight bound. It is an upper bound for $g$ and they agree for $n=1$. However, that doesn’t mean it cannot be improved. A better bound might be $f_k(n)=n^{1+k^{-1}}$. This family has the property that $g(n)<f_k(n)<f(n)$ for $n>1$ and $g(1)=f_k(1)+f(1)$. I am generally not a fan of the term “optimal bound” because it’s usually inaccurate. The optimal bound for a sequence of integers is simply that sequence of integers, so if you have an “optimal bound” you almost always have an expression for the underlying process. There are contexts in which the previous paragraphs is wrong, however, and you seem to think that you’ve proven that you bound is the best possible. If that’s the case, there aren’t any caveats to that sentence, and what you’ve proven is indeed a bound rather than an expression for the number of vertices in the graph, then “optimal bound” or “best possible bound” is the terminology that I would recommend using. 

It is known that first order logic is too general to be decidable. Adding axioms with special meaning (e.g. expressing notions such as necessity/obligation, provability, etc.) leads us to modal logics but some of them (especially multidimensional fusions or products of them) are undecidable too. As I understand, then undecidability generally is created by quantifiers - it is quite hard to prove of refute formula, that should be valid in all worlds (if accessibility relation allow them). The undecidability can be handled by several approaches: 1) lowering the expressivity of the logic or considering the less expressive fragments; 2) following ideas of max-SAT problems; 3) moving to approximate reasoning (probabilistic, fuzzy-logic, etc.). All these approaches has this drawback: they tries to reformulate or make less relevant the original problem that was created as conscise and clear model of the real world problem. Maybe there is better way how to approach such undecidable situations - simply by adding additional axioms that reflect the real-world situation. E.g. axiom can be added that the number of variables is bounded in the logic (there can be different axioms depending on how we model the reason why there are only finite number of instances of some class in the world - e.g. bounded resources, restricion by law, etc.). So - the question is - is there some research trend that investigates the modal logics with aim - what axioms should be added to them the regain the decidability of logics (and according - the suitability for them for automated reasoning tasks, for use in autonomous systems)?