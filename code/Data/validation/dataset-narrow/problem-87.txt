According to the current RFC, window scaling cannot be negotiated dynamically. The RFC explicitly states: 

Though it is possible to allocate addresses to virtual machines from the link prefix connecting the physical machine to a router, that is not the approach I would recommend. Rather I would recommend that you get the hosting provider to route a shorter prefix to your physical machine. The prefix length you need depend on the number of VMs: 

Those numbers are assuming the provider only hand out prefixes on nibble boundaries and that you want a /64 per VM. The overlap between the ranges is because I allowed for an HD-ratio anywhere between 80% and 95%. The reasons I would recommend getting a prefix routed to the physical machine and subdivide that into a link prefix per VM are twofold. 

An attacker on the path One way to perform a MITM attack is by having access to a node which is on the legitimate path between the two endpoints or a node directly connected to an Ethernet segment used by the legitimate path. Assuming the legitimate path used between the two endpoints is identical for IPv4 and IPv6, then an attacker will be just as close to the IPv4 path as to the IPv6 path. If the attacker controls a node on the path, then the attacker can obviously MITM both protocols. If the attacker only control a node connected to the same Ethernet segment as a hop used by the legitimate path, it takes a bit more work. In this case MAC spoofing would work equally well for attacking both IPv4 and IPv6. But it is difficult to both capture the packet that way and then pass it on to the legitimate destination. If the attack is performed by spoofing at a higher layer, then attacks are possible against both IPv4 and IPv6, but it is different packets which need to be spoofed in the two cases. In case of IPv4 it is ARP packets, in case of IPv6 it is neighbor discovery packets. Certain switches have features to protect against the above spoofing attacks. However if the switch was designed to protect against ARP spoofing but has no protection against neighbor discovery spoofing, then the attacker would only be able to MITM the IPv6 traffic and not the IPv4 traffic. BGP attacks Without being anywhere near the path between the two endpoints, it is possible to perform MITM attacks through some BGP trickery. Even if the legitimate path is identical for IPv4 and IPv6, it is still possible that prefix lengths and route origin authorization is different enough between the two, that the attack is not equally efficient against IPv4 and IPv6. Influencing the choice of IPv4 vs IPv6 Should an attacker somehow control only IPv6 and not IPv4, the attacker may obviously have an interest in influencing the client to transmit traffic over IPv6 rather than IPv4. If the client is using the happy eyeballs approach, then it will usually use the fastest of the two connections. A MITM simply forwarding packets between client and server can be expected to increase latency, thus the client is more likely to chose the connection not under attack. However if the MITM instead of forwarding packets decide to terminate the TCP connection and run another TCP connection towards the server, then it is possible that the MITM can achieve a better latency from the client's perspective than the legitimate path. The exact details of the algorithm vary between implementations, for example it is possible to give one protocol a head start (measured in milliseconds), and if that head start is large enough variations in latency introduced by the MITM may not affect the outcome. 

Link-state and distance vector aren't actual routing protocols, but types of routing protocol. Since different environments have different requirements, there are different routing protocols. The protocol internet routing works on (BGP) is a distance vector protocol, because it is extremely scalable. Also, you don't want to be dependant on the link state information from other companies to route your traffic. You basically only want to know if they can get the traffic towards the destination and if they are closer to the destination than yourself and the other systems you are connected to. 

A 'normal' GRE tunnel is a used as a point-to-point connection. A /30 (or even /31) would be a better use of your subnet space. There also exist multipoint GRE tunnels, such as DMVPN. Here you can have multiple tunnel endpoints connected to one tunnel interface. In that case, you will want a bigger subnet. 

MAC addresses aren't stored in RAM, but in TCAM. You can adjust the Resource Allocation of your TCAM by using a different SDM profile. The default is 6K unicast MAC addresses. The only profile that offers more space for is the VLAN profile, which offers 12K address, but reduces the number of routes you can use to 0. Having 6K MAC addresses is indicative of a different problem though. When you see that many MAC addresses on a switch, you might be looking at Layer 2 segments that are too large. When you have too many hosts in the same Layer two segment, you have a lot of overhead of all those chatty hosts. Also, if anything bad happens on the network, and there is no segmentation, everything will be affected. Also, seeing so many MAC addresses on the 3750X probably means that your network is very oversubscribed, making the 3750X a huge bottleneck. So, the better question to ask yourself first is: Why are there so many unicast MAC addresses on this switch, and how can this be reduced? 

If you announce the two different /48 the traffic will be routed across the internet to the right data center, which keeps things simpler for you. If on the other hand you announce just the /47 in both locations you have to get the traffic to the right data center. This may be desirable if you have a private connection between the data centers that you find to be more reliable than the public internet. Doing both of the above will serve as a sort of failover. Usually the traffic will go straight to the correct data center. But your private connection will be there as backup. However if other networks think you are sending them too many announcements they may decide to ignore your /48s and use just the /47, and your private connection will see some more traffic. If you don't have a private connection between the data centers the best choice will most likely be to advertise the two /48 and not advertise an aggregated /47. All of the above applies to IPv4 as well, just with different prefix lengths. What to do if you can't get more IPv4 addresses If you go ahead and advertise a /25 from each data center there is a significant risk the advertisements will just be ignored. Even if it works today there is a risk it will stop working in the future, so you will need a different plan. If you don't have a private connection between the two data centers there is the possibility to use an IPv4 over IPv6 tunnel between the two data centers as a private connection. The obvious drawback of the tunnel approach is that the tunnel is not going to be more reliable than the internet connection between the two data centers. And avoiding using the tunnel by only advertising the specific prefixes isn't an option because those specific prefixes would be too long. An option worth pursuing if you are using the same transit provider at both locations is to advertise both the aggregated /24 and the more specific /25s. What you would need from the transit provider to advertise to the world is the /24. The two /25s you'd only need the transit provider to accept and use within their own network in order for the traffic to be routed to the correct of your two data centers. Obviously before you do anything like that you'd have to discuss it with your transit provider to ensure that it is a configuration they are willing to support. Other caveats with a tunnel Another caveat in case of any tunnel is MTU issues. You need to ensure that you aren't doing something silly on your tunnel which would cause large packets to be silently dropped. Moreover you'd better configure your servers with a low enough MSS that it will work even if the people you are communicating with are silently dropping too big errors. For a setup like the one I describe setting the MSS to 1200 should be safe. If your setup is going to involve any sort of DSR load balancing it is worth keeping in mind that the load balancing may need a tunnel as well. In that case make sure your DSR load balancer is configured such that the tunneling it is doing will be instead of the tunneling to connect your data centers - not another layer of tunnel on top of it. Conclusion The simplest solution is to just get enough IP addresses. But alternatives exist if you absolutely need them. 

Both Reverse Path Forwarding and Unicast Reverse path Forwarding do basically the same thing: Verify that the data is coming from the same direction you would expect it to come from. Their function is slightly different though: 

These addresses are nowhere in the internet routing tables, so if you would send a packet with a destination in these ranges on the backbone of the internet, they will simply get dropped. This is because millions of people use the same addresses. These addresses need to be translated to something useful for the internet. This is where Network Address Translation comes in: We have two computers: 

If you are talking to a machine on a different network, you only need to know the IP address. If you are communicating with a machine on your local network segment, you need to know the IP address and the MAC address. 

NB: For the reflection to happen, the RR does not have to be able to route to the destined networks. All calculations and validation of what goes into the routing table, will be done at each router individually. 

ISIS, just like OSPF, runs a Dijkstra Algorithm to find the shortest path. All information for this algorithm is contained in the TLV's. L2 Communication with neighbors is done in two ways: -When connected to a shared segment, use the Layer 2 protocol of that segment to communicate. This is done to be able to traverse switches that might not be able to speak the OSI layer 2 protocol CLNS. -When connected to a point to point network, communication on Layer 2 is CLNS. This doesn't mean that there is no L3 communication. ISIS routers still need a layer 3 address. Since we are talking OSI, and not IP, the address is slightly different. In this case, the address is called a Network Entity Title (NET), which is one address for the entire system (so not one per interface). The NET has many forms, but for most ISIS adjacencies, works as follows: . It doesn't really matter what you use as identifier, but say we have router 192.0.2.5 in area 52, we could make the NET 49.0052.1920.0000.2005.00 Since the addresses are in HEX you prefer 49.0052.0000.B00B.0000.00 (The addresses are hexadecimal). *) There are other levels in OSI routing, but those aren't significant for the current operation of ISIS A short illustration of routing 

As previous answers also points out the solutions are going to involve either having a private connection between the two data centers or having enough IP addresses to advertise a block from each data center. Those two options are however not mutually exclusive and there are a few more aspects to keep in mind when configuring this. How to advertise if you have enough addresses You'll likely end up deciding to get an IPv6 prefix which is short enough to advertise one half from each data center, which means a /47 or shorter. You then have a choice to make in how to announce this. 

One scenario that fits your description of "translate an address from a public IP address to another public IP address" happens every time I access StackExchange. Even though every computer on my network has public IP addresses I cannot access StackExchange directly because StackExchange only supports IPv4. So this answer is being sent through a NAT64 which translates public IPv6 addresses into public IPv4 addresses. Cases of translating between different public IP addresses within the same protocol also happens. I have come across a company which had a of IPv4 space and assigned addresses from that range to internal hosts. But they still used a NAT to translate the addresses such that externally traffic would be seen originate from an IPv4 address outside of that . I don't know why that company chose to use a NAT when they in fact had enough IPv4 addresses to not need it. I think every such deployment could work better without the NAT, but I can't say that with absolute certainty since I obviously don't have intimate knowledge of what happens behind every NAT in the world. 

The switches in this picture only need to know on what port to forward the packet to the next hop, but they don't alter the MAC address. 

R1 knows routes from R2 (Direct) and R5 (Direct) R2 knows routes of R1 (Direct), R3 (Direct), R4 (Reflected by R3) and R5 (Reflected by R1 and R3) R3 knows routes of R2 (Direct) and R4 (Direct) R4 knows routes of R3 (Direct) and R5 (Direct) R5 knows routes of R1 (Direct), R2 (Reflected by R1) and R4 (Direct) 

When a computer asks for a webpage, it wil first select a random unused portnumber from the random range (1024-65535). Let's pick . Then the following sequence will happen: Computer send it's packet with: source IP , source port , destination IP , destination port . The packets arrive at the webserver, it sees it's own IP and port , so it knows this is a request for a webpage. The webserver then sends the webpage back in packets with Source IP , Source port 80, destination IP , destination port . The computer recieves these packets, and knows wich requested webpage it was, because of the portnumber . These port combinations are often written as such: and . Now, the number of computers on the internet far outnumbers the number of IPv4 addresses available. To preserve address space, a set of private address ranges was introduced, that can be freely used for address sharing. These rangese are referred to as RFC1918 and are the following: