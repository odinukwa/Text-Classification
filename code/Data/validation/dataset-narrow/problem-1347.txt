...which seems to be a pretty standard method of unprojecting a point from a projection matrix, however this serves to introduce another point of possible instability. Still, I'd like to stick with the SlimDX Unproject routine rather than writing my own unless it's really necessary. 

Given a fixed rotation and a target "center" point, how to I find the position the camera should be in so that that point is the center? LookAt changes the rotation keeping the position constant. Basically, I'm trying to do the reverse, but the math escapes me :-). Thanks! Camera is currently psuedo-isometric (orthographic with rotation from Euler angles [X:35.264389683ish°, Y:45°, Z:0°]). Might want to change these a bit or allow rotation though, so ideally a solution would work for any rotation. Can easily get the projection matrix. EDIT: thinking about it, there would be infinite such positions that satisfy this constraint. I would want to fix the Y component of the position (camera height) and find only an X/Z. Thanks to Mokosha's answer below, here's the final code I'm using: 

I'm a tad confused about the turn based option with iOS5. Does this take care of everything needed to make a multiplayer turn based game?i.e all the game turn data is stored with apple or do I need to still provide a server for something? 

I'm a bit late to this question as I've only just started considering the same question myself. I've just launched a game on FB which we created a global leaderboard for, but it also has the option to display just the friends scores. The FB score and achievements API does look good, but I know for my own game (puzzle game) people absolutely want to see who is scoring well in the game across the network, and also what scores are possible. Also if you just make it friends only than unless each player has LOTS of friends who are all playing it, their leaderboard is going to look pretty empty, which I would argue discourages people from playing, for me the more scores people see being posted the bigger inventive for them to do well themselves. The ideal solution is a global leaderboard and a local one. 

I am currently working on a project that does 2D sprite-like graphics on Windows 8 (Metro-style app). For that purpose I am using Direct3D with quads to act as sprites. My problem is that it get's very slow (30fps at 100 sprites) and profiling led me to believe that the bottleneck is withing the CreateBuffer call. How can I solve that problem in an elegant way? Wouldn't gathering copying vertex data from all elements that share the same texture in a single, bigger, buffer be more cost-prohibitive, as it is all done on the CPU? 

If I'm calculating a "camera space" on the CPU, by multiplying the view with the projection matrix on the CPU , and afterwards multiplying the world to the result my vertices do not pass to the pixel shader (probably because they are thrown of the screen space). On the other hand if I'm multiplying the world with the view and the result with the projection, all on the GPU the result is right. What exactly happens on the GPU that doesn't happen when multiplying on the CPU? 

I'm trying to unproject the mouse position to get the position on the X-Z plane of a ray cast from the mouse. The camera is fully controllable by the user. Right now, the algorithm I'm using is... 

Lots of games have a generic "error material" and "error mesh" that is really obvious to see. Pair this with a warning in the logs, of course. 

The problem turned out to be one of numerical stability. I was able to solve the problem by ortho-normalizing the input rotation matrix before doing the operation. 

Any shader wizards out there have an idea of how to achieve an oily/polluted water effect, similar to this: 

Looks like you're on the right track. I did this before in a game, and instead of changing where on the texture the impact is centered, I merely rotated the sphere. I also used a procedural shader instead of a texture. Here's some of the code I used (public domain, do whatever you want with it). EDIT: Uploaded a video of it: $URL$ (NOTE: This code is for XNA 3.1, and has a couple calls to internal functions, so it won't work out of the box. It also does a lot of allocation, so will not perform well on the 360) 

I'm working on a 2D pixel art Unity game. I have multiple layers of scrolling so I need to use a perspective camera, the problem is though that it seems to mess up using particles as when the screen scrolls the particles move in perspective, when I need them to stay just in the x and y. Is there way to achieve this? I don't particularly want to go through every particle in real time and zero out their Z value, but maybe that's the only way? 

This might well be a very dumb question, but here goes anyway, I'm planning my turn-based ios game center game, obviously I know I'll need 2 iDevices to test it on, but how would I test the online turn-based play between the devices? As I'm to understand it, if the 2 devices are local (i'e close to each other) they automatically revert to a local communication method? is it possible to force them to communicate online so I can test that part of the project? 

I would expect a and b to be identical (or inverses of each other). However, it looks like q1 = (x, y, -z, -w) while q2 = (-x, -y, w, z). In other words, the Z and W components have been switched for some reason. Note: decomposes the transform matrix and returns just the rotation part of it (I've tried normalizing the result; it does nothing). The matrix is a complete transform matrix and contains a translation (and possibly a scale) as well as a rotation. I'm using D3DXMatrixDecompose to do the actual decomposition. 

The problem is that the projected position is "jumpy". As I make small adjustments to the mouse position, the projected point moves in strange ways. For example, if I move the mouse one pixel up, it will sometimes move the projected position down, but when I move it a second pixel, the project position will jump back to the mouse's location. The projected location is always close to where it should be, but it does not smoothly follow a moving mouse. The problem intensifies as I zoom the camera out. I'm not sure what's causing the problem, but I'm thinking it might be numerical instability? EDIT 1: Video showing the problem EDIT 2: A little snooping around in .NET Reflector on SlimDX.dll: 

I'm working on a 2D tile based game. I want NPC's to be able to destroy tiles, and ideally I would have a function, which takes a central x,y and then based upon a circular area from that point (radius) gives me all the tiles that fall within that circular area so I can destroy them. Any ideas as to how to do this? 

Im creating an iPhone game with Adobe AIR, and I want to be able to load a simple text msg into an dynamic text box on the games front screen from my server (and then be able to update that text file on the server, so it updates automatically in the game after the game is on the app store) How would I go about acheiving that? is it as simple as using a getURL? are there any specifical issues with trying to do this on the iPhone via AIR that I should be aware of? Thanks for any advice. 

I am trying to make a 2D isometric RPG and I kind of hit a wall when it comes to lighting. I was thinking of using shaders, if I manage to understand them.The problem I am anticipating is the presence of light sources outside the screen.In order to calculate shadows and so on I'd still need to have those objects rendered even if they're offscreen or else light would pop in and out if I move the view around the map. I was thinking of drawing the entire level, not just what is seen, but that would mean drawing at negative and outside the view coordinates.Does that work or I should seek a better, more efficient alternative? 

How can I draw a dashed curved line to a x,y point in as3? Basically I'm creating a game where you have a turret, and I want the arc the turret would fire a projectile along to be displayed as a dashed/dotted line along the arc to wherever the mouse x,y is. Ideally it would use the drawing API, rather than using any bitmap manipulation. 

What's the best way to create a neon glow line effect in Flash AS3? Say similar to what's going on in the game gravitron360 on the xbox 360? Would it be a good idea to create movieclips with plain lines drawn in them and then apply a glow filter to them? or perhaps just apply the glow filter to the entire movieclip layer the movieclips are on? or just draw them manually and create a glow effect by converting the lines to fills and then softening edges? (wouldn't blend as well but would be the fastest CPU wise?) Thanks for any help 

After tweaks and many, many matrix multiplications done by hand I figured it out. When passing data to shader DirectX implicitly transposes it, therefore: A*B on CPU sent to shader becomes (A*B)t (where t denotes transposed). (A*B)t according to formal math is Bt*At(observe the change in order of operation). In order to premultiply your matrices (View and Projection) in my case I had to apply transpose to their product, not each one. WRONG: At*Bt sent to GPU becomes (At*Bt)t=Btt*Att=B*A RIGHT: (A*B)t sent to GPU becomes (A*B)tt=A*B Check the wikipedia article on Transpose 

I'm not sure about OpenGL but DirectX allows you to over write the default left-handedness therefore it wouldn't matter. As you've said, it's "nothing but" a convention, and at least DirectX allows you to work with both. Conventions do not matter by themselves, the only problem is that you need to be consistent with your choice. Mixing two such systems leads to either confusion (if you do make the conversions) or to all sorts of errors if you do not (but why would anyone do that, except for mistakes). As to what Eric Haines refers to as "right-handed data" I bring this quote from the beginning "OK, so only for viewing you must also know the handedness of the data." and that's exactly where handedness matters, when viewing it. Does a Z-component of 1 make the object closest possible to the screen or furthest? That's why you need to know the handedness of the data, to interpret the data correctly when doing the depth test. 

I've searched for information on this, but cannot find it, is this not something you can do yet with Kobold2D/Cocos2D? or are there options I've missed? 

I'm working on a game where players can setup villages, which can contain defending units. Any of these units (each on their own tiles) can be set to "campaign" which means they are no longer defending but can now be used to attack other villages. And each unit on a tile can have up to a 100 health. So far so good. Oh and it's all asynchronous so even though the server will be aware that your village is being attacked, you won't be until the attack is over. The issue I'm struggling with, is the following situation. Let's say a unit on a tile is being attacked by a player from another village. The other player see's your village and is attacking your units. You don't know this is happening though, so you set your unit to campaign and off you go to attack another village, with the unit which itself is actually being attacked by this other player. The other player stops attacking your village and leaves your unit with say a health of 1, which is then saved to the server. You however have this same unit are attacking another village with it, but now you discover that even though it started off with a 100 health, now mysteriously it only has 1... Solutions? Ideas? Edit The simplest solutions are often the best. I referred to Clash of clans below, well after a bit more digging it seems that in CoC you can only attack players that are offline! ha, that almost solves the problem. I say almost because there's still the situation where a players village could be in the process of being attacked when they come back online, still need to address that. Edit 2 A solution to the "What happens when a player is attacking your village and you come online" issue, could be the attacking player just get's kicked out of the village at that point and just get's whatever they had won up to that point, it's a bit of a fudge but it might work.