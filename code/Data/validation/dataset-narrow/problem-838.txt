is the most reliable way to get a user's IP address when your app is behind a reverse proxy/load balancer. However I don't know what you mean by "trust"? is an HTTP header that can be easily modified by the client or any system between you and the client. You don't want to use it for anything like authentication. 

Yes, if you have reserved instances purchased in , for example, then you explicitly want to specify at launch. RI's are purely a backend billing thing that function like an invoice credit. The EC2 instances themselves have no awareness of whether they're an RI or not. The way RI's are handled is actually one of my top five complaints about AWS. I'm hoping that they improve on this soon. 

Have you tried rebooting your router? The fact that some of the servers behind your NAT gateway work, but others do not leave me to believe that the problem is on your end, not Amazon's. If it's a consumer grade device, try updating the firmware. What brand/model is it? 

I used yum to update from kernel 2.6.32-220 to 2.6.32-200.23.1 on my CentOS 6 x64 system. I now receive the following message on the console at boot: 

Your stated requirements are extremely vague so expect to get only extremely vague replies. Having said that, look into Amazon EC2 and CloudFront Streaming. 

I'm using CentOS 5.5 x64 on both the dom0 and domU. I am attempting to pass-through a 3-port NIC (Realtek Semiconductor Co., Ltd. RTL-8110SC/8169SC Gigabit Ethernet (rev 10)) to the domU using pciback. However, when the first port on the NIC is brought online, it causes the domU to crash. Any suggestions? (eth0 is the on-board NIC, which works fine). Edit: By the way, adding 'swiotlb=force' to the domU kernel line (as recommended in the dump) causes the domU to fail with the same error, only it happens immediately upon launching the vm. 

Given your requirements, I would agree that using a VPC is the most optimal solution. Since it sounds like you've done your research, you know that a VPC allows much finer-grained control over subnet and host addressing. To answer your question, that is the "best practices" approach. What I would do is create two private subnets, one in each AZ, and place an Elastic Network Interface with a static, private IP address in each subnet. Then you can attach/detach the ENI to the appropriate instance at will. This allows some cool stuff and functions like hot-swapping a NIC between servers while traffic is still flowing through it. Yes, there is a significant learning curve with setting up a VPC, but the tradeoff is greatly increased security and flexibility when using multiple EC2 instances that need to talk to each other. It's worth noting that utilizing the AWS API (as you also mentioned) is also a viable solution for your immediate needs. But the further you go down this path of writing a custom solution, the more time consuming it becomes to maintain as your needs grow. 

EDIT 2: Thanks to @Christopher Karel for referencing a DMARC report parsing tool at dmarcian.com. The lions share of entries are listed as forwarders (which makes sense). There is one server (*.mailhop.org) listed as "preserv[ing] DKIM" - I've sucessfully sent mail over one of the Ruby language forums which has worked, and I know from my research they use mailhop.org. Under the category "Servers that break DKIM signatures (or create spoofed signatures)" are listed , , (dunno why this appears here, maybe another list I'm on uses them as well in a different configuration), among others and the lists I've been most active on are Arch and a few hosted by Google Groups so this makes sense. About 400 messages in total - I haven't sent nearly that many messages, so I guess maybe it's counting retries. I'm getting depressed - at the moment it seems like my choices are: 

I've got 6 physical drives in RAID-Z2, which I intend to one-by-one convert to dm-crypt devices. My process was roughly: 

Turns out there doesn't seem to be anything wrong with my configuration. What's happening is that my messages are being processed by mailman correctly, and being relayed out to the list. There are a couple of receivers however which (for whatever reason is unique to them) reject the message. Because I have actually correctly configured SPF, I'm seeing the rejection message from those destination SMTP servers, not from the Mailing List relay itself. Some awesome folks in the Arch community helped me chase this one down, as they had access to said ML server. 

I'm having trouble connecting to my remote host via SSH. I have narrowed the issue down to my local host only as other clients make nominal (fast and stable) connections every time. Attempting to connect to from via SSH will time out all but about 1 out of 10 attempts (it hangs here and then times out): 

UPDATE 1: Worth noting that I've been able to duplicate this behavior on a second SSH host, as well as an IRC server, thus proving (in my mind) that this is an issue wholly within some config on my local host. 

This solution still doesn't allow different processes to bind to the same port. And I'm not even sure that I'm on the right track here by looking for an iptables solution. Any suggestions? Is there maybe a hack that be applied in userland? Thanks! 

I get a similar story in the Dom0's log. But as you can see, it completely disables the NIC's IRQ and shuts down the interface. 

This is not possible with Elastic Beanstalk (at least not without really misusing it). Elastic Beanstalk is "fire and forget" type of PaaS solution aimed at simple deployments. If you really need this type of functionality, look into CloudFormation which lets you get much more granular with your instance configurations. 

You need to set up either a POP3 or (preferably) an IMAP server. Then create your email boxes there as normal. Use the appropriate PHP functions to simulate a mail client and periodically poll the email boxes for new messages. 

Cisco and SonicWall VPN's are both IPSec-based (as are most VPNs used in the corporate world). You can interconnect them if you set up a site-to-site VPN. We do this all of the time with our clients to avoid the same problem you're encountering. Our firewall is just a Linux box running iptables and a IPSec daemon called "Raccoon". You just have to make sure that the dozen or so different settings all match. 

First off, you have two conflicting requirements: you don't want a do-it-yourself approach, but you want it cheap. You need to figure out which of those two is more important. What's this server needed for? If it's feasible to host it off-site, you could look at leasing a box at a datacenter (Rackspace, Cari, etc.) You could even get a fully managed server so you only have to worry about the application itself. Of course this extra service is more costly. For the super-cheap start-up route, you could even use Amazon EC2. However, EC2 is going to be more expensive in the long run and you're going to get yoru hands dirty managing it. If it's not feasible to host it offsite (it's also functioning as a file server for the office, etc) then yes, buying a server from Dell (or similar) would be your best bet. The cheapest that you'll likely be able to find a server for sale is from your local off-lease reseller, Craigslist, or Ebay. You can find really nice, recently decommissioned servers for awesome prices. Be aware though that they don't normally come with support though, so once again you'll be on the hook for that. Edit: If you're purchasing used gear, be sure that everything is in order with the OS licensing. If the OS came with the hardware (OEM version), you should be ok. However, larger corporations will sometimes purchase the OS separately from the hardware (MS Open Licensing). That type of license would not be transferable to you when you purchase the box. 

Looks to me like this is a DKIM signature failure, but I have no idea why. Is the receiving server trying to verify my DKIM signature against the mailing-list-server's key, or vice versa? For some reason, I wouldn't expect this to happen - I remember reading somewhere that in cases like this Relays and such will sometimes remove/munge headers like this to ensure these types of failures don't occur? 

Which exits cleanly, and brings the device back into the pool. Perhaps this is due to the load order of different modules during boot? Maybe the activation of dm-crypt devices is done such that ZFS begins importing pools before the LUKS container is properly open? 

UPDATE 2: Also worth noting that while my localhost has trouble with these outbound connections, other clients (including on one, and one off, my LAN) have no issues whatsoever to any of the same remote hosts, or any other hosts. Again, leading me to believe that this is solely some config issue within localhost (but maybe I'm wrong?). 

Once the resilvering was finished (which worked fine), I rebooted the machine to verify the setup before continuing to other disks. What I found, however, was that ZFS labeled as UNAVAIL. verified that dm-crypt activated the LUKS container correctly. Running causes ZFS to begin resilvering but then completes and resumes healthy operation in a manner of seconds. I'm guessing the dm-crypt device is simply not loaded when ZFS first tries to accesses ? Is it a question of load-order or do I need to be using a different identifier for the LUKS device in ? How do I ensure that ZFS sees these LUKS devices on reboot? This is a box (Arch) if that matters. Thanks! 

This is a recent problem, but unfortunately I don't recall making changes to anything relevant. I'm not sure what to check. Maybe it's worth noting that this affects all SSH connections (such as git over ssh and ) and not just the command line SSH tool. I don't have any trouble accessing over any other protocol (e.g. , , BitTorrent, etc). The only active/uncommented line in is: 

Not unless a) both your providers support BGP and b) they'd be willing to advertise your routes and c) you have your own ASN. Otherwise DNS is your only option. It's not a horrible choice though if you set your TTL really low and using one of the smarter DNS provider that can redirect traffic based on non-responsive ping. CloudFlare is also an option if your site is primarily static information that can be cached and served to users in the event of an outage. Really though, if you truly need this level of HA, you should be hosting in a datacenter. 

I have successfully set up OpenVPN connection between my firewall at home and my EC2 instances. It works quite well, but I'm using Linux at both endpoints, so my experience won't directly translate to your config. As much as I hate IPSec VPNs, you might find that an easier route to try. Have you looked into Amazon's new "Virtual Private Cloud" service yet? This sounds ideal for your needs. 

This is expected behavior of EC2. If you want more granular control over your IP addressing, you're going to have to create instances inside of a VPC. 

Find a service that includes Plesk with their VPS package. Plesk is a web-based server management GUI. If you're even a semi-competent sysadmin, you'll be able to easily manage the everyday tasks using it. But if you're serious about broadening your skillset, I would recommend that you find an old computer in a storage closet at work and install Linux on it (the same distro as your VPS). Use it as your in-house development/testing server and learn how to admin it via SSH. 

With a NAT connection, the host computer (your primary, physical machine) is acting like a router/firewall. The VM piggybacks off the network interface of the host and all packets to/from the VM are routed through it. Since the host computer actually sees IP packets and TCP datagrams, it can filter or otherwise affect the traffic. When the VM is using bridged mode, it's connecting to the network via the host at a lower level (Layer 2 of the OSI model). The host machine still sees the traffic, but only at the Ethernet frame level. So it's unable see where traffic is coming from/going to or what kind of data is contained in that traffic. 

Keep SPF, DKIM, DMARC, and ADSP and give up using mailing lists, or Drop this DNS security/reporting layer and have my normal outgoing mail rejected by Google, Yahoo!, Live, etc. 

But this isn't working; my conditionals are rendering nothing (empty strings). Even if a small refactoring would get the job done, this smells to me. Is there a more idiomatic way to alternate small details like this with Salt without so much templating boilerplate? 

EDIT 3: My proposal from edit #2 above did not work. I had to wipe the drive and re- the device because ZFS would not allow me to replace the device with itself. After resilvering was complete I rebooted and is and device is . It's worth noting that does appear in as well as , so it is being loaded correctly. I can verify this by running: 

From what I know, if it's in it is - by definition? - not subject to change (even across reboots). I will replace the definition of the dm-crypt-name in my zpool with the id-name and report back. Same drive, same LUKS container, just a different way of addressing it. 

Where else can I look? What other debug tools can I use (all I can think to do is run )? I tried running on remotehost while attempting a connection, but couldn't figure out how to filter the packets from the shell running thus infinite-loop spamming myself out of any useful diagnostics. 

I've got an IP that isn't on any blacklists, a PTR correctly configured, DKIM signatures validate perfectly, I thought everything was set up correctly. But now I can't contribute to mailing lists. When I send to the list address, sometimes the message goes into a black hole, sometimes I get an email to my address, and in other cases I see entries I believe are related in reports sent to . My theory is that the SPF policy is too restrictive. The mailman (or other) list server is acting as an SMTP relay for my messages, right? So I changed