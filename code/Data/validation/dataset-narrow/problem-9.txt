git is configured to use schannel (windows native implementation), but schannel use windows certs bundle and not a the cainfo bundle. To switch to openssl to use a custom bundle file use this: 

I disagree with your definition, kubernetes, openshift and other are scheduler and as such should go in the SDDC part. IaC things are Vagrant/Terraform/Cloudformation/Vmware Cloud management. They are about writing code to define the infrastructure. With this in mind k8s may fit both, a is IaC to drive the k8s SDDC. Let take exemple for a k8s cluster running on top of vSphere infrastructure: You have a scheduler k8s on top of another scheduler vSphere. SDDC on top of another SDDC. K8s is concerned by its node load (which are vSphere VM), vSphere is concerned by its nodes load (ESXi hosts). With this in mind k8s will move pods (containers) around its nodes, where vSphere will move k8s nodes around its hosts. This indeed could lead to a spike or freeze of k8s nodes when both wish to move their loads at the same time. The solution is just an architecture solution: disable vSphere DRS on your k8s nodes so there won't be a move of your k8s nodes around while they are already moving containers. Each time you overlay systems with the same behavior, you have to plan their definition properly to avoid race conditions. Worst case would be running a docker swarm cluster on top of kubernetes on top of mesos on top of vSphere infrastructure on top of Nutanix partitions. (Absolutely doable but I don't think anyone would do that out of demonstration purposes) So yes, this setup makes sense, it mainly require a careful design of all layers to achieve the best performances. 

Of course this answer is just an overview on how it can tackle your problem and is far from exhaustive about it. 

Or if you just want an alert if the difference between averages is over 1 second (assuming values are in milliseconds) you can use this IF condition: 

Well, you won't be able to apply an Agile methodology to a large team. One of usual principle is to work on Pizza Team (Less than 10 persons which can share a large pizza for diner together) because the lack of formalism advocated by Agile process makes it hardly applicable to a large team, the information would be scattered and some would be lost in the crowd. So before thinking about the CI system, you'll have to review the organization around the software you build. This mainly need to refactor a large project in smaller independent pieces, this could be separate softwares (and you'll take the path of microservices) or it could just be an architecture design within the software, where a class/object/library is given to a small team. This team has to document its service input and output (service contract/service orientation). Once this is done you can split the responsibility of each independent piece to a smaller team which will be able to apply an Agile process. This may solve the CI/CD problem, splitting the code base would allow each team to follow it's own pace, as long as it's interface is properly versioned and that the input/output are fixed for a type of call you can make parts of the product evolve while some other part keep a previous behavior. The main drawback is that the service contracts from each part must be compatible between versions in use, which need a dependency system to know which part use which version of what before dropping an unused version of an API. This brings problems to make breaking changes and usually need a careful transverse planning between producer and consumers. 

A third parameter can be used to access another account (I do prefer to switch role to another account before). Stripped down version of the script with awk script as a oneliner: 

On the second form, A is available to the shell when the line is parsed, and as such the resulting 's stdin is 

Your problem is that grub file change adhere to and not debconf, as per this incident on apt list you're not alone. As workaround I found this answer on askunbuntu. Removing the from the UCF configuration system should be enough, for your case: 

After a long fight, Frodo the Chaos Monkey has been able to melt your One Server and bring freedom to all applications, driving you to the way of reproducible Servers at the same time. Credits: 

I think you're taking the problem on the wrong side, you may start a whole new infrastructure aside and then switch loadbalancers from blue to green, loosing sessions, breaking ongoing transactions etc. The proper way to achieve what you're doing is coding differently, when A relasease a breaking API ni version n, a should be able to continue to answer call to api in version n-1. the usual method is to have the version in the uri or an header, for exemple: and (for exemple if n is 2). With that, you can do a rolling update of B, with backends still using api v1 and new ones using api v2. 

From your list of tools: Jenkins and Github have apt/yum repositories you can use to install and upgrade. For Atlassian products, best up to date information about repositories I can found is This ShipIt experiment and it seems unlikely to change from this forum post The workaround may be parsing the mailing list to update the deploy. Now if you really want something automated to handle the installation and configuration of your tools, you can try a Configuration Management System like Chef/Puppet/Ansible/Salt. For Chef I know better, there's cookbooks for Jira and Confluence maintained. For the rest you'll be on your own writing the bits to deploy and configure. This means having 4 CI/CD systems (at least), two 'groups' validating each other, as a pipeline won't be able to validate and upgrade itself properly (inception). That sounds overkill in my opinion. At the end of the day, there's no silver bullet for all and every software you may use, each will have its own particularity and way to be installed and you'll have to workaround those bits. 

So in your case for a port number (I assume unpriviledged) I would go for a variable with something like: 

Your impression is false, linux containers (LXC) exists since 2008, mesos and docker have started later. All three makes use of cgroups available since kernel 2.6.28. For your overall question, mesosphere have a blog post about it. But mainly you're looking at it from the wrong point of view, choosing the underlying orchestration system should not be done from 'how to deploy this application?' point of view, but more on 'What would be the best orchestration for what I have to deploy as a whole ?'. Making the choice between swarm/kubernetes/mesos/k8s on mesos/swarm on mesos/whatever is very dependent on your environment, your existing knowledge, your team skills etc. and we can"'t really help you choose without an extended description on what you're willing to manage. 

Using an instead, they are not parsed IIRC and should prevent the conversion. As you already said, use a wrapper script around your launcher to define the value instead before launching the app, something along the line of this should do: