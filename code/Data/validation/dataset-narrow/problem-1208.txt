Lets define the class $ZBQP = \{ L \mid \exists \textit{P-uniform circuit family } \{C_i\}, \forall n \in \mathbb{N}, |x| = n, |\langle 0|C_n|x \rangle - I(x \in L)| \leq 9/10 \Longleftrightarrow x \in L\}.$ We note a construction of Ashley Montanaro, that for any quantum circuit $C$ there exists some multilinear polynomial of size linearly proportional to $C$, $f_C$, such that $\langle 0 | C|0\rangle = \frac{gap(f_C)}{2^n}$ where $n$ is the number of variables in the polynomial and $gap(f) = |f^{-1}(0)| - |f^{-1}(1)|.$ We now define CAPP, the Circuit Approximate Probability Problem, which is a function problem: $C \mapsto v \textit{ where } |v - Pr_x(C(x) = 1)| \leq 1/10.$ Using this problem, we can get a $2/10$ error approximation for $gap(f)$, as $gap(f) = 2^n (Pr(f(x) = 0) - Pr(f(x) = 1))$ and thus we can get an approximation for $\langle 0|C_n|0 \rangle$ (or for $\langle y| C_n |x \rangle$ by modifying the circuit and thus $f_C$ in the obvious way). As we have a two sided error for $ZBQP$ and this approximation gets us close enough to distinguish which side we're on, it seems that this allows us to solve $ZBQP$ problems in basically whatever function classes where we can do $CAPP$, which is suspected to be in $FP$ and is already in $FBPP$. Does $ZBQP \neq BQP$ for any reason I'm missing? It seems like they may be equal, but I dunno. 

We have some quantum circuit $C$ with $k$ ancillae and $n$ input bits of depth $d$ and size $s$, and we can define a function $f$ which, for any $x \in \{0, 1\}^n$, is the random variable which is the first bit of output from $C|x, 0^k\rangle$, i.e. $Pr(f(x) = 1) = |(C|x, 0^k\rangle)_0|^2$. We define the sensitivity of this function at $x$ as $s(f, x) = \sum_{y : ham(x, y) = 1} |Pr(f(x) = 1) - Pr(f(y) = 1)|$ and the average sensitivity $S(f) = \mathbb{E_x[s(f, x)]}$. We know by an extension of Boppana's 97 paper on the average sensitivity of circuits to probabilistic classical circuits (those which we can compare these to), that these have average sensitivity $O(log(s))^{d-1}$. I think exploring the average sensitivity of these quantum circuits would be a nice way to resolve some of the open problems stated here. My intuition is that the average sensitivity will be higher than in the classical case, but still lower than the maximal average sensitivity which one gets for parity, showing that $QAC_{wf}^k \neq QAC^k$. I'd be quite satisfied with approaches to use or just interesting discussions of this as answers, as I don't expect for someone to actually resolve this here. 

We say that a Boolean function $f : \{0, 1\}^n \rightarrow \{0, 1\}$ is helpful for another Boolean function $g$ if $f(x)$ can be computed with a smaller circuit given $g(x)$ as an extra input bit. I'm curious about questions like "What is the probability that $f$ is helpful for $g$ given that $g$ is helpful for $f$, where $f, g$ are distributed uniformly randomly?" Another way to phrase this question is "Is the helpful relation mostly directed?" Just to get the intuition across, one simple example of this is parity, where if you're computing the parity of the bits indexed by elements of some set $S$, $\chi_S$, then $\chi_T$ will only be helpful when the set of extra indices you have to compute parity on to correct this to $\chi_S$ is less than $|S|$. Specifically, we have to compute parity on $S - T$, $T - S$, then add these to $\chi_T(x)$, so if $|S \triangle T| < |S|$, $\chi_T$ is helpful for $\chi_S$. I'm sure this has been looked at before, so I'm mostly looking for references here. One can define a similar, stronger notion, where you define $Inner(f)$ to be the set of functions computed by an internal node to a size-optimal circuit for $f$. For parity it seems that most of the internal functions are parity functions on less inputs. What other functions, which are not some easily recoverable distortion of parity on a subset of the bits, are helpful for parity? 

Define $SIZE$-$DEPTH(s, d)$ to be the functions which are computed by circuit families of size $O(s(n))$ and less than depth $d(n)$. We know from Boppana's 1997 paper on the average sensitivity of low depth circuits that if we have functions $s, d, s', d' : \mathbb{N} \rightarrow \mathbb{N}$, where $log(s(n))^{d(n)-1} = o(n)$, $log(s'(n))^{d'(n) - 1} = o(log(s(n))^{d(n) - 1}$, we know that $SIZE$-$DEPTH(s, d) \neq SIZE$-$DEPTH(s', d')$. This is true because in $SIZE$-$DEPTH(s, d)$ we can compute $PARITY$ on a larger number of bits than in its $s', d'$ defined counterpart. This separates a large number of low complexity classes, most interesting to me being $qAC^0 \neq FOLL$. On the other hand, when $log(s(n))^{d(n) - 1} = \Theta(log(s'(n))^{d'(n) - 1})$, I don't know of a method to separate them. Obviously there are the degenerate cases where $s(n) = \Theta(s'(n)), d = \Theta(d')$, but I tried to compute the limit and get some constraints on $s, d, s', d'$ but it is seriously gnarly and it doesn't seem to give me anything good. If $d$ is constant you can do something but it doesn't give me much intuition. Can anybody come up with interesting examples, perhaps illustrating the size-depth tradeoffs that you'd imagine would be present, of $s, d, s', d'$ for which the respective classes cannot be separated by Boppana? If so, can you show a separation between these two classes in another way? Is there some reason I'm missing that all such cases are degenerate? 

Say I generalize the language which consists of pairs of isomorphic graphs to take the following form: $GI(f) = \{ (G, H) \mid \exists \psi : V_G \rightarrow V_H, Pr_{a, b \in V_G} ((a, b) \in E_G \Longleftrightarrow (\psi(a), \psi(b)) \in E_H) \geq f\}$ Is there any work on this language? The obvious question is whether there exists $f$ such that $GI(f) \in P$. The funny counterpart to this language is $IG(f) = \{ (G, H) \mid \forall \psi : V_G \rightarrow V_H, Pr_{a, b \in V_g}((a, b) \in E_G \Longleftrightarrow (\psi(a), \psi(b)) \in E_H) \leq f \}$ Just wanted to hear the thoughts of anyone who wanted to have a go at constructing algorithms for different constant values of $f$ or perhaps for $f$ as a function of the size of the vertex sets or something. 

Let $f \in \mathbb{Z}_2[x_1, ..., x_n]$ be arbitrary. We define $gap(f) = |f^{-1}(0)| - |f^{-1}(1)|$. I want to understand, as a function of any properties of $f$ you find relevant (number of terms, sparsity of variable occurrence, etc.), upper bounds on the the quantity $\mathbb{E}_{i \in [n]} |gap(f) - gap(f + x_i)|.$ Doing a little bit of manipulation, I can do at least something, but it isn't as strong as I'd like. We define $X^{(i)}_{a, b} = \{ x \mid f(x) = a \wedge x_i = b \}.$ Note then that $f^{-1}(a) = X^{(i)}_{a, 0} \oplus X^{(i)}_{a, 1} $ $(f + x_i)^{-1}(0) = X^{(i)}_{0, 0} \oplus X^{(i)}_{1, 1}$ $(f + x_i)^{-1}(1) = X^{(i)}_{1, 0} \oplus X^{(i)}_{0, 1}$ and thus that $gap(f) - gap(f + x_i) = |X^{(i)}_{0, 0}| + |X^{(i)}_{0, 1}| - |X^{(i)}_{1, 0}| - |X^{(i)}_{1, 1}| -|X^{(i)}_{0, 0}| - |X^{(i)}_{1, 1}| +|X^{(i)}_{1, 0}| + |X^{(i)}_{0, 1}| = 2|X^{(i)}_{0, 1}| - 2|X^{(i)}_{1, 1}|$ which is two times the gap of $f$ restricted to inputs where $x_i = 1$. Rewriting this further in terms of the number of zeroes of this restricted $f$, one can use Schwartz-Zippel to get a bound, but it is hardly informative. This problem is a toy version of something which would yield interesting results in quantum circuits: it is a step towards computing the average sensitivity of quantum circuits. As such, if one can find an infinite family of polynomials which bounds this quantity above, say, $\sqrt{s}$, where $s$ is the number of terms in the polynomial, this would be a very interesting result in this respect. For more information on how this relates to quantum circuits, see this paper. 

I'm curious about ways in which you have seen non-uniformity be useful in computation. One way is randomness, as in $BPP \subseteq P/poly$, and another is look-up tables which are used to show that all languages have non-uniform circuits. In particular, I'm interested in ways that objects known to exist via the probabilistic method and other non-constructive (or not-constructive-enough) proof methods can be leveraged using non-uniformity. I'd prefer the examples to be natural, not contrived. To be clear, a circuit for a contrived problem could be something like: given some language $L \in P$, I create a polynomial size circuit by computing some really hard function $f(|x|)$ using my advice and asking whether $f(|x|)^{n/|f(|x|)|} \oplus x \in L$. 

I want to be very specific. Does anyone know of a disproof or a proof of the following proposition: $\exists p \in \mathbb{Z}[x], n, k, C \in \mathbb{N},$ $\forall G, H \in STRUC[\Sigma_{graph}] (min(|G|, |H|) = n, G \not\simeq H),$ $\exists \varphi \in \mathcal{L}(\Sigma_{graph}),$ $|\varphi| \leq p(n) \wedge qd(\varphi) \leq Clog(n)^k \wedge G \vDash \varphi \wedge H \nvDash \varphi.$ Intuitively, this should be true if all non-isomorphic graphs can be distinguished using "$Clog(n)^k$ local" statements, and I'd imagine that this is false. Of course any graph can be distinguished using polynomial quantifier depth, as you can simply specify your graph modulo isomorphism: $\varphi = \exists x_1 \exists x_2 \exists x_3 ... \exists x_n (\forall x (\bigvee_{i \in V_G} x = x_i) \wedge (\bigwedge_{(i, j) \in E_G} E(x_i, x_j))) \wedge (\bigwedge_{(i, j) \notin E_G} \neg E(x_i, x_j))) \wedge (\bigwedge_{(i, j) \in V_G^2 \mid i \neq j}x_i \neq x_j).$ Edit: So it seems that the locality intuition I had is false. A formula of quantifier depth $k$ has Gaifman locality bounded by $O(3^k)$, which means that a log depth formula is basically global. For this reason, I have a hunch the proposition will turn out to be true, which would be much harder to prove in my opinion.