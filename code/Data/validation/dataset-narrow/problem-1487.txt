It's almost impossible to convey a sense of wonder when they don't appreciate what they have. My personal favorite approach is to point out that the Apollo Guidance Computer (AGC), which sent us to the moon, was a 2Mhz processor with 2k of RAM. The original Game Boy had a 4MHz processor and 8k of RAM. The old game boy was more powerful than the AGC! Well, almost. The AGC did have triple redundancy on all circuits, so you would have to duct tape 3 Game Boys together if you really wanted to compete with it! And, of course, a modern cellphone chuggs along at 1800Mhz! I find it helps to first appreciate just how blindingly powerful and fast computers actually are. Then we can talk about where they came from. One of the calculations I did a while back was comparing the speed of a cache hit versus going out to memory to get the information. It turns out, due to serendipity, that the difference in speed between a L1 cache hit and a round trip to memory is actually the same speed difference as that of a Cheetah at full sprint vs. the top speed of a snail. No joke! Of course, that doesn't help if you don't have a sense of how fast either of those are, so let's compare them both to something we can appreciate: how long it takes to load a web page. There's a latency associated with going across the world over fiber optics. It turns out that your round trip ping time from America to Europe (the absolute bare minimum portion of loading a web page) can be put on this scale between cheetahs and snails. This web page access proceeds at the speed of the San Andreas fault slowly opening in California! Yes. On this scale of speeds, California actually starts sinking into the ocean! 

Another element to add to the solution is to slightly delay the HTML tags. You can start with a WYSIWYG web page tool. In that they create the web page that meets your listed objectives. Then you can switch from the visual results into the raw HTML. Using the generated HTML you can demonstrate simple changes to the code that are then visible in the rendered page. Add in simple CSS next, and they can witness the explosion of possibilities. If you can do that yourself on a large-screen, or projector, in a short demonstration first, then have them do it themselves, while making it all fit into one class session, that would be good. An additional tool would be a server for the room that each has a directory on that they can "publish" their page, and you can display it on the projector. Any simple server would work, even IIS on Windows XP could handle the task. That provides them with the chance to have their work on display as well, giving a nice ego boost, and likely increasing their investment in learning more to make it better. 

Neither is always better, and both have their strengths. The idea of scoring higher marks as a criteria for better is going to be unpredictable without knowing who is granting those marks. Someone who is heavily in favor of one style over the other may grant higher marks to low quality uses of their favored style than they would to high quality answers in the other style. The idea of being faster is both personal and situational. If someone is more comfortable using one over the other, they will usually be faster with that style, whichever it is. Some projects seem to do better in one style than they do in the other, even when the person doing the project is proficient in both styles. This is related to the strengths and weakness of each style. Pseudo code is more free-form, and allows one to concentrate on how to solve the problem or design the algorithm without having to choose the proper symbol to draw, or how to leave room for other branches on the chart. Pseudo code is also closer to the programming statements that will be used, eventually, to implement the algorithms, and can speed up the coding process. Being free-form makes it harder to spot missed checks on conditionals. It is also harder to see the overall pattern of a larger algorithm in pseudo code. Flowcharts diagram the algorithm in a visual manner that makes the entire algorithm visible. When the logic gets complex, this visual representation enhances the ability to trace all branches and confirm that every conditional has been fully handled. It can also show cases where things are getting to complex, and need to be re-factored. The downside to this visual representation is that the creator frequently needs to interrupt their work on the algorithm to make adjustments to the chart, or to redraw sections that no longer fit on the page/screen they are using. These points are even greater detractors when the flowcharts are created on paper rather than in a program designed for flowcharts. The apparent speed gains from pseudo code's closeness to the final language can be offset by the error checking, and corrections needed, but not spotting logic error in the planning, which is one of the strengths of a flowchart. In addition, the larger picture view provided by the flowchart that can lead to re-factoring, can lead to more compact and efficient code, which is a gain every time the program is executed, even if it took longer to code the first time. Ideally the students should be taught each method, using exercises that are both a good fit and a bad fit for that method. After leaning the two methods they should have exercises that help them learn how to select the proper one for a given situation. While it may not be appropriate for the classroom, often a programmer on a larger project will use both methods: the flowchart to see the whole picture, and plan the program's overall flow, and pseudo code for many of sections seem to be compact or straight forward. Bottom line is that the best one to choose is the one that gets the job done right the first time. A fast solution, which then needs lots of corrections is not so fast after all, and a pretty picture of the program can still have logic errors if the programmer is not looking at the real problem the correct way. 

I find the "box" aspect is far more important than the named aspect. Maybe it's personal bias. However, we can combine the two: it's a named box. So you can say "Go look in the 'object color' box." If you're working with pure data (no objects), it may be effective to set up a white board, and mask off a few "boxes." Each box gets a name like "number of chores done today." Concepts like "Add 1 to the number of chores done today" start to become really meaningful that way! And it just so happens that the word for these spaces on the whiteboard is "box," which is similar to the 3d boxes you might put objects in. Even better, it puts her in an excellent position to deal with the nuanced behavior of reference mechanics when she gets there. If you're used to thinking of variables as spaces on a whiteboard, writing references to objects, like referencing the members of your family by name, is easier. For many people, the jump to reference mechanics is a real struggle because they got used to the idea of "x is my bear, that's in a box on the shelf" rather than "x is a variable referencing my bear. Y also references the same bear." (I personally have struggled to help people with reference mechanics because it forces them to unlearn whatever models they used up to that point, and unlearning is hard) You can even use different color markers for references and data. That starts to get them used to the idea that there is some fundamental difference between the word "dad" and a reference to Golo Roden. 

In the question cover the facts that, first, the comments state, , and second, some future coder using the class might not read the comments. State that you want them to make the needed changes "at the design level" which would force the future coder to only have one object of that class. "The best method will cause a compile-time error if the rule is violated." An alternative statement could be to rewrite the code such that "it is impossible for two objects of the class to be instantiated by the program." 

Source: Executive Office of the President, Office of Science and Technology Policy, Fact Sheet, Oct. 14, 1999 After review, and an appropriate comment period, it was finally edited to read: 

Emphasis mine Discussion The question places collaboration and plagiarism as possible coexistent concepts. They are not, as recognized in a comment by mickeyf. If two (or more) students are collaborating (working together) on a project, neither can plagiarize the other's work. "There is no I in team". [The excerpt also mentions using online resources and relying heavily on peer code, both of which could be plagiarism if not acknowledged.] It is possible that the habit of doing very little work in collaboration with others could lead to plagiarism, making the student at-risk of plagiarizing, as the excerpt noted. It is possible, in very rigid, or high-stakes, environments, to be morally obligated to cite sources of inspiration, such as from casual interactions with others, to acknowledge their input. The U.S. Department of Health & Human Services, The Office of Research Integrity, in their section on plagiarism, Acknowledging the Source of Our Ideas, covers some research published by Alan Gilchrist in a 1979 Scientific American article where Mr. Gilchrist purportedly felt obligated to credit a source outside of the normal research he conducted. Holding students to that standard in the classroom would require them to credit the instructor, the textbook, and likely half of their classmates, in every program they wrote. It would be interesting to see a class project with a comments section listing sources that was longer than the code itself. The objective of the classroom experience ought to be learning, the instilling of knowledge, habits, and patterns of thought, into the minds of the students. When collaboration is part of that process, there is no need to be looking for the evils of plagiarism where it cannot exist. When, however, the excessive collaboration, or other impediments, interfere with the process, then they need to be addressed. That, however, is unlikely to be the result of any bright-line test or standard. Rather, it is likely to come from the instructor's observation of patterns of behavior, and work, exhibited by the students affected. 

I'm not a teacher, but my experience is that OO (and other related encapsulation techniques) teach you to write what you want the computer to do, while procedural coding teaches you to write how you want the computer to do it. OO is a powerful way to ignore the how until you need it. As a result, anyone learning in an objects-early approach is going to struggle unless there's some benefit to learning to think this way. If your course starts with several helpful libraries (like perhaps a sprite-manipulation library), it could benefit from object-early (or any form of early encapsulation). Personally, the challenge I've had with object-late is the side effect of telling the computer how to do tasks: you get used to the idea of telling the computer exactly what to do. The mental models which are built around telling the computer exactly what to do are tricky unless you're willing to take the time to push all the way down to the transistor level. At some point you have to admit that you're just telling the computer what to do and you trust that it knows how to do it. Objects-early teaches you that lesson from day one. Objects-late teaches it later. 

The first set of ideas is to present how the use of computers can help them now with their classwork. The second set is to show your students the application of what they are learning in your class to things they already know, or will be taking soon. The third set of ideas shows how computers are being used in the work-a-day world to make things easier, or better, in the field they are really interested in. The final idea is a method of beginning the idea of collaboration in your school before the other instructors realize it's even possible. 

Markup languages are for giving names to things. How can be different between 'languages', with, for example, HTML and XML using , Markdown using special characters around text, and $\LaTeX$ using dollar signs () around text and key words. No matter how it's done, all the markup language is doing is giving some kind of name to the thing, usually text, that it is attached to. Using a markup language is the same as using labels under the paintings in the museum. They mean nothing by themselves. They only have meaning once someone reads them, if they are in a language the reader understands. Markup text only has 'meaning' when read by a program that understands that language, interprets the tags, or other markup, and then following programmed instructions of what to do with the text the markup has named. Programming languages, on the other hand, are instructions to the computer about what to do. Programs are written in text, often in the same text editor used for writing markup text. They are then compiled, or interpreted, to create machine code that the computer will follow. Once created, the program will follow the instructions it was given, even if that's not what the programmer intended. An example of using markup could be the following image. It has what you need to know to change a flat tire on a car or truck. 

Version control is most effective in an environment where at least one user understands it quite well. As long as you have one individual on the team that understands how to recover from a messy situation, everyone else can comfortably learn as they go. However, if one does not have such a knowledgeable individual, there may be no clear way to recover from the sorts of situations that VCS is supposed to help you with. For example, if I'm not on your team, and you come across a "Tree conflict" in Subversion, it's unlikely that anyone has bookmarked the StackExchange answer that lists each tree conflict and the series of commands which resolve it. Instead, "Tree conflict" quickly becomes "wipe out your repository and do it again." In a commercial setting, there are typically senior developers or team leads who are actively monitoring the state of the repositories and can guide you down your path. In an academic setting, one is not so lucky. If I were to introduce VCS to a curriculum, I would use it in the context of group projects, and I would want to make sure the VCS tools are actively maintained and used. This may call for extra effort on my part, or that of a TA (which may not be an acceptable cost). I'd say 95% of the value of VCS becomes apparent when one is working on a team, rather than on their own. 

Since your students are getting the beginning of Boolean from you, you have the advantage of being able to lay the proper groundwork to work within. To begin with, hopefully, you will be stressing the point that Boolean logic is two-state. You can use the word binary if you choose, as long as they are not predisposed to think binary = computer, since while Boolean logic is handy for computers to deal with, it is not just for computers. To connect the symbols, meanings and math together, make it explicit, and demonstrate. Start with the concept that is the same as nothing and is the same as something. "I have an apple in my hand" is if you have no apples in your hand, even if you have an orange, or a pencil. The same statement is if you do have an apple in your hand. It is not, however, more if you have two apples, or twenty apples, in your hand, however, it is still just . Zero, as a number, represents nothing as well - zero apples is no apples. Therefore, it makes sense (dare I say it is logical?) to use the number to represent . Using the previous demonstrative phrase, it only takes one apple to make the statement , and at least one is something. Five is also something, but that would leave out everything from one to four as maybe, and Boolean logic has no , so that creates a problem. If some starts at one then there is not need for a . Using for something, and therefore , gives two symbols to use instead of the words and , which can get quite long to write in a very short while. The next step is to introduce the symbols for and . Here I will, marginally, disagree with how and why your are using center dot for . I am not opposed to that usage, only the reasoning behind the choice. The students have not had algebra yet, so it seems a safer choice than . You can tell the students you have chosen for because it is what they are most likely to encounter later. They should also be told that it can also be written as , and that both can also be used for multiplication ins algebra. The same way that means for this class, and will mean in mathematics (and in rectangular coordinates). Likewise using for in your class, while it will mean addition in mathematics. Rather than shelter them now, only to create confusion later, deal with the reality that we only have so many different symbols we can use, and many times they will have different meanings in different places, and knowing when, and when not, to use as is part of learning about Boolean logic. We need to toss in one more symbol here as well. Replacing the word with the symbol (or symbol of your choice) also comes in real handy. Since the students have not had algebra the next step might be difficult. Connecting the Boolean operators with the mathematical functions. Connecting the addition to first, because it is easier to apprehend, you can give the samples , , and . Rewrite them in symbols as , and . The first two will be obvious, make sense, and get no questions. The third will start them thinking and should get some questions about "why not ?" Return to the apples: zero apples made the statement false while any apples, one, two, or a dozen, made the statement true. So, any number other than zero is true. You can call it part of being a two-state system - either it is zero, or it is other than zero. Therefore, the last of the three samples can be expanded to: 

Can you see how murky that would be if you blurred the 3 hats? It needs to be clear that, in this process, you will have at least 1 person in your corner: your Scrum Master. If they can't see that, they may rebel against the idea. Now sprint planning will be the last major challenge I think. There's a few issues here. One is that you have too many people on the team. SCRUM teams work best in small numbers. A classroom is likely too many. You will probably have to adapt the sprint planning process to fit reality. The other challenge in planning is that your students aren't the experts here. You are. They don't really know enough to break down the backlog items into tasks that can fit into the sprint. As a result, you may have to help. As part of the Product Backlog, you may want to provide suggestions for how to approach each curriculum item (such as "Lecture" and "Problem set A" and "Problem set B" and "Research"), along with some way of estimating how long the task should take. Let them assign the story points -- it's an essential learning process for SCRUM. If they want to try to learn the curriculum in a different way from what you provided, then you may need to introduce the concept of the Sprint Goal, and explain how they can use that to provide cohesion. Also, do remember flexibility. As a PO, you are going to have to demonstrate to your customers that these students learned the material. That's all. If you can work with them to find clever ways to demonstrate that they are learning what they need to learn, then always let them deviate from the obvious curriculum. If you're teaching sockets, do you really need the backlog item "Learn to use ?" Or can we add a new item "use asynchronous threads to add functionality to the awesome product produced last sprint?" The answer really depends on how much freedom you have in your curriculum.