Same as the CHECK TABLE ... QUICK option above. Note that you can specify multiple tables, and that mysqlcheck only works with MyISAM tables. Checking tables with myisamchk Finally, there is the myisamchk command-line utility. The server must be down, or the tables inactive (which is ensured if the --skip-external-locking option is not in use). The syntax is: , and you must be in, or specify, the path to the relevant .MYI files (each MyISAM database is stored in its own directory). These are the available check options: 

More thorough, yet slower repair option than -r, usually only used only if -r fails. Reads through all rows and rebuilds the indexes based on the rows. This also uses slightly less disk space than a -r repair since a sort buffer is not created. You should increase the key_buffer_size value to improve repair speed if there is available memory. 

Unfortunately I'm not aware of limiting characters but you have the option to enable word wrap for SQL Server Management Studio Tools-->Options-->Text Editor-->All Languages-->Settings - Check Word Wrap 

The fastest repair, since the data file is not modified. A second -q will modify the data file if there are duplicate keys. Also uses much less disk space since the data file is not modified. 

The most commonly used option, which repairs most corruption. If you have enough memory, increase the sort_buffer_size to make the recover go more quickly. Will not recover from the rare form of corruption where a unique key is not unique. 

Can make the process faster by specifying which keys to use. Each binary bit stands for one key starting at 0 for the first key. 

I am running a Stored procedure to export data to an Excel sheet. Issue is that The column headers are being displayed at the bottom or they are missing at times. What am I missing here ? SQL Server Version 

2) Populate your data and keep it up to date This can be done from your application, cronjob or trigger in mysql. Whichever you feel safe with. 3) Change your query to something like this 

innodb_log_buffer_size depends mostly on the size of your transactions. If you don't have big blobs in large transactions somewhere around 16M to 64M should be sufficient. See what works best for your workload. Start from a low size and keep an eye on innodb_log_waits status: 

Now, matching (same structure) is actually not mandatory if you only want to drop it but you need to have a valid frm file. If you do this you should be able to drop the table afterwards: 

If it is not then you have to restart MySQL to make it happen. Oracle is working on getting more and more variable dynamic and you can see the trend going through 5.5 -> 5.6 -> 5.7. Unfortunately though there's always going to be parameters which require restart. 

By having more tables you're certainly not going to increase the memory allocation for MySQL. Number of tables has no influence on memory usage. Discussing memory allocation is out of scope now but this may be useful to take a look: MySQL memory calculator. 

Because you set as the primary key, the referencing column (pid) is not pointing to a unique item. From postgresql doc: 

No. Two separate index is not the same as a composite. Although MySQL now has index merge other than analytical queries it's not very efficient. In your case the best to have the unique key and a single column index. Start the composite with the higher cardinality column. If has more distinct values than it's good as it is. If has more than I would suggest to use . Also create a separate index which is only the column that is the second in the unique key. For example 

Repairing tables with myisamchk The server must be down, or the tables inactive (which is ensured if the --skip-external-locking option is not in use). The syntax is myisamchk [options[ [tablenames]. Remember again that you must be in, or specify, the path to the relevant .MYI files. The following options are available: 

Passes a new path for storing temporary files if you dont want to use the contents of the TMPDIR environment variable 

After we know which users we will drop, the below script can be used to drop the orphaned users taking in account the need to first remove the association to schemas and database roles. 

our company is planning to administer the report server database and the requirement is to get the list of the tables used in stored-procedures in the productions server database.Is there any query/function to retrieve this information ? 

This option stores when the table was checked, and the time of crash, in .MYI file. You can also use wildcard to check all the .MYI tables at the same time, for example: 

Note that myisamchk only works with MyISAM tables. For those of you still using the old ISAM table types, there is also isamchk, though there is really little reason not to upgrade to MyISAM. Repairing tables In most cases, only the index will be corrupted (the index is a separate, smaller, file with records that point to the main data file) - actual data corruption is extremely rare. Fixing most forms of corruption is relatively easy. As with checking, there are three ways to repair tables. These all only work with MyISAM tables - to repair corruption of the other table types, you will need to restore from backup: 

Script 1 The data in this table is populated by the monitoring procedures and provides an historical context for examining issues. But to monitor what is happening right now more is required. There are three things that help to determine the health of replication. 

(These are only the very basics there are much more your can do here) You should worry about IO usage first because CPU and Memory are less likely to become the bottleneck. Keep an eye on IO utilization to identify when you're likely to hit the ceiling of what your system can do. If your writes are competing for locks it's possible you will experience high CPU usage but that's usually coming from mutex contention not "actual" CPU work. These can be remedied designing your tables and queries in such a way that they don't lock out each other. 

You can use replace into flag () and where condition () while also omitting the create statement (): 

The behaviour you're describing is called MVCC (Multi version concurrency control). Strictly saying it's not delete + insert. It is more like: 

tl;dr Yes, will contain the rows that were just updated. Please note that you're not in a transaction context. So every query is an implicit transaction in this specific case. Assuming you did have a begin somewhere would still see the rows because it's the same connection and the same transaction. If you started the transaction and opened a separate connection or you had a concurrent process/request it would only see the rows without commit if your mysql is running with transaction level. You can check the global settings by: 

Your key_buffer, innodb_buffer_pool and innodb_log_buffer together already exhausts the available memory in a a t2 instance. If you also consider the per thread allocations (>3M) * 70 (max connections) the possible usage is growing by another 210M minimum. You have 270MB InnoDb data. If you don't expect it to grow significantly over time almost 600MB buffer pool is overkill. Make it somewhere around 300MB or if you expect it to grow then adjust with care. The 256MB innodb_log_buffer is completely superfluous. It's in the same order of magnitude as your data. You're never going to write that much that needs to be buffered. Increase your innodb_log_file_size rather if you are maintaining a write heavy operation. Key_cache_size is also way overprovisioned. You don't need more than what the size of your myisam indexes. Drop your per thread buffers and improve as it is necessary. Without seeing the usage hard to say exact numbers but I would start with something like this: 

Last process is to periodically delete rows from the replication status table so the data does not get stale 

QUICK The quickest option, and does not scan the rows to check for incorrect links. Often used when you do not suspect an error. FAST Only checks tables if they have not been closed properly. Often used when you do not suspect an error, from a cron, or after a power failure that seems to have had no ill-effects. CHANGED Same as FAST, but also checks tables that have been changed since the last check. MEDIUM The default if no option is supplied. Scans rows to check that deleted links are correct, and verifies a calculated checksum for all keys with a calculated a key checksum for the rows. EXTENDED The slowest option, only used if the other checks report no errors but you still suspect corruption. Very slow, as it does a full key lookup for all keys for every row. Increasing the key-buffer-size variable in the MySQL config. file can help this go quicker. Note that CHECK TABLE only works with MyISAM and InnoDB tables. If CHECK finds corruption, it will mark the table as corrupt, and it will be unusable. See the Repairing tables section below for how to handle this Checking tables with mysqlcheck The second method is to run the mysqlcheck command-line utility. The syntax is: . The following options pertain to checking (mysqlcheck can also repair, as well as analyze and optimize. 

T-SQL script which you can use to monitor the status of transactional replication and performance of publications and subscriptions. Things to be considered before executing the below script Requires permission on the following tables inside distribution and master databases 

Following information was found on sybasewiki Hope this helps ! How to start the sybase server? After log in your Linux/Unix machine. 

You still need to wrap this into and make sure your mail is sent as proper html otherwise it will be only be creepier. As it was described by Baron Schwartz: $URL$ 

The optimizer evaluates the possible gains of using indexes vs doing a full scan (filtering unwanted rows on the fly). As the ratio of filtered and total rows gets closer to 1 the benefit of using index decreases. The exact tipping point is dependent on the actual data, query, etc. so it's hard to say an exact number when it becomes useless. Generally speaking a 50/50 split is not sufficient for a B+TREE index to work efficiently and most cases full scan will be preferred over using indexes. (Unless it can be used for index-only scans) The index is still getting updated regardless of its usefulness in queries. 

MySQL is completely capable of serving as your full text search engine. InnoDB FTS indexes are reasonably good. With the size you described it should all fit in memory but of course that depends on the other tenants on the shared hosting. If it's not available (you mentioned shared hosting) you can implement your own pretty easily. Full text search is just basically inverted indexing. This way you can also have any custom trickery over it you want in your application which might not be possible with InnoDB FTS. You can see a basic implementation of this and performance + overhead comparison here: $URL$ 

Create a slave with xtrabackup (set master_info_repository to table if you have MySQL 5.6.2+) Have it replicated and let it catch up Stop the replication: (optional) Make a backup of master info file if you have MySQL older than 5.6.2 Make a note of the position with Make the mysqldump Destroy the database and all the files in and remove all the relay logs Restore the database with mysql_install_db and execute the dump (make sure you have file_per_table settings) (only on <5.6.2) If necessary restore replication (if it was in table than the dump contains the information so no need) 

Attempts to recover every possible row from the data file. This option should not be used except as a last resort, as it may produce garbage rows. 

Repairing a table requires twice as much disk space as the original table (a copy of the data is made), so make sure you are not going to run out of disk space before you start. Repairing a table with REPAIR TABLE The syntax is, as would be expected, . This method only works with MyISAM tables. The following options are available. QUICK The quickest, as the data file is not modified. EXTENDED Will attempt to recover every possible data row file, which can result in garbage rows. Use as a last resort. USE_FRM To be used if the .MYI file is missing or has a corrupted header. Uses the .frm file definitions to rebuild the indexes. Repairing tables with mysqlcheck The mysqlcheck command-line utility can be used while the server is running, and, like all the methods of repair, only works with MyISAM tables. The syntax is: 

Solution : You need to run a table(s) repair on the database Identifying table corruption Checking tables There are three ways to check tables. All of these work with MyISAM tables, the default, non-transactional table type, and one with InnoDB, the most mature of the MySQL transactional table types. Fortunately, MySQL now allows you to check tables while the server is still running, so corruption in a minor table need not affect everything on the server. 

The code below requires the Ad Hoc Distributed Queries server configuration option be enabled. Here I create the email to be sent assuming the previous Script 3 found an issue . 

Checks tables (only needed if using mysqlcheck under another name, such as mysqlrepair. See the manual for more details)