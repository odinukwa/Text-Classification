The only dynamic adjustment of MTU size is to avoid IP fragmentation. That is changing the TCP segment size, to match the smallest IP packet size. IP packets can be divided up by say multilink PPP but that only lasts for the single MLPPP hop. Bottom line no protocol ever changed sizes to reduce retransmissions it was said in the old days that you might want to manually adjust data sizes down when using bad links but we are talking at least 15 years ago. 

I use routers for my remote office ethernets because since I do not buy line rate 'CIR' I need to traffic shape. Switches don't do that. Router QoS is also easier to deal with because switch QoS has lots of hardware dependencies. 

The switch keeps an arp cache like any host. One reason for having an arp cache and using it is when you have non routed subnets (like oracle RAC clusters) so you may not want to put an SVI on the L3 switch (I will run a direct connection between the two switches involved in the NIC team only allow the non routed vlans over it) and put SVIs in the switch for the address space so I can ping the heartbeat interfaces. Then look at the arp table then can find with switch port, easier then getting an ifconfig from the server. It is true that in general the SVI in a switch is just used for management so the only arp entry is for the default gateway, but in certain configurations using multiple SVIs and exploiting ARP can be a great help. 

The idea if not use ECMP if HSRP is in use may be ok for SERVERS where ingress traffic may be higher than egress traffic, in a PC situation IN GENERAL ingress traffic from the WAN (responses) is higher than egress traffic (ingress). We like most people just set the ARP timers. you can mess with CAM timers BUT if you have say an MDF with the layer 3 switch and an IDF with 2 collection switches and say 5 access switches, it is a LOT easer to configure on the L3 SVI than doing all access switches. 

I have discovered weird routing from our ISP all related to BGP. Here is the scenario (real-one). - there is a /19 prefix bought about 10 years ago, which was registered with ARIN authority. - as bussiness grew each site got it /24. The trouble starts in APNIC region in ASIA. We export one /24 prefix the regular way using two local ISPs. When trying to reach this prefix from different ASIA sites like India or China all traffic is sent to US West Coast then back to our site. Except additional hops, this also adds about 150ms latency. What I already tried: - AS prepend each ISP at a time so the other left would be preffered for all inbound traffic - both tests went similar as in both scenarios traffic hit US before reaching this trouble site. As there is no other local special config I can think of like communities, how can I explain this? Are both local ISP taking in consideration the ARIN info and based on that send traffic to US? Thanks! 

If you don't have access to the NAT_Firewall this will not work. Presumably that firewall will SNAT, still you need a DNAT for ISAKMP connection. A solution that probably will work would be to have two Cisco devices and use Cisco Easy VPN, one device acting as a simple client behind the NAT_Firewall. The cheapest devices would be some 88x, 89x Cisco routers with Security License enabled. 

A reboot will surely alleviate the problem for the moment, but as time passes and router memory loads you will probably hit the same log error. You can either remove some roles you have for this router, or a more uncommon method, would be to schedule an automatic reload at every 1 week or later. 

Yes, VPN routers are also routers. So you just have to carefully read the router datasheet/documentation. If you are looking to "vpn router", this usually names a small business product, marketed with VPN to make you buy it. I wouldn't expect to have broad capabilities, nevertheless some products allows you to splin LAN into several VLANs or at least use one port as DMZ (basically offering you two "Lan ports"). 

You also need to set up a PIM RP since you only have 1 routing device you do not need to support auto-rp or bsr ip pim rp-address rp-address [access-list] the access-list has the multicast IP range so access-list 10 239.192.0.0 0.0.255.255 would make the 4900m the RP for the private multicast address range 

FETs are not required to connect 2Ks, they are far cheaper than SFPs and for some odd reason (to me) you can only order them when you order 2ks. As Ricky said you are going to see a non standard Ethernet encapsulation but that is a matter of does wireshark support it. Cisco will be happy to take the extra $$s for SFP+ 

The logic seems to be if there is not contention I will get the data at line rate (32ms) 150 users woudl consume 150*40000*8 = 49,152,000 which is 50 % of 10 meg. If the link is contended and hence policed to 50 meg it will take twice as long as only 50% of the BW is usable 

I cannot speak for anyone else but I do a TOR 8 to 16 port 'terminal server' that is connected to a management Ethernet, we do not try to use the structured cable to bring them to a central set of terminal servers. We then test as part of the turn up. We also home run the cables, as it is less likely that someone will disconnect one in error and you don't know that the cabling is wrong till you really need it. Unless you have on site people you really trust, I would not try to save $$s on this. 

Assuming that all link speeds are the same, things become hop count. If you explicitly set a root bridge the switch 'across' from it in the ring will have the blocked port, it will be the port with the higher MAC address. There is no real difference in blocked port selection between rapid and 'classic' STP 

I am on the 1st phase of implementing a similar solution. 802.1x it's been for a while now and although it's grown up and globally supported it's vulnerable when meeting local OS network stack. I have deployed it several times on small and medium networks and usually it works for 90% of the workstations, maybe 95%. There is always an old Windows install that simply turns off your day. Based on that I am working with FreeRadius. It requires broader knowledge except basic networking, but it doesn't interact in any way with the workstations, it's transparent for the user. You can also try FreeNAC which is similar still it's been discontinued for some time now. 

I have deployed ASAs in similar scenarios and all went well, with careful planning and maintenance. For the outside interface, first of all secure your OSPF process using MD5. You are to connect this interface to your L2-aggregate switches. On your inside interface we can dive into: - technically you can connect it to your L3 switch so you will split the role or the load between your network devices, also makes sense for a regular firewall (if at some moment you will have issues with your L2-aggreg devices, at least the network from bottom to the firewall is working) - for this scenario as ASA is VPN-used it means you can also connect your inside to the L2-aggregation switches. Without those L2-aggreg switches your 5545 will become useless for your network. Nevertheless for this choice you have to think about monitored interfaces as all your firewall physical interfaces will be connected to one physical device. Bottom line: if I have ports and capacity for better logical and troubleshooting I would connect inside straight to L3-bottom-switches. Finally regarding your 1st question: I have used inside interface both as a shared network with the other inside firewall (you could run into some details with same-security-traffic command and also as a dedicated network, than using bottom switches connect to the rest of the network. I prefer the last one as in this case VPN L2L filtering is done on the firewall (ASA 5545) instead of group-policy ACL (and then applying it to the tunnel-group). It is easy to manage, view, troubleshoot (for me) and also it keeps me away from some ASA more delicate traffic hairpin scenarios. 

ASIC can be thought of as a kind of chip. It is normally built in order to do something in hardware that otherwise would be done is software. So Cisco can build an ASIC for anything it wants. Depending on the model of the switch there is 1 or many ASICs. TCAM is a memory design since it is usually found on the chassis systems it is implemented as 1 of many asics. TCAM is used for particular lookup functions like routing (CEF) or ACLS, so if an ASIC does not need to do that kind of lookup it works separately from TCAM. On the other hand ASICs that handle QoS marking work hand in glove with TCAM. The presentation below on cisco live discusses some of the design tradeoffs, and a good place to look to get an understanding of what goes into switch design BRKARC-3466 - Exploring the engineering behind the making of a switch (2013 Orlando) it contains lists of the asics and a lot of general switch design information 

The google search indicates the UTM appears to be a firewall. While you could get say a cheap router/firewall put it on a shelf and if the UTM dies physially replace it, that seems a bad idea as that boxes are not functionally equivlant. This is a form of redundancy though a static kind, as mentioned in the comment. Net of this is that if you need the firewall function you need a duplicate physical box. MAYBE you can 'limp along' with a less expensive spare box while you wait for your replacement firewall but that is a business call. Lastly most people here will tell you that your ISP connection will fail far more often than your hardware and that is what you need to make redundant first. 

I will assume you are running IBGP, you never send a prefix you received via IBGP to an IBGP neighbor, also there would be split horizon (don't send a route back to the person who sent it to you). Since this box only has one neighbor and it is not originating any routes by itself, it will not send any routes, so the policy is implicit, but there. 

Anytime possible I would use EIGRP (faster convergence and failover) over the tunnels then next in preference would be OSPF. GRE is not supported by ASA as far as I know. 

Whenever possible I would go for IPS module, it s one of the best security products available on the market. As long as you have the license just fine tune it and use it accordingly to your needs. For any other scenarios when IPS not available, threat-statistics will prove helpful. 

There are two "central" locations each one having one satellite or spoke site. Let's have: - zone A and its spoke_zone A1 - zone E and its spoke_zone E1. Both region A and region E have a similar deployment scenarios: - 1 x 5508 WLC - several LWAPs in the existing network (local network). - FlexConnect for other several LWAPs for the spoke zones A for the A1 and E for the E1. I'm thinking how can I achieve a backup solution for all these 4 sites: - A1 and E1 can achieve it through FlexConnect and one mode only: local switching & local authentication. - what about A and E regions? How can I bring some backup WLC solution here? I know of Mobility Groups, still I don't think it helps too much as I have only L3 connectivity between A and E region through MPLS. What if I try and get L2 connectivity in between using some solutions like "poor-man's EoMPLS" like L2TP v3, I will be able to connect one VLAN pair, will this be enough ? - what else can I do in case of WLC breakdown in either of the two regions (A or E)? 

I would suggest to create a 2nd Remote-Access tunnel group for all your remote-access users. Start migrating them, one by one and when you are done you can delete the existing Default L2L Group, or you can change the PSK. If you encounter some users that don't want to change, you can enforce a specific VPN Client version and inform them you are doing a major security update. 

Each VLAN creates its own broadcast domain in 1 or more physical switches. If you have a switch taken out of the box it tends to put all ports in vlan 1 so for say a 24 ports the broadcast domain includes all 24 ports. If you were to create a vlan 2 and configure half the ports to be members of vlan 2 you then have 2 broadcast domains each of 12 ports. if you create a vlan 3 and put half the ports that are still in vlan 1 in it you would end of with 3 broadcast domains 2 with 6 ports and 1 with 12. 

Most products require you to configure MAC addresses in DHCP for imaging to, so a normal PC will not use DHCP addresses from the imaging server, this begs the question why have a PXE VLAN? I use one for servers but all production networks are tagged so we can rebuild the server without needing to change the switch, but I would suggest this setup is needlessly complex. Use 2 DHCP servers 1 to build and one for normal operations and have a small scope in the build DHCP server. 

You probably want to be polling the CAM/MAC tables, that would have the MAC address of any devices send any traffic through the switch. ARP is L3 CAM/ARP is L2 

IPv4 and IPv6 operate as 'ships in the night' as far as routing is concerned, so I see not benefit to separate VRFs with ipv4 in one and ipv6 in another. Also any dual stack hosts would need separate interfaces or separate tagged VLANs to operate dual stack. Now if you are concerned about RAM in the router VRF will not help that, for that concern route summarization or default routing would help there, and that applies to both IPv6 and ipv4 

Well you normally need to use virtual links to talk to area 0 via a different non area 0 area or you connect 2 parts of area 0 through a non zero area. So virtual links do not apply. You can have a non contigious area if its not area 0, but as hinted above, not really a good idea. That being said you proposed topology will work without virtual links.