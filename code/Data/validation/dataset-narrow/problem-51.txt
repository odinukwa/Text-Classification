DHCP runs over UDP ports 67 & 68, so you will need to open those for this to work. Depending on your setup you might also be missing a DHCP relay configuration on your FW to forward DHCP requests to your server. 

The main difference between the two is that MPLS services usually come with service level guarantees regarding availability and performance that you won't get with an ISP, but of course those guarantees come with a typically higher cost. 

Presumably, the outer vlan ID is used if you want to carry both your VXLAN trunk and a bunch of other non-VXLAN VLANs together on a traditional 802.1q trunk. So you end up with an outer .1q trunk just like you've always done, and an inner VXLAN trunk. The switches involved in this trunk have no knowledge of VXLAN, to them it's just another flow, like any other UDP traffic. 

Although this seems to be an AP-based rather than WLC-based command, it would appear you can get the info you want from the AP CLI through 

If you need to view the whole capture in one go, you can then use the utility to merge the N logfiles into one large one to work with in Wireshark. 

There is absolutely no rule to the effect that pings follow the same path on return, quite the opposite in fact. ICMP packets are routed based on their destination, so if you have asymetrical routing somewhere in your network, the ICMP request will take one path, and the reply will take another. This is also why it is often useful when troubleshooting to get traceroutes from both ends of your network. In this case though, are you not missing some routes ? On R1 for instance you have a route towards 192.168.2.2/32, but not towards 2.1. 

This is indeed a typical config, and most likely doesn't require you to change your hardware. On one hand, you have the /30 which will be used on the point to point WAN link between you device and the first IP device on the ISP's side. So you should set your device up with the IP they gave you (.142) and a default route pointing to the ISP's device at .141 Then, they are saying they have assigned a /29 block go you. What this means is basically that there is a static route on their side pointing to you WAN IP (.142) for that /29 range such that any traffic for that range is sent to your router. At that point it's up to you to decide how to use it. You can either route it to another device on your network (a firewall, say) with a static route, or use it on the router itself for handling NAT rules. The range does not need to be associated with any physical interface on the device: the router will be receiving the traffic anyway, due to the ISP's static route, it just needs to know what to do with a packet reaching it with a dest IP in that range: route it further, or process it. 

It depends if you are seeking to find the single summary network that covers at least all of your list, or the shortest list of networks that covers your list exactly. In the first case, what Bungicasse described works. In the second case, it's not very difficult, and is a lot like the problem of handing back change for a payment with a minimal number of coins. You just go through it methodically, with subnets of decreasing size. You would consider that a /17 (192.168.0.0 to 192.168.127.255) is too large, and that /18 ranges (192.168.0.0 to 192.168.63.255 or 192.168.64.0 to 192.168.127.255) do not align on the right ranges. So you start with 2 /19 s and fill in with smaller ranges above and below them 

It's not entirely clear what risks you are trying to cover, but my suggestion would be to create a layer 2 vlan across your set of switches, and propagating it to the firewall. None of the switches should have an IP interface in that vlan, such that the only way out of it is through the firewall. You can then use the firewall to enforce whatever rules you want, allowing or disallowing traffic to the Internet and to or from your other vlans. DHCP isn't much of an attack vector : your devices only send traffic on their local vlan, and then a relay takes over (if necessary) to talk to the DHCP server. 

Typically in order to handle this type of scenario, you need to add an ACD (Automatic Call Distribution) component to your telephony solution, and tie it into your CRM. The idea is that your CRM tool contains information that will allow the routing to be performed, such as whether a given caller has a primary assigned service rep, or simply who handled that caller's last call. The caller is usually identified by their phone number, and you might have an initial voice server step where you get more information (customer number or whatever) to help with the identification. When a call comes in, the ACD will query the CRM for this info and based on the reply will instruct the telephony solution to route the call to the appropriate operator. Note that you can now buy all of this stuff in a SaaS/Cloud approach which is both independent of the brand of VoIP platform you are using, and much easier to setup than it once was. If you don't have a full CRM platform, it is often possible to use something more basic (essentially, a spreadsheet with customer name, phone number and preferred operator) to feed the ACD, but you don't get all the benefits then. 

There seems to be a confusion here : in a distance-vector routing protocol, the routers don't just get routes to their neighbors (which would be trivial in most cases) they get their neighbor's full routing table. A router can then compare the various routes it has gotten from its neighbors for a given destination network and select which appears to be the shortest to add to its own table. So in your example, R2 receives R3's routing table, and will update its own table accordingly, with a route to 192.168.178.0/24, and then pass that on to R1 as part of its own routing table. 

MPLS support is only rarely a requirement for enterprise equipment, especially relatively simple setups like the one you describe. MPLS itself is usually hidden away in the carrier networks. For your situation you basically you have two options : 

I'm not familiar with this specific model, but having no counter incrementation on vlan interfaces is pretty common. It's not so much a limitation of SNMP as a limitation of how the switch itself is built. The ASICs behind the interfaces often do not allow for updating per-vlan counters. Also beware that if you look at the standard MIB2 counters, you're usually seeing either physical interfaces or layer 3 Vlan interfaces (SVIs). So even if you were to read a non-zero value there, it would be packets routed to or from that VLAN on layer 3, not packets switched within that VLAN on layer 2. 

I assume you are using OpenDNS' web filtering functionality here, and it looks like that essentially involves using their DNS servers to handle lookups, rather than your own. You could define two SSIDs, associate them with different VLANs (on a single physical port) behind the APs, and then simply differentiate the settings that you provide to clients over DHCP (since you have two vlans, you'll need two scopes). For a user in the guest vlan, your DHCP would provide the OpenDNS settings, for your standard unfiltered users you would provide settings pointing to your internal DNS or whatever else you want. 

You can do this with Cisco ISE. The idea is that your users get assigned different guest types, and ISE will return an ACL name to the WLC depending on the guest type. You would then tune the ACL on the WLC to allow access to whatever resources are appropriate. Nevertheless, I would tend to agree with Ron Maupin's answer, in that you probably want to separate categories that are as fundamentally different as staff and guests by using different SSIDs, and use the mechanism I described above only to differentiate guests (e.g. short-term and long-term guests, or guests vs staff BYOD devices...). Also keep in mind that the configurations on ISE and the WLCs are not exactly intuitive, and are - to my eyes at least - prone to relatively subtle mistakes that can have serious security consequences. 

There are various ways you can have encryption without using a single widely-known PSK, but you'll need some sort of extra step by the users to actually make use of it by getting some form of credentials. I have seen at least two ways to do this : 

If you only need the IP to be fixed on one network, than the simplest approach is to make a static DHCP reservation on the DHCP server for that network specifically. That way your machine stays in DHCP mode all the time, but will always get the same address when it connects to that specific network. 

I believe you are confusing which part of the Steelhead infrastructure that setting refers to. The latency that is mentioned in that setting is between your client PC (with Steelhead mobile) and the local Steelhead, not the SMC. The idea is that with a latency under 10ms you have a high likelihood of being on the same branch location as the Steelhead, so it makes sense to activate the location-aware optimizing, and thus to offload optimization to the Steelhead rather than doing it alone on the client PC (it is also possible to combine both). I think the default 10ms setting makes good sense on typical wired/wireless LANs, it may even be a little high in some environments. 

Remember that DHCP does not do subnetting. You design your subnets, configure your routers to allow the different subnets to communicate, and finally add DHCP servers to distribute addresses to devices in those subnets. The DHCP server needs to be configured according to how you've done your subnetting of course. You can place DHCP servers wherever you like if you design redundancy appropriately : I run just a handful of DHCP servers for a corporate network of almost 2000 locations. The trick is setting up DHCP Relay functionality (aka ip helper in the Cisco world) so that a subnet without a local DHCP server can be served by a server elsewhere. 

It is often possible to setup VPNs with dynamic IPs, so long as the central hub has a fixed IP. This usually involves setting things up so that the VPN Concentrator uses some other criteria in the ISAKMP config to differentiate between incoming VPN establishment requests, like an FQDN for example. This does not require the use of DynDNS. I personally prefer this approach as it does not introduce an outside dependency on a third-party service like DynDNS. See one example for a Cisco approach here : $URL$ But many other brands also support similar configs. 

With the advances in wireless tech over the past few years, the reliability and performance of WiFi are such that the average user probably won't notice the difference in day to day work. So in practice, to answer your question 2), 802.11ac may not quite match a full wired Gig port, but only a very few users could possibly generate enough traffic to notice. However, it remains much more complex than wired networking, and requires a great many more parts to be in working order. You can have interference issues, transmit power issues, PC driver issues, authentication issues... that for the most part just don't occur on a wired network. So wireless is going to cost more to manage day-to-day, just because of the number of things that can go wrong. Regarding your question 3) for an inter-building bridge, I would definitely go with fibre, using wireless only if I had no other options, for all the reasons I mentioned above (reliability mostly) 

Traffic can be routed between VLANs by a router, there is no requirement for a firewall (which ultimately is really a router with some filtering features, anyway). There is no way to say for sure whether you are crossing a firewall or other filtering mechanism on your network path. The best you can do is try to detect side effects of a firewall's presence, usually more because of its advanced security features than because of its ruleset. For example, if you capture traffic at either end, and the absolute TCP sequence numbers don't match, you probably have a firewall in between, rewriting them. Or if you have a session ending with a TCP RST, and that packet doesn't make it to the other side, it was probably dropped by a firewall. There are other effects that can be visible in various TCP/IP headers, but they are usually pretty subtle and more a clue than a definite sign a FW is present. 

This is pretty much what most corporate WANs used to look like, back when reaching the Internet was a gimmick and all the real work happened in the datacenter. My own corporate network is still pretty much set up this way in Europe and the US... but we have a couple thousand branch offices to manage, and moving that to a different architecture takes time and money. So far we have managed to make it work, but continuing to scale it is a challenge. However if I was starting fresh, I definitely wouldn't bother with backhauling web traffic to the datacenter. If you look at the data it's fairly easy to understand why. Traffic from sites on my network increases by about 25 to 30% every year (driven by heavier web apps, video use, etc...), and 75 to 80% of the total traffic to the datacenter is just passing through on its way to the Internet. Given that we use a cloud proxy service, the datacenter doesn't even really provide any security filtering which would have justified going through it in the past. As a result, we are putting Internet links back into more and more locations, because that's where the traffic is actually going (Google, Salesforce, etc...), and it's fairly trivial to source 50 to 100Mbps of local broadband, whereas getting and more importantly managing multi-gig Internet links into the datacenter gets complex fast, if only because it creates a single point where any hiccup will balloon into a major incident fast. 

Note that this is not a highly intuitive solution, so I would encourage you to use an actual load balancing system (like Microsoft NLB if you are in a Windows environment) rather than resorting to something like this which you may have difficulty troubleshooting over time. Also, if you are trying to manage not different servers but different Internet links, you can use the tracking feature there as well. 

On the TCP level, since you have a real connection between a local and remote host, your connection is uniquely identified by a 4-tuple (source IP, source port, destination IP, destination port). So whether on the server or client side, the theoretical limit is pretty high, since even for a given client and server, and a specific server port, you can still open 65536 individual connections that have a unique 4-tuple. In practice, as Ron Maupin stated above, you would run into other limits first. On the UDP level, since there is no connection, your socket is only identified by its local IP and port, and it's typically up to your application to deal with separating the data coming from different hosts (look at the UDPClient.Receive method in .Net for example). 

You have it slightly backwards actually. The NTP source, such as your router, doesn't actively relay anything of its own initiative. It can however act as a time server for other devices, and it doesn't care whether said devices are Cisco, Checkpoint, or whatever so long as they present themselves as well-behaved standards-compliant NTP clients. You'll need to activate the NTP server functionality through a command such as : 

Most likely the firewall just dropped the packet without sending an RST packet, probably after hitting a session timeout value of some sort. This is typically configurable behaviour. I personally prefer having that RST packet sent precisely because it helps clients behave normally, but I have heard arguments to the effect that this should not be done on externally-facing firewalls to avoid providing any kind of feedback to potential attackers. I have seen this cause quite a few issues because clients typically don't handle this kind of scenario very elegantly. Essentially, they keep retrying through the original TCP session (which is now dead) and never try to re-establish a new one. Eventually a client-side timeout triggers and the user gets a nasty error message. Setting up HTTP keepalive appropriately for the app can help to fix this. 

In a word: no. YouTube provides no mechanisms to allow a network device like a firewall to differentiate between content types. The only method I'm aware of that sort of works is to use a proxy to set a volume quota on YouTube or other streaming media sites in general, high enough so that the odd business use is possible, but streaming music videos all day is not.