I think that both the question and the answers to date conflate two things that can be separated: imperative programming and programming with primitive data. These are not the same thing and thinking of them as one leads to some of the difficulties. Programs don't all have to be C-like programs from 1980. Using modern languages (java, python, ruby, scala...) the instructor can, instead, create a virtual world in which students have their first programming experiences. So, rather than first introducing strings ("hello world") and ints (with their operations - and the limitations of those operations) students can program with "things of interest." While my own preference is to have them learn OOP principles early on, that isn't necessarily implied by having a virtual world. In the Karel series of books (Karel the Robot, Richard Pattis) and its successors in Java, Python, and Ruby the students first introduction is with a few primitive actions (move, turnLeft, ...) and one kind of primitive "value" (beeper). The world is very rich - provably a Turing Machine. Using such a world, this one or one of your own devising, you can present the computing model you prefer to students with very little distracting detail (maxInt...). You can then teach program logic and structure separate from that detail. Once the students have a basic grasp of the "fundamentals" (i.e. not int and string) you can introduce those concepts incrementally. But it is amazing how much you can teach without explicit counting. One feature of the Karel books that may be a plus or a minus is that, while they give a good foundation in computation, they are not intended to have enough material for a complete course, either at secondary or university level. One person I know is working to build a complete course around Karel J Robot, but I think that is a bit optimistic. But they are good for an introduction, at least: a short course or the first third-half of a regular course. 

I see you are in the UK. I think the constraints are different in different places and at different levels. But most of the examples you give are of the ephemera of computing - current languages, frameworks. That may be a misplaced focus. There are other topics, more fundamental, that increase in value over time: encryption, quantum computing, Big Data, Massively Parallel computing, etc. You need to teach within some current framework, of course, but also to think about how you are preparing your students for taking a wider view. I used Java/Eclipse for a long time, but realize that it wasn't a "forever" solution. I don't think I really did enough preparing for the day when Eclipse won't be available (or desirable), however. But one concrete thing you may be able to do, subject to constraints, is to have one "Over the Horizon" course, named that, perhaps, or "Bleeding Edge Computing" maybe. It covers the latest and greatest even if you know that the topics may not have the legs to last. A more boring name, but probably a good focus, is "Current Trends in Computing." Students are warned in such a class that this may seem "cool" today, but "cold" tomorrow. A second thing, not quite the same, is to rotate a series of courses on the rising but likely important things, as listed above, that you can't justify putting into the curriculum as a continuing course. Big Data one term, Quantum Computing the next, etc. The second solution is much more work, of course, since the course development is harder and maybe won't be amortized over several years. A third choice is just to let one Prof (in rotation) teach whatever he/she think is the most interesting thing they know and work on. "Professor Williams' Current Research" or something. As for yourself, go to a lot of conferences (constraints again). Visit the real world when/where possible to see what goes on in the trenches. See what is going on now. Experiment a bit as time permits. 

Any book on elementary number theory will likely have quite a few recurrences as examples and in the exercises of the early chapters. For example, the sum of the first n odd integers is $n^2$. As a recurrence this is just $n^2$ = $(n-1)^2$ + $2*n - 1$. Or possibly it will be shown as $a_n$ = $a_{n-1}$ + $2*n -1$, with $a_1$ = 1. Some books on discrete math have many of these as well. Some even have these in summation form, rather than as recurrences. Likewise the sum of the first n integers (start counting with 1) is $n(n+1)/2$. From these recurrences or sums you can develop a program to give the students or have the students prove the relations and then develop the program themselves. Even a web search for recurrence relation turns up some ideas. A rather important sum (the geometric sum) is this: Let r be a real number and k a non-negative integer. If $r \neq 0$ then $\sum_{n=0}^k(r^n)$ = $(1 - r^{k+1})/(1-r)$. Moreover, if $|r| < 1$ then as k increases this sum approaches 1 - r which leads to an infinite sum that is pretty comprehensible. Also David Gries' The Science of Programming has interesting examples that he shows along with how to develop programs from pre and post conditions. The book has been mentioned in answers to other questions here also. 

It has been noted that I often promote Greenfoot. I'm not affiliated with the site or its developers, nor have I ever been. I know some of the developers and I have produced materials for use with Greenfoot. I also occasionally submit bug reports and feature requests to the site. But Greenfoot aligns well with my general teaching philosophy and makes Object-Oriented Programming easy to teach to novices in an interesting and engaging way. 

Talk about it. Talk about the two original situations with the door. But more important: don't use just this one example and expect everyone to get it. That is unlikely to happen. Use a different example in which an is needed. Talk about the difficulty of writing this with condition $doorIsOpen()$ rather than $!doorIsOpen()$. Come at the target (learning) from lots of directions. A quick, ungraded, pop quiz can also tell you whether they have the concept or whether you need to do more. It can also let you know who you need to work with more intensively. Be flexible. Surround them with a cloud of understanding. 

At some point in the execution the program counter (PC) may be at point (a) or at point (b), but not both simultaneously, of course. If the PC is at point (a) then the "state of the computation" includes the fact that x is 3. If it is at point (b) then the state is that x is not 3. In this view the state of the computation changes as the program executes (and is dynamic). In the former view the program state is often thought of as static, though that isn't quite correct (since things change). I will refer to this second notion of "state" as Implicit State. It is the current location of the PC and all that implies about what has gone before, no matter how implemented. Now to the question: What is the fundamental difference between (pure)FP and (pure)OOP? 

Complexity class _ is described here: $URL$ One of the easiest examples to explain is given there as: The decision problem version of the integer factorization problem: given integers n and k, is there a factor f with 1 < f < k and f dividing n? It is easy to explain as most students will understand factorization and will know, or can be convinced, that finding factors is a hard problem. It is also clear that a solution (factor), once found/guessed, is easily checked. Showing that it is in class NP is a harder slog, of course.