why I was tasked with creating a custom service that was installed on a server in our old domain and ran with a dedicated account. It worked perfectly and everyone was happy. A couple of weeks a go we all moved to a new domain and the older server was decommissioned. The new server had the older service installed along with a new domain user to execute the service. The code I wrote failed because the server had new components on it. This was logged in the services custom event log, very clear, missing dll. Rebuilt the service with newer components and tried to get the owner to deploy it, they refused until I had it working locally with the new domain service runner user account. Using my personal domain account on my machine to execute the service runs fine. Any attempt to start it with the domain account gives logon failure. I was able to run 

Seems I missed a trick, even though all the examples for psloglist show the argument -u with just a user name it does work with a domain. So my working solution is 

but that instantly returns and no command window appears and no file is created. I presume this is because DOMAIN2\USER cannot create the event.log file on my machine, how can I get around this? DOMAIN1 has no trust with DOMAIN2 and I cannot added it. 

if is binary the does not execute the and if its plain text then it does. This now matches script and other "text" files that are not marked as "plain" 

For a single folder or set of folders recursively set the layout to include additional columns and make those changes for any user that logs on. We have a server(Windows 2012) that has a folder that holds emails. In Windows Explorer I have setup all the extra columns to show Subject, From, To etc but how can I make those customisations available to any other users that RDP on to the server? I have no desire to affect all folders or make it the Default configuration. 

The mainstream PC itself becomes a portal for consumer optimization and market research. Therefore, it is critical for this model to collect and upload all preferences and habits of a customer, and sell processed data to merchants. Google does this, Amazon does this, and Microsoft wants a piece of this pie having a perfect opportunity with "point-of-sale trminal". That's why the seemingly innocent search application becomes wrapped into so information-hungry "digital assistant". The Cortana, therefore, is a backbone of this Microsoft business strategy. That't why Microsoft will restore Cortana by any means, and they succeeded. 

The question is ill-formulated. There are many "microcodes" in modern x86/IA64 CPU, and there is a difference between "microcode patch" and microcode. The microcode in its classic understanding (as step-by-step elements of execution of long CPU instructions) is almost certainly en-carved in silicon, as there is no reason to keep bugs unfixed along many generations of CPU, when new silicon/RTL is compiled with every new manufacturing node. However, all recent CPUs have several internal units that are controlled by independent microprocessors that are embedded inside the x86 CPU chip. Most notable/known is so-called "P-unit", a processor that controls dynamic power management of the CPU. As core frequencies went up and leakage went up with further miniaturization of CPU transistors, the only way to keep power in reasonable limit is by aggressive clock throttling and dynamic power gating. The problem is that the CPU can execute infinite varieties of software codes, and each reaches a certain peak of power consumption. Some patterns of "power viruses" may not be known at the moment when CPU was finalized for retail, and some parameters of managing algorithms must be corrected. This is done via dedicated "microcode patches". There are several more microprocessors of this sort that control other CPU blocks like graphics and memory. The details of patching process are top secret, to prevent malicious interference. Here is some hacker's report on the attempt to reverse engineer the mechanism. In short, the x86 architecture microcode is not loaded in modern CPUs, but microcodes for various auxiliary embedded microprocessors can have patches. 

If this is a developer instance to test code go with 2 or 3. If it is a production deployment and you are expecting to run a cluster then 3. WSL is create for running small scripts, testing things but I have not found it very friendly as a replacement for Linux server. YMMV 

Immediately with no access to the server: If HTTPS is used and the viewer/attacker has not got the server SSL key then no. If HTTP is used and the traffic is not encrypted in another manor (wireless WPA comes to mind), then the data packets for the zip file will be available to recover the zip file. After 10 days with no access to the server: no Immediately with access to the server logs: The server is all powerful in this situation and could have done anything with the request information. All bets are off depending on the server type, version and configuration not to mention the competency of the operator. After 10 days with access to the server logs: Same as above. The amount of time that a server holds its logs and what is in them is an unknown factor 

i was all set to give one of the Get-NetTCPConnection answers an upvote, after all it worked on my machine. Sadly it did not work on the Windows 2008 servers that were running Powershell 3.0 that had to do the check. However the following worked perfectly 

to ensure that there was absolutely no way I was entering the password incorrectly. Additionally I got the domain admins to reset the password and ensure the account is not locked out. Why on this one machine can I not run this service as this domain user? 

Do not worry about any "Security Assist" or AMT or any other operating system component. You are screwed anyway. From wikipedia article: 

Your case front panel likely has a standard 20-pin plug, with cables to two front panel USB 3 receptacles. To interface it with the on-board 10-pin USB2 header, you would need an adapter like this one: $URL$ The adapter connects only USB2.0 wires, and leaves USB3 set of wires unconnected. When a USB3.0 device is plugged in, it won't find expected termination on loose wires, and falls back into USB2.0 mode. ADDENDUM1: If you would like full USB 3.0 functionality from your front panel, there are 4-port PCIe controllers, two ports on back, and 20-pin header internally, where you can plug your front panel directly. $URL$ 

USB devices have the metal shroud for a reason - to protect data signals from ESD - ElectroStatic Discharge. By removing the shield you expose signal pins to ESD, which will definitely increase the risk of damaging the USB interface permanently and losing all your data. If you want to gamble with your data, you sure can remove everything. 

Third scenario happens when a device assert the chirp, but the host doesn't respond with chirp toggling. This means that the USB host is not HS, and the link proceeds as a FS link. More details of this process are covered in this SU post. 

Modern SoC found in cheap ultra-books use eMMC with 5.x specifications. The 5.+ interface can handle up to 400 MBytes/s data rate. In most cases the SoC would have a dedicated eMMC controller, having 8-lane parallel interface. USB 3.0 sticks, in practice, are using the same eMMCs but with USB-to-MMC bridge. It seems apparent that direct connection to eMMC IC is better than a connection coming over any bridge. Of course, the performance will differ depending on eMMC chip internal architecture that is used in a particular device. But you will be hard pressed to find a USB 3.0 flash performing faster than 100MBps on writes and reads. All bets are that internal flash will work better for running OS. 

is being expanded to the name of your batch file instead of being passed to as a template for multiple filenames. You should use a double percentage mark to prevent this: 

A hard link is a file system feature that cannot cross a file system boundary. You can't hard link files on C: to D: because they are separate file systems. They might each contain the same type of file sytem (eg. NTFS) but they are separate file systems. 

(Note: Instructions and screenshot from Excel 2013 but should apply to Excel 2010) Let's assume the cell with your formula is C4 and the "two other cells" are C5 and C6. 

SciTE v2.23 on Windows seems to work fine with these character sets for me. Have you set the encoding to UTF-8? 

Windows 7 has the Snap feature which can be done with keyboard or mouse. Keyboard shortcuts: Snap left: Windows + Left arrow Snap right: Windows + Right arrow Full screen: Windows + Up arrow 

You can then add a pivot chart if you wish. Tested in Excel 2010. Note: You could also do this using Histogram in Data Analysis but if your data is likely to change/grow then pivot tables are easier to update. 

This will return the number of characters (bytes) that the compressed file would have been if it was written to disk. 

If you have the Zip code in cell A1 you can use the formula to format the Zip code as 5 digits wide with leading zeros and then merge that instead of the numeric version. 

Use a Pivot Chart and add month/year grouping on the Date field and your summarization choice (sum, average, count, etc.) on the Value field. 

You are looking for something called "wireless USB hub", something like "IOGEAR Wireless USB Solution (GUWH104Kit)". It was a fad couple of years ago. Latency will be still an issue. 

With unlimited SMA passthrough connectors, the solution is straightforward. You need to make a pair of special USB cables. And I am sure there is no COTS of this sort. You need to take two cheap SMA cables (of proper gender), cut the other end, and solder it to board similar to this one, but with USB plug. This will make the enclosure-to-host part of USB cable. Within the enclosure you need to make another half of the cable, from two SMA to proper USB plug. If your device has the Type-B connector, just use a cut of proper end of normal USB cable. You can do the same for Type-A plug, without any interposer board. This arrangement will also work even for HS USB communication. Only make sure that you connect SMA connectors in right way, D+ to D+, and D- to D-, and that the coax cables are of the same length. And you will need a third SMA channel to pass the VBUS (red wire) through. 

It sounds like you have a virus infection. The Sandisk is notoriously known for puting some questionable self-executable malware on its flash drives, for so-called security or whatever. There used to be a special hack tool to remove that stuff in the past. 

I believe the picture shows a general RS-232 full-size DB25 COM port, and not a parallel port. Technically the stack-up should work with a special USB/PS/2 compatible mouse, which operates in LS USB mode (1.5Mbit/s). However, the picture shows a USB stick, which can operate only at FS rates (12Mbits/s) and above. This "setup" will not work because the setup can operate only at 1.5Mbit/s USB 1.0 rate, while the FS USB device needs serious processing of data signals at 12 Mbit/s, and needs a carefully scheduled special service from PC host, which cannot be provided by COM port. So the simple answer is: the COM port PS/2 to USB converter cannot provide the necessary communication speed nor proper USB protocol for a FS/HS memory stick. Specifically it "stops working" between the stick and green USB-PS/2 adapter. ADDENDUM1: one fundamental evidence that this setup is a joke is that neither EPP or COM ports have any 5V power, which is necessary to power the USB stick. ADDENDUM2: yes, this is the PC parallel port, per description of DELL 2550 sever, and thanks to "plugwash". The PP is worse, since PP does not have any UART serdes conversion hardware, and bit-banging of the port from x86 PC is clearly out of range for 12Mbps receiver processing (which needs 20ns sampling/reading rate). 

Are you creating your message in HTML? Tabs generally get replaced with spaces in HTML messages. Try creating your e-mail in plain text format and the tabs should be retained and you'll get the expected behaviour when pasting into Excel. 

I believe the minimum size option uses higher JPEG compression on images in the document to reduce file size at the cost of image quality. The change should be subtle but noticeable if you look closely. 

Set up a free 2GB Dropbox account for them as a backup solution and for sharing photos and other files with family and friends. 

Yes, it's quite easy to achieve using the Polygonal Lasso tool in Photoshop. (You may wish to delete the background first using the Magnetic Lasso tool.) Use the Polygonal Lasso tool to select the first pie slice then cut it to the clipboard. Then create a new document and paste the slice on to that. By cutting and pasting in this way you are moving the image pixels so you avoid the risk of accidentally copying the same pixels (on the edge of a slice) to more than one of the new A4 images you are creating. Tip: You will probably want to select Antialias on the Polygonal Lasso tool and use a small feather (1 px) or none at all (0 px). 

Low quality / High compression JPEG saved as PNG - 8x8 pixel blocks are clearly visible But if the JPEG compression was low (high quality) then these blocks may be difficult to see... 

Excel datetimes are represented as the real numbers with 1 being 01-01-1900. Depending on your typical response time, you might choose to format the result as hh:mm:ss or as fractions of days. You can use inbuilt and custom number formats to achieve the result you want. Note: If you do not enter the starting and ending time in a format that Excel understands as datetimes then they will be treated as text and you won't be able to apply the formula I have shown. 

Sound means that your device has sensed VBUS from your port, and asserted "connect" event" - pulled D+ high. This results in connect sound. However, it looks like your device failed to respond to enumeration sequence that must follow the connect event. The investigation depends on whether the port is USB3.0 port, and if the device is USB3 device. If the drive is USB2, failure to enumerate can be caused: (a) failure in digital logic in flash drive: drive fails to respond to USB_RESET signaling, or fails to respond to GET_DESCRIPTOR inquiry. Did you try your flash drive in any other computer? (b) Out-of range termination in the flash drive, such that the host detects false disconnect event; (c) Host port has too much sensitivity in disconnect detector, so with (b) it causes premature disconnect and failure of enumeration. (d) Host failed to provide correct chirp sequence, or chirp amplitude is marginal.. To find the root cause, 

Why do you want to divide the write time by half? Under your (optimistic) assumptions of Write rate of 30MB/s and 40MB/s for Reads, the answer is simple: in BEST case your application layer will take 25s to read the ENTIRE file, and then 33s to write it back to another drive. So it will take 25+33=58s total, and not a second less. This is the most optimistic estimate under your basic ASSUMPTIONS for data transfer rates. If your application layer has smaller buffer, reads and writes will go in smaller chunks in interleaving manner, so the transfer time will be somewhat longer due to protocol(s) overhead. ADDENDUM: I guess the confusion comes from wrong assumption that each port in the shown card operates as independent channel. It is not. All EHCI controllers are implemented as "root hubs", meaning that each controller has only one list processor (aka DMA), and all HS ports share the same 480Mbps bandwidth. To get reads/writes to go in parallel, one needs to install two cards in system. Or more.