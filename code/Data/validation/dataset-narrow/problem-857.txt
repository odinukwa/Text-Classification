Your directives should use absolute paths. It's not easy to predict where they are going to attempt to read files from with relative paths. 

Yes, you have to have an active RHEL subscription to download packages from RHEL's repositories. If your machine has never been subscribed, or the subscription is expired, you will not be able to use any of the repositories provided by RHEL. Red Hat states, in relevant part: 

The usage statement clearly says that requires a argument, but you haven't provided one. Add in your router argument and optional SNMP community: 

Typical Web filtering appliances/services classify web sites into categories, and then each category is permitted or blocked based on corporate policy. Some, such as Barracuda, use a reputation based system. They almost always also allow for local exceptions. So, if you host the jQuery code on your own site, it will be permitted or blocked the same as the rest of your site would be. If you use a hosted solution such as jquery.com or Google APIs, then it will be permitted or blocked based on the classification for that domain. If you want to be 100% sure that your code would get through to sites that would normally permit your web site to be viewed, host all of the JavaScript within domains under your control. 

As several people noted, "Pizza Box" refers to a 1U server. "Lunch Box" refers to a portable computer inside a transportable case vaguely resembling a child's lunch box. This type of computer usually has a keyboard and display that pop out of the case somehow. These are typically used in military applications. 

keeps its own history, so you can find out when a package was installed or updated using its history. For instance, will give you all the transactions involving ruby, where the oldest one is usually the one where the package was installed. 

The Linode kernel you are using doesn't have the modules your firewall wants. This is why you get the error "No chain/target/match by that name." (And firewalld is a front-end to iptables.) To resolve the problem, you need to run the kernel provided by the virtual machine, rather than the Linode kernel. Do this by setting the Linode to boot and then installing a kernel with if one isn't already installed. 

The problem is that uwsgi is systemd-aware, and the systemd unit tells systemd that uwsgi will notify systemd when uwsgi is ready to begin processing requests. By default uwsgi starts in this mode when on a systemd system, unless you tell it to daemonize. In that case, uwsgi does not talk to systemd. This is why systemd waited for a while and finally gave up waiting for uwsgi to tell systemd that it was ready. Rather than having uwsgi daemonize and log directly to a file, the documentation suggests that you should let it log to its default of standard error, and let systemd pick up the logs and log them. You'll want to do this if you eventually will have logging sent elsewhere, such as an ELK stack. For example: 

Only if you want to rewrite your nginx configuration every time you restart that container. Better to just give it a static IP address. 

See Red Hat Enterprise Linux Lifecycle for more information. You should also spend about an hour yelling at the idiot vendor who says you have to remain on 5.7. 

I've looked at (you can too) but I'm not exactly sure what to tweak to permit access to crontab for users who have not yet changed their passwords. I'm well aware that I can force everyone to change their passwords with , and users who change their password will regain access to crontab (and whatever else might be broken) but I have a few users where I need to edit their crontab before their next login, and using as root also fails with exactly the same error as above. Strangely, this issue didn't show up on my dev box; I've run into this on the staging box just prior to deployment. Users on the dev box with old MD5 passwords can access crontab just fine, and the is identical. The dev and staging boxes are supposed to be identical, aside from their IP addresses. I suspect I've missed something really obvious and stupid... So my question is, how can I enable access to crontab for users who haven't yet changed their passwords and been SHA-512 hashed? Or, how can I work around this issue? 

You really don't want to disable keep-alive. Your server performance will suffer, for starters. Your clients will experience slower loading times. In rare cases, you may even get fired. Don't even THINK about doing this on a production web site. If you're just testing, you can set the HTTP header . 

Connect to the machine via a different interface. Connect to the machine at the console. Set up the bridge in the system's startup scripts (you didn't specify what sort of system) and then reboot. 

Nagios considers a host or service that is acting in the manner you describe to be flapping. You may wish to tweak your flap detection for this host/service. 

I have Windows Server 2008 R2 running virtualized in a KVM virtual machine. Recently the virtual machine decided to stop booting, and it offered to Launch Startup Repair. However, upon entering Startup Repair the virtual hard drive was nowhere to be found. 

You need to add two custom domains for your website in Windows Azure. You already added , now you need to add the same way, except this time you will use the A record that Microsoft gives you in your DNS instead of the CNAME. You also have to set up the special record for it. 

FirewallD is very new, and as such it's going to take some time to get accustomed to. You can begin by reading the Fedora wiki page on FirewallD, which has a complete list of its command line options/usage. My best guess on what happened is that you accidentally put the firewall in panic mode, where it blocks all network connections. This is based on the fact that the only option to which begins with is . You will have to go to the server console or remote into the server's OOB management interface (iLO, DRAC, IPMI) to recover from this. The correct way to add a service is with or . 

By default, for a wireless connection such as yours, "Available to all users" is disabled by default. This is enabled by default only for wired connections. 

You're trying to use the same Unix domain socket for both dev and production. Use different sockets for them. 

You need two networks, not just one. The VM connected to both networks must then have two virtual NICs, each of which is connected to one of the networks. 

Debian jessie includes ipset 6.23, so that should be no problem. But because your VPS provider uses LXC, you will need to ask them to enable ipset to work in your container. 

This happens when your IP address is listed in the Spamhaus PBL. This DNSBL contains a list of known dialup/dynamic IP address ranges which should not ordinarily be sending mail via SMTP. To fix the problem, change your mail client's outgoing mail server settings to connect to port 587 instead of port 25. 

The Microsoft Basic Display Adapter, as the name implies, is meant to be basic. This means you are locked to a resolution of 1024x768 and have minimal desktop eye candy. 

The next course of action is to check with your provider (in this case Amazon) to see if they know anything about the issue. It seems that they do: 

In your https virtual host, you specified an IP address to listen for connections on. Thus, requests which connect to any other IP address on the host will never match that virtual host. If you really wanted to do this, you could add a second IP address to the declaration, or just make it a wildcard . 

You edited your shell script with a Windows text editor (never, ever do this if you value your sanity) and as a result it has carriage returns at the end of every line. These are not treated specially by UNIX-like operating systems. To fix the file, run on it. 

Second, WordPress sent explicit instructions to not cache the redirect, so it would not be cached anyway. 

Or you can select some other folder with Browse if you want to select a background image from somewhere as a wallpaper. 

will undo the transaction listed. If you don't have a working on your system, then you've damaged it beyond reasonable repair and should restore from backup. 

The firewall entries and the CIFS errors have no obvious relation to each other; they occur way too many minutes apart. And besides, that traffic was blocked. 

It looks like you've used MySQL packages from the IUS community repo. Unfortunately these packages don't appear to be 100% compatible with the original packages, and so you get broken dependencies such as this one. Remove all of the existing MySQL packages first (your databases won't be touched) and then install the packages from the remi repository (which ARE compatible and have no dependency issues). You also need to be sure you have disabled or removed the conflicting repo (IUS). 

Don't just disable IPv6 entirely; this will cause you problems later when you roll out native IPv6 into your datacenter. 

This is not a technical question, and the answer is not technical either. I colocate servers in a datacenter which is regularly audited for PCI-DSS and SAS-70 Type II compliance. My agreements with them specify that they will treat my data confidential (the same as theirs). You need a legal agreement with the datacenter or managed service provider you do business with that they will not swipe your customers' data off your server, and you will need copies of their PCI compliance audits to provide to your own auditors, when they show up. 

You are not running into the long standing issue with using with . You simply aren't using at all in the appropriate . Thus the document root is inherited from the level above. You can either add the directive to the block, or make it a nested as in the answer you linked to. 

This generally means that the client opened a connection, but then disconnected after receiving a response to its previous request. It can also be a client that connects and then immediately disconnects without sending anything. Since the web server was expecting something, it logs a bad request (HTTP 400). These are mostly harmless. 

Don't attempt to set the environment variable on the remote host. This is set automatically by ssh and should not be changed. 

Only a few hundred megabytes, and your disk will be full again. You said you expected to have much more disk space than this shows, so I would recommend you contact Linode to find out what's going on. 

This gives you plenty of room to process both normal traffic and spikes of up to 5x your normal load. You can raise if you start getting much busier and see log entries about running out of children, but check your free RAM before you do; if you ever get to that point you'll probably have to upgrade the server. 

You can get the original client address of the connecting ELB in the variable , but be aware that this variable was only added in nginx 1.9.7, so you'll need to be running a very recent version of nginx. 

The remote end (i.e. Microsoft) is identifying itself in (or more likely ) by a hostname that apparently doesn't exist. Thus the connection is being rejected since you have in . What you do about it is up to you. If it were me, I'd consider telling Microsoft that they have broken mail servers, though I wish you good luck finding the right person to tell. 

I'm going to say it's a 90% chance it's SELinux related. You can confirm it by looking for entries in . CentOS has SELinux enabled by default. When you run from your PHP script, it is most likely running under 's security context, which doesn't permit outgoing network connections. The quick fix is to allow to make outgoing network connections: 

This example is incomplete and may be insecure; it only demonstrates how your issue may be resolved. Be sure to secure your web server properly. 

It's probably running postfix, not sendmail. The command is provided mainly for cross-compatibility. You'll find the configuration files for postfix in and documentation at the Postfix homepage. 

For the configuration you want, you need to have the virtual machine's NIC use your existing bridge br0 on the host. Unfortunately vagrant-libvirt doesn't seem to support this configuration (it only uses macvtap, which is meant to take over a physical interface completely and doesn't help you here because the host cannot use the interface). I would contact the author of vagrant-libvirt and ask for this functionality to be added. 

Not using official packages. They would attempt to use the same configuration files and data directories, which would result in a crash at best, and data loss at worst. If you really want to do this, try using containers. 

Log in with your normal user account (the one for yourself, that you didn't put in a chroot) and to root, then you can fix the problem. If you somehow managed to chroot your own user account, or never created one in the first place (don't ever repeat this mistake) then you will have to get on the console, reboot to single user mode and recover it from the console. 

The answer for a very long time has been "sort of". Currently the Linux device tree is managed by , a userspace device manager which replaced devfs several years ago. udev populates /dev with any device nodes the system needs, depending on the rules configured in its configuration files. On the newest Linux systems, /dev is in a temporary RAM disk provided by . You could call these virtual. Example: 

If you watch your shutdown process carefully, you will see, after virtually everything has been done, that init will kill anything that's still running. On a Red Hat/CentOS 6 system you'll see: 

In IPv6, addresses in the subnet are link-local addresses, (RFC 4291) and are automatically assigned on any interface on which IPv6 is enabled (which is by default in any modern operating system). These are roughly comparable to IPv4 link-local addresses, (RFC 3927) except that in IPv6, every interface always has a link-local address. These addresses are only usable on the same subnet; they are not meant to be routed, and any halfway decent router will not even make the attempt. They also cannot be disabled; they are used for neighbor discovery, DHCPv6, and various other IPv6 internals. For that reason it's relatively safe to add to your whitelist, to accept connections from any host on your subnet. 

The file just causes the startup scripts to run at boot time, and then reboot again. (Actually it runs some invocation of that prints lots of dots, but since that's just a frontend to I don't care...) You could just run this yourself without rebooting, and that's generally my first step when trying to diagnose a weird SELinux issue. Keep in mind that the reason for the reboot is that changing the security contexts affects running services, so at a minimum you should restart the affected services (i.e. restart sshd). If this does solve the problem, then somewhere in the output you'll see a changed security context which was the cause and resolution of the issue. Most likely it is not in or .