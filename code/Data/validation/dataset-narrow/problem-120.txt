A software application running on a computer is a process. When this application provides some kind of network service (e.g. a web server) clients need to have a way to contact this service over the network. First, they need to have the IP address of the computer to allow the network to transport data packets between the client and the server. Now, since the computer/server can provide many different kinds of network services there needs to be a way to address the desired service on said server. For this, numbered ports are used as a kind of subaddress. Most services have a well-known port number that they usually use, e.g. TCP port 80 for the web server. The application/process is listening to new connections on its service port. Any connection or data comming on to this port is passed to the process by the operating system. When a client wants to talk to the web server it opens a connection - a socket - between any of its own ports to the service's port on the web server's IP address. You can see this in a URL: $URL$ says "open a connection to TCP (implied by HTTP) port 80 and use the HTTP protocol to fetch whatever is there". Since HTTP uses port 80 by standard the ":80" part can be omitted. 

The 3560 uses the physical port that can get a link and deactivates the other as long as the link is up. When both variants can get a link (at power on) the SFP port is prioritized. You can disable the SFP priority with the command. 

The local loop is your home's or business's dedicated connection to the nearest concentrator (often within a PoP). The concentrator basically multiplexes many connections to a single or very few connections and is connected to the ISPs core network, possibly via more concentrators. This follows the general paradigm of the network idea where you connect all nodes in a hierarchical way. Concentrators have been digital for quite a while since digital multiplexing is much easier than analog. Currently (mostly finished), the shift goes away from virtual circuits towards packet-switched networks which are far more efficient. Using packet switching, you can use the simple local loop for countless applications including telephone calls, even simultaneously. 

Q1: yes Q2: for that telnet (obsolete) and SSH can be used in addition to various proprietary protocols, even a COM server connecting to the serial console Q3: telnet is the easiest with (basically) connecting through a TCP socket instead of a serial line - because it's so simple (first defined in 1969's RFC 15), there's no inherent security against password interception, man-in-the-middle attacks or replay attacks Q4: out-of-band access is everything that's not in-band (ie. using the same interface as the data transmissions) - this can be a serial port or a dedicated network port that's not used for data 

Consumer-grade hardware is explicitly off-topic here, but since this is a more general question: all low and practically all medium-grade switches use store-and-forward switching. High-performance, low-latency switches often use fragment-free with fallback to store-and-forward on a port where the error rate exceeds a certain threshold. Note that current fragment-free switches support 802.1Q/ad VLAN tagging and can only start forwarding after having received the VLAN tag(s). Pure cut-through is more or less obsolete. 

Not sure if I got you correctly - normally, you just set up a rule for source/destination as required, without NAT and put it above the SNAT rule. 

This seems to be pretty much out of context... Proxy ARP is required when a non-local destination should appear local to a source. In this case, the source is a router and there is no next-hop route, the destination is supposed to be local to the router. However, it really isn't, so a regular ARP for the local destination would fail (with it being outside the broadcast domain). In this case the (hidden) next-hop router has to reply to the ARP request on behalf of the destination (proxy ARP) to make it appear local. The proxy-ARP router sends its own MAC instead of the destination's, the IP packet is sent to the router and forwarded to the destination. An alternative to proxy ARP would be a static ARP table entry on the source router. Your example doesn't work because the destination is not local to the source router. If instead the source router had a local interface 10.0.1.1/16 and tried to forward a packet to 10.0.2.20 it would assume the destination is local. However, the destination subnet is really segmented into 10.0.1.0/24 and 10.0.2.0/24 and there's a hidden gateway in between. This gateway would have to answer with its own MAC to the ARP request for the destination's IP and then simply forward the packet. Usually, ARP trickery is only required when your network has grown out of proportion or isn't designed reasonably. In nearly all situations, a good cleanup or renumbering would be advised. 

If you connect a repeater hub to the monitor ports you create a network loop. STP will block one port, without STP your network might go down. If the monitor ports are egress only, a switch would be a better solution (see 3.) as it could keep up with the data rate much better. Roughly, there are four solutions: 

SSH is an application protocol running on top of layer 4 TCP. A switch basically works at layer 2, so it doesn't affect SSH at all (unless it has higher layer features that do affect IP, TCP or even higher). If the network is flat (i.e. without VLAN trunking which would be unlikely for an edge port) you don't have to configure anything - neither IP nor MAC addresses will change. You should however check your company policy whether you're allowed to attach network equipment if it's not your job. 

The serial ports are configured incorrectly. You can configure them within 172.21.0.0/16 but each side must have an IP address in that subnet. When RIP is active an the serial interfaces the routes should get across. Without RIP, each router requires a route to the other side's PC subnet through the opposite router's serial port. You can't use the PC-facing IP address. 

Usually the port comes up - due to lack of autonegotiation, the auto side will choose half duplex, resulting in a duplex mismatch. Fast Ethernet uses "fast link pulses", an expanded scheme. Autoneg disabled on both sides leaves only the carrier (pause symbols) to detect the link. FDX/HDX will be as set up, potentially mismatching. 

As Ron wrote, routers just check and drop errors, there's no correction. Usually, you leave forward error correction (FEC) to the physical layer where the trade-off between cost, performance and reliability is best decided. For Ethernet, 10 GbE introduced optional FEC which has become mandatory for many faster PHYs (because with growing speed it gets harder and harder to reliably transmit error-free data without FEC). The Ethernet FCS is a simple checksum on layer 2 which just drops error frames, just like higher layer checksums. 

Unicast flooding shouldn't happen when traffic is flowing in a somewhat predictable pattern. Switches learn MAC-port associations by the source addresses of frames running through them. When there's been no traffic from a certain MAC address for the MAC-aging period the table entry is dropped. The next frame to that MAC is flooded to all ports, emulating a repeater hub. To avoid active MACs being aged out you need to either raise the MAC-age period so that there's traffic from each source address within that period or you make sure that each active source MAC does send traffic within the period by e.g. sending a broadcast that will update all switches in the broadcast domain. Unless you run some delicate L2 load-balancing, a very high edge fluctuation or similar it usually doesn't hurt raising the MAC-aging to one or more hours. 

Network connections generally are usually many to many - the whole point for a network -, only rarely point to point. Nodes with the same subnet address need to be located in the same subnet. 192.160.2.4/24 and 192.160.2.6/24 are located in the same subnet, so they must be connected by a common switch & VLAN. When the server interfaces are bonded and you need two connections to distinct(!) subnets you need to unbond them and configure them separately and you must separate the router subnet. Whether the server NICs are bonded or not, when connected to the same subnet, both routers need to be connected to this subnet as well. Then, which router is selected for an external IP depends on the local routing table and its metrics. The server interfaces require unused IP addresses from the same 192.160.2.0/24 subnet as the routers, at least one when bonded and at least two when separate. By default, the server would try to reach either router through any of its interfaces. For a layer 3 topology your chart might make sense (with unbonded server NICs and accordingly set routing table). Connecting this way on the physical layer (wiring) would be cumbersome at best. 

Since a routed packet carries the router's MAC address as source in its frame: no, that's not possible. Layer 2 doesn't have enough information to filter L3 traffic. However, if everything happens within the same L2 segment/VLAN you can filter out the source MACs you don't want. You'd have to include all (non-filtering) routers as they could be used to circumvent the filtering. That being said and from your comment: many layer 2 (=non-routing) switches can also filter by layer 3 and 4 information - it depends on the specific hardware. 

There's no real 'SFP25' standard, there's only SFP28 (SFF-8402). Since only the SFP-10G-SR seems to work in the switch: are you sure the port is SFP28-compatible and the rate isn't limited to 10G? Many vendors limit the choice of transceiver to their own brand. So, the Dell NIC might only work with Dell transceivers (or 'compatible' ones faking the brand). However, this doesn't seem to be the case as both transceiver speeds work in the server but only the 10G in the switch. Edit: Another thought: you're within spec with the MM fiber, aren't you? OM2 is fine for 80 m with 10G, but probably only 20 m or so with 25G (unspec'ed). OM3 should go 70 m and OM4 100 m. 

A switch buffers frames - this is in contrast to a repeater hub that can't buffer anything. As @jcbermu has pointed out, both frames from A and B are first stored in their respective ports' receive buffers. The frame that is received in completeness first is then transferred to port D's transmit buffer and transmitted to D. The second finished frame is also transferred to port D's transmit buffer but since the port is currently transmitting it is just queued and sent out once A's frame is finished. A switch normally uses a first-come-first-served principle. When priorities and QoS come into play the switch uses multiple transmit buffers for each port where higher priority frames are generally transferred first (depending on implementation). When the total ingress flow for a certain destination port is faster than the port can transmit for more than a very short period (microburst) the queue buffers quickly overflow and the switch drops packets. 

"Modem" is a portmanteau word for MOdulator/DEModulator. In a nutshell, digital data is modulated into an analog signal by the transmitter, transmitted over a line, and demodulated back into digital data on the receiver side. There are numerous ways to do this, depending on what kind of transmission line you have. 

In addition to the network-centric answers already present, you should alternatively be able to change the MAC address in Linux using : 

Note that I'm using "hub" in the figurative sense as a central traffic connector, not as in "repeater hub". A wireless access point works more like a bridge than a repeater. 

To answer your questions: PC1 looks at its local routing table and decides it needs R1 to reach the web server. It uses the server's IP address as destination but as destination MAC address for Ethernet transport it uses the router's MAC. The router looks at the destination IP address and decides to forward the packet out of the interface facing the web server. Since it's an Ethernet interface and the destination IP is local to the segment it'll ARP the IP address of the server and use the MAC as destination. 

Many routers have an integrated switch (with a few ports) or ports that can be configured as one or more switching groups. SOHO routers very often have a single switch group that can't be separated. Think of it as a switch connected to a router port in a single case. When you connect devices to ports in the same switching group they belong to the same L2 segment and (usually) to the same L3 subnet. Different switching groups or separate (true) router ports mean separate L2 segments and accordingly, separate L3 subnets. Communication across separate L3 subnets requires routing - you can either use the router in your diagram or add another one that's connected to both subnets. 

very early, low-complexity copper connections for new speed grades short, low-cost, low-overhead connections 

802.1Q allows different 4094 VLANs, 0 and 4095 are reserved and can't be used. QinQ (802.1ad) defines inner and outer tags, theoretically allowing 4094^2 VLANs. Shortest path bridging (802.1aq) uses 24 bits for the VLAN ID, allowing 16 million VLANs. VXLAN is a slightly different technology in that it tunnels over UDP/IP. This produces much more overhead, eating into the MTU or requiring baby jumbos. The upside is that the tunnel can be routed, the difference to other tunneling protocols being the integrated VLAN service, so a single tunnel can link virtually unlimited L2 segments. Essentially, you can use any L2 tunneling protocol instead of 802.1Q VLANs - of course, a tunnel wouldn't be as light-weight, as easy to use and usually only point-to-point. In a completely different approach (and probably more to your intention), you could set up locally administered addresses (LAA) on your NICs, dedicating a few bits to the "VLAN ID" and use MAC-based wildcard filtering on the switches - if you can find switches supporting this. However, since the MAC address and thus the "VLAN ID" originated on the client (instead of the VID on a switch) there wouldn't be any significant security.