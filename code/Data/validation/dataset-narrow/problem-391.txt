Does anyone here know if there are any tools, not using mysql's built in replication that will sync up two databases when the slave has been inaccessible from the internet for extended periods of time? The idea is to set up a virtual machine basis for our web developers, who can power on the VM and have it automatically clone from a slave of the production DB for the purposes of testing/development. they all require their own DB's but they should all replicate the master DB on startup. Diagram of operation: Production DB -> Production Read Only Slave -> Dev Virtual Machine 

I would have thought that databases would know enough about what they encounter often and be able to respond to the demands they're placed under that they could decide to add indexes to highly requested data. 

My question is would I go about setting up the following?: First Server (master) -> Second Server (slave) -> Third Server (slave) Tutorial links welcome! I tried to Google, but I'm sure I've gotten the wrong keywords 

I have two tables which I'm trying to reconcile the differences of in postgresql. Table A is old and needs updating. Table B is an updated, schema identical version of Table A which I have the data for in a temporary table in the database of Table A. Unfortunately some time after the two databases diverged someone changed the UUIDs of records in table B and I need table A to match table B. The schema for both tables is: 

I have found the problem which was that the databases started by the Windows service manager were started with a user that appears not to have sufficient permissions. This is confusing since I have selected the default setting while installing to use Oracles virtual user. This virtual user seems not to have write permission to some files of the database. I have changed the user by which the services are started from Oracles virtual user to the Windows "Local System" option. Since that both databases are running seemingly fine. 

The said file does in fact not exist. But such a file does also not exist for the other database. The directory contains a though for both databases. As far as I know oracle uses this pattern when starting the database. If cant find said file it goes on to use . I have created a INITDBNAME.ORA file and added the content: 

EDIT The Mirosoft Service Manager reports both inscantec as runngin. Setting ORACLE_SID does not make any difference. After the installation of both instances I can connect via 

I would like to create a trigger before inserts and updates to ignore any value given by these statements and instead use the next value in sequence - as if no value was defined in that statement. I don't want to use since this throws an error. I would rather ignore any value given and use the next possible value. What I am looking for is a way to identify the sequence used for this identity ans use in a before-insert/update trigger. In this article a SQL statement is given to get the name of the sequence that is used for the identity which I maybe could use within the trigger (???) but the statement doesn't work for me: 

I need to search through Table A and Table B and match records based on template_folder_uuid_parent and heading, then set the UUID of the Table A record to the UUID from Table B. Once changed in Table A the UUID will cascade correctly. 

Basically part of our Postgresql table is used to keep server access logs, and as such sometimes during production this can get pretty large. is there any way of setting in postgresql to have a maximum number of records a table can have and to push off the oldest record? 

Basically I have one (for now) mission critical postgresql database that I will need up to the minute recovery for, I've never implemented a working WAL archival before so I would like to know what is the best way to do this. The machine we are going to backup to is remote, and we have ssh keys set up, so I was going to have the WAL's rsync'd over. Is that wise with that archive_command option? A Step by Step guide with examples on how to set these things up would be amazing as I couldn't find one I understood (I'm not a DBA) 

Using pgBarman, This was really easy as it walked me through it all, plus it's open source! I stumbed upon this while googling link to pgBarman tutorial (pdf) link to pgBarman site 

I want to automatically check for null ID's over all id columns in my database, I have to check all tables of which there is about 50,000 so manually doing this is infeasible 

But this goes well only for a short time. After couple of minutes it starts to throw ORA-01110 when I connect to the first instance. The data files are not missing. They are in the location in which Oracle reports them missing. 

If the statement would work I would have the sequene name as a string but I guess I would need the object itself to request the nextval. Is a trigger the right way to go or should I look for something else? For Oracle 11g I have implemented this functionality using trigger and sequences. The trigger looked like this for inserts: 

I have installed Oracle 12c R2 on my local Windows 10 (64 Bit) machine. For the installation I choose only to install the software. After the installation I have used the tool that comes with the installation to create databases. After the first database was created and started I was able to connect to it without any problems. But after I created a second database and restarted the machine only the newly created database was started. The first database is not started on boot and I cannot start it using sqlplus. I get the error 

error. Also confusing was that if the pfile was inside the Oracle Directory the command failed saying it cannot access the file. EDIT After I have deleted both instances, rebooted and created both instances again I can currently access them both. When I try to login to the first instance I get the following error: