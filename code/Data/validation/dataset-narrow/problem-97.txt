Here pair 1 consists of fiber 1 and 2 and so forth. To make sure you have them crossed in relation to the patch cable, the LC connector houses are turned away from each other in both ends. For instance, at the primary wiring closet, you turn the connector right and in the secondary you turn it left. That way the connection will be established without the need to break the duplex cables, when they come gathered. Crossover example: 

The Nexus switch will use the vPC link as a normal layer 2 trunk if it's the only way to get the traffic to the destination. Cisco has made the Nexus with the intent to prevent bridge forwarding looping and duplicate packets, to make Layer 2 work correctly without needing Spanning Tree Protocol (STP) to do so. The exception is, if the end hosts are individually connected to either one of the Nexus switches without any redundancy. In your case, if the primary firewall is only connected to one of the Nexus switches, then it will utilize the vPC link to carry traffic to it. vPC technology provides sharing of: Control plane, configuration and consistency check, vPC advertisements, Spanning-tree, HSRP, IGMP and MAC address tables. All this information is encapsulated in standard Ethernet frames and only sent out on the vPC link. All frames are tagged CoS = 4 for reliable communication. Good read: $URL$ Cisco official vPC design guide document for all Nexus switches: $URL$ 

On a Nexus environment you need to update both kickstart and system image when upgrading to a whole new software train. Currently version 7.1(4)N1(1) is safe harbor. Under hardware, you can see which specific version, your Nexus is and thereby find the correct software on Cisco download center. 

Packets only traverse Internet backbones hosted by commercial, government, academic and other high-capacity network centers. The Internet exchange points and network access points, that exchange Internet traffic between countries, continents and across the oceans only route your packet, if it needs to go outside your country. Internet service providers, often Tier 1 networks, participate in Internet backbone traffic by privately negotiated interconnection agreements, primarily governed by the principle of settlement-free peering. 

Every Cisco ASA platform comes with a certain number of implicitly activated features and capacities as a part of the Base License. In other words, these capabilities are fixed in the given software image for the particular hardware; you cannot selectively disable them. One example of such a feature is Active/Active failover, which is always available on all Cisco ASA 5585-X appliances. Some platforms offer the optional Security Plus license, which may unlock additional features or capacities on top of the Base License. For example, you can increase the maximum concurrent firewall connection count on the Cisco ASA 5505 from 10,000 to 25,000 by installing a Security Plus license. Source and all optional licenses/features explained here. 

Power consumption on Cisco's new 3650 platform is very variable. It all depends on traffic flow, PoE and utilization of ports on the switch model. Cisco has made a Power Consumption table, which shows different usage for different scenarios. It's available via the provided link. Picture is for future reference. Remember to add your inline power of Access points, IP phones or cameras. It is not possible to show the live power consumption via IOS. Source: Look for table 12 

Source: $URL$ Tunneling Tunneling is a method used to transfer a payload of one protocol using an internetwork transportation medium of another protocol. The data that need to be transferred are typically frames/packets belonging to a certain protocol (different to the protocol used to send data). Because of this, the payload cannot be sent as it is produced by its origin. The frames need to be encapsulated in an additional header, which provides the routing information necessary to transmit the data correctly, before sending. A tunnel (a logical path, which interconnects the end points between that the frames must travel) is created and the frames are routed between the tunnel endpoints through the internetwork. When the encapsulated packets reach the destination end point of the tunnel, they are de-encapsulated and the original packets contained inside are sent to the intended destination. This overall process including the encapsulation and de-encapsulation is called tunneling. Both Layer 2 and Layer 3 (of Open Systems Interconnection Reference Model) use tunneling. Typical Layer 2 tunneling protocols are PPTP (Point-to-Point Tunneling Protocol) and L2TP (Layer Two Tunneling Protocol). Layer 3 usually uses IPSec tunnel mode as a tunneling protocol. Encapsulation Encapsulation is the process of encapsulating the packets inside an additional header before tunneling. This additional header contains the routing information necessary to send the encapsulated payload through the intermediate internetwork. This information is essential because the payload is sent through a network (protocol) different to the network in which the data was created. In Layer 2 (which uses frames as the unit of exchange) tunneling, both PPTP and L2TP do encapsulation in a PPP (Point-to-Point Protocol) frame. In Layer 3 (which uses packets as the unit of exchange) tunneling, IPSec tunnel mode encapsulates IP (Internet Protocol) packets with an additional IP header. Difference Tunneling is a method used to transfer a payload of one protocol using an internetwork infrastructure of another protocol. Encapsulation is the process of encapsulating the frame with an additional header so that it can be sent (tunneled) through the intermediate network correctly. Tunneling is referred to the whole process of encapsulation, transmission and de-encapsulation, while encapsulation is only a step within this entire process. However, regardless of this whole-part relationship, tunneling is sometimes also known as encapsulation. 

In the picture above we have a network of four hosts connected to a hub. Since hubs work in the half-duplex mode and each port on a hub is in the same collision domain, packet collisions can occur and CSMA/CD is used to prevent and detect them. Host A detects that there are no other signals on the network and decides to send a packet. However, Host B also assumes that no other station is transmitting and sends a packet as well. A collision occurs and it is detected by Host A and Host B. The sending stations send a jamming signal telling all hosts on the segment that a collision occurred. After a random period of time, Host A and Host B resend their packets. But in more modern Ethernet and especially in todays networks based on Ethernet switching, the collision domain is limited to the connection from the switch to your end device and your transmission of the jam signal would not impact any other devices in the network. Switches work in full-duplex mode and each port on a switch is in a separate collision domain, so no collisions can occur. Source: $URL$ 

Blocking State A LAN port in the blocking state does not participate in frame forwarding. A LAN port in the blocking state performs as follows: 

TCL has only recently become available on the Cisco CSR1000v. NX-OS TCL support with High Availability is available on Cisco IOS XE Denali 16.3.1. Release notes: $URL$ 

I think it always makes sense to summarize or supernet your IP addresses. Supernetting is also known as CIDR (classless interdomain routing) as defined by RFCs 1517, 1518, 1519, and 1520. In IPv4, CIDR is one way of attempting to manage the shortage of TCP/IP addresses until IPv6 takes over. ISPs frequently use supernetting to allocate IP addresses most effectively. There may be scenarios where you have many LANS, WLANs, or VLANs that might be optimally suited for supernetting to best administer your network needs. Keep in mind that supernetting introduces complexity to network administration that needs thorough planning, testing, documentation, and administrator competence. Most new routing equipment and current operating systems support CIDR in their implementation of the TCP/IP protocol. However, before a supernetting implementation, it is critical to ensure that all components of your network are supernetting-aware. This includes operating systems, network services, routers, routing protocols (RIP2, for example does not support CIDR), and any network-based services used on your network. 

Converting my comment to an answer. VSS uses the supervisor tengigabit links to create the VSL. When implemented the configuration is made by VSS and cannot be changed. Traffic will be load-balanced only if necessary and no matter if it's layer 2 or 3. VSS uses Interchassis stateful failover which results in no disruption to applications that rely on network state information (for example, forwarding table info, NetFlow, Network Address Translation [NAT], authentication, and authorization). VSS eliminates L2/L3 protocol reconvergence if a virtual switch member fails, resulting in deterministic subsecond virtual switch recovery. Note that the data planes of both chassis are active and hence forward traffic at full combined capacity of 1440 Gbps. 

Here on it's pretty much straight forward if you have read the above on AutoQoS. Class maps and policy maps We need to create class maps to match the ACL's. You need to use the match-any statement otherwise it wont work. This is because we want to check all lines in the ACL and match the traffic. If a match is found the traffic will be marked. All traffic that is not matched will be put into default. 

As long as you cross the cables as shown on the pictures it does not matter if you start with A to B or B to A when you finish off the stack. You should prioritize your switches, so that you know who will be master if a switch breaks down in the stack. For instance i would: 

The list of available file systems differs by platform and operation. Refer to your product documentation or use the EXEC command to determine which prefixes are available on your platform. File system prefixes are listed as following: 

Cisco's complete guide to config register commands/use on ALL routers: $URL$ Personally i've only made use of changing the config register in practice a few times, mostly password recovery on the old Cisco 2600 and 2800 Series Routers. Once i had to fiddle about with the baud rate in order to send a file faster to a router via console. 

The picture clearly shows a routing protocol between the routers and the 3560 switches, but for clarification, HSRP is configured as follows: The standby ip interface configuration command activates HSRP on the configured interface. If an IP address is specified, that address is used as the designated address for the Hot Standby group. If no IP address is specified, the address is learned through the standby function. You must configure at least one Layer 3 port on the LAN with the designated address. Configuring an IP address always overrides another designated address currently in use. When the standby ip command is enabled on an interface and proxy ARP is enabled, if the interface’s Hot Standby state is active, proxy ARP requests are answered using the Hot Standby group MAC address. If the interface is in a different state, proxy ARP responses are suppressed. Example: 

Core: Cisco 897 series, Cisco 3650 Series, Cisco 3850 Series and Cisco 6500 Series Access: Cisco 3560CX Compact series and Cisco 2960X Series 

I've run out of lines after adding some content to my answer. Apparently 30000 lines is the limit. This is why i've added an additional answer: Marking incomming traffic based on port/type Introduction This section will cover how to mark incoming traffic using access lists to check the source port or type. The difference from the above examples are, that by using access lists you can decide specifically what you want to prioritize through your network. Where AutoQoS gives priority to the 'most common' protocols and types of traffic, this example gives you total control to design QoS as you like. The idea is simple: detect and remark traffic coming into your network from hosts. Transport the marked classes throughout your network. Prerequisites Before you configure QoS as explained below you must have a thorough understanding of how it works and take notice of the following: 

Converting comment to answer. With HA the Fortigate needs to be the same model, as you already have. When using VRRP it allows you to use different hardware or even upgrade one Fortigate and still run redundant. Nat doesn't run faster or slower depending on your redundancy model. 

The left picture is the primary wiring closet. The right picture is the secondary wiring closet. This way you are 100% that all connectors are crossed. 

Upstream bridge sends a proposal out of a designated port. As a matter of fact, it just sets the proposal bit in outgoing configuration BPDUs. Downstream bridge receives the proposal, and if it agrees with the upstream port role, it starts the process known as synchronization. Synchronization implies the downstream bridge blocking all non-edge designated ports, prior to sending an agreement to the upstream bridge. Synchronization is needed to make sure there are no loops in the topology, after the upstream bridge unblocks its designated port. If the downstream bridge does not agree with the proposal, it will continues sending it’s own configuration BPDUs with the proposal bit set. Eventually one of the bridges will accept the superior information and send an agreement.