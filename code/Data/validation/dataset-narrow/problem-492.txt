Below is included some example code to demonstrate the usage of . I'm less interested in feedback on the example code, but it is of course still welcome. main.cpp 

Squash the bug! I don't know the cause, but your program appears to loop forever when I give your algorithm the sequence: 1,8,4,6,5,2,0,3. This is almost certainly not desired behavior. Code Simplicity Return the new pivot You can avoid taking the pivot by reference by changing to return the pivot value. The new function signature would be: 

End-brace comments are unnecessary In general, you don't need to add a comment at the end of a block indicating what just ended, like this: 

Using functionality already present in OpenCV is not only clearer and shorter (by a factor of 3), but also allows the code to be more flexible. You will notice: 

This is my first attempt at writing custom iterators, so I am interested in feedback on correctness and general points to improve. It seems like my use of is suspect, but I don't know if I can avoid it. Here are the class definitions: RowRange.hpp 

And then simply at the end of the function. But then this function signature looks familiar: Use the standard library, Luke! There already exists a function in the standard library. You can replace your entire function with it, and simplify : 

organization It is a good idea to keep your standard library directives sorted alphabetically. This makes it easy to spot duplicates, or to add new dependencies in the right position. is for constants C++11 introduces , which you should use to declare a true constant: 

You could change the to a and increment and in the increment statement, but I find this more readable. Writing it this way also makes it explicit that there is a loop over each of your string arguments, which makes analyzing complexity much easier. But wait! All that iterator comparison is complicated. Wouldn't it be nice if there was another way? Turns out, there is , which is essentially what the inner loop does. Then the loop can be simplified: 

instead of using and , which I find more difficult to understand. portability Your functor assumes that will call it in order starting with and ending at . This is not the case: does not guarantee a particular iteration order. Since C++ doesn't allow you to zip ranges easily, the best portable equivalent I can come up with is this: 

I think that's 16 pixels, but it's a good plan. The pack instructions were used inefficiently (in the linked question that was not really an issue) and that would be improved by processing more elements simultaneously. For example, something like this: 

How much you should unroll by depends a lot on the precise code and the actual processor. For example on Haswell the initial target performance would be 2 FMAs per cycle (so unrolling by a factor of 10), but that would mean the kernel cannot come from memory since both available loads are needed for the image, limiting the performance to half the target performance. Getting to 50% of the goal isn't great, but there is hope: after unrolling, multiple iterations can share the same load from the kernel. That load can be a wide load, and instead of the appropriate element for the iteration can be shuffled into all lanes. This alone can reduce the number loads from the kernel to a quarter of the original (or an eighth, with AVX). And there is more: unrolling a different way. If multiple unrelated convolutions (different rows) are interleaved, the load from the kernel can be re-used for each of them. If you do 4 of these, you could try doing an in-register transpose (there is for that, which is more of macro than a proper intrinsic) and then just using 4 wide stores. That transpose is fairly ugly, weighing in at 4 unpacks and 4 movelh/hl's for a total of 8 Âµops to port 5, but it turns 16 scalar stores into 4 wide stores so that looks like a decent trade. With all this unrolling it's easy to go too far, running out of registers and spilling to the stack in the inner loop would just murder the performance so definitely avoid that - always check the assembly (you don't have to write it, just read). Unrolling by a total factor of 8 or 10 is probably OK, both in terms of being enough to reach (or get close to) the latency-throughput product and in not exceeding the number of available registers. So for example 4 rows and 2 iterations of the inner loop makes a factor of 8. Unrolling the inner loop depends on the kernel being a nice size, if it isn't then part of the last iteration is wasted work since it's partially multiplying data by the kernel-padding. So unrolling rows may work out better in general. 

Short variable names like , , and aren't very descriptive, and make it hard for others to understand the code. Try to pick more descriptive names. Make sure you don't include unnecessary logic. For example, your check will always be , since you only insert tuples, and is a float. It can be removed, saving you a line of code and a level of indentation. 

This clutters the code. It should be obvious what each block is doing. If it isn't obvious, you probably have too many nested blocks. Which means... Create a method for the inner loop Your inner loop over the vector can be succinctly extracted to a function of its own. Creating a function allows you to give a descriptive name to what you're doing, and limit the scope of variables. It also makes the outer loop easier to read and understand. I have rewritten the inner loop into its own function that makes use of standard algorithms. It is slightly less efficient than your original method, but improves immutability, readability, and simplicity of the outer loop. 

In addition to Nobody's excellent answer, there are some other improvements which can be made. Header organization Order your headers alphabetically -- it becomes easier to remove duplicate includes, and is just more organized. -correctness Mark variables and function parameters which are only read as . This guarantees they can't be accidentally modified, and makes your code easier to reason about. Additionally, you do not provide overloads for your and functions, which you should do. Currently it is impossible to use these methods on a object or reference. Iterator typedefs It looks like you want to treat as a container type. In that case, you should add iterator typedefs like those found in standard-library containers, since some algorithms may depend on their existence. For example, 

Code Style Whitespace and Braces Be consistent in your usage of whitespace and braces. and statments should have a space between the keyword, parentheses, and opening brace (if using K&R style braces). Also, don't omit braces in an , then include them in the . For example: 

Uses the operator, which bidirectional iterators do not support. Calling your sort on a will fail to compile. You can make your code compliant with bidirectional iterators by changing the above line to: 

There are some issues, such as not using obvious built-in solutions, an inefficient algorithm and what looks like a logic error possibly caused by having odd array-growing logic. I'll start with the error. In you assume that there are at least two numbers. That may not be true, if the user immediately enters 0 - which raises the question of what the GCD of the empty set is (0 or 1, depending on who you believe), but whatever it should be, it's bad form to crash with an out-of-bounds exception. The odd array-growing logic is probably part of that problem, it leaves a spurious 0 in the array which you thereafter actively ignore - it's simpler to not have it there to begin with. Anyway, you wanted an array that can change size - that's usually called which, conveniently, already exists. You can also avoid saving up the input entirely, by computing the GCD while reading the input. The GCD algorithm is strange and inefficient. It's not the familiar GCD algorithm, which is already a strike against it by itself since that makes it hard to tell what it's doing, and there is no redeeming quality. This is an algorithm with a very bad worst case, as much as O(min*N) (if the GCD turns out to be 1). I strongly recommend using the modulo-based version of the Euclidean algorithm, which is efficient and recognizable, or maybe Binary GCD if you want something different. In the unlikely case that you rejected it because it takes only two inputs, of course and so on, so you can simply loop over your input and call GCD on the gcd-so-far and the number from the input. Or, as mentioned, you could compute the GCD while reading the input, something like this: 

That doesn't really address the SSE2 side of the store directly, but you can do the same thing but with separate add/mul. Proper use of AVX would use the wider vectors. For this code that's a fairly trivial change, just make almost everything wider (except the matrix). If AVX is available, you should use it in this case - it doesn't help for everything, but for this type of code (almost purely vertical SIMD, apart from some broadcasts) it's great. FMA is also a free performance win here (especially on Haswell and Broadwell), well worth using even if it means writing two versions and doing runtime dispatch to also support the Bridges (which are perhaps not old enough yet to completely disregard). Supporting 32bit machines is annoying. They don't even have enough registers to load all of that matrix, so everything gets bogged down by the extra loads that are suddenly required. I don't see good fixes. Rearranging the multiplication so that the matrix can be held in 4 registers does work, but then a horizontal addition appears which is bad, and the multiplication wastes a lane on padding. I expect it would be worse than the extra loads, on the other hand if we're talking about old hardware like Core2 (which had x64 support, but at the time installing a 64bit OS was a rarity) then extra loads are extra bad since the load throughput used to be only 1/cycle. On the other hand, horizontal addition also used to be much worse than it is now. It just seems like all options are terrible. It depends on your audience of course, but frankly I don't think it's worth expending much energy on.