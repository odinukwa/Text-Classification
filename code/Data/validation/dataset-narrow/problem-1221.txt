For arbitrary $b$, Alon, Babai and Itai showed a lower bound on the probability space size of $m(n,\lfloor k/2 \rfloor)$ where $$ m(n,k) = \sum\limits_{i=0}^k \binom{n}{i}$$ which is $\Omega(n^{k/2})$ for constant $k$. They also gave a construction of size $O(n^{k/2})$ in the case of $b = 1$. For $b=1$ there is a paper by Karloff and Mansour which shows lower bounds and upper bounds for arbitrary probabilities, i.e., for $p_1,\ldots,p_n$ with $p_i = P(Y_i = 1)$. E.g., there are probabilities $p_1,\ldots,p_n$ such that the probability space size is at least $m(n,k)$. They also say that $m(n,k)$ is also a upper bound for arbitrary probabilities. I don't known any construction with a better upper bound than $O(n^k)$ which is given by the construction (see here) mentioned by Thomas as a comment. 

Perhaps I'm missing something but I think there is a good lower bound with the probabilistic method: If you color each vertex indepedently with probability $1/2$ for each color then your have a monochromatic edge with probability $2 \cdot (\dfrac{1}{2})^k = 2^{-k+1}$. With the Lovasz local lemma you get that the shift-chain has property $B$ if $$k(n-k)+1 \leq \dfrac{2^{k-1}}{e}-1.$$ I can't directly solve this inequality but if you have $k = \Omega(\log(n))$ then you get on the left hand side somethink like $n \log(n)$ and on the right hand side $n^c$ (so the inequality is true for $n$ large enough). There is a better bound of $O(\sqrt{k/\ln(k)} \cdot 2^k)$ on the number of edges for a $k$-uniform hypergraph so that the graph has property $B$. 

There is an interesting and promising new community-based project for a graph database: Introducing paper The Open Graph Archive: A Community-Driven Effort or the direct link Graph-Archive.org Time will show if it is a good place to go for test instances. 

I don't know how you can get or see the bound of $\sqrt{(t+1)(n-t+1)}$ from the original bound $\sqrt{n(n-\vert (2(t-1) -n+1 \vert )}$ but here is the proof that this bounds are asymptotically equal up to a constant factor: First see that (I exclude $t = 0$ because the threshold function is always $1$) $$ n(n-\vert (2(t-1) -n+1 \vert) = \left\lbrace  \begin{array}{ll}  n(2t-1) & 1 \leq t \leq n/2+1/2\\ n(2n-2t+1) & n/2+1/2 \leq t \leq n-1 \end{array} \right. $$ Define $f_1(t) = n(2t-1)$, $f_2(t) = n(2n-2t+1)$ and $g(t) = (t+1)(n-t+1)$. Now you have to calculate the maximal value (according to $t$ within the defined intervalls) of the fractions $f_1(t)/g(t)$, $f_2(t)/g(t)$, $g(t)/f_1(t)$ and $g(t)/f_2(t)$. You can do this with differential calculus or approximation with the help of the graph (with $n$ large enough): $f_1(t)/g(t) \leq f_1(n/2+1/2)/g(n/2+1/2) \leq \dfrac{n^2}{n^2/4} = 4$ $f_2(t)/g(t) \leq f_2(n/2+1/2)/g(n/2+1/2) \leq \dfrac{n^2}{n^2/4} = 4$ $g(t)/f_1(t) \leq g(1)/f_1(1) = \dfrac{2n}{n} = 2$ $g(t)/f_2(t) \leq g(n-1)/f_2(n-1) = \dfrac{n/2}{n/3} \leq 3/2$ This gives you $$n(n-\vert 2(t-1)-n-1\vert) = \Theta((t+1)(n-t+1))$$ and also the wanted result $$\sqrt{n(n-\vert 2(t-1)-n-1 \vert)} = \Theta(\sqrt{(t+1)(n-t+1)}).$$ Is there an easier way to see/get this result? 

Sorry this is too long for a comment :) Maybe the complete graph is a trivial graph but it illustrates that e.g. graphs $G = (V,E)$ with large cliques of size $\Omega(\vert V \vert)$ also have exponentially many $0$ obstructed induced subgraphs. And I don't think that $N$ can be easily computed in such graphs. I also think that 3-regularity doesnt help: Let $A$, $B$ be a partition of $V$ each of size $\vert V \vert /2$. The induced subgraph consisting of nodes from either $A$ or $B$ is a cycle and the edges between $A$ and $B$ form a perfect matching. This graph is $3$-regular and every induced subgraph consisting of at least all nodes in $A$ or all nodes in $B$ is $0$ obstructed. 

Now, regarding the number of facets needed to describe $T$. First, I believe your conjecture "for any $N$ there is a graph for which $T$ has more than $N$ facets" is not true. What we can show is that $T$ has finitely many facets, because the projection cone $W$ has only a finite number of extreme rays, and these generate all the facets (unfortunately, usually many more inequalities too). Note, however that this alone does not disprove your conjecture. However, that this still allows the number of facets to be exponential, and curiously this is precisely the case. At least for directed graphs, I seem to have a proof somewhere that for the complete bipartite graph $K_{n,n}$ on $n$ nodes with $n$ distinct source nodes in one partition and $n$ distinct destination nodes in the other and capacities all equal to $1$, all the $\{0,1\}^n$ vectors $b$ except for the all-zero vector generate a facet $\sum_n b_n t_n \le q$ for some appropriate $q$, and this gives you $2^{n}-1$ facets. I don't know about the undirected case, the above may either hold or not hold. For $K=3$ in particular, this gives 7 facets (plus the non-negativity conditions, but that's trivial) for $K_{3,3}$ in the directed case. As far as I can work it out now, the same applies to the undirected case as well. I have fairly good reasons to believe that this is in fact the upper bound for the directed case, but I may be completely wrong here. You can find an awful lot of results on this topic in Schriver's heroic survey: Alexander Schrijver: Combinatorial Optimization - Polyhedra and Efficiency, Volume 3, Part VII, Multiï¬‚ows and Disjoint Paths Should you have any comments, results, or further reading (apart from my own papers) on this topic, count me very very interested. 

Associated with any capacitated graph $G$ and set of source-destination pairs $(s_k, d_k): k \in 1, \ldots, K$, there is an "aggregate-flow set" $T$. This $T$ is a polyhedron and it is well-defined. You can see this for yourself by considering the following construction: take the multicommodity-flow polytope (i.e., the polyhedron of the feasible arc-flows or path-flows) and apply an affine mapping that to each commodity orders the sum of the individual flows. As affine maps of polyhedra are again polyhedra, you get the required result. If $G$ is connected and the edge capacities $c$ are strictly positive, then $T$ is a full-dimensional, compact, convex polyhedron in $\mathbb{R}^n_+$ (so it is in fact a polytope). $T$ is down-monotone: $t \in T \Rightarrow \forall x \in [0, t]: x \in T$. You can obtain all the valid inequalities that describe $T$ using the Japanese Theorem due to Onaga and Iri: for any non-negative weight set $w_{ij}: (i,j) \in E$ on the edges $E$ of $G$, the inequality: $$\sum_{k=1}^K \beta_k . t_k \le \sum_{(i,j) \in E} w_{ij} c_{ij} $$ is valid for $T$, where $\beta_k$ denotes the shortest path distance from $s_k$ to $d_k$ for commodity $k$ over the weights $w$, $t_k$ is the aggregate-flow for the $k$th commodity and $c_{ij}$ is the capacity of edge $(i,j)$. In fact, you get all the valid inequalities for $T$ this way. Any weight set that is not an extreme ray of the below projection cone $W$ generates redundant inequalities for $T$, where $$W = \{(w,\beta): \forall k, \forall P \in \mathcal{P_k}: \sum_{(i,j) \in P} w_{ij} \le \beta_k, w \ge 0\}$$ where $\mathcal{P_k}$ denotes the set of all paths between $s_k$ and $d_k$. This sort of answers your second question. 

In a nutshell, the time hierarchy theorems say that a Turing machine can solve more problems if it has more time for computation. In detail for deterministic TM and time-constructable functions $f,g$ with $f(n) \log f(n) = o(g(n))$ it is $$ DTIME(f(n)) \subsetneq DTIME(g(n))$$ and for nondeterministic TM and time-constructable functions $f,g$ with $f(n+1)=o(g(n))$ it is $$ NTIME(f(n)) \subsetneq NTIME(g(n)).$$ There are a lot of (old and current) results which use the time hierarchy theorems to prove lower bounds. Here are my questions: 

R. Moser and G. Tardos: A constructive proof of the general Lovasz Local Lemma In general the lovasz local lemma is used to (noncronstructively) prove the existence of some (combinatorial) object. Moser and Tardos showed that you can efficiently find this object with a very simple algorithm (in most applications of the LLL). Great result and nice paper! 

There are a couple of randomized parallel algorithms for the maximal independent set problem, e.g. A Simple Parallel Algorithm for the Maximal Independent Set Problem, A fast and simple randomized parallel algorithm for the maximal independent set problem. These algorithms were the (or one of the) first examples where $k$-wise independent events/random variables are used to derandomize parallel algorithms. One algorithm (which is described here in the chapter "Fast MIS v2") works as follows: 

I think the number of true points isn't a good measure to say anything about the size of the smallest decision tree. There is a chapter in Branching programs and binary decision diagrams: theory and applications by Ingo Wegener about the size of decision trees for boolean functions. The size of the smallest DT is determined up to constant factors by the number of leaves of the tree. There is a lemma in the book that says: If you have a DT for a function $f$ with $s_0$ 0-leaves and $s_1$ 1-leaves then $f$ can be represented by a DNF with $s_1$ monomials and a CNF with $s_0$ clauses. So even if you have a function with only a small number of true points, the size of the smallest DT could be very large. So you need small size of CNF and DNF to have a small DT size. There is a upper bound of the DT size with respect to the sum of the minimal number of monomials of $f$ and the minimal number of monomials of $\overline{f}$. Lets call this sum $DCNF(f)$. Then you have the following upper bound for the number of leaves $DT(f)$ of the smallest DT for the function $f: \lbrace 0,1 \rbrace^n \rightarrow \lbrace 0,1 \rbrace$ $$ DT(f) \leq n^{O(log^2 DCNF(f))}. $$ 

Let $X_0, \ldots, X_{2^n-1}$ be $k$-wise independent random $0/1$ variables over a sample space $\Omega$ and $Prob \left[ X_i = 1 \right] = p$ for every $i$ and some $0 < p < 1$. Let assume $n$ is dividable by 2 and $f(x,y): \lbrace 0,1 \rbrace^{n/2} \times \lbrace 0,1 \rbrace^{n/2} \rightarrow \lbrace 0,1 \rbrace$ is defined by $f(x,y) = X_{\vert xy \vert}$ where $xy$ is the concatenation of $x$ and $y$ and $\vert z \vert := \sum 2^i \cdot z_i$. I'm interested in the 1-way 2-party (deterministic) communication complexity of $f$ such that both players know the random sample (out of $\Omega$) which is chosen at the beginning of the protocol, i.e. both players know the current value of every $X_i$. Of course, it is also ok to know something about the expected number of communicated bits. Motivation: At first I think this is an interesting problem :) However, I'm currently dealing with such random functions and want to show some lower bounds for my computational model using communication complexity. 

My first guess would be to do a simple graph transformation and running the shortest-path algorithm on the transformed graph. This way, we could convert angular deviation between two roads into an additional shortest path cost along the path and thusly penalize paths involving heavy turns. The conversion would go along the following lines: say, we are at some node 'n' of degree 'd'. Then, we could substitute this 'n' with a complete graph on 'd' nodes, with each node in this complete graph associated with an edge incident to 'n'. In addition, a 'u-v' edge in the complete graph would have cost proportional to the angle between the edges corresponding to 'u' and 'v'. Exactly how you set the proportion is a matter of taste: I would first try a linear function and experience with different scaling factors. 

This will be a bit long, but please bear with me. First, let me clarify the terminology a bit. I think what you are interested in here are in fact the facets of the polytope (i.e., "the minimum set of irredundant valid inequalities" or the "maximal dimensional faces still distinct from the polytope itself") rather than the faces. Plus, as you write, the object you study is much better called the "aggregate-flow polytope" or, as some authors refer to it, the "demand polytope" or the "throughput polytope". Call this polytope $T$. Here is what I know about $T$: 

What you need is called a "distance oracle". Unfortunately, I am not very familiar with distance oracles, so I can only refer you to the seminal paper due to Thorup and Zwick: Mikkel Thorup and Uri Zwick. Approximate distance oracles. STOC '01, 2001. Here is an excerpt from the abstract: Let $G = (V, E)$ be an undirected weighted graph with $|V| = n$ and $|E| = m$. Let $k$ be an integer. We show that $G = (V, E)$ can be preprocessed in $O(kmn^{1/k})$ expected time, constructing a data structure of size $O(kn^{1+1/k})$, such that any subsequent distance query can be answered, approximately, in $O(k)$ time. The approximate distance returned is of stretch at most $2k - 1$, i.e., the quotient obtained by dividing the estimated distance by the actual distance lies between 1 and $2k - 1$. [...] The space requirement of our algorithm is [...] essentially optimal. According to their results, what you request is basically doable even for weighted graphs: choosing $k=1$ yields a distance oracle of size $O(n^2)$ obtained in expected time $O(mn)$, which can answer your shortest path queries with $1$-stretch in $O(1)$ time! Distance oracles is a very well researched field, so you will be able to dig further I believe. 

You might be interested in Rachit Agarwal's 2011 INFOCOM paper: Rachit Agarwal, P. Brighten Godfrey, Sariel Har-Peled Approximate Distance Queries and Compact Routing in Sparse Graphs, IEEE INFOCOM 2011 From the abstract: [For a] graph with average degree $\Theta(\log n)$, special cases of our data structures retrieve stretch 2 paths with $O(n^{3/2})$ space [...] at the cost of $O(\sqrt{n})$ query time. Note that their distance oracle is only for sparse graphs, but the logarithmic degree bound seems plausible. Added bonus, the algorithm also works for weighted graphs.