After having been through this process for a for a few clients now I would generally start with ensuring that you have implemented at least the following controls - note that none of these are specific to SOX, as route/switch/transport doesn't generally play a role in financial reporting aside from a pure availability standpoint: 

Given the 4-layer model you are working within, TLS would fall the Application Layer. The Transport Layer only deals with the connection mode between processes - TCP/UDP multiplexing and the like. 

VLAN "Names" are locally significant to devices and different devices will allow different length strings to name them, so no need for them to match (although it helps when troubleshooting if they are at least similar). As long as your VLAN 1 is native on the Aruba port and matches the correct subnet on your firewall, this topology should work just fine. As a general rule though, I tend to avoid using VLAN 1 on any device in the network, due to various vendor-specific quirks that it often comes with. 

No. Ask your provider for two independent L3 links. *The problem with the topology as drawn is that it looks like your provider is relying on you to have a switch to plug their two links into so that their HSRP heartbeat will pass between their two edge devices. If you install an L3 device between them (eg: the SRX cluster) I suspect that the HSRP fail-over will never work (it will probably go active/active). If your provider can't/won't provide this, I'd try another provider, but if you have L8 issues preventing this, then your best bet would be an individual L2 switch for each provider, a dedicated VLAN trunked across both for the provider network, and a link from node0 into Switch A and a link from node1 into Switch B eg: 

And you'll see you only get one match. The prefix you enter into the test command basically says "show me all the routes that match this prefix or longer" - in a similar to the way a command works. However, when matching a prefix list, prefixes are matched exactly, so even though our prefix list has a covering prefix (eg: ) that doesn't cause a match because that exact prefix isn't in the routing table. 

Yes, this is expected behaviour. Even though PC3 sees the ARP request from PC1, it does not populate it's ARP cache with the IP-to-MAC mapping of PC1. While this may not seem to be the most efficient method of distributing address to host information, you need to remember that the ARP protocol was developed in 1982[1] and even back then the author made the following very relevant point: 

Ethernet switches use the source MAC address of an Ethernet frame to populate their forwarding table. When a switch is powered up for the first time, it's forwarding table is empty. When it receives a frame sourced from MAC A on Port 1 destined for MAC B, it will not know where to send it, so will flood it to all ports except port 1 (assuming single VLAN across all ports). It will then update the forwarding table and map MAC A to Port 1. Now, whenever a frame is received destined to MAC A, it will be simply sent out Port 1 and not all other interfaces. As more traffic is sent through the switch, the forwarding table will start to be populated such that all hosts in the LAN will become known and less and less flooding will occur. 

Now if you apply this to an interface (say and then poll the [1], you will get a list of all counters, including one called under a filter called . It's probably not exactly what you're after, but unfortunately it's about as close as you can get with the Juniper MIBs today. [1]$URL$ 

Realistically, it depends on the size of the current spanning tree and how it is disrupted. In an RSTP or MSTP environment, if an interface goes hard down (eg: it's disconnected or otherwise shut down), then the topology change will trigger immediately - between only two switches, a new tree should establish in less than a second and forwarding will recommence. If there is break not caused by link down (eg: configuration change, intermediate device failure etc), then RSTP and MSTP will wait for 3x Hello Interval (3x2 (default) = 6 seconds by default) before re-converging. STP on the other hand is a lot slower because it has a slightly different state machine - it will wait 10x Hello Interval (20 seconds) for a BPDU timeout, and then sits in listening State for another 15 seconds, followed by the learning state for another 15 seconds, giving you somewhere around 50 seconds to converge. Bear in mind though that these figures are for a single switch - if you have a large network diameter, downstream switches may start detecting failure at slightly later times, meaning they will start this process later and ultimately add more time to a complete topology re-convergence. Added to this is when you're using protocols like VSTP/PVST/PVST+ the switch needs to do this re-convergence for every VLAN, which if there are a lot can be quite taxing on the CPU thus slowing down the r-econvergence further. 

however, it doesn't do quite what you are asking. Firstly, create your prefix-list and match it in a policy: 

This appears to be a defect - I just recreated a similar environment on an EX42000-VC running 15.1R3.6. 

The MUCH easier way to do this is via LLDP - this will show you each interface that is part of the LACP bundle and which port it attaches to on the remote switch. If you don't/can't/won't enable LLDP on both sides, you can trace it out the harder way: The actor is the local switch, partner is remote - looking at the output you can see that port ge-1/0/11.0 is attached to Partner Port ID 1 and ge-0/0/11.0 is attached to Partner Port ID 0. If you log into the switch on the far end, run the same command and it will show you the Actor port with ID 0 and 1, which will equate to the interface mappings. But you really want LLDP here, so you can gather all this information only looking at one switch. 

Because of the above issue around L2 and HSRP heartbeats, this will not work. You are also correct - is only an L1 monitoring solution. If HSRP fails over upstream for any reason other than link/node failure, the SRX will continue to forward out node0 and all your traffic will be dropped. Continuing on from above - if I was ordering redundant links from a provider, I would want them to be redundant at L1, L2 and L3, which the above are not. What you really want are non-reth interfaces facing two independent L3 circuits, one attached to each node - then you can use BGP to handle provider fail-over, and leave the chassis-cluster fail-over to handle device-level failures, independent of the upstream provider. 

DPCs (Dense Port Concentrators) were the original line cards released for the MX series back around 2006. They were named so because they were a fixed configuration with high (for the time) port capacity. Not long after, MPCs (Modular Port Concentrators) were released, which as the name implies were just a carrier card for MICs (Modular Interface Cards) so you could pick and choose your interfaces. MPCs also used Juniper's Trio ASIC, which gave them much better scale and features than was possible on the older DPCs. These days, MPCs aren't always modular - some only come in fixed form-factor, however the name has stuck and they still all include one or more Trio ASICs. DPCs are all end of life 

On the SRX, a down tunnel should also take down your st0.x interface as well, in which case your configuration should work fine. A couple of reasons for this not working: I have seen a few versions of Junos that broke this (early 12.1X44 releases), so a code upgrade may fix this. I'm using 12.1X46D55 on an SRX240 and it correctly drops the st0.x interface when the tunnel is down. Also, ensure that you have DPD (dead-peer detection) enabled, so that the box doesn't wait for a re-key interval to know that the far side is down. AWS supports this by default, so you should be able to fail over in ~30 seconds. 

You would need some form of script to do this in a sane manner - it would need to log into the switch, check the LLDP neighbor and update the port description. I question the point of this though, since you have this information in LLDP already, and it is automatically updated when someone re-patches their device, unlike the script method which would have to be re-run every time a port changes state (in case people are moving stuff). LLDP also wouldn't work for most hosts, without installing 3rd-party agents, but APs and Phones (and some printers) are able to self-report out of the box. You don't mention your switch vendor, but some support NetBIOS snooping, whereby you can discover the SMB Network Name of connected devices automatically as well. 

In short, neither. There are a lot of resources online discussing precisely this (real-time protocol design, especially in gaming), but to summarise, the model whereby one host acts as a "server" and keeps track of game state (all players, statistics and object state in a world), and all clients communicate with the server via UDP is the industry standard. UDP connections are used because you negate any round-trip latency associated with connection set-up or segment acknowledgement. Because you have a server tracking state, it doesn't need to care about the client receiving frames or not - the client and server just send deltas, which they then update from the last known state. This is of course an over-simplification of a very complex topic, but the gist is that there is no need for upper-layer protocols to be hacked over the top of UDP to make it "reliable" - the nature of real-time traffic, is that it is worthless if not delivered within a very short window. I highly recommend the following article discussing experiments and observations by John Carmack when writing the Quake 3 networking code: $URL$ 

The short answer is no - PVLAN functionality is there for a reason - it changes the way the default flooding and learning mechanisms work to ensure that hosts in a VLAN don't see each other, while being able to see their gateway devices and other "public" resources. Having said that, you could re-create something functionally equivalent using a lot of ACLs either on the switch (at either L2 or L3 depending on hardware capabilities), or on the hosts themselves (L3) to restrict traffic flow between all public hosts. Depending on your requirements/ruleset, this could either be really simple (bar traffic to any other hosts on the same subnet except the gateway), or very tedious (some inter-host traffic allowed, but different for each host). If you go down this path, look into some automation tooling (Ansible etc.) to make this easier. 

You'll then see when you look at your interfaces that the MX will pop both tags on ingress, and then push two new ones to match the egress interface eg: 

Yes. You do not want to extend Layer 2 MAN links beyond the border of each location - this is bad design for a number of reasons: 

More information here: $URL$ This is an inherent issue with NAT (Network Address Translation) - the only way to get around it is to specifically configure R to port-forward your traffic back to A. 

(apologies for woeful ASCII art) If you are patching directly between both devices (i.e. no structured cabling), you will need a patch lead that maps cores 1-12, 2-11, 3-10, 4-9. These patch leads are known as MTP Polarity B (essentially an MTP cross-over cable). If you are using single-mode to connect the devices, then none of this will apply - your QSFP+ single-mode transceivers will present LC connectors, and regular OS1 patch-leads will work just fine. Alternatively, you could also just use QFSP+ DACs (Direct-Attach Copper) which are pre-terminated. 

I could be wrong, but I think VLAN ID is in the second last column of your output, in which case, you have a bunch of different VLANs all trunked on and you are just seeing the same MAC in multiple VLANs (which is perfectly legitimate. Keep in mind that ARP Tables and MAC-address-tables are two very different things - one relates to routing (L3), and one to switching (L2).