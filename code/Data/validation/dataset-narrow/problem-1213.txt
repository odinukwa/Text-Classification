EDIT: This proof is wrong, as pointed out in the comments. (Should I delete the post?) It intuitively feels like if Hamiltonicity is NP-hard for k-regular graphs, then it should also be NP-hard for (k+1)-regular graphs. Here's a back-of-the-envelope reduction, which looks fine to me, but of course there could be a mistake. Let G be a k-regular graph. Let G' be a the graph Cartesian product of G and an edge. In other words, G' is the graph which has two copies of G, and every vertex is connected to its copy. G' is now (k+1) regular, since each vertex got 1 extra edge. Claim: G has a Hamiltonian cycle if and only if G' has a Hamiltonian cycle. Proof: If G has a Hamiltonian cycle, it's easy to see that G' has one too. Say (u,v) is an edge in the Hamiltonian cycle. Traverse the cycle from u to v without using that edge, and now instead of using the edge, go to v' from v, where v' is the vertex corresponding to v in the copy of G. Now traverse the cycle in the reverse order in this graph, which will bring us back to u'. Now go from u' to u, which completes the cycle. If G' has a Hamiltonian cycle starting from vertex u, consider the same sequence of traversals on G. Every time a move is made to an adjacent vertex in the same graph, we make the same move in G. Every time a move is made to the corresponding vertex in the other graph, we do nothing. Since every move is valid on the graph G, and the cycle ends on vertex u, this is a Hamiltonian cycle. 

It's not completely obvious to me that this problem can be reduced to element distinctness (ED). What if the two sets are disjoint, but the sets contain repeated elements? If you just solve ED on the union of the two sets, ED will return YES, but the sets are disjoint. But this problem (let's call it Set Disjointness or SD) has query complexity $\Theta(n^{2/3})$ when the two sets are of size $n$. To show a lower bound of $\Omega(n^{2/3})$, we can reduce ED to SD. Here's a simple probabilistic reduction: Take any ED instance. Randomly partition it into two parts and solve SD on this instance. If it was a NO instance of ED, it will be a NO instance of SD. If it was a YES instance, then with probability >= 1/2, it will be a YES instance of SD. For an upper bound of $O(n^{2/3})$, I can't, off the top of my head, think of a reduction to a known problem. The easiest way I can think of is to use Ambainis' algorithm for ED, but modify it to work for this problem. It is known that Ambinis' algorithm actually works for any two-place relation R(.,.), not just the relation EQUALITY(x,y), which is 1 iff x and y are the same. So we can use the relation R(x,y) = 1 iff x = y and x and y are from different sets. 

As Ryan says, this class is PSPACE. This class is often called NC(poly) in the literature. Here is a direct quote from the QIP = PSPACE paper: 

This characterization is almost tight. However, there could be a quadratic gap between the upper and lower bounds. For example if $1/\gamma^C = \log |C| = k$, then the lower bound is $\Omega(k)$, but the upper bound is $O(k^2)$. (I also think this gap is achievable, i.e., there exists a concept class for which the lower bounds are both $\Omega(k)$, but the upper bound is $O(k^2)$.) 

Most quantum classes that are studied (like QMA, BQP, QIP, and exotic ones like QMIP and QRG) have a classical counterpart and you get the quantum class by thinking quantumly and changing your definition of "efficient computation" to "polynomial time on a quantum computer." Often there are two steps to be made to reach from a well-known class to a quantum class. The first step adds randomness and error, and the next step adds quantumness. So for NP, the chain of classes is $NP \subseteq MA \subseteq QMA$. In NP the verifier is deterministic, and the certificate or proof is a bitstring. In MA, we modify the verifier to be a BPP machine (give it access to randomness and allow it 1/3 probability of error), while the certificate remains a bitstring. In QMA, we allow the verifier to be quantum and the certificate to be a quantum state. Since a quantum verifier can simulate a probabilistic one, QMA contains MA. The easy way to get a quantum class out of most natural classical classes is to change one's notion of "efficient computation" from P or BPP to BQP, and change one's notion of information exchange from bits to qubits. So, for example, QIP is the same as IP when the BPP verifier is made BQP and the communication allows qubits instead of bits. Finally, to get back to QMA: If you truly believed that BQP captures efficient computation in our universe, then QMA is the set of all problems that have an efficient verification procedure. That is, if you met an almighty prover, it would be able to convince you with high probability of $x \in L$ assuming you can handle qubits and do quantum computation. (And of course when $x \notin L$, there is almost nothing it could say to fool you.) 

This problem has been studied in great detail, not just for the case of imperfectly cloning 1 qubit to get 2 copies, but more general problems of how to get m copies of a state given n copies, etc. I don't work in the area, but I'll try to give you some answers. Others may be able to provide a better answer. For the problem you describe, 1 qubit to 2 qubit cloning, the optimal cloner is due to 

Andrew W. Appel's "Is POPL Mathematics or Science?" This paper studies varies CS conferences and tries to classify them as theoretical or applied based on whether authors order their names in alphabetical order (theoretical) or by contribution (applied). 

This was a comment, but it became too long. I want to give an explicit example where the input size increases. Take the classic reduction from CircuitSAT to 3SAT. The usual idea is to assign a variable to every gate in the circuit. The variable's value is the output of the gate. The you add the constraints that make a gate's output reflect the gate's input and gate type. So if a gate (whose variable is g_1) is an AND gate and has input wires coming from gates g_2 and g_3, you'll get a constraint like g_1 = g_2 AND g_3. We also have variables for the inputs, of course. With this reduction, even though there are n inputs, if the size of the circuit is, say, $O(n^5)$, then the resulting SAT instance will have $O(n^5)$ variables, which will require $O(2^{n^5})$ time to solve by brute forcing on a deterministic TM. You also asked why E is not closed under Karp reductions. That's easy. Take a problem that only be solved in $O(2^{n^2})$ time, and therefore it is not in E. Now we can Karp-reduce this to a language in E by padding the input with $O(n^2)$ zeros. The language in E to which we're reducing is the original language with each input of size n padded with $O(n^2)$ zeros. Now since the input size is $O(n^2)$ and we know an algorithm that solves this in $O(2^{n^2})$ time, this problem is in E. So we reduced a problem not in E to a problem in E, showing that E is not closed under Karp reductions. 

Recommend a few good hotels to conference participants I've been to conferences where the recommended list of hotels had 10+ hotels (or none, with the message "this is a large city with many hotels, feel free to pick any"). While it's nice to have so much choice, first it means that someone who doesn't know the city will have to pick which one is optimal for them. Second, this greatly reduces the chance of being in the same hotel as a lot of other conference attendees. Instead, conference organizers, who are locals and can evaluate hotel optimality much better than attendees, can recommend something like 3 or 4 hotels at most, based on their price. There should be a cheap option for students and people on a low budget, and another one for those without funding constraints. That way a lot of attendees will end up at the same hotel and have the chance to interact during breakfast, commute to and from the conference together, etc. Sometimes this suggestion is not feasible when the hotels in the area are small and will get full really fast. I mean to direct this suggestion to conferences where it is feasible to make such recommendations. 

Quantum Mechanical Computers (PDF) by Richard Feynman. He introduces the idea of quantum computation, describes quantum circuits, explains how classical circuits can be simulated by quantum circuits, and shows how quantum circuits can compute functions without lots of garbage qubits (using uncomputation). He then shows how any classical circuit can be encoded into a time-independent Hamiltonian! His proof goes through for quantum circuits too, therefore showing that time evolving Hamiltonians is BQP-hard! His Hamiltonian construction is also used in the proof of the quantum version of the Cook-Levin theorem, proved by Kitaev, which shows that k-local Hamiltonian is QMA-complete. 

Background A read-once formula over a set of gates (also called a basis) is a formula in which each input variable appears once. Read-once formulas are commonly studied over the De Morgan basis (which has the 2-bit gates AND and OR, and the 1-bit gate NOT) and the full binary basis (which has all 2-bit gates). So for example, the AND of 2 bits can be written as a read-once formula over either basis, but the parity of 2 bits cannot be written as a read-once formula over the De Morgan basis. The set of all functions that can be written as a read-once formula over the De Morgan basis has a combinatorial characterization. See, for example, Combinatorial characterization of read-once formulae by M. Karchmer , N. Linial , I. Newman , M. Saks , A. Wigderson. Question Is there an alternate characterization of the set of functions that can be computed by a read-once formula over the full binary basis? Easier Question (added in v2) While I'm still interested in an answer to the original question, since I haven't received any answers I thought I'll ask an easier question: What are some lower bound techniques that work for formulae over the full binary basis? (Other than the ones I list below.) Note that now I'm trying to lower bound the formula size (= number of leaves). For read-once formulae, we have formula size = number of inputs. So if you can prove that a function needs a formula of size strictly greater than n, then that also means it cannot be represented as a read-once formula. I'm aware of the following techniques (along with a reference for each technique from Boolean Function Complexity: Advances and Frontiers by Stasys Jukna):