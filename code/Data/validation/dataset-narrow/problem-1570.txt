Discovering statistics with SPSS/R - Andy Field R Beginner and R for Everyone Predictive Analytics - The Power to Predict Who Will Click, Buy, Lie or Die Data Science for Business and many more 

This example demonstrates how to estimate the accuracy of a linear kernel support vector machine on the iris dataset by splitting the data, fitting a model and computing the score 5 consecutive times (with different splits each time) The cross_validate function differs from cross_val_score in two ways - 

Match users directly to products and content Recommend based on what you have bought or viewed in the past Commonly used for document recommendation: webpages, news articles, blogs etc. 

Feature Selection is a technique which is used when we you know the target variable(Supervised Learning) When we talk with respect to Unsupervised Learning, there is no exact technique which could do that. But there is something which can help us in those lines i.e., Dimensionality Reduction, this technique is used to reduce the number of features and give us the features which explains the most about the dataset. The features would be derived from the existing features and might or might not be the same features. There are different techniques which are available for doing so: 

I think you can try using Gephi, you might get that visualization and you can apply couple of Community Detection algorithms. Best part is, it is an open source tool. But one drawback of using it is, you cannot handle huge datasets. If you can extract exact sample from population. Then it shouldn't be an issue. If you have a small dataset then you can directly import to Gephi. Try using it, the graphs(outcome) over there are animated too. Let me know if you have any issues. 

Welcome to the Site! We know that this problem is Multi-Class Classification Problem. To get a confusion matrix for the same you can use the following command: from mlxtend.evaluate import confusion_matrix 

In my Scenario, I had to remove all the Non-English as my model wasn't trained to handle such words. by which my model performed well. There was an increase of 2-3% of accuracy, which was significant for me. To Improve these Models Accuracy: Now, to improve my model I made an new dictionary for some words like not great - which falls under a Neutral Sentiment(but I don't have one), If these words are found then that tweet is pushed to negative. By this you can expect better segregation of sentiment. In the same way to improve you need to look for things which are not classified properly(wrongly classified by models- False Positive or False Negative these terms are with respect to Confusion Matrix) and find a pattern which is being missed by the model and use that for maximizing your models capacity. 

Oversampling: There are many techniques under this, ROSE and SMOTE are the most famous techniques used for oversampling. In ROSE it just increases the minority classes. In SMOTE it synthetically generates more number of rare minority classes for balancing. Most of the Scenarios SMOTE gives better results than ROSE but you should try both. Other than that there is just another techniques which just duplicates the records to the make it equal n number. This Link, is for implemenation of SMOTE in Python. UnderSampling: There are many techniques under this too, but this Link-1, Link-2 gives you better idea about undersampling. Generally I don't prefer Undersampling, as you would loose some infomation. 

I think they are 2 different things, Lets start with Feature Selection: This technique is used for selecting the features which explain the most of the target variable(has a correlation with the target variable).This test is ran just before the model is applied on the data. To explain it better let us go by an example: there are 10 feature and 1 target variable, 9 features explain 90% of the target variable and 10 features together explains 91% of the target variable. So the 1 variable is not making much of a difference so you tend to remove that before modelling(It is subjective to the business as well). I can also be called as Predictor Importance. Now lets talk about Feature Extraction, Which is used in Unsupervised Learning,extraction of contours in images, extraction of Bi-grams from a text, extraction of phonemes from recording of spoken text. When you don't know anything about the data like no data dictionary, too many features which means the data is not in understandable format. Then you try applying this technique to get some features which explains the most of the data. Feature extraction involves a transformation of the features, which often is not reversible because some information is lost in the process of dimensionality reduction. You can apply Feature Extraction on the given data to extract features and then apply Feature Selection with respect to the Target Variable to select the subset which can help in making a good model with good results. you can go through these Link-1,Link-2 for better understanding. we can implement them in R, Python, SPSS. let me know if need any more clarification. 

Yes as you told, calling the specific columns from Database is better than extracting everything. I generally use Dataframes rather than vectors. Dataframes are very efficient and the transformation using Dataframes is much easier and better. You can go through this link, for better understanding on Vector Vs Dataframe. Currently, I use 1 year data and consists of 100,000 records. Query takes like 8 minutes to extract the data in Rstudio using SQL DB and store it in an R-dataframe. After the extraction is over I don't hit the database meaning no read and write on the database by which the DB Server is not effected. After doing all the modeling and finally I commit the data into SQL DB to store the committed data(results). 

Firstly, welcome to the site! When do we use Ensemble model? when there are 2 models which perform moderately then we combine their results to get a model which performs better. In your scenario you already have a model which gives you good results what is the point of implementing Ensemble Models? As @Tagoma said, it depends on your data and your goal. For example, you are trying to predict stock rates, every 0.01% matters. In such scenarios you need to use complex algorithms to maintain balance on that slim line i.e., not to over-fit, not to over-train and just predict. Measures to check if your model is over-trained is by giving some random data and see how it performs, add some noise in the training data. One more important thing to do is, to check for the Predictor Importance and see if there is any highly correlated feature with the target variable. For example, you are planning to predict age and if you have DOB as a feature in that yes of course you would predict with 99.99% accuracy but that is not what we use ML for. If all of them are satisfied and achieving that accuracy then it means that your model's performance is good. Finally, Implementation of Ensemble is dependent on your business problem and your understanding on business. 

It would be great if you can find any trends which are similar, as you know a generalized model gives you better result when compared to the model which is built for a specific purpose. 1st question is how many data points do you have?, assuming that you have good amount of data to train for each model in each product then it is fine(you can go ahead with your current process) but in a scenario where you have less data points then, you can find if there is a trend similar is followed in 2 different products(will be outcome of your Exploratory Analysis), then you can combine such data together, by this you are generalizing the model. As Dan Jarratt has said, I would also agree with him. Ensemble Model would help you in getting better results and with good Accuracy, for better understanding you can go through this Link on Ensemble modelling in R. Do let me know if you have any questions. 

Finally, you can apply Ensemble model by combining results of the 2 or more models. For measuring the accuracy you can use Confusion Matrix(By diving the data into Test: 30% of data and Train: 70% of data).