We upgraded from 20 Mbps to 50 Mbps DIA about two months ago. This required a router upgrade as well. Since then, anyone who starts a large HTTP download - e.g. an ISO, large spreadsheet or log, movie file, etc. - can take all of the available bandwidth and block others from accessing the internet. The old router didn't have any kind of QoS configured on it. Further, it was a very vanilla config. It simply had some named ints, the security levels of each, and the IP addresses associated with each int. The ISP supplied the new router and we don't have access to view the config, but they said they don't have any kind of QoS configured on it either. My questions are: 

I'm auditing switch interface descriptions at work. I work nights and sometimes people during the day shut down their computers when they leave, so I don't see which computers are on interfaces when I'm not there. I have a mix of Cisco 3500 and 3600 series switches where it's possible to use curl (then some grep statements) 

Encryption with RSN adds a overhead of ~16 bytes per frame. This is negligible in a ~1500 byte frame, and is even more negligible considering that with current 802.11 modulations, the coordination function (CSMA/CA) becomes a major overhead. Most encryption is done in hardware directly on the wireless module (most CPU would have trouble running AES at 300 mbps) so enabling encryption should have no other bottleneck. However, enabling WEP disables 802.11n, so reduces the throughput. 

It all boils down to the loss probability distribution and traffic pattern. Take for example a typical wireless link, with a steady 10-30% loss rate. If you ack each received frame (like 802.11abg), you will quickly detect when a frame has been lost, so you will not loose time to wait for a timeout. If you were to NAK instead, you will become dependent on the traffic pattern: - If you send a single request packet and expect an answer, and that request is lost, you will have to have a timeout that expires if you do not get an answer. - If you are just sending a stream of packet to a mostly mute recipient, then it is acceptable to only receive a NAK when the recipient receives the next packet or so. But this mean that the recipient has to reorder packets and that the sender must keep track of a large backlog of messages that it has sent. (guess what solution 802.11n choose ? both. The receiver sends a variable-length bitmap of frames that it has received) Now take a typical Internet network: You have close to 0% packet loss, until something bad happens, and you have a close to 100% packet loss for a certain time following some exponential distribution law, from a 200ms interruption to a minute and a half. Acking each packet would seem pointless in a non-lossy network, until you consider the case when the link is severed: you will not receive ACK or NACK for a possibly extended amount of time, and the receiver will typically not send anything until the link is restored. If you use ACK, the sender will stop sending and keep its backlog until the link is restored. If you use NACK instead, then the receiver may eventually tell you that it has not received the packet that fell off the sender's backlog since a long time, and the connection is essentially unrecoverable. 

I have deployed ASAs in similar scenarios and all went well, with careful planning and maintenance. For the outside interface, first of all secure your OSPF process using MD5. You are to connect this interface to your L2-aggregate switches. On your inside interface we can dive into: - technically you can connect it to your L3 switch so you will split the role or the load between your network devices, also makes sense for a regular firewall (if at some moment you will have issues with your L2-aggreg devices, at least the network from bottom to the firewall is working) - for this scenario as ASA is VPN-used it means you can also connect your inside to the L2-aggregation switches. Without those L2-aggreg switches your 5545 will become useless for your network. Nevertheless for this choice you have to think about monitored interfaces as all your firewall physical interfaces will be connected to one physical device. Bottom line: if I have ports and capacity for better logical and troubleshooting I would connect inside straight to L3-bottom-switches. Finally regarding your 1st question: I have used inside interface both as a shared network with the other inside firewall (you could run into some details with same-security-traffic command and also as a dedicated network, than using bottom switches connect to the rest of the network. I prefer the last one as in this case VPN L2L filtering is done on the firewall (ASA 5545) instead of group-policy ACL (and then applying it to the tunnel-group). It is easy to manage, view, troubleshoot (for me) and also it keeps me away from some ASA more delicate traffic hairpin scenarios. 

Why when we had 20 Mbps service did we not have this problem where any one user could monopolize all the bandwidth to the internet? Am I correct in thinking that Quality of Service configurations would prevent this or does QoS simply identify which traffic has priority over another, and does nothing for competing traffic of the same type? If it's the latter, and my vocabulary is wrong, what statements do I need to configure and where (we have a Cisco 4507 core switch, a Cisco Pix on the primary ISP, a Cisco ASA on the backup ISP, and the inaccessible ISP router is a Cisco 2911) so that no one user can take all the available bandwidth to our internet connection? 

We had a broadcast storm that went undiagnosed for several hours. After the problem switch was unplugged and traffic returned to normal, we had a handful of machines and switches that were broken. On one switch, the sole uplink interface had to be moved to another int. On another, one of the two etherchannel physical members is down. One machine has a SSD and it didn't boot up after it was shut down. BIOS says it's a 32 KB disk. At least one other server's fans would ramp up to high RPMs every couple of minutes. I read that storm traffic not intended for a machine is dropped by the NIC, but broadcast traffic is sent up the network stack and can cause high CPU utilization. I imagine if the OS was writing log files because of the increased network activity it could eventually fill up disk space and/or burn up an SSD because of the increased read/writes. 

There are two "central" locations each one having one satellite or spoke site. Let's have: - zone A and its spoke_zone A1 - zone E and its spoke_zone E1. Both region A and region E have a similar deployment scenarios: - 1 x 5508 WLC - several LWAPs in the existing network (local network). - FlexConnect for other several LWAPs for the spoke zones A for the A1 and E for the E1. I'm thinking how can I achieve a backup solution for all these 4 sites: - A1 and E1 can achieve it through FlexConnect and one mode only: local switching & local authentication. - what about A and E regions? How can I bring some backup WLC solution here? I know of Mobility Groups, still I don't think it helps too much as I have only L3 connectivity between A and E region through MPLS. What if I try and get L2 connectivity in between using some solutions like "poor-man's EoMPLS" like L2TP v3, I will be able to connect one VLAN pair, will this be enough ? - what else can I do in case of WLC breakdown in either of the two regions (A or E)? 

Of course yes, otherwise, you would not be able to have multiple IPIP tunnels to different peers. But this can only happens if you have actually specified the address of the peer on the ipip interface. But you did, right ? If you also specify the local address to be used by the tunnel, the kernel will also check it. 

Zeroconf is not designed to work in this situation, so don't expect things to work out of the box. Zeroconf has three component: IPv4LL, mDNS and DNS-SD. 

Anyway, broadcast is so 1990, if you can use multicast instead, and enable MLD/IGMP snooping on the AP, then the AP may be smarter and only deliver the multicast frames if clients actually subscribe to the multicast address. And depending on the client capabilities and the AP configuration, the multicast frames may even be sent as unicast, at higher data rates and with less packet loss. IPv6 has no broadcast anyway. 

If your AP want to use a 5 GHz channel which is also used by radars, it NEED to support Dynamic Frequency Selection (DFS for short). In that case, it may perform a survey on the target 5 GHz channel to check the presence of radar pulses, then may start using it, while still checking for radars. If a radar pulse is detected after the AP has started, it sends a Channel Switch Announcement telling the stations that the AP will change channel after the next X beacons. The stations must obey or they will be disconnected. Of course, the channel switch mechanism may also be used for other purpose than to switch away from a radar channel. 

to get the running config, MAC address table, interface descriptions, etc. I'm using this to generate reports of MAC address tables and int descriptions when I'm not at work so I can audit switch interfaces to see what phones and PCs are online when I'm not in. I have MAC addresses documented from machines when they are unboxed, so I can compare the MACs I have with the ones reported in the automated curl statements. This will also be used to see if anyone's violating the "Don't BYOD" policy. This has worked flawlessly with the 3500s, 3550s, 3560s, and 3650s I have. I also have some sg300s that don't appear to be able to do that. Is that an accurate assumption? 

on my Cisco Catalyst 4507R. Thing is, there's nothing in that slot. Back in December I did insert a module into that slot, but said the module wasn't supported, so I pulled it out a few minutes later. It appears these messages have posted regularly to my syslog server ever since. There is no clear interval between successive messages; I've seen a difference of four minutes to ten hours between messages. How do I tell the chassis there's nothing in that slot? Also, if I do populate that slot with a module, do I have to do some sort of initialization? The module I tried installing was, I believe, a 48 port RJ45 module. If not that, it could've been a nine or 18 port GBIC module. 

Whenever possible I would go for IPS module, it s one of the best security products available on the market. As long as you have the license just fine tune it and use it accordingly to your needs. For any other scenarios when IPS not available, threat-statistics will prove helpful. 

I have discovered weird routing from our ISP all related to BGP. Here is the scenario (real-one). - there is a /19 prefix bought about 10 years ago, which was registered with ARIN authority. - as bussiness grew each site got it /24. The trouble starts in APNIC region in ASIA. We export one /24 prefix the regular way using two local ISPs. When trying to reach this prefix from different ASIA sites like India or China all traffic is sent to US West Coast then back to our site. Except additional hops, this also adds about 150ms latency. What I already tried: - AS prepend each ISP at a time so the other left would be preffered for all inbound traffic - both tests went similar as in both scenarios traffic hit US before reaching this trouble site. As there is no other local special config I can think of like communities, how can I explain this? Are both local ISP taking in consideration the ARIN info and based on that send traffic to US? Thanks! 

This sounds like broken broadcast to me. First, the fact that your laptop works is maybe due to how Windows tend to do strange things with DHCP, like trying a unicast DHCPREQUEST with its previous lease to try to renew it. I assume that it only works in your case because you always connect to the main site before connecting to the remote site, or your laptop was never connected to another network. Try connecting a laptop that has never seen the main network before, or use a LiveCD. I would expect it to not work. Either fix/configure your wireless bridge to support broadcast (I would look at the AP side, you maybe have to register the client bridge or something) or deploy a DHCP relay on your remote site. 

This kind of problem require a very specific solution. Your best bet would be to use something like 802.11s or another mesh routing protocol that support mixing wireless and wired links. Using a wireless-unaware protocol like STP is asking for trouble. If a wireless link degrades but remain usable enough for STP, you will have horrible performance. Alternatively, if your hardware does not support any mesh technology and you are not willing to change it, i would set A as a 4addr wireless client, so it can try roaming to the 'best' AP. But i admit i haven't understood the situation with E and F. 

A reboot will surely alleviate the problem for the moment, but as time passes and router memory loads you will probably hit the same log error. You can either remove some roles you have for this router, or a more uncommon method, would be to schedule an automatic reload at every 1 week or later. 

I am on the 1st phase of implementing a similar solution. 802.1x it's been for a while now and although it's grown up and globally supported it's vulnerable when meeting local OS network stack. I have deployed it several times on small and medium networks and usually it works for 90% of the workstations, maybe 95%. There is always an old Windows install that simply turns off your day. Based on that I am working with FreeRadius. It requires broader knowledge except basic networking, but it doesn't interact in any way with the workstations, it's transparent for the user. You can also try FreeNAC which is similar still it's been discontinued for some time now. 

I would suggest to create a 2nd Remote-Access tunnel group for all your remote-access users. Start migrating them, one by one and when you are done you can delete the existing Default L2L Group, or you can change the PSK. If you encounter some users that don't want to change, you can enforce a specific VPN Client version and inform them you are doing a major security update.