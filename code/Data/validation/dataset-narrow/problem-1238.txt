Disclaimer: I can only vouch for my research fields, namely formal methods, semantics and programming language theory. The situation is possibly different in other parts of the discipline. It seems that TCS has become rather conference-oriented. Researchers aim at publishing in the next conference. Sometimes a journal version appears. Sometimes it doesn't. In other disciplines (biology, mathematics, and most others I guess) this is unheard of. The effort put into writing the conference papers is a lot lesser, but in turn, the conference papers count a lot less. The "real deal" is the journal publication. Arguing whether this situation is good or bad could result in a flame war, and doesn't have a precise answer. Instead, let's try a more factual question: How did we become so conference-oriented? How did conference papers gain so much weight? 

Augmenting Andrej's answer: There is still no widespread agreement on the appropriate interface monad transformers should support in the functional programming context. Haskell's MTL is the de-facto interface, but Jaskelioff's Monatron is an alternative. One of the earlier technical reports by Moggi, an abstract view of programming languages, discusses what should be the right notion of transformer to some extent (section 4.1). In particular, he discusses the notion of an operation for a monad, which he (20 years later) revisits with Jaskelioff in monad transformers as monoid transformers. (This notion of operation is different from Plotkin and Power's notion of an algebraic operation for a monad, which amounts to a Kleisli arrow.) 

Augmenting Noam's answer: Removing the implicit currying, $f : A \to B \to C$ is the same thing as $uncurry( f) : A \times B \to C$. Strong monads $T$ give a map (two, actually!): $dblstr : T A \times T B \to T (A\times B)$. We therefore have a map: $ T A \times T B \xrightarrow {dblstr} T(A\times B) \xrightarrow{uncurry(f)} TC $ If we instantiate this to the continuation monad, we obtain your construction. Generalizing to $n$-variables, the following should work (I didn't check all the details through). Once we choose a permutation $\pi$ over $n$, we have a $\pi$-strength morphism $str_{\pi} : T A_1 \times \cdots \times T A_n \to T(A_1 \times \cdots \times A_n)$. (The monad laws should guarantee that it doesn't matter how we associate this permutation.) Therefore, for every $n$-ary morphism $f : A_1 \times \cdots \times A_n \to C$, we can construct: $\gamma f : TA_1 \times \cdots \times TA_n \xrightarrow{str_{\pi}} T(A_1 \times \cdots \times A_n) \xrightarrow{Tf} TC$. But I still don't think this really gives you the answer you're looking for... 

Lexical closures are an implementation technique in languages with first-class functions. I'm interested in a simple operational description of function closures. Does anyone know of such a description? 

Note that most of the categories you considered are 'abstract', i.e., they require structure or properties of an abstract category. As computer scientists we should also be familiar several concrete categories which turn out to be useful: Concrete categories 

My knowledge is a bit stale, as I haven't actively researched this field in the last couple of years. None of these is probably the state of the art, but a good place to start looking backwards (i.e., chase references) and forwards (i.e., see who cites it). If you're looking into information flow (making sure classified information doesn't leak to untrusted roles), a reasonable place to start is Martin Abadi et al's Dependency Core Calculus. I think it's reasonable enough that anyone who does formal methods in the area would refer to it (directly, or once removed). If you're looking into access control/authorisation (role A says role B controls the data, role B says you can access the data, etc.), Abadi recently published a tutorial book chapter on the subject, so might be a good place to start. If you're looking into authentication (whether the agent saying he is A is indeed A), I defer to someone else. I'll try to have a look later. 

First, the property "having first-class functions" is a property of a programming language, not of particular functions in it. Either your language allows for functions to be passed around and created at will, or it doesn't. Functions that accept or return other functions as arguments are called higher-order functions. (The terminology comes from logic.) Functions that don't are called first-order functions. Perhaps this latter notion is what you wanted. 

If I understand correctly, you just want a definition of the logic; then you can find a definition of MSO$_j$ (where 2 is a special case) by example in ''Elements of Finite Model Theory'' of Leonid Libkin. Even if you are interested in infinite model, the definition of the logic is the same. Quickly is just the set of formulae with existantial quantification over sets of the elements of the universe, then existantial quantifications over those sets; then a first-order formula. 

${\Sigma_2^P}^{NP}$ is the set of language decided by an alternating turing machine in existential, and then universal state, with an oracle in NP. Both the universal and the existantial part can querye NP. Hence, in this case you decided to write this as $(NP^{NP})^{A}$ then the way you should think of it is as $(NP^{NP^A\cup A})$ (by $\cup$ I mean an oracle either to $A$ or to an $NP^A$ language). Hence ${\Sigma_2^P}^{NP}$ is equal to $(NP^{(NP^{NP})})^{NP}$ which is certainly equal to $(NP^{NP^{NP}})$ since every query you could make to the $NP$ oracle, you could make it to the $NP^{NP}$ oracle. 

I guess that notions I describe are already well known, may be by combinatorician, but I do not know their name or any book/article about them. So if you have a link/title I would love to read it. Let $r$ be an integer, let $P_r$ be the set of partial (pre)order over $[1,r]$ and $T_r$ the set of total (pre)order. I say that $P\in P_r$ is included in $T\in T_r$ if it is included as subset of $[1,r]^2$, or to state it another way, if for all $i,j$ with $i$ less than $j$ for $P$ then it is also less for $T$. Finally I say that $P$ and $P'$ are incompatible if there is $i,j$ with $i<j$ for $P$ and $i>j$ for $P'$ (or if $i=j$ for $P$ and $i<j$ for $P'$). Let $P\in P_r$ with $i<j$ and no $k$ such that $i<k<j$, then $P_{i,j}$ is the same partial (pre)order, except that $i$ and $j$ are incomparable. I would like to find an efficient data structure to store a subset of $P_r$. I can't imagine something better than a trie of depth $r(r-1)/2$, with one level for every pair $(i,j)$ with $i<j$. If possible I would want to be able to efficiently add and remove elements from the set, or at least to easily transform $P$ into $P_{i,j}$ as defined above. I need to know if for a given subset $S$ of $P_r$ and $P\in P_r$, $P$ is incompatible with every $P'\in S$. Or an equivalent problem would be to figure out if a set $S$ is such that its element are one to one incomparable. I also need to know if for every total (pre)order $T$ it is a superset of a partial order $P\in S$. Intuitively, to each $P\in P_r$ is associate its set $T_P=\{T\in T_r\mid T\supseteq P\}$ and I need to know if $(T_P)_{P\in S}$ form a partition of $T_r$. Then let $T_S=\bigcup_{P\in S} T_P$, then I would also be interested by having a way to efficiently describe $T_S$. (That is, efficiently checking for a given $T\in T_r$ if $T\in T_S$. 

Usually I give the factoring problem as example; I first ask for the number that divide 15; usually people can answer 3, 5, and have fun wondering if 1 and 15 are correct answer. Then I give a huge number (more than 10 digits) and ask if they can tell me what are the dividers; and I explain that, even for computer scientist, this is a really hard question. Then if I have time, I try to explain that the question is either to figure out how to solve this problem, or to prove that it will always take a lot of time( a notion that we precisely know how to define). And then a little word of cryptography, to explain why it is usedd, and a word about how many time it take team of scientist to break the key of number with hundreds of digit (I avoid to speak of bits because people seems to better know what a digit is) 

To answer to your comment, I guess I should make another answer, speaking only on Krom and Horn (May be I should ask a question about those to CSTheory) I suggest that you read section 5.3 page 34 of my paper about the problem I met on Horn and Krom in High Order logic. You will meet the same problem in Variable Order (which is clearly a superset of High Order). I don't know if you did pay attention to it, but SO(krom) is equal to P when the first order is universal; indeed you can express NP-complete problem if you add existantial first order variable. (I don't remember the example I had before, I can try to search it if you want it) I don't know what this syntactical resctriction would become for high order or variable order logic... my point is just that you should also think of a good way to restrain quantifiers, because restraining the quantifier-free part alone is not usefull (at least for Krom formulae)