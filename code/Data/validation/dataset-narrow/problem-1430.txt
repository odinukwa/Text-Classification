It's likely you're always going to get a collision with the floor; if you're using gravity, your cube is essentially going to be almost constantly hitting the floor in addition to any other objects it hits. The trick is in determining if there are additional collisions that involve a wall. Without knowing much about your specific implementation, here's what I'd suggest: In , check every 's normal to see if it's perpendicular to the floor. For now, I'll assume that your cube rotates to have its vector parallel to the ground on which it's moving (resulting in its vector pointing away from the ground). If that's wrong, let me know how you have it set up and I'll try to edit the answer to fit. My code is in C#, if you're using JavaScript, there will obviously be some differences. In your cube's collision code, you'll want something like this: 

Your question is a little vague. Are you specifically asking if Edge uses 2D or 3D graphics? Or looking for thoughts on whether your similar game should be in 2D or 3D? Edge certainly looks like it's using full 3D graphics, a fixed camera angle, and orthographic projection. The fact that a number of game objects rotate leads me to believe that it's all 3D cubes that can be transformed in various ways. Rather than going through the process of animating a sprite for the necessary cube rotations, 3D graphics would look smoother with less overhead, in my opinion. However, one could very easily make a similar style of game in isometric 2D. If you're asking how you should do it, what does your past experience point to? Do you have more 2D or 3D work experience and do you want to branch out into what you don't know as well? What engine(s) are you considering? I think, all things being equal, a simple 2D version of that style of game would be quicker to set up than a 3D one. 

Hi and thanks for your questions. If your collision is not detected there are 3 obvious problems that could happen. First your ball is moving to fast or your collision detection time interval is to low. This causes the ball to appear once in front and after behind the rectangle. To solve this simply interpolate over the last translation of your object and check each time for a collision. This is anyway a good point because it improves the precision of your collision detection. More can be read online. Second your algorithm of collision detection does not work correctly. To prove this you should first give your variables meaningful names this helps you and us to understand your code faster and probably. 

If this is the problem you have multiple choices. First reduce the size of every tile. Second use a tile format to squeeze out your white spaces. You can find a nice video here. Split your tiles in multiple textures. Anyway you are limited to your number of texture channels. Additionally your image has no squared size to a number of 2^n. This leaks memory and slows down your rendering pipeline. Even if you do not use the space you should resize your image. I hope I could help you. Have further questions? please tell us. :) Michael 

Hi MT8 and thanks for your question. I am not familiar with the AndEngine but I recognized some issues that are typically for this problem. Normally you get no limit cap by the number of division. These are just passed parameters to the graphics pipeline where to get the specific tile from in the image(texture). One thing that can cause the problem is the size of your image. Graphic cards have a hardware specific maximum and minimum value. In order to get more tiles with the same size in pixels you have to increase the size of your texture. The texture you posted is huge in size and most mobile graphic chip can not handle it. So what to do? First check your limitations. Since you are using an Android Engine I assume you are using OpenGLES. You can get the max dimension by: 

If you're using a regular Unity GameObject, you can just use to access the forward direction of your object. See the Unity documentation for details. If you're using a different way to track your object, Spherical coordinates are essentially polar coordinates expanded with a third dimension. EDIT: I assume in Minecraft is the vertical axis and and are on the horizontal plane. If this isn't the case, the principles would still apply but the , , and would need to be assigned differently: The and directional components can be determined from the yaw fairly easily: and . I'm not familiar with modding Minecraft to know whether or yaw is in degrees or radians—you may need to convert it in order to get real results from those trig functions. It's also possible that you may need to add a constant to the yaw to match the actual axes in the game (like adding or subtracting 90° to align with the world axes). The component can be determined from the pitch: . Again, you may need to convert between degrees and radians or add a constant to match world axes. 

I've considered taking a course in linear algebra but my courseload is already pretty heavy so I haven't been able to justify the extra work. My understanding of linear algebra has grown much more significantly as I've taken a series of game engine programming classes. For me, use of Vectors, Matrices, etc. has been (generally speaking) more prevalent on the engine side of things than on the game side. Of course, that's not to say I haven't used matrices in game code—I just don't use them as often as I have in engine coding. ymmv There are also plenty of books that can help you understand the math you'd need to know, as well. I like this book which has a chapter titled "3D Math for Games." 

Depending on the amount of data you have to store PlayerPrefs should be perfect for that. If player prefs is not enough or does not suits your needs you can store project custom data in a text file (personally i place it in resources but it could be anywhere) and read it when needed for ex : i made a plugin for unity to define different sizes atlases path, and everything is stored in a textfile where i have some JSON arrays, and when i load my scene i read my file and forget about it 

this should already make your code easyer to maintain and it could allow you to switch between targets painlessly EDIT: And to stress it even more as Byte56 stated : Get rid of all the useless stuff 

Copying my comment up there on why you do not get the proper result your way : Lerp(A,B,C) returns the interpolated value placed at (C*100) percents between A and B (in that order) If you use what you wrote every frame this is what happen : CameraPosition gets incremented, and then that incremented value is passed (in the next frame) as parameter to the next frame incrementation. Lets admit that instead of Time.time you used 1, you would get : 

Actually Lights does not contain colliders, but what you can do is add a CircleCollider2D component to a light, then track if your object collide with the collider of this light and only then trace a ray from your object (character) to the light, if the ray hits a collider before hitting the light then you know your character is in the shadow part of this light! I am not sure you could go away with this without using raycast2D, but dont be afraid once you get a hold on it it can be very straight-forward. For example to put on your character : 

You don't say anything about what your game is, so it's hard to know whether you should or shouldn't have such collectibles. Some platformers do have additional tokens to collect, and some don't. There's no tradition that requires they be included in a game. What matters is if they fit in how your game should be played. I imagine you're more likely to be able to think of games where there's some sort of reward for collecting them. Some games offer extra lives for collecting enough things, others allow unlocking additional features (areas, characters, all sorts of stuff). If there's a purpose to them, they can add additional replay value or extra goals for skilled players. The Super Mario Bros. games award extra lives (among other things depending on the title) for collecting enough coins, giving them a specific purpose and a reward. The reward for players skilled enough to collect more coins, is that they earn additional chances in-game. Mario games are more arcade-style gameplay, and the player benefits directly from being able to earn additional lives. Metroid, on the other hand, does not feature similar non-upgrade collectibles. Your tokens are either direct upgrades (new armor, weapons, etc.) or health and ammo. There are no extra things that exist solely to be collected. This doesn't hurt the game because the game isn't designed around the need for such collectibles. Both of these series are considered classic platformers, one has them, the other doesn't. The list could go on, of course... Look at the design of your game and determine what the purpose for collectibles would be. If you think your game would benefit from them, try it. 

If your game is playing and you have pressed this frame, the first set statements' conditions will be true. This will change to which will then make the second set of conditions true, chaning it back to . You'll probably just need to set up a series of conditionals that exclusively check the game state at the beginning of the frame. Either by using a statement instead of a series of s or at least putting subsequent s within blocks: 

You should have the "Gizmos" menu in the scene view, check if everything is checked there, you should also know that importing from blender will naturally downscale your objects to 0.1 of their scale, you can change that by setting scale back to 1 in the import settings. When your objects are downscaled to the point you cannot see them if you focus on one of them you'll loose the visibility over the gizmos and vice versa. If after checking this it is still occuring could you post the specifics of your scene setup? 

Unity (or any other 3D engine i believe) is not using pixels for positioning objects in space (maybe mostly because there is no Z axis in pixels and also because it brings thousands of other issues) Unity uses Unit system (i personally see it as metric) you should take the unit cube as one meter, this means few things : 

According to those docs over here, you should be able to create a basic surface shader with diffuse and lighting. And by tricking the in doing no specific action except getting vertex position and converting it to color you want (using an struct which could be a bit more evolved). After doing that and getting back the color you got in inside your albedo infos, you just let surface shaders do their job and take care of the lighting (you can specify it there ) EDIT : I think i'm starting to get what you mean by vertexColor, you mean Weight Shade : giving a vertex a 0-1 value and from this value get the color mix which correspond? or you just need access to the property in your input data for : 

Just a supposition here but a way to go without artifacts could be mesh conforming : in short casting your mesh B onto your mesh A, easy to implement with morphed planes but could be a whole other issue with closed meshes. What you need to do is create a function which will approximate the new point coordinates based on a set of points (as you have greater count with mesh A) and remap the point, kill the triangles, recreate the triangles the normals and then interpolate... Mesh conforming demo EDIT : one of the simple way to do that would be to approximate new base position based on the same vertex index than the one of mesh A ex: Mesh A 20 Vertices Mesh B 10 Vertices Kill Mesh B triangles Set Mesh B Vertices in index Order using for ex : 

Hi Matthew and thank you for your question. Since ActionsScript uses garbage collection there are only 2 reasons. First you have references to these objects in your own objects or from a manager in fixel. In this case be aware to null your references. Maybe the tool mentioned here could be useful. Second your garbage collection did not trigger automatically. In this case force it to clean up. Sometimes garbage collection can not or need many attempts to free all memory. This is caused by circular references. I.e. A references B and B references A and you null the reference to A. So what to do. Check if you really null your references and that no reference is left from your side of code. If the problem continuous check if flixel tracks some references internally and lookup how to remove them. If the problem is not solved check for objects that reference each other. Normally this should not cause this problem because garbage collection checks for circular references. I hope I could help you. Have further questions?, please tell us. Michael 

I did not really look for mistakes in code because im not familiar with java and the method naming confused me. Whatever it is important to check each side unless you do not check the relative position of the objects before. Especially the corner test seems wrong to me because you did not test all of them. The third problem I could think of is that maybe the coordinate system of the objects given to the intersect method are not the same that are used to render them. The second question about velocity and smoothness is more about detecting the best fitting collision point and calculate the reflecting vector. Anyway this gives you only the direction. Calculating speed and velocity gets more complicated and is based on the physical properties of your objects material. If you explain more what kind of physical reaction you want I can try to explain more, better make a new question because these are 2 different topics. I hope I could help you. If you have further questions just tell us. Michael 

In unity, SortingLayers (or camera layers for that matter) are not groups of object you should see them as tags : specifically for the sprites, sorting layers are used to define the order of render of the objects. you can go through all the sprite-renderers and check their layers and apply something to their transforms but that will consume "a lot"* of resources. better solution is to really group your objects by parenting them to the same transform, and then you move that transform. For ex : 30 objects and you want to make three "layers" (but once again it is parallax layers not sorting layers (they can be related (you want stuff to be drawn in order) but are not the same thing)) what you would do in that case if create three empty game objects and drag 10 object onto each of them, then you'd move those 3 game objects according to the camera to achieve the parallax effect 

Actually for that particular case for future reference i want to add as answer that restarting my computer did gave me 60FPS after reboot on the emulator, without changing anything, with more optimization it could go even faster. @concept3d answer is still the valid one though and the article about why FPS is an incomplete indicator is a perfect reference 

Either two sprites backing together, or a custom shader with no Backface culling could be the way to go, you could use a mod of the original sprite shader which is here : Unity Built-in Shaders (select the last version and you should find them in the same order as in the menu) I did a shader once with a different texture on each side, with the same vertex count but i'm not close to my code right now. EDIT : If you go for the custom shader dont forget to create a material and associate it with your sprites. I just realized by the way that there could be an issue with the fact that the Sprite renderer accepts only one texture, but you could trick it by making a texture with the front and back on the same texture, and then offsetting your UV's to match the correct positions.