Disadvantages can depend on your specific use case. For example, I cannot know if, for some obscure reason, you want to be able to add a column only for a set of customers. The only "standard" disadvantage that I have on the top of my mind is that you won't be able to store some partitions on a different media. But there are reasons not to do that (for example, backups manageability). Also, MySQL never parallelise queries - so, in this respect, there is no difference between using partitioning or using separate tables. 

Nice question. My objection to your design is: you choose to consider user input and predefined input as the same thing (the only difference being the value of ). But they are not, in my opinion. Because predefined input are different options, but different user inputs could indicate the same idea written with synonyms, wrong spellings, etc, or could be just jokes or junk characters. You say that this saves you from having empty strings or NULLs. But I believe that the absence of a value (custom text) is a valid use for an empty string. 

I'll assume that the last 2 queries have the same execution plan (something you can check with ). But I suggest you check if the execution plan is optimal, which means, if an index is used for both the and the clauses. The answer to your question is simple: cache. Data that are read from time to time are probably stored in InnoDB buffer pool, others aren't. Check if you can increase innodb_buffer_pool_size - the general recommendation is, 80% of total memory. 

So triggers are a fundamental part of the process (unless the table is readonly or you are definitely sure that no one is going to modify it now). The problem is that, before MySQL 5.8 and MariaDB 10.3, you can have only one triggers for each combination of table + timing + event. For example, your table can have only one trigger . One thing you can try is, turn your existing triggers to - unless you already have an trigger, this will do the trick. And do the same with INSERT and triggers. Or try to use from GitHub, as someone already suggested. This would work because this tool doesn't create any triggers: instead, it reads the binary log and applies the changes to the new table manually. 

You don't need to query all databases, and anyway you can't. You need to query only one database called , which contains all metadata about your databases (table structures, etc). Here is the query you want: 

Yes, you can do it. Be sure to keep innodb_lock_wait_timeout readonably low, for example 2 seconds. Deadlock that last for 2 seconds are completely harmless, if they are rare (and usually they are very rare). Remind developers to avoid long transactions, and avoid foreign keys (because they propagate locks, making deadlocks more likely). Of course I am assuming that you can keep a very low value for those timeouts. But can you? I don't know your workload but, for example, a statement may lock some rows for 10 seconds every hour. In such cases, can you afford a low timeout? If not, then everything I wrote above does not apply to you. 

No, you cannot alter an index. Because, even if PostgreSQL allowed this, it would need to rebuild the index anyway. Unless it implemented very smart checks on the clause, which would serve quite rare use cases. Having many indexes is also not optimal. Every time you run a query, the planner has to consider all existing indexes and pick up the best one. If you have several indexes, the planner takes more time. Not ages - but still, this delay affects each and every query involving that table. My suggestion is... be patient and build a big index. You can use to avoid locks. 

gh-ost is very similar, the main difference is that it creates no triggers, and uses the binary log instead to detect the changes to the original table. To answer your question more directly - yes, it is possible to add a column on the slave. And most probably it will simply work, as long as it has a default value. But it is very likely that in the future you will regret this choice, because you'll need to do something that will break replication. I recommend to sure to check the documentation and fully understand the dangers, before doing such a thing. 

This will do what you asked. But in your examples "domain.com" is always at the end of the string. To look for strings ending with a certain substring: 

Why does the documentation state that InnoDB uses B-Tree? Well, not all MySQL users are supposed to know what B+Tree is. This may be an oversimplification, but in that context it seems to me acceptable. You wrote that you know the difference between B-Tree and B+Tree. Than the different performance characteristics should be clear: 

I don't think that helps with free space reclaiming. It will only update index statistic. You could run without , I think it will reclaim space immediately if the table is empty (otherwise it will just update the free space map). But if you completely remove old rows, will be much better: it will reclaim disk space immediately. 

The order columns is important. If you reverse it, the index will not be useful. Now you just need to run a query like this: 

Dave's answer is good, I would like to add that there is a big difference between OLTP and data warehouse. If the database is used for DWH, having many columns in the same table will save a lot of s, which is good. In that case, you typically have a small number of queries and they are big. Writes are scheduled and you probably don't care much about their performance. 

As you may know, the problem with master-master setup is conflicts. If the same row is (for example) deleted and updated at the same time on different masters, this will result in a replication breakage. You mention that you want to do this only for failover, but then this risk remains during failover. For example, you want to upgrade master1. You switch the DNSs. New writes are directed to master2. A long transaction completes on master1, it's replicated to master2, and a conflict happens. This can also happen if whatever you are using to automate the failover cannot connect to master1 for some seconds, but master1 is still running. It switches. New writes go to master2. Some clients are still connected to master1, they write, conflict happens. Of course reusing the same connections (for example via a proxy) will increase this risk - but still, I consider it as a good optimization. Other possible disaster causes include human errors. You do something manually with your data, but you do it on master2 by mistake, et voila' a conflict appears. This should answer your question "what could go wrong", but there is one more important point: someday you may need to scale more, and not only reads. In most cases, one cannot simply distribute the writes and maybe even add one more master - because of conflicts. I am not saying that master-master is bad. I use it. But I suggest you to evaluate 2 alternatives, in case you didn't: 

You could in theory, but MySQL doesn't allow the trigger to query the same table. In other words you should create a trigger for table , and the trigger should run a on , but this is not possible, you would get an error. An alternative is to add a column to table, which contains the number of students. The initial value should be 0, then you could update that value with a trigger on the table . There should also be a trigger and - even if apparently it doesn't make sense - it's better to have a trigger , which checks if you are changing the class of a member. 

Another thing is, sometimes every server is restarted. When it happens, if the buffer pool is simply emptied, your queries will be slower after restart - until hot data are cached again. But you can avoid this by setting: 

In this way, your buffer pool will be (partially) written to disk on shutdown and reloaded at startup, so your queries should be fast even after a restart. 

Only one primary key per table is permitted. But a primary key can consist of any number of columns. Having many columns in a primary key however is often (not always) a bad choice. Some notes about this... 

Just try to connect in a non-secure way and be sure it doesn't work. If you are not sure wether you are using SSL or not to connect, then yes, the simplest way is using the command line client: 

I've seen ALTER TABLEs running for days. The problem is not a timeout, the problem is that if the query fails at some point, you'll have to restart it from scratch. But what is your use case exactly? The server will continue to accept queries from the applications? If not, your idea is ok, I see no caveats. Otherwise, use . It is designed for this purpose, and it avoids to overload a server. However: don't disable the binlog! You will break incremental backups for no reason! Just run . Instead, if the server doesn't need to accepts connections from applications, and the table is InnoDB, you can restart it with . The operation will be much faster. But then remember (it's vital) to restart it again, without that option. 

Logical data is how your applications see the data, and how they query data. In the case of a relational database, the design of tables, along with their columns and relationships, is the logical model. In other database models the logical level could be queues, collections, or any type of data structure used by applications. But how are those data structures written to disks (and to memory)? That is the physical layer. It is the set of files written to disk to contain data, and the format used to represent data in such files. So what is the independence between physical and logical layers? It is the principle that states that programs which query a database don't need to know how it stores data physically. For example, an SQL query mentions table and columns, not files and bytes from that file. 

MariaDB doesn't have that variable, MySQL has. MariaDB is not a drop-in replacement for MySQL. The error you see makes me think that replication from 10.1 to 5.7 is not possible. One could investigate more, but take a look at this compatibility table: there is not an explicit incompatibility statement, but at least they don't guarantee that replicating from 10.1 to 5.7 is possible. Even if you choose to assume that such replication is possible and find a way to set it up, MySQL supports some syntax that MariaDB 10.1 does not support - not because it's more advanced, but because they took different directions. Such statements will break replication. 

If you are learning MySQL, skipping MEMORY storage engine is not a bad idea. InnoDB is the default storage engine and it is suitable for most cases. Only in edge cases it makes sense to use another one, and you probably shouldn't consider this option before knowing InnoDB quite well. However, to answer your question, first let's check pro's and con's of MEMORY. Cons: 

I think that is because you don't assign it a value. And after you increment it, nothing changes because . Also your UPDATE will not work if is not 0. Unrelated: I suggest to use a foreign key instead of . 

Why does show ? I'm not sure. But technically, whenever you don't use a secondary index, you always use the primary key - because data are stored in the primary key, just not in a particular order. 

It doesn't mention TokuDB (despite it being distributed with MariaDB), so I would exclude that this engine is supported. 

So the question becomes, which use cases don't suffer because of the cons and take advantage of the pro's? Well, a first obvious generic answer is, avoid all use cases where data loss is a problem. More specifically, you could consider MEMORY for: 

InnoDB uses B+Tree indexes, not B-Tree. All details about InnoDB data structures can be found here. You may also want to look at these diagrams. The author of both the resources, Jeremy Cole, was head of MySQL team at Google. Why is the syntax instead of ? This question should be posed to some MySQL or MariaDB engineer, but I see at least two possible reasons: 

No, there is clearly no good reason. Most probably the index originally contained another column that has been dropped - at least, this is the only explanation from the top of my mind. 

Walter Mitty's answer is good, but I'd like to add something. If the column contains unique values, the surrogate key (the column) can be added only for performance reasons. But this makes little sense if the other column is small (integer, date...) and the DBMS does not organise tables by primary key (like InnoDB). Or it does, but the table is almost read-only. For example, even performance considerations advice against adding a surrogate key, if the other column is something like , or . On a more theoretical note: an entity can even have zero attributes. Since all tuples and tables are unique by definition, in relational algebra exactly 2 tables exist with 0 columns: one is empty, one has 1 tuple with 0 columns. But in practice, I don't know if such tables can be created in an existing RDBMS, and I don't know if SQL standard allows this. 

Tables with the same structure but different sets of rows are sometimes called orthogonal tables. I don't believe in universal truths in the database world (which means: your use case could have peculiarities that I am not considering), but in general I consider orthogonal tables a bad idea. From a theoretic perspective I can tell you that I especially don't like using metadata (table names) as data (age range). But what does it mean? Tables designed in this way prevent you from running easily multi-table queries, like these: 

Because the query has finished and InnoDB doesn't know anymore what query it was. does not guarantee to give you this information. However you have the thread id and you know at what time the deadlock was detected. You can use to check which queries that thread executed at that time or before that. Even if you use the ROW format (recommended), you will still see useful information. Or, maybe you have the slow log enabled. You probably have that query logged - especially if you have , which I recommend. 

You should edit the original question to add information, instead of replying yourself. However, if these are really the steps you followed: 

I think that, if your purpose is to avoid locking, you should use pt-online-schema-change (a tool from Percona Toolkit) or Gh-ost (from GitHub). Here is how pt-osc works: 

The obvious answer is: . There is no optimisation for this, it just counts all entries in the primary key. Of course anything requiring a full table scan or a full index scan will be really slow. Optimised queries should not be slow. Slower? Yes, because indexes will be quite big. You can always partition the table, and your queries will read smaller portions of indexes (but don't expect any type of parallelisation). Of course to be sure about the performance you should run a test. If you have the applications queries written in a binary log or slow log, replay the log with some tool or a custom script. If you don't have, write some realistic queries and make a test with sysbench (some trivial lines of lua language are required). 

As you probably know, the way to do this is a foreign key whith . But you don't want this, so I see 2 options (there may be more as I'm not a SQL Server expert): 

But in general, B+Tree is considered superior. How much? I don't know, but surely not orders of magnitude. 

If the data you are talking about is big, of course having a different table for each customer will make your queries faster, because both data and indexes will be smaller. And - assuming that you use - you will have other advantages concerning operations, for example if one table gets corrupted InnoDB will need to repair a smaller quantity of data. Another solution, probably a bit cleaner, is using partitioning. You can physically partition a table into more files, so the effect is the same: the portion of data and indexes you query will be smaller. You can partition by customer id. Some advantages are: