Work with differences between angles, not absolute angles. Make sure that (where appropriate for the application) you are treating any particular angle θ as equivalent to θ + 2π. This is the reason for all of the uses of modulo; the π offsets are used to control where we flip from positive to negative numbers, which affects the overall behavior of the algorithm, but not in a way which is dependent on the input range. 

Now the actual algorithm. is the start point of the wave, the ending point (both vectors). is the amplitude of the wave: the maximum distance away from the center-line it reaches. is the number of points to generate. is the number of repetitions of the sine wave (I think your code has this at ). 

Note that these options are different not just in efficiency but in the resulting behavior of the game: a periodically triggered set will cause voxels to update all in sync at the same instant (there can be no phase difference), whereas the priority queue can represent the exact time instants of something like "this voxel does something 1.5 seconds after it comes into existence, and every 1.5 seconds after", but takes more resources to manage that extra information. 

Note that in the second case we divide rather than multiply. This is simply because we computed the aspect ratio as rather than ; take the reciprocal if you find it easier to understand that way. Again, this is not the only way to manage aspect ratio; this is just a very simple one for making sure that your content is neither squished nor cut off. Figure out what you want to happen when your window is wide, tall, or whatever; then work out the mathematics of it. 

As to the specific mathematics of the matter, given that you are doing resolution independence, all you need to start out with is the aspect ratio, a single number: . For example, if the window is square it will be 1; if it is 800 by 600 it will be 800/600 = 4/3 = 1.333̅. For example, suppose you want the orthographic projection you have written to gain additional space on the left and right sides if the window is widened. You can do that like this: 

Per-pixel image processing on the CPU is something where microöptimization is worth thinking about from the start. You're doing memory allocation and object initialization on a per-pixel basis; this is probably most of your problem. The first thing you should do is figure out how to use only arrays of primitives ( etc.) to perform your computation. 

I'm not familiar with libgdx, and you haven't provided any code showing what you're doing, but it looks like you're applying the transformations in the opposite order than you should. Swap the translation (tile position) and the rotation (orientation of the upright item), apply any needed small corrections and you'll be fine. 

Looks like a simple typo - you are updating tempPoint.z using varX, not varZ, so your coordinates move in unison and the shape collapses to a line. This is a common sort of mistake when writing componentwise math and you should learn to recognize the symptom. Avoiding this mistake can be helped by using vector operations where possible, like where var is a vector instead of varX and varZ. 

These two methods are completely equivalent except for needing slightly different values for . (If you want to learn the math behind this, looking up compound interest and continuous compounding would be a place to start.) 

Yes, this is a reasonable approach. Note that in principle what you need is not an array, but a set. This is relevant because if one of your active voxels is destroyed/replaced, you need to be able to efficiently remove it from the set. If your platform doesn't have a set type, then use a hash table with the voxel coordinates as keys and dummy values. Another case that might arise is a voxel which does something on a schedule (once or repeating), but not every frame. If you want to support this efficiently, then you should keep track of the voxels to be triggered and the in-game-time to trigger them, and the best kind of data structure for that is a priority queue, which allows you to efficiently ask the question “which voxel needs to run next?” so you don't have to check the entire set. However, if you have many voxels which should update on the same schedule, but less than every frame, the set approach is again appropriate; you simply don't do it every frame. (If you need to spread the CPU load you could choose to do part of the work in each frame. Say you're doing it every 3 frames: Copy the set into an array, divide the length by 3, and iterate over one third for each of the next three frames.) 

There are two possible causes for this type of problem, depending on exactly which problem it is. I'll list both: 1. You are seeing other colors from your texture along the edges of the tiles. This looks to me like the problem in this case, because all of the edge pixels are one of three colors which are plausibly in your texture: white, black, and brown. If you are using multiple tile images right next to each other in a single texture (a texture atlas), as I assume you are doing, this is inevitable. It occurs because the GPU does not perfectly match up interpolation along the edge of a triangle with interpolation along the texture, and you get little bits of the adjacent texture. There are a number of things you can do. 

I haven't debugged your code for you, so here are some bits of general advice on how to make things more robust: 

There's a lot of variety in how you could do this; I'm going to suggest the “obvious to me” choices, but there are lots of variations that could be designed. Disclaimer: I haven't actually implemented anything like this. First, you need a data structure that covers your world. If you are doing NPC movement in a 3D space, then you probably have, or will eventually need, such a structure for pathfinding purposes — say, a navigation mesh. So, let's assume we can add a field for scents to that. So, what do we put in that field? I propose a list of records (scent, strength, time). This list is kept at or below a maximum length, and sorted by strength — so weak scents will be discarded. The scent could be either something explicitly defined for each entity or entity type, or it could simply be the entity type — depending on what you want to be able to track distinctly. The time is a timestamp of when this scent record was last updated. When an entity passes through an area (e.g. a given triangle of the navigation mesh), it's time to update the scent list. First, decrease all the strengths according to the amount of time passed according to the time value vs. the current time — exponential decay is probably a reasonable choice here. Then add the current entity's scent to the list, perhaps with a strength dependent on the entity type. Then if the list just got too long, discard the lowest strength. To obtain a tracking result, find the scent in the list for the current location, then do the same for all of its neighbors, and go in the direction of the strongest scent (that isn't the direction the tracker just came from). For extra realism: 

This guarantees that, for windows at least as wide as they are tall, anything you draw with x and y coordinates within -50 to 50 will be visible. On the other hand, if the window is narrower than it is tall, the -50-to-50 range will be cut off. Let's say you wanted to make sure that it is always visible (so that your content is at its maximum size if the window is square, but smaller otherwise); in that case, you simply do the same thing to the height instead of the width. 

This is probably not better than offsetting the coordinates to produce a texturable triangle strip, and I haven't tested it, but since you're looking for ideas: Use a thick line width, and a fragment shader which draws a glow on one side by comparing the interpolated projected vertex coordinate (passed from the vertex shader) to and deriving a gradient from the difference. I don't know exactly how varyings are interpolated on thick lines, so I don't know how well this will actually work. Note that wide lines may be inefficient or even not supported by your hardware. 

I'm not familiar with DirectX, but the BoundingFrustum docs you link to say that it can be constructed from a projection matrix. All you need to do, then, is multiply your actual projection matrix by a matrix which (if you used it to draw with) would scale/translate the graphics so that the rectangle you want fills the viewport, then use that matrix product to construct a BoundingFrustum. The matrix should just be an appropriate scale and translation in X and Y coordinates. You can test it out by actually drawing using the modified projection matrix. 

In this way, you don't have to implement any additional architectural features to support the development feature of hot reload: you only need the game-save feature that you will likely be writing anyway, and your development process will thus also give a thorough workout to the save feature — including loading old saves in new “versions” of the game, something which is tricky and likely to annoy players if done wrong!