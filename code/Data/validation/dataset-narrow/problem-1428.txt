The client and the server will go out of sync eventually, so you'll have a smoother game if you interpolate instead of simulating with the server and then correcting, but this will induce extra lag. You cannot answer this definitely, it's up to you to decide which suits your application better. Also your questions seems a bit lacking in terms of describing what is actually happening in your game/application. 

If you want it to be fast too, you need to render it with a custom pixel-masking shader, it should be just as simple as this process, if you know how to use shaders, but i do not know how to help you there. Edit: An easy way get this running in an approximated way is to just draw a particle effect at the point of the impact like Felsir suggested, which is also rotated towards the center of the ship (or just center of the texture). You probably won't see a huge difference between this and a masked shield texture, it'll be a lot faster too. 

I am refactoring some parts of the game engine I am working on. This engine is made in C# with XNA. The part I have trouble with is shader/material and the render queue. In the new version I will give ability to indicate differents render states per pass within a technique (blend state, rasterizer state, ...). In my engine, all renderables have a material and each material is associated to one technique (thus to one or more passes). Later, when the game will be running, I will add renderable objects to the render queue and then sort it based on the pass used by each material. What I want to achieve is to reduce states changes between draw calls by first grouping same passes together and then passes with nearly identical states to be as closed as possible to minimize changes. But this solution seems to be problematic when it comes to use technique with more than one pass with completely different states. Passes within a same technique can be completely separated in the render queue and not rendered one after the other. If I say that it's because I have always see multi-passes technique render in a loop and all passes rendered immediately like that : 

.blend files are not supposed to be used in games directly. You should first export them to another format (obj, 3ds, own custom format..) and use that in your game instead. .blend files (blender project files) are to 3D models what .psd files (Photoshop project files) are to 2D pictures. You wouldn't put a Photoshop project file on the web, but use jpeg, png, etc. instead. While .blend files are great for editing purposes, they store lots of useless information, e.g. your game doesn't care about layers. Such features make .blend files complex and slow to load in your game. You should research whether one of the existing formats is good enough for you ("supports enough bone weights" and other requirements), then pick one to export to, as described in $URL$ If none of the existing formats is good enough for you, you might want to install a 3rd party export plugin for blender or write your own exporter. You will then need to teach your game engine to load the chosen file format. 

But it doesn't work at all and I don't find what's going wrong. Objects in my scene seems to appear and disappear in a strange way, sometimes appears when I'm not watching them or disappears when frustum faces them (I look at draw calls to determine if the isVisible test returns true or false). Here is my code: The Axis-aligned bounding box 

The smallest increment you can do on a float in C# and have a significant value to be different from 0 is float.Epsilon. From MSDN Single.Epsilon 

_signPlane is an array of Vector3 using the following formula and applied for each plane once per frame when the frustum is updated: 

$URL$ Edit: Sorry for the french reference but i haven't find any date on the english wikipedia. The translation is: 

I'm trying to implement an axis-aligned bounding box with center/half-size instead of min/max. And I have some problems when it comes to create a method to detect if the aabb is visible or not. I try to do the same as on this website at "Method 5": $URL$ I'm trying to implement this formula: 

You made a simple mistake there, you go through your array, and as soon as the cell you look at does not have the specified item in it, you insert it into that cell or go on if it already has something else in it: 

Now you have the total angle that you need to use for you cannon. Keep in mind that you may need to translate from radians to degrees. You may also need to offset the angle by 90 degrees or so depending on where 0 degrees are in your coordinate system. 

So, i figured out how to do it quick and dirty, i subclassed Array (libGDX.util) to allow for faster removal of Entities and then i swapped it with the normal Array inside the Engine class of Ashley: 

Now I have three models to draw, Model1, Model2 and Model3, each one use a different technique from the previous list. If I add those three models in the render queue I will end up with the following render queue : -> Set state A -> Draw Model1(Pass1) -> Draw Model2(Pass1) -> Draw Model3(Pass1) -> Set state C -> Draw Model1(Pass2) We can see that the Model1 will be drawn two times (two passes for the Technique A) but the draw call are separated by others draw call. I don't know how to resolve this. What will be a good solution to this problem? How can I design my render queue to reduce state changes as much as possible between draw calls. EDIT: After searching a little more, I have found this helpful article : $URL$ It seems to be an elegant way to sort object by depth and materials. And in the material id, I can had a pass id to sort same pass together that will allow to reduce state changes. Currently my renderer draw objects directly in the backbuffer without lights nor shadows, everything is flat. So I will just loop over my render queue and call draw methods. But in a future I will probably implement deferred rendering. I don't know a lot about it but I know that I have to render my objects in different render target to gather differents informations (Z-buffer, Normal buffer, G-Buffer, ...). I assume that for z-buffer and normal buffer I will use the same shader on every objects no matter which material they use. But for the G-buffer I will use the materials of each object so that means different shaders with different number of pass. If I use the solution in the previous link, if I have an object with a material that needs to do two or more passes, my render queue will have at least two times the object (one for each pass). But for Z-buffer or normal buffer isn't it useless to have the same object multiple times? What I see is that I will need to have at least two different render queue : one for G-buffer in which an object can be multiple times depending on the number of pass the material require and another render queue for Z-buffer or other buffer in which each objects are only one time. Am I right? 

It's important, that you set your Sprites height to and you may need to move around your a bit but that shouldn't be that hard. 

This doesn't support all features of its superclass Array, only enough to be used with Ashleys Family-Assignment-Code, so it's probably very buggy without further editing it! 

Of which , and are chosen when spawning the plane and then never touched again by the random movement code and the others are used to steer it (randomly) towards it's target. To move the plane, this is getting executed each tick (delta is the time between two updates): 

You can do this via masking on the cpu if you prefer to not use shaders yet. You'll need these resources: 

So what you could do with this: 1. Loops and turns You set to a random positive or negative value, and leave it like that until you reach a randomly chosen Angle (or for a randomly chosen time or until you are heading towards a randomly chosen point, whatever works best) and then set to smoothly decrease your turnrate until is zero again. In the image, two example-paths are shown, red is the acceleration phase, green the deceleration phase. 

Your answer to the collision problem is true/false. Instead you can differentiate between no collision, penetration of the object and touching the object. Then only disallow movement in the case of penetration, but allow touching. I'd also suggest you move the collision code out of your tank and GameObject. Tanks and GameObjects both really just contain a collection of collision shapes. Your collision code doesn't care about anything but the shapes (perhaps also their old position, rotation, movement direction and speed). You don't want to write new collision code every time you add a new kind of actor. This is basically composition versus inheritance at work. 

I'm not quite sure whether I understand you correctly, but you can assign different buffer objects to different attributes. The buffer object currently bound while calling glVertexAttribPointer will be used as the data source: 

But I don't know if I can deferred pass rendering from a same technique instead of using them one after the other as in the previous example. Here is an example of what will probably happen with the solution I try to build: 

I've just tried to draw it normally and it appears at the center of the scene. After that, i don't know what to do to make it appears at the bottom left of the screen regardless of where the camera looks, as if that was part of the UI. 3DSMax has the same thing at the bottom left of each frame. 

Input.GetButtonDown is fired during the frame when user pressed the button. The function return true only one time when user pressed it. From the Unity Script Reference: Input.GetButtonDown() 

In addition to the tools NathanReed mentioned, ImageMagick can now also do this. It supports more source (and target) formats than the NVidia texture tools, which is quite convenient, and allows performing lots of image operations during conversion (like flipping, scaling to powers of two etc). $URL$ Example: 

In your call to glViewport you are specifying less pixels in width and height. Your projection matrix is defined in terms of pixels. That's why you will have to calculate a new projection matrix after a glViewport call. 

You seem to be confused about the link process in general, so sorry if I go a bit on a tangent first. You need to differentiate between object files, static libraries and dynamic libraries. Apple adds "Frameworks" to the mix in OSX. They are just one possible way of adding foreign code into your executable. Roughly speaking: