It probably depends on what it's for and what your employee is telling you to do (if you get to that stage). If this is just for yourself, don't bother with Autocad, just use Max, it's so much more fun. Max and Maya are great tools for 3d visualization, I've seen some wicked home interiors made with these packages. You can model everything in Max for visualization, but if you need technical specs then Autocad might be the way to go. Listen to what anyone says about Autocad, because I don't know it much, I've studied Max and to a lesser degree Maya. So an autocad user might have some things to consider. 

Can I just suggest that you absolutely forget about biomes if you can't make and use height-maps yet. Step by step is the way to go. 

Well, this is both funny and painful because of how much time I spent trying to resolve this issue. The corruption might have been a clue. I loaded up the program tonight and the issue is non-existent now. It turned out to be a driver issue, because I have just installed the AMD Catalyst 11.10 Preview driver and haven't touched the re-sizing code. That makes sense. :) 

I agree mostly with Asher, XNA is ... was a good language to learn on and C# is very intuitive and far easier to work with than C++. C# and Java are incredibly similar, so you'll feel something familiar there. What you know in C++ can be applied to C#, you just have to forget about all the annoying and confusing stuff :) But if you are going to learn a framework, just start learning SlimDX, I've recently given up on XNA because well... it's based upon DX9, an aging framework, and it looks like XNA has reached the end of the road. It cannot run DX10/11 under the hood, and that's what you want to be using. That is current technology. Using SlimDX is incredibly similar to using XNA but it is far more powerful and you know you are learning current technology. 

Never used it myself, but there was some interest a while back (or maybe still is) in Collada. Projects I've worked on have always rolled our own export formats, you'll always have exactly what you want that way, just depends how much work you want to do. 

A 10-minute implementation of a simple spring system (or so he says on his blog ;) ). The system can handle multiple warps and other things distorting the grid. Updated to add some minor addition detail: A few other details. From an interview that used to be hosted on the Bizarre Creations website (that site has now disappeared due to the company closure) there was a question: Q: One of the most striking new graphical features in the game is the "gravity grid" play area. How did you make this look so cool; does every object in the game really have its own gravity? The grid itself is made up of 60,000 points, each one exerting a small amount of force on its neighbour. The simulation itself sits on the edge of stability which is what causes it to swing about so much when one of the game objects gives it a small push! Only a few types of object affect the grid. As the grid system is rather expensive to calculate, it actually runs on the second core along with the audio system, (the first core being dedicated to gameplay and particles, the third is used to render the audio). 

imagine the +'s as the vertices of your mesh. Simply randomize the height of the corner verts (A,B,C,D), then average the mid-verts between these, with a little randomness as well. Keep doing this foreach mid-vert until all your verts are positioned in the z direction. You'll end up with a fairly natural looking terrain. There are all sorts of ways in which you can modify your height algorithm, using various noise and smoothing methods. There's not really any math behind generating a simple terrain mesh. Not until you look at more complex methods, when you're after more interesting results. But you have to be comfortable with generating height maps first. 

But this doesn't behave as expected. The geometry is a dark red, when it should be white. What the turtle is going on here. 

Forget about tessellation and compute shaders. You simply want to maintain a system copy of the terrain and send it (or parts of it) to the GPU every frame. Yes it's slow, but it ain't that slow :) The trick is to make the section your updating small enough to not bog down the computer. So you don't want to be updating a terrain 1000x1000 tiles. Use chunks of terrain, I use 16x16 tile chunks with 4 tri's per tile, indexed. I can update a terrain chunk in real time no problems. I was going to suggest a dynamic vertex buffer, but you don't even need that.. here's the code i use to update geometry, just use the default resource usage : 

Do you want to capture the screenshot from within the game for some purpose, or from a development PC? From the development PC there are simple facilities provided, you easily use the Target Manager SDK to achieve this (you'll need to read the full description to see what else you need to set up as specifics are NDA'd). From within the game, the simplest way is to insert something after the frame has been rendered to first flush the GPU (to ensure that everything has finished being rendered before you continue). The game should have a pointer to the current frame buffer somewhere, you'll know the format of that buffer (the stride, etc), you can then do what you want, including writing it out in a format of your own choice with a little work. 

Just look at what the big games do. They have the ability to scale. Some automatically, some manually. Detect the capabilities of the platform you're trying to run on and adapt as best you can. Maybe ship with assets at different levels of detail and use the highest you can. 

You'll usually find the graphics card manufacturers provide decent tools for compression textures, such as Nvidia here. These seem to be supported on multiple platforms. For hardware accelerated rendering you'll not find any lossless formats supported that offer any compression. The most popular current formats supported for example by graphics cards under DirectX are DXT1/3/5 for images, DXTN for normal maps. I don't use OpenGL but I'd expect these to be supported even if called something slightly different. I've typically seen DXT textures zip to about half their original size, so it's possible just using zlib will get you the same end result (then decompress before uploading to the gfx hardware). 

Isn't it as simple as rendering your gun geometry (or 2d HUD style gun) near the camera and narrow the field of view. 

I can't find a way to simply set a uint to a shader constant variable. But the following is a workaround : 

Can I recommend getting 2d shadows working first, even if it's just for the level that your avatar is currently on. It will be easier to start looking at the code that way and get it working. I have implemented shadows in 2d tile maps in a couple of ways. One shadowcasting method which I found described by Eric Lippert at Microsoft works quite well. And the other way, which I did myself first time i looked at this kind of thing was to orthogonally sweep the visible tiles and tile-edges and generate edges (and maybe corners iirc) describing the scene in the lowest number of edges. You can then cull hidden edges and form any custom shadowing features such as recessed shadows if you want to show a little bit of wall. Then create your shadow geometry (projective shadow casting ?) and render it over the top. But if I try to take that idea to 3d, it just becomes easier to do it in 3d. While the method described by Eric Lippert could presumably be converted to 3d. But I think you'll find that doing it in 3d is expensive. Perhaps take a look at the source code for Brogue as well. It may have a more efficient implementation for 2d visibility/shadow casting. Good luck.