This problem is known as MAX-COVER. A good algorithm for MAX-COVER is the greedy algorithm: at each stage, we pick a set which maximizes the number of uncovered elements. This algorithm produces a cover of size $s$ which covers a fraction of $1-1/e$ of the optimum. Feige proved that it is NP-hard to outperform this algorithm by any constant. 

No. Consider the following function on $\{0,1\}^n$: $$ f(x) = x_0 \land \cdots \land x_{n-\sqrt{n}-1} \land (x_{n-\sqrt{n}} \oplus \cdots \oplus x_{n-1}). $$ Clearly this function is hard for AC0. On the other hand, the function is almost constant, so almost all of its Fourier spectrum is on the first level. If you want a balanced counterexample, consider $$ g(x) = x_0 \oplus \left[x_1 \land \cdots \land x_{n-\sqrt{n}-1} \land (x_{n-\sqrt{n}} \oplus \cdots \oplus x_{n-1})\right]. $$ This function is almost always equal to $x_0$, so almost all of its Fourier spectrum is on the first two levels. 

Not exactly what you asked for, but a context in which similar circuits appear. If you remove the gate $1-x$ (which is not even mentioned in the title!) then what you get is a monotone arithmetic circuit. The classical monotone circuit lower bounds of Razborov have been extended to monotone arithmetic circuits (with the same results) by Pavel Pudl√°k, Lower bounds for resolution and cutting planes proofs. 

The usual proof that the halting problem is undecidable already gives you exactly such an algorithm. Given an algorithm $A$, we construct an algorithm $B$ that on input $x$ computes $A$ on program $x$ and input $x$, and then enters an infinite loop iff $A$ answered "halts". Now consider giving $B$ itself as an input. If $A(B,B)=\text{"halts"}$ then $B$ doesn't halt on $B$, so $A$ is wrong. Same if $A(B,B)=\text{"doesn't halt"}$. So $\langle B,B\rangle$ is an example input on which $A$ is wrong. 

Elaborating on Mike's answer and Vazirani's comment, you get the dual by considering the general form of an optimality proof for the solution to the original problem. Suppose you have a maximization problem given some linear inequalities, and without loss of generality, suppose you're trying to maximize the variable $x$. Given a solution in which $x = B$, how do we know that it's optimal? One way is to try to get a bound on $x$ by taking linear combinations of the linear inequalities. Some linear combinations give you a bounds of the form $x \leq C$, and you're trying to get the best (minimal) $C$ possible. Weak duality states that $B \leq \min C$, which is obvious by definition. Strong duality states that when $B$ is finite, then $B = \min C$. This means that if the maximum is $B$ then there is a "reason" that you can't get beyond $B$, which doubles as a proof of optimality. This point of view is actually helpful sometimes. Let $f$ be a set function ($f$ takes a set and outputs a real number), and $S,O$ be two sets. Suppose you're trying to derive an inequality $f(S) \geq (1-1/e) f(O)$ from a bunch of inequalities regarding the function $f$ (that's a real-life example). You write a linear program in which the values of $f$ are the variables, $f(O) = 1$ is a constraint, and the objective is to minimize $f(S)$. The solution to this program is $\min f(S) = 1-1/e$ (let's assume $1-1/e$ is best-possible), and the solution to the dual gives you a proof of $f(S) \geq 1-1/e$. This leaves open the question of why strong duality actually holds. There are two proofs of this fact for linear programming, one involving the simplex algorithm, the other Farkas's lemma. Farkas's lemma is probably the "correct" way to understand the situation, reducing everything to some intuitive geometric fact. However, I confess that this intuition goes over my head. In more general situations (let's say semidefinite programming), you need to use the more general Karush-Kuhn-Tucker conditions (a form of Lagrange multipliers) to get the dual and conditions for strong duality. This is treated in texts on non-linear or convex optimization. 

This is another classical example of inductive enumeration. I assume that we are given some DFA for the language $L$ over an ordered alphabet $\Sigma$. Let's start with the easier case of words of length $n$. Using linear algebra, given a prefix $w$, we can compute efficiently $N(w,m) = |\{ x \in \Sigma^m : wx \in L\}|$. Define $N(m) = N(\epsilon,m)$ for short (this is the number of words of length $m$). We define the code $C'(w)$ of a word $w \in L$ as follows: $$ C'(a_1\cdots a_n) = \sum_{i=1}^n \sum_{b < a_i} N(a_1\cdots a_{i-1} b,n-i). $$ In order to code words of arbitrary length, we simply use the formula $$ C(w) = \sum_{n<|w|} N(n) + C'(w). $$ It is straightforward to compute the inverse of this encoding. This encoding deviates from your specification by ordering first according to length and only then lexicographically, but as dkuper mentions this is unavoidable if you want your range to be $\omega$ rather than a more exotic linear order. There could be a "trick" which allows using simpler formulas in this particular case, but this is the basic idea. 

The best known example is probably checkers (also known as draughts), which has been solved recently in 2007 (the game is a draw). Other examples are listed in the Wikipedia page on solved games; notable among them are connect four and nine men's morris. Additionally, several chess endgames have been solved. This perhaps doesn't seem like an answer to your question, but if an expert (such as Marion Tinsley) loses to a computer program, then the computer must have found a "more optimal" move. 

Given a Turing machine $T$ and an a number $n$ encoded in unary, decide whether $T$ halts in time $2^n$. There is an $O(C^n)$ algorithm for this, and there's an almost matching $\Omega(c^n)$ lower bound (where $c < C$). See the proof of the Time Hierarchy Theorem. If you're looking for more natural problems, Wikipedia has a list of EXPTIME-complete problems, such as evaluating positions in certain generalized versions of board games, and problems involving succinct circuits. 

Let's assume that your three-valued logic consists of the truth values Yes, No and "unknown". We can think of these truth values as the sets $\{\top\}, \{\bot\}, \{\top,\bot\}$, and then the logical operations result in all possible values. For example, Yes and Unknown is Unknown while No and Unknown is No. A trick known as "double rail logic" uses two binary variables to represent each truth value: Yes is 1,1; No is 0,0; and Unknown is 1;0. The connectives And and Or are implemented using two matching gates, and Not by two negation gates followed by a swap. More generally, $k$-valued logic can be implemented by encoding each truth value using $\lceil\log_2 k\rceil$ bits. The logical operations are implemented using constant-size Boolean circuits. The advantage of the encoding above is that the circuits are very simple, in particular they read each input only once. 

Perhaps you'd be interested in switching networks. According to Potechin's Bounds on monotone switching networks for directed connectivity, one way to separate L from NL is to show that there is no polysize switching network for directed connectivity. There is in fact a (trivial) polysize switching-and-rectifier network for directed connectivity. The difference between the two models is that the former is undirected and the latter directed. Potechin has been working on separating L and NL, but so far his method only works for monotone networks. See also his STOC 2012 paper with Siu Man Chan. (More papers are on the way.) 

The answer to your question is the contents of section 1.3.2, titled "[w]hen $\mathcal{P}_{p,r}$ is known to be difficult". (Here $\mathcal{P}_{p,r}$ is the problem of computing the norm $\|A\|_{p,r} = \sup_{\|x\|_p=1} \|Ax\|_r$.) According to that section, the only cases which are known to be difficult are $\mathcal{P}_{\infty,1},\mathcal{P}_{\infty,2},\mathcal{P}_{2,1}$. For example, $\mathcal{P}_{\infty,1}$ (even restricted to positive semidefinite matrices) is a generalization of MAX CUT. Since $\|B'B\|_{\infty,1} = \|B\|_{\infty,2}^2$, $\mathcal{P}_{\infty,2}$ is also hard. Finally, $\mathcal{P}_{2,1}$ is as hard as $\mathcal{P}_{\infty,2}$ as part of the more general observation (proved in section 1.3.1) that $\mathcal{P}_{p,r}$ is as hard as $\mathcal{P}_{1/(1-1/r), 1/(1-1/p)}$. The thesis goes on to prove that $\mathcal{P}_{p,r}$ is hard whenever $p > r$ - this is the chapter you were reading (chapter 2). Section 1.3.1 described some easy cases: $\mathcal{P}_{1,\ast}$, the symmetric $\mathcal{P}_{\ast,\infty}$, and the case that MCH mentioned, $\mathcal{P}_{2,2}$. Section 1.3.3 covers some approximability results, several novel of which are described in section 1.4 and the remaining chapters. The title of section 1.3.2 appears in the table of contents (page iii) - just a hint for next time.