I am using two MySQL server instances on the same server to filter replication to a third external server. My filter slave is using the blackhole engine as described here: $URL$ Both master and slave use statement based replication. The documentation says: 

It is interesting to note that MySQL creates the /var/run/mysqld directory when the server is started, and deletes it when the server is shut down (and no other process is using it). In my /etc/init.d I have two related startup scripts: mysql and mysqld_multi. When the mysql script runs, it checks the my.cnf file, finds that there is no [mysqld] group, and therefore, starts a server instance with default settings. It creates the /var/run/mysqld directory, as mentioned above, and gets everything going. At this point I have a server instance running with default values that I did not specify. Then comes the mysqld_multi script. It looks for groups of [mysqldN] in my.cnf, and starts server instances accordingly. This will start two additional instances according to my specifications. At this point I have three server instances running instead of the two I requested in the configuration file. If I remove the mysql script from /etc/init.d, the default instance will not start, but neither will the other two because: 

I am about to split a large database into a bunch of federated instances. Currently, most of the primary keys are auto-generated identity ints. Obviously, that's not going to work in a federated setup. I've read people using auto-generated GUIDs to replace the ints, but that data type has well-known performance sapping problems on its own. What are some of the strategies I can use for having unique values for primary keys across federated members? 

I've inherited a very volatile table which is a map of who holds what resource in the system. At any given moment, there could be a dozen inserts/deletes/reads going against that table. However, there are never any more than 30-40 rows in the system. The system was written in the SQL 2000 era and the access to the table is serialized via sp_getapplock/sp_releaseapplock system sprocs, so that only 1 request is modifying the table. In addition, the INSERT & DELETE statements execute . Reading the notes from a decade ago, it states that without these restrictions, the system would experience non-stop deadlocks. I've ported the database to SQL Server 2016 Enterprise Edition. Now that the throughput of the system has increased 10 fold, this table is easily the biggest bottleneck. What are my options for a table as volatile as this with SQL 2016? I am looking for fast (hopefully concurrent) access and no deadlocks. 

We had an issue in our dev environment where a procedure call timed out from the web server after 30 seconds. I traced the query and ran it manually (same params and all) from SSMS and it executed in about 2 seconds. I then ran 

In SQL Server there is a separate thread that periodically (default 5 seconds, lower interval if a deadlock has just been detected) checks a list of waits for any cycles. I.e. it identifies the resource a thread is waiting for, then it finds the owner of that resource and recursively finds which resource that thread is in turn waiting for, thereby identifying threads that are waiting for each others resources. If a deadlock is found then a victim is chosen to be killed using this algorithm: 

Sometimes when inserting data in a table with many columns it could be useful to know which columns must be specified if the insert-statement shouldn't fail. I wrote this query to find out which columns are not nullable, identity, computed, timestamp and have no default value. 

We had a plan to capture table changes with CDC until we realized that it doesn't support In Memory tables. Is there another way (preferably as straightforward as CDC) to capture data changes (from in memory tables) in SQL Server 2016? 

With SQL Server 2005, you could look at the Task Manager and, at least, get a cursory look at how much memory is allocated to SQL Server. With SQL Server 2008, the Working Set or Commit Size never really goes above 500 MB, even though the SQLServer:Memory Manager/Total Server Memory (KB) perf counter states 16,732,760. Is there a setting where it will actually show the server memory in the Task Manager? Or is it a result of them changing how memory is used in SQL Server 

It states Table Scan (HEAP). Not quite sure what it means in the context of a partitioned table. I also don't see that it uses any kind of index. And yet, it must, because the query comes back fairly fast (e.g. the table has 6 million rows). So, my questions are: 

The above statement makes me assume that if I had both of my MySQL instances set to row based replication, nothing would make it to the third, external database. Which kind of makes sense since there are no actual rows in the filtering blackhole database. However, I have been thinking... Would it not be possible for the filtering middle instance to simply pass on any row based instructions it receives to its own binlog, i.e. would a row-row filtering blackhole setup not work? 

The short version of the problem is that, upon boot, the default mysql startup script starts an unneeded general instance of the server with default settings, followed by mysqld_multi starting the required instances correctly, resulting in too many server instances. I'm on Ubuntu 14.04. Just upgraded the MySQL Server to version 5.7. I am aiming at running two instances of the MySQL server, one master and one slave, using the same binaries, but other settings being different. The point of such a setup is to filter tables out of the replication process. Before replicating to a third external instance, controlled by a third party, I want to make sure that only certain tables show up in the binary logs. I have been using this method successfully for years. After upgrading to MySQL 5.7 my setup looks like this: 

What does Table Scan (HEAP) mean for a partitioned table? Does it indeed use an index, perhaps behind the scenes? Is there anything I need to do to improve efficiency? 

I am partitioning a table based on a column that is not a primary key? I've read some conflicting information today on whether the partition column must be a part of the primary key. My gut says no, but I am not 100% sure. So questions... 

I have table partitioned on (int). I also created a non-clustered index for on the table. When I run the following: 

From what I can tell Procedure Cache Hit Ratio below 95% is a problem. On my box, the values hover from 85 to 95%. How do I fix this issue? The server seems to have plenty of RAM so that shouldn't be an issue. What else can it be? 

I have a situation where multiple client apps send messages via the Service Broker (utilizing stored procs). These messages are picked up by yet another client app and then processed. The way the messages are picked up is that the app issues the following SQL statement (pseudo code): 

The transaction owner/application developer is responsible for minimizing the risks of deadlocks occurring, and to do that they should: 

Because when you're creating a full backup you're creating a backup of the data (as it is physically and as it is materialized from the log). Restoring it somewhere else restores it as data, not log. 

I'm using Red Gate SQL Compare to create a release script based on differences between SVN and a database. This results in a script containing a bunch of table- and procedure-changes and it works fine. However, one thing puzzles me, it's using transaction isolation level serializable. I know what it does to dml-statements, but I'm not sure what it means for ddl. Can someone enlighten me, perhaps with an example? 

The original log file might be truncated so the space can be reused, but it's size might stay the same. 

Identify threads that are not unkillable (e.g. a thread that is rolling back a transaction is unkillable). Find the thread with the lowest deadlock priority. Chose the one that is cheapest to roll back, i.e. the one that has done the least work so far. 

I have an app that's local to the SQL Server and thus has a Shared Memory connection to it. I was wondering whether the RAM taken by the connection (including data transfers) counts against the max memory limit set for the SQL Server. The reason I am asking is that the SQL Server is maxed out on memory (e.g. Target Server Memory = Total Server Memory and other metrics). If the RAM taken up by Shared Memory connection counts against it, wouldn't I be better off using TCP connection to the SQL Server? 

I run on box box and get multiple rows per single SPID. For example, see below. Does this mean that SQL Server has broken the query into 23 parallel sub-queries? If that's the case, why is it ignoring MaxDegreeOfParallelism setting of 8? Or is this something else? 

I've setup a test SQL Server 2016 server. I've installed 2 instances, restored a backup on the primary. Then restored a backup on the secondary with , then restored the transactional log on the secondary, also with . I then followed the prompts in the Mirroring Wizard off the Database Properties page and ended up getting an error: . What am I missing?