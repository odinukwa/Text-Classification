In closing, there's obviously a hardware problem. But in one specific configuration, the monitor still fully works on the old laptop. Do I nevertheless have to throw it away and buy a new one? Or can I force its detection (in Windows) somehow to make it work on the new laptop? 

What could cause my system not to boot into the Windows 10 installer from a presumably correctly built USB drive, like ever? When trying, I see the screen flickering once (~.5s), and then it shows the boot animation (a simple spinner) on the manufacturer's boot screen (Gigabyte logo, plus a white bar at the bottom), just as it does when the USB drive is not plugged in. This spinner will stay there forever (I've waited up to an hour), but nothing happens. I've physically removed all other SATA drives from the system to rule out any effect they might have. UEFI system. Only Windows 10 was installed before, but stopped booting (which is why I'm trying to boot into the recovery system from the USB in the first place). I've tried both by selecting the USB drive from the F12 boot target menu my UEFI firmware offers, as well as by rearranging priorities until it has top spot. I've tested both with the option "Default Secure boot" enabled as well as disabled. I haven't seen any difference. I've also restored the default settings, which also hasn't made any difference. The USB drive has been created by downloading the latest Windows 10 ISO using Microsoft's MediaCreationTool, then writing it to the drive using the latest version of Rufus. File system has been set to FAT32. Partition scheme has been set to GPT. (But I've also tested both the hybrid MBR/GPT as well as the pure MBR schemes to no avail.) The same USB drive boots just fine into the Windows 10 installer on another UEFI system. I've tested two different USB drives, the Windows 10 installer won't boot from either. I was able to boot Linux Mint from both successfully. The only other possibly interesting (or misleading) data point I have is that if I pull the USB drive at just the right moment during the boot process, I'll get a 'blue screen' that looks like a Windows installation screen. This led me to believe that it did indeed load something from the USB drive. Or maybe it didn't, and this just somehow triggered the message. It says "A required device isn't connected or can't be accessed" and offers me three options: "Enter to try again", "F8 for Startup Settings" and "Esc for UEFI Firmware Settings". I press F8, and I end up back on the black manufacturer screen, this time without a loading spinner animation. -- TLDR: Correctly built Windows 10 USB drive doesn't work on a single machine that has no other drives. Linux boots just fine on the same machine. Why? 

My UEFI/GPT installation of Windows 10, 64-bit doesn't boot anymore. It's stuck somewhere in the bootloading process with a blank screen and no error message, I cannot tell at which point exactly. I suspect that something has been written into the UEFI firmware's NVRAM that prevents Windows from starting up. Opening the drive on another machine reveals that the partitions, file systems and data are all there and fine. It just doesn't boot anymore. For possibly unrelated reasons not relevant to this question, I'm unable to boot into the Windows RE environment, but I can boot from Linux USB drives, for example. Is there a way to repair the BCD and the other bootloader files of Windows 10 without booting into WinRE? If I understand correctly, commands like bcdedit affect the NVRAM of the UEFI firmware, so I cannot run those on another machine "against an external drive" that I've mounted, can I? Any other way to do the same thing, possibly from a live Linux system? 

Seems like the culprit was presumably hardware failure of the dedicated GPU. One more data point I hadn't mentioned before was that Mint would freeze for pretty exactly 240s while booting from the USB drive, also with a black screen. But then it did come up. I tried booting Ubuntu from a USB drive next, and it wouldn't start at all, just like Windows environments. Even the common fix of setting in the grub options had no effect. Eventually, I switched off the dedicated GPU in the UEFI configuration, and since then, I can boot just fine from all USB drives. 

No, this does not improve privacy. While, depending on the VM-software you use (and the settings therein), the VM might use a different IP- and MAC-address, which might make the connection slichtly anonymous (But do not rely on it!), this does not in improve privacy. As Hennes stated in his answer as well, contents of any non-encryped connection can be read (and possibly changed) by all intermediate persons, e.g. employers as well as Internet Service Providers. Using a SSL-secured connection (for websites, also known as HTTPS) prevents intermediate persons from seeing what you send (and receive), although it still does not prevent them from knowing where you connect to (as DNS-lookups, which map a name like to an IP-address like are usually not encrypted). Better ways of ensuring privacy on the internet are: 

To create a thumbnail from an image file, you can run the following ImageMagick command: . However, I am in a situation in which I want to limit how wide an image is, but the height is not restricted. How can I instruct ImageMagick to resize larger images to a specific width, without restricting the height? 

After this, testing by creating and (as shown in the guide) worked successfully. I now tried adding a domain for one of my projects. : 

However, the actual copying step takes forever using . I've also tried but this also takes so long (it ran for multiple hours before hanging) that the shell session breaks beforehand. Is there another, smarter way to copy/move this large amount of files to its new location on another hard disk? The VPS is running Ubuntu 16. 

Copy images to new location. Rename current directory, and give a symlink to the new location its old name. Remove the old directory. 

I am on Linux Mint 18.1 (which is based on Ubuntu 16) and usually browsing the internet through a VPN. However, recently I wanted to set up a simple server on my own computer that runs at a custom port. Now it turns out that (obviously...) using the VPN makes it impossible for people to connect to this port. So what I'd like to do, is to add an exception, that allows (only) this port to not use a VPN. Is this possible? 

I recently moved to a new computer, and copied over all existing git repositories for webdevelopment projects from my old computer. On that old computer, I had installed apache to serve certain folders from as subdirectory of my home folder as development websites (either static or using PHP). So, for instance, a personal project would live under . Now on the new computer, I tried setting up nginx, to use it in a similar way. I followed this guide on DigitalOcean to install nginx (and MySQL and PHP) on my laptop that runs Linux Mint 18.1 (Serena). I configured nginx as follows: : 

(I also added a symbolic link from sites-enabled to this: ). After restarting nginx (), and adding to my -file, I was greeted with a 404 error. Looking in , I find out that the requests I do fail because of the following reason: 

I expect this has to do with file/directory rights management in linux/unix. My home directory is obviously owned by myusername, while nginx is run by the user www-data. However, I am not sure how to alter the rights of this folder so that www-data/nginx is able to access it (and the files within). How can this be resolved? And why did I not run into this problem while configuring Apache on my previous computer (also running Linux Mint)? 

According to the Unicode standard, (the underscore character) is part of a word. This means that when you skip your cursor to the next word (in many interfaces you can do this with Ctrl + the arrow keys) you will skip over all the characters as well as the letters and numbers in-between. However, vim (where moving to the next/previous word is done using or in normal mode) regards not as one word, but as five: . I would like to configure Vim's behaviour such that is also properly considered a word character. How can this be done? 

Note that even through you use systems like the above-stated, these protect your transport. What they do not protect against is how you interact with the sites. 

You can see that I loaded the correct monitor driver. Changing the frequency does not work/has no effect, it will always jump back to 59Hz when reopening the dialog. 

Are you sure you're sending the tabs to the right device? As there's no maintenance site for these, it's easy to have old device entries in your list which are no longer connected to a physical device. I also commonly have stale duplicate device entries (e.g. when I reinstall the OS of a phone without remembering to disconnect Sync first). I would try renaming the "desktop" device in Sync and confirming that the new device name shows up on the mobile. If not, you know you have a setup issue on the desktop. If the new name does show up on the mobile, then it's something else. 

After switching the Encryption Type in the Wireless Network Properties from AES to TKIP, I get downstream speeds of 22+Mbps again. Pings and upstream speeds are basically unaffected (11ms -> 10ms, 0.9Mbps -> 1.0Mbps). This is reproducible: after switching back to AES, I get the old downstream speeds again. Explanations are welcome, all of this makes no sense to me. When it was still fast a few days ago, was I still on TKIP? Then what switched me!? Or why is AES suddenly so much slower than TKIP? Why is it just as fast on other networks? Edit: A bit a research made me believe that by switching to TKIP, I implicitly also switched from 802.11n to 802.11g (because TKIP is not allowed on n due to its security problems). That would also explain why I'm now seeing a connection speed of 54Mbps. So now the question becomes, why does g work, but n stopped working? (Mind you, I still prefer a connection speed of 54Mbps with 22Mbps actual throughput over connection speeds of 130Mbps with 2Mbps throughput.) 

By using bash's variable, I can scale up the number of containers in Docker Cloud as much as I want, while still collecting the results individually. 

When connecting the same setup to my new laptop, Windows will display "No Monitor" and give me a selection of resolutions. No matter what I choose here, the monitor will display 1280x1024. Here's one more data point that I can't figure out what it means: when I connect the 'broken' monitor via the HDMI port to my old laptop, it gives me a couple of weird resolutions (e.g. 1920x1080, 1680x1050, 1400x1050), but not 1920x1200. The refresh rate is shown as 59Hz instead of the usual 60Hz. I can change it and apply the change, the screen flickers and the new refresh rate is displayed, but opening the same dialog will show it as 59Hz again. Here's what it looks like when connected to the old laptop via HDMI, stuck at the wrong resolutions at 59Hz: 

I've got two HP ZR24w external monitors. Used for years. A few weeks ago, I turned the system off in the evening while it was still working fine, and when I turned it back on the next morning, one of the monitors started behaving oddly. Here's the current situation: I just got a new laptop. When I connect the 'broken' monitor via an HDMI-to-DVI cable. The monitor shows an active DVI signal, but no image. Windows does not detect a monitor at all. I unplug the monitor and connect the DVI end of the same cable to the other monitor. It works perfectly, uses the native resolution and Windows detects the display. I also ran a subset of the tests with Ubuntu 14.10. Bottom line: 'broken' monitor connected via HDMI-to-DVI cable doesn't work, other monitor is detected automatically. So it's not a pure OS problem either. I think at this point, we can conclude that there's something broken with the hardware of the first monitor, possibly the EDID? However, here's the oddity: I also have a DL-195, a USB-to-DVI converter. With that, I can connect the 'broken' monitor to my old laptop and it's working at the correct resolution, even though Windows lists it as "No Monitor". Here's what it looks like when it works (even though it says "No Monitor", but the resolution is correct and it works perfectly well):