This will maintain a rough balance between the size of any two neighboring countries, and the 'disconnected' check (which can be done with a simple flood-fill algorithm) makes sure that no country ever breaks apart into pieces. Updating the boundary list is a constant-time operation - the changed hex will obviously always still be on the boundary, and you can just check its six neighbors to see if any of them has either become a boundary cell (because its neighbor is now in a different country) or stopped being a boundary cell (because its neighbor's in the same country now), modifying the boundary set as needed. For a refinement of this approach, you can even make the condition of which hex to change a bit randomized - rather than always 'balancing' the two countries, you can always make the swap with a certain probability, and even gradually diminish that probability over time (similar to the cooling process in a Simulated Annealing algorithm) to start to force them to be roughly the same size. Note that this won't guarantee that all areas are exactly the same size (which is impossible unless N perfectly divides your grid size anyway), and it won't even guarantee that all countries are within one hex of each other in area; it should guarantee (run for enough iterations) that each country is no more than one hex larger or smaller than each of its immediate neighbors, though. 

To second a note made in comments: the notion of defining your track via a chain of points making up its spine should work just fine; if the red path in your question is what you're getting out of your procedure, then I would start by considering changes to that. My recommendation for doing the 'chain of points' version of the track is essentially a linear version of a spline: at each point along the spine Pi, define the current tangent to the track Ti by Ti = Normalize(Pi+1-Pi-1) (this is the central difference approximation to the derivative). Once you have the tangent you can find a 'rib' vector at a right angle to the tangent: if the tangent is Ti = (Tx, Ty), then the rib vector is Ri = (Ty, -Tx). With the spine points and the rib vectors, you can define the outer boundaries of the track: the left boundary is BiL = Pi-w*Ri and the right boundary is BiR = Pi+w*Ri (this creates a track of width 2w — that is, w units out to either side of the central spine). Once you have that, you can think of the track as the union of the quadrilaterals &langle;B0L, B1L, B1R, B0R&rangle;, &langle;B1L, B2L, B2R, B1R&rangle;, etc. This approach will occasionally have problems around hairpin turns (particularly if the curvature gets to be tighter than the width of the track), and you may want enough manual control over the intermediate points that I would use this as just an autogenerated starting point rather than the final result of the process — but it should serve as a good starting point for building the track. This also means that the collision envelope for the track should be the same as the displayed envelope, which is important in its own right — the player should expect that what they see on the screen actually represents the functional bounds of the track. 

The issue I suspect you're seeing has nothing to do with your code, but rather is a fundamental issue with interpolation along the surface of a sphere (in this case, for the viewDirection). Between (almost) any two points on a sphere there's a single great circle - for instance, arbitrarily fixing our 'start' point at the north pole, the great circle would be the meridian that the end point lies on. Interpolation from one point to the other moves along this great circle. Now, for most points on a sphere, nearby points correspond to nearby great circles; for instance, the meridians that Los Angeles and Phoenix lie on are fairly close to each other. But when the destination point is the antipode of the original point — the south pole to the start point's north pole — there's no longer a single great circle through them both, but instead all the great circles through one go through the other. What's worse, this means that points near the south pole aren't 'most points'; two points near each other and both near the south pole can have wildly divergent meridians. I suspect that what you're seeing is a manifestation of this instability in the meridian - or in other words, the interpolation arc. When the look target is directly behind the character, then things like the first-order inaccuracy in your 'Euler integration' of the character's position, and the way that changes the look direction frame-to-frame, are going to lead to these wildly different interpolation arcs from one frame to the next, and this will likely lead to the 'stagger' that you're seeing. As far as what to do with it, the best thing that springs to mind is to not recompute the 'target' look direction every frame; instead, use the same one for a span of several frames, then compute a new one and use that for several frames, etc. If need be, you can even interpolate from one target to the next over the span of a few frames so that the direction of motion doesn't change too abruptly. 

If you have your transformation encoded as a matrix, then this simplifies even further (since then the rotation is simply a column extraction), and the code ends up looking something like: 

This is obviously very rough pseudocode; if there's any piece of it that's unclear just let me know and I'll try and explain, but it's going to be hard to cover all the details without just a huge code dump... 

While I basically agree with Nathan's answer, I wanted to emphasize that (a) another reason to find all the matches at once is for presentation purposes: it just looks better to blow them all up together — and in the more-than-one-dimensional case, it can be relevant because not all matches will stay matches after partial destruction (think of a plus shape on a 2d match-3), and (b) if this is like most match-3s, you'll probably need an outer-outer loop for handling the 'nested' matches that appear (imagine a situation like RGGGRR). What's more, in the 1d case you can actually get by with a single loop through the interior and some careful tests. My structure would look something like this: 

I've got a small handful of competitive word games in progress, and while the preference is for (mostly asynchronous) play against other human opponents, I'd like to provide players the option of playing against an AI. I have my dictionary and I can easily give the AI full dictionary knowledge while it's playing, but my concern is that having the AI regularly playing words they're not familiar with will be a frustrating experience for players: 'I would have won that game if it'd just used words I know!' — even if the AI's overall skill level is turned down. I'd rather create a weaker AI through a combination of (un)tuned play parameters and a weaker vocabulary — but I'm not sure how to limit that vocabulary to 'common' words. I've looked at several word frequency lists (for instance, the list of all words that appear in the Project Gutenberg books, sorted by number of occurences) but they all have a number of false negatives: words that everyone knows that simply don't show up with any real frequency (for instance, CHEETAH shows up less frequently in the PG texts than VOCATIVE or SUTTEE). I've tried using search results to get estimates of a word's popularity, but they also tend to be prone to spurious mis-estimates, and of course it's hard to get search results for an entire dictionary without running afoul of the terms of service on the search engines. Does anyone have suggestions on other good means of determining a rough frequency of word usage, or other ways of limiting word game AI that will feel natural to players? 

This is somewhat similar to thalador's perlin-noise approach, except that we're building our noise function explicitly here (via its fourier transform, essentially) and using it to 'wobble' a 1d line (circle) rather than taking a level set. 

Note that this code is missing a lot of the details - it doesn't tell you how to initialize next_x and next_y, for instance. There are ways of eliminating most of the divides, making it easier to handle special cases like vertical and horizontal lines. Whether you increment or decrement cell_x and cell_y depends on which quadrant your line is in - note that for my example line, you'd actually be decreasing cell_x each tick, since m (x1-x0) is negative. You also have to decide how you're going to handle cases where your line goes precisely through the corner between cells, rather than transitioning on an edge; there are lots of small details that can go wrong, and it needs a lot of testing. Still, hopefully this will give you a picture of what the core idea of the algorithm is. 

The line here can be written as '(x,y) = (x0,y0)+t*(m,n)', where m=x1-x0 and n=y1-y0. If the dimensions of a grid cell are gx and gy, then dx — the distance (in terms of the t parameter) that it takes to cross one grid cell — can be found with a bit of quick algebra: from the pair of equations x = x0+mt, (x+gx) = x0+m(t+dx) we get gx = m*dx, or in other words dx=gx/m. Likewise, dy=gy/n. The algorithm keeps track of next_x (the distance to the next red point along the line) and next_y (the distance to the next blue point along the line) and updates them every time it hits another crossing, so the central loop looks something like this: 

Given the discussion in the comments, this comes down to finding a random point on a circle. For instance, if we find a point (x,y) at random within a circle of radius 1, then the vector (.05*x, .05*y, 1) will be a roughly-random vector within the cone of angle arctan(.05) (or approximately 2.9 degrees) about the z axis. There are several different methods of finding a random point on a sphere, but the most straightforward by far is what's known as the rejection method : find a point at random within the square of radius 1 and then reject it (that is, find another random point) if that point is outside the unit circle. Assuming that rand() returns a random number between 0 and 1.0, then the pseudocode for doing this would look something like: 

Since the area of the square is 4 and the area of the circle is π, the probability that the point will be inside the circle is π/4 and the average number of times you'll execute the do loop is 4/π, or approximately 1.27 times for each random point within the circle; there's a less than 1% chance that you'll need more than 3 iterations of the loop to find a point within the circle. This uniform point in the circle can then be translated into a nearly-uniform vector in a spread about the z-axis by means of the method I listed above; in particular, if the maximum angle from the z axis is theta (so the cone's width is 2*theta), then pseudocode for using the random point would look something like: 

What's more, from our relative vector we can find the precise angle that the line from cX to oX is at: 

Because this fills the voxel array with only 0s and 1s, it can mean that the marching cubes interpolation along edges looks a little too 'regular' and results in surfaces with too many identical slopes on them. Instead, you may want to 'subsample' the heightmap to build your voxel array, using something like: 

Now, the good news: it turns out that this lexicographical ordering, suitably tweaked, works for comparing two hands in any of the classes, as long as their class is the same. For instance, since the way of comparing pairs is to compare the pairs first, then the other three cards, you can sort your hand to put the pair first (or even one card of the pair first!) and run this same comparison. (So, for instance, a hand like A9772 would be stored as either 77A92 or, better yet, 7A927; the hand A9972 would be stored as 9A729, and comparing with the above code you'd start by pitting 7 against 9 and find that A9972 won). A hand of two pair would be stored with the higher of the two pairs first, then the lower, then the 'kicker' (so, e.g., A9977 would store as 97A97); three of a kind would be stored with one card of the three first, then the kickers, then the other cards (e.g., A7772 would be 7A277); a full house would be stored with one of its three and then one of its two (e.g., 99777 would be stored as 79779); and straights and flushes can both be stored in 'direct lexicographical' order since they're both compared just like high-card hands are. This leads to a straightforward outer comparator function that works for all classes of hands with the already-given function: 

then your point is in the inner rectangle. How you want to handle the edge cases with respect to points in the center box is, of course, up to you - be careful with them, though! Once you know your point isn't in the inner box, the most straightforward way of testing each of the other regions is by doing two 'half-space' comparisons against the diagonal lines that bound them. To explain in slightly more detail: the equation of a line, generically, is 'A.P=b', where P=(x,y) is an arbitrary point on the line, A is a vector perpendicular to the line, and b is some constant; what's more, if a vector in the direction of the line is (vx, vy), then the vector (vy, -vx) is perpendicular to the line. What's that mean here? Well, consider the dividing line in the top-left corner: this line goes from (sx_0, sy_0) to (ix_0, iy_0), so a vector in the direction of the line is (ix_0-sx_0, iy_0-sy_0) and a vector perpendicular to the line is (iy_0-sy_0, sx_0-ix_0) (be careful - notice how the second coordinate got flipped!) What's more, we can find the value of b by plugging in one of the two points we know is on the line: for instance, using (sx_0, sy_0) we find that the dot product is sx_0*(iy_0-sy_0)+sy_0*(sx_0-ix_0), or (cancelling out the sx_0*sy_0 terms) sx_0*iy_0-sy_0*ix_0. In other words, the equation of the line is (iy_0-sy_0)*x+(sx_0-ix_0)*y = sx_0*iy_0-sy_0*ix_0. What's more, which side of the line a point is on is determined by whether the dot product is less than or greater than sx_0*iy_0-sy_0*ix_0. Finally, to use this: consider for instance the top region. Then this is the section that lies to a specific side of the line from (sx_0, sy_0) to (ix_0, iy_0) and also on a specific side of the line from (sx_1, sy_0) to (ix_1, iy_0). In other words, to test your point (tx, ty), you'll know that it's in your region a if: