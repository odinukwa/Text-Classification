Let an explicit field be a field for which equality is decidable (in some standard model of computation). I am interested in the factorization of univariate polynomials over an explicit field. It is known that over some explicit fields, testing irreducibility of polynomials is undecidable [1]. Though, over many fields, the irreducible factorization of polynomials is known to be computable in polynomial time, either deterministically (over $\mathbb Q$ [2] or any number field) or probabilistically (over finite fields [3]). Here the size of the input is the size of the dense representation of the polynomial, that is the list of all its coefficients. 

An example I have in mind is double. The paper Fast parallel computation of polynomials using few processors has two versions: 

Consider a set of $n$ points in $\mathbb Z^2$. It is known that their convex hull can be computed in time $O(n\log n)$, or even $O(n\log h)$ where $h$ is the number of points in the convex hull. These bounds are in given (for instance) in the model of algebraic decision trees. What is the bit-complexity of computing the convex hull of $n$ points in $\mathbb Z^2$, whose both coordinates are bounded in absolute value by $M$? I am interested on the one hand in the dependence of the complexity in $M$, and on the other hand in the possible gain in complexity one obtains using the fact that the input points have integer coordinates. In my problem, I see $M$ as a large parameter, that is $\log(M)$ has the same order of magnitude as $n$. Note that I am especially interested in the problem with the additional requirement that the points on the convex hull have to be listed in the order of the (say) counterclockwise rotation, beginning for instance at the leftmost point. I am also interested in the same questions in higher dimensions. 

What problems are known to belong to $\mathsf{BPP}$ but not known to belong to $\mathsf P$? More precisely, I am interested in independent problems, that is whose derandomizations are not known to be equivalent. For instance, it is known that derandomizing PIT and multivariate polynomial factorization are equivalent and I would count them as only one problem. The motivation of my question is that it is common to say that "there are few problems in $\mathsf{BPP}$ not known to be in $\mathsf{P}$", but I was not able to find a list of them. In particular, if I have to cite problems in this category, I usually cite the factorization of univariate polynomials over finite fields, or the factorization of multivariate polynomials. I suppose that there exist examples that are not related to polynomial factorization, for instance in other domains such as graph theory or formal language theory. P.S.: I find curious that a similar question does not exist on this website yet. My apologies if I simply did not find it (or them)! 

Suppose you are given two lists $L_1$ and $L_2$, each of which contains pairwise distinct elements from some set $S$. What is the complexity of computing the intersection $L_1\cap L_2$ of the two lists? If you have an order on $S$, you can sort your both lists and then compute the intersection in linear time, achieving $O(n\log n)$ complexity where $n=\max(|L_1|,|L_2|)$. More specific questions are then: 

Let $C$ be an arithmetic circuit that represents a polynomial $f\in\mathbb K[x_1,\dotsc,x_n]$, with the promise that $f$ has at most $k$ nonzero terms. What is (known about) the complexity of computing $f$ in its sparse representation, given $C$? I am interested in deterministic and randomized complexity, and in the link with PIT. In particular, does the promise that $f$ is sparse imply good algorithms? A priori, I am more interested in the case of $\mathbb K$ being some finite field, though results over other fields may be relevant. 

Given two point clouds $A,B\subset\mathbb Z^d$, let $A\oplus B$ be their Minkowski sum, defined as the set $\{ a + b : a\in A, b\in B \}$. Is there any known result for the following problem? 

The problem is the following: Given an arithmetic circuit computing a polynomial $P$, is $P$ identically zero? This problem can be solved in randomized polynomial time but is not known to be solvable in deterministic polynomial time. Related is Shub and Smale's $\tau$ conjecture. Given a polynomial $P$, we define its $\tau$-complexity $\tau(P)$ as the size of the smallest arithmetic circuit computing $P$ using the sole constant $1$. For a univariate polynomial $P\in\mathbb Z[x]$, let $z(P)$ be its number of real roots. 

Note: This is an expansion of a previous comment, since the OP explicitely asked for weaker upper bounds. The total degree of polynomial $f$ is bounded by $2^{L(f)}$ since each operation can at most double the degree of the polynomial. Thus, for each $m\in M$, $\deg(m)\le 2^{L(f)}$. Now, for some variable $x$ and degree $d$, there is a SLP conputing $x^d$ by binary exponentiation if size at most $2\log(d)$. For a monomial $m=x_1^{d_1}\dotsb x_n^{d_n}$, one can separately compute each $x_i^{d_i}$ and then take their product. Thus $L(m)\le 2n\log(d) + (n-1)$ where $d$ is the total degree of $m$ (which is of course an upper bound on each $d_i$). Together, one obtains for $m\in M$: $$L(m)\le 2n\log(\deg(m))+(n-1)\le 2nL(f)+(n-1).$$ Since $n\le L(f)+1$, one can conclude $$\forall m\in M, L(m) \le 2L(f)^2+3L(f).$$ Remarks. The bound as stated is very rough. In particular, the upper bound on $L(m)$ given is the second paragraph is not tight. Yet, domotorp's answer shows that one cannot hope for a much better bound, and more precisely that the quadratic dependence on $L(f)$ cannot be removed. To tighten the construction, one could use the best known constructions on addition chains. Note that the precise bounds are still not known for this problem. 

Your problem is $\mathsf{NP}$-complete, and you can find a proof for instance here (I gave a sketch in comments). A remark: If you consider $\{\langle M,x,t\rangle : M$ halts on $x$ in $t$ steps $\}$, then you can only show it is $\mathsf{NP}$-hard. But as you mention that you consider $t$ polynomially bounded (in the sizes of $M$ and $x$, I guess), then your problem belongs to $\mathsf{NP}$. 

A lot is known, and it is a very active area! It is important to specify the representation of the input polynomials, since it they are given as lists of coefficients or nonzero monomials, the problem is trivial. Thus one usually assumes the polynomials to be given as arithmetic circuits (a.k.a. straight-line programs). And the general case actually boils down to testing whether a given polynomial is the zero polynomial. There are two main settings that have been studied: the whitebox case in which one has the arithmetic circuit and can inspect it, and the blackbox case in which one knows some things about the circuit (size, formal degree, ...) but cannot inspect it, only evaluate it on some values. Here are some of the restrictions on the circuits that have been studied: 

For $\mathsf{MA}$, I do not know of any example. My refined question: Do we know other problems in $\mathsf{AM}$ or $\mathsf{MA}$, not known to be in $\mathsf{NP}\cup\mathsf{BPP}$? I am not interested in problems for which the only proof that they belong to $\mathsf{AM}$ is by using one of these two protocols. Edit: My main motivation is to be able to give examples of $\mathsf{AM}$ or $\mathsf{MA}$ algorithms to explain what these classes are. 

For the journal version, the reason for having Berkowitz and Rackoff as third and fourth authors is that the original result was only by Valiant and Skyum while Berkowitz and Rackoff helped them to simplify and improve it for the journal version. But I have no idea why the conference version was already non-alphabetically sorted! 

I am not sure about specifically depth-three lower bounds, but there has been a lot of depth-4 (and 5) lower bounds, usually assuming other constraints as well. For instance (and without any claim of exhaustivity): 

I do not agree with your statement in the question that $\omega$ is not well-defined by "the smallest value for which there is a known $n^ω$ matrix-multiplication algorithm." When people are using this constant, it is because their algorithm relies on a matrix multiplication, and by a complexity $n^\omega$, they mean "the optimal complexity of our algorithm is given by the optimal algorithm for matrix multiplication." I am not saying that it is not possible to define $\omega$ otherwise (e.g. saying that $\omega$ is the best achievable complexity). Btw, the best known upper bound for matrix multiplication has just been improved to $2.3737$ if I am not mistaken. 

It is well-known that palindromes can be recognized in linear time on $2$-tape Turing machines, but not on single-tape Turing machines (in which case the time needed is quadratic). The linear-time algorithm uses a copy of the input, and thus also uses a linear space. Can we recognize palindromes in linear time of a multitape Turing machine, using only a logarithmic space? More generally, what kind of space-time trade-off is known for palindromes? 

In his paper Straight Line Programs and Torsion Points on Elliptic Curves, Qi Cheng relates Bürgisser's $L$-conjecture (a variant of Shub and Smale's $\tau$-conjecture¹) to the Torsion Theorem and to Masser's Theorem in the field of elliptic curves. Very roughly, if the $L$-conjecture is true (or a weaker version of it), then one can "easily" deduce these both theorems. Their original proofs are much harder. ¹ The $\tau$-conjecture asserts that if a polynomial $p$ has a constant-free straight-line program (or arithmetic circuit) of size $\tau$, its number of integer roots is at most $(1+\tau)^c$ for some absolute constant $c$. 

The paper Vandermonde Matrices, NP-Completeness, and Transversal Subspaces [ps] by Alexander Chistov, Hervé Fournier, Leonid Gurvits and Pascal Koiran may be relevant to your question (though it does not answer it). They prove the $\mathsf{NP}$-completeness of the following problem: Given an $n\times m$ matrix over $\mathbb Z$ ($n\le m$), decide whether there exists a $n\times n$ submatrix whose determinant vanishes. 

This survey by Nitin Saxena is a good source for these results. Note though that it is already more than one year (!) old, and this is a very active area. So the most recent results are not covered. Finally, there are links between the derandomization of PIT and the derandomization of other problems: 

I'd say that the gap in the arithmetic settings tells us that matrix multiplication is inherently a much more parallel task than the determinant. In other words, while the sequential complexities of both problems are closely related, their parallel complexities are not that close from each other. A relevant paper is Fast parallel matrix inversion algorithms by Csanky where he proves that the arithmetic complexity $D(n)$ of computing the determinant of an $n\times n$ matrix (that is the depth of an arithmetic circuit computing the determinant) satisfies $$ O(\log n)\le D(n) \le O(\log^2 n).$$ To the best of my knowledge, these are still the best known bounds for this problem. This has to be compared with the trivial depth-$3$ arithmetic circuit computing a matrix multiplication, given by the formula $(A\cdot B)_{ij}=\sum_k A_{ik}B_{kj}$. 

Automata theory and algebraicity Automata theory has given some interesting results to characterize algebraicity. I mention two of them, with references. It is by no way exhaustive. 1. An algebraic closure of $\mathbb F_q(t)$ Let $\mathbb F_q(t)$ be the rational function field over the finite field with $q$ elements, where $q=p^s$ for some prime $p$ and integer $s$. Let $\mathbb F_q[[t]]$ be the ring of formal power series over $\mathbb F_q$. One can characterize the power series which are algebraic over $\mathbb F_q(t)$, that is roots of a monic polynomial with coefficients in $\mathbb F_q(t)$, using an automata-theoretic description. Theorem (Christol [1]). A formal power series $\sum_{i=0}^{\infty} a_i t^i$ is algebraic over $\mathbb F_q(t)$ if and only if the sequence $\{a_i\}_{i=0}^\infty$ is $p$-automatic. Actually, this method allows to give a description of an algebraic closure of $\mathbb F_q(t)$. It is known that the field of generalized power series of the form $$\sum_{i\in I} x_i t^i\text,$$ where $I$ is a well-ordered subset of $\mathbb Q$, contains an algebraic closure of $\mathbb F_q(t)$. Again, the generalized power series which are algebraic can be characterized using an automata-theoretic description. Theorem (Kedlaya [2]). A generalized power series $\sum_{i\in I} a_i t^i$ is algebraic over $\mathbb F_q(t)$ if and only if the sequence $\{a_i\}_{i\in I}$ is $p$-quasi-automatic. 2. Transcendental numbers Automatic sequences are also used to characterize transcendental numbers. For instance, Theorem (Adamczewski & Bugeaud [3]). Let $b$ be an integer $\ge 2$. Let $x\in\mathbb R$ and let $\mathbf x=\{x_i\}_{i=0}^\infty$ be the sequence of digits of its base-$b$ representation. 

What are the examples of problems known to be in $\mathsf{AM}$ (resp. $\mathsf{MA}$) which are not known to be in $\mathsf{NP}$ nor in $\mathsf{BPP}$? For $\mathsf{AM}$, I know the following two examples: 

Quick clarification: There may be very different explicit fields, depending on the complexity (for instance) on the equality test or of the standard operations (addition, multiplication). Actually, I am not aware of any result about polynomial factorization which is not a polynomial time upper bound, or undecidability. So I am interested in any kind of different result (exponential time is just an example). Conditional lower bounds are of interest too. References. [1] A. Fröhlich et J. C. Shepherdson (1955): On the factorisation of polynomials in a finite number of steps. [2] A. K. Lenstra, H. W. Lenstra Jr., L. Lovász (1982): Factoring polynomials with rational coefficients. [3] E.R. Berlekamp (1967): Factoring Polynomials Over Finite Fields. 

Let $\mathbb K$ be a field of characteristic $0$ or at least $d(d-1)+1$, and $p\in\mathbb K[x_1,\dotsc,x_n]$ be a polynomial of total degree at most $d$. If $d$ is fixed and $n$ is growing, one has the following complexity bounds for the reduction of the factorization of $p$ to the factorization of a degree-$d$ univariate polynomial: (The notation $\tilde{\mathcal O}(\cdot)$ ignores logarithmic factors.) 

One approach on this question, related to complexity-theoretic questions, is due to Shub and Smale [1] who proved that if $n!$ is ultimately hard to compute, then $\mathsf{VP}\neq\mathsf{VNP}$ over some field. Their model of computation is the straight-line programs: The goal is to compute $n!$ from the constant $1$, using only additions, subtractions and multiplications. That $n!$ is ultimately hard means that the number of operations needed is asymptotically not bounded by some polynomial in $\log n$. For more recent results in this direction (and pointers to the relevant literature), you can read a paper of Cheng [2]. The paper contains also a very brief remark about the standard complexity of the problem, that has to be exponential in $\log n$ (because of the output size), and of the modular variant of it (computing $n! \bmod m$) and its relations with integer factoring. [1] Mike Shub and Stephen Smale. On the intractability of Hilbert’s nullstellensatz and an algebraic version of “P=NP?”. Duke Math. J., 81:47–54, 1995. [2] Qi Cheng, On the Ultimate Complexity of Factorials, Theoretical Computer Science, Volume 326, Issues 1-3, Pages 419-429. 

Schwartz - Zippel - DeMillo-Lipton Lemma is a fundamental tool in arithmetic complexity: It basically states that if you want to know whether an arithmetic circuit represents the zero polynomial, all you need is to evaluate the circuit on one input. Then you'll obtain a nonzero value with good probability if the circuit does not represent the zero polynomial. This is a particularly important lemma since no polynomial-time deterministic algorithm is known for this problem. The lemma is usually known as Schwartz-Zippel Lemma. A history of this lemma can be found on Lipton's own blog. 

As mentioned by Daniel, you can find some informations in the book A Course in Computational Algebraic Number Theory (link). In particular, there are several ways of representing elements of number fields. Let $K=Q[\xi]/\langle\varphi\rangle$ be a number field with $\varphi$ a degree-$n$ monic irreducible polynomial of $\mathbb Z[\xi]$. Let $\theta$ be any root of $\varphi$. The so-called standard representation of an element $\alpha\in K$ is the tuple $(a_0,\dotsc,a_{n-1},d)$ where $a_i\in\mathbb Z$, $d>0$ and $\gcd(a_0,\dotsc, a_{n-1},d)=1$, such that $$\alpha=\frac{1}{d} \sum_{i=0}^{n-1} a_i\theta^i.$$ 

The second bullet point is quite vague. What I want to understand is whether sorting the lists (or one of them) is necessary though the answer does not need to be sorted.