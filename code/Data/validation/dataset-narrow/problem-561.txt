Basically, I use to check whether the box should be displayed or not. Note that is changed in other parts of the code (for example, when an item gets selected becomes . Is this a good way to make things work? Or did I overlook a much easier way to do this? 2) The wrapped element must be the first direct child of . 

I am especially uneasy about the fact that I check twice if the type is 'and' or 'or'. I need to fully check this because I need to add a feature to this: I need to add the ability to add an parameter: 

The more I think about it, the more I think that a much better Polymer-ish way of doing it would be to require the input field to have a specific ID, and and use that ID to distribute the right content. So MAYBE the template should be: 

Which creates an entry for every space-separated string in . That way, I can make composite queries if needed. At this point, I don't quite understand where to plug that in. Here is the function... 

I totally suck at recursion. I have a function that works but it also looks horribly wrong. I would love to 1) Know how to write it properly 2) Know about resources to read/study so that I don't get so stuck again. The function is simple: given something like this: 

I have just finished writing this: $URL$ This is the source at the time of me writing this post: $URL$ This is one of my first complex-ish Polymer widgets. I was wondering if you could have a look for me. Questions: 1) I coded the keyboard navigation as best as I could. Focus is tricky. I found it really, really difficult to make sure that when the input field loses the focus, the suggestion bar should disappear. I think there must be better ways of doing it. Do you have any hints on that? At the moment, I have this in the template: And then: 

This is my very very very first attempt to write anything meaningful in node. The client side is a simple form that has login, workspace, and simply saves them onto the database. It would have been a 5-liner in PHP! My question really is: does this code look sane/good? I am trying to avoid using async.js for now, just because I want to get my hands dirty a little to start with. A few notes: 

Now you can access the created IDs using . Of course you'd want to store the or something in the same table, to relate them. EDIT: Untested replacement So I've just roughly written some SQL I think should work instead of everything including and below the statement. The main issue I have with that part of your trigger is that it will only work for one-row updates, and it performs an INSERT then an UPDATE on that inserted data, which can be optimised. 

Rather than inserting the EpisodeHistory, then checking and updating based on the data we've just inserted, this code just does the operation all in one. First I'll explain the left join. The point of the join is to find the of the earliest matching row (since we want to put it in , right?). So we do a normal select of the table, except we also add a column for , which, when combined with the fact that we've put in the join condition, will means it will only join to the first that matches. This makes sure that if there are two rows with the same , and , it will only join to the one with the lowest . Now the actual columns that are inserted are fairly simple. If the left join fails (if no rows in EpisodeHistory match), selecting will return . Therefore, means that if a was not found in the join, it will just do a normal insert of . If one was found, it will blank that field. The next line is fairly simple in that it inserts if the join happened, otherwise it puts in 0. Since the entire operation can be done in one statement like above, so you can ignore that bit I said above about temporary tables and an clause. This code above also has the added bonus of working for multiple-row updates. It's a trigger... You may already know, but the SQL Server community is fairly divided when it comes to whether triggers should be avoided or not. They can be easy to forget, hard to debug, and can hinder performance as they become part of the write operation. Since you mention performance I'll elaborate on that aspect, and I'll make some assumptions I hope you can forgive. I'm going to assume there's an application that sits in front of this database, and the application prompts the insert/update. Say the user is on a form and makes changes to an episode, and submits the change. Usually the application will wait for confirmation of the update/insert operation before proceeding (before loading the next page, for instance). With the trigger, the application now has to wait for the initial insert/update, as well as the trigger to complete its operation too. Therefore, if you haven't already, consider the possibility of separating out this process. In this example I gave above, you could have it so that the application still waits for the initial insert/update operations, loading the next page normally, but then in the background (asynchronously) it tells the database to perform audit operations. Boom, you've reduced page load time, better UX. This also has the benefit of you not having to worry so much about performance tuning the auditing operation. Checksum? I'm going to assume since performance is an issue that you've considered indexes, and have an index set up to optimise this and comparison. Have you considered the use of ? I don't have any experience with it myself, however I'd imagine you could use it in combination with persistent computed columns to improve the load when write and maybe reading to the indexes. In this instance you'd have an extra column on both tables called something like , which would be a checksum of eDescription, and you'd put that column in the index instead of . Then when you perform the comparison to see if they're the same, you'd be comparing the relatively small and light checksum column instead of the potentially-huge column. Minor issue I see when you set the , you select from multiple tables. It's recommended to use joins instead â€“ use of multiple tables in the clause is being depreciated by all DBMSs. If anything's unclear, let me know. Hope you found this helpful. 

I'd suggest to filter out unneeded elements, instead of replacing them by -1. Keeping and processing all the -1 is unnecessary: 

Then comes for free from Foldable defined as . This allows you to use other monoids for which is less costly compared to of lists, for example or . 

Since you need to abort your computation early and return a value different from the final output, the transformer would be useful. 

Just one more note, please post code that compiles, especially for CR, it's much easier to work with; see $URL$ 

Here results into , where the result is if the character is or if it doesn't match any supported operation. And then we use twice from , which, specialized for , applies to yelding . 

This returns a pure result, but works somewhat more efficiently than (which is otherwise the way to go in Haskell), at the expense of being more imperative. 

I'm not sure about this. It's indeed weird and breaks the usual expectations that is a ring, although it's probably not a big deal. I'd certainly note this in the docs for the instance. 

Alternatively you could even keep the result in an ST variable. Also with can be replaced with (untested): 

Second, if you could generate all the products in a non-increasing list, you'd just be searching for the first element of such a list satisfying the predicate, which would also speed the search very much. See data-ordlist package, which implements many useful functions on sorted lists, in particular in your case you'll probably need or 

In Haskell you can always use , see The Haskell Report. So your original code could be written as an one-liner as follows: 

First, since is commutative, you can save 1/2 of your computation if you restrict yourself to cases where : 

what is the other node it connects? My guess is that the other node is determined by the index of the list in the vector. In any case, this should be documented in comments for the types. Also, a question comes to my mind, why the graph is a , but the list of edges is a ? Regarding comments, I'd suggest you to use the Haddock syntax, as it's then very easy to generate documentation from the code. Also it's not clear what means in the vector. It could mean that an element hasn't been explored yet (infinite distance), which would work well with manipulating distances, but it seems to be used for elements that have been removed from the queue. I'd rather use a queue that allows proper removal of elements, and use that deals with infinity (see below) For representing distances it'd be useful to have a separate data type, something like 

Per billinkc in the comments, before would do what you intend. Per Michael Green, avoid using where possible. I recommend using instead. Here's an example: 

It will only work as intended for single-row updates The fact that you use and tells me this was designed with one-row updates/inserts in mind. But what happens when you update multiple rows? (In case you don't know, the trigger only fires once for the whole changed set, rather than once for each row. The changed rows are added to the and tables). To solve this, I'd recommend using a temp table or variable table instead of , and the clause instead of . For example: 

Since s are used, you'll only ever be returned rows where the is smaller than the , so the code works as intended. If I understand correctly, you want the code to check that is smaller than AND is bigger than . However, those two conditions are the same so you only need one of them. As a sidenote, your code will not work as intended for the following reasons: (1) It will bring back any actors who have starred in ONE movie together, rather than two, and (2) it does not list the movie names they have starred in. The first problem is easy to fix; add to the end of the statement. The second problem depends on the version of SQL Server you are using (use to find out): 

Now you've got the table with a single column and a single row with the new ID you just inserted, so when you need to access that ID when inserting addresses and phone numbers, you can join or subquery like you would any other table. As far as I'm aware, variable scoping doesn't matter in SQL Server stored procedures â€“ if you declare inside the block, it will still be accessible once the code has left that block. So you could declare the table right before the insert to keep its use obvious, or near the top of the query like normal coding languages, to imply it is used not only in that block. Everything else looks good to me. 

In addition to the other great answers, I'd like to point out a few details. First, in your function you skip too far, you need to go through elements one by one. Your code applied to passes. Rather you need to pattern match like this: 

Somewhat old question, but still it's a pity it hasn't been answered :). Putting aside the asymptotically better solution suggested in the comments, and focusing just on the code: Pluses: Top-level types for all funtcions, that's very good, as well as comments. The code shows good understanding of various Haskell functions and idioms. My most general comment is that there is disproportion between code verbosity and complexity. Usually more complex code should be more verbose and more descriptive. Visually, most of the code is just simple read/write/swap ST operations, but the important part is squeezed into not-so-easy-to-understand and uncommon combinations of folds/scans/sequence/>=>/>>= etc. I'd probably separate the simple parts (read/swap) into helper functions and expand/simplify the complex parts a bit. Function somewhat mixes pure and mutable approaches. While it mutates its first argument, it keeps the scalar product pure and passes it as an argument in and out. This is somewhat confusing and complicates the computation of the minimum ( with ). If the product were a ST variable too, the code gets simpler (untested): 

And this is actually a very natural way how to express the solution: If we already know the longest paths in the part below a particular level (represented by and in recursive right-fold), we can compute the paths for this level as well. 

This leads you to creating a monadic interface of your parser. So your type could be something like: 

Interestingly, the inner type is already a monad, corresponding to , or alternatively . Now standard monadic should correspond to and to the identity matcher. And also to . Such an interface will give your matchers all the power monads offer with very little effort. 

Or, you can also avoid doing recursive operations yourself and instead use existing list functions. Some hints on alternative solutions (which could be good exercises):