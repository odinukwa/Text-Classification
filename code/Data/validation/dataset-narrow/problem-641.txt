I think you can improve the 'Inverse rotor pass' a lot by hard-code the inverted rotors instead of searching the inverse function every time. Your is never below so you could try to replace 

How to compare the the Algorithms: Either determine the complexity of your algorithm and the complexity of the solution in the tutorial. If you want to avoid to determine the complexity based on the source code you can simply implement the tutorial solution and compare the runtime of your algorithm and the runtime of the of the tutorial-algorithm. To get a good idea of the complexity behavior of both algorithms you need inputs of different lengths to approximate the runtime related to the size of the input. How to improve yours If your approach is very different you might not be able to improve your algorithm by looking on the tutorial-algorithm because they are too different. If the Tutorial-algorithm is better at all, you can try to understand the steps it does and try to memorize the general idea of this steps for your next algorithms that address similar problems. 

The code is now shaping up nicely. Let's consider the final loop. Here you're ing until it's empty. Why not just loop over it in reverse? (The stack is going to be destructed anyway). Iteration is probably cheaper than mutation. 

First of all, you're only referring to once, and never use any further. The quick solution would be to iterato over instead: 

Also, there is a bit of a trouble with race-conditions here, but that's probably easily solvable using transactions and locking. Or, better, use 1 query (which is also faster!) 

The algorithm itself. Your algorithm is also far from optimal, calculating collatz(16) several times. First, when trying to add 3, it goes 

And similar for match2 and match3. However, the real complixity in your implementation lies in the determining of the error message to show. I would suggest building a dictionary mapping the display error to internal errors: 

In general, no, this would not be the fastest approach. However, assuming that all the lines are quite small, I think you won't do better by the 'general' fast approach. You could use . 

Simplified tail-recursive code: end-recursive methods are likely to be detected by the interpreter and transformed to a loop. So this code might be faster and may nor waste memory. For more information see wikipedia Tail call 

I have never written any Lua code before, but a short view in a tutorial at $URL$ let me come up with this: Extract a method which returns 3 values: 

You can also unroll the - loop, by copying the inner body 2 more times. If you can manage to change the mask_function: 

So binary search should be faster, if comparison is the main factor, for n > 4. If n is constant (its seams 64 in your case) you can even hard-code the binary search to avoid the overhead of a loop. (that is also possible for linear search.) As an example how to hard-code a binary search: [for a array with 8 entries] Code will get quite long for 64 entries, but it will be fast. If your intervallBoundary array is intervals[0..7]: 

It is a matter of taste, so there is no 'better'. But more common seams to be because often the conventions of JavaBean are used. If you work in a team, I would discuss the naming conventions to use with them. 

I really see no reason for anything to slow down purely based on the selection of the radio button, is there a way to improve this code? 

I have a method that retrieves information relating to a Contact that was made between two Companies. I am looking to improve my code in any way and am intrigued in hearing any recommendations you may have on how this method can be improved. I use it throughout my program but modify it according to the DataModel I am attempting to load. 

I use a here as I couldn't get the styling I was looking for in a . I also created a minimal version of a , so I can search on fewer properties. Reading around there are solutions but many are < 5 years old. I'm also aware that can be slow so I suppose I should be looking at a different approach to the itself. I'd appreciate any help and advice, thanks! 

From the code you can see there are two more methods involved in the filtering; CompanyMatchesFilters 

Why do you need a linear search [O(n)]? You can determine in which interval the value belongs by a binary search [O(log n)] (do not implement is with a recursion! use a loop or hard-code it))). Average number of comparisons for linear search is n/2. Binary search needs a constant number of comparisons of ceiling( ln(n) / ln(2) ). 

If a number can not be divided by 2 it can also not be divided by any even number. So you can check2 and than only the odd numbers. you can make a list of all little prime numbers and check these and from the point where you have not the primes, try all odd numbers you can stop checking at sqrt(n) but that is quite expensive to calculate. Not so good, but still halves the work, stop at . 

But only profiling will tell you if / how much speed improvement that brings. Also you should always profile before trying to optimize. See were the bottleneck is. 

You need to check if each letter occurs the name number of times in both strings. One method would be to sort the letters and compare the lists of letters for equality. Here is my approach: 

Because is inside the loop, it always gets reset. Are you sure you have tried the algorithm with larger files? (And tested it is correct)? There are more reasons why I think your code is broken, for instance the handling of , and where the assignments take place. Rewriting . What should do is the following: 

(my preference is the second). Finally: please use capitalization when writing strings for the end-user. So, instead of , write . (The final space is to make the question look even better when entering the data, but that's merely convention.) After making the changes, I ended up with 

Especially if the file is large, and needs to be transfered over the network, it's good to know what the file is working on. Now, I assume the is now a bug, as the file no longer gets truncated. Assuming we can replace it with instead, we could write: 

Wow, we saved a few lines of code. If we're lucky, it's also going to gain us some performance. Next, you have . This can be replaced by (as that's how dict containment checking works). Furthermore, can be replaced by . Furthermore, you write followed by . You can simplify this to . 

In my point of view you cannot implement and any clearer or simpler. In the method I would somehow separate the values and also not print two times and not at all. Here is my suggestion: 

calculate distance to each polygon surrounding circle and eliminate all polygons which are too far away to be a match Entity: performs a loop through all not eleminated polygons. Polygon Loop: loops through ALL vertices of the polygon in the current iteration. Vertex Loop: if the distance between the entity and the current vertex is lower than the distance between the entity and the previous vertex, save the current vertex and the ID of the polygon the vertex belongs to. Once all loops are finished, take the nearest polygon/vertex and get the vertex of the polygon to the left and right of the nearest vertex. Check the left and right vertices to see which is closest to the nearest vertex. Doing so, finds the nearest line of collision to the entity. 

You can move your method to a Utils-class and pass instances of different Classes all implementing the same Interface. e.g. Based on your parallelizationEngine #3: Utils: 

I have a DataGrid that I filter when the user inputs text into a search box. The column that is filtered is based upon which radio button the user selects (Name, Town or Post Code). Although initially nothing happens until the user has started typing into the searchbox, for some reason there is a noticeable delay in selecting the different radio buttons. Intuitively I thought that something was happening when the radio button is clicked, but there is (as far as I can tell) nothing being called. The C# program is relatively long, so I'll include the XAML for the radio buttons and the methods that they are being used but not the whole program, unless nothing is found originally. SearchGrid 

I have around 350 loading into a and am already noticing some lag when filtering on their . This concerns me as we could easily reach > 1000 quickly and I need filtering to be as quick as possible. I'm trying to avoid calling as I know this is expensive but I am not quite sure how to do this here. Here is my code: C# 

to a method passing true or false as a parameter and reuse it instead of having nearly exactly the same code twice. 

If possible I would try to avoid a method like . If someone manages to manipulate the this becomes a classical injection problem. If you do not need the flexibility to make any kind of db requests, use prepared statements for specific requests which only get some parameters. 

I think speed will only increase a bit, if at all, if you use arrays (The List implementation you use may already use an array). But you will reduce memory consumption if you switch to an array based implementation if you reduce the number of objects used this way. You should profile both implementations to compare speed and memory consumption. 

If shape and number of polygons do not change (or at least not often), I would add an extra step (the new first step) to your algorithm. Calculate the center and radius of the smallest surrounding circle for each polygon. This way you can calculate in a minimal and maximal distance of all vertices from the given position in one run without iterating through them. If the minimum distance for a polygon is greater than the maximum of an other polygon, no vertex of that polygon can be the nearest => we can ignore this polygon. Than proceed like you did before.