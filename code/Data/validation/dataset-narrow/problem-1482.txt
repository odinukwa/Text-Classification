Honestly, your suggestion of just going by the download counts seems unwise in some respects. While popularity does probably offer a good indication of maturity and stability, it doesn't tell you whether the library actually does what you want, in the way you want. Let's take my React example again. Yes, it's popular, and indeed, it is a front-end framework, but it requires a lot of 'buy-in' — you have to deliberately design your pages around React to get much out of it. jQuery might fit my use-case perfectly, despite being a little less popular, but by just picking the popular library, I'm stuck with even more work. As an analogy, how do you pick which car you want to buy? You probably don't buy a Ford Fiesta just because everyone else did. You probably take a look at the specifications, fuel economy, and perhaps give it a test drive. Putting that investment in and learning a little about the popular libraries is well worth it. You only have to do it once to learn the philosophy and the goals of that project, and once it's done, you know when you want to pick that library above the others. You can try and tell them metrics to look at... or you can accept that you need to dedicate time to trying the popular libraries, and getting that 'test drive'. Spend a lesson trying React, and get your students to tell you what they think. Going beyond the trivial 'Hello world' might be helpful (I hear the TodoMVC example is fashionable and more complex). Or, if you can't afford the time, I think you'll simply have to tell your students which library you want them to use. What your students are doing now is great, if a little inefficient. You can help by prodding them in the right direction — share what you know, and give them a nudge if they start burying themselves in too many libraries. Sometimes, I think all that's needed is a little poke to say that not all JavaScript projects need to handle every possible future concern, and to Keep it Simple, Stupid. 

The whole point of TDD is to try and reduce the number of defects in software. If your students are confident enough to think that they won't benefit from automated testing, fine — but have some tests prepared to run on their code to ensure that it's actually correct. If they fail your tests (which you need not specify in advance), then their solution is not a complete, working one, and they need to go back and figure out what went wrong. I imagine you could gamify this a little bit if you wanted — I've talked about Codewars before, which uses 'hidden' unit tests to see if your solution works or not. You could do the same with your students' submissions, but you might not even need to use a framework to do that. You mentioned web services — why not just black-box test it a little to see what happens when you put in unusual results — does it fail when it should? You could even try fuzzing the code to see if completely random nonsense produces the right response. Essentially: make the costs in the class the same as in industry — defective code is not a valid solution to your assignments. In a job, a serious bug might cost your employer a large sum of money. You could emphasise that in your classes, and show them cases where testing has not been done, leading to huge amounts of cost. If you follow TDD, you shouldn't really be spending much more time testing, unless your students replace the writing tests before writing code with just writing code without testing. Otherwise, surely the costs are very similar in terms of time if the tests get written either way? That is, of course, ignoring the productivity benefits of having tests that you can rely on while writing your code, so TDD might even be quicker! 

So, the 'smart' solution uses 5 lines. One student submitted a solution to that function with 1382 lines.3 Wait, what? I suppose you'd quickly realise that this student's solution was... sub-optimal... if you asked them how many lines when they presented their project. And here's why: 

If you're just looking for the key points on how you can begin to solve the problem, you need only read the second section, but the first section provides valuable context on what the actual problem is and the root causes. Why are so few girls interested in Computer Science? There is an issue, not limited to CS, but throughout STEM fields (particularly Physics, Mathematics and Computer Science, according to recent examination statistics) with gender balance, where women are extremely underrepresented. In 2014, only about 10% of entrants for the Computing A-Level were female. Miura (1987) suggests that women's self-efficacy regarding computing is lower, which leads to lower interest in the field and lower uptake at undergraduate level. Fisher, Margolis & Miller (1997) also propose that women have less previous experience than men in the field—many have already started to self-teach or practice at home, whereas this is less true for women in the study. They also state that, from their interviews, women seemed to appreciate computing more as they went through their studies, whereas many of the men in the study showed a keen interest as soon as they were introduced to computing. Fisher & Margolis (2002) discuss the "Geek Mythology"—the stereotypical male computer scientist—and its effect on women: 

Is there any way of evaluating code style and design automatically (or at least detecting very poor solutions)? I've thought about using some static code analysis to try and evaluate solutions (e.g. cyclomatic complexity, or tools like these), although I've not tried them yet. Are there any reliable solutions to this, or must it be done manually? Does static code analysis help in any way? 

Node.js (and the JavaScript world in general) seems particularly prone to short-lived, highly popular libraries and frameworks which re-invent existing features in different ways. You need only see the Stack Overflow blog which illustrates this trend well enough: 

In other words, if $\mathbb{F}$ is the set of values representable by a floating point number, $\mathbb{Z} \subseteq \mathbb{F}$ (the integers are a subset of the values represented by floats). Or, if you want an image to show: 

There are an immense number of use cases for neural networks (although there is a lot of hype around the subject with some unrealistic promises!). I would imagine a basic grasp of calculus and a firm understanding of the basics (syntax, algorithmic thinking, etc) would be necessary, although it would depend on what depth you wanted to teach. You could discuss superficially by just introducing the structure of a neural network, but many of the really interesting applications require a more in-depth knowledge (i.e. linear algebra/matrices) to fully appreciate the topic. The course Neural Networks for Machine Learning seems highly relevant here, and it might be worth examining the topics covered to see how it may be possible to teach this. I don't think it's something you can really skim if you want to actually get to the good stuff, but if you don't have time, showing some examples and providing resources for your students might still be worthwhile if they want to put in the time themselves. 

With some basic knowledge of the framework used (Express), you can tell that when the route is accessed, will be sent. So, without looking too deeply, event-driven programming is the obvious choice. But, this isn't the end of the story. If you're not used to event-driven programming, the fact that your code might not run in the order you expect is very confusing. 

There are many groups aiming to change the culture around computing, such as Django Girls, an organisiation running free, one-day courses for girls and women interested in web development with HTML, CSS and Python. Events like this would seem to satisfy the goals of a supporting group of instructors, and a real-world problem to solve, which favours participation from women. As a teacher, even changing the classroom environment may help to favour women and girls. Cheryan, Davies, Plaut & Steele (2009) state: 

The cheapest instance () is priced at $0.0058 per Hour, though you'd probably want to look at a more powerful instance to save time. For $20 per student, you could give them 22 hours of compute time or 3500 hours of time (or something in between this if another option would fit better). It would be wise to test the time taken for EC2 to run a few epochs yourself first before going and paying for your students to do it; you could then work out what a 'reasonable' amount would be to give them, or if this is feasible at all. This is unfortunate in some ways, however, as it means that students who work quickly are advantaged more than those who spend hours experimenting. It also means that students that need more time would have to work at their own expense; whether this is permitted by your University's policies or ethical is questionable. I would anticipate that it'd be easy for students to accidentally waste credit if they weren't familiar with AWS too. For this reason I'd be wary of putting this into practice... but it's better than overloading the students' personal laptops. 

Note that in this example, you subtly introduce the fact that comparing values is done with , not , and there's a link to values, types, etc. Whether you explicitly mention them at first is up to you—some resources do recommend it, and some don't. 

I would consider teaching in Python if you wanted to give your students a taste of programming in a text-based language—pretty much the only type of language used professionally. A visual programming language like Scratch is probably better for younger groups, and teaches the underlying programming concepts well, but you will reach a point where you must write in a text-based programming language. There are very few programmers who work professionally in visual programming languages, so Python provides a nice 'first step'. Note that I would specifically recommend Python 3, because it has far fewer 'oddities' that you'd like to avoid. I've briefly discussed this here in comparison to Python 2; it seems like a no brainer to teach in Python 3, which is much more intuitive. Regarding your constraints: 

You can create 'Clans' (perhaps for your class) so a league table is shown—the gamification might be a good motivator for some. The difficulty of the kata increases as you get better (and harder kata give higher rewards), so the difficulty should ramp up and help students develop their skills. This, of course, does require students to be relatively comfortable with the syntax of at least one programming language. If you've not taught any of the language itself yet, you probably should do that before you teach algorithmic thinking—a basic handle on how a programming language is used would probably be useful so that students can understand what an algorithm can and can't do. 

I don't really think there's a silver bullet to this problem. To be able to think algorithmically, you need to solve lots of problems, over and over. Some students will naturally have the ability to be able to describe algorithms without much teaching, but it's not a universal skill, and it comes at different rates for different people. In an ideal world, adapting the level of difficulty of the algorithms to design would be useful: get an easy algorithm right, and then move on to a harder one, until you get stuck, and then go back down until you master algorithm design for even complex problems. However, that would require a lot of attention to do in person, so to get that level of support, you need an automated solution. I highly recommend Codewars as a good tool to practice solving simple problems that scale up in difficulty—I had great fun trying some myself a while back.