In a dual stack network, a host has both an IPv4 and an IPv6 configuration allowing them to choose which protocol to use. When communicating with an IPv6 host, it will use its IPv6 address, when talking to an IPv4 host, it will use its IPv4 address. From your question, I gather that you have IPv4 on all systems, but IPv6 is only configured on the routers. To make the network fully dual stack, the hosts should also be configured to run IPv6. To allow an IPv4-only host to an IPv6-only one requires some kind of address translation. There are different so-called "IPv6 transition mechanisms". Most are designed to be able to deploy IPv6-only networks and still allow the machines to talk to IPv4 networks. 

With store-and-forward, the router starts sending the first bit of the packet to the final destination only after receiving the last bit from the source. When not buffering, the router will start sending the first bit of the packet immediately after receiving it. The first bit is arrives at the final destination when the second bit arrives at the router. By receiving and sending the packet in parallel, the router can finish the job faster. One could argue the actual delay in this case is (L+1)/R because the sending can only start after receiving one bit, thus after a time 1/R. 

You might be interested in RFC 6164: "Using 127-Bit IPv6 Prefixes on Inter-Router Links". The abstract clearly mentions security as a motivation: 

According to RFC 793, TCP uses a retransmission timer per segment in its retransmission queue. That means segment 2000 in your example will only be retransmit when its own retransmission timer expires. When ACK num 2000 is received, the CWND allows for 2000 outstanding bytes. But at this point, there are 3000 bytes outstanding, so nothing extra is sent. TCP waits for the respective retransmission timers before resending segments 2000, 3000 and 4000. However, in your example scenario, four segments are sent at once, meaning their respective retransmission timers will expire at (almost exactly) the same time. That would result in the retransmission of segments 2000 and 3000 immediately after retransmitting segment 1000. To clearly answer the question, RFC 793's TCP will not "wait for another expiration of the retransmission timer" because there is no such thing as "the retransmission timer". TCP will wait for the expiration of any of the currently active retransmission timers to retransmit the corresponding segment. In reality, TCP has evolved since 1981. For example, Fast Retransmit (RFC 2581/5681) is an exception to the above rule. After receiving three duplicate acks indicating the out-of-order reception of a segment, fast retransmit will kick in retransmitting a segment before its retransmission timer expires. TCP is byte-stream oriented, and the retransmission queue holding previously sent segments is only one of many ways to implement retransmissions. A TCP implementation might as well do without such a queue and generate a new segment starting from the first unacknowledged byte in the buffer. No specification requires this to be the exact copy of a previously sent segment. It could have a different size or contain a partially overlapping part of the bytestream. Introducing features like selective acknowledgments further complicates things. 

The packet arrives on some layer 3 interface. The destination IP is 10.5.89.34, and the MAC address on the incoming frame is the MAC address of the receiving interface. The routing table says packet should go out to a directly connected subnet on VLANIF94. A new ethernet frame has to be built containing the same dest IP, but with the dest MAC address set to the address of 10.5.89.34, which needs to be found through ARP. An ARP request "Who has 10.5.89.34?" is broadcasted from the VLANIF94 interface. Since this is a vlan-interface, it will be sent out of all ports in vlan 94. The copies of the frame will be vlan tagged if they go out of a tagged port, and untagged if they go out of an access port. An ARP reply will be received informing the router of the MAC address for 10.5.89.34, and the original packet can be sent out VLANIF94 in a frame using this MAC address as its destination. The frame will be sent out the switch port in vlan 94 which is listed with that dest MAC address in the MAC address table (this entry was learned in step 4). 

The security issues described are the "ping-pong issue" (routing loop) and neighbor cache exhaustion, but as mentioned in the document, for IPv4 the discussion is a bit more academic: 

The generic answer to your question would be "exclude mode is to be used when the list of IPs you want to listen to is longer then the list of IPs you do not want to listen to". The most common use case is actually the most extreme case: listening for packets from any source. This means using exclude mode with an empty exclude list. Since IGMPv1 and v2 do not support source-specific multicast, this is the way their behaviour for a "group join" is emulated in IGMPv3. 

Some work has been done to determine subtle differences in DHCP packets from different OSes, resulting in DHCP fingerprints. Examples include the options present in DHCP request and their order, and the content of certain options like option 55 (parameter list). Have a look at the papers and signatures at fingerbank.org. This suggests (have not tested it myself) passive OS fingerprinting based on DHCP traffic can be done. The result can possibly be improved by including other information, like generic IP properties (TTL, diffserv, ...). Active fingerprinting might provide a better result, but might not be an option in your use case. The Fingerbank website mentions a couple of open source products which use the signatures. Proprietary DHCP appliance Infoblox seems to include a similar feature, but no technical details are provided. 

which is . You may have noticed it is not possible to do the reverse mapping. All multicast IPs start with the 4 bits , leaving 28 bits for 2^28 different multicast addresses. Since there is only room for 23 bits in the multicast MAC address, such a MAC corresponds to a group of 32 multicast IP addresses. 

The fact that Dijkstra's algorithm cannot handle negative edges is not an issue in routing. Because Dijkstra's is a greedy algorithm, it needs to know about all nodes to be able to calculate path costs. In link state routing protocols, every router has a full map of the network on which it can executes Dijkstra's algorithm to populate its routing table. Unlike Dijkstra's, the distributed version of Bellman-Ford used in distance-vector routing protocols can handle the gradual increase of available information in the incoming advertisements. 

I don't know how to show it in the CLI, it's not in the output of or afaik... Another option could be to query it using SNMP. Avaya supports the IF-MIB, and the ifTable entries contain an value (.1.3.6.1.2.1.2.2.1.9): 

Your Cisco 2500 WLC can authenticate wireless clients in many different ways, one of them being a captive web portal with username and password. A Radius server can be used, but this might be overkill if you are only going to set it up for authentication on the wireless network. Users can also be defined directly on the WLC. Explaining how to set this up is beyond the scope of this Q&A site, but have a look at the Wireless Controller Configuration Guide, more specifically at the sections "Managing User Accounts" and "Managing Web Authentication" 

However, you are using a QFX3500, and I cannot find a similar statement in the QFX range documentation. Here, Juniper states (2): 

The bezel is the decorated plastic panel making your router or switch look nice in the data center. Here's an drawing from Cisco: 

I would not recommend a fixed speed and duplex setting in this (or almost any) situation. The days of frequent autoneg issues and incompatible implementations are gone, on recent equipment such issues are very rare. If autoneg is not working, switching to a fixed setting is a workaround, hiding the underlying issue that causes the autonegotiation to fail. Not fixing this issue might allow it to bite you later. Also, the probability of speed or duplex mismatches and the like is actually much higher in an environment with fixed settings, caused by left over settings when moving equipment around. As an example, if in your case the cable is to blame, setting both sides to 1000 fixed could disable the link with the faulty cable completely. Autonegotation gracefully degrades you to 100. It is of course up to you or your monitoring equipment to detect and fix this. Interesting blog post, with links some vendor recommendations: "EtherealMind on Autonegotiation" 

So the bezel side of a device is often called the front. The back, containing all the interfaces is in this case called the "business side", because it is the important side. You bought the device to connect stuff to, not for its decorative appeal... Fans blowing "business to bezel" will take air in at the business/back side and blow it out the front/bezel side. A correct airflow direction is important for cooling, and depends on how your datacenter is cooled and how the device is put in the rack. 

I would assume /17 to /32 are the smaller prefixes. Prefix is used as a synonym (1) for network in this case. The prefixes are longer, thus the networks they describe are smaller. I can see this could indeed be considered confusing, smaller as the opposite of shorter, but that's natural languages for you. (1) It's probably a metonym, but that's a discussion for a different stack exchange site... 

Detecting link on a port is not done using ethernet frames, but with electrical pulses known as normal link pulses. If no frames are being sent, a device puts these on the wire every 16 ms (+/- 8 ms). They are also used for autonegotiation. A link is considered down if no frames and no pulses are received. Receiving the pulses will make a Cisco tell you the port is up, but as we all know, it is perfectly possible to have "". The normal link pulses are not frames, and will not be forwarded by hubs or switches. Keepalive frames are forwarded or switched, and can be used to detect a loop. 

Ping is just a small program which sends ICMP Echo Requests, and receives the ICMP Echo Replies. Actually, many different implementations of ping exist... On Windows, the default ping utility sends 4 echo request by default. So, when everything is working fine, you will see 4 echo replies. You can send more (or less) requests by passing the option to the ping executable. On Unix systems, the default implementation will keep sending echo requests until interrupted by the user (with Ctrl-C), and the option to send a specific number of requests is . 

One cable for one connection is the correct way to go. Two 100 Mbps connections on one UTP wire might work under some circumstances, but it might as well cause all kinds of weird problems. If the cable run is straight and not too long, you could try to use the existing wire to pull through a pair of cables and use both sockets. Careful, this could also go wrong and you could end up with no working cable at all. If you want to connect multiple devices, the best option might be to wire one socket and then set up an ethernet switch to provide multiple ports. 

You seem to be confusing slaves and caching servers. Note that, unlike the masters and slaves, the caching servers are not operated by or on behalf of the owner of the zone, but can be any DNS server in the world that has obtained information about the zone. The refresh time tells a slave when to check for new information from the master server. The TTL is meant for caching servers, telling them for how long information can be cached. QUESTION 1: Yes, a slave server will update its zone information through a zone transfer after refresh_time seconds. QUESTION 2: Lowering the TTL before a DNS change prevents DNS servers around the world from caching the old IP address after it has been changed. Slave servers can be explicitly notified of a change, but sending a low TTL with responses is the only way to incluence the behavior of caching servers. 

When the server's MSS is less than 1452, the router should not touch the MSS. The client will see the correct value sent by the server. and will match if Wireshark does not interpret the data in the TCP stream. If wireshark can make sense of the data, it can update . They don't have to match. For example, in the case of HTTP, can contain the total length of an HTTP POST request reassembled from which is spread over multiple TCP segments. 

The documentation for the Juniper EX series switches indeed mentions the possibility of creating a VLAN without specifying a VLAN id (1): 

So multiple addresses can be useful, but the decision to allocate over 16 million of them was clearly taken at a time when nobody worried about an address shortage... Note that IPv6 only has one loopback address (::1/128). 

Negative edge weights are indeed not very useful in routing applications of the algorithm. Being able to handle negative weights is one property in which Bellman-Ford differs from Dijkstra, but it is not the reason it is preferred in Distance Vector algorithms. Running Dijkstra's algorithm requires full knowledge of all edges and weights in the network. Unlike link state routing algorithms, distance vector algorithms do not construct such a full network map. This means Dijkstra's algorithm cannot be used in distance vector algorithms. (Distributed) Bellman-Ford works without the full network view and thus can be used in distance vector algorithms. 

Strictly speaking, when performing (pure) NAT, only IP addresses are translated, and every internal IP address has to be translated to a different external IP address. This can be a static one-on-one mapping in the case of static NAT, or a dynamic mapping with a pool of public addresses. With dynamic NAT, the router selects one IP address from the NAT pool when an internal hosts wants to connect to the internet. When a second host sends traffic to the internet, a second external IP from the pool is used. This works just fine, but the number of hosts that can use the internet is limited by the number of external addresses available in the NAT pool. When the 11th host behind a NAT router with a pool of 10 addresses wants to set up a connection, the connection will be refused (until one of the previous mapping times out). NAT overload overcomes this limitation by allowing internal hosts to share external IP addresses. To keep the connections apart, in addition to swapping the internal IP for an external one, the router can change the source port of the outgoing traffic. Because NAT overload is used most often, it is sometimes considered the default and just called NAT. Other terms include Port Address Translation (PAT) and Network Address Port Translation (NAPT). In Linux iptables, it is called masquerading. 

after two RTT measurements have been made. After the first measurement, SRTT is initilized to the value of this first measurement, ie. . You were close, according to the RFC alpha be 1/8 (= 0.125). Note, in RFC's, means "there may exist valid reasons in particular circumstances to ignore a particular item, but the full implications must be understood and carefully weighed before choosing a different course." (RFC 2119)