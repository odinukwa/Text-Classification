For the sake of the argument, let us suppose we can actually figure out that it means for "$K$ to trick $M$". You considered in your question the case when $M$ is supposed to fight against just one machine $P$ that tries to trick it. However, there will be infinitely many other machines $P_1, P_2, \ldots$ that try to trick $M$. These are just variations on $P$, with modifications of source code, using slightly different algorithms, etc. Let us make one further reasonable assumption. Without loss of generality, think of machines as computing partial functions from $\mathbb{N}$ to $\mathbb{N}$ (just encode inputs and outputs as numbers in a reasonable way). Our extra assumption is this: if $P$ and $P'$ compute the same function (but maybe using different algorithms), and $P$ tries to trick $M$, then also $P'$ tries to trick $M$. In other words, "tries to trick" is a property of machines which does not depend on how they work but on what they do. By Rice's theorem $M$ cannot correctly recognize all the machines that try to trick it. Therefore, either it gets tricked by some machine, or it answers "maybe" for some innocent machine that is not trying to trick it. 

That is a lot of work, too. Some projects along these lines have been done (for instance the interpretation of $\lambda$-calculus in a cartesian closed category). I am not aware of anyone formalizing toposes, for instance. In summary, using a proof assistant to help check that you're not doing anything wrong in the internal language is a good idea (in fact, it is a very good idea, as attested by homotopy type theory, where we used Coq and Agda to develop new theorems which were only later unformalized into English), but using it to get statements about models is unlikely to work without a lot of extra work. Which is not to say that you shouldn't try! 

The main reason for avoiding sets in semantics of types is that a typical programming language allows us to define arbitrary recursive functions. Therefore, whatever the meaning of a type is, it has to have the fixed-point property. The only set with such a property is the singleton set. To be more precise, a recursively defined value $v$ of type $\tau$ (where typically $\tau$ is a function type) is defined by a fixed-point equation $v = \Phi(v)$ where $\Phi : \tau \to \tau$ can be any program. If $\tau$ is interpreted as the set $T$ then we would expect every $f : T \to T$ to have a fixed point. But the only set $T$ with this property is the singleton. Of course, you could also realize that the culprit is classical logic. If you work with intuitionistic set theory, then it is consistent to assume that there are many sets with fixed-point property. In fact, this has been used to give semantics of programming language, see for example 

A similar issue arises regarding instances of effects. A realistic programming language must allow dynamic creation of new effect instances. Some situations which require this are: 

The above example returns , as it should. Now let's separate the handler into two handlers and apply them, as you suggested: 

Multicore OCaml simulates instances with first-class modules. To my mind that is a hack, as they're using the genericity of modules to simulate generation of fresh names, and as far as I can tell, it's difficult to write a handler that captures all instances of a given effect. Let me also say that resources are not a hack. They are inspired by comodels by Plotkin and Powers. I find it a pity that the people who're doing effects largely ignore resources. They think it's possible to write programs without local references. That's just denial for the sake of theoretical simplicity. 

Suppose there were a computable $f$ as described in the question. Then we could solve the Halting problem as follows. Given a Turing machine $T$, consider the computable function $g$, defined by $$g(k) = \begin{cases} 1 & \text{if $T$ halts in $\leq k$ steps} \\ 0 & \text{otherwise} \end{cases}$$ This is a computable, nondecreasing and total function. Therefore, we may use $f$ to establish that the range of $g$ is decidable. But now we just check whether $1$ is in the range to figure out whether $T$ halts. Notice that I never used the finite/infinite distinction. The above argument works even if we assume that $f$ enumerates a finite set. Are you sure you got your theorem correct? The one I know says that an infinite set is decidable if it can be enumerated by a computable strictly increasing function. There is of course another theorem stating that every finite set can (obviously) be enumerated in increasing order. Supplemental: Let us look at the matter from a constructive point of view. We have two constructive theorems, assuming Markov principle (which is generally used in computability theory): 

You did not say why you want a formalization, but presumably you want to do things with it, for instance prove properties of dictionaries and operations on them. In fact, your question can be understood in two ways: you want a mathematical description of dictionaries, or you want a computer formalization of dictionaries. For a computer formalization have a look at the Coq standard library module FMaps, and if someone can find something better, please post it in the comments or just edit this question. For a mathematical description all you have to note is that a dictionary is the same thing as a mapping with a finite domain. That is, if we have a dictionary (using Python style syntax): 

for all $\lambda$-terms $M$ and $N$, if $M x = N x$ then $M = N$, or for all $f, g$ if $\forall x . f x = g x$ then $f = g$. 

Yes, LEM implies K. See HoTT book Theorem 7.2.5, known as Hedberg's theorem, which shows that any type with decidable equality satisfies axiom $K$. If we assume excluded middle, all types have decidable equality. Your second principle is known as UIP or Uniqueness of Identity Proofs. It is equivalent to Axiom K, see Theorem 7.2.1 in the HoTT book (just scroll up from 7.2.5 by one page). Neither of these can be derived in Martin-LÃ¶f intensional type theory, by a famous result of Thomas Streicher and Martin Hofmann. 

I will attempt to write the same answer as Neel with fewer technicalities (and therefore not really correct). By the way, you are using very strange terminology, which I will avoid. For each type $T$ appearing in a programming language we can define a partial order $\leq_T$ as follows: 

The problem "Does a reference escape its scope?" is undecidable. An effect system can only overapproximate the answer to the question, so there will necessarily by tricky situations in which the compiler will claim that a reference might be escaping its scope, but it really won't. However, this is unlikely to be a real problem. After all, if a sophisticated compiler can't tell whether a reference is escaping its scope, how can we expect humans to do it? Note that there are uses of references where we want them to escape scope. Here are some such cases: 

The equation $e = e' : 0$ only captures the fact that $0$ has at most one element so I don't think Neel is capturing the whole story. I would axiomatize the empty type $0$ as follows. There are no introduction rules. The elimination rule is $$\frac{e : 0}{\mathtt{magic}_\tau(e) : \tau}.$$ The equation is $$\mathtt{magic}_\tau(e) = e' : \tau$$ where $e : 0$ and $e' : \tau$. Throughout $\tau$ is any type. The equation is motivated as follows: if you managed to form the term $\mathtt{magic}_\tau(e)$ then $0$ is inhabited by $e$, but this is absurd so all equations hold. So another way of achieving the same effect would be to pose the equation $$x : 0, \Gamma \vdash e_1 = e_2 : \tau$$ which is perhaps not so nice because it fiddles with the context. On the other hand, it shows more clearly that we are stating the fact that any two morphisms from $0$ to $\tau$ are equal (the $\Gamma$ is a distraction in a CCC). 

The first approach is subsumed by the second, sort of (because the first approach is slightly broken). One should never consider expressions with free variables without explicitly specifying a context in which they appear (this is a lesson one learns as soon as one wants to formalize $\forall$ and $\exists$ that are allowed to range over possibly empty types or sets). In a single-sorted theory, equations without context $t_1 = t_2$ can always be equipped with a context $\Gamma \vdash t_1 = t_2 : S$ where $S$ is the single sort and $\Gamma = x_1 : S, \ldots, x_n : S$, with $x_i$ being the free variables in $t_1$ and $t_2$. Leaving the context implicit like that is not quite right. For example, what if I want to write down an equation that involves $x_1$ and $x_2$ in a context which also mentions $x_3$? You might think that sort of thing is going to be useless, but it isn't, not if $x_3$ could come from an empty type. Also, as soon as you think about categorical semantics you will see that it makes little sense to have bare equations without contexts. So I would advise you to put your equations in contexts, and then use the shorter form as an abbreviation. One reference where everything is done explicitly in a context all the time is Bart Jacob's "Categorical Logic and Type Theory", Chapter 8 is about polymorphic type theory and might be of particular interest to you. 

If you're going to work only in the internal language then you can just use a proof assistant. There is a minor technicality of having or not having powersets, since proof assistants are typically type theories, but Coq's is consistent with an interpretation of Coq in a topos. You're suggesting however to use the machine as a sort of translation tool that would get you from the internal language to the interpretation in a model. This is a fine idea, except I think it would not be as useful as one might expect. It is true that the translation from the internal language to the model is mechanical, but unfortunately it produces convoluted translations that need a lot of massaging before they're useful. (If you ever tried to use the Lawvere-Tierney interpretation of topos logic in a sheaf topos you'll know.) There is one more problem, namely the reverse translation. We often start with a known concept or object in the model, and would like a good description or axomatization of it in the internal language. This is typically hard work and real math. I do not see how current proof assistants could help. On the technical side of things one would have to worry about formalizing: 

It is best to just forget the idea that in general a computation gives back a value, two values, possible values, or anything like that. There may be particular monads for which it does make sense to speak about "computations having values", but not for all monads. The OP also suggests that intensional features of computations (one computation takes a different number of steps than another) should be expressible with monads. This is true, but whatever intensional features you want to capture with the monad (memory usage, time), you have to expose them explicitly in the monad. For instance, we could do this: 

If you are a bit more careful about definitions, and in particular recursive definitions, then such confusion cannot arise. In your example, we must first decide whether 

Regarding your second question, I seem to remember that for higher-order types the question was linked closely to whether PCF+timeout was equivalent to Type Two Effectivity (Turing machines with infinite inputs and outpus), i.e., Kleene's second partial combinatory algebra. John Longley claimed for a while that Kleene's second algebra was equivalent to PCF+timeout+catch, but in the end he never published a detailed result. On the other hand, I am pretty sure that John Longley opus magnum "On the ubiquity of certain total type structures" (Mathematical Structures in Computer Science 17(5) (2007), 841--953) implies that the higher-order functionals definable in PCF+timeout are precisely the hereditarily effective ones. 

It is easy to get confused about what it means to "represent" or "implement" a real number. In fact, we are witnessing a discussion in the comments where the representation is contentious. So let me address this first. How do we know that an implementation is correct? The theory which explains how to represent things in a computer is realizability. The basic idea is that, given a set $X$, we pick a datatype $\tau$ and to every $x \in X$ a set of values of type $\tau$ which realize it. We write $v \vdash x \in X$ when $v$ is a value that realizes $x$. For example (I shall use Haskell for no good reason), a sensible implementation of $\mathbb{N}$ might be the datatype where $v \vdash k \in \mathbb{N}$ when $v$ evaluates to the numeral $\overline{k}$ (thus in particular does not represent a natural number, and neither does a diverging program). But some joker could walk by and suggest that we use to represent natural numbers with $\mathtt{True} \vdash 42 \in \mathbb{N}$ and $\mathtt{False} \vdash n \in \mathbb{N}$ for $n \neq 42$. Why is this incorrect? We need a criterion. In the case of "joker numbers" the easy observation is that addition cannot be implemented. Suppose I tell you I have two numbers, both represented by $\mathtt{False}$. Can you give a realizer for their sum? Well, that depends on whether the sum is 42, but you cannot tell. Since addition is an "essential part of what natural numbers are", this is unacceptable. In other words, implementation is not about sets, but about structures, i.e., we have to represent sets in such a way that it is possible to also implement the relevant structure. Let me stress this: 

The proof is hidden somewhere in Troelstra and van Dalen, Constructivism in mathematics, volume 2, I suppose. More likely, it can be found in Troelstra's investigations, if you can lay your hands on it. It goes like this. Suppose we could define the modulus of continuity in typed $\lambda$-calculus with fixpoint operators. Then we could interpret it in a domain-theoretic realizaiblity model, for example in $\mathsf{PER}(\mathcal{P}\omega)$ where $\mathcal{P}\omega$ is Scott's graph model. In this model the choice principle $AC_{2,0}$ is valid. But it is known that $AC_{2,0}$ together with extensionality of functions (which holds in every realizability model) is incompatible with existence of modulus of continuity. If I get a moment, I will fill in the details later. See also M. Escardo, T. Streicher: In domain-realizability not all functionals are continuous, published in Mathematical Logic Quarterly, volume 48, issue Supplement 1, pages 41-44, 2002. 

The connection goes the other way around, too. A while ago theoretical computer scientists who work in domain theory got interested in relativity. They proved results about how to reconstruct the structure of spacetime from the causality structure. This is something quite familiar to domain theorists, where the beasic objects of interest are partial orders whose topology is determined by the order. You might have a look at $URL$ 

I make my coauthors learn Mercurial, and I used to make them learn Subversion. If you are a Subversion fan, just read this, it is all true. No matter what system you use, by far the hardest thing is to get the other person to install the software and start using it. Skype is the perfect solution. Recent versions of Skype allow "desktop sharing" which really helps when you want to lead your coauthor through the installation procedure. And I have used straight desktop sharing combined with Skype to write a paper with my coauthor. It works pretty well. What is really needed is a "Github for scientists". Something that gives a repository, has version control, collaborative editing, etc. Guess what, there is $URL$ 

My advice would be to make sure that your translation function is compositional and straightforward, i.e., for a typical construct $A * B$ the translation function $t$ should have the form $t(A * B) = s(t(A), t(B))$, where $s$ is the translation of $*$. Thus the translation should follow the syntax of the input language. If you want to perform any "optimizations", those should come as convinient tactics that get used after the translation phase. This will make it easier to pove that your translation works correctly. Concretely, if your input language has a construct for defining recursive types, such as in Haskell, then you should translate those to $\mu \cdots$ even if they are not actually using the recursion, because that is what they are. You can always have a simple lemma afterwards which shows that $\mu$ can be omitted in certain cases. If you set up your tactics the right way, the theorem prover will simplify things by itself (and do much more if needed). But you should not put $\mu$ in front of a definition that cannot be recursive, such as . In other languages, for example in Ocaml, the only way to introduce a new type is with , which may be recursive, so there you'd put $\mu$ in front of everything. 

How about Ulrich Berger's work? For example Strong normalization for applied lambda calculi. The "recursively defined constants" part gets you inductive types, more or less. And don't be put off by the word "untyped", he gets results for typed systems too.