One of my client is having issues with one of the jobs failing every weekend to perform index maintenance on a couple of databases. It is a SQL job which uses maintenance plans underneath. Okay, so the maintenance plans consist of check database integrity task, followed by 3 t-sql task in sequence which runs the same script but for different databases (code provided below) and finally runs a reorg task and then update of statistics. I know this seems a bit weird the way they are running things at this time but I will change it moving forward. Presently, I am stuck with this job completing the maintenance check but failing to execute the t-sql task with the following error. Executing the query "USE XMain; declare @frag_Temp as Table ( ..." failed with the following error: "Incorrect syntax near '-'. Changed database context to 'XMain'.". Possible failure reasons: Problems with the query, "ResultSet" property not set correctly, parameters not set correctly, or connection not established correctly. 

All, I would like to know what path should I chose in order to achieve MCSE for SQL 2016. I already completed MCSA certification for SQL 2012/2014 and would like to upgrade it to MCSE SQL 2016/2017. Kindly, let me know what is the best approach for this. Is there any direct path or do I need to take n number of exams to get that certification. Also, would like to know what resources or links you'll can share that can help me possibly get through to that certification...most likely in first attempt. I only would choose one exam but it should be more focused towards honing my existing DBA skills. $URL$ Thanks 

Recently, we've done some optimizations to the functions and now the BI Manager has tasked me with a request to compare the result of the 2 functions as below making sure the row counts match, along with the exact values of each field. In the same request he is expecting this to be a while loop that will loop all the YTD ranges dating back 20 years. (not sure if this is really practical in order to test the validity). However, the while loop is not a mandate for the same. Is there a way to compare the result of the 2 functions without hard coding the ranges and automating the same like for e.g declaring a variable and then based on the date range calculating the next date range etc without the user intervention. Last but not the least a script that would validate there are no differences in the results of both the functions which means that the optimization did work. I am thinking of using except clause but I am not sure if it would work with functions. Also, if that won't work what else would be a possible way of doing it. I would really appreciate for all the help. It is a big impact for the company if I could complete this task. However, I am not even sure if this is something that should be even handled by a DBA. Functions Original Function: report.fnReportDealCore_original(@StartDate, @EndDate, -1) New Optimized Function: report.fnReportDealCore(@StartDate, @EndDate, -1) Example of Run Dates dating back 20 years 

We can create the database trigger on concrete schema event (ON SCOTT.SCHEMA) or on all schemas (ON SCHEMA). However, we can also use ON DATABASE when creating database trigger. What is the difference between them? Is it some legacy stuff? ON DATABASE should be used when using AFTER STARTUP or AFTER STARTUP because it's definitely related only to database but the same stuff that is done using ON SCHEMA might be done using ON DATABASE, so what's the difference? I can't find references in Oracle docs about that. 

We can't COMMIT/ROLLBACK in DML triggers because transaction is handled manually after DML statement. However, database triggers seems to be an exception. For example, suppose there's a database trigger: 

Suppose we have a server that has only 1 CPU with 1 core, so we need 1 Oracle database license for installing a database into it. Now, if we would need to add a second server, combine them into cluster and install database into it, then how many licenses do we need - 2 database licenses and 1 Clusterware licenses or 1 database license and 1 cluster license? I'm not sure, how Oracle treats joined into Oracle cluster servers - as one server or still as separate servers? Because we would need to buy expensive Oracle cluster software, then it would be logical for Oracle to treat joined servers as one. 

Oracle has partitioning and clustering features. Partitioning enables to split table or indexes into multiple tablespaces and store on various servers. So it's done manually. Clustering enables several servers to make operate as one. This IMHO is handled transparently. However, it's possible to have several tables (in different server databases) and group them as one, and use it. From the perspective on table partitioning and table clustering, IMHO both ways implement shared everything because the data is split into the different locations. The theory about shared nothing architecture is that each database node is independent. But how this looks in practice? Both ways (partitioning and clustering) splits data into different sources and could be also described as horizontal partitioning. However, if we had for example, two different database servers we would need to synchronize the data between them... Anyway, any thoughts on that would be appreciated :) 

What I want to do I want to select all values in one query. E.g. select the latest value for DeviceId=1 and SensorId=1,2,3,4,5. I have come up with the following so far, where I select with the IN keyword to get values for multiple sensors. However, I still need to group them and sort out the one with the highest date. I'm thinking of adding a GROUP BY clause, but don't know how to get it right (the ones I've tried has failed so far). 

I have a large partitioned time series table where each partition is stored in it's own file. Since it's time series based partitioning divided by week and I'm only storing data that is new I have never more than 2 partitions I'm actively writing to at once. I have a FILLFACTOR set to 75 on the index since the data is coming in somewhat randomly. The old data partitions are taking up quite a bit of space, utilizing only about 60-70% of that space. Is it possible to automatically change the FILLFACTOR on said partitions, rebuild the indexes and shrink the files? Since I'm not writing to those partitions anymore they shouldn't grow back in size. 

The table is partitioned weekly on the Date column. What I do now So, what I do is the following. I select the largest value in each partition that is before the current date/time. and pick out the largest value. 

Background I have a couple of devices, each with a couple of sensors. I log these every now and then and stores them in a table described below. When someone requests a web page, I fetch a couple of these values (the latest logged) one by one and displays them to the user. But currently this takes too long time because there are too many values that needs to be fetched, the fetch takes about 8ms per value and in total we talk about around 300ms increase in total page load time - for a relatively good page. 

1/1/1997 – 1/31/2997 2/1/1997 – 2/28/1997 3/1/1997 – 3/31/1997 …. 1/1/1998 – 1/31/1998 2/1/1988 – 2/28/1998 … Through 9/30/2017 

My manager has asked me to work upon a request. I am not sure if it is reasonable or weird but he wants me to setup an alert based on the "waiting task" that we see in the activity monitor. Basically, if the value in the "waiting task" goes above 10 then we need to be alerted upon. I am not sure as to how I would replicate the same information that we see in Activity monitor as this seems to be live data. Closest DMV and the column I could think of is "waiting_tasks_count" in sys.dm_os_wait_stats. However, this does not seem to be in line with what he is looking for and the column consists of cumulative values over a period of time since last time SQL was restarted. Can someone shed some light on where I can find a query or a counter that I can alert upon? I have thought about a query at this time but I think I can't calculate the delta correctly it always shows me 1. Can someone help me out exactly where I am going wrong here. 

I have a SQL job that runs an SSIS package and it basically pulls records from staging table and dumps it into the master table. It used to take around 8 hrs. to run but in these last 10 days or so the run duration has increased and I would like to know if there is a way I can find out where the job is spending more time and what it is waiting on either running a profiler trace or running a tsql script inside a job to capture anything useful. It runs every day except Sat at 11p est. 

AFAIK there are three major structure types used for storing Oracle index data: B-tree, R-tree and Bitmap. All indexes use one of these structures. However, not sure about CONTEXT, CTXCAT and CTXRULE Oracle text indexes... 

I found there are special "Oracle Text" indexes that improve performance for wildcard queries. Such index construction requires a little bit more work but still is a way how to create prefix indexes: $URL$ 

You can create an index and define prefix length, so the index will store only first starting symbols from each of column value. It looks like this in MySQL: 

Is it possible to monitor role and privilege grant/revoke using triggers? I' aware of doing that using Oracle audit tools however, it's interesting is it possible to do that using triggers. 

The trigger does not contain autonomous transaction procedure with commit inside that, so who is commiting the insert? This triggger works like a charm and inserts new record into log table after user logon. It smells like hidden Oracle functionality and I can't find any reference in Oracle docs about that. I'm using Oracle11g. 

Hash indexes are usefull when you have a large table with URLs and you need to query by them. So, a solution would be to have an additional column "url_crc32" that will be filled with hashed URL value via trigger on inserts. An index on url_crc32 would be definitely faster than index on URL column that is a type of text. It's not very common case to query data by URL. The more frequent case would be to query text data by fragment and hash indexes are useless in such case. So, I'm curious do you use such hash indexes, and if so then when do you use? IMHO Oracle does not have native hash indexes, so that must be done manually.