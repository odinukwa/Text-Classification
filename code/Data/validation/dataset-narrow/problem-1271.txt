I am not sure flash allows P2P without Stratus (and v10+ only). But if you want to go socket route I suggest you give Red5 a shot $URL$ . I wrote a small how-to on installing it on ubuntu here: $URL$ It's a bit old, but should still be valid. If I were to make a networked flash game today I'd weigh my options between RED5 and SmartfoxServer $URL$ 

I come from a different stream of life (TV Production), but it's basically the same. You need a production bible. But, to put it more simply - you need what you need and nothing more. 

Devices like these are super cheap, and I bet you can get a hold of a second computer to run it on (it doesn't need anything special) so you can capture your game from your game running machine (be sure to have a computer with S-Video out for this cheap version). There is also something like this for higher quality capture - $URL$ but requires USB 3 and is more expensive, but you can capture HDMI and higher resolution. I really see no better option than either of these two. 

It's not a full answer, but it's too long for a comment... From your question I presume you want to use a LOD system (geomipmap approach) and you're creating your mesh by cube subdivision, so why not to think about a LOD during both stages - mesh creation and rendering? You start from just a 6 planes, so it's really easy to tell which sides are connected. Then, when you subdivide one of the planes you know which neighbors are at the all 4 edges. You can also store the newly created, internal edges. This way you can create a hierarchical, tree-like data, where you start from 6 quads and every quad have 4 child quads. Having such data you can easily iterate over all LOD levels. You can even store the mesh data precomputed for all LOD levels, or you can create them on the fly, depending on camera move. There are really many possibilities here, but I can't help you more as I don't know what data are you going to need for your algorithm to work. 

You are making a 3d engine. You want best of multiplatform worlds. Suddenly you realize that if you want to use Direct3D on Windows machines and OpenGL on OSX/Linux, you'll have to sacrifice supported features of both to least common denominator. Some may use OpenGL across three OS', since it appears to be least common denominator by itself. All is good. Then, you have to port your graphics API backend to Nintendo's GX, you also have to make a PS3 and Xbox360 path. What do you do? Do you design your own API which is least common denominator in itself and write backend implementations for it for each platform or do you write for each platform it's own branch? If you opt to design your own API, do you use bridge pattern or your own voodoo? Where does madness stop where you realize everything and kitchen sink approach must stop and you basically have separate engine for each platform as a branch. Or you stick to everything and kitchen sink and keep platform specifics in backend module specializations for each platform. 

What I think you need is to create a object that will allow you to set up players position and orientation. Next, connect a object as a child of so it moves and rotates with your main object. Then connect a as the child of so it moves with , but can rotate in its own local space, so you can rotate a head. At the end connect a as a child of the and move it backward by some amount. This way a will be always at some distance from the , looking at it, regardless of the orientation. 

If your objects are not animated I'd make just a transform animation between first and the second. When you want to change the objects you just play the animation and stop at the end. If you want to change back, you just play the same animation backwards, to . When you objects have their own animations it gets more tricky so in such case I'd make separate objects and replace one with another when transition animation ends. This way you wouldn't have to worry about too many animations at the same time, in the same object. According to different types of controls: Implement both in your game, so you can play as the ice cube and as the water (with selection at compile time for now). Then store somewhere your current player mode and in all your input methods like MouseMoved, KeyDown, etc. add a simple and select which of your controlling code to run. 

I was very fond of Andrew Rollings and Ernest Adams on Game Design. It goes into depths of interactive game mechanics as related to player, which is the only unique element to game development as editing is to movies. Having said that I'd consider suggesting screenplay writing material as it shows you what connects with people and what doesn't. I'm not talking about linear progress material here like stories, but what kind of characters connect with people, themes, motifs etc. In that area I suggest these: 

Here is what Mike Acton (Engine Director at Insomniac Games of Spyro the Dragon, Ratchet & Clank and Resistance fame) had to say about this when asked here. Note he was asked about both STL and Boost in general as related to usage in game dev. STL/Boost, does it belong into gamedev? If only parts of it, which ones? 

I'm not sure it's your exact problem but I had similar issues. It looks like Blender doesn't generate coords by default. Even if you can render your object with texture in Blender - it doesn't mean you'll have in the exported mesh. You need to explicitly add some UV channel - I don't know Blender very well so you need to look for some tutorials for this (But it's very simple, if you know where to click). In 3D MAX, when you create a basic object and select you'll get the out of the box. There's also a simple way to verify if that's the case. When your mesh doesn't have an channel but it's used in the rendering, then your values will be set up to defaults - which means that some corner texel will be used as a texture for entire object. Now, if you move or change your texture, so texels on the corners will have different color - your mesh should also change the color during rendering. 

or whatever your values are. You'll have a frequency paired with coordinate like a key->value pair. You can then quantify key scale to a color. For example key of 0 is black and maximum key you have in your key-value list is red, and everything between is a gradient between black, mid point yellow and max point red. Quantify each result to a color and there you have it. 

I'd personally try with L-System. I wouldn't be surprised if there are examples you could find with google. 

If you're really interested in technical aspects of screenwriting you can also take a look at Screenwriter's Bible - but that one is more oriented towards technical aspects of screenplay formats and structures. 

We have a mixed art/tech environment, but hiring process is always the same. Cull interesting resumes and offer candidates a task from start to finish on his own where you give him only a high concept. For programmers a small game that can be made in several days (can use programmer art or stock) where you give him a concept of what it should do and tech to do it with. A really basic game. For artists it's either a spec work or a pitch for concept. They can work on their own on that, can use whatever help they need (google, ask around, whatever) as long as they finish on scheduled deadline. Test consists of first cull if project is actually what it was supposed to be (does it work at all etc.) and where you go through process he used to make it and code review where you discuss his decisions while making it. 

When you're rotating your phone and not moving it then the acceleration returned will lie on a sphere with Earth G radius. For example let's say your phone lies almost flat on the table - your acceleration X and Y values will be small and your method should work, but when you turn your phone 90 deg your acceleration X or Y will get its maximum value and your method will break. In practice, for rotations just around 15-30 deg you should start noticing some strange effects, like non-symmetrical steering in front-back directions. To solve it you could store entire initial rotation, computed from initial acceleration vector and during the game compute actual rotation and a X/Y differences between them. 

I think the simplest way is to divide your terrain into grid and manage which grid tiles to load/unload. Let's assume you want to have 3x3 grid all the time, with one center tile under your player, and one additional tile in each direction. Now, during every frame you check if your player has moved to another tile and if so, you load new tiles in the direction of movement and unload the tiles that are too far away. After this load/unload phase you'll still have a 3x3 grid centered over your player. I can't make you a fine picture of it now but here's some sketch: link This way you can manage quite big terrains but there're some problems you should know: Tiles connection You need to make sure that the shape of some tile at its edge is the same as the shape of its neighbor (the second tile that shares this edge) or you'll get holes in your terrain. It's quite easy if you use procedural data, like Perlin noise but it's very hard to model such meshes in 3D modelling application. Grid size and scale You can split your grid into 3x3 or even 10x10 tiles. Every tile can be few meters in size or i.e. 1km - all this depends on your specific needs. If you manage many small tiles your load/unload times will be smaller but you'll do it more often. Additionally, when you make game like a flight simulator you'll need different setup than for FPS. Deferred loading It's not a 'problem' but I've seen some interesting optimisation that I could share. It was in the Terrain Manager for the Ogre engine. It was also grid-based but much more complicated, with Quad-Trees, LOD, tile stitching, etc. The trick was done during load/unload phase, where instead of checking they checked then the Manager loaded only this one tile and returned control to the engine. In the next frame Manager did the same check and loaded 1 another tile. In this simple way you can split your loading into multiple frames, which lowers your FPS variations. 

Check out this simple fragment shader implementation with explanation on why's and how's $URL$ Although it is fragment/GL and not D3d9, it's simple as it gets, so you should be able to understand what you need to do. 

PixelJunk shooter from Q-Games has nice set of fluids. There is a GDC paper they have published here: $URL$ (PDF!) Jos Stam from Alias Maya fame (now Autodesk) wrote paper on real time fluids in games here: $URL$ (PDF!) And he wrote a simple FFT fluid solver here: $URL$ (PDF!) where he included source in that PDF at the end. 

I personally use Mercurial. There is an asset management oriented VCS from AVID called Alienbrain $URL$ which used to be heavily marketed towards game developers. 

Each list contains layout sheets (or character layouts for characters - front, side, 3/4), notes, mechanics notes for animation, etc. Whatever you need or might need. Story/Game production sheet. 

In a typical shaders, no mater if it's a vertex or fragment one, you have somewhere a dot product between light direction and surface normal. Then you have a check if the result is less than , which means your surface has light at its 'back'. Now, if you compute instead of just you should get lighting on both sides of your geometry. 

When you select a object you should see an Animation Import Settings in your Inspector. There should be an option called , which selects a default animation mode: 

I'd consider a grid as a "base" type of tiles in any game. Such grid is simple to imagine and moves over this grid are simple to understand. It's also very simple to implement "under the hood". Those are few reasons why even the Chess game uses it :). Additionally, this grid helps you make "regular" levels, because and are natural directions here. So if you make, let's say a SimCity clone it's very easy to have perpendicular roads. The biggest disadvantage of grids is that they doesn't keep distances very well, because when you move by one tile in directions you basically move by one tile size, but when you move in directions like then you'll move by . It's not so big problem in computer games but it was a big flaw in board games. Because of this problem people tried to find some other way to divide 2D space, so the movements between tiles would be more similar to the real movement. It happens that the only possible way, better than squares is to use . grids are much better for strategy-like games because movements are more natural, but they are much harder to implement. They have also 3 main directions, where one of them may be OR but not both! So try to imagine a city with perpendicular roads built on a such grid... Personally, for a game like I wouldn't think much and used . In fact, I'd use squares in every game that is not a turn-based tactical game. But depending on your taste you need to choose your own. Maybe you'll want to make a one-of-its-kind, clone :) ? 

As Justing said, OpenCV. But if you want to get your feet wet quickly, I suggest you try dabbling with openFrameworks It has an addon that wraps OpenCV and you will learn a lot from it. 

I'll correct you, since you are wrong. Let's assume you want to become a writer, a good one. Do you just need to learn to read and write and type fast on keyboard and that would be it? Of course not. If you want to become an artist SERIOUSLY consider going through real, traditional art lessons. Drawing, figure drawing especially, doodle in your notebook, give yourself tasks etc. Constantly draw and paint whatever you want to make. Parallel to that you can teach yourself some poly modeling program along with detailing program - a combo of maya+zbrush or maya+mudbox or 3dsmax+mudbox or modo+zbrush or whatever. You see, you need only a few weeks at most to learn any of these programs sufficiently to know pretty much everything you need to know. What then? You are an artist all of a sudden? Just like by learning Word you are a writer? You, hopefully, understand what I'm talking about. I'd suggest a plan: