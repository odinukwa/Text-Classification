A really good question as arguably MOOCs these days are preferred/easily accessible over conventional textbooks in CS. I had the experience of supplementing my curriculum with MOOCs in 2015 and since then, in every course, there are some supplements from them. Here are my observations about this experience: Clear Advantages 

I got a chance to teach Introduction to Computing & Programming course to Chemical Engineering entry students and their syllabus included both Programming concepts & Excel. I began the course with just Algorithms and after 4 weeks, switched to Excel & then on programming. Off course they are different to your target audience a bit but I found Excel('s functions) pretty helpful for them to comprehend the syntax (after a couple of weeks of Excel, I switched to Visual C++), so the pros you mentioned are really there. Cons Using Excel alone can make students thinking in terms of sheets/tables which can make them picking the concepts of arrays,etc. pretty tough later on and even if you go in some depth of Excel functions, still I don't feel its worth an entire course (even to learn programming). Conclusion/Suggestion My personal experience of using Excel as catalyst was really good one and I think using an user-friendly/easier IDE like Visual Studio with Excel is worth a try 

And this shows the basic construct (he, unintended pun) of OOP. A singleton can be . There's only one, and if someone's asking for one, a reference to the existing one is given. Just before it was built, asking for an would create one single . So it's a singleton. Now, the has-a relationship can be explained with a object. Our has a collection of s. A wall is not abstract, but rather concrete (pun #2), and can also be extended (pun #3?) to a or . The is a singleton extending . So this analogy covers most of what's discussed when teaching OOP. 

Despite all this, I still feel there is no alternative to a Paper-book. I used to hear it since long time, but there are some reasons behind it: 

I have been teaching Operating Systems basics in a class and after Processes, Child Processes and Threads, we have managed to move to "Process Scheduling" Now, ironically, as we know that it is not the Process which is scheduled, but the threads precisely (we are following Linux Ubuntu there). Here is what Silberchatz book (by the way, the title of the chapter is also "Process Scheduling") says about it: 

I think that naming conventions are very important. It can be useful to explain that it makes the code much easier to understand. In the beginning (1 or 2 tests after introducing the convention), you should take just a few points off if the name of a variable or method doesn't tell you anything about it (e.g. calling the sum of an array or instead of or preferably ). You should tell them that you will take a few points for it. After a short amount of time, you'll find that you don't need to take points off for bad naming, because students will learn that it is important. Again, just one or two points for bad naming should do the trick. However it is necessary to explain why it's important for their code to be easily understandable). 

I saved the time by not slowing down too much during demonstration (to show them how to use every feature of the IDE) but recorded all the work (using Screen-Recorder software) and it really worked. If there is a better approach than that, I hope someone would enlighten us here about that too but my experience with this methodology was excellent one. 

(Silberschatz, Operating System Concepts, 8th Edition) Although, I have taught them the respective algorithms; should I bring this discussion within the class and press the panic button by telling that its not the Processes which are scheduled but Threads? This question has been in my mind since long time and I couldn't look for a better place to get an answer than here. 

I keep seeing students use in lab lessons: For example, a simple physics calculation of kinematics. Many, many students use to hold the variables: 

This is an introductory genetic algorithm to give the idea, before going into more complex exercises. 

Introduction lesson. Here it would be good to show real world usages of the subject being introduced. Background lesson. Here you should teach the background (Mathematical or otherwise necessary background knowledge). This step is very important. Without it, very few students will be able to keep up. For some subjects, this part of the block can stretch to a double lesson (usually when the teaching pace indicates that one lesson won't be enough). A bit of hands-on experience with the tool\subject. This can be a small task or project the the students do. Usually a lab lesson. 

Now I would talk on general terms, @Buffy has a good idea of giving them projects. I like it but I would like to add little bit more: A complete/successful project doesn't always guarantee that a student has covered all the basics of even OOP (assuming he develops project in an OO language/paradigm) or SQL, etc. (I am coming from a Pakistani background where OOP and SQL still have lion's share in market, this suggestion may vary depending upon the industry you have) I think if I were to give any student a suggestion, it would be to firstly cover OOP and SQL properly and then complement it by project I agree that now SW industry has much more technologies and not everyone gets away with such a luck, but my experience still tells me that OOP/basic algorithm development and SQL are almost necessary for lot of jobs. So my conclusion is, both OOP, SQL, etc. (Theory) and Project (Practical) are necessary for you even if you are Final year student and water has reached near your throat. P.S: @ctrl-alt-delor's answer has a detailed analysis of technologies road-maps and I would like to refer to it for choosing a specific tool(s). 

As a special lesson, I would like to show students the very basic idea of genetic\evolutionary algorithms. I let them play a bit in a genetic algorithm online game, to get the idea. Then I teach them the main concepts (Population, individual with genes, mutation, crossover, fitness etc.) and I introduce the Traveling Salesman Problem. Then I go through solving TSP with genetic algorithm with them, so they see it in action and in practice. However I'm out of practice exercises. So, I am looking for problems that have a solution which can vary in its "goodness", and its goodness can be judged by some requirements. To explain this, take the example of a timetable for tests over a month. a solution is a random time table. a good solution is one where tests are suffeciently spaced so that students have time to revise. in the game, a solution is just any vehicle, but a good solution, is one that gets far. Note: I am not necessarily looking for an answer that shows any previous knowledge about genetic algorithms (though it is appreciated ), just any problem as described above. What kinds of exercises\problems such as those are used? The students are high-school students learning in java, and they are familiar with OOP. 

Easily Available (Mostly) Free Students have access to world's leading professors sitting in their home A huge community of similar (and more experienced - many students take a MOOC more than once) students makes ideas sharing, etc. Many students find Video lectures (can forward, reverse whenever some thing isn't clear - can view them calmly in your room, on mobile, etc.) much easier to understand. 

It's not too much difficult to make non-C/C++ programmers understand about pointers if we take the above points and start from some basic examples like URLs being used to point to web pages etc. It has worked for my case (a great deal), hopefully it will help you and others too. 

The most basic: the number of options that an $n$ long binary number is $2^n$, and that's where it all starts (until Quantum computers come along, but that's something else) Algorithm correctness: proof by induction. The entire field of boolean algebra. Need I say more? The entire field of Machine Learning is nothing but computations of mathematical models (Neural networks are nothing more than the simplest of arithmetic calculations - weighted sums of weighted sums of...) 

Simply put: the command line can do things which the GUI apply cannot. In Windows this is easily seen. CMD can perform operations that no other GUI based tool can. In Linux there aren't many graphical tools anyway, but the terminal is by far the simplest way to get things done. To show them the strength of the command line, explain that GUI tools don't always specify the error message (depends on the error), should one occur. Command line does (regardless of which error occurred). Another way to motivate the students would be to say that the terminal can do anything that any graphical tool can, and the reverse is not true. This would show them just how useful it is. Additionally, the terminal can override anything. 

Heaps of MOOCs means you can get distracted. There will be points where not only a class lecture and MOOC's lecture will contradict, but also among a couple (or more) of MOOC's. An example I have observed recently when supplementing my ML class with Andrew Ng's lectures and later on found some disagreement of concepts between respectable professors about Neural Networks theory in Neural Networks dedicated course. So, it requires you to thoroughly study and guide them before suggesting any MOOC, otherwise it creates a panic among students when they discover such a (even minor or just re-worded) differences. Those sites barely scratch the surface of what is available â€“ Exactly does my experience say: Often these MOOCs etc. get students very excited in the start but merely after a couple of weeks its realized that they never go into depth like they do in their (university) classes. I tried to supplement a Bioinformatics course using a famous MOOC course but they never went beyond the scope of E.Coli/Yeast and once hype was over, it was pretty disappointing for students.