MX, CNAME, PTR, and NS records point to hostnames. A records point to IP addresses. Putting an IP address in an NS record is a pretty common DNS misconfiguration. One reason is that you might have NS records pointing to servers outside of your domain for someone doing secondary DNS for you. That remote domain might change the IP address of the server (but leave the hostname alone). 

It will work. You will get more loss at the splice than if you were splicing like fiber but you can do it. You can even mix the fiber types in longer runs. Reference: Mixing of G655 and G652 Fibers in a Network 

The default gateway of each PC needs to be the same as the subnet router port IP in its network. So the subnet router port in the first network would have the address 10.0.0.1 and the PC would have 10.0.0.2 and the default gateway would point to 10.0.0.1. This tells the PC "when I have a packet that must go to a destination that is not on my own network, send it to 10.0.0.1, and that device will know what to do with it". The "default gateway" is really just a route to 0.0.0.0/0 which means "the rest of the IP address space that I don't have a more specific route for". In fact, you can eliminate the routes on the subnet routers, too, and just give them a default gateway to the central router. So instead of having a route to 20/8 and 30/8 on the subnet routers, you could just put a route to 0.0.0.0/0 pointing to 192.168.1.2 on the first router, 192.168.2.2 on the second one, and 192.168.3.2 on the third. The only router that needs to know explicitly how to reach any of the 10.x.x.x routes is the central router at the top of your diagram. All of the rest can just have default routes. 

You can attach cisco switch with two PCs behind the router. Dot1q trunking can be used with 1 vlan per PC for traffic generation and second one for SLA probes. The router must be used for inter-vlan routing, traffic shaping also should be configured here. IPERF/JPERF can be used for traffic generation. On both switch ports you can mark the traffic with specific DSCP value, which needs to be used later in the policy. Speed can be easily measured with IPERF: 

You can add ip flow ingress/ip flow egress under the interface (Ethernet0 in your case). This will enable NETFLOW caching of the traffic passing through that link. No worries no risk involved. After that you can execute show ip cache-flow and you will see all the packets passing through that interface. Most probably the rest of the devices have more specific routing and default gateway is not used at all. 

It is to prevent routing loops due to bad practice or configuration errors. Example: Jackweasel.COM is single-homed to some transit provider Victim.NET who has assigned them a private ASN, say 65000. Someone at Jackweasel.COM decides to initiate a peering session with Clueless.ORG who has a public ASN, and has agreed to peer with Jackweasel using the private ASN that Jackweasel has (it would surprise you how many people would not notice off that bat that they are setting up a peering session with someone who is using a private ASN and might also peer with someone else). Now Jackweasel announces routes learned from Clueles to Victim. Victim will now keep that full path in its route announcements to prevent a loop just like it does with regular BGP announcements using public ASNs. Basically it is a matter of "someone is multihomed with a private ASN so I now have to treat the path the same as I do with public ASNs to prevent routing loops in other networks". It also might break connectivity to the announced routes for everyone else on the planet using that same private ASN. You might also be surprised at how many people accept routes with their own ASN because their network is not fully meshed. They have a colo in Virginia and one in California and they are each announcing a different /24 using the same ASN so they allow announcements carrying their own ASN to be installed so the two colos can talk to each other. But it also helps protect the Jackweasel who did this because they now see THEIR own private ASN in route announcements from Clueless (and who knows how many other peers they might have set up that way) that they sent to Victim. 

The practical rule for latency calculation is ~0.3 ms for every 100km. In other words for the distance between Singapore and Canada (13 000 km straight line) the latency should be around 390ms. I assume it is little bit lower. You can measure it by using ping. The output will give you the RTT. Once you have that value you can use following calculator: TCP CALCULATOR So if we consider that you really have 100Mbit/s international traffic available and default TCP window size of 64kbyte you will get following as speed: 

Do you receive some error message when trying? Are you sure that you are using the correct username ? (Note: "patrick" is listed in the config snipped, "Patrick" can be seen in the running config) 

Since you say you see no capabilities, there is no "route refresh" capability being advertised so there is no choice but to reset the BGP session in order to effect the change in routing policy. References: 

As long as you are fully meshed and the you can backhaul your own traffic arriving at one site but destined to the other, sure, it will work. So if your peering session drops with either ISP, your more specific will be withdrawn (you HOPE!) and the traffic will flow to the aggregate route on the other ISP and you can then backhaul the traffic to the other site. The most frustrating problem I see is network providers that advertise unreachable routes. Either through some screwup internally or whatever, they announce a route to their peers that they can not actually reach inside their network. There isn't much of a workaround for those cases. As for the F5 handing reply traffic back via the interface on which it was received, most load balancers can do that. I don't specifically know if the F5 will but I know Citrix Netscaler will and A10 will so it seems to be a rather standard feature. 

If you really want to explore the topic for measuring optimizing TCP perfromance I'd recommend to read RFC-6349 

I have personally done that ARP timeout set to 60 sec for a single VLAN caused 0.05% ARP usage on cisco 29XX series. It is running like that for over a month. No problems at all. Still I'd not recommend using the network for solving clustering problems. 

Very strange topology... However in my opinion you have to add route on "Router to configure" for 192.168.10.X network pointing to PC1 ( 192.168.0.9). 

The thing is that you have an MPLS network in the middle of your traceroute. Actually results from traceroute are not really accurate when it comes to MPLS environment. What happens is that all ICMP TTL exceeded messages originated by a P device first have to be tunneled to the other edge using the original label stack before being sent back to the originator of traceroute operation. Therefore, you will always see end-to-end RTT across the provider core in the output. You need to trace from PE router toward a provider-scoped IP address to resolve this "layering" problem and observe proper RTT. NOTE: DNS resolving is correctly configured. 

You can configure a Palo Alto Networks firewall to fail over to the other ISP. You need to set up two sets of NATs -- one for one ISP and one for the other -- or set two DMZs, one for one ISP and one for the other (or overlay two subnets on one interface). It will use both for inbound and will fail over to the second for outbound when one fails. You can start reading here. 

All data bits flow at exactly the same speed down the wire (the speed of light in the medium of travel). So a bit of data travelling 1000 miles down a 10 meg circuit arrives at the other end at exactly the same time as a bit travelling down a 100Gig connection. The difference is the RATE at which the signal can transition state between 1 and 0. The faster you can transition the state of the signal, the faster you can send the next bit. So -- basically there is no such thing as "speed" because it all operates at the same speed (the speed of light), what differs is the RATE of data bits you can send. That is the "bandwidth". The faster I am able to flip the state of the signal from 1 to 0 and back again, the more data I can send in a given amount of time. Imagine two signalmen using old time semaphore flags. One signals quickly, one signals slowly. The actual light reaching your eye is arriving at the same speed in both cases but one can send a lot more data in a given time than the other. That signalman has more bandwidth and can send more data in a given period of time. The data doesn't travel faster, but that one can pack more data into a given slice of time. 

RSTP protocol which is now widely implemented is sending BPDUs only on designated ports. Those 9 are sent during convergence activity in the past. 

1) Issue the flash_init command and the load_helper command switch: flash_init switch: load_helper 2) Issue the dir flash: command in order to view the contents of the Flash file system. After you have verified where the Cisco IOS image file resides, try to boot the image. Issue either the 

3) If you issue the boot command and the result is in a successful bootup, either the default switch> prompt or the hostname> prompt displays 4) If you issue the boot command and the command does not result in a successful bootup, either the switch: prompt displays or you are stuck in a continuous reboot again. The only option to recover the switch is an Xmodem file transfer 

I can't figure out why you are running two instances of OSPF on the the 2900's. This looks way more complicated than it needs to be. You can run OSPF in passive mode on the firewall and distribute a default route from the 2900's. You put a static route on the 2900's for your /24 pointed at your firewall outside IP. Since this is active/standby, if the firewall fails over, the IP address moves with the active firewall. There really is no need to announce anything from the firewall, it is just listening for a default. If you are announcing a default, there is really no need for HSRP either, that can go away. The firewall will just send the traffic to where it hears the default. It might well load balance to both 2900's, though. Seems you are making it a lot more complicated than it needs to be. There is only ONE firewall address in this configuration so a static route will work just fine. Even so, there is no need for more than one OSPF instance and the only thing you are using that for is to handle the case where a router dies. Then the firewall uses the remaining path where it hears the remaining default route. 

Latency can be extracted from iperf test, but I'd recommend adding SLA probes via some external software like this one 

Imagine a situation when packet arrives at the first router and it's size is nearly to the MTU of the physical egress port of the router, then it is encapsulated with IPSEC headers. Those additional headers will probably exceed the MTU of the egress port In such situation the packet is going to be fragmented after encryption - post-fragmentation. Of course this forces the remote IPsec peer to perform reassembly before decryption. You can avoid post-fragmentation if you set the MTU in the upstream data path to ensure that fragmentation occurs before encryption (prefragmentation). Prefragmentation is really important from performance perspective because it is moving the reassembly task from the remote IPSEC peer to the end host.