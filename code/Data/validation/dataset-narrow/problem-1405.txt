What you're seeing is post-process effects. Basically they first render the scene into a framebuffer object (FBO), then take that as a source texture and perform various operations on it. Among other things they talk about bloom effects etc, which are done in the same manner. 

So far this has been the best resource I've found: $URL$ Most specifically: $URL$ Still, haven't found The Book. 

Some games are difficult to play because the controls are difficult. If you look at the early Angry Birds, you never really know where the birds will fly. Later revisions make the controls easier, by showing preview of the curve the bird will fly. At the same time they can make the levels themselves more difficult. The effect is that the player feels more in control, and this is a good thing. Compare parkour in assassins creed to parkour in mirror's edge - in creed the player feels much more in control. Granted, the scope and focus of the games is different, but in general, player feels much more bad ass when parkouring in assassins creed than in mirror's edge. Other examples of great controls include super meat boy and the knytt games - make it as easy and as natural as possible for player to control the character - in other words, make the game easy to play - and then build a challenge to the player. The result feels fair - the challenge isn't to learn controls, but what the actual challenge should be. To answer the question, whether games should be "easier" in new versions.. I don't feel that is the case; should they improve in new versions? Yes. 

First, multiplying by powers of two is much cheaper than multiplying by an arbitrary number, since you can do it by bit shifting. Most of the time the compiler can do this for you, so whenever you write "* 16" in your code, the compiler actually does a shift by four, and you don't need to worry about it - you just need to give the compiler the opportunity by designing your data structures this way. Second, since cache lines, memory busses and other information highways in your computer also tend to be designed to use powers of two, you may get a better performance overall this way. Third, we old geeks just are used to playing around with powers of two, so it's a habit. (Fourth, other old geeks who design your hardware and your compilers also like powers of two, so this is not going to change any time soon). 

If I interpret your question correctly, you want to know which 256 colors to pick to a palette to make things look good. This is called the black magic art of color reduction. There's plenty of ways to perform it, some work better than others, and all of them are wrong, as what you're doing is removing information. One common way is to place all desired colors into an octree and then reading out the 256 biggest cells; another is to do median-cut of the color space until you have 256 segments. Easiest solution would probably be to drop all the desired colors into photoshop (or something similar), and convert to 8-bit paletted picture. Photoshop, at least, contains variety of methods to do the conversion. 

Here's one scheme I came up with when someone was asking for it on some board long ago. Using percentages or doubled variables doesn't really work, as you can search for "any" values and freeze them. Instead, make a monster of a data type. Basically, store your important values as a structure with: 

This so much depends on so many things that there simply can't be a definite answer. Some communities value college more than others, and college costs more in some places than others. Others have covered a lot of ground, but I'll give my couple cents. Even if games is all you'll ever want to make, get a real education. What you study doesn't matter at all. Don't take comp sci if it isn't what you really want. You can study anything at all and get into games, as long as you have the drive to make games. In fact, having a medical, social psychology, history, philosophy or just about any unrelated degree combined with experience in programming might give you a better base for making games than your generic "game industry" school. The world really needs more cross-dicipline people. And to top this off, let's say you do end up making games, and find yourself in a situation not too uncommon, that it's not all that you expected it to be. Finding a "real job" with a "game" degree is bound to be more difficult than getting a "game" job using a "real degree". 

To have complete freedom between the sprite frames and their sizes, each part has to have a reference points (both from and to). 

Unfortunately, the module formats (family which XM format is part of) are not perfectly specified, and various replay routines play them slightly differently. There's really nothing you can do, apart from "fixing" the replay routine (to which you probably have no source) or modifying the XM itself (so it plays "wrong" in the XM editor, but "right" with your replay routine of choise). 

Mesa and other libraries that implement the opengl API are dynamically linked, so yes, your application doesn't need to know what the actual library is. 

In short: OpenGL 1.x will still be supported. It's theoretically possible for someone to write an OpenGL implementation that only supports 3.x and up, but supporting the older stuff gives you such a wide range of existing applications that it would be silly not to support it. Some parts of the OpenGL 1.x pipeline may be implemented in a non-optimal (i.e. slow) manner, but things will still work. ATI drivers made picking horribly slow at some point, prompting changes in Blender, for instance. On the OpenGL ES side things are a bit more complicated. I'm not aware of any instances of it, but ES 2.0 and onwards are so much different from ES 1.x that it's possible that some devices have no ES 1.x support. In most cases, ES2+ hardware emulated ES 1.x in software (generating shaders on the fly and fun things like that). 

I wrote and presented a short crash course on the world of game programming; you can find the slides here: $URL$ ..and the practical stuff here: $URL$ Apart from that, I wholeheartedly agree with Nick, there. It's also best not to do this alone; find same-minded people and start a local game programming club! =) 

One thing others haven't mentioned yet is that it's important to finish your projects. Having a portfolio with a bunch of unfinished things isn't nearly as impressive as a portfolio with one finished, well-polished thing. Also, if you base your work on someone elses' existing work (such as some open source engine, or freely available art assets), make sure you mention on your portfolio which part is yours. 

No. Desktop OpenGL doesn't need EGL. Practically all mobile devices that support OpenGL ES are based on EGL, though (I haven't seen a single one where this isn't the case, but then again, I haven't played with iOS devices for example, so I may be wrong). 

I've built a simple dialogtree system: $URL$ the "engine" itself is currently plain c, but the data produced by the editor is pretty simple to use in any language. The tool outputs XML, JSON and a custom binary format. The main concept is pretty simple: 

I did not find a question on these lines yet, correct me if I'm wrong. Trees (and fauna in general) are common in games. Due to their nature, they are a good candidate for procedural generation. There's SpeedTree, of course, if you can afford it; as far as I can tell, it doesn't provide the possibility of generating your tree meshes at runtime. Then there's SnappyTree, an online webgl based tree generator based on the proctree.js which is some ~500 lines of javascript. One could use either of above (or some other tree generator I haven't stumbled upon) to create a few dozen tree meshes beforehand - or model them from scratch in a 3d modeller - and then randomly mirror/scale them for a few more variants.. But I'd rather have a free, linkable tree mesh generator. Possible solutions: 

Go grab gDEBugger. It's free for everyone now - you just need to register to get a free 1-year license. With it, you can check if you're fill bound, vertex processing bound, shader bound or cpu bound - as well as check if you're doing something stupid like rendering 10000 separate objects. 

When I was a kid, everything had a speech synthesizer in it, more or less. A couple years back I started to wonder where the technology is going after all these years, and after some research found that it's going nowhere. Storage has increased, making concatenative synthesis more life-like, but little else has improved. Text to speech seems to be the primary research field. Most books I've found of the subject of speech synthesis skim on the actual voice generation and then spend hundreds of pages on text to speech. I'm not interested in text to speech as such, but more on the voice generation. Yet, I haven't found a single book with good, practical explanation of this. Concatenative synthesis is simple to grasp, but formant is the one I'd like more information about. (The third method, physical modelling, would be a plus, but not all that interesting). What makes this game specific is that I'd love to make a tool that lets low budget/downloadable games have speech, without having to go out to get actual voice actors and having to store hundreds of megs of oggs with the game. Since the author is in complete control of the voice editing before release, text to speech is less important; what's more important is the voice synthesis. So, anyone know any good books about this? 

Since you listed OpenGL as a tag, and nobody else has linked to it yet, the OpenGL shading language (aka. orange book) is a pretty good resource. It covers the shading language, as well as plenty of use cases. 

32bit floats have 24 bits of significant precision, so the best precision you're going to get is 6 bits per component. I haven't tested this, but basically all you need is: 

..and when handling physics, just loop through the whole array and handle the ones that are alive. YES, you will be "wasting time" looping through unused array slots, but you should be able to handle the situation where all of the slots are in use, so this is not as big a problem as it seems - the simplicity is worth it. Alternatively you could use linked lists, but then you get the overhead of traversing the linked list - the worst case performance will be much worse than looping through an empty array. As a bonus feature, you can use the "alive" as a counter that you decrease on every physics loop to give the bullets a limited range; and the "age" of the bullets can also affect the amount of damage they cause. If you have huge amounts of bullets, you can skip the "find first free slot" scan and just pick a random slot; if it's in use, just don't spawn a bullet. Nobody will notice. EDIT As Sam Hocevar pointed out, the search is not necessary if, when removing bullets, you move the latest bullet on top of the currently removed one, like: 

There's one way to "escape" GPL or (practically) any other license. Make a clean-room implementation. Hire two groups of people. The task of the first group is to study the original material in minute detail and describe it. The second group, who never, ever get to see the original material, will write a new implementation based on the description. This is how BIOS on original PC clones was created; the BIOS was the only bit IBM didn't let other people copy. This doesn't mean that you're safe from lawsuits.. patents and "look and feel" crap is still out there, and at least in the US, anyone can sue anyone for no particular reason (or at least it seems so..) 

Yes, it is possible. The "How" depends a lot on what exactly you're after. Altering height can be done simply by applying a scaling transform matrix before rendering. The other things you mentioned require more work, and there are several ways to go about it. One way would be to make several versions of the mesh and interpolate between the desired features (like stomach size). Interpolating between two meshes is straightforward, but if you have several features you want to alter (like stomach size and hip width), it gets a bit more complicated. One way to solve this is to somehow "paint" weights to the vertices (through, for example, vertex colors in modelling programs) and use those when interpolating, in order to avoid the change of one thing affecting some other thing. Or maybe you just want to apply some kind of "space modifier" to the mesh, where you just specify that "within this area, scale things outwards" or some such. It all.. depends. =) 

Here's what I would do. Step 1: Don't sort. Just do it. See if it's a problem. Most likely isn't. Step 2: Limit particles into such that do not really need sorting, such as: 

The simplest solution I can think of is to create a virtual function for whenArrivedAtFinalWaypoint, call that from update, and implement that for the child classes. 

There's one good reason not to use the scene graph as the container for game objects, and that's instancing. If you want to reuse some resources, it makes much more sense to just refer to the resource from your scene graph several times than to have several actual copies. 

Step 3: if more is needed, split particle rendering into bits that have to be in front and the rest, and perform rendering in several passes (could fix complex smoke, for instance) Step 4: if more is still needed, or if you need a general solution, one thing that comes to mind would be to use MRTs to get a very rough N bucket sorting done; render the particles into N output surfaces and compose them in a separate pass. Anything further would require more information about your specific use case. But I'm pretty sure you don't really need order independency after all. Just use enough particles in random enough and it'll be ok =) 

If you have 10000 separate objects, the bottleneck is probably primitive count, not vertex, polygon, or fill. Bake your objects into smaller number of higher polygon objects for speed. Minecraft has a concept of blocks of cubes, but I can't find the reference at the moment. Here's also my experiments on drawing tons of cubes with various techniques. Doesn't include baking (yet). 

With a quick search through the GLUT spec, GLUT does not seem to have mouse capture capabilities. The best you can do (like you seem to be doing) is to warp the cursor to the center and hope the user isn't fast enough (or isn't using a tablet) =) Or, you could switch to SDL or SFML, as GLUT is only designed for testing, not "real" software. 

Each node (which I call "card", as with the above analogue) of the dialog consists of question text and zero or more answers. Each of the answers leads to another card. There's also a tag system where certain answers are shown to the user only if a tag is set (or a tag is not set). Entering a card sets (or unsets) specified tags. This is pretty much everything one needs to do just about any kind of dialog in a game. The "question text" can be plain text, or it can be a script to drive animation or whatnot.