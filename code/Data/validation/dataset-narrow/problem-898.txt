Unless your company is in the business of sending emails, then I would only look at this as a last resort. There's a lot of companies out there that send bulk emails, so I'd be inclined to shop around (or re-negotiate fees) before investing time & resources into building up and supporting your own MTA solution. Keeping a company agile and able to pivot is critical. Outsourcing non-critical services allows you to more easily accomplish this. Having said that, if you are in the business of sending emails, then you absolutely should look at setting up your own MTA - though you might still want to look at hosting this on a VPS environment. 

I recently did a remote upgrade via SSH from Ubuntu 10.10 to 11.04, which seemed to go well, rebooted when prompted. I waited a while and tried to reconnect and could not via SSH. After a little digging, it looks like this server is actually a guest running on ESXi 4.0. I don't have physical access to the system, however I can log into it via SSH. If I run I see the guest in question. indicates that the guest is powered on. I'm stuck here. I assume that the guest doesn't have a valid IP address or SSH is turned off. After a couple hours of googling I still do not know how to get a shell open to the guest via the host. Can anyone help me figure this out? 

Since you are dealing with ip addresses, it's probably easier to treat them as integers instead of strings. You can use the function to do this. Here's a working function to help you out: 

For a reverse proxy, fixing the links in your content output (as mentioned in the other answer) is the better way to go, however mod_proxy_html is another possibility. That said, if you're serving both applications out of the same Apache server why bother with the two virtual hosts? You should be able to serve two different languages from the same virtual host, that way you can skip the reverse proxy step completely. 

What you probably want to do is a reverse proxy. Assuming the other websites on the linux server are running under Apache. Then using mod_proxy your config would be something like this: 

It's called a Reverse Proxy. You can do it with Apache as well as other web servers. There are also dedicated proxy servers that you could use as well. 

There are many other ways to configure a reverse proxy both with Apache and with other web or proxy server software. The only thing you need to configure on the Windows server is to make sure any URLs output by it use the external address. 

Use Perl to evaluate the query_string and then use an statement to skip the rest if the parameter is not set. Perhaps something like this*: 

It looks like you've already changed your DNS, which is fine. But I wanted to mention that if you want to test your virtual host configuration before messing with the DNS settings (useful if you want to keep an old site live while you get everything ready on the new host) you can temporarily make the change in your hosts file on your local computer and the change will take effect immediately. 

CentOS 6.2, bind 9.7.3, rsyslog 4.6.2 I recently set up a server, and I noticed that named had stopped logging to after the logs had rotated. I thought that was odd, since all logging happens through and doesn't write directly to the log file. It was even more odd because I had HUPed after updating a zone file, and it still wasn't logging. After I stopped and restarted named, logging resumed. What's going on here? The syslog PID hasn't changed (/var/run/syslogd.pid matches the PID shown in ps). Is rsyslog opening a new socket when logrotate rotates its logs and HUPs it? /etc/logrotate.d/syslog: 

Are you sure you know everything the scripts are doing? Maybe the process is disk bound. Some Linux machines run every night and update the database used by . To do so, they scan the entire disk compiling a list of filenames. There's a lot of I/O but not much CPU usage. Maybe Windows does something similar? Compiling statistics by parsing the web logs? If you really are doing lots of SQL queries, maybe they're running on non-indexed fields of large tables, and MySQL has to scan through a lot of records. I think you need to take a closer look at what the nightly process does, in order to track down why it takes so long. 

For one-shot deals, scp is handy. If it's a lot of files, then rsync is a good idea. If a connection is dropped, rsync can pick up where it left off. I knew that rsync had compression (), and have just learned that scp does as well (). 

It looks like your rule is getting you to a PHP file. I'm not sure what you mean by "downloading a php file" if you mean its downloading the code as plain text then you've likely got a problem with you php handler and not the routing. Otherwise it probably means that the PHP code is using the original URL to do routing and not your rewritten URL. What it sounds like you really want to do is have your final rule be a redirect. So your rules should be something like this. 

If neither of Adrian Lang's examples work you could try something like this. The rewrite conditions will prevent it from doing further rewrites if the file exists. 

EDIT: It should work without the RewriteCond as the first two conditions should cover it unless you're doing more rewrites in that directory or something. Are you using custom error pages? Something is changing the Request_URI so that it no longer matches any of the conditions. If you're not on a shared host or if your host supports it try setting up a rewrite log this will tell you exactly what is going on. 

Using this setup if you goto the rt stuff will be returned. If you goto to (or another other hostname or IP pointing to this box) you'll get the trac stuff. is the thing the determines how the request will be serviced. Also anything outside of the sections will be applied if not overridden so make sure you don't have any rewrite rules or anything else there that might mess things up. 

For your second solution, I think you can simply use "#" in your .qmail file instead of piping through . 

I can't comment on SEO, but the typical use of the 204 response is to not refresh the current page. It's probably most appropriate with a request other than GET (like POST or DELETE): Excerpt from HTTP/1.1: Status Code Definitions: 

From that, I was able to find out which VirtualHost was responsible, look closely at its logs, and figure out that there was an old osCommerce directory in the site's directory tree, which I ultimately removed. I've left the wrapped in there in case it can help me with any future attacks. 

Even though VirtualHosts log to their own error_log files, I found output from in . I ended up wrapping with the following shell script: 

Two weeks ago, I was notified by my VPS provider that my server (CentOS 5.5, yum is up to date) had originated "NULL byte/Directory Traversal" attacks agains some servers at DreamHost. I spent a few hours going over the server with a fine toothed comb and didn't find anything. Before logging in, I retrieved a copy of the sshd binary and confirmed that it hadn't been modified. I installed a rootkit checker (chkrootkit-0.49) that found nothing. I checked the web logs of the websites I host, looking for a hit that may have triggered a script on my server to initiate the attacks but found nothing. Checked /var/log/secure and /var/log/messages around the times of the attack but found nothing. Checked , but found nothing. Did a on key directories looking for files modified in the past 3 days, but nothing. What else can I do to to find the cause of the attacks? I wrote a script to check for outbound TCP connections on port 80, but only came up with legitimate connections (SpamAssassin and ClamAV downloading updates, Joomla checking its site for updates, etc.). Even if I did see an active outbound connection, would I even be able to dump data from the process (in the directory) to show me the account originating the attack? After watching the server for a few days, I gave up. Now I've received another complaint from DreamHost, so it's happened again. I've requested detailed logs from DreamHost, but then what? Where else can I look? If I can't find the source, is there something I can install to monitor the server and log data when it starts making outbound connections to tcp/80 in the DreamHost IP space? What would I log? Just get a of all traffic in that timeframe and try to sift through it manually? Update See my accepted answer for the solution I came up with. I'm still interested in options for logging the source of all outbound port 80 traffic -- a way to know what the source process is and perhaps its parent process (and the parent's parent). 

A better way to accomplish what you want might be to, if possible, match the records in both name servers then switch the name servers first. That way no matter what name server the client gets it will give the same answer. Then when you're sure the new name servers are working you can lower the TTL there and switch the individual records. Also, since the fqdn of the name servers will likely be different, I think the time it takes for clients to make the switch will be affected more by the time it takes the registrar (GoDaddy) to make the change with the root name servers than the TTL of the NS records themselves. 

If I'm following your setup correctly you have your SPF record set on the root, but you are sending email from the sub-domain if the 'envelope from' of the email is root@mail.myapp.com then you need to change the "@" txt record to "mail". if you were sending mail from root@myapp.com then your setup would be correct. So something like this 

Many of the guides for setting up Wordpress (or similar applications) on nginx with php-fpm use a configuration that in part looks something like this: 

Unison might work, I believe it meets all your criteria. It can work peer-to-peer, but if this is for more than 2 users it'll be easier to have a central location to sync to. 

I'm assuming here that by "\u002f" you mean "/" and you mean the brackets "[]" to be part of the substitution and not in the actual URL. EDIT Ok, since you mean you want to rewrite the HTML output with mod_proxy_html. Then I think it would be something like this. 

Maybe the line-ending conversions in vsftpd were written inefficiently, and since binary mode is most commonly used, no one has bothered to improve the algorithm used in vsftpd. Or, it could just be that passing data from a tcp socket out to disk really is a lot faster than having to check every character for CR and LF. The check could introduce enough latency in the connection to reduce your transfer speed. Are you running tests locally on Ethernet (low latency, would be affected greatly by additional latency) or across the Internet? 

It's going to be almost impossible to get "varied" IP addresses for a single host. An ISP providing VPS services is going to have a block of IP addresses on the same subnet assigned to the machine hosting the VPS instances. You could get a few IPs, but they'll be contiguous. Also, it's unlikely the ISP will appreciate you running a honeypot on the VPS, especially if it's not set up correctly and hackers end up using it to attack other hosts on the ISP's network or the general Internet. Why not run the honeypot off of your home Internet connection? Set up your router to route all packets to a single machine on your internal network. You could even route them to a virtual machine running under VMware on one of your other systems. If you really want to have honeypots on multiple IPs, you should just get multiple VPS instances with different ISPs. 

And continues logging after the rotate -- it's just named (and possibly other services) that aren't connecting to correctly. Here's /var/log/messages-20120212: 

You'll probably need to tweak these because I don't understand all of what you're trying to accomplish. For example the RewriteCond below seemed redundent so I left it out. If you really are trying to rewrite everything under the guide directory you'll have to incorporate it back in. 

FreeBSD*... Just saying... Seriously any of the ones listed as having packages are probably good candidates. *I know it's not Linux 

As an alternative to setting up your own email server you may want to check with your Domain Name Registrar they often provide low cost email services that would let you do forwarding. A service such as Google Apps would also allow forwarding (and a bunch more) and is easy to setup. Your milage of course may vary but I've always found the "simplest" servers to be the ones I don't have to setup. 

Instead of linking to the static files directly use your controller to read in the files and return them. Then in order to avoid the extra overhead on every call, cache the files in a separate cache location. You can then use the same process to cache your dynamic content and you it could also allow you to build things like your css dynamically. For example you could merge the css from different modules into one file or change the human readable JavaScript into a highly minimized version. 

Personal I've been happy with FreeBSD. For some reason it's always made a little more sense to me than other *nix OS (It has great documentation). The ports system is great for applying updates, and I've had little problem with updates breaking things. Pkg_updating especially helps. With any distro, if you're using packages that come with the os or even through 3rd party repo's, you're going to have to wait a least a little bit for them to build the latest version of the software you want, and sometimes that's a good thing because there may be stability or dependency issues you might not know about. Of course, you can always build directly from source, then you never have to wait. PS: Upgrading the base os is also quite easy and stable using freebsd-update even between major versions.