Your approach and implementation are valid (disregarding that line). As long as there is only one instance of . There is nothing in the code you have provided that leads to an over-O(nÂ²) runtime. Therefore it is reasonable to expect a drop in framerate by half at 100 planets. That is 100 planets at 150fps. 200 planets at 30fps. etc. As this does not match with your observations some questions arise. Most prominently: Are you sure the fps are lost in ? Have you measured it with a profiler? Which statement is the offender? Is there any notable difference in memory consumption? Is the garbage collector busy? Can you render 100-200 planets at 300fps when there is no gravity? 

@Byte56 is right. You only want a direction vector without any information about the distance to the target. You can get that by normalizing your vector to unit length. Do this: 

In my opinion it is perfectly fine to model the behavior with a FSM. Oftentimes we create inferior models with cluttered if-statements like suggested in the comments. But the FSM is not the problem. To me it seems like you are experiencing jittering movement because your AI ship is always just at the border between "too far" and "close enough". Think about widening this border by using too different radii. One for getting a bit closer than absolutely necessary (r1=50m) and one for "oh I'm no longer close enough" (r2=80m). Where r1 < r2 and r2 = your original radius. Go to state once you are within r1 and only go back to when you are within r2 no longer. In the meantime fire at the player and dodge bullets. 

I am now creating a 64 bit and 32 bit executable of my game. How could I achieve so that the executable and dlls lie in a separate folder without changing all the path variables in the game? To clarify I want to have a folder structure like this: 

There can be multiple reasons for the Debug mode being slower. One of the most likely ones(that affect performance the most) is that you are still linking with a dll that has Optimization off(you can still generate debug info, but make sure to turn Optimization on) The second is because when debugging there is a special memory allocator used, that is somewhat slower, tough that shouldn't have such a high impact on performance, unless the application is extremely memory-intensive. Edit: In my experience the algorithm that parses large sets of vertices and optimizes them for vertex locality is extremely memory intensive, so much, that it takes 20x longer in the debugger even in release builds. 

The problem is a typical starters error: you chose both loops iteration variable to be the same, so they modify each other. You should always choose nested loops to use a different iteration variable(usually called i, j, k), otherwise things will get messed up. In other languages completely, but here you got the two objects already and using the keys only to remove, so only the removal part got messed up. The correct code should be: 

It depends if any of your physics can happen outside the flat player space. As ghostonline said debris and ragdoll animations are a classic example of out-of-2D physics in an 2.5D game. Another example is bullets: If there are any projectiles in your game, do they follow the curvature of your 2D space or do the travel straight ahead even if that means they will leave those bounds? Also mapping a physical 2D space to a curved 3D visualization correctly is (correct me if I'm mistaken) .. not that easy. You will need an injective projection functions probably involving lots of splines or something similar. While having curved 2D game spaces is a nice add-on, it requires quite some overhead for the code. That might be the reason why there is no such thing in Trine. But the game was fun anyway, wasn't it? I'd think twice about a feature like that. 

Modelling everything in the metric system I also observed that gravity feels much too weak with regards to the player jumping (in a platformer). Much like "on the moon", "jelly", "too much phyics", not "arcade" enough. On the other hand players in games are regularly able to jump to great unrealistic height too. TLDR: high gravity feels very fast paced and arcade, realistic gravity sometimes might not give the desired game experience. 

Picking in OpenGL can be done, by rendering the primitives you want to check for, assigning each one a unique color, based upon which you can look it up. Then you can check what color is rendered for example on the center of the screen, this way getting the object pointed at. This was done in older games, but is frowned upon, because it can be a huge performance hog. 

Picking in an OpenGL based app, is usually done using external libraries to do the ray-casting. Usually a game has a Physics engine, which must be able to do a ray-cast, so most of the time the actual physics engine is used to do ray-casting. One of such libraries is bullet. Now if I understand you correctly, what you propose is simply the method used by a physics engine, it uses matrices to translate the object into world-space, then doing a ray-cast in world-space. 

Answering your comment: By rendering only quarter tiles, the possibilities decrease dramatically. You shouldn't have to handle tiles on tiles, as they should be on a different layers alphablended or keycolored on each other. Also, I don't see why would you need built-in neighbors, but that could be handled separately in the neighbor calculation, perhaps using some sort of maps(list of pairs that blend). The map is usually static, and the images are low-res, so no need to worry about performance. 

Look out for Nintendo DS titles. They tend to use the stylus for game mechanics similar to yours. There are rhythm games like Elite Beat Agents employing something similar to your attack/defend game mechanics but based on music. Elite Beat Agents is actually quite challenging but fun to play. I'd also recommend playing The World Ends with You! It's an action RPG with very similar combat mechanics. It's also quite innovative and unique. Regarding crippling the player (controls) I'd always advise not to. I haven't seen a single game where not-being-in-control due to darkness, staggering, impairing effects, etc. was adding fun. Realism != Fun != Immersion. 

As already suggested by @Philipp creating, storing and rendering are often handled very differently when in comes to indoor vs. outdoor. This is because the requirements and challenges are typically very differrent. Example: Outdoor: 

All the games I know of that display lots of terrain make heavy use of LODing to create the illusion of huge amounts of very detailed surfaces. The CryEngine is king at this. And in World of Warcraft you can even see the LOD transitions when using low-performance settings. The second post at $URL$ describes many different techniques to visualize huge terrains efficiently. Especially the HLOD article $URL$ seems helpful. I doubt that displacement mapping will get you anywhere near the performance obtained by simply reducing the number of triangles for far-away terrain. Especially for mobile devices lacking hardware support. 

I am developing a game, but as I am working on it alone, the amount of content I can create is very limited. Because of that I want my game to be modded, for this purpose I am planning to create a complete modding API which would be exposed for lua scripting. I would also create tutorials to get people started. And the "Original" game would also be a "mod"(similar to Warcraft III maps) . My question is: What can a developer do to encourage modding of its game? PS: my game is a sandbox-ish multiplayer survival(most things are procedural). 

I base all this on personal experience from implementing an animated mesh with assimp and glm myself.(which now works) But it might not be the correct way of doing things. 

I think you are over-using the component model. While what you are saying could be accomplished and would work, the general way of doing this is making the camera a global thing. Sometimes it is just much easier to make an exception than to try force everything into a rigid view of "everything must be a component". So I recommend making the camera not a component but rather a property of the RenderSystem. There you could even have a list of cameras, and the RenderSystem would have much more control to optimize the way things get rendered. 

You can check for talent dependencies programatically by querying the complete talent table, and building a linked tree. You can also do that with SQL but it will require either recursive subselects or lots of queries. Better do it in your code. If there are multiple dependencies, like for example depends on AND use two tables to represent the dependency graph: 

So you see indoor and outdoor typically don't have much in common. That's why there are dungeon portals and explicit loading screens in games like World of Warcraft when switching from on to the other. To get a better answer please explain the workings and shortcomings of your current renderer. You can also learn a lot about indoor rendering from the good old Quake toolchain. 

You might want to "just calculate" the answer but I'm sure that you'll find it insufficient once you've got it because of the highly interactive nature of your "free fall" physics. Consider using a different approach: Searching. Here is how it's done for Super Mario AI: $URL$ Searching possible pathes to get from A to B allows for unlimited interactivity in mid-air while still being computationally efficient. 

All zeroes but ones on the diagonal. Called identity matrix. Does nothing when multiplied on a vector or matrix. Use glLoadIdentity to reset matrices. 

It seems you are using non-power of 2 texture dimensions and mipmapping which calls for trouble because the minifying interpolation has incomplete information along the edges. Prefer to manually expand all textures to power of 2 before loading. Use the desired color for those padding pixels. If you have many small textures of arbitrary dimension it might also be a good idea to create a single power of 2 texture atlas. 

where is the device resolution and is the size of play area in meters( in this case the latter is ) Note: This is just a very simple implementation, and needs some refinement, but I hope that you get the idea. Note 2: I assume you are using floating point numbers to represent coordinates.(should be the case already with lua.) Edit: In the example above (the position of the object) ranges, which means . So for example an object in the middle of the screen would have the coordinates 

To clarify things a bit: I want to create a kind of database for my game, that simply is a class that stores all game-state information like object positions, player scores, etc. The main problem I am facing, that the whole game is to be scripted, to the level of the (lua)script controlling what members should the database have. The reason for this is that I want to create a game that gives modders complete access to the game via lua scripting.(its one of the core features) For this to be viable I need to be able to add custom elements to the database. I want to avoid using a 'real' database and roll my own solution. For example I want to be able to do the following in the script file: 

Model space! See the ancient but still excellent NeHe tutorials for more info on these topics: $URL$ , especially $URL$ 

True. GL_PROJECTION is for choosing between orthogonal (2D, UI) and perspective (3D) projection. Do not touch yet. 

Maik is right, Baraff's papers are an excellent start, but don't forget Chris Heckers write-up on rigid body dynamics: $URL$ ! Also his advice on "[..] you will throw your engine away" is entirely true. But you will learn a lot! Regarding the CUDA/OpenCL part of your question: If you know CUDA then switching to OpenCL becomes very easy. I'd recommend learning CUDA first, because there are so many good tutorials, example code and computation libraries out there. For example: 

No and yes. No, only one model is used. Yes, there is a way to ignore certain parts of a model. Actually it is quite simple: You don't animate them. And when you have two animations that don't overlap in "parts affected" it is trivial to combine them (i.e. running them at the same time). Technically the "ignore" part of the animation matrix is the identity matrix and multiplying both animation matrixes produces the desired combined animation. 

But be aware: Getting started on CUDA is easy, getting started on physics simulation is a good bit harder, but combining both is quite a challenge! 

I would recommend either leaving this system as-is and worry about performance later or use Assimp, which not only does this all for you, it supports more formats with consistency, and will save you some headaches later with its tangent generation and other useful preprocessing. Some pseudocode for aligning as asked for: 

Edit: From the video it seems you are overshooting the position you are aiming for. There are three ways to solve this: 

The way I(And I believe many others) do it is to have not only one noise generator, but multiple ones, configured differently, and then interpolate between them based on some value(perhaps chunk type, perhaps just another noise function). Also generating a specific terrain type is more feasible by combining multiple noises too. The website of libnoise has some nice information about all this, and also about the various noise generation and mixing techniques. Some basic generators are: 

EDIT: To answer your comments, there is no reason to precalculate the matrices. But I see no problem in doing so. But if you also want to interpolate... It doesn't look straightforward. Maybe you could store a matrix for every frame but that would be quite a lot of data. Well To expand on this here is some calculation: Assuming 4x4 matrices of float(4byte) data. Lets assume you have 16 bones in your model. And you want 200 animation frames. And you want interpolation so you do 2000 animation frames instead(10 subframes)(Assuming a bad case scenario). This would require 2000kB of memory/disk space. Thats not a lot.(Except if you are doing skinning on GPU, then if you consider 100 different models, this is 200MB animation data, which is quite significant.) But you could just easily calculate it on the fly with even more accuracy, and don't need to have larger files. And mainly: write, test and maintain the extra code to do it the other way around. So the more I think about it the less feasible reasonable it seems.