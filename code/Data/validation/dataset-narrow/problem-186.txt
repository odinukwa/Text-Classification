On Cisco 5508 v7.2.103.0, I have a couple of WLANs configured. Call them ABC and XYZ for the sake of this question. ABC uses 802.1X and gets a splash page redirect URL pushed down. XYZ uses PSK and uses the WebAuth external config to push a login page redirect URL. Both the splash and login pages are served under the same base (external web server) URL such as $URL$ and /login.html. 

Dedicated means not a shared medium. Dedicated Line @ Wikipedia Leased means just that... you're leasing the line which could be using a shared services such as a MPLS VPN (or Frame Relay in the old days). Leased Line @ Wikipedia A serial line is a type of interface using running HDLC or PPP. I wouldn't put this in the same category as dedicated or leased lines. Dedicated Internet Access (DIA) is a common term used by ISPs and can be provided over leased or serial lines. You can't really have dedicated without leasing (i.e., a contract), unless you own the cable plant, but you could use something other than serial like Ethernet. 

Usually you are presented with throughput in Mbps (M-bits/sec) and Mpps (M-packets/sec). These are considered backplane or box throughput numbers. Marketing materials usually present the numbers in the best light which is under ideal conditions of large packets with 1500 bytes in length. Realistic throughput can be obtained under test conditions that use Internet Mix (IMIX) of data where both packets lengths and protocols vary. 

After reading the HTTP host-based load balancing in the Fortigate Load Balancing doc, I can see how you can have an atypical load-balancing configuration that could result in what you describe. However, without part of your config, we cannot be certain if this is the case for you. Fortigate FortiOS allows a Virtual Server to be created that is tied to Real Servers that each have a different host header configuration. Should any requests match the VIP of your Virtual Server, the load balanced requests will only go to Real Servers that match that . The most important part which nicely explains your symptoms, is that one of the Real Servers can omit the host header so it matches on any host header. The Real Server without a host header might have been configured as a sort of "catch-all" that lands on a site that does the redirect. Using the example below, only the 1st and 2nd rservers handle traffic matching your preferred DNS name via the host header, but the 3rd rserver takes anything matching all other host headers which includes the DNS VIP itself and sends to a site that could do a redirect. 

For Remote Access (RA) and LAN-to-LAN (L2L) VPN, I currently operate a pair of Cisco VPN 3005 Concentrators tied to Internet edge routers on the outside and the inside tied to an internal pair of PIX 535s on what is the firewall outside interface before being allowed to pass through to our real internal networks. Both the VPN 3005s and the PIX 535s are being replaced with the ASA-5545X platform. These firewalls are not for our primary Internet traffic, only VPN, and they may also serve as an internal firewalls for traffic going into the data center across private lines. With the internal firewall ACLs being combined in a single firewall that serves VPN traffic and potentially other private line traffic, for security boundaries and to eliminate any potential routing issues, should the inside interface of the VPN-firewall (5545) stay in a separate subnet from the main Internet firewall or does it really not matter? OSPF is currently running on the Internet firewall (w/default-originate) and the VPN 3005. As this data center is our primary DC for web traffic -- our bread and butter -- I must eliminate any potential issues with the placement of the VPN firewalls that could interfere with this even in the slightest way. **Should the inside interface of the 5545 land first on the L2 edge switches and then trunk to the agg switches for better security or just have the inside drop straight into the Agg layer, also considering that private line traffic may come through yet another interface on the 5545 in the future. Only the relevant parts of the L3 connectivity are shown below with the ASA-5545X* that's in question. 

You could try disabling the Next Generation Maps in to see if this makes a difference. It did on my map test. There are performance reasons for not doing this. 

The /30 only provides two useable host addresses and your router and the ISP have consumed them. This net block is commonly known as the WAN block from your ISP and is used for just that link. For the access side, you should have a separate (public) LAN block provided to you by the ISP. This could be as small as a /29 or to a /24 or larger, depending on your needs (with justification). The LAN block is where you should be concentrating your "access network". On this side of the fence, you place your firewall or other publicly facing devices here that should be protected from the Internet. 

You do have asymmetrical routing, but that shouldn't be the issue. Instead, I suspect the issue is link delay involving your 3G link. Since IPSec IKE uses UDP/500 or UDP/4500 with NAT-Traversal, there's no guarantee of packet delivery. Your VPN client -- the IKE initiator -- sends the first IKE message and is awaiting a response from your ASA. The ASA IKE response message is either dropped or delayed too long that your VPN client sends another IKE message, causing the ASA to log the . I would think your DSL link is more reliable -- less delay, less jitter, less packet loss -- than the 3G mobile network. Any reason that's not your default gateway? To test the 3G link as the issue, force the DSL to be your default. 

On Internet edge routers speaking eBGP to multiple carriers and iBGP to one another, all interfaces on the LAN and WAN side are GE except for one Serial full-DS3 (~45Mbps) on each router. Although I think I'm hardly sending much traffic outbound on the serial interfaces -- in the 3-10Mbps range -- I see constant output queue drops (OQD). Is the likely explanation that there really is bursty traffic I'm not seeing as the load-interval is at the 30 second minimum and SNMP polling is averaging traffic over 5 minutes, so those won't illuminate the burstiness? The platform is a Cisco 7204VXR NPE-G2. Serial queuing is fifo. 

AFAIK, the answer is NO. I never understood how this valuable feature has escaped IOS for so many years or I manged to never discover it. ;-) I use the following technique in some cases when I want to be absolutely sure I'm configuring the interface that I think I am. Comments (!) shown. I know this technique is long-winded for the net vets, but it fits perfectly with the paranoid crowd which is sometimes both. 

Typical use cases seldom consume all available bandwidth at each port and, therefore, aggregated bandwidth on your uplinks will probably use less than 1Gb unless you're pushing lots of packets. This is called oversubscription which is an expected design element. I have access switches in a data center with a couple of hundred web server VMs connected to each and all their uplink traffic fits over two pairs of 2x1Gb bonded (etherchannel) ports. That's a 200:4 or 50:1 rough oversubscription. You really need to understand your expected traffic patterns to determine if oversubscription will work (and at what ratio) or not. Etherchannel can combine eight 1Gb links to make an 8Gb pipe, so consider that as a cheaper alternative to 10Gb. 

I'd like to push more outbound traffic on the DS3, but not with my concern on the OQD. The tier 2 ISP behind the DS3 has POPs that double as peering-points with 6+ tier 1's, so the idea is to get that traffic on-net with the client asap as opposed to our primary ISP on the GE who is a tier 1, but must work their way towards their peering exchanges. Inbound traffic is not a concern. Is there a better queueing strategy than fifo in this situation? Looking at the Cisco docs on input & output queue drops, incrementing outbound queue size is not recommended as the packets are already on the router and it would be better to drop at input so TCP can throttle the app back. There's plenty of bandwidth on our GE links, so there's no really need to throttle the input. There are no policy-maps on these routers. 90% of outbound traffic comes from our HTTP responses; most of the rest from FTP and SMTP. The GE links push 50-200+Mbps. Would you recommend any adjustments to the output queue size buffer? These serial interfaces are our backup links that I'd rather utilize more for the reason given earlier (if valid), but tempered with my BGP policies that attempt not to overload that serial interface (which appears very underloaded most of the time). 

In all cases, the client detail shows the redirect URL was set. In the two cases where everything worked as expected with the redirect, webauth/run state, and traffic flow (being either allowed or denied), I don't think the ACLs are the issue. Nothing else is being pushed down from ACS other than the redirect URL. The two WLANs are hardcoded to different VLANs. Could this be random behavior or are my eyes just playing a trick on me? I seen slightly different behavior with different devices -- some more random, some less. What's the best approach to narrow this problem down? Update: DNS is not the issue. General IP reachability randomly works in browser. Regardless of the webauth state (RUN vs WEBAUTH-REQD), sometimes the browser gets through and sometimes does not. (Initial requests are always plain-text HTTP.) I've even seen regular traffic get through for non-web apps such as SMTP, so I'm really thinking Webauth is mucking with this, but I don't see anything obviously wrong. I have a preauth ACL that's fairly liberal and a guests ACL. I've even added permit any/any to both ACLs that didn't make a difference. 

This is my interpretation of TCP Vegas for your questions. Other scholars here could correct this or augment it. Q1. "The change of the modified slow-start is that the window is increased every other RTT..., but what is the meaning of other RTT?" A1. During SlowStart, the cwin (congestion window) is increased every other RTT, meaning this is in comparison to TCP Reno which increases every RTT; the algorithm simply skips every other RTT that may be seen with ACKs, for example, in computing the RTT metrics and exponentially increasing the window. Q2. "When the algorithm change to the lineal growth phase (or congestion avoidance phase)?" TCP Vegas only allows exponential growth every other RTT. When the window is not increasing -- the other "every other" RTT -- Vegas compares the expected and actual rates and comes out of SlowStart when the actual rate falls below the expected rate by one MSS. Q3. "And, there is any reduction of the window when a duplicated ACK is received?" Vegas only decreases the cwin if the retransmitted segment was previously sent after the last decrease. Segment losses before the last window decrease do not imply the current cwin is congested, so the cwin is not decreased further.