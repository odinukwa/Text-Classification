So basically the code just blocks until a message is received. This all works fine. My question is about the implication of issuing a command which hangs on to some service broker based resource basically forever. Are there any performance issues associated with this pattern that I should know about? For reference, this is SQL Server 2005. 

From what I can tell Procedure Cache Hit Ratio below 95% is a problem. On my box, the values hover from 85 to 95%. How do I fix this issue? The server seems to have plenty of RAM so that shouldn't be an issue. What else can it be? 

I have an app that's local to the SQL Server and thus has a Shared Memory connection to it. I was wondering whether the RAM taken by the connection (including data transfers) counts against the max memory limit set for the SQL Server. The reason I am asking is that the SQL Server is maxed out on memory (e.g. Target Server Memory = Total Server Memory and other metrics). If the RAM taken up by Shared Memory connection counts against it, wouldn't I be better off using TCP connection to the SQL Server? 

I have table partitioned on (int). I also created a non-clustered index for on the table. When I run the following: 

Avoid a single database. My recommendaion is: start with separate databases on the same server - to reduce the costs, including maintenance costs. If workload increases, you can setup a new machine and move some databases. If only one application's workload increases, you can move only that one. To do this, it is important to monitor the workloads of different applications. So I recommend to install User Statistics plugin, from Percona. And yes, the good way to distribute the workload and face crashes is to use replication or a cluster (replication is much simpler). Nowadays, we need to have no single points of failure. With MySQL you will also have another way to reduce costs: if you have applications on 3 servers, you can replicate all those databases to 1 slave - this is called multisource replication. Other benefits of using multiple databases include: 

is only needed because created_at is not unique. If is not the first column, MySQL will have to read all rows and copy them to a temporary table (which could be in-memory or on-disk) to sort them. If you decide to use the id, just keep the above snippets, but replace with . 

As another answer highlighted, Query Cache is not the only cache. Its use is not even advisable in most cases - in fact, it was removed in MySQL 8.0. The reason is that it has scalability problems (it's governed by a global lock) and it invalidates data far too frequently to be useful in a normal workload. But InnoDB buffer pool contains indexes and data accessed frequently. After your first query, some indexes and data are cached, so next time they will be read from memory. Probably some data/index pages are accessed only once per query, in which case you should be able to see a slighter difference between second and third execution (first time these pages are not cached). How to avoid the difference between query execution times? Well, there is no way to make the query faster the very first time it runs, as it needs to read from disk. But then, if your buffer pool is big enough, your query will always be fast. Keep in mind that a big buffer pool is very important for MySQL performance. The general recommendation is to keep it 75-80% of total memory. But in reality, things are more complex: 

What does Table Scan (HEAP) mean for a partitioned table? Does it indeed use an index, perhaps behind the scenes? Is there anything I need to do to improve efficiency? 

Must the partition column be part of the primary? Is it recommended one way or the other? Do I have to create an index for the partition key, or does the DBMS do it automatically on its own? 

I've setup a test SQL Server 2016 server. I've installed 2 instances, restored a backup on the primary. Then restored a backup on the secondary with , then restored the transactional log on the secondary, also with . I then followed the prompts in the Mirroring Wizard off the Database Properties page and ended up getting an error: . What am I missing? 

I have a situation where multiple client apps send messages via the Service Broker (utilizing stored procs). These messages are picked up by yet another client app and then processed. The way the messages are picked up is that the app issues the following SQL statement (pseudo code): 

I am about to split a large database into a bunch of federated instances. Currently, most of the primary keys are auto-generated identity ints. Obviously, that's not going to work in a federated setup. I've read people using auto-generated GUIDs to replace the ints, but that data type has well-known performance sapping problems on its own. What are some of the strategies I can use for having unique values for primary keys across federated members? 

If you eventually decide to use master-master, I suggest to regularly test failover during normal work hours with a non-crazy traffic. So you will avoid bad surprises when the situation is bad. Hope this helps. 

There are of course alternatives more intrinsically secure, like mysqldump and Xtrabackup. But I'll assume that you know how they work and you decided that a simple file copy is better for your use case (for example, because data are too big for mysqldump and most of your tables are not InnoDB). 

First of all, I discourage you from using the slow log with output, in production. The reason is that writes are locking, which limits the concurrency of your workload. Moreover, CSV stored engine does not support indexes. Any non-trivial query will be very slow, so I don't see any advantages in doing this. Of course you could use MyISAM and add indexes, but then writes will become more expensive. That said, the correct way to "rotate" the table is copying it and than truncate it. You will probably lose some queries every time: the ones ran after the copy but before the statement. 

This query doesn't take advantage of the primary key in any way. The number of rows examined (about 160K rows) shows this. So your assumption that your does nothing is incorrect: it examines several rows. The reason why your SELECT is faster is pretty clear. This expression is computed once, at the beginning of query execution: 

I would have expected this to result in a simple clustered index scan. However, looking at the live query statistics, and the actual execution plan, the majority of the query's execution time comes from sorting the results after the index scan. Why is the ordered data being sorted again? $URL$ 

My first attempt to delete the data simply took far too long - it's historical data so there are a few million rows. After that failed, I asked around and someone suggested disabling check constraints, deleting, and then re-enabling the constraints for those specific tables (which I will NEVER do again, terrible idea). The disable and delete ran fairly quickly, I had to leave the enable running all night but it did succeed. From then on, the database has been at 100% CPU, and one of the queries occasionally never completes. It's the same query every time: 

If I want to query the logs, in order of date, I have been told I can use the partition number in order to avoid a sort when the results from each partition are joined back together. 

This query uses the index , and usually takes no time at all to execute. Occasionally though, a query will just sit there executing until it times out (after 30 seconds). So far, I have tried: 

I will answer what you asked, but first let me tell you that I don't understand why you want to do that. An autoincremental id is very good for this task. But it is correct to also use a timestamp column, because it is a bad practice to rely on an id for sorting. Why? Because there are cases when its order might not be chronological - for example, if you use Galera cluster and you have failovers. To do what you asked, first create this index: 

I don't think that someone can give you magic numbers like the acceptable number of columns, or information too strictly related to your workload, like if it is a good idea to split the table. There are too many variables: number/types of existing columns and indexes, number of queries, how many columns you read per query, and so on. Proper tests will give you a good answer. All we can say is that, yes, common sense says that such a table should be split if possible. But then, every query will need to read from multiple partitions? Every new row will have matches in all partitions? This could slow down your application. Ideally, most of the queries should be able to read from only one partition. So the first suggestion would be to check with developers if some queries can be rewritten so that they will read less columns - possibly by rewriting some . You also ask about the best possible match condition. Here the answer is easy: join by primary key. All matching rows should have the same . It should be an columns on only one table. You first insert new rows into the table, then to the others, in this way: 

I run on box box and get multiple rows per single SPID. For example, see below. Does this mean that SQL Server has broken the query into 23 parallel sub-queries? If that's the case, why is it ignoring MaxDegreeOfParallelism setting of 8? Or is this something else? 

I have an SQL Server 2014 Enterprise Edition with a lot of data. I would like to mirror the data from that to at least 3-4 servers. The mirrors are all SQL Server 2014 Standard Edition (no more money is available for Enterprise licenses). How do I mirror the data from my main box (with the Enterprise Edition license) to other boxes? I tried the mirroring feature, but it seems that it only allows single mirror. I could you use Always On Availability groups, but that would require that all mirrors also be Enterprise Edition (unless I am reading the docs wrong). At least one of the mirrors needs to be there almost real-time (1-2 minute delay is fine) data replication. The other mirrors could have 1-2 hours delay. So what are my choices? P.S. All the secondary servers are just read only. P.S. The purpose of the mirrored boxes are partially to off-load readonly queries to them. These mirrors need to have near real-time data replication. Another purpose is for analytics, which is a heavy load. Today everything is on the same box and we are forced to do analytics at night so as not to disrupt users and there is just not enough time. P.S. The servers are nearby each other - on the same subnet, connected via a 10Gb link. P.S. Our license also allows a no cost upgrade to SQL Server 2016 when it becomes available. Does that change anything? 

...note that you should do them in the opposite order. It makes no sense to get the coordinates from a running master, those coordinates have no use for you. Note down the coordinates before restarting the master: those coordinates describe the state of initial slave state (the files you scp to the slave). 

Replication cannot work in your case, because developers databases will often change, and conflicts with the master break replication (by design). Also, developers cannot rely on data that are constantly changing. You need to take some form of backup and send it to developers machines. Here are the best solutions in my opinion: 

Of course you will be able to obtain the same information with multiple queries, or with . But it seems to me less clean and, should you ever need to add or remove a table, or change the usage of (from 20,25,30 to 20,30,40), you'll need to make much more changes. There are even more obvious case when the "one table" solution is better: maybe one day you'll need a query which returns people whose age is less than 23. Flexible designs are usually better. For specific use cases, you can always create views, if really needed. 

I don't think that your approach is wrong, but I don't have much information. Your question is clear, but this space is limited compared to the complexity of your system. Definitely you shouldn't consider using Clickhouse for OLTP. Not only because and are not (yet) supported, but also because this database is designed to provide good performance for analytics. It lacks more or less everything is needed to optimize an OLTP workload. Kafka is a good idea? Maybe. But you won't have transactions, for example. I suggest to try to optimize your MySQL environment first. Some very generic points - sorry if they sound obvious to you, but of course I can't know your skills lever: