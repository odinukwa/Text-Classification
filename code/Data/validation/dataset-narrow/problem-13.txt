Difference between Continuous Integration, Continuous Delivery and Continuous Deployment. Picture copied from codeproject.com Whether you do continuous delivery or continuous deployment is very much an implementation choice. If you do continuous deployment, changes in code will be deployed automatically after the acceptance tests are passed. This may or may not be desirable for your product. With continuous delivery, people can make a choice whether a particular code change is deployed or not (and possibly where exactly it is deployed). Since the difference between continuous delivery and deployment is small and many people are unaware of the exact difference, the two terms are sometimes used interchangeably. 

Yes, but it's by preventing the things you mention in your question as much as possible. You are right that there are only so much developers that can work on the same code before things become unmanageable. You need someone or something that has an overview of all changes and makes sure integration works fine and regression doesn't occur. This is hard to scale if everything happens in one repository. Before starting any work you need to separate functionality in such a way that things can be integrated later with little or no effort. This means that you want to split functionality into parts that are independent, or at least have as little dependencies as possible. How you do this depends very much on the product you are developing. In the past separation of functionality was done by creating different libraries. The downside to this is that you need a good method of managing those libraries. Old versions of Windows for example had a bad library management system which caused the infamous DLL Hell. Nowadays micro-services is (becoming) a popular way to do this, although this also has it's drawbacks (e.g. communication overhead, more services to monitor) If separation based on functionality is difficult, another option may be to separate development in time. Instead of multiple teams working simultaneously on many different features, you have 1 team that works on only 1 or a few features at a time. When separation of work is not possible, you'll need tools and tests that make sure things align. Automated unit and integration testing can be a big help here, but ultimately there will be limits to how big a project or team is to be workable. 

However many people on the Internet argue that this is incorrect because it violates REST/HTTP specifications; "embedding of API version into the URI would disrupt the concept of hypermedia as the engine of application state". Itâ€™s more appropriate to use the Accept header to request a particular version. For the latter people suggest to use a Vendor MIME type, for example something like Nevertheless, the reason why many API designers do include an API version in the url is because it's easy to implement and debug (clearly visible which version you are using). Side note: in our organization we recently decided to support both a versionless endpoint that always point to the latest stable version of our APIs, as well as an endpoint with a version specification. This allows users to choose if they want to commit to our latest API (which may require making changes when a newer version is released), or to connect to a fixed API version (which may become deprecated over time). 

Continuous delivery and continuous deployment both take continuous integration one step further, by adding a 'deployment to production' step to the process. The difference between continuous delivery and deployment is that for delivery this step is done manually and for deployment is it automatic. 

I do not think that there is a single correct piece of advice for such a broad question, but here are my thoughts your situation: As a starting point look at your current workflow, processes, and technologies being used at the company and then research some tools (Jenkins, Kubernetes, Docker, Grafana, Ansible, Kubana etc) or techniques(writing your own scripts or programs) that might be useful to your company or any projects you are working on. I would also suggest maybe attending local DevOps meetups or talks in your area for more exposure. 

From my experience (where I currently work and another company where a friend works at) the DevOps team's report to the CIO. Also to note that our DevOps team works a lot with, mostly alongside the CTO on a "day to day" basis compared to the CIO. 

Resolution 1 So I solved this with the following script. I originally posted the question just in case there was an easier way that I was not aware of. 

The Amazon Cognito streams feature can be used to backup data. Currently, Amazon does not provide a solution to backup their Cognito user Pools. You can use the following NPM package called "cognito-backup": Install: 

Background: Besides for providing support to our current infrastructure and to our Developers, we do monthly planning as a DevOps team for what we want to accomplish on top of helping dev teams within sprints and new projects that are launched. However, during the month we often notice extra things that need to be done and improved, which we then add to our backlog. We also are responsible and assist with various other things that fall beyond our scope, but we assist the business were we can :) Answer: As soon as you notice you are not getting round to or postponing lots of tasks especially maintenance, I think that is a good indicator(from what I have experienced). Also, the more new projects and dev teams that come in the thinner the DevOps team gets spread, the more people you will need. Its super easy just to get caught up in the day to day completing tasks, but I believe its super important (even once a month) to take a step back and assess this. 

I have multiple AWS accounts and I need to list all S3 buckets per account and then view each buckets total size. Currently, I can only view the storage size of a single S3 bucket with: 

There is a plugin, which you can use in your pipeline to disable the job on failure. You will be able to use this plugin for single failure or to disable after multiple failures. $URL$ 

Resolution 2 Using Dashboards in CloudWatch in the AWS console. You can then simply specify all S3 buckets and add the numbers stats to show the storage size metrics. This won't cost you plenty of API calls and can be significantly faster depending on the size of the s3 buckets(takes quite awhile to get the size on very large buckets). Verdict Creating the Dashboard (Resolution 2) on each AWS account was the most efficient option for me cause it is way quicker for me to log in and grab the metrics manually from each AWS account than to wait for the scripts API calls to finish. :( 

You can install 'Bitbucket Server Webhook to Jenkins' in Bitbucket. $URL$ Once install you will need to enable the 'Post Receive' Hook on the required repository. Remember to enable 'poll SCM' for the Jenkins Job. Update You can test the configuration of the plugin here: 

So if you want to keep your Docker image as small as possible, consider using OpenJDK instead. There's an official OpenJDK Dockerfile repository or you can just use . The basic "easy to run" Dockerfile for OpenJDK 7 is as follows (taken from the website listed in the previous sentence): 

Snapshot Permissions Boto3 has a function that allows you to create volume permissions, which is what AMI Sharing with AWS Marketplace requires you to do. will allow you to share your AMI with the marketplace account like so (you can also use a JSON representation if you prefer, it's in the docs): 

First of all, Rancher actually contains implementations of both Kubernetes and Mesos within itself. However, they did make their own system called Cattle which is heavily based on Docker's Swarm. I'll touch upon this in the section for Rancher. Secondly, since each one offers similar base features (load balancing, resource isolation, etc) I'll try to go more into what makes them different rather than focusing on differences among those common features unless they're significant. Kubernetes Highly performance focused, also featuring cloud storage orchestration (a feature missing from Mesos, although there's probably a plugin for it). Has API options to allow for automated scaling of resource usage as needed by individual containers (and for the reverse if a container is not being hit hard while others are). Something important about Kubernetes is that unlike other container orchestration software it doesn't provide a comprehensive configuration or any kind of comprehensive self-healing. Instead, it focuses on continuous deployment of multiple apps with an easy rollback system at the app level (as a result you might want to look into micro-services when using it). Each app is a small piece and can be deployed/configured individually. They make a point in their docs to say that Kubernetes is not a traditional PaaS (platform as a service) system since it lacks middleware for virtual hardware or databases and it doesn't build your app itself. It's designed to (as they say themselves) remove the need for manual container orchestration, instead automating the process by continuously pressing towards a target app state. Mesos Monolithic in comparison to Kubernetes. Focuses on the big picture moreso than the individual services, although it still allows for management of individual services. Provides built-in middleware for things like Spark, Hadoop, etc. Best usage of Mesos will involve many plugins as it's designed to be easily extended. If you need fine-grained control over managing your application (insofar as there's a plugin available for what you want to do or you have a team member willing to build one if there isn't) you'll want to use Mesos. Rancher (and Cattle) Potentially the best option in that it is itself a superset of the previous two, having an implementation of both. This might also be seen as a downside as more complication in your management software is rarely a good thing and might lead to unforeseen issues. Rancher features an application catalog that allows for one-click deployment, something Kubernetes doesn't have due to its design philosophy. However, seeing as Rancher has an implementation of Kubernetes, you can use Rancher if you feel these features are missing from Kubernetes. Cattle is based off of a stack system, where you group related services together. It also houses Rancher Compose, a feature similar to the Docker service of the same name. This is probably the most interesting part of Cattle, the rest of it being fairly standard (although the Secret management is still in beta). If you have experience with Docker Compose you should read up on it here (I don't, so I'm probably not the best person to write about it). Resources: "What is Kubernetes?", "Overview of Rancher", "mesos.apache.org: 'What is Mesos?'"