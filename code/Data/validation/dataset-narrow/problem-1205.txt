H.W. Lenstra. Integer programming with a fixed number of variables. Mathematics of Operations Research, 8:538–548, 1983. R. Kannan. Minkowski’s convex body theorem and integer programming. Mathematics of Operations Research, 12:415–440, 1987. Andras Frank and Eva Tardos. An application of simultaneous diophantine approximation in combinatorial optimization. Combinatorica, 7:49–65, 1987. 

As Juho pointed out, the problem is known to be #W[1]-complete by the work of Flum and Grohe. However, there does exist a randomized approximation scheme which runs in FPT time and returns an estimate which is a $(1+\epsilon)$ factor away from the correct solution with high probability. See "Approximation Algorithms for Some Parameterized Counting Problems", by Arvind and Raman, ISAAC 2002. 

The Bandwidth problem remains NP-hard to approximate within any constant factor even when restricted to caterpillars (a special class of trees where all vertices of degree $>2$ lie on a path). This is shown by Dubey, Feige and Unger in "Hardness results for approximating the bandwidth". 

Undirected (Vertex) Geography is in P. In particular, the game on graph $G$ with starting vertex $v$ is a win for player 1 if and only if every maximum matching of $G$ uses the vertex $v$. This can be checked in polynomial time. The above is Theorem 1.1 from the paper "Undirected Edge Geography", by Fraenkel, Scheinerman and Ullman, Theoretical Computer Science 1993. 

I think the best known result is that the blow-up can be quasi-linear (the new instance has size $n\cdot(\log n)^{O(1)}$). This is given in Dinur's 2007 paper (Thm 8.1), which is also cited by the Moshkovitz-Raz paper mentioned by Yuval Filmus. As far as I know it is still open if the blow-up can be brought down to linear. Some people call this the Linear PCP conjecture, see e.g. the recent paper by Bonnet, Egri and Marx 

The Travelling Repairman Problem (TRP) is known to be NP-hard on weighted trees. In this problem, which is also sometimes called the Minimum Latency Problem, the goal is to find a tour that visits all the vertices of a graph while minimizing the average latency. The latency of a vertex $u$ is the cost of the tour from the origin until the tour visits $u$. Note that in the related (and more famous) TSP problem, the goal is to minimize the maximum, rather than the average latency. I think the TRP is generally considered a more complicated problem (in fact TSP is in P for tree metrics). NP-hardness on trees was shown in R.A. Sitters "The Minimum Latency Problem Is NP-Hard for Weighted Trees", ISCO 2002. 

In Defective Coloring we are given a graph $G$ and an integer $\Delta^*$ and are asked to partition the vertices of $G$ into the minimum possible number of color classes so that each class induces a graph of maximum degree at most $\Delta^*$. (If $\Delta^*=0$ this problem is just Coloring). In [1] we showed the following regarding this problem parameterized by treewidth: (R1) the problem is W[1]-hard; (R2) the minimum number of colors can be 2-approximated in FPT time; (R3) there is no $(3/2-\epsilon)$-approximation in FPT time, under standard assumptions. [1] Rémy Belmonte, Michael Lampis, and Valia Mitsou: Parameterized (Approximate) Defective Coloring. STACS '18. 

One relevant TSP version is "Group TSP". In this problem, the "cities" are divided into groups and the goal is to find a tour that visits each group at least once. This has also been studied on the plane, which is closer to what you describe. Here each group is a closed region of the plane and it suffices to visit one point in the region to cover it. See e.g. the paper "Approximation Algorithms for Euclidean Group TSP", by Elbassioni et al. in ICALP 2005. 

Graph Balancing (also known as Min Out-degree Orientation) is another example of this phenomenon. In this problem we are given an undirected edge-weighted graph. The goal is to orient the edges so that the resulting digraph's (weighted) maximum out-degree is minimized. The problem is often motivated by a scheduling scenario. Imagine that each vertex is a processor and each edge is a job which is only allowed to run on one of its two endpoints. The weight of an edge is the length of the corresponding job and the goal is to minimize the makespan. The problem is NP-hard and APX-hard, even if all weights are 1 or 2 (see Ebenlendr et al. "Graph balancing: a special case of scheduling unrelated parallel machines" in SODA 2008). It is however in P for unweighted graphs (see Asahiro et al. "Graph classes and the complexity of the graph orientation minimizing the maximum weighted outdegree" in CATS 2008). 

$(k,r)$-center is another (arguably natural) problem that is $W[1]$-hard parameterized by vertex cover. (See a recent preprint by Katsikarelis, me, and Paschos here - sorry about the self-promotion!). The problem here is to select $k$ vertices (centers) so that all other vertices are at distance at most $r$ from the closest center. This generalizes $k$-Dominating Set (which corresponds to $r=1$). More strongly, the problem is $W[1]$-hard parameterized by vertex cover and $k$. The catch with our reduction is that we need to produce an edge-weighted graph, i.e. we need the edges to have different lengths. We can replace weighted edges with paths, but then this only proves W-hardness when the problem is parameterized by feedback vertex set. Indeed, if all edges have uniform weights then the problem is FPT parameterized by vertex cover. This example reinforces Daniel's point (which I agree with) that it would be surprising to find a problem that is W-hard by vertex cover, without having some additional input given besides the graph. 

When we are given a tree decomposition of a graph $G$ with width $w$, there are several ways in which we can make it "nice". In particular, it is known that it is possible to transform it into a tree decomposition where the tree is binary and its height is $O(\log n)$. This can be achieved while keeping the width of the decomposition at most $3w$. (See e.g. "Parallel algorithms with optimal speedup for bounded treewidth", by Bodlaender and Hagerup). So, logarithmic depth is a property of a tree decomposition which we can get almost for free. My question is if there exists a similar result for clique-width, or perhaps a counter-example. In other words, given a clique-width expression for $G$ using $k$ labels, does there always exist a clique-width expression of height $O(\log n)$ for $G$, that uses at most $f(k)$ labels? Here, the height is defined naturally as the height of the parse tree of the clique-width expression. If a statement similar to the above is not known, is there an example of an $n$-vertex graph $G$ with small clique-width $k$, such that the only way to construct $G$ with $f(k)$ labels is to use an expression with large depth? 

How about the following transformation: Given a graph $G(V,E)$ with $V=\{1,\ldots,n\}$ construct $G'(V',E')$ as follows: $V'$ initially consists of two sets of vertices: the vertices $u_i, 1\le i\le n$ and the vertices $v_{i,j}, 1\le i,j\le n$ (a total of $n^2+n$ vertices). We add the following sets of edges: first, connect all $v_{i,j}$ with $v_{i,k}$ for $k\neq j$, so the graph now consists of $n$ cliques of order $n$ and $n$ isolated vertices. Next, for all $i$, connect $u_i$ with the vertex $v_{i,i}$. Then, for all $i$ connect $u_i$ with all vertices $v_{j,i}$ for which $(i,j)\in E$. On the other hand, for all $i,j$ such that $(i,j)\not\in E$ construct a new vertex $v'_{i,j}$ and connect it to $v_{i,j}$ (this constructs two new degree-1 vertices for each non-edge of $G$). This completes the construction. The claim is that $G'$ has a vertex cover of size $n(n-1)+k$ if and only if $G$ has a dominating set of size $k$. The intuition is that any vertex cover must take at least $n-1$ vertices from each clique (giving at least $n(n-1)$ vertices overall), allowing us to select exactly $k$ of the $u_i$ vertices to represent the dominating set. The vertex that is left out of the $i$-th clique encodes the vertex of the original graph that was used to dominate $i$. Observe that the leaves $v'_{i,j}$ ensure that vertices corresponding to non-edges are not left out of the vertex cover. Thus, the direction dominating set of $G$ $\to$ vertex cover of $G'$ is straightforward: select the vertices from $u_i$ that represent the dominating set and from each clique select all vertices except the one that is adjacent to a selected $u_i$. For the converse direction, first note that it is never optimal to take a $v'_{i,j}$ vertex in the vertex cover since these vertices have degree 1, so their neighbors must be selected. Second, observe that in any vertex cover that selects all $n$ vertices of a clique we can exchange one of them with its neighboring $u_i$ vertex, therefore we can assume that an optimal vertex cover selects $k$ such $u_i$ vertices. These must be a dominating set of $G$. 

In the Path Coloring problem we are given a tree T and a collection of paths on that tree (the idea is that T is a communication network and the paths are communication requests). We want to color the paths with a minimum number of colors so that two paths that share an edge take distinct colors. This problem is known to be polynomial-time solvable if T is a bounded-degree undirected tree. It is however NP-complete if T is a bi-directed binary tree. I believe both results are given in the paper below. [1] T. Erlebach and K. Jansen. "The complexity of path coloring and call scheduling". Theoretical Computer Science, 255(1-2):33–50, 2001. 

After a while I found an answer in the literature, so I'm posting it here in case it is useful to someone else. It is in fact possible to re-balance clique-width expressions so that they have logarithmic depth. The result is given in the paper "Graph operations characterizing rank-width and balanced graph expressions" by Courcelle and Kanté, WG '08. I quote Theorem 4.4 from the paper: "Every graph of clique-width or NLC-width $k$ is the value of a 3-balanced clique-width expression of clique-width or NLC-width at most $k \times 2^{k+1}$" The catch here is that the number of labels blows up exponentially in the balancing. It seems that for clique-width no better result is currently known. The same paper gives a similar result with only a constant blow-up for rankwidth, but this doesn't help, since the difference between clique-width and rankwidth can be exponential in the worst case. 

I can only give a partial answer to this question. A result by Lenstra (later improved by Kannan, and Frank and Tardos) states that ILP with $k$ variables can be solved in time $k^{O(k)}$ (times a polynomial in the size of the ILP). Therefore, ILP is in P when the number of variables is $O(\log n/\log\log n)$. I am not sure if a $2^{O(k)}$ algorithm is known, or if such an algorithm would contradict the ETH. I found this information in Daniel Lokshtanov's dissertation. Here are the relevant references. 

Given a CSP where all constraints have arity at most $q$ we want to distinguish between the case where everything is satisfiable and the case where at most $1/2^q$ fraction of the constraints are satisfiable, in polynomial time. Here is how this can be done. First, all predicates used in the CSP must have at least one satisfying assignment (otherwise we know that the instance is not perfectly satisfiable and we are done). If a used predicate has two or more satisfying assignments, then, if we take a random assignment for all variables some constraint is satisfied with probability at least $2/2^q>1/2^q$. Since all other constraints are satisfied with probability at least $1/2^q$, by linearity of expectations there exists an assignment that satisfies strictly more than $1/2^q$ fraction of the constraints and we are done in this case. Finally, suppose that all predicates used have exactly one satisfying assignment. Then the CSP is an instance of DNF-SAT, which can be decided in polynomial time (we only need to check if any two constraints have a conflict). 

So, in short, the question is, since QBF is PSPACE-complete for bounded pathwidth formulas, why isn't Geography PSPACE-complete for bounded pathwidth graphs? I think the problem with this hardness argument is that the reduction from QBF to Geography by Schaefer does not preserve the pathwidth/treewidth of the formula. The reason is that, in Schaefer's construction, the variables must be added in the graph in the order in which they are quantified, NOT the order of the path decomposition. Hence, you cannot (in an obvious way) guarantee that the resulting digraph has small (undirected) treewidth. 

Indeed this concept exists. Two vertices $u,v$ that have the same neighbors are often called twins. They are called true twins if they are also connected, and false twins otherwise. In your definition, all vertices of $X$ are true twins. It looks like there are several other names in the literature for these concepts. See e.g. this MO question. In FPT algorithms we sometimes call the number of twin classes into which a graph can be partitioned the neighborhood diversity of the graph, see e.g. here (warning: self-citation!), and here for the related notion of twin-cover. 

Treewidth plays an important role in FPT algorithms, in part because many problems are FPT parameterized by treewidth. A related, more restricted, notion is that of pathwidth. If a graph has pathwidth $k$, it also has treewidth at most $k$, while in the converse direction, treewidth $k$ only implies pathwidth at most $k\log n$ and this is tight. Given the above, one may expect that there may be a significant algorithmic advantage to graphs of bounded pathwidth. However, it seems that most problems which are FPT for one parameter are FPT for the other. I'm curious to know of any counter-examples to this, that is, problems which are "easy" for pathwidth but "hard" for treewidth. Let me mention that I was motivated to ask this question by running into a recent paper by Igor Razgon ("On OBDDs for CNFs of bounded treewidth", KR'14) which gave an example of a problem with a $2^{k}n$ solution when $k$ is the pathwidth and a (roughly) $n^k$ lower bound when $k$ is the treewidth. I am wondering if there exist other specimens with this behavior. Summary: Are there any examples of natural problems which are W-hard parameterized by treewidth but FPT parameterized by pathwidth? More broadly, are there examples of problems whose complexity is known/believed to be much better when parameterized by pathwidth instead of treewidth?