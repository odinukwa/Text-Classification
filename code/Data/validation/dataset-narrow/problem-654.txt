The above has the try-finally block that is common, it does not hide anything, so the concurrency-controls are all visible in a single place, and it is really not much longer than your existing code. 

Your binary tree setup does not appear to be well balanced.... and no, the counter is unnecessary. I think you have perhaps over-thought the process... If the data is pre-sorted, you can simply bifurcate your data in a recursive process. Your method is very close to what I would do, so copy/paste: 

Many of these constraints can be avoided or reduced if you store array data in a 2-dimensional structure. Each 'row' is a portion of the overall span. If each row has the same, fixed size, then the translation from the logical linear system, the matrix system, is: 

This sub-select is better because it can do an indexed lookup in the table in the sub-select based on the column. Apart from that, I don't see a better, or neater way to do it. 

Solution 1 This solution has the least issues with it, other than the manual copy from tmp to array. Again, use Insertion Sort This is a missing solution, and it has some value to it, even though it is not performance. The reason it is useful is because, in an actual sort, it can do more logic than just test evenness for each value. Consider this code: 

Going through some smaller items in your code. Your class is public, which is fine, but it should also be final. There is no reason for people to extend your class. The constructor should be private, and all the Map fields should be private as well, but you should have getters for those maps... , , etc. On the class, the method content should be merged in to the method, and that method should not be public either, assuming the background thread is defined in the same package as you. Restricting these permissions will make your application better defined. The remaining concern with your code is whether the Map instances themselves are Mutable (well, they are mutable, but should they be?). I would recommend making them readonly using Collections.unmodifiableMap() which will prevent the actual Map content from becoming corrupted by some thread polluting the data. 

I am a fan of using primitives. In this case, the performance benefit would be minimal, but the number of copies would actually be less..... In reality, I would probably use the approach similar to what other answers have given (+1 to them all), but you should be aware that the following code is likely faster, has fewer iterations through the loop, and will scale better..... if you ever need to make millions of copies... ;-) (now here with a cheesy test case in ideone too) 

but, the actual exception may be , which is a subclass of SQLException. Using to match the exceptions is a problem.... you should use: 

200_success and DJanssens both make good points. I want to add that, again, Regular Expressions are often useful for text manipulation. This work requires a complicated pattern if you want to keep the groups, but if you can ignore the groups, it is easier. Note also, that are also more efficient than String concatenation. Two traditional Java versions. One using a simple split, the other using a more complex one: Simple split 

In PostgreSQL, you can use the mechanism to help. It still requires a subselect, but consider the following query: 

The sum gives and indices act like a stack, and the depth is how deep the stack is (again, assume sorted data): 

Where is the Head pointer, and is the previous. We add the value to the HashMap, and advance our pointers: 

Your print-grid method would likely benefit from some Linq, but what you have is OK.... rather, it is very readable. Linq (or using a StringBuilder) will improve performance by reducing the calls to Write. 

That style of loop is needed because we modify the List while iterating over it (so the keeps on increasing). I hope that gives you some ideas. 

Then, have your loop, and, filter the records... But, let's get our aggregation system set up first, too.... 

I agree with other comments, your naming for the product methods as add and sum is very confusing.... 

Pairing combinations like this is a very common thing to do in any language. There's a very 'idiomatic' way to do this type of operation: 

As for all those conditions that are tested in the cascading blocks? Well, there's not much you can do about that. They are guard conditions. Your only option is to perhaps incorporate the cascade somewhere else, but all that does is shift the logic. I would live with it. It is clear, flows logically, and so on. 

You can easily test your real application/system with a simple (non-web-based) test factory your code is in distinct chunks, application layer, and data layer, and you don't need to change the application unless there are functionality changes.... 

Your code is, for the most part, consistently styled, and predictably structured, which is nice. I am not a fan of the comma-on-the-new-line style of continuation. I prefer the comma at the end. But, at least you are consistent with this. One inconsistency which I see is that for smaller selects you have multiple selected columns on a single line. 

This array represents the buttons that you check for a winning condition (except is only in here once ;-) ) Now, with the above structure, consider the following loop: 

I timed this method against yours for a few sizes of data here in ideone: $URL$ Note the timing results: 

and discovered that your code fails for . This is just bad form. The 'assignment' gave a whole bunch of positive and negative test cases, but you only chose to test the positive ones. That counts as 'half-a-job' when testing is concerned. It took me a few minutes to copy/paste the tests in and found what should be a 'fail-the-assignment' condition. Then I looked at your algorithm and figured it was 'failing' early tests too early... let me try to explain.... consider the following: 

Regex Yeah, yeah, the whole "use a regular expression, now you have two problems...." but, this concept is: 

Using the native features of Java is important. Consider the new-to-Java8 features of a streaming file-by-line reader: 

So, calling will return 1. returns 57. But, you can do crazy numbers now too, like is 53415676171057707 See this code running on ideone: Knights Note that you have now confirmed you are using Python 3.4. Python 3.1 introduced the method. This makes the determination of the power much easier (from a programming perspective - bitlength can be thought of as an implementation of the log2): 

loop until done is the pointer setup swappable? If yes, then swap them, reloop otherwise, bring the pointers one step closer to being swappable 

You know, Your code is good.... the algorithm is not the best, but the code is well presented, clear, and really, it's good. For an interview I would personally have ranked you as "good attention to detail, well structured, consistent, good". Then, I would have asked you why you chose the algorithm you used. let's break down your process: 

Now, you have a function which times how long it takes to get a complete response (or fail) from a server. Now, instead of having an infinite while-loop, have a non-daemon scheduled thread executor instead. Something like: 

scan all the characters again, and count the number of U characters before, and after the longest C sequence. O(n) Decide whether it is possible to contain the complete longest C sequence in the result. ..... from here it gets fuzzy, and I m not sure you can keep it to , but you get the idea. 

The above functions also do an in-order scan of the data. The difference is that the recursion is designed to go past the leaf node, and to treat the node as if it was the end of a duplicate streak. By doing it this way, and by pushing the duplicate-detecting values down with the recursion, you can detect the end-of-duplicates in a much easier pattern. I created a 'main method' that compares the above code with yours: 

Note that summing the values instead of finding the max, will be approximately equally efficient. In each case, you are going through all elements just once. Java 8 Notice, in Java 8, this would be a nice problem....: 

That pattern will find in the line, and remember whatever the is, in group 1. You can now convert each line in to a matcher, and filter those lines which match, and recall the database. Additionally, the Streaming API is able to terminate when the first match is found. The code would all look like: 

The equals method is a bit more complicated. Your code does appear to keep the hashCode/equals contract, so that is good, but, sometimes there are better ways than others to test for things. For example, often when you override hashCode and equals it is because these instances are used in a Set or Map. A shortcut is to often check for identity before checking for equality.... i.e. This can (often/sometimes) save a lot of internal processing to resolve equality. I have a template I tend to use for and it goes like this: 

Since your current zoom is consistently bound to 0 and 100, you can rely on bounding the difference only. See this running in ideone. 

try-with-resources You should become friends with this, it is nice. Your code closes and flushes the streams, which is good, but it would be better to let the system do it automatically.... Your code: 

would be sufficient to catch those people who inadvertently misunderstand the way your Runnable is supposed to work. The second problem I see in your code is the poor handling of the InterruptedException. At a minimum, you should re-set the interrupted flag when you log the message. Even if you don't know how to handle the exception, you should let someone who can handle it to do it. 

Short Answer Yes, I believe it will be functional.... Dubious Recursion Calling this method recursive is a problem. It is not a recursive method. Just because it is calling itself does not mean it is a recursive function. What you have is a bad loop. From Wikipedia: 

Now, we have a fast way to find any data record in for a given name. Using that structure becomes easy again, by looping for each of the values, and updating them based on the value that was indexed, if any. Loop for each record, search in the index, use the default if the index value was not found. To make the code a bit more flexible, and because the "column" names change from to , it helps to have a structure containing this column mapping: 

Your code here is pretty mixed up and is not representative of a decent test of concurrency. It will work and give you the results you expect, but the reason is a bit polluted. The internal code for looks like: 

So, that's a "simplified" version, how to make it faster? Well, there's a few things. First up, nothing can be for sure unless you test it, so, run some experiments. Things I would try: 

Right, now for the actual implementation.... using JMapper. Unfortunately there are some real concerns I have in here. DestinationClazz Do you have an actual class called DestinationClazz? I imagine not. I think this is supposed to be a generic type, but then you are not treating it like a normal type. For example, your class definition is: 

Note that the pattern includes the underscore. The second pattern contains two zero-length lookahead/lookbehind alternatives. With CamelCase, you split before the first Capital after a lower letter, and you also split before the capital before a lower-case letter (or end-of-word). Consider where we split before the H, and before the C of Case. These are marked by Transitions, one is from lower-to-upper, the other is from upper-to-lower. In each case, we split before the upper. Note, that is a regular expression identifier for all upper-case Unicode letters. The needs to be escaped in the String constant, so in the constant, you will see two patterns: and The first represents any upper-case character, the second represents any non-upper-case character (including digits, and other punctuation). So, there are two parts to the TRANSITION pattern: