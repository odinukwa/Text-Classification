I may be wrong, but I don't think this is possible unless you restrict access to the data to be via stored procedures - then the procedure can trigger audit mechanism that you can expose to the users. You would also need polling of the audit if both users need to be aware. 

They don't. The quoted text just explains why postgres needs to use modulo 231 arithmatic (which means transactions can wrap around as long as old transactions are 'frozen' early enough): 

There are more efficient ways of doing this if your employee table is large, but this is the way I find easiest to understand :) testbed: 

Oracle has Java server-side, but I'd caution that it is not a replacement for PL/SQL. There is no better language than PL/SQL for manipulating data stored in the database - Java may be appropriate for computationally intensive business logic. For postgres, 

So both relations are 'many:many'. As gbn also said, adding "comma separated ids" would be something of a disaster in database design: you would regret it many times over. 

-- edit As @Leigh has commented, an alternative, neater, approach is to have a single function concatenating the (modified) regexs: including the on the end in either case makes the ordering deterministic (repeatable) which might be a good thing even though the question doesn't specifically ask for it. 

InterBase version 6 was released under an open-source license in mid-2000, and was immediately forked to become the Firebird project. Later versions of InterBase reverted to closed-source and the projects have diverged. Both are still actively developed. Developer’s tools and libraries traditionally support both servers but they are growing apart. 

Apart from the traditional SUM(CASE), there are two other ways of getting this sort of PIVOT output. The first is using the PIVOT and UNPIVOT operators introduced in 11.1: 

I think of this as an esoteric variation of the "True Fractions" approach in that blog post — the advantage being that there is no need to introduce a user-defined type (at least if you are using Postgres). This works using the natural ordering properties of and mapping a sequence of them onto a binary tree such that it is always possible to generate another value between any two existing adjacent values: 

but assuming your table name is something different (which I highly recommended), the error returned indicates that the parser is interpreting as a column name: 

It isn't compressed (unless the string is long), it's just that for (unlike ) the length specifier is merely a constraint that determines the maximum length: 

Expand the rows in both tables for all the days in the month and join them together. Assign a 'group' to each series of rows where and don't change for a period (a "gaps and islands" problem). Group the results. 

results (timings should probably be taken with a pinch of salt but each query is run twice to counter any caching) first using the function we've written: 

If you create the index before loading the table, the time taken to load the data will be significantly increased. pre load: 

In a comment you explain that your motive is to have the convenience of not displaying the contents of columns with long content, rather than not displaying the column itself: 

Please take a look at $URL$ When you include the nested table it is like a join, so if you want a single row per customer, you will need to do some sort of unpivot (note that there could be more than two phone numbers in the nested table — Oracle needs to know how many columns to return. This will return all the rows: 

You will find that is a great deal faster because it does a tiny fraction of the IO that does. Of course if the data isn't evenly distributed it will cause the result to be less accurate, but this can be more than offset by increasing the sample size. …but… 

However I tried and failed to get the RTM Linux version of 2017 installed on Debian Stretch, ultimately using Ubuntu. 

COUNT(expr) will count the number of rows where expr is not null, which can be used to figure out which groups have any nulls: 

This seems to be a quirk of SQL*Plus and rather than pipelined functions - the following demonstrates the same effect: 

I would suggest, as others have done, that using UUID is much better (ie much less error-prone) than inventing a new UUID-lite. I still don't think it is your best bet however — you aren't sharding so there is no actual need to have non-overlapping IDs between deployments that I can see from the information you have provided. Presumably you have other ways of identifying a deployment in a database than looking at IDs in these tables. 

You can use the windowing function and divide by three to group the rows into 3s, perhaps like this: testbed: 

Based on this statement, I am assuming that an Employee and a Project are permanently tied to a Division. In which case you should consider using a composite key for the PK: 

or just : waits for all sessions to disconnect. This mode is rarely used in practice because it relies on well-behaved clients not leaving connections open. This used to be the only mode that did not cancel running transactions. : disconnects sessions once currently running transactions complete, preventing new transactions from beginning. : disconnects all sessions immedately and rolls back interrupted transactions before shutting down. Note that the disconnections are immediate, but the shutdown may not be as any interrupted transactions may take time to roll back. 

and the like this will even apply to tables created after the was made - it gives a database privilege As you also want to you will also need to 

If by 'compatible' you mean 'certified by Oracle', I think you'll need to go back to SQL Developer 1.5: 

I vote for option 1. Bear in mind that RAID 0 means "no protection" - do your logs matter? (yes they do). It also has the benefit of simplicity The SQL Server docs say: 

Check constraints are ignored in MySQL so we have to consider or as false and as true. At most 1 row can have You may consider it an improvement to add a trigger to change into on insert/update as a workaround for the lack of a check constraint - IMO it isn't an improvement though. I hoped to be able to use a char(0) because it 

edit: A change to the documentation has apparently been comitted but isn't yet showing in the 9.4 docs 

When vacuum runs, does it efficiently free the space occupied by the deleted rows by rewriting the entire block, or does block fragmentation occur with new rows fitting into available 'holes' only if they are smaller than the deleted row that has made way for them? 

Yes, certainly, assuming your controlfile and spfile are in ASM too and therefore survive the failure intact. This is the kind of thing you need to test in your own environment to give confidence you will be able to pull it off for real when disaster strikes - there really is no substitute for testing your DR procedures to make sure you are not making any invalid assumptions such as: 

No, procedures that read data from the database are also generally non-deterministic (because that data might change between calls)