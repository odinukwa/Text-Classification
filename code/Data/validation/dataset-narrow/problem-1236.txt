Representing boolean functions by polynomials or rational functions either perfectly or approximately is an important topic while polynomials and rational functions is the body of algebraic geometry. Why is algebraic geometry not that applicable to this area of complexity theory? Or atleast what are some of the important papers in representing boolean functions that uses algebraic geometry? 

Supposing we have a linear equation in $n^2$ variables with integer (negatives allowed) coefficients of at most $m$ bits each. Partition $\Pi_1$ the variables into $n$ disjoint sets of $n$ variables each. Make another partition $\Pi_2$ the following way. Pick $1$ variable in every disjoint set of variables in $\Pi_1$ form a new subset of variable of size $n$. Pick $1$ variable in every disjoint set of variables in $\Pi_1$ not picked before to form a new subset of variable of size $n$. So we have another disjoint partition into $n$ disjoint sets of $n$ variables each. (1a) Is it $\mathsf{NP}$-complete to decide if there is a valid (valid here means vanishing) $0/1$ assignment with exactly $n$ of assignments to be $1$ with exactly $1$ assignment per disjoint set? (1b) Is it $\mathsf{NP}$-complete to decide if there is a valid (valid here means vanishing) $0/1$ assignment that satisfies exactly $n$ of assignments to be $1$ with exactly $1$ assignment per disjoint set $\Pi_1$ AND with exactly $1$ assignment per disjoint set $\Pi_2$? Does subset sum reduce to both of these? What is a good reduction from any $\mathsf{NP}$-complete problem? It seems to me that the problem (1a) and (1b) qualify as some restricted version of $n$-sum problems. This seems to imply problem is $\mathsf{NP}$-complete. That is it is likely that some special case of $n$-sum reduces to these problems. Since $n$ is a function of number of variables $n^2$ are these problems $\mathsf{NP}$-complete? 

I am essentially asking if the polytope is reasonably round what is the difficulty of counting and decision problems. Here for quantifying roundedness I use width and max distance (but may be some other quantification which I do not know may be appropriate). I think some strange partition of 0/1 cube with convex faces might suffice for 1. 

Let $x$ and $y$ be two $n$-bit numbers. Is the computational complexity of adding $x$ and $y$ strictly smaller than multiplying $x$ and $y$ upto multiplicative and additive constants? 

In the communication complexity model Disjointness and its complement are candidate $coNP^{cc}$ and $NP^{cc}$ problems. I am tempted to say $AND$ of disjointness functions is a candidate for second level but that seems to have some trouble since there is at least one variable in first disjoint function different from other and somehow that seems artificial and am not sure. It might be I can non-trivially permute the variables and $AND$ permuted disjointness functions and that reuses variables. What is the essential difficulty here in generalizing disjointness functions? Also I can take $2^{O(\log^cn)}$ different $coNP$ (not necessarily disjoint) functions in same variables and $AND$ them together. This will give a function at second level and iterating the process will give higher level functions. This process seems legitimate. 

Is there a place to locate the reference "[Smi88] D. V. Smirnov, ``Shannon's Information Methods for Lower Bounds for Probabilistic Communication Complexity,'' Master's thesis, Moscow University, 1988" mentioned in this paper $URL$ 

What is the relation between number $0$-monochromatic rectangles in characteristic matrix and communication complexity? What is the relation between number $1$-monochromatic rectangles in characteristic matrix and communication complexity? Precisely how does this connect to logrank conjecture? Is the number of $0$-monochromatic rectangles always almost same as $1$-monchromatic rectangles? 

Unique Games results provide very interesting barriers to results through semidefinite programming. Lovasz theta ($\vartheta(G)$) function is an incarnation of SDP. Is UG conjecture true $\iff \vartheta(G)$ is best approximation number for independence number $\alpha(G)$ of classes of graphs whose $\alpha(G)$ computation do not have efficient procedure if $P\neq NP$? (I am adding $P\neq NP$ to avoid cases where other techniques such as Haemer's Bound gives better approximation). 

Is P=BPP necessary to derandomize Vazirani-Valiant reduction? If not what would derandomizing Vazirani-Valiant reduction tell about P=BPP? 

We know from here that permanent of $0/1$ matrix modulo $2^t$ is in $DTIME(n^{t+3})$ and hence in $P$. My question is whether permanent of $0/1$ matrix modulo $2^t$ is in $L$ as well or is the current best algorithm outside $NL$? Suppose deciding if permanent of $\{0,1\}$ matrices is greater than $r\in\Bbb R$ has a $BPP$ algorithm which uses only logarithmic space then is there a name for the complexity class of such a situation? Clearly it cannot be $BPP\cap L$ since $BPP\cap L=L$ would mean $PP=L$ ands the algorithm is deterministic which it clearly is not? 

Does $BPP^{NP}\subseteq\Sigma_k^P\cap P/poly^{NP}\subseteq BPP^{\oplus P}$ hold at some $3\leq k$? Also is $BPP^{BPP^{\oplus P}}\subseteq BPP^{\oplus P}$ known? 

can we compute determinant in a class smaller than $NC^2$? can we compute determinant in $O(n)$ arithmetic operations? if each entry is in $\{0,\pm1\}$ can we compute determinant in $O(n)$ bit operations? 

Deciding Graph Homomorphism is in general NP-Complete. Are there any results which study this problem when the underlying graphs have algebraic structure (such as deciding homomorphisms from Cayley or Cayley coset graphs to other graphs with some definite structure as well)? In addition complexity results I am also interested in helpful algebraic and/or spectral techniques. 

Let $x_1,x_2,\dots x_n$ be literals. Let $P(x_1,x_2,\dots,x_n)$ be one of the following Boolean function: $0)$ Equality function - $Eq_k^n(x)=1\iff x_1+\dots+x_n= k$ $1)$ Threshold function - $Th_k^n(x)=1\iff x_1+\dots+x_n\ge k$ $2)$ Majority function - $Maj_n(x)=1\iff x_1+\dots+x_n\ge \lceil\frac{n}{2}\rceil$ $3)$ Modular-$s$ function - $MOD_k(s)=s\iff x_1+\dots+x_n\equiv 0\mod k$ If a function 'represents' $P(x_1,x_2,\dots,x_n)$, that means the function and $P(x_1,x_2,\dots,x_n)$ agree on $x_i\in\{0,1\}$. If a function is rational then its degree is the sum of degrees of numerator and denominator. What is known about the smallest degree of a: $A)$ polynomial $p(x_1,x_2,\dots,x_n)\in\mathbb R[x_1,x_2,\dots,x_n]$ $B)$ rational function $r(x_1,x_2,\dots,x_n)\in\mathbb R(x_1,x_2,\dots,x_n)$ that represents $P(x_1,x_2,\dots,x_n)$ in each case of $0,1,2$ and $3$? In which case the gap is the largest? It seems intuitively that $2,3$ should be the most complex with possibly the largest gap for $3$. Note that both the polynomial and the numerator and denominator of the rational function can be multilinear since $x_i^t=x_i$ on $\{0,1\}$. 

We know that using FFT we can compute multiplication of an $a$ bit number with a $b$ bit number in $(a+b)^{1+\epsilon}$ time. My question is supposing we want to compute $A\bmod B$ where $A$ is an $a=f(b)$ bit number for some linear function of $b$ with $B$ a $b$ bit number, what is the time and space complexity of such an operation? Could it be done in fully linear ($O(a+b)$) time and space complexity (at least assuming $B$ is fixed per $b$ bits and $A$ is input)? I have been unable to find such a reference or procedure for this operation even when $B$ is fixed (which is the case useful in operations such as Diffie Hellman key exchange).