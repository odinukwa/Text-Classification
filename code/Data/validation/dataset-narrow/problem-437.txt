Stream vs Loop The main problem I see with a stream based approach is (besides the overhead of the streams), that it is more difficult to optimize compared to a loop approach as the abstraction level is higher. For example converting the implementation to a parallel approach is in my opinion way more complicated with a stream approach. Algorithm improvements (not directly related to the question) You can use a (or directly a // array) to ensure that each entry in the sieve consumes only one bit (instead of currently (likely) 8). You are storing all values from to in the sieve, you can save memory by skipping multiples of (and , , ...) at the cost of some additional calculations to convert between sieve position and value. For larger values of it might be advantageous to divide the sieving process in smaller steps and use a small array instead of a large array for all values and sieving the complete range at once. The sieving process can be converted to a parallel implementation with nearly linear speedup as two or more values can be sieved simultaneously (sieving process of each value is independent from other values). Approx. performance for , included my implementation (which utilizes most of the improvements mentioned above) as reference value: 

First and foremost, Phyton is not my language of choice (or in other words, I don't know it at all), so I'm just trying to add something regardless of the language. Yes, you would benefit a lot from multithreading here, it's quite a basic case. I give for granted that Phyton does nothing to complicate using of multiple thread, obviously, because doing multithreading itself is cheese task even when using the basic OS APIs. As a general rule of thumb, unless you are dealing with a really fast computation where the additional overhead added by threading will worsen the performances, there is no point in not using parallelism everywhere. It's one of the easiest things to do in computer programming, and it allows you to "choke" the hardware to the point that no matter what, you are granted to be going as fast as the PC allows. 

(I would initialize with a ternary operator instead.) Types As the values of , and are always in the range , you can use instead of for these variables, arithmetic is likely to be faster than arithmetic. Alternative implementation The remaining range is quite small -> you could cache the results for every number in the range to avoid calculating the sum on each invocation. 

You can use the method to require only one lookup for most map implementations (esp. important for concurrent maps that may contain values to ensure reliable results). 

Besides that could (and should) be a local variable. The spacing between operators is inconsistent, you should add whitespace around the operators (except for unary operators) to improve readability. 

because I have no idea how you instanced and set the dm object before, and you need to do the same here; I just added a generic call to the constructor to help you understand. Another big warning: you need to understand multithread programming, otherwise this code will sooner or later blow up in your face. Usually in the worst possible moment. 

It's just 6 milliseconds for each barcode, including save to disk: it's not that slow at the end of day, and you have a custom library doing most of the job, so that means that you really have to squeeze every single possible fraction of millisecond. In every loop you already know the size of the final string (just add the length of each single part of if), so when instancing the StringBuilder use that number to set the initial capacity. Or, just in case, set it to the maximum possible string length and see what's faster. Use a parallel for. If this thing is running on an average working PC, let's say an 8 cores, going from 6ms to 1ms could be a plausible scenario. Even taking into account that you need to instance a new encoder for each barcode, I'd say that it's realistic to at least expect the final time to go down to an half, even a third. Give proper names to loop variables. 

If you need to take ownership of a pointer, use /. C++14 adds , but you can use it C++11. Note - Don't add make_unique to like shown in the linked answer. DRY (don't repeat yourself) up your and . The two statement bodies for each function essentially does the same work. In , you trade away a pointer copy for a branch. 

You can simplify this problem by filtering/partitioning any non-positive value from the array. Once you have a filtered array of positive integers, you can use the filtered length to determine the upper-bound of the lowest positive integer. For a distinct sequence of integers \$D = [1, 2, 3, ..., n]\$, the lowest positive integer is guaranteed to be \$n+1\$. If you remove any value from \$D\$ and replace it with any other value (or simply remove it), then the lowest positive integer of \$D\$ is in the range \$[1, n]\$. To find it, we can simply track integers in a boolean table, upto \$n\$, marking the ones witnessed. A linear search of the boolean array for the first unmarked entry will give us a zero-based index of the lowest positive integer missing. Add one to make it one-based once again. Filtering, marking witnesses, and searching are all linear operations. Note - Since you know the upper-bound, you can narrow your range further by making a second filter pass which removes any elements larger than the array length. Would help with data locality if you have smallish arrays loaded with largish values. While using a boolean array does meet your space complexity requirement, a constant space solution does exist. Remember that every element in your filtered array is positive, so we can repurpose the sign bit of each value as a signal that we've witnessed a value of the sequence. We can use the indices of the filtered array the same way we did the boolean array above. Rather than search for the first element marked false (unwitnessed), we search for the first value that is still positive. 

MyWord Your / implementation is not conform with the specification of - equal objects can currently return different hash codes. The implementation of should return the hash code of instead of . The constructor performs no argument checks -> it is possible to create i.e. an instance with , which will lead to s thrown by the method. The method could return . Alternative implementation A priority queue is not a good data structure to determine the frequencies as you have to iterate the queue for each input element. You can use a to convert the input array to the frequencies with complexity (plus additional to sort the resulting frequencies, or to create a heap). Using the stream api this could be written as: 

The content of the Parallel.For will be executed in multithread, so you need a unique instance of every variable you modify and for every class you call a method of, so keep an eye on the 

So, one of the thing here is that the CPU is waiting for your hard disk to provide data, and then the hard disk is waiting for the CPU to ask for something. The first and more obvious point is that accessing disk to get a few bytes each time is terribly inefficient: disks (HDD or SDD is the same, in this case) are best for sustained reading. The OS cache will help you so that it will read a bunch of data ahead for every request you make, but you know you are going through the entire file so you shouldn't rely on the cache and try to be as efficient as possible in your code. In fact, as rolfl points out 

Currently each future processes elements (increasing the increases the total workload ()). Instead you want to divide the workload between each of the futures: 

In the array version you can use post/pre increment and pre decrement (most likely no difference in terms of performance but shorter and in my opinion better readable). 

generateValue The conversion to and from strings slows your method down, bitshifts are more appropiate ( returns the same result). As @Piers Williams already stated, an iterative approach is preferable. A possible implementation: 

In my opinion returning an is the best option as the method requires ints, anything else would imply additional conversions. 

Runtime improvement If you take a look at the last digit of the first few fibonacci numbers you will see that the digits are repeated after 60 numbers. As the digits in this range have a sum of you can calculate the sum for instead. Bug The task states that the given integer are non-negative, is a valid value. Currently you are returning i.e. for the range as is treated as , the initialization of sum has to be changed to: