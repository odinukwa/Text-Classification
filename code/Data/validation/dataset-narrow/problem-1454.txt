I have some existing code which does catmull-rom interpolation on two vectors (facing and up). I'm converting this to use quaternions instead (to replace the two vectors). Is there a general way to convert the vector based interpolation to a quaternion one? The approach I'm using now is to exact the axis and angle from the quanternion. I then interpolate each of those independently and convert back to a quaternion. Is there a more direct method? 

I'm trying to do a blur on a texture with an alpha channel. Using a typical approach (two-pass, gaussian weighting) I end up with a very dark blur. The reason is because the blurring does not properly account for the alpha channel. It happily blurs in the invisible part of the image, whcih happens to be black, and thus results in a very dark blur. Is there a technique to blur that properly accounts for the alpha channel? 

I've recently started with mobile programming (cross-platform, also with desktop) and am encountering wildly differing hardware performance, in particular with OpenGL and the GPU. I know I'll basically have to adjust my rendering code but I'm uncertain of how to detect performance and what reasonable default settings are. I notice that certain shader functions are basically free in a desktop implemenation but can be unusable in a mobile device. The problem is I have no way of knowing what features will cause what performance issues on all the devices. So my first issue is that even if I allow configuring options I'm uncertain of which options I have to make configurable. I'm wondering also wheher one just writes one very configurable pipeline, or whether I should have 2 distinct options (high/low). I'm also unsure of where to set the default. If I set to the poorest performer the graphics will be so minimal that any user with a modern device would dismiss the game. If I set them even at some moderate point, the low end devices will basically become a slide-show. I was thinking perhaps that I just run some benchmarks when the user first installs and randomly guess what works, but I've not see a game do this before. 

I have some code that rotates an object around an axis. It does this by creating a quaternion for a rotation and then multiplying by the old orientation: 

Quaternions, when converting to rotation matrices, can be treated as either left-handed or right handed. One rotates in one direction, and obviously the other in the opposite direction. If you mix formulas from different sources you will often find the results don't always line up -- though one would hope if using only equations from one source it'd be consistent. So in short, this is a typical issue that arises. It is a matter of interpretation and neither result is more correct, just perhaps not consistent in your system. Either take the time to make all your formulas line up (which is often non-trivial), or simply negate the angle if you want something quick. 

I found a C++ library that contains the intersection code I want. It looks reasonably well commented so I can follow what is happening. 

This need to create the rotation quaternion each time seems like it may be redundant. Is it possible to somehow create a quaternion and somehow apply to it? That is I would prefer code like this: 

You start at block 0, which we give value 4 (random number) To walk right we get delta X+1 = 1 You are now at Block 1 with a value 4+1 = 5 Right again, Block 2 with a value 5-1 = 4 Right again, Block 3 with a value 4+0 = 4 Walk left, delta X = -1 You are now at Block 2 with a value 4-(-1) = 5 Left again, Block 1 with a value 5-1 = 4 Left again, Block 0 with a value 4-0 = 4 

Given some event in a game, what is the maximum delay to producing audio that the player will properly associate the audio with that event (and not perceive lag)? 

Disconnect the rendering from the world and you can do wraparound and correct rendering without resorting to any cloning or teleporting artifacts. First, in your world you have a fixed size world, from to . Anytime an object goes below 0 you wrap it to the end, and anytime an object is over wrap it to the start. This means that all logical objects in your world are always within the range . Second, for rendering you'll do modulo on the position. So the left side of the screen is "Base" and the right side is "Base + Size". So you look through your world for anything within that range. You'll actually search for the modulo range, which maps it back to . The trick while searching is to return the object's position relative to the on the left side. This converts to local coordinates of the screen so the renderer itself doesn't have to worry about the modulo, only the lookup does. You don't need to clone anything since each renderer only deals with the object in one location. If your world is produced in segments, or using 3D structures, you'll have to segment it. Thus it isn't one consitunous block, but can be moved to accomodate this rendering. You don't need many blocks, at a minimum 2. 

In this way I can store in my object and simply apply it partially on each time step. I know that if I apply twice, it would be like doulbing the ellapsed time. So I'm guessing I might want some kind of quaternion exponentation. Is this a define op? More importantly, is its performance still acceptable (or faster) than creating from an axis/angle each time? 

I don't recall where I saw the demo but I think I know what he is talking about -- or at least can provide related information. The problem with the character not moving on the screen, being fixed at the center, is that the human player will not perceive any motion. The user will immediately feel that something is wrong, but perhaps not be able to pinpoint it. If the character is moving it is essential that some kind of actual motion is done. One of the concepts used here is the player box. This is a region of the screen where the character always resides. Unlike a fixed location however the character can actually move all around in this box. The screen only starts to scroll as they approach the edge of the box. This means that each time the user changes directions they'll actually see their sprite move on the screen (regardless of what the background is doing). From here you can start improving the effect by experimenting. Some games slowly center the character in the box again. Some have a kind of logrithmic box so that the first movements move the sprite a lot, but less and less as they get to the side of the box -- or this may be tied to the character's speed as well. What works well depends on your game, and by no means is there a definitive "best" solution. 

It looks like you might be asking two different questions, so I'll answer them each separately (though one may influence the other). Taking Time: What you want is that the battle actually executes over a longer period of time, rather than just as quickly as can be calculated. This gives the user the impression that something is actually hapenning and allows them to change their orders during the battle. Here a timeslicing approach makes sense. Presumable you will be hosting several battles on the same server, so you'd probably need to do this anyway. In this approach each of your active games represents an object on the server. Now your server will poll each active game at a fixed interval. Say every 30s: you can adjust upward to lower total load and downward to improve user real-time feedback. Each interval you will simply step each active game by 30s (scaled to the world time). Calculations: Trying to represent 10000 units as 10000 objects is simply not going to be possible. Perhaps if you write in C++ and have a very optmized algorithm you could do it, but you still wouldn't be able to support many active games on one server. Instead what strategy games tend to do is lump together units into groups. So you have 500 rifleman, 2500 infinitry, 20 artillery, etc. That is, reduce your battle to a small number of actual objectds. These cumulative objects can then fight each other in turn. In the simplest model, say for infinitry, you could simply multiple per unit HP times the number of units to get one virtual infinity unit with a really high HP, and also a really high firing power. This is perhaps not ideal, but it is a decent logical starting point. Here you don't really do pure die roling anymore, you'll be using statistical projections (easier than it sounds). So if each unit has only a 10% chance to hit, the logical group will simply do 10% of its total damage each round. Again, simplified, but gives you the basic idea. 

If I understand your question correctly you'd like that each block be random, but blocks beside each other are related. In terms of a game, the sequence of rooms is random, but neighbouring rooms have to be compatible in some way. Going right isn't a problem since you have the current room and can easily apply the contsraint to the next room. Going left is a problem since you can't be certain which room was there. Instead of trying to generate a specific block number instead think about the transitions between the blocks. Your random generator will produce a transition delta between the rooms. The delta value for a given block will be random, but based on a fixed seed (thus constant for a particular game). You then apply this delta to the player's current room number to get the new block. If you are going right you add the delta, and if going left your subtract the delta. That is, you are currently in Block with a value of . Let's say the left-delta of block uses as a seed and the right transitions uses . To go right you calculate the transition of and add it to . To go left you calculate the delta at and subtract it from . An example with values, say the delta values are [ 0, 1, -1, 0 ].