Should you write a 'real' parser? - Depends. Parsers can be complicated, and they make assumptions. Regardless, you have already written your own parser, and it is 'real'. This is the BIG question... is it right? - With regexes it is often hard to tell, and it requires careful analysis of the regex and the data to find out. I have looked at your code, and inspected the regex, and, frankly, it was more complicated than I could easily understand in one sitting.... (and without 'playing' with the code). So, is it right? I don't know. Are the regexes too complicated (can they be simplified)? - yes, I would say yes to being too complicated, and unsure about whether they can be simplified. Other suggestions? - yes, a few.... which leads on to: 

That runs the benchmark on both your function, and the Scanner function, and does a warmup run (to get JIT optimzations done), and a "Final" run to get real results.... what are the results, you ask? 

Note, I have tried to continue using your all-caps keywords.... despite myself ;-) Hmmm, some aditional notes: 

Still, the most reliable way to break the MD5 algorithm (assuming an unsalted password), is to use rainbow tables. These rainbow tables are databases of MD5 values, and the input texts that produce those MD5s. In other words, it is a reverse-lookup for a password. Rainbow tables answer the question "what password would create the MD5 abcxxx...xxx?" Various groups of people have published rainbow tables, and you can search for them. Typical tables are based on calculating the MD5 sum for common passwords. They are typically a few hundred gigabytes in size. Remember, there are far fewer 'typical' passwords than there are possible MD5 sums.... It has taken many people a number of years to build these tables, so you are leveraging the work of others to help solve your problems. Some of the tables are available as web-services. In other words, you can just query an online database for common passwords that produce a specific MD5 sum. If the tables are comprehensive enough (have the right coverage of typical passwords), it is typically reasonable to expect a solution in a few seconds or so. Note: after reading up on hashcat, it is apparent that it is not a brute-force tool, it is a calculation algorithm that exploits weaknesses in MD5. Additionally, it can also leverage the performance capabilities of GPU accelerators. While 28,000 brute-force calculations per second is not great, the 2.2billion reported by hashcat is not an apples-to-apples comparison. 

This is almost three times faster than your version for the fromString, and another 0.2-times faster than your toString. Here is the code that is (in my experience) about as fast as you can get with Java: 

There is no need for the array-of-Integer to count the number of values in each line. By putting the complexity of the generic types in the static method generics declaration area, the actual parameter has the simple type . 

You should never use variable names like . This is too easy to confuse with . While it is tempting to use such things, and it is the same reason the language designers chose to use , I much prefer names like: 

I had a general review primed up for this question, but other answers beat me to those more general aspects. @TheKittyKat provided a good starting point on the most efficient means of calculating the sum of each sequence, and then subtracting the double-count Now, the solution @TheKittyKat provides for each sequence, is, for example: 

Note that I have stripped out your InterruptException handling. It was not sufficient for "real" code, and if you replace it, should probably go outside the calls. If someone interrupts your code, continuing in a loop is probably not the right thing to do. 

In your case, you have three parameters, the , , and for the car. These things can't be changed after the Car is built. You want a Car that has , but not . The non-builder way to do this would be to have a single constructor that takes all the parameters: 

By performing only two scans through the file (the first is a full scan, the second is an in-order-but-random-and-selective scan) you reduce the amount of times you process the data. In your current system, you are scanning the file many times (once and then an additional one for each KEY_FRAME record and an additional one again for each second...). The loops you have at the end are very costly: 

Then, create an implementation of the factory for the current version of the web site (because you will need a new version when it changes). OK, so now you have a simple factory implementation for the data interface. The benefits of this are: 

Your Version as IntStream I have removed the code that's not relevant (including the ) Problem2IntStream.java 

That is a system for recursively calculating the value at a given row/column (assuming valid input). It does a fair number or recalculations, but the point is that it solves the problem as stated. 

So, I recommend you create a 'HTMLScheduleFactory', and that HTMLScheduleFactory has a special configuration file for each version of your source-page formats. That configuration file tells the HTMLScheduleFactory where in the HTML to locate all the things you may need. Conclusion I recommend that: 

Note the creation of the WaitGroup and the killer channel that allows you to capture the no-solution condition, and the early solution killer. Also note the different mechanism for creating the closure. I am not recommending one way vs. the other, but creating the variables in the inside scope like allows you to access inside the goroutine without worrying about the scope, just like a parameter-based closure function. The recursive function is simplified with the loop, but more complicated by the killer process: 

Now, whether you are marked on that, or not, is a different story. I have found that the academic application of marks for comments is often contrary to the need for comments... particularly when the code is good code. Good code seldom needs comments. let me say that again. 

Use Attributes. Atributes are a convenient storage system, and don't have the same white-space uncertainties as element content. I would convert all your current text-based values to attributes (and I would also incorporate the quantity as suggested by Pimgd): 

and you will still get the echo, you will get the new error handling, and you will handle spaces in names just fine. 

With the above stack, you should not need any casts from to Simplifications Now, looking at some other parts of your code, let's simplify... Chained constructors: whenever possible, have just one constructor that "does stuff" for your class, and have your other constructors call the main one. Your constructors look like: 

Results Running the two code chunks above, as well as your code chunk, for a number of iunput values ("foo", "bananas", and "supercali......"), with a number of test values (including the input value itself), and then benchmarking the results (using Microbench ), I get: Your code: small, medium, large (microseconds) - 0.24, 0.5, 1.2 

Try-with-resources are a great way to isolate and also nest exception handling. In your case, a nested try-catch would be best. Additionally, a function to handle returning the error-state to the client would help a lot too. Consider the following: 

I have spent a couple of hours struggling with a bit of a performance mystery, but, the long and short of it is that I have essentially produced a manual stack in C, and made it generic for the use-case you are investigating. The mystery is that compiling with: 

To me, this means that, for this type of CPU-intensive work, the overhead of the streams is still significant. It is essentially 5 times faster than your code, and 3 times faster than the fastest Streams alternative. This problem is a tiny problem though... the computations are really small, and the method overhead of the streams will be the bulk of the runtime. I don't know where the performance/usability curve will cross from being 'wasteful' to 'useful', but, it is not useful for this problem. Also, because I am new to this, the standard Java is more readable ;-) The Framework I took the liberty of playing with your framework. This is what it looks like now in my environment: Problem.java 

If someone were to say: what would your function do? For a start, it will end up with an array of a very, very large size.... that can't be right.... ... next, computers are binary machines, and binary numbers are powers of 2.... there has to be a way for the base infrastructure to make that easier? Well, there is. When written in binary, these are the first few powers of 2: 

This uses a Go slice as a queue, shifting the value from the front of the queue, and adding another value to the end of the queue. A trick is computing the two values "ahead" instead of the two values "before" the "current" item. This allows you to have simpler logic for the first and second results (but at the expense of calculating a single value you will never use). See this running in the playground 

Then your overall complexity will drop to O(pc log p) because that part of the complexity will bcome dominant. 

Note that the in-place process does not simply overwrite the input file. It creates a new file to put the output in, and then, when it's complete, it renames the new file over the input file (which is a safe, atomic operation which can't fail part way through). 

Edit 2. 'Obviously', what I suggest you do is not necessarily the best thing. Your code was working fine, and the mechanism will be faster (slightly) than mine because it does not do the additional 4 processes and keeps the logic inside bash internal commands. Here is my 'shift' system applied to your code: 

Your code is somewhat hypothetical, in the example you give, it is 0 * 0, which will be pretty fast.... Still, let's put things in to perspective. You are performing 10 million loops in 1.5 seconds. A modern Intel CPU runs at 3.9GHz. In 1.5 seconds, that's about 6billion cycles (5.85 billion or so). about 6 billion cycles for 10 million loops is about 600 cycles per loop. Now, in that loop, you are: 

But, does not mean array length, it means "end-exclusive", or "ignore-from" or something. One of the common tricks in the quickSort is to use the actual index of the last element in the partition, instead of the length. For example, you call the method with: 

Your friend is right, and there's ways to parameterize the code to make it more useful. Consider three things: 

There are a number of concerns I have here, some of them style related, but mostly about the actual functionality.... mounts and may not necessarily be actual mount points. You should first check to see whether it is a mount point before testing it. This is because it may inaccurately reflect the space if it is not actually a mount. Additionally, it is (remotely) possible that, even if it is normally a mount point, that the partition may be unmounted too, but that's a remote problem. The program is a useful one for identifying whether a folder is in fact a mountpoint. It returns a useful exit code (0 if it is). 

There are a few things that stand out to me immediately in your code. Some good, some are troubling. Style First up, your code is neat, and well structured. Indentation is good, and I even appreciate the fact that you have braced 1-liners and got the space right in your expressions. Traditionally, C puts the open brace on the new line.... I am not a fan of that, but I don't write C very often, so I stick with a style I use in Java. Just thought I would point that out, though. Sorting Your sort algorithm is ... basic, but effective. I would agree that it is a problem. As a suggestion, you should use an insertion sort, and do the sort at the same time as the . That way you load the data in an always-sorted way: 

You can see this running here in your forked code. In theory, this will turn your code from an \$O(n \times m)\$ operation to become an \$O(n + m)\$ one, where \$n\$ and \$m\$ are the sizes of the two arrays. 

At some point everyone ends up trying to parse HTML. And, in some of those cases, it is even unavoidable...... ... but, some suggestions (in order or preference): 

performance review of SQL code without knowing the cardinality of the data, and the indexes used, is a real challenge, but, I would recommend that you try two things: first, try make table a top-level item in the Join: 

There, now Node is self contained, immutable, and generic. It can contain any object type, just specify the type you want when you construct it, for example: 

identify how large the list normally are. benchmark the code as it is. focus first on the PHP. How much time is taken sorting the data for the in clause. benchmark the SQL query using values that are randomly sorted, and compare it to queries with ordered values. 

Summing, not max I believe the better solution to this problem would be to sum all the values from each array, and then to compute the ratio afterwards. The math is simple. If you have the two data arrays and the corresponding set where you know that is some factor times larger, then you have: 

One of the tenets fo SOLID programming (the first one, in fact) is that classes should have a single responsibility. Here you have a class which has two distinct functions: view a card ; edit a card. The code complexity you have introduced just to differentiate between the uses of your class is more than the complexity of what you would have if you had two classes. Your instinct is right, you are not doing this the right way. In this particular case, I would recommend copy/pasting the class, and making each version a specialization for either View or Edit. The and should instead be incorporated in to the method. The logic can be split quite simply as well. What is nice about this is that the code becomes much more reusable... you can have the two specialized classes, and adding a new way to access the Activity (swiping '>next', etc.) would be much easier to do.