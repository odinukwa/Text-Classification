Also make sure your method has a quick abort. Just do a real quick bounding box overlap test and see if there is a collision and if it's worth finding the exact point of impact. 

Have it make a list of tiles as it progresses. If a neighboring tile is outside the bounds of your grid, then that entire region is not bounded by the brown tiles, and can be ignored. 

This also requires that you use s instead of s. The styling of the toggle can be made to match that of your buttons now. 

The three color channels are increased over time, leading to a white color. It looks like some of the particles don't have a chance to change color before they disappear, making the edges colored. The writing demo source is available here. And the entire source here. 

Turn when colliding with the object. This is the easier form, since it can use the existing collision detection and response code to add some steering. Turn before colliding with the object. This is a little more advanced where the characters need to test the position where they're going to be soon. When an obstacle is detected in that forward position, the character turns (hopefully avoiding a collision altogether). 

The player class should have a and a . If the is flagged as , then any attempts to change are applied to and the is set to not repeat. Then, when the ends, will take its place. 

Luckily, the project is opensource. That includes the demos used to create the videos. So we can see from the demo source: 

Well, I'm pretty sure, the fragment shader doesn't have a concept of a mesh. I'm mostly sure the vertex shader doesn't either. You could update the vertex shader to let it know which mesh it's processing via a variable, but I assume you want something all GPU side. So I believe the answer is, no, it does not. However, I'd love to be wrong, I think that would be pretty useful. 

Find out where and what the closest surface to "connect" to is. This can probably be solved following the normal of the edge out (like a ray) to see what is out there (up first then down?). If you bump into a platform, find the top edge that's closest (the edge you bumped into) and move to problem 2. If it's terrain, move to problem 2. How to connect to two surfaces. Likely this can be done almost the same way as problem 1. You found the direction you need to go in problem 1, now create a normal on each end of the edge in that direction. Now the ends where you started and the points where those normals bump into something else are your 4 points for a quad. Finding how when you bump into something. I'm assuming you have some height map you can reference. Hopefully you'd be able to use that along with your ray to find if something exists at that point in 3D space. Otherwise you'll have to check all the primitives (triangles? quads?) in the area to see if there was a intersection. 

I'm sure your steering code is fine, however there are some values you need to change to get it to work properly. There are a few factors to steering that need to be accounted for to successfully stop the first time. If your mass is too high or your acceleration is too low the object will oscillate. The object won't have the power it needs to stop its self before overshooting the target. This can be solved by increasing the acceleration available for stopping, or by increasing the stopping distance. 

Then, your loop is nonsense. You're just updating the same enemy every time. Then you can iterate over all your enemies like this: 

So when the force of friction and the force being applied are equal, the object will not accelerate. So if it's stopped, it's not going anywhere and if it's moving it'll continue to move at that speed. So you're going to want to collect some information to simulate friction. 

The first option is easier to implement, but less flexible. The second option will be harder to implement, but far more flexible. 

Where is your 0-1 value. Sorry, I don't know AS3, so I can't write it in that language. If it's just and vectors this is the same as: 

Remember to not get carried away with entities and components. It's totally fine to not have your as a component. If you know for sure there's only going to be one of something, it doesn't make much sense to make it a component. Components are made to be reused in numerous entities, combined with other components. This doesn't make the game less pure, it makes the code cleaner. Entity systems are just a tool for part of your game, it doesn't need to be all encompassing to be a good system. Use it only where it makes sense to you. 

Blender saves Quaternions in W, X, Y, Z format. I was loading them X, Y, Z, W. My code for converting a Quaternion to a matrix was incorrect. I'm actually still not sure why this is incorrect, but I know the following code works, as part of my Quaternion class: 

The basic idea being that you'll need to export through an intermediate format to get the textures working. Another step by step tutorial is available here, which includes images to make things easier. 

A* is the go to for most path finding situations. It's no different with 3D spaces, including flying through the air. Basically, you'll break your game up into nodes. This is called the navigation mesh. These nodes are typically cubes of various sizes. They don't all have to be the same size, you can make large open areas one big cube and the open areas near terrain smaller to have finer precision. 

The simplest thing would be to remove it and add a new UV sphere. Once the sphere has been placed, the options for changing it's attributes is gone. The only option I know of is to add a subdivide surface modifier to your sphere. That will subdivide all the quads, but it essentially only allows you to double your rings and segments, not increase them separately or by a factor less than 2. So to easily replace an existing UV sphere, you can do the following: 

It's still a good idea to control physics from the method, since it's unlikely the physics needs to be updated as often, and physics on a fixed update is much easier to predict (determinism) than physics on a variable update. 

If you're testing each voxel individually for visibility each time, I suppose you won't save much. However, typically you'd want to build a buffer that represents the surface of your voxel world. You don't just "draw" voxels, you need to build a mesh that represents the voxels. Building that mesh is expensive, so you want to reduce the number of times you need to do that. The first way is by only rebuilding the mesh when voxels change. So you build a buffer containing the vertices that represent your voxels. Then you draw that buffer every frame. Now that you have a buffer, you need to rebuild it every time something changes. That means throwing the entire thing away and rebuilding it all. But building is expensive, so maybe there's a way we can reduce the amount of waste when something changes? Yes, we can just rebuild the world around the voxels that changed. If we only have to update the chunk around the changed voxel, we save ourselves a lot of time in rebuilding something we already had. Now the terrain is chunked into smaller parts, we can just draw the chunks that are visible to us and we can just rebuild the chunks that have voxels change in them. We can do even more now that we have chunks. For example, with chunks that are far away, we can build buffers for those that have reduced polygon count, so they're not so expensive to draw. All in all, chunks allow us to have more control over what we draw and when. It enables us to implement performance features we wouldn't be able to otherwise. 

Iterative empirical testing. Add some test sliders to your GUI that control the force applied for the upward and downward directions. Other than that, consider changing the way force is applied. Add gravity into the mix, when the plane is horizontal its lift offsets gravity. The lift decreases with change in pitch. Your force is always forward, when pointing down it's in addition to gravity, when you're pointing up gravity is subtracted from the force. Basically, think about how to make it more realistic if you want it to feel more realistic. 

I'm just running this in my head so I'm probably off by one or something, but I believe the above will fill the array with this configuration: 

It has an component and a component. First we want to see how long it is when it travels one unit in the direction. So what do we do? We want to scale the entire vector so that the component equals . To figure out what to scale it by, we do the following: 

Where there are drag/drop components. The components have inputs and outputs. Components can be simple things like , or gates, or more complex like a test for nearby enemies. Ideally the visual representation should be compiling a written language script in the background. This offers a powerful tool for learning the language too. If a beginner can "write" their program visually, then read the code it produces they're far more likely to understand it and be able to modify the code produced. Eventually being able to write more powerful code than the visual tools alone allow. This fulfills the requirement of easing users into programming. The backbone of the system, of course, is a written language. The visual tools are just to give users a fast way to program something simple, and allow for beginners to get started. The written language allows for advanced users to do advanced things. And you can even allow users to create their own components, by making custom scripts. Then they can re-use components they made in a quick and easy interface for fast programming. Good luck! Sounds like a fun project.