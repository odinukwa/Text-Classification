Your results indicate changing routing. This has nothing to do with how operates. Please rerun your tests, and rerun them a second time if routing appears different. The no route to host, may be a firewall blocking port 3306. attempts to open a TCP connection using increasing TTLs. This should in most cases bypass the firewalls if you are connecting to a permitted port. The mechanism is described in the output. Your first output is normal output when your firewall is in a mostly closed configuration. Unless there is a rule permitting it, the normal UDP traceroute will fail. Your second request shows a longer path. Depending on your firewall configuration, this may be the normal routing. Or it may be that a shorter path had not yet been discovered. The routing has nothing to do with . The annotation after each time indicates that communication is . The ae nnotations are also included in the man page for traceroute. The third request uses a shorted path. This may be a hairpin NAT configuration on the firewall. Or it may be that a shorter path has been discovered. The TCP server appears to be responding. A few notes: 

To do what you want you may want to look at some of the documentation on multiple ISP connections. The concepts may be close enough to what you are trying to do. This Shorewall Multi-IPS documentation may give you an idea how to do it. 

If you have ssh access, you can tunnel the VNC connection over ssh. VNC access is often blocked by firewalls. VNC is not an encrypted protocol, and I wouldn't run it directly over the Internet. You can usually run ssh to any appropriate system on the target network. You don't need to have an ssh connection to the target system. 

You could use a daemon to open ports on demand. Some daemons such as will build restrictive rules which only open the ports to the requesting server. The daemon will adjust your iptables firewall by maintaining rules in a couple of chains. I investigated Firewalling Google Chat and Skype. I found that Skype is not designed to play well with firewall restrictions. Each user needs an incoming port forwarded to their device. Additional ports are required for each connection. However, it is not necessary to shut the firewall down to use Skype. Other than the incoming port for each user, you will need to enable outgoing connections on the ephemeral ports for the devices being used. Incoming restrictions can be quite tight. I was able to get working with a Shorewall firewall by adding the required chains in the configuration file. 

There are many ways to verify the Remote domain including: Callouts, SPF, DMARC, Whitelists and Blacklists. These all depend on DNS. Greylisting is a technique to ensure a real mail server is sending the mail rather than a spambot. Spamfilters such a Spamassassin use a combination of techniques to validate the mail which usually includes scoring the above tests as well as content and headers. 

If you have a static IP, you usually configure all the things you get from DHCP manually. This includes DNS and other entries. Your administrator can give you the appropriate values. This is the preferred configuration for servers and other systems which need to work even if DHCP is down. Alternately, your administrator can configure DHCP to provide your static IP address as a reservation. This will provide you the fixed address whenever you plug into that network, but allow you to obtain a different IP address when you plug into other networks. This works well for portable systems which need a static address. On many networks, your IP address will be essentially static unless you off the network for a long period of time even without a reservation. As you are running Linux you can configure your static IP address in addition to the IP address provided by DCHP. Many DHCP clients allow this to be configured. On Debian (Ubuntu) based systems you can configure the IP address using a statement to the DHCP setup in . A stanza like this: 

You should be able to control this at the kernel level with . Setting the net.ipv4 and/or net.ipv6 forwarding values off. 

The is equivalent to for SMTP traffic. Try rate limiting in that ACL. SMTP connections give you more ACL options where you can place the message. (Note: is a blackhole variant of so you won't see reject messages.) Discarding is rather drastic, and I would use or for SMTP traffic. Rate limiting is covered in chapter 42 section 38 of the Exim Specification. You can test with modified configuration so you can rate limit harder while testing than you would once you implement. Allow time for the test limits to clear before implementing. Try adding the following to your : 

EDIT: If each LB has a public IP address then you really want an active/active configuration. Otherwise, you are likely to fail to respond to half your requests. Active/passive should be using a single IP address for incoming traffic. The passive node does an address takeover when the active node dies. In Active/Active mode, both LBs will have different public IPs. Normally, there would be one or more DNS names with both IPs listed in their entries. Simpler systems will use normal DNS round robin balancing between the two LBs. More complex systems will use short TTLs on the DNS entries and try to balance the load by handing out the address of the least busy LB as the first DNS entry. In Active/Passive mode, both LBs handle the same public IP address (with only the current active note passing traffic for that address). There are a variety of heartbeat monitoring techniques that can be used by the passive node to monitor the active node. 

Try visiting the link in the log message. It indicates someone is attempting to connect to "$URL$ Do you have links that have paths like :995, :110 and :143? This may be a malformed REST response. 

The NTP offsets you are seeing are milliseconds not seconds. If you have problems with the dates put in your e-mail headers being off, then it may be your clients. If you can get a copy of the headers, it should be easy to determine where the issue is. The Date: header should have almost exactly the same time as your the last Received: header (first MTA server to handle e-mail). NTP is far more accurate that is required for e-mail headers. If there is an issue, check that your servers are synchronized with your NTP server. It appears you gathered this data relatively soon after restarting your NTP client. This is indicated by the poll vale of 256. It should rise to 1024 once things have stabilized. Your NTP server is tracking your local server as noted by the "*" to the left. Given its stratum and jitter this is unlikely to change. If it where to report a time significantly different from the other servers, it might get evicted. Two other servers are being used to determine if the current clock can be trusted. These are indicated by "+" to the left. They will be chosen from the lowest statum servers. The other two are not participating in voting as indicated by "-" to the left. The voting servers may shift over time based on their stability as a source for your server. The jitter of these servers should not cause you any issues, unless your local server gets evicted. 

I use which should be available as a package. Configuration can mostly be done with . Once it is installed add the appropriate alias to . You likely want to configure using a (mail relay). You will need to decide if you want any local email, or want to send all messages to your account. Either or should be just about as easy to configure. 

I have run various backup routines that need to root access to access all the files. They all connected with restricted access, usually via a non-root account. can be configured to run commands without requiring a password. It should be simple to create a wrapper script the elevates to access via and runs the required command. Programs with the setuid bit set run as the user that owns them. This is generally more secure unless the program allows access to an unrestricted shell. 

Configurration for DMARC with reporting. Until the reports indicate you don't have issues, I would not use a policy. You may want to start with as your policy. 

Although I would recommend not sending from domains so you could define DKIM_DOMAIN as follows. You could use domain rewriting to remove the portion of the domain, although I would try to avoid getting it there in the first place. 

UDP is easy to spoof source address on, packets could be coming from anywhere. Someone could be forging a packet to your broadcast address. Filter port 5353 incoming and outgoing, multicast DNS should be local. Filter the broadcast address on your firewall. Filter outgoing traffic to the the target address to ensure you aren't the one sending the traffic. This looks suspiciously like the amplification attacks which where run on DNS last year. Those were done by forging the source address. If this is the case you are the real target. 

In the directory there should be a config file per site. They are in the form "config-sitename.php". They should have line starting . Edit the defined value to be the name of the mysql host. Verify the permissions in mysql on the remotehost to ensure they allow the user to connect from the webserver. The table has a hostname which can be used to restrict access to a host. Setting the hostname to allows any host to connect. It is more secure to set it to the name of the host that will be connecting. Drupal should use a similar mechanism. You can start the transition by enabling the mysql on the server to listen on and getting usres to transition to this from the socket. 

Static IPs are normally outside the pool range as you do not want static IPs assigned to other hosts. As long as the static IPs are in an IP range local (or relayed) to the DCHP server they can be served. The leases file records which addresses from the pool have been assigned to a host and when that assignment expires. This is used to ensure that multiple hosts don't get assigned the same IP address. The presence of an active lease does not indicate that host is currently connected to the network. As static IP assignments are know by their definition, they do not need to be recorded in the lease file. If the lease time is too long and clients frequently change, it is possible to run out of addresses while only a few hosts are currently connected. This is more likely in a hot-spot or guest network than a typical office network. 

You may want to configure this as a zone rather than a forwarding zone. This will require that the the primary server allow zone transfers of this zone from the slave. You can also configure the primary zone to notify the slave zone when the zone changes. There are two caching values for a domain. For positive matches, the caching time can be set for each domain but is usually but defaults to the value specified in the $TTL line. For negative matches, bind uses the minimum value of max-ncache-ttl (default 3 hours) and the minimum value from the SOA record. If you don't search for the domain before the primary is loaded, the forwarding domain should forward the request, find it and cache it. 

The complexity of the daemon is not really the issue. The frequency of use is. xinetd allows you to get increased logging, and depending on the configuration an extra layer of security. All of the daemons you mentioned can be and are run under a super server in some configurations. If you rarely use the daemon consider running it under the super server. This will allow you to reduce the number of daemons running and the resulting overhead. inetd and xinetd have some very simple services built in. These services should be disabled unless needed. Other services don't have a daemon interface, so must be run by a super server. Many services which have network daemon capabilities, have flags which tell them they are running under inetd. You should consider startup overhead and configuration stability before running daemons under a super server. A heavy startup overhead is one reason to run a rarely used service as a daemon. The services you listed are usually relatively heavily used when installed, so are run as daemons. Apache is optimized to run as a daemon. If it is used much it is best run as a deamon. Mail servers generally fork a new server for each incoming call, which has low overhead on most OSs. If it isn't used as a mail hub or delivery from remote sites it shouldn't be listening on any address other than localhost. It doesn't need to do that unless you have programs running on the server which use TCP/IP to send email via localhost. sshd has relatively low startup overhead, except for random data for encryption. It does require a fair bit of random data, which may not be readily available if run under a super server.