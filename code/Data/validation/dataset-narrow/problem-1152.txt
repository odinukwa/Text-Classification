Scientists learn new knowledge for humankind, and then share what they learn through research papers. Moreover, we live in information overload, so readers only have time for the most important knowledge. 

For a correctness proof, I'm looking for a usable notion of program equivalence $\cong$ for Barendregt's pure type systems (PTSs); missing that, for enough specific type systems. My goal is simply to use the notion, not to investigate it for its own sake. This notion should be "extensional" — in particular, to prove that $t_1 \cong t_2$, it should be enough to prove that $t_1\; v \cong t_2\; v$ for all values $v$ of the appropriate type. Denotational equivalence Denotational equivalence easily satisfies all the right lemmas, but a denotational semantics for arbitrary PTS seems rather challenging — it'd appear hard already for System F. Contextual/observational equivalence The obvious alternative are then various forms of contextual equivalence (two terms are equivalent if no ground context can distinguish them), but its definition is not immediately usable; the various lemmas aren't trivial to prove. Have they been proved for PTS? Alternatively, would the theory be an "obvious extension", or is there reason to believe the theory would be significantly different? EDIT: I didn't say what's hard above. Easy part: the definition Defining the equivalence is not too hard, and the definition appears in many papers (starting at least from Plotkin 1975's study of PCF, if not earlier — the source might be Morris's PhD thesis from 1968). We $t_1 \cong t_2$ if for all ground contexts $C$, $C[t_1] \simeq C[t_2]$ — that is, $C[t_1]$ and $C[t_2]$ give the same result. You have a few choices here with lots of alternatives: For instance, in a strongly normalizing language, if you have a ground type of naturals, you can say that ground contexts are the ones that return naturals, and then $a \simeq b$ means that $a$ and $b$ evaluate to the same number. With nontermination, for reasonable languages it is enough to use "X terminates" as observation, because if two programs are equivalent when observing termination, they're also equivalent when observing the result. Hard part: the proofs However, those papers often don't explain how hard it is to actually use this definition. All the references below show how to deal with this problem that, but the needed theory is harder than one thinks. How do we prove that $t_1 \cong t_2$? Do we actually do case analysis and induction on contexts? You don't want to do that. As Martin Berger points out, you want to use, instead, either bisimulation (as done by Pitts) or a logical equivalence relation (that Harper simply calls "logical equivalence"). Finally, how do you prove extensionality as defined above? Harper solves these questions in 10 pages for System T, through considerable cleverness and logical relations. Pitts takes more. Some languages are yet more complex. How to deal with this I'm actually tempted to make my proofs conditionally on a conjectured theory of equivalence for PTS, but the actual theories require nontrivial arguments, so I'm not sure how likely such a conjecture would be to hold. I'm aware (though not in detail) of the following works: 

Based on the explanations here [1] I know that 3-valued first order logic has many different versions, which differ in the definition of their operations (e.g. implication). All of these (as far as I know) are complete, i.e. any probable statement could be proven. Also these are (just as in the 2-valued case are Semi-decidable, i.e. the correctness of statement given axioms, could be proved, also wrong statements could not be disproved.) Also these are consistent, i.e. they don't contain contradiction. Suppose I define my arbitrary 3-valued first order logic (by arbitrary, I mean, arbitrary $\Rightarrow$, AND, OR). Is it true that, it is 

I think this is a typo. In the Definition 2.1 and Definition 2.2, the estimation of $c_D$ is done by empirical summation of $\mathbf{1}(c(x_i) = y_i)$. Later in the Definition 3.1 it used the following notation : $$ ... = \Pr_{...} \left( \sum_i Z_i < k \right) = ... $$ In this notation $Z_i=1$ corresponds to correct decisions or $c(x_i) = y_i$, and $Z_i=0$ corresponds to the mistakes or $c(x_i) \neq y_i$. I suppose that in this binomial representation $Z_i = 1$ (correct decision) corresponds to tail"). That said, the right sentence seems to be "... having k or less errors is at least $\delta$" 

EDIT: again, (part of) the basic idea is that pushouts act as a union with some glue. This allows defining "rewrite rules" for graphs — you match the left-hand side to the graph, and then glue the right-hand side to the (rest of) the graph in a corresponding manner. I'm afraid I can't add details because I've never gotten more than the intuition. 

I was reading about Call-by-Push-Value in the introducing paper from 1999, but I have some confusion, partially because of my unfamiliarity with domain theory. I might have figured it out, but I'd hope to get it confirmed. (If this is not the appropriate venue, advise is welcome on which one is). I was confused by the statement: 

*Apparently, some (non-formalists) claim that set theory is not "just syntax", but something ontologically different. I'll ignore this subtle philosophical issue; the only reference I know on it is Raymond Turner's Understanding Programming Languages. 

Define $G(n, p)$ as a random directed graph ($n$ vertices; we put edge between two vertices with probability $p$). What are the known results for the following problem: Fix two vertices $v$ and $u$. What is the probability that there is at least a path (of length at most $k$) between $u$ and $v$? (clearly the result should be a function of $n$, $p$ and $k$). Upper-bound would work too, if there is no known exact answer. 

Suppose I have a collection of (hidden) first-order rules: $$ \mathcal{R}: \{ Q_i(x) => P_i(x) \}_{i=1}^{k} $$ all defined over $x \in \mathcal{X}$. I can use these rules and (automatically) generate a large collection of (training) data for my supervised system: $ \mathcal{D}: \{(x_i, y_i)\}_{i=1}^{n} $, say for $y_i \in \{-1, +1\}$, and run a supervised system on this sampled data, and test on a heldout set. If my rules are compatible (not contradictory) a rule-based system should be able to get a perfect score on the sampled set. However, I am not sure how would a supervised do on this. Are there any possibility/impossibility on the ability of supervised systems for learning first-order rules (possibly with some assumptions) and based on finite samples? This is basically the reverse of rule-learning, in which the goal is to learn some rules $\mathcal{R}$, given a training data $\mathcal{D}$. I did a little bit of Googling but didn't get anything directly relevant (all I found was algorithms for first-order rule induction or training supervised systems that use 1st order rules as features). That said, it's possible that I am missing some results on this. Would appreciate any thoughts on this. 

I expect the answer to be "obviously yes", but to my inexperienced eye, that's not directly obvious, because the definition of infinite Böhm-reduction does not include a transitivity rule (it wouldn't work), and because I couldn't find a relevant lemma in the papers themselves. I'm referring in particular to the definition by Czajka [1] of the relation $\rightarrow^\infty_{\beta\bot}$, called infinitary Böhm-reduction. I've looked at [2], which however does not include Böhm-reduction (such that the defined relation isn't confluent IIUC, which is a problem for me). Rationale: Defining reduction for infinitary $\lambda$-calculus is tricky. In particular, you cannot create an "infinite transitive closure" which allows an infinite number of transitivity steps, but you need to be more careful. In particular, if you define multi-step reduction coinductively, you cannot include a transitive rule, lest your relation becomes total and thus degenerate. So one ends up doing transitivity elimination, which is not always trivial; and given how unintuitive coinduction is, I'm afraid I'd fool myself when attempting a proof. [1] Łukasz Czajka, 2014. A Coinductive Confluence Proof for Infinitary Lambda-Calculus. Proc. of Rewriting and Typed Lambda Calculi, Springer. $URL$ [2] Jorg Endrullis and Andrew Polonsky, 2011. Infinitary Rewriting Coinductively. In Proc. of TYPES, volume 19 of LIPIcs, pages 16–27. Schloss Dagstuhl. $URL$ [3] Richard Kennaway, Jan Willem Klop, M. Ronan Sleep, and Fer-Jan de Vries, 1997. Infinitary lambda calculus. Theoretical Computer Science, 175(1):93–125. $URL$ 

The famous FTPL algorithm [1] is analyzing linear cost function. Is there any generalized proof for nonlinear functions known? Note that in the last paragraph of [1] it says "It would be great to generalize FPL to nonlinear problems". In [2] (page 69, 70, 71) there is analysis of FTPL for general functions, but the resulting bound $O(T)$ does not attain the optimal bound (i.e. $\sqrt{T}$). Are you aware of better analysis for FTPL (with general nonlinear functions) that attain the optimal regret? Update: The algorithm in [2] is indeed $O(\sqrt{T})$ (by choosing $\eta = 1/\sqrt{T}$) but it is calling the linear optimiazation oracle many times (not just once as in [1]), which results in having a different bound. [1] $URL$ [2] $URL$ 

A nice example is Tate et al.'s Generating Compiler Optimizations from Proofs. He uses pullbacks and pushouts as generalized unions and intersections, in categories where arrows are (IIRC) substitutions. Ross Tate claims (on the paper webpage) that details were overwhelming without the abstraction afforded by category theory. Personally, I'd like to submit as "suggestive evidence" (if there can be any evidence of such a claim) diagrams (6) and (7) in their paper — they look complex enough in diagrammatic form. Let me quote their comments inline. 

Thanks for the question; I had similar questions few years ago, before starting in research (I'm not necessarily assuming that's your case). I've looked at a couple of the links, and they don't really look like research papers in form; I mostly can't really tell if their technical content could be made into a paper because I'm not an expert in the field, but I'm guessing "no". If you compare your links to a paper, you'll notice several differences. But highlighting them and their rationale might help. The key concepts are: