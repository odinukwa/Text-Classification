Routing is the decision over which interface a packet is to be sent. This decision has to be made for locally created packets, too. Routing tables contain network addresses and the associated interface or nexthop. This refers to and (in a Linux context). Forwarding refers to packets which reach a system but are not destined for this system. Forwarding is a decision of the system: "I take the packet and try to get it towards its destination." Instead of just dropping it. "forwarding" is a common term in the context of packet filters. Linux' Netfilter has three chains in its base table: INPUT, OUTPUT, and FORWARD. This chain just makes the decision "Shall this packet be forwarded or dropped?" (if forwarding is generally enabled on the system; Linux again: /proc/sys/net/ipv4/ip_forward). 

A memory jump sounds like an bug. If that is the case the problem may be solved by caring about this inode manually (with ; I am not familiar enough though to explain how to do that). If it's not a bug and just needs more memory then there is a "solution" which does not require adding RAM but it would certainly "redefine performance"... The problem is that e2fsck does not use swap memory as equivalent. At least that was the situation in a similar case. Does your swap space get filled completely before crashes? Probably not. You can trick into accepting swap as real RAM: You can boot a second Linux in a VM and export the block device to be checked to the VM. You configure the VM with more memory than physically available. in the VM will see more RAM. Of course, this does not make the use of scratch_files unnecessary. I had problems starting a VM with more memory allocation than there was physical(!) RAM available but according to the Fedora docs this is supposed to be possible (maybe that was not even a KVM/QEMU problem but some fancy kernel stuff). 

The Basic Tier is free. It provides basic features, a moderate allotment of logs, and access to built-in metrics. If you try using metrics other than the built-in ones, you may get this error. As per this documentation the Monitoring agent's metrics are only available with the Stackdriver Premium service tier. 

wget might get disconnected during the download but you can use options described in above link that will help you make the download successful, like the -t and -c options for trying the download more times or continue getting a partially-downloaded file, respectively. After the file is downloaded you can use 7ZIP to unzip the file in the directory where it was downloaded to using the command: You can copy the file to a GCP bucket using the command: If wget and 7zip are not installed in the VM you can install them as per instructions, wget and 7zip, as follows. This examples are for Ubuntu or Debian Linux VMs: 

Are you trying to sftp into a GKE Docker container? Have you checked that your firewall rule has the correct priority set and that no other rule above it is hampering you efforts? 

If you want to create a backup of your VM instance which includes your E-commerce (Magento) and have the VM backup include files, configuration files, databases in the VM disk, orders info, etc, you can create a snapshot of your VM as per the following snapshot documentation link. This documentation will guide you to create a snapshot backup of your instance persistent disk which will include the VM instance configuration file and database if hosted locally, depending on your configuration. To create a snapshot: 

Isn't your LAN test server on at least a 100Mbits network...? However: Traffic shaping does not influence the network on layer 2. Your NIC will continue to accept packets at 100Mbit/s. But every traffic (of the shaped type) above the configured limit will be thrown away by the shaper. This gets detected (so far the theory) on higher levels (TCP or the UDP application) so that the communication partners reduce the amount of data they send respectively. 

Then you can extract it from the package (e.g. by midnight commander ta least in case of RPM). If you made important, hard to repeat changes to the file then you have a backup, don't you? 

You need not set routes on the server if just simple clients connect. If 172.16.20.1 connects as a gateway for the local network then you need a route for 172.16.20.0/24 but that is probably (and best) set in the OpenVPN config for 172.16.20.1. Edit 1 If you cannot configure the routing on certain systems and their routing would not send the traffic back the right way then you need NAT (more precise: SNAT): 

On the gateway you must allow forwarding within the LAN net, of course. But then you can use SNAT even locally. That's probably more fun than testing with the connection to the customer. :-) 

and replace with (or the with ). Or you rename it ( instead of ) in one of these ways and delete is manually afterwards. 

kills the script and all processes it has created. I do not understand what use has. If you just want to detach the process from the terminal then use nohup or screen. Giving the screen session a name would make killing the script easy, too. 

It takes more time to create a full disk snapshot which can degrade system performance. This may be a negative factor for a production system serving thousands of users. Recovering your lost data from a point in time is easier and faster if you do it from an incremental part of your full snapshot backup. 

If you want to have full copies of your VM disks regularly, you can consider creating custom images of your (boot) disks, as explained in this public documentation. 

This error appears to suggest that you’re using the Stackdriver Basic Tier which allows ‘Logging agent only’ as per the documentation, section ‘Stackdriver account service tiers’. I presume you would need the Premium Tier: 

The only option at present is to create snapshots/images of the VM Instance boot and the additional disks, however there is a feature request so that this feature can be made available in the future. There is no ETA but any updates can be checked on this link above. 

The first successful snapshot of a persistent disk is a full snapshot that contains all the data on the persistent disk. The second snapshot only contains any new data or modified data since the first snapshot. Data that hasn't changed since snapshot 1 isn't included. Instead, snapshot 2 contains references to snapshot 1 for any unchanged data. Snapshot 3 contains any new or changed data since snapshot 2 but won't contain any unchanged data from snapshot 1 or 2. Instead, snapshot 3 contains references to blocks in snapshot 1 and snapshot 2 for any unchanged data. 

Have you installed RStudio in a Linux VM? If so you can ssh into your instance using command and then use wget from inside your instance to download the file: 

If the CPU does not slow down the data input (because deflating takes more time than reading) then extracting is faster than copying. If you instead copy from a SSD to another device and your CPU is from stone age then copying will be faster. 

This is most probably a firewall problem on one of the systems. You can use tcpdump to check whether packets are not sent at all or discarded by the recipient system: 

You create a new directory and hardlink all binaries they need (like itself and make this directory part of the users' . These hardlinks maybe have to be recreated after package updates. 

I don't know this Intel stuff but you could try this: Copy the whole content of the disk to be replaced to the new disk using dd (don't forget ). If your RAID solution does not store serial numbers and the like then there is a chance that the RAID continues working after changing the disks. I would expect this to work with software RAID. 

You are asked just once. You can copy the respective entry from the file to the same file for other users. Or you put it into then it's valid for all users. 

in the file for the server and restart the server afterwards. You have to use one of these formats of the command then: 

VPN connections are secure "by definition". Otherwise you would not call it a VPN. Security is reached by crypto keys. Looking at MAC addresses in this context does not make sense. It is not clear what the connection shall look like but I assume that no routing is intended. So you need at least four rules in your firewall (for the physical interface, say eth0): 

At the Google Cloud Platform click on Products & Services which is the icon with the four bars at the top left hand corner. On the menu go to the Compute section and hover on Compute Engine and then click on Snapshots. At the menu above click on CREATE SNAPSHOT At the ‘Create a snapshot’ page fill in all the required information and choose the correct disk for your VM Instance. Click on create a snapshot and wait until the snapshot is created. 

As this GCP public documentation states, Snapshots are incremental and automatically compressed, so you can create regular snapshots on a persistent disk faster and at a much lower cost than if you regularly created a full image of the disk: 

Can you run a dig command from your client machine to one of the machines the DNS server resolves for and share the results? Take into account that the Google Cloud DNS server that you have at the other end has to be registered with higher level DNS servers in order to be reached as explained in this page. If not, the world has no way of knowing you have a DNS server service on the Domain Controller. If you have already registered the DNS server, then you have to look at your client configurations as well, check your client machine name, domain name and name server you have set up. If it’s a Linux machine you should look at the configurations in /etc/resolv.conf and add the nameserver which depends a bit on which unix version you have. 

The first snapshot that is created is a full backup of all your data in the VM boot disk. Any further backups contain any new data or modified data since the first successful snapshot. It would be very important that you follow the recommendations and instruction in the above documentation link to ensure that your snapshot is successful. It is also important to check and test that this backup is correct and check that you can recreate your systems from it should a disaster occur.