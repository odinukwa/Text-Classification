Yes, but "afford" is so much more than just straight up dollar values. Yes, the feature set that Unity Pro gives you at the cost they charge is ridiculous, especially considering the fact that it's seat licenses instead of per-title licenses. But on top of that, it's a really easy tool to use. You're not spending as much time training artists and designers how to use the art pipeline. It's easy to say "just drag in your textures and models and they're good to go. On top of that, it's one of the very few tools that actually let's you do 3D in a browser with any kind of regularity. They support pretty much every shader platform from fixed function to DX9+ as well as Mac and Windows. That tech alone is invaluable if you want to target the growing "browser based game" market. From a programming side of things, what you get from Unity is a firm grasp of component design (compared to rolling your own C++ engine, which is usually too heavy on the inheritance side), as well as a very quick and visual environment to try out game code. You'll hopefully learn good design practices by using Unity, that you can take over to future C++ engines. Sure, it's fine to have a preference of one language over another. Personally I prefer C# over C++. But what language you use is really driven by the project requirements more so than anything else. Developers can't really afford to be fanboys since you don't want to lock yourself out of a market because you happen to not like the tools or language for one reason or another. Besides, once you really learn a second language you can see that it's mostly just picking up new syntax and paradigms, and it really isn't that hard usually to add new tools to your tool belt. Yes, you should learn and understand C++, but on a high level you need to understand good design first. 

Great answers so far from James and Ricket, I only answer to add a note of caution. Message passing / event driven communication is certainly an important tool in the developer's arsenal, but it can easily be overused. When you have a hammer, everything looks like a nail, and so on. You absolutely, 100%, should be thinking about the flow of data around your title, and be fully aware of how information is passing from one subsystem to another. In some cases message passing is clearly best; in others, it may be more appropriate for one subsystem to operate over a list of shared objects, allowing other subsystems to also operate on the same shared list; and many more methods besides. At all times you should be aware of which subsystems need access to which data, and when they need to access it. This affects your ability to parallelise and optimise, as well as helping you avoid the more insidious problems when different parts of your engine become too closely entwined. You need to be thinking about minimising unnecessary copying around of data, and how your data layout affects your cache usage. All of which will guide you to the best solution in each case. That being said, pretty much every game I've ever worked on has had a solid asynchronous message passing / event notification system. It allows you to write succinct, efficient maintainable code, even in the face of complex and quickly changing design needs. 

Fundamentally there's nothing specific to iOS about what you want to accomplish. The high level techniques are going to be the same. That being said, one easy way to get started is by using Unity. They have a character customization tool that will get you started. Demo: $URL$ Project: $URL$ (Note that the streaming of assets through their "asset bundles" system requires Unity Pro, but the concepts should get you started.) 

Personally I don't think there's that much special about racing games that makes them that specific to choose engines for. I would think that things like cost, language, platforms, art pipeline, etc. are more relevant to the topic at hand. Since there are at least a dozen "what engine should I use for game type X" questions out there I'm not going to rehash the same answers over and over. A lot of the problems with making a game can be solved by not picking a design that requires advanced features. Don't try to make a racing game with Forza-style ultra realistic physics. Don't try to make a game where there are streaming levels or procedurally generated levels. Solve the "make the game fun" part first, then add the complicated features. Pretty much any engine with some kind of middleware can be used to some success to make a car work. Visibility problems and solutions (occlusion culling, mainly) are going to be similar in pretty much all engines. All that being said, if you're completely floundering about, the Unity guys put together a sample project with a pair of cars that would get you up and running pretty quickly, and the Unity engine itself is easy to use. See $URL$ 

I think Unity3D is the best solution out at the moment to provide these, also it has a lot less limitations that other things Ive tried, a large community and lots of libraries (assets) available for it. To save space you can compress all your game assets like images and whatnot. This is actually the default, images will be compressed and also squished to a 1024 maximum resolution. You can override and change these settings in the inspector when you select your asset. 

I was just talking to a game dev who said its possible, that it involves downloading the android sdk and few other things. If this is possible can someone tell me how? Also is it possible to build a .apk file and install on your device? Is it possible to release something developed this way on the play store? 

Development speed Can make it once and then build to multiple devices. Less weird random "not working" or performance problems on particular hardware setups. 

The brute force solution would be to iterate over all objects which might be in between the two characters and test them each individually (GameObject.FindObjectsOfType is probably your friend here). However a much simpler and cheaper solution would be to do a ray-cast from one character's position to the other. If any results are returned they'll be in the way of the two characters. Bear in mind that will draw a thin ray from the local origins of the characters though, if you need partial collisions (e.g. a collider just off to one side of that ray but which the character would hit if they tried to move towards the other character) then you'd need a sweep test (moving the character's collision volume along the path towards the other character) of some sort. You might be able to get away with 5 raytests instead - one in the centre and one for each corner of the character's AABB. 

Gah! Don't change pitch. At all. Unless you want the player to feel like they're playing a drunk, and fighting the camera. Your focal point is set by the player's control, don't change it. I'm not even sure it warrants a 'formula' - I think you'd be better served with some predictably random motion. Look into low frequency Perlin noise to generation your offset curves. Any simple formula you can think of will be predictable enough that it defeats the whole point of the bob - to give the impression that the avatar isn't moving in an artificial way. You can combine trig functions to get a pseudo-random smoothed curve, but you're far better off using Perlin noise which is perfect for this sort of work. I'm not aware of any research on 'good' head bobbing, but I'd say if you're going to do it, you need to do some serious cold testing and iteration. You (the implementer) are not in a good position to judge the effectiveness of your implementation, because very quickly after you start, you'll become hyper-sensitised to the amount and manner of the bob. What others might find good, you'll obsess over and reject. Most of all, keep the motion subtle. The temptation when implementing is to crank up the 'bob' factor until it's noticeable, because you want to see it taking effect. That's no good. Ideally the player doesn't even notice the bobbing - if you ask them after the testing whether they noticed their viewpoint bobbing when they ran, I think they should say no. The purpose of a bobbing motion in the viewpoint is to make the motion feel natural, so that you don't feel like you're sliding around as a camera on top of a wheeled dolly. The player's hind-brain will pick up on the artificial nature of a naive implementation, but it only takes small subtle variations from that to fool the perception. 

This is all very game specific. It all depends on how your game handles its UI and the size of things on screen to determine how you're going to solve the pixel density and resolution disparity issues (which should be pretty similar to how you're solving iPad vs iPhone, assuming you are). Any optimizations you're doing for the iOS version should apply to the Android version. You really just need to get a couple of target devices and test on them. As for specifics, if you're not using OpenGLES 2.0 and you are doing fixed function shader stuff you need to realize that you have fewer texture stages on Android hardware than on iOS hardware. It's generally 2 instead of 4 I think. One thing that Android users are used to that you'll have to add is soft "back" button support. Basically check for and go "back" where appropriate. I think this also includes exiting the application if you're, for example, on the main menu. 

Fluid dynamics is one of those super hard things to set up, that once you've got it working allows for a whole range of interesting effects. It's probably overkill for most games, unless you actually need things to move like a fluid (as in, flow from one point to another). For soft-body masses, I would considering instead using nets of springs to simulate your bodies; much more straightforward to implement, and far easier to handle from a gameplay point of view. As a possible initial implementation: imagine that your body would have a centroid, that you could apply forces to and move around. Around that centroid, you'd attach additional nodes, linked to the centroid with a spring, and linked to each other to form a network that holds its shape. For example a hexagon of 6 nodes around the outside, each linked to their neighbour and also the centroid via springs. As you apply forces to the centroid, the springs act to pass on that force to the outer parts of the body; the front compresses towards the centroid, the rear elongates as it is pulled with the centroid. That's not the only way to do it, you can have the movement forces applied equally to all the nodes, it all depends on how you imagine these bodies to work internally. Apply forces to all nodes equally, and the body won't deform unless it encounters something else. And it's in encountering "something else" that things get interesting, and cause your body to deform nicely. Bear in mind you're simulating something soft and squishy, not a bunch of hard spheres connected together. So maybe instead of using rigid body collision, give each of the nodes a repulsion from the other objects in your simulation. Then, as you move your body towards an object smaller than itself, the gap between nodes will widen to allow the object to slip between them. After the object has passed through, the springs that hold the body together will cause it to reform into its original shape. Objects larger than the body won't be able to fit through the gaps, so your body should collide with the larger object and flatten against it. It's possible you want to implement rigid body physics as well, to prevent a squishy object penetrating through something that should be solid, but it should be a backup to the repulsion-based forces that are simulating the squishy exterior of your body. In terms of rendering, you can get a nice blobby effect with a pixel shader or render-to-texture approach, basically rendering a circle around each node such that the overlaps are invisible, but around the edges there are nice soft circular edges. So look up spring networks and Verlet integrated spring simulations, and you should be able to get the foundations of a system that will let you do 'blobby' physical mechanics without doing full on free-moving fluid simulations. 

I want to simulate blobs of water in a 2d game in Unity3d. One possible way of doing it is to use 3d metaballs moving in a 2d plane though this is very processor intensive. Do you think it would be possible to make 2d metaballs, so I end up with a 2d meshes something like in the picture (In this case its 2 metaballs in conjunction) and then apply some kind of shader to make it look like they are bulging out and refracting the texture behind them like drops of water? I ask because I dont have much experience with shaders and am not sure what is possible. 

I'd say yes. I have been using unity for this purpose. You will have that 20Mb lump of the unityengine to start off with, but after that your project will increase in size normally. If your really concerned you could try Corona SDK which is a 2d sdk that builds to iOS and Android, but you may run into limitations with it though (like facebook integration for example) The reason I use a pre-existing engine/framework/sdk rather than write my game from scratch is because I want the following benefits.. 

It's worth noting that the platforms with quality control requirements (e.g. X360, PS3, DS, etc.) will all require you to have some form of animation in your loading screen (or in fact any screen which remains static for more than a few seconds). This is because otherwise the user may think that your game has crashed, when in fact it is just taking a long time to load. Even where this is not a requirement, I'd certainly advise it. Any form of animation is fine, but a simple progress bar may not be the best, as any large steps in the loading may result in the progress bar not moving at all for a while, meaning the screen is just as static as if there were no bar at all. Better to show some continually moving image, like a rotating icon, in addition to a progress indicator. 

Use it individually. Texture atlases are used to gain efficiency by minimising texture swaps for many small textures, and avoiding wastage due to textures having to be bumped up in size to dimensions that are a power-of-two. A single image on an atlas gains you nothing except more book-keeping, and if the atlases are required to be power-of-two in size, your example image would need to be 2048x2048. That's a lot of wasted space. The original tags included Android, which brings some extra factors to the discussion: A 1920 x 1080 image will most likely need to be compressed to work on Android anyway, which comes with a need for power-of-two sizing. PNG is not a native format, so any PNG images will have to be converted and probably compressed before use. So even storing and using it individually, for loading and rendering it will be bumped up to 2048x2048 before it's compressed. You could use it at its native resolution uncompressed, but it would be massive in memory, and you probably want to avoid that. In practice we've always used compression on full-screen backdrops, but left texture atlases uncompressed (because the quality drop is far more noticeable on the smaller sprites); that's a pretty common policy for most places I believe. 

This a a weird question. I'm making a game in unity. I have a grid of columns and the height of the columns is changing (lerping) randomly (just cus it looks cool!) I was wondering could I procedurally generate some sort of 2d contour map, then each column would take its height from the contour map, that way nearby columns would be similar in height. Also how would I then get this contour map to fluctuate and change randomly? If my grid of columns is 10x10 that means this contour map can also be just a 10x10 array with only 100 data points. Can anyone think of a cheap way of achieving something like this? 

I'm writing a plugin for this library for Unity3d. I have it working and now I am looking for an efficient way to draw the particles. My 1st test just uses sprites and runs fine on my laptop but I doubt it will be so good on a mobile device. Is there a cheap way of simply drawing lots of particles to the screen each frame? The library generates an array of all the particle positions which updates in FixedUpdate() so I can just draw everything in that array each frame. I'm thinking maybe somehting in the Graphics namespace would handy here, like maybe Graphics.DrawTexture Also I might consider doing some kind of metaballs like pass over the particles to make them look more liquid like.