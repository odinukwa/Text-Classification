VSIDS heuristic fir selecting which variable to branch on next. CDCL: conflict-driven clause learning heuristic which learns a new clause from a conflict. 

It's undecidable because we can interpret natural numbers (with addition and multiplication). For example, let $Ind(f)$ be the formula: $$f(0)=1 \land \forall x \ \big(f(x)=1 \to f(x+1)=1\big)$$ Now we can define the characteristic function of the set of natural numbers using its universality property as a minimal inductive function: $$Ind(h) \land \forall f \ \big(Ind(f) \to \forall x \ (f(x)=0 \to h(x)=0)\big)$$ (As Emil wrote in his comment we don't even need the language of RCF, we can pick an arbitrary member of the structure as $0$, define a successor function as an injective function whose range lacks our $0$, and then define natural numbers using them. So the undeciability result applies to the second-order language of any infinite structure.) 

You can find more in Klaus Weihrauch's book "Computable Analysis". You may also want to take a look at Steven Vickers' nice book called "Topology via Logic". 

The key idea really is that the language of ZFC itself is very easy to capture. We can express that string $\pi$ is a ZFC-proof of $\varphi$ in much simpler systems that ZFC (e.g. Cook's $V^0$ which captures computation in $AC^0%). If we can express that, then we can express anything ZFC can express. That is there is polynomial-time computable function $t$ that maps any well-formed formula in the language of ZFC to a formula in the language of PA such that the formula is provable in ZFC iff there is a string that PA proves it is a ZFC proof of the the translation with: just encode the ZFC proof, PA can verify syntactically that it is a valid ZFC proof, and if there is such a string that PA proves is a ZFC proof of the formula, then it is actually a ZFC proof of the formula. It is key here that I didn't quantify for the existence of the ZFC proof in the PA translation. The reason is that PA might not be able to prove the existence generally. E.g. let $f$ be computable function whose totality is provable in ZFC but not in PA. Then the formula $\forall x \exists y f(x)=y$ is probable in ZFC but not in PA (with any resonable encoding). The reason is that if we can prove it then we prove the totality. This is generally related to what is called interpretability and interpretation in logic. Essentially we have L1 and L2 and they have their own semantics, and we ask if everything in L1 can be faithfully expressed in L2. Think of the formulas as capturing the subsets of the standard models of those languages. E.g. for ZFC this would be the standard model $\mathbb{V}$ while for PA this would be standard natural numbers $\mathbb{N}$. Before thinking about expressing things, you need to think about how subsets of these two structure map to each other. What does it mean to map a set in ZFC to a set in PA. We can restrict our interest to subsets of $\omega$ in ZFC. Then the question becomes. We can restrict ourselves to arithmetic subsets of $\omega$. Then these subsets are expressible in PA clearly. For any such set we have a PA formula. For size we really need to talk about families of formulas. If the family is uniform, that is it is obtained by sectioning another arithmetic formula, then the size relation is still polynomial: let the formulas in ZFC be $\varphi_n(x) := \varphi(n,x)$. To obtain the translation in PA, translate $\varphi$ and then plugin $n$: $[[\varphi_n(x)]] := [[\varphi(x,y)]]_{y/n}$. The only part that changes is $n$, the rest remain the same. For provability the story is not about standard models but also non-standard models that satisfy the axioms. Is it the case that every function over natural numbers that is total in every model of ZFC is total in every model of PA? The answer is no. 

The theory of real closed fields (RCF) is complete for the first order theory of real numbers in the language you described. Therefore it is equivalent to checking if RCF proves the formula. By Tarski's quantifier elimination for RCF this can be computed. Tarski's algorithms complexity is non-elementary and there is a doubly exponential lowerbound for the problem. A more efficient algorithm than Tarski's algorithm is given by Saugata Basu "An Improved Algorithm for Quantifier Elimination Over Real Closed Fields", FOCS 1997 (which seems to be almost optimal, see Theorem 1) (a draft of the paper is available here). Also check Saugata Basu, "New Results on Quantifier Elimination Over Real Closed Fields and Applications to Constraint Databases", Journal of the ACM, 1999. 

Let's the edge corresponding to a route its bottleneck. Given $G$, $S$, and $T$, we want to compute the list of bottlenecks for all routes in $G$ from $S$ to $T$, i.e. we want a least of the form $(s,t,e)$ where $s\in S$, $t\in T$, and $e$ is the bottleneck edge for some route from $s$ to $t$. We don't need all possible bottlenecks for a route but just one of them, and it is better if the set of bottlenecks we get is minimal. Questions I am looking for references on algorithms for this or similar problems. Does this problem have a name? 

If we consider $f(x)=n$ then we get the definition of $n$-c.e sets. They don't need to be c.e. because c.e. is not closed under complement. Take two c.e. sets and take their difference. It is a $2$-c.e. set but it does not need to be a c.e. set. Barry Cooper and colleges have been interested in these sets and the notion of computability in limit. You may want to check his "Definability in the Real Universe" article from "Computability In Context: Computation and Logic in the Real World". 

Multiplication is complete for $\mathsf{TC}^0$ and this is a well know result. The reduction is from Count (number of 1 bits in a binary number). Comparison of binary numbers is in $\mathsf{AC^0}$ so $\mathsf{Majority}$ is reducible to $\mathsf{Count}$. To reduce $\mathsf{Count}$ to $\mathsf{Mult}$ do as follows: consider input is $a_0a_1\ldots a_n$. Insert $k$ 0s between $a_i$s and call it $a$. Multiply it with $b$ which is like $a$ except that $a_i$s in it are replaced with 1s. Pick $k>3n$. The number in the middle section of $ab$ is the answer. The reduction is in $\mathsf{FO}$ and shows that $\mathsf{Count} \in \mathsf{FO(Mult)}$. 

Assume a framework in communication complexity where we have two players A(lice) and B(ob) and a R(eferee). A and B don't communicate directly with each other. In each round of communication, each of them sends a message ($m_A$, $m_B$) to the R. R computes two functions $f_A(m_A,m_B)$ and $f_B(m_A,m_B)$ and sends the results to them. The functions are fixed. The idea is that the communication between the players is restricted. Moreover the referee might do some processing on the messages. Example: A and B send two (arbitrary large) numbers to R, R checks which of them is greater and informs the players. In this framework, we can design a simple protocol that easily computes the following function using a single round. A and B send $x$ and $y$ to R, R returns the answer to them, and they output the answer. $$f(x,y)= \begin{cases}0 & x\leq y\\ 1 & ow \end{cases}$$ Obviously this is not an interesting case, since the function we are computing is the same as the referee functions. A more interesting case is when we have a fixed linear inequality $\vec{a} \cdot \vec{x} \leq \vec{b} \cdot \vec{y}$ and the values for the variables are partitioned between players (A has $\vec{x}$ and B has $\vec{y}$). The task is to decide if the inequality is correct. The protocol in this case is that players compute their part and then send them to the referee. Question: Has this kind of communication complexity been studied? If yes where can I find more about this? 

The time and space hierarchy theorems relativize. They are uniform, so they don't seem to naturalize. I think indirect diagonalization results like the TimeSpace lower bounds of Lance Fortnow, et al. and also Ryan Williams's result do not relativize because they are not black box (but I am not sure about this). The proofs don't seem to naturalize since they use hierarchy theorems. The proofs of permanent not in uniform $TC^0$ use hierarchy theorems and don't seem to work for nonuniform case, and doesn't seem to naturalize. On the other hand, I don't know if they relativize, they may with a suitable notion of relativization. 

Is the evaluation problem for $\mathsf{AC}^0_d$ circuits in $\mathsf{AC}^0_{d+1}$? What is the least depth $k(d)$ such that the evaluation of an $\mathsf{AC}^0_d$ circuits can be computed in $\mathsf{AC}^0_{k(d)}$? How about the evaluation problem for $\mathsf{TC}^0_d$ circuits? By evaluation problem for a complexity class $C$ I mean the following promise problem: 

What is the best known speed-up result of deterministic computation by nondeterminism? What about $\mathsf{\Sigma^P_kTime}(n)$ or even $\mathsf{ATime}(n)$ in place of $\mathsf{NTime}(n)$? Assume that complexity classes are defined using multiple-tape Turing machines to avoid the well-know peculiarities of the sub-quadratic time single-tape Turing machines. 

Note that there are known separations for some unbounded complexity classes, e.g. $decidable \neq computability \ enumerable$, and also equalities like $NPSpace = PSpace$ and $primitive \ recursive = nondeterministic \ primitive \ recursive$. (It is instructive to think about why the trivial padding using them is not helpful for settling P vs NP.) We should be more careful about what we mean by a question like $P$ vs $NP$ and $EXP$ vs $NEXP$. If $P$ vs $NP$ is a padded version of it (e.g. $EXP$ vs $NEXP$ and $E$ vs $NE$) then Boaz's answer will also apply to it. The evidence for $EXP \neq NEXP$ is much weaker than $P \neq NP$ and has less dramatic consequences, and there are people who find $EXP = NEXP$ plausible so the situation is more complicated there and we have a much weaker intuition about the expected answer. An equality will not help in practice and it is not known to have a effect on the really interesting case which is $P$ vs $NP$, and an inequality is formally and conceptually as difficult as an inequality between $P$ vs $NP$. 

Knuth's "The Art of Computer Programming" would probably be the book with the highest ratio. If you want a more textbook style book then Cormen, Leiserson, Rivest, and Stein's "Introduction to Algorithms" would be my suggestion to a mathematician. There are also many lecture notes and a few Wikibooks on algorithms. 

It is in uniform AC0 = AltTime(O(1), O(lg n)). Bit(j,i) -- the i-th bit of binary representation of unary number j -- is in uniform AC0. See e.g. Cook and Nguyen, Logical Foundation of Computational Complexity, 2010. Comparison then is just two log bounded quantifiers. 

My main question is the one above. But it would be interesting to know about the following generalization of the problem. Let $B$ be $A$ sorted according to some comparison oracle $\leq$ and $f$ a function given by an oracle. Given $A$ and oracles for $\leq$ and $f$, what can we say about the time needed to compute $m = \max_{i \in [n]} f(B[i],i)$? We can still compute $m$ in $O(n \lg n)$ time. But can we prove a super-linear lower-bound for this generalized case? If the answer is yes does the lower-bound hold if we assume that $\leq$ is the usual order on integers and $f$ is a "nice" function (monotone, polynomial, linear, etc.)?