To emulate this project, I am trying to first add a reference to Microsoft.Build.dll. But Visual Studio warns me that it cannot load the .dll. I looked at MSDN and the document referenced Microsoft.Build.Evaluation. This is suppose to be available in the Microsoft.Build.dll and then I'll have access to the Project class. Has anyone had any experience with this? 

This helps you keep a high level of organization which will be very important as data content grows, game content expands, etc. Edit After actually attempting to use .ODS (OpenOffice Calc file) and connecting from an application, it is actually not possible as initial posts on OO site implied. I could not find anything specifically showing teh codez on implementation. Also, using Excel files might be okay while developing a game so data can be tweaked without overhead from a database. However, and this is important, if you plan on doing this, you must have MS Office installed so you can reference Microsoft Excel Interop COM. This may be beneficial at first, but I wouldn't want to remove or change a bunch of code to get an application ready for Alpha, Beta, or RC. A very simplified library would take more effort than I could see being useful. I am going to use .CSV files for early stage data storage. There are some drawbacks, but overall I feel this is a much better option. Everything is contained within my libraries. .Net has very useful classes for reading these text files. Also, as .CSV files, the data is easily manipulated; and, for later stages of development, all I need to do is have my data files serialized to XML, then later to serialized encrypted binary. 

Excel is an excellent solution.I had been wondering how this should be done. But thinking about it, Excel is while a very popular tool and quite adequate for this duty, I would not recommend this practice. Additionally, actual database, as @notabene suggests, brings a lot of extra overhead that you really don't need. I see a couple of options, one of which is akin to using Excel: 

I am not using Unity or XNA. Eventually, I will probably use OpenTK for graphics. But for the concept of a game I'm writing, I am using the console for keyboard input and visual logging of events, etc. I am also using a WPF window to display world and player data. Update: I am using 0 deg as North. I understand that this may not be 'standard'. I don't mind switching to the standard where 0 deg is East if necessary. The standard keys are W, A, D, S and Left/Right arrows. W: move forward A: move left D: move right S: move backward L Arrow: rotate left 2.5 (degrees) R Arrow: rotate right 2.5 (degrees) I am new to the physics of movement within a 2D space (as if I am looking down from overhead). What I have is a and model; each encapsulates an object. Edit: added the conversion to radians in the following method. Seems to work more correctly as long as the orientation is 0, 90, 180, or 270 degrees. Move Model: 

Is there a need for a dedicated, true game-oriented data library? Maybe...unless someone knows of such a library already in existence. To the point of the OP's question, look at each page csv file as a single data table - akin to a table in a database. Each page file should contain related data: 

...either way, free and you have complete control. I personally would be inclined to go with binary serialized and encrypted data. Two reasons: 

#1 I am trying to understand the rotation first of all. If is increased or decreased by 2.5 per rt/lf arrow key press, how do I keep the resulting value as a true degree value? #2 How can I use the degrees as the facing to properly move the entity? Btw, here are the methods: 

Draw the images or text with static location in an other spritebatch.Begin, which doesn't have a matrix transform. 

I also tried to create my own algorithm for tessellation, but it produced micro-cracking, then found this (on AMD's site if I recall correctly), which works like a charm: 

If your Health pickup is an object, you could set it to null if you detect a collision. The garbage collector will do the rest for you. But don't try to reference that object after it is null because it will give your a runtime error. 

This one means it will "wrap" your texture around the model and sample from the nearest texel. You should try out the other sampler states too. Mirror will mirror your texture if the texture coordinates are outside the (0,1) bounds. Clamp will not tile your texture. You can also do it in the shader while you are declaring your sampler: 

If you want your faces to not be uniformly lit, you should have smoothed normals on the faces. You can achieve this, by having your vertex normals account for their adjacent faces. So each corner should have one normal which points outwards, not three normals for each face. 

Set culling to cull front faces first, then render your clouds. This will render the backfaces. After that, switch culling to cull backfaces, and render the clouds, which will render the front faces on top of the back faces. This will prevent rendering your backfaces on top of the front faces, but still keep back faces visible all times. Update: From the pictures, I see that the backfaces are only visible when you are inside. Just switch the order of the above instructions: Render front faces first, backfaces later so they are discarded by the z buffer if you are outside. Just render with culling disabled in that case. 

Could anyone solve this problem and if yes, how? I imagine many games use this method to select the correct input method for gamepads, but the problem is not common at all. For the time being, I began writing a wrapper for raw input but I'd be happy if this also got solved. 

I would advise against coming up with your own logic like pausing at the last frame of animation, or such if you plan on doing more animations later. I've done this when I started and it can very quickly go out of hand. You could accomplish this with a state machine. This is a simple yet very easily customizable way of doing animations in case you implement it well. This is used very often in game development. For example, you define a start state, "idle" where the standing animation plays. From there you could go into several states which have different rewuirements. For example, the ducking state has a requirement of inputting the down key. You could create three states: duckStart, duck, duckEnd. DuckStart state: from idle state you could go to this state if you input down key (just an example). The animation where the character goes from standing, to ducking animation plays. Duck state: you can go to this state, from duckStart state if the duckStart animation reached its last frame and you are still pressing down key. DuckEnd state: you can go to this state from duckStart state, or the duck state if you cancel the down key press. You could look up Finite State Machines for further information. 

It would tile it but I imagine you would probably want some controlled tiling? And for that you have to modify your uv texture coordinates by hand for every vertex. 

Try not to think in screen position, but world position. Place the emitter above the camera position with some offset each frame and spawn particles from there.