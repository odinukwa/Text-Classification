However, there are only archives up to about *.log.8.gz, so logrotate fails when it tries to interact with . Why on earth is it trying to do that? I suppose I need to touch fake files to fill it out? This seems wrong somehow. 

I have an nginx instance that is set to log access to /var/log/nginx/access.log and errors to /var/log/nginx/errors.log, but as soon as logrotate runs each week, the file gets moves to *.log.1 and the new *.log file gets created, but nginx continues to log to the log.1 file instead of the new .log file (and nothing gets gzipped). The first time I noticed this, it had been 3 weeks since the log rotation and the log was getting huge. Running made nginx start logging to the right place again, but the problem started again the next week. The more important reason this is frustrating is that I have the logs set to upload to Loggly via rsyslog, and when nginx stops logging to the file I have rsyslog polling, then things stop uploading and I don't get any alerts. I suspect it has something to do with restarting nginx, or reloading the config, because it didn't start until I had made a config change and reloaded the config in a way that I thought was normal. I tried running but the files continued to get logged to the wrong location until I ran , which I already know does not solve the problem. Any idea of what's going on? I admit I'm no expert on logrotate or nginx administration, but my Googles have failed me on this one. Here is my nginx logrotate script, and let me know if there's anything else you might want to see. The nginx.conf has nothing special in it with regard to logging, other than defining the output locations. 

Our small startup company plan to deploy a web application on Glassfish, I and wonder if some of the experience user out there can answer me couple question. When I shopping for server, I usually look at RAM amount, as GF does required good amount of RAM to run, below are the two sites with significant price different for the same amount of RAM. I wonder why?? Godaddy: $URL$ Versus $URL$ Does below plan from Godaddy consider good to run GF application. 

I need to change to . Here is what I've been trying: I configurate the . I have still have default Network Listeners to be http-listener-1 and http-listner-2. I change the Default Web Module to (The only option in the drop down list, since I only deploy 1 application). For the , I try this 

I am working on a email confirmation for a website and I am really new to this. So if anyone please kindly show me how to set up postfix to send out mail. I only need to send out mail (Plain text is fine, although encrypted mail would be a plus). I am using Java to send out mail. Please help please 

Here is problem I have. So I download mysql 5.5.13 on the web site, but when I the packages, it required me to update glibc. 

I attend and work at a university where we have a packet shaper (an old Packeteer -- 3-ish years old or so) which relegates P2P traffic to the lowest priority in the queue in order to prevent P2P abuse (BitTorrent, etc.). However, the game StarCraft 2 was just released, and from what I've been able to gather, it requires P2P to be available to play the game online. We have already enabled all the ports that the game requires, but its P2P traffic, of course, is not getting through during peak network usage hours due to the high demand, making gameplay impossible outside the hours of 4am-6am. As far as I know, I don't know a way to tell the packet shaper to not limit P2P traffic of only a certain type (i.e. StarCraft 2 P2P traffic). Is there a way to do this? Or would we need a different packet shaper? 

Thus, when cron starts back up upon a reboot, it waits for networking to get up, then restarts the cron daemon. That fixes the problem of crontabs not being read at all for LDAP users. However, since it's the cron daemon being restarted and not the computer, entries are ignored. Is there a way for a user to make a command run upon restarting the daemon, rather than a reboot? Or is there a better solution to this overall problem? Thanks. 

Now from my machine, if I try to connect to this db via (mysql client software), well I cant. Well from the table above, seem like it only allow localhost to connect to this db. Keep in mind that both my db and my GF are on the same VPS. Please help 

Both does not work. What does docroot need to point to, for this to work? what I try to do is: when I type localhost:8080/ScholarActive-war, then my application load, I want to make so that if I type locahost:8080, it will load the app as well, then what left is changed the port to 80. But no luck. Any Idea? 

On my Ubuntu VPS, i have a mysql server running and a Glassfish 3.0.1 Application Server running. And I am having a hard to have my GF successfully ping the database. Here is my GF set up Assume: is the ip of my VPS 

I am reluctant to do it, since I might break stuffs (system calls, script and other things). For some reason, my SUSE does not have either. (This is the company server not my personal server). So my guess would be to downgrade the mysql server rpm package to some thing that compatible with SUSE 10.3 without the need to upgrade . 1.Does anyone know what version of mysql server that compatible with SUSE 10.3 out of the box? 2.I am using SUSE Enterprise Edition 10.3, what is the likelihood that when i update glibc, something will break. I have lot of bash script running, and I am scare if I update glibc, there is chance that my bash script will not work anymore.