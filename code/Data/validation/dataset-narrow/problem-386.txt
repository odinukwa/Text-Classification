I have a primary database in recovery mode which is part of group. Is there a way to minimally log insert operation under recovery model? I have a process that is executed each day and insert few millions of records in a table. While the operations continued the transaction log file size is increased dramatically ( from 1 GB to 40 GB). As I have read I can used some variations of which are not fully logging the operation but I am concern about the effect of switching the recovery model? 

As you can see each entry is updated in different times on different date. Could anyone tell why this is happening? 

I am going to create history table which is populated by trigger (after insert, update, delete). As only 20% of the columns are going to be updated, I decided to log only the changed values - if the values are not changed, value is going to be used in the history table. For example: 

It might be slow, especially if there are millions of records, so I optimize my application by using a paginated user interface that will display 50 records at a time. So for example, I want to get records 101 to 150 because the user decided to go to page 3, I might say something like 

I am looking for a technical term (or phrase, or something concise) that describes the process of limiting the number of records returned from a query through the use of and . For example, I have an application that displays a bunch of records in a table. If I do something naive like this 

Does writing make it any more clearer that the column is meant to hold an ID of a team (as opposed to maybe a team name)? If I saw that was linked to a key on the table I would assume the column is meant to hold an ID. I find that if I started following a convetion where I tack on I'll end up with a lot of columns with in them, but am not sure whether it adds any value. 

When the temporary table is used, the correct count value is used for the rows returned by the function. All involved indexes are rebuilt. Why I am worried about this? This join is part of more complex query which execution is very slow. I believe this is due to the fact that the statistics that are used by the engine are wrong and not the optimal execution plan is used. Even when the query use parallelism again nested loop is used to join the tables. If I use a or hints on join the correct statistics are used and better execution plan is built but I prefer to find a way to provide the correct statistics instead of forcing the engine to do something. Could anyone tell why always one row is expected? Maybe because table-valued function is used, the engine thinks one row is going to be read from the table/index? 

I don't know what kind of words I should be using to describe my design decisions so that others will immediately understand what I'm doing. 

I have a list of records that contain a column of arbitrary strings. I would like the application to display them sorted in some order (preferably alphabetically, since humans have to read the data). I can choose to have the database sort the data before returning it to me, or I can choose to have the database give me the raw search results and let the application deal with it. Currently the database is sorting it cause I don't think I can write a very efficient sort anyways, but I'm wondering whether there are any situations where I want a sorted list, but it would be better to have the application do it? 

I have found that you can do on columns using the clause(example here and here). Unfortunately, there is nothing mentioned about performance optimization in the official documentation. Could anyone tell is there any optimization at all? Has anyone made some performance test? Also if there is optimization I guess it will affect only specific situations, too. 

Its body statement is executed for 0 seconds (with given parameters). The function itself (with the same parameter is never executed - I was waiting for 20 minutes and only part of the result was returned). There must be something wrong with the statistics and respectively the query execution plan that is created because the function is executed instantly: 

Does this mean, that if I used same password to create and protect each DMK in my databases across all instances, the key will be the same? If not, it is OK to create a DMK on one database, and to restore it on all instances in order to have the same key everywhere and to need make a backup of only one key? 

We have a couple queries that involve datetime fields. In particular, we are checking for things like 

I have a table of Teams. Each has an ID. I have another table that holds Players. Each is assigned to a team. So my tables might look something like 

What are some practices for designing a table, or queries, when it comes to case-sensitive data and case-insensitive queries? For example, I have a table that holds household goods, and presumably because I intend to display this data on a client, I would like to have the original names. If one of the products is called "Vacuum Cleaner" and someone's doing a search through the database for vacuums, I wouldn't want a term like "vacuum" to not find this particular vacuum. Currently I am using Postgres so I could probably get away with the operator, but if a database system didn't support this kind of operator, what would be some alternatives? 

Basically, the index is created for 20 minutes, so I need a way to guarantee user experience is not blocked. The alternative is to have separate window for maintenance in which the database to be in single user mode. 

I guess this means I need to use one of these types of encryption in order to be sure the data is protected? 

I am testing feature and once the operation of encrypting column is done I have a file with hundreds objects failed to be refresh by the procedure. Should I investigate these errors and perform the refreshing by myself? What are the risks of not doing this? 

Does this mean that I do not need to care(renew, backup, etc) about Service Master Key and Database Master Key as I am using external keys to protect the Symmetric Keys? When a new key vault is created the location is specified: