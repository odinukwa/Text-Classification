Every context free language over a one letter alphabet (or equivalently every langauge recognized by unary PDAs, unary DPDAs or 1 counter machines) is regular. See: S. Ginsburg, H. Rice: "Two families of languages related to ALGOL", Journal of the ACM, 9: 350â€“371, 1962. For what regards PDAs with bounded stack reversals they are equivalent to bounded context-free languages. In general a language $L$ over alphabet $\Sigma$ (with $|\Sigma|\geq 2$) is bounded if and only if there exists non empty words $w_1,w_2,...,w_n$ such that $L\ \subseteq w_1^*w_2^*...w_n^*$; but not all bounded languages are context-free (for a characterization of bounded CFG languages by finite union of stratified linear sets see Ginsburg's theorem). I don't know much about them, but they have been studied intensively, see for example: Oscar H. Ibarra, Bala Ravikumar , On Bounded Languages and Reversal-Bounded Automata (citing and cited articles). EDIT: another result is that linear LR(1) languages are equivalent to the class of languages accepted by deterministic one-turn PDA (M. Holzer, K. J. Lange, On the Complexities of Linear LL(1) and LR(1) Grammars) 

following the definition, convert each $(X_1 \vee X_2 \vee \cdots \vee X_k)$ clause of the 1-in-$k$ SAT problem into $(X_1 \wedge -X_2 \wedge \cdots \wedge -X_k) \vee (-X_1 \wedge X_2 \wedge \cdots \wedge -X_k) \vee $ $\cdots \vee (-X_1 \wedge -X_2 \wedge \cdots \wedge X_k)$; convert to CNF distributing ORs over ANDs; convert the resulting CNF formula to $k$ SAT 

I was interested in finding the center of each zone; if you are interested in the exact length of the bridge you can use various techniques. For example: 

A simplee trick (explained here) that let you use the $\log$ approach even when you must sum probabilities. Problem: $\log(\exp(a) + \exp(b))$ can lead to an underflow, to avoid it you can use this formula: $\log(x + y) = \log(x) + \log(1.0 + \exp( \log(y) - \log(x) ) )$ Or use another approach: $\log(\exp(a) + \exp(b)) = \log( \exp(a - C) + \exp(b - C)) + C$ Setting $C = \max(a,b)$ For example: $\log(e^{-120}+e^{-121}) = \log(e^{-120}(e^0 + e^{-1}))= \log(e^0+e^{-1})-120$ 

EDIT (Aug 1): I posted a small report with a more detailed proof on my blog; the reduction idea is the same, but the "gadget" used are better explained (you can also directly download the pdf from here) 

Not all information relevant to the planning of the routes is known by the planner when the routing process begins; Information can change after the initial routes have been constructed. 

I think that it is linked to the PCP theorem (in particular $NP = PCP[O(\log{n}), O(1)]$). An excerpt from a Madhu's paper: ... The notion that a verifier can perform any polynomial time computation enriches the class of theorems and proofs considerably and starts to offer highly non-trivial methods of proving theorems. (One immediate consequence is that we can assume theorems/proofs/assertions/arguments are binary sequences and we will do so henceforth.) For instance, suppose we have an assertion $A$ (say the Riemann Hypothesis), and say we believe that it has proof which would fit within a 10,000 page article. The computational perspective says that given $A$ and this bound (10,000 pages), one can efficiently compute three positive integers $N, L, U$ with $L \leq U \leq N$ such that $A$ is true if and only if $N$ has a divisor between $L$ and $U$. The integers $N$, $L$, and $U$ will be quite long (maybe writing them would take a million pages), yet they can be produced extremely efficiently (in less than the amount of time it would take a printer to print out all these integers, which is certainly at most a day or two). (This specific example is based on a result due to Joe Kilian, personal communication) ... ... far beyond my complexity theory skills :-) 

Consider $X$ an $\mathsf{NP}$-complete language e.g. $3-SAT$. I'm looking for an algorithm $A$ for solving $X$ with the following property. Given $M \subset \lbrace 0, 1 \rbrace^*$ any set of words s.t. $X$ with promise $M$ is decidable in polynomial time, I require $A$ to decide $X$ with promise $M$ in polynomial time 

The motivation for the question comes from Levin search which would satisfy the above condition if we considered the candid search problem instead of the decision problem Is the answer affected by adding the assumption $M \in \mathsf{P}$? 

It is possible to restrict attention to functions $u:\lbrace 0,1 \rbrace^* \rightarrow [0,1]$ since any function satisfying the 2nd condition can be brought to this form by a linear redefinition Consider $u$, $v$ asymptotic optimization problems. $f: \lbrace 0,1 \rbrace^* \rightarrow \lbrace 0,1 \rbrace^*$ is a called a reduction of $u$ to $v$ when the following conditions hold: 

Consider any language $L$. Define $s(L) \in {\lbrace 0, 1 \rbrace}^\omega$ (an infinite sequence of bits) by the recursive formula $$s(L)_n=\chi_L(s(L)_{<n})$$ Here $\chi_L$ is the characteristic function of $L$ i.e. $\chi_L(w)=1$ for $w \in L$, $\chi_L(w)=0$ for $w \notin L$ A language $U$ is called a "universal (closed) predictor" when $$\forall L \in \mathsf{P} \, \forall n>>0:s(L)_n=\chi_U(s(L)_{<n})$$ It is easy to see $U \notin \mathsf{P}$ by considering $L = U^c$. However, $U$ can be recursive. To give an example, consider the language decided by the following algorithm $A$. Given input $w$, $A$ runs all possible programs in shortlex order, allowing each to execute for time $t(|w|)$ where $t$ is a function of superpolynomial growth. Once it reaches a program $R$ that outputs $w$ plus one or more bits and doesn't halt, $A$ outputs the first bit $R$ outputted after $w$. It easy easy to see that (under mild conditions on $t$) $A$ always halts and the language it decides is a universal predictor. $A's$ time complexity is approximately $2^nt(n)$ Given $a \in {\lbrace 0, 1 \rbrace}^\omega$, define $s(L, a)$ by $$s(L, a)_{2n} = \chi_L(s(L, a)_{<2n})$$ $$s(L, a)_{2n + 1} = a_n$$ A language $V$ is called a "universal open predictor" when 

To understand the motivation for the easiness condition, note that if $f$ is s.t. the formulas it produces only have existential quantifiers (which implies $f^{-1}(\textsf{TQBF}) \in \textsf{NP}$) then the condition requires that not only $f^{-1}(\textsf{TQBF}) \in \textsf{P}$ but that the $\textsf{NP}$-witnesses can be produced in polynomial time (in fact it is even stronger: we should be able to complete any prefix to an $\textsf{NP}$-witness whenever possible). 

Consider a set of $n$ MDPs (Markov decision processes). An MDP $M$ is selected from this set according to some probability distribution $\xi$ and then interacts with a fixed policy $\pi$ for time $T$ yielding a total expected reward of $V_\pi$ (where the expectation value is w.r.t. $\xi$, the random transitions in $M$ and possibly random decisions by $\pi$). The problem of designing a policy such that $V_\pi$ is as high as possible is known as reinforcement learning (specifically, we only consider here the special case of model-based Bayesian reinforcement learning with a finite set of $n$ models). A policy $\pi$ for which $V_\pi$ equals the highest possible value $V^*$ is said to be Bayes optimal. It is often claimed that computing a Bayes optimal policy is intractable, therefore we need to use algorithms that are not Bayes optimal but still satisfy good performance bounds (e.g. PSRL or some UCB algorithm). However, I am not sure to which extent this intractability is backed by complexity theoretic hardness theorems? In fact, this kind of reinforcement learning can be regarded as a special case of solving a POMDP (partially observable Markov decision process). Namely, we can consider a POMDP $\hat{M}$ in which a random transition at the initial state samples $\xi$ in a manner which is unobservable, and the resulting MDP $M$ governs the following transitions. Now, Papadimitriou and Tsitsiklis proved in 1987 that solving POMDPs is PSPACE-hard. The proof works by reducing QSAT to computing the value of a POMDP. Moreover, examining the reduction shows that the POMDP they construct is exactly of the form $\hat{M}$! Specifically, the random unobservable transition in the beginning serves to select a clause in the formula of the given QSAT instance. Thus, Papadimitriou and Tsitsiklis's result indeed shows that finding a Bayes optimal policy is intractable (under standard complexity theoretic assumptions). However, notably, their proof only works when exact Bayes optimality is required. This is because the universal quantifiers in the QSAT instance are replaced by random transitions in the MDP, which means that it might be possible to achieve high reward even for unsatisfiable formulas. Now, Goldsmith, Lusena and Mundhenk proved in 2001 that even approximating the value of a POMDP is intractable. However, in their proof the POMDP is not of the form that interests us. More precisely, they start with a basic construction that is of the form $\hat{M}$, however they require a probability amplification that runs the basic POMDP many times, and each time it runs the unobservable part of the state is randomly reset. So, AFAIK, it seems possible to have e.g. a polynomial-time approximation scheme that accepts a set of MDPs and $\xi$ as above and produces an $\epsilon$-approximation of $V^*$. Such a scheme would be possible to use to compute a nearly Bayes optimal policy (with $V_\pi \geq V^* - T\epsilon$). Does such a scheme exist? Or is there another theorem that forbids it? 

Note that any computable language $L$ can be turing-reduced to any other language $L'$ which contains at least one yes-instance and one no-instance (i.e. we have $L \leq L'$) by letting the reduction mapping do all the computation and then mapping to a yes-instance of $L'$ if the original instance is in $L$ or a no-instance of $L'$ if it is not, so naturally a decidable language like $\mathcal{E}^\ast$ can be reduced to the halting problem. However, we cannot reduce the halting problem $\text{HP}$ to $\mathcal{E}^\ast$ as $\mathcal{E}^\ast$ (assuming that your alphabet is $\{0,1\}$) contains every possible input and thus has no no-instance. Therefore it is not possible to find a function that maps the no-instances of $\text{HP}$ to the no-instances of $\mathcal{E}^\ast$ as there are none (or more differently: since $\mathcal{E}^\ast$ is decidable, we cannot reduce $\text{HP}$ to it as it is undecidable and the existence of a reduction would contradict that -- can you see why?) 

On the first question: First off, I do not think the statement $\mathsf{XP} \subseteq \mathsf{NP}$ is meant to be implied at that point. To explain what is meant, let me ask a question: What is the parameterized counterpart to $\mathsf{NP}$? This question naturally arises when defining a notion of intractability of parameterized problems as classical intractabilty is thought to correspond with $\mathsf{NP}$-hardness. A first attempt yields $\mathsf{ParaNP}$, basically a nondeterministic $\mathsf{FPT}$, but a theorem states that if some parameterized problem $(L, \kappa)$ is $\mathsf{ParaNP}$-complete, then already a finite union of slices (the $k$th slice of $(L,\kappa)$ is the set of instances $x$ in $L$ of parameter $\kappa(x) = k$) is already $\mathsf{NP}$-complete and thus all the hardness is already exhibited by some parameter values. Conversely, it means that problems whose slices (for fixed $k$) are solvable in polynomial time are not $\mathsf{ParaNP}$-hard -- thus this class does not yield hardness results for problems like SAT (parameterized by the number of variables), $k$-Clique (parameterized by the size of the solutions) and many other problems which are believed not to be in $\mathsf{FPT}$. Now, (uniform) $\mathsf{XP}$ deals exactly with this kind of problems whose slices are in $\mathsf{P}$, but the definition allows for very large running times if the parameters get large w.r.t. the input size and indeed, if we parameterize by the input length, we can use exponential time algorithms and as such, $\mathsf{XP}$ contains problems from $\mathsf{EXP}$ using some suitable parameterization, but not problems like $k$-Colorabilty parameterized by $k$. So neither $\mathsf{ParaNP}$ nor $\mathsf{XP}$ are the class that we sought out to find and in this light, we can (sort of) understand that slide as an attempt to partition the landscape of $\mathsf{NP}$ problems and their parameterized versions into somewhat meaningful parameterized complexity classes (however, it suggests $\mathsf{XP} \subseteq \mathsf{ParaNP}$ which is not the case). On the second question: Arguably, one can interpret the statement $\mathsf{XP} = \mathsf{NP}$ to mean that "the class of unparameterized versions of the naturally parameterized problems in $\mathsf{XP}$ coincides with $\mathsf{NP}$" and since membership in $\mathsf{XP}$ means that the slices of a problem are in $\mathsf{P}$, we get that unless $\mathsf{P} = \mathsf{NP}$ there exist some problems in $\mathsf{NP}$ which are not in $\mathsf{XP}$ when using some parameterizations (like $k$-Colorability parameterized by $k$) and thus falsifying our interpretation of $\mathsf{XP} = \mathsf{NP}$. This of course is a bit speculative, but given that one class is parameterized while the other is not together with the results we have seen, I have no better interpretation to give. Sources: M. Grohe, J. Flum: Parameterized Complexity Theory