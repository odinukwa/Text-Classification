I've been doing Agile development for more than four years, including my SQL Server projects, and I really like it. I think it is important to understand why and when Agile is useful, from the perspective of the whole system, and general purpose Agile-related books such as the following fit the bill: " Agile Principles, Patterns, and Practices in C#", " Patterns of Enterprise Application Architecture". The following two books are focused on database development, as you asked, but I would read the general purpose ones first: "Agile database techniques", "Refactoring databases" 

It saves me a few keystrokes. Yet I think naming conventions are very subjective and as such I don't have a strong opinion one way or another. 

I think SQL_Kiwi provided a very good analysis. If you need to solve the problem in the database, you should follow his suggestion. Of course you need to retest that it still works for you every time you upgrade, apply a service pack, or add/change an index or an indexed view. There are three other alternatives: 

Overall, 755 times out of 10000 the COUNT(*) results were not multiples of 10. Of course, every time time we run this repro script, we shall be getting somewhat different results, but we should still frequently get wrong totals. Edit: the explanation is quite simple: although a select running under REPEATABLE READ does acquire a range lock on the rows it has read, this range lock does not prevent inserting new rows. As such, when some of the 10 new rows get inserted into the pages which have already been read by the select, the do not get counted. 

As usual with such problems, it is very easy to accomplish in Java or C++ or C#. If you really need to do it in the database, you can use an RDBMS with fast cursors, such as Oracle, write a simple cursor, and enjoy fast performance without having to write anything complex. If you need to do it in T-SQL, and you cannot change database design, Itzik Ben-Gan has written up several solutions in "MVP Deep Dives vol 1", and some new solutions using OLAP functions in his new book about window functions in SQL 2012. Alternatively, you can add another column consecutiveMarker to your table, and store precalculated values in it. We can use constraints to ensure that pre-calculated data is always valid. If anyone is interested, I can explain how. 

I want to conduct stress test on our MySQL DB. I have the list of queries i need to execute. I have tried using Apache JMeter for this but it is very time consuming. Is it possible to run mysqlslap with custom .sql file containing INSERT, UPDATE, SELECT queries on specified MySQL database? 

I am trying to evaluate AWS RDS to use as possible DB for our application. I have created a DBInstance(micro) and added IP security group. I am able to connect to the DBInstance from Xampp shell command line and i am able to run queries from that. But when i try to connect with workbench to the same DBInstance, it gives me error that 'MySQL server has gone away'. Following are the steps i followed to connect with workbench: 

Give the Endpoint address of DBInstance as Hostname. Port : 3306 Set the username and password to master user and its password. 

Is there any tool available which can do stress testing using the log file created by MySQL general log? After a lot of search on google I found few stress testing tools which only use some benchmarks for stress test. One solution is using Apache JMeter, but it does not create test plans from MySQL log file and creating custom test plan for all the queries I have is too time consuming. Or is there a tool which can at least create .sql file from MySQL log? 

I am new to MySQL and linux and also AWS. Previously i have worked with windows azure and .NET framework. Currently I am trying to get DBT2 benchmark to run for AWS RDS for MySQL. I was able to connect to RDS with shell command line from MySQL. But i was not able to configure or install the benchmark on the DBInstance. To configure the dbt2 one needs to run shell script on the system. So far i have 'cd' to directory where files for dbt2 are located. But when i try to run './configure' it gives error that "'.' is not recognized as an internal or external command, operable program or batch file." Same error if i use 'sh ./configure'. I am just a starter in this, is there something i am doing wrong? How can i even run any shell script on AWS RDS system? Any help is appreciated. 

If you switch to snapshot isolation, this effect should be gone. The following repro script shows how COUNT(*) running under REPEATABLE READ returns wrong results with high concurrency. Prerequisites We need a table with data and a function that provides random integers: 

If you use a multi-statement UDF, then your inner select is executed exactly once for each outer row. The multi-statement UDF is treated as a black box: the execution plan will now show access to the objects used in your complex view. On the other hand, a subquery and/or an inline UDF is flattened out by the optimizer. When this is the case, the execution plan will include access to the objects used in your complex view. 

Note that your design does not prevent cycles. We can easily enforce that via constraints as well. I can elaborate if you are interested. Regarding the efficiency of finding qualifying descendants, we can add some redundant data and get much better speed. For example, E is a descendant of A, but not a direct one - B is between them. We can store the following rows: 

I have been doing unit testing T-SQL for more than four years so far. I think it much easier to use C#, which is more versatile. For example, in C# I have no problem unit testing a stored procedure that returns two or more result sets - it is plain impossible if you use T-SQL. I described the process in this article and in this blog post. 

The following behavior may be caused by missing indexes on referring side of your FKs: "the price changes take approx 1 hour to process (vs. 1-2 minutes) and sys.dm_tran_locks shows the transaction taking almost 90,000 different locks, compared to around 100-150 when foreign keys were being dropped/recreated" When a row is deleted or its PK/Unique is mutating, the database engine need to make sure there are no orphans. When there is no proper index to support it, it scans the whole thing. 

This means that there can be no overlaps. As you have seen, for every time window, there can be at most one preceding it, and at most one following it. The following interval cannot begin before the end of its previous one. Together these two statements mean that there can be no overlaps. **