Maybe you need to build more textures if your level is too long... or you can modify the texture scrolling it and adding new columns of pixels in the scroll side. 

How can achieve this? EDIT: I've just relized that the NoWriteColors.ColorWriteChannels1 should be NoWriteColors.ColorWriteChannels. :) Now it's clipping right. Any other approach? 

2) really you need to move the verticesd that way? When you draw a model is usual to pass a model transform matrix as argument to the shader, use it to translate your model. 

Later you can use this class as base for other components like AnimatedSprite, Enemy, Player, Background, ... Usually there is no problem with having many sprite objects... but is known that changing too many times the drawed texture can cause a penalty... but is easily solved ordering by texture with SpriteSortMode.Texture in your spritebatch.Begin() method or using testures atlas to avoid using too many textures. $URL$ 

In this video I show how do it with code...the projection/view is isometric, but all calcs are done in 3D... $URL$ When I calculate the mouse ray, I check for collision against a plane... but the procedure is analog to check against a list of boundingspheres associated with your objects. The algorithm should be similar to this: 

is not used to cause problems. the greatest problem is class or struct name collision. if you have this: 

Maybe you should use the step trace to debug your execution flow... worth it... :) Anyway is a common copy/paste bug... hehehe 

The problem... i'm drawing polygons, in this case boxes, and i want clip children polygons with its parent's client area. 

If your grid array is displayed as a Rectangle(ox,oy, 10*CELL_SIZE, 10*CELL_SIZE), where (ox,oy) is an offset... then the cell coords are 

The issue with this is that it becomes evident that game engines are executing a lot of switch statements (eg the names of properties) in the View. 2.Declaring the view as updating to the entirety of the model. Eg, instead of saving the changes as specified in 1) the view updates the render objects on every tick by inspecting the entire model, as opposed to the provided changes of 1). The tradeoff between 1 and 2 is the necessity of the additional execution of storing the property changes on the state tick. 3.Declaring animation logic in the state logic. Eg, instantiated member render objects are dummy objects when rendering is not performed. The questions: 

I have been thinking about quad trees with regards to terrain rendering. From my understanding the basic functionality of quadtree terrain rendering is to frustum cull the terrain in such a manner: 

where node.bounds is a 3d bounds calculated as containing the maximum heightmap value of the contained terrain My questions are the following 

I would like to know the correct implementation to declare game logic and view logic: I see 3 ways of implementing this: 1.Storing (eg writing preprocessing to store the change to a property) property changes to data entities that are dispatched to listener(s) of the data entity. The main listener being the view, where the view contains the declared rendering logic (ie changing the entities animation based on a property change, changing the entities render object position). 

If we are in fact testing a 2d portion of terrain with it's bounds calculated to include the maximum heightmap value against the 3d frustum, what is the preferred bounds calculation for generating the node.bounds in the quadtree? That a tree is necessary because that one has to iterate every portion of a 3d scene to calculate frustum occlusion in a general way. Eg, there is no shortcut algorithm to calculate the set of 3d cells generated from a 2d grid that intersect the viewing frustum. As a more general question and to question the obvious, is there a way to calculate cells in a viewing frustum without having to iterate every cell in a scene? Presumably not otherwise you wouldn't need trees for culling 

The above code basically just checks to see if the enemy is either too far left or right of the target (x axis), or too far above or below the target (y axis), and if they are, moves them towards the target. You'll probably want to change the 's and 's for faster movement. and are the equivalents for your current speed. 

I'm not familiar with libgdx, but in general: Yes, you should definitely create a coin class. If all coins use the exact same sprite, you can make the sprite variable , so that it's only created once and shared by all instances of coin. Alternatively, if there is some variance between coins (for example, some coins are red and some coins are blue), you could implement the flyweight design pattern for similar efficiency. As for creating the coins, you can have the class take x and y positions as constructor arguments. Then you can create as many as you like, wherever you like, and store them in some sort of data structure (for example, an ArrayList). To make them generate in a line, offset their y positions by a fixed value multplied by the iteration of the loop they're being created in. Sample code to do this (won't compile, see code comments for details): 

In your method, you should be setting up the collision box after you add the vector to the player's . Otherwise the collision box will always be at the player's position at the last update, not the current one. When the player has a high velocity (such as when falling), this will make it appear that the box is lagging behind. 

From what I can see, all of your enemies are being updated with this line of code, so they're all being moved to the left rather than moving towards their desired target. That's why the ones off the right hand side of the screen appear and the others don't. Try changing your method to something like this (this isn't particularly good movement code, but hopefully it will help you see where you're going wrong): 

I wrote an article about auto tiling that is a technique used to achieve that. $URL$ Here is a video showing it running: $URL$ 

The grid has a plane associated. It should be Y=0, if you want to get 2D coords easily, the normal will be Vector3.UnitY If you want to do zoom you should do it by modifying the camera view The Camera.World has not sense, it should be the plane world... or the transformations that you apply to the grid... if you don't apply it should be Matrix.Identity 

B) Are sure you are calling to captureMovement()? Are you clearing the list every frame? Before or After calling updateGhost()? EDIT C) Is the ghost instance you are using in the turtle class the same you are using in the game1 class? D) I'm worried about the clearing of ghostmovements... where do you clear it? E) I have redone your ghost code using enums and a data driven approach 

Your movement vector is obtained substracting source position to target position and the angle usually in radians is 

The View Matrix is the Camera matrix, i usually use: Matrix.CreateTranslation(-Position.X, -Position.Y, 0) * Matrix.CreateRotationZ(Rotation) * Matrix.CreateScale(Scale) * Matrix.CreateTranslation(Viewport.Center.X, Viewport.Center.Y,0); This is the projection Matrix used by SpriteBatch (source) 

but I'm not sure that it is what you need... usually is used to work with a camera, so the viewport is fixed and you change the camera... like if you were watching tv... the tv, (your viewport), is fixed..., but the camera is what you moves to show other parts of the film's world. 

You should realize that usually the right way is the easy way... you should use matrix transforms... I'd do something similar to this: 

don't generate a plane from a normal, generate the bounding box and its corners... this way you will know what are the front, back, right, left, top and bottom sides, and the code is easier... if there are true AABB, you only need two points that keep min and max coordinates... and then knowing the intersection is much easier... 

An emergent system, perhaps? I think you're describing something very similar to emergence, which is when an ensemble produces a set of characteristics not displayed by any of its individual components. Tracy Fullerton's Game Design Workshop has an interesting section on games as systems, which might provide more insight. 

You should definitely do this in the class. However, your question seems to allude to something inhibiting you from doing this, although I'm not sure what. If you're worried about good code design, then it's fine to use and methods to retrieve and set the positions you need when detecting and resolving collisions. This doesn't violate encapsulation. A would also be extensible, meaning when you go to write other collision stuff, you can modify and generalise your rather than cluttering lots of other classes with collision logic. If you find an issue down the line with some collision code, it's much easier to change it once in the rather than lots of times in each individual class which implements collision detection/handling. Edit: Ok, I see what you mean now. You're describing continuous collision detection. I had discrete collision detection in mind! I'm not used to this type of collision detection, so I'm not going to be of much help. I guess you could work the character's position at the next update based on current velocity, etc. and pass that to the , but I'm sure there are better ways of doing it. You do have the option of using discrete collision detection, which is when you update the world, then check to see if anything has collided. If they have, you separate them, then render the scene. It's very easy to implement, and given that your game's a simple platformer, I can't see any major downsides to implementing it this way. It's up to you though! 

The first element on your struct ExplosionVertex is position, so the first element in your VertexDeclaration has to be VertexElementFormat.Vector3 Your VertexDeclaration has to describe your particle struct, and the order is very important 

You need to define a center for rotation... in this case the box center.. then when you detect the mouse down you store vector (A) from the center to the mouse coords... this is your initial vector.... ans should store your shape rotation as initial rotation. then while you move the mouse and it continues being down you calculate the second vector (B) from the center to the current mouse coords... now you can calculate the angle between to vectors... as you should know it can be calculated normalizing the two vectors and calcultaing the dot product... so you get the cosine... now you get the angle with an arccosine function... this angle should be added to the initial rotation of your shape... ans set the new rotation for your shape. so you only have to build your transform matrix for your shape... the easiest way is to store your vertex coords relative to the center of the shape, if you don't store that way you should get that points relative to it... Your transform matrix should similar to this... 

If you want to set your ship at the center and face to the mouse you have to use something similar to this. Keep in mind that maybe you need to add some angle offset (90º, º180 or 270º) to your ship to face in the right direction. 

if you are recalculating the difference maybe due the float precission lost when you convert to int. 

I think are doing over engineering the cubes... it would be easier to use an enum, it is better because let's you indexing cube properties in arrays or sorting the cubes easily, You don't need to store the texture and graphicsdevice for each cube... you can implement a CubeCollectionRenderer or similar where you manage that... 

The questions regarding other engines deals with the fact that perhaps it has been evaluated that it is not a sufficiently optimized implementation to consume the state in a View as opposed to executing direct calls to render objects. So, on tick we update the game data simulation. For example: 

As specified in the title, what is the correct implementation to reacting to the game state in the sense of where should one declare display/rendering/animation (view) logic that reacts to the game state? What is the implementation used in most game engines that facilitate large projects? (if possible, please specify for specific engines: SupremeCommander/clones, SC2, Unreal, ID, Frostbite, Anvil) Which implementation do studios implement to architect projects using said engines? It's apparent that it is possible to not seperate model from view in the above engines. Eg, if you implement an entity, you would presumably want it to be viable in multiplayer, coop, and single player. 

With regards to an alternative grid implementation: Has this implementation been contemplated for general purpose terrain culling? I am presuming that some form of grid base terrain culling is certainly preferred in certain games, namely top down games where the possibility of terrain in the distance of being on camera is non-existent. 

Is there is a way to calculate cells in a quadrilateral without having iterate every cell in a grid? eg, from shaving off cells from slopes or something? If there is, in what fashion should one assign the lod cell based on distance? I haven't contemplated this in detail because #1 may be impossible The terrain would not be optimally culled in this 2d culling algorithm against the quadrilateral frustum projection onto the heightmap, because the height value at the edges may be outside the screen, correct? $URL$ In this post, he describes assigning lod from a grid and from a quad tree. The illustrations are confusing with regards to whether question #1 is correct and terrain rendering with quad trees serves to draw the terrain mesh against the frustum as opposed to just as a function of distance 360 around the camera as at appears to do with his grid implementation. Please specify whether it appears that he is infact not frustum culling in the grid implementation but is frustum culling the quadtree. 

This can do the trick, though if angle between forward and playerForward is 180º, it won't turn If you need the angle... you can use this: 

I'm using this library to load content in background with no problems. $URL$ It let's unload individual assets, force file read (for editors), know the relationship among assets... it's worth 

When you resize, the backbuffer changes... so you have to recalc your control sizes... in the game class you can subscribe to this event to recalc your controls: 

In your draw method you have a destination rectangle and source rectangle, use them. Source is related to your texture, it would be the red box. Destination is related to your screen. 

Null reference exceptions are thrown because you are trying to access to a reference typed variable that is not assigned. In the UpdateMouse method code, the only candidate to throw that exception is the array, that maybe is not assigned, check it. 

I think you want something similar to this $URL$ I developed that for a 48h gamejam... you can donwload the code here... $URL$ I used something similar to your code to get the 3D coords... but I rotated the planet and the player was in the same pos, I think you are interested in the creature movement, is this: 

if you have to use the spritebatch, only accepts to draw rectangles, and you define the polygon in a map editor, why don't precalc the texture? You can still use your polygon for physics, only have to create its skin. 

you are changing the Diffusecolor in the same effect. there is no easy way to clone a model so the answer is before draw set the color properly for each model 

You should determine what side of the rectangle is colliding with the ball, and get the normal N of that side. If the ball movement vector is V, then the reflected vector is: