For unclear reasons, this problem no longer persists. It may be that it disappeared on Ubuntu upgrade. 

I assume that you are referring to $URL$ . For what it is worth, I use it to warn for numerical intervals to good effect. Don't know about graphing. 

If the issue really is to set up an 6-to-4 router, and assuming that you can spare a Linux box as router/bridge, you want to do three things: 

It seems unlikely that or (and in other samples , and even ) suddenly decided that it wanted to read hundreds of MBs, having previously read very little for hours on end. This behavior goes on for about an hour and various processes show up with 100+ MB read over this period. What can explain these high numbers for normally well-behaved processes? I thought read for these numbers which should be reasonably accurate for actual EBS activity? 

This says the mail was successfully received. On my server the next step is spam cleaning. Then comes the delivery: 

At a guess, jfs is compiled as a module and is loaded in dom0 (for any of numerous reasons) but not domU. Perhaps manually insmod'ing jfs.ko in domU will resolve problem? 

change all relevant passwords in the environment, reboot the boxen on a live CD and dd the full disk image across the network to somewhere for later analysis, scrub the disks using dd if=/dev/zero of=/dev/<whatever>. Make sure you overwrite the MBR, reinstall using a public repository, analyze the image to try to find out what happened, and report the conclusions to some relevant clearinghouse. 

It appears the reply for pool.ntp.org changed recently. This is making my CentosOS 6 ntp servers unhappy. 

rpm files from RHEL6 use different magic number RHEL5 python2.4 does not recognize sha256 which is used to checksum downloads in CentOS 6 yum uses different database format in RHEL6 such that a chroot environment built by RHEL5 yum will not be comprehensible to yum from RHEL6 

You do not need to run your own DNS server. It is customary to have a so-called MX record describing how to deliver mail to addresses in that domain, but it is not strictly necessary. This is how it works: A mailserver that wants to deliver mail to your server asks its DNS server for an MX record: 

Quality In my experience, your company suffers in reputation from bad phone lines, so make sure you get get decent quality from your installation. Quality is among other things: 

Is my interpretation of the error message correct that the -generic kernels are not bootable by pv-grub? Is there any other kernel/package in Ubuntu containing rpcsec_gss_krb5 that are bootable (none relevant found by apt-file, but perhaps there are external repos)? Is there another community AMI that satisfies my criteria? 

install radvd on the LAN side of the router. setup a 6to4 tunnel to pass your IPv6 traffic over to IPv6 Internet setup firewall rules for IPv6 

Obviously, these are dangerous commands, so backup, backup, backup. Also, doing this may cause issues if someone is trying to work with files in /home while this process goes on, so please make sure no users are logged in and no public services are running. 

Self-learning is fine for most sysadmin knowledge, given one condition. In order to become a competent sysadmin of any set of systems you need to recognize when you fail to achieve what you want because you do not understand the architecture/principles underpinning the software you are trying to beat into submission (as opposed to the stupid thing just being obnoxious). At this point, you need to step back and read up on what the developers wanted to accomplish. Apache is a good case in point. Mostly, configuring Apache is just a case of whacking at location directives and redirect instructions until they do what you want. However, in order to successfully create virtual hosts, you absolutely need to understand how virtual hosts work. For public systems, the great danger is not so much that you don't get your setup working, but rather that you do not understand enough to realize that it is insecure. Some tips to help you get started: 

My understanding is thus: there is a message queue. A PHP script consumes messages from this queue. The action taken varies across disk access, network activity and CPU intensive tasks. (what coredump said on managing to utilize multiple processes at all.) Also, if there is latency in some tasks (e.g. talking across network links), you may even want more scripts than number of cores. Ultimately, only measurement can tell. Build a test system and hammer it with a realistic message mix. It does not matter so much what sort of system you test on, as long as it actually has multiple cores. A virtual machine is fine; you will still get a decent feeling of what happens as you increase number of consumers. 

In the end, I had to pick a different option. Setting the spec.hostNetwork option pushed the pod into the node address space, 10.240.0.0/16 for which the VPN worked fine. As far as I can tell, when you create a GKE cluster, there is some "magic" networking set up for the pod address space, which appears not to have correct routing as regards VPNs. It is possible that Karman is correct, but I can find no way to declare an explicit virtual network for the pods to stick the firewall rules on. Simply sticking them on the default network does not seem to help. Creating a new non-legacy network does not help as GKE refuses to create a cluster with pod address in an existing virtual network and GCE SDN refuses to create virtual subnetworks for an address space that GKE has already claimed. 

Don't worry about it. The config you have is not going to eat your RAM. Note that the three www-data processes are forks, so they don't actually use that much extra memory if they are not serving data. 

I had a similar problem some time back. I stopped the inaccessible host and started a new instance where I attached and mounted the inaccessible host's partition. (I didn't expect this to work for EBS snapshots, but it did.) After fixing the partition, I unmounted it and started the old host back up. My problem was that the installation had been trashed, but you should be able to update SSH keys or set a new root password or whatever. All this assumes that the host will not auto-terminate on shutdown: remember to check the policy. 

I am in the process of switching from Xen to qemu-kvm. My current Xen installation has a number of LVM volumes each with a partition (rather than a full disk image). In Xen, I start each VM with a configuration like so: 

I would recommend you take a look at collectd. It can be configured to log numerous measurements into RRD-files for later analysis. It requires very little CPU and will help you to understand how your performance changes with load. I have not found a truly awesome tool to actually draw graphs from the generated RRDs, but unless you want to project them in realime, just using rrdgraph on command line is typically enough to periodically check for big changes. 

to main.cf. If your server was listening to all interfaces, the /var/log/maillog (at least I think that's where the log is in CentOS) should probably be your next stop. See if there are any relevant lines in there that talks about the mail you expecetd to receive. It should look something like this: 

If this is the case, you need to do something like this article suggests: $URL$ If it is indeed just a partition, fdisk complains like so: 

I need a cheap setup to store historic snapshots of a dataset in the 100-200GB range. These will see little use, but need to be kept online for some time (shared by Samba). The box housing the dataset is a Dell PowerEdge 750 with a PCI-X CERC 6-channel SATA controller. It has 4 SATA channels free. I am considering the following setup. Your experience with similar solutions would be greatly appreciated. I would add a 4-channel bracket in the free slot and connect these with ordinary SATA cables. I would then purchase a STARDOM 1U chassis or similar and use 4 ESATA cables to interconnect these to the bracket and use 4 ordinary 7200 rpm SATA disks in a RAID5 configuration using Linux software RAID because I want to be certain that I can read these disks when the PCI-X controller caves in. Specifically, my questions are thus: 

The previous ones to this question are all worthy answers, but they are all colored by large-scale thinking. If you have only a single host, providing web sites whose failure will not immediately kill kittens, you may want to think somewhat smaller. I would suggest the following: Use logwatch or similar system that aggregates your logs and mails you a summary. Read the summary at least every other day. Use a tool that crunches your weblogs (e.g. analog) into a readable summary. If you want to be a bit more ambitious, use a cloud service to monitor your sites. However, the essence of systems maintenance remains the same: kill each issue that occurs dead so that it can never occur again. This is an important point, because it means that there should be no "regular" maintenance. Now for the bigger scale: Among the first issues you have when you scale up is that something breaks and you don't know it. This must never occur again. Then you get a full-scale monitoring solution. Also, having seen the issue occur on one host, you want to prevent it occurring on any other host. That's when you get a configuration management system. But you must not at this point be complacent. All your effort should go into permanent solutions. 

Is it possible to resize the guest's root partition without rebooting the guest? Just doing lvextend on the host and resize2fs from the guest does not seem to be enough. 

If I read you correctly, your root filesystem is listed as sdb1 in fstab, but in reality seems to be sda1? Your disks have probably swapped order at some point, or maybe there was a CD player during installation that you removed later? Anyway, root device is typically not read from fstab. It is configured in your bootloader: see the /boot/grub/menu.lst file. Here root device is typically given like this: "root (hd0,0)". Disk 0 is simply the "first" disk by some measure. When the kernel starts, it has to read the startup stuff from somewhere: that is the root filesystem. Under normal circumstances, that filesystem is "adopted" by the starting system, so it will not be confused by naming issues. 

There are many ways to do this. Depending on circumstances, either may be preferable. I think the most straight-forward (if not the shortest) approach is simply something like: 

The most basic bit is that you need the rpmbuild tool and you need to write a spec file. I have the following script that takes a spec file and a tree as it would look installed on the target machine: 

You should see traffic from the client here. UPDATE: Similarly, traffic from the server should arrive on the client through its IPSec interface and can be inspected with tcpdump there. 

If you have a line like the next-to-last, mail should be delivered to dovecot, and you need to trace the problem there. 

The trick in above conf is that postfix+libsasl2 does this: ${cyrus_sasl_config_path}/${smtpd_sasl_path}.conf Once we have gotten that far, in /etc/postfix/sasl/smtpd.conf we can tell libsasl that we wanna talk to saslauthd: 

If you are on a consumer IP connection, chances are port 25 is blocked in one or both directions. Some ISP block outbound, some block inbound, some block both. 

I need to find a fix for this. Can I execute su differently or is there a replacement I can use instead? (Preferably no sudo and I would prefer not to allow ssh root login.) 

User still retains a login that was created before the user was removed from a group giving privilege User is explicitly listed i /etc/sudoers 

The first line tells the box to look in table "1" for info on packets that go out from IP 1.2.3.4. The second line creates table "1" saying that the default gateway in that table is 1.2.3.1. The last line ensures that this takes effect immediately. For more info, see e.g. $URL$ 

EDIT: Even if you can't go to the site of the failing browsers, maybe there is remote desktop or remote assistance to help you? 

I am trying to do Kerberos-auth:d NFS4 on EC2. In order to do this, it seems one wants a kernel at least 2.6.35 in order to get decent encryption algos. The distro I could find that provides this is Ubuntu/Natty, which has 2.6.38. However, the default images are the -virtual flavour, which lacks rpcsec_gss_krb5. Thus I'm trying to make an image that boots a -generic image, but these seem not to be appreciated by the EC2 pv-grub loader: 

Don't do a big bang implementation. Start with some users and work from there. End user equipment How are your users going to talk on the phone and how do you connect that equipment to Asterisk. Some users appreciate a headset connected to their PC, while others need a grey handset with analog dial pad or they will just be confused. Which will you provide and how will they connect to Asterisk? For so called softphones (i.e. a SIP client installed on your PC) not much need to be done. You need a mechanism to handle accounts for these users (e.g. LDAP) and they need decent headsets. For connecting traditional analog phones, there are various sorts of equipment. For small installation, you may be able to get your hands on Zyxel Prestige 2002s (2 ports each), but for larger installations you need rack-mountable equipment of some sort. Services In my experience it is very difficult to get users to actually tell what they expect from a phone system, but once you give them something, they start having all sorts of opinions. So you need to be very clear about what services you provide and require a somewhat anal change management process (more so than is normally required in a small company). Conclusion This sounds dangerous and ominous, but know that the reward is equally great. The advantage of being able to create dedicated phone services, with the same sort of detailed control that you have with other IT services can be very rewarding. It will take some time for your users to get used to the thought that they can actually request fancy features from their phones, but once they get started, you can make their work a lot easier. Some features my users found very useful: