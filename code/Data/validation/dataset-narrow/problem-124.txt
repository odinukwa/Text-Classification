I suppose the firewall load-balancing could be doing the redirect itself, but we cannot tell with the limited info provided. 

When creating VLANs for just L2 on a switch -- routing will be handled by a device within that VLAN such as a load-balancer -- it isn't necessary to create the vlan interface. As a matter of habit, I always create the interface anyway-- no IP address - so I get all the interface bits and packet stats in "sh interface". Are there any negatives to what I think is a best practice to just create the L2 interface? When do you create or not create the interface for a L2 VLAN? I am looking for answers that discuss only L2 VLANs, not the merits and use cases for L3 VLAN SVIs. Cisco reports a L2 interface as EtherSVI on my 6500 -- no IP address. Is it correct or incorrect to still think of a L2 interface as an SVI though the we all know the usual use-case is to have an IP address for routing? The question is only about whether or not I should have this L2 interface in the first place. You can see only the L2 counters are incremented, but still giving some value. 

24 hours later will show thousands of OQD. We do push out more traffic around 3am each day, so maybe there is some bursty traffic here I'm not giving enough weight towards. 

I can see why this would get pretty annoying, so how can we turn that into a much shorter one-liner? JunOS doesn't have the ability to alias a command built into the OS. What we can do, is use a SLAX script. It's a bit more obnoxious at first, but it's kind of nice. The "script": I'll use a much more basic command to keep everything short, but you can replace the show command you see in the code with any other show command you would want to use. Feel free to also make the variables a more coherent name for your use case. 

tl;dr Many different devices can encounter multiple OSI levels. Whichever end point is requesting something from a layer 7 protocol (like HTTP), will use all 7 layers before putting it on the wire. Intermediate nodes, like routers and switches might only use up to the first 3 layers, firewalls or WAN accelerators can affect layer 4, load balancers do interesting things as well. If you're interested in a more detailed answer, look below - I tried(?) to keep it fairly simple, and use a real world example. For reference: OSI Model 

You're correct, not the person you were speaking to. TCP establishes a connection between a "client" and "server", anything in between is just the the paths. It doesn't care how the traffic gets there, just that it does get there (using the built in sequence numbers, acknowledgments, and congestion avoidance capabilities). In your diamond example, you load share over both of the middle routers, you could just have one primary and one backup path, etc. It doesn't matter, as long as IP reachability is present, TCP can handle the loss. 

Unless you want to get into the GEO-IP mapping business, leave this for the professionals. It will never be 100% and accuracy is probably closer to 70-80% at best. Proxies in front of the clients may mask their actual locations since the proxy IPs would be different. If you're app is HTTP, some Content Delivery Networks (CDNs) if you use one have the ability to embed Geo information in the HTTP request header for your web app to make a block decision on. Again, some CDNs proxy the entire site so the IP connecting to you is never the same as the real client. See $URL$ 

Your SNMP index may not match your port number. On some platforms, the indexes are not even persistent across reloads unless configured to be. I'd expect to find an interface speed of 2Gbps in your SNMPwalk for your 2-port LACP. You should scrutinize any ports showing a speed > 0 besides your physical ports 1-24 as possibly the LACP virtual interface. I'd recommend investing some time to install and learn Cacti. Cacti excels at SNMP monitoring especially using the standard RFC IF-MIB. You can enable debugging when Cacti queries your platform which will correlate other helpful elements of your ports like descriptions. Keep in mind that your SNMP counters for your VLAN interface may only count octets going into and out of the VLAN, not within the VLAN. 

Without physical limitation, I would say 3 racks are ideal, but 2 racks are a minimum. The middle rack is for patch panels of all cable terminations. You don't want any equipment there. The other racks for equipment. 600 terminations with cable management would take up nearly a 42U rack. With redundant equipment, I prefer to rack like devices in opposite racks. This avoids the issue of a single power pole affecting all of your redundancy -- imagine worse case even with dual power supplies going to different PDUs in the same rack with your amp draw on a single PDU > half of it's capacity. Now imagine one of the PDU fails, so all the equipment then pulls double the amps from the remaining PDUs, and since your over budget on your draw, you just tripped the breaker on your redundant PDU and all equipment in that rack goes offline. Having like equipment -- redundant routers, firewalls, agg switches, access switches, wireless LAN controllers, etc -- in different racks would mean a single rack can take it all out. You also avoid someone falling off a ladder or tripping and ripping cables out of your equipment and having a bigger impact than you would like. 

I was working with a customer who was implementing OAM in JunOS, the show commands to display statistics are unwieldy. They wanted a way not to have to type the full command everytime they needed to retrieve statistics. Here's what I mean: 

NOTE: It's fair to mention that other things can interfere with the typical behavior (firewalls, NAT/PAT, ACL's, etc.) But it's best to have a very solid understanding of where all the encapsulation and de-encapsulation is taking place to understand how those affect the network and the traffic. 

I think your issue is coming from a simple misconception of how SNMP data (OIDs) is structured, and how , , and interact with it. SNMP organizes the OIDs into related nested trees (or tables), the MIBs define those trees and the OIDs in them. It's important to understand how and works before getting into 

First, ALGs are technically independent entities. If we are looking at JUST the ALG, it cares only about the SIP signaling packets, not which ports are used. You define the ports by application and bind the ALG to that application. Below is an example: 

So you're almost on the way to answering your own question. It might be possible to push more data down CAT5(e)/CAT6, but the hardware would have to support it. The question is really not "whats possible" more than "whats feasible". There are already a lot of ways to scale between 1G and 10G. The development cost of hardware to push, let's say, 4G or 8G isn't really worth it as we already have fiber optics that can push 10G over even longer distances. If the concern is shorter distances of ~100m, and you know that hardware would have to be replaced anyway, fiber is the way to go. Fiber optics are cheap as long as you don't buy major vendor branded transceivers (SFP/XFP) as $1000+ each, you can buy commodity transceivers for a couple hundred bucks - and the hardware to physically support them isn't any different. 

The best you can usually do is look for communities with your provider that allow you to indicate prepends per peer of your provider. This assumes your provider has such communities and has the peering relationships for this to work. Prepending your own announcements to your peer would have no variation upstream from your provider. Though this method does not alter localpref one AS removed from your provider, it has similar impact in making that path back to you less desirable. There is an exception to influencing localpref upstream that I'll describe at the bottom, though it's probably an edge case. Some providers such as XO [AS2828] allow you to advertise your prefixes in such a way that your provider announces your routes with with specific prepends for certain peers of theirs. For example, XO accepts: prepends once for AT&T prepends twice for Level3 preprends thrice for Sprint On Savvis, the community is which prepends once for AT&T. These providers usually have communities to indicate the well-known communities of NO_EXPORT or NO_ADVERTISE to specific peers. One Tier 2 provider I know, InterNAP, is able to influence localpref upstream because they buy transit, so they are a customer of the Tier 1's. They have communities that you could use where they attempt to translate those into specific Tier 1 communities for your upstream advertisements which set localpref to peer-, mid-, or high-level values. See $URL$ Example References: XO Communities that Change Customer Announcements to Certain Peers at AS2828 Border Savvis Prepend Community Attributes I have no affiliation with the providers used in the examples other than direct experience as a customer. 

Once your file(s) are copied, you must enable them. This prevents anyone who can copy files to the device from executing potentially destructive scripts. 

If you look under the section for password-policy in the link below, you'll find password-memory in the available commands. $URL$ 

I have a pair of ASR9k's that I plan on migrating to Juniper MX960's. Below is a piece of the configuration: 

In terms of subscriber management, I understand there are two major approaches - DHCP and PPPoE. I know I'm being very general, so give me some rope. If using DHCP, RADIUS/AAA will authenticate the user, and then allow DHCP to happen, assign the address, etc. If I'm using PPPoE, the PPPoE session establishes, and the address is assigned via IPCP. My question is, if I'm using PPPoE, can we use DHCP to assign the address? And if so, how is that address conveyed to the client? Will DHCP choose the address and be sent to the client via IPCP? 

So, basically, you're not defining the filter as "inet" in your dynamic-profile. OR It could be your filter itself that you're not defining as "inet". 

Your original question relates to planes 4 and 5, which correspond to SCB2. The second KB article will help with this more accurately. I'd strongly advise making sure another engineer isn't working on this, or that the SCB isn't offline intentionally - if it was offlined but another engineer due to errors then turning it back online might cause problems. If you don't see any evidence that it was offlined intentionally, work through the article and see what happens. 

For term sessions, I believe the best option is to use app or OS keepalives to maintain the connection through the SLB which allows you to keep your idle timeout where you want it. This is app and OS dependent. See Keep Your Linux SSH Session From Disconnecting as one method that may work. The concern of your manager in raising the idle timeout is highly subjective. The typical flow rate (conn/sec) and idle durations between your environment and his last could be vastly different. If your flow rate or idle durations are much lower, you could afford to increase the timeout. You'll need to zero into flow capacity, what you have free, and how quickly you cycle through them. The CSM's default idle timeout is 3600. Same for the ACE for idle TCP connections. 

To get to the heart of your question, a single L3 (layer 3) switch could do what you want and be divided into logical networks via VLANs and the switch will handle the routing between the networks though this is far from an optimal solution. Each VLAN interface will have an IP address configured which becomes the default gateway for all devices it serves. Although not recommended for several reasons with security at the top, your Internet connection could even technically connect on the same switch and work, but that's asking for trouble; I'm sure this is why your consultant recommended at least 1 switch and and 1 router so the two are separated. You really should have a firewall between the two or at least firewalling functionality on your router. Ideally, you would hare pairs routers, firewalls, and switches for redundancy and separation of functions to provide security boundaries. 

224.0.0.9 is a protocol standard multicast address, meaning that it is reserved for all RIPv2 speaking routers. This reduces unnecessary overhead, and only speaks to RIPv2 routers, instead of a full broadcast. Here is a portion from the RIPv2 RFC. $URL$ 

I'll try to apply your example, with a really terrible analogy (you have been warned). You need more than just StudentID's, let's say you have StudentID and Major. So your would have to have something in common for it to be efficient. If you didn't, you would have really terrible performance, this is one of the many reasons proper subnetting is a good idea, For example: 

Source: TCP/IP Guide What layers encapsulate the data depends on what generates the data. In general, de-encapsulation will only happen for what is relevant to the data's current place in the network (on a router, on a host, etc.) By this I mean, if I'm a router, I don't care that there is an HTTP request buried in this packet if all I'm trying to do is route traffic via Layer 3 - I will only strip off enough headers to get what I need, do my job, and move on to the next packet. We all use the internet everyday in some way, so here's what a typical HTTP request will look like, taking the OSI model into account. For simplicity's sake, we can assume the network is available and there aren't any problems. 

This is more of a scalability issue than performance. Only a limited number of directly connected subnets will go to a router which handles routing for a far larger number of networks. Performance becomes an issue on a router when Mbps (bits/sec) or Mpps (packets/sec) realistic maximums are hit among other things and less about how many subnets are behind it unless it's handling a large number of networks that requires a lot of Mbps and Mpps throughput. 

As @Mike Pennington suggested, Cisco Prime would be the best all-around-solution for monitoring Cisco LWAPs connected to Wireless LAN Controllers as you gain much more than just a simple ping alert mechanism. Wireless requires a systemic view that considers not only individual APs going up and down -- and any good wireless deployment has allowances for that to prevent a single AP being so disruptive to the system -- but includes the ability to see AP coverage and overlap as well as interference. Since wireless is inherently a dynamic system responding to environmental changes -- bodies moving about, different reflections of signals from static objects moved on occasion, and AP power adjustments from detection of surrounding friendly or rogue APs -- you need a platform that deals with all this (as the WLCs do) and a network management system that shows you this system view with the ability to alert when issues arise. 

Between your data and voice VLANs, you may want to alternate what you consider the primary DHCP server for a given VLAN. I do this to help spread the lease load out a bit. If a DHCP server's scope is full, it won't reply with a DHCPOffer, so the offer would come from another DHCP server, assuming it's not also full. Keep in mind when troubleshooting that a Windows client will remember the IP they had leased last and attempt to get that again. Also keep in mind any reservations you do must be done on both servers and accounted in any ACLs you have such as in firewalls. See Understanding and Troubleshooting DHCP in Catalyst Switch or Enterprise Networks for detailed explanation and sniffer traces of the DHCP relay process.