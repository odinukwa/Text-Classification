I am not sure if you're interested in all constraints but INFORMATION_SCHEMA.TABLE_CONSTRAINTS doesn't seem to return the DEFAULT constraints -- TABLE_CONSTRAINTS (Transact-SQL) 

I am not sure if there is a better way but something simple like this should do it. If you run this query on the Publisher, it will compare the tables and will return you the difference in tables. The Publisher needs to be linked to the Subscriber. 

You can use CNAME in DNS. When you're done with GARDB1, rename it to something else (GARDB1_OLD). Create a CNAME in the DNS server called GARDB1 which should point to GARDB2008. It should solve your problem because GARDB1 will resolve to GARDB2008 now. Ideally what you need to have is a generic CNAME that you can just re-point to a new DB server each time you are migrating. Perhaps next time you plan to migrate, you can implement it. Or you could go with what @SeanGallardy suggested. 

That gap you see above prodkbp is in the output as well. Not sure if that matters either. My production server has that anomaly as well so I can't imagine that has anything to do with it. Basically everything looks right but something is still wrong. I cannot install Enterprise Manager Environment 

Which also looks OK. Most of the solutions point to SERVICE_NAME mismatches. However I don't appear to have one. v$parameter output 

That was difficult to figure out on my own. Research for the general error "Access Denied" in this context led to many different avenues but none that address my specific problem. Most stemmed from not using Reporting Configuration Manager to set up the service account. I did in my case and was able to verify the actions it took were done correctly. RsExec role, URLReservations using new account etc. I ran into a thread that said... 

Using RCSI on the subscriber(s) is a common way to design this type of a scenario to avoid blocking. RCSI will allow readers and writes to play nice together but won't solve writers blocking writers. Since the report queries are readers and the transactional replication is a writer, this feature is a good fit for this. You just need to make sure that your TempDB is configured to support your workload for the versioning. Also remember that enabling RCSI adds 14 bytes to each inserted/updated row which might cause internal fragmentation. 

No update yet because the threshold is 24,796.4 - 20247 = 4549.4 but we inserted only 4548 rows for ID 8. Now insert this one row and double check the histogram: 

Windows 2008R2 with firewall disabled for testing (not that it changed anything). Listener.log doesn't show anything of worry. Just evidence of me restarting the listener many times. I am aware that I could configure a static listener with but I would like to understand why this is not working. This is the 4th time around that I have been doing this and I have not run into this problem yet. I am basically stuck since I am not sure where else I should be looking. 

For testing I have been trying to install Oracle 11g on a test system with a single database several times with the aid of snapshots. This most recent iteration I have been having issues getting the database to register with the listener. I am to understand that PMON, as long as the database is running, will attempt to register itself at regular intervals with a listener that is running locally on the same machine using port 1521. I have such a listener running but the service is not registered it seems. 

There is nothing wrong! This is how DBCC CHECKDB works. You can read Jonathan's post explaining this behavior and a workaround if you're on the Enterprise Edition -- DBCC CHECKDB Execution Memory Grants – Not Quite What You Expect The only strange thing is that usually this happens with servers with larger amount of RAM! Here is also a really good article on Understanding SQL server memory grant 

Perhaps, if you see a big IO Queue on your SAN, you have a lot of IO bound queries on top of your memory pressure. Check the PLE and Memory Grants Pending counters on this server. If you PLE is very low and you have lots of pending memory grants, your server might benefit from additional memory. Also look if you need to add any indexes (review missing indexes DMV) -- Are you using SQL's Missing Index DMVs? 

According to post here and on SO it should just be an issue with the service name. Problem is it looks right to me. Listener.ora 

So it would seem the issue was not the service name specifically but that the request was going to the IPv6 address which was not set up in any of the required files. Looking at listener.log ( which for me was located D:\app\Administrator\diag\tnslsnr\dvp-oracle\listener\trace\listener.log) I found these entries associated to my connnection attempts. 

Really new to Oracle and being a DBA in general. I am trying to set up a development environment so that I can play an learn oracle better. Enterprise Mananger failed to configure itself when I first created the database using the Database Configuration Assistant. No biggie. Just need to user emca.exe I had some issues with the Listener but those might have just been me being impatient in waiting for the service to register or the service not running. Right now my issue is this from the emca log: 

Yes, as soon as you pass the threshold of 20% + 500 from the total rows. The auto update will trigger. You can run though this scenario by re-running STEP#1, but then modify STEP#2 by running these queries: 

This should give you a list of the objects that are in the WarehouseDatabase databse but not in the NewWarehouseDatabase database. 

Check this article -- Reversing Log Shipping! Now what you need to do is to take the log backup with NORECOVERY on the primary and restore this log on the secondary with RECOVERY. This will preserve the log chain. 

MBR cannot handle partitions bigger that 2 TB, thus if your partition is bigger than 2 TB you have to use GPT. There is no performance gain as far as I know. It's all about the capacity! 

That tells me that the database registered itself dynamically correctly. prodbkp is my SID. This might be a case issue since I named the DB "PRODbkp" but everything else seems to be fine since I can connect with just fine. Case should not be an issue with service names as per docs.oracle.com tsnnames.ora 

As part of the troubleshooting I was doing to try and address the issue I ran Process Monitor while I was trying to start the service. I tracked as event that also had a result of "Access Denied" which was the service trying to read files inside the directory where reporting services was installed an running from. In my case it was: "C:\Program Files\Microsoft SQL Server\MSRS10_50.MSSQLSERVER\Reporting Services" I check the security of the folder and the service account I was using had no rights to the folder. That is why giving it local admin rights fixed it because that group did have access. I gave my service account Modify access to the folder and its contents. After that I was able to start the service. 

It depends on the session's execution plan. If a session executes a query with a serial plan then yes, you can say 1600 queries, but if it runs a query with a parallel plan, then a session can have multiple worker threads per session. Tasks, Workers, Threads, Scheduler, Sessions, Connections, Requests – what does it all mean? 

When I need to do something like this, I just use sys.objects. After you restore the NewWarehouseDatabase databse, create a Linked Server on the instance where you have WarehouseDatabase to point to the instance where you have the NewWarehouseDatabase databse. Then write an EXCEPT query using sys.objects. Something like this: 

I can connect to the db using and running shows the DB in question. So between that tnsping and I know the listener is at least running. does not appear to have an effect either. Not that it should matter since I should just have to wait a minute for it to work on its own. I then went looking for any PMON related logs. It should have been in the trace folder ($ORACLE_BASE/diag/rdbms/database_name/SID/trace/SID_pmon_PID.trc) with other trc files but it was not there. I then used the following query to verify where it should be 

I was having an issue getting SQL Server Reporting Services 2008R2 SP3 working under a domain service account on Windows Server 2008R2. It started with this What am I missing for my SSRS Service account local server permissions? and I have progressed from there some. I have a domain account setup as the service account for SSRS and the service is running. However on the /ReportServer and /Reports pages I am getting page cannot be displayed on my local server. Looking at the logs under "C:\Program Files\Microsoft SQL Server\MSRS10_50.MSSQLSERVER\Reporting Services\LogFiles" I saw two errors 

We tried to use ODBC for QB few years ago but gave up on this idea because it was painfully slow! So our developers created an extract application using QB API to export the data we need out of the QB to a CSV file which we import into a table on our SQL Server. This process have it's own drawbacks like when a QB client gets updated to a newer version everybody needs to get on the same version otherwise the export application fails. Again, we developed this few years ago and tested with, perhaps, an old ODBC driver. Also have only handful of QB clients that need to be maintained. This has been working for us all these years. Here is a good starting point if you'd like to start developing an application using QB SDK -- QuickBooks Desktop HTH