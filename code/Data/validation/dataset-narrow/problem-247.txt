Most likely /etc/my.cnf or /etc/mysql/my.cnf. Also check /home/username/my.cnf and /home/username/.mysql/my.cnf If no luck there you can run 

Create table test1 (innodb) w/ an auto increment PK Insert a couple rows w/o specifying PK values, letting auto inc do its job Create table test2 like test1; Alter table test2 modify pk_col int(10) unsigned not null; -- no auto_inc Shutdown mysql backup test1.frm; cp test2.frm test1.frm Restart mysql select * shows all rows as expected, w/ previously auto_inc created PKs 1,2 and 3 Insert a row w/o a PK specified, gets created w/ PK value as 0 (the default value). Insert a row specifying PK of 5 Shutdown mysql restore original auto_increment test1.frm Restart; show create table lists auto_inc Test insert a row w/o specifying PK, generated auto_inc value of 6 (+1 the highest value even though the last one created by virtue of auto_inc was 3 

Federated tables are going to be inherently slow, especially when doing joins. It's basically copying down an entire copy of the table for each join. Federated tables should simply be avoided. 

You could use events to run a periodic optimize, but I get the feeling if you experienced such improvements you may need to look elsewhere. An optimize on innodb is effectively just running alter table engine=innodb to rebuild it, reclaiming empty space that is the result of deleting many rows. An estimate of how much data isn't actually being used can be found by comparing the data_length and data_free numbers in show table status. After performing the optimize the operating system now has as much of the table as it can in disk cache since it just read the whole thing. This will yield short term improvements until the less frequently accessed pages are purged from the cache. In a perfect world you would set your innodb_buffer_pool_size large enough so it's able to hold all your innodb tables in memory. Of course this is not always possible due to budgets or sufficiently large datasets. At the same time, if this is a dedicated DB server with only innodb tables set the buffer pool to 70-80% of the system memory, leaving the rest for OS overhead and disk cache. EDIT Along the same vein of ensuring appropriate hardware, get as fast disks as you can. PCI-E SSD based cards such as Fusion IO are the best you can do today. Can't afford that? Then get a multi spindle SAS RAID disk array. 

I've had to solve this specific problem and realized there's not way to say "all tables except these". What I did to work around this was create an internal database, restricted_tables. It had a couple of simple table schema: 

If you're doing this to get a slave running, in both cases you'll want to have run show master status before shutting down/taking the snapshot so you'll know what to CHANGE MASTER TO when spinning up the new slave. I would recommend setting read_only=1, then check the position. If going the snapshot route you can set read_only=0 so the master can continue to take writes. 

However that intro paragraph is the only mention of LDAP in the entire post. I've read through that as well as the general Percona PAM installation post. Every setup instruction seems to be talking about authenticating against a local unix account. No mention of specifying an LDAP server or anything. I found one other SourceForge project and some other mentions of perhaps slapping mysql_proxy infront. Frankly that SF project doesn't feel very production ready. Am I missing something about this percona plugin being able to authenticate via LDAP? If I'm completely off base with that plugin perhaps my larger questions is "How can I get users authenticated via LDAP?" 

We use cake for some internal applications. And yes it does at times, pardon my french, suck. This isn't anything to do with mysql per se. Once you start defining more than basic models and go down the "has many"/"has many belongs to many" relationships, the underlying queries it generates can be less than sub par. Do you have table with multi column primary keys? Forget about it. Frankly there are just times you need to break the molding your framework is supposed to shield you from and write your sql more directly :-\ That being said, as with anything else interacting with your DB you'll want to ensure you have proper indexes and appropriate buffer pool/key buffer. 

Problem again being during the shuffling there could have been some M2 writes that made it to s2 but never s1. Can anyway think of a clean way to tweak these approached to make it work? One of my requirements is having minimal downtime for the Master-Master cycle while allowing more extended replication downtime for the slave-only instances. Even if it's overly complicated what ever approach I go would with end up being scripted so if there's some kind of rapid looping/checking until just the right time that shouldn't be a problem. Edit In Response to Rolondo's solution: An end goal of what I'm trying to accomplish with this is to stop slaving (at least sql_thread execution) on S1 and S2 to have time to do some lengthy comparisons (checksuming etc). A concern I have is after step 04 is even though these steps are stopping/starting the master SQL threads, the slaves (S1/S2) replication to their respective masters (M1/M2) is still going. There is a non zero amount of time that occurs between measuring/comparing the M's relationship with each other. Even if they look good by the time I would issue stop slave to S1/S2 something could have come into M1 or M2 and made it into just their slave. Would you agree with this or am I missing something? 

It's important to note that $date is not literal mysql syntax but just an example place holder for the starting date you want. If this is for reporting I imagine the query will be ultimately generated from some script? If that's true it might be simpler in that language and then pass in the literal value as part of the constructed query. I'm a fan of keeping queries as simple as possible so I'd leave it like that. I'll leave room for others to contribute answers to accomplish what you want in a single SQL-fu query. Edit: After rereading your post it seems you probably are using the date type. In which case the following block in italics may be redundant. I'm leaving it in the event it's helpful to others (and since I took the time to write it :-) You said you're using a "datestamp"? That is not technically a Mysql datatype. Is it a datetime, timestamp or date (time and year also exist but from your context I feel those are not applicable)? I ask because you may want to make it just a date column instead of the others. If this is the right choice for you really depends on the details of how the columnn is being used and the table being queried over all. If it's sole purpose is just to pull records in a date range, regardless of time, then date is definitely the way to go. For one, it only required 3 bytes instead of 4 or 8. I can elaborate on other reasons you'd want to use date if it matches your usage requirements (i.e. you don't care about the time portion). You can find details about the different types at $URL$ $URL$ If and only if you are using date specifically you might consider the following: Run the query with prefixed with "explain". Details on how to interpret the output and what is best can be found at $URL$ Once you have that explain change the query to be