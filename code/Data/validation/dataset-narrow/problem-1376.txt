I just learnt unity basics and would like to learn everything else related to 2d development beginner to advanced in less time. Because i dont want to stick to game business/development for a long time. Any websites if you know that has everything thats mentioned above? 

I'm trying to create a Character touch controls for 2d platform. In my script Im using one horizontal swipe and hold touch gesture and one vertical swipe gesture without hold.Both are different methods called in . And here is my script : 

Im using rigidbody 2d and I'm creating a platformer. When i press the button the character transforms very little in y axis. 

Problem: 1:When i swipe and hold horizontally the character moves fine but when i take my finger back it triggers the vertical swipe method. 2:When i try to swipe only vertically the horizontal swipe is also triggered. 3: The two swipe gestures are overlapping and triggered at same time on a Single touch. Solution(Guess):Dividing the touch screen equally half and forcing horizontal touch gestures strictly on left side of touch screen and vertical touch gestures on right side. But I'm beginner(You can see my coding style) and would like to know how to do it programatically. Im still learning. 

} The problem here is the player doesn't move when you swipe and hold on the touch screen but only moves when you keep swiping. Can you please help whats wrong or missing in the code so that the player moves when swiped and held? 

Creating resolution independent sprites is tough and memory consuming. How can .svg assets be used in unity for any kind of 2d game? What are alternatives to .svg that can be used in unity? Can sprites with various shapes be generated within unity? Would like creating universal art asset that'll support all devices with different resolutions.(we'll handle the aspect ratio ) 

In other words the list would be keeping track of an internal total as you create it. To get a value you have a further two sub-options, in both cases you will need to choose a value between 0 and 170 (the current internal total). Linear Search () Simply loop over the list until the current item has a value less than the random value. Binary Search () Extend the internal representation to the following: 

Farseer has springs. Elastic and Inelastic Collisions An elastic collision is when the kinetic (movement or momentum) energy of colliding bodies remains the same after a collision (it can still be distributed differently between the bodies). This means that no energy is lost to other forms of energy (for example, sound, heat and light). Elastic collisions (or "super-elastic", where the energy is greater) only happen at the molecular level - however elastic collisions can be passable in games. An inelastic collision is when a portion of the kinetic energy is converted to other forms of energy. For example, when two billiard balls collide you hear a sound (although this does have a negligible impact on the total momentum). If a car collides with another one a lot of energy is lost to deformation and heat. At the macro-scale these types of collisions are more accurate; and will generally improve the stability of your physics simulation (they reduce the chance of a rounding error or such from introducing more energy). Wikipedia has very good articles on both elastic and inelastic collisions, Physics for Game Programmers has a free excerpt on both. 

Balance is mostly attained by intuition and play testing. Games where balance is important usually have extended beta cycles and frequent updates because of this. In your specific example "Magic" attains balance through years of experience in play balancing - if they find that they have released an unbalanced deck they might come up with a ruleset to address it. Unfortunately I don't think you could really fit balance into any of the UML models - considering that UML is typically used to design transactional or architectural software you would have a hard time fitting the balance problem-set into it (and would likely be wasting a lot of your time). One of the methods you might want to look into is "zero-sum balance". Basically each "thing" can exert so much "stuff" into the world given a certain amount of external factors. Taking the example of a strategy game you could do your initial balancing by saying that each unit must exert 300 damage points within 15 seconds. This way you can work out hit damage based on, say, attack speed. More complicated systems obviously have more variables and are likely impossible to calculate - so you have to need to guesstimate (intuition): any errors on your part can easily be fixed by releasing balancing patches. Another option is to try to autonomously break your balance using AI and adjust to avoid that scenario: doing this would likely teach you a lot of the intuition involved in balancing. If there was a simple way to ensure balance you wouldn't see Blizzard releasing patches for Starcraft, IceFrog wouldn't have been so famous because of his balancing prowess. It all comes down to testing and listening to your community: which are often rife with people who are very experienced with balance - especially if your game's subject matter manages to attract such a community. One of the main reasons balance is hard because there is a lot of "ghost in the machine" (where a computer exhibits surprising behaviour) involved in games. For example, if you are using a dice-roll/random damage system the random number generator you are using could introduce balancing factors. Another problem is ingenuity: you might make some unit that can teleport and completely underestimate how important mobility is. Things like this simply can't be modelled at all. 

Frag_details consists of either [r, g, b, a] for a coloured poly, with texid set to 0, or [texture x, texture y, 0, 0] for a textured one. However, samplers must be uniform, and uniforms can't be modified. So how on earth would I swap between textures in one draw? Do I have to set them all up as uniforms and then pick from those? I'd have to use an array, and know the length, which isn't really practical for a UI system where buttons will be clicked, tabs changed, and so on. Is there a way to do this? 

For the sake of anyone stumbling across this later, here is what I did. In the GLSL Fragment shader, it outputs a constant after main() called gl_FragDepth, which will be set to gl_FragCoord.z unless you change it. So, with some trial and error, I discovered the magic number was 0.0006, and set it per-vertex, so the top two had this and the bottom two had 0. So now in my fragment shader under the texture coord is this line: 

I'm currently working on a 3Dish game; it's on a grid, with 3D props and the camera looking down on the grid at about 45ยบ, but I want to use 2D sprites for the player and NPCs. Currently, I'm using a quad as a canvas, but I've run into some problems. If the quad is coming up vertically from the floor, foreshortening squashes the player. If I tilt the quad to the same angle as the camera (manual billboarding), the player looks fine but will clip through 3D objects to the "north" from the camera on the grid. I've looked into point sprites but it seems like these would have the same problem. So, tilting the canvas is out. I need the player to be able to go in front and behind things. My latest and most promising attempt was to turn the vertical-oriented square canvas into a trapezoid, to compensate for the perspective change. (The canvas is 32x32; at a 45ยบ angle it ended up having a top length of 28.14 and a height of 39.68.) This gets me a square canvas again, but the texture isn't right. It ends up slightly squashed; on nearest-neighbour sampling it loses a row of pixels in the middle (on the character where it's noticeable) and gains one somewhere at the top (above the character's head...) My maths on the trapezoid might not be exact, but this doesn't really seem like the right answer for keeping things pixel-perfect. Is there a way to use that canvas quad as, I don't know, like a window onto another rendering context which would be pixel-perfect? Context: This is in Python, PyOpenGL and Pygame; the maximum GLSL version my computer can handle is 120 so it's openGL 3-ish but not quite. 

I'm going to go ahead and answer this with the procedural approach. I'll assume you have a workable knowledge of linear algebra. I am going to hash over this quite quickly so feel free to ask me to expand on any point of the answer. Consider this overhead: 

Now what 'occurred to me' is that in the first example 83% was just "0.5 out of 0.6" (in other words "0.5 out of 0.5 plus 0.1"). In random event terms that means either: 

As per my comment, does not work. However, you should be able to use a to achieve what you are after. You can map a one-dimensional index to a two-dimensional index using the following function: 

Angle-Based With this one you basically ensure that, once again, we don't fall within a deadzone - but also that the angle is within certain ranges. 

From the deferred rendering articles/tutorials I read it's a limitation in XNA (likely because the XBox 360 probably discards the depth buffer when you change render targets, hence they apply the limitation to Windows as well). What you need to do is use MRT (Multiple Render Targets) and write/test the depth against another that is something along the lines of . When you have finished 'compositing' your depth buffer write it out to the real depth buffer using a screen quad and associated pixel shader. The first article in J.Coluna's (quite brilliant) series on LPP describes the problem briefly - and his code should provide a nice reference for working around the issue. 

Spatial hashing, quadtrees or octrees can be used to find candidates for the nearest neighbour quickly: and then you can use the loop on that candidate set to get the actual nearest neighbour. Initial Premature Optimization 

My math might be a bit wrong, so I have wikied the answer. I assume you want to do the continually homing scenario - where the missile P1 travelling at a velocity V1 constantly tries to turn toward the player P2; but at a limited turning rate.