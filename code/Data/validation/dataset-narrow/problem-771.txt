Server not found means DNS resolution failed. Check your DNS. Do you have both www.domain.tld and domain.tld setup? Do the IPs appear in access.log? 

If you're willing to step down to IP based user identification, you can expect openvpn to reassign the same VPN-IP for a user's lifetime. See assigned IPs in ipp.txt (/etc/openvpn/servers/VPN/logs, path may vary). Then, check if traffic passes through linux kernel. It might stay within the OpenVPN daemon, not sure about that. tcpdump and see what happens. If it passes through the linux kernel, normal IP accounting would work well (MRTG et al). If it does stay in the daemon, openvpn-status.log contains the external IPs of the currently connected users. Correlating that with MRTG data may be a tough exercise, though. So check if there's any config option for openvpn to force traffic through the kernel. You're using a Linux server, right? 

SATA Interposer Cards are another solution. I recently experienced exacly the same fate and found this thread. The overall tenor is that SAS protocol is better suited for RAID than SATA, because SATA is lacking features. This is why the same physical drives are equipped with SAS controllers, then sold as Nearline SAS. Searching further, I found: $URL$ I'm investigating upgrading one of my storages with a batch of these. Right now, the price difference between 3 TB SATA vs SAS is 400% (vanilla price, same brand, specs and shop, Germany). I obviously can't tell if this strategy works out well, but it's worth a try. Comments very welcome :-) 

The Server Reboot in your case is not related to the issue of the DNS registration. While I cannot conclude why the server restarts in your case, you can eliminated the cause of the DNS registration failure error, please refer to the following links: 

Please also be aware that not all queries are cacheable. For example, if a query contains function like NOW(), it would not be cached. Please find the detailed description of which queries cannot be cached: $URL$ 

I have solved the issue by disabling "Hardware Large Receive Offloading" in pfSense settings (System / Advanced / Networking | Network Interfaces) There is a checkbox "Disable hardware large receive offload" and I have turned it to "Checked" (ON). The description says the following on this option: 

According to HP documentation, the network adapters on Gen8/Gen9 (model 331 based on the Broadcom BCM5719 chipset) support standard TCP/IP offloading techniques including: - TCP/IP, UDP checksum offload (TCO) (moves the TCP and IP checksum offloading from the CPU to the network adapter). - Large send offload (LSO) or TCP segmentation offload (TSO) (allows the TCP segmentation to be handled by the adapter rather than the CPU). That's what pfSense writes about these features: 

and rebooting. The question remains: Is this typical for current 6 gb/s equipment? Is this the sad state of SATA storage? Or is some of my equipment (the sff-8088 cables come to mind) bad? The Problem was: Synchronizing HW RAID-6, disks kept offlining. Fetching SMART values reveiled that those which offlined did not increase powered-on hours anymore. That is, their firmware (CC4C) seems to crash. Digging into the matter by switching to Software RAID-6, with the disks passed-through, I got tons of kernel messages scattered across all disks, with 6 gb/s: 

Unfortunately it does make sense, but I don't see how the card has much to do with it. The 5V / 12V line is provided by the power supply, and the drives might be drawing on 5V, which may be underrated or non-existant at all. So the drives won't spin up when the card tells them to. If you are very lucky, you only need to enable staggered spin-up in the card BIOS to lower the peak power consumption (you wrote it sometimes does boot). If that works, perform a random write load test before doing anything productive. I looked up your power supply, it's 560W which is a really low total (2U storage chassis have 900W or 1400W). I'm using a dozen Seagate Momentus 750GB in a 2U storage chassis with 900W and Adaptec 5445Z. Slightly different story, but the Momentus series is also "notebook class", so Seagate disabled the activity LED (now THAT's gonna stop me). The drives work very well (good overall IOPS). Can't tell anything about long-term, though. I planned to go for WD Scorpio next time, but now I'm going to reconsider this idea. Seems the manufacturers really don't want us to do this. 

Change the MySQL config to log queries without indexes, so you will be able to find such queries and add indexes and/or modify the application that sends generates such ill queries. You should enable "log-queries-not-using-indexes" Then look for non-indexed joins in the slow query log. 

There is no traffic-shape on pfSense. What can be the reason? If I CHECK the option "Disable hardware large receive offload", it becomes fast again, but I don't want to disable it, I want pfSense to use hardware large receive offload with VMWare VMXNET3. Update: I have upgraded VMWare to latest 6.5 with all patches and pfSense to 3.4.5 BETA, have updated the firmware to latest versions, and it didn't help. 

Do not Increase Per-Connection Buffers! Not all buffers in my.cnf are allocated only once for the server instance. Some buffers are allocated for each connection. Please see more information at $URL$ : Quote: 

In fact there were not hardware/drivers have issues, but a misconfiguration. LRO and TSO should never be enabled on a router. Only if pfSense is configured as an end-point (e.g. a DNS server), these options may be enabled. Let me quote from the FreeBSD bugtracking entry: 

If you're using syslog, you can configure your log server to replicate logs live to another server (e.g. rsyslog) for real-time backup. Then backup all rotated files as already suggested for long-term archival. logrotate can be configured for custom applications, too, and can apply bash scripts on rotated logs. So you may skip /var/log in external backup tools altogether and copy logs to an archive directory which is more static. 

Without knowing anything about mono asp.net, try disabling cookies when testing. It might be your application is locking session storage to keep things serial, thus consistent, per-user. Without cookies (also across domains), your tabs get unique sessions each. 

On two Supermicro 847E16-RJBOD1 enclosures, I have trouble accessing SATA disks on the rear backplane with 6gb/s. The only significant difference between rear and front backplanes is total cable length from HBA to backplane, which is about 1m + 30cm vs. 1m + 70cm. SAS signalling shouldn't be affected at these lengths, and I always assumed HBA and backplane will connect with SAS signalling whatever disk type attached. Is this assumption wrong? Do SATA disks limit HBA to backplane cable lengths? 

The Speed of Memory Access Contrary to the common logic, access to memory is not O(1). More RAM you have, slower is the access to any data in this RAM. So, using less RAM may actually provide faster access to the RAM - this is a general rule, not only applies to MySQL. Please see The Myth of RAM - why a random memory read is O(√N) Now let us get back to the MySQL join_buffer_size. Tuning MySQL join_buffer_size 

We have ProLiant DL360 Gen8 and Gen9 servers running VMWare ESXi 6.0 with virtual machines under various versions of Windows that are routed via pfSense 2.3.4-RELEASE (64-bit) with Open-VM-Tools package 10.1.0,1. The virtual machines that work via pfSense are demonstrating very low upload speed, for example: ping 2ms, download 134 Mbps, upload 0.25 Mbps (by the way, 0.25 Mbps is acceptable speed for Remote Desktop connections, but, in practice RDP barely works, the client frequently stalls for a few seconds, or refresh occurs in squares, taking 5-10 seconds to refresh the screen, is unstable, or sometimes even reconnects -- making the work via RDP practically impossible). Tweaks on the affected Windows machines like “netsh interface tcp set global autotuninglevel=highlyrestricted” didn’t change anything. The virtual machines that have direct connection, bypassing pfSense, don't have these issues - they have about the same upload and download speed. All virtual machines (pfSense, Windows, etc - all) are using VMXNET3 adapter. The following options are all unchecked in the pfSense: 

like Inigo said in his comment. Just below ProxyPass. (wow just realized I'm over a year late with this post, "unanswered question" it is but I doubt the author ever comes back) 

There's Sheepdog integrated in Qemu, providing distributed image storage as well. Don't use it myself, but it seems to cover your goals. $URL$ 

Configure Jenkins to run on Port 8078, unencrypted, but on the localhost IP 127.0.0.1. No firewall needed, as no one from outside can connect that IP. Only if Jenkins cannot be configured to bind to 127.0.0.1, you need a firewall. Create a special user account with a custom shell that acts as a telnet client to 127.0.0.1:8078. You can do so with a very simple bash script. Authorize all public keys to use that account. Connect to SSH at port 22 as usual with the special user. The connection will open the special telnet shell. 

Try turning on error_reporting(E_ALL); and point your browser to the image URL. Comment the type header to see any error messages that may be hidden if your browser only displays a broken pict message. And fix that missing semi-colon Ben mentioned. Edit: And sanitize $_GET['src'] you may be opening a big security hole there.