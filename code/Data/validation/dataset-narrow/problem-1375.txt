Definitely not. is just a tool and you should use it when it fits your desired result. If your widgets are supposed to be laid out in a tabular way, then use . Otherwise, it's perfectly okay to position your widgets manually if that's what you need. Two alternatives to 

I'm in a bit of a dilemma regarding how certain engine components — like camera and UI — know who to follow, whose health and other attributes to represent on the screen. How do you architect a system where does communication between those components and the entities take place? I could have a separate entity that represents the player, but that seems a bit 'hard-coded'. What if I want to pan the camera? What if the player starts controlling another entity? In other words, how do I abstract away the data sources for components like the camera and UI, such that they don't care what entity they represent? 

What good free and widely used tools are there for editing 2D skeletal animations? Preferably, one that allows me to write custom animation exporters. One pretty good indie tool that I know of Demina, but it's not ideal. It doesn't allow you to export the data as you want (although, it is open source, so you can change that) and I find it clunky in how you edit individual joints. What other tools would you recommend? 

An event system will do for a lot of cases, but that is more suited for propagating information that changes or is generated 'rarely' (like the death of the player). For something like entity health and position — which need to be known every frame — an event system isn't well suited. 

Imagine I have a skeleton — that is a set of bodies held together through various constraints and joints — and I want to flip it. Bodies cannot be flipped in Box2D, so how can I fake that? Here's an example: I have a humanoid skeleton, made out of different Box2D bodies: the head, torso, upper arm, lower leg, etc. These Box2D bodies are held together by joints. Some of the joints have angle constraints, like the ones between the upper and lower arm, which do not allow the 'elbow' to twist unnaturally. When I turn my character the other way around, I should flip the skeleton and its joints should be flipped as well. How can I achieve that in Box2D? 

Very simple as you can see. It runs fine in webGL, but it seems it won't compile in OpenGL. I am no expert in shaders so I have no idea what might be wrong. Am I using some syntax that only exists in webGL? Also just in case, here is my vertex shader (which compiles fine): 

I ended up with a simple idea that worked surprisingly good, so here it is: In my particle engine, I generate particles per gameloop tick, and running at 60 FPS we have, for an elapsed time in seconds, particles generated. This could vary if your game isn't fluid and frames drop, but we assume it runs correctly. Now what happens is that the prewarn function is launched once the particle emitter starts, and emits this number of particles. Then we have to simulate where they are, because they should have been all generated at different dates, when in truth they haven't. All of this is done with a simple for loop (example in ): 

That's not really beautiful but it works. If someone knows a way to get precision in desktop shaders, that would be better though. 

As suggested in the comments, the precision directives are not supported in the OpenGL version that haxe/lime compiles to. Adding a doesn't work either, maybe haxe or lime doesn't read these I don't know. Anyway I found the solution reading through the lime samples: 

I am working on a physics engine that uses basic Euler integration to compute forces. So, here is the thing: 

Also you may want to provide some context as to why you are doing the same rotation 20 times in the same for loop (which effectively shouldn't do anything) what is your objective? 

I am programming in (language compiling to multiple platforms) and I have written some shaders. My fragment shader runs fine in html5, but when I try to compile for native (OS X and/or Neko, a VM for Haxe) I get a shader compilation error, but no details (I am using which is a platform abstraction that does these things for me). Here is the shader: 

If you have only a basic knowledge of C++, I don't think that's going to be enough to (easily) develop something like a platformer. Python is an easy to learn language so it's not a bad choice at all. If you pick C++ I recommend you use SFML for graphics and sound, and either Box2D or Chipmunk for physics, if you want such a thing. If you do pick Python have a look at Pygame (graphics) and Pymunk (physics). But developing a platformer isn't exactly easy; you might want to start with something easier, like an adventure game (where you only click around the screen and you don't have to worry about complex character interactions). 

How do you usually solve collisions between entities and the ground? Sending collision events hardly seems appropriate since almost everything touches the ground at almost all points in time. Calling collision handling functions doesn't sound any better. How is this normally achieved? Is handling of slopes significantly harder? 

I'm writing a component-based entity system and one of the components is the entity's state, which dictates how it reacts to game events. In case anyone has experience with implementing states, how granular should they be? To give you an idea about how granular they are in my case, I have a state and a state (as opposed to simply a state) and I fear that they might be too granular. What do you think? 

I have a very general question: In games, what use does the programming concept of a window have? Or, in other words, why do some game dev libraries offer interfaces through which to create multiple windows? — Why would you need more than one windows in a game? Are multiple windows used as different views/states of the game? (I.e. in-game, main menu, pause menu, etc.) 

When positioning manually One piece advice, though, if you decide to position your widgets manually: don't use absolute pixel coordinates. If you your screen is 400px wide and you want a widget's X coordinate to be 200px, set it to , instead. This will allow your widgets to be position correctly, even if the screen size changes and it takes no extra effort on your part. 

Dotproduct produce scalar value, or constant. Therefore, we have a simultaneous equation, which can be solve using any mathematical method of your choice--- I prefer cramer rule. Another thing to point out is the magnitude of U and V will expand or compress your isometric coordinate. For example, if I define u and v to exactly cover 1 full isometric tile, then (1,1) would be the same thing as 1u + 1v which is the bottom-right corner of the first tile in my isometric system, where top-left most is the origin. 

How would I apply a mask for pixel shading effect to restrict it only to some part of image? For example I have a height tile: 

After a few days of researching, I found a solution to this particular transform. This is much more mathematical than program-oriented. Therefore, I will be using pseudo code. Now, given a screen coordinate (x,y), we first want to represent (x,y) respected, or fixed, to the world, not the screen. For example, my game use the top-left most corner of isometric map as (0,0). So anything representation of coordinates in this game will be respected to this world. 

Now, given that we already know where the point lies in cartesian coordinate and representation of vector U and V in term of cartesian i j. What we want to find is the isometric counterpart of this point: isometricPointXY, which is our desired isometric coordinate. Now, with U,V, and W in term of i j, which enable them to dotproduct each other and produce scalar quantity. We can use this property to produce 2 simultaneous equations: let A.B be A dotproduct B, from equation above 

I want to create various sprite tool and map editor using XNA. Now, the problem is I do not know how would I implement the window forms and components (such as button, check box, sprite list, etc.) into my program and allow it to completely control my XNA environment. If there is any tutorials or examples that show how to make editor for XNA, then I would be very pleasing. Thanks 

I am wondering what would be a good way to handle enemy crowds generation and simulation. For example in a hack'n'slash game, how would one go about placing enemies and managing their movement in the world with it feeling at least a bit natural? What I am looking for is the general approach behind this. I can write (and have written) some code to simulate as best as I can these things, but it feels a bit "hacky", it's just each enemy having a pre-scripted behavior. I am wondering if there are general simulations method to manage enemies walking in the world and chasing players, as it is an element that exists in many games. In my case, what I have done is to give them random intervals of time in which they can choose a random direction and move for a random duration. Then if the player gets near a certain range they will stop that and chase him (applying pathfinding), but maybe there are more general ways of thinking others than pre-scripting pseudo-random behavior? 

So now imagine I want to apply a force to jump, I will use at the moment the player presses the jump button. But: What happens is that the amount of movement depends on the gameloop speed, since the force is applied for a single frame. I feel like I missed something about how you should use forces, but I don't see how I should manage it properly. In which cases should we use a force, considering this deltaTime issue? And also, what should I use instead? 

I'm wondering what are good ways to find people you can work with on indie projects. Is there anywhere some sort of list of game developer forums ? Or if it doesn't exist, what websites would you advice for that matter ? PS : I know the question may sound a little off-topic, but I think it actually relates to project management, sorry if it is not the case.