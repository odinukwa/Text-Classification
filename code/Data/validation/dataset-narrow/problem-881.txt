Copy the file somewhere new, then have nginx produce a redirect to that contents new location. This is only a temporary measure but sending 302s from the webserver versus parsing and executing PHP every time will be much much cheaper. Genuine users browsers should just honour the redirect. 

Because the utility is exclusively a DNS lookup utility. Most applications use the library calls or . These libraries interrogate a file called to determine the lookup priority and policy of how to perform different lookups. Typically contains the line 

It basically requires that the XFS block size be at least equal to the systems page size. This means two things. 

Probably. Reading the manual, trying this stuff out for yourself is the first step. Whether or not it will get you into where you want to be is a different question. A business which has services handling thousands of requests a second for example is very difficult to replicate in a training environment off of your own back. But, yes - demonstrating your knowledge and knowing you can put it into practice should at least get your foot a bit into the door. 

Before we answer how this is done in SELinux type enforcement, consider how you would do this in DAC (discretionary access control; the standard UNIX security model). How this works in the Unix Security Model In DAC, the subject is primarily the UID, but the GID and supplementary GIDs also define a subject. Objects are files, directories, unix sockets and are mostly referred to by their paths (although some exceptions exist, like IPC shared memory). Normally, when you run a program - there is no transition. User wants to run . When he does so, the process is instantiated and inherits the subject of along with any other properties of his subject (GID, supplementary groups etc). However, there are some programs that when ran do transition. When user runs the command, transitions into , which is of course necessary to make changes to the shadow file. This automatic transitioning behaviour is controlled by flipping the SUID bit in the filesystem permissions, its defined who you transition into by setting the owner of the executable file on disk to the target subject you want to transition into. So for clarity in the example becomes because the permission mode is 4755 and the owner is . So, setuid performs transitioning in the standard unix access control model. Unfortunately setuid programs have a horrendous history of security problems. This is due to the limitations in the DAC security model when it comes to how transitions are evaluated. The setuid transition process performs no check on the subject (user) invoking the program. Both and will transition to along with , and if they invoke . It is not possible (without having the program itself check and we all know how reliable that has been) to make it so that when calls he transitions to but if calls passwd for it not to transition to . The only thing you could do is outright deny from ever calling in the first place using POSIX ACLs but that is not granular. It is also not possible (without the application doing it and having privileges to do it) to have the owner of the file be someone else other than the person you want to transition into. So cannot run and become the user instead of . How this works in the SELinux Security Model The subject in selinux is referred by the label type that the user or process is running in. This might be , or for example. Objects are files, directories, sockets etc just like in DAC and are referred to also by their type and also have labels. , and are examples of different object labels SELinux uses. Under normal circumstances, just like in DAC, no transition occurs. If executes (or the way SELinux sees it, if executes a object), it is instantiated and inherits the subject of from the caller. However, some programs will transition when called. If executes the object labeled (which is unsurprisingly) he transitions to . This is defined in a type transition rule that in policy looks like this: 

Because a username must be resolved to a UID, so if the user does not exist no resolution can occur, whereas a UID is a terminating type (it describes itself without resolution). Technically all chown requests by the operating system must be done against a UID. The username is for your benefit, not the operating system. 

If you used the certificate to perform mutual authentication. Its a wildcard certificate or a certificate which hosts multiple domains (the losses double, or triple or whatever many hosts can be used for it) The certificate is multi-purpose in some other fashion. The certificates purpose is to ensure the integrity high value data (medical records, financial transactions and the like). The other end expects a high degree of trust and/or is reliant on the integrity of your system to make operational decisions. 

Yes, there is. The audit subsystem has some pretty neat accounting features. Running the following command will audit changes to the file: 

Given you are actually making a spool file. This gives other macros the ability to work with that spool if they have 'manage spool' privileges in their policy. 

Even under best circumstances (using an epoll set) 2 million entries in an epoll set is expensive. Thats never going to happen with a worker or prefork model. You need to be spreading this load out more evenly. You probably need another 10 nodes at least to get anything worthy of what a user would call a service. 

Firstly, dont use fakeraid if your optiong for linux. Its useless. It does not balance reads/writes at all, opting to read from ONE of the disks. Dont do it. With regards to the hardware/software raid, my experience has been that software (mdadm) RAID is really very good where the number of disks does not exceed six. Theres a few reasons for this. 

Your filesystem must support it (most do these days, they can be enabled by remounting the filesystem with ACL support on most filesystems). Stuff like NFS wont work. The standard Unix group ACL becomes a mask. I.E if a file says g+x the file is executable with the command above. if its g-x the file is not executable, regardless of whether or not permissions set are rwx in the ACL. This ensures you avoid a situation where you would have to mark all directories rwx in the acl and all files rw-. 

Providing only the headers of the partition were destroyed this may work. If that doesn't work however, you can try to fix the filesystem using by specifying the superblock address. Backup the data with dd or something before you do this. 

Newer distros/kernels support the command which, should do what you want, providing you are root when you do it. Here is an example (Fedora 20). 

This will manipulate the zone file in such a way that it will add the correct serial number and append the right nameserver. You need to call the script for every zone file. You can use or a shell loop of a glob to do this. This relies on the format of the serial number being such that it contains "; Serial Number" on the line. It also expects the domain name to be declared as the first word on the first line. Finally it expects the nameserver declared in "$LASTNS" To be there. You can change the value before running the script though. Oh and running this script against a zonefile already manipulated by the script will break the zonefile. There is a simple test to fix this but will leave you to work that out. 

The login programs set these variables. You can of course override HOME if you must, or even unset it -- but unless you went to effort to modify the source of each program you can not ever get rid of it. Note even if you alter HOME to be something else the authoritative source of your home directory will always be present in or the derivative. If you login via a real TTY, login will set it. From util-linux in login-utils/login.c 

This is the absolute worst case scenario. So, broadly speaking -- whats the impact? There is no negligable impact for 97% of your served requests. Of the 3% that are affected, expect a higher delay in those being served up -- probably 500 millisecond. BUT of those 3% of unlucky requests around 2% of them anyway would have been slow because they wanted something out of the 6500Mb cache that was never in pagecache anyway! They however do suffer from the high disk utilization now. So, in summary with my contrived and assuming example you'll see in broad terms about a 3% loss in efficiency. (100% efficient would be all objects for every request are served out of memory). In 'normal' running in this contrived example performance would be about 98% efficient. Not bad for a cache that doesn't fit into memory! 

Yes, if you are receiving genuine packet loss. Things are much more complicated than that unfortunately. 

This will allow you to do (almost) what you can do as root as unconfined. Oh and one final tip. Using is a bit tricky with RBAC (it does a lot of stuff which gets it into all sorts of places). Instead you can use the command which does the same thing without a lot of overheads. I actually restrict use in sudoers like so; 

This file is placed into memory and cached, but all new objects in the cache are sent to the 'inactive' list by default. This evicts 1750MB of your 'cooler/inactive' memory from the varnish cache and replaces it with the catted file. The kernel is now forced to write out 1750M of this data back to the disk (in the absolute worst case scenario). IO Wait and device utilization takes a hit because you are reading in a 2G file and writing out a 1750M file. 97% of inbound requests are unaffected by this because they want the hottest 1750Mb of varnish data which is in the active portion of page cache! 3% of unlucky clients want data in the cooler cache. These guys see a delay now because the disk utilization is already pretty high and they are queueing to fetch back pages into page cache again! Since the catted file is never re-read quickly enough page cache evicts those pages in favour of the 3% of clients wanting some cooler data.