I know it's possible to server static files using error_page in NGinx, but I was wondering if it was possible to server an url from my local (socketed) Flask app that is served through UWsgi. Here's the NGinx configuration : 

(with other params). Here's my problem: All the server are publicly available, not a part of a private network (The servers I took comes from different offers and doesn't offer this possibility, unfortunately). For the frontend, that means YOU can plug your uWSGI instance to it ... not great. I've found out that I can secure the subscription system, so this should be ok (can you confirm or infirm it?). But now, the parameter on the sub_servers is public, which is discouraged by uWSGI (first point). So my question: How can I take advantage of / from uWSGI on servers that are facing public access while keeping things secure? Thank you for your help! 

But then, I can't even access facebook.com nor www.facebook.com via http/https. So my question is quite simple : how can I redirect all https access to facebook.com (and eventually all sub facebooks : facebook.fr, www.facebook.fr, etc) to www.facebook.com (redirecting to www domain) in HTTPS ? Thanks for your help ! :) 

I have a website build with Play! Framework that I show with NGinx using ssl. Everything works fine but I'd like to implement a file upload limit based on url : 

Is it possible for a VirtualHost to listen to the public IP, without having to set it in the file (but by using the environment configuration) : 

What is bothering me is the ProxyPassMatch that allows to load any file in the directory that ends with .php*. I only want to execute files in but since it's an alias the part is already appended => 

I recently configured a Debian 8 with Apache 2.4. Since I have a fairly recent version of Apache, I used ProxyPassMatch instead of FastCgiExternalServer. But when configuring my alias for PhpMyAdmin, I wondered if this was secure. Here's my configuration : 

And, as you might expect, I have a fleet of servers that contains the actual code and runs uWSGI that subscribe to this fastrouter, like this: 

I made a shell script that deletes an unix user and among other things, here the command used to delete the user : 

I know it's a security issue, but just by curiosity (I can't find a proper answer to that!), is it possible? I defined cifs.broadcast=255.255.255.255 in the Alfresco configuration, but whatever I define, I can't access it. I'm trying : 

I actually own two linux web servers and I was wondering how I could make them work together in case one goes down. From what I found, cluster seems to be the closest, because it would replicate the data (for mysql as example) from srv1 to srv2, and vice-versa. I found a howto on HowToForge, but they talk about 4 servers. After reading, it seems legit, because the cluster need a server to synchronise the data (and a second server in case the first goes down!). So it's not what I'm looking for, or eventually not in that way. What I'd like would be that srv1 & srv2 are identical (mysql and apache files) in case srv1 goes down. The aim at the end will be to build a FailOver (and not a LoadBalancing) system. For the IP, I will switch it manually from my registrar. Is it possible to do it with only two servers? Thanks for your help ! (If I was not clear, I'm sorry, It's not really clear in my mind too). 

I've build a simple Mail server for my personal use, but Google reject my emails whatever I do. I worked hard finding the initials problems (wrong SPF entries in the DNS), but now, everything seems fine, and I still got this kind of messages from Gmail : 

I setup an Apache2 server with the mod_cband to limit download speed at 512kb/s, and I was wondering what happens if I reach the limit. For example, if my server connection is 100Mb/s, I would theorically be able to serve 195 users. What happen if I have 200 simultaneous users ? Does the last 5 will have an error, or just the download speed that will be lower ? Thanks for your help ! 

Is there an alternative to this module that would call a script with any GET request? The main thing I want to do is log data, so it's not a problem if the content of the renderer request is not given with it. Thanks for your help :) 

The folder is correctly removed, but if I go to the /etc/passwd, I can still see the user in the file. I tried the command manually and there was no errors. What am I missing? (I can show any log if you need them, I just didn't find any odd things) Note: If I do this command () manually for the users already deleted, they are correctly removed from the file. This seems to indicate that when it's being called by the script, it fails for some reasons. 

But when I go to the $URL$ url, I have a correct xml page with a list of my projects. What is wrong? (Please ask me what I have to show you more from my server to help you.). 

When I'm trying to access an url like image%20xyz.jpg, I got a 404 error. When I look into the logs, Apache converts the %20 into \xa9 (and every url encoded characters are transformed to their \xXY values instead of the correct chars (space in that case). I tried AllowEncodedSlashes but this doesn't work. Which Apache directive should I put in my VirtualHost or .htaccess to make something like 

From my understanding, when successfully update the certificate, it returns a success state (exit(0)), so the is followed, and so nginx is reloaded. Yes but it doesn't work. I recently had my server showing again an expired certificate, so I certainly misunderstood something, and/or my cron task is not good. Could you show me the path please? :) 

I have a Load-balancer (LB) server using uWSGI that redirects traffic to sub-servers (workers). These workers are powerful and I can easily run 16 uWSGI processes (using the parameter ), but the LB is a basic VPS since it only redirect requests to the real worker. Since it's a basic server, I can only run one or two processes for uWSGI on that LB. My question: Does this limit on the LB affects the performance from the workers? Or since the LB only redirect traffic, once it's done, it can handle another request while the worker treats the first request? Thank for your help.