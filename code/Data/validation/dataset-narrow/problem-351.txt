I'm analyzing a database of login records for a university and I'm trying to write a query that will give me an idea as to how many users are using the labs for short bursts, verse a more extended stay. I have the query below query, which tells me how many times each user has used a lab for less than or equal to 10 minutes. What I want is a result that tells me this and their total number of logins. 

The duplicated a's in the first group and b's in the second group are due to other rows in the data (I'm okay with this, but removing that would be a bonus). My main problem is I need that final a to be treated as a different group; so basically showing the first each time a cluster appears. 

It sounds like your database administrator has set the value to . Change this value to , and do a restart. The restart will take a long time as normal, but the following reboots should be much faster. If this device is really a "blackbox" to you, I doubt you can change this yourself. I'd contact your DBA. See the documentation for more details. 

This isn't a big deal for such a small query, but most of them return many fields (often 20+) and I'm not a fan of so many case statements for obvious reasons. Because of how Reporting Services work, I can't do a general replacement either, it must be done on each and every field. Is there a more efficient method where I could replace every value in the row with 'Confidential' in a single case statement, or at least something more elegant? Edit: To clarify, that there isn't just this one field in the select. I only wrote one for the example, but in production, some reports are looking at displaying a huge amount of columns. I'm trying to avoid making two comparisons on every column for reports that could return rather large sets of data. 

I work on a relatively small development team that works with an Oracle (11g) database. It's recently been requested that all the developers be given the role so that we can utilize SQL Tuning Advisor when developing complex queries. Some have raised concerns that this may have significant performance and/or security implications, but I have not been able to find concrete answers to what these implications are. If this role were to be given to the various members of my team, what are the major pitfalls we should be watching out for? I've included the tag for Oracle 12c as well, since we'll be upgrading to that in the near future. If there's a significant difference between the two, I'd appreciate it if it was at least pointed out. 

In a current report, I'm trying to track the migration of a person from department n, to n+1, or to n+k. My data is split into a row per term (university data). An example: 

I'm working with Microsoft Reporting Services 2008. In our database, we have a small group of confidential students that need to be taken into account for several queries. If they are a confidential student, the database needs to essentially return nothing. Currently, we do something along the lines of: 

I have created two identical procedures in two schemas. I have then granted execute on each procedure to a third schema. I call each procedure using the qualified object name. When calling the procedure in one schema there is no issue, when calling the second I get PLS-00302: component must be declared. Why? Here's the code I'm running, actual usernames/passwords have been obscured. Firstly the procedures are created in and and execute is granted to 

If the function does not need to be called from SQL you could change it into a procedure with an OUT parameter, though this still requires a "junk" variable it might look very slightly cleaner? 

Earlier today we had a problem logging into a database that had just been created automatically. When on the actual box (Linux) , i.e. a local connection, was fine, though, it was occasionally impossible to do anything once connected. Otherwise, whether using a session on the box or not did not work at all. and DNS testing revealed nothing and there was no problem in . The Listener was accepting the connection but not handing it off to the database. This was confirmed by using on the listener log and watching it accept the connection. There is a logon trigger on the database that inserts the user details / time etc into a table, but this doesn't have any indexes and there cannot have been any locks. We finally traced the issue. There was a conflict in the file that creates the temporary tablespaces for the database. It resulted in there only being 5MB of tempspace instead of the normal 25GB. Disabling the logon trigger and then adding the additional temporary tablespaces, sorted everything out. There were some sessions already running that would have been using some of this tablespace. Apparently Oracle requires some temporary tablespace in order to accept an incoming connection. The specific version used on this DB was 9i, though I think this applies to all. Why and what is it used for? 

The pk constraint, for the IOT, would become with a separate constraint on the pk solely for structure. is null in approximately 99% of the table so this isn't very selective anyway. Main index used is, I think, , we tested about 20 combinations and this came up top by a long way. I am completely unwilling to add any time at all to these queries, 0.01s a day added by select is 41 minutes a day. We'd much rather settle for "good enough" than perfection. 

We need to add a column to a table that gets hit about 250 times a second, approx 170 selects, 125 inserts and 60 updates. The column will be a simple . The does not matter for the inserts or updates i.e. not part of the primary key, which I'll enforce separately. We basically don't want to have to do an over a range scan 170 times a second, as the number executed will drop massively. Does an index organised table guarantee that will always come before when running the following query: 

You can create a username and password also provide grant access to them. so that all clients can access the mysql from their local by using the username and password provided by you. 

I am getting the below error in mysql while trying to ping. i am using mysql version 5.5.37-0ubuntu0.12.04.1. when ever i use mysqladmin i am getting the below error. Please suggest how to clear this issue 

Error Cause: The control file change sequence number in the log file is greater than the number in the control file. This implies that the wrong control file is being used. Note that repeatedly causing this error can make it stop happening without correcting the real problem. Every attempt to open the database will advance the control file change sequence number until it is great enough. 

I had some changes in that table and it got executed. mainly the primary key. pl go through the same, 

Try the above query in terminal or check the below link to repair table or databases via phpmyadmin $URL$ 

In create table you have set teams as primary key, and also you are aware that primary key does not allow duplicate values. 

I had created table with engine BLACKHOLE basically the BLACKHOLE storage engine acts as a “black hole” that accepts data but throws it away and does not store it. Retrievals always return an empty result. I heard that we can retrieve the data by creating a new table same as the old table with storage engine as innodb or myisam. but i had tried that also but unable to get the result. Can any one pl help me on this issue to fix it. 

Check the insert query for teams field you have mentioned values as 1 and if you insert the same value for second record it will behave as below. 

This error happens when Full back up is not restored before attempting to restore differential backup or full backup is restored with WITH RECOVERY option. Make sure database is not in operational conditional when differential backup is attempted to be restored. Please have a look on the below blog. $URL$ 

WITH (NOLOCK) is the equivalent of using READ UNCOMMITTED as a transaction isolation level. So, you stand the risk of reading an uncommitted row that is subsequently rolled back, i.e. data that never made it into the database. So, while it can prevent reads being deadlocked by other operations, it comes with a risk. In any application with high transaction rates, it's probably not going to be the right solution to whatever problem you're trying to solve with it. SQL Server 2005,2008 and 2008 R2 will support Nolock. Pl look on the below link $URL$ 

If you anticipate that your database file(s) will exceed more than 1TB in size you should configure the server to put the data files across multiple VHDs. How can spread my databases across multiple VHDs? Create one or more dynamic volumes consisting of multiple VHDs at the operating system level and put your database files on these volumes. Split your tables and indexes into separate database filegroups and then place those filegroups in different files (MDF + NDF) which are spread across separately attached VHDs. Note that this will not offer any benefit for transaction logs because SQL Server does not stripe across transaction log files but uses them sequentially. If you are migrated to Azure and want to compare the performance of your databases before and after the migration then take a SQL Server baseline(enter link description here) 

If you don't want to use this function though, why not just remove it from your code? The only time I can think of there being a valid use-case for this sort of structure is when you're running identical code in two different schemas/on two different databases but this function is useless in one of them. If that's the case the function is still useful in the other and so you will want to do something with the result anyway. 

As far as I can tell this doesn't appear to be a permissions issue (though it obviously is). The system privileges of the 2 users are identical, the following queries return no results: 

The following are examples used to convey the point, there are multiple instances of each of these examples within your ERD. Naming Consistency is key. Some table names are pluralised () some are not (). Your table contains data about many tickets so I normally prefer pluralised table names. You're prefixing every column with the name of the table. This makes for column names like , which isn't instantly understandable to readers. If I named the primary key of then you store and you might access , which makes everything more understandable. Relations There's a couple of relations that don't exist, for example you've got in (makes sense if you have preassigned seating) but no relation to ? Why not? If your cinema/theatre doesn't have preassigned seating then you don't need this data. There are some duplicates within tables. Why does contain both and ? Data duplication There are some unnecessary (unenforced) relations that are allowing for data inconsistencies. If a must happen within a an a ticket must be at a then there's no need for to contain any information about the hall in which the movie is going to be shown. It's unclear what the difference between the and is. Maybe one of them is the number of minutes the screening runs for? This information is already within and so is another duplication. Data There's no need to persist the age as you've already got the date of birth. I've written about this on Stack Overflow a few times. It's quite an assumption that all staff and movie names will be 45 characters or less. I find the inclusion of in the staff table a little off-putting. What's the purpose of storing this information? Are the chromosomes of the person selling you a movie ticket that important in this cinema/theatre. I also don't understand why it's 10 characters long. How to start Think about exactly what information is required to go within each table. If you're not sure it's required then don't add it in. If you need to add something later then so be it, but you haven't included a lot of unnecessary data. I'd set-up some test tables with dummy data to see if what you're creating will actually work. Every relation to another table should be enforced. If you've got some unenforced relations then either add a foreign key constraint or remove the column. Your cinema probably has tickets, so removing the data will prevent you selling tickets.