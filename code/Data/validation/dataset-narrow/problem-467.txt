This is some 30% faster than your code, not too much, but the idea of not checking divisibility, but stepping in longer strides over a sequence, is one you want to hold to: 

Note that the tests, which all pass, run your test samples against the values returned by your code. So both this and your implementation agree, which is a good thing. 

Explicit looping in Python is (very) slow, and you have a double loop, which isn't helping. Your inner loop is effectively setting to a slice of of the form , and you can take advantage of that to speed things up considerably. The only tricky part is figuring out how many items you have to set, to properly build the right hand side of the assignment. It is not hard to figure out that if you have a list with items, and you set every -th item starting with , you will in total set elements, which can be computed directly as . Putting it all together: 

In terms of raising the as soon is called (rather than when its result is iterated), this general pattern is likely the best. There are a couple of other points that bear mentioning, though. First, is one of the worst ways to handle a detected error (marginally better than, say, ). Make the assertion self-documenting so that if when it gets triggered sometime in the future, you have more immediate information in the stack trace about what is going on. At a minimum, include a message with the assertion: 

Note that I have modified your conditions a little, since yours seemed slightly off. The branch of your condition effectively says "if the zeroth column is "name" or the first column isn't a match, it must be a header" - I've changed it so that instead, an appropriate value in the zeroth column is a header, and a non-matching first column on is ignored. I've maintained a temporary 'headers' list, because your code is currently robust against those appearing anywhere in the file. A better way to maintain that robustness would be if you know - or, preferably, can parse from your file before now - how many variables you have data for. Then you could do away with that list and do this: 

You may also want to look at the ABCs (Abstract Base Classes) in the module, which provide a convenient way to check for certain general attributes in an object. 

You are building a lot of intermediate sorage that you don't really need, as you could simply iterate over both dictionaries simultaneously. Using the method of dictionaries (or if you are using Python 2.x will also save you a bunch of dictionary look-ups: 

It may be marginally faster than your code, but I think the most important improvement is in compactness and readability. 

It's not very relevant for traversal, but a dict-of-sets may be a better overall structure than a dict-of-lists, as it would let you check for edge existence between two random nodes in amortized constant time, as opposed to worst case linear on the number of edges. Using sets instead of lists for things like is bound to have a significant impact on performance for larger graphs though. Another point to consider, since you are building an iterator, is to make your function return, well, an iterator of course! You can always materialize them calling on the return, but for traversals of huge graphs it may spare you a generous amount of memory. 

Second, you could inherit from the stdlib one and add the missing functionality. If you want to add directly to timedelta this way as well, you would also have to override and to turn any object they are about to return into your extended . I was going to suggest monkey patching as another option (this being one limited context where it does seem worth it), but it turns out you can't ( and use ). I only recommend adding the strict compatibility things this way. The idea is to set it up so that if you stop supporting 2.6 down the track, you can delete this code without having to adjust anything else, except maybe some imports. in particular ought to stay separate, especially because it fairly specifically enforces/assumes your local policy ("serialised dates will be in one of these two formats"). 

Then you can move your inside the loop, in place of the . At that point, continuing the search to find all pairs is trivial: change the to a , and your function will become a generator that will keep yielding every pair that works until it has exhausted the search space. This outer loop: 

I'm working on several projects involving Telegram bots and I've decided to make a library that meets my needs. Basically, there is already a Python library for Telegram bots ( in my code), but I wanted to wrap it to make it even more convenient to me. In terms of functionality it works fine. But I'm a self-educated programmer, so I realize that my code often lacks consistency and readability. That's why I'm here, looking for advices on how to understand how to write the code efficiently. Any critique is welcome, regarding formatting, more efficient and fast code flow, or whatever; and here are the specific questions that concern me: 

I use PyCharm and it suggests me to make some methods in class static. For example, , , . As I understand, it is because they don't use anything from within the class, so they are instance-independent (I might be wrong). Is making them really beneficial? Maybe, memory usage is better? I can pass several functions to my main loop, specified in . Their roles are described in the code (I hope I wrote it fine). But sometimes I may not need, for example, . I thought about passing as a default parameter, but is not callable, so I pass an empty which does nothing. Maybe I can do it better somehow instead? There is a parameter which I want to remain constant. But I had an urge to put it into the class as a static variable. Is it an acceptable practice to use global variables from outside a class in the class? Errors happen, and my code handles them and prints them. But I need a way for it to print detailed data on an error. I mean, when I run a code in terminal and it encounters an error (outside ), it prints it in a very detailed manner, with a full tree of functions, files and line numbers leading to the error. I've been browsing the web and the best I could find was which I use, for example, in my . It is far from being detailed and does not lead me to where this error actually happened. Is there some way to recieve and print a detailed error log when it is caught and is triggered? Methods like , and (contained in are very simple, they just have some statements with one operation. I've seen people writing one-operation statements in a single line, like I did here. PyCharm doesn't like it at all and shows warnings. So I want to know, is it better in terms of code consistency and readability to write such statements on separate lines, or is it okay to leave them like this? I often see people use and in their classes. But I still can't understand how they determine whether a method should be public, private or "weakly-private" (I'm not sure what a single underscore does). Looking for recommendations in this affair as well. PyCharm formats docstrings automatically for me. As I understand, it is reST syntax. It's said to be widely used, but there are competitors? Should I stick to it or it is better to use some other docstring syntax? Since Python is not strict about types, I think I need to specify the types of arguments and return values. Should I write it plainly in and ? I tend to use with breaks, especially in functions that rely on connection to some external server, downloading/uploading functions, etc., but people often tell that using with breaks is a bad practice. If so, what can I replace them with? 

This functions returns the last position in which could be inserted in and still keep it sorted, which corresponds to one past the last occurrence of in haystack if it indeed is there. Not only is this approach often times faster than the three-way binary search approach, it also gives you much better defined returns if the has repeated entries: either the first or the last, not an undefined one. It is no surprise that Python's standard library's package implements and following these ideas. Note that writing this functions iteratively is extremely simple, and a much, much better option: 

While they stayed in the language, and are therefore fair game, reading Guido's 10 year old essay on how he planned to get rid of , , and for Python 3 will probably have you looking at those a little differently: I for one always try to come up with more Pythonic alternatives when tempted to use them. 

Since we do constant work per entry, and keep a constant number of values as state, this solution uses \$O(1)\$ space and takes \$O(n)\$ time. For completeness: 

avoid bare , it can mask bugs, and even cause some - eg, you might catch and ignore . instead. Consider adding a docstring to explicitly say that it tries two formats, as well as that it gives you a timezone-aware datetime. 

Going down, is a .. very strange name for a list. It seems to contain solutions, although you put two numbers in it each success, which seems odd; but I'll assume that that makes sense, and say call it . You don't need the number at all - the way you use it, it will always just be . The two statements could be combined, as in: 

Your problem essentially boils down to repeatedly finding the (global) maximum of some (local) values. Python for "the maximum of some values" is , and Python for "do this iteratively on this sequence of things" is a for loop (or, in this case, a list comprehension). You want the indexes of maxima, rather than the values, but takes a argument so you can do: 

There are cleverer ways of computing a quotient of factorials, but that is left as exercise. You also have to handle all the possible permutations with less than the full possible digits. There may be a better way of not having to brute-force your way through this, but I'm out of cleverness right now, so I am going to go with something very unsophisticated: 

In your case, you want to take into account extra contributions from multiples of the factor squared, cubed, etc... This is relatively straightforward to do also: 

Note that the last timing means ~30 ns per item retrieved, right where you wanted to be. If you need to extract the boolean values one at a time, you are going to have to deal with the painful Python overhead. Notice that simply getting a single item from an array is terribly slow: 

That was tricky... Actually, your blocks are pretty irrelevant, apart from getting the right slice of to do the with the corresponding , so I went the easy route of creating an array as follows: