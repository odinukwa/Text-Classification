I enabled SSL by following this guide: $URL$ except that I have the keys and cert in both gluster and glusterfs files as the guide seemed to use one at the beginning and the other one afterwards: 

How do you install SQL Server in a remote server where you don't have the option to put a CD or DVD on the machine (or have anybody do it for you)? That is, having the ISO image. I can think of installing a CD emulator, but most of the look like nasty software I wouldn't want on a server. 

But I'm not so sure how it should work. It doesn't seem to be working out of the box. Even though mounting of glusterfs volumes happens after the network starts, it happens before GlusterFS starts: 

The /dev/xconsole error happens even if I disable TLS and everything seems to be fine. Not sure if I should read anything into it. Maybe there's another log file to inspect that I'm missing? Searching I found this bug report: $URL$ From that, it seams that rsyslog tls is just broken on Ubuntu and that's the end of it. No workaround, no fixes coming, nothing. Am I reading it right? Is there any workaround or any other way to move forward? 

I'm setting up a freebsd router and want certain IPs on my network to be forwarded to our local webserver if they make port 80 requests. An example would be - banned user tries to surf the web, but all his requests are forwarded to the web page which notifies him that he is banned. As I understand I can use IPFW for this and maybe NATD. I would be grateful if someone could show me a good example on how to do it. 

This way all my outgoing traffic is departing ISP B (since it sends me more specific routes) and all my incoming traffic comes in from ISP A (it shows up as a better route on the internet). If one of the ISPs goes down, the internet will still be available through another ISP. 

I've configured some sites on IIS pointing to E:\WebApps and subfolders. In basic settings when I click the Test Settings... button (connection as the application user) I get the error: 

I have a web app running with nginx and I'd like to analyze the logs to get information about how many hits each file is getting, and which 404s and other errors we are generating (something Google Analytics can't provide). Normally I would just drop awstats in a server, but with nginx, due to the lack of cgi-bin, it's not trivial. Is there another trivial solution to get this information? I don't mind paying a third party to do this analysis for me. 

and I get logged in without being asked for a password because I already copied my public key. Due to forwarding, I should be able to ssh to pupeno@b1 from b1 and it should work, without asking me for a password, but it doesn't. It asks me for a password. What am I missing? This is the verbose output of the second ssh: 

I have a question about correct isc-dhcp configuration. I want to lease ip addresses to users based on switch port. For this I use DLink DES-3200 series switches. Everything works well, but recently I've decided to lease particular subnet to all unknown user, i.e. not explicitly specified in dhcpd.conf file. Here is a config example: # dhcpd.conf 

After reading man dhcpd.conf and playing around I've managed to achieve my goal by making the following ammendments to my dhcpd.networks file: 

So my question is, what is the best solution to make sure I keep the state of static NAT and stateful firewall rules (not ZBF) on both routers at the same time? Again, I want traffic to leave through ISP A and return through ISP B. Is it possible at all or do you think it would be better to purchase a pair of ASA 5500 series with Active/Active support and do NAT and inspection on them? 

and it did create /var/lib/bacula/bacula.sql, but when I run the job it gets deleted. Any ideas what's going on? The whole output looks like this: 

Is there any book you'd recommend to learn how to administrate a public-facing (IIS7, SQL Server 2008) Windows Server (2008 in this case)? I've searched for books in this matter and I've found "Windows Server 2008 Undercover", "Windows Server 2008 Unleashed", etc, which from the table of contents seems to be centered around the Windows server in a local network that is working as the PDC, or Active Directory server, or serving files, or some other tasks for local clients. The last of which I don't have any. I haven't used Windows in ages (not even in the client), so even basic things are puzzling for me at the moment. 

and the rest being the stock Ubuntu configuration I start to get the wrong results. When I see the main page it's fine, but when I go to a specific post I get a RSS feed instead. Like if the cache is returning the wrong content. I've disabled my RewriteRules as it seems mod_cache doesn't work with that. I'm not even sure where to start to debug such a thing. Any ideas? 

I am new to powershell, but I've been reading manuals and practiced a little bit. My objective is to List all users in all Security Groups under specified path. I have found the way to do it: 

Is there a way to make a global alias in Sendmail so it would send email to all users? I tried to create an alias and included the list of all my users, but when I try to process it by m4, I receive an error that the line is too long. 

Here I supply the list of IP addresses that are all alive, as you can see in previous command, but only 2 hosts out of 8 show up as alive. Can anyone explain this behavior of nmap and maybe tell the work around ? I want to use nmap in the shell script to quickly determine alive hosts. Previously I used 'fping -a' command, but nmap seems to be better at discovering hosts behind the firewall, so I would like to switch to it without modifying my script too much. Any help will be appreciated. 

I created a bunch of upstart jobs for my services that I'm running on an Ubuntu 12.04. I can successfully start them and stop with with: 

I've checked that my IIS is running as NETWORK SERVICE so I've given read, read and execute and list folders contents access to not only E:\WebApps but also to E:. But I still get the error. This machine is not part of a domain. Any ideas what am I missing? I've tried putting a web.config in E:\WebApps, and restarting IIS and the site in particular, but it made no difference. 

Also, there's no reason to have separate files. I have one file pupeno.com.conf which includes the definition for non-ssl and ssl pupeno.com virtual hosts. Think about what you want to enable and disable in one go with a2ensite and a2dissite. I consider $URL$ and $URL$ the same thing thus it's on pupeno.com.conf. 

at the end of dhcpd.networks file (which I include into shared-network 'clients' clause, see above), all my clients start getting ip addresses from 172.20.111.0 range, regardless if they have a class specified for their port. Is there a way to make dhcpd server first look at class declarations and then subnet ? 

We have 2 upstreams ISP A and ISP B. ISP A (10Mb/s) is our main upstream with good bandwidth. It sends us default route over bgp. ISP B (2Mb/s) is our backup upstream with a small bandwidth, but it sends us Full Routing Table. I am new to BGP so I'm looking for a way to make sure that most of the inbound and outbound traffic would use ISP A and fail-over to ISP B. What are the best ways to do it? 

At my company we have a single Cisco 3925sec/k9 router running BGP with 2 ISPs. Now we want to purchase a redundant router of the same model to eliminate a single point of failure. I can set up BGP between routers and ISPs no problems. We plan to send out all traffic through ISP A and receive all traffic through ISP B (ISPs send us only default gateways and we can play around with as-prepends and local_pref attributes for that). 

but when cron runs, it somehow tries to connect to the public IPs of the machine, which fails, because they are not bound by postfix: 

Using Ubuntu 12.04 or 14.04, how can I prevent an upstart service from starting until a couple of network volumes (GlusterFS) get successfully mounted? 

I have around between 3 and 8 upstart jobs in various Ubuntu boxes that I wish to easily start, stop or restart all together. It seems that upstart would make it easy to do that, but I'm not sure how. Should I use dependencies to make a single dummy job that depends on all the others? One of my requirements is that I wish to still be able to stop some without them restarting because others are started. How should I go about doing this? 

Rails and Django are development frameworks, to be able to serve requests from a web browser, they need a web server that will execute the code. I'm not sure about Node.js, but I would expect they are similar. Rails and Django are not web servers by themselves, but they use a small web server during development to makes things easier. That's how you can run, for example: