is the standard place to install third party applications and libraries but you can use any path away from the system paths. 

You can point as many DNS A records to an IP address as you want. In addition, nginx can be configured to listen on different ports, but it will also handle virtual hosts for HTTP so can listen for for different DNS hostnames on the same port. 

Also to listen over ssl you would need to enable ssl and have certificates installed or you will get a protocol error. You would at least need: 

User crontabs are stored in and you can write to the user file as long as you format it correctly - is really just a wrapper around a text editor to ensure that the file parses correctly and is in the right place. 

It is becoming increasingly difficult to establish and maintain reputation for standalone mail servers when dealing with the large mail providers. Among the things you have to consider are whether your server, or IP address or indeed netblock are on RBLs, which can be a legacy issue from previous users of the address. Also ensure that your configuration matches your IP address, particularly that your HELO address resolves to the sending IP address. Zimbra itself can be hard to debug for inbound mail so turn on logging in the setup stage. 

Two things come to mind: Can your lsyncd process read the exclude file? You should be able to see this in the status log. Also, have no blank lines in the exclude file as that gets interpreted as 'exclude all'. 

The PERC boards have a battery that often fails, usually after about five years of use, and this can cause the effect you are seeing. This can also happen if your disks are mismatched for a number of reasons. You should be able to install and use the Dell diagnostic tools (, etc) and MegaCLI to detect any issues. The PERC will also probably warn in and certainly will show problems in POST on boot. I would also strongly recommend a backup as soon as possible as there is the potential for loss of data. You are correct about importing foreign configs and this may fix the issue but it can also wipe the array depending on the state of the system. I inherited a couple of hundred Poweredge machines and this is a regular problem. 

Broadly speaking you would configure the Huawei routers to be gateways on each VLAN and send routed traffic to them, but with the information you have given that is about as much as I can tell you. 

Use on the directory. However you are actually hitting a limit of the file system and this can cause performance issues with your storage. The common solution is to partition your namespace in a more structured way, or, depending on what your requirements are, a more flexible filesystem such as xfs, zfs or btrfs. 

might work. I can't guarantee this as I can't test it at the moment but it's the general route for working with variables at a low level. Updated: nginx needs to know about its backends at startup, so you define them in your upstream directive: 

The most common provisioning tool is Cobbler, which extends Kickstart in combination with PXE boot and yum repositories, either public or private. It is also often used in combination with a configuration management tool such as puppet or Ansible. 

The 403 error in the page is coming from a web beacon at Vimeo and the error indicates that it doesn't have permission to post to the service. I would guess that the beacon is linked to the video on the page. 

Such strings can often be exploit tests but if they are coming from legitimate sources, by which I assume they are addresses that are known to you, they could be some kind of port check or a keepalive process from an application - would that make sense in this context? 

You would also need a URL redirect record for www.imgshare.org as that's actually a different process from the DNS lookup. I'm guessing you also would also need to remove the CNAME for parkingpage.namecheap.com. However, you should also configure your actual server correctly rather than relying on Namecheap. 

which would suggest that it's getting held within the outlook.com network, so you may be better off ticketing Microsoft about it. A delay of 21 hours (give or take) doesn't have a significance that I'm aware of. 

There are a couple of ways of doing this, either serve requests to the application using the connector, or by configuring apache as a reverse proxy with and sending requests to the tomcat web server. Both will work as a subdomain or as a Directory or Alias directive, so set up will be along these lines: This is a simple configuration for mod_jk (from $URL$ 

From the point of view of nginx you can add a rule to manage the in-memory lifespan of static files alongside in-browser caching with something like this: 

SLEEPing connections are connections for which complete data hasn't yet been received. They are often used for applications to improve the speed of queries so depending on the application may be being caused by that but in the context of replication it's likely to be because you have a lag in processing, which could be due to large amounts of data being replicated or complex queries being processed. If you have a slow or sporadic connection then that will be the issue and really it's MySQL doing its job properly. 

It would be better to use a link balancer as a gateway. There are many types and a common open source solution would be to use pfSense with x86 hardware - pfSense even sell appliances that run this. Cisco iOS doesn't have good multiWAN capability in low end devices. 

You have a lot of conflicting configuration here. I would suggest creating a for and and another for and/or *.cms.domain.com with the . There is also precedence in so domain.com should be last. The easiest way out of the common config issue is to symlink to each directory and then you at least have consistency. 

This is actually a software issue, not or , and if you are running the same software in two processes then it wouldn't be impossible to cause collisions. A quick look at the documentation suggests that while there is collision detection for a single application, two separate processes in different userspaces wouldn't do this. The simplest fix would be to configure differently for each pool. 

The headers are either going to be sent from apache if you have configured specific values for file types or from your backend either in code or from the backend HTTP server. Those cache control headers would appear to be defaults, which would suggest nothing is being explicitly set. What is delivering the content? I have to admit I had to look up mod_cache_socache but it wouldn't appear to set headers at all. Having a look at 'willingness', documentation suggests that it may be related to your backend not providing modification dates or hashes or other indicators of freshness. Also don't get confused with the front end headers and the cache content. Without knowing much more my guess would be that you need a bit of granularity in your caching rules and in your front end header rules. 

Look at . This should do what you need, possibly with a bit of scripting. A more advanced option would be something like Splunk or graylog. 

No, you are in control of what is sent from your server. Gmail's limitations are part of its service to prevent abuse. However, what you may find is that receiving servers (particularly Gmail) may limit your inbound mail if you are abusing it in any way. 

should do it. There are also header control extensions for django that can do the same thing. Cloudflare should honour these headers without any changes. 

Firstly check the python application as it could be out of date and is probably misreading the version. CentOS shows the base version as installed and is patched to keep up with changes and it could just be a case of fixing the version that is being looked for in the code as a quick fix, but if the application is being actively developed you need to let the developers know or fork it for yourself if you can. An up to date on CentOS 7 should be If it's absolutely necessary to run this application, the official RHEL approach would be to containerise, but you would still need to provide a working glibc, which wouldn't be possible with stock CentOS 7. If this isn't viable, and as an absolute last resort, it is possible to install a newer version of than 2.18 as that is five years old now and has been updated for several vulnerabilities and I'm not sure off the top of my head if it will build with the version of in CentOS 7, but any newer version should work as follows: ++++ This can potentially affect the functionality of your computer so make sure you know what you are doing ++++ You can build the version of you require elsewhere on your server and add it to for the application. Note this must only be done for the application only. 

You can't resolve a URL such as with DNS or hosts, just the left hand side separated by the forward slash. All you can really do is configure a virtual host on your staging server to point at your project folder and use hosts or a local DNS server to resolve the domain. 

Your DNS hasn't been updated correctly. Use something like IntoDNS to analyse how your domains are resolving and any problems arising from this. 

The process is documented by AWS here. In short, you would have to convert your image into a virtual machine disk and upload it to AWS using the command line tools. 

I believe (but I can't really prove it) that this is an issue with upstream routing in some providers. I manage a large number of machines using apf, many of which are at one particular provider, and these machines have no problems. Other similarly configured machines at other providers have done in the past, and we never managed to find a cause on the servers apart from restarting iptables fixing the issue. It was always HTTPS on port 443 and never HTTP, so I think it must be either in an upstream firewall or router and is affected by a firewall being reloaded, which would suggest something to do with arp or other mechanisms at that level. 

Place a stanza after the general configuration and it will be more likely to work - the configuration is read from top to bottom so any settings in your virtual host configurations would overwrite the settings as shown there. Also, you can test your configuration with which is helpful in showing where errors are. 

In the standard and design checks for the existence of a file and then sends the file path to over a TCP/IP or unix socket for execution so needs to be able to see the file - is the file server whether the file is a static html file or a script, and is the processor in this case. 

Did you add the Comodo CA bundle to your certificate? You should have received it or a link to it with the certificate. It needs to be added to the certificate file after the site certificate to work with nginx. To test your certificate, use the Qualys SSL Test. 

BIND's logging is usually good by default although you don't mention what OS you are using but it does normally show any configuration errors. A common issue is that it's configured to listen on localhost, which I think is the default so you may need it to listen on an interface. You can test from your desktop with nslookup in a cmd window with which should show if your server is responding at all. You could also use a forwarding DNS server instead so you would need to configure forwarders in your BIND configuration. This guide may help. 

You can't give an address priority but you can disable the entry in . Presumably your server handles mail for your domain using as well as with virtual maps. The convention is to allow the virtual mapping to handle addresses found in in this case. To remove an entry from comment it out and run 

usually connects to the process on the server on port 5666 or using on port 2098, so you would need to open whichever port you are using in your AWS security groups. If you can only allow access from your home IP that would improve security a little. Also check that is listening on or the internal IP of the instance rather that . 

Assuming that your phtml files are PHP, they would need to be interpreted by php-fpm as with your php files so this should work: 

SSL certificates are not assigned by IP address but by name, and nginx has supported SNI for a long time so you can have as many SSL certificates per IP address as you want as long as you issue them for names that resolve to the IP address. Create a virtual server per IP address: 

You can check the reputation of your IP address at Barracuda Central as you've probably found, and the point is that it may not be a bad email that is causing the problem but the reputation of the IP address, the netblock, or indeed the provider. Barracuda used to be something of a black hole so that they are actually now providing a service, albeit a paid one, is actually an advance. 

Send to tell receiving browsers to release a cache entry. This has to be sent for every object in the cache so is probably better done with a script. 

is the number of number of server processes you start with, and is the number of threads per process. The Webfaction settings should be reasonable in most situations although a thousand requests a minute may need some tuning, but probably mostly in the application. In normal use would take a request, pass it to and wait for its return, which should be near instantaneous, so what is actually taking its time is whatever the python script is doing. Your worker threads are therefore in a wait state and will build up as requests come in while other requests are being processed, so even a static page will end up waiting if your threads are occupied. Look at what the application is doing and for solutions. You may be able to cache queries using or similar. If the time that your application takes to process a request is unavoidable, look at making it asynchronous using a message queue like Celery, so rather than having your web server wait for responses, you can poll for them using browser side scripting. Splitting the static page serving from the dynamic will also improve the response. If possible you could run multiple sets of workers, or pass static page and object serving to , which is a more common way of handling . Another method would be to serve python through a native web server such as or and use apache as a reverse proxy, which may improve the backend response although still won't help if processes are causing large numbers of waiting threads. 

You need to specify a for as effectively matches anything and I assume sitebuilder actually handles the hostname response. 

MQTT needs the stream protocol so you need to separate your HTTPS and stream configurations. Something like this should do it: 

If you look at $URL$ you will see that the nameservers are not responding for the domain so it needs to be dealt with by the hosting provider: 

Nginx also provides and weighted connections (there is also for session persistence) so your backends can be configured like this: 

proxy_pass is probably the better way to do this as you are presumably updating links and moving images to the new server. A redirect should also return a status response of some kind which could cause problems for search.