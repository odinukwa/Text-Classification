Here's a SQL Fiddle demo* link for this query: $URL$ UPDATE To return only one set, you could add in one more round of ranking: 

That is, a gap is considered as intersecting the contract period when its end either comes after or exactly matches the contract beginning while at the same time the gap's beginning either comes before or exactly matches the contract's end. As I have already said, the first and the last matching gap may go partly outside the contract period, i.e. like this: 

defines the column as a timestamp with nanosecond precision (9 digits after the decimal point). (As you have SQL Server background, you can compare this to the SQL Server type, which also has optional precision.) For reference, see IBM Knowledge Center - Datetime values. It looks likely that the column in question is defined differently between the development environment and production, the development definition being (no fractional seconds) and the production definition (or simply , which means the same). That explains why your developer never has to specify fractions of a second in the development environment – because the column's values cannot possibly have fractional seconds. At the same time, she may have to specify timestamps with a fractional part in the production environment because the column type there allows fractions of a second in the values and some timestamps apparently do have fractional parts. 

Using the above query as a derived table, you can filter the output further on and get the difference total: 

The easiest fix is to remove all the branches that check for equality to 0, because they are just superfluous: 

How it works By adding the container type column and making it participate in the foreign key constraints, you prepare a mechanism preventing the container type from changing. Changing the type in the type would be possible only if the foreign keys were defined with the clause, which they are not supposed to be in this implementation. Even if they were deferrable, changing the type would still be impossible because of the check constraint on the other side of the —junction table relationship. Each junction table allows only one specific container type. That not only prevents existing references from changing the type but also prevents addition of wrong type references. That is, if you have a container of type 2 (animals), you can only add items to it using the table where type 2 is allowed, which is , and would be unable to add rows referencing it to, say, , which accepts only type 3 containers. Finally, your own decision to have different tables for , , and , and different junction tables for each entity type, already makes it impossible for a container to have items of more than one type. So, all these factors combined ensure, in a purely declarative way, that all your containers will be homogeneous. 

This is not an attempt at a different implementation of the same logic. This is merely an attempt at simplifying (and, hopefully, speeding up) the existing query. What I have noticed is that the two correlated subqueries that are being compared have just one difference. The second subquery has an extra condition in its clause, namely this one: 

You are right in thinking that items of a list should be stored as individual values of a column, i.e. in separate rows of that column, rather than as a single value (CSV string or anything like that) – at least if you expect to have queries against individual items of the list. Relational databases are designed to work that way, and storing multiple values of a column as a list (single value) is a no-no in such cases. Regarding your data sample of fruits and vegetables, I am assuming that you are not thinking of splitting two lists of values exactly like that, storing each list's elements alongside each other on the same row without there actually being a relationship between them, just for the sake of normalisation of the way the vegetables and fruits are stored. That would be wrong. I mean, if currently you have a row with a list of fruits and a list of vegetables such that each fruit and each vegetable are related to this particular row, i.e. like this: 

That way the names will always be predictable and, when comparing the schemas, you will not run into this issue again. The same applies to all types of constraints in SQL Server (defaults, primary keys, foreign keys, check constraints). 

You can see that each product is listed only once. Joining that table to the other two will not produce duplicates. Therefore, just substitute the above query, as a derived table, for the in your query (also removing your GROUP BY from it, of course): 

The double apostrophes surrounding the items turn into single apostrophes when the entire statement is parsed. Assuming the linked server is configured properly and is a valid dataset name on the remote side, that should get you going. Things become much trickier, though, if the list must necessarily come from a variable (or parameter). The problem is, there is no easy way to parametrise an OPENQUERY's nested query. In particular, none of these methods will work: 

Note: the above assumes that both feg.sort_order and eat.ID are either declared as PKs or have a UNIQUE constraint defined on them. Otherwise they cannot be referenced. You can still store references without a formally defined relationship between tables, but you cannot have guaranteed data integrity that way, so I recommend you make sure you can declare the new columns as foreign keys. The next step would be to populate the new columns from the current ea.Element_Answer one. That can be done in one go with an UPDATE statement like this: 

There appear to be two key issues here. One is finding a way to match an 'out' quantity with all relevant 'in' quantities. In your case, row 5 needs to be matched with rows 1 and 3 because it uses both rows' quantities, as follows from the order of ins and outs. You could try using a method like this. Take the two subsets of the table, ins and outs, and calculate two running totals for each, one including the current value (call it ) and the other excluding it (i.e. the running total of all preceding values). Let us call the former and the latter . You will get these results for each subset: 

As ypercubeᵀᴹ explained, you cannot return a boolean expression in a THEN clause. Using OR as an alternative to CASE is one way to rewrite your condition. However, since in the end the chosen column is being checked using the same condition, you can still have a CASE here, but the CASE needs to return either or only, and the condition will then be applied to the result of the CASE rather than inside the CASE: 

MS Access does not support CASE expressions. The most generic equivalent would be the Switch function. Using that function, a SQL CASE expression like this 

As has already been mentioned more than once, you cannot expect rows to be in a certain order without specifying that order explicitly using the ORDER BY clause. For the problem described in your question, you actually do not need a UNION at all. Use only the LIKE condition to cover both full and partial matches: 

Next, join the aggregated result set back to the original table on and on (separately) to access the corresponding s: 

Your data sample seems to suggest that the two columns are the only columns that can change in each group of duplicates. In other words, duplicates are determined by columns . One other assumption that your data sample prompts is that a row with a greater corresponds to a row with a greater as well. (In fact, the two columns always have the same value in your example.) Finally, for the purpose of this answer, I am also going to assume that when you are saying "first" or "last" (row in the rectangle), you are talking about the earliest or latest datetime value. With those out of the way, you can generate the desired result set from your table if you just group the rows by the columns listed above and take for and for – that is, like this: 

In your particular situation, the CASE expression does not have an ELSE clause. That means that is implied, although may be more appropriate here. So, you can rewrite the query like this: 

The problem is that you are using conditions as expressions in your second query, i.e. inside a CASE expression after and after . Boolean/logical expressions cannot be used like that in Transact-SQL. You can only use them as conditions in contexts where conditions are expected. In a Searched CASE expression, for instance, a condition can only go after the keyword. The resolution of the issue you are facing depends on whether each of the two columns needs to be compared to the same value or to a different one. If it is the same value, then you can move the part outside your CASE expression: 

So, in your case QUOTED_IDENTIFIER gets reset at parse time and is, therefore, OFF by the time CREATE INDEX is executed. The engine complains about it as expected. To resolve this, you don't have to resort to dynamic SQL, it is enough to put a line just after the CREATE INDEX statement to make it a different batch from the subsequent SETs, which would cause it to be parsed separately from them: