Short Version Suppose that you want to consider a model of quantum computation in which the gates used in the circuits may depend on the input size. Are there pitfalls to avoid when defining the circuits, to avoid obtaining unreasonable computational power from combining the coefficients themselves? Conversely: what limitations (aside from the conservative one of having a gate set of size $O(1)$ for the entire circuit family) yield a model whose complexity is still reasonable, and in particular does not disrupt too many of the things which we know hold for gate-sets of size $O(1)$? Motivation and Details The class $\def\EQP{\mathsf{EQP}}\EQP$ is the set of languages which can be decided with certainty by a polynomial-size uniform circuit family. Except — because of the fact that there is no exactly universal gate-set for quantum computation, the gates allowed may change from problem to problem. And it would seem that people remain unsure of whether to allow infinite gate-sets, so that the gates which are used in each circuit for a problem may depend on the input size. It seems reasonable to me, in principle, to allow a unitary circuit family to use an infinite gate-set: for instance, a set in which the different gates used by the circuit on inputs of length $n$, grow as $O(n)$ rather than the scenario of $O(1)$ which is possible with (approximately) universal gate-sets. Gate-sets which scale as $O(n)$ are part of classical circuit complexity, after all. Furthermore, it's not clear to me that it should be necessary to allow a gate set of size larger than $O(n^2)$ — which would allow for a constant number of gate-sets having arity ranging from constant to the entire system. For many purposes, it may even be enough to have a gate-set of size $O(1)$ for each circuit size, but a different such set for each $n$ — so that one may describe the gate set used by the family as being $O(n)$ for the first $n$ circuit sizes. However, allowing even a single distinct gate for each input size allows you to do strange things, even if you require that the coefficients of the gates be nicely behaved. For instance, you could allow as a gate a controlled-QFT gate $\Lambda\mathrm{QFT}$, acting on $2n$ qubits, which is defined on $\def\ket#1{|#1\rangle}\ket{m}\ket{x}$ for $m,x \in \{0,1\}^n$ by $$\begin{aligned} \Lambda\mathrm{QFT} \ket{m}\ket{x} &= \ket{m} \otimes \mathrm{QFT}_m\ket{x} \\[1ex]&= \begin{cases} \tfrac{1}{\sqrt m} \sum\limits_{k=0}^{m-1} \mathrm{e}^{2\pi i kx/m} \ket{m}\ket{k}, & \text{if $0 \leqslant x < m$}; \\[2ex] \qquad\ket{m}\ket{x}, &\text{otherwise}.\end{cases} \end{aligned}$$ This effectively allows you to simulate gates which not only depend on the input size, but on the input itself. In addition to being strange in itself, and making it potentially difficult to obtain a meaningful notion of complexity (how much work is being absorbed into the machine which describes the gates?), it would undo classic results in quantum computational complexity such as $\mathsf{EQP \subseteq LWPP}$ [Fortnow+Rogers-1999]. Admittedly, that result relies on a definition of $\EQP$ in terms of quantum Turing machines rather than circuits, so inherently depends on the gate-set of a circuit being finite; it would not be shocking to negate it, but negating it is a warning sign that we may be doing something unreasonable. It would still be nice to find a way to keep it intact. There is a potentially more awkward problem, however, which I am less well-equipped to consider myself. If we study $\EQP$ out of interest in theory of computation (as opposed to practical application, where $\mathsf{BQP}$ will be more relevant for the foreseeable future), it doesn't make sense to consider coefficients which are themselves only computable to finite precision. Instead we should probably consider coefficients which are expressed symbolically as algebraic numbers: that is, where each individual gate has coefficients drawn from some finite extension of $\mathbb Q$. This picture of quantum computation is preicsely what the classic results $\mathsf{BQP \subseteq PP}$, $\mathsf{EQP \subseteq LWPP}$, and $\mathsf{NQP = coC_=P}$ rely on, so I'm quite comfortable allowing the coefficients be specified abstractly and "symbolically", so that the only precision involved is the length of the representation of a polynomial of which a given coefficient is a root, or something similar. The problem is this: completely aside from whether or not you can hide non-trivial polynomial amounts of computation in the computation of the coefficients, I worry that the linear combinations of these algebraic coefficients, arising from the matrix multiplication itself, might itself hide non-trivial amounts of work by simulating a Blum-Shub-Smale machine. I'm not very familiar with the issues involved in that, so I wonder whether allowing infinite gate-sets might be a bit of a minefield. Question #1. What theoretical problems (as opposed to practical problems, i.e. let us not concern ourselves any more with experimental implementation than we would with the polynomial hierarchy) does one have to worry about — for bounded error as well as for exact quantum computation — if one considers infinite gate-sets allowing the simulation of complicated arithmetic over the reals? Question #2. What are the sufficient conditions for an infinite gate set to be "benign", from a standpoint of computational complexity? 

How badly do things go wrong if there is a single eigenvalue crossing with the ground state — where there can be any number of crossings between other energy eigenvalues, but which are well-separated from the crossing of the ground state with the first excited state? Does the answer to the above question depend crucially on details of the physical system involved? Are there special cases for which the "error" is known to be bounded by constants (i.e. the state still has a substantial overlap with the ground state after the level crossing, though the overlap may be bounded away from 1)? Are there special cases for which the overlap with the ground state, after the crossing, is almost certainly going to be nearly zero? Are there systems for which the question of whether the system is in the "bounded error" regime or the "unbounded error" regime will depend very sensitively on certain factors? 

Preamble. The complexity class AM are those problems which can be solved by a two-round interactive proof system between a prover "Merlin" and a verifier "Arthur". A problem — which tests some property of an object X — is in AM if: 

which is derived from lecture notes on computational complexity and related topics. On page 187 ("Supplementary Lecture G: Toda's Theorem"), he defines the operators 

(Because these are multi-sets, they're actually multi-hyper-graphs. We may consider the edges to have some generic labels to distinguish them.) We may consider the dual hypergraph $H$ in which the vertices and the edges are interchanged; that is, where 

Again, it is not clear to me whether substituting the base sets with arbitrary subspaces of $\mathcal H_2^{\otimes n}$ gives rise to a more interesting problem than just using the subspaces $\mathcal E_j$; though if we restrict ourselves to the case of CNF formulae (either in the commuting or the non-commuting case), the results we obtain would correspond to some notion of complexity of a frustration-free Hamiltonian whose ground-state manifold consisted of standard basis states representing cliques. 

In particular, we impose no particular structure on the circuits $C$ (aside from being binary trees), do not allow fan-out (so that each bit of $x$ is used only once), and the gates may be asymmetric. By allowing only two-bit gates, I exclude the NOT gate (but which may be simulated by having multiple gates which are related to each other by negations, such as AND/NAND; and I also exclude gates that simply output constants with no inputs, so that the number of gates in the circuit will in fact always be $n-1$ for an $n$-bit input. For the sake of brevity, I will refer to 2-TREE-OPSAT below simply as OPSAT; though analysis of the problem may become much more difficult for circuits allowing arbitrary k-input gates (k-TREE-OPSAT) or allowing fan-out (which we might call k-FANOUT-OPSAT). [Edited to add: we can easily adapt this to consider the more general problem of the current revision of your question, in which we attempt to map a given $x \in \{0,1\}^\ast$ to a target value $b \in \{0,1\}$, by interchanging the roles of $0$ and $1$ in the analysis below; this has the effect of interchanging the roles of AND and OR, NAND and NOR, etc.] $\def\et{\wedge}\def\ou{\vee}\def\AND{\mathop{\text{AND}}}\def\NAND{\mathop{\text{NAND}}}\def\OR{\mathop{\text{OR}}}\def\NOR{\mathop{\text{NOR}}}\def\EQUAL{\mathop{\text{EQUAL}}}\def\PARITY{\mathop{\text{PARITY}}}$ For a fixed choice of $x \in \{0,1\}^n$, the problem of choosing a suitable tree with suitable gates is not unlike a logical disjunction: using equivalences such as $$ \OR(x,y) \;\equiv\;\Bigl(\AND(x,y) \;\ou\; \PARITY(x,y)\Bigr) $$ we may perform reductions between collections relating more complicated gate sets to simple (and powerful) gate sets; a may speak of one gate set being able to emulate other gates not belonging to the set, by wisely choosing some element of $\mathcal G$ which has the same effect (when presented with a particular input) as a gate $G \notin \mathcal G$. In particular, certain combinations of gates (such as $\{ \OR, \NAND \}$) can simulate the constant function yielding $1$: we say that such gate-sets are tautologous. We proceed by considering gate sets including different types of gates $G$, later excluding those gates from later cases of the analysis, to show that gate-sets involving any single one of the gates leads to a tractible problem. We will proceed in the order of the number of two-bit strings which satisfy the gate in question, starting from the constant $1$ gate to the constant $0$ gate. 

If you have very few cycles, here's an algorithm which will use less space, but take substantially longer to terminate. [Edit.] My previous run-time analysis missed the crucial cost of determining whether the nodes we visit are among those previously sampled; this answer has been somewhat revised to correct this. We again iterate through all of the elements of S. As we explore orbits of the elements s ∈ S, we sample from the nodes that we've visited, in order to be able to check if we come across them again. We also maintain a list of samples from of 'components' — unions of orbits which terminate in a common cycle (and which are therefore equinumerous to cycles) — that have previously been visited. Initialize an empty list of components, . Each component is represented by a collection of samples from that component; we also maintain a search tree which stores all those elements which have been selected as samples for some component or other. Let G be a sequence of integers up to n, for which membership is efficiently determinable by computing some boolean predicate; for example, powers of 2 or perfect pth powers for some integer p. For each s ∈ S, do the following: 

which in any case is (or was) widely referenced in the literature. Unfortunately, I can't seem to locate a copy of it (physically embodied or otherwise) that does not require an investment of about $50, and a couple of weeks for shipping and handling, for the entire textbook. Can anyone provide an alternative reference, or possibly show me where to find an inexpensive electronic copy of the one book chapter? I would be satisfied with any widely available standard text on abstract algebra which proved this proposition, for example. 

Put simply: what is the correspondance between Turing machines with oracles, and uniform circuit families with oracles? How are the latter defined in order to obtain the same computational model, for a given oracle Turing machine? This may be an elementary question, but it is not obvious where to look, and I'm the sort of person who likes to make sure that my foundations are using good-quality mortar. If there is a standard reference, please point me to it. (Papadimitriou's book, for instance, does not seem to describe circuits with oracles at all.) My working hypothesis is this: a uniform circuit family with access to an oracle (e.g. for solving an NP-complete problem) is defined as follows: 

then for any error parameter δ>0, evolving the system under the Hamiltonian H(t/T), from time t = 0 to time t = T, suffices to ensure that the final state of the system is within δ (in the Euclidean norm) of the E(1)-eigenstate of the Hamiltonian H1, provided that $$ T \geqslant \frac{10^5 \| H' \|}{\delta^2 \lambda^3} \,\max \Bigl\{ \tfrac{1}{\lambda}\!\| H' \|^2\,,\; \| H'' \| \Bigr\} \;. $$ In particular, the smaller the desired error — and the smaller the guaranteed eigenvalue gap λ about the energy eigenvalue — the larger T must be and therefore the longer the evolution must take for this Theorem to guarantee an error less than δ. By slowing the rate of evolution of the Hamiltonian in regimes where the eigenvalue gap is small, and increasing the rate where the eigenvalue gap is large, we can try to optimize the evolution of the Hamiltonian in order to achieve a minimum evolution time for any given error precision. The usual notion of adiabatic evolution follows for the case that E(s) is the ground energy for the Hamiltonians H(s). Level Crossings. A non-negotiable feature of the Hamiltonian evolution, if we are to apply an adiabatic theorem, is that there exist an eigenvalue gap. I suppose that if the final Hamiltonian is degenerate because some number of excited states converge upon the ground-state energy — but that there is a gap between these cold convergent energy eigenvalues and the warm non-convergent eigenvalues — then things will still be okay; the cold-but-not-ground energies might become populated, but as these states converge to the ground-state manifold of the final Hamiltonian anyhow, nothing is lost. However, if there is a level crossing — where the ground state's energy intersects the first excited state's energy at one time t, and separate again — then the adiabatic theorems say nothing. In the context of Adiabatic Quantum Computation, everything that I have heard is in the regime where one assumes (or strives to ensure) that there are no level crossings, and one tries to make the eigenvalue gap as large as possible wherever possible. This corresponds naturally to a model of computation with very tightly bounded error. However, if one is content to repeat the computation several times, then constant error suffices; and so if at a level crossing half of the amplitude leaks into the first excited energy state, with the remainder remaining in the ground state manifold of the Hamiltonians H(s), this is no terrible loss. Of course, the question is then: what actually does happen to the amplitude of the ground-state manifold at a level crossing? How much does it depend on the particular system or the details of the evolution of the Hamiltonian? Can the responses be applied to the regime where there is always a gap, but it is inconveniently small? 

— The class described doesn't change if we require Merlin to give a useful answer not just with high probability, but for any challenge that Arthur may issue; we might say in this case that we require Merlin's answer always to be valid for YES instances, and what Arthur tests is the validity of the answer. So if Merlin ever produces an invalid response, Arthur knows that the problem instance is a NO instance. This is the setting I'd prefer to consider. An example is Graph Non-Isomorphism: given graphs G and H with the same set of vertex labels, Arthur can randomly select one of the graphs and produce a "scrambled" version F by permuting its vertex labels, sending a presentation of it to Merlin. If the two graphs are non-isomorphic, Merlin can identify which of G or H Arthur chose by determining whether F ≅ G or F ≅ H, and can respond by identifying which of the two F is isomorphic to. If the two graphs G and H are isomorphic, however, Merlin cannot distinguish which graph F came from, and any answer he gives can only be correct by chance. Thus, for YES instances Merlin can always send a valid response to any challenge; for NO instances any response which Merlin might send will be with high probability invalid. In the above problem, not only does there exist a valid response that Merlin can issue to Arthur for each challenge, but in fact there is a unique valid response: i.e. indicate which of G or H Arthur chose, given that this can be determined by identifying which is isomorphic to F. Question. Does imposing a constraint along these lines — that for YES instances, for any challenge Arthur might send, there is exactly one valid response for Merlin — yield a more restrictive class, in the sense of yielding a class which is not known to equal AM?