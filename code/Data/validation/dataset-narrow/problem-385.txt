I am configuring a 10g Express database on Windows 2003 that will be the back end for a public web server. There are many other things to do to harden the database but a good place to start is user privileges. I know the user needs Connect and Create Session privileges. All the tables, procedures and packages are owned by them. Are there any other privileges required for basic CRUD operations on their own schema? 

you need a package to read a long column. Sadly Oracle continues to use this datatype but does not recommend anyone else use it. 

As Goliardico points out you have to have the same tablespaces and users but the users cannot have any objects with the same name as objects to be imported. The caution about empty tables is also applicable and a real gotcha if you don't notice. 

I've seen it done both ways. If you want to bulk up your database size just start using BLOBS. Pro's for storing documents in your database 

You should look up the CASE construct. Adrian's article is quite helpful. The Oracle documentation is here. With the kind of query you want to do I can't help but think there are some omissions in the database schema.. Surely you can add some constraints on obj_C and obj_D so that null is not allowed? This would simplify things. 

The application I maintain does something similar that is database OS independent for around 100 users but in a much simpler fashion. Users are authenticated by the application and authorized from the database. Here are the details: 

Here is a script I have used on Oracle 9i and 11g that grants more than I've ever needed. Further pruning of the permissions on a production system would be a good exercise in security. Edit @ miracle173 asks what is the difference between the script below and just granting DBA privilege? The most important difference is that by granting individual privileges you can remove what is unnecessary. If you grant a DBA role then you cannot pick and choose unless you edit the role which is not advisable. The requirements change from when you are developing a database where you could need everything to a database that has been deployed to production where you want to have the least privileges necessary. Best practice is exactly what Leigh Riffel answered: do what you need to do with the least privileges. Edit @miracle173 correctly points out that SYSTEM tablespace is not recommended for a user. I have changed it to USERS in the script and on my primary development database. Edit @miracle173 also makes some good points on the distinction in privileges between a DBA who maintains and a developer. I do DBA and application development for the databases I work on so you could break down the script according to what you are doing. Practices and standards vary by industry, organization and habit so what you need to work with can change from instance to instance. It's common in my shop for the development database to have more privileges for admins and developers than production. 

How could I save the user input in the query as text? The problem is the dynamic substitution. If the user entered 1 for casestatus_in and 390 for userid_in I would like to save the query with the substituted variable for reuse later : 

Or when using the sqlplus interface EXEC DISABLE_TRIGGERS; I have to hope that this is not production code as a procedure that disables all the triggers could have many consequences. This code as originally posted should be more comprehensive if used in production, particularly for a migration. Triggers do things, whether you agree with their use or not, they can enforce business logic and stitch together poorly implemented business logic. 

This brings me to the old fashioned idea of holding the business logic in the database as a series of decision tables. Is this still done or has the idea that the efficiency of holding the business logic in the application so obviously better? Edit: Workflow is implemented as a service. My understanding is that it was aimed at long running workflows. In our case users press the save button and the workflow runs. Our issues are - Painfully slow to develop with on our machines, freezes, crashes - difficult to debug - now and again the workflow manager throws errors for a few hours for no reason we can find - touch one workflow and you have to change 14 other files - application is slow for users, part of which we have traced to the workflows. Validating in the database starts to look good because the validation is all based on data in the database. @catcall There are 10 or 12 lawyers who do not use the application but have 8 or 10 admins do the data entry. We just finished the desktop upgrade but the boss does not believe that programmer contractors should have better equipment than staff. So Windows XP with 4 cores and 3 GB of ram is the best we can do. I will investigate if there is any classification of types of business logic. Some of it can be done more efficiently in the application. Other types might be more easily changed and configured on the database side. 

This solution does not require triggers but requires setup and causes a performance hit if you enable it for all tables. Auditing has been built into Oracle for many releases. There is an article here which goes into some detail. Basically, you turn it on, tune it for what level of detail you want and the output is available as a dba view or as XML. Check the system parameter AUDIT TRAIL, it sounds like you want the fine grained auditing available from 9i onwards so you can access the SQL_BIND and SQL_TEXT. There is an SCN number so you can flashback to the state of the data when the change was made. Keep in mind that there is a performance hit for all this. You must have the hardware and resources available if this is a production system. 

So you should be able to see what changes are invalidating the MV. Next you should examine the alert log to see if anything has been logged. I wonder if you have a complex chain of materialized views? Does one depend on another? Is only one becoming invalid and others are not? Try this query to see what depends on what dbms_snapshot.get_mv_dependencies( list IN VARCHAR2, deplist OUT VARCHAR2); I would not recommend your suggested workaround until you understand what changes are invalidating the view. Edit: Metalink note 264036.1 says: "This is expected behavior. When there is a DML on the master table, all the MVs based on this table are marked as INVALID. Though the status is INVALID, you will be able to query the mview. However, the query on MV will not return latest update done in master table unless MV is refreshed." From the way you are using the Materialized Views I am not sure why you cannot issue a refresh of each view that is marked invalid. 

There are multiple solutions to this problem but the driving issues are cost, allowable downtime and complexity. 

Yes, you need a script but it doesn't have to be 1000 lines. --make a table or global temporary table to put the results in 

I agree that the archive logs can be deleted when they are beyond a set period of time. Doing this solved a similar space issue for a database I maintain. However some thought about the "why" would be a good idea. If this is a development database and it is not performing the same way as production then you have an issue with your application stack. 1) Is production performing the same way but you have lots of disk space so you don't care? Or is this only on the development VM image? Just cleaning up log files solves the problem but not the root issue. 2) I have not noticed any differences for Oracle databases that have been virtualized. 3) Check the size of the .dbf files. Do they represent a significant portion of the space used? If so, then you may need to increase the VM disk size. 

It's not clear from your question what brand of database you are connecting to. I will assume it's Oracle. You need this information: 

Edit: the original poster asks how to track incidents. More information is needed such, Oracle version, what kind of incidents, how often do you want to receive notifications. 

The trick is get the packages and dependent code recompiled in one go. If you are refreshing a development database with new data you will have an enormous list of invalid procedures. As well, with dependent code you find yourself recompiling over and over. You can use this command located in $ORACLE_HOME/rdbms/admin/utlrcmp.sql: 

I think you want to change your table structure. Discounts and items are related but are not always the same. Today you discount T-Shirts by 15% tomorrow you realize you have way too many and want to change that to 20%. Sure you can update the table but then you loose all records of what the discount was. When a customer calls to say they only got a 15% discount but should have received 20% all you can say is that it is 20% now. I suggest breaking this into an 

This could be done this way. I don't like it much as it is not very elegant and looks fragile if unexpected things happen. 

I maintain an Oracle Enterprise 11.2.0.3 database where one user has editioning enabled. I understand that this was an irreversible choice according to the documentation. If I wish to revert that user to a non-editioned status can I export their objects, drop and recreate the user and then import the old objects? 

Try shutting down the database and then issuing the startup command. Then try your script. If you get the same error verify basic connectivity by connecting from sqlplus with the same name and password. Check your log file location and the any operating system error logs as well. 

I confirm that a full or incremental backup during business hours can make your database inaccessible to end users and web services. Factors that can make things worse: 

The next part is synchronizing the information. In our organization if new users are added or permissions for existing users are changed IT does the job in the morning. The application typically has a window of low usage overnight (ie: not 24 hours a day/usage). On the application web server we have a windows service which syncs the groups and users. On the database at night I run a scheduled job which truncates the group-user links and recreates them by a direct query to Active Directory using DBMS_LDAP. For your purposes you would want to write a more sophisticated package that has a database package running three LDAP queries to synchronize groups, users and group users instead of my truncate solution. I found DBMS_LDAP to be powerful but poorly documented. If the IT department should happen to change the OU that users are in you don't get a lot of useful information from the Oracle end. Tim's site was very useful with this article and here has the code I reused. Edit: There are two parts to using an application: 

I have seen this become necessary if the database is being used by a poorly coded application. It's surprising how many "Enterprise" grade front ends are not able to let go of a session when the end user finishes. If there are problems that this is addressing you should be able to see this in the application error logs or the database logs. If you can't see any errors then there is no need to restart Oracle. @miracle173 If you restart the application it releases the sessions but causes other application errors which usually result in the application's index of files needing to be rebuilt. If you kill the sessions on the database the application does not release these sessions and you have to restart it after a while or it will crash from too many sessions. This is a quietly acknowledged bug. We can upgrade the application or...restart the database. @Phil madness might be preferable to the abuse of a database system on the altar of sloppy programming. Enterprise application, yes, built with good standards and an understanding of what databases do well; no.