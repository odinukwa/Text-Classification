I know the 3750X's have a management interface on the back which is a 10/100 Fast ethernet port. Its right next to the RJ-45 console port. I also believe that the 2960 switch that you listed there also has a management port on the front of it, above the SFP ports. Assuming your switches aren't too far away, you could use the management interfaces to manage your devices remotely if you will. Of course you would require additional cabling back to another "management switch" which would likely contain the VLAN required just to manage these devices. Otherwise, you could also run a terminal server server such as an OpenGear or something of that nature and have the console connections linked back to this device in order to remotely control them if your entire network is having issues or what not. These management interfaces do operate on their own VRF and will also not participate in STP as they're not running on the active VLAN that is being trunked down to them. However, I have seen it where some organizations like to have the management VLAN on the same subnet as the hosts on the switch. This allows them to ping and check the arp table/mac address table and pinpoint where devices are a bit easier than if it was just a simple L2 network. There are of course pro's and con's to each method, however, given that you wanted to go about a out-of-band method. I would say the management interface is probably is your best direction. 

What is the best practice for putting 802.3x flowcontrol on a userport and does this inhibit performance if the application/system isn't designed for it? Eg) 

I have a network which has many devices sending data to 224.0.0.225 on a VLAN which spans multiple switches. Each device (aprox 12 of them) is sending reporting data at roughly 500-600 kbps. Each port on the VLAN, whether the receiver sends a join or not, is getting flooded with roughly 6mbps of multicast traffic. IGMP snooping is enabled on all the switches and the local VLAN. pim sparse-mode is configred on the mrouter/default gateway. If I do a on the switch, there is no entry in the snooping table. I know 224.0.0.1 - 224.0.0.255 fall within the link-local reserved IP Multicast range meaning a router will not forward packets within this range. These ranges are also used for routing protocol chatter. eg) EIGRP, OSPF, HSRP...etc I have two questions: 1) I think the answer is YES - for 224.0.0.1 224.0.0.255...does IGMPv2 ignore this range for snooping and does the switch just forward this to all ports? 2) Is there a way to force IGMP to snoop this multicast traffic and only send it to the ports which request it with an IGMP join? I have a feeling this is one of those instances where the application/programmers need to design their devices and application to respect scalable non-consumer networks. Thus they should be using a multicast address in the 239.0.0.0/8 range. 

2) Packets with a destination IP (DIP) address in the 224.0.0.X range which are not IGMP must be forwarded on all ports. 

The TACACS+ authentication returns a fail, so the router tries doing local authentication. I guess you should provide us with the sanitized configuration. If you have 

This looks similar to converting AP from CAPWAP to autonomous - BVI1 interface gets reverted back to DHCP should prevent the AP from reloading when no DHCP is detected and/or CAPWAP can't join the controller. 

For some large-scale temporary locations that I've worked at. The business ran 25-pair with amphenol ends on both sides. This allowed them to just remove the patch panel and breakout boxes when they left....leaving the very expensive 25 pair. Anyways, They had an amphenol patch panel which had short patches to all the switch ports. The had an amphenol break-out box where all the users in that area would patch to. This gave them 6 ports per "drop". I'll see if I can find a picture or part number of the breakout box. Careful when purchasing 25 pair though as it may not conform to cat5/6 standards. 

Given the topology you gave in your comment. The L3 switch is probably the best place to put the DHCP server. This also sets you up in event you add an additional WAN router and have two circuits or connections coming into the office there. This would eliminate the single-point-of failure if the DHCP server were to reside on one of the routers which "went away" Otherwise you would need to utilize the ip helper-address on the VLAN interface. 

I remember dealing with this exact same issue a long while ago. The reason why by default the ME3400 or any of the ME series don't have CDP enabled is due to the fact they're supposed to be deployed at the PE/CE. A service provider would not want to leak its CDP information to the customer. 

Assuming that you manage the fiber yourself (dark fibre, your own runs...etc), then yes - this should be possible as long as you have the proper configuration on both sides of the Cisco ISA570. 

I'm redistributing from EIGRP to iBGP here and by putting delay on a specific interface within the LAN, I've changed the metric value for 3.20.2.1 to metric 5222400 The path for 8.20.2.2 is then set as best since it has a smaller metric of metric 107520 How exactly is the metric there calculated? I'm assuming its part of some eigrp to bgp delay formula but I cannot find any specific information to how it relates on Cisco's documentation so far. Thanks! 

on all the interfaces between that device and the RP? Also don't forget to have so it finds the RP automatically. Also - if you have redundant links between you and the RP...PIM routing (or branches) do not follow the same path as the regular routing table. They WILL check for the RPF (reverse path forwarding) to make sure the source of the multicast stream is coming from the right direction. But it is possible to have the standby HSRP link be the DR (designated router) on the PIM side of the house. You can change this behaviour by setting the DR priority. the higher the X the higher in value. You can also check to see whether the router see's the multicast joins by issuing it should also list the RP. will also tell you if it see's the upstream multicast neighbour I believe VRRP follows the same concept however I am not 100% sure since I infrequently use multi-vendor default gateways. 

Welcome to the field of network engineering! DTP stands for Dynamic Trunking Protocol and is crucial to the commands below. It is also Cisco proprietary. switchport mode access - Always forces that port to be an access port with no VLAN tagging allowed EXCEPT for the voice vlan. DTP is not used and a trunk will never be formed. switchport nonegotiate - turns off DTP and forces the interface into a trunk. switchport mode dynamic desirable - pro-active DTP negotiation will begin and if the other-side is set to trunk, desirable, or auto. The interface will become a trunk. Otherwise the port will become an access port. switchport mode dynamic auto - allows the port to negotiate DTP if the other side is set to trunk or desirable. Otherwise it will become an access port. switchport mode trunk - This interface will always be a trunk no matter what happens on the other side. It will also use DTP to negotiate a neighbouring interface that is set to dynamic desirable or dynamic auto into a trunk. In the real world - I have never seen *dynamic auto*or dynamic desirable as generally network engineers try and make layer 2 related items (such as switchport settings) stable and static. There are also security risks associated with this. An access role port is usually used for an single host or device. You must also specify which VLAN you would like it to be associated with, otherwise it will default to VLAN 1 in the Cisco world. eg) 

You should be able to keep the set interface command however the router should automatically select the interface which matches its routing table. Without the set ip next-hop command, the router will forward the packet based on its routing table - regardless of the interface required. For 12.2 based code - take a look at Cisco's documentation. 

What viable companies, products or options are out there today for TCP Acceleration over satellite or high latency IP networks? The average satellite RTT is upwards from 600ms (depends on the location) TCP doesn't work too well as the window sizes are kept small due to the delay in receiving ACKs. An accelerator is required to spoof the ACKs to trick the device to start sending the next set of data while the original packet is still in transit. 

Take a look at Implement trunk and trunk protocols for more examples and to learn more about ISL or dot1q tagging along with some more command and debug information. 

I understand the risks of using third party ram but paying for the Cisco branded memory modules and CF cards on an old ASA which is no longer covered but Smartnet is ludicrous. There are plenty of third parties who claim they sell compatible RAM. Does anyone have any experience as to what memory the ASA 5520 or any of the 55x0 series is compatible with? 

Firstly, performance on a wired connection will usually ALWAYS be better than a wireless connection. A wireless network is using a shared medium (air) to transfer data. Wireless communication has always been and is still half duplex. As much as MIMO allows multiple data channels to be formed, only one device can still occupy the given channel-space at a time. Anyways, back to your issue. You're using a 2602 which contains a 3x4 MIMO. Its configured in autonomous mode. I'm going to assume you have a few APs configured with the exact same SSID/password in order to extend the coverage area or device density. You should check a few things.... 

Generally speaking you can install MRTG or any network graphing and historical data software which can pull interface statistics via SNMP. A nice and easy free software for this is CactiEZ. It can be easily run out of the box on an old server or mounted and installed easily on a VM. However, since you're using a Cisco router, you can enable NetFlow on your interfaces and export that information to a Netflow collector/software such as Solarwinds Traffic Analyzer. This allows you to use the router to classify the types of traffic traversing that interface and report that back to the collector. You can then get better statistical information on what kind of traffic is being utilized and where its coming and going to as well. 

I would do a debug on your TACACS+ server while you are trying this. I'll assume that you only want to use TACACS authentication and only fall-back to local logins if it can't access the server? Try using this: 

I can't find any 3650's at the moment but I have a 3850 running 3.7.3E. Looks like it will tell you the actual consumption. 

Assuming that these ports are just access ports and are not participating in any routing or VLAN trunking which would cause a STP re-convergence or a routing re-convergence. It should be safe to move them. You should not have to specify the id field. This command should simply work: 

I know this isn't specifically on topic - however I believe its worth mentioning that IPv6 actually has the ability to assign an IP address based on the MAC address by using eui-64 notation. This also does not require a DHCPv6 server as it is stateless. Please see the following links for more information (1st 2 google results, how original) $URL$ $URL$ 

I don't believe you can block youtube.com with your router anymore. YouTube.com runs over HTTPS now which would disallow the router from inspecting the packets. Your best bet is to probably block the DNS requests for youtube.com so they can't reach the actual youtube servers. 

No one seems to have mentioned that with Fibre - you have the future option for DWDM. However, I guess if you're debating between fibre & copper on a run - DWDM would probably be your last thought as if you really needed additional bandwidth you'd just run another cable (since the run would be short enough) But over LONG runs & links - DWDM allows you to future-proof your fibre investment if you have the correct hardware. 

I don't think you're going to see any website with direct step-by-step instructions on how to do this. There maybe a few blogs which speak to a blogger's personal experience....however, this is how I would approach it. I'm going to assume that your current 3560Gs have L3 links to the core and an L2 link (or portchannel) between the two switches. I will also assume that you're using interface tracking to help swap HSRP states and pre-emption and etc... While you are adding the 3750X to the original 3560G switches. All you would require is to extend the L2 link to the 3750X stack. You can pre-provision the 2nd 3750X and even have it running and connected when you do this entire process. Then move the L3 uplinks from the standby 3560G to the first 3750X and ensure that HSRP is configured in order to facilitate the failover. Once that is done...begin migrating your cabling/device cable to the 3750X stack. Then move the final 3560G L3 link to the 2nd 3750X switch. You should now also be able to remove the L2 link between the 3750'ss and 2560's and power them off. Since you're using HSRP - the 3750X's should become active under your control (via a priority change) Finally, after you are left with just the 3750X in a stack-formation. You will no longer require HSRP to run between the two switches since the 3750X will really be seen as one switch all together. Ultimately, the end solution should have 2x L3 uplinks to your core or router, and the VLAN interface existing solely on the 3750X stack. I would also have the each of the L3 links attached to the separate 3750X switches as well. This final solution should give you a more robust design from preventing spanning tree and HSRP timers from delaying your network re-convergence and allowing the routing protocol to do the upstream path selection instead of HSRP.