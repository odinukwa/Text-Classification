(For reference: $P^{NP[\log]}$ is $P$ with an $NP$-oracle, but the $P$ machine is only allowed to make $O(\log n)$ queries to the oracle. $P^{NP}_{tt}$ is the problems that are polytime truth-table reducible to $NP$; this is equivalent to nonadaptive polytime Turing reductions, i.e. all the queries to be made are decided in advance, then all the queries are made, then some computation is done without queries to find the result.) 

n-coloring the n x n Sudoku graph is trivial, but if some of the colors are given to you (the extendability version) it becomes NP-complete. By the "Sudoku graph" I mean the natural graph whose associated coloring problem is Sudoku. Namely, suppose $n=k^2$ is a square. The graph will have $n^2$ vertices, which we will denote by $(r_1, r_2; c_1, c_2)$ for $r_1,r_2,c_1,c_2 \in [k] = [\sqrt{n}]$. For each fixed $(r_1,r_2)$, the vertices $(r_1, r_2; *, *)$ form an $n$-clique; for each fixed $(c_1, c_2)$ the vertices $(*, *; c_1, c_2)$ form an $n$-clique; and for each fixed $(r_1, c_1)$, the vertices $(r_1, *; c_1, *)$ form an $n$-clique. 

Such a lower bound for integer inputs is indeed known, and is not just a trivial consequence of the result for the reals: 

The most efficient (and also simplest) algorithms for this are based on the notion of a strong generating set, introduced by Sims. Strong generating sets can be computed efficiently using the Schreier-Sims algorithm. Essentially any introductory book that talks about computational group theory should have a decent introduction to this (and if it contains an introduction to this that isn't decent, I'd think it's not a very good book). While the standard deterministic algorithm for this takes quadratic time, there is a randomized nearly-linear time algorithm. See Seress's book "Permutation Group Algorithms," Chapter 4 (the nearly-linear time Monte Carlo algorithm is Theorem 4.5.5). 

Borodin's Gap Theorem: For every total computable function $g(n) \geq n$, there is a total computable function $t$ such that $DTIME[g(t(n))] = DTIME[t(n)]$. In fact, this holds for any Blum complexity measure in place of $DTIME$. See also the wikipedia page and references therein. 

I think this is open. Note that if instead of testing equivalence under rotations you ask for equivalence under the general linear group, then already testing equivalence of degree three polynomials is GI-hard (Agrawal-Saxena STACS '06, author's freely available version), and in fact is at least as hard as testing isomorphism of algebras. Now, GI-hardness is not evidence that your problem is not in $\mathsf{P}$, as indeed, your whole questions is essentially whether we can put GI into $\mathsf{P}$ by the approach you suggest. However, the fact that cubic form equivalence already seems significantly harder than GI (e.g. we still do not know if algebra isomorphism is in quasi-poly time, unlike GI) suggests that (a) people have thought of this approach and (b) it is still open. While I don't know for sure if similar results hold for the orthogonal group, I would be surprised if they didn't hold (esp. if you move from degree 3 to degree 6). 

A really simple solution: Build a suffix tree for the first string, $S$, and annotate all nodes with $s$. Then insert all suffixes of the second string, $T$. Annotate nodes you pass through or create with $t$. The path label for any node that is annotated with both $s$ and $t$ is a substring of both $S$ and $T$. (See, for example, these lecture notes a quick web search turned up.) 

As has been pointed out, this problem is similar to the more commonly known edit distance problem (underlying the Levenshtein distance). It also has commonalities with, for example, Dynamic Time Warping distance (the duplication, or “stuttering,” in your last requirement). Steps toward dynamic programming My first attempt at a recursive decomposition along the lines of Levenshtein distance and Dynamic Time Warping Distance was something like the following (for $x=x_1\ldots x_n$ and $y=y_1\ldots y_m$), with $d(x,y)$ being set to $$ \min \begin{cases} d(x,y_1\ldots y_{m-1})+1 & &\text{▻ Add letter at end}\\ d(x,y_2\ldots y_m)+1 & & \text{▻ Add letter at beginning}\\ d(x,y_1\ldots y_{m/2})+1 & \text{if $y=y_1\ldots y_{m/2}y_1\ldots y_{m/2}$} & \text{▻ Doubling}\\ d(x_1\ldots x_{n/2},y)+1 & \text{if $x=x_1\ldots x_{n/2}x_1\ldots x_{n/2}$} & \text{▻ Halving}\\ d(x_1\ldots x_n,y) + 1 && \text{▻ Deletion}\\ d(x_1\ldots x_{n-1},y_1\ldots y_{m-1}) & \text{if $y_n = y_m$} & \text{▻ Ignoring last elt.}\\ \end{cases} $$ Here, the last option basically says that converting FOOX to BARX is equivalent to converting FOO to BAR. This means that you could use the “add letter at end” option to achieve the stuttering (duplication) effect, and the deletion at an point. The problem is that it automatically lets you add an arbitrary character in the middle of the string as well, something you probably don't want. (This “ignoring identical last elements” is the standard way to achieve deletion and stuttering in arbitrary positions. It does make prohibiting arbitrary insertions, while allowing additions at either end, a bit tricky, though…) I've included this breakdown even though it doesn't do the job completely, in case someone else can “rescue” it, somehow—and because I use it in my heuristic solution, below. (Of course, if you could get a breakdown like this that actually defined your distance, you'd only need to add memoization, and you'd have a solution. However, because you're not just working with prefixes, I don't think you could use just indexes for your memoization; you might have to store the actual, modified strings for each call, which would get huge if your strings are of substantial size.) Steps toward a heuristic solution Another approach, which might be easier to understand, and which could use quite a bit less space, is to search for the shortest “edit path” from your first string to your second, using the $A^\ast$ algorithm (basically, best-first branch-and-bound). The search space would be defined directly by your edit operations. Now, for a large string, you would get a large neighborhood, as you could delete any character (giving you a neighbor for each potential deletion), or duplicate any character (again, giving you a linear number of neighbors), as well as adding any character at either end, which would give you a number of neighbors equal to twice the alphabet size. (Just hope you're not using full Unicode ;-) With such a large fanout, you might achieve quite a substantial speedup using a bidirectional $A^*$, or some relative. In order to make $A^*$ work, you'd need a lower bound for the remaining distance to your target. I'm not sure if there's an obvious choice here, but what you could do is implement a dynamic programming solution based on the recursive decomposition I gave above (again with possible space issues if your strings are very long). While that decomposition doesn't exactly compute your distance, it is guaranteed to be a lower bound (because it's more permissive), which means it'll work as a heuristic in $A^*$. (How tight it'll be, I don't know, but it would be correct.) Of course, the memoization of your bound function could be shared across all calculations of the bound during your $A^*$ run. (A time-/space-tradeoff there.) So… The efficiency of my proposed solution would seem to depent quite a bit on (1) the lengths of your strings, and (2) the size of your alphabet. If neither is huge, it might work. That is: 

In many nonuniform models - Boolean circuits, algebraic circuits, decision trees, branching programs, etc. - computing exact complexity seems to be significantly harder than computing asymptotic complexity. While I maintain hope that your intuition is correct - that understanding exact complexity of small instances might lead to asymptotic insights - I know of only a few cases where this has happened: 

Note that the implication in (2) only goes one direction (existence of obstruction implies no inclusion of varieties), so it is possible that $perm$ is not a $p$-projection of $det$ and yet no representation-theoretic obstructions exist. So in this case, just proving that no obstructions exist is not enough to show that $perm$ is easy. On the other hand, in (1) the inclusion of algebraic varieties is both necessary and sufficient for the inclusion of complexity classes. [In the above of course many details have been omitted - the reliance on the input size, how to talk about the complexity class $P$ instead of $det$, the fact that the inclusion of varieties is equivalent to $perm$ being approximable by $p$-projections of $det$, ... But the essence is still right.] 

For Buchberger, it depends what you want it for, but generally speaking the answer is no. First, as pointed out on the Wikipedia article, the complexity upper bound given by Tarski-Seidenberg is horrendous, whereas Buchberger's algorithm is exponential space, which is optimal (since ideal membership is EXPSPACE-complete). Second, Tarski-Seidenberg is for semi-algebraic sets over the reals (that is, allowing $\leq, <, =, \neq$), whereas Buchberger's algorithm works not only for the reals, but for polynomials over any field, or even over other rings (such as $\mathbb{Z}$). With minor modifications, Buchberger's algorithm even works in various noncommutative analogues of polynomial rings. Third, Grobner bases (and hence, Buchberger's algorithm) can be used for many more things besides quantifier elimination. For example, intersecting ideals, quotienting ideals, computing syzygy modules of ideals, proof systems (hence algorithms) for Tautologies, coding theory, group cohomology, applying toric geometry to algebraic geometry (where we think of the initial ideal as a way of deforming an arbitrary variety into a toric variety, and thereby learn things about the original variety that are easier to deduce for the toric one), the list goes on... (I am less familiar with Wu's method.) 

As far as I can see, the value of each item depends on which bin it is added to. Its full quality if it is added to its primary preference, and a reduced quality (reduced by -0.5 and -1, respectively) for its secondary and tertiary preferences. Do I understand you correctly? In this case, this problem can be formulated as a min-cost flow problem, which resembles min-cost bipartite matching (but with the added twist of bin capacity). I.e., it is not an NP-hard bin packing problem at all (unless P=NP). Construct a flow network with a source, a sink, and two "layers" of nodes, corresponding to the items (first layer) and bins (second layer). Add edges from the source to the items (zero cost, capacity 1) and from the bins to the sink (zero cost, capacity equal to the bin capacity, i.e., from 1 to 3). From each item, you add an edge to each of its primary, secondary and tertiary bins, with capacity 1 and a cost of its adjusted quality multiplied by -1 (to go from a positive value to a negative cost). Now just run a standard min-cost-flow (or min-cost max-flow) algorithm to get your answer. Of course, not all items will be matched if the total capacity is less than the number of items, but the match will produce the matching that gives the greatest total (adjusted) quality. If you don't want to muck about with min-cost flow, you could split each bin node into multiple nodes (the number of nodes corresponding to the bin capacity), and duplicate the edges from the items. So if an item has an edge with a given cost to a bin node with a capacity of 3, you'd now have 3 bin nodes, and that item would have an edge to each of them with the given cost. You could then just use an algorithm for min-cost bipartite matching, such as the Hungarian algorithm. (You will now no longer have a source or a sink, of course.) This latter version is probably more practical to implement, and libraries for the Kuhn-Munkres algorithm are available in multiple languages. 

For every linear objective function, $(E,\mathcal{F})$ has an optimal basis. $(E,\mathcal{F})$ is a matroid embedding. For every linear objective function, the greedy bases of $(E,\mathcal{F})$ are exactly its optimal bases. 

UPDATE: a3nm contacted SIAM directly about the SODA proceedings, and they said they did not guarantee open access in perpetuity :(. But least they are OA for now! 

[Upon reading more of the comments on the question, I realized that this answers Jukka's second formulation, but the original question was actually more about Jukka's first formulation. I'll leave this answer and the comments here for discussion for a while.] The problem you are trying to solve (as formalized by Jukka's second comment above) is not computable, and so in particular does not have an EXP upper bound (proof below). You might also be interested in Chapter 6 of Juris Hartmanis' book "Feasible Computations and Provable Complexity Properties" which discusses the difference between the collection of languages decidable in a given time bound, and the collection of languages provably decidable in that time bound. Proof: Intuitively the idea is that, any algorithm $A$ can only look at finitely much data before deciding the runtime of $M$. So we can construct an $M$ for which the finite amount of data that $A$ looks at is not enough to decide even an upper bound on the runtime of $M$. Formally, suppose there were some algorithm $A$ which, given the description of a Turing machine $M$ as input, with the promise that $M$ runs in time $n^c$ for some unknown constant $c$, outputs a $k$ such that $M$ runs in times at most $n^k$ (i.e., $c \leq k$). (Note that this is a promise problem: if $M$ describes a Turing machine which does not run in polynomial time, we do not care what $A$ outputs, or even if $A$ halts.) Then $A$ fails on a description the following machine $M_0$. Let $n_0$ be the length of a known description $D$ of $M_0$. On input $0^n$, $M_0$ starts trying to compute $A(D)$. If it takes more than $n$ steps, $M_0$ halts. Otherwise, $M_0$ gets the output $k = A(D)$. $M_0$ then loops for $n^{k+1}$ steps and halts. $M_0$ runs in polynomial time and so satisfies the promise, yet $A(D)$ outputs a $k$ such that $n^k$ is not an upper bound on the runtime of $M_0$. 

Another reason is that this is often without loss of generality, since frequently (though not always - see below) complexity of functions and decision problems are equivalent. Every decision problem can be viewed as a function whose only values are 0 and 1. Conversely, given a function $f$, there are several associated decision problems which usually have the same complexity as $f$, for example: 

If you don't use the flow per se, but use the Ford-Fulkerson algorithm (or some version, like Edmonds-Karp), you can get both the max-flow and the min-cut directly as a result. When looking for augmenting paths, you do a traversal, in which you use some form of queue of as-yet-unvisited nodes (in the Edmonds-Karp version, you use BFS, which means a FIFO queue). In the last iteration, you can't reach $t$ from $s$ (this is the termination criterion, after all). At this point, the set of nodes you reached forms the $s$-part of the cut, while the nodes you didn't reach form the $t$-part. The leaf nodes of your traversal tree form the “fringe” of the $s$-part, while the nodes in your traversal queue form the fringe of the $t$-part, and what you want is the set of edges from the $s$-fringe to the $t$-fringe. This can also easily be maintained during traversal: Just add an edge to the cut when it is examined, and leads to an unvisited node, and remove it if it is traversed (so its target becomes visited). Then, once Ford-Fulkerson is finished, you'll have your min-cut (or, rather, one of them) right there. The running time will be (asymptotically) identical to Ford-Fulkerson (or Edmonds-Karp or whatever version you're using), which should give you what you were looking for. 

You could get a Google Scholar profile, and it'll keep feeding you recommendations it thinks will be relevant to you, based on your publications. 

Actually, the complete and general description of a problem that can be solved by a greedy algorithm is a matroid embedding, which generalizes both the concept of a matroid and that of a greedoid. The answer is no—a problem solvable by a greedy algorithm need not have a matroid structure, but it will have the structure of a matroid embedding (which is, alas, much more complicated). A mental model for some of this could be finding minimum spanning trees. The structure used by Kruskal's algorithm is a matroid, but that used by Prim's algorithm (which requires a start node) is not. (It is, however, a greedoid—and a matroid embedding.) Helman et al. (1993), in their paper An Exact Characterization of Greedy Structures define their notion of a greedy algorithm in terms of set systems, which is the same formalism that is used for matroids and greedoids. A set system $(S,\mathcal{C})$ consists of a set $S$ and a collection $\mathcal{C}$ of subsets of $S$, the so-called feasible sets. A basis for the set system is a maximal feasible set, that is, a set that is feasible but not contained in any other feasible set. An objective function $f:2^S\rightarrow\mathbb{R}$ associates each subset of $S$ with a value. An optimization problem, in this formalism, consists in finding a basis of maximum objective value for a given set system and objective function. The greedy algorithm, defined in terms of this formalism, is quite simple: You start with the empty set, and successively add a single element until you reach a basis, always ensuring that (i) your set is feasible at each step, and (ii) the element you add maximizes the objective function of the resulting result, wrt. all the alternative elements you could have added. (That is, conceptually, you try adding all feasible alternatives, and choose the one yielding the highest objective value.) You could, perhaps, argue that there might be other forms of greedy algorithm, but there are several textbooks on algorithms and combinatorial optimization that describe this set-system based algorithm as the greedy algorithm. That doesn't prevent you from describing something that doesn't fit, but could still be called greedy, I suppose. (Still, this does cover anything that could potentially have a matroid structure, for example, though it is much more general.) What Helman et al. do is that they describe when this algorithm will work. More specifically: