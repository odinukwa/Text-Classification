If you stop D3D from rendering -- typically by detouring the D3D calls directly -- you may see an increase in performance. It will depend primarily on whether the application's performance is actually bound by limitations on the GPUs resources. You may also destabilize the game, which may be making some decisions based on responses it gets from the GPU (for example by using queries) which it will of course no longer get, since you suppressed transmission of any commands to the device. Ideally of course, rendering and game logic are wholly separate, but sometimes this isn't the case. You'll probably have to do a fair bit of juggling and balancing what you detour. You could, for example, allow all resource creation to succeed so that you don't have to deal with the game not coping with your proxy resources (which may not match its internal validation), but if the problem you're seeing with performance is that you're overloading the resources stored on the GPU, you will not see any benefit from this approach. If at possible, profile before you commit to a lot of work. Use Resource Monitor to watch system performance counters and be aware of the complexities of profiling the GPU. 

You should have a very well-defined set of interfaces that are allowed to transmit or receive messages -- giving them a reference to a EventScheduler should be trivial. If it isn't, or if you feel like that would involve passing the event scheduler to "too many" distinct types, then you might have a larger design problem on your hands (a promiscuous dependency, which singletons tend to exacerbate, not solve). Remember that while the technique of passing the scheduler to the interfaces that need it is a form of "dependency injection," you aren't in this case injecting a new dependency. This is a dependency you already have in the system, but you are now making it an explicit one (versus a singleton's implicit dependency). As a rule of thumb, explicit dependencies are more preferable as they are more self-documenting. You also afford yourself more flexibility by decoupling the consumers of the event scheduling from each other (since they are not all necessarily tied to the same scheduler), which can be useful for testing or simulating local client/server setups or a number of other options -- you may not need these other options, but you have not expended effort to artificially restrict yourself from them, which is a plus. EDIT: All I mean when I talk about passing the scheduler around is this: if you have some game component that is responsible for responding to collision, it's probably created via some collision responder factory that is part of your physics layer. If you construct the factory with a scheduler instance, it can then pass that instance to any responders it creates, which can then make use of it to raise events (or perhaps subscribe to other events). 

I don't think there are fewer glitches in games today at all. If anything, I would put my money on there being more bugs and defects in shipping game software than in the past, simply because games are massively more complex than they were years ago -- many games these days ship with bugs, as evidenced by the number of day-one patches that exist for a lot of games. There's no way to stop a programmer from making a mistake; the programmer (and most other game developers) operate in essentially a full-trust environment where they can do anything because they are creating the product. There are techniques that can help alleviate certain classifications of defects (unit testing, for example, smoke and regression tests, usability testing, et cetera), however. Console games undergo fairly rigorous certification procedures that help catch some bugs -- but this was almost always the case, starting in some form or another with the NES. But as the plethora of tool-assisted speedrun videos for various NES games (which generally exploit bugs and glitches for fast completion), that didn't make those games bug free. There's an argument that could be made that the increased complexity in art and visualization techniques for games tends to hide some bugs -- for example, as games approach a more realistic presentation, errant NPC behavior that is technically a bug might be perceived by a player as emergent. That doesn't mean that there isn't a software defect there, though. It's very difficult to gather scientific evidence regarding bug count in shipping products, but I would say that if you were able you would either find that the numbers are relatively stable, or increasing. Decreasing seems quite unlikely. One argument you could make for there being fewer bugs, however, is the fact that some games are built on existing engine technologies that have been iterating (and thus weeding bugs out) for years. However, this is not true of all games and any time an individual game adds a new feature to the engine or at the higher-level gameplay layer there's a risk of introducing a bug. 

The higher the generation, the more expensive it is. You don't want to predict or avoid the actual collections -- it's usually impractical to try. What you want to do is avoid the scenarios that create undue pressure on the collector and allow the heuristics used by the implementation to do their thing. This means don't try to outsmart the collector by forcing a now and then, et cetera. Microsoft has a lot of documentation about the collector and its behavior, this page is a good start. Rico Mariani also writes about GC issues frequently, for example, this is pretty interesting. 

You can use the stencil buffer using a technique similar to the one described here for rendering to a non-rectangular viewport (as that is essentially what you are doing). When you clear you scene, clear the stencil buffer to some fixed value (say zero). When you render the lit areas, configure the stencil mask to write a different value (say one) to the buffer. Then render your regular scene with the stencil function configured to accept only fragments where the stencil value is greater than 0. This will cause only fragments within the lit areas to render. It's straightforward, but it has the (fairly severe) disadvantage of providing very hard edges to the lit regions. The other options are to perform the entire effect in the pixel shader using a shader global for the position and radius of the light source (problematic for supporting more than one light source) or alpha blending precomputed textures into the scene (this is the most general method, easily supporting multiple light sources and smooth transitions into darkness). 

It looks like you want to do something like: -- you may also want to scale by the elapsed time stored in the GameTime object so you get frame-rate independent movement. 

It really doesn't matter -- you can use either polling or event-based interrupts to simulate the other kind of input, so that decision is largely irrelevant in trying to mimic the characteristics of the input from older devices. That said, you can find a lot of information about systems that old on emulation enthusiast websites (this one, for example, contains a wealth of information about the hardware and memory-mapped registers uses by the GameBoy -- it's similar to the document linked in some of the comments, if not exactly the same in a different format). To achieve emulation of a particular game's input characteristics you'd want to do it at a higher level -- taking into account things like how the game handles two opposing directional bits set for joystick input, for example. Many older games don't handle this well, because it is generally not possible to physically interact with the device fast enough or in such a fashion as to cause some of the potential states to exist. This is how tool-assisted speed runners do some of their work. You may want to scan through the TASVideos resource page for Pokemon and see if maybe there are any control-related oddities you should be emulating if you really want that level of similarity to the game. But I don't think it matters very much to the end result if you choose polling or not, even though that is generally what was used on the GameBoy. 

You don't have a choice. It's not really about advantage or disadvantage; it's the only way to go. XNA doesn't have a 2D graphics API; it's rendering API is only 3D. You can implement 2D in terms of 3D by simply only considering your X and Y dimensions, and you can abstract this out to provide wrapper interfaces that look like they are fully 2D, but in order to submit any kind of rendering operations to the XNA API you're going to have to speak it's language (the language of the underlying Direct3D implementation), which is 3D. 

I like Google Code a lot -- if you are willing to make your project open-source, it's pretty awesome. It provides you with hosting for code (SVN or Mercurial), files for releases, a simple-but-effective wiki, and a straight-forward bug tracker. The downsides are that access control for the wiki is limited, and edits to the wiki cause commits to your repository. I've heard good things about github, and from what I've seen of it while grabbing people's code from it, I like it. But I have never used it for more than that, because I don't have a compelling need (or desire) to use distributed version control. In the realm of less-general tools, Perforce is a powerful version control system that is used by just about every professional game development studio I have worked at or know of. They have free limited-user licenses. You need to host and administer the server yourself, though, which is something I have very limited experience doing so I can't comment much to that. I have used Trac for bug tracking before (and still do for my own projects that I host on my private SVN). It's also simple -- I am a fan of simple bug tracking and such, instead of systems like Bugzilla, which I think are too much trouble to configure. I don't use Trac's built-in wiki, really, preferring DokuWiki instead. There is also the ever-popular MediaWiki, if that's your thing. Backup-wise, I mostly use Backblaze, which is awesome but violates your "free" constraint. If I couldn't use Backblaze I'd just back everything up via a cron job or something to an external hard drive and mirror that to my web server, probably. 

In a few rare cases, driver-specific workarounds or behavior can be triggered in D3D by passing otherwise invalid or undocumented parameters to certain Direct3D entry points. These are uncommon, usually not a good idea to rely on, and aren't made available for querying except by checking the hardware and driver versions. Similarly, a few pieces of hardware and/or a handful of drivers can play a bit fast and loose with their conformance to the D3D specification (whichever one they claim to support), but that's not really what you're looking for either. While there are functions to query the above mechanisms, none of the mechanisms provide any way to introduce new entry points into the API or introduce entirely new functionality without versioning the API itself (which is what OpenGL's extension mechanism allows for). In summary, there's no equivalent to in Direct3D because there's no equivalent capability in the API. Your friend's program likely just has a legitimate bug of the variety that manifests as you describe (any number of things could be causing it). 

Profile and see. In C++, for example, dynamically allocation on the heap is usually a "slow" operation (in that it involves walking through the heap looking for a block of appropriate size). In C#, it's usually an extremely fast operation because it involves little more than an increment. Different language implementations have different performance characteristics with respect to memory allocation, fragmentation upon release, et cetera. Implementing a memory pooling system can certainly bring about performance gains -- and since mobile systems are usually underpowered relative to desktop systems, you may see more of a gain on a particular mobile platform than you would on a desktop. But again, you'd have to profile and see -- if, currently, your game is slow but memory allocation/release doesn't show up on the profiler as a hot spot, implementing infrastructure to optimize memory allocation and access probably won't get you much bang for your buck. 

Note that you can just wrap the calls that might return , ignore their actual return value, and pretend it was on a temporary basis. This can be a quick way to test that the code path for handling the error works at the most basic level, although it is still good to check by stimulating the error for real, because the real error will come with side-effects that are much harder for you to simulate. 

The effect is pretty primitive by modern standards. Fundamentally, it looks like you can break the wave effect down into columns where each column is a simple sprite that is falling downward under the influence of a gravity-like force, leaving behind contrail-style sprites that are fixed in position. The falling sprite for each column is a noisy water sprite: 

In the context of graphics programming and shaders, a "rim" shader would be one that focuses on achieving a lighting effect related to the silhouette or other feature/contour edges of an object (crudely, "the outline" of the object). Typically this would be to simulate rim lighting (more examples), which comes about from back-lighting a subject. I suppose if you wanted to stretch it, you could consider shaders employ other edge-related effects (such as drawing the outlines on cel shaded scenes) "rim shaders" as well, since they do have something to do with the feature edges of the object. More I think more traditionally the term is used to refer to the lighting effect. 

XNA includes APIs for performing animation and rendering of avatars. To get an avatar into your game, you need to initialize the gamer services component by adding a new instance of to your game's component list (typically in your game's constructor): 

You can assign any arbitrary matrix to the pipeline's projection matrix in XNA, even one that doesn't perform a useful projection (you probably won't see useful results doing that, but you can). So you can construct an orthographic projection matrix yourself or use one of XNA's helper methods and use that. You'll also have to adjust the view matrix to position the camera from the angle you want, of course.