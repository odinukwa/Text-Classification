I was trying to create the drive through Server manager, when I create the drive through Drive Management it worked fine. 

What I am trying to understanding is what the purpose of the other key lock(5ebca7ef4e2c) is and what its locking. 

So as you can see from the estimated number of rows, the first one is 3.2511 which came from the density vector and for the second one the estimated number of rows of 7 comes from the histogram. So is it true that SQL Server can sniff the variable when we recompile adhoc query or is it something that I do not understand? 

From my testing I do not see an option to encrypt a symmetric key with Database Master key. Isn't the Database master key a Symmetric key. What do they mean by public key of th database master key? 

I am testing -SubscriptionStreams parameter in replication and wanted to make sure it is using multiple streams when applying transactions on subscription. When I check the subscriber there is only one SPID applying the transaction. May be my understanding is wrong, but is it supposed to have multiple SPID's when SubscriptionStreams is enabled or it does it internally. Is there any way to verify that it has picked up the parameter change? Publisher and distributor are SQL 2014, subscriber is SQL 1008R2 

And now the , Scan is gone and it has to scan the entire table to get that value. Why do you do this SQL Server? 

The problem In the midst of this, I realized I wanted the ability to combine multiple teams into one team. For example if I create a Team A and Team B but then realize they should work together on something, I would want to combine them as Team C and assign Team C the task. Idea 1 My first idea was when the two teams were combined, that all the members from the combined teams would just be added together in one mass array of ObjectIDs. I don't like that for several reasons. 

It makes dropping members difficult. If I drop a member from Team A and want it to reflect into Team C, that's going to take a lot of extra effort to keep it consistent. It also makes adding a member difficult. I add a member to Team B, thus I must add the member to Team C. I'd imagine that would be a lot more taxing in terms of writes. 

What I Have I am currently hashing out the data model for an application that will utilize MongoDB. In my setup, users or (as they are called in the schema) will be created and then assigned to teams (). Currently the set up is like so: 

I've read other methods to create a table for login information and they referenced a LEFT JOIN in SQL, but that seems like it would only be good if I was referencing 1 other table and not two different tables. How can I pull EMPLOYEE information if the Login ID entered is from the EMPLOYEE tables and vice versa for customers? 

We are just entering Azure world and will be migrating SQL server soon.I am trying to test throughput on Azure VM (DS13_V2) which is supposed to give 384MB/Sec as per documentation. Here is the configuration : a) No of cores : 8 b) Attached 2 disks (1TB each formatted with 64K block size) to the VM which are P30 disks(200mb/sec). c) I have striped 2 disks into one and called it F: drive with total 2TB which in theory is capable of giving 400mb/sec. Test: I ran SQLIO (with Test file size - 20GB on the striped drive F:) with multiple combinations and looks like throughput is throttled at 256mb/sec consistently. I even ran diskspd which also gives me the same 256mb/sec throughput. Question: I am wondering where the bottleneck is or anything that i am missing as VM is capable of giving 384mb/sec and my striped disks are capable of giving 400mb/sec (200mb/sec each) wherein i should be seeing a throughput of 384mb/sec. Please let me know if any suggestions would help me in doing a better storage test. 

Issue : I was moving a non clustered index on a 3TB table from one file-group to another (userfilegroup to index) and it took 11 hours and never completed and i had to kill the process as it was blocking other processes. Rollback is taking forever. It has been 10 hours since i killed the process and no clue what is happening. Locks are still held and are impacting other processes. I see the percent_complete as 0% and kill with statusonly also shows 0% after so many hours. Can you please suggest me if there is a way that i can check if rollback is still doing anything or just got stuck . I am afraid to restart the server as it has to go through the rollback process anyways. Only positive thing that see is under sp_who2 diskIO moving for this SPID. ****Any help is much appreciated....**** 

I made the login table independent of customer and employees. The login table holds a foreign key to a categories table that will hold types of user logins (either customer or employee for now). By keeping it separate, it won't be a requirement for any person to have a web access account. Business rules can dictate if the employee requires an account, it can be created with their initial addition into the server. 

I am creating a sample web application for a business and I am stuck at the login implementation. There is supposed to be two different users (login types?). I will have employees and customers. I have a table for employees and a table for customers set up already. Let me caveat that I understand the following is not SQL, just the notes I've taken so far in a .txt file. I have my employees 

Idea 2 The best idea I can come up with at the moment is to add an field to the document. This will start to get a little verbose in terms of queries but it's the best I can think of so far. There is a better way to do this. I know there is. Suggestions? A little Background Perhaps this will help some understand if the solution seems all to simple to figure out. This project is my first endeavor into MongoDB and NoSQL. I come from an all SQL background for interacting with databases. 

I am looking for a robust open source tool for monitoring SQL server. Ours is a small organization and we don't have any monitoring tool in place and would like to know if any open source tool is available so that we can start monitoring lower environments to start with. 

We have migrated our SQL server 2012 infrastructure from on-premise to Azure cloud recently where in all the production VM's are build with pre-images of SQL 2012 enterprise edition. So,here is the question and issue that we are currently facing : We want to upgrade SQL server from 2012 to 2016 and wanted to know if there is a way to perform in-place upgrade with pre-images installed without having to actually migrate ? . What we heard from our infrastructure team is that we can't do an in-place up-gradation if it comes as a pre-image and will need to spin of another VM and perform migration which would incur cost again. Any suggestions or workarounds without having to put migration efforts are much appreciated and thank you for all the help that you render to folks like me and to SQL community. 

I am trying to understand why is my query (update statement) causing clustered index update in the plan? Based on my clustered index (in the where clause), I am just updating columns in my table. What is the need for SQL Server to do clustered index update? I am not updating clustered key for SQL Server to reorganize/order the table according to clustered key, instead it has to update the columns or NC index on them wherein clustered key pointer to the NC rows will be the same (since I am not updating the clustered key). Can someone explain me why such behavior from SQL Server?