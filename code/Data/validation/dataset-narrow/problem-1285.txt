This is a really general question, so you're probably only going to get overly-general answers until you post a new, more specific question. It's also going to differ pretty significantly depending on the style of game. For example, the algorithms used to implement Sudoku solvers differ from those used to solve tic-tac-toe, chess, or Go (game trees / alpha-beta pruning). And I'm not sure what kind of AI is necessary for Snake -- generally it tends to be mostly random. Alpha-beta pruning is probably the most common search technique for most of the class of board games you're thinking of (at least as far as I know, but I'm admittedly not terribly familiar with AI). There's also Negascout and whatever this is (these last two links aren't that great, if you spend more time sifting through the Google search results you can probably find better since you presumably have a more detailed idea of what you're really looking for). 

Before rendering the text, compute its bounds. If the text would be too long horizontally, split the string you render into substrings. This can be done as an implementation detail of the text rendering API, so users don't have to know their string was too long to fit. If you employ a bin-packing technique to place each text substring in your render target (this one, for example, is simple and effective and this page describes some improves to it) you can fit quite a lot of text onto a single render target sheet, especially if you start getting fancy and trying to rotate some of the strings. If you ever fill a render target sheet, create another one. You can't really resize render target textures -- you destroy them and recreate them, so simply creating a new one alongside your existing one is generally easier on computing resources. Plus, it allows you to build a caching mechanism into your text rendering -- exploiting the fact that if a piece of text was rendered this frame it will probably be rendered again next frame, which can save you from having to re-rasterize a lot of text into your sheets. 

when rendered. The good news is that this is easily generalizable so a 1x1-sized entity can use the same code path as a NxM-sized entity: you only need to track the entity's position in the world and the size, in tiles, of the sprite. If your system provides you the ability to specify entity positions in non-integer / non-tile values, you can simply use the exact center of the sprite as the origin, as it can simplify things just a bit. 

As far as I know, neither technique you described is used as presented in any modern game. The first technique has, if nothing else, some serious image quality concerns and the second (while similar to selection buffer picking) adds nothing to the table and suffers all the drawbacks of selection buffer picking. It is difficult to say from these theoretical perspectives what the performance of these techniques would be and how they'd compare to alternatives. Much of it will depend on the complexity of the underlying scenes, the size of the desired render targets (as well as their bit depth), what other optimization can be made for a particular implementation, et cetera. I would be confident in saying that they'd probably be on-par with existing techniques -- certainly they won't be so much faster as to overwhelm their disadvantages. You're effectively trying to turn everything into an image processing problem and image processing is not all that fast, and generally has accuracy complexities. I'll cover some of the major disadvantages for each proposal below: 

Flipping an asset at render time is relatively trivial to do, even on the CPU. Creating an entirely new asset that is just a copy of an existing asset is essentially a way to double your asset footprint for no gain. If you have the budget in memory, disk, et cetera for unique assets per direction, they can provide extra visual fidelity (for example, Super Metroid provided unique sets of sprites for both directions Samus could face, and because she is a very asymmetrical character it made the game look a little better). But often a flip is good enough, and cheaper. 

It looks to me like a standard 2D side-scrolling camera. It just happens to be looking into a 3D world and using perspective projection so you get that slight sense of depth. I've seen some people call this a "2D 3D camera" in shorthand, but it doesn't have a standard name. 

It's certainly viable, and if it makes you more productive in the long run, then it could be a good idea. However I'd advise caution on two points: 

As an entry-level programmer, you're going to have very limited say in what you ultimately end up getting to do -- entry level programmers are often hired as generalists. You will likely have to spend some time doing some level of grunt work (which is more akin to your apparent definition of "low level" than is traditional); it's the nature of the beast. You are only minimally competent, at best, after college anyhow. You can help avoid this by paying careful attention in your job interviews to the kind of work other programmers describe doing. You want to find a place where tedious grunt work like connecting forms to the game engine for editors is handled via a resuable architecture platform, and doesn't involve much programmer intervention: where tedious grunt work has been engineered out as much as possible, because the programmers know that grunt work is not intellectually stimulating and they want their fellow programmers to be intellectually stimulated. That is, assuming you even look for a job in games, because... 

After all, that work has to happen at some point and your only other approach here is to track whether or not you've started it yet and then make the views that happen to be the first and last to draw make the appropriate calls. This is ugly. So ultimately in this approach you have one giant conflated frame that includes both input processing, logic updates, and render commands in an unstructured order. This is both hard to follow, hard to profile, and potentially extremely problematic as the complexity of your rendering increases (for example, if you don't have an order-independent transparency implementation you have to sort transparent things back-to-front and make sure they render in that order to get correct transparency; how is that bulk operation done in response to individual model updates?). It also raises some serious questions about the viability of the approach under concurrency scenarios. I wouldn't advise this approach at all. If you really want to adhere that closely to the MVC pattern, I'd make the "rendering" that your views do in response to model updates simply be the preparation of any bookkeeping that needs to eventually be consumed by the renderer when you later call . Things like making sure any visually-impacting properties that changes (like a unit going to a "critical health" state) are reflected in the data the renderer will eventually consume (like the "tint" color for that particular unit's shader). 

In case it's not clear, "Nx" is the X component of N, et cetera. Now that we've got that expansion, remember that (A,B,C) are often the names of the plane's normal's components, so we can rename: 

Like most reverse-engineering tasks, there isn't necessarily a fool-proof method of accomplishing this. 

Sure, you can use C#. One of the bigger issues to be aware of in terms of performance in C# or other .NET ecosystems is the GC -- the .NET framework provides several flavors of GC, including a "server" GC, that are worth learning about. Intelligently managing memory (for example, by pooling) is still a good technique even in a managed environment. There are several robust APIs for interacting with SQL, communicating via TCP, et cetera in C#, either as part of the base framework or via third-parties, so you should have no trouble there. You can utilize ASP.NET or similar if you really want your server to be web-based; if you just want to run a process and listen for TCP connections you can just deploy an .exe and the appropriate dependencies to the server machine, open up the appropriate ports, and run the .exe. 

No, there is no single, central, comprehensive source for this information. There's MobyGames; I'm not sure how they aggregate all their data, it's not completely accurate but it may be your best bet. There's also the US Patent and Trademark Office or the copyright office, via which you may be able to wade through trademark or copyright filings to find "official" names. Not all of those would correspond to actual shipped titles, though, and you probably won't find the smaller titles on any of those sites. 

you can create a (as just one example) and store pointers to and in that vector and treat them uniformly by way of their common interface. You should also consider that its generally good practice to divorce your rendering and game logic code. The effect of storing different classifications of game object in different ways should have no impact on the organization of your rendering queue; you'd still want that to operate on (essentially) a single list of its own type of object (for example, sprites in a 2D game). The most straightforward way to achieve this is to store a pointer or reference to the renderable component (sprite, or some higher level construct if needed) inside the game logic components. 

The principle here is to treat each contiguous set of elements in the array as a single row. That's how you arrive at the indexing math used to compute . Another issue you touched on is how your grid resizes. This is an issue regardless of the grid implementation you use. You might try handling it by only increasing the actual storage for the grid; never decrease it. Almost any implementation of a grid is going to involve a copy of the existing grid elements when the grid resizes. Implementations utilizing linked-lists won't (or will minimize them), but then you're back to having cache-coherency issues. You want to minimize that copying, and at a minimum you only need to resize to increase storage. You can keep, independently, a variable indicating the grid's logical size and only process that many rows, ignoring any extra "deactivated" rows that might exist beyond that when your grid resizes down. This means the resize-downward operation only involves setting a variable to the new, lower number. This can be extended to apply to cases where the grid resizes in both directions, even though your specific case does not currently seem to require that. I mentioned cache coherency/locality of reference a few times, and that's because I'm assuming since your game is "grid based" your doing a lot of iteration over all (active) cells in the grid. It's that kind of use-case where coherency of your data can have a surprising impact on performance, although it's still true that at the specific numbers you mentioned it's unlikely to be that big of a deal. 

I don't think there is much of a market for selling code, as I alluded to above. Art is another matter. You can draw up a license to restrict the purchaser in whatever manner you see fit, but do note that the licensing is something a potential buyer will consider in determining the value of the product. Although it's always possible for somebody to purchase your product and then violate your license, so you need to be prepare to defend whatever license you use, which can be costly. Also you should probably have a real lawyer (which I am not) answer legal questions w.r.t to licensing issues. 

A is a generic image format, and a is a generic key-value "property list" format. Neither are inherently concerned with sprites or sprite sheets. That means the answer to this question depends highly on what's in files -- primarily the file. Normally any sort of spritesheet metadata (which is what your sounds like) has both sprite frame names and the positions of each frame. Or something similar, like sequence names and sequence boundaries, where each frame in a sequence is a fixed size. If you have this size and position information available in the sprite, you can interpret it to know how to extract the individual sprites associated with the individual names. If you do not have this information in the , you probably can't correlate the names in the property list file to the frames in the image. (It's possible that the organization of the file is such that each sprite is a fixed size and they match 1:1 in a certain order (for example, you look at individual frames from left-to-right, top-to-bottom, and that traversal of the corresponds to a document-order traversal of the ), in which case you also have sufficient information to do the correlation you want, but that's going to depend on the author of the data.) 

Uniquely identifying log messages has a bit of a subjective art to it. There are several ways you can implement it, with potential pros and cons. You should choose the one that works best for you. You could consider the message text the unique property. I think this is the worst option, personally, because it means two textually identical messages in two different source locations could be throttled or suppressed, making it more difficult to figure out which code is the offending code. It also means slight variations in message state ( and ) will not clump together for throttling and duplicate detection purposes, and usually this isn't what I want. Alternatively, you can consider the source location (via and in C++ or similar constructs in other languages) the unique thing. This tends to flip the behavior from the first option around on its head. You can also consider messages unique based on the format string instead of the unformatted value (in the case of the fake render state message above, that would be ). I personally tend to use different methods for throttling and for duplicate detection (and usually do both), but the specific methods I choose tends to depend on what the general shape of the logging in an individual project tends to be. 

You're using FPS is a profiling metric, which is a pretty bad idea because it is a non-linear measure. 525 FPS is about 0.001904 seconds per frame. 515 FPS is about 0.001941. That is a difference of about 0.000037 seconds, which is significantly less than a millisecond. Even between 480 (0.00208) and 525 FPS, that's only a difference of 0.000176 seconds (again, less than a millisecond). With a timing delta that small and with the very limited set of information you've provided, it's quite likely that the differential is entirely due to the fact that you are drawing additional geometry and have provided different inputs to the graphics pipeline, causing it to do different things. Especially since your explanation makes it sound like you stopping using (which will be an improvement) and then applied the bias to solve the depth-fighting problems. 

While I'm far from an expert on SC2 modding (having barely even played the game), I've stumbled across this question in the archives here several times and each time I've gone out researching ways in which this might be accomplished. Unfortunately, every time I've come up empty, and I have to conclude at this point that it's not really possible to use the SC2 mod tools to blacken or "re-fog" a portion of the game. I did some across this thread, however, which is about solving a problem of 'radar tower' like units, and which you may be able to modify to achieve something similar to what you want: Make a unit with an event, when other units come within a certain radius of that unit, apply a visibility modifier to hide that unit. You'd need to do some further scripting to render the primary unit non-player-controllable, probably, and it won't replace the fog of war on the map, but it could result in making anything that walks into that range invisible, which may be close enough for your purposes.