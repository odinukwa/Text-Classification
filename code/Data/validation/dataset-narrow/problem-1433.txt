OK, you have this "impact" stat. And you want this stat to "determine size of prey it can kill". I can only assume this means that the prey will have some corresponding "size" field, and if the "size" exceeds the impact, the hunter can't kill them. So that appears to be your goal with the design. So let's look at the implementation to see if that achieves that goal: 

It's because "blend shaders" are things that don't actually exist. Imagine if someone decided to implement "vertex shaders" in say, the GeForce 256. There's no hardware support for them, so it would either be implemented on the CPU, or the language would have to have a lot of limitations. Vertex positions would have to pass through one or two matrix multiples; you couldn't do any other math to them. Texture coordinates could get exactly one matrix multiply. Or you could take texture coordinates by multiplying the vertex position by a matrix. Or you could use a special function to generate it. But you couldn't use regular math. And so on. There are no "blend shaders" in real hardware. Therefore, a blend shader is bound by the limitations of the actual hardware, which doesn't allow for programmable blending. Blending hardware operates on a specific sample(s) within a specific pixel. It is given a value from the fragment/pixel shader, and it is given a value from the framebuffer. Any apparent additional functionality from blend shaders is carefully created by modifying the actual fragment/pixel shader used by the hardware. Even so, you're still stuck with the basic limitations of blending. 

while just having a larger constructor function. There is an argument to be made for objects which have 15 or 20 pre-conditions, which would make a constructor very, very hard to work with, and it would make things easier to see and remember, by pulling those things out into the interface, so that you can see how the instantiation works, one level higher. Optional-configuration of objects is a natural extension to this; optionally setting values on the interface, before making the object run. JS has some great shortcuts for this idea, which just seem out of place in stronger-typed c-like languages. That said, chances are, if you're dealing with an argument list that long in your constructor, that your object is too big and does too much, as is. Again, this is a personal-preference thing, and there are exceptions far and wide, but if you're passing 20 things into an object, chances are good that you could find a way to make that object do less, by making smaller objects. A more-pertinent reason, and one which is widely-applicable would be that the initialization of an object relies on asynchronous data, which you don't have, currently. You know that you need the object, so you're going to create it anyway, but in order to have it function properly, it needs data from the server, or from another file which it now needs to load. Again, whether you're passing the needed data into a gigantic init, or building out an interface isn't really important to the concept, so much as it's important to the interface of your object, and the design of your system... But in terms of building the object, you might do something like this: 

The most common method is to not bother. Just use generic animations like most MMOs. One guy makes an attack, the other guy makes a blocking animation. Damage is dealt, numbers appear, everyone is happy. Now, if you actually give a damn about how your game looks, you need to expend effort. The idea is fairly simple. To coordinate animations between entities, you need to... coordinate animations between entities. The two entities need to talk to each other and work out which animations each of them will play. One entity should probably be the "leader" in terms of who's in charge. It dictates when things will happen and how they will occur. Let's say the attacking entity is always the lead. The attacker informs the defender that he's being attacked. So now the attacker references the defender and vice-versa. Next, both must select which animation to play. This is generally done by a table or something similar based on the available parameters. For each possible set of parameters that affects which animation to play, you have an entry in the table that says which to play. So you'd have ranges of enemy sizes, self-sizes, ranges of distances to the target, etc. The attacker and defender play a different animation obviously. But the tables they select from are designed to match: given the same attacker size, defender size, and distance, the attacking animation selected will match the defender's animation selection. Then they play their animations. Note that timing may need to be involved here. Especially if distance is involved, you generally don't want the defender to be defending until the attacker is close enough. So he won't play his animation until the attacker reaches a certain distance. This requires the defending entity to track the position of the attacker and play the animation at the right time. Your biggest problem (and the reason why most games punt on it and use generic anims) is likely going to be what happens when a third entity gets involved. If you're already in the middle of a lengthy scripted sequence, what do you do if someone else tries to attack you? This is generally not a good thing. So oftentimes, you simply say that nobody can attack someone who is attacking/defending currently. In some games, elaborate animations are only used for specialized events. Generic animations are for basic fighting, but you might have a special anim for the final blow. 

If you want a list of things to do to end up with sprites like what you end up with in Diablo / Diablo II / StarCraft / Fallout, then the first step is to create your 3D model, texture it, and animate it (walking, attacking, hurting, dying, etc). Then, when all of that is done you want to set the camera to the same angle as what you would see in the game. Then you would turn your model 45 degrees and save pictures of each stage of each animation, and keep doing that until you had pictures of every model, in every animation, from every angle. To save space, things that didn't make sense to happen at every angle didn't. Treasure chests were not shown from the back, et cetera. Some games had characters that could look straight up and down, and straight left and right, but other games only used characters who were facing on 45 degree angles. To add multiple kinds of armour, using the old-fashioned Diablo II procedure, you'd have to put each KIND of armour on your model, and save out all of the pictures in all of the poses in all of the directions. I say "KIND" of armour, because most of the armour was just recoloured versions of the same model. They did that recolouring in the game. So you'd make one kind of gauntlet, and add that to the model, and then in-game, you'd just recolour it. BUT if each type of character needs to look different in chainmail, then you need to model each kind of character wearing chainmail. There are more-modern ways of doing this... ...but if what you want is for the game to look like Diablo II, then this would be the way to accomplish it. Saving all of this to a sprite-sheet is relatively simple: You take all of the little pictures and you copy and paste them all into one big picture. For the purposes of importing the sprite-sheet into the game and making it dynamically-usable, or for the purposes of using "masking" to change the colours of armour, et cetera, those are outside of the scope of your current problem. Also, if this sounds like it's a lot of work to do manually, it really, really is. But that's why you want to look into "Batch Processing". So that you can write a script that says "Take all of the versions of this model, and for each animation, save a picture every X % of the way through the animation, and name it ".png" You could then write a batch process which would take all files in that folder, and put them in order, or put them out of order... ...or make one huge spritesheet, or just make one spritesheet per character, per armour type, et cetera. A more-modern game might treat the character like a ragdoll. 

What you have is a connectivity graph. And generally, the best way to group the connected nodes (ie: characters) together is with a graph search algorithm. Depth-first, breadth-first, whichever. All you're doing is building a list of which nodes are reachable from all others. So long as your graph is undirected (if A is visible to B, then B is visible to A), this works fine. There may be some algorithms to improve this for specific cases. For example, if sometimes characters don't move (and terrain doesn't move too, so immobile characters remain visible) then you can choose not to test them again to update their connectivity graphs. But in general, you're going to have to retest visibility every frame. Odds are, that's going to be slower than the graph traversal to find the visibility groups. 

The BC1-3 and BC7 formats can also be in the sRGB colorspace. OpenGL provides similar sRGB variants and GL_COMPRESSED_SRGB_ALPHA_BPTC_UNORM_ARB. Obviously, none of these are lossless. As I understand it, BC6H and BC7 are not widely supported in tools, though I seem to recall that NVIDIA's texture tools do support them. Case 2 If you're talking about normal 8-bit-per-channel images, you already know your options. But for more exotic texture types, like floating-point, 10-bit-per-channel, and normal maps, you're out of luck. The simple fact is that most general image compression software is intended for regular old images. Most people who deal with floating-point textures don't really care enough about loading speed or disk space to bother with compressing them. They're big, but they've accepted that. And it's really hard to losslessly compress floating-point values. So really, just stick with known paths for regular images, and use zlib or 7z or some other general compression method for the others. That's generally about the best you can do. Do note that any lossless image compression technique can be made to work on any pixel data, so long as that data can fit. So you can always put a normal map in a PNG, even if it is a 2-component normal map (the third component is 0). It may not compress well, but it will probably beat out pure-zip. 

Well, first, you're right that if you want to have thousands of permutations of these scenes, which operate in "real-time", your options are either to make a stupid amount of videos/slideshow images which would be altogether prohibitive in size... So you've got a few answers... You can certainly build a 3D scene, where you build a render-engine which takes models/textures, and animate them. You probably don't want to have thousands of stars on screen, though. The alternative is similar... ...build an engine, and instead of making 3D models, just use images (transparent) of batches of stars. You can move the image of a star (or stars) around. Likewise, those sprites (think of it like using collage cutouts, you're moving around on a board), you could treat some of them like a slideshow -- so mini videos or mini slideshows of just small groups of stars and tiny details which you couldn't make models. And then you can randomize collections of those pieces, their positions, movements, et cetera... Voila, reusable pieces (smaller size), useful for creating many different scenes. 

The same steps you would take to protect any data. Lua isn't special just because it's text. If you need the user to be unable to easily modify the data, employ some encryption. The more complex the encryption, the more difficult it will be for them to deprocess it. However, as I understand iOS (which is admittedly not much), you probably don't have much to worry about from casual cheating. Users can't easily inspect an application's private data. So I wouldn't be concerned. 

Following this is a detailed change log of every revision of the spec. Furthermore, what does it matter what it is based on? It copies and modifies the GLSL specification; you don't need to look at any particular GLSL spec to read the ESSL spec. 

This is actually quite easy to say. Just not as easy to do. Things feel like busywork when the player is thinking of them as busywork. Which means that the following are probably going on for the player: 

Well, let's get the simple stuff out of the way first. You have this between strings (the name of the event, presumably) and integers (the index of the registered event listeners). Lookup time in a is based on two things: the number of items in the map, and the time it takes to do the comparison between two keys (ignoring cache issues). If the lookup time is a problem, one way to handle it is to change the comparison function by changing the string type. Let's assume you're using and for comparison. This is highly inefficient; it does a byte-wise comparison. You don't care about the real string less-than comparison; you just need some kind of comparison that gives a strict-weak ordering (because doesn't work otherwise). So you should use a 32-byte fixed-length string instead of . I use these for identifiers. Comparison tests for these fixed strings don't do byte-wise comparisons; they do 32-bit (or 64-bit) comparisons instead. It takes every 4 bytes as an unsigned integer and compares it with the corresponding 4 bytes of the other string. That way, the comparison only takes at most 8 compares. It ensures a strict-weak ordering, though the ordering has nothing to do with the data as characters. Storing strings longer than 31 bytes (need the NULL character) truncates the string (but from the middle, rather than the ends. I find that entropy tends to be greatest at the beginning and the end). And strings shorter than that pad out the remaining characters with . Now, you could ditch the entirely and use a hash table. If you really have over 100,000 different kinds of event types, this could be a good idea. But I don't know of a game where that would be a remotely reasonable thing. 

Really, there are a lot of things that you can do, here. Perhaps your cutscenes might appear "out of sync" if you line up animations with key moments in the text... That's okay, if you teleport forward in the scene, as well as on the cards, or play everything at double-speed if people are trying to fast-forward the text... ...or selectively choose which animations appear in fast-forward or not... ...or just ignore it altogether (as long as player-state is perfect when the game starts again). Players who are actively trying to speed-read, or are actively trying to skip the cutscenes and get back to gameplay aren't going to be upset that you didn't find a way to convey ALL of the animation and voiceovers, et cetera, in the 500ms that they were willing to wait, before playing again. The point is more that you should try to appease both, if possible, and do so without stepping on your art, unless they're asking to skip it. 

Okay, so the PseudoScript is kinda ugly, but that's the idea. Now, it doesn't matter what order anything happens in. We've calculated the baseline with the ints, and then we use the baseline (rather than a running tally) to calculate fractions, which we then convert to ints (totally optional - some games only do that for the user-visible stats), and add them to the final stat. You might think this is cheating the player, by not adding the fraction to the final tally. What it's really doing is giving everyone a fair experience, because now: Olag: 

This blend mode is used to keep overlapping shadows from growing ever darker or lighter. It simply takes the darkest value written to that pixel. It should look good enough. You should also use the color write mask to turn off color writes. Render the table. When doing so The blending should be set up as follows: 

The absolute most you get with object-space normal maps is less computation time (not having to transform the light direction into tangent space, or alternatively, transforming the normal from tangent space into model space). But that's not a big deal, especially nowadays with deferred renderers running around. 

In general, you should not be using glDrawArrays at all. If your model has repeated vertices, you'll get a lot more bang for your buck performance-wise from an index list. There, optimized strips or even triangles will be able to use the pre and post-T&L vertex caches. This means less memory fetching and less vertex shader execution. 

No. Strictly speaking, a texture is a term for one or more images that are bundled together in an object called a "texture", within the context of a GPU-based rendering system. A texture can be used when rendering a 3D object. Or it can be used when rendering a 2D object, because 2D objects are just special cases of 3D objects. A sprite is the term for an image, or part of an image, that is used to represent an entity (or part of an entity) in a game rendered with sprite/tile-based graphics. You can put sprites inside textures. XNA does this internally, as it uses your 3D rendering system to render your stuff. 

The benefit there is that you can now use dependency-injection/inversion-of-control more-easily in your systems. Instead of saying 

That all comes down to how your game is organized, currently. BUUUT, there are some quick wins to be had with various organization systems (if you're talking about dealing with many elements, rather than, say a PONG number of collisions to test against). For example, a quick win might be to use quadtrees/octrees to do your sorting. Think of it like this: You know that the enemies in the top-left aren't going to be colliding with the walls in the bottom-right. So why not do some work ahead of time, to cut those checks out? Depending on the language you're using and the hoops you might have to jump through to have multidimensional lists which contain lists, all of which also contain your items... ...I've got a list of enemies which span the whole screen. Instead, I'll make a list, which contains 4 lists -- each of those lists is going to represent a quadrant of the screen (NE, NW, SE, SW). Then, I'm going to stuff the position data of each entity into one of those buckets. Right off the bat, I've shaved a TON of superfluous collision checks. As objects move over the bounding lines, I should take them out of one bucket and put them in the appropriate new bucket. If there are still areas where there are lots of collisions going on, you can use recursion to break one of THOSE buckets up into 4 smaller buckets (so breaking NE into NE:NE, NE:NW, NE:SE, NE:SW), and within that quadrant, assigning all of the objects into the quadrants of the quadrant. If one object is too big to fit inside of the smaller bucket, or is now crossing over the lines, then leave it in the parent bucket, and check that one exception object against all of the objects in the smaller buckets (beats checking all of them, though). You can recursively do this until you hit a threshold which you set for yourself (eg: "no more than 5 levels deep, but until you hit that depth, no more than 5 collisions to check per quadrant"). That said, if you DON'T have lots of collisions to check for, then this kind of optimization can actually slow things down. For instance, you wouldn't want to do this for, say, Super Mario Bros III, because there just isn't enough stuff going on to warrant the maintenance of the quadtree. But quadtrees and octrees are used in many, many games - even higher-end 3D games. Octrees are similar, except they also deal with height (or depth -- whichever axis you're not using in a quadtree in your game). So instead of breaking a square into 4 quadrants, you're breaking a cube into 8 octants. Hope that helped.