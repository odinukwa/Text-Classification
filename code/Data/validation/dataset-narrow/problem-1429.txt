Then when you're teleporting through and clone the camera, set the other camera's clear flags to "Depth Only" and it's depth to 1. 

So I'm using an external DLL with Unity to login to a web service and access functions from it. The DLL works perfectly fine in a command prompt project, but when run in Unity I can log in successfully, but when I try to use any commands I get a session has expired error. The DLL stores session cookies in the endpoint, so it appears that Unity isn't allowing this custom endpoint to store cookies. Does anyone know how to make Unity allow custom endpoints to store cookies? Or where in an endpoint I could parse the cookie from so I could feed it in with any service commands? For reference, here's a link to the main DLL, and here's a link to ContentService. The main DLL is compiled for .NET 3.5 so as to work with Unity. Just as a reference, here's the exact error code I'm getting in Unity: 

After hours of research and programming I figured out how to properly get the visual effect for this. If you'd like to just buy a portal system that works for visuals and most everything else you need, check out the Portalizer Unity Package. I program in C# and that package is in JS, but the logic behind it is incredibly useful and well thought out. In general I followed his logical thinking, with some tweaks for my game and a first person controller. Essentially what you do is use a modified version of This water shader/script. Have two mirrors in the scene, and have a camera render what it sees in each reflection to the other mirror. You'll need to create a modified transformation matrix to account for the relations between the two portals. To help decrease the performance hit, read This article about near plane clipping. This will help you render only what needs to be seen through the portal. I may create a more detailed tutorial with pictures and source once I figure out how to blend the cameras properly for a FPS teleport. Right now I'm too exhausted and busy to write a full tutorial and this should suffice because it gives you most of the code needed. 

I managed to fix the problem, turning the shadows to Soft Shadows, setting the strength to 1, and putting a culling mask on certain objects made the light shine on the proper surfaces and not pass through anything. 

You then take the main camera and uncheck your special layer from it's culling mask (I unchecked DepthMask layer) and set it's depth to 0. 

But that should only cause the game to stop rendering, which is fine. I just need the update loop to continue. 

Before I get to my question, I know the most obvious solution would be to use the normalized view port rect, however I need more complex shapes than a rectangle, and I've looked in to using the view port rect and it seems to not be my solution. EDIT: Some people were confused by my question, let me go in to a bit more detail. 

So I'm using Unity's profiler to help debug some of my code in the standalone. I've got it running smoothly, and writing all it's data to a .data file which I can read. However, the binary file Unity creates for profiler information gets quite huge very quickly. I'm hoping to get past this by writing the profiler data log to a zip archive. I have dotnetzip installed, and can add files to a zip archive. What I'm trying to figure out is how I could possibly either write the profiler data log directly to the zip archive, or write the profiler binary data to a variable of some sort which I could store in a stream and write to the zip archive on quit. This way I won't ever have to have the large file on the user's drive. Another option would be to continuously write the binary data to the log on the drive, then get the binary info from that log, write it to a stream, put it in to a zip archive, then delete the log. However I'd have to do this every few seconds, and that may get slightly process intensive. 

I'm working on a little ramp and ball game in Unity, I modeled the ramp outside Unity and exported it to a .FBX file, then I imported the ramp in to Unity. I set up the ball and ramp, both have Rigidbodies, Ramp is set to isKinematic = true, yet when I play the game the ball just falls right through the ramp and hits the floor below it fine. So it's something wrong with the ramp. Am I doing something wrong? Are .FBX files unable to apply physics? Thanks, Tim. 

What I want is a way that an editor script can tell when it has been attached to an object in the scene. OnEnable() and Awake() only happen when you bring an object with the editor script attached to it up in the inspector. Is there any built in method to accomplish this? Or perhaps some work around? The editor script only needs to tell when itself has been added to an object, not any other components. 

Basically what I'm doing is having a ball you can pick up and drop on a ramp. When you pick up the first ball, the second ball follows close behind, and when you drop the first ball on to the ramp the second ball drops on to the ramp as well, rolling down and launching off. The second ball continues to follow the first through the air. How could I go about getting the second ball to follow the first, while still keeping the rolling-gravity effect? Thanks. 

EDIT: After doing some research on my own I found that by deleting the debug.keystore file everything fixed itself. So currently I'm exporting my game strictly for testing to the Android. However, when I attempt to build for the Android, I get these errors: 

Does anyone have any ideas what these errors are, and how I could fix them? This is my first time building for any mobile device, so I'm a bit confused (Also, I do have the Android SDK.) Thanks, Tim. 

So currently I'm exporting my game strictly for testing to the iOS (iPad.) I don't own a Mac, so I'm having my client make a build from his Mac, but that means I need very specific instructions for him as he isn't very tech-savvy. I've looked online and can't find much at all about what all you need to export from Unity and make a file for the iOS, then sync it to your iPad. Could anyone provide a video or and help at all for this? Thanks, Tim. 

What's happening is as the player moves in to one portal, I create a clone FPS controller and move it out of the other. This gives me two cameras, and the view you see on the right above. It's just showing one camera, and clipping through the portal. What I want is something similar to this where the cameras blend to create the illusion of a smooth transition. What I want to do is delete everything from the green checker image to the left in the image below, and replace that with the other camera. That way you get the part of camera A's view that is peaking out of the portal, blended with the part of camera B's view that's peaking out of the other portal, to get one complete image. And as you move through the portal the cut changes appropriately. I've been designing a portal system, I have everything down, including getting the player to smoothly move through the portal. My main problem now is getting that camera blend effect Valve does. I need two cameras to blend together seamlessly, as if you were poking your head through the portal. And it can't just be a rectangle, it has to match however the player is looking through the portal. My best lead on this right now is to possibly project a depth mask shader behind each portal, then make the camera from the portal you're traveling to be depth only. Then somehow mix the two cameras. My main problem is figuring out exactly how I'd do this, how to make the second camera only render what's outside of the portal, and have the rest default to camera 1 to get one full screen projection. If you could give me ideas, or explain how I may do this with the depth mask shader that would be a tremendous help. I'll continue to work on this and update as I make break throughs. 

I've ran in to an odd issue with my Unity3D game completely pausing in certain scenarios, even with the Run In Background player setting on. For reference I'm on Windows 7 Ultimate using Unity 4.3.3 In The Editor: If I tab out of the editor while the game is running everything keeps working fine. *In Windowed Mode:* If I'm running the standalone in windowed mode and tab out, everything keeps working fine. However, if I grab the top bar on the window to move the window around, the game pauses until I release the window. Nothing updates, nothing runs while it's paused. In Fullscreen Mode: If I'm running the standalone in fullscreen mode and alt+tab out the game pauses. Not resuming until I tab back in to the game. This is causing issues with the multiplayer aspects of my game, because the client stops sending messages to the server whenever they alt+tab out or move the window. I know the graphics device is getting lost when I tab out, because I get this error in my log: 

So turns out this was a Unity bug. I reported it to Unity and they confirmed it for me. Not much to do besides wait for the next update. 

EDIT 1: So it seems this is a common issue with Unity, and it comes from a bug in which custom camera matrices break deferred lighting and shadows. This topic right here talks about it a bit, but the solution they provide doesn't seem to work in my case. So now I need to figure out why Unity does this, and if I can't fix it, figure out how I can get the lights/shadows on to the render texture I display. I've been using the script below to render a portal effect, all it is is a modified version of Unity's water.cs script. Now this script works in forward rendering, but for some reason when I turn the rendering path to deferred it doesn't render any lights or shadows on the rendertexture (I've tested it, the error is happening in the render texture this script produces.) I've been scouring through the script, and testing every section, but I can't seem to find why it wouldn't be rendering lights or shadows to the render texture it outputs. I'm going to continue researching and looking through the script, it seems the problem is due to the custom projection matrix I make for the camera. This is the area that is causing the problem: 

I actually got it working with this shader, this works on everything with the scene, no need for setting any render queues. I made this in Strumpy Shader Editor, seeing as I don't have too much shader writing experience. All I had to do was turn off the RGBA on the color mask, set render queue to Geometry -10, and check the advanced shadows pass box (which adds in the bit below that renders after the final pass.) 

Coming back to this much later, I completely forgot about this question. The problem ended up being caused by the artist I was working with, he set the meshes on the items to nearly 100x the size they visually were. This meant when I was trying to spawn items with the script above they were colliding with EVERYTHING in the level. After fixing the meshes on the items the above script worked perfectly fine. 

Basically I'm trying to use the "Flame" particle effect to simulate the flame on a torch. My problem is the flame is far too big. I've been trying too figure out how to resize the flame to fit the torch, but nothing seems to work. I've adjusted all the properties, and the scale itself. But no matter what it's too big. Anybody know how I could accomplish this? 

I've been researching this for a while, and had no luck yet. I figured I'd ask here to see if anyone had any good ideas. Essentially what I want is a shader that can make only part of an object transparent based on a slider. Similar to fill effects on 2D sprites, the object would fill from the bottom up, when the slider was set to 0 the whole object would be transparent, when it was set to 50 just the bottom half would be visible, and when it was set to 100 the whole object would be visible. I've tried various masking effects, but it would be best if I could build this in to existing shaders or have a separate mask. Is there perhaps a way to adjust the alpha on individual pixels used for the diffuse texture without incurring great performance loss? 

So I figured out how to do this efficiently. What I do is every X minutes write all the data to a stream and delete the data file. This causes the data to not take up so much disc space. Then on application quit I write all that data from the stream to a compressed archive. I end up getting roughly 1 megabyte a minute from the Profiler, rather than 1 gigabyte. 

So I have two legacy FBX animations; Animation A and Animation B. What I'm looking to do is to be able to fade from A to B regardless of the current frame A is on. Using animation.CrossFade() will play A in reverse until it reaches frame 0, then play B forward. What I'm looking to do is blend from the current frame of A to the end frame of B. Probably via some sort of lerp between the facial position in A and the facial position in the last frame of B. Does anyone know how I might be able to accomplish this? Either via a built in function or potentially lerping of some sort? EDIT: Does anyone perhaps know of a way to read bone positions of an animation at a certain frame? Perhaps if I could read that I could fake animations by doing Vector3 lerps. 

The suggested answers were very good, but I ended up going for a different technique using a depth mask. What you do is take THIS script and shader, you put the script on every object with a renderer in your scene and set the render queue to 3020 (I'll post a script to make this easy later). Then, you create a box of planes (all facing inwards, in the picture you can't see the side of the box closest to you, but when you're inside the box all you should see is gray) behind BOTH of your portals like so: 

So after much working I found out this is a bug with Unity. It happens in their Deferred Lighting -> RenderingToTexture pipeline. What's happening is they are cutting it to only show the first pass. I'll be filing a bug report to Unity, and hopefully this gets fixed soon. As a simple work around I'm just setting the portal camera to forward rendering path, it's still missing shadows, but at least it shows lights now. 

So what I ended up doing was using AnimationUtility.GetAllCurves(clip) to cache animation curve data from each AnimationClip in the editor. Once you serialize this data you can build to whatever platform you want. What you do is take the animation curve data for a given animation, and using the key.time and key.value Keyframe variables create a new AnimationClip using only the frame you want to blend from and a second AnimationClip using only the frame of another animation that you want too blend to. You then use animation.AddClip(); on this temporary clip, then crossfade between the two. Giving you a seamless fade from any point of one animation to any point in another. The code for this project is private. However, if anyone else having this problem needs further help or guidance feel free to contact me at tim@terabytetim.com