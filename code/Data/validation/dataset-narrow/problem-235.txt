I think this is probably a good design that you proposed. Just make sure that the table is indexed properly. Consider that every query to the table will probably filter by content_type so that should probably be the leading column in a multi-field index. 

As mentioned, the leading % makes things tricky, but if the event_details field contains a list of delimited items and you are searching for one of those items then you could create a child table event_history_details that contains one row for each item in the event_details field for each event. Such a setup would scale well and be SARGable. Unfortunately it involves changing more than just the query. 

Consider having a row in the table for each attempt that the user makes at the test. This means, then, that you would have to make the composite primary key of the table to be and (which can be an column). I would maybe think that the table should be a many-to-many relationship between and rather than between and , assuming that each time a user attempts the test they may get different questions. Either way the primary key on this table needs to include more than the single foreign key, it should include both foreign keys. 

You could deal with the issue by specifying the style and doing an explicit from string to datetime rather than an implicit conversion. $URL$ 

Storing in mysql table should be fine. You need to consider how the data is going to be accessed and retrieved when you're designing the table and indexes on it. I'd say that you're likely to be doing queries which return all of the past searches for a particular user (or perhaps even just the most recent by user) so it would probably make sense to cluster the table by and . This design should also help reduce contention if lots of inserts are happening at the same time since each user will be inserting into a different part of the table. 

Your table is extremely wide, and every time that you run a query it needs to read the entire table to find the rows needed. There are two ways that you could reduce the amount that must be read, firstly by reducing the number of rows that the DB must read (e.g. by clustering the table by ) but you suggest that most of the time, most of the rows will match the date criteria, so that probably won't get you very far. The other possibility to reduce the size of the data is to reduce the width of the rows. I don't know a whole lot about baseball so I don't understand what those fields are storing, but I can guess that almost all of the fields in your table don't need to store numbers as high as 2 billion. I think I counted 88 fields for about 352 bytes per row. Changing them to or could save 180-260 bytes per row. Along similar lines I think there are 28 fields devoted to ids of umpires, managers and pitchers. Perhaps if this data is infrequently queried it could go into another table with the same primary key; only join the tables when necessary. Maybe some other fields too. If you could do both of these then scanning the table would probably be far quicker which can make up for be fact that your queries seem very difficult to index for. 

You don't want your test database to retain the same internal id number as the production database. Hence it would be best to use RMAN's command DUPLICATE, because it sets a different id (and also a new database name). This command is specifically designed to do what you require. 

In case you specify each block is read once and written two times to backupset copies. The two backupset copies are supposed to be bit-to-bit identical. Both copies have the same backupset key (BS_key) in RMAN. You cannot mix tape and disk copies - either both copies go to or both to . 

Jay, this isn't officially documented, so I'm speaking only from my own experience. In RMAN, the command is synonymous with . Also the command is synonymous with . I'm not sure about ; it might be also a synonym of , although I've never tested the latter. In your scenario, the former would work as expected. In particular, neither or require all the datafiles to come from "a single backup of database" (from a single run of ). Actually, RMAN doesn't even have a concept of "a single backup of database". 

In some versions of Oracle, you cannot put space between the beginning-of-line and the WALLET_LOCATION keyword, and you must put space between the beginning-of-line and the definition of a wallet. Your snippet indicates that you failed at one of these things. I think they removed this silly requirement starting from some Oracle version, but better safe than sorry. Good: 

XE does not support Streams, as officially documented. SE and SE1 support Streams but without redo capture. EE and PE (Personal Edition) fully support Streams, and also support Logical Standby. 

Verify here you have had only a single control file and not two or three of them. If you have had more than one control file, then this instruction is not for you. 

No. If the datafile has been occupied by a partition of a table, you need to ALTER TABLE EXCHANGE PARTITION with some empty dummy table. Then drop the exchanged table. Then rebuild the invalidated indexes. This works if you don't have foreign keys to the table. This is quite a troublesome operation. Then you are free to drop the corrupted datafile. 

Any information that has a 1:1 relatatuonship to the patient can go into the patient table, ie stuff like name, birthdate, blood type, gender... all of these things the patient can have only 1 of so you dont need to worry about supporting multiple records in the same table for the same patient because all details can be stored in a single row For 1:Many relationships, this is where you include the patient id as a foreign key. So for example maybe you have a visit table that holds data like room, date&time, facility, doctor (if only 1 doctor will ever be assigned to a particular visit). A patient can have many visits, but each visit only has 1 patient,thus the 1:Many relationship. Since visits must be for a valid patient, this is where the foreign key checks referential integrity because you wouldnt want a visit record with a nonexistant patient id Testing would be a good example of a many:many relationship as it could hold many (types) of tests and each patient could have multiple tests. Here you should but specifics about the test itself in a test table (cost, result eta, test type) and then make a patienttests table to be the bridge between patients and tests. Here for patient id and test id would be foreign keys, but usually also participate in a multi-column primary key. If patients could only have each test type once, then a patient id+test id orimary key would be unique and thus serve as a suitable primary key, but since patients could be retested a 3rd column like date or visit id would be necessary to make that patient-test record unique. Read up on database normalization. Its going to take some practice and it might seem like you are storing redundant data at first but once you understand the normal forms you will understand how to properly define the relationships between your tables and when to put data in the same table vs create a linked table with foreign keys 

I would recommend looking at circular replication, where all servers are connected in a ring, and each server is slave to previous and master to the next, so any change in 1 replicates all the way through the ring. I've used this at my work to link 3 servers (one external webserver, 1 internal US wamp server, 1 Asian office wamp server). It was fairly easy to set up and the only problems I've had was when the asian office was not reachable for 2 whole days due to widespread internet outage in the area. As soon as it came back up, the replication resumed. These 2 links were particularly helpful for me: $URL$ $URL$ as was the replication chapter of High Performance MySQL: Optimization, Backups, and Replication, which also had some different replication schemes you might find interesting if circular is not suited for your needs.