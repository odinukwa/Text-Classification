You could always go for the "less is more" approach and use as little and as simple artwork as possible. Retro-style vector graphics are pretty popular these days, so there's plenty of inspiration to get there. Just draw some lines and make 'em glow a bit. 

You could consider running a simple PID controller in your game. It's simple to implement in a function like the one you have already. By tweaking the parameters (or computing them, there are many techniques) you should be able to get a pretty neat behaviour. Be sure to run your physics loop with a fixed time step though, as this is necessary to achieve stable regulation when implemented with discrete/digital logic (as oppossed to analog circuits....) However, some non-linear daming that Lunin suggests might be an option. That would allow the chopper to "soft-snap" to the target height. It depends on how "physics-y" you want your game to behave. :) 

Render a large quad (with your texture) to a smaller render target, performing whatever blur/downsampling algorithm is appropriate. I.e. for each target pixel, sample the number of texels from the source you'd want to combine. The simplest (and thus fastest, but ugliest) is the box filter, which usually uses 4 samples from the large texture and put their average into a single texel/pixel in the target. Repeat this step until destination is 2x2 to get all mip-map levels for a texture. There are two-pass techniques that are more efficient if you don't need the intermediate textures, and just a result, see this gamasutra article. 

But many API are Java only (also available via JNI). NDK 5 version is the first usable for C++ developers because it offers: 

I'm working on a game which can't run at Full speed on some devices. On Tegra2, with many optimizations, performance is near 40 fps. The framerate is stable but animations aren't smooth enough, so i need a vsync. With 2.3 Android SDK, we can use EGL library natively. So i try to use eglSwapInterval but no success. In this GDC Paper, it seems that Tegra2 can do it. Ps: Thread.sleep() to force a constant FPS is not an acceptable solution 

You can use this extension: EXT_texture_format_BGRA8888. But, you need to check that your device can handle it. Galaxt Spica or Moment doesn't. Otherwise just do a conversion. In my engine, i swap BGRA to RGBA before loading into glTexImage. 

Note: old android gpus don't support multi context. So the opengl context is lost when you switch to another application => no solution available (You can hack to preserve your context on screen pause). Note 2: HoneyComb function is setPreserveEGLContextOnPause 

You should see some half transparency texture. Ps: Your result color will be darker, because it is a mix with color in backbuffer*0.5 and the gl_FragColor*0.5. Blending is done after the fragment in the OGLES 2.0 pipeline. Your equation is: 

You can use OpenGL ES 2.0 simulator on windows to try your code. ARM (Windows) or Imagination (Linux & Windows). On OS X, you can use iPhone simulator. 

For reading, it clearly depends on your platform, and what kind of input you want to read. Note that it's easy to convert one thing to another in your input layer. (I.e. poll and emit events to the engine, or listen to events and emit state to the engine.) For processing, there are a few different options: 

I used the textures from this file used in the GLUT Caustics Example for a game I did ten years ago. Might work for you too. It's an animation as a set of textures. Load them as a 3d texture for smooth interpolation when rendering, then use projective texturing to compute texture coordinates. The technique explained in the article (albeit with a pretty old OpenGL version, today you'd use a shader instead). 

There's been similar stuff in various games, where you character becomes harder to control when you're drunk or on drugs (GTA3 et. al.), where aim stability is affected by experience/etc and also where the screen display is severely affected by different things (many RPG-FPS:es has this). I suggest you research that and see if it makes for a good gameplay component. It will make users be frustrated if done improperly, so careful tuning is required. Usually challenging, but overcome-able (...) gameplay mechanics are good. So a dim view, or laggy/overshooting (but predictable) mouse pointer may work well, but be careful with randomness. Game outcome based too much on chance aren't that fun (for most of us at least, some people enjoy bingo... but these rarely buy videogames). Personally, I enjoy "bad control" or "random jittery targets" as an occasional change to the regular gameplay, but I don't think I'd enjoy having it as a core gameplay feature. 

$URL$ This is still how networking is done in RTS games. P2P is also the normal way of handling connections. Using a lock timestep model however results in the irritating case of desync and cheating handling. There is good way of recovering when a desync happens and all RTS games simply says "Quit the match". Bug tracing desync errors is also a nightmare. 

When creating your own model for a weapon, say the M4 carbine, and using the model in your game. Do you need a license to use it commercially? I know that racing games like GT5 has a license for each and every car, but the same apply for weapons? 

It really depends on what you want to do. Is it a game? Then use an engine like Unity. If you want to learn 3D programming and math from the ground, writing your own tech demos could work. Remember that engines are tools, nothing more, nothing less. The DirectX vs OpenGL doesn't matter, pick one, learn it and you will easily change to the other. If you want to learn one of these start your own demo project from scratch, but don't expect being able to finish a game with it. If you just want to learn the graphics programming part of it, using any tool that supports writing shader code directly will work. Like Unity support Cg. Note also that Cryengine is only just released. It doesn't have a large community or documentation yet. Unreal, while maybe more limited, does give you that. 

In the vertex shader, you can use Texture too. This is the "VTF" tricks. This is used in GPU Particle engine. Look this document: Nvidia VTF Introduction 

You should search Toon Shading too. For english readers, a short tutorial. For french readers, there is a great tutorial. 

You can use a static VBO to send these data one times. If you need advanced physics, this is probably not the solution and you must use the CPU. With Neon instructions, you can have a great speedup. Warning the Tegra2 (available on few android tablets) doesn't support this instructions set. 

Please remove the MipMapping flag for your texture... You need glGenerateMipmap because you use MipMapping and OpenGL need a smaller texture. On bad cards(INTEL), GenerateMipmap is a costly operation. This operation must be called one times. Add this instruction when you load your texture after glBindTexture : 

Did you use my port of irrlicht for android ? For 2d sprites on Android and iphone, i use the same tricks as you: batching. I try many solutions in OpenGL ES 1.x and 2.x: 

I tried to backport modifications but it is now two distincts Pipelines. My port of Irrlicht is not complete but usable. Other developers have used it on market. As i said to Irrlicht developers, it will be better to use NativeActivity for an official port (available with 2.3 devices). 

Android APIs are Java. Since 2010, Google provides the NDK (a SDK) for C/C++ developers. The NDK offers two ways: 

James reponse only relates to PC and not for the implementation on the specific platforms. While all engines abstract the platform for the far majority of the game code, some parts have to be written per platform. This includes all I/O including network, rendering, audio, device input & I think video output. Compare the rendering code for say Unreal on the Xbox and PS3. The Xbox uses the Xbox DirectX version, while the PS3 uses libgcm (the OpenGl library is too slow). To simplify it a bit, on all platforms the gameplay programmers only see a "AudioSystem.PlaySound(SoundName here), while for each platform they function internally would call the platforms API for sound output. See also Tatrad's comment for more programming. 

Neither. The only thing you should send are the commands. Example: These 20 units should move to (X,Y) and then let each player figure out how they get there. The tricky part is making sure they all do the exact same thing. To achieve this a lockstep model is used, the links below should explain it in detail. Also, you should only sync the important pieces. Anything that doesn't change the gameplay shouldn't get synced. Animations in RTS games is usually only for the visual side. Another thing, RTS games are usually not client-server, but P2P. That way one of the players can't cheat because when any inconsistency is detected, you simply disconnect. Here is something to help you get going: $URL$ $URL$ $URL$ 

Use OpenGL Extensions Viewer to know OpenGL versions supported by your Hardware. Start OpenGL on OS X Use XCode 4.1 (4.2 beta for Completion with C++/C). They are samples provided by Apple for AGL, the link between OpenGL and Window system. 

I'm working on iPhone and Android but OpenGL ES is the same. So on mobile Platform (and Destop too), you must use DrawCalls carefully. I try to use < 50 to render a scene. For my sprite engine on OpenGL ES 1.x, i use an unique coordinates system for the rendering function. So for each sprite and at each frame, i compute its positions in this coordinates system. That's a lot of operations for CPU but i can use one glDrawElement for all sprites using the same texture. I have two categories of sprite: 

Do you want to synchronize on vsync ? There are differents solutions depending on your platform. Search vsync on google. On directx, you can limit on fullscreen app with D3DPRESENT_INTERVAL_ONE or use WaitForVerticalBlank on windowed app. Look this article 

For 3d physics, you can use 3D Physics Engines as Bullet, Newton or O.D.E. It is probably at first sight overhead... but you can use it for many great effects or add physic in your gameplay. You can use PAL to abstract the Physics Engine. 

Languages are only tools... So use them wisely. To create a good game, it can be easier to use XNA or Unity3D. Mastering C is a good first step, but you must learn C++, D, python, lua ... C++ is a very difficult langage. So use it carefully.