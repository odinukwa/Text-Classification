I don't have first hand experience with it, but I'd like to mention a framework I've read about: $URL$ Quoting the about page: 

In which case the answer would simply be (3) - the letter d is the fourth element in the matrix starting from the top and to the right (once again, zero based). Conversion You can convert from a (X,Y) pair to a simple (index) by doing: 

Context Old Lucas Arts (ScummVM era) point and click graphic adventure games used precomputed pathfinding. Here's a rough outline of the technique. Step 1 The floor in each room was divided into what they called "walk boxes", which were pretty much equivalent to nodes in a navigation mesh, but limited to trapezoid shapes. E.g: 

Besides reading this book, I also complemented my learning with articles from the official App Hub Education Catalog which you can find here: 

All the other classes take the buffer as a parameter to the method, and rendering to it is as simple as doing, for instance: 

Disclaimer: I'm not an artist so this is just programmer's art knowledge. You're having the grid effect in your example mostly because of that lighter patch of grass on the bottom edge of the tile: 

Rendering Points - Method 2 (Small Line with Primitives) In the comments, eBusiness raised the following question: 

Updated fiddle here. Edit 2 Yet another improvement, this time to the entire mouse move event handler (assuming the changes above are already in place): 

TL;DR A simple is enough to store all the information you need. Read on for the details. Context I'll drop in a little trick here then. Are you aware that when working with 2D matrices there's a way to index them with a single number, instead of having to provide a (x,y) pair? For instance, where is the letter d in the following matrix? 

And you can find a whitepaper describing the technique in detail here. The downside is that it requires a geometry shader. 

It's been more than a year since this topic was created, and since then there's been quite a bit of development on the XNA side. For instance, here's a list with a few popular XNA games that have been released for PC and are currently being sold on Steam: 

This is actually just a 90 degrees rotation matrix. You could concatenate this matrix at the end of your previous transformation, so that the conversion is done automatically as part of the matrix multiplication. Or, alternatively you can just do it manually at the end like: 

In other words, in some games it's possible for objects to depend on each other and require a specific order of updating. In this scenario, you might need to devise a more complex structure than a list to store objects and their inter-dependencies. 

One effect that I think looks pretty cool for a top-down game taking place in the ground, is to create a texture which contains only the shadows formed by the clouds and wrap that over the scene. I've used that in this demo although the effect is subtle. As for the video you linked, I believe the effect is probably based on some sort of animated perlin noise so look into that. There are many resources on the subject online. 

And sometimes you don't need a process that spans several frames - a single frame is enough. The following makes that easy: 

If you're referring about not having to hardcode all of of those anchor points, you could move them to an external file, and after loading all of the images, just read and iterate through your anchor file and set the values. The file could look like: 

I've been using this method which was taken from Game Coding Complete to detect whether a point is inside of a polygon. It works in almost every case, but is failing on a few edge cases, and I can't figure out the reason. For example, given a polygon with vertices at (0,0) (0,100) and (100,100), the algorithm is returning: 

The three arguments taken by Vector are its (x, y, z) components. Here's a visual representation of a Vector in 3D space: 

But I'd recommend even more reading this series to get a solid grasp on C++. There's two books on general C++ and one on the STL. All I can say is that these remain to date my favourite C++ books. The books are divided into small sections that tackle specific C++ problems. And even if it's not a game programming book, it's where I learnt most of my C++. Game Programming Gems LINK 

Render all of the particles using additive blending to a separate texture (or render target) with its background cleared to transparent. Render that texture (or render target) on top of your scene using alpha blending. 

Since your sprites can rotate, clipping them manually won't be as easy as just moving your vertices and texture coordinates around. There are many cases where you'd actually need to replace a single vertex with two new vertices. But by doing so your primitive would stop being a triangle so you'd also need to triangulate the result, which is not simple. Check the following image for a clearer view: 

At this point, your list is empty, so your snake has no body. Let's say you want a snake of length 5 and the head should start in position (5,2) and grow towards the bottom. Just add those positions to the list when the game starts, for instance: 

Next you'll need to have a instance that matches your ground. The easiest way to calculate it is to use the constructor that takes three points on the plane, and passing it any three vertices from the ground object. Example of how to calculate the ground plane: 

Where horizontalDistance and verticalDistance are floats controlling the offset in world units from the character's origin. You may also add the scaling operation as in your example before the translation. And you might also want to change the object's rotation so that it remains fixed in relation to the character when being grabbed. For that try adding a rotation matrix before the translation with a magnitute of character.Yaw degrees or character.Yaw + 90 degrees or whatever fits your need. 

- Pushes a new state into the stack. - Replaces the current topmost state in the stack with a new one. - Removes the N topmost states from the stack. 

I know this is an old post, but for future reference, you should not implement a camera like this, i.e.a by offsetting all the objects in the world manually. That makes your life much harder than it has to be. That remains true for both 2D and 3D games. Implementing a camera should be done using a view matrix instead. You simply calculate a view matrix based on the camera's position and orientation in the world, and pass that matrix as a parameter to SpriteBatch.Begin. XNA automatically applies that transformation to everything it draws, which gives the impression you're "watching the scene" from the camera's point of view. Here's a writeup I did on the subject with a few extra catches: $URL$ 

No, I think your components should be as generic and reusable as possible. And the examples you gave certainly don't need specific components. Here's an example of the type of components you could be thinking about: 

Afterwards all you have to do is the fill the list with objects of any type that inherits from and when calling on them the program will automatically choose the right version for each object. No extra code needed: 

About character collisions with a wall, for instance (I'll use some arbitrary values as example): if you are 10 units (e.g. pixels) away from a wall, and a single step would normally move you 20 units in that direction, the correct behavior is for your character to move 10 units and stop there. If you cancelled the action instead, you'd remain 10 units away from the wall which is not what you'd want. One way to do this is to move the character by the full amount, then detect the collision and its depth i.e. how much the bounding boxes of the character and the wall are overlapping, and move the character back by that same amount. If you do this correctly you shouldn't be getting any "jiggle" behavior from your character, he'll just press against the wall and stop there. If he's jiggle'ing then you're probably moving him back too much (you're probably moving him back to position he was before the collision, instead of clamping it against the wall boundary). That being said, I usually see gravity being treated as a special case. In most implementations I've seen, the character stores an flag and gravity is only applied when that flag is false. Edit: I guess you could expand this last concept and create additional flags such as or , but only when the boundaries of the character and the wall match exactly. In that case you could perhaps bypass movement altogether. But if the boundaries are not matching precisely, you should let the movement take place and let the collision detection system resolve any intersections. 

The execution flow I'm picturing is for clients to recieve user input and send a notification to the server. Then the server validates it, and broadcasts an action to be executed by all the clients. It shouldn't matter if there is only one client (i.e. singleplayer) or multiple clients (i.e. multiplayer). 

Having these three, you can make the sprite move the in the specified direction by doing the following in the method: 

Ice is translucent so I believe the single most important thing you have to simulate in your shader to get realistic results would be subsurface scattering or SSS for short. SSS basically describes how rays of light penetrate the surface of translucent objects and scatter underneath it, being reflected multiple times in an irregular fashion, before finally exiting through a different location. Here's a picture that I think demonstrates the effect nicely: 

And if you're not using a view matrix... you should :-) Explanation The view matrix transforms coordinates from world space into view space. The inverse of this matrix does the opposite - it transforms coordinates from view space back into world space. Since your mouse coordinates are defined in view space, all you need to do is transform them with the inverse view matrix to convert them into world space. 

Finally, with this information in place, you only need to decide the maximum number of entities there can be in any cell (i.e the density of the cell) and start adding entities in random positions and using the probabilities above to decide the type of each of them. This will provide you with a nice mix of randomness, and at the same time clustering based on the rules you define when filling in the probabilities grid. 

Step 3 On the other hand, calculating the shortest path between two nodes was extremely fast and trivial, just a series of lookups into the matrix. Something like: 

Then, all of these have parameters that will vary from entity to entity. For example, and still thinking about the ball: 

Attempt #1 I couldn't find anything wrong with your camera class, but I found a few anomalies in your rendering code. As far as I could tell, your calculations inside the camera class are correct. Further more, even if you were calculating the camera position wrong, since the parameter is set to match the character's position, I think the model should still appear centered in view no matter what, which is not the case here. So I looked into your class and noticed some strange things. In particular these lines: 

But I warn you that it will perform extremely slow, so use it only as a test drive, and then switch over to the method. 

The MyLevel Class Here's the class that loads, stores and draws the level. For now, I omitted the implementation of the method purposely, but I'll show it later. For now notice that the class is basically a wrapper around an array of lists of sprites. Each position in this array is one layer from the level, and the constructor takes how many layers exist in the level. There's a method that lets you add new sprites to a specific layer, and the method simply iterates over the sprites in each layer drawing them in order. 

Making the Shader Work with SpriteBatch As for writing a pixel shader that works with , there's really not much to say (would be a different story if you were writing a vertex shader though). Check this sample to get you started. I'll copy one of the examples here: 

Then just tweak the variable to your liking. And of course you can inline all of those calculations in a single line of code if you wanted. I just presented the steps separatedly so I could comment each of them, and for clarity. If this is not what you meant, then I don't see how you can have an object that is following both the player and the mouse at the same time, unless it's always drawn half way between them or something similar. Or perhaps the reticle's X coordinate follows the mouse, while the reticle's Y coordinate is fixed relative to the player? That's another possibility. 

To be more precise, if I needed to recreate this functionality from scratch in another API (e.g. in OpenGL) what would it need to be capable of doing? I do have a general idea of some of the steps, such as how it prepares an orthographic projection matrix and creates a quad for each draw call. I'm not too familiar, however, with the batching process itself. Are all quads stored in the same vertex buffer? Does it need an index buffer? How are different textures handled? If possible I'd be grateful if you could guide me through the process from when SpriteBatch.Begin() is called until SpriteBatch.End(), at least when using the default Deferred mode. 

There's also a bigger problem at hand which is that when separating the circles you could be creating new intersections between circles that you already handled earlier in the loop. And to close it off, here's a simplified and optimized version of your loop above (although it still doesn't solve the problem I just mentioned above): 

That's not really much of a problem here because your foot sensor collision response will always be moving the character up. You'll be handling collisions with walls separately anyway, using the middle sensor. I've made this picture for another question but I'll repost it here for context: 

You're pretty much asking us to program the entire gameplay logic for you. You should tackle one problem at a time, and post a question for one specific problem. I'm just going to answer the question on your title (How to move a sprite in a straight line) since that's the more concrete problem. First define variables for the , (which should be normalized) and of your sprite. You probably already have the position since you're drawing the sprite on screen. 

I think the way that makes more sense is to have each circle move back half of the depth, instead of moving only one of the circles. That should be as easy as adding half of the penetration depth to each circle but in opposite directions: 

And now the XNA side code. When you create the you must let it know what the viewport size is, because it's needed by the vertex shader (in fact it's needed by any custom vertex created to be used with because you need to do a viewport adjustment): 

For a comparison, see both of these links - D3DXMatrixPerspectiveLH and D3DXMatrixPerspectiveRH. Since DirectX is left handed, you'd normally use the left handed version which has a 1 in the third row fourth column. On the other hand, OpenGL and XNA are both right handed and I can confirm that the perspective matrices they generate use -1 instead, although OpenGL has it in the fourth row third column, whereas XNA has it in the third row fourth column like DirectX (column major matrices versus row major matrices). 

The first thing you'll want to calculate is the distance between both points, and a normalized vector containing the direction from start to end. Also, you should "snap" the object position to the point. This step is done only once, at the beginning: 

Validating Position requires basically comparing the camera's position against the corners of our limiting range. Since the limiting range is defined in world space, I get the camera's corner position in world space by multiplying Vector2.Zero by the inverse of the View matrix. Step 3) Apply the validations to the setters: 

As you can see I'm using vectors and linear algebra though, not trigonometry, so you'll have to adapt it to your needs. Both and are normalized vectors pointing in that particular direction. Throttle, Brakes, Steering Other than that the only other relevant part was how I applied the forces to the car to make it move and steer: 

But since it would be troublesome to implement these interfaces everytime, XNA already provides two implementations which you can just inherrit from and they're ready to go. They are: 

For instance, with N equal to 3 you would get something like the image below (I've painted the middle section in red so that you can see where the repetition occurs). Then, simply changing the value of inc would make the road scroll in one direction or the other, depending on whether you incremented or decremented it. 

Depends on your spritesheet and how you'd like to refer to each sprite. Horizontal Strip, Evenly Spaced