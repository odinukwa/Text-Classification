The features you described are known as low variance features and in general you should remove those features. The rationale behind this, is that low variance feature contain less information. See this for a succinct explanation and some code in python. Be sure to normalize your features. One of the advantages is to speed the training phase. 

When $T$ gets larger, i.e. $$T \rightarrow \infty $$ the probability distribution resembles the uniform distribution, so $q_i = \frac{1}{n}$. You can find the proof here, as well as some other interesting properties. Given the previously mentioned fact, I guess he is referring to smoothing in the sense that the noise if left out and what remains are the important patterns of the data, that is the distribution is made less 'spiky' as @Emre mentioned. 

One simple example of an application of citation analysis is ranking. Imagine you do a keyword search over a collection of scientific articles, How do you rank the result set from most relevant to least? A measure one could use is the amount of citations an article has or the quality of the citations it has and also the quality of the articles the paper refers to. This problem is closely related to the problem of ranking web pages according to its hyperlinks. 

creates a regex that finds the word blood ignoring case. The function change, replace the input text with 'Blood test' in case the string 'blood' was found. Finally you used the apply method from pandas DataFrame to transform the column. Finally the apply method, as the name suggests, 'applies' the function change to every value in the 'title' column. More info on regular expressions using Python and pandas apply method can be found here and here. If you want to know more about text processing in Python I would recommend you take a look at the pointers in this question. 

The main difference between explicit density models and implicit density models is that explicit density models, use an explicit density function and implicit density models don't. In other words explicit models assume some prior distribution about the data. For example the work of Dinh et. al., which in the reference link is classified as an explicit model, use an isotropic unit norm Gaussian as the prior (page 7, of the above link). One example of implicit density model is the work of Bengio et. al, also mentioned in the reference link, to estimate the distribution of the data they learn the transition operator of a Markov chain whose stationary distribution estimates the data distribution. 

I would use the first approach, given that both train and test are known, there is no need of generalization i.e. you don't expect unseen vectors. In order to avoid the problem you mentioned, you have to find the most similar vector to a vector in considering only vectors in . For example: 

Yes, your method is valid and it has been studied before it is known as Mean of Word Embeddings (MOWE) or Sum of Word Embeddings (SOWE), although your method is more a weighted mean of vectors. I think that a good starting point for knowing more about the academics of the method is this paper: How Well Sentence Embeddings Capture Meaning. It discusses your method and give some pointers to other papers that also discuss the validity of the method. 

A great source is the personal page of Xavier Amatriain (former Head of Engineering at Netflix and Quora). There are several links at publications detailing the system and architecture of recommender systems. In particular you could take a look at this Building industrial-scale real-world recommender systems, there is also this talk Lessons Learned from Building RealÂ­-Life Recommender Systems and this blog post System Architectures for Personalization and Recommendation 

This problem is an instance of the more general assignment problem. In the assignment problem you have: 

Beyond its use in deep learning, backpropagation has been used in many other areas, ranging from weather forecasting to analyzing numerical stability. In fact, the algorithm has been reinvented several times in different fields. The general, application independent, name is "reverse-mode differentiation" [3]. The modern version of backpropagation, also known as automatic differentiation, was first published by Seppo Linnainmaa [1] in 1970. He used it as a tool for estimating the effects of arithmetic rounding errors on the results of complex expressions [2]. Gerardi Ostrowski discovered and used it some five years earlier in the context of certain process models in chemical engineering [2]. In the sixties Hachtel et al. considered the optimization of electronic circuits using the costate equation of initial value problems and its discretizations to compute gradients in the reverse mode for explicitly time-dependent problems [2]. Others researchers that discovered it include Bernt Speelpenning. He arrived at the reverse mode via compiler optimization when asked to automatically generate efficient codes for Jacobians of stiff ODEs [2]. More info can be found in: Deep Learning in Neural Networks: An Overview and in Who invented backpropagation? and references therein. [1] Who invented backpropagation? [2] Who Invented the Reverse Mode of Differentiation? [3] Calculus on Computational Graphs: Backpropagation 

The line is the one that transforms your dataframe into a dict. For more on transforming a dataframe into a dictionary see the documentation, also this question provides different ways of transforming a dataframe into a dictionary. For reading excel files, instead of csv files, see this. 

This question is a bit tricky to answer, it will depend on your usage of Python, but Python is not a fast language per se. However, the pandas library in Python have been reported to handle tables of 33M-100M rows, see this. I myself have used to handle around 10M rows from a Postgres table. For a detailed experimentation using pandas, see this. In the link they apply some operations on datasets of 88M rows and 74 columns. 

I suggest you use a weighted per-attribute similarity, for instance let a and b a pair of tuples representing the attributes of some car A and another car B. For example: 

In standard agglomerative clustering you receive a matrix $M^{n \times m}$ representing $n$ samples of dimension $m$ that you want to cluster. In feature agglomeration the algorithm clusters the transpose of the matrix, i.e. $M^T$ so it clusters $m$ samples of dimension $n$, these samples represent the features. The default distance used to cluster the features (samples in the transpose matrix) is the euclidean distance, but you can also use l1, cosine and others. For example suppose you have 3 samples of dimension 3 (a matrix 3x3 matrix):: 

Given that K=2, the possible values for c(x, z) are 00 = 0, 01 = 1, 10 = 2 and 11 = 3. Then considering the target expression and all the values of z above you have the following, (for x = "this sentence"): 

A simple approach could be the following: suppose $i \in \{0,1\}^d$ is the vector you want to predict which of the $0$ entries could be $1$ and $j \in J$ the rest of the feature vectors. Take the $k$ nearest neighbors, under some suitable distance (Jaccard, Hamming, Manhattan distance). For each $0$ entry the probabilities could be the percentage of the $k$ nearest neighbors that have $1$ in the corresponding entry. This problem has been extensively study in the collaborative filtering community. The best known example being the Netflix Prize. This blog post provides a nice explanation of this approarch for binary data. Another, more involved, approach is matrix completion, in particular check this reference. If you are into deep learning check this. 

Main Idea: The main idea is the you could measure how good is the output and the input of your model simply representing it by some mathematical object, for example a vector in a high dimensional space and then using some error function to measure the fitness (how good your model is performing). A possible formalization The scenario your describing fits in a more general optimization function, the most general optimization scenario is; $$ min_{x \in X} f(x) $$ where $X$ is the domain. In the case of image processing and computer vision $x$ is a matrix of pixels, this matrix of pixels can be represented by a vector $x \in \mathbb{R}^{m \times n}$. In the case you describe you could also represent the input (painting) as a vector $y\in \mathbb{R}^{m \times n}$. Then $f$ coul be RSME between some $x$ and $y$, i.e. $f(x) = {\| y - x \|}_2$. Notice that $y$ is given and it does not change. Now the key question here is how to represent a stroke, or more formally a function the values of $x$. A very basic idea can be represent the stroke by the following tuple $(o, e, t, c)$ where $o$ and $e$ are two dimensional points, the origin and the end of the stroke; $t$ is the thickness of the stroke and $c$ is the color of the stroke. Let $S$ be the space of all the strokes, assuming the thickness and colors are finite, S is finite. The possible pairs of $o$ and $e$ are finite namely all the pairs of possible points in $m \times n$. Now let $S^k$ be the composition of $S$ with itself $k$ times. Finally the problem can be represented the following way: $$\min_{s \in S^k}{\| y - t(s, x) \|}$$ Where $t$ is the function that applies $s$, that is a number of different strokes to an empty canvas $x$, by empty canvas I mean a matrix full of zeros. Summarizing the ideas expose above are a possible formalization of your problem, of course is not the only one. The main issue is that the robot does not "learn" is simply computes the optimal set of strokes to apply. Other ideas Another possible approach is to use reinforcement learning, this learning paradigm does not needs labeled training samples, it relies in a reward function $R$ to guide the learning process. Also if defines a set of states and actions the agent can be or do. The states could be the strokes and the actions add another stroke, the reward function can be a variation of the error function. Also I am far from being an expert in reinforcement learning I guess is worth looking into it. A proven approach The problem you describe has been demonstrated in real life. See this paper: Feedback-guided Stroke Placement for a Painting Machine. The paper demonstrates a system that describes your scenario, also see this site for more work of the authors or this for the site of the project.