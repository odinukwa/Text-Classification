We did some research on the problem of proving in tree-like Resolution whether a fixed graph $G$ has a clique of size $k$ (where $k$ is usually small). In particular we discovered that refutations of size $n^{\Omega(k)}$ are needed for a large class of graphs. You can find the paper Parameterized Complexity of DPLL Search Procedures at this link. 

I'm sure you know the following paper, but I put a link to it because other readers may be interested: Interpolation by Games This paper is an attempt to use the communication complexity framework to show lower bounds for cutting planes. The protocol is used to produce an interpolant circuit for unsatisfiable CNF: $$ A(x,y)\lor B(x,z). $$ Player $A$ gets input $a$ and $y^a$, player $B$ gets $b$ and $z^b$. If there is a shallow tree-like proof in cutting planes then the two players have a communication protocol such that 

Resolution is a scheme to prove unsatisfiability of CNFs. A proof in resolution is a logical deduction of the empty clause for the initial clauses in of the CNF. In particular any initial clause can be inferred, and from two clauses $A \lor x$ and $B \lor \neg{x}$ the clause $A \lor B$ can be deduced as well. A refutation is a sequence of deductions which ends with an empty clause. If such refutation is implemented, we can consider a procedure that keeps some clauses in memory. In case a non-initial clause must be used again and it is not in memory anymore, the algorithm should must it again from scratch or from the ones in memory. Let $Sp(F)$ the smallest number of clauses to be kept in memory to reach the empty clauses. This is called the clause space complexity of $F$. We say say that $Sp(F)=\infty$ is $F$ is satisfiable. The problem I'm suggesting is this: consider two CNFs $A=\bigwedge_{i=1}^m A_i$ and $B=\bigwedge_{j=1}^n B_j$, and let the CNF $$A \lor B = \bigwedge_{i=1}^m \bigwedge_{j=1}^n A_i \lor B_j$$ What is the relation of $Sp(A \lor B)$ with $Sp(A)$ and $Sp(B)$? The obvious upper bound is $Sp(A \lor B) \leq Sp(A) + Sp(B) -1$. Is this tight? 

Background The $\mathcal{H}$-factor problem (a.k.a. the degree prescribed factor problem, or the degree prescribed subgraph problem) is defined as follows: Given a graph $G=(V,E)$ and a set $H_v \subseteq \mathbb{N}$ for each vertex $v \in V$, does $G$ contain a spanning subgraph $F$ such that $\operatorname{deg}_F(v) \in H_v$ for all $v \in V$? (I would also say that $H_v \in \mathcal{H}$ for all $v \in V$, but I have never seen it stated this way. Thus, the $\mathcal{H}$-factor problem is defined by $\mathcal{H}$ and the input is a graph $G=(V,E)$ and a mapping $f : V \to \mathcal{H}; v \mapsto H_v$.) A spanning subgraph is also known as a factor, hence the name. This framework of problems captures many classic problems. For example, when $H_v = \{1\}$ for all $v \in V$, the problem is to determine if $G$ contains a perfect matching, also called a 1-factor. Question What is currently known about the complexity of this problem for different $\mathcal{H}$? What about the special case when $\mathcal{H}$ is a singleton set (so $H_v$ is the same for all $v \in V$)? Strongest Results I Know Tractability: If each set in $\mathcal{H}$ does not contain two consecutive gaps, then the $\mathcal{H}$-factor problem is in P (Cornuejols 1988). A integer $h$ is a gap in $H \subseteq \mathbb{N}$ if $h \not\in H$ but $H$ contains an element less than $h$ and an element greater than $h$. Hardness: There exist some $\mathcal{H}$ such that the $\mathcal{H}$-factor problem is NP-hard (Lovasz 1972). See (Szabo 2004) for a modern reference that cites these two results. 

Notice that for pushing changes to your central repository you first have to commit to your local repository and the you have to push all the commits (even more than one) to your central repository. Create a user-local repository 

I notice that no one is giving the "small" tutorial for GIT, so I'll try to cover it. GIT is faster and superior to SVN, but maybe it is easier for you to get an SVN account on a server at your university, since SVN is well established. Also may of your collaborators would know how to use it. Even if you collaborate using SVN you may want to use GIT for your own local versioning (I do!). First bit of warning: GIT is very powerful and for basic usage is only slightly harder to use than SVN (e.g., one option to be added in the command line; two steps commit for central repository). Second bit of warning: GIT has the philosophy of considering a set of changes to be atomic (a $\Delta$ as they call it) even if the set spans several files. Also in GIT you have the notion of local repository and central repository. GOOD: You can work offline. BAD: You need two steps commit to a central server. Basic commands assuming you already have a repository 

I'm not sure that I understand your question. The way I understand it leads to the following construction which is an invertible function from $\{0,1\}^n$ to 3CNFs: Input: $x \in \{0,1\}^n$ ($x$ is indexed from 0 to $n-1$) Output: a 3CNF with $\frac{7}{3}n$ clauses (assume 3 divides $n$) For $0 \leq i < n/3$ pick input variables $x_{3i},x_{3i+1},x_{3i+2}$ and add to the final formula the seven clauses on these three variables which are satisfied by the input. The output 3CNF is clearly satisfiable only by the assignment. This procedure is well defined for every input and it is invertible. Unfortunately these formulas are easy to recognize, so they are easy to solve. Another RANDOM process is to add to the formula random clauses among the ones which are not falsified by the given assignment. The formula will stay satisfiable, but no other assignment will satisfy it if you add many generated clauses (I guess $100n$ would be more than enough). Formulas generated in this way are usually hard to distinguish from purely random 3CNFs with a similar clause/variables ratio (which are unsatisfiable with high probability). 

This problem is tractable. Let $G = (V,E)$ be the input graph with $|V| = n$ and let $e$ and $o$ be the number of vertex-induced subgraphs of $G$ with an even and odd number of edges respectively. Of course, $e + o = 2^n$. In polynomial time, we can compute $e - o$, which I explain below. With two equations and two unknowns, we can solve the linear system to determine the value of $e$. From $G$, we create an instance of a counting constraint satisfaction problem (#CSP). Every vertex in $V$ is a Boolean variable and every edge in $E$ a constraint $f$ that depends on its incident vertices. The constraint $f$ evaluates to 1 unless the both vertices are assigned 1, in which case, $f$ evaluates to -1. The symmetric notation for this constraint is $[1,1,-1]$. Now the answer to this #CSP instance is (by definition) $$\sum_{\sigma : V \to \{0,1\}} \prod_{e \in E} f(\sigma|_{I(e)}),$$ which is a sum over all vertex subsets, the product of the outputs of every constraint $f$, where $I(e)$ is the vertices incident to $e$ and $\sigma|_{I(e)}$ is the restriction of $\sigma$ to $I(e)$. Fix a subset of $V$. Assigned 1 to the vertices in the subset and 0 to the vertices not in the subset. If either vertex incident to the same edge is assigned 0, then this edge is not in the vertex-induced subgraph and the constraint $f$ on this edge contributes a 1 to the product, which has no effect. If both vertices incident to the same edge are assigned 1, then this edge is in the vertex-induced subgraph and the constraint $f$ on this edge contributes a -1 to the product. Vertex-induced subgraphs with an even number of edges contribute a 1 to the sum while vertex-induced subgraphs with an odd number of edges contribute a -1. Thus, the answer to this #CSP instance is exactly $e - o$. Since the constraint $f$ is affine, this #CSP is tractable. The polynomial algorithm for any set of affine signatures is given in The Complexity of Complex Weighted Boolean #CSP by Jin-Yi Cai, Pinyan Lu, and Mingji Xia. There may be a simpler algorithm for this particular case. If such an algorithm is known, it is probably contained in one of the references cited in the above paper. 

which have exactly |V|, and |V|+1 = O(|V|) edges, respectively. This works for an arbitrary number of graphs, as long as you fix the number of nodes. If you restrict the number of edges not to O(|V|) but to |V|, you get a biggest lower bound of 2 for graphs of at least 4 nodes. EDIT Since the first and second example have diameter 1 with $|E| \leq |V|$ (so, clearly $|E| \in O(|V|)$) the statement that each such graph has at least diameter 2 does not hold. 

Problem I have an undirected graph (with multi-edges), which will change over time, nodes and edges may be inserted and deleted. On each modification of the graph, I have to update the connected components of this graph. Properties Additional properties are that no two components will ever be reconnected. Obviously, the graph can have cycles to an arbitrary amount (otherwise the solution would be trivial). If an edge $e$ does not contain a node $n$, it will never adopt that node. However, if $n \in e$, it can change to $n \notin e$. Approaches I have two possible approaches so far, but as you will see they are horrible: Slow state-less I can search (dfs/bfs) the graph starting from the modified element(s) every time. This conserves space, but is slow as we have O(n+m) for each modification. Stateful fast(-er) (?) approach I can store all possible paths for each node to all possible nodes, but if I see it correctly, this will take O(n^4) memory. But I am not sure how the runtime improvement is (if there is one at all, because I have to keep the information up-to-day for every node in the same component). Question Do you have any pointers, how I can learn more about that problem or perhaps some algorithms I can build on? Note If there is a vast improvement in runtime/memory I could live with a non-optimal solution that sometimes says two components are one, but of course I would prefer an optimal solution. 

The referee is turned into a probabilistic protocol for inequalities. In this way it is possible to turn lower bound for tree-like probabilistic protocols in the communication complexity framework into lower bound for tree-like cutting planes proofs. If we had lower bound for communication protocol of the form of a PLS, then we would get lower bound for dag-like cutting planes proofs. Notice that this technique does not depend on the actual inference rules of cutting planes. If we assume the inference rules to be (1) positive combination (2) integer division with floor we can build the monotone interpolant circuit using Pavel Pudlák argument. 

You need to understand that $\mathsf{CSP}$ problems have a structure that generic $\mathbf{SAT}$ problems do not have. I will give you a simple example. Let $\Gamma=\{\{(0,0),(1,1)\},\{(0,1),(1,0)\}\}$. This language is such that you can only express equality and inequality between two variables. Clearly any such set of constraints is solvable in polynomial time. I will give you two arguments to clarify the relation between $\mathsf{CSP}$ and clauses. Notice that all that follows assumes $\mathbf{P}\not=\mathbf{NP}$. First: constraints have a fixed number of variables, while the encoding of intermediate problems may need large clauses. This is not necessarily an issue when such large constraints can be expressed as a conjunction of small ones using auxiliary variables. Unfortunately this is not always the case for general $\Gamma$. Assume $\Gamma$ to just contain the $\mathsf{OR}$ of five variables. Clearly you can express the $\mathsf{OR}$ of less variables by repeating inputs. You cannot express a larger $\mathsf{OR}$ because the way to do it using extension variables requires disjunctions of positive and negative literals. $\Gamma$ represents relations on variables, not on literals. Indeed when you think about 3-$\mathbf{SAT}$ as a $\mathsf{CSP}$ you need $\Gamma$ to contain four relations of disjunction with some negated inputs (from zero to three). Second: each relation in $\Gamma$ can be expressed as a batch of clauses with (say) three literals. Each constraint must be a whole batch of such clauses. In the example with equality/inequality constraints you cannot have a binary $\mathsf{AND}$ (i.e. relation ${(1,1)}$) without enforcing a binary negated $\mathsf{OR}$ (i.e. relation ${(0,0)}$) on the same variables. I hope this illustrates to you that $\mathbf{SAT}$ instances obtained from $\mathsf{CSP}$s have a very peculiar structure, which is enforced by the nature of $\Gamma$. If the structure is too tight then you cannot express hard problems. A corollary of Schaefer Theorem is that whenever $\Gamma$ enforces a structure loose enough to express $\mathbf{NP\backslash P}$ decision problems, then the same $\Gamma$ allows enough freedom to express general 3-$\mathsf{SAT}$ instances. 

Neither, they are domain elements. Any two domain elements would do: $\{+1, -1\}$, $\{0,1\}$, $\{\text{cat}, \text{dog}\}$. Physicists have wonderful imaginations and thus name certain parameters based on their physical intuition for the behavior of nature. In this case, they interpret the states of the particles interacting in the Ising model as either spinning up or down. Furthermore, opposite spins produce opposite effects, such as their resulting magnetic fields being the negative of each other. Thus, the state of the particles (i.e. the spins) are succinctly represented in the model as either $+1$ or $-1$. Another good naming example from physics is in string theory. The equations that describe the motion of these exceedingly small "objects" reminded the physicists of the equations that describe the motion of strings. Thus the name. The Potts model is a generalization of the Ising model. One of the generalizations is that each particle can take one of $q$ values (i.e. the domain size is now $q$). By continuing the intuitive naming from the Ising model, these $q$ states are also called spins. 

Boaz Barak addressed this in a blog post My takeaway from his post (roughly speaking) is that we only know how to design cryptographic primitives using computational problems that have some amount of structure, which we exploit. With no structure, we don't know what to do. With too much structure, the problem becomes efficiently computable (thus useless for cryptographic purposes). It seems that the amount of structure has to be just right. 

As long as you have an unbounded call-stack size you can encode your tape on the call-stack, and random-access it by rewinding the stack-pointer without returning from the function-calls. EdIT: If you can only use the ram, which is finite, this construction does not work anymore, so see below. However it is highly questionable why your stack can be infinite but the intrinsic ram is not. So actually I would say you do not even can recognise all regular languages, as the number of states is bounded (if you do not count the stack-rewind trick to exploit the infinite stack). I would even speculate that the number of languages you can recognise is finite (even if languages themselves can be infinite, e.g. is okay, but only works for a finite number of s). EDIT: This is not true, as you can encode the current state in extra functions, so you can truly recognise ALL regular languages. You can most likely get all Type-2 languages for the same reason, but I'm not sure if you can manage to put both, the state and the stack-constent on the call-stack. But on a general note, you can effectively forget about the ram, as you can always scale the size of the automaton so your alphabet exceeds the capacity of the ram. So if you could simulate a TM with only a stack, Type-2 would equal Type-0, wouldn't it?