Check the SIDs of the accounts in SQL and AD before the SQL login deletion to confirm they are indeed the same and the AD admins didn't really delete and recreate the AD user account just telling you otherwise. Articles: $URL$ and $URL$ There may be a way to get both from PowerShell but confirm what the AD domain and forest functional levels are and research with your version of SQL Server for known bugs -- maybe it's time to upgrade/update one or the other. 

Use double backslashes [] in the folder path to separate folders rather than just one to escape the first backslash since by default a single backslash is used as a special escape character and ignored when used alone 

Restore it to a dummy DB, purge the data that you don't want them to have, make another full backup, drop the dummy DB, and then provide them the copy of the BAK file at that point. 

Additionally, not having DBO role permissions may mean. . . (Since you have so many different versions of SQL Server from 2005 - 2014, it may be best to have a small set of users test this initially to see who screams to iron out any kinks, etc.) 

This means if you want the XML element, etc. to have a value of rather than being blank, then your statement would need to use the function and say if the value is then replace with literal value to be as the actual XML value. 

Additonally, having db_ddladmin role permissions may mean. . . (Since you have so many different versions of SQL Server from 2005 - 2014, it may be best to have a small set of users test this initially to see who screams to iron out any kinks, etc.) 

Add the full path (example) where the mysqldump.exe is located to the environmental system variable of the OS where you're running this. Example: and then press enter to get this in the command window where you'd type 'mysqldump' as shown here and then press enter. Furthermore, you could put the full path to the mysqldump.exe in with double quotes around it and then press enter as well e.g. and then press enter. 

db_ddladmin vs db_owner From what I can tell from what I tested and read up on, for the most part your list looks accurate except DOES allow you to . I did confirm that the other security permissions you listed were indeed denied. Denied with DDLADMIN only: 

Consider testing with the parameter too and see what results you get with your logic. This may work for your need as well. 

SQL Server get drive space information, get volume space information, get disk space information, get disk free space, disk space allocation, report disk space, report storage space 

Noting that the. . . 1. will allow access to all tables 2. will allow , , and access to all tables 3. will allow access to all executable objects 

Yes, active transactions are included in transaction log backups and this is how the database restore option works. It's important to understand how database restore operations and options work in SQL Server that'll help you get a better understanding as well so I put another hyperlink at the bottom with nothing quoted for further reading on this topic. Below are some resources that give good explanations for this as well to help put all the pieces together. Some of the article may be a bit dated, but the explanations seems accurate and the concept is still the same for your inquiry. Transaction Log Backups 1 

This way your Reporting Services app server recycle operation happens every day at the usual and designated time per the value you set in the config file, then right after that happens (giving ample time for full completion) the dummy report runs before any production reports run for the day, and then every subsequent report for the next 24 hours runs as expected without needing to wait for the RS app server post 'recycle' load operations to complete. You also could leave out the PowerShell scripted solution altogether as well if this works. 

From the Manage Server Connections window click on the "MySQL Connection" that is giving you this error, then from the SSL tab you will want to ensure the Use SSL field has a value of If available so it only uses SSL if it's available or else it'll connect without SSL encryption. 

You can put logic in the stored procedure to and then that with the query that returns the other values from the other query in the stored procedure and ensure the very first row returned is 

I've copied the logic I've used with success on this sort of task below. I run the create table logic once (for both) but save it to a commented out or skipped SQL Agent step for future reference only. I shared both the and the capturing methods and logic below but be sure you're on the DB to run the processes as it's logic is implicit. Be sure to specify the table and DB Names in the processes since its logic is explicit. SP_WhoIsActive Table Capturing Create Table 

I use the below to get SQL Server OS drive partition\volume information SQL Server per instance in both GB and MB. INFORMATION: This is using a SQL system DM () and table with the to get the volume information from which that instance can see. It then does mathematic calcutations (e.g. dividing by 1024 a time or two or three or perhaps multiplying by 100, etc. as you see below in the statements) to these and lists in both MB and GB as and uses the function. This will get both and space space per disk partition in both GB and MB as well as the percentage of per disk partition using straight . 

Second Script Before you run the below TSQL, you will need to move the applicable physical data and log files to the new locations as you plugged into the first script. 

For the msdb SQL Server Agent roles, granting allows them the ability to manage jobs which only they own, and see the job history of those jobs too. To compare schema on all table of any DB, assuming you want to also allow them to have to all tables, the role should be fine per DB. Otherwise, if you want to be specific, then allow explicit on the schema per DB which you want to all them to compare and to the tables you want them to be able to compare the data. EXPLICIT EXAMPLES TSQL (per the article) 

Configure MySQL Workbench to not require SSL encryption If you get the MySQL Workbench error of "SSL connection error: SSL is required but the server doesn't support it" then you likely just need to change a setting that's defined within the MySQL Connections within MySQL Workbench. 

Log Shipping With log shipping and the DB staying in standby mode, it stands there waiting for new transactions from the primary to commit. You cannot make changes to the secondary DB without breaking the transaction log chain and thus breaking the log shipping entirely as it's no longer an accurate replica. 

Have you considered creating additional custom roles for more "all object" DB-level access that each person needs rather than granting them the role as that will probably give them more than they actually need to DB level objects as well. I usually give what's needed exactly and nothing more for them to do their job and if there's a "usual" or "standard" need for DB level object access to all objects in a DB, I create a custom DB role sort of like the the but see my below example. This way you can grant the people what they really need to ALL DB object in a particular DB if you're not getting object level explicit in your DBs for their security. 

Since you're running PowerShell through SQL Server from an agent job, you could try calling a PowerShell script with your saved PS logic in it rather than running raw PowerShell commands to see if that makes a difference for a potential workaround. Try explicitly putting the full OS path on the server to point to and then pass your PowerShell commands after that in case the issue has to do with environmental variables not working correctly for PowerShell within the shell. 

Some things to check, read up on, or try not knowing the Server OS version, etc. (Sounds like a Windows Update broke something with the OS and SQL error log is catching it (extended event notifcation) but perhaps not able to send a notification, etc.) 

Issues when Loading Data with MySQL LOAD DATA INFILE You appear to have a few issues going on here and to resolve you can make a few adjustments to get your data to load without error. I've source referenced and quoted the items in more detail below so you can read up on each for a more thorough explanation. In short though essentially you can: 

To Change Secondary DB with Log Shipping in Standby Mode The changes must occur on the primary DB first, and then those changes must be in a transaction log that is then applied to the secondary DB before the changes are effective on the secondary DB. 

If you really want to know why it's failing, here are some things to check with the package and how to troubleshoot to ensure it's not a connection or authentication issue. Look at the that appears just before the and change the properties for the FTP connection. This should include the , the the FTP server listens on, the , and . Ensure that all FTP attributes in these connection string properties are set correctly, and test from command line or an FTP client tool to ensure that whatever you have value wise in there also allows connection via that method to ensure it's not a password or incorrect value issue of what you're connecting to. 

Create the [user account object] service account in AD () Create a SQL login i.e. the service account in #1 () Create a SQL credential with that same () account credentials, Create a SQL Server Agent Proxy account to use for the "Run As" from the SQL Agent job to execute PowerShell 

For the security credential/context which the application uses to authenticate to the DB, set an EXPLICIT DENY to it on the table to not allow it to access it at all (e.g. SELECT, UDPATE, DELETE, etc.). You should really have the application credential locked down in the DB which it uses anyway to ONLY allow it to ONLY have the EXPLICIT level of access it needs to each DB object specifically in the name of security. So why the user table is a concern now, wonder what other tables, etc. it has access to due to poor security design.