The existing system: I have a FreeBSD based backup/archive server, which pulls the backups from the live servers via rsync every night and does a zfs snapshot to archive the backup contents for a specific time. This results in the situation, that on this server there are lots of ... 

Does write-through cache mode cause a performance degradation of the array over time? I don't think so. With an activated write-cache, the controller is able to perform certain operations to optimize the pending write operations. For example this description of the cache operation is taken from the whitepaper for HP Smart Array controllers: 

Regarding the measured 33x difference between your results, following up on our discussion in the comments, it turned out, that showed that setup B had the disk drive cache enabled by default, while it was disabled on setup A. Using resulted in both systems showing a similiar performance. Is it safe to run the RAID with disk drive cache enabled? Running a RAID with disk drive cache enabled is actually similiar to running a RAID controller with non BBU backed volatile cache with write caching enabled (forced write-back mode). It enhances the performance, but at the same time increases the possibility of data-loss and data-inconsistency in the event of a power failure. If you want to avoid this chance, while still having a decent I/O performance, it is advisable to have a controller with BBU backed-cache and to configure your volume to write-back mode with disk caching disabled. The difference between your two RAID controllers I don't know if you already knew, but there is more between software and hardware RAID (this is an interesting article regarding this). In the end the MegaRAID SAS 2008 is more or less an HBA or IO-Controller with added RAID capability, while the MegaRAID SAS 3108 is a real RAID Controllerâ„¢ (also called ROC or RAID-on-Chip), which has a dedicated processor for handling the RAID calculations. The SAS 2008 is especially known for horrible write performance with some OEM firmwares (like the DELL one in the PERC H310 which I mentioned in the comment). Especially the synchronous mode in combination with your chosen record length and file size seems to result in really poor results with software/fake RAID. For reference, this is what I get on my workstation using 10k WD Velocity Raptors in software RAID1: 

In the end nothing to worry about - pull a working BBU / controller from another server or get yourself one on ebay. Dead BBU batteries are a really common problem with any controller (the lithium ion cells just wear off with the years) and the reasoning why most RAID controllers use flash-based cache and no BBU nowadays. 

Adding to the other answers (they all have valid points - bandwidth is important here, too!). A quick websearch revealt that the NAS you mentioned seems to have a Marvell 5281 CPU running at 500MHz and 128 MB of RAM. While technically rsync can handle multiple connections, I would suggest you don't try to run all the jobs at the same time, but instead leave a gap between the jobs that is long enough for each job to complete before the next one starts, so that ideally no jobs run simultaneously. This hardware doesn't look strong enough for me to feature 20 simultanous connections. You'll of course need to calculate this offset based on your available bandwidth at that location and the overall write performance of your NAS. 

You don't write anything about the kind of failure on the non working server. I'll assume that the problem is not a broken RAID due to failed hard drives. Obviously, in that situation, it would be of little help to move the broken disks to another server ... Generally the RAID configuration is stored on the disks by the H700 (and also most other RAID controllers nowadays). This is supposed to make it easy to move RAID sets between similiar controllers/servers. You just need to move the disks to the working server (I would make sure to plug them in the same slots nevertheless). When booting up you'll have to enter the RAID BIOS. There will be a menu "Import foreign config". In a normal situation (i.e. all disks working perfectly) the controller is even supposed to detect this by itself: 

That should be possibly if we assume the drives are really OK as shown in your screenshot. You could also try to start from your HP SmartStart CD and run the Array Diagnostic Utility. The ADU log will show more details then the screenshots you posted. It may be possible, that you are able to simply reenable the Logical Drive in the ADU, for example if the reason for the failed state is a temporary problem with detecting the drives. 

To give an anecdotal response; the 840 Pro did work on the H310 when I tried them. The problem is, especially the firmware of the H310 has a ridiculous low queue depth preset and because of this may (depending on your work load) suffer from a terrible I/O performance. You have a chance to change that, through cross-flashing the controller to get rid of the PERC firmware. The controller is an OEM version of the LSI SAS 2008 and can be reflashed to LSI mode (queue depth 600 if I remember correctly). Another possibility is to get a proper controller (PERC H700/H710 for example) - those also work with the 840. EDIT Here is a good comparison between various controller queue depths. The H310 has a queue depth of 25, while for example the H700 has a queue depth of 975. 

Most MySQL installations come with networking disabled by default, e.g the my.cnf contains a line similiar to which limits the network access to localhost for security reasons. If you choose to enable networking by altering this line you need to make sure that you reconfigure all your MySQL users, to distinguish between local and remote MySQL users. You'll want to make sure all your remote users also have in their GRANT statement to enforce encryption for all remote connections. MySQL has a step-by-step setup for secure remote connections here. On most (all?) linux based webservers MySQL remoting is disabled and the commonly accepted way to open up a remote MySQL connection here, is to tunnel SQL through SSH, so MySQL can be left unchanged and configured to allow only local connections. This is also possible on Windows Servers, but of course only with the added overhead of installing an SSH server (for example via Cygwin) first. I would personally prefer to use the SSH variant as it allows MySQL to be left unchanged - you don't need to mess with your users & permissions inside MySQL. Also as a matter of personal opinion, I would think opening up MySQL as a protocol over the network is widening the attack surface of the server to a greater extent, then having SSH running does - especially if you are using key based authentification with SSH. 

Regarding howto replace the controller (if it should be needed). The PERC5 does indeed store the volume configuration on the disks themself. When you replace the controller it will just show all drives as "foreign". Inside the RAID BIOS there is a menu "Foreign Config" which allows you to import the config from the drives. This process works pretty flawlessly IMHO. 

In a working install the config file is within that folder and is an ordinary subdir of the folder. Is the file lost? Any chance to get it back? 

My interpretation of the above output is, that this domain should be resolved to my server after a maximum of 3600 seconds (as I'm changing both, the NS and A records). As I did move the above domain, 3 hours after receiving the TRANSFER ACK it is still resolving to the wrong DNS server: 

RDP (in standard configuration)? MSSQL (2012)? Active Directory? WSUS (without domain if 3. is unsafe)? 

I would assume your second Logical Drive is running in degraded state since a few month as someone already took a broken disk out without replacing it. The "INTERIM RECOVERY" state means a disk is missing/broken, but due to the redundancy provided by the RAID controller, the data is still accessable for now, until a second disk is going to break. If the data on the second Logical Drive is important to you, I would advise you to boot the system with a live CD and copy the data of to a safe location as soon as possible. In the long run, you'll need to add the third disk back to the server, so the array is able to rebuild and return to a healthy state.