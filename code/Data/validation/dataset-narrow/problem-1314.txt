Is it possible to tell Unity to not load asset bundle dependencies automatically so they can be loaded manually. If so, how can this be done? 

I believe this may be the fastest way we could do it. If the tiles aren't in an array, however, you can use the bounds checking method described by Lasse. If that's not fast enough, you could use a quadtree. This data structure allows use to quickly check where things are in the world. Read about it here: $URL$ It's a pretty simple structure to create and helps in far more than just object culling. 

On the surface Entity-Component seems like a good way to program games. Everything is a game object and those game objects are made up of components. The attraction is components are very flexible, just requiring you to "add" them to a game object to inherit it's functionality. So, obviously a good example might be a platform the character has to jump on. Maybe this thing has a collider, a moving component, maybe a rotating component, or maybe even a rigid "RotatingAndMovingPlatformComponent". Okay, that sounds great, just add all these components to the game object and that's it, you have this extra functionality. However, I find that this level of complexity is where it's usefulness ends. Try this with menus, complex character movement with multiple states, abstract ideas like game modes or game state, and your flexibility and modularity are destroyed. Menus involve a lot of specifics, complex character movement often involves many states meaning either communication between these components is needed or there must be a controlling component made just for this type of character. On top of this, some components will need to rely on game state in some way. I see very little benefit to programming this way over ordinary inheritance. The lack of object structures at compile time makes doing a lot of things very difficult and unreliable. I feel the best and easiest way of going about things would be using larger components with more dependencies. I don't see this as a problem ( more like unreal 4's architecture ), but then I wonder what's the point in the Entity-Component architecture. 

I have a situation where I would want two of the same components( in a hierarchy ), to be on a GameObject. If this component has an RPC method, it obviously cannot change name per instance of the component. Which RPC method will be called? Unity says this: "if two RPC functions in different scripts have the same name only one of them is called when RPC is invoked" This says nothing about which will actually be called. Does Unity define a behavior for when this happens? Is there any alternatives that will avoid this? 

In order to improve the extend ability of our maps, we load different components of the map at run time. The idea is a user can use Unity to make a map, drop it into a folder and it will be loaded. The problem I'm facing is loading in navmeshes at run time. Before Unity 5, it was possible to give a scene a navmesh using Resources.Load and then NavMesh.Instantiate. NavMesh.Instantiate is now gone for whatever reason, and nothing seems to replace it. Now when trying to use Object.Instantiate with a navmesh asset and instantiating an agent, I get the error "Failed to create agent because there is no valid NavMesh". Is there any known way to set a navmesh at run time anymore? 

Of course this is a waste of memory, but it saves jumping around in memory a lot, so we save a bit of time. Of course there will be situations where you find EXACTLY the same final vertex( same position, same texture coordinate, same normal etc ). In this case you'll want to index rather than copy it. This will save you A LOT of space. 

When the mass of the list is first created, loop through them all and find the relevant values. Store these max values somewhere, and every time a new rectangle is added to the list, check if it any of it's components is larger/smaller than the stored rectangle. If so, replace it. When removing you might have to run through the entire list again and check the new bounds. However, you only have to do that when you remove a rectangle, which shouldn't be too often I'd assume. This is the way I'd probably do it at first. If it's too slow for your needs, you might have to look into more complex data structures. 

Will clear all resources correctly. However, it may be desirable to load the required resources, free the compressed data, and then free the loaded resources at a later time. How can this be done? 

Where start is the initial position of the object you are moving and end is the place you want to be once currentTime = totalTime. In your case, the end vector would be directly below the object that is being moved. If you want constant movement while the timer is running, then make sure you know when the timer is running and just do something like this: 

Here in our Game1 class, we maintain a list of meteors. Every frame we update them ALL by looping through them. We do the same with drawing. When we construct, we pass in information that should vary between meteors. 

There we go. It's a bit annoying we have to specify paths instead of UnityEngine.Object references, but besides that it's pretty easy. So, how do we build this? We can't use the method we used before because that's for editor asset bundles. We can use an overload of that method though: 

When you transform you are transforming the coordinate space, not the object. If you translate, scale then rotate, the transformations should have no effect on each other. That's one of your problems, potentially. Your cubes are scaling from the center because that is where the origin is in model space. Each vertex of your cube is placed relative to the center( 0, 0, 0 ) of the cube. To change this either make your model origin the bottom center( I don't recommend this ) or translate up by half the cubes height after scaling. EDIT: To go more in depth about why your cubes are scaled from ( 0, 0, 0 ), you should understand how vectors work. All vectors have an origin and a distance from that origin( unlike a point, which just has a location ), this origin is zero. To scale a matrix, we can simply multiply it by a scalar: 

How can I have events based off animations without relying on them? Take for example reloading in a FPS game. You'd hit a button to reload your weapon, the animation will play, then animation will hit a certain frame, then the weapon will be reloaded. There's a dependency on the animation eventually hitting that key frame before the weapon can reload and the character can go into another state. Without the animation, the weapon would never reload, and without some arbitrary timeout, the character would be stuck in that state forever. Checking for the existence of an animation is an option. However, this requires us to still know about some sort of animation, and what it's playing. Am I over engineering this? Would it be okay for the logic of some object to have some information about it's animations? 

$URL$ Here's what you're looking for. You want to find all components of this type in the scene. Since Unity 5 you should be able to find interface in the generic versions of Find* or Get* methods. You should probably only do this in Awake, Start or some other method that does not run every frame since finding these can be pretty slow. 

I've noticed that syncing a transform( in Unity, so a Vector3, and a Quaternion ) ends up being close to 1000 byes per second received on a client( send rate of 20hz ). Multiply this by a generous 20 entities a single match might have and that's about 15k-20k bytes per second. Is this too much? What should I be aiming for? What data rates do games typically have? 

Usually we call "logic" "update" and "view" "draw". Ideally the view would only want to redraw when the logic has changed. It's true that if you slow down the update speed, everything will be slower. This is why we used fixed time steps. With a fixed time step, update should always be consistent. The only time it wouldn't be is: 

We get the vector difference between the player and the enemy( the vector between the player and enemy ), then we normalise so the vector is of unity length and only describes a direction. Using that and an origin, Ray can figure out that it must shoot from origin towards direction. 

As you can see here, we provide the IMovable interface, but we don't purely rely on the information given to us through it. So, how do you add a target to follow? Drag and drop it from the editor, maybe set target in some code that knows about the true implementation of the interface. You can go crazy making all these different movement components. All you have to do is drag and drop one onto the object and you have that functionality.