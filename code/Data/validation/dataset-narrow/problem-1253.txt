Let $p_1,...,p_n$ be a list of numbers, each specified by $n^{O(1)}$ bits. Let $\mu = \sum_{i} p_i$ be the sum of all numbers in the list. I want to sample from the set $\{1,...,n\}$ where each $j$ is drawn with probability $p_j/\mu$. I'm looking for a reference where the complexity of this problem is analyzed explicitly taking the bit size of the numbers into consideration? I was only able to find references where the numbers $p_j$ are treated as ideal real numbers. In this case, on a turing machine operating over the reals, the complexity seems to be $O(n)$ pre-processing time and $O(\log n)$ per sample. 

Does sampling functions from $X$ uniformly at random in time $n^{O(1)}$, implies the existence of pseudorandom generators of small seed-length that fool all functions in $X$? I remember of having read somewhere that the natural proofs method does not encompass Razborov lower bounds for monotone Boolean circuits because one does not know how to sample n-bit monotone Boolean functions efficiently. Why would such a sampling algorithm imply lower bounds based on cryptographic assumptions? 

It is well known that each resolution refutation $\Pi$ for an unsatisfiable CNF formula $F = C_1\wedge C_2 \wedge ... \wedge C_m$ over variables $X$ can be translated in polynomial time (in the size of $\Pi$) into a deterministic branching program $P$ solving the following search problem: 1) $P$ has one source node and one sink node for each clause $C_i$. 2) For each assingment $\alpha:X\rightarrow \{0,1\}$ there is a consistent path in $P$ from the source node to some sink node associated with a clause that is falsified by $\alpha$. Question: Is there a proof system strictly stronger than resolution where each proof $\Pi$ can be translated in polynomial time (in the size of $\Pi$) into a not necessarily deterministic branching program $P$ solving the search problem above? 

(also asked here, no replies) A $(d,\lambda)$-quantum expander is a distribution $\nu$ over the unitary group $\mathcal{U}(d)$ with the property that: a) $|\mathrm{supp} \ \nu| =d$, b) $\Vert \mathbb{E}_{U \sim \nu} U \otimes U^{\dagger} - \mathbb{E}_{U \sim \mu_H} U \otimes U^{\dagger}\Vert_{\infty} \leq \lambda$, where $\mu_H$ is the Haar measure. If instead of distributions over unitaries we consider distributions over permutation matrices, it's not difficult to see that we recover the usual definition of a $d$-regular expander graph. For more background, see e.g.: Efficient Quantum Tensor Product Expanders and k-designs by Harrow and Low. My question is - do quantum expanders admit any kind of geometric interpretation similar to classical expanders (where spectral gap $\sim$ isoperimetry/expansion of the underlying graph)? I don't define "geometric realization" formally, but conceptually, one could hope that purely spectral criterion can be translated to some geometric picture (which, in the classical case, is the source of mathematical richness enjoyed by expanders; mathematical structure of quantum expanders seem to be much more limited). 

Given a finite set of quantum gates $\mathcal{G} = \{G_1, \dots, G_n\}$, is it decidable (in computation theoretic sense) whether $\mathcal{G}$ is a universal gate set? On one hand, "almost all" gate sets are universal, on the other, non-universal gate sets are still not well understood (in particular, of course, it is not known whether every non-universal gate set is classically simulatable), so I imagine giving an explicit algorithm for checking universality could be nontrivial. 

Has some notion similar to the OR-Weft hierarchy been studied in parameterized complexity theory? What kind of functions can be computed by circuits of constant OR-weft? 

Let $D_{t,d}$ be the class of circuits of depth at most $d$ and OR-weft at most $t$. Say that a problem $P$ belongs to OR-$W[t]$ if there is a parameterized reduction from $P$ to $WCS[D_{t,d}]$ for some $d$. Questions: 

Say that a node of a circuit is small if it has fan-in at most 2 and large if it has fan-in greater than 2. The weft of a circuit is the maximum number large nodes in any path from an input node to an output node. Let $C_{t,d}$ be the class of circuits of weft at most $t$ and depth at most $d$. The notion of weft is used fundamentally in parameterized complexity theory to define the W hierarchy. Namely, a parameterized problem P belongs to $W[t]$ if there is a parameterized reduction from P to $WCS[C_{t,d}]$ for some $d>1$, where $WCS[C_{t,d}]$ is the problem of determining whether a circuit in $C_{t,d}$ has a satisfying assignment of Hamming weigth exactly $k$. I'm interested in circuits in which only OR gates are allowed to be large. More precisely, say that a circuit $C$ has OR-weft at most $t$ if the following conditions are satisfied. 

Not sure if this is directly linked to your question, but reading it made me think about an article by Peter HÃ¸yer I read some years ago. In it, he shows how the most popular quantum algorithms like Grover's or Shor's follow the same pattern of applying what he calls "conjugated operators" and he builds new algorithms also based on that same pattern. As I said, it's been a few years since I've read it so my description is a bit sloppy, but here's the link in case you want to check it out. $URL$ 

I am working on an algorithm for which the running time is a random variable $X$ that has finite expected value, but infinite variance. Are there examples of other algorithms for which this is the case? Are any such algorithm used in practice, or does the infinite variance make the running time too unpredictable? 

Regarding question A, it is possible to adapt the PRNG to yield uniformly distributed numbers using this. However, the range of this new uniform generator has size smaller than $K$, unless the PRNG is itself uniform. The number of possible outcomes of this new generator will depend on the min-entropy of the original generator. To get some intuition on why this is so, try to view the problem from an adversarial point of view where the goal is to guess the outcome of the PRNG. If $P_{guess}>1/K$ is the probability of the most probable outcome of the PRNG, then there is no deterministic way to lower the adversary's guessing probability without adding randomness. Therefore if you are to transform the outcome to a uniform distribution then all the equaly likely outcomes must happen with probability at least $P_{guess}$, so there can be at most $1/P_{guess}$ outcomes. Of couse, I'm assuming that the adversary knows the deterministic procedure that is applied, as is usually the case in cryptography. So the answer to question B is that this nesting trick does not increase randomness, it can only decrease it. There is no deterministic procedure that can increase randomness. Hope this helps 

Obs: Note that sampling uniformly from X is not the same as sampling uniformly from the circuits representing function from X, since many circuits may represent to the same function. 

Group isomorphism can be solved in time $n^{O(\log n)}$ Graph isomorphism can be solved in time $n^{\log^{O(1)} n}$ Isomorphism of linear codes can be solved in time $2^{O(n)}$ ... 

Let $X$ be a set of $n$-bit Boolean functions of the form $f:\{0,1\}^n\rightarrow \{0,1\}$. For instance, $X$ could be the set of $n$-bit monotone Boolean functions, or the set of $n$-bit functions computable by circuits of size $s$, or the set of n-bit Boolean functions computable by branching programs of width $w$, etc. What are the implications of an efficient algorithm that samples a function from $X$ uniformly at random? Examples of concrete questions are the following. 

Where for each $n$ we assume that an isomorphism is a permutation of the set $\{1,...,n\}$. Is there a well studied variant of isomorphism problem that is known to be solvable in time $2^{O(n\log n)}$ but not in time $2^{O(n)}$? Obs: Note that $n!\cdot n^{O(1)} = 2^{O(n\log n)}$ is roughly the time necessary to test all permutations. 

Suppose I have an exponentially large graph $G$ ($|G|=2^n$) supplied with an efficient (of size $poly(n)$) randomized circuit $C_G$ implementing the random walk on $G$ - that is, $C_G$ takes a vertex index $i$ and outputs a random neighbor of $i$. Has this type of graph specification been studied and is it more powerful that the standard succinct representation, where $G$ is given as an efficient circuit that given $i,j$ outputs whether $(i,j)$ is an edge in $G$? I could imagine that being able to perform a random walk could help e.g. in detecting triangles in a dense graph (e.g. by choosing a random starting vertex and performing a random walk of length $3$; on the other hand, deciding triangle-freeness in the usual succinct model in NP-hard) 

Although, to be honest, representation theory at the level required above can be learnt in two evenings (maybe three, if you want to learn representation theory of the symmetric group $S_n$), so there should be no pressure to learn it in advance. 

Consider the set $S = \{1, \dots, n\}$ and $n$ subsets $S_i \subseteq S$ of size $d$ each (think of $S_i$ as neighborhoods of vertex $i$ in some $d$-regular graph, although the graph structure is not important here). Each vertex can have label $0$ or $1$. Each set $S_i$ comes with 2 constraints: there can be at most $k_i$ zeroes in $S_i$ and at most $l_i$ ones in $S_i$ (assume that $k_i + l_i \geq d$, otherwise constraints are clearly inconsistent). The problem - is it possible to check in time $\mathrm{poly}(n)$ (with fixed $d$) whether this constraint problem is satisfiable by at least one labelling of vertices? It smells like something NP-hard, but I don't see an obvious reduction e.g. from $d-SAT$ since it's not clear you can implement negation by only this type of constraints. 

Back in 2005, Scott Aaronson posted a list of 10 "semi-grand" challenges for quantum computing theory which contained the following challenge: 

The decisional version of your problem can be written in the folowing form: $$EQ(s_1,t_1)\lor EQ(s_2,t_2)\lor \dots \lor EQ(s_n,t_n).$$ This is very similar to the inner product $$x_1y_1\lor x_2y_2\lor\dots\lor x_ny_n.$$ The communication complexity of those two problems is equivalent, since equality can be done at constant randomized communication cost. Also, finding an $i$ such that $s_i=t_i$ is at least as hard as the decisional version of the problem. Therefore, your problem is as hard as solving $IP$ when only one clause is satisfied. I have no direct proof, but my intuition lets me believe that $IP$ with only 1 satisfied clause is as hard as general $IP$. So the randomized complexity of your problem would be in $\Theta(n)$ if I am not mistaken. I hope this helps. 

Brassard, Hoyer, Mosca and Tapp showed that the generalized Grover search, called amplitude amplification, can be used to obtain a quadratic speed-up on a large class of classical heuristics. The intuition behind their idea is that classical heuristics use randomness to search for a solution to a given problem, so we can use amplitude amplification to search the set of random strings for one that will make the heuristic find a good solution. This yields a quadratic speed-up in the running time of the algorithm. See section 3 of the paper linked above for more details. 

We say that a Turing Machine $M$ is mortal if $M$ halts for every starting configuration (in particular, the tape content and initial state can be arbitrary). Is every recursive language recognized by a mortal Turing Machine? (i.e. if there is a TM that accepts $L$, there is also mortal TM that accepts $L$) 

The syntactic monoid of a language $L$, which is $\Sigma^{\ast}$ quotiented by $\sim_{L}$, is usually bigger than the set of equivalence classes of $\Sigma^{\ast}$ quotiented by $\equiv_{L}$. Informally, the Myhill-Nerode relation $\equiv_L$ only cares about the prefixes of a word $w$ (since it reflects the processing of $w$ by a DFA), while the syntactic monoid has to encode the information about all possible infixes of $w$ (otherwise you won't get the algebraic structure $[x]\cdot[y]=[x \cdot y]$) 

First, prepare a state $\frac{1}{\sqrt{3}}((-1)^{f(0)}|00\rangle + (-1)^{f(1)}|01\rangle + |11\rangle)$ (which can be done easily using single black-box query and unitaries). Notice that two such states correspondng to different $f$'s have always inner product $\frac{1}{3}$. You can easily turn this observation into an algorithm succeeding with one-sided error $\frac{8}{9}$ or better if you allow two-sided error (note that the best classical procedure can achieve probability at most $\frac{2}{3}$). 

I wouldn't think so. I'm assuming your $a_n$'s are normalized, i.e. that $||\sum_n a_n |n\rangle|| =1$. But then your wish output is not normalized since $$||\sum_n e^{ia_n} |n\rangle|| = \sqrt{\sum_n |e^{ia_n}|^2} = \sqrt N$$ where I assume there are $N$ terms in the sum. Quantum (unitary) operations have to preserve the norm so there can't be one that maps the first state to the second one. 

Lov Grover published an article in 1997 in which he shows that if you can query the database on multiple items, then a single query suffices to find the marked element. However, it requires a number of preprocessing and postprocessing steps in $\Omega(N\log N)$. If you let $S_1, \dots, S_N$ denote the elements of the database, you query the oracle with the string $S_{i_1}, \dots, S_{i_\eta}$ for some number $\eta$ and the oracle returns $1$ if the marked state appears an odd number of times in the string and $0$ if it appears an even number of times. You query this oracle on a superposition $(|S_1\rangle+ \dots+ |S_N\rangle)^\eta$ and then apply the inversion about the mean operator from Grover's algorithm. Now in each the the $\eta$ subsystems, the marked element has a greater amplitude than the unmarked ones. Measuring all subsystems yield the marked state with greater probability and to have sufficient certitude about the resulting state, $\eta$ must be in $\Omega(N\log N)$. 

(this is not specific to TCS conferences, but would work for better conferences in general) A nice idea I saw in a mathematical conference for young researchers is asking every participant to write a short "research statement" - in case of junior participants who don't yet have much results, a description of interests would be OK. Then, some time before the conference, the statements are published on the webpage. A working example of this: $URL$ (conference in geometric group theory) I think this would be especially helpful for junior participants suffering from the "I don't know anyone here" problem, but also the other way, since even students aren't anonymous mass anymore. Of course, this is rather feasible for smaller conferences/workshops, not 400-people events, but still I think it's worth implementing. 

Is there any software package allowing decomposition of unitaries from $U(2^n)$ into quantum circuits over a predefined universal gate set? 

It is well known that some major complexity classes, like P or NP, admit a full logical characterization (e.g NP = existential 2nd order logic by Fagin's theorem). On the other hand, one can also define complexity classes in communication complexity (where P = problems solvable with poly(logN) communication etc. - see Complexity classes in communication complexity theory for more). My question is - are any descriptive complexity characterizations known for communication complexity classes (or do any such results from standard complexity classes transfer to communication setting easily)?