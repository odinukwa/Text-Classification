Software assurance give you the right to upgrade during software assurance life . You don't have to transfer license but request new one. Its in your microsoft vlsc account. $URL$ be carefull with virtual licensing . microsoft say : 2012 r2 is 2 vitual + 1 physical references : $URL$ 

Termina server (rdp server now) work like that : -user connected on server view printer localy installed on the server or connected by script/group policy. -if remote printer is enabled on tse and client tse , user on the server can view localy installed printer on the server if the driver is installed on the server (for 2003 server). And only the user connecting their printer . To resolve your share problem with connected printer via remote session its better to use printer as local one (with ip with or without vpn) because rdp 2003 is not very good at handling printer job. And this prevent share right delete. And there is near 0 compression on print job with old rdp protocole. 2008 and later are better at handling printer job inside rdp session. 

Don't understand exactly what you need to know (and where is the question)but if i understand a few: use dhcp relay. How to do that : $URL$ 

1- If you want comment to your perf we need to see your logstash filter config . Logstash performance is a mix of filter/output/worker setup . More filter = less event/seconds . A good idea is to scale wide if you have logstash perf problems . More worker more instance could increase event/seconds perf . People work with sender to rabbimq queu and scale logstash node behind . 2- see 1 3- there is IO limits and sometine its better to have more node. Elasticsearch is designed to work with shard/node etc . 4- logstash monitoring is only process monitoring for the moment . There is some clue about doing that with java debugger but you have to find information in logstash user group . For elasticsearch there is marvel to monitor you elasticsearch cluster . 

Don't know a all in one solution but look for this : 1- use a software to read iis log and with some "code" email a result when someting match your monitored file . Look for elk stack with email output in logstash . Don't forget to enable logging first . 2- use a web app you code to generate a mail when someone do a get on this file. 

Azure disk management is not smooth and easy. To resize your sys disk no other solution than delete the vm with retain disk . Resize with the tool after deleting the disk from "vm" but keep data in the blob. After resize you have to add a vm with an existing disk . Remember to save vm name , disk name , acl in firewall etc . Last resize of an old azure vm i used this blog post : $URL$ There is a new solution with cloud explorer but i never tested (and you have to delete the vm like the first one methods). And i don't explain how to expand ubuntu lvm because there is already many blog about that : ( $URL$ 

I am running pfsense 2.0.3 nanobsd 4g i386 on virtualbox. VM configured with 4gb ram, there's 8 gb total on host system, with two net interfaces configured as host only. This will go on an SSD mini atx box, but for now I am just running on VM for learning pfsense. I assigned interfaces, em0 to WAN, and em1 to LAN. From the windows host(hosting the VM) I brought up the browser and tried to connect to the LAN IP. I was intermettently getting timeouts and I would reboot the server or use the reboot web configurator option, and sometimes I could get the login screen but after logging in with default user/pass, I'd get a blank page. Absolutely no error messages or feedback of any kind. I typed password carefully, thinking maybe it was doing anonymous authentication, since according to their documentation provides a blank page by-design. After many tries and reboots I finally got the wizard screen. I completed the wizard and the final page indicated it was going to redirect after a few moments, after a few minutes it redirected but failed to retrieve the next page. From there the web configurator again was not responsive, timing out. I rebooted and still same thing. How do you troubleshoot something that gives you absolutely no feedback or error messages? Any ideas about what might be wrong would be welcome, but primarily: How do I troubleshoot failures in the web configurator? Is there logs specific to the web configurator, or do I need to poke around in the web server logs, pfsense logs, etc.? Is there any documentation on directory structure that would help me find these? I've found from distribution to distribution, that each has it's own idea of where user programs, logs, etc are stored. 

We are doing nightly full backups and noon differential backups. We use Full recovery model with SQL Server 2005, but logs are never backed up and are truncated(TRUNCATE_ONLY) after the full backup. Restoring to a point in time is not a requirement, restoring to one of the nightly or noon backups is sufficient (Not my decision). So the question at hand is, since they are throwing away the logs every night, is there any reason to not use Simple Recovery model? Is there any benefit to using Full Recovery model if we are throwing out the logs every night? Thanks. 

So my understanding of one scenario that ZFS addresses is where a RAID5 drive fails, and then during a rebuild it encountered some corrupt blocks of data and thus cannot restore that data. From Googling around I don't see this failure scenario demonstrated; either articles on a disk failure, or articles on healing data corruption, but not both. 1) Is ZFS using 3 drive raidz1 susceptible to this problem? I.e. if one drive is lost, replaced, and data corruption is encountered when reading/rebuilding, then there is no redundancy to repair this data. My understanding is that the corrupted data will be lost, correct? (I do understand that periodic scrubbing will minimize the risk, but lets assume some tiny amount of corruption occurred on one disk since the last scrubbing, and a different disk also failed, and thus the corruption is detected during the rebuild) 2) Does raidz2 4 drive setup protect against this scenario? 3) Does a two drive mirrored setup with copies=2 would protect against this scenario? I.e. one drive fails, but the other drive contains 2 copies of all data, so if corruption is encountered during rebuild, there is a redundant copy on that disk to restore from? It's appealing to me because it uses half as many disks as the raidz2 setup, even though I'd need larger disks. I am not committed to ZFS, but it is what I've read the most about off and on for a couple years now. It would be really nice if there were something similar to par archive/reed-solomon that generates some amount of parity that protects up to 10% data corruption and only uses an amount of space proportional to how much x% corruption protection you want. Then I'd just use a mirror setup and each disk in the mirror would contain a copy of that parity, which would be relatively small when compared to option #3 above. Unfortunately I don't think reed-solomon fits this scenario very well. I've been reading an old NASA document on implementing reed-solomon(the only comprehensive explanation I could find that didn't require buying a journal articular) and as far as I my understanding goes, the set of parity data would need to be completely regenerated for each incremental change to the source data. I.e. there's not an easy way to do incremental changes to the reed-solomon parity data in response to small incremental changes to the source data. I'm wondering though if there's something similar in concept(proportionally small amount of parity data protecting X% corruption ANYWHERE in the source data) out there that someone is aware of, but I think that's probably a pipe dream. 

hum not a fun problem. This could be a raid card problem ... try to start without repair (f1) if its okey just change the drive. you can change it "online" . 

In the website world some people use ww2 to load balance and/or do A/B testing with "real user load" on a second cluster . Sometime its just a trick used to load with real user and do some benchmark on new stuff :) 

If you think about ssh when you talk about "logged" you can use syslog and rsyslog . For rsyslog check that : $URL$ With some setup you can send log by mail or with log system stack (elk stack , graylog2 , splunk , etc). 

You can do that with url rewrite and binding on you iis site . check for iis rewrite modules rules here : $URL$ 

I don't have a reply for point 1-2-3 but you can check with your virtual enginner about Vmware host config . If he is VCP he will understand the stuff :) You really have to check your host because windows problems could be on the host not in the guest . There is many hardware feature that could explain your problems , directpath io , rss , vcpu , power management scheme ... I can give you some link that help your virtual team , or you :) This link is about tuning the host $URL$ And this fat pdf : $URL$ And this one is about rss : $URL$ 

Some driver are just not ready for terminal services (remote desktop services now) . There is compatibility list on printer driver support site. Sometime another driver for another printer model work in remote desktop but you can have weird problems like bad character or black images etc. No real solution other then get a 100% remote desktop ready printer and driver :) EDIT : or try this : epson universal printer driver 

Probably a trust problem . Doucle check ntp :) Weird problems sometime are just a stupid clock problems . Set same ntp on the two domain . Double check the trust , and dns name . If you ping the domain name and all ok check for eventslogs on source and target server . Try with Test-computersecurechannel in pshell . 

There is solution for your need : 1- use a hids software agent on client to log event to a server . Need install on client , config server , don't work outside without vpn etc . (Ossec or other siem/hids tools do the job) 2- use windows audit capability to centralize all events. This work without tools on client side . you just have to run script/gpo with configuration to send security log to a centralization server . Look this one : $URL$ After that you need some script to read audit log in centralized server and write to database . There is tools like Nxlog ,Snare that do the job (read event log and format for a syslog ). And logstash can read syslog and write in a database (nosql database , or sql database) . There is commercial software doing that too but its not the place to talk about that (google for commercial product). 

EveryDNS used to have this, but I switched to DynDNS because I found out my router has support for DynDNS. 

Scenario: Excel file, with a SSAS data source connection Pivot Table/Charts with filters and slicers Published to Sharepoint 2010, such that users can access the report as a Excel Web Access Web Part, such that they can't break/change the pivot table other than changing filters and slicers. Note that I am NOT talking about powerpivot. Rather just using a regular data source connection. As users access the report, I would like the most current data(within the last day) from SSAS to be reflected in the report. Assume that the SSAS database is refreshed daily already. 1) Does Excel Services and/or the webpart automatically refresh the data when the report is opened/viewed through the Web Access Web Part? And/or can it be configured to periodically refresh the data? 2) What are the server software requirements to support this? Does it require SQL Server Enterprise edition? Or is standard enough? Does it require Sharepoint 2010 Enterprise, or is standard enough? when I say "support this" I mean both the Excel Web Access Web Part as well as the refreshing of the data from SSAS into Excel. 3) Does the Web Part allow them to only interact with filters/slicers? Or will they be able to mess with/break the pivot table? If so, will changes/breakage they make only be persisted for their session and not effect future sessions or other users? I would test this myself but I have had difficulty getting the trial of Sharepoint setup on my home computer(ultimately I won't even be the person setting it up in production anyways) and I just want to know what edition will support these features. Thanks. 

Where can the pfsense log files be located and viewed? I have searched the documentation and it doesn't indicate the log files location for the various components of pfsense. 

Just FYI, the case sensitivity is dependent on the collation. There are case-insensitive colations you could use as a workaround, perhaps temporarily. 

If I have a mirrored pair of 250GB drives in a pool, and I later buy two more drives and add another mirrored pair to the same pool, can that second mirrored pair be 500gb? Such that my total usable space would be 750GB? Or do all the mirrored pairs in a pool need to be the same size? 

Intel AMT is a motherboard feature found in certain chipsets such as Q67. So if you are looking for a superMicro board with this, then just find out which intel chipsets support Intel AMT, and then look for supermicro boards with that intel chipset. There are some various other requirements as far as what CPU you use, etc. In a nutshell the motherboard keeps one of the ram chips powered, the northbridge powered(which runs the management interface), the onboard ethernet connection, and an extra flash chip to store settings. So you can connect to the system over ethernet and access the remote managmeent features/power-on/power-off etc. I am not sure though if this is available in any chipsets targeting servers though, but it is really powerful and would seem to be well suited for servers.