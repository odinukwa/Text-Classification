To celebrate Alan Turing 100th birthday, I want to watch a documentary about his life. However, there are several documentaries to choose from. Which documentary about Alan Turing is your favorite? Please include only one documentary per answer. 

Boaz Barak addressed this in a blog post My takeaway from his post (roughly speaking) is that we only know how to design cryptographic primitives using computational problems that have some amount of structure, which we exploit. With no structure, we don't know what to do. With too much structure, the problem becomes efficiently computable (thus useless for cryptographic purposes). It seems that the amount of structure has to be just right. 

Deciding if there is a graph homomorphism is easier than counting the number of (weighted) graph homomorphisms. Weighted Case For undirected target graphs $H$ (i.e. the number of weighted graph homomorphisms from an input graph $G$ to $H$), there is a dichotomy theorem. Jin-Yi Cai, Xi Chen, Pinyan Lu. Graph Homomorphisms with Complex Values: A Dichotomy Theorem. That is, every target graph $H$ either defines a #P-hard or polynomial time computable counting problem (see Theorem 1.1). It is a bit difficult to explain which graphs $H$ define polynomial computable problems (see Theorem 5.7 for the statement and page 4 for the index of the conditions), but it is also polynomial time computable to decided if a target graph $H$ defines a easy problem (see Theorem 1.2). The tractability follows from the ability to efficiently compute the exponential sum over a sequence of variables modulo $q$ that form a quadratic polynomial in the exponent of a $q$th root of unity, where $q$ is a prime power (see the beginning of section 12). Unweighted Case The unweighted case is much simpler. Below, I state Theorem 1.1 from the following paper. Martin Dyer, Catherine Greehill. The complexity of counting graph homomorphisms. (Also this direct link to a free PDF.) Theorem 1: Let $H$ be a fixed graph. Then problem of counting $H$-colourings of graphs is #P-complete if $H$ has a connected component which is not a complete graph with all loops present or a complete bipartite graph with no loops present. Otherwise, the counting problem is in P. 

It is known that first order logic is too general to be decidable. Adding axioms with special meaning (e.g. expressing notions such as necessity/obligation, provability, etc.) leads us to modal logics but some of them (especially multidimensional fusions or products of them) are undecidable too. As I understand, then undecidability generally is created by quantifiers - it is quite hard to prove of refute formula, that should be valid in all worlds (if accessibility relation allow them). The undecidability can be handled by several approaches: 1) lowering the expressivity of the logic or considering the less expressive fragments; 2) following ideas of max-SAT problems; 3) moving to approximate reasoning (probabilistic, fuzzy-logic, etc.). All these approaches has this drawback: they tries to reformulate or make less relevant the original problem that was created as conscise and clear model of the real world problem. Maybe there is better way how to approach such undecidable situations - simply by adding additional axioms that reflect the real-world situation. E.g. axiom can be added that the number of variables is bounded in the logic (there can be different axioms depending on how we model the reason why there are only finite number of instances of some class in the world - e.g. bounded resources, restricion by law, etc.). So - the question is - is there some research trend that investigates the modal logics with aim - what axioms should be added to them the regain the decidability of logics (and according - the suitability for them for automated reasoning tasks, for use in autonomous systems)? 

Automata are not really needed to prove this result. Let $K$ be a regular language and let $R = \{w \in A^* \mid h^{-1}h(w) \subset K \}$. Then the complement of $R$ is $$R^c = \{w \in A^* \mid h^{-1}h(w) \cap K^c \not= \emptyset \} = h^{-1}h(K^c).$$ Since regular languages are closed under homomorphisms, inverse of homomorphisms and complementation, $R$ is regular. Now if $L$ is another regular language, the set $\{w \in L \mid h^{-1}h(w) \subset K \}$ is equal to $L \cap R$, which is regular as well. 

This question is related to the so called insertion systems. An insertion system is a special type of rewriting system whose rules are of the form $1 \rightarrow r$ for all $r$ in a given language $R$. Let us write $u \rightarrow_R v$ if $u = u'u''$ and $v = u'ru''$ for some $r \in R$. Let us denote by $\buildrel{*}\over\rightarrow_R$ the reflexive transitive closure of the relation $\rightarrow_R$. The closure of a language $L$ of $A^*$ under $\buildrel{*}\over\rightarrow_R$ is the language $$ [L]_{\buildrel{*}\over\rightarrow_R} = \{ v \in A^* \mid \text{ there exists $u \in L$ such that $u \buildrel{*}\over\rightarrow_R v$} \} $$ Recall that a well quasi-order on a set $E$ is a reflexive and transitive relation $\leqslant$ such that for any infinite sequence $x_0, x_1, \ldots$ of elements of $E$, there are two integers $i < j$ such that $x_i \leqslant x_j$. The following theorem is proved in [1]: 

There are lot of applications of Horn clauses (notable examples include use of rules in cognitive architectures and knowledge bases, as well as use of rules in business rules programs). Are there formal methods that can help specify and verify Horn clauses. Is there semantics of Horn clauses. One can perceive Horn clauses as something similar to programming code of traditional programming languages and therefore one can expect the denotation, operational and similar semantics as well for Horn clauses. 

I am acquinted with the basics of such notions as logic programming, monotonic and non-monotonic reasoning, modal logic (especially dynamic logic) and now I am wondering - does logic programming provides anything new to any logic? As far as I understand, then (at least in dynamic logic) the logic programming refers to the formalization of state transitions (by actions, i.e. - logic programing can be understood just as logic about actions). But the same notion "logic programing" seems to be in use even in domains, where there is not state transition, just exploration of one state (or set of states - in case then the initial set of premises are vague enough to describe more than one state). It seems to me that some authors simply use the notions "logic programming" for describing the procedure how to evaluate the query (I am reading currently about defeasible logic programming). But such procedure (although practical indeed) does not add anything new to the underlying logic. E.g. there is notion of "rational closure" (e.g. used for adaptive logics; just the consequence set for some set of premises) which should contain all the possible knowledge about state and therefore all the possible results of "logic programing" (if it is indeed perceived just as state exploration, derivation). So - the question is - does logic programming provides anything new to the logic and does every logic (to be completely understood and readied for applications) need to have its own logic programming? Maybe I am just missing the point... Just for reference I find the following works interesting about this subject, if there are more along this line, then it would be great to hear! 

The reference that I promised above is Holographic Algorithms with Matchgates Capture Precisely Tractable Planar #CSP by Jin-Yi Cai, Pinyan Lu, Mingji Xia. Theorem 6.1 proves that counting matchings in 3-regular planar graphs is #P-hard in the special case that $[y_0, y_1, y_2] = [1,0,1]$ and $[x_0, x_1, x_2, x_3] = [1,1,0,0]$. 

(Making comment an answer as requested and expanding a bit.) "A curious mind" should read Schaefer's dichotomy theorem and the generalization by Allender et al. that shows that every possible SAT variant is either trivial or in one of six well-known complexity classes: 

The book Perspectives in Computational Complexity: The Somenath Biswas Anniversary Volume published this summer (July 2014) largely agrees with the consensus that we reached here. On page 199, it says: 

The paper Quantum Complexity of Testing Group Commutativity considers the problem of identifying if a given group is commutative. The group is given via a certain oracle and the complexity of the problem is measured by the number of quantum queries to this oracle. The paper gives an algorithm for this problem as well as an analysis of this algorithm that yields an upper bound of $O(k^{2/3} \log k)$. I think the analysis of their algorithm can be improved to give an upper bound of $O(k^{2/3} \log^{2/3} k)$. Their quantum algorithm uses a quantum random walk on the following graph. The vertices are $\ell$-tuples containing distinct elements from a universe of size $k$. Two vertices are adjacent if 

Finally, for nondeterministic automata, the characterization is simply that $L$ is a submonoid of $A^*$. 

I think the answer to your question can be found in Theorem 3.1 of [1], where it is credited to Wechler [2]. An algebra is stable if it is closed under left quotient. 

You may have a look at the following book Automata, Logics, and Infinite Games, A Guide to Current Research, E. Grädel, W. Thomas, T. Wilke (Eds.), LNCS 2500 (2002) 

Let $\mathcal{A} = (Q, A, \cdot, q_0, F)$ be the minimal DFA of your language $L$. If I understand correctly, you would like to have a permutation $\sigma$ on $A$ such that $$ q \cdot \varphi(a) = q \cdot \sigma(a) $$ for every state $q$ and letter $a$. This will happen if and only if, there exists $\sigma \in \mathfrak{S}(A)$ such that, for each letter $a$, $$ \varphi(a) \in \bigcap_{q \in Q} L(q, q \cdot \sigma(a)) $$ where, given two states $p$ and $q$, $L(p, q) = \{u \in A^* \mid p \cdot u = q\}$. For instance, in your example, you get the following conditions when $\sigma$ is the identity \begin{align} \varphi(a) \in L(0,0) \cap L(1,1) &= \{ u \in A^* \mid |u|_b \text{ is even }\} \\ \varphi(b) \in L(0,1) \cap L(1,0) &= \{ u \in A^* \mid |u|_b \text{ is odd }\} \\ \end{align} and the following conditions when $\sigma$ is the transposition $(1\ 0)$ \begin{align} \varphi(a) \in L(0,1) \cap L(1,0) &= \{ u \in A^* \mid |u|_b \text{ is odd }\} \\ \varphi(b) \in L(0,0) \cap L(1,1) &= \{ u \in A^* \mid |u|_b \text{ is even }\} \\ \end{align} which, altogether, gives your condition. 

This problem is tractable. Let $G = (V,E)$ be the input graph with $|V| = n$ and let $e$ and $o$ be the number of vertex-induced subgraphs of $G$ with an even and odd number of edges respectively. Of course, $e + o = 2^n$. In polynomial time, we can compute $e - o$, which I explain below. With two equations and two unknowns, we can solve the linear system to determine the value of $e$. From $G$, we create an instance of a counting constraint satisfaction problem (#CSP). Every vertex in $V$ is a Boolean variable and every edge in $E$ a constraint $f$ that depends on its incident vertices. The constraint $f$ evaluates to 1 unless the both vertices are assigned 1, in which case, $f$ evaluates to -1. The symmetric notation for this constraint is $[1,1,-1]$. Now the answer to this #CSP instance is (by definition) $$\sum_{\sigma : V \to \{0,1\}} \prod_{e \in E} f(\sigma|_{I(e)}),$$ which is a sum over all vertex subsets, the product of the outputs of every constraint $f$, where $I(e)$ is the vertices incident to $e$ and $\sigma|_{I(e)}$ is the restriction of $\sigma$ to $I(e)$. Fix a subset of $V$. Assigned 1 to the vertices in the subset and 0 to the vertices not in the subset. If either vertex incident to the same edge is assigned 0, then this edge is not in the vertex-induced subgraph and the constraint $f$ on this edge contributes a 1 to the product, which has no effect. If both vertices incident to the same edge are assigned 1, then this edge is in the vertex-induced subgraph and the constraint $f$ on this edge contributes a -1 to the product. Vertex-induced subgraphs with an even number of edges contribute a 1 to the sum while vertex-induced subgraphs with an odd number of edges contribute a -1. Thus, the answer to this #CSP instance is exactly $e - o$. Since the constraint $f$ is affine, this #CSP is tractable. The polynomial algorithm for any set of affine signatures is given in The Complexity of Complex Weighted Boolean #CSP by Jin-Yi Cai, Pinyan Lu, and Mingji Xia. There may be a simpler algorithm for this particular case. If such an algorithm is known, it is probably contained in one of the references cited in the above paper. 

A language $L$ is a marked product of $L_0, L_1, \ldots, L_n$ if $L = L_0a_1L_1 \cdots a_nL_n$ for some letters $a_1, \ldots, a_n$. Concatenation hierarchies are defined by alternating Boolean operations and polynomial operations (= union and marked product). The Straubing-Thérien hierarchy (starting point $\{\emptyset, A^*\})\ $ and the dot-depth hierarchy (starting point $\{\emptyset, \{1\}, A^+, A^*\})\ $ are of this type, but you can take other starting points, notably the group languages (languages accepted by a permutation automaton). 

As you pointed out, there are several ways to define minimal transducers, but I only know of two mathematically appealing definitions. The first result concerns the reduction of linear representations of recognizable series (= defined by weighted automata). The best reference is Chapter II, Minimization, in one of these two books (the more recent is an update of the first one, with many new additions): [1] J. Berstel and C. Reutenauer, Noncommutative rational series with applications, Encyclopedia of Mathematics and its Applications, 137. Cambridge University Press, Cambridge, 2011. xiv+248 pp. ISBN: 978-0-521-19022-0 (2] J. Berstel and C. Reutenauer, Rational series and their languages, EATCS Monographs on Theoretical Computer Science, 12. Springer-Verlag, Berlin, 1988. viii+151 pp. ISBN: 3-540-18626-3 In the case of sequential functions, one can adapt Nerode's construction to obtain a minimal sequential transducer. The algorithmm was first given in [3] G. N. Raney, Sequential functions. J. Assoc. Comput. Mach. 5 (1958) 177-180. See also Thm XII.4.2 in [4] S. Eilenberg, Automata, Languages, and Machines. Vol. A, Pure and Applied Mathematics, 58, Academic Press (1974) The algorithm was extended to so-called subsequential functions by Choffrut. See the survey [5] C. Choffrut, Minimizing subsequential transducers: a survey. Selected papers in honor of Jean Berstel. Theoret. Comput. Sci. 292 (2003), 131-143. You may also have a look at A tutorial on sequential functions for an introduction. 

It is known that many logic problems (e.g. satisfiability problems of several modal logics) are not decidable. There are also many undecidable problems in algorithm theory, e.g. in combinatorial optimization. But in practice heuristcs and approximate algorithms works well for practical algorithms. So one can expect that approximate algorithms for logic problems can be suitable as well. However the only reseach trend along these lines I have managed to find is the max-SAT problem and its development was active in nineties. Are there some other active research trends, workshops, keywords, good references for the use and development of approximate methods for modal logics, logic programming and so on? If automated reasoning is expected to gain prominence in the future applications of computer science then one will have to be able to go beyond undecidability constraints of logics and approximate methods or heuristics can be natural path to follow, isn't it so? 

There is known connection between classical and modal logics and type theory (lambda calculus), but are there connections between nonmonotonic logics (e.g. defeasible logic) and type theory (lambda calculus)? Maybe HoTT provides some generatlization where such connections can be found? If such connections can not be established then widely available proof assistants (Isabelle, Coq) are not useful for nonmonotonic logics, aren't they? 

Background The $\mathcal{H}$-factor problem (a.k.a. the degree prescribed factor problem, or the degree prescribed subgraph problem) is defined as follows: Given a graph $G=(V,E)$ and a set $H_v \subseteq \mathbb{N}$ for each vertex $v \in V$, does $G$ contain a spanning subgraph $F$ such that $\operatorname{deg}_F(v) \in H_v$ for all $v \in V$? (I would also say that $H_v \in \mathcal{H}$ for all $v \in V$, but I have never seen it stated this way. Thus, the $\mathcal{H}$-factor problem is defined by $\mathcal{H}$ and the input is a graph $G=(V,E)$ and a mapping $f : V \to \mathcal{H}; v \mapsto H_v$.) A spanning subgraph is also known as a factor, hence the name. This framework of problems captures many classic problems. For example, when $H_v = \{1\}$ for all $v \in V$, the problem is to determine if $G$ contains a perfect matching, also called a 1-factor. Question What is currently known about the complexity of this problem for different $\mathcal{H}$? What about the special case when $\mathcal{H}$ is a singleton set (so $H_v$ is the same for all $v \in V$)? Strongest Results I Know Tractability: If each set in $\mathcal{H}$ does not contain two consecutive gaps, then the $\mathcal{H}$-factor problem is in P (Cornuejols 1988). A integer $h$ is a gap in $H \subseteq \mathbb{N}$ if $h \not\in H$ but $H$ contains an element less than $h$ and an element greater than $h$. Hardness: There exist some $\mathcal{H}$ such that the $\mathcal{H}$-factor problem is NP-hard (Lovasz 1972). See (Szabo 2004) for a modern reference that cites these two results. 

A result of Krohn-Rhodes (1966) states that every DFA can be simulated by a cascade of reset (also called flip-flop) automata and automata whose transitions semigroups are finite groups. The group complexity of a language is the least number of groups involved in such a decomposition of the minimal DFA of the language. Languages of complexity $0$ are exactly the star-free languages and there exist languages of any complexity. However, no effective characterisation of the languages of complexity $1$ is known. 

There are several relevant references on the subject. I just indicate a few of them. I suggest you to browse the references of these articles to get more. Early references include the work of Françoise Gire. [1] F. Gire, "Relations rationnelles infinitaires", Thèse de 3ème cycle, Paris VII, 1981. [2] F. Gire, Une Extension aux Mots Infinis de la Notion de Transduction Rationnelle, 6th GI Conf., Lect. Notes in Comp. Sci., Volume 145, 1983, p. 123-139. [3] F. Gire, M. Nivat, Relations rationnelles infinitaires. [Infinitary rational relations] Calcolo 21 (1984), no. 2, 91--125. Interesting results can be found in [4] Latteux, M.; Timmerman, E. Rational $\omega$-transductions. Mathematical foundations of computer science (Banská Bystrica, 1990), 407--415, Lecture Notes in Comput. Sci., 452, Springer, Berlin, 1990. Section 4.3 of [5] is also a very good reference. [5] L. Staiger, ω-Languages, Vol 3, Chapter 6 of the Handbook of Formal languages edited by G. Rozenberg and A. Salomaa, (1997) 339-387. Springer-Verlag, Berlin. Finally, here is a more recent paper, where you will find other relevant references. [6] Finkel, Olivier. On the accepting power of 2-tape Büchi automata. STACS 2006, 301--312, Lecture Notes in Comput. Sci., 3884, Springer, Berlin, (2006).