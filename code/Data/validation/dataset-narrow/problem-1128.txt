You might think of it this way: does a math problem have a proof that is human-readable, or does it inherently require a "computer proof." Examples: is the starting position of checkers a draw? (Answer: yes.) Is the starting position of chess a win for white? (Answer: unknown, but most gradmasters think it is a draw.) The proof that the starting position of checkers is a draw ultimately requires one to accept that the computer really did accurately verify a lot of special cases. If a proof about chess ever exists, it will probably require human readers to accept that a computer correctly verified even more special cases. And it may well be that there is no shorter method to proof those statements. Those are problems in PSPACE. If a problem is "just" in NP, then (intuitively) a human being could hold the entire proof in his/her head. That human might need to be a very specialized mathematician, of course. This metaphor will break down if pushed too hard -- an NP-proof of size $n^{1000000}$ probably won't ever fit into anyone's head. But the basic idea that "witnesses are small" is part of the reason NP-complete problems have so much industrial significance. 

If I understand your question correctly, it attempts to relate intelligence to reproduction. The connection between the two goes back to the very beginning of the theory of applied computation. von Neumann in 1948 envisioned a robot that could duplicate itself completely. First it assembled all the pieces of the robot. Then it copied the memory tape that it had itself. Then it placed the memory tape in the new robot. However, von Neumann never published this, and it was not until 1966 that Burks fleshed out his notes into a proof, in Theory of Self-Reproducing Automata, that it became public. This paper was one of the precursors of the field of Artificial Life. Broad brush, there are two philosophical positions in that field: "strong alife," and "weak alife." Weak alife states that any living process must be chemical in nature. Strong alife states that a living process can occur in any medium. (So, for example, software entities could be alive, whatever "alive" means.) von Neumann was an early believer in strong alife, it appears. There are a great many algorithms that try to produce descendents that are fitter (i.e., more able to solve problems that require some form of "intelligence" to solve), and different algorithms have different metrics of success. Luc Steels wrote a book on this general subject in 1993: The Artificial Life Roots of Artificial Intelligence. I don't know how to steer you more specifically, but perhaps you will find a vocabulary in those works that will help you ask a more precise question. Good luck. 

Yes, you can use standard dynamic array methods, like doubling in size when it gets too large. Some data structures like to avoid this, as a full rebuild is a really large cost. But this isn't a big deal for us, as this data structure is highly amortized anyway. In other words, you have to do about $\Theta(\log N)$ rebuilds of the entire data structure every $N$ insertions anyway, just to maintain balance. This just adds an extra one. 

Yes, here (this was a class project; beyond that I know almost nothing about that code). The author of that code has a nice writeup of the data structure as well. Some more recent academic work on that data structure has experimental results. You may try looking through those as well (though of course, many are variations on the original concept). 

While this doesn't answer your exact question, CFG parsing is a decision problem that was reduced from matrix multiplication (so it is as hard as matrix multiplication in a sense). Specifically, in [1] it was shown that CFG parsing is as hard as boolean matrix multiplication. In particular, if CFG parsing (a decision problem) can be solved in $O(gn^{3-\epsilon})$ time, boolean matrix multiplication can be solved in $O(n^{3-\epsilon/3})$ time. An interesting aspect is that matrix multiplication can also be used for fast CFG algorithms, so the problems are computationally equivalent in a sense. The reduction has some unusual aspects because boolean matrix multiplication requires $n^2$ output bits, whereas CFG parsing only requires one. To deal with this, the paper assumes that the CFG parser solves certain subproblems when parsing the string (and argues that this is a reasonable assumption to make). The reduction makes $n^2$ queries to these subproblems to obtain the product matrix. Thus CFG parsing is a decision problem that is computationally as hard (in a sense) as matrix multiplication. However, this is not specifically a decision version of matrix multiplication, and furthermore, the reduction relies on the idea that CFG parsing is actually made up of $n^2$ decision subproblems. 

Because Bitcoin and many other cryptocurrency mining certificates are "rare" in that their respective hash is less than a very small number, can we leverage their rarity in probabilistic proofs of other interesting problems? In more detail, in Bitcoin mining miners compete to build a block by constructing a Merkle root of financial transactions, call it root $r$, and also finding a nonce, say nonce $c$, such that a cryptographic hash $H_S(r\Vert c)$, thought of as a number between $0$ and $1$, is less than a moving difficulty target $d$. (The hash is salted with other information $S$, such as the hash of the previous block; however, most of that extra information is constant for each block mined, hence I'm sweeping that under the rug for now.) Miners find such pairs $(r,c)$ about once every ten minutes. The adjustable difficulty $d$ is presently about $2^{-72}$. Thus, miners perform roughly $2^{71}$ hashes every ten minutes or so. Furthermore, $r$ is $256$ bits while $c$ is $32$ bits. Accordingly, we can consider $r\Vert c$ as a $288$-bit number $q=2^{32}r+c$. A quick application of the prime number theorem suggests that this $288$-bit number is prime about once every $\log 2^{288}\approx 200$ blocks. This corresponds to a beacon of roughly one pair $(r,c)$ every 33 hours such that $q=2^{32}r+c$ is prime. (There may be other ways to increase the frequency of the beacon, e.g. by setting $q'=2^{33}r+2c+1$, etc., but for simplicity $q=2^{32}r+c$ suffices.) For example, after a little bit of hunting on the main Bitcoin blockchain, at height 520605 Wolfram|Alpha confirms that the hexadecimal Merkle root and nonce . is prime. We can say that not only is $q$ prime, but also $q$ is rare in that $H_S(q)$ is less than the small target $d$. 

Gurevich in formulating the conjecture about a logic that could capture $\mathsf{P}$ requires the logic to be computable in two ways: (1) the set of sentences legally obtainable from the vocabulary $\sigma$ has to be computable, given $\sigma$; and (2) the satisfiability relation needs to be computable from $\sigma$, i.e., ordered pairs consisting of a finite structure $M$ and a sentence $\varphi$ such that all models isomorphic to $M$ satisfy $\varphi$. Also, significantly for comparison with this randomized logic result, the vocabulary $\sigma$ has to be finite. (A vocabulary is a set of constant symbols and relation symbols, for example, equals sign, less-than sign, $R_1,R_2,\ldots$) This is a paraphrase of Definition 1.14 of this paper by Gurevich, which is reference [9] in the quote Kaveh gave. The paper about BPP and randomized logic presents a significantly different framework. It starts with a finite vocabulary $\sigma$, and then considers a probability space of all vocabularies that extend $\sigma$ with some disjoint vocabulary $\rho$. So a formula is satisfiable in the new randomized logic if it is satisfiable in "enough" logics based on extensions of $\sigma$ by different $\rho$. This is my butchering of Definition 1 in the Eickmeyer-Grohe paper linked to by Robin Kothari. In particular, the vocabulary is not finite (well, each vocabulary is, but we have to consider infinitely many distinct vocabularies), the set of sentences of this logic is undecidable, and the notion of satisfiability is different from the one put forth by Gurevich. 

What most intrigues me is the ability to apply the theory of computer science to other disciplines, especially biology and cell biology. If this notion intrigues you also, I'd suggest you take a look at the following: an essay by Jeannette Wing about the importance of Computational Thinking; and an NSF report about applying the Algorithmic Lens to other scientific disciplines. 

Finally, as an example of using Bitcoin certificates in conjunction with Koiran's result, consider Chao and Gao's description of automated proofs of interesting geometric theorems. Given a problem in plane geometry, Chao and Gao construct systems of algebraic equations for the hypotheses and conclusion, and apply the Wu-Ritt method of characteristic sets to test whether the conclusion polynomial follows from the hypothesis polynomials. 

The above protocol is not perfect, some kinks I think would need to be worked out. For example, it's not clear how to generate two random graphs $G_0$ and $G_1$ that satisfy good properties of rigidity, for example, nor is it clear how to adjust the difficulty other than by testing for graphs with more or less vertices. However, I think these are probably surmountable. But for a similar protocol on knottedness, replace random permutations on the adjacency matrix of one of the two graphs $G_1$ and $G_2$ with some other random operations on knot diagrams or grid diagrams... or something. I don’t think random Reidemeister moves work, because the space becomes too unwieldy too quickly. [HTY05] proposed an Arthur-Merlin protocol for knottedness, but unfortunately there was an error and they withdrew their claim. [Kup11] showed that, assuming the Generalized Riemann Hypothesis, knottedness is in $\mathsf{NP}$, and mentions that this also puts knottedness in $\mathsf{AM}$, but I’ll be honest I don’t know how to translate this into the above framework; the $\mathsf{AM}$ protocol of [Kup11] I think involves finding a rare prime $p$ modulo which a system of polynomial equations is $0$. The prime $p$ is rare in that $H(p)=0$, and the system of polynomial equations corresponds to a representation of the knot complement group. Of note, see this answer to a similar question on a sister site, which also addresses the utility of such "useful" proofs-of-work. 

Related: Rengo Kriegspiel, a blindfolded, team variant of Go, is conjectured to be undecidable. $URL$ Robert Hearn's thesis (and the corresponding book with Erik Demaine) discuss this problem. They prove other problems undecidable through "TEAM COMPUTATION GAME", which is reduced directly from Turing machine acceptance on empty input (see Theorem 24 on page 70 of the thesis). So it seems to me that such a reduction would imply Rengo Kriegspiel is Turing complete. On the other hand, their discussion says that this reduction would be very difficult (see page 123). So while this is a potential avenue, it appears that it has been looked into previously. 

A paper by Abboud et al. recently accepted to SODA 2016 shows that subtree isomorphism cannot be solved in $O(n^{2-\epsilon})$ time unless the strong exponential time hypothesis is false. Of course, we can verify an isomorphism in linear time. In other words, the SETH gives us a natural problem in $\sf{P}$ with an $\Omega(n^{1-\epsilon})$ gap between finding and verifying. In particular, a $O(n^2/\log n)$ algorithm is known for rooted, constant-degree trees (for which Abboud et al.'s lower bound results still apply). So under SETH, the almost linear find-verify gap is essentially tight for this problem. 

At the beginning, you will have one chunk. Ordered file maintenance doesn't make sense for very small arrays. Pick a smallish number (like 64 or 1024), and only start this whole chunking method once you grow above this small number. In the small array do something naive, pushing elements around as necessary. 

The hash family you give has expected max load $\tilde{O}(n^{1/3})$, as shown in this recent paper: Mathias Bæk Tejs Knudsen, "Linear Hashing is Awesome" 

You may be interested in the $k$-creative sets, invented in [1] as a conjectured counterexample to the Berman-Hartmanis conjecture that all NP-complete sets are isomorphic to SAT. "Isomorphic" is different from a Turing reduction (significantly weaker in fact), but these sets were shown to be NP-hard directly and as far as I know there's no known reduction to SAT. That said, by the definition of NP-completeness there must be some reduction between the two, so while this meets the criterion of "no known" reduction it may not be exactly what you're looking for. [1] Joseph, D. and Young, P. Some remarks on witness functions for nonpolynomial and noncomplete sets in NP. Theoretical Computer Science. vol 39, pg 225--237. 1985. Elsevier. 

I am most interested in how these failures relate to consensus and other distributed agreement problems. Thank you. 

I've started looking at incidence structures and combinatorial designs (possible motivation: to upper-bound some structures in generalized self-assembly), and the Wikipedia article makes the following interesting-yet-unexplained statement: block designs have application to software testing. (The Wikipedia page with the claim is here). My google-fu doesn't pick up a good reference for this application. Can anyone give me a lead? 

Stanford University now has a Youtube channel, with free access to HD video of full courses on everything from dynamical systems to quantum entanglement. More conferences and workshops are videotaping their talks. What are videos online that you think everyone should know about? I'll seed this with a few answers to presentations that are mostly expository, but what I'm hoping might happen is that this community wiki could turn into a resource to share excellent presentations of new research, as well as a place to learn (or reinforce) background in an unfamiliar area. 

This answers the question asked in the question-title, but not the one asked in the question. A shocking example of jump-in-hardness arises from the question, "How many satisfying assignments does a planar formula have, modulo $n$?" This was widely thought to be #P-hard, and it is for "most" values of $n$, but if $n$ is a Mersenne integer (for example $n=7$, because 7 is of form $2^3-1$), then the answer can be computed in polynomial time. This was first discovered by Valiant, in his groundbreaking Holographic Algorithms paper. 

Suppose we have an orthogonal polygon with holes (all walls are axis-parallel). All vertices can be on integer coordinates, if that helps. Partition the polygon into rectangular rooms. I would like to find the best room to start from, to visit all the rooms (rectangles). There's a limitation on my movement: in any room, I can only leave by two directions, say north and west. (Here best means there would only be one source in the plane dual graph with directed edges showing how to walk from room to room. If more than one source is required, I wish to minimize them.) I have been looking at art gallery problems, and at VLSI papers on building rectilinear floorplans from network flows, and they are all tantalizingly close but far. Can anyone provide suggestions so I can focus my search/proof construction? EDIT to fix problem pointed out by Peter Taylor. I can choose two directions per room. (probably they need to be adjacent, so NE is ok but NS is not.) If I enter one room northward, I am automatically choosing South as one of thst new room's directions. (so only two in or out directions per room) If I choose a direction, and there are multiple rooms adjacent in that direction, I can enter all of them (and all of them then have the reverse direction assigned as one of their two directions), so the naive greedy approach would be to choose the direction that maximizes the number of rooms I can enter at that stage. I hope this is now complete, and understandable.