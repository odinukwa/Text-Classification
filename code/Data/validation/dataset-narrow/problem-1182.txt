Ryser: $n(n-2)2^{n-1} + n$ additions and $(n-1)(2^{n}-1)$ multiplications. Ryser+Gray code: $n(2^{n}-2)$ additions and $(n-1)(2^{n}-1)$ multiplications. Number of multiplications: For each nonempty subset of $[n]$, $n-1$ multiplications are used to multiply $n$ sums together. Number of additions for Ryser: for each nonempty $S \subseteq [n]$, and for each $i \in [n]$ you compute $\sum_{j \in S} a_{ij}$ which uses $|S|-1$ additions. $\sum_{\emptyset \neq S \subseteq [n]}(|S|-1) = \sum_{k=1}^{n} (k-1) \binom{n}{k} = \sum_{k=1}^{n} k \binom{n}{k} - \sum_{k=1}^{n} \binom{n}{k} = n2^{n-1} - (2^{n}-1)$. Additions for Ryser+Gray: The Gray code version does not give you a smaller formula, but only a smaller circuit (which is still good, I just thought it was worth pointing out). Its savings require the re-use of previously computed quantities. For each $i \in [n]$, it does a Gray code over the nonempty sets $S \subseteq [n]$. Since there are $2^{n}-1$ such sets, and each transition of the Gray code involves a single addition/substraction, that gives the $2^{n}-2$. 

An arguably more natural problem - not designed specifically for the purpose of finding a problem that might be in $\mathsf{BPP} \backslash \mathsf{RP} \cup \mathsf{coRP}$, and also not so closely related to a problem known to be in $\mathsf{coRP}$ - is furnished by Problem 2.6 of [1]: Given a prime $p$, integers $N$ and $d$, and a list $A$ of invertible $d \times d$ matrices over $\mathbb{F}_{p}$, does the group generated by $A$ have a quotient of order $\geq N$ with no abelian normal subgroups? In [1] it is shown that this problem is in $\mathsf{BPP}$. While asking for quotients with no abelian normal subgroups might seem eccentric, the class of groups with no abelian normal subgroups (sometimes called semisimple) is actually fairly natural from the point of view of the structure theory of groups. See [2] and references therein. [1] L. Babai, R. Beals, A. Seress. Polynomial-time theory of matrix groups. STOC 2009. [2] L. Babai, P. Codenotti, Y. Qiao. Polynomial-time isomorphism test for groups with no abelian normal subgroups. To appear, ICALP 2012. 

The problem you describe has definitely been considered (I remember discussing it in grad school, and at the time already it had been discussed long before then), though I can't point to any particular references in the literature. Possibly because it is linearly equivalent to uncolored graph isomorphism, as follows (this is true even for canonical forms). Call the problem you describe EQ-GI. GI is just the special case of EQ-GI where each graph has just one equivalence class consisting of all vertices. In the other direction, to reduce EQ-GI to GI, let $(G, \sim_G)$ be a graph with equivalence relation with $n$ vertices, $m$ edges, and $c$ equivalence classes. Construct a graph $G'$ whose vertex set consists of the vertices of $G$, together with new vertices $v_1, \dotsc, v_c$, one for each equivalence class in $=_G$, as well as $n+c+1$ new vertices $w_0, \dotsc, w_{n+c}$. Connect the $w_i$'s in a path $w_0 - w_1 - w_2 - \dotsb - w_{n+c}$, connect each $v_i$ to $w_0$, and for every vertex in $G$, connect it to the corresponding equivalence class vertex $v_i$. Then $G'$ has at most $n + 2c + n +1 \leq O(n)$ vertices and can be constructed in essentially the same time bound. (It also has at most $m + n + c + (n+c+1) \leq m + 4n + 1 \leq O(m+n)$ edges - which is $O(m)$ for connected graphs - but that's somewhat less relevant since most GI algorithms have running times that essentially only depend on $n$.) Update: Since there was some confusion in the comments, I'm adding here a sketch of the correctness of the above argument. Given $(G_1, \sim_1)$ and $(G_2, \sim_2)$, let $G_1'$ and $G_2'$ be the graphs constructed as above; let $v_{i,1}$ denote the vertex $v_i$ from above in $G_1'$, and $v_{i,2}$ the one in $G_2'$, and similarly for $w_{i,1}$ and $w_{i,2}$. If there is an isomorphism $G_1' \cong G_2'$, it must send $w_{i,1}$ to $w_{i,2}$ for all $i$, since in each graph $w_{n+c}$ is the unique vertex that is the endpoint of any path of length at least $n+c+1$. In particular, $w_{0,1}$ maps to $w_{0,2}$. Since the neighbors of $w_0$ that aren't $w_1$ are exactly the $v_i$, the isomorphism must map the set $\{v_{1,1},\dotsc,v_{c,1}\}$ to the set $\{v_{1,2},\dotsc,v_{c,2}\}$ (and in particular both $\sim_1$ and $\sim_2$ must have the same number, $c$, of equivalence classes). Note that the isomorphism need not send $v_{i,1}$ to $v_{i,2}$ for all $i$, but is allowed to permute the indices of the $v$'s so long as the corresponding equivalence classes can be mapped to one another. Conversely, based on this description of how isomorphisms between $G_1'$ and $G_2'$ can look, it is easy to see that if $(G_1, \sim_1) \cong (G_2, \sim_2)$ then this gives an isomorphism $G_1' \cong G_2'$. 

Moderately exponential time and $\mathsf{coAM}$ (for the opposite of the problem as stated: Coset Intersection is typically considered to have a "yes" answer if the cosets intersect, opposite of how it's stated in the OQ.) Luks 1999 (free author's copy) gave a $2^{O(n)}$-time algorithm, while Babai (see his 1983 Ph.D. thesis, also Babai-Kantor-Luks FOCS 1983, and a to-appear journal version) gave a $2^{\tilde{O}(\sqrt{n})}$-time algorithm, which remains the best known to date. Since graph isomorphism reduces to quadratic-sized coset intersection, improving this to $2^{\tilde{O}(n^{1/4-\epsilon})}$ would improve the state of the art for graph isomorphism. 

But classifying all equivalence classes is also stronger than what we usually care about, since the number of equivalence classes that show up as natural complexity classes is comparatively small (despite the forbidding size of the complexity zoo). However, there are other "numerical" invariants we can associate to languages. One such is their density: the density of a language $A$ is the function $d_A(n) :=$ number of strings in $A$ of length $\leq n$. Note that density is preserved, up to a polynomial change, by poly-time isomorphisms, but not necessarily by polynomial-time equivalences (e.g. all languages in $P$ are polynomial-time equivalent, but they can have wildly different densities). We know things like: if $A$ is polynomially sparse ($d_A(n) \leq poly(n)$) then $A$ cannot be $NP$-complete unless $P=NP$ (Mahaney's Theorem). There are lots of other results about sparse languages and their relation to complexity classes. For good surveys, see Cai and Ogihara "Sparse Sets versus Complexity Classes" in Complexity Theory Retrospective II (available online - just Google) and Hemaspaandra and Gla√üer's pair of articles "A Moment of Perfect Clarity I,II" in SIGACT News. 

This is basically what dynamic data structures and streaming algorithms are about. A few links, off the top of my Google: 

If you're interested in the group theory that's relevant for Graph Isomorphism, then in addition to Seress's book that David Eppstein mentioned, I would highly recommend 

If $GI$ is in $coNP$, then we would have the result: $GI$ is not $NP$-complete unless $NP=coNP=PH$. (Currently known: $GI$ is not $NP$-complete unless $\Sigma_2 P = \Pi_2 P = PH$). Since $GI$ is in $coAM$, obviously derandomizing $coAM$ (doi link) would put $GI \in coNP$, but I don't know of any candidate graph properties for putting $GI \in coNP$ otherwise. I look forward to more answers though! Interestingly, in that paper they also show that Graph Non-Isomorphism has subexponential size proofs -- that is, $GI \in co NSUBEXP$ -- unless $PH = \Sigma_3 P$. This is at least headed in the direction of showing conditionally that $GI \in coNP$. 

The Complexity Theory Companion by Hemaspaandra and Ogihara. It's not exhaustive in terms of techniques (I imagine no such book is), but I think it qualifies as an answer to your question. Here are the titles of the chapters: 

Note, however, that if instead of multiplicities you merely want a separating module, then the strong perm v det conjecture is true if and only if there exists a separating module. 

Every $k$-critical graph (requires $k$ colors but every subgraph needs at most $k-1$ colors) is $k$-constructible, and for all graphs $G$ $\chi(G) \geq k$ iff $G$ contains a $k$-constructible subgraph. This is a bit more complicated than what you asked for, since you'd also need to allow adding vertices, adding edges, and merging vertices, but it still feels like it's in the same spirit. The Hajos number of a $k$-colorable graph $G$ is the minimum number of steps needed to construct $G$ from $K_k$; there is no polynomial upper bound on the Hajos number unless NP=coNP. 2) Although not about graphs in particular, people have also studied circuits over sets of natural numbers. Here each input is a finite subset of $\mathbb{N}$, the gates are union, intersection, complement, + and times. So, in between (?) addition chains and graph addition chains, you might consider "subsets-of-$\mathbb{N}$" addition chains, by allowing only restricted inputs and a restricted gate set. As you can see from the Wikipedia table, several of the related problems are NP-complete, such as minimizing circuits with only $\cup, +$ gates (which might reasonably be considered "addition chains", esp. if you restrict the inputs to be all singletons, e.g.), or minimizing formulae with $\cup,\cap,+$ gates. 

Many people have mentioned Kolmogorov complexity or its resource-bounded variants, but I think something closer to what you're looking for is the notion of (logical) depth. There are several variants on depth, but they all try to get at something like what you're talking about. In particular, neither purely random strings nor very highly ordered/repetitive strings are deep. One notion of depth is intuitively: a string is deep if it has a short description, but the only way to reconstruct the string from that short description takes an inordinate amount of time. This is the notion of depth and several others are introduced and developed in [1]. The other standard reference is [2]. I would look at those, then do a forward reference search. [1] L. Antunes, L. Fortnow, D. van Melkebeek, N. V. Vinodchandran. Computational depth: concept and applications. Theoret. Comp. Sci. 354(3):391--404. Also available freely from the author's webpage. [2] C.H. Bennett. Logical depth and physical complexity. In R. Herken (Ed.), The Universal Turing Machine: A Half-Century Survey, Oxford University Press, Oxford (1988), 227‚Äì-257. 

Here's what they show. Let $G_{i} \leq S_{i}$ be a sequence of permutation groups. Let $s(G_{i})$ denote the number of orbits of $G_{i}$ in its induced action on $\{0,1\}^{i}$ (by permutation of the coordinates). Let $\mathcal{F}(G)$ denote the class of languages $L$ such that $L \cap \{0,1\}^{n}$ is invariant under $G_{n}$. Then all languages in $\mathcal{F}(G)$ have circuits of size at most $poly(s(G))$ and depth at most $poly(\log(s(G))$, and this is essentially tight. 

Actually, I think that the phenomenon here is that GI in some sense has too much structure. It is in some ways the group-theoretic nature of its witnesses which leads to the $\mathsf{coAM}$ algorithm for GI and is one of the pieces of technical evidence why people believe GI is not $\mathsf{NP}$-complete. My thinking here is that there is so much structure that the problem is "too rigid" to encode arbitrary $\mathsf{NP}$ problems. Another way to capture this is the fact that the counting and decision versions of GI are equivalent, whereas for all known $\mathsf{NP}$-complete problems this is not the case unless the polynomial hierarchy collapses. This can also be viewed as capturing some aspect of structure/redundancy: for unstructured, general problems, counting solutions seems to be much harder than telling if one exists, whereas the extensive structure of GI allows one to show that counting and decision are equivalent. (On the other hand, group isomorphism seems even more structured than GI, yet no counting-to-decision reduction is known for group iso. Perhaps this says that GI is in sort of a "just right" level of structure - too structured to be NP-complete, but unstructured enough to allow a counting-to-decision reduction.) 

studied partially reversible algorithms - that is, if you are willing to pay some entropy, for standard algorithmic tasks can one improve upon the general irreversible-to-reversible simulations mentioned above. Reversible computing has a whole community of researchers devoted to it, viz. the Reversible Computing conference, now in its 10th year. It has actually been known for a long time, going all the way back to Landauer and Bennett, that the relationship between computational irreversibility and entropy generation is more subtle than is suggested by the tagline "erasing a bit generates $\ln(2)$ entropy." However, in the past 20 years or so nonequilibrium statistical mechanics has advanced to the point that this more subtle relationship can be captured by precise numerical equations involving not just entropy difference, but also a difference of KL divergences, see 

First of all, the relation you defined is usually called polynomial-time isomorphism ($\cong^p$). Although isomorphism is an interesting notion that has been studied, the (weaker) relation that is more frequently of concern in complexity is polynomial-time equivalence: $A$ and $B$ are equivalent ($A \equiv_m^p B$) if there are polynomial-time many-one reductions (aka Karp reductions) from $A$ to $B$ and vice versa, but those reductions need not be inverses to one another, and need not even have polynomial-time inverses. Sometimes we also care about equivalence under polynomial-time Turing reductions rather than many-one ($\equiv_T^p$), aka Cook reductions. For example, either of these notions of equivalence is "good enough" for $P$ vs $NP$ (that is, you don't need to consider isomorphism classes). From the perspective of polynomial-time equivalence, there is partial "good reason" that you don't hear about numerical invariants: they can't work in general. A theorem in Andrew Marks's thesis states that $\equiv_T^p$ is complete for countable Borel equivalence relations (the introduction of his thesis gives a good overview of Borel equivalence relations and their significance). In particular, this implies that there is no Borel function $f: 2^{\mathbb{N}} \to \mathbb{R}$ such that $A \equiv_T^p B$ iff $f(A) = f(B)$. The reason I say this is only partially a good reason is that there still might be a Borel function $f:2^{\mathbb{N}} \to \mathbb{R}$ such that if $f(A) \neq f(B)$ then $A \not\equiv_T^p B$. Or there might be a non-Borel function that does the job, but if there is we're a little unlikely to find it...