Well, Game engine is a generic term, Physics engine is more specific, the "problem" is that the functionalities that a game engine provides are up to the developers that have coded that particular game engine. There are very basic game engine that have no physic support or they expect you to add to it manually, and game engine that support physics and fractures in real time. Your view shouldn't be about how they work together in the first place, just look at what a game engine offers and if you need a physics engine add it to your code. There are also some engines that mimic the physic with pre-baked collision and explosions, there are several approach to this, depending on what you have, what you want to achieve and what is your target machine, you better look to the features and how they are implemented, only the name "physics engine" can't tell you what you are dealing with. 

If i have a vertex shader that manage some movements and variations about the position of some vertex in my OpenGL context, OpenGL is smart enough to just run this shader on only the vertex visible on the screen? This part of the OpenGL programmable pipeline is not clear to me because all the sources are not really really clear about this, they talk about fragments and pixels and I get that, but what about vertex shaders? If you need a reference i'm reading from this right now and this online book has a couple of examples about this. 

It seems you are using non-power of 2 texture dimensions and mipmapping which calls for trouble because the minifying interpolation has incomplete information along the edges. Prefer to manually expand all textures to power of 2 before loading. Use the desired color for those padding pixels. If you have many small textures of arbitrary dimension it might also be a good idea to create a single power of 2 texture atlas. 

@Byte56 is right. You only want a direction vector without any information about the distance to the target. You can get that by normalizing your vector to unit length. Do this: 

All the games I know of that display lots of terrain make heavy use of LODing to create the illusion of huge amounts of very detailed surfaces. The CryEngine is king at this. And in World of Warcraft you can even see the LOD transitions when using low-performance settings. The second post at $URL$ describes many different techniques to visualize huge terrains efficiently. Especially the HLOD article $URL$ seems helpful. I doubt that displacement mapping will get you anywhere near the performance obtained by simply reducing the number of triangles for far-away terrain. Especially for mobile devices lacking hardware support. 

Look out for Nintendo DS titles. They tend to use the stylus for game mechanics similar to yours. There are rhythm games like Elite Beat Agents employing something similar to your attack/defend game mechanics but based on music. Elite Beat Agents is actually quite challenging but fun to play. I'd also recommend playing The World Ends with You! It's an action RPG with very similar combat mechanics. It's also quite innovative and unique. Regarding crippling the player (controls) I'd always advise not to. I haven't seen a single game where not-being-in-control due to darkness, staggering, impairing effects, etc. was adding fun. Realism != Fun != Immersion. 

my goal is replacing with any other operation on the fly with my C++ program, maybe with a GUI, but in general terms with C++, the problem is that until now i'm able to run a shader only after compiling it, so i have something like a static approach. The same goal applies to the values of the vars that i would also like to change through C++. It's possible with a programmable pipeline? I'm not interested in performance, just if is possible for the C++ to dynamically communicate and exchange data with the OpenGL pipeline. 

I'm starting with the programmable pipeline and the shaders in C++ for OpenGL 3.0+, i would love to be able to change some settings on the fly, for example replacing a function with another function, supposing that i have a shader with an operation like 

The only real thing that is different is the amount of devices, Apple just sell 1-2-3 new product each year, Android offers 1 new product every day/week. The emulator it's not buggy, it's just not intended for profiling, if you want to profile an Android application you have to do the same thing that you have done for iOS: consider the lowest profile device that match your requirements and buying it. You are supposed to have at least a basic know-how about the ARM architecture, otherwise you can make a difference between all the devices on the market, begin to outline the hardware features that are important for your application and buy that device for real testing. 

True. GL_PROJECTION is for choosing between orthogonal (2D, UI) and perspective (3D) projection. Do not touch yet. 

Note the and instead of and . The difference is the preserved perpendicularity of z on the plane if is moved away from the origin. I guess you wanted to do that through but that doesn't suffice. Also note that I normalized . This will result in orthonormal XYZ on both planes and and means that scale is preserved. If the triangles and are not similar (i.e. one is stretched) then but . Don't normalize anything if you want to preserve stretching. 

No and yes. No, only one model is used. Yes, there is a way to ignore certain parts of a model. Actually it is quite simple: You don't animate them. And when you have two animations that don't overlap in "parts affected" it is trivial to combine them (i.e. running them at the same time). Technically the "ignore" part of the animation matrix is the identity matrix and multiplying both animation matrixes produces the desired combined animation. 

Modelling everything in the metric system I also observed that gravity feels much too weak with regards to the player jumping (in a platformer). Much like "on the moon", "jelly", "too much phyics", not "arcade" enough. On the other hand players in games are regularly able to jump to great unrealistic height too. TLDR: high gravity feels very fast paced and arcade, realistic gravity sometimes might not give the desired game experience. 

it's performance hungry, especially for the memory ( RAM and CPU/memory controller ), this also means that to run a simple game you need at least a computer with medium range specs the JVM it's not standardize, especially on Mac, the first official Java version on Mac is the actual version ( Java 7, first and only one ), the previous versions are provided by Apple and are not standard, especially for the part related to the window system and the graphical appearance, also in many GNU/Linux installations the default JVM is OpenJDK and not Java from Oracle Java generates bytecode and not compiled code, even if you obfuscates the code it's really really easy to crack, sometimes it's also easy to do reverse engineer If you distribute java code you are implicitly asking the user for installing the JVM, most of the users do not have this abilities and most of the times they just expect that your program will run/install right after the download without additional software for what i know Machinarium is in Flash ( probably even worst than Java ), the original one on PC/MAC/Linux, the others are porting. if you are interested in Java and you want to code games, do yourself a favor and just use C# 

I know this 2 products but i have never used them for production, since I have a bunch of cool shaders i would like to use them under OpenGL with GLSL but i don't know where to start. If it's not possible to convert them directly, where i can learn the Renderman syntax for the shaders? 

OpenGL mixes camera and model transformations which is highly unintuitive at first (GL_MODELVIEW). Read the tutorials at the end on my answer to better understand things. 

Model space! See the ancient but still excellent NeHe tutorials for more info on these topics: $URL$ , especially $URL$ 

All zeroes but ones on the diagonal. Called identity matrix. Does nothing when multiplied on a vector or matrix. Use glLoadIdentity to reset matrices. 

But be aware: Getting started on CUDA is easy, getting started on physics simulation is a good bit harder, but combining both is quite a challenge! 

In my opinion it is perfectly fine to model the behavior with a FSM. Oftentimes we create inferior models with cluttered if-statements like suggested in the comments. But the FSM is not the problem. To me it seems like you are experiencing jittering movement because your AI ship is always just at the border between "too far" and "close enough". Think about widening this border by using too different radii. One for getting a bit closer than absolutely necessary (r1=50m) and one for "oh I'm no longer close enough" (r2=80m). Where r1 < r2 and r2 = your original radius. Go to state once you are within r1 and only go back to when you are within r2 no longer. In the meantime fire at the player and dodge bullets. 

I'd advice on using SQL databases whenever you can. They are robust, well known, easy to interface, scalable and all. The only downside might be performance. But as you are not asking about how to store your live game objects on every update performance of the database itself will very likely not be a problem. Make sure to learn about serializing you savegame-relavant part of your game state. Pushing those into a database should be fairly easy then. 

Having an application that uses shaders that have been wrote in GLSL, what is the best strategy for the distribution in the real world and for the desktop and mobile? I'm aiming to distribute this in a binary form or as plain serialized text, i would like a good suggestion on this. 

There is this Windows Advanced Rasterization Platform on the most recent Windows platforms which i think it's what you are looking for or there are commercial solutions like Pixomatic. 

There are different technologies for this, there is no standard, at least no one that i'm aware of. The multi-monitor technology from ATI is named eyefinity and it's probably the most mature technology among the ones available on the market. The eyefinity capabilities are accessible through the AMD display library SDK . Nvidia calls its multi-monitor technology nVidia Surround and there are little to none informations for the developers, there is this page that mix the surround technology with the 3D technology and i don't think that is useful at all. If you are interested in this you can try to browser and ask in the Developer Zone. 

The answer to your 3 questions is subject to the laws that are applied in your country, also a trademark is a different concept if compared to a registered IP or a registered copyright, and there are also other possible options. Each country has its own law and usually its own patent office, also do not assume that a registered IP is protected worldwide, this is a political issue and can also affect your distribution strategy. 

Maik is right, Baraff's papers are an excellent start, but don't forget Chris Heckers write-up on rigid body dynamics: $URL$ ! Also his advice on "[..] you will throw your engine away" is entirely true. But you will learn a lot! Regarding the CUDA/OpenCL part of your question: If you know CUDA then switching to OpenCL becomes very easy. I'd recommend learning CUDA first, because there are so many good tutorials, example code and computation libraries out there. For example: 

It depends if any of your physics can happen outside the flat player space. As ghostonline said debris and ragdoll animations are a classic example of out-of-2D physics in an 2.5D game. Another example is bullets: If there are any projectiles in your game, do they follow the curvature of your 2D space or do the travel straight ahead even if that means they will leave those bounds? Also mapping a physical 2D space to a curved 3D visualization correctly is (correct me if I'm mistaken) .. not that easy. You will need an injective projection functions probably involving lots of splines or something similar. While having curved 2D game spaces is a nice add-on, it requires quite some overhead for the code. That might be the reason why there is no such thing in Trine. But the game was fun anyway, wasn't it? I'd think twice about a feature like that. 

You can check for talent dependencies programatically by querying the complete talent table, and building a linked tree. You can also do that with SQL but it will require either recursive subselects or lots of queries. Better do it in your code. If there are multiple dependencies, like for example depends on AND use two tables to represent the dependency graph: 

you will be fine with a commercial solution, otherwise if you want the maximum flexibility and you have the know-how, you probably want to code your own stuff and avoid spending money and legal issues. Also all the software that you mentioned offers legal problems when it comes to using them on the job, some of them offers more complex issues, because for example the UDK, it's not really free for every use, if you are going to use it in the place where you work, you have to pay, no matter what you are producing with it. There are also nasty things like the standard Autodesk EULA allows Autodesk to basically fetch your computer for data without explicit warnings ans in "silent mode". If i was you, i would switch to Blender and Gimp, this 2 are really powerful software, with a rich set of APIs and 0 legal issues, and they are free. 

Yes, also this is a common scenario for both desktop and mobile users, with OpenGL the fixed pipeline approach is just deprecated and when using old code on modern devices you are just guessing, because any GPU maker that wants to stick with a modern OpenGL approach is not forced to support old functions and the old approach for the pipeline. These days you get OpenGL ES 2 capable devices from the low end market up to the high end, and the OpenGL ES 3 will come soon, adopting OpenGL ES 1.x is just an old and deprecated approach for the market of today. OpenGL ES 2 introduces the programmable pipeline on mobile devices discarding the old fixed-pipeline approach; probably for this reason you find it more difficult to use, but just a change of mindset and some hours passed on coding will make you change your idea about this.