The solution to this problem might not be one big change; rather, lots of little changes might improve participation from girls and women in CS classes. Trying to create real-world scenarios, in a balanced classroom environment may bring some more success, but it's often hard to know if the solutions you try actually have any effect. Ensuring the culture of the class doesn't become too male-oriented might also help to avoid bias against women in the demographics. I'd be very interested to hear anyone's experiences with applying methods like this, and whether they did seem to make a perceptible difference. 

It might be worthwhile to encourage your students to consider how and why they wrote their user stories as they did. You can check that they're not developing user stories that are too broad (too many epics rather than stories) as they go along if you want to provide some support and prevent them from being too unrealistic. As you should probably be estimating the amount of work for each user story, ask them to document that so you can check it. Unrealistic timings—or no timings at all—should be caught early so that you can make sure they finish the project on time. If you follow the 'planning game' of XP, then you can also look at how the requirements were sorted by risk and value. Yet another point to document and mark if needed. As mentioned by Kaneki, sprint retrospectives provide time for your students to reflect on their progress. Encourage them to use this wisely in place of a huge specification detailing implementations, tests, etc. In short, there's loads to document about Agile, but you might not need to write everything on paper. If it's easier for you, consider just being a part of the retrospective meetings and looking at how these go instead of meticulously writing down every detail. 

Let's consider your Data Structures course example. The material from there is used throughout CS, and more advanced courses probably expect you to have completed Data Structures already, and will assume understanding. If the instructor never actually introduces to all the data structures that the syllabus lists, then your later course will be assuming knowledge that the student doesn't necessarily have. It depends what exactly you mean by not making content King—if you simply don't teach some of the material and don't mention it much, then your students won't know it. However, something to consider: 

Personally, I'd introduce Sinatra first. Which one of these is going to be easier to explain? Sinatra's "Hello World" example... 

There's an awful lot of stuff included, but then again, all the batteries you'll ever need are included, too. For playing with neural networks, Keras might be worthwhile. That said, your students may derive some value from implementing the algorithms themselves, at first. The key is to be able to find truly motivating problems: 

Note that I've discussed a lot without ever actually explaining how you could write any programs. Of course, any machine learning class would be a little incomplete if your students had never actually applied their skills. Since your students know Python, I can highly recommend scikit-learn. It's widely regarded as an exceptionally good ML library, and the API is very friendly — you can almost treat it as LEGO, and plug together the pieces needed to do your classification/regression/clustering... even without really knowing how each piece works entirely. You can get functional (though not exactly effective) solutions simply by connecting the appropriate pieces in a pipeline. For example, if you wanted to classify some texts, you'd just: 

There are all sorts of things you could cover — machine learning is an extremely interesting and growing field, with many different approaches and tools you could explore. Some of the more popular tasks for machine learning algorithms include classification, regression and clustering. Not every application fits into this grouping (e.g. AlphaGo, the Go playing program which beat Lee Se-dol). I might suggest starting with Naive Bayes classifiers. Your motivating example here could be spam filtering; Naive Bayes classifiers were used in some of the first 'learning' spam filters, dating back to the 1990s. If your students are familiar with Bayes' theorem, the assumptions of NB classifiers shouldn't be a huge leap (you may find this derivation interesting). There are also various other interesting options such as random forests (apparently used by Quora to find duplicate questions), support vector machines and so forth which could be explored potentially. Many of the most 'fashionable' techniques involve neural networks, and I would recommend spending a decent amount of time with the theory. Unlike some of the classifiers and regressors I mentioned earlier, neural networks tend to be a bit more involved — a Naive Bayes classifier essentially just needs to be given some data in an appropriate form and is "plug and play", so to speak. The (free) online book Neural Networks and Deep Learning gives a reasonably accessible explanation of neural networks in their various forms (starting with perceptrons, leading towards sigmoid neurons, gradient descent, backpropagation, deep learning, etc.). As you can imagine, there is an immense amount of content even in just the field of neural networks. Likely you won't want to cover all of the book's topics, but you don't need to go too far to reach another interesting motivating example: classifying the MNIST dataset of handwritten digits. That's something which is relatively hard traditionally, but much simpler with the usage of a neural network. 

I did a (rather unscientific) study of a few popular tutorials for Python to see what they did after "Hello, world": 

Giving students credits for a cloud service like AWS might be useful in this case. Amazon's pricing is reasonable for a cloud instance: 

Michael0x2a has a good point that some services may have free credits which you might be able to tap into; for example, Azure offer $100 of credit to students; AWS Educate is also pretty generous, with member institutions gaining \$200 per instructor plus \$100 per student (non-member institutions get less). 

In an ideal world, helping a student to find a passion in CS would be great. But for some people, a subject conflicts so much with their abilities and interests that it's not likely they'll ever enjoy the subject with a real passion. And that's fine. You can't force someone to like a subject—it's an exercise in futility—but, if you're willing to put the effort in and understand what the student is interested in, you could make your course more relevant to them. With a curriculum that's very rigid, you might not have much scope for changing your materials too much, but it would help to know exactly what your student likes or dislikes. For example, if your student finds the mathematical side of CS difficult, you might be able to change your teaching to use analogies and ideas from other subjects. Perhaps you could think of a program as a 'recipe', or a 'script', if that helps. However, you need to be mindful not to take analogies too far, or focus your teaching so much on one person that it becomes detrimental to others. In a large class, you might not really be able to change a lot, but if you have time, you could discuss multiple ways of thinking about a problem. In other words: try to teach relevant content, and do the best you can for that student. But if they have no intention of pursuing the subject, there is only so much you can do for them, and some of the topics in the curriculum might be irrelevant to them. And, with teaching, the curriculum marches relentlessly on, whether everyone understands or not. If you're able to deliver more personalised teaching, you probably can make a bigger effect, but it might be infeasible. 

Image licensed under the CC BY-SA 3.0 by Bidgee of Wikimedia Commons. Floors (in European countries) are typically numbered with 0 (or G) as the ground floor, then 1 as the first floor above ground, etc. This could easily be compared to a list/array of floors, with being ground, being the first floor, and so on. Note that this analogy won't work particularly well in North American countries, as their convention is to number the ground floor as 1. Nevertheless, the visual element of a building and lift numbered from zero could serve as an intriguing example to illustrate zero-based indexing. 

What's the point? Why does the number of lines in the project matter all that much? Unless the code is extraordinarily long or short (i.e. orders of magnitude away from what is expected), lines of code aren't a good indicator of whether a project is good or bad. I've heard of one example where some students were set the task of creating a Caesar cipher1 program. If you're aware of it, you'll know that it can be trivially solved by using modular arithmetic2: 

You ask it to give you a list of numbers from $0$ to $n - 1$, and it gives you a . The new doesn't do that. Instead, it makes an object that knows the start, end and step that you asked for... but it doesn't give you a list! This object will, however, give you the next element of the sequence if you ask for it. Running specifically asks for the list of all the integers, but in the vast majority of cases, you don't need the list, so there's no point making it and storing the whole thing in memory. Imagine you wanted to print the numbers 1 to 1000. Python 2's would generate every number up front, before you can begin iterating. Clearly, this is very wasteful and pointless; it's much easier to work out each number at the end of the iteration, and doesn't require nearly as much memory. However, I suppose that the merits of the feature aren't really relevant or important to absolute beginners; it's better that they gain some understanding of how to use the feature before understanding the merits behind it. Instead, consider explaining like this: