You can't. Only an OpenGL ES Extensions could allow it, but nothing is available. This item is on the Aras wishlist (Unity Engineer). Why can't you use IOS emulator to do videos ? The emulator is often faster than real devices. 

With OpenGL ES 1.x, i gess there is no solution. With OpenGL ES 2.x, you can use gl_PointCoord in fragment shader to select a part of your texture. A typical PointSprite Fragment shader: 

Response for Android devices. Jbox2D is so bad... Since NDK is available, i use it with native Box2D. January 2010, there was a 3X factor without garbage collector lags. There is many NDK ports as in libGDX note: With 2.3 devices, the new GC fixes lags... 

Response from EboMike computed with PVRUniSCo Editor: mix() brings the shader from 4 cycles to 12 cycles (PowerVR). The PowerVR 530/535 is very slow. Andreno 200 and PowerVR 530/535 are first GPU generation (OpenGL ES 2.x) for hdpi resolution. You can't redraw a full screen at 60FPS with a simple texture. I wrote GPUBench to test shaders performance and it is very bad on these GPU. The second generation (Andreno 205, Powervr 540) is far better. Today, i try to minimize Fragment shader with one or two operations. You can try to optimize your shader because GLSL compilers are bad (on mobile platform). Note: for powervr gpu, read this document. PVRUniSCo Editor can compute cycles used in shaders. My toughts: 

I'm working on doing a simple template for OS X, Android and iPhone. It will be available in few days on my blog. The project should be easily portable on Windows and Linux because i use glfw. 

You should look the BitSquid Tech Engine. It is build using DOD concepts. The blog of Niklas Frykholm is very interesting. There are many articles on how this engine is designed. At the GDC 2011, Niklas has made a presentation about Data Driven Renderer. 

GPU are very difficult to program. You should search howto to sort a list on a GPU. Many thesis have search to do it. Use a CPU with one thread is easy, use multi-threads is more difficult, use many computers with parallel library as PVM or MPI is hard and use a gpu is the hardest. 

The problem is the Application.mk, you need at least android platform 2.0 for OGLES 2.0. In your application.mk, add this line: 

Andreno SDK provides a windows library to compress your texture without Compressonator. You can build your own tool to convert PNG, BMP, TGA or JPEG to ATITC on windows platform. Otherwise, Unity3D which is running on OS X and windows generates ATITC for mobile assets, but i don't find the internal tool which does it (No wine too). NB: our build system can compress to ETC, PVR and DXT on Win, OSX and Linux but for ATITC we zip all src images, send them to a server and use ATI Compressonator to compress them and download them when it's done. NB 2: use PVRTextTool for PVR, it is faster or better than textureTool (Apple's one). 

You can use YAAM, an alternative market, with Paypal paiement. Like the market, there is an application which manages update. For Moblox(our game) customers, it is very easy. YAAM is an open source product, so you can developp your own Market if you want. 

glDrawTexfOES is the faster method to draw efficiently quads but it is not available on old phones. VBO is efficient for static quads. If you use VBO with FloatBuffers, there is a bug on Android 2.2 and 2.1 devices which causes slowness. Use the libgdx.so, to transfert data into VBO for performance. If you use NDK, there is no performance issues. Your question is not OpenGL ES related but OpenGL Java Wrapping issue. Ps: in efficient opengl es 1.x engines, you have a tool to batch drawcalls. It is recommanded to limit your drawcalls to 50. Ps 2: the FloatBuffers is very slow on android devices < 2.3. The libgdx has rewritten this part to speed its engines. You should look this issue. 

You should port your game on Desktop. OpenGL ES 2.0 can be easily port on OpenGL 2.1. With a desktop version, you can use many tools to debug and profile your OpenGL code. Yes, it is a lot of work but you will develop quicker with a Desktop port. If you refuse to port your OpenGL ES code, there are OpenGL ES emulator on windows too (Theren't android emulators). $URL$ Note: With a video capture tool, you can't expect 30FPS. Only hdmi output present on many devices can help you... Note 2: an OGLES 2.0 android emulator with hardware support is in the google labs, but no availability date. 

Angry Birds is written in C/C++ and use its own 3d engine. For the physics part, rovio use Box2D. For the iphone version, they use ObjC to initialize the application and create the OpenGL ES context; otherwise it is C/C++. If you want to develop your own game, it is easier to use Unity3d. If you need OpenSource library, use cocos2d. Ps: You can find interesting symbols in .so of the android version. 

Try Adobe Air. With the end of mobile Flash, Adobe recommends to use it. With Adobe Air, you can develop standalone apps for many platforms (Android, iOS, BB, ...). I'm not a great fan because of performance... Pro: 

In my OpenGL ES 2.X engine, i compute the MVP matrix (Model View Projection) on CPU Side and inject it in vertex shader. The Orthogonal projection is a 4*4 matrix. When i have the MVP, i inject it in the vertex shader with: 

The mMvp is my matrix 4*4 on CPU side. The getUniformLocation can be done only one time after you have loaded the program shader. An example of vertex shader: 

Most of these games use the famous "Mode 7" tricks. It is just a rotozoom. This operation was done by coprocessor on console so it was very fast on these hardwares. Real 3d operations were too costly. But with actual hardware, it is easier to simulate with real 3D. A rotozoom is a rotation and a zoom on a sprite. Look this explanation or this SDL implementation. Search on google "MODE-7 floormap" to find samples and code. F-Zero Mode 7 was one of the first game to use it on snes. 

Don't use Renderscript for gamedev. It doesn't use GPU today and it is not portable. libgdx author has tried Renderscript and there is an interesting debate. 

Use honeycomb API. There is an option do preserve your OGL context. Otherwise, you need to reload your context. It is not difficult nor painful. You need to understand that there is a two cases (Android 2.1): 

Frame Buffer Object allows to create a texture where you can draw. That is Render To Texture. It is very fast (no use of CPU) and useful for mirror effects or post 2D effects. But it is a gpu object so you can access to its content with CPU; you need glReadPixels if you want to use it on CPU. the main advantage is you can set your size. So you can create a small FBO for a good framerate. 

ETC1 textures have no alpha channel so we use a special shader with two textures (rgb texture and alpha texture). Compressed format are very easy to load (100 or 200 loc). On desktop, DXTC (S3TC) is present on many cards. So, you shoud use it. Compressed Textures Pro 

I use this method for Moblox and paint levels with these boxes. For best rendering on most phones, my bounding boxes have 1.66 ratio. With ratio 1.33 or 1.77 phones, there are background elements not visible but i have designed my Level with centered actions. So players don't care. 

Operations with signed or unsigned int have the same cost on current processors (x86_64, x86, powerpc, arm). On 32bits processor, u32, u16, u8 s32, s16, s8 should be the same. You can have penalty with bad alignement. But convert int to float or float to int is a costly operation. You can easily find optimized implementation (SSE2, Neon ...). The most important point is probably memory access. If your data doesn't fit in L1/L2 cache, you will loose more cycle than conversion. 

Image texture format is a performance choice too. I recommend you to use compressed textures as much as possible. On mobile platforms, it can improve greatly performance (40% or even more), memory usage and time loading. Consider a texture 1024*1024: 

For particle computations with OpenGL ES 2.x (iPhone 3GS, 4 or many Android Phones), you can use the vertex shader but the equation must be very simple and depend on few variables. The main idea is to send parameters with uniform or attributes: 

You can read my old tutorial with code and the phil hassey blogs about porting its game from IOS to Android. 

The gl_Position is a special predefined variable. It must contain the position of the vertex. An example of fragment shader. For each point to draw, the final color "gl_FragColor" must be computed: 

On OS X, you can use PhysicsEditor. It is a tool for Box2D or Chimpmunk but there is a txt export for your need. The main difficulty is to find a mac. Note: there is a windows version too. But i didn't use it. Try it and add a comment if it is useful. 

But at least, you can use OpenGL 2.1 on every recent mac. Note: OpenGL is the desktop version, and OpenGL ES is the mobile one. Don't use ES on desktop platforms. Ps: if you have a GMA 950 Card (Intel chipset), you should have problems. Don't support them. On my mbp, it is: 

The main problem is Fillrate. On mobile GPUs, your fill rate is low that you can't do Deferred shading in realtime at native resolution. On iPhone 4 & iPad 1, fillrate is just ridiculous. The only device IOS with good fillrate is iPad 2, but i doubt there is enough... On android, only Tegra devices have the GL_NV_draw_buffers to use MRT but fillrate is very low too. The Mali 400 seems to have the best fillrate. If you want cry, just try to fill a color rectangle at fullscreen resolution 4 times... Many devices can't do it 60 fps. On desktop GPUs, you have 10 times (or more) fillrate as mobile gpus. Don't forget that mobile GPUs use the same memory as CPU and you don't have dedicated memory. There are some examples in WebGL (same API) so that isn't a limitation of the API. 

So as you, all transformations are done by the CPU for OGLES 1.x or OGLES 2.x. If you have neon instructions, you can use them to speed your computations. Ps: on iphone or android devices, i'm not CPU limited but fill rate limited. So it is very important to limit overdraw. 

I'm a developper of Iopixel (formely Ellismarkov). For moblox, we use my own port of Irrlicht for Android for code base but we rewrite parts of Irrlicht for better performance and better iOS/Android compatibility: 

Android uses its own Java like implementation. You write Java syntax code and can use Many Java APIs, but there are many differences: