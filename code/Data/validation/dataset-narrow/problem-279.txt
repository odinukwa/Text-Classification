You can create a username and password also provide grant access to them. so that all clients can access the mysql from their local by using the username and password provided by you. 

If you anticipate that your database file(s) will exceed more than 1TB in size you should configure the server to put the data files across multiple VHDs. How can spread my databases across multiple VHDs? Create one or more dynamic volumes consisting of multiple VHDs at the operating system level and put your database files on these volumes. Split your tables and indexes into separate database filegroups and then place those filegroups in different files (MDF + NDF) which are spread across separately attached VHDs. Note that this will not offer any benefit for transaction logs because SQL Server does not stripe across transaction log files but uses them sequentially. If you are migrated to Azure and want to compare the performance of your databases before and after the migration then take a SQL Server baseline(enter link description here) 

In your relation schema, there are three candidate keys: , and . Since, for instance, violates the BCNF, we can decompose the original relation in: 

The answer is yes. Here is an example. Suppose that you have a table , with columns , and also a table , that contains additional information about certain special projects, with other columns, referenced by other tables, etc. So you have in this table a foreign key for the table, which contains the “general” informations about those special project. This foreign key, let’s call it FkProjectId, is also a primary key for the table. 

Has every functional dependency a left hand side which is a superkey? If this is not true, are the attributes on the right hand side prime attributes? (i.e. belonging to any key?). 

Note that this decomposition preserves the functional dependencies. Addition How the decomposition is obtained? Starting from the original relation: 

The only candidate key of your relation is {D DA HA L NF} (perhaps with R you mean D?) You can verify this by calculating the closure of those attributes, {D DA HA L NF}+, and seeing that it contains all the attributes, while, if you remove any one of them, the closure of the remaining set does not contains all the attributes (this is the definition of a candidate key). The relation is only in first normal form, since the second normal form requires the absence of partial dependencies, that is of dependencies in which non-prime attributes (i.e. attributes not belonging to any key) depends only on part of a key. In this case only the last functional dependency is not partial. 

Hi I need to set auto increment for a table as S1. I tried by altering the table and also by creating by new table I am aware how to set auto_increment but when i try to set auto increment as S1 i am unable to do. since i need the primary key values should be S1,S2,S3 as following records. can any one please suggest the data type for that, 

This error happens when Full back up is not restored before attempting to restore differential backup or full backup is restored with WITH RECOVERY option. Make sure database is not in operational conditional when differential backup is attempted to be restored. Please have a look on the below blog. $URL$ 

WITH (NOLOCK) is the equivalent of using READ UNCOMMITTED as a transaction isolation level. So, you stand the risk of reading an uncommitted row that is subsequently rolled back, i.e. data that never made it into the database. So, while it can prevent reads being deadlocked by other operations, it comes with a risk. In any application with high transaction rates, it's probably not going to be the right solution to whatever problem you're trying to solve with it. SQL Server 2005,2008 and 2008 R2 will support Nolock. Pl look on the below link $URL$ 

To bring a schema in 3NF, first you have to find a canonical cover of the dependencies. Then, you can apply either the “analysis” algorithm to find the Boyce-Codd Normal Form (which is more strict that the 3NF) or you can apply the “synthesis” algorithm to find the 3NF. In this case, both the algorithms gives the same results. Here is a canonical cover of the dependencies: 

The algorithm that decomposes a relation schema to produce the BCNF operates in the following way: at each step, a dependency is searched that violates the Normal Form. If one if found (as in the example), the schema is decomposed in two subschemas, one with the attributes of , and the other one with the attributes of the relation minus all the attributes determined by . Then the same steps are applied to all the schemas obtained, while there are other dependencies that violates the BCNF. So, in the example, the original schema is decomposed in the following two schemas: 

part, since it does not change the result of the query, but only slows down its execution. Another possibility is to rewrite the query by using a join instead of a IN: 

It will ask for password don't enter anything first time because it will use blank, n just press enter you are done. N later you can set password too...:) 

I am getting the below error in mysql while trying to ping. i am using mysql version 5.5.37-0ubuntu0.12.04.1. when ever i use mysqladmin i am getting the below error. Please suggest how to clear this issue 

Error Cause: The control file change sequence number in the log file is greater than the number in the control file. This implies that the wrong control file is being used. Note that repeatedly causing this error can make it stop happening without correcting the real problem. Every attempt to open the database will advance the control file change sequence number until it is great enough. 

The error (2003) Can't connect to MySQL server on 'server' (10061) indicates that the network connection has been refused. You should check that there is a MySQL server running, that it has network connections enabled, and that the network port you specified is the one configured on the server. Start by checking whether there is a process named mysqld running on your server host. (Use ps xa | grep mysqld on Unix or the Task Manager on Windows.) If there is no such process, you should start the server. If a mysqld process is running, you can check it by trying the following commands. The port number or Unix socket file name might be different in your setup. host_ip represents the IP address of the machine where the server is running. 

And since this is an exercise, I will leave to you the task of projecting over , and , and discovering how the natural join of the three relations differs from the original relation . Finally a terminological note: a relation instance is not an array! There is no order in the rows or the columns of a relation, while in an array the order is essential. 

A multivalued dependency A->->B means that each value of A determines a set of values of B (and not a single value of B as in functional dependencies). For instance, suppose that have an attribute and an attribute , and each programmer can know several languages, you have the multivalued dependency: programmer-id ->-> know-language So, supposing that the programmer with program-id 7 knows SQL and Ruby, this means that in a table in which you have both attributes and , every time there is program-id 7 there must be two different rows, one with language 'SQL' and one with language Ruby, and all the other attributes equal: 

I had some changes in that table and it got executed. mainly the primary key. pl go through the same, 

Your BHCR is 98.92% its perfectly Good and Great. If the value of the Buffer Cache Hit Ratio (BCHR) counter is "high", then SQL Server is efficiently caching the data pages in memory, reads from disk are relatively low, and so there is no memory bottleneck. Conversely, if the BCHR value is "low", then this is a sure sign sign that SQL Server is under memory pressure and doing lots of physical disk reads to retrieve the required data. Prevailing wisdom suggests that "low" is less than 95% for OLTP systems, or less than 90% for OLAP or data warehouse systems. You can also test the true nature of the BCHR 

Try the above query in terminal or check the below link to repair table or databases via phpmyadmin $URL$ 

Check the insert query for teams field you have mentioned values as 1 and if you insert the same value for second record it will behave as below. 

I think the best option is the first solution, since the field is a VARCHAR: this means that no significant amount of space is occupied if the value is NULL. On the other hand, with the second solution you have a table more to maintain, other indexes, need to join if you need the value, etc. Too much hassle for a problem that can be solved in a very simple way. 

The relation has 20 tuples. Note that the key of One is (it is underlined), so we are sure that each tuple has a different values for , so the cardinality of is 20, but it could have the same (or different) values for , so we know with certainty only that it has at least a value for (see the example of @ypercubeᵀᴹ). Since we know that ⊆ , we know that must have at least one tuple, and possibly more. Note that the fact the is a not a key of relation means that there could be many tuples with the same value of this attribute. 

I had created table with engine BLACKHOLE basically the BLACKHOLE storage engine acts as a “black hole” that accepts data but throws it away and does not store it. Retrievals always return an empty result. I heard that we can retrieve the data by creating a new table same as the old table with storage engine as innodb or myisam. but i had tried that also but unable to get the result. Can any one pl help me on this issue to fix it. 

If the tables were dropped, ApexSQL Recover can recover them even from databases in the simple recovery model. ApexSQL Recover can recover both table structure and table records On the other hand, ApexSQL Log cannot recover records lost when a table was dropped, it can only recover the table structure In case the records that were lost using DELETE (not DROP TABLE), both ApexSQL Log and ApexSQL Recover can help The advantages of ApexSQL tools over recovery to a point in time is that ApexSQL will recover just the tables you specify (creates CREATE TABLE and INSERT INTO scripts) , while a point-in-time recovery will roll back all the transactions that happened in the meantime A DROP TABLE statement marks the MDF file pages used by the dropped table for deallocation. These pages are actually still in the MDF file until overwritten by new operations. To prevent new operations overwrite the data necessary for successful recovery, we recommend creating a copy of the original MDF and LDF files immediately