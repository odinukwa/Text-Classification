The type is a union. Only a single member of the union can be active at any point in time. Your crash is likely because you are accessing the member when it isn't the active member. The proper way to do this is to check the event's field before accessing the rest of it: In practice you'll probably want a switch statement in there as the number of events you have grows. 

Ignoring the possibility that needing these tiles may itself be a bad design (with the names you have chosen it's hard to tell the details of these classes) for the moment...if needs a list of walkable tiles, then it needs a list of walkable tiles. It is generally better to make dependencies more explicit than less so, as it makes code more self-documenting. By passing the list directly to , you explicit call out the fact that it needs such a list. If you instead make everything static and public so you can just access the static list held elsewhere in the code, all you do is hide the dependency without actually solving or removing it. For a small game that doesn't need to scale this won't be a problem, per se, but it may lead you down the path of a bad habit so you may want to consider not doing it. At the very least keep this in mind for the next project you work on. 

No, not really. Game developers have not traditionally been great at respecting the conventions established by an operating system. Although to be fair, lots of regular application developers don't either. The and documents folders are for saving per-user data. The difference between them, for the purposes of this question, is primarily that is where stuff the user should not need to see or interact with goes, and the documents folder is for the user's documents: stuff they'd want to see and interact with. Games will sometimes store their settings and save files in the documents folder because it makes them visible, so less technical users will see them and be reassured that they do exist, or will be more likely to correctly back them up if their backup method is a crude, "copy the stuff in my user folder to another drive." Games will also sometimes store files there because they haven't changed the behavior of the relevant code from older OS versions, as you suspect, or simply because they don't care to think about the problem that much. It's silly and usually wrong, but it is what it is. 

In the resulting window, set the provider to Git (you'll want to make sure you have Git installed; if you do and have your Git configuration set up, it will populate everything for you). Make sure the checkbox to generate a is checked, and hit accept. It will do all the hard work for you. If you aren't using the editor, if you're working directly with the engine from source or something, or you just want to do everything yourself, you'll want to set up a that basically excludes all the generated/intermediate file directories, like this (which is basically the one the editor would set up): 

Actually, while C++ is an important language for anyone aspiring to enter the field professional, it is by no means the language you have to learn to make games and, in fact, makes for a rather poor first language (primarily due to its complexity, the wealth of incorrect/poor information on the language out there, and most important its cultural penchant for assuming the programmer is right, which is bad for a neophyte). 

Many (especially older) cartridge-based consoles have homebrew development subcultures that have built CompactFlash-based cartridges that you can purchase, load up with your home-brew ROM, and insert into a (usually modded) system. For the NES, the most popular option seems to be the PowerPak from RetroZone. It does not appear to require a modded NES, since the lockout chip for the system has been circumvented. You could, of course, also build such a cartridge entirely yourself if you had the requisite engineering knowledge and equipment. But buying one is probably much easier. 

The color resolution (bits per pixel) of a surface is strictly bound to the format of that surface, yes. You can use CheckFormatSupport to determine what formats are available for what uses at runtime. 

There are many, many ways to approach this, depending on the needs of your game and what you want the API surfaces to look like. This is also not a problem that really has anything to do with entity systems. A physics API should maintain a list of physics object (often "rigid bodies"), detect, and resolve the collisions between them. The API can be a "system" in the common component-based parlance, or not. A physics object can be a physics component or not. It doesn't matter: the solution is the same. You don't want the physics code itself to know anything about the interactions between specific objects, beyond the fact that they collided (and perhaps some metadata about the collision). Instead, design your physics API to support the notification of a collision to interested parties, who can subscribe to events on the physics API if needed. You can implement this behavior with the observer pattern. Thus you delegate the processing of the interaction elsewhere. In whatever higher-level code deals with the interaction now (typically something more at the "game" level), you can employ techniques such as double-dispatch to resolve interactions between two runtime component types (normal dynamic dispatch in C++ and most languages is done only on a single parameter, the pointer; double-dispatch is a way to perform dynamic dispatch on two parameter types, which is all you have varying in the case of two objects interacting). Back in the physics system itself, you can avoid the n-squared problem of checking every rigid body against every other rigid body using spatial partitioning techniques. By dividing up your simulation space into distinct regions (for example using quad-trees or oct-trees, or even simple separation-of-axis approaches) reduces the problem space for detecting collisions by immediately discarding large numbers of objects that cannot possibly collide. 

This isn't something WPF is particularly well-suited for; it's 3D capabilities, while backed by hardware acceleration eventually, are very abstract and high-level. Using only technology built-in to WPF itself, your best bet is probably to leverage the class. This object has a list of 3D positions and a list of indices into that 3D position list. Every three indices into the position list define a triangle with the three referenced position points. Thus, you'd need to: 

To specify that face without indices, you must specify the vertices . Two vertices ( and ) are repeated in the vertex buffer. However, with indices, you can have a vertex buffer containing only the required vertices (, , , and ) and six indices: . Since indices are generally much smaller than vertices and many vertices generally repeat in practical models, this can be a significant space-savings. Note that some vertices will only share partial attributes. For example, when rendering a cube with texture mapping, one generally wants unique texture coordinates per face, so you will have multiple vertices with the same position and different texture coordinates. That amount of duplication is acceptable and necessary; it's when you duplicate an entire set of vertex attributes that you'd start to see benefits from indexing. If indeed all your mesh vertices are 100% distinct, there is no benefit to indices (in fact you'd use more space in the consumption of the redundant index buffer). This doesn't always occur, however. 

The idea of using a separate transparency map is a bit of a throwback to an earlier era, where we would use black-and-white bitmaps as transparency masks to draw sprites. That said, it's still a perfectly viable technique today. There's really no appreciable performance difference between using a color and alpha map versus one color map containing alpha as an additional color component. There may be some minor issues regarding disk or memory footprint, but those will mostly be irrelevant in the grand scheme of things. A good reason to use separate image sources like this today is not for game runtime performance but authoring performance. If you only have tools available to you that don't work well with images containing alpha channels, or you simply prefer to work this way, it can be more efficient for you to do so rather than in a context where the alpha is embedded into the color. Similarly if you've chosen a particular image format that doesn't support embedded alpha channels for other important reasons, you may end up using this "separate mask image" technique. 

You're calling SetTexture in your main program (effectively). This binds the texture to a sampler index, not a named sampler variable in shader code... you're not assigning in the shader anything. So when you sample it, you get black (all-zero) and multiplying all-zero the way you do will of course still yield all-zero. You could confirm this by simply outputting a flat color from the shader instead -- don't multiply by the sampled color -- and you should see something. To fix this, you could use the Effect interface and call SetTexture on a compiled effect, or you could indicate that your sampler should be bound to register 0 (which is what you're setting the texture to): 

You're only seeing the top layer of your data from the overhead view because your depth buffer is enabled. One way to fix this and possibly achieve the result you want is to disable writes to the depth buffer when rendering that volume data: 

I would avoid offers rewards of a physical nature unless they are very simple to product (like stickers). Anything that will incur a manufacturing cost and administrative time on your part probably aren't your best bet; you have to pass those costs on to your donators and you rarely end up with very high-quality results. Above all, try to tailor your rewards to what is unique or compelling about your game in some fashion. It's hard to provide many suggestions without knowing more about your game, but making sure the rewards jive with the brand and feel of the game itself can really help establish a firm bond between the donator and your project which will help keep them interested and more likely to spread the word around. 

is a packed integer data type. Elements of this type in a buffer need 32 bits of space, with the Z, Y, and X (or B, G and R) components packed respectively into ten bit chunks starting at the low bits (that is, Z is bits 0 through 9, Y is bits 10 through 19, et cetera). The W (or A) component is stored in the high two bits (30 and 31). The "REV" suffix refers to the fact that the data is "reversed," because the Z component is stored in the least significant bits. This format allows higher precision in the XYZ/RGB channels at the cost of precision in the W/A channel. The pipeline will unpack the channel data and apply normalization back to ( for the unsigned variant) if you ask for it (using the parameter of ). Other than that, and deciding in your shaders to accept them as normalized floating point values or their original fixed-point integer values, they should not require special handling. 

It's not really, strictly speaking, Unity's problem but they may be willing to help you out if you explain your situation. 

If you are not keen on building all that yourself, something like the iOS bridge, or just resign yourself to building your GUI with Unity's built-in primitives. 

They're both similar, in that they are both parallel projections (lines that are parallel in the source are parallel in the projection). In a parallel projection of onto the plane becomes . When and are equal, the projection is orthographic; otherwise the projection is oblique. Another way to look at it is that in an orthographic projection, the projector lines intersect the plane being projected on to at a perpendicular angle (thus, they are orthogonal, thus the name of the projection), whereas in an oblique projection those lines form oblique angles (non-right angles) with the projection plane. 

At the time of writing, all the major current and upcoming generation consoles (but one) don't make it possible to publish indie games without paying some kind of fee. With the Xbox One, Microsoft's ID@Xbox program may provide what you are looking for. Currently, there's no explicit mention of payment on their site, but there's also no explicitly mention of gratis licensing, so you'll have to wait for more details to emerge as the console nears release, probably. Additionally, right now they are only accepting applications from developers with a proven indie track record, so you may find getting accepted difficult. Your next best bet is probably the Xbox Live Indie Games, on the 360 platform via XNA. This is not a free program -- membership costs $99 per year. If you don't mind considering portable systems, Sony's mobile developer program also costs $99 per year, but as of May 8th Sony had stated that the fee for indie developers would be waived. 

This could be what it happening to your text. Note that if true, it would be possible to eventually capture a screenshot of your text in it's blurry form, although you may have a hard time getting that to happen normally depending on the resolution at which your players end up moving in the world; you might have to set up a contrived example rendered at fixed coordinates to do so. The solution is, fortunately, rather simple: subtract 0.5 units from the components of your vertex positions in transformed screen space. Another good write-up of the issue can be found here. 

No. If you request a buffer store (via ) larger than the implementation can satisfy, you'll get a error. Buffers may be temporarily (or permanently) backed by CPU memory depending on their state, but a overly-large buffer store will never overflow out of GPU memory into CPU memory. To handle the large volume of data you're describing, you'll want to page the relevant data for your world into the GPU buffer as it becomes needed (visible / near visible), leaving the rest resident in RAM (or on disk, if that's an option). 

If the developer builds the game with the intent of supporting mods, then you can create mods through whatever means the developer has elected to support. Generally the language used to build the game and the specific technologies used to build the game (Direct3D, in this case) are not relevant to the game supporting mods in this case. If the developer does not build the game with mod support, it's still possible to alter the game but generally you will have far fewer options and all of those options will be much more difficult. At this point it does matter what technologies the original developer used. For example, it's possible to hook (using DLL injection or hooking, for example using the Detours toolchain) function calls the game makes to the D3D interfaces and redirect them, allowing you to draw extra information on the screen. You can also examine the game's data files and attempt to reverse engineer and modify them. Decompiling, modifying, and reassembling the executable or its dependent DLLs is also an option but one that sits on questionable ethical and legal grounds -- I would not recommend this approach. Your best bet would be to contact the developer and express your interest in a modding API and toolset.