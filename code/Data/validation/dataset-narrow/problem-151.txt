If you didn't have an interface locally that was available to respond to ping, you wouldn't be able to use it. The functionality might exist in a an ASA to use a random addresses, presumably for security auditing reasons. It would look similar to this: 

RFC 2328, A.3.2 The Hello packet The field is populated with the subnet mask you're using with that interface. CIDR Notation is nothing more than a shorter version of your subnet mask for the sake of brevity. And for that matter, subnet masks are just a condensed version of bit positions. Imagine having to write in decimal every time you wanted to configure a port. 

EANTC: Cisco Catalyst 6500 with Supervisor720 — 10 Gigabit Ethernet Performance Test Although this doesn’t show latency, which would be the real testament to the speed of these platforms, they do say go on to say “Catalyst performance unaffected by the addition of value-added services such as ACLs, QoS traffic classification and NetFlow Statistics gathering.” Once you look to add additional flexibility, such as extended ACLs, you require additional checks against the data. This adds latency. The key is that you choose which is most appropriate for the application for your business requirements. Not everyone needs an extended ACL when a standard ACL will do. As most indicated in the comments, the amount of routines a router will need to go through every moment dwarfs a file system ACL in pretty much every way. Does this mean they’re better? Not necessarily. But they are certainly faster at what they do, just limited. 

is a virtual interface that’s used to guarantee routes make it into the RIB; remember, routes must have a next-hop in order to make it into the RIB. When a packet arrives at a device that has a route to and nowhere else, it will discard it similar to how an ACL would. Think of this as the virtual interface where packets go to die efficiently. Most routing protocols, such as EIGRP, automatically generate a Null 0 route when summarizing addresses. 

To confirm it's working, you should see something similar to this. Note the additional entry on the forwarding table for entry . 

I’ve never heard the term switch-back-delay, nor can I find anything referencing it on the internet or in RFC 5798. The you’re really looking for is Preemption Hold Time. This is the time a higher priority VRRP speaker will wait until preemption of the mastership role happens. There isn't a hold timer reference in the RFC, so that’s a vendor specific implementation. VRRP only operates in 3 different modes. 

Your Juniper EX2200 console connections will use the same connection you use when logging in remotely. Getting is completely dependent on your setup. The following syntax would prevent root login: 

If you are referring to a possible performance penalty on your firewalls ability to process packets, then there shouldn't be any for this simple of an operation. The only time that would come into play is if you begin setting up multiple filters to inspect packet headers in real-time on multiple SPAN ports. By the sounds of it, you're only looking to SPAN traffic egressing your network onto a specific port. 

When pinging the multicast address of , 3 replys came back; sent a reply, sent a reply, and replied to itself because it is also listening for that address. 

No, you don’t need to. WAN, in this sense, is just blocking inbound requests by default. I’ll assume the reason you’re using pfSense is to perform routing functions between those 2 networks (?). If you aren’t using it for any real firewall functions, then you would be alright to, technically, just use multiple LAN interfaces. 

I would argue that a sender refusing to abide by congestion control algorithms is attempting a DoS attack. To me, it's akin to saying "I don't care if you're getting too much data, out of order, and with missing data. I'm just going to send it anyways, even if you don't accept." If you get the time, RFC 5681 isn't that bad of a read. Especially if you need something to help you sleep. The good thing is that a sender that falls into this category is going to be sending more than it's receiving, meaning you can drop traffic before it reaches your border without much effort. This is also easy to detect if you're monitoring your hosts bandwidth usage. If you were the receiver, however, you might have a little more of a difficult time. This is something webmasters constantly battle with. 

Getting a printer on 2 VLANs at the same time isn't practical. Unless there is some limitation between the VLANs (i.e. ACL), your easiest option is to just put the printer on one VLAN, and then get the people in the neighboring VLAN to communicate with it through the router. PfSense can certainly route between VLANs, so you shouldn't have any issues. 

This is the most difficult part for people: If the facts don't add up to legitimately support your case, then perhaps there aren't any serious issues and you should really consider if it's as bad as you're making it out to be. We've all made things out to be worse than they are from time to time, but if you find yourself digging deeper and deeper for an issue, then maybe there isn't one. If the facts do add up and they still don't want to take action, then just wait for the day you can say "I told you so... err, with all due respect" and perhaps next time they'll listen and take your proposals more seriously. 

I think John Kennedy is right, there isn't anything out there that seems like it fits the bill on your questions; but I'll give a wag at it anyhow. 

Judging by your comments, you're simply trying to simplify your initial statements. The easiest solution is to use the statements released after 12.1. Example usage: 

The command is used to load configuration files on boot. It should have no impact to your current configuration unless you reboot. It's worth noting that even Cisco considers configuration autoloading an unneeded vulnerability. It's default is off, and probably for good reason. 

I’ve been trying to come up with an graceful way of connecting these points. How do I make this a reliable connection and look professional? What have others done? 

Based on your comments, the default ACL didn't load into your configuration, for whatever reason. The behavior for the feature is to use a quiet mode after certain parameters have been violated. In your case, after 3 failed attempts within 60 seconds will apply a quiet period ACL for 120 seconds. If you haven't explicitly defined a quiet mode, it will default to the below ACL. 

Again, while this is theoretically possible, you’re trying to sidestep VLAN separation to accomplish a test bed setup that will never reflect a real network. 

I think this approach is a little off. VLANs, in their simplest form, are simple to configure and associate with their respective ports. You mentioned that this is a L3 switch, configure some switched virtual interfaces (SVI), put the VLANs on different subnets, and route between the VLANs. 

The interface appears to be a built-in Juniper sFlow sub-system that allows communication between the internal collector and agent. 

Enable Activate bandwidth management on WAN interface and declare the interface speed Generate a new bandwidth object and configure it for . Edit your default firewall rule and enable the bandwidth object you created earlier for both ingress and egress. 

I can't imagine any Tier 1 provider, in their right mind, would peer with Google for no monetary value. Ever. Google (i.e. Youtube) is a source of a large percentage of global internet traffic, 11% back in 2011. The premise behind a peering agreement is that 2 providers transmit an equal amount of each others traffic for a few reasons. But most notably, redundancy and performance. When you have one peer in this agreement making up an unbalanced source of internet traffic, you begin to get ugly disputes, like the one between Cogent (Netflix's ISP) and Verizon. 

Create object Create object Match that Action object to the sites you want (or don't want) Map the object to the object with an 

For obvious reasons we aren’t going to automate this entire process for you, but this should set you off in the right direction. 

Based on your comments, everything looks correct. Althought 50.50.50.50 may not have a direct/learned route to 2.2.2.2, he does have a default-gateway set to 14.0.64.2. 

We recently had a sporadic reboot of a distribution switch for an unknown reason. No recent hardware/software changes have been made. Our log files don't indicate anything leading up to the incident. The system is a 6509-E running software version 15.1(1)SY on both active and backup supervisor modules. The system had a primary and backup supervisor card (SUP720) running in SSO. The system was actively functioning in Standby Hot, but the Backup RP never took over as the Active RP, which caused a complete system reboot. The backup RP eventually booted back up and came back online with the most recent configuration, but the primary supervisor card slot won't boot any cards. We replaced the card with the same card model with no luck. The cards were all tested on a backup 6509 chassis, all of them booted without any issues; which eliminates the possibility of a faulty card. When trying to boot the cards on this chassis, this is as far as we get: 

RIP, in and of itself, is an application, but it supports the network layer of the OSI model. There are daemons you can download on your computer, like routed, that allow servers to talk to other RIP processes. Just try to understand the theory that each application/daemon supports a different purpose (or layer) of the OSI model. I hope this doesn't add anymore confusion... 

No, that isn't possible unless they know (or obtain) the shared secret. Cisco outlines how the authentication takes place.1 

This issue is a result of the engine-id changing. If you run into this syslog message, that is the exact definition of the problem. 

Juniper would never be able to automatically associate a VLAN name to a VLAN tag by default. If you just specify a VLAN by name, there isn't any way to figure out what VLAN that traffic belongs to. 

We're having issues where SNMPv3 ceases to accept SNMP requests on our Juniper EX series switches. In what seems like random occurrences, Juniper nodes refuse SNMP authentication credentials. This is what we end up getting: 

They have a pretty simple writeup over at Networklessons, but in-depth information on how it works are on Cisco's site. It can be as complicated and secure as you want it. Your 2 questions are one and the same. A barebones config would be like this: Create a group 

Cisco You should be able to use the OIDs under 1.3.6.1.2.1.15.5.1 (bgpPathAttrEntry) for Cisco devices. There are 2 OIDs in particular that should accomplish what you're looking for. 1.3.6.1.2.1.15.5.1.1 (bgpPathAttrPeer) - The IP address of the peer where the path information was learned. 1.3.6.1.2.1.15.5.1.2 (bgpPathAttrDestNetwork) - The address of the destination network. 

End-user computers, generally, do not require this level of redundancy. You would see this level of fault tolerance in a stacked/chassis setup for something like a server farm. You would have two routing engines, two power supplies, multiple cards and multiple links to that node with 802.1ax (i.e. LACP/PAgP) to help protect you in every instance from an outage. If you want redundancy, split the network into two. Have half your connections going to one switch, and the other half going to the former. 

An archive at SourceForge has the below command output snippet that shows a connection between and port (sFlow port)1: 

This is a completely viable network buildout. In this instance, the STP election process would be drastically reduced because most of the processing has been pushed to , thus, almost completely eliminating propagation delay and requiring the bare minimum amount of BPDUs. Imagine again a more sophisticated network topology by simply extending the first: 

If I'm reading what you wrote correctly, both of those solutions appear to be pretty standard. If you're working with a fixed amount of addresses, then you're left with 2 options - NAT or assign only when necessary. Assuming your routers are capable of handling however many clients you need to NAT, then this option is totally viable. Probably the easiest too. You translate your addresses from an large scope to publicly routable addresses. Changing the DHCP lease duration might even become unnecessary. If you have devices that absolutely need addressing from a predefined subnet, then you can always hand out this address range to the devices that need it. Oftentimes, phones and printers don't fall into that category. You stand to reduce address consumption by a significant margin if you get stingy with addresses. 

There will always be overlap between these departments, nearly without exception. How much that overlap is depends greatly on what the organization is. Why would your IAO not be concerned with what the configuration of your networking equipment looks like? Insecure SSH configurations, absent port-security config statements, and switch/router versions are all things a security professional's job entails. The same can be said about servers. On the flip side, there are portions of the Firewall that might be prudent for your network admins to get involved in (such as passively monitoring traffic).1 The IT field is one that requires a great deal of lateral affluence, so everyone is usually all up in everyone else's cool-aid. 

These are BPDUs sent from the switch to detect another device that's also transmitting BPDUs. If you don't want your switch transmitting these and you have a cisco device, place this configuration on any applicable switchports. 

I'll reiterate what I said above, a host attempting something like that should be considered compromised. That is abnormal host behavior. QoS will help to minimize the internal impact, but having control of your hosts is even more vital (not to mention CYA when your ISP comes complaining). 

Everything comes out to the same thing in the end. So having these shorthand ways of representing the same data just makes sense. 

To kill it as soon as possible. If you drop packets furthest down the path, you'll be wasting bandwidth (perhaps valuable), that could have otherwise been dropped sooner with no ill effects. As a heads up, this mentality isn't just limited to extended ACLs, it applies to all ACLs. There isn't any good reason in waiting to drop traffic. 

seems like your easiest option. Point it to something outside of your network (like google). Using that will resolve any device along the path. 

We currently have a bunch of Tripp Lite UPS that we’re preparing to deploy emergency power off capabilities to throughout our network. I have been provided Normally Closed tail circuits to connect to our UPS equipment. This is the diagram displaying the wire order from the voltage source. 

Running gives a more detailed output of . Note that both active and backup are running the same software versions, 15.1(1)SY. 

Damon, I'm afraid there is something wrong with your specific implementation. I, personally, can't think of an instance where a router doesn't respond to an icmp request on any of it's interfaces. Others, please chime in if that's inaccurate. At any rate, I mocked it up in GNS3 to make sure there weren't any funky software bugs.