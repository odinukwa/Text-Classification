Alternatively, you could try writing an app to help you out (in the onCreate()) have not tested in Android things though: 

That web page is looking at the versions of Raspbian. Pixel is a desktop environment. Recently Raspbian Stretch was released and can be seen on the page you referenced by the latest folder date (2017-09-08). So you would be able to get Pixel (the desktop environment for Raspberry Pi) on Stretch or on later versions of Jessie. According to the Raspberry Pi web site, all you need to do yo update the version of Pixel is run the following commands: 

This website gives a few examples: Computer hope. Also, as stated in the comments perhaps you should try typing: 

Unfortunately, this doesn't work. Even though it seems to be replicated in many tutorials and blogs. However if I take the GROUND from the 6v and attach it to the 5v of the Pi, my creation can't go fast enough: 

I have since moved on from this technique. But the problem with this code is that the c program sets the PWM and then exits, meaning that any memory and control is released from the application. Therefore the GPIO pins just retain their state when the application terminates. 

Open up a terminal and type Log into your Pi from your laptop with the default username 'pi' and password 'raspberry' 

If you don't want your password stored in plain test you can generate the hash on the command line (and assuming you have the SD card mounted (I stole this from a script I wrote): 

Let's tackle counting frames before anything else as that's relatively easy. The Pi's YUV format is YUV420p which uses 1.5 bytes per pixel, so as long as you know the resolution you recorded at and the size in bytes of the final recording, we can easily work out how many frames there are. For example, I've just made a test recording in YUV format on my Pi at a resolution of 320x240, and the resulting file is ~167Mb, so the number of frames is: 

Despite producing 40 frames per second of image data in numpy arrays, the CPU usage of this script is minimal. Comment out the print statement, which is actually quite CPU heavy, to see the overall CPU usage: it's about 2% on my Pi3 so there's plenty left over for whatever image processing you want to do. 

Media center is already there: OpenELEC. For calling: no, that's a much more complicated proposition and there's no "simple" way I'm aware of at the moment. 

The problem (and I've just noticed this is also a problem in the other post, which I missed in my reply to that one) is that you're setting after setting . Here's what's going on under the covers: 

starts off as True The loop tests ; it's True so we continue into the loop We read the state of GPIO18. Let's assume it's True for now (i.e. the button isn't pushed, given the reversed logic of a pulled-up circuit) The first statement tests but it's False so we skip down to the next statement. The second statement tests . That's True so we continue into the body of the statement. is called which will halt the program until Enter is pushed. 

I may be wrong there, it could just be formatting on the question (your if's CONTENTS required no indentation). 

EDIT If you REALLY want to avoid the use of extra cables, you could mount the SD card to your normal pc (assuming linux I show how to mount here) and add the following to /data/misc/wifi/wpa_supplicant.conf: 

There are other logical problems as well. My Python isn't great but it looks to me like the IF statements that control the LED pin are unreachable due to the WHILE TRUE loop. Maybe they should be indented too? 

So I had a look and the "hat" (Hardware Attached on Top) seems to occupy all the GPIO pins on the Pi, but there are some exposed on the hat itself: 

I have the following code which I use to run some DC motors on the Raspberry Pi with an L293D H-Bridge. I should be able to control which motor is driven and in which direction. 

And my code (simply) is like below. You can check out the sub project as well but that has other stuff in it like hosting it's own web site and displaying on a Nokia 5110 screen. 

What I recommend is that you time the gif's so they only play once, since they seem to repeat, also they are different lengths so you want to make the delay a variable. Here is a basic solution: 

I have written a small C application to do PWM for some motors connected to a Raspberry Pi. I am using the PiGPIO library. The code as follows: 

There's no way I'm aware of to plug the camera into a normal computer; the interface is quite specialized, and as I understand it the vast majority of the camera's functionality is implemented in the Pi's GPU rather than on the camera's ISP. That said, shipping data from the Pi's camera to another machine for processing is quite easy. 

It shouldn't be too tricky to adapt this to loop over the frames of the file, reading and converting each in turn (obviously it'll be a bit slow on a Pi, but you could run this anywhere). 

You can use the video splitter build into picamera to achieve this. We'll set up one stream which pipes output to your cvlc process, and another which writes to disk with a resizer in the pipeline to reduce its resolution. 

For a definitive answer to this I'd recommend posting to the RPi camera forum and hoping for 6by9 or JamesH (the firmware devs) to answer as they'll know for certain what's going on under the covers. My (limited) understanding is that analog gain is the gain applied to the sensor itself and that the firmware "prefers" modifying this as opposed to digital gain (which is gain applied by the firmware to the captured data). In other words, analog gain is applied first and presumably adjusts the sensitivity of the camera, while digital gain is presumably multiplication (or some other form of scaling?) of the resulting pixel values (whether this is done to the raw 10-bit bayer data, or later on in the pipeline I don't know). The maximum value of each gain is 8.0 (and obviously the minimum is 0.0). From experience (but without any deeper insight into the underlying logic) I can say that when the firmware wants more gain (because the scene is too dark) it usually pushes analog gain up while leaving digital gain at 1.0. Only once analog gain hits the limit (8.0) have I seen it start to push digital gain up far above 1.0. That said there are circumstances where digital gain hovers around 1.1 or 1.2 while analog gain is below 8.0. Why this occurs I don't know (perhaps digital gain was above 1.0 in a dark scene which brightened and the firmware adjusted analog gain down first?) Anyway, my guess is that when digital gain is ~1.0, analog gain must be in the range 1.0 <= gain < 8.0, and when digital gain is >~1.3, analog gain must be 8.0. One interesting question which I don't know the answer to is what happens in extremely bright scenes? Does the firmware dip analog gain below 1.0, or does it leave analog gain at 1.0 and reduce the digital gain first? This isn't something I've had the opportunity to test, but I'd be interested to hear any results. If you want to have a play with this further, this little curses based script may prove useful: 

So I have achieved this by creating a Raspberry Pi Bluetooth Low Energy Peripheral device. The code is on Github for the Raspberry Pi peripheral and for the accompanying Android app. Just make sure your raspberry pi is up to date. Raspberry Pi Bluetooth Ble Peripheral with Bleno: 

where *** is the name of the deb file, as mentioned in this answer Since there are thousands of deb packages, you'll have to find the required ones for pixel in some of these lists: 

Works fine, but if I change MAX to 255 and use it only works sometimes, and when it does work only the left will run. What should I do to make them both be able to work, and work consistently? This does not work consistently when I compile and run as follows: 

Launch Remote Desktop Connection which can be found at Start->All Programs->Accessories->Remote Desktop Connection Type in the IP Address for your Pi which you noted above. Click Connect (you may get a security warning at this stage just click OK if you do. After all it is your Pi on your network so nothing to worry about security wise). Leave the Module on the default of sesman-Xvnc and enter your username and password for your Pi. (The default is pi and raspberry if you haven't changed them). Click OK and after a few moments you should be greeted my your Raspberry Pi's desktop! 

The RPi educational materials include a short workshop on using the camera module. Part of this ("Camera programming: Capture when activated") demonstrates wiring and code to take a picture in response to an external button being pushed. On the RFID side of things, it looks like the amusingly named RFIDIOt library is something that would enable Python to talk to several RFID readers. So, assuming you have a RFID reader that you can connect to the Pi (and which is compatible with RFIDIOt), it shouldn't be terribly difficult to modify the recipe to your purposes: replace with some code that waits for a valid RFID token, e.g. and you should be well on your way. You'll probably find there's a bit of fine-tuning to do (you may have to implement some form of debounce - I'm not familiar enough with RFID to know if this is an issue), and of course the script needs modifying to continually wait and take pictures instead of stopping after the first one. 

The presentation timestamp is the time according to the camera's clock. While that will be by far the most accurate measure of the frame's capture time you may not find it that much use as the camera's clock is not synced to the Pi's clock and has no idea what the "real" time is. In other words, it's just a count of microseconds since the camera was initialized. I think about the closest you can easily get to the precise frame capture time (at least according to the Pi's internal clock) will be the time that the first packet of the frame's data gets written to the requested output. You could capture this pretty easily with a custom output. For example, the following little script enhances the PiYUVArray class to include a timestamp set on the first write to the stream (it also resets it on truncate in case you want to reuse the stream for multiple captures): 

If promoted enter your password (the default is "raspberry") Type "Y" and press enter. This is now installing xrdp onto your Pi which is the software we are going to use for the remote desktop connection. Wait for it to complete. Restart your Pi. We are going to check that xrdp is going to start up automatically. When your Pi has booted to the command prompt look for [ ok ] Starting Remote Desktop Protocol server : xrdp sesman. This shows you that xrdp is installed and automatically starting up on start up of your Pi The last step is to make a note of the IP address of your Pi which should also be displayed on the start up screen. Run the command 

Now I have noticed the L293D H-Bridge getting quite warm when run like this, but not alarmingly warm. I want to know why this is happening and if I have not perhaps missed something important. I have tried having a separate pin on the Pi for pin 1 on the L293D (1,2 Enable), but the problem is the same. It's odd to that connecting a ground to live should 'fix' the issue. Please be aware I have checked my battery, it's the right way around. EDIT I fixed a mistake with power and ground on the right side of the chip. Voltages: 

It looks to me like you are not assigning your array values. Change your read_temp method to use the index you give it.